==================================================================
Running repvggA0: num_gpu_per_node = 4, num_nodes = 1.
==================================================================
dtype = float32
gpu_num_per_node = 4
num_nodes = 1
node_ips = ['192.168.1.13', '192.168.1.14']
ctrl_port = 50051
model = repvggA0
mixup = False
use_fp16 = None
use_xla = None
channel_last = False
pad_output = None
num_epochs = 160
model_load_dir = None
batch_size_per_device = 64
val_batch_size_per_device = 64
nccl_fusion_threshold_mb = 16
nccl_fusion_max_ops = 24
fuse_bn_relu = True
fuse_bn_add_relu = True
gpu_image_decoder = True
image_path = test_img/tiger.jpg
num_classes = 1000
num_examples = 1281167
num_val_examples = 50000
rgb_mean = [123.68, 116.779, 103.939]
rgb_std = [58.393, 57.12, 57.375]
image_shape = [3, 224, 224]
label_smoothing = 0.1
model_save_dir = ./output/snapshots/model_save-20210130142727
log_dir = ./output
loss_print_every_n_iter = 100
image_size = 224
resize_shorter = 256
train_data_dir = /DATA/disk1/ImageNet/ofrecord/train
train_data_part_num = 256
val_data_dir = /DATA/disk1/ImageNet/ofrecord/validation
val_data_part_num = 256
optimizer = sgd
learning_rate = 0.1
wd = 3.0517578125e-05
momentum = 0.9
lr_decay = cosine
lr_decay_rate = 0.94
lr_decay_epochs = 2
warmup_epochs = 5
decay_rate = 0.9
epsilon = 1.0
gradient_clipping = 0.0
------------------------------------------------------------------
Time stamp: 2021-01-30-14:27:27
[1mWARNING: 'flow.train.CheckPoint' is deprecated. Please use the new API:[0m
flow.train.CheckPoint().save(path) => [1m[92mflow.checkpoint.save(path)[0m
flow.train.CheckPoint().load(path) => [1m[92mflow.load_variables(flow.checkpoint.get(path))[0m
flow.train.CheckPoint().init() is not needed any more.

Loading data from /DATA/disk1/ImageNet/ofrecord/train
No MixUp
loss.shape (1,)
predictions:  (256, 1000)
Optimizer:  SGD
Loading data from /DATA/disk1/ImageNet/ofrecord/validation
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_initial_model.
Init model on demand.
train: epoch 0, iter 100, loss: 6.876171, top_1: 0.002461, top_k: 0.010586, samples/s: 2843.178 1611988173.0336897
train: epoch 0, iter 200, loss: 6.834788, top_1: 0.003906, top_k: 0.016602, samples/s: 2950.730 1611988181.7094526
train: epoch 0, iter 300, loss: 6.705215, top_1: 0.004844, top_k: 0.023242, samples/s: 2997.485 1611988190.2501068
train: epoch 0, iter 400, loss: 6.621125, top_1: 0.007773, top_k: 0.030977, samples/s: 2973.159 1611988198.8603177
train: epoch 0, iter 500, loss: 6.441760, top_1: 0.010625, top_k: 0.040352, samples/s: 2957.902 1611988207.5150886
train: epoch 0, iter 600, loss: 6.420123, top_1: 0.012812, top_k: 0.046055, samples/s: 2933.695 1611988216.241502
train: epoch 0, iter 700, loss: 6.279149, top_1: 0.014805, top_k: 0.050820, samples/s: 2912.114 1611988225.0321515
train: epoch 0, iter 800, loss: 6.358055, top_1: 0.016641, top_k: 0.060977, samples/s: 2944.972 1611988233.725033
train: epoch 0, iter 900, loss: 6.207529, top_1: 0.019336, top_k: 0.067969, samples/s: 3012.802 1611988242.2219892
train: epoch 0, iter 1000, loss: 6.227210, top_1: 0.022344, top_k: 0.078359, samples/s: 2938.248 1611988250.9346812
train: epoch 0, iter 1100, loss: 6.204092, top_1: 0.027266, top_k: 0.082812, samples/s: 2967.512 1611988259.5615382
train: epoch 0, iter 1200, loss: 6.003432, top_1: 0.027773, top_k: 0.090078, samples/s: 2984.711 1611988268.1384997
train: epoch 0, iter 1300, loss: 5.935633, top_1: 0.029883, top_k: 0.097070, samples/s: 2987.583 1611988276.7072868
train: epoch 0, iter 1400, loss: 5.963343, top_1: 0.033477, top_k: 0.106797, samples/s: 2981.894 1611988285.2924314
train: epoch 0, iter 1500, loss: 5.895234, top_1: 0.037461, top_k: 0.117148, samples/s: 2947.168 1611988293.9787304
train: epoch 0, iter 1600, loss: 5.959136, top_1: 0.040195, top_k: 0.127891, samples/s: 2950.699 1611988302.6546378
train: epoch 0, iter 1700, loss: 5.862865, top_1: 0.044570, top_k: 0.135117, samples/s: 2970.231 1611988311.2735186
train: epoch 0, iter 1800, loss: 5.766052, top_1: 0.045937, top_k: 0.144687, samples/s: 2943.332 1611988319.9712381
train: epoch 0, iter 1900, loss: 5.660671, top_1: 0.051055, top_k: 0.151406, samples/s: 2922.109 1611988328.7319226
train: epoch 0, iter 2000, loss: 5.687139, top_1: 0.055898, top_k: 0.161680, samples/s: 3014.179 1611988337.2251287
train: epoch 0, iter 2100, loss: 5.626448, top_1: 0.059727, top_k: 0.169531, samples/s: 2961.330 1611988345.869895
train: epoch 0, iter 2200, loss: 5.675904, top_1: 0.060352, top_k: 0.176445, samples/s: 2946.022 1611988354.5595624
train: epoch 0, iter 2300, loss: 5.534850, top_1: 0.066211, top_k: 0.189883, samples/s: 2992.392 1611988363.1146398
train: epoch 0, iter 2400, loss: 5.618894, top_1: 0.067266, top_k: 0.190664, samples/s: 2945.291 1611988371.8065023
train: epoch 0, iter 2500, loss: 5.529949, top_1: 0.075078, top_k: 0.201133, samples/s: 2989.358 1611988380.3703005
train: epoch 0, iter 2600, loss: 5.484149, top_1: 0.074414, top_k: 0.204883, samples/s: 2974.793 1611988388.9757838
train: epoch 0, iter 2700, loss: 5.502373, top_1: 0.075703, top_k: 0.209063, samples/s: 2990.626 1611988397.5358725
train: epoch 0, iter 2800, loss: 5.501852, top_1: 0.084062, top_k: 0.217070, samples/s: 2950.804 1611988406.2114646
train: epoch 0, iter 2900, loss: 5.499978, top_1: 0.087930, top_k: 0.230039, samples/s: 2884.226 1611988415.087332
train: epoch 0, iter 3000, loss: 5.491076, top_1: 0.083672, top_k: 0.228945, samples/s: 2966.448 1611988423.7171915
train: epoch 0, iter 3100, loss: 5.494540, top_1: 0.090352, top_k: 0.240195, samples/s: 2992.822 1611988432.2710092
train: epoch 0, iter 3200, loss: 5.135305, top_1: 0.089688, top_k: 0.242891, samples/s: 2925.610 1611988441.021324
train: epoch 0, iter 3300, loss: 5.387871, top_1: 0.099219, top_k: 0.253750, samples/s: 3005.648 1611988449.5387437
train: epoch 0, iter 3400, loss: 5.167720, top_1: 0.099023, top_k: 0.254453, samples/s: 2948.558 1611988458.2214553
train: epoch 0, iter 3500, loss: 5.229397, top_1: 0.105430, top_k: 0.261211, samples/s: 2970.375 1611988466.8392518
train: epoch 0, iter 3600, loss: 5.236774, top_1: 0.106133, top_k: 0.268984, samples/s: 2952.322 1611988475.5103862
train: epoch 0, iter 3700, loss: 5.162279, top_1: 0.112578, top_k: 0.276484, samples/s: 2992.099 1611988484.066796
train: epoch 0, iter 3800, loss: 5.052128, top_1: 0.111797, top_k: 0.284180, samples/s: 3000.178 1611988492.5990794
train: epoch 0, iter 3900, loss: 5.153796, top_1: 0.117734, top_k: 0.289219, samples/s: 2960.578 1611988501.2460508
train: epoch 0, iter 4000, loss: 5.080898, top_1: 0.121953, top_k: 0.291172, samples/s: 2921.335 1611988510.0092669
train: epoch 0, iter 4100, loss: 5.188395, top_1: 0.122852, top_k: 0.300078, samples/s: 2986.565 1611988518.5808797
train: epoch 0, iter 4200, loss: 5.192718, top_1: 0.127109, top_k: 0.305898, samples/s: 2990.267 1611988527.1420093
train: epoch 0, iter 4300, loss: 5.140800, top_1: 0.128008, top_k: 0.309531, samples/s: 2970.359 1611988535.7604768
train: epoch 0, iter 4400, loss: 4.947769, top_1: 0.135664, top_k: 0.320312, samples/s: 2994.298 1611988544.3101017
train: epoch 0, iter 4500, loss: 5.069659, top_1: 0.134570, top_k: 0.316992, samples/s: 2911.886 1611988553.1016243
train: epoch 0, iter 4600, loss: 5.026352, top_1: 0.138555, top_k: 0.326641, samples/s: 2985.775 1611988561.6762643
train: epoch 0, iter 4700, loss: 4.775744, top_1: 0.142617, top_k: 0.329492, samples/s: 2927.851 1611988570.4192212
train: epoch 0, iter 4800, loss: 4.941777, top_1: 0.142969, top_k: 0.331914, samples/s: 2885.928 1611988579.2906861
train: epoch 0, iter 4900, loss: 4.923352, top_1: 0.150039, top_k: 0.335352, samples/s: 2894.286 1611988588.1348505
train: epoch 0, iter 5000, loss: 4.997577, top_1: 0.147578, top_k: 0.341641, samples/s: 2981.566 1611988596.720947
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_0.
validation: epoch 0, iter 195, top_1: 0.161038, top_k: 0.369010, samples/s: 2945.575 1611988613.9229693
train: epoch 1, iter 100, loss: 5.051001, top_1: 0.151094, top_k: 0.350000, samples/s: 2974.177 1611988639.1145396
train: epoch 1, iter 200, loss: 4.744684, top_1: 0.155078, top_k: 0.353672, samples/s: 2931.732 1611988647.846492
train: epoch 1, iter 300, loss: 4.895723, top_1: 0.157109, top_k: 0.359766, samples/s: 2990.294 1611988656.4076474
train: epoch 1, iter 400, loss: 4.944866, top_1: 0.159844, top_k: 0.359844, samples/s: 2989.115 1611988664.97193
train: epoch 1, iter 500, loss: 4.916136, top_1: 0.162070, top_k: 0.367422, samples/s: 2992.881 1611988673.5255938
train: epoch 1, iter 600, loss: 4.784726, top_1: 0.165391, top_k: 0.369570, samples/s: 2993.426 1611988682.0776694
train: epoch 1, iter 700, loss: 4.879880, top_1: 0.169648, top_k: 0.376094, samples/s: 3005.226 1611988690.597479
train: epoch 1, iter 800, loss: 4.617264, top_1: 0.168594, top_k: 0.373906, samples/s: 2952.630 1611988699.2663841
train: epoch 1, iter 900, loss: 4.684015, top_1: 0.172148, top_k: 0.375273, samples/s: 3012.452 1611988707.764917
train: epoch 1, iter 1000, loss: 4.727581, top_1: 0.175977, top_k: 0.382266, samples/s: 2953.815 1611988716.4312344
train: epoch 1, iter 1100, loss: 4.743749, top_1: 0.176016, top_k: 0.386914, samples/s: 2969.106 1611988725.053314
train: epoch 1, iter 1200, loss: 4.713352, top_1: 0.179023, top_k: 0.387930, samples/s: 2967.486 1611988733.6802015
train: epoch 1, iter 1300, loss: 4.654734, top_1: 0.184453, top_k: 0.395977, samples/s: 3006.148 1611988742.1960285
train: epoch 1, iter 1400, loss: 4.655951, top_1: 0.180195, top_k: 0.394375, samples/s: 2850.990 1611988751.1754513
train: epoch 1, iter 1500, loss: 4.526017, top_1: 0.184688, top_k: 0.393555, samples/s: 2992.271 1611988759.7307596
train: epoch 1, iter 1600, loss: 4.616926, top_1: 0.191211, top_k: 0.408047, samples/s: 2938.322 1611988768.443211
train: epoch 1, iter 1700, loss: 4.714269, top_1: 0.197422, top_k: 0.410469, samples/s: 2942.804 1611988777.142378
train: epoch 1, iter 1800, loss: 4.726378, top_1: 0.192344, top_k: 0.406484, samples/s: 2893.465 1611988785.9899004
train: epoch 1, iter 1900, loss: 4.819767, top_1: 0.193477, top_k: 0.410195, samples/s: 2949.426 1611988794.6695483
train: epoch 1, iter 2000, loss: 4.600360, top_1: 0.200313, top_k: 0.414844, samples/s: 3000.768 1611988803.2008142
train: epoch 1, iter 2100, loss: 4.526858, top_1: 0.200117, top_k: 0.417539, samples/s: 2956.490 1611988811.8596168
train: epoch 1, iter 2200, loss: 4.670314, top_1: 0.203594, top_k: 0.419609, samples/s: 2895.913 1611988820.6997378
train: epoch 1, iter 2300, loss: 4.473603, top_1: 0.204492, top_k: 0.423125, samples/s: 2857.926 1611988829.6572099
train: epoch 1, iter 2400, loss: 4.504100, top_1: 0.209141, top_k: 0.431367, samples/s: 2988.770 1611988838.2226174
train: epoch 1, iter 2500, loss: 4.825469, top_1: 0.209258, top_k: 0.428906, samples/s: 2975.806 1611988846.8252804
train: epoch 1, iter 2600, loss: 4.510869, top_1: 0.207148, top_k: 0.430977, samples/s: 2988.057 1611988855.3930852
train: epoch 1, iter 2700, loss: 4.663970, top_1: 0.211875, top_k: 0.432539, samples/s: 2968.857 1611988864.015632
train: epoch 1, iter 2800, loss: 4.307298, top_1: 0.208320, top_k: 0.435898, samples/s: 2955.498 1611988872.6777902
train: epoch 1, iter 2900, loss: 4.545284, top_1: 0.213164, top_k: 0.439805, samples/s: 3000.154 1611988881.2103667
train: epoch 1, iter 3000, loss: 4.584684, top_1: 0.213711, top_k: 0.439453, samples/s: 2972.176 1611988889.8236368
train: epoch 1, iter 3100, loss: 4.561905, top_1: 0.218203, top_k: 0.444648, samples/s: 2969.870 1611988898.4434466
train: epoch 1, iter 3200, loss: 4.418639, top_1: 0.220703, top_k: 0.441641, samples/s: 2959.015 1611988907.0950336
train: epoch 1, iter 3300, loss: 4.363636, top_1: 0.218398, top_k: 0.445156, samples/s: 2972.668 1611988915.7067647
train: epoch 1, iter 3400, loss: 4.440405, top_1: 0.222266, top_k: 0.451445, samples/s: 2967.982 1611988924.3321645
train: epoch 1, iter 3500, loss: 4.562207, top_1: 0.229492, top_k: 0.457930, samples/s: 2922.693 1611988933.0912154
train: epoch 1, iter 3600, loss: 4.295504, top_1: 0.229570, top_k: 0.455313, samples/s: 3008.664 1611988941.599972
train: epoch 1, iter 3700, loss: 4.345763, top_1: 0.230586, top_k: 0.458008, samples/s: 2971.080 1611988950.2164054
train: epoch 1, iter 3800, loss: 4.373788, top_1: 0.231094, top_k: 0.460820, samples/s: 2962.408 1611988958.8580837
train: epoch 1, iter 3900, loss: 4.295616, top_1: 0.231758, top_k: 0.459531, samples/s: 2999.169 1611988967.3936627
train: epoch 1, iter 4000, loss: 4.455645, top_1: 0.233164, top_k: 0.462305, samples/s: 2855.694 1611988976.3582594
train: epoch 1, iter 4100, loss: 4.371496, top_1: 0.236289, top_k: 0.462305, samples/s: 2927.427 1611988985.1031363
train: epoch 1, iter 4200, loss: 4.465079, top_1: 0.237773, top_k: 0.469570, samples/s: 2986.846 1611988993.6740117
train: epoch 1, iter 4300, loss: 4.477804, top_1: 0.236211, top_k: 0.468398, samples/s: 2977.470 1611989002.272061
train: epoch 1, iter 4400, loss: 4.253454, top_1: 0.240625, top_k: 0.474570, samples/s: 2977.313 1611989010.870238
train: epoch 1, iter 4500, loss: 4.396403, top_1: 0.242578, top_k: 0.478438, samples/s: 2949.568 1611989019.5497031
train: epoch 1, iter 4600, loss: 4.335955, top_1: 0.242266, top_k: 0.473633, samples/s: 2953.180 1611989028.2181315
train: epoch 1, iter 4700, loss: 4.546923, top_1: 0.240234, top_k: 0.476289, samples/s: 2989.323 1611989036.7820468
train: epoch 1, iter 4800, loss: 4.412931, top_1: 0.245664, top_k: 0.479609, samples/s: 2915.958 1611989045.5613387
train: epoch 1, iter 4900, loss: 4.026361, top_1: 0.246094, top_k: 0.484453, samples/s: 2973.254 1611989054.17133
train: epoch 1, iter 5000, loss: 4.105742, top_1: 0.248242, top_k: 0.483125, samples/s: 2936.064 1611989062.8905141
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_1.
validation: epoch 1, iter 195, top_1: 0.261979, top_k: 0.511178, samples/s: 2810.555 1611989080.9061997
train: epoch 2, iter 100, loss: 4.171246, top_1: 0.253164, top_k: 0.487070, samples/s: 2968.915 1611989105.622884
train: epoch 2, iter 200, loss: 4.372975, top_1: 0.258906, top_k: 0.489531, samples/s: 2963.957 1611989114.259928
train: epoch 2, iter 300, loss: 4.322598, top_1: 0.259570, top_k: 0.494297, samples/s: 2993.614 1611989122.8114784
train: epoch 2, iter 400, loss: 4.243876, top_1: 0.258711, top_k: 0.496719, samples/s: 3001.264 1611989131.3412025
train: epoch 2, iter 500, loss: 4.325070, top_1: 0.258555, top_k: 0.495117, samples/s: 2974.834 1611989139.9467185
train: epoch 2, iter 600, loss: 4.388449, top_1: 0.253906, top_k: 0.491641, samples/s: 2992.477 1611989148.5015156
train: epoch 2, iter 700, loss: 4.175850, top_1: 0.257812, top_k: 0.493125, samples/s: 2960.305 1611989157.149291
train: epoch 2, iter 800, loss: 4.293830, top_1: 0.257617, top_k: 0.497031, samples/s: 2908.486 1611989165.9516065
train: epoch 2, iter 900, loss: 4.492269, top_1: 0.264883, top_k: 0.500977, samples/s: 3033.836 1611989174.3892732
train: epoch 2, iter 1000, loss: 4.248759, top_1: 0.267852, top_k: 0.502930, samples/s: 2936.934 1611989183.1062016
train: epoch 2, iter 1100, loss: 3.987559, top_1: 0.260234, top_k: 0.501328, samples/s: 2950.191 1611989191.7832391
train: epoch 2, iter 1200, loss: 4.158987, top_1: 0.266406, top_k: 0.507109, samples/s: 3016.177 1611989200.2708228
train: epoch 2, iter 1300, loss: 4.334082, top_1: 0.265156, top_k: 0.507461, samples/s: 2954.564 1611989208.9353628
train: epoch 2, iter 1400, loss: 4.153764, top_1: 0.270117, top_k: 0.509844, samples/s: 2922.126 1611989217.6961548
train: epoch 2, iter 1500, loss: 4.180248, top_1: 0.268320, top_k: 0.506563, samples/s: 3006.533 1611989226.2109041
train: epoch 2, iter 1600, loss: 4.213502, top_1: 0.268906, top_k: 0.509219, samples/s: 2972.453 1611989234.8234282
train: epoch 2, iter 1700, loss: 3.876912, top_1: 0.275078, top_k: 0.513555, samples/s: 2989.441 1611989243.386928
train: epoch 2, iter 1800, loss: 4.284357, top_1: 0.271992, top_k: 0.511680, samples/s: 2876.903 1611989252.2852492
train: epoch 2, iter 1900, loss: 4.047436, top_1: 0.273281, top_k: 0.510117, samples/s: 2945.727 1611989260.9758155
train: epoch 2, iter 2000, loss: 4.084836, top_1: 0.276211, top_k: 0.513750, samples/s: 2952.496 1611989269.6464283
train: epoch 2, iter 2100, loss: 4.204414, top_1: 0.276094, top_k: 0.516484, samples/s: 2996.399 1611989278.1899655
train: epoch 2, iter 2200, loss: 4.335163, top_1: 0.275547, top_k: 0.520664, samples/s: 2909.206 1611989286.9896915
train: epoch 2, iter 2300, loss: 4.202319, top_1: 0.278281, top_k: 0.520195, samples/s: 2978.499 1611989295.5847125
train: epoch 2, iter 2400, loss: 4.174811, top_1: 0.281875, top_k: 0.524102, samples/s: 2953.545 1611989304.252294
train: epoch 2, iter 2500, loss: 4.114879, top_1: 0.276953, top_k: 0.517578, samples/s: 2956.645 1611989312.910614
train: epoch 2, iter 2600, loss: 4.223388, top_1: 0.276875, top_k: 0.518477, samples/s: 2933.177 1611989321.6384275
train: epoch 2, iter 2700, loss: 4.159625, top_1: 0.281250, top_k: 0.523008, samples/s: 2921.849 1611989330.3999481
train: epoch 2, iter 2800, loss: 4.122027, top_1: 0.283984, top_k: 0.523984, samples/s: 2975.916 1611989339.002372
train: epoch 2, iter 2900, loss: 3.986191, top_1: 0.283477, top_k: 0.527500, samples/s: 2983.751 1611989347.5821435
train: epoch 2, iter 3000, loss: 4.023041, top_1: 0.284023, top_k: 0.525117, samples/s: 2980.231 1611989356.172135
train: epoch 2, iter 3100, loss: 4.296948, top_1: 0.283125, top_k: 0.525664, samples/s: 2921.117 1611989364.9358344
train: epoch 2, iter 3200, loss: 3.972879, top_1: 0.285742, top_k: 0.535937, samples/s: 2954.313 1611989373.6012368
train: epoch 2, iter 3300, loss: 4.017234, top_1: 0.285000, top_k: 0.525820, samples/s: 2925.380 1611989382.3521354
train: epoch 2, iter 3400, loss: 4.379250, top_1: 0.288242, top_k: 0.533203, samples/s: 2925.060 1611989391.1043754
train: epoch 2, iter 3500, loss: 4.155266, top_1: 0.294492, top_k: 0.535508, samples/s: 3001.741 1611989399.6324797
train: epoch 2, iter 3600, loss: 4.198413, top_1: 0.291914, top_k: 0.533398, samples/s: 2950.744 1611989408.3083546
train: epoch 2, iter 3700, loss: 4.203920, top_1: 0.292031, top_k: 0.541172, samples/s: 2952.446 1611989416.9791136
train: epoch 2, iter 3800, loss: 4.247556, top_1: 0.292383, top_k: 0.538125, samples/s: 2980.713 1611989425.5675817
train: epoch 2, iter 3900, loss: 4.158090, top_1: 0.287461, top_k: 0.531406, samples/s: 2956.315 1611989434.227268
train: epoch 2, iter 4000, loss: 4.074324, top_1: 0.294375, top_k: 0.539922, samples/s: 2965.994 1611989442.8581858
train: epoch 2, iter 4100, loss: 4.291621, top_1: 0.296055, top_k: 0.542148, samples/s: 2970.514 1611989451.476217
train: epoch 2, iter 4200, loss: 4.001307, top_1: 0.293984, top_k: 0.538125, samples/s: 2971.064 1611989460.0926864
train: epoch 2, iter 4300, loss: 4.264777, top_1: 0.299063, top_k: 0.543164, samples/s: 2961.665 1611989468.7368538
train: epoch 2, iter 4400, loss: 4.126623, top_1: 0.299961, top_k: 0.544648, samples/s: 2992.098 1611989477.2923207
train: epoch 2, iter 4500, loss: 4.104162, top_1: 0.298164, top_k: 0.537578, samples/s: 2956.966 1611989485.9502962
train: epoch 2, iter 4600, loss: 4.064007, top_1: 0.304648, top_k: 0.548555, samples/s: 2981.102 1611989494.5372653
train: epoch 2, iter 4700, loss: 4.173794, top_1: 0.299023, top_k: 0.543438, samples/s: 2991.650 1611989503.0944357
train: epoch 2, iter 4800, loss: 3.951332, top_1: 0.302227, top_k: 0.551562, samples/s: 2945.077 1611989511.7869465
train: epoch 2, iter 4900, loss: 4.200949, top_1: 0.298086, top_k: 0.542422, samples/s: 2910.258 1611989520.5833447
train: epoch 2, iter 5000, loss: 3.842710, top_1: 0.307969, top_k: 0.557734, samples/s: 2859.425 1611989529.536204
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_2.
validation: epoch 2, iter 195, top_1: 0.308814, top_k: 0.569191, samples/s: 2965.653 1611989546.621276
train: epoch 3, iter 100, loss: 4.060825, top_1: 0.315312, top_k: 0.560586, samples/s: 2956.748 1611989571.4029808
train: epoch 3, iter 200, loss: 3.775770, top_1: 0.309766, top_k: 0.555195, samples/s: 3023.259 1611989579.8706665
train: epoch 3, iter 300, loss: 3.950486, top_1: 0.315078, top_k: 0.560781, samples/s: 3008.496 1611989588.3807087
train: epoch 3, iter 400, loss: 3.934969, top_1: 0.312344, top_k: 0.561797, samples/s: 2913.950 1611989597.1652458
train: epoch 3, iter 500, loss: 3.982587, top_1: 0.320234, top_k: 0.566055, samples/s: 2996.306 1611989605.7090855
train: epoch 3, iter 600, loss: 4.093667, top_1: 0.308047, top_k: 0.556289, samples/s: 2927.360 1611989614.4541748
train: epoch 3, iter 700, loss: 4.029486, top_1: 0.316875, top_k: 0.558359, samples/s: 3019.237 1611989622.9331162
train: epoch 3, iter 800, loss: 3.962329, top_1: 0.316211, top_k: 0.564336, samples/s: 2996.309 1611989631.4769082
train: epoch 3, iter 900, loss: 4.211763, top_1: 0.308867, top_k: 0.556797, samples/s: 2965.760 1611989640.1088662
train: epoch 3, iter 1000, loss: 4.080001, top_1: 0.315547, top_k: 0.562031, samples/s: 2951.425 1611989648.7827485
train: epoch 3, iter 1100, loss: 3.987323, top_1: 0.311328, top_k: 0.563438, samples/s: 2961.802 1611989657.4260318
train: epoch 3, iter 1200, loss: 4.166730, top_1: 0.309766, top_k: 0.558398, samples/s: 2946.780 1611989666.1134803
train: epoch 3, iter 1300, loss: 3.989902, top_1: 0.312930, top_k: 0.562617, samples/s: 2980.639 1611989674.70218
train: epoch 3, iter 1400, loss: 3.866750, top_1: 0.315937, top_k: 0.561211, samples/s: 2966.146 1611989683.3329093
train: epoch 3, iter 1500, loss: 4.005915, top_1: 0.312344, top_k: 0.558984, samples/s: 2960.897 1611989691.9790015
train: epoch 3, iter 1600, loss: 4.035272, top_1: 0.313711, top_k: 0.564961, samples/s: 2948.021 1611989700.6627011
train: epoch 3, iter 1700, loss: 4.182455, top_1: 0.312344, top_k: 0.563125, samples/s: 3015.569 1611989709.1520133
train: epoch 3, iter 1800, loss: 3.936190, top_1: 0.322734, top_k: 0.564336, samples/s: 2969.177 1611989717.7739427
train: epoch 3, iter 1900, loss: 4.065705, top_1: 0.314531, top_k: 0.564180, samples/s: 2963.165 1611989726.4133317
train: epoch 3, iter 2000, loss: 3.995469, top_1: 0.318789, top_k: 0.566406, samples/s: 2979.100 1611989735.0066056
train: epoch 3, iter 2100, loss: 3.935009, top_1: 0.318320, top_k: 0.566016, samples/s: 2882.075 1611989743.8890197
train: epoch 3, iter 2200, loss: 3.966628, top_1: 0.325547, top_k: 0.573477, samples/s: 2948.271 1611989752.5721428
train: epoch 3, iter 2300, loss: 3.890993, top_1: 0.327734, top_k: 0.572500, samples/s: 2952.965 1611989761.2413583
train: epoch 3, iter 2400, loss: 3.976216, top_1: 0.322383, top_k: 0.571328, samples/s: 2935.472 1611989769.9623435
train: epoch 3, iter 2500, loss: 3.772611, top_1: 0.320391, top_k: 0.569648, samples/s: 2963.849 1611989778.5996711
train: epoch 3, iter 2600, loss: 4.049653, top_1: 0.317148, top_k: 0.564766, samples/s: 2966.332 1611989787.2298915
train: epoch 3, iter 2700, loss: 3.991014, top_1: 0.323398, top_k: 0.570352, samples/s: 2953.868 1611989795.896497
train: epoch 3, iter 2800, loss: 3.765125, top_1: 0.320547, top_k: 0.569961, samples/s: 2944.429 1611989804.5909142
train: epoch 3, iter 2900, loss: 4.058322, top_1: 0.330000, top_k: 0.576211, samples/s: 2981.803 1611989813.1762953
train: epoch 3, iter 3000, loss: 3.874008, top_1: 0.322383, top_k: 0.573242, samples/s: 2977.737 1611989821.7734067
train: epoch 3, iter 3100, loss: 4.022543, top_1: 0.325742, top_k: 0.571445, samples/s: 2957.501 1611989830.4294195
train: epoch 3, iter 3200, loss: 4.077455, top_1: 0.328828, top_k: 0.575234, samples/s: 2965.981 1611989839.060565
train: epoch 3, iter 3300, loss: 3.864179, top_1: 0.325000, top_k: 0.576641, samples/s: 2970.428 1611989847.678832
train: epoch 3, iter 3400, loss: 3.842401, top_1: 0.325469, top_k: 0.570742, samples/s: 2904.473 1611989856.4928215
train: epoch 3, iter 3500, loss: 3.889923, top_1: 0.327109, top_k: 0.581211, samples/s: 2983.673 1611989865.0728486
train: epoch 3, iter 3600, loss: 3.969377, top_1: 0.327578, top_k: 0.571758, samples/s: 2940.277 1611989873.7795312
train: epoch 3, iter 3700, loss: 4.002594, top_1: 0.322500, top_k: 0.565977, samples/s: 2975.692 1611989882.3825645
train: epoch 3, iter 3800, loss: 3.865571, top_1: 0.327695, top_k: 0.574727, samples/s: 2965.364 1611989891.0155635
train: epoch 3, iter 3900, loss: 3.892336, top_1: 0.327969, top_k: 0.573984, samples/s: 2957.634 1611989899.671132
train: epoch 3, iter 4000, loss: 3.862756, top_1: 0.328633, top_k: 0.571953, samples/s: 2861.036 1611989908.618985
train: epoch 3, iter 4100, loss: 3.880986, top_1: 0.327188, top_k: 0.574375, samples/s: 2997.246 1611989917.1602502
train: epoch 3, iter 4200, loss: 4.005178, top_1: 0.328203, top_k: 0.577031, samples/s: 2963.520 1611989925.7986014
train: epoch 3, iter 4300, loss: 4.034433, top_1: 0.319570, top_k: 0.569375, samples/s: 2997.791 1611989934.3380537
train: epoch 3, iter 4400, loss: 3.785100, top_1: 0.327305, top_k: 0.579414, samples/s: 3005.850 1611989942.854836
train: epoch 3, iter 4500, loss: 3.855397, top_1: 0.330703, top_k: 0.583359, samples/s: 2968.292 1611989951.4794502
train: epoch 3, iter 4600, loss: 3.856230, top_1: 0.330664, top_k: 0.579336, samples/s: 2961.898 1611989960.1225584
train: epoch 3, iter 4700, loss: 3.946669, top_1: 0.333164, top_k: 0.577891, samples/s: 2951.498 1611989968.7960174
train: epoch 3, iter 4800, loss: 3.612744, top_1: 0.333242, top_k: 0.584727, samples/s: 3000.143 1611989977.329041
train: epoch 3, iter 4900, loss: 3.744744, top_1: 0.336172, top_k: 0.587070, samples/s: 2968.743 1611989985.9521143
train: epoch 3, iter 5000, loss: 4.086472, top_1: 0.335859, top_k: 0.586680, samples/s: 2969.400 1611989994.573768
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_3.
validation: epoch 3, iter 195, top_1: 0.366406, top_k: 0.627224, samples/s: 3034.848 1611990011.272314
train: epoch 4, iter 100, loss: 3.847850, top_1: 0.336875, top_k: 0.587422, samples/s: 2876.293 1611990036.2422087
train: epoch 4, iter 200, loss: 3.798913, top_1: 0.343320, top_k: 0.589922, samples/s: 2954.870 1611990044.906211
train: epoch 4, iter 300, loss: 3.923325, top_1: 0.340430, top_k: 0.585625, samples/s: 2983.831 1611990053.4853773
train: epoch 4, iter 400, loss: 3.968904, top_1: 0.343125, top_k: 0.593125, samples/s: 3002.400 1611990062.0119112
train: epoch 4, iter 500, loss: 3.993425, top_1: 0.341719, top_k: 0.591094, samples/s: 2989.258 1611990070.57592
train: epoch 4, iter 600, loss: 3.899149, top_1: 0.345234, top_k: 0.594844, samples/s: 3004.007 1611990079.0978746
train: epoch 4, iter 700, loss: 3.796331, top_1: 0.337422, top_k: 0.588516, samples/s: 2993.558 1611990087.6495938
train: epoch 4, iter 800, loss: 3.985126, top_1: 0.343281, top_k: 0.589883, samples/s: 2949.596 1611990096.3287487
train: epoch 4, iter 900, loss: 3.678030, top_1: 0.335195, top_k: 0.579883, samples/s: 2972.831 1611990104.9401355
train: epoch 4, iter 1000, loss: 3.671584, top_1: 0.339805, top_k: 0.589492, samples/s: 2918.851 1611990113.7105808
train: epoch 4, iter 1100, loss: 3.652996, top_1: 0.337500, top_k: 0.590703, samples/s: 2978.998 1611990122.3040795
train: epoch 4, iter 1200, loss: 3.847560, top_1: 0.346445, top_k: 0.591367, samples/s: 2964.927 1611990130.9383569
train: epoch 4, iter 1300, loss: 3.801942, top_1: 0.334531, top_k: 0.582617, samples/s: 2967.995 1611990139.5637107
train: epoch 4, iter 1400, loss: 3.773860, top_1: 0.340195, top_k: 0.590156, samples/s: 2952.424 1611990148.2345784
train: epoch 4, iter 1500, loss: 4.015214, top_1: 0.342578, top_k: 0.592656, samples/s: 2923.553 1611990156.9910183
train: epoch 4, iter 1600, loss: 3.793356, top_1: 0.337813, top_k: 0.588437, samples/s: 2948.333 1611990165.6739202
train: epoch 4, iter 1700, loss: 3.829884, top_1: 0.339219, top_k: 0.588711, samples/s: 2998.253 1611990174.2123072
train: epoch 4, iter 1800, loss: 3.739910, top_1: 0.339336, top_k: 0.588594, samples/s: 2991.925 1611990182.7685926
train: epoch 4, iter 1900, loss: 3.882986, top_1: 0.344180, top_k: 0.590430, samples/s: 2961.394 1611990191.413138
train: epoch 4, iter 2000, loss: 3.820112, top_1: 0.346289, top_k: 0.593711, samples/s: 2908.587 1611990200.2147388
train: epoch 4, iter 2100, loss: 3.695059, top_1: 0.346562, top_k: 0.593320, samples/s: 2947.798 1611990208.8991199
train: epoch 4, iter 2200, loss: 4.165592, top_1: 0.340039, top_k: 0.589648, samples/s: 2953.877 1611990217.5657465
train: epoch 4, iter 2300, loss: 3.752508, top_1: 0.343086, top_k: 0.597930, samples/s: 2904.659 1611990226.3791614
train: epoch 4, iter 2400, loss: 4.162347, top_1: 0.341914, top_k: 0.592031, samples/s: 2940.140 1611990235.0862563
train: epoch 4, iter 2500, loss: 3.654247, top_1: 0.345508, top_k: 0.593164, samples/s: 2969.845 1611990243.7061846
train: epoch 4, iter 2600, loss: 3.815326, top_1: 0.345703, top_k: 0.592031, samples/s: 2990.774 1611990252.2658174
train: epoch 4, iter 2700, loss: 3.899568, top_1: 0.340586, top_k: 0.588086, samples/s: 2944.414 1611990260.9602537
train: epoch 4, iter 2800, loss: 3.618544, top_1: 0.347148, top_k: 0.598789, samples/s: 2950.548 1611990269.6366222
train: epoch 4, iter 2900, loss: 3.710239, top_1: 0.342422, top_k: 0.594922, samples/s: 2920.485 1611990278.402271
train: epoch 4, iter 3000, loss: 4.002275, top_1: 0.345078, top_k: 0.599258, samples/s: 2977.246 1611990287.0008807
train: epoch 4, iter 3100, loss: 3.795559, top_1: 0.345547, top_k: 0.596953, samples/s: 2848.476 1611990295.98829
train: epoch 4, iter 3200, loss: 3.698447, top_1: 0.348438, top_k: 0.596172, samples/s: 3008.215 1611990304.4981604
train: epoch 4, iter 3300, loss: 3.473335, top_1: 0.348711, top_k: 0.596328, samples/s: 2948.113 1611990313.1820188
train: epoch 4, iter 3400, loss: 3.919358, top_1: 0.349062, top_k: 0.597305, samples/s: 2951.468 1611990321.8552926
train: epoch 4, iter 3500, loss: 3.915635, top_1: 0.349180, top_k: 0.596172, samples/s: 2947.685 1611990330.5405695
train: epoch 4, iter 3600, loss: 3.616676, top_1: 0.350898, top_k: 0.599805, samples/s: 2969.989 1611990339.1596243
train: epoch 4, iter 3700, loss: 3.957855, top_1: 0.353164, top_k: 0.601367, samples/s: 2997.038 1611990347.7014208
train: epoch 4, iter 3800, loss: 3.709853, top_1: 0.344648, top_k: 0.594609, samples/s: 2974.795 1611990356.3070326
train: epoch 4, iter 3900, loss: 3.647321, top_1: 0.344766, top_k: 0.595859, samples/s: 2974.196 1611990364.9144704
train: epoch 4, iter 4000, loss: 4.008110, top_1: 0.349805, top_k: 0.600039, samples/s: 2963.017 1611990373.5543141
train: epoch 4, iter 4100, loss: 3.835948, top_1: 0.348203, top_k: 0.596758, samples/s: 2907.516 1611990382.3590612
train: epoch 4, iter 4200, loss: 4.000642, top_1: 0.349687, top_k: 0.596875, samples/s: 2971.001 1611990390.9756858
train: epoch 4, iter 4300, loss: 3.729145, top_1: 0.348516, top_k: 0.598086, samples/s: 2987.890 1611990399.5435467
train: epoch 4, iter 4400, loss: 3.791254, top_1: 0.354219, top_k: 0.604336, samples/s: 2963.031 1611990408.1834047
train: epoch 4, iter 4500, loss: 3.951461, top_1: 0.352070, top_k: 0.600273, samples/s: 3027.367 1611990416.6395364
train: epoch 4, iter 4600, loss: 3.797325, top_1: 0.349297, top_k: 0.594180, samples/s: 2939.919 1611990425.3472633
train: epoch 4, iter 4700, loss: 3.840643, top_1: 0.355508, top_k: 0.605781, samples/s: 2942.413 1611990434.0476408
train: epoch 4, iter 4800, loss: 3.549113, top_1: 0.345352, top_k: 0.600391, samples/s: 2936.358 1611990442.7660224
train: epoch 4, iter 4900, loss: 3.893044, top_1: 0.350234, top_k: 0.604062, samples/s: 2914.180 1611990451.5505629
train: epoch 4, iter 5000, loss: 3.746396, top_1: 0.350586, top_k: 0.599688, samples/s: 2940.642 1611990460.2560956
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_4.
validation: epoch 4, iter 195, top_1: 0.385036, top_k: 0.653666, samples/s: 3007.600 1611990477.1044133
train: epoch 5, iter 100, loss: 3.740458, top_1: 0.357969, top_k: 0.607617, samples/s: 2888.281 1611990502.012894
train: epoch 5, iter 200, loss: 3.820103, top_1: 0.352031, top_k: 0.602383, samples/s: 2989.256 1611990510.5768273
train: epoch 5, iter 300, loss: 3.823969, top_1: 0.358320, top_k: 0.611016, samples/s: 2999.530 1611990519.1117527
train: epoch 5, iter 400, loss: 3.928673, top_1: 0.357383, top_k: 0.603984, samples/s: 2969.644 1611990527.7320428
train: epoch 5, iter 500, loss: 3.812387, top_1: 0.363320, top_k: 0.609492, samples/s: 2944.864 1611990536.425138
train: epoch 5, iter 600, loss: 3.660802, top_1: 0.361484, top_k: 0.606289, samples/s: 2942.500 1611990545.1253145
train: epoch 5, iter 700, loss: 3.724986, top_1: 0.358125, top_k: 0.606445, samples/s: 2981.318 1611990553.712067
train: epoch 5, iter 800, loss: 3.799261, top_1: 0.358125, top_k: 0.608594, samples/s: 3011.553 1611990562.212641
train: epoch 5, iter 900, loss: 3.898015, top_1: 0.360078, top_k: 0.608477, samples/s: 2976.110 1611990570.8145173
train: epoch 5, iter 1000, loss: 3.873477, top_1: 0.358438, top_k: 0.612891, samples/s: 3020.507 1611990579.290065
train: epoch 5, iter 1100, loss: 3.637802, top_1: 0.361914, top_k: 0.610156, samples/s: 2986.954 1611990587.8604217
train: epoch 5, iter 1200, loss: 3.765985, top_1: 0.360156, top_k: 0.613437, samples/s: 2990.281 1611990596.4215431
train: epoch 5, iter 1300, loss: 3.525565, top_1: 0.361406, top_k: 0.611094, samples/s: 2964.776 1611990605.0568018
train: epoch 5, iter 1400, loss: 3.880449, top_1: 0.363047, top_k: 0.618125, samples/s: 3001.494 1611990613.5854263
train: epoch 5, iter 1500, loss: 3.684401, top_1: 0.362031, top_k: 0.614648, samples/s: 2974.664 1611990622.191368
train: epoch 5, iter 1600, loss: 3.805262, top_1: 0.356680, top_k: 0.607891, samples/s: 2930.743 1611990630.9263532
train: epoch 5, iter 1700, loss: 3.831162, top_1: 0.361445, top_k: 0.607734, samples/s: 2959.979 1611990639.5751324
train: epoch 5, iter 1800, loss: 3.827841, top_1: 0.360664, top_k: 0.612305, samples/s: 2962.623 1611990648.2161033
train: epoch 5, iter 1900, loss: 3.709725, top_1: 0.363867, top_k: 0.612148, samples/s: 2950.655 1611990656.8925164
train: epoch 5, iter 2000, loss: 3.792412, top_1: 0.362852, top_k: 0.613789, samples/s: 2917.705 1611990665.6662116
train: epoch 5, iter 2100, loss: 3.690380, top_1: 0.361289, top_k: 0.610781, samples/s: 2994.573 1611990674.2149246
train: epoch 5, iter 2200, loss: 3.787948, top_1: 0.365430, top_k: 0.617930, samples/s: 2911.714 1611990683.0071175
train: epoch 5, iter 2300, loss: 3.583445, top_1: 0.367305, top_k: 0.614492, samples/s: 3045.268 1611990691.413634
train: epoch 5, iter 2400, loss: 3.945347, top_1: 0.365391, top_k: 0.612852, samples/s: 2960.261 1611990700.0613437
train: epoch 5, iter 2500, loss: 3.679026, top_1: 0.367930, top_k: 0.617734, samples/s: 2959.364 1611990708.711878
train: epoch 5, iter 2600, loss: 3.673181, top_1: 0.366758, top_k: 0.617617, samples/s: 2944.585 1611990717.4057715
train: epoch 5, iter 2700, loss: 3.830085, top_1: 0.360312, top_k: 0.609453, samples/s: 2998.277 1611990725.9440274
train: epoch 5, iter 2800, loss: 3.829732, top_1: 0.371836, top_k: 0.621758, samples/s: 2951.207 1611990734.6185634
train: epoch 5, iter 2900, loss: 3.810889, top_1: 0.358359, top_k: 0.617148, samples/s: 3007.994 1611990743.129076
train: epoch 5, iter 3000, loss: 3.872416, top_1: 0.376016, top_k: 0.619648, samples/s: 3005.061 1611990751.648003
train: epoch 5, iter 3100, loss: 3.582260, top_1: 0.371797, top_k: 0.617305, samples/s: 2981.253 1611990760.235144
train: epoch 5, iter 3200, loss: 3.661704, top_1: 0.366484, top_k: 0.617305, samples/s: 2955.307 1611990768.8987298
train: epoch 5, iter 3300, loss: 3.654421, top_1: 0.368516, top_k: 0.614727, samples/s: 2979.398 1611990777.489715
train: epoch 5, iter 3400, loss: 3.806652, top_1: 0.368281, top_k: 0.612891, samples/s: 2974.233 1611990786.0970228
train: epoch 5, iter 3500, loss: 3.865224, top_1: 0.368711, top_k: 0.617070, samples/s: 2907.375 1611990794.9026096
train: epoch 5, iter 3600, loss: 3.688384, top_1: 0.369102, top_k: 0.619883, samples/s: 2906.811 1611990803.7091243
train: epoch 5, iter 3700, loss: 3.735547, top_1: 0.375430, top_k: 0.622930, samples/s: 2932.987 1611990812.4374251
train: epoch 5, iter 3800, loss: 3.901412, top_1: 0.365000, top_k: 0.612461, samples/s: 2968.740 1611990821.0608041
train: epoch 5, iter 3900, loss: 3.786556, top_1: 0.368711, top_k: 0.619141, samples/s: 3020.105 1611990829.5371318
train: epoch 5, iter 4000, loss: 3.704750, top_1: 0.371484, top_k: 0.620234, samples/s: 2978.297 1611990838.132748
train: epoch 5, iter 4100, loss: 3.802084, top_1: 0.366328, top_k: 0.618125, samples/s: 2964.672 1611990846.7686472
train: epoch 5, iter 4200, loss: 3.675417, top_1: 0.368242, top_k: 0.620078, samples/s: 3010.435 1611990855.2714248
train: epoch 5, iter 4300, loss: 3.623243, top_1: 0.372227, top_k: 0.622305, samples/s: 2924.991 1611990864.0237858
train: epoch 5, iter 4400, loss: 3.663495, top_1: 0.372070, top_k: 0.618516, samples/s: 2963.477 1611990872.6620986
train: epoch 5, iter 4500, loss: 3.930881, top_1: 0.374219, top_k: 0.627031, samples/s: 2978.793 1611990881.25662
train: epoch 5, iter 4600, loss: 3.575434, top_1: 0.375312, top_k: 0.624102, samples/s: 2905.603 1611990890.0667377
train: epoch 5, iter 4700, loss: 3.770456, top_1: 0.378594, top_k: 0.630391, samples/s: 2939.600 1611990898.7754815
train: epoch 5, iter 4800, loss: 3.773710, top_1: 0.375234, top_k: 0.623672, samples/s: 3004.314 1611990907.2964797
train: epoch 5, iter 4900, loss: 3.659284, top_1: 0.370352, top_k: 0.622305, samples/s: 2987.695 1611990915.8650053
train: epoch 5, iter 5000, loss: 3.740658, top_1: 0.376133, top_k: 0.628203, samples/s: 2983.475 1611990924.4455934
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_5.
validation: epoch 5, iter 195, top_1: 0.407392, top_k: 0.671054, samples/s: 3007.884 1611990941.3253326
train: epoch 6, iter 100, loss: 3.706691, top_1: 0.377695, top_k: 0.632812, samples/s: 2973.309 1611990966.3093214
train: epoch 6, iter 200, loss: 3.856171, top_1: 0.378320, top_k: 0.625625, samples/s: 3011.730 1611990974.8096855
train: epoch 6, iter 300, loss: 3.783089, top_1: 0.374609, top_k: 0.626523, samples/s: 2976.271 1611990983.4108062
train: epoch 6, iter 400, loss: 3.473660, top_1: 0.382383, top_k: 0.635234, samples/s: 2925.635 1611990992.1609395
train: epoch 6, iter 500, loss: 3.770568, top_1: 0.374063, top_k: 0.625352, samples/s: 2971.564 1611991000.7760432
train: epoch 6, iter 600, loss: 3.464897, top_1: 0.378125, top_k: 0.629805, samples/s: 2963.300 1611991009.415021
train: epoch 6, iter 700, loss: 3.802099, top_1: 0.375312, top_k: 0.630859, samples/s: 2926.716 1611991018.1634712
train: epoch 6, iter 800, loss: 3.623677, top_1: 0.376523, top_k: 0.624375, samples/s: 2982.613 1611991026.7450883
train: epoch 6, iter 900, loss: 3.625885, top_1: 0.381250, top_k: 0.634141, samples/s: 2971.069 1611991035.361564
train: epoch 6, iter 1000, loss: 3.405262, top_1: 0.383750, top_k: 0.635508, samples/s: 2947.685 1611991044.046297
train: epoch 6, iter 1100, loss: 3.560288, top_1: 0.380547, top_k: 0.625938, samples/s: 2975.345 1611991052.6503377
train: epoch 6, iter 1200, loss: 3.654393, top_1: 0.379844, top_k: 0.631641, samples/s: 2976.626 1611991061.2506824
train: epoch 6, iter 1300, loss: 3.626317, top_1: 0.383164, top_k: 0.630742, samples/s: 2949.793 1611991069.9297547
train: epoch 6, iter 1400, loss: 3.785535, top_1: 0.383867, top_k: 0.631641, samples/s: 2957.285 1611991078.5858474
train: epoch 6, iter 1500, loss: 3.638950, top_1: 0.385703, top_k: 0.630625, samples/s: 2995.910 1611991087.1308885
train: epoch 6, iter 1600, loss: 3.777760, top_1: 0.380547, top_k: 0.626484, samples/s: 2968.656 1611991095.7543135
train: epoch 6, iter 1700, loss: 3.630868, top_1: 0.377969, top_k: 0.631406, samples/s: 2970.944 1611991104.3710418
train: epoch 6, iter 1800, loss: 3.862758, top_1: 0.380273, top_k: 0.631680, samples/s: 2874.396 1611991113.2772665
train: epoch 6, iter 1900, loss: 3.567769, top_1: 0.377383, top_k: 0.626523, samples/s: 2996.549 1611991121.8203719
train: epoch 6, iter 2000, loss: 3.728381, top_1: 0.385547, top_k: 0.630039, samples/s: 2996.796 1611991130.3628812
train: epoch 6, iter 2100, loss: 3.501625, top_1: 0.385352, top_k: 0.633633, samples/s: 3013.302 1611991138.8585482
train: epoch 6, iter 2200, loss: 3.655719, top_1: 0.382422, top_k: 0.634141, samples/s: 2961.424 1611991147.5030067
train: epoch 6, iter 2300, loss: 3.689843, top_1: 0.383125, top_k: 0.634297, samples/s: 2931.184 1611991156.2367477
train: epoch 6, iter 2400, loss: 3.615588, top_1: 0.385234, top_k: 0.634609, samples/s: 2963.436 1611991164.8753471
train: epoch 6, iter 2500, loss: 3.525633, top_1: 0.377734, top_k: 0.626641, samples/s: 2963.661 1611991173.513309
train: epoch 6, iter 2600, loss: 3.766842, top_1: 0.379492, top_k: 0.628086, samples/s: 2977.564 1611991182.1113777
train: epoch 6, iter 2700, loss: 3.801817, top_1: 0.383477, top_k: 0.631914, samples/s: 2920.876 1611991190.8754423
train: epoch 6, iter 2800, loss: 3.743839, top_1: 0.385469, top_k: 0.641367, samples/s: 2930.808 1611991199.6115525
train: epoch 6, iter 2900, loss: 3.694881, top_1: 0.387266, top_k: 0.632930, samples/s: 2951.386 1611991208.2840998
train: epoch 6, iter 3000, loss: 3.510695, top_1: 0.379766, top_k: 0.630977, samples/s: 2973.185 1611991216.894404
train: epoch 6, iter 3100, loss: 3.641185, top_1: 0.383789, top_k: 0.632891, samples/s: 2948.243 1611991225.5776234
train: epoch 6, iter 3200, loss: 3.704604, top_1: 0.387109, top_k: 0.637031, samples/s: 2988.763 1611991234.1429405
train: epoch 6, iter 3300, loss: 3.777669, top_1: 0.381211, top_k: 0.634531, samples/s: 2990.162 1611991242.704438
train: epoch 6, iter 3400, loss: 3.737125, top_1: 0.385195, top_k: 0.630508, samples/s: 3008.762 1611991251.212925
train: epoch 6, iter 3500, loss: 3.685759, top_1: 0.391797, top_k: 0.641094, samples/s: 2955.258 1611991259.8754015
train: epoch 6, iter 3600, loss: 3.701452, top_1: 0.389180, top_k: 0.640938, samples/s: 2973.991 1611991268.483447
train: epoch 6, iter 3700, loss: 3.456537, top_1: 0.389766, top_k: 0.642578, samples/s: 2983.709 1611991277.0633914
train: epoch 6, iter 3800, loss: 3.449806, top_1: 0.386523, top_k: 0.636641, samples/s: 2974.330 1611991285.6702483
train: epoch 6, iter 3900, loss: 3.526061, top_1: 0.389688, top_k: 0.640352, samples/s: 2906.178 1611991294.4791892
train: epoch 6, iter 4000, loss: 3.666713, top_1: 0.384180, top_k: 0.635117, samples/s: 2914.757 1611991303.261947
train: epoch 6, iter 4100, loss: 3.646519, top_1: 0.385039, top_k: 0.636641, samples/s: 3002.023 1611991311.7894976
train: epoch 6, iter 4200, loss: 3.332145, top_1: 0.389492, top_k: 0.636523, samples/s: 2940.248 1611991320.4963691
train: epoch 6, iter 4300, loss: 3.612819, top_1: 0.392422, top_k: 0.641836, samples/s: 2922.985 1611991329.2544324
train: epoch 6, iter 4400, loss: 3.542839, top_1: 0.388555, top_k: 0.635000, samples/s: 2955.816 1611991337.9153697
train: epoch 6, iter 4500, loss: 3.553600, top_1: 0.386992, top_k: 0.637578, samples/s: 2991.421 1611991346.4732528
train: epoch 6, iter 4600, loss: 3.729712, top_1: 0.390078, top_k: 0.639961, samples/s: 2972.228 1611991355.0862508
train: epoch 6, iter 4700, loss: 3.485249, top_1: 0.389297, top_k: 0.638828, samples/s: 2973.743 1611991363.6949031
train: epoch 6, iter 4800, loss: 3.630860, top_1: 0.386602, top_k: 0.637500, samples/s: 2830.286 1611991372.739918
train: epoch 6, iter 4900, loss: 3.547286, top_1: 0.392578, top_k: 0.639648, samples/s: 2982.664 1611991381.3228445
train: epoch 6, iter 5000, loss: 3.466642, top_1: 0.390273, top_k: 0.639141, samples/s: 2945.238 1611991390.014842
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_6.
validation: epoch 6, iter 195, top_1: 0.407873, top_k: 0.672837, samples/s: 2886.914 1611991407.5704515
train: epoch 7, iter 100, loss: 3.580855, top_1: 0.397109, top_k: 0.642148, samples/s: 2880.308 1611991433.4037228
train: epoch 7, iter 200, loss: 3.488259, top_1: 0.396367, top_k: 0.650117, samples/s: 2900.657 1611991442.2294676
train: epoch 7, iter 300, loss: 3.447040, top_1: 0.389453, top_k: 0.644258, samples/s: 2978.505 1611991450.8244586
train: epoch 7, iter 400, loss: 3.414756, top_1: 0.390742, top_k: 0.641289, samples/s: 2938.212 1611991459.536998
train: epoch 7, iter 500, loss: 3.578677, top_1: 0.400820, top_k: 0.651406, samples/s: 2984.270 1611991468.1154044
train: epoch 7, iter 600, loss: 3.479398, top_1: 0.397383, top_k: 0.645234, samples/s: 2965.089 1611991476.7494175
train: epoch 7, iter 700, loss: 3.583016, top_1: 0.396914, top_k: 0.643164, samples/s: 3022.779 1611991485.2182577
train: epoch 7, iter 800, loss: 3.653050, top_1: 0.392852, top_k: 0.641563, samples/s: 2966.028 1611991493.849324
train: epoch 7, iter 900, loss: 3.566233, top_1: 0.395703, top_k: 0.642344, samples/s: 2937.365 1611991502.5645006
train: epoch 7, iter 1000, loss: 3.528267, top_1: 0.399023, top_k: 0.644687, samples/s: 2987.845 1611991511.1325345
train: epoch 7, iter 1100, loss: 3.740877, top_1: 0.396406, top_k: 0.643047, samples/s: 2934.709 1611991519.8557868
train: epoch 7, iter 1200, loss: 3.751380, top_1: 0.393672, top_k: 0.643516, samples/s: 2990.299 1611991528.4167387
train: epoch 7, iter 1300, loss: 3.837434, top_1: 0.399922, top_k: 0.645000, samples/s: 2939.870 1611991537.1245458
train: epoch 7, iter 1400, loss: 3.678002, top_1: 0.395625, top_k: 0.643867, samples/s: 2970.382 1611991545.7431314
train: epoch 7, iter 1500, loss: 3.501185, top_1: 0.391289, top_k: 0.639453, samples/s: 3006.033 1611991554.2592769
train: epoch 7, iter 1600, loss: 3.577501, top_1: 0.393555, top_k: 0.646641, samples/s: 2874.900 1611991563.1639783
train: epoch 7, iter 1700, loss: 3.588356, top_1: 0.396680, top_k: 0.643047, samples/s: 3008.098 1611991571.6742685
train: epoch 7, iter 1800, loss: 3.580517, top_1: 0.393555, top_k: 0.640469, samples/s: 2985.578 1611991580.2487946
train: epoch 7, iter 1900, loss: 3.484860, top_1: 0.395000, top_k: 0.645977, samples/s: 2968.613 1611991588.8724217
train: epoch 7, iter 2000, loss: 3.386108, top_1: 0.398125, top_k: 0.648867, samples/s: 2974.310 1611991597.4795363
train: epoch 7, iter 2100, loss: 3.367717, top_1: 0.394766, top_k: 0.641836, samples/s: 3020.534 1611991605.9547417
train: epoch 7, iter 2200, loss: 3.576839, top_1: 0.397695, top_k: 0.648125, samples/s: 2881.018 1611991614.8404357
train: epoch 7, iter 2300, loss: 3.688313, top_1: 0.397383, top_k: 0.649727, samples/s: 2997.169 1611991623.3819726
train: epoch 7, iter 2400, loss: 3.537812, top_1: 0.395000, top_k: 0.644961, samples/s: 3024.101 1611991631.847184
train: epoch 7, iter 2500, loss: 3.394989, top_1: 0.395937, top_k: 0.647344, samples/s: 2985.306 1611991640.4225297
train: epoch 7, iter 2600, loss: 3.549389, top_1: 0.399297, top_k: 0.644336, samples/s: 3007.220 1611991648.935356
train: epoch 7, iter 2700, loss: 3.578224, top_1: 0.393750, top_k: 0.646523, samples/s: 2953.854 1611991657.6020265
train: epoch 7, iter 2800, loss: 3.690051, top_1: 0.395078, top_k: 0.645430, samples/s: 2973.304 1611991666.211957
train: epoch 7, iter 2900, loss: 3.514822, top_1: 0.392695, top_k: 0.640977, samples/s: 2945.200 1611991674.904062
train: epoch 7, iter 3000, loss: 3.630480, top_1: 0.401172, top_k: 0.647070, samples/s: 2888.641 1611991683.7663453
train: epoch 7, iter 3100, loss: 3.636323, top_1: 0.393750, top_k: 0.644766, samples/s: 2942.537 1611991692.4664652
train: epoch 7, iter 3200, loss: 3.536809, top_1: 0.397852, top_k: 0.646953, samples/s: 3017.233 1611991700.9509284
train: epoch 7, iter 3300, loss: 3.764068, top_1: 0.401484, top_k: 0.651094, samples/s: 2992.188 1611991709.5065703
train: epoch 7, iter 3400, loss: 3.596140, top_1: 0.402266, top_k: 0.651094, samples/s: 2990.298 1611991718.0678246
train: epoch 7, iter 3500, loss: 3.525284, top_1: 0.401836, top_k: 0.649375, samples/s: 2944.010 1611991726.7632425
train: epoch 7, iter 3600, loss: 3.422063, top_1: 0.394805, top_k: 0.644258, samples/s: 2998.432 1611991735.300936
train: epoch 7, iter 3700, loss: 3.661182, top_1: 0.392227, top_k: 0.647344, samples/s: 2988.416 1611991743.867416
train: epoch 7, iter 3800, loss: 3.714905, top_1: 0.399062, top_k: 0.645039, samples/s: 2990.302 1611991752.42843
train: epoch 7, iter 3900, loss: 3.723588, top_1: 0.398281, top_k: 0.647500, samples/s: 3022.178 1611991760.8996966
train: epoch 7, iter 4000, loss: 3.661960, top_1: 0.398828, top_k: 0.650977, samples/s: 2981.257 1611991769.4861171
train: epoch 7, iter 4100, loss: 3.645933, top_1: 0.396562, top_k: 0.645625, samples/s: 2882.511 1611991778.3672726
train: epoch 7, iter 4200, loss: 3.414963, top_1: 0.400391, top_k: 0.647852, samples/s: 2930.952 1611991787.1016614
train: epoch 7, iter 4300, loss: 3.716306, top_1: 0.397344, top_k: 0.650508, samples/s: 2915.686 1611991795.8818326
train: epoch 7, iter 4400, loss: 3.512963, top_1: 0.396094, top_k: 0.648906, samples/s: 2948.509 1611991804.5640643
train: epoch 7, iter 4500, loss: 3.562003, top_1: 0.396328, top_k: 0.646406, samples/s: 3015.675 1611991813.0538833
train: epoch 7, iter 4600, loss: 3.584102, top_1: 0.400391, top_k: 0.647266, samples/s: 3012.200 1611991821.5518804
train: epoch 7, iter 4700, loss: 3.606454, top_1: 0.402422, top_k: 0.648359, samples/s: 2932.073 1611991830.282819
train: epoch 7, iter 4800, loss: 3.620056, top_1: 0.401406, top_k: 0.650742, samples/s: 2981.201 1611991838.8699777
train: epoch 7, iter 4900, loss: 3.540625, top_1: 0.406680, top_k: 0.651328, samples/s: 2939.072 1611991847.5802834
train: epoch 7, iter 5000, loss: 3.530772, top_1: 0.399922, top_k: 0.650195, samples/s: 3015.376 1611991856.0702727
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_7.
validation: epoch 7, iter 195, top_1: 0.427424, top_k: 0.690124, samples/s: 2906.681 1611991873.4630384
train: epoch 8, iter 100, loss: 3.496456, top_1: 0.410820, top_k: 0.663008, samples/s: 2939.263 1611991897.8918772
train: epoch 8, iter 200, loss: 3.260313, top_1: 0.409609, top_k: 0.660234, samples/s: 2952.346 1611991906.5627956
train: epoch 8, iter 300, loss: 3.562182, top_1: 0.404453, top_k: 0.654727, samples/s: 2943.475 1611991915.2600322
train: epoch 8, iter 400, loss: 3.728529, top_1: 0.406953, top_k: 0.654336, samples/s: 2988.505 1611991923.8262444
train: epoch 8, iter 500, loss: 3.659561, top_1: 0.401562, top_k: 0.653125, samples/s: 2960.139 1611991932.474419
train: epoch 8, iter 600, loss: 3.481209, top_1: 0.407383, top_k: 0.655977, samples/s: 2993.900 1611991941.0252373
train: epoch 8, iter 700, loss: 3.521530, top_1: 0.407656, top_k: 0.658164, samples/s: 2975.867 1611991949.6277447
train: epoch 8, iter 800, loss: 3.454370, top_1: 0.406680, top_k: 0.653438, samples/s: 2968.286 1611991958.2522242
train: epoch 8, iter 900, loss: 3.509993, top_1: 0.403906, top_k: 0.656992, samples/s: 2999.251 1611991966.7876654
train: epoch 8, iter 1000, loss: 3.627388, top_1: 0.404531, top_k: 0.651172, samples/s: 2971.274 1611991975.403575
train: epoch 8, iter 1100, loss: 3.724895, top_1: 0.400000, top_k: 0.650273, samples/s: 2906.153 1611991984.212424
train: epoch 8, iter 1200, loss: 3.705913, top_1: 0.408555, top_k: 0.656250, samples/s: 2989.647 1611991992.7752771
train: epoch 8, iter 1300, loss: 3.505603, top_1: 0.403516, top_k: 0.652070, samples/s: 2943.174 1611992001.473442
train: epoch 8, iter 1400, loss: 3.609667, top_1: 0.410742, top_k: 0.661367, samples/s: 2981.737 1611992010.0589852
train: epoch 8, iter 1500, loss: 3.560452, top_1: 0.404141, top_k: 0.650195, samples/s: 2948.588 1611992018.7410378
train: epoch 8, iter 1600, loss: 3.575744, top_1: 0.404805, top_k: 0.657578, samples/s: 2934.022 1611992027.4663277
train: epoch 8, iter 1700, loss: 3.494470, top_1: 0.404570, top_k: 0.657773, samples/s: 2961.418 1611992036.1108544
train: epoch 8, iter 1800, loss: 3.314445, top_1: 0.402734, top_k: 0.654570, samples/s: 3009.624 1611992044.6168704
train: epoch 8, iter 1900, loss: 3.600499, top_1: 0.408320, top_k: 0.654922, samples/s: 2915.296 1611992053.398185
train: epoch 8, iter 2000, loss: 3.647086, top_1: 0.410039, top_k: 0.657227, samples/s: 3002.455 1611992061.924497
train: epoch 8, iter 2100, loss: 3.666276, top_1: 0.408047, top_k: 0.657109, samples/s: 3005.993 1611992070.4408164
train: epoch 8, iter 2200, loss: 3.512964, top_1: 0.410742, top_k: 0.660078, samples/s: 2932.956 1611992079.1692626
train: epoch 8, iter 2300, loss: 3.619828, top_1: 0.407969, top_k: 0.659766, samples/s: 2968.612 1611992087.792827
train: epoch 8, iter 2400, loss: 3.612628, top_1: 0.407656, top_k: 0.652617, samples/s: 2930.761 1611992096.5276923
train: epoch 8, iter 2500, loss: 3.477055, top_1: 0.405586, top_k: 0.654336, samples/s: 2997.751 1611992105.0675025
train: epoch 8, iter 2600, loss: 3.575790, top_1: 0.408945, top_k: 0.654336, samples/s: 2993.447 1611992113.6194441
train: epoch 8, iter 2700, loss: 3.351538, top_1: 0.409375, top_k: 0.656758, samples/s: 2914.302 1611992122.403776
train: epoch 8, iter 2800, loss: 3.505634, top_1: 0.413633, top_k: 0.659336, samples/s: 3002.028 1611992130.9314017
train: epoch 8, iter 2900, loss: 3.527978, top_1: 0.407422, top_k: 0.656172, samples/s: 2920.154 1611992139.6980102
train: epoch 8, iter 3000, loss: 3.413241, top_1: 0.410469, top_k: 0.657969, samples/s: 2982.818 1611992148.2804558
train: epoch 8, iter 3100, loss: 3.545227, top_1: 0.408047, top_k: 0.658320, samples/s: 2986.556 1611992156.8523195
train: epoch 8, iter 3200, loss: 3.626300, top_1: 0.412578, top_k: 0.660586, samples/s: 2950.234 1611992165.5294785
train: epoch 8, iter 3300, loss: 3.377911, top_1: 0.410742, top_k: 0.660469, samples/s: 2988.987 1611992174.0942597
train: epoch 8, iter 3400, loss: 3.509061, top_1: 0.401562, top_k: 0.653320, samples/s: 2944.651 1611992182.7880049
train: epoch 8, iter 3500, loss: 3.294669, top_1: 0.413828, top_k: 0.660898, samples/s: 2988.164 1611992191.3551848
train: epoch 8, iter 3600, loss: 3.601405, top_1: 0.413867, top_k: 0.653906, samples/s: 2947.535 1611992200.040352
train: epoch 8, iter 3700, loss: 3.582967, top_1: 0.404727, top_k: 0.655586, samples/s: 2991.173 1611992208.5988655
train: epoch 8, iter 3800, loss: 3.417170, top_1: 0.410781, top_k: 0.659883, samples/s: 2995.176 1611992217.1459236
train: epoch 8, iter 3900, loss: 3.382010, top_1: 0.410859, top_k: 0.656484, samples/s: 2979.499 1611992225.7379634
train: epoch 8, iter 4000, loss: 3.500597, top_1: 0.405664, top_k: 0.655352, samples/s: 2983.317 1611992234.3190646
train: epoch 8, iter 4100, loss: 3.390754, top_1: 0.409727, top_k: 0.656211, samples/s: 2941.511 1611992243.0221379
train: epoch 8, iter 4200, loss: 3.514020, top_1: 0.402891, top_k: 0.658398, samples/s: 3001.937 1611992251.5498748
train: epoch 8, iter 4300, loss: 3.732170, top_1: 0.402969, top_k: 0.654922, samples/s: 2982.920 1611992260.1321127
train: epoch 8, iter 4400, loss: 3.525728, top_1: 0.406094, top_k: 0.655508, samples/s: 2983.603 1611992268.71247
train: epoch 8, iter 4500, loss: 3.765078, top_1: 0.410508, top_k: 0.659375, samples/s: 2922.797 1611992277.4710035
train: epoch 8, iter 4600, loss: 3.554187, top_1: 0.409141, top_k: 0.661016, samples/s: 2936.970 1611992286.1875203
train: epoch 8, iter 4700, loss: 3.419970, top_1: 0.411367, top_k: 0.658555, samples/s: 2965.650 1611992294.819642
train: epoch 8, iter 4800, loss: 3.383393, top_1: 0.411484, top_k: 0.659023, samples/s: 2966.750 1611992303.4486184
train: epoch 8, iter 4900, loss: 3.354164, top_1: 0.407930, top_k: 0.652383, samples/s: 3009.412 1611992311.9552472
train: epoch 8, iter 5000, loss: 3.453303, top_1: 0.411055, top_k: 0.654727, samples/s: 2986.476 1611992320.5272565
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_8.
validation: epoch 8, iter 195, top_1: 0.432051, top_k: 0.696995, samples/s: 2977.672 1611992337.4804423
train: epoch 9, iter 100, loss: 3.413983, top_1: 0.422305, top_k: 0.667969, samples/s: 2829.982 1611992362.7896328
train: epoch 9, iter 200, loss: 3.729276, top_1: 0.415977, top_k: 0.672188, samples/s: 2995.598 1611992371.3354843
train: epoch 9, iter 300, loss: 3.357697, top_1: 0.419531, top_k: 0.671562, samples/s: 2956.448 1611992379.9945936
train: epoch 9, iter 400, loss: 3.447807, top_1: 0.413672, top_k: 0.664375, samples/s: 2948.176 1611992388.6777682
train: epoch 9, iter 500, loss: 3.640870, top_1: 0.412930, top_k: 0.665625, samples/s: 3008.997 1611992397.1856484
train: epoch 9, iter 600, loss: 3.353746, top_1: 0.410352, top_k: 0.659492, samples/s: 2870.598 1611992406.1036537
train: epoch 9, iter 700, loss: 3.428055, top_1: 0.412070, top_k: 0.662891, samples/s: 2967.089 1611992414.731656
train: epoch 9, iter 800, loss: 3.625334, top_1: 0.421367, top_k: 0.667109, samples/s: 2994.170 1611992423.2816176
train: epoch 9, iter 900, loss: 3.581669, top_1: 0.411992, top_k: 0.658203, samples/s: 2998.721 1611992431.8185596
train: epoch 9, iter 1000, loss: 3.371865, top_1: 0.419648, top_k: 0.667383, samples/s: 2977.071 1611992440.4178588
train: epoch 9, iter 1100, loss: 3.449452, top_1: 0.417031, top_k: 0.660078, samples/s: 2977.631 1611992449.015111
train: epoch 9, iter 1200, loss: 3.417996, top_1: 0.409922, top_k: 0.663086, samples/s: 2894.632 1611992457.8590443
train: epoch 9, iter 1300, loss: 3.488640, top_1: 0.411719, top_k: 0.658398, samples/s: 2960.631 1611992466.5058854
train: epoch 9, iter 1400, loss: 3.424646, top_1: 0.418828, top_k: 0.663086, samples/s: 2932.925 1611992475.2343102
train: epoch 9, iter 1500, loss: 3.492248, top_1: 0.412500, top_k: 0.666016, samples/s: 3002.757 1611992483.7597895
train: epoch 9, iter 1600, loss: 3.439984, top_1: 0.411602, top_k: 0.662617, samples/s: 2923.370 1611992492.516827
train: epoch 9, iter 1700, loss: 3.466959, top_1: 0.410664, top_k: 0.666055, samples/s: 2944.159 1611992501.2119339
train: epoch 9, iter 1800, loss: 3.529190, top_1: 0.415781, top_k: 0.666328, samples/s: 2973.854 1611992509.8203382
train: epoch 9, iter 1900, loss: 3.429370, top_1: 0.416758, top_k: 0.665625, samples/s: 2922.315 1611992518.580552
train: epoch 9, iter 2000, loss: 3.644472, top_1: 0.416445, top_k: 0.663320, samples/s: 2975.297 1611992527.1847377
train: epoch 9, iter 2100, loss: 3.435403, top_1: 0.415508, top_k: 0.667422, samples/s: 2945.982 1611992535.8746321
train: epoch 9, iter 2200, loss: 3.349536, top_1: 0.418516, top_k: 0.667070, samples/s: 2982.795 1611992544.4572282
train: epoch 9, iter 2300, loss: 3.546792, top_1: 0.416680, top_k: 0.664570, samples/s: 2904.134 1611992553.2721162
train: epoch 9, iter 2400, loss: 3.176694, top_1: 0.416445, top_k: 0.665469, samples/s: 2959.236 1611992561.9230394
train: epoch 9, iter 2500, loss: 3.464235, top_1: 0.416055, top_k: 0.663516, samples/s: 3010.239 1611992570.4272594
train: epoch 9, iter 2600, loss: 3.379026, top_1: 0.416406, top_k: 0.665859, samples/s: 2992.382 1611992578.9823625
train: epoch 9, iter 2700, loss: 3.554694, top_1: 0.415859, top_k: 0.661758, samples/s: 2959.611 1611992587.63265
train: epoch 9, iter 2800, loss: 3.380611, top_1: 0.412734, top_k: 0.655117, samples/s: 2984.469 1611992596.2098994
train: epoch 9, iter 2900, loss: 3.472600, top_1: 0.413672, top_k: 0.666289, samples/s: 2960.767 1611992604.8563957
train: epoch 9, iter 3000, loss: 3.483340, top_1: 0.417891, top_k: 0.665898, samples/s: 2990.217 1611992613.4175153
train: epoch 9, iter 3100, loss: 3.555896, top_1: 0.414961, top_k: 0.667500, samples/s: 2970.115 1611992622.03715
train: epoch 9, iter 3200, loss: 3.466005, top_1: 0.417305, top_k: 0.665859, samples/s: 2977.863 1611992630.6334739
train: epoch 9, iter 3300, loss: 3.710737, top_1: 0.413438, top_k: 0.662969, samples/s: 2820.723 1611992639.7091699
train: epoch 9, iter 3400, loss: 3.555214, top_1: 0.416797, top_k: 0.666953, samples/s: 2957.785 1611992648.3645005
train: epoch 9, iter 3500, loss: 3.352969, top_1: 0.413438, top_k: 0.666250, samples/s: 2979.925 1611992656.955124
train: epoch 9, iter 3600, loss: 3.338464, top_1: 0.417891, top_k: 0.667031, samples/s: 2957.855 1611992665.6100245
train: epoch 9, iter 3700, loss: 3.547876, top_1: 0.418711, top_k: 0.664180, samples/s: 3010.201 1611992674.1144483
train: epoch 9, iter 3800, loss: 3.388518, top_1: 0.417969, top_k: 0.666523, samples/s: 2945.039 1611992682.8070405
train: epoch 9, iter 3900, loss: 3.381367, top_1: 0.422734, top_k: 0.674102, samples/s: 2992.720 1611992691.3611166
train: epoch 9, iter 4000, loss: 3.380894, top_1: 0.417148, top_k: 0.663828, samples/s: 2928.067 1611992700.1042101
train: epoch 9, iter 4100, loss: 3.383923, top_1: 0.423359, top_k: 0.667383, samples/s: 3004.332 1611992708.6252015
train: epoch 9, iter 4200, loss: 3.450194, top_1: 0.417656, top_k: 0.666016, samples/s: 2890.797 1611992717.4808064
train: epoch 9, iter 4300, loss: 3.441611, top_1: 0.420586, top_k: 0.667461, samples/s: 3000.417 1611992726.013032
train: epoch 9, iter 4400, loss: 3.510727, top_1: 0.416797, top_k: 0.665508, samples/s: 2935.054 1611992734.7351446
train: epoch 9, iter 4500, loss: 3.470880, top_1: 0.413438, top_k: 0.661992, samples/s: 2924.044 1611992743.4901066
train: epoch 9, iter 4600, loss: 3.368263, top_1: 0.415156, top_k: 0.666172, samples/s: 2940.863 1611992752.1950777
train: epoch 9, iter 4700, loss: 3.451055, top_1: 0.413633, top_k: 0.664648, samples/s: 2946.049 1611992760.884682
train: epoch 9, iter 4800, loss: 3.760255, top_1: 0.418750, top_k: 0.668633, samples/s: 3013.824 1611992769.3788798
train: epoch 9, iter 4900, loss: 3.581105, top_1: 0.417305, top_k: 0.666797, samples/s: 2970.798 1611992777.9960527
train: epoch 9, iter 5000, loss: 3.507381, top_1: 0.425078, top_k: 0.672070, samples/s: 2946.884 1611992786.68319
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_9.
validation: epoch 9, iter 195, top_1: 0.452905, top_k: 0.719111, samples/s: 2921.507 1611992803.9832292
train: epoch 10, iter 100, loss: 3.577652, top_1: 0.427227, top_k: 0.673711, samples/s: 2907.452 1611992828.8455257
train: epoch 10, iter 200, loss: 3.258088, top_1: 0.427227, top_k: 0.675547, samples/s: 3027.516 1611992837.3012881
train: epoch 10, iter 300, loss: 3.573935, top_1: 0.425078, top_k: 0.666914, samples/s: 2975.655 1611992845.9043992
train: epoch 10, iter 400, loss: 3.345294, top_1: 0.423398, top_k: 0.671875, samples/s: 2972.609 1611992854.5163722
train: epoch 10, iter 500, loss: 3.402532, top_1: 0.424258, top_k: 0.671562, samples/s: 2959.334 1611992863.167161
train: epoch 10, iter 600, loss: 3.392558, top_1: 0.425977, top_k: 0.671406, samples/s: 2993.692 1611992871.7182615
train: epoch 10, iter 700, loss: 3.534923, top_1: 0.423867, top_k: 0.668047, samples/s: 2999.701 1611992880.252507
train: epoch 10, iter 800, loss: 3.366881, top_1: 0.428320, top_k: 0.677305, samples/s: 2944.846 1611992888.9456387
train: epoch 10, iter 900, loss: 3.449444, top_1: 0.426289, top_k: 0.668750, samples/s: 2958.430 1611992897.5989838
train: epoch 10, iter 1000, loss: 3.424388, top_1: 0.426836, top_k: 0.669023, samples/s: 3019.651 1611992906.0766656
train: epoch 10, iter 1100, loss: 3.676995, top_1: 0.419961, top_k: 0.666445, samples/s: 3003.302 1611992914.6006432
train: epoch 10, iter 1200, loss: 3.571385, top_1: 0.420859, top_k: 0.670898, samples/s: 2957.986 1611992923.2551162
train: epoch 10, iter 1300, loss: 3.403038, top_1: 0.422461, top_k: 0.673008, samples/s: 2993.685 1611992931.8065226
train: epoch 10, iter 1400, loss: 3.601768, top_1: 0.427148, top_k: 0.671719, samples/s: 2972.766 1611992940.4181616
train: epoch 10, iter 1500, loss: 3.352798, top_1: 0.424531, top_k: 0.670312, samples/s: 2955.319 1611992949.0804298
train: epoch 10, iter 1600, loss: 3.364427, top_1: 0.420156, top_k: 0.666484, samples/s: 2933.566 1611992957.8069751
train: epoch 10, iter 1700, loss: 3.398447, top_1: 0.424844, top_k: 0.668828, samples/s: 3019.732 1611992966.2845764
train: epoch 10, iter 1800, loss: 3.458773, top_1: 0.419492, top_k: 0.670625, samples/s: 3009.415 1611992974.7911317
train: epoch 10, iter 1900, loss: 3.432703, top_1: 0.419570, top_k: 0.669063, samples/s: 2992.953 1611992983.3445477
train: epoch 10, iter 2000, loss: 3.283715, top_1: 0.423867, top_k: 0.669336, samples/s: 2954.886 1611992992.0081735
train: epoch 10, iter 2100, loss: 3.407899, top_1: 0.424687, top_k: 0.676641, samples/s: 2808.411 1611993001.123669
train: epoch 10, iter 2200, loss: 3.570744, top_1: 0.420234, top_k: 0.672070, samples/s: 3019.843 1611993009.6009138
train: epoch 10, iter 2300, loss: 3.417069, top_1: 0.426563, top_k: 0.675234, samples/s: 2969.327 1611993018.2224488
train: epoch 10, iter 2400, loss: 3.684047, top_1: 0.422227, top_k: 0.665117, samples/s: 3008.979 1611993026.7302651
train: epoch 10, iter 2500, loss: 3.445708, top_1: 0.421797, top_k: 0.672500, samples/s: 2974.491 1611993035.3367965
train: epoch 10, iter 2600, loss: 3.493265, top_1: 0.428242, top_k: 0.669922, samples/s: 2917.370 1611993044.111829
train: epoch 10, iter 2700, loss: 3.529263, top_1: 0.421367, top_k: 0.671250, samples/s: 3010.105 1611993052.6164918
train: epoch 10, iter 2800, loss: 3.548232, top_1: 0.421484, top_k: 0.669219, samples/s: 2941.979 1611993061.3180835
train: epoch 10, iter 2900, loss: 3.492594, top_1: 0.421641, top_k: 0.668320, samples/s: 2964.003 1611993069.955104
train: epoch 10, iter 3000, loss: 3.423564, top_1: 0.426406, top_k: 0.672305, samples/s: 2958.653 1611993078.6078787
train: epoch 10, iter 3100, loss: 3.318036, top_1: 0.423906, top_k: 0.671133, samples/s: 3032.103 1611993087.0506513
train: epoch 10, iter 3200, loss: 3.346150, top_1: 0.421563, top_k: 0.673086, samples/s: 2917.637 1611993095.824999
train: epoch 10, iter 3300, loss: 3.509610, top_1: 0.426523, top_k: 0.672539, samples/s: 2939.526 1611993104.533767
train: epoch 10, iter 3400, loss: 3.458588, top_1: 0.426797, top_k: 0.671836, samples/s: 2986.754 1611993113.104894
train: epoch 10, iter 3500, loss: 3.413135, top_1: 0.423594, top_k: 0.668711, samples/s: 2925.994 1611993121.8541884
train: epoch 10, iter 3600, loss: 3.712139, top_1: 0.425312, top_k: 0.674414, samples/s: 2970.835 1611993130.471248
train: epoch 10, iter 3700, loss: 3.359721, top_1: 0.421914, top_k: 0.670312, samples/s: 2901.947 1611993139.2929463
train: epoch 10, iter 3800, loss: 3.257120, top_1: 0.419844, top_k: 0.668867, samples/s: 2991.427 1611993147.8506615
train: epoch 10, iter 3900, loss: 3.439862, top_1: 0.422773, top_k: 0.675547, samples/s: 2905.928 1611993156.6602454
train: epoch 10, iter 4000, loss: 3.496051, top_1: 0.427383, top_k: 0.673008, samples/s: 2986.997 1611993165.2307148
train: epoch 10, iter 4100, loss: 3.327887, top_1: 0.416992, top_k: 0.671094, samples/s: 2942.983 1611993173.9293792
train: epoch 10, iter 4200, loss: 3.457911, top_1: 0.416523, top_k: 0.667422, samples/s: 2976.380 1611993182.5304866
train: epoch 10, iter 4300, loss: 3.391905, top_1: 0.421445, top_k: 0.673164, samples/s: 2953.793 1611993191.197311
train: epoch 10, iter 4400, loss: 3.384370, top_1: 0.423477, top_k: 0.669961, samples/s: 3003.767 1611993199.7199478
train: epoch 10, iter 4500, loss: 3.321881, top_1: 0.425586, top_k: 0.677500, samples/s: 2948.952 1611993208.4009655
train: epoch 10, iter 4600, loss: 3.528650, top_1: 0.424648, top_k: 0.666211, samples/s: 2937.335 1611993217.116313
train: epoch 10, iter 4700, loss: 3.425087, top_1: 0.418828, top_k: 0.670000, samples/s: 2984.154 1611993225.6950016
train: epoch 10, iter 4800, loss: 3.635243, top_1: 0.431445, top_k: 0.673867, samples/s: 3009.382 1611993234.2017004
train: epoch 10, iter 4900, loss: 3.580080, top_1: 0.429141, top_k: 0.675039, samples/s: 2989.745 1611993242.764323
train: epoch 10, iter 5000, loss: 3.346724, top_1: 0.427266, top_k: 0.678438, samples/s: 2972.771 1611993251.375796
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_10.
validation: epoch 10, iter 195, top_1: 0.468930, top_k: 0.727524, samples/s: 2852.047 1611993269.0968919
train: epoch 11, iter 100, loss: 3.764890, top_1: 0.428281, top_k: 0.678203, samples/s: 2857.592 1611993294.3966694
train: epoch 11, iter 200, loss: 3.427235, top_1: 0.426328, top_k: 0.676680, samples/s: 2991.340 1611993302.9546947
train: epoch 11, iter 300, loss: 3.526362, top_1: 0.434766, top_k: 0.681211, samples/s: 3026.084 1611993311.4145105
train: epoch 11, iter 400, loss: 3.497411, top_1: 0.423672, top_k: 0.674102, samples/s: 2994.774 1611993319.9627993
train: epoch 11, iter 500, loss: 3.501791, top_1: 0.427266, top_k: 0.674141, samples/s: 2939.551 1611993328.6714873
train: epoch 11, iter 600, loss: 3.395644, top_1: 0.428828, top_k: 0.677227, samples/s: 2961.374 1611993337.3161466
train: epoch 11, iter 700, loss: 3.234235, top_1: 0.431602, top_k: 0.680937, samples/s: 3040.769 1611993345.7351162
train: epoch 11, iter 800, loss: 3.422238, top_1: 0.427891, top_k: 0.676133, samples/s: 2959.474 1611993354.3852184
train: epoch 11, iter 900, loss: 3.470645, top_1: 0.426875, top_k: 0.674336, samples/s: 2962.702 1611993363.0259912
train: epoch 11, iter 1000, loss: 3.330155, top_1: 0.427539, top_k: 0.675703, samples/s: 2958.784 1611993371.678308
train: epoch 11, iter 1100, loss: 3.448096, top_1: 0.425117, top_k: 0.676250, samples/s: 2963.560 1611993380.3164554
train: epoch 11, iter 1200, loss: 3.582164, top_1: 0.429023, top_k: 0.678203, samples/s: 2956.299 1611993388.9759278
train: epoch 11, iter 1300, loss: 3.332678, top_1: 0.434648, top_k: 0.680430, samples/s: 2989.456 1611993397.5393627
train: epoch 11, iter 1400, loss: 3.568163, top_1: 0.425703, top_k: 0.675781, samples/s: 2928.447 1611993406.2813025
train: epoch 11, iter 1500, loss: 3.417047, top_1: 0.428320, top_k: 0.677461, samples/s: 3017.947 1611993414.7637496
train: epoch 11, iter 1600, loss: 3.383548, top_1: 0.434570, top_k: 0.679961, samples/s: 2830.814 1611993423.807188
train: epoch 11, iter 1700, loss: 3.417395, top_1: 0.423086, top_k: 0.673594, samples/s: 2967.036 1611993432.4353967
train: epoch 11, iter 1800, loss: 3.097639, top_1: 0.435469, top_k: 0.680117, samples/s: 2988.682 1611993441.0009632
train: epoch 11, iter 1900, loss: 3.352907, top_1: 0.428398, top_k: 0.676289, samples/s: 2990.490 1611993449.5613885
train: epoch 11, iter 2000, loss: 3.485770, top_1: 0.426914, top_k: 0.674883, samples/s: 2976.967 1611993458.1607394
train: epoch 11, iter 2100, loss: 3.407086, top_1: 0.430664, top_k: 0.678633, samples/s: 3026.331 1611993466.619924
train: epoch 11, iter 2200, loss: 3.240265, top_1: 0.430273, top_k: 0.678555, samples/s: 2923.002 1611993475.377954
train: epoch 11, iter 2300, loss: 3.334329, top_1: 0.426250, top_k: 0.671328, samples/s: 2952.206 1611993484.0495815
train: epoch 11, iter 2400, loss: 3.553779, top_1: 0.426797, top_k: 0.678633, samples/s: 3002.392 1611993492.5759733
train: epoch 11, iter 2500, loss: 3.513346, top_1: 0.426172, top_k: 0.674297, samples/s: 2957.942 1611993501.2307205
train: epoch 11, iter 2600, loss: 3.453877, top_1: 0.430195, top_k: 0.676133, samples/s: 2978.289 1611993509.8261728
train: epoch 11, iter 2700, loss: 3.623391, top_1: 0.425000, top_k: 0.675859, samples/s: 2997.708 1611993518.366113
train: epoch 11, iter 2800, loss: 3.396681, top_1: 0.431211, top_k: 0.682227, samples/s: 2951.658 1611993527.0391104
train: epoch 11, iter 2900, loss: 3.498883, top_1: 0.428633, top_k: 0.674687, samples/s: 2937.438 1611993535.7542937
train: epoch 11, iter 3000, loss: 3.448951, top_1: 0.423281, top_k: 0.671406, samples/s: 2946.489 1611993544.4425013
train: epoch 11, iter 3100, loss: 3.377857, top_1: 0.432891, top_k: 0.680937, samples/s: 3000.126 1611993552.9755764
train: epoch 11, iter 3200, loss: 3.502625, top_1: 0.428672, top_k: 0.675195, samples/s: 2952.162 1611993561.6471117
train: epoch 11, iter 3300, loss: 3.346500, top_1: 0.429844, top_k: 0.677344, samples/s: 2968.839 1611993570.2699811
train: epoch 11, iter 3400, loss: 3.418058, top_1: 0.427422, top_k: 0.669375, samples/s: 2970.176 1611993578.88898
train: epoch 11, iter 3500, loss: 3.453745, top_1: 0.425508, top_k: 0.677031, samples/s: 2978.038 1611993587.485332
train: epoch 11, iter 3600, loss: 3.513782, top_1: 0.433633, top_k: 0.679453, samples/s: 2951.757 1611993596.158086
train: epoch 11, iter 3700, loss: 3.463633, top_1: 0.435586, top_k: 0.676016, samples/s: 2932.717 1611993604.8871863
train: epoch 11, iter 3800, loss: 3.531060, top_1: 0.429414, top_k: 0.677695, samples/s: 2916.722 1611993613.664435
train: epoch 11, iter 3900, loss: 3.498985, top_1: 0.430898, top_k: 0.681016, samples/s: 2961.626 1611993622.3081493
train: epoch 11, iter 4000, loss: 3.548956, top_1: 0.427891, top_k: 0.674805, samples/s: 2906.055 1611993631.1172574
train: epoch 11, iter 4100, loss: 3.342535, top_1: 0.427266, top_k: 0.678125, samples/s: 2988.777 1611993639.682617
train: epoch 11, iter 4200, loss: 3.420847, top_1: 0.431797, top_k: 0.681484, samples/s: 2974.368 1611993648.2894824
train: epoch 11, iter 4300, loss: 3.232698, top_1: 0.430820, top_k: 0.680391, samples/s: 2981.910 1611993656.8745992
train: epoch 11, iter 4400, loss: 3.451300, top_1: 0.422070, top_k: 0.670312, samples/s: 2968.425 1611993665.4987016
train: epoch 11, iter 4500, loss: 3.300560, top_1: 0.431211, top_k: 0.678320, samples/s: 2989.780 1611993674.0612044
train: epoch 11, iter 4600, loss: 3.283966, top_1: 0.431016, top_k: 0.679375, samples/s: 2979.219 1611993682.6542258
train: epoch 11, iter 4700, loss: 3.516521, top_1: 0.430586, top_k: 0.677422, samples/s: 2978.368 1611993691.2493827
train: epoch 11, iter 4800, loss: 3.478702, top_1: 0.425273, top_k: 0.674102, samples/s: 2968.883 1611993699.8722808
train: epoch 11, iter 4900, loss: 3.368652, top_1: 0.427422, top_k: 0.673047, samples/s: 2950.710 1611993708.548019
train: epoch 11, iter 5000, loss: 3.338263, top_1: 0.426758, top_k: 0.674687, samples/s: 2965.159 1611993717.1816156
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_11.
validation: epoch 11, iter 195, top_1: 0.456811, top_k: 0.715565, samples/s: 2821.240 1611993735.0912185
train: epoch 12, iter 100, loss: 3.387044, top_1: 0.437070, top_k: 0.680391, samples/s: 2921.742 1611993759.6748157
train: epoch 12, iter 200, loss: 3.158250, top_1: 0.445586, top_k: 0.693750, samples/s: 2985.905 1611993768.2483428
train: epoch 12, iter 300, loss: 3.248034, top_1: 0.437227, top_k: 0.686914, samples/s: 2980.953 1611993776.8365886
train: epoch 12, iter 400, loss: 3.348438, top_1: 0.433437, top_k: 0.680156, samples/s: 2993.824 1611993785.3871288
train: epoch 12, iter 500, loss: 3.321718, top_1: 0.436250, top_k: 0.684453, samples/s: 2991.591 1611993793.9444776
train: epoch 12, iter 600, loss: 3.479289, top_1: 0.437539, top_k: 0.684063, samples/s: 3024.531 1611993802.4085307
train: epoch 12, iter 700, loss: 3.424146, top_1: 0.435039, top_k: 0.681367, samples/s: 2920.676 1611993811.1736486
train: epoch 12, iter 800, loss: 3.431054, top_1: 0.440977, top_k: 0.683789, samples/s: 2980.931 1611993819.7615752
train: epoch 12, iter 900, loss: 3.210888, top_1: 0.441289, top_k: 0.689453, samples/s: 2828.114 1611993828.8134892
train: epoch 12, iter 1000, loss: 3.310871, top_1: 0.436836, top_k: 0.686328, samples/s: 3023.888 1611993837.2794986
train: epoch 12, iter 1100, loss: 3.468061, top_1: 0.437031, top_k: 0.683359, samples/s: 3008.025 1611993845.790006
train: epoch 12, iter 1200, loss: 3.348858, top_1: 0.434570, top_k: 0.676172, samples/s: 2995.046 1611993854.3375216
train: epoch 12, iter 1300, loss: 3.468438, top_1: 0.434805, top_k: 0.683516, samples/s: 2996.698 1611993862.880195
train: epoch 12, iter 1400, loss: 3.337229, top_1: 0.439961, top_k: 0.686172, samples/s: 2938.856 1611993871.5910838
train: epoch 12, iter 1500, loss: 3.507143, top_1: 0.430586, top_k: 0.682852, samples/s: 2979.230 1611993880.1838796
train: epoch 12, iter 1600, loss: 3.537501, top_1: 0.428594, top_k: 0.681953, samples/s: 2995.193 1611993888.731003
train: epoch 12, iter 1700, loss: 3.563572, top_1: 0.437891, top_k: 0.682383, samples/s: 2997.930 1611993897.2701898
train: epoch 12, iter 1800, loss: 3.545392, top_1: 0.439297, top_k: 0.683750, samples/s: 2943.654 1611993905.9669516
train: epoch 12, iter 1900, loss: 3.210374, top_1: 0.433867, top_k: 0.681016, samples/s: 2944.359 1611993914.6614127
train: epoch 12, iter 2000, loss: 3.335167, top_1: 0.433828, top_k: 0.681133, samples/s: 2961.838 1611993923.3047004
train: epoch 12, iter 2100, loss: 3.316870, top_1: 0.431094, top_k: 0.682109, samples/s: 2977.749 1611993931.9018161
train: epoch 12, iter 2200, loss: 3.463453, top_1: 0.434453, top_k: 0.678945, samples/s: 2935.686 1611993940.6220703
train: epoch 12, iter 2300, loss: 3.593658, top_1: 0.435078, top_k: 0.678711, samples/s: 2986.770 1611993949.1932292
train: epoch 12, iter 2400, loss: 3.328101, top_1: 0.434844, top_k: 0.679805, samples/s: 2942.368 1611993957.8936708
train: epoch 12, iter 2500, loss: 3.293195, top_1: 0.434766, top_k: 0.681680, samples/s: 2926.242 1611993966.6420946
train: epoch 12, iter 2600, loss: 3.200521, top_1: 0.431563, top_k: 0.685195, samples/s: 2958.821 1611993975.2942061
train: epoch 12, iter 2700, loss: 3.436203, top_1: 0.435312, top_k: 0.680742, samples/s: 2989.871 1611993983.8564813
train: epoch 12, iter 2800, loss: 3.494400, top_1: 0.429883, top_k: 0.674687, samples/s: 2987.967 1611993992.424137
train: epoch 12, iter 2900, loss: 3.409133, top_1: 0.432266, top_k: 0.680273, samples/s: 2962.373 1611994001.0658665
train: epoch 12, iter 3000, loss: 3.224855, top_1: 0.434297, top_k: 0.680430, samples/s: 2972.594 1611994009.6778858
train: epoch 12, iter 3100, loss: 3.292730, top_1: 0.435352, top_k: 0.683047, samples/s: 2960.020 1611994018.3264413
train: epoch 12, iter 3200, loss: 3.366767, top_1: 0.438633, top_k: 0.683906, samples/s: 3000.992 1611994026.85699
train: epoch 12, iter 3300, loss: 3.414880, top_1: 0.436055, top_k: 0.686602, samples/s: 2904.755 1611994035.67009
train: epoch 12, iter 3400, loss: 3.402996, top_1: 0.435820, top_k: 0.681836, samples/s: 2946.525 1611994044.358318
train: epoch 12, iter 3500, loss: 3.451006, top_1: 0.430156, top_k: 0.675039, samples/s: 3002.649 1611994052.8841255
train: epoch 12, iter 3600, loss: 3.421130, top_1: 0.433477, top_k: 0.684453, samples/s: 3003.362 1611994061.4079266
train: epoch 12, iter 3700, loss: 3.316404, top_1: 0.430781, top_k: 0.678711, samples/s: 2995.474 1611994069.954284
train: epoch 12, iter 3800, loss: 3.458306, top_1: 0.429531, top_k: 0.683008, samples/s: 2781.083 1611994079.1591513
train: epoch 12, iter 3900, loss: 3.349220, top_1: 0.433711, top_k: 0.677852, samples/s: 2938.482 1611994087.8711443
train: epoch 12, iter 4000, loss: 3.557250, top_1: 0.436484, top_k: 0.685195, samples/s: 2980.170 1611994096.4612727
train: epoch 12, iter 4100, loss: 3.244522, top_1: 0.434727, top_k: 0.682617, samples/s: 3026.760 1611994104.9191403
train: epoch 12, iter 4200, loss: 3.364624, top_1: 0.434531, top_k: 0.678438, samples/s: 2978.571 1611994113.513879
train: epoch 12, iter 4300, loss: 3.448103, top_1: 0.440508, top_k: 0.683789, samples/s: 2940.439 1611994122.2201054
train: epoch 12, iter 4400, loss: 3.409754, top_1: 0.431133, top_k: 0.681484, samples/s: 2998.394 1611994130.7579334
train: epoch 12, iter 4500, loss: 3.460888, top_1: 0.431641, top_k: 0.684297, samples/s: 2989.796 1611994139.3204422
train: epoch 12, iter 4600, loss: 3.405246, top_1: 0.433164, top_k: 0.683086, samples/s: 2944.122 1611994148.0157194
train: epoch 12, iter 4700, loss: 3.648672, top_1: 0.428125, top_k: 0.678984, samples/s: 3019.820 1611994156.4931307
train: epoch 12, iter 4800, loss: 3.366737, top_1: 0.428203, top_k: 0.676133, samples/s: 2986.233 1611994165.0657275
train: epoch 12, iter 4900, loss: 3.523649, top_1: 0.439414, top_k: 0.687578, samples/s: 2982.303 1611994173.6496727
train: epoch 12, iter 5000, loss: 3.425854, top_1: 0.428789, top_k: 0.675156, samples/s: 2964.600 1611994182.2849197
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_12.
validation: epoch 12, iter 195, top_1: 0.445733, top_k: 0.708634, samples/s: 2877.459 1611994199.852421
train: epoch 13, iter 100, loss: 3.304891, top_1: 0.443867, top_k: 0.691875, samples/s: 2968.235 1611994225.113892
train: epoch 13, iter 200, loss: 3.356150, top_1: 0.438516, top_k: 0.689023, samples/s: 2996.611 1611994233.6569383
train: epoch 13, iter 300, loss: 3.192379, top_1: 0.438555, top_k: 0.679492, samples/s: 3020.122 1611994242.1337516
train: epoch 13, iter 400, loss: 3.610203, top_1: 0.440117, top_k: 0.686133, samples/s: 2961.390 1611994250.7780254
train: epoch 13, iter 500, loss: 3.449068, top_1: 0.444414, top_k: 0.689805, samples/s: 2968.099 1611994259.4031353
train: epoch 13, iter 600, loss: 3.478837, top_1: 0.437734, top_k: 0.690391, samples/s: 3013.074 1611994267.9001005
train: epoch 13, iter 700, loss: 3.355015, top_1: 0.440273, top_k: 0.689609, samples/s: 2974.913 1611994276.5046022
train: epoch 13, iter 800, loss: 3.441956, top_1: 0.440820, top_k: 0.691562, samples/s: 2977.001 1611994285.1038928
train: epoch 13, iter 900, loss: 3.446825, top_1: 0.436211, top_k: 0.687227, samples/s: 2967.368 1611994293.7311385
train: epoch 13, iter 1000, loss: 3.265931, top_1: 0.438398, top_k: 0.685508, samples/s: 3036.909 1611994302.1607618
train: epoch 13, iter 1100, loss: 3.385419, top_1: 0.438711, top_k: 0.686094, samples/s: 2979.664 1611994310.7523189
train: epoch 13, iter 1200, loss: 3.411418, top_1: 0.438125, top_k: 0.686680, samples/s: 2991.275 1611994319.3104734
train: epoch 13, iter 1300, loss: 3.321812, top_1: 0.440234, top_k: 0.685195, samples/s: 2987.737 1611994327.8788557
train: epoch 13, iter 1400, loss: 3.206134, top_1: 0.436367, top_k: 0.688906, samples/s: 2979.667 1611994336.4703605
train: epoch 13, iter 1500, loss: 3.224878, top_1: 0.435195, top_k: 0.685195, samples/s: 2973.701 1611994345.0791812
train: epoch 13, iter 1600, loss: 3.206624, top_1: 0.440820, top_k: 0.686836, samples/s: 2956.220 1611994353.738864
train: epoch 13, iter 1700, loss: 3.445021, top_1: 0.443711, top_k: 0.688828, samples/s: 2956.591 1611994362.397513
train: epoch 13, iter 1800, loss: 3.202320, top_1: 0.439023, top_k: 0.685391, samples/s: 2990.680 1611994370.9574983
train: epoch 13, iter 1900, loss: 3.454486, top_1: 0.437930, top_k: 0.684648, samples/s: 2963.691 1611994379.5953107
train: epoch 13, iter 2000, loss: 3.245437, top_1: 0.435508, top_k: 0.678672, samples/s: 2953.842 1611994388.262014
train: epoch 13, iter 2100, loss: 3.503819, top_1: 0.443555, top_k: 0.691680, samples/s: 2994.074 1611994396.812299
train: epoch 13, iter 2200, loss: 3.448751, top_1: 0.439023, top_k: 0.686172, samples/s: 2952.548 1611994405.4826734
train: epoch 13, iter 2300, loss: 3.167403, top_1: 0.442148, top_k: 0.683789, samples/s: 3003.665 1611994414.0056274
train: epoch 13, iter 2400, loss: 3.461544, top_1: 0.439727, top_k: 0.688281, samples/s: 2950.785 1611994422.6812375
train: epoch 13, iter 2500, loss: 3.558295, top_1: 0.444727, top_k: 0.688086, samples/s: 2985.613 1611994431.2557256
train: epoch 13, iter 2600, loss: 3.358950, top_1: 0.437695, top_k: 0.687773, samples/s: 2968.944 1611994439.8783321
train: epoch 13, iter 2700, loss: 3.383900, top_1: 0.443828, top_k: 0.690703, samples/s: 2953.122 1611994448.5471072
train: epoch 13, iter 2800, loss: 3.516135, top_1: 0.441680, top_k: 0.689063, samples/s: 2945.529 1611994457.238206
train: epoch 13, iter 2900, loss: 3.601227, top_1: 0.437891, top_k: 0.684375, samples/s: 2992.716 1611994465.7923396
train: epoch 13, iter 3000, loss: 3.545942, top_1: 0.431797, top_k: 0.679609, samples/s: 2937.926 1611994474.5060902
train: epoch 13, iter 3100, loss: 3.459828, top_1: 0.441016, top_k: 0.687109, samples/s: 2964.441 1611994483.1417382
train: epoch 13, iter 3200, loss: 3.342736, top_1: 0.438086, top_k: 0.683945, samples/s: 2965.232 1611994491.7750676
train: epoch 13, iter 3300, loss: 3.241279, top_1: 0.440352, top_k: 0.688125, samples/s: 2979.424 1611994500.3673406
train: epoch 13, iter 3400, loss: 3.399805, top_1: 0.435391, top_k: 0.684922, samples/s: 2967.256 1611994508.9949753
train: epoch 13, iter 3500, loss: 3.487178, top_1: 0.436406, top_k: 0.683555, samples/s: 2983.466 1611994517.5754375
train: epoch 13, iter 3600, loss: 3.494061, top_1: 0.441211, top_k: 0.687187, samples/s: 2967.765 1611994526.2015448
train: epoch 13, iter 3700, loss: 3.528362, top_1: 0.441836, top_k: 0.681289, samples/s: 2929.558 1611994534.9400516
train: epoch 13, iter 3800, loss: 3.191387, top_1: 0.429297, top_k: 0.684766, samples/s: 2977.706 1611994543.5377097
train: epoch 13, iter 3900, loss: 3.393761, top_1: 0.435469, top_k: 0.682305, samples/s: 2955.182 1611994552.2001047
train: epoch 13, iter 4000, loss: 3.378384, top_1: 0.444570, top_k: 0.690977, samples/s: 2970.461 1611994560.8181605
train: epoch 13, iter 4100, loss: 3.400290, top_1: 0.439453, top_k: 0.685703, samples/s: 2974.039 1611994569.4263337
train: epoch 13, iter 4200, loss: 3.430306, top_1: 0.442461, top_k: 0.685195, samples/s: 2976.960 1611994578.025335
train: epoch 13, iter 4300, loss: 3.353848, top_1: 0.441133, top_k: 0.688789, samples/s: 2963.992 1611994586.662342
train: epoch 13, iter 4400, loss: 3.463232, top_1: 0.442891, top_k: 0.685195, samples/s: 2987.704 1611994595.2309005
train: epoch 13, iter 4500, loss: 3.389596, top_1: 0.446641, top_k: 0.690273, samples/s: 2899.168 1611994604.0609517
train: epoch 13, iter 4600, loss: 3.346124, top_1: 0.429414, top_k: 0.682344, samples/s: 2954.108 1611994612.7268653
train: epoch 13, iter 4700, loss: 3.544150, top_1: 0.439805, top_k: 0.687109, samples/s: 2928.246 1611994621.46927
train: epoch 13, iter 4800, loss: 3.382579, top_1: 0.445352, top_k: 0.687148, samples/s: 2948.818 1611994630.15074
train: epoch 13, iter 4900, loss: 3.502000, top_1: 0.443867, top_k: 0.685703, samples/s: 2957.913 1611994638.805443
train: epoch 13, iter 5000, loss: 3.375071, top_1: 0.440273, top_k: 0.686328, samples/s: 3003.557 1611994647.3286211
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_13.
validation: epoch 13, iter 195, top_1: 0.474720, top_k: 0.735136, samples/s: 2933.243 1611994664.6683996
train: epoch 14, iter 100, loss: 3.332781, top_1: 0.451289, top_k: 0.698633, samples/s: 2919.128 1611994695.1532936
train: epoch 14, iter 200, loss: 3.212454, top_1: 0.444648, top_k: 0.686758, samples/s: 2962.478 1611994703.79479
train: epoch 14, iter 300, loss: 3.380495, top_1: 0.442305, top_k: 0.686953, samples/s: 3002.707 1611994712.3203506
train: epoch 14, iter 400, loss: 3.351652, top_1: 0.449297, top_k: 0.692109, samples/s: 3011.716 1611994720.8204653
train: epoch 14, iter 500, loss: 3.445295, top_1: 0.449531, top_k: 0.692969, samples/s: 2990.644 1611994729.3804588
train: epoch 14, iter 600, loss: 3.525467, top_1: 0.441914, top_k: 0.689727, samples/s: 3008.493 1611994737.889742
train: epoch 14, iter 700, loss: 3.379968, top_1: 0.446406, top_k: 0.697266, samples/s: 3015.505 1611994746.379286
train: epoch 14, iter 800, loss: 3.467031, top_1: 0.449531, top_k: 0.692617, samples/s: 2939.864 1611994755.0871048
train: epoch 14, iter 900, loss: 3.358615, top_1: 0.440781, top_k: 0.690430, samples/s: 3038.958 1611994763.5110347
train: epoch 14, iter 1000, loss: 3.365117, top_1: 0.440195, top_k: 0.690977, samples/s: 2995.730 1611994772.0565243
train: epoch 14, iter 1100, loss: 3.322892, top_1: 0.438789, top_k: 0.690937, samples/s: 2961.412 1611994780.7010572
train: epoch 14, iter 1200, loss: 3.545300, top_1: 0.442695, top_k: 0.688125, samples/s: 2977.358 1611994789.2992728
train: epoch 14, iter 1300, loss: 3.402726, top_1: 0.442695, top_k: 0.689492, samples/s: 2979.374 1611994797.8917346
train: epoch 14, iter 1400, loss: 3.409021, top_1: 0.441367, top_k: 0.691914, samples/s: 2947.932 1611994806.5757651
train: epoch 14, iter 1500, loss: 3.367672, top_1: 0.445742, top_k: 0.690859, samples/s: 2973.576 1611994815.1849172
train: epoch 14, iter 1600, loss: 3.428307, top_1: 0.449453, top_k: 0.693438, samples/s: 2978.867 1611994823.7787771
train: epoch 14, iter 1700, loss: 3.469767, top_1: 0.450469, top_k: 0.693750, samples/s: 2986.951 1611994832.3494062
train: epoch 14, iter 1800, loss: 3.381675, top_1: 0.443867, top_k: 0.686836, samples/s: 2998.849 1611994840.8859446
train: epoch 14, iter 1900, loss: 3.523180, top_1: 0.443359, top_k: 0.688594, samples/s: 2953.044 1611994849.5550702
train: epoch 14, iter 2000, loss: 3.388634, top_1: 0.440664, top_k: 0.692031, samples/s: 2967.683 1611994858.1812851
train: epoch 14, iter 2100, loss: 3.483419, top_1: 0.446602, top_k: 0.693633, samples/s: 3013.930 1611994866.675163
train: epoch 14, iter 2200, loss: 3.489643, top_1: 0.448945, top_k: 0.692656, samples/s: 2977.690 1611994875.2724676
train: epoch 14, iter 2300, loss: 3.403883, top_1: 0.440508, top_k: 0.690195, samples/s: 2964.346 1611994883.9084635
train: epoch 14, iter 2400, loss: 3.163859, top_1: 0.444922, top_k: 0.691016, samples/s: 2932.714 1611994892.6376793
train: epoch 14, iter 2500, loss: 3.307992, top_1: 0.447578, top_k: 0.693203, samples/s: 2975.693 1611994901.2407465
train: epoch 14, iter 2600, loss: 3.441970, top_1: 0.445312, top_k: 0.691406, samples/s: 2954.943 1611994909.9040022
train: epoch 14, iter 2700, loss: 3.113465, top_1: 0.444844, top_k: 0.692070, samples/s: 2969.191 1611994918.5258982
train: epoch 14, iter 2800, loss: 3.498481, top_1: 0.445586, top_k: 0.693281, samples/s: 2945.019 1611994927.2185895
train: epoch 14, iter 2900, loss: 3.515491, top_1: 0.443633, top_k: 0.688281, samples/s: 2942.688 1611994935.9180999
train: epoch 14, iter 3000, loss: 3.406630, top_1: 0.438477, top_k: 0.687227, samples/s: 2978.566 1611994944.5128057
train: epoch 14, iter 3100, loss: 3.548365, top_1: 0.440352, top_k: 0.685664, samples/s: 2968.426 1611994953.1369724
train: epoch 14, iter 3200, loss: 3.299442, top_1: 0.443984, top_k: 0.688281, samples/s: 2966.850 1611994961.7656746
train: epoch 14, iter 3300, loss: 3.566136, top_1: 0.439180, top_k: 0.686914, samples/s: 2991.034 1611994970.3244863
train: epoch 14, iter 3400, loss: 3.445709, top_1: 0.447500, top_k: 0.689531, samples/s: 2990.788 1611994978.884129
train: epoch 14, iter 3500, loss: 3.368771, top_1: 0.444375, top_k: 0.691602, samples/s: 2926.460 1611994987.6319344
train: epoch 14, iter 3600, loss: 3.522578, top_1: 0.443984, top_k: 0.690156, samples/s: 2942.426 1611994996.3321705
train: epoch 14, iter 3700, loss: 3.480087, top_1: 0.447656, top_k: 0.686875, samples/s: 2928.284 1611995005.0745907
train: epoch 14, iter 3800, loss: 3.527072, top_1: 0.439805, top_k: 0.687305, samples/s: 2976.513 1611995013.6764603
train: epoch 14, iter 3900, loss: 3.236982, top_1: 0.437422, top_k: 0.686680, samples/s: 2968.502 1611995022.2990513
train: epoch 14, iter 4000, loss: 3.558996, top_1: 0.439688, top_k: 0.686758, samples/s: 2998.452 1611995030.8373435
train: epoch 14, iter 4100, loss: 3.648441, top_1: 0.442188, top_k: 0.689141, samples/s: 2994.593 1611995039.3856382
train: epoch 14, iter 4200, loss: 3.573938, top_1: 0.441133, top_k: 0.690195, samples/s: 2957.954 1611995048.0401585
train: epoch 14, iter 4300, loss: 3.214433, top_1: 0.442930, top_k: 0.687891, samples/s: 2985.609 1611995056.6146348
train: epoch 14, iter 4400, loss: 3.307179, top_1: 0.440430, top_k: 0.688516, samples/s: 2858.874 1611995065.569323
train: epoch 14, iter 4500, loss: 3.368629, top_1: 0.449414, top_k: 0.690508, samples/s: 2968.913 1611995074.19192
train: epoch 14, iter 4600, loss: 3.338377, top_1: 0.440117, top_k: 0.686758, samples/s: 2861.652 1611995083.1378212
train: epoch 14, iter 4700, loss: 3.296534, top_1: 0.444531, top_k: 0.690117, samples/s: 2913.898 1611995091.9233024
train: epoch 14, iter 4800, loss: 3.355465, top_1: 0.444023, top_k: 0.691406, samples/s: 2994.374 1611995100.47262
train: epoch 14, iter 4900, loss: 3.354463, top_1: 0.446016, top_k: 0.696562, samples/s: 2868.009 1611995109.3987997
train: epoch 14, iter 5000, loss: 3.327979, top_1: 0.447188, top_k: 0.692813, samples/s: 3002.181 1611995117.9258685
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_14.
validation: epoch 14, iter 195, top_1: 0.471775, top_k: 0.731110, samples/s: 2973.519 1611995135.0024195
train: epoch 15, iter 100, loss: 3.512618, top_1: 0.448164, top_k: 0.691797, samples/s: 2973.852 1611995160.3573437
train: epoch 15, iter 200, loss: 3.331588, top_1: 0.448164, top_k: 0.694844, samples/s: 2987.918 1611995168.9251914
train: epoch 15, iter 300, loss: 3.476548, top_1: 0.452539, top_k: 0.698711, samples/s: 2941.686 1611995177.6277492
train: epoch 15, iter 400, loss: 3.453651, top_1: 0.447930, top_k: 0.693594, samples/s: 2990.959 1611995186.18684
train: epoch 15, iter 500, loss: 3.312397, top_1: 0.456406, top_k: 0.695703, samples/s: 2926.666 1611995194.933983
train: epoch 15, iter 600, loss: 3.212092, top_1: 0.452578, top_k: 0.696562, samples/s: 2979.542 1611995203.5260074
train: epoch 15, iter 700, loss: 3.290194, top_1: 0.448398, top_k: 0.694180, samples/s: 2999.275 1611995212.0612886
train: epoch 15, iter 800, loss: 3.459926, top_1: 0.437227, top_k: 0.686836, samples/s: 2998.656 1611995220.598475
train: epoch 15, iter 900, loss: 3.171602, top_1: 0.450273, top_k: 0.695664, samples/s: 2966.204 1611995229.2289867
train: epoch 15, iter 1000, loss: 3.431566, top_1: 0.447148, top_k: 0.697969, samples/s: 2986.570 1611995237.8007028
train: epoch 15, iter 1100, loss: 3.306357, top_1: 0.450078, top_k: 0.696445, samples/s: 2962.153 1611995246.4430487
train: epoch 15, iter 1200, loss: 3.376215, top_1: 0.451914, top_k: 0.695547, samples/s: 2967.621 1611995255.0695553
train: epoch 15, iter 1300, loss: 3.280213, top_1: 0.449727, top_k: 0.693555, samples/s: 2961.573 1611995263.713568
train: epoch 15, iter 1400, loss: 3.346292, top_1: 0.446992, top_k: 0.690547, samples/s: 2994.885 1611995272.2616355
train: epoch 15, iter 1500, loss: 3.224355, top_1: 0.452852, top_k: 0.695430, samples/s: 3008.054 1611995280.7720044
train: epoch 15, iter 1600, loss: 3.290497, top_1: 0.450156, top_k: 0.698672, samples/s: 2908.014 1611995289.5752113
train: epoch 15, iter 1700, loss: 3.314777, top_1: 0.444492, top_k: 0.692852, samples/s: 3006.015 1611995298.091553
train: epoch 15, iter 1800, loss: 3.527794, top_1: 0.452227, top_k: 0.691953, samples/s: 2953.738 1611995306.7584577
train: epoch 15, iter 1900, loss: 3.326089, top_1: 0.447188, top_k: 0.694258, samples/s: 2944.466 1611995315.4527626
train: epoch 15, iter 2000, loss: 3.540373, top_1: 0.446641, top_k: 0.692813, samples/s: 2908.537 1611995324.2544072
train: epoch 15, iter 2100, loss: 3.226902, top_1: 0.453789, top_k: 0.698320, samples/s: 2866.499 1611995333.1851554
train: epoch 15, iter 2200, loss: 3.389911, top_1: 0.447656, top_k: 0.697852, samples/s: 2987.507 1611995341.754162
train: epoch 15, iter 2300, loss: 3.333120, top_1: 0.446641, top_k: 0.692422, samples/s: 2998.705 1611995350.2912
train: epoch 15, iter 2400, loss: 3.176044, top_1: 0.444766, top_k: 0.691016, samples/s: 2963.238 1611995358.9303832
train: epoch 15, iter 2500, loss: 3.455728, top_1: 0.446836, top_k: 0.692383, samples/s: 3025.009 1611995367.393271
train: epoch 15, iter 2600, loss: 3.280831, top_1: 0.448672, top_k: 0.695547, samples/s: 2972.936 1611995376.0041945
train: epoch 15, iter 2700, loss: 3.236740, top_1: 0.446641, top_k: 0.692187, samples/s: 2988.991 1611995384.5689702
train: epoch 15, iter 2800, loss: 3.491261, top_1: 0.448672, top_k: 0.694844, samples/s: 2945.139 1611995393.261245
train: epoch 15, iter 2900, loss: 3.444905, top_1: 0.449648, top_k: 0.696211, samples/s: 2925.221 1611995402.0128322
train: epoch 15, iter 3000, loss: 3.382667, top_1: 0.446875, top_k: 0.695273, samples/s: 2887.152 1611995410.8795507
train: epoch 15, iter 3100, loss: 3.243829, top_1: 0.450234, top_k: 0.698398, samples/s: 2934.639 1611995419.60303
train: epoch 15, iter 3200, loss: 3.427486, top_1: 0.448867, top_k: 0.691953, samples/s: 2918.905 1611995428.37346
train: epoch 15, iter 3300, loss: 3.350775, top_1: 0.450313, top_k: 0.698086, samples/s: 2970.506 1611995436.9914875
train: epoch 15, iter 3400, loss: 3.362797, top_1: 0.449609, top_k: 0.693438, samples/s: 2972.372 1611995445.6041126
train: epoch 15, iter 3500, loss: 3.349132, top_1: 0.443867, top_k: 0.691875, samples/s: 2969.984 1611995454.223767
train: epoch 15, iter 3600, loss: 3.331335, top_1: 0.446055, top_k: 0.693047, samples/s: 2947.733 1611995462.9083183
train: epoch 15, iter 3700, loss: 3.327323, top_1: 0.450586, top_k: 0.692969, samples/s: 2977.681 1611995471.5056403
train: epoch 15, iter 3800, loss: 3.375004, top_1: 0.443750, top_k: 0.687109, samples/s: 2915.630 1611995480.2858844
train: epoch 15, iter 3900, loss: 3.027013, top_1: 0.444453, top_k: 0.689297, samples/s: 2968.260 1611995488.9105186
train: epoch 15, iter 4000, loss: 2.994445, top_1: 0.449648, top_k: 0.693672, samples/s: 2916.814 1611995497.6872308
train: epoch 15, iter 4100, loss: 3.429682, top_1: 0.448320, top_k: 0.694727, samples/s: 2950.174 1611995506.364636
train: epoch 15, iter 4200, loss: 3.364705, top_1: 0.447031, top_k: 0.694063, samples/s: 2958.471 1611995515.0178027
train: epoch 15, iter 4300, loss: 3.387666, top_1: 0.442305, top_k: 0.692305, samples/s: 3004.085 1611995523.539522
train: epoch 15, iter 4400, loss: 3.319567, top_1: 0.446875, top_k: 0.691953, samples/s: 2939.757 1611995532.247769
train: epoch 15, iter 4500, loss: 3.382524, top_1: 0.442812, top_k: 0.694102, samples/s: 2945.436 1611995540.939091
train: epoch 15, iter 4600, loss: 3.289808, top_1: 0.449609, top_k: 0.694727, samples/s: 2947.409 1611995549.6248531
train: epoch 15, iter 4700, loss: 3.364975, top_1: 0.443672, top_k: 0.696016, samples/s: 2958.128 1611995558.2788136
train: epoch 15, iter 4800, loss: 3.318349, top_1: 0.443281, top_k: 0.689688, samples/s: 2996.851 1611995566.821102
train: epoch 15, iter 4900, loss: 3.464592, top_1: 0.443008, top_k: 0.689102, samples/s: 2969.508 1611995575.4421012
train: epoch 15, iter 5000, loss: 3.003646, top_1: 0.449609, top_k: 0.691484, samples/s: 2993.777 1611995583.9931467
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_15.
validation: epoch 15, iter 195, top_1: 0.488482, top_k: 0.744992, samples/s: 2889.113 1611995601.5249372
train: epoch 16, iter 100, loss: 3.210305, top_1: 0.463281, top_k: 0.704883, samples/s: 2968.478 1611995625.9359975
train: epoch 16, iter 200, loss: 3.476707, top_1: 0.461484, top_k: 0.704492, samples/s: 2968.249 1611995634.5605018
train: epoch 16, iter 300, loss: 3.321964, top_1: 0.459688, top_k: 0.700977, samples/s: 2932.956 1611995643.2889466
train: epoch 16, iter 400, loss: 3.383992, top_1: 0.452539, top_k: 0.698516, samples/s: 2995.244 1611995651.8358264
train: epoch 16, iter 500, loss: 3.176211, top_1: 0.453867, top_k: 0.698320, samples/s: 3001.255 1611995660.3656757
train: epoch 16, iter 600, loss: 3.331367, top_1: 0.453398, top_k: 0.700391, samples/s: 2979.817 1611995668.9567623
train: epoch 16, iter 700, loss: 3.184624, top_1: 0.453477, top_k: 0.697266, samples/s: 3005.062 1611995677.4756956
train: epoch 16, iter 800, loss: 3.237475, top_1: 0.451484, top_k: 0.695977, samples/s: 2988.389 1611995686.0422897
train: epoch 16, iter 900, loss: 3.169821, top_1: 0.464414, top_k: 0.705742, samples/s: 3009.937 1611995694.5473523
train: epoch 16, iter 1000, loss: 3.273388, top_1: 0.451836, top_k: 0.698008, samples/s: 2963.361 1611995703.1862903
train: epoch 16, iter 1100, loss: 3.348509, top_1: 0.456445, top_k: 0.703438, samples/s: 2985.803 1611995711.7602046
train: epoch 16, iter 1200, loss: 3.476906, top_1: 0.453633, top_k: 0.698750, samples/s: 2986.424 1611995720.3322244
train: epoch 16, iter 1300, loss: 3.249915, top_1: 0.454961, top_k: 0.702461, samples/s: 2978.426 1611995728.9273446
train: epoch 16, iter 1400, loss: 3.343938, top_1: 0.452148, top_k: 0.695352, samples/s: 2913.767 1611995737.7133427
train: epoch 16, iter 1500, loss: 3.378901, top_1: 0.450430, top_k: 0.696719, samples/s: 2973.091 1611995746.3238094
train: epoch 16, iter 1600, loss: 3.285400, top_1: 0.451914, top_k: 0.697891, samples/s: 2942.147 1611995755.0250053
train: epoch 16, iter 1700, loss: 3.520452, top_1: 0.449492, top_k: 0.695859, samples/s: 2894.601 1611995763.8689969
train: epoch 16, iter 1800, loss: 3.432210, top_1: 0.443867, top_k: 0.693867, samples/s: 2945.973 1611995772.5589008
train: epoch 16, iter 1900, loss: 3.137950, top_1: 0.451875, top_k: 0.695977, samples/s: 2964.109 1611995781.1955607
train: epoch 16, iter 2000, loss: 3.573773, top_1: 0.450703, top_k: 0.695742, samples/s: 2991.150 1611995789.7540593
train: epoch 16, iter 2100, loss: 3.364353, top_1: 0.451289, top_k: 0.698867, samples/s: 2940.118 1611995798.4612038
train: epoch 16, iter 2200, loss: 3.432744, top_1: 0.445859, top_k: 0.690508, samples/s: 2999.751 1611995806.9952955
train: epoch 16, iter 2300, loss: 3.324357, top_1: 0.450039, top_k: 0.698477, samples/s: 2980.587 1611995815.5840812
train: epoch 16, iter 2400, loss: 3.443319, top_1: 0.445742, top_k: 0.693711, samples/s: 2910.181 1611995824.3808653
train: epoch 16, iter 2500, loss: 3.162990, top_1: 0.449922, top_k: 0.695117, samples/s: 2969.467 1611995833.0019104
train: epoch 16, iter 2600, loss: 3.313844, top_1: 0.450195, top_k: 0.695469, samples/s: 3006.312 1611995841.517401
train: epoch 16, iter 2700, loss: 3.455956, top_1: 0.453047, top_k: 0.696289, samples/s: 3012.080 1611995850.0163991
train: epoch 16, iter 2800, loss: 3.279999, top_1: 0.446523, top_k: 0.693477, samples/s: 3004.491 1611995858.5370793
train: epoch 16, iter 2900, loss: 3.197269, top_1: 0.450391, top_k: 0.695078, samples/s: 2951.875 1611995867.2094853
train: epoch 16, iter 3000, loss: 3.196393, top_1: 0.457734, top_k: 0.699922, samples/s: 2965.767 1611995875.8413067
train: epoch 16, iter 3100, loss: 3.361042, top_1: 0.453828, top_k: 0.695469, samples/s: 2985.962 1611995884.4147527
train: epoch 16, iter 3200, loss: 3.315186, top_1: 0.457070, top_k: 0.702031, samples/s: 3000.019 1611995892.9480026
train: epoch 16, iter 3300, loss: 3.323715, top_1: 0.446680, top_k: 0.694805, samples/s: 2993.228 1611995901.5006628
train: epoch 16, iter 3400, loss: 3.375929, top_1: 0.457344, top_k: 0.699922, samples/s: 2950.255 1611995910.1779437
train: epoch 16, iter 3500, loss: 3.381733, top_1: 0.454219, top_k: 0.700820, samples/s: 2958.691 1611995918.8303828
train: epoch 16, iter 3600, loss: 3.243415, top_1: 0.448477, top_k: 0.695195, samples/s: 2994.223 1611995927.3802075
train: epoch 16, iter 3700, loss: 3.364913, top_1: 0.450977, top_k: 0.696719, samples/s: 2976.576 1611995935.9806604
train: epoch 16, iter 3800, loss: 3.337396, top_1: 0.444727, top_k: 0.691562, samples/s: 2986.650 1611995944.552125
train: epoch 16, iter 3900, loss: 3.284058, top_1: 0.450039, top_k: 0.698867, samples/s: 2972.361 1611995953.1648078
train: epoch 16, iter 4000, loss: 3.234826, top_1: 0.445234, top_k: 0.691992, samples/s: 2983.905 1611995961.7442195
train: epoch 16, iter 4100, loss: 3.358687, top_1: 0.451094, top_k: 0.694805, samples/s: 3002.467 1611995970.270511
train: epoch 16, iter 4200, loss: 3.416653, top_1: 0.450508, top_k: 0.698750, samples/s: 2994.573 1611995978.8192842
train: epoch 16, iter 4300, loss: 3.377965, top_1: 0.447031, top_k: 0.693477, samples/s: 2991.576 1611995987.3767424
train: epoch 16, iter 4400, loss: 3.456344, top_1: 0.455117, top_k: 0.696836, samples/s: 3008.295 1611995995.8864381
train: epoch 16, iter 4500, loss: 3.496868, top_1: 0.451875, top_k: 0.697031, samples/s: 2996.003 1611996004.431138
train: epoch 16, iter 4600, loss: 3.157595, top_1: 0.448594, top_k: 0.692930, samples/s: 2967.406 1611996013.0582244
train: epoch 16, iter 4700, loss: 3.490645, top_1: 0.453945, top_k: 0.701094, samples/s: 3000.523 1611996021.5900733
train: epoch 16, iter 4800, loss: 3.488463, top_1: 0.451406, top_k: 0.701172, samples/s: 2965.337 1611996030.2233121
train: epoch 16, iter 4900, loss: 3.207069, top_1: 0.451406, top_k: 0.696914, samples/s: 2950.702 1611996038.8990638
train: epoch 16, iter 5000, loss: 3.517511, top_1: 0.449062, top_k: 0.695312, samples/s: 2991.943 1611996047.4553735
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_16.
validation: epoch 16, iter 195, top_1: 0.490745, top_k: 0.746014, samples/s: 2935.648 1611996064.6965737
train: epoch 17, iter 100, loss: 3.288789, top_1: 0.453945, top_k: 0.699609, samples/s: 2974.163 1611996089.2788637
train: epoch 17, iter 200, loss: 3.220774, top_1: 0.460273, top_k: 0.702578, samples/s: 3010.682 1611996097.7819104
train: epoch 17, iter 300, loss: 3.327106, top_1: 0.458711, top_k: 0.701406, samples/s: 2993.997 1611996106.33238
train: epoch 17, iter 400, loss: 3.100245, top_1: 0.459375, top_k: 0.699453, samples/s: 2894.725 1611996115.1760244
train: epoch 17, iter 500, loss: 3.287424, top_1: 0.457305, top_k: 0.702305, samples/s: 2966.863 1611996123.8047175
train: epoch 17, iter 600, loss: 3.174621, top_1: 0.457109, top_k: 0.701641, samples/s: 2996.747 1611996132.3473873
train: epoch 17, iter 700, loss: 3.207011, top_1: 0.452930, top_k: 0.699414, samples/s: 2998.027 1611996140.886275
train: epoch 17, iter 800, loss: 3.570071, top_1: 0.458359, top_k: 0.702227, samples/s: 2975.070 1611996149.4910316
train: epoch 17, iter 900, loss: 3.257647, top_1: 0.458320, top_k: 0.706211, samples/s: 2966.686 1611996158.120276
train: epoch 17, iter 1000, loss: 3.292384, top_1: 0.454023, top_k: 0.698984, samples/s: 3012.201 1611996166.6189806
train: epoch 17, iter 1100, loss: 3.411430, top_1: 0.456875, top_k: 0.699688, samples/s: 3001.293 1611996175.148752
train: epoch 17, iter 1200, loss: 3.268641, top_1: 0.459258, top_k: 0.702227, samples/s: 2992.089 1611996183.704593
train: epoch 17, iter 1300, loss: 3.337010, top_1: 0.452188, top_k: 0.697148, samples/s: 2998.909 1611996192.2409785
train: epoch 17, iter 1400, loss: 3.290930, top_1: 0.454375, top_k: 0.698203, samples/s: 2984.976 1611996200.817258
train: epoch 17, iter 1500, loss: 3.300423, top_1: 0.457148, top_k: 0.695937, samples/s: 2974.008 1611996209.425195
train: epoch 17, iter 1600, loss: 3.172939, top_1: 0.451602, top_k: 0.702812, samples/s: 2959.533 1611996218.0752265
train: epoch 17, iter 1700, loss: 3.261792, top_1: 0.452188, top_k: 0.693086, samples/s: 2954.547 1611996226.739792
train: epoch 17, iter 1800, loss: 3.166790, top_1: 0.452930, top_k: 0.699375, samples/s: 2996.185 1611996235.284076
train: epoch 17, iter 1900, loss: 3.296212, top_1: 0.454258, top_k: 0.701758, samples/s: 2931.170 1611996244.017789
train: epoch 17, iter 2000, loss: 3.327884, top_1: 0.456641, top_k: 0.706875, samples/s: 2982.136 1611996252.602171
train: epoch 17, iter 2100, loss: 3.315518, top_1: 0.455039, top_k: 0.700781, samples/s: 2909.924 1611996261.399727
train: epoch 17, iter 2200, loss: 3.112001, top_1: 0.456484, top_k: 0.698164, samples/s: 2800.156 1611996270.5420234
train: epoch 17, iter 2300, loss: 3.542670, top_1: 0.455547, top_k: 0.698555, samples/s: 2963.363 1611996279.1808932
train: epoch 17, iter 2400, loss: 3.218052, top_1: 0.459922, top_k: 0.700898, samples/s: 2917.233 1611996287.9563117
train: epoch 17, iter 2500, loss: 3.263374, top_1: 0.451484, top_k: 0.698047, samples/s: 2996.762 1611996296.498763
train: epoch 17, iter 2600, loss: 3.395818, top_1: 0.454453, top_k: 0.698906, samples/s: 2955.655 1611996305.1601837
train: epoch 17, iter 2700, loss: 3.204923, top_1: 0.445703, top_k: 0.694453, samples/s: 2997.747 1611996313.7000217
train: epoch 17, iter 2800, loss: 3.456361, top_1: 0.449805, top_k: 0.697578, samples/s: 2974.182 1611996322.3075314
train: epoch 17, iter 2900, loss: 3.263233, top_1: 0.455117, top_k: 0.696719, samples/s: 3003.218 1611996330.8317065
train: epoch 17, iter 3000, loss: 3.280086, top_1: 0.455898, top_k: 0.699648, samples/s: 2957.234 1611996339.4882348
train: epoch 17, iter 3100, loss: 3.494120, top_1: 0.448008, top_k: 0.698398, samples/s: 3025.007 1611996347.951045
train: epoch 17, iter 3200, loss: 3.134146, top_1: 0.452930, top_k: 0.698477, samples/s: 2939.852 1611996356.6589167
train: epoch 17, iter 3300, loss: 3.356621, top_1: 0.454492, top_k: 0.699336, samples/s: 2949.333 1611996365.3389385
train: epoch 17, iter 3400, loss: 3.312223, top_1: 0.457617, top_k: 0.701602, samples/s: 2979.681 1611996373.9304771
train: epoch 17, iter 3500, loss: 3.280370, top_1: 0.458594, top_k: 0.700508, samples/s: 3015.253 1611996382.42058
train: epoch 17, iter 3600, loss: 3.174085, top_1: 0.452109, top_k: 0.701055, samples/s: 2961.167 1611996391.065836
train: epoch 17, iter 3700, loss: 3.355933, top_1: 0.458867, top_k: 0.698633, samples/s: 2957.347 1611996399.7222717
train: epoch 17, iter 3800, loss: 3.262642, top_1: 0.449961, top_k: 0.701445, samples/s: 3011.637 1611996408.2225928
train: epoch 17, iter 3900, loss: 3.257344, top_1: 0.457617, top_k: 0.703164, samples/s: 2972.147 1611996416.835998
train: epoch 17, iter 4000, loss: 3.239473, top_1: 0.450820, top_k: 0.696562, samples/s: 2938.097 1611996425.5490253
train: epoch 17, iter 4100, loss: 3.240156, top_1: 0.452734, top_k: 0.698086, samples/s: 2962.210 1611996434.191281
train: epoch 17, iter 4200, loss: 3.168763, top_1: 0.450234, top_k: 0.698164, samples/s: 2940.697 1611996442.8967233
train: epoch 17, iter 4300, loss: 3.402346, top_1: 0.459727, top_k: 0.700937, samples/s: 2955.768 1611996451.5577326
train: epoch 17, iter 4400, loss: 3.164030, top_1: 0.454492, top_k: 0.696719, samples/s: 2943.727 1611996460.2543259
train: epoch 17, iter 4500, loss: 3.214855, top_1: 0.453203, top_k: 0.704609, samples/s: 2986.064 1611996468.8272908
train: epoch 17, iter 4600, loss: 3.414089, top_1: 0.459062, top_k: 0.700234, samples/s: 2997.839 1611996477.3667989
train: epoch 17, iter 4700, loss: 3.338134, top_1: 0.454180, top_k: 0.697930, samples/s: 2951.863 1611996486.0395045
train: epoch 17, iter 4800, loss: 3.214365, top_1: 0.455313, top_k: 0.695742, samples/s: 2889.217 1611996494.8998287
train: epoch 17, iter 4900, loss: 3.340791, top_1: 0.457695, top_k: 0.698633, samples/s: 2924.225 1611996503.6544178
train: epoch 17, iter 5000, loss: 3.175102, top_1: 0.452617, top_k: 0.701016, samples/s: 3014.122 1611996512.1487782
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_17.
validation: epoch 17, iter 195, top_1: 0.492488, top_k: 0.746154, samples/s: 2967.225 1611996529.316195
train: epoch 18, iter 100, loss: 3.207714, top_1: 0.460742, top_k: 0.705430, samples/s: 2911.826 1611996554.0903192
train: epoch 18, iter 200, loss: 3.280717, top_1: 0.464414, top_k: 0.706680, samples/s: 2974.968 1611996562.6955655
train: epoch 18, iter 300, loss: 3.315942, top_1: 0.459805, top_k: 0.701172, samples/s: 3025.647 1611996571.1567922
train: epoch 18, iter 400, loss: 3.465607, top_1: 0.460391, top_k: 0.706172, samples/s: 2915.323 1611996579.9376895
train: epoch 18, iter 500, loss: 3.378954, top_1: 0.464609, top_k: 0.707031, samples/s: 2942.884 1611996588.6366267
train: epoch 18, iter 600, loss: 3.387218, top_1: 0.460742, top_k: 0.712070, samples/s: 3001.857 1611996597.164755
train: epoch 18, iter 700, loss: 3.418389, top_1: 0.455430, top_k: 0.701680, samples/s: 2937.072 1611996605.8809047
train: epoch 18, iter 800, loss: 3.391544, top_1: 0.460898, top_k: 0.702930, samples/s: 2971.402 1611996614.496439
train: epoch 18, iter 900, loss: 3.330878, top_1: 0.453320, top_k: 0.702500, samples/s: 3009.614 1611996623.002459
train: epoch 18, iter 1000, loss: 3.187041, top_1: 0.462539, top_k: 0.706992, samples/s: 2993.934 1611996631.553085
train: epoch 18, iter 1100, loss: 3.468961, top_1: 0.461914, top_k: 0.704844, samples/s: 3001.147 1611996640.0830808
train: epoch 18, iter 1200, loss: 3.272665, top_1: 0.457070, top_k: 0.703828, samples/s: 2944.185 1611996648.7781763
train: epoch 18, iter 1300, loss: 3.282066, top_1: 0.452539, top_k: 0.697734, samples/s: 2953.615 1611996657.4454718
train: epoch 18, iter 1400, loss: 3.456675, top_1: 0.455742, top_k: 0.701055, samples/s: 2925.509 1611996666.1962214
train: epoch 18, iter 1500, loss: 3.357064, top_1: 0.461914, top_k: 0.702148, samples/s: 2939.127 1611996674.9062366
train: epoch 18, iter 1600, loss: 3.220370, top_1: 0.461289, top_k: 0.706289, samples/s: 2969.199 1611996683.5280614
train: epoch 18, iter 1700, loss: 3.351563, top_1: 0.457539, top_k: 0.706133, samples/s: 2970.540 1611996692.1460292
train: epoch 18, iter 1800, loss: 3.445494, top_1: 0.455508, top_k: 0.699141, samples/s: 2980.094 1611996700.7363515
train: epoch 18, iter 1900, loss: 3.397291, top_1: 0.457891, top_k: 0.703516, samples/s: 3016.136 1611996709.2240632
train: epoch 18, iter 2000, loss: 3.288516, top_1: 0.462539, top_k: 0.706719, samples/s: 2971.585 1611996717.8390434
train: epoch 18, iter 2100, loss: 3.241171, top_1: 0.452852, top_k: 0.698008, samples/s: 3006.974 1611996726.3525465
train: epoch 18, iter 2200, loss: 3.208316, top_1: 0.458320, top_k: 0.701406, samples/s: 2965.487 1611996734.9852607
train: epoch 18, iter 2300, loss: 3.162408, top_1: 0.457891, top_k: 0.702422, samples/s: 2978.705 1611996743.5795064
train: epoch 18, iter 2400, loss: 3.322304, top_1: 0.454609, top_k: 0.696875, samples/s: 2961.311 1611996752.2243128
train: epoch 18, iter 2500, loss: 3.050027, top_1: 0.461016, top_k: 0.706836, samples/s: 2936.659 1611996760.9418685
train: epoch 18, iter 2600, loss: 3.220646, top_1: 0.463672, top_k: 0.703438, samples/s: 2997.822 1611996769.4814095
train: epoch 18, iter 2700, loss: 3.432340, top_1: 0.464453, top_k: 0.702500, samples/s: 2973.341 1611996778.0911875
train: epoch 18, iter 2800, loss: 3.217663, top_1: 0.460039, top_k: 0.704297, samples/s: 2975.345 1611996786.6952562
train: epoch 18, iter 2900, loss: 3.359100, top_1: 0.461367, top_k: 0.704648, samples/s: 2990.745 1611996795.2548282
train: epoch 18, iter 3000, loss: 3.269341, top_1: 0.456250, top_k: 0.697266, samples/s: 2906.695 1611996804.0621614
train: epoch 18, iter 3100, loss: 3.246972, top_1: 0.458867, top_k: 0.702617, samples/s: 2939.722 1611996812.770447
train: epoch 18, iter 3200, loss: 3.297718, top_1: 0.458711, top_k: 0.701289, samples/s: 2965.759 1611996821.4023128
train: epoch 18, iter 3300, loss: 3.395304, top_1: 0.458047, top_k: 0.699414, samples/s: 2953.033 1611996830.0714757
train: epoch 18, iter 3400, loss: 3.255853, top_1: 0.454922, top_k: 0.699219, samples/s: 2894.437 1611996838.9159055
train: epoch 18, iter 3500, loss: 3.404866, top_1: 0.457031, top_k: 0.705352, samples/s: 2960.111 1611996847.564273
train: epoch 18, iter 3600, loss: 3.243841, top_1: 0.460313, top_k: 0.700430, samples/s: 2963.379 1611996856.2029808
train: epoch 18, iter 3700, loss: 3.263266, top_1: 0.460234, top_k: 0.705000, samples/s: 2976.713 1611996864.8031025
train: epoch 18, iter 3800, loss: 3.320977, top_1: 0.454648, top_k: 0.701992, samples/s: 3006.295 1611996873.3185916
train: epoch 18, iter 3900, loss: 3.098169, top_1: 0.455586, top_k: 0.699063, samples/s: 2975.971 1611996881.92084
train: epoch 18, iter 4000, loss: 3.313954, top_1: 0.459062, top_k: 0.701992, samples/s: 2959.377 1611996890.5712554
train: epoch 18, iter 4100, loss: 3.384502, top_1: 0.454922, top_k: 0.697812, samples/s: 2962.996 1611996899.2111967
train: epoch 18, iter 4200, loss: 3.113487, top_1: 0.457930, top_k: 0.701367, samples/s: 2916.242 1611996907.98958
train: epoch 18, iter 4300, loss: 3.034586, top_1: 0.456641, top_k: 0.698398, samples/s: 2984.161 1611996916.568184
train: epoch 18, iter 4400, loss: 3.314318, top_1: 0.456406, top_k: 0.702656, samples/s: 2971.726 1611996925.1827738
train: epoch 18, iter 4500, loss: 3.508480, top_1: 0.459531, top_k: 0.703789, samples/s: 2979.332 1611996933.7752218
train: epoch 18, iter 4600, loss: 3.260896, top_1: 0.458164, top_k: 0.705117, samples/s: 2956.893 1611996942.4329839
train: epoch 18, iter 4700, loss: 3.486142, top_1: 0.461094, top_k: 0.704102, samples/s: 2964.111 1611996951.0696166
train: epoch 18, iter 4800, loss: 3.158389, top_1: 0.456016, top_k: 0.704531, samples/s: 3014.889 1611996959.5608947
train: epoch 18, iter 4900, loss: 3.198227, top_1: 0.458164, top_k: 0.699180, samples/s: 2963.920 1611996968.1982687
train: epoch 18, iter 5000, loss: 3.491547, top_1: 0.462578, top_k: 0.702070, samples/s: 2998.544 1611996976.7356403
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_18.
validation: epoch 18, iter 195, top_1: 0.479848, top_k: 0.737520, samples/s: 2958.294 1611996993.8484347
train: epoch 19, iter 100, loss: 3.434212, top_1: 0.469414, top_k: 0.711719, samples/s: 2920.994 1611997018.927948
train: epoch 19, iter 200, loss: 3.144350, top_1: 0.461406, top_k: 0.710664, samples/s: 3002.575 1611997027.4538522
train: epoch 19, iter 300, loss: 3.391973, top_1: 0.459531, top_k: 0.704766, samples/s: 3003.980 1611997035.9758725
train: epoch 19, iter 400, loss: 3.292804, top_1: 0.464180, top_k: 0.708359, samples/s: 2888.439 1611997044.8388555
train: epoch 19, iter 500, loss: 3.142342, top_1: 0.466719, top_k: 0.708477, samples/s: 2894.871 1611997053.6820087
train: epoch 19, iter 600, loss: 3.295459, top_1: 0.466367, top_k: 0.711836, samples/s: 3004.269 1611997062.2032282
train: epoch 19, iter 700, loss: 3.070088, top_1: 0.464414, top_k: 0.707617, samples/s: 2889.795 1611997071.0620027
train: epoch 19, iter 800, loss: 3.321815, top_1: 0.465898, top_k: 0.709922, samples/s: 2938.379 1611997079.7743535
train: epoch 19, iter 900, loss: 3.434263, top_1: 0.461406, top_k: 0.703047, samples/s: 2976.056 1611997088.3762207
train: epoch 19, iter 1000, loss: 3.425188, top_1: 0.466914, top_k: 0.710352, samples/s: 2956.347 1611997097.0356793
train: epoch 19, iter 1100, loss: 3.321688, top_1: 0.461641, top_k: 0.708086, samples/s: 3028.156 1611997105.4896128
train: epoch 19, iter 1200, loss: 3.202907, top_1: 0.462148, top_k: 0.707852, samples/s: 3014.626 1611997113.9815273
train: epoch 19, iter 1300, loss: 3.173060, top_1: 0.462266, top_k: 0.708945, samples/s: 2988.233 1611997122.54846
train: epoch 19, iter 1400, loss: 3.274601, top_1: 0.457266, top_k: 0.702734, samples/s: 2984.800 1611997131.1252103
train: epoch 19, iter 1500, loss: 3.322064, top_1: 0.461133, top_k: 0.706523, samples/s: 3006.617 1611997139.6398456
train: epoch 19, iter 1600, loss: 3.267769, top_1: 0.460938, top_k: 0.706172, samples/s: 2917.334 1611997148.4149997
train: epoch 19, iter 1700, loss: 3.070365, top_1: 0.457422, top_k: 0.700508, samples/s: 2946.384 1611997157.1035113
train: epoch 19, iter 1800, loss: 3.355624, top_1: 0.454102, top_k: 0.704648, samples/s: 2930.118 1611997165.840471
train: epoch 19, iter 1900, loss: 3.195830, top_1: 0.462461, top_k: 0.708984, samples/s: 2933.482 1611997174.5673008
train: epoch 19, iter 2000, loss: 3.159772, top_1: 0.460313, top_k: 0.701094, samples/s: 2978.214 1611997183.1629877
train: epoch 19, iter 2100, loss: 3.409730, top_1: 0.459727, top_k: 0.699961, samples/s: 2944.354 1611997191.8576622
train: epoch 19, iter 2200, loss: 3.220567, top_1: 0.464922, top_k: 0.706992, samples/s: 3000.668 1611997200.3890247
train: epoch 19, iter 2300, loss: 3.306130, top_1: 0.462969, top_k: 0.707734, samples/s: 2950.521 1611997209.0655365
train: epoch 19, iter 2400, loss: 3.337858, top_1: 0.464648, top_k: 0.706133, samples/s: 2965.127 1611997217.699171
train: epoch 19, iter 2500, loss: 3.136390, top_1: 0.456719, top_k: 0.707187, samples/s: 2956.972 1611997226.3568172
train: epoch 19, iter 2600, loss: 3.102627, top_1: 0.457539, top_k: 0.703008, samples/s: 2985.273 1611997234.932159
train: epoch 19, iter 2700, loss: 3.367693, top_1: 0.459844, top_k: 0.703750, samples/s: 2932.970 1611997243.6605024
train: epoch 19, iter 2800, loss: 3.287331, top_1: 0.457461, top_k: 0.705000, samples/s: 2960.169 1611997252.3085947
train: epoch 19, iter 2900, loss: 3.287855, top_1: 0.461562, top_k: 0.707187, samples/s: 2930.665 1611997261.0438395
train: epoch 19, iter 3000, loss: 3.307148, top_1: 0.460703, top_k: 0.704805, samples/s: 2912.035 1611997269.8350081
train: epoch 19, iter 3100, loss: 3.356868, top_1: 0.456719, top_k: 0.706367, samples/s: 2981.761 1611997278.4204812
train: epoch 19, iter 3200, loss: 3.058686, top_1: 0.453477, top_k: 0.701406, samples/s: 2985.298 1611997286.9958355
train: epoch 19, iter 3300, loss: 3.194332, top_1: 0.457422, top_k: 0.701094, samples/s: 2974.747 1611997295.6017637
train: epoch 19, iter 3400, loss: 3.208073, top_1: 0.458984, top_k: 0.705430, samples/s: 2962.207 1611997304.2439084
train: epoch 19, iter 3500, loss: 3.244560, top_1: 0.458164, top_k: 0.701992, samples/s: 3037.009 1611997312.6731322
train: epoch 19, iter 3600, loss: 3.307610, top_1: 0.462031, top_k: 0.703477, samples/s: 2995.594 1611997321.2190099
train: epoch 19, iter 3700, loss: 3.283869, top_1: 0.459492, top_k: 0.707383, samples/s: 2982.928 1611997329.8014207
train: epoch 19, iter 3800, loss: 3.287952, top_1: 0.454219, top_k: 0.701641, samples/s: 2967.240 1611997338.4287987
train: epoch 19, iter 3900, loss: 3.422290, top_1: 0.457773, top_k: 0.697187, samples/s: 3011.213 1611997346.930313
train: epoch 19, iter 4000, loss: 3.411562, top_1: 0.463047, top_k: 0.702383, samples/s: 2983.374 1611997355.5111995
train: epoch 19, iter 4100, loss: 3.320509, top_1: 0.455859, top_k: 0.698828, samples/s: 2940.006 1611997364.2186606
train: epoch 19, iter 4200, loss: 3.092249, top_1: 0.463281, top_k: 0.704922, samples/s: 2956.553 1611997372.8773968
train: epoch 19, iter 4300, loss: 3.422885, top_1: 0.459609, top_k: 0.705352, samples/s: 2969.067 1611997381.4996839
train: epoch 19, iter 4400, loss: 3.208861, top_1: 0.457031, top_k: 0.701914, samples/s: 3013.893 1611997389.9936078
train: epoch 19, iter 4500, loss: 3.334435, top_1: 0.456250, top_k: 0.699375, samples/s: 2934.817 1611997398.7166162
train: epoch 19, iter 4600, loss: 3.231896, top_1: 0.466445, top_k: 0.708242, samples/s: 2972.875 1611997407.327743
train: epoch 19, iter 4700, loss: 3.358341, top_1: 0.461328, top_k: 0.701992, samples/s: 3003.375 1611997415.8514051
train: epoch 19, iter 4800, loss: 3.215691, top_1: 0.464453, top_k: 0.706758, samples/s: 2986.875 1611997424.4223263
train: epoch 19, iter 4900, loss: 3.251863, top_1: 0.458125, top_k: 0.700859, samples/s: 2913.922 1611997433.2077284
train: epoch 19, iter 5000, loss: 3.326931, top_1: 0.461953, top_k: 0.707383, samples/s: 2928.896 1611997441.9481452
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_19.
validation: epoch 19, iter 195, top_1: 0.491406, top_k: 0.751042, samples/s: 2959.864 1611997459.0359592
train: epoch 20, iter 100, loss: 3.172300, top_1: 0.464414, top_k: 0.709297, samples/s: 2956.154 1611997483.889984
train: epoch 20, iter 200, loss: 3.257290, top_1: 0.468008, top_k: 0.710742, samples/s: 3012.729 1611997492.387308
train: epoch 20, iter 300, loss: 3.102532, top_1: 0.465430, top_k: 0.713867, samples/s: 3024.349 1611997500.8518474
train: epoch 20, iter 400, loss: 3.359543, top_1: 0.468164, top_k: 0.710547, samples/s: 2988.224 1611997509.4189894
train: epoch 20, iter 500, loss: 3.226446, top_1: 0.470898, top_k: 0.715039, samples/s: 2982.216 1611997518.0030262
train: epoch 20, iter 600, loss: 3.236947, top_1: 0.473516, top_k: 0.713516, samples/s: 2998.404 1611997526.5408964
train: epoch 20, iter 700, loss: 3.416780, top_1: 0.465742, top_k: 0.712344, samples/s: 3017.443 1611997535.0248747
train: epoch 20, iter 800, loss: 3.239929, top_1: 0.467539, top_k: 0.712695, samples/s: 2981.479 1611997543.611254
train: epoch 20, iter 900, loss: 3.278110, top_1: 0.467305, top_k: 0.710234, samples/s: 2903.193 1611997552.4291723
train: epoch 20, iter 1000, loss: 3.060133, top_1: 0.467305, top_k: 0.712969, samples/s: 2948.301 1611997561.1120934
train: epoch 20, iter 1100, loss: 3.584057, top_1: 0.469219, top_k: 0.709531, samples/s: 2999.298 1611997569.6474857
train: epoch 20, iter 1200, loss: 3.365038, top_1: 0.461055, top_k: 0.707969, samples/s: 2990.369 1611997578.2082937
train: epoch 20, iter 1300, loss: 3.315545, top_1: 0.468242, top_k: 0.707617, samples/s: 2990.493 1611997586.7687116
train: epoch 20, iter 1400, loss: 3.299444, top_1: 0.461484, top_k: 0.705313, samples/s: 3013.315 1611997595.2644396
train: epoch 20, iter 1500, loss: 3.394859, top_1: 0.462930, top_k: 0.708555, samples/s: 2857.964 1611997604.2218726
train: epoch 20, iter 1600, loss: 3.254251, top_1: 0.464883, top_k: 0.707617, samples/s: 2909.235 1611997613.0213244
train: epoch 20, iter 1700, loss: 3.269853, top_1: 0.461562, top_k: 0.711016, samples/s: 2944.895 1611997621.7143512
train: epoch 20, iter 1800, loss: 3.233924, top_1: 0.467422, top_k: 0.709023, samples/s: 2959.875 1611997630.3633385
train: epoch 20, iter 1900, loss: 3.287413, top_1: 0.463789, top_k: 0.710430, samples/s: 2980.161 1611997638.9534848
train: epoch 20, iter 2000, loss: 3.236238, top_1: 0.465703, top_k: 0.707070, samples/s: 2978.730 1611997647.5477486
train: epoch 20, iter 2100, loss: 2.999926, top_1: 0.461523, top_k: 0.707227, samples/s: 2974.395 1611997656.154541
train: epoch 20, iter 2200, loss: 3.433610, top_1: 0.468320, top_k: 0.709727, samples/s: 2959.669 1611997664.804221
train: epoch 20, iter 2300, loss: 3.466426, top_1: 0.463789, top_k: 0.707070, samples/s: 2950.121 1611997673.481819
train: epoch 20, iter 2400, loss: 3.264769, top_1: 0.468906, top_k: 0.709883, samples/s: 2964.120 1611997682.1184652
train: epoch 20, iter 2500, loss: 3.318108, top_1: 0.462617, top_k: 0.706016, samples/s: 3015.357 1611997690.6084025
train: epoch 20, iter 2600, loss: 3.095907, top_1: 0.464297, top_k: 0.711016, samples/s: 2974.885 1611997699.2136416
train: epoch 20, iter 2700, loss: 3.143544, top_1: 0.461758, top_k: 0.706602, samples/s: 2983.711 1611997707.7935152
train: epoch 20, iter 2800, loss: 3.058545, top_1: 0.465859, top_k: 0.708164, samples/s: 2993.443 1611997716.3455892
train: epoch 20, iter 2900, loss: 3.214140, top_1: 0.462773, top_k: 0.703906, samples/s: 2963.678 1611997724.9835
train: epoch 20, iter 3000, loss: 3.290007, top_1: 0.465039, top_k: 0.706328, samples/s: 2989.995 1611997733.5453598
train: epoch 20, iter 3100, loss: 3.567178, top_1: 0.459141, top_k: 0.705547, samples/s: 2950.413 1611997742.2221482
train: epoch 20, iter 3200, loss: 3.377925, top_1: 0.462227, top_k: 0.704727, samples/s: 2932.543 1611997750.9517667
train: epoch 20, iter 3300, loss: 3.359226, top_1: 0.463398, top_k: 0.706602, samples/s: 2998.101 1611997759.4906056
train: epoch 20, iter 3400, loss: 3.296955, top_1: 0.461289, top_k: 0.703906, samples/s: 2957.110 1611997768.1476119
train: epoch 20, iter 3500, loss: 3.418418, top_1: 0.462305, top_k: 0.708672, samples/s: 2945.428 1611997776.8390427
train: epoch 20, iter 3600, loss: 3.048652, top_1: 0.458164, top_k: 0.706836, samples/s: 2961.134 1611997785.4844925
train: epoch 20, iter 3700, loss: 3.239211, top_1: 0.455781, top_k: 0.704023, samples/s: 3000.630 1611997794.0159419
train: epoch 20, iter 3800, loss: 3.351503, top_1: 0.462539, top_k: 0.703203, samples/s: 3004.933 1611997802.5352669
train: epoch 20, iter 3900, loss: 3.314169, top_1: 0.463086, top_k: 0.707227, samples/s: 2953.452 1611997811.203236
train: epoch 20, iter 4000, loss: 3.207271, top_1: 0.462656, top_k: 0.708398, samples/s: 3005.175 1611997819.7217143
train: epoch 20, iter 4100, loss: 3.297697, top_1: 0.462500, top_k: 0.703281, samples/s: 2984.881 1611997828.2982712
train: epoch 20, iter 4200, loss: 3.242176, top_1: 0.463047, top_k: 0.710508, samples/s: 2884.336 1611997837.1738594
train: epoch 20, iter 4300, loss: 3.317475, top_1: 0.462773, top_k: 0.710781, samples/s: 2972.853 1611997845.7850547
train: epoch 20, iter 4400, loss: 3.230763, top_1: 0.461875, top_k: 0.707656, samples/s: 2928.078 1611997854.5279858
train: epoch 20, iter 4500, loss: 3.197369, top_1: 0.464570, top_k: 0.708047, samples/s: 2988.089 1611997863.0952857
train: epoch 20, iter 4600, loss: 3.396779, top_1: 0.465430, top_k: 0.704258, samples/s: 2965.005 1611997871.7294385
train: epoch 20, iter 4700, loss: 3.321592, top_1: 0.460664, top_k: 0.706133, samples/s: 3001.786 1611997880.2576358
train: epoch 20, iter 4800, loss: 3.238200, top_1: 0.462695, top_k: 0.705742, samples/s: 2966.590 1611997888.887163
train: epoch 20, iter 4900, loss: 3.238049, top_1: 0.457539, top_k: 0.701680, samples/s: 2975.498 1611997897.4906821
train: epoch 20, iter 5000, loss: 3.210944, top_1: 0.462383, top_k: 0.706250, samples/s: 2973.632 1611997906.09968
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_20.
validation: epoch 20, iter 195, top_1: 0.511899, top_k: 0.765485, samples/s: 2903.628 1611997923.5900788
train: epoch 21, iter 100, loss: 3.222343, top_1: 0.483984, top_k: 0.726016, samples/s: 2879.748 1611997948.8488047
train: epoch 21, iter 200, loss: 3.296746, top_1: 0.477656, top_k: 0.719063, samples/s: 3019.923 1611997957.325775
train: epoch 21, iter 300, loss: 3.507754, top_1: 0.474219, top_k: 0.714258, samples/s: 2937.530 1611997966.0406845
train: epoch 21, iter 400, loss: 3.318054, top_1: 0.469375, top_k: 0.714219, samples/s: 3003.600 1611997974.563843
train: epoch 21, iter 500, loss: 3.146716, top_1: 0.469883, top_k: 0.719063, samples/s: 2949.556 1611997983.2430675
train: epoch 21, iter 600, loss: 3.257737, top_1: 0.474102, top_k: 0.715547, samples/s: 2909.823 1611997992.040861
train: epoch 21, iter 700, loss: 3.162284, top_1: 0.462383, top_k: 0.710547, samples/s: 2958.241 1611998000.6946092
train: epoch 21, iter 800, loss: 3.398159, top_1: 0.466523, top_k: 0.710156, samples/s: 3002.466 1611998009.220958
train: epoch 21, iter 900, loss: 3.219455, top_1: 0.467773, top_k: 0.712148, samples/s: 2963.730 1611998017.858665
train: epoch 21, iter 1000, loss: 3.264590, top_1: 0.465000, top_k: 0.708242, samples/s: 2976.230 1611998026.4601533
train: epoch 21, iter 1100, loss: 3.039305, top_1: 0.467852, top_k: 0.711602, samples/s: 2939.923 1611998035.1678867
train: epoch 21, iter 1200, loss: 3.199789, top_1: 0.471484, top_k: 0.710977, samples/s: 2983.482 1611998043.748437
train: epoch 21, iter 1300, loss: 3.435017, top_1: 0.466211, top_k: 0.708984, samples/s: 2962.936 1611998052.388506
train: epoch 21, iter 1400, loss: 3.069141, top_1: 0.465742, top_k: 0.711523, samples/s: 2966.621 1611998061.0178661
train: epoch 21, iter 1500, loss: 3.405611, top_1: 0.465820, top_k: 0.707734, samples/s: 2952.311 1611998069.689354
train: epoch 21, iter 1600, loss: 3.442218, top_1: 0.469023, top_k: 0.708711, samples/s: 2906.866 1611998078.4957705
train: epoch 21, iter 1700, loss: 3.294919, top_1: 0.466719, top_k: 0.711055, samples/s: 2947.020 1611998087.1825137
train: epoch 21, iter 1800, loss: 3.253795, top_1: 0.463594, top_k: 0.712148, samples/s: 3014.834 1611998095.6742656
train: epoch 21, iter 1900, loss: 3.311746, top_1: 0.467617, top_k: 0.709102, samples/s: 2896.697 1611998104.5115266
train: epoch 21, iter 2000, loss: 3.290767, top_1: 0.466836, top_k: 0.713555, samples/s: 2973.782 1611998113.1201603
train: epoch 21, iter 2100, loss: 3.243725, top_1: 0.467305, top_k: 0.707031, samples/s: 3027.017 1611998121.577253
train: epoch 21, iter 2200, loss: 3.274823, top_1: 0.463008, top_k: 0.704102, samples/s: 3009.504 1611998130.0836325
train: epoch 21, iter 2300, loss: 3.473504, top_1: 0.466289, top_k: 0.709102, samples/s: 2958.058 1611998138.7381496
train: epoch 21, iter 2400, loss: 3.330093, top_1: 0.465742, top_k: 0.713516, samples/s: 2983.571 1611998147.3182826
train: epoch 21, iter 2500, loss: 3.379610, top_1: 0.469297, top_k: 0.711016, samples/s: 2958.880 1611998155.970224
train: epoch 21, iter 2600, loss: 3.329472, top_1: 0.466758, top_k: 0.710273, samples/s: 3000.171 1611998164.5030355
train: epoch 21, iter 2700, loss: 3.287928, top_1: 0.467656, top_k: 0.713477, samples/s: 2996.606 1611998173.0460205
train: epoch 21, iter 2800, loss: 3.295209, top_1: 0.464180, top_k: 0.707852, samples/s: 3006.884 1611998181.5598383
train: epoch 21, iter 2900, loss: 3.262321, top_1: 0.466328, top_k: 0.708945, samples/s: 2975.333 1611998190.163923
train: epoch 21, iter 3000, loss: 3.413881, top_1: 0.463438, top_k: 0.706289, samples/s: 2941.614 1611998198.8666542
train: epoch 21, iter 3100, loss: 3.267010, top_1: 0.461875, top_k: 0.705977, samples/s: 3022.594 1611998207.336558
train: epoch 21, iter 3200, loss: 3.325001, top_1: 0.460078, top_k: 0.708242, samples/s: 3000.876 1611998215.8669753
train: epoch 21, iter 3300, loss: 3.162430, top_1: 0.459492, top_k: 0.705664, samples/s: 2956.289 1611998224.5265322
train: epoch 21, iter 3400, loss: 3.027335, top_1: 0.464141, top_k: 0.707227, samples/s: 2951.266 1611998233.2012837
train: epoch 21, iter 3500, loss: 3.340174, top_1: 0.465313, top_k: 0.706133, samples/s: 2971.114 1611998241.8171463
train: epoch 21, iter 3600, loss: 3.353840, top_1: 0.465273, top_k: 0.707812, samples/s: 2986.213 1611998250.389846
train: epoch 21, iter 3700, loss: 3.269600, top_1: 0.459023, top_k: 0.705781, samples/s: 2982.934 1611998258.9721136
train: epoch 21, iter 3800, loss: 3.206539, top_1: 0.465586, top_k: 0.708086, samples/s: 3007.542 1611998267.483874
train: epoch 21, iter 3900, loss: 3.262073, top_1: 0.463477, top_k: 0.700898, samples/s: 3013.969 1611998275.977663
train: epoch 21, iter 4000, loss: 3.176099, top_1: 0.465898, top_k: 0.702930, samples/s: 3018.527 1611998284.4586446
train: epoch 21, iter 4100, loss: 3.263906, top_1: 0.462187, top_k: 0.705234, samples/s: 2959.249 1611998293.1095023
train: epoch 21, iter 4200, loss: 3.346808, top_1: 0.463555, top_k: 0.711133, samples/s: 2973.398 1611998301.7191436
train: epoch 21, iter 4300, loss: 3.138944, top_1: 0.463398, top_k: 0.704531, samples/s: 2944.049 1611998310.4146771
train: epoch 21, iter 4400, loss: 3.541668, top_1: 0.462070, top_k: 0.705703, samples/s: 2947.816 1611998319.0990748
train: epoch 21, iter 4500, loss: 3.086201, top_1: 0.464570, top_k: 0.708711, samples/s: 2949.097 1611998327.7797258
train: epoch 21, iter 4600, loss: 3.159242, top_1: 0.464180, top_k: 0.704688, samples/s: 2993.914 1611998336.3304079
train: epoch 21, iter 4700, loss: 3.501406, top_1: 0.463047, top_k: 0.703086, samples/s: 2910.161 1611998345.1271427
train: epoch 21, iter 4800, loss: 3.374449, top_1: 0.466328, top_k: 0.707812, samples/s: 2973.558 1611998353.736404
train: epoch 21, iter 4900, loss: 3.501203, top_1: 0.463320, top_k: 0.706523, samples/s: 2964.654 1611998362.3714173
train: epoch 21, iter 5000, loss: 3.235474, top_1: 0.460820, top_k: 0.705781, samples/s: 2969.939 1611998370.9911203
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_21.
validation: epoch 21, iter 195, top_1: 0.494872, top_k: 0.749619, samples/s: 2919.032 1611998388.2820141
train: epoch 22, iter 100, loss: 3.303461, top_1: 0.482148, top_k: 0.721797, samples/s: 2904.876 1611998413.1519575
train: epoch 22, iter 200, loss: 3.365675, top_1: 0.465781, top_k: 0.709883, samples/s: 3017.663 1611998421.6354837
train: epoch 22, iter 300, loss: 3.352024, top_1: 0.469883, top_k: 0.713906, samples/s: 3004.911 1611998430.1548958
train: epoch 22, iter 400, loss: 3.187928, top_1: 0.471445, top_k: 0.714805, samples/s: 3006.029 1611998438.6709719
train: epoch 22, iter 500, loss: 3.009223, top_1: 0.471289, top_k: 0.717383, samples/s: 2985.940 1611998447.244492
train: epoch 22, iter 600, loss: 3.222080, top_1: 0.474570, top_k: 0.717187, samples/s: 2945.717 1611998455.9351263
train: epoch 22, iter 700, loss: 3.142505, top_1: 0.467461, top_k: 0.715313, samples/s: 2991.074 1611998464.4938774
train: epoch 22, iter 800, loss: 3.336724, top_1: 0.471562, top_k: 0.714844, samples/s: 2965.868 1611998473.1254015
train: epoch 22, iter 900, loss: 3.441155, top_1: 0.474062, top_k: 0.713047, samples/s: 2964.449 1611998481.7610025
train: epoch 22, iter 1000, loss: 3.068471, top_1: 0.466523, top_k: 0.711797, samples/s: 2955.486 1611998490.4229531
train: epoch 22, iter 1100, loss: 3.381894, top_1: 0.467852, top_k: 0.713242, samples/s: 3003.496 1611998498.9464545
train: epoch 22, iter 1200, loss: 3.257862, top_1: 0.468516, top_k: 0.712187, samples/s: 2983.955 1611998507.5255826
train: epoch 22, iter 1300, loss: 3.171785, top_1: 0.468711, top_k: 0.714570, samples/s: 2957.736 1611998516.1808674
train: epoch 22, iter 1400, loss: 3.149526, top_1: 0.465547, top_k: 0.711602, samples/s: 2982.071 1611998524.7654502
train: epoch 22, iter 1500, loss: 3.291380, top_1: 0.471680, top_k: 0.710234, samples/s: 2961.497 1611998533.4097388
train: epoch 22, iter 1600, loss: 3.316413, top_1: 0.470430, top_k: 0.712695, samples/s: 2925.004 1611998542.1618514
train: epoch 22, iter 1700, loss: 3.221544, top_1: 0.462813, top_k: 0.712187, samples/s: 2862.407 1611998551.1053588
train: epoch 22, iter 1800, loss: 3.173470, top_1: 0.473398, top_k: 0.715391, samples/s: 2969.263 1611998559.7270162
train: epoch 22, iter 1900, loss: 3.253301, top_1: 0.473320, top_k: 0.715273, samples/s: 2946.678 1611998568.4148352
train: epoch 22, iter 2000, loss: 3.429949, top_1: 0.470508, top_k: 0.715781, samples/s: 2990.476 1611998576.9752343
train: epoch 22, iter 2100, loss: 3.300828, top_1: 0.469141, top_k: 0.715352, samples/s: 2955.006 1611998585.638558
train: epoch 22, iter 2200, loss: 3.189219, top_1: 0.463633, top_k: 0.706562, samples/s: 2913.747 1611998594.424504
train: epoch 22, iter 2300, loss: 3.238550, top_1: 0.473125, top_k: 0.714180, samples/s: 2875.004 1611998603.3288388
train: epoch 22, iter 2400, loss: 3.140344, top_1: 0.471719, top_k: 0.713945, samples/s: 2989.784 1611998611.8913212
train: epoch 22, iter 2500, loss: 3.142880, top_1: 0.470391, top_k: 0.710195, samples/s: 2976.490 1611998620.492055
train: epoch 22, iter 2600, loss: 3.264575, top_1: 0.468750, top_k: 0.711953, samples/s: 2949.851 1611998629.170451
train: epoch 22, iter 2700, loss: 3.147786, top_1: 0.465586, top_k: 0.711992, samples/s: 2922.030 1611998637.9315548
train: epoch 22, iter 2800, loss: 3.372130, top_1: 0.464609, top_k: 0.709453, samples/s: 3010.600 1611998646.434788
train: epoch 22, iter 2900, loss: 3.059784, top_1: 0.468164, top_k: 0.713164, samples/s: 2980.851 1611998655.0229168
train: epoch 22, iter 3000, loss: 3.271333, top_1: 0.465820, top_k: 0.706875, samples/s: 2992.122 1611998663.578723
train: epoch 22, iter 3100, loss: 3.113977, top_1: 0.463398, top_k: 0.710898, samples/s: 2925.752 1611998672.3286052
train: epoch 22, iter 3200, loss: 3.272413, top_1: 0.467461, top_k: 0.710078, samples/s: 3000.867 1611998680.8594666
train: epoch 22, iter 3300, loss: 3.298097, top_1: 0.462266, top_k: 0.706680, samples/s: 2864.704 1611998689.7958598
train: epoch 22, iter 3400, loss: 3.267958, top_1: 0.467031, top_k: 0.710820, samples/s: 2981.729 1611998698.3814116
train: epoch 22, iter 3500, loss: 3.345084, top_1: 0.469570, top_k: 0.714336, samples/s: 3006.570 1611998706.8962362
train: epoch 22, iter 3600, loss: 3.170449, top_1: 0.469102, top_k: 0.707344, samples/s: 2977.932 1611998715.4927297
train: epoch 22, iter 3700, loss: 3.182815, top_1: 0.464141, top_k: 0.707656, samples/s: 2960.094 1611998724.1411846
train: epoch 22, iter 3800, loss: 3.257296, top_1: 0.467187, top_k: 0.708047, samples/s: 2979.515 1611998732.7331114
train: epoch 22, iter 3900, loss: 3.368293, top_1: 0.470977, top_k: 0.714922, samples/s: 2990.331 1611998741.2940142
train: epoch 22, iter 4000, loss: 3.385424, top_1: 0.467422, top_k: 0.710742, samples/s: 3014.565 1611998749.7861905
train: epoch 22, iter 4100, loss: 3.231087, top_1: 0.468711, top_k: 0.712812, samples/s: 2950.264 1611998758.4633095
train: epoch 22, iter 4200, loss: 3.196480, top_1: 0.471484, top_k: 0.710508, samples/s: 2836.022 1611998767.4901237
train: epoch 22, iter 4300, loss: 3.168100, top_1: 0.467148, top_k: 0.709727, samples/s: 2941.920 1611998776.1919003
train: epoch 22, iter 4400, loss: 3.137315, top_1: 0.468594, top_k: 0.710430, samples/s: 2946.337 1611998784.8806725
train: epoch 22, iter 4500, loss: 3.649325, top_1: 0.466602, top_k: 0.710547, samples/s: 2991.406 1611998793.4385045
train: epoch 22, iter 4600, loss: 3.139978, top_1: 0.466406, top_k: 0.706797, samples/s: 2890.742 1611998802.2957637
train: epoch 22, iter 4700, loss: 3.328067, top_1: 0.459570, top_k: 0.707227, samples/s: 2996.255 1611998810.838303
train: epoch 22, iter 4800, loss: 3.326858, top_1: 0.467656, top_k: 0.714023, samples/s: 2955.406 1611998819.500802
train: epoch 22, iter 4900, loss: 3.212496, top_1: 0.465352, top_k: 0.706641, samples/s: 2944.533 1611998828.1944358
train: epoch 22, iter 5000, loss: 3.228987, top_1: 0.472969, top_k: 0.718633, samples/s: 2988.906 1611998836.7595482
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_22.
validation: epoch 22, iter 195, top_1: 0.492728, top_k: 0.751062, samples/s: 2904.627 1611998854.1842625
train: epoch 23, iter 100, loss: 3.116752, top_1: 0.477969, top_k: 0.723047, samples/s: 2942.462 1611998878.9165297
train: epoch 23, iter 200, loss: 3.159706, top_1: 0.482227, top_k: 0.724727, samples/s: 3009.008 1611998887.4242637
train: epoch 23, iter 300, loss: 3.335479, top_1: 0.470625, top_k: 0.714570, samples/s: 2982.898 1611998896.0064793
train: epoch 23, iter 400, loss: 3.131208, top_1: 0.475781, top_k: 0.719141, samples/s: 2925.335 1611998904.7577648
train: epoch 23, iter 500, loss: 3.332839, top_1: 0.473281, top_k: 0.713125, samples/s: 3031.392 1611998913.2025192
train: epoch 23, iter 600, loss: 3.293465, top_1: 0.469414, top_k: 0.714922, samples/s: 2995.434 1611998921.748797
train: epoch 23, iter 700, loss: 3.476793, top_1: 0.471680, top_k: 0.713711, samples/s: 2998.785 1611998930.2856662
train: epoch 23, iter 800, loss: 3.198104, top_1: 0.467461, top_k: 0.712852, samples/s: 2999.123 1611998938.8214617
train: epoch 23, iter 900, loss: 3.140758, top_1: 0.469805, top_k: 0.713984, samples/s: 2974.907 1611998947.42683
train: epoch 23, iter 1000, loss: 3.503275, top_1: 0.470156, top_k: 0.712930, samples/s: 2995.859 1611998955.9719198
train: epoch 23, iter 1100, loss: 3.222353, top_1: 0.469336, top_k: 0.714102, samples/s: 2935.419 1611998964.6930459
train: epoch 23, iter 1200, loss: 3.202003, top_1: 0.471406, top_k: 0.712500, samples/s: 2991.070 1611998973.2517803
train: epoch 23, iter 1300, loss: 3.247484, top_1: 0.471250, top_k: 0.716289, samples/s: 2972.265 1611998981.8649695
train: epoch 23, iter 1400, loss: 3.220217, top_1: 0.468242, top_k: 0.711406, samples/s: 2979.790 1611998990.4559517
train: epoch 23, iter 1500, loss: 3.312507, top_1: 0.474727, top_k: 0.716289, samples/s: 2984.909 1611998999.0324273
train: epoch 23, iter 1600, loss: 3.159412, top_1: 0.470234, top_k: 0.717578, samples/s: 2975.856 1611999007.6350386
train: epoch 23, iter 1700, loss: 3.300761, top_1: 0.467031, top_k: 0.715313, samples/s: 3016.405 1611999016.1219983
train: epoch 23, iter 1800, loss: 3.456406, top_1: 0.466836, top_k: 0.711875, samples/s: 2989.552 1611999024.6851509
train: epoch 23, iter 1900, loss: 3.161597, top_1: 0.472813, top_k: 0.713086, samples/s: 2981.450 1611999033.2715278
train: epoch 23, iter 2000, loss: 3.266304, top_1: 0.468398, top_k: 0.710391, samples/s: 3014.292 1611999041.76445
train: epoch 23, iter 2100, loss: 3.189350, top_1: 0.470000, top_k: 0.710898, samples/s: 2908.482 1611999050.5662692
train: epoch 23, iter 2200, loss: 3.152663, top_1: 0.466758, top_k: 0.710742, samples/s: 2942.521 1611999059.2662694
train: epoch 23, iter 2300, loss: 3.344473, top_1: 0.472344, top_k: 0.716836, samples/s: 2920.809 1611999068.0310092
train: epoch 23, iter 2400, loss: 3.179043, top_1: 0.474062, top_k: 0.717148, samples/s: 2986.447 1611999076.6031294
train: epoch 23, iter 2500, loss: 3.117625, top_1: 0.467461, top_k: 0.709063, samples/s: 2948.345 1611999085.2858381
train: epoch 23, iter 2600, loss: 3.141963, top_1: 0.468008, top_k: 0.711758, samples/s: 2930.460 1611999094.0216591
train: epoch 23, iter 2700, loss: 3.079312, top_1: 0.474297, top_k: 0.717461, samples/s: 2881.432 1611999102.9060795
train: epoch 23, iter 2800, loss: 3.194551, top_1: 0.467852, top_k: 0.714414, samples/s: 3013.530 1611999111.4011977
train: epoch 23, iter 2900, loss: 3.014981, top_1: 0.470703, top_k: 0.717109, samples/s: 2980.064 1611999119.9915748
train: epoch 23, iter 3000, loss: 3.214185, top_1: 0.476016, top_k: 0.715156, samples/s: 2965.231 1611999128.625067
train: epoch 23, iter 3100, loss: 3.309189, top_1: 0.467617, top_k: 0.710000, samples/s: 2994.309 1611999137.174693
train: epoch 23, iter 3200, loss: 3.430708, top_1: 0.469258, top_k: 0.715117, samples/s: 2943.793 1611999145.8708682
train: epoch 23, iter 3300, loss: 3.250776, top_1: 0.470781, top_k: 0.712031, samples/s: 2885.505 1611999154.7440536
train: epoch 23, iter 3400, loss: 3.352797, top_1: 0.469180, top_k: 0.708828, samples/s: 2945.790 1611999163.4330945
train: epoch 23, iter 3500, loss: 3.234952, top_1: 0.468672, top_k: 0.710156, samples/s: 2926.853 1611999172.1801636
train: epoch 23, iter 3600, loss: 3.329260, top_1: 0.466719, top_k: 0.708789, samples/s: 2961.656 1611999180.8235857
train: epoch 23, iter 3700, loss: 3.221202, top_1: 0.465898, top_k: 0.708281, samples/s: 2955.339 1611999189.4857697
train: epoch 23, iter 3800, loss: 3.516279, top_1: 0.472383, top_k: 0.717266, samples/s: 3001.268 1611999198.015857
train: epoch 23, iter 3900, loss: 3.333198, top_1: 0.472266, top_k: 0.713320, samples/s: 2939.409 1611999206.7247734
train: epoch 23, iter 4000, loss: 3.168183, top_1: 0.464297, top_k: 0.710195, samples/s: 2998.403 1611999215.2628229
train: epoch 23, iter 4100, loss: 3.321018, top_1: 0.468828, top_k: 0.715117, samples/s: 2974.408 1611999223.8693962
train: epoch 23, iter 4200, loss: 3.220791, top_1: 0.469180, top_k: 0.712227, samples/s: 2997.171 1611999232.4109068
train: epoch 23, iter 4300, loss: 3.298595, top_1: 0.471641, top_k: 0.717305, samples/s: 2985.237 1611999240.986265
train: epoch 23, iter 4400, loss: 3.336230, top_1: 0.467266, top_k: 0.707305, samples/s: 2966.334 1611999249.6171403
train: epoch 23, iter 4500, loss: 3.220597, top_1: 0.470469, top_k: 0.712852, samples/s: 2966.856 1611999258.2452633
train: epoch 23, iter 4600, loss: 3.130903, top_1: 0.470430, top_k: 0.715664, samples/s: 3015.723 1611999266.734129
train: epoch 23, iter 4700, loss: 3.069326, top_1: 0.464531, top_k: 0.709414, samples/s: 2917.314 1611999275.5093951
train: epoch 23, iter 4800, loss: 3.301188, top_1: 0.472148, top_k: 0.713320, samples/s: 3065.312 1611999283.8607497
train: epoch 23, iter 4900, loss: 3.285736, top_1: 0.475625, top_k: 0.714492, samples/s: 2995.012 1611999292.4082987
train: epoch 23, iter 5000, loss: 3.023659, top_1: 0.469492, top_k: 0.713125, samples/s: 3014.882 1611999300.899488
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_23.
validation: epoch 23, iter 195, top_1: 0.517368, top_k: 0.768269, samples/s: 3032.489 1611999317.6809978
train: epoch 24, iter 100, loss: 3.260220, top_1: 0.477187, top_k: 0.721953, samples/s: 2931.536 1611999342.5305943
train: epoch 24, iter 200, loss: 3.173470, top_1: 0.480508, top_k: 0.722266, samples/s: 2975.221 1611999351.1350048
train: epoch 24, iter 300, loss: 3.384790, top_1: 0.474180, top_k: 0.716367, samples/s: 3020.424 1611999359.6106298
train: epoch 24, iter 400, loss: 3.135436, top_1: 0.477109, top_k: 0.720391, samples/s: 2954.680 1611999368.2749476
train: epoch 24, iter 500, loss: 3.332991, top_1: 0.482773, top_k: 0.714375, samples/s: 3002.900 1611999376.7999172
train: epoch 24, iter 600, loss: 3.094301, top_1: 0.473945, top_k: 0.717852, samples/s: 2967.377 1611999385.4271386
train: epoch 24, iter 700, loss: 3.044083, top_1: 0.467461, top_k: 0.715078, samples/s: 2942.939 1611999394.1259508
train: epoch 24, iter 800, loss: 3.129734, top_1: 0.479102, top_k: 0.714492, samples/s: 3014.716 1611999402.6176379
train: epoch 24, iter 900, loss: 3.328609, top_1: 0.468477, top_k: 0.712695, samples/s: 2988.575 1611999411.183534
train: epoch 24, iter 1000, loss: 3.260270, top_1: 0.473398, top_k: 0.714688, samples/s: 2945.717 1611999419.874223
train: epoch 24, iter 1100, loss: 3.111478, top_1: 0.470430, top_k: 0.713594, samples/s: 3000.925 1611999428.4060721
train: epoch 24, iter 1200, loss: 3.129999, top_1: 0.474375, top_k: 0.713711, samples/s: 2945.097 1611999437.0972311
train: epoch 24, iter 1300, loss: 3.329205, top_1: 0.475078, top_k: 0.721289, samples/s: 2975.112 1611999445.7019656
train: epoch 24, iter 1400, loss: 3.097612, top_1: 0.472852, top_k: 0.716875, samples/s: 3032.047 1611999454.1450868
train: epoch 24, iter 1500, loss: 3.156036, top_1: 0.471133, top_k: 0.712187, samples/s: 2951.922 1611999462.8174555
train: epoch 24, iter 1600, loss: 3.248592, top_1: 0.476016, top_k: 0.717148, samples/s: 2937.354 1611999471.532745
train: epoch 24, iter 1700, loss: 3.274744, top_1: 0.473203, top_k: 0.716641, samples/s: 2992.616 1611999480.0871718
train: epoch 24, iter 1800, loss: 3.235113, top_1: 0.475352, top_k: 0.718203, samples/s: 2996.759 1611999488.629687
train: epoch 24, iter 1900, loss: 3.342654, top_1: 0.477422, top_k: 0.716016, samples/s: 2879.979 1611999497.518627
train: epoch 24, iter 2000, loss: 3.160630, top_1: 0.467813, top_k: 0.711562, samples/s: 2963.170 1611999506.1579845
train: epoch 24, iter 2100, loss: 3.271324, top_1: 0.474805, top_k: 0.714844, samples/s: 2952.706 1611999514.8286622
train: epoch 24, iter 2200, loss: 3.225032, top_1: 0.478047, top_k: 0.719609, samples/s: 2999.812 1611999523.3621118
train: epoch 24, iter 2300, loss: 3.444313, top_1: 0.478906, top_k: 0.719219, samples/s: 2979.071 1611999531.9552224
train: epoch 24, iter 2400, loss: 3.229618, top_1: 0.475078, top_k: 0.715586, samples/s: 2938.697 1611999540.6666007
train: epoch 24, iter 2500, loss: 3.369278, top_1: 0.480898, top_k: 0.719922, samples/s: 3008.487 1611999549.1757953
train: epoch 24, iter 2600, loss: 2.962847, top_1: 0.474375, top_k: 0.714492, samples/s: 3005.992 1611999557.692113
train: epoch 24, iter 2700, loss: 3.299181, top_1: 0.475508, top_k: 0.715586, samples/s: 2926.578 1611999566.4395618
train: epoch 24, iter 2800, loss: 3.224486, top_1: 0.469297, top_k: 0.714180, samples/s: 2989.346 1611999575.00328
train: epoch 24, iter 2900, loss: 3.125064, top_1: 0.472461, top_k: 0.714531, samples/s: 2897.835 1611999583.8375359
train: epoch 24, iter 3000, loss: 3.140159, top_1: 0.479180, top_k: 0.720352, samples/s: 2965.066 1611999592.4713728
train: epoch 24, iter 3100, loss: 3.117006, top_1: 0.469297, top_k: 0.711133, samples/s: 3019.679 1611999600.9491165
train: epoch 24, iter 3200, loss: 3.193035, top_1: 0.466562, top_k: 0.708242, samples/s: 2979.685 1611999609.5406404
train: epoch 24, iter 3300, loss: 3.248348, top_1: 0.471680, top_k: 0.712578, samples/s: 2965.965 1611999618.171905
train: epoch 24, iter 3400, loss: 3.235992, top_1: 0.464844, top_k: 0.714570, samples/s: 3004.012 1611999626.6938295
train: epoch 24, iter 3500, loss: 3.245886, top_1: 0.470977, top_k: 0.716367, samples/s: 2940.323 1611999635.4003136
train: epoch 24, iter 3600, loss: 3.197217, top_1: 0.466875, top_k: 0.709258, samples/s: 2924.910 1611999644.1528053
train: epoch 24, iter 3700, loss: 3.401414, top_1: 0.471719, top_k: 0.712617, samples/s: 2968.142 1611999652.7778203
train: epoch 24, iter 3800, loss: 3.234730, top_1: 0.470508, top_k: 0.717227, samples/s: 2966.707 1611999661.4067163
train: epoch 24, iter 3900, loss: 3.147249, top_1: 0.475430, top_k: 0.713750, samples/s: 2959.227 1611999670.0576317
train: epoch 24, iter 4000, loss: 3.215179, top_1: 0.472422, top_k: 0.716562, samples/s: 2997.964 1611999678.5967906
train: epoch 24, iter 4100, loss: 3.246702, top_1: 0.465781, top_k: 0.710977, samples/s: 2993.989 1611999687.1472237
train: epoch 24, iter 4200, loss: 3.271720, top_1: 0.469258, top_k: 0.715117, samples/s: 2929.493 1611999695.8859658
train: epoch 24, iter 4300, loss: 3.319685, top_1: 0.471250, top_k: 0.717031, samples/s: 3006.531 1611999704.400722
train: epoch 24, iter 4400, loss: 3.162202, top_1: 0.470078, top_k: 0.712930, samples/s: 2962.146 1611999713.0431077
train: epoch 24, iter 4500, loss: 3.153848, top_1: 0.468984, top_k: 0.713398, samples/s: 2911.118 1611999721.8369834
train: epoch 24, iter 4600, loss: 3.204694, top_1: 0.475313, top_k: 0.717930, samples/s: 2918.627 1611999730.608225
train: epoch 24, iter 4700, loss: 3.440618, top_1: 0.468789, top_k: 0.713008, samples/s: 3007.597 1611999739.1201031
train: epoch 24, iter 4800, loss: 3.211755, top_1: 0.474453, top_k: 0.715898, samples/s: 2963.197 1611999747.7593324
train: epoch 24, iter 4900, loss: 3.084396, top_1: 0.471875, top_k: 0.715781, samples/s: 3011.555 1611999756.260041
train: epoch 24, iter 5000, loss: 3.129070, top_1: 0.467852, top_k: 0.711836, samples/s: 2988.263 1611999764.826817
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_24.
validation: epoch 24, iter 195, top_1: 0.516086, top_k: 0.767508, samples/s: 2900.397 1611999782.3473895
train: epoch 25, iter 100, loss: 3.352440, top_1: 0.483477, top_k: 0.725664, samples/s: 2910.569 1611999806.7473848
train: epoch 25, iter 200, loss: 3.076054, top_1: 0.483438, top_k: 0.726953, samples/s: 2983.842 1611999815.3267303
train: epoch 25, iter 300, loss: 3.312978, top_1: 0.482578, top_k: 0.725117, samples/s: 2978.833 1611999823.9207404
train: epoch 25, iter 400, loss: 3.216644, top_1: 0.473750, top_k: 0.715820, samples/s: 2966.660 1611999832.550005
train: epoch 25, iter 500, loss: 3.172264, top_1: 0.478242, top_k: 0.722344, samples/s: 2937.139 1611999841.265949
train: epoch 25, iter 600, loss: 3.068859, top_1: 0.477109, top_k: 0.716250, samples/s: 2972.428 1611999849.8784254
train: epoch 25, iter 700, loss: 3.533268, top_1: 0.470430, top_k: 0.717656, samples/s: 3010.102 1611999858.3831635
train: epoch 25, iter 800, loss: 3.201911, top_1: 0.476992, top_k: 0.718398, samples/s: 2903.926 1611999867.1987991
train: epoch 25, iter 900, loss: 3.200702, top_1: 0.474492, top_k: 0.715859, samples/s: 2935.455 1611999875.9197302
train: epoch 25, iter 1000, loss: 3.231922, top_1: 0.474648, top_k: 0.714141, samples/s: 2980.065 1611999884.5103176
train: epoch 25, iter 1100, loss: 3.124053, top_1: 0.474766, top_k: 0.718086, samples/s: 2980.146 1611999893.1004965
train: epoch 25, iter 1200, loss: 3.364173, top_1: 0.477930, top_k: 0.719531, samples/s: 3005.654 1611999901.6176517
train: epoch 25, iter 1300, loss: 3.289146, top_1: 0.478398, top_k: 0.719102, samples/s: 2960.504 1611999910.2647717
train: epoch 25, iter 1400, loss: 3.209707, top_1: 0.471602, top_k: 0.717344, samples/s: 2981.317 1611999918.8516388
train: epoch 25, iter 1500, loss: 3.224435, top_1: 0.475977, top_k: 0.718320, samples/s: 2987.627 1611999927.420403
train: epoch 25, iter 1600, loss: 3.107813, top_1: 0.475391, top_k: 0.721641, samples/s: 2977.766 1611999936.017307
train: epoch 25, iter 1700, loss: 3.273872, top_1: 0.482305, top_k: 0.717852, samples/s: 2900.206 1611999944.8442366
train: epoch 25, iter 1800, loss: 3.294055, top_1: 0.472266, top_k: 0.719531, samples/s: 2977.641 1611999953.4416983
train: epoch 25, iter 1900, loss: 3.240115, top_1: 0.472891, top_k: 0.716250, samples/s: 2965.086 1611999962.0754943
train: epoch 25, iter 2000, loss: 3.295673, top_1: 0.476094, top_k: 0.716602, samples/s: 2981.756 1611999970.661043
train: epoch 25, iter 2100, loss: 3.308969, top_1: 0.472109, top_k: 0.713789, samples/s: 2946.902 1611999979.3482463
train: epoch 25, iter 2200, loss: 3.342867, top_1: 0.472891, top_k: 0.716055, samples/s: 2965.874 1611999987.9797122
train: epoch 25, iter 2300, loss: 3.196203, top_1: 0.466055, top_k: 0.710625, samples/s: 2979.851 1611999996.570686
train: epoch 25, iter 2400, loss: 3.209731, top_1: 0.470547, top_k: 0.715625, samples/s: 2943.075 1612000005.2690704
train: epoch 25, iter 2500, loss: 3.283819, top_1: 0.473477, top_k: 0.716680, samples/s: 3009.199 1612000013.77632
train: epoch 25, iter 2600, loss: 3.298606, top_1: 0.476367, top_k: 0.722070, samples/s: 2915.774 1612000022.5563624
train: epoch 25, iter 2700, loss: 3.156560, top_1: 0.477031, top_k: 0.720391, samples/s: 2998.959 1612000031.0925183
train: epoch 25, iter 2800, loss: 3.191762, top_1: 0.473438, top_k: 0.717852, samples/s: 2980.669 1612000039.6811333
train: epoch 25, iter 2900, loss: 3.102922, top_1: 0.475781, top_k: 0.717187, samples/s: 2938.394 1612000048.3934917
train: epoch 25, iter 3000, loss: 3.074142, top_1: 0.475586, top_k: 0.719805, samples/s: 2958.412 1612000057.0466452
train: epoch 25, iter 3100, loss: 3.353480, top_1: 0.475117, top_k: 0.719102, samples/s: 2935.167 1612000065.768563
train: epoch 25, iter 3200, loss: 3.407046, top_1: 0.475234, top_k: 0.716094, samples/s: 2978.127 1612000074.3645902
train: epoch 25, iter 3300, loss: 3.269252, top_1: 0.471992, top_k: 0.715547, samples/s: 2988.925 1612000082.9294431
train: epoch 25, iter 3400, loss: 3.071200, top_1: 0.471758, top_k: 0.715625, samples/s: 2956.839 1612000091.587353
train: epoch 25, iter 3500, loss: 3.366339, top_1: 0.476914, top_k: 0.720234, samples/s: 2944.187 1612000100.2824152
train: epoch 25, iter 3600, loss: 3.272058, top_1: 0.470938, top_k: 0.711797, samples/s: 2987.120 1612000108.8526576
train: epoch 25, iter 3700, loss: 3.432328, top_1: 0.474766, top_k: 0.716367, samples/s: 2952.008 1612000117.5246136
train: epoch 25, iter 3800, loss: 3.080939, top_1: 0.478086, top_k: 0.718906, samples/s: 2946.588 1612000126.212651
train: epoch 25, iter 3900, loss: 3.211782, top_1: 0.477852, top_k: 0.717227, samples/s: 2870.577 1612000135.1307507
train: epoch 25, iter 4000, loss: 3.281182, top_1: 0.472930, top_k: 0.714375, samples/s: 3046.488 1612000143.5339003
train: epoch 25, iter 4100, loss: 3.177780, top_1: 0.473828, top_k: 0.716328, samples/s: 2927.318 1612000152.2790437
train: epoch 25, iter 4200, loss: 3.216392, top_1: 0.474453, top_k: 0.714609, samples/s: 2988.863 1612000160.844668
train: epoch 25, iter 4300, loss: 3.408809, top_1: 0.477969, top_k: 0.716328, samples/s: 2960.531 1612000169.4913974
train: epoch 25, iter 4400, loss: 3.248408, top_1: 0.474180, top_k: 0.717773, samples/s: 3019.650 1612000177.969466
train: epoch 25, iter 4500, loss: 3.469743, top_1: 0.475313, top_k: 0.714180, samples/s: 2977.191 1612000186.5677812
train: epoch 25, iter 4600, loss: 3.313382, top_1: 0.469570, top_k: 0.709453, samples/s: 2966.907 1612000195.1963751
train: epoch 25, iter 4700, loss: 3.128535, top_1: 0.474414, top_k: 0.715742, samples/s: 2926.667 1612000203.9434667
train: epoch 25, iter 4800, loss: 3.169270, top_1: 0.475039, top_k: 0.721602, samples/s: 2998.164 1612000212.481979
train: epoch 25, iter 4900, loss: 3.312147, top_1: 0.478398, top_k: 0.717734, samples/s: 2996.366 1612000221.0257177
train: epoch 25, iter 5000, loss: 3.250640, top_1: 0.473711, top_k: 0.716133, samples/s: 2917.583 1612000229.800077
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_25.
validation: epoch 25, iter 195, top_1: 0.514984, top_k: 0.763462, samples/s: 2945.456 1612000246.979952
train: epoch 26, iter 100, loss: 3.159661, top_1: 0.480039, top_k: 0.724609, samples/s: 2897.082 1612000271.6180084
train: epoch 26, iter 200, loss: 3.113932, top_1: 0.477461, top_k: 0.723945, samples/s: 2951.019 1612000280.2930255
train: epoch 26, iter 300, loss: 3.368946, top_1: 0.484883, top_k: 0.723359, samples/s: 3011.055 1612000288.794833
train: epoch 26, iter 400, loss: 3.352682, top_1: 0.482539, top_k: 0.723242, samples/s: 2869.850 1612000297.7152002
train: epoch 26, iter 500, loss: 3.291600, top_1: 0.482344, top_k: 0.723047, samples/s: 2981.725 1612000306.3011477
train: epoch 26, iter 600, loss: 3.180405, top_1: 0.475156, top_k: 0.722344, samples/s: 2984.336 1612000314.878915
train: epoch 26, iter 700, loss: 3.204796, top_1: 0.478398, top_k: 0.721445, samples/s: 3013.880 1612000323.3733504
train: epoch 26, iter 800, loss: 3.061213, top_1: 0.477500, top_k: 0.720781, samples/s: 2979.305 1612000331.9657516
train: epoch 26, iter 900, loss: 3.134295, top_1: 0.480586, top_k: 0.721445, samples/s: 2991.958 1612000340.521806
train: epoch 26, iter 1000, loss: 3.497453, top_1: 0.479258, top_k: 0.720938, samples/s: 2976.851 1612000349.1215394
train: epoch 26, iter 1100, loss: 3.480517, top_1: 0.478594, top_k: 0.723203, samples/s: 2996.043 1612000357.6661305
train: epoch 26, iter 1200, loss: 3.034863, top_1: 0.475195, top_k: 0.722539, samples/s: 2854.647 1612000366.6370735
train: epoch 26, iter 1300, loss: 3.057980, top_1: 0.480078, top_k: 0.723242, samples/s: 2946.658 1612000375.3217025
train: epoch 26, iter 1400, loss: 3.184897, top_1: 0.474727, top_k: 0.715039, samples/s: 2999.447 1612000383.8566616
train: epoch 26, iter 1500, loss: 3.180579, top_1: 0.470820, top_k: 0.716133, samples/s: 2954.912 1612000392.5206761
train: epoch 26, iter 1600, loss: 3.272848, top_1: 0.475938, top_k: 0.721602, samples/s: 2971.312 1612000401.1359656
train: epoch 26, iter 1700, loss: 3.034658, top_1: 0.477539, top_k: 0.717383, samples/s: 2950.679 1612000409.812002
train: epoch 26, iter 1800, loss: 3.234833, top_1: 0.472773, top_k: 0.711602, samples/s: 2927.985 1612000418.5551305
train: epoch 26, iter 1900, loss: 3.079089, top_1: 0.475156, top_k: 0.715156, samples/s: 2957.272 1612000427.2117603
train: epoch 26, iter 2000, loss: 3.346925, top_1: 0.479453, top_k: 0.717461, samples/s: 2975.899 1612000435.8141215
train: epoch 26, iter 2100, loss: 3.194171, top_1: 0.477578, top_k: 0.717109, samples/s: 3008.300 1612000444.3239772
train: epoch 26, iter 2200, loss: 3.015371, top_1: 0.478320, top_k: 0.724336, samples/s: 2994.459 1612000452.8731086
train: epoch 26, iter 2300, loss: 3.155413, top_1: 0.481523, top_k: 0.722734, samples/s: 3009.046 1612000461.3807607
train: epoch 26, iter 2400, loss: 3.046141, top_1: 0.480664, top_k: 0.721953, samples/s: 2934.625 1612000470.1041553
train: epoch 26, iter 2500, loss: 3.321383, top_1: 0.481250, top_k: 0.722539, samples/s: 2983.803 1612000478.6839166
train: epoch 26, iter 2600, loss: 3.186178, top_1: 0.475703, top_k: 0.717812, samples/s: 2900.704 1612000487.5092988
train: epoch 26, iter 2700, loss: 3.290644, top_1: 0.479453, top_k: 0.724414, samples/s: 2966.905 1612000496.1378896
train: epoch 26, iter 2800, loss: 3.267592, top_1: 0.472852, top_k: 0.718242, samples/s: 3010.853 1612000504.6404536
train: epoch 26, iter 2900, loss: 3.246295, top_1: 0.472461, top_k: 0.715313, samples/s: 2977.073 1612000513.2394588
train: epoch 26, iter 3000, loss: 3.123528, top_1: 0.478047, top_k: 0.718906, samples/s: 2998.376 1612000521.7773883
train: epoch 26, iter 3100, loss: 3.224228, top_1: 0.475547, top_k: 0.715977, samples/s: 3009.728 1612000530.2832031
train: epoch 26, iter 3200, loss: 3.189673, top_1: 0.472383, top_k: 0.715820, samples/s: 2892.604 1612000539.1333642
train: epoch 26, iter 3300, loss: 3.033921, top_1: 0.474961, top_k: 0.718008, samples/s: 2952.233 1612000547.8047378
train: epoch 26, iter 3400, loss: 3.285420, top_1: 0.474609, top_k: 0.719727, samples/s: 2925.404 1612000556.5557506
train: epoch 26, iter 3500, loss: 3.183279, top_1: 0.474805, top_k: 0.718242, samples/s: 2953.427 1612000565.2235255
train: epoch 26, iter 3600, loss: 3.192238, top_1: 0.473438, top_k: 0.717656, samples/s: 3010.891 1612000573.7260182
train: epoch 26, iter 3700, loss: 3.123650, top_1: 0.480117, top_k: 0.717305, samples/s: 2963.902 1612000582.3636901
train: epoch 26, iter 3800, loss: 3.362525, top_1: 0.475469, top_k: 0.716406, samples/s: 2976.168 1612000590.9649434
train: epoch 26, iter 3900, loss: 3.390782, top_1: 0.479414, top_k: 0.717930, samples/s: 2948.551 1612000599.6472716
train: epoch 26, iter 4000, loss: 3.401845, top_1: 0.478477, top_k: 0.717773, samples/s: 2977.982 1612000608.244229
train: epoch 26, iter 4100, loss: 3.538866, top_1: 0.473633, top_k: 0.713086, samples/s: 2986.974 1612000616.8140962
train: epoch 26, iter 4200, loss: 3.186905, top_1: 0.473945, top_k: 0.712383, samples/s: 3003.490 1612000625.3375864
train: epoch 26, iter 4300, loss: 3.134071, top_1: 0.471406, top_k: 0.716406, samples/s: 2942.942 1612000634.0363846
train: epoch 26, iter 4400, loss: 3.172431, top_1: 0.470820, top_k: 0.716914, samples/s: 2963.095 1612000642.6759553
train: epoch 26, iter 4500, loss: 3.105581, top_1: 0.481445, top_k: 0.718086, samples/s: 2937.026 1612000651.392214
train: epoch 26, iter 4600, loss: 3.290680, top_1: 0.475586, top_k: 0.716562, samples/s: 2998.696 1612000659.9293468
train: epoch 26, iter 4700, loss: 3.239679, top_1: 0.473203, top_k: 0.713867, samples/s: 2990.907 1612000668.4885716
train: epoch 26, iter 4800, loss: 3.144218, top_1: 0.472422, top_k: 0.718477, samples/s: 2934.755 1612000677.2116153
train: epoch 26, iter 4900, loss: 3.120492, top_1: 0.480625, top_k: 0.718594, samples/s: 3034.635 1612000685.6474993
train: epoch 26, iter 5000, loss: 3.308492, top_1: 0.478672, top_k: 0.720547, samples/s: 2950.808 1612000694.3232505
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_26.
validation: epoch 26, iter 195, top_1: 0.518930, top_k: 0.770232, samples/s: 2877.681 1612000711.9124506
train: epoch 27, iter 100, loss: 3.164401, top_1: 0.486094, top_k: 0.725039, samples/s: 2869.432 1612000737.310708
train: epoch 27, iter 200, loss: 3.279724, top_1: 0.482109, top_k: 0.721367, samples/s: 3001.847 1612000745.838762
train: epoch 27, iter 300, loss: 3.214321, top_1: 0.490586, top_k: 0.728008, samples/s: 2897.654 1612000754.6737304
train: epoch 27, iter 400, loss: 3.102511, top_1: 0.477617, top_k: 0.719570, samples/s: 2941.040 1612000763.3780446
train: epoch 27, iter 500, loss: 3.238428, top_1: 0.482422, top_k: 0.724844, samples/s: 2982.148 1612000771.9623566
train: epoch 27, iter 600, loss: 3.056990, top_1: 0.479297, top_k: 0.721836, samples/s: 3020.242 1612000780.43875
train: epoch 27, iter 700, loss: 3.117484, top_1: 0.476484, top_k: 0.716680, samples/s: 2984.524 1612000789.0160966
train: epoch 27, iter 800, loss: 3.437100, top_1: 0.479023, top_k: 0.719727, samples/s: 3004.781 1612000797.5369053
train: epoch 27, iter 900, loss: 3.380625, top_1: 0.480000, top_k: 0.723789, samples/s: 2987.991 1612000806.103408
train: epoch 27, iter 1000, loss: 3.270379, top_1: 0.484766, top_k: 0.726133, samples/s: 2969.393 1612000814.7247047
train: epoch 27, iter 1100, loss: 3.159349, top_1: 0.481328, top_k: 0.720195, samples/s: 2991.938 1612000823.2811623
train: epoch 27, iter 1200, loss: 3.232545, top_1: 0.476016, top_k: 0.721250, samples/s: 2985.998 1612000831.8544593
train: epoch 27, iter 1300, loss: 3.024572, top_1: 0.475664, top_k: 0.720117, samples/s: 3004.157 1612000840.3759727
train: epoch 27, iter 1400, loss: 3.380231, top_1: 0.473203, top_k: 0.718711, samples/s: 2986.228 1612000848.948586
train: epoch 27, iter 1500, loss: 3.363142, top_1: 0.478477, top_k: 0.723047, samples/s: 2988.194 1612000857.5157723
train: epoch 27, iter 1600, loss: 3.183753, top_1: 0.473438, top_k: 0.713437, samples/s: 2973.329 1612000866.125545
train: epoch 27, iter 1700, loss: 3.361140, top_1: 0.472773, top_k: 0.716211, samples/s: 2950.636 1612000874.8016448
train: epoch 27, iter 1800, loss: 3.262652, top_1: 0.484414, top_k: 0.722148, samples/s: 2956.858 1612000883.459478
train: epoch 27, iter 1900, loss: 3.255970, top_1: 0.478867, top_k: 0.716641, samples/s: 2981.537 1612000892.045651
train: epoch 27, iter 2000, loss: 3.355873, top_1: 0.481445, top_k: 0.721016, samples/s: 2883.114 1612000900.9250689
train: epoch 27, iter 2100, loss: 3.353716, top_1: 0.474570, top_k: 0.718633, samples/s: 3001.192 1612000909.454862
train: epoch 27, iter 2200, loss: 3.090550, top_1: 0.478242, top_k: 0.720742, samples/s: 2953.190 1612000918.1235144
train: epoch 27, iter 2300, loss: 3.244794, top_1: 0.480273, top_k: 0.719688, samples/s: 2922.163 1612000926.884059
train: epoch 27, iter 2400, loss: 2.977124, top_1: 0.477578, top_k: 0.717148, samples/s: 2944.676 1612000935.577845
train: epoch 27, iter 2500, loss: 3.340758, top_1: 0.480469, top_k: 0.719883, samples/s: 2962.952 1612000944.2178648
train: epoch 27, iter 2600, loss: 3.104886, top_1: 0.478516, top_k: 0.722539, samples/s: 2899.429 1612000953.0471437
train: epoch 27, iter 2700, loss: 3.108254, top_1: 0.475273, top_k: 0.722305, samples/s: 2944.636 1612000961.74088
train: epoch 27, iter 2800, loss: 3.219585, top_1: 0.478555, top_k: 0.721172, samples/s: 2999.512 1612000970.275559
train: epoch 27, iter 2900, loss: 3.413182, top_1: 0.477852, top_k: 0.716836, samples/s: 2998.204 1612000978.8140683
train: epoch 27, iter 3000, loss: 3.154566, top_1: 0.479844, top_k: 0.719023, samples/s: 2893.667 1612000987.6611876
train: epoch 27, iter 3100, loss: 3.205056, top_1: 0.479063, top_k: 0.720586, samples/s: 2984.709 1612000996.2380576
train: epoch 27, iter 3200, loss: 3.310162, top_1: 0.476016, top_k: 0.720898, samples/s: 3004.554 1612001004.7584884
train: epoch 27, iter 3300, loss: 3.105275, top_1: 0.480391, top_k: 0.719492, samples/s: 3012.231 1612001013.2572021
train: epoch 27, iter 3400, loss: 3.192428, top_1: 0.482773, top_k: 0.725039, samples/s: 2915.087 1612001022.0390065
train: epoch 27, iter 3500, loss: 3.295078, top_1: 0.478438, top_k: 0.718516, samples/s: 2960.693 1612001030.6856658
train: epoch 27, iter 3600, loss: 3.136907, top_1: 0.483281, top_k: 0.722734, samples/s: 2918.548 1612001039.4571078
train: epoch 27, iter 3700, loss: 2.999514, top_1: 0.474961, top_k: 0.718398, samples/s: 3029.222 1612001047.9081395
train: epoch 27, iter 3800, loss: 3.081580, top_1: 0.475117, top_k: 0.719102, samples/s: 2973.690 1612001056.5174823
train: epoch 27, iter 3900, loss: 3.446984, top_1: 0.476602, top_k: 0.720156, samples/s: 2944.641 1612001065.2107334
train: epoch 27, iter 4000, loss: 3.124520, top_1: 0.473477, top_k: 0.718437, samples/s: 2973.814 1612001073.8192
train: epoch 27, iter 4100, loss: 3.072504, top_1: 0.477852, top_k: 0.718477, samples/s: 3020.671 1612001082.2941449
train: epoch 27, iter 4200, loss: 3.292057, top_1: 0.474180, top_k: 0.720898, samples/s: 2996.406 1612001090.8377206
train: epoch 27, iter 4300, loss: 3.048008, top_1: 0.474844, top_k: 0.717109, samples/s: 2961.495 1612001099.4819868
train: epoch 27, iter 4400, loss: 3.383862, top_1: 0.475469, top_k: 0.716445, samples/s: 2943.117 1612001108.1802418
train: epoch 27, iter 4500, loss: 3.355892, top_1: 0.471367, top_k: 0.718398, samples/s: 2975.439 1612001116.784075
train: epoch 27, iter 4600, loss: 3.278163, top_1: 0.476133, top_k: 0.721719, samples/s: 2954.107 1612001125.450289
train: epoch 27, iter 4700, loss: 3.102595, top_1: 0.480859, top_k: 0.720313, samples/s: 3009.556 1612001133.9561954
train: epoch 27, iter 4800, loss: 3.076307, top_1: 0.482500, top_k: 0.720078, samples/s: 2988.126 1612001142.5233467
train: epoch 27, iter 4900, loss: 3.045209, top_1: 0.479844, top_k: 0.719219, samples/s: 2995.736 1612001151.068874
train: epoch 27, iter 5000, loss: 2.871618, top_1: 0.484023, top_k: 0.725664, samples/s: 2988.204 1612001159.635912
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_27.
validation: epoch 27, iter 195, top_1: 0.525841, top_k: 0.774840, samples/s: 2925.419 1612001176.9430468
train: epoch 28, iter 100, loss: 3.305537, top_1: 0.490664, top_k: 0.728555, samples/s: 2934.587 1612001201.1316686
train: epoch 28, iter 200, loss: 3.164467, top_1: 0.490625, top_k: 0.729648, samples/s: 3024.548 1612001209.5957046
train: epoch 28, iter 300, loss: 3.313552, top_1: 0.486797, top_k: 0.724609, samples/s: 2955.580 1612001218.2576818
train: epoch 28, iter 400, loss: 3.244414, top_1: 0.488750, top_k: 0.729883, samples/s: 2941.416 1612001226.9605882
train: epoch 28, iter 500, loss: 3.174602, top_1: 0.481641, top_k: 0.719688, samples/s: 2934.486 1612001235.6844656
train: epoch 28, iter 600, loss: 3.261995, top_1: 0.484023, top_k: 0.721641, samples/s: 2905.746 1612001244.494557
train: epoch 28, iter 700, loss: 3.055929, top_1: 0.485039, top_k: 0.731094, samples/s: 3008.724 1612001253.003153
train: epoch 28, iter 800, loss: 3.333378, top_1: 0.476367, top_k: 0.724141, samples/s: 2987.388 1612001261.5725873
train: epoch 28, iter 900, loss: 3.216642, top_1: 0.485508, top_k: 0.722578, samples/s: 3010.428 1612001270.0762546
train: epoch 28, iter 1000, loss: 3.356305, top_1: 0.476172, top_k: 0.722734, samples/s: 3000.715 1612001278.6075215
train: epoch 28, iter 1100, loss: 3.114018, top_1: 0.483711, top_k: 0.722812, samples/s: 3003.513 1612001287.131027
train: epoch 28, iter 1200, loss: 3.015769, top_1: 0.476992, top_k: 0.721016, samples/s: 2985.247 1612001295.7065346
train: epoch 28, iter 1300, loss: 3.190670, top_1: 0.479922, top_k: 0.721016, samples/s: 2961.904 1612001304.3495178
train: epoch 28, iter 1400, loss: 3.234127, top_1: 0.479297, top_k: 0.727266, samples/s: 2961.885 1612001312.9927201
train: epoch 28, iter 1500, loss: 3.100351, top_1: 0.481250, top_k: 0.721875, samples/s: 2975.836 1612001321.5952709
train: epoch 28, iter 1600, loss: 3.149250, top_1: 0.479766, top_k: 0.717852, samples/s: 2968.245 1612001330.2201324
train: epoch 28, iter 1700, loss: 3.248180, top_1: 0.477695, top_k: 0.723594, samples/s: 2996.570 1612001338.7630029
train: epoch 28, iter 1800, loss: 3.224133, top_1: 0.479844, top_k: 0.722109, samples/s: 2955.358 1612001347.425529
train: epoch 28, iter 1900, loss: 3.063631, top_1: 0.480156, top_k: 0.723633, samples/s: 2971.039 1612001356.0418174
train: epoch 28, iter 2000, loss: 3.139705, top_1: 0.483047, top_k: 0.724180, samples/s: 2972.796 1612001364.653284
train: epoch 28, iter 2100, loss: 3.002208, top_1: 0.478867, top_k: 0.720586, samples/s: 2997.791 1612001373.1927757
train: epoch 28, iter 2200, loss: 3.092899, top_1: 0.478008, top_k: 0.719883, samples/s: 2949.014 1612001381.87383
train: epoch 28, iter 2300, loss: 3.259280, top_1: 0.480312, top_k: 0.721484, samples/s: 3014.531 1612001390.365929
train: epoch 28, iter 2400, loss: 3.286201, top_1: 0.478125, top_k: 0.723594, samples/s: 2963.106 1612001399.0054839
train: epoch 28, iter 2500, loss: 3.330642, top_1: 0.477852, top_k: 0.716406, samples/s: 2967.843 1612001407.6312208
train: epoch 28, iter 2600, loss: 3.129433, top_1: 0.474766, top_k: 0.720039, samples/s: 2963.836 1612001416.2686834
train: epoch 28, iter 2700, loss: 3.110218, top_1: 0.481602, top_k: 0.720625, samples/s: 2932.775 1612001424.997665
train: epoch 28, iter 2800, loss: 3.243749, top_1: 0.474883, top_k: 0.715313, samples/s: 2954.044 1612001433.663795
train: epoch 28, iter 2900, loss: 3.175714, top_1: 0.478984, top_k: 0.720195, samples/s: 2951.045 1612001442.33861
train: epoch 28, iter 3000, loss: 3.213857, top_1: 0.482773, top_k: 0.721211, samples/s: 3000.544 1612001450.8705297
train: epoch 28, iter 3100, loss: 3.228649, top_1: 0.473906, top_k: 0.718125, samples/s: 2916.421 1612001459.648288
train: epoch 28, iter 3200, loss: 3.080099, top_1: 0.481211, top_k: 0.725313, samples/s: 2971.895 1612001468.2623208
train: epoch 28, iter 3300, loss: 3.411747, top_1: 0.475430, top_k: 0.711406, samples/s: 2905.413 1612001477.0735445
train: epoch 28, iter 3400, loss: 3.324993, top_1: 0.482578, top_k: 0.719375, samples/s: 2798.739 1612001486.2204225
train: epoch 28, iter 3500, loss: 3.150366, top_1: 0.485938, top_k: 0.723359, samples/s: 2964.172 1612001494.8568938
train: epoch 28, iter 3600, loss: 3.159159, top_1: 0.480586, top_k: 0.722500, samples/s: 2978.240 1612001503.4527028
train: epoch 28, iter 3700, loss: 3.270014, top_1: 0.487344, top_k: 0.722891, samples/s: 2993.853 1612001512.0033996
train: epoch 28, iter 3800, loss: 3.057143, top_1: 0.481797, top_k: 0.723320, samples/s: 2974.271 1612001520.610669
train: epoch 28, iter 3900, loss: 3.069378, top_1: 0.480000, top_k: 0.719375, samples/s: 2952.731 1612001529.2807093
train: epoch 28, iter 4000, loss: 3.203029, top_1: 0.478477, top_k: 0.717461, samples/s: 3012.475 1612001537.7785168
train: epoch 28, iter 4100, loss: 3.219266, top_1: 0.481133, top_k: 0.717070, samples/s: 2934.878 1612001546.5012004
train: epoch 28, iter 4200, loss: 3.176674, top_1: 0.475313, top_k: 0.712383, samples/s: 2982.353 1612001555.0850532
train: epoch 28, iter 4300, loss: 3.217801, top_1: 0.472930, top_k: 0.716562, samples/s: 2970.891 1612001563.701971
train: epoch 28, iter 4400, loss: 3.304886, top_1: 0.475664, top_k: 0.720898, samples/s: 2994.052 1612001572.252275
train: epoch 28, iter 4500, loss: 3.082786, top_1: 0.479766, top_k: 0.720938, samples/s: 2957.814 1612001580.9072955
train: epoch 28, iter 4600, loss: 3.286431, top_1: 0.478711, top_k: 0.720117, samples/s: 2970.736 1612001589.5247335
train: epoch 28, iter 4700, loss: 3.279526, top_1: 0.483672, top_k: 0.726055, samples/s: 2949.058 1612001598.2054405
train: epoch 28, iter 4800, loss: 3.216071, top_1: 0.480156, top_k: 0.719883, samples/s: 2981.867 1612001606.79097
train: epoch 28, iter 4900, loss: 3.150928, top_1: 0.479453, top_k: 0.721836, samples/s: 2937.272 1612001615.5064538
train: epoch 28, iter 5000, loss: 3.022962, top_1: 0.479180, top_k: 0.719258, samples/s: 2955.897 1612001624.167209
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_28.
validation: epoch 28, iter 195, top_1: 0.532813, top_k: 0.779227, samples/s: 2995.252 1612001641.1557
train: epoch 29, iter 100, loss: 3.128557, top_1: 0.482617, top_k: 0.727656, samples/s: 2963.587 1612001665.8134015
train: epoch 29, iter 200, loss: 3.060262, top_1: 0.487031, top_k: 0.728320, samples/s: 3004.167 1612001674.3349915
train: epoch 29, iter 300, loss: 2.964487, top_1: 0.486484, top_k: 0.725391, samples/s: 2926.386 1612001683.0828607
train: epoch 29, iter 400, loss: 3.186124, top_1: 0.480391, top_k: 0.725547, samples/s: 3007.765 1612001691.5941944
train: epoch 29, iter 500, loss: 3.237398, top_1: 0.482969, top_k: 0.723320, samples/s: 2998.086 1612001700.1331596
train: epoch 29, iter 600, loss: 3.105166, top_1: 0.477852, top_k: 0.719844, samples/s: 2984.897 1612001708.7095268
train: epoch 29, iter 700, loss: 3.178037, top_1: 0.477930, top_k: 0.725391, samples/s: 2996.615 1612001717.252556
train: epoch 29, iter 800, loss: 3.272360, top_1: 0.483203, top_k: 0.726875, samples/s: 2927.058 1612001725.998507
train: epoch 29, iter 900, loss: 3.003995, top_1: 0.486406, top_k: 0.726680, samples/s: 2986.328 1612001734.5708282
train: epoch 29, iter 1000, loss: 3.134796, top_1: 0.481875, top_k: 0.727617, samples/s: 2897.734 1612001743.40532
train: epoch 29, iter 1100, loss: 3.118731, top_1: 0.482852, top_k: 0.725117, samples/s: 3027.237 1612001751.861858
train: epoch 29, iter 1200, loss: 3.249197, top_1: 0.480352, top_k: 0.725781, samples/s: 2951.653 1612001760.534991
train: epoch 29, iter 1300, loss: 3.144847, top_1: 0.484570, top_k: 0.724414, samples/s: 2944.711 1612001769.2286348
train: epoch 29, iter 1400, loss: 3.174476, top_1: 0.483008, top_k: 0.721484, samples/s: 2975.297 1612001777.8327148
train: epoch 29, iter 1500, loss: 3.105675, top_1: 0.477266, top_k: 0.717656, samples/s: 2988.450 1612001786.399053
train: epoch 29, iter 1600, loss: 3.273926, top_1: 0.490352, top_k: 0.731406, samples/s: 3043.181 1612001794.8112948
train: epoch 29, iter 1700, loss: 3.174189, top_1: 0.483633, top_k: 0.725859, samples/s: 2971.816 1612001803.425567
train: epoch 29, iter 1800, loss: 3.298436, top_1: 0.480039, top_k: 0.723945, samples/s: 2910.858 1612001812.2203233
train: epoch 29, iter 1900, loss: 3.039790, top_1: 0.482656, top_k: 0.726719, samples/s: 2937.915 1612001820.9338677
train: epoch 29, iter 2000, loss: 3.147626, top_1: 0.483867, top_k: 0.723672, samples/s: 2954.686 1612001829.5980246
train: epoch 29, iter 2100, loss: 3.190011, top_1: 0.478398, top_k: 0.726250, samples/s: 2922.010 1612001838.3592196
train: epoch 29, iter 2200, loss: 3.123857, top_1: 0.481914, top_k: 0.721758, samples/s: 2998.187 1612001846.8976793
train: epoch 29, iter 2300, loss: 3.057220, top_1: 0.487969, top_k: 0.728594, samples/s: 3003.603 1612001855.4207497
train: epoch 29, iter 2400, loss: 3.019191, top_1: 0.482969, top_k: 0.724336, samples/s: 2925.589 1612001864.1712723
train: epoch 29, iter 2500, loss: 3.032349, top_1: 0.478594, top_k: 0.724570, samples/s: 3012.898 1612001872.6679196
train: epoch 29, iter 2600, loss: 2.956632, top_1: 0.479102, top_k: 0.721914, samples/s: 2978.584 1612001881.2626586
train: epoch 29, iter 2700, loss: 3.240316, top_1: 0.481094, top_k: 0.718867, samples/s: 2963.119 1612001889.9022245
train: epoch 29, iter 2800, loss: 3.203745, top_1: 0.481133, top_k: 0.723867, samples/s: 2976.519 1612001898.5028024
train: epoch 29, iter 2900, loss: 3.082377, top_1: 0.481641, top_k: 0.719453, samples/s: 3031.222 1612001906.9482763
train: epoch 29, iter 3000, loss: 3.073991, top_1: 0.484492, top_k: 0.725039, samples/s: 2962.314 1612001915.5901372
train: epoch 29, iter 3100, loss: 3.228358, top_1: 0.479258, top_k: 0.720313, samples/s: 2990.085 1612001924.1518712
train: epoch 29, iter 3200, loss: 3.160010, top_1: 0.479219, top_k: 0.716445, samples/s: 2980.556 1612001932.7410455
train: epoch 29, iter 3300, loss: 3.324360, top_1: 0.480781, top_k: 0.716562, samples/s: 2916.149 1612001941.519524
train: epoch 29, iter 3400, loss: 3.367623, top_1: 0.484297, top_k: 0.724531, samples/s: 3024.645 1612001949.9834023
train: epoch 29, iter 3500, loss: 3.219380, top_1: 0.481914, top_k: 0.721250, samples/s: 2972.337 1612001958.59604
train: epoch 29, iter 3600, loss: 3.422243, top_1: 0.483359, top_k: 0.724922, samples/s: 2975.655 1612001967.1992056
train: epoch 29, iter 3700, loss: 3.276836, top_1: 0.476250, top_k: 0.720938, samples/s: 2977.816 1612001975.796083
train: epoch 29, iter 3800, loss: 3.259460, top_1: 0.481797, top_k: 0.720938, samples/s: 2890.240 1612001984.6536248
train: epoch 29, iter 3900, loss: 3.281093, top_1: 0.480234, top_k: 0.722422, samples/s: 2997.266 1612001993.1946023
train: epoch 29, iter 4000, loss: 3.188925, top_1: 0.480742, top_k: 0.719336, samples/s: 2981.837 1612002001.779965
train: epoch 29, iter 4100, loss: 3.344147, top_1: 0.476523, top_k: 0.722891, samples/s: 2962.441 1612002010.4214551
train: epoch 29, iter 4200, loss: 3.020026, top_1: 0.478633, top_k: 0.723008, samples/s: 2986.056 1612002018.9946609
train: epoch 29, iter 4300, loss: 3.291123, top_1: 0.476758, top_k: 0.721328, samples/s: 2932.737 1612002027.7237697
train: epoch 29, iter 4400, loss: 3.221442, top_1: 0.479961, top_k: 0.721523, samples/s: 2936.005 1612002036.4430504
train: epoch 29, iter 4500, loss: 3.085127, top_1: 0.481641, top_k: 0.722344, samples/s: 2958.242 1612002045.0969067
train: epoch 29, iter 4600, loss: 3.208164, top_1: 0.478516, top_k: 0.720273, samples/s: 3015.509 1612002053.5862632
train: epoch 29, iter 4700, loss: 2.955288, top_1: 0.478281, top_k: 0.720859, samples/s: 2882.741 1612002062.466688
train: epoch 29, iter 4800, loss: 3.017111, top_1: 0.479336, top_k: 0.718281, samples/s: 2984.446 1612002071.0445292
train: epoch 29, iter 4900, loss: 3.156190, top_1: 0.484297, top_k: 0.722617, samples/s: 2969.310 1612002079.6660464
train: epoch 29, iter 5000, loss: 2.987893, top_1: 0.484453, top_k: 0.726680, samples/s: 2980.656 1612002088.2547607
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_29.
validation: epoch 29, iter 195, top_1: 0.519832, top_k: 0.766907, samples/s: 2902.950 1612002105.6458507
train: epoch 30, iter 100, loss: 3.254636, top_1: 0.490312, top_k: 0.730508, samples/s: 2943.088 1612002136.0504255
train: epoch 30, iter 200, loss: 3.045686, top_1: 0.490234, top_k: 0.729805, samples/s: 3000.702 1612002144.5818872
train: epoch 30, iter 300, loss: 3.180841, top_1: 0.492969, top_k: 0.734141, samples/s: 2988.236 1612002153.1487803
train: epoch 30, iter 400, loss: 3.054580, top_1: 0.485508, top_k: 0.728594, samples/s: 2960.119 1612002161.7969825
train: epoch 30, iter 500, loss: 3.060042, top_1: 0.486992, top_k: 0.726797, samples/s: 2965.696 1612002170.4290514
train: epoch 30, iter 600, loss: 3.222955, top_1: 0.487656, top_k: 0.723750, samples/s: 2927.768 1612002179.172915
train: epoch 30, iter 700, loss: 3.149726, top_1: 0.485469, top_k: 0.729609, samples/s: 2937.873 1612002187.8866277
train: epoch 30, iter 800, loss: 3.419398, top_1: 0.483672, top_k: 0.724922, samples/s: 2964.035 1612002196.5235813
train: epoch 30, iter 900, loss: 2.893000, top_1: 0.485625, top_k: 0.730469, samples/s: 3002.169 1612002205.0506701
train: epoch 30, iter 1000, loss: 3.106505, top_1: 0.485898, top_k: 0.726172, samples/s: 2992.153 1612002213.606401
train: epoch 30, iter 1100, loss: 3.203199, top_1: 0.486602, top_k: 0.726211, samples/s: 2938.697 1612002222.317704
train: epoch 30, iter 1200, loss: 3.287575, top_1: 0.484219, top_k: 0.726680, samples/s: 2997.885 1612002230.8571875
train: epoch 30, iter 1300, loss: 3.141366, top_1: 0.480938, top_k: 0.722539, samples/s: 3004.986 1612002239.3762841
train: epoch 30, iter 1400, loss: 3.339841, top_1: 0.482617, top_k: 0.724453, samples/s: 3007.706 1612002247.887775
train: epoch 30, iter 1500, loss: 3.035073, top_1: 0.488398, top_k: 0.729375, samples/s: 2888.710 1612002256.7497966
train: epoch 30, iter 1600, loss: 3.301844, top_1: 0.484492, top_k: 0.726016, samples/s: 2963.558 1612002265.3881047
train: epoch 30, iter 1700, loss: 3.115743, top_1: 0.483398, top_k: 0.722891, samples/s: 2997.111 1612002273.9296887
train: epoch 30, iter 1800, loss: 3.294172, top_1: 0.478477, top_k: 0.721484, samples/s: 3007.909 1612002282.4405804
train: epoch 30, iter 1900, loss: 3.205597, top_1: 0.483711, top_k: 0.725703, samples/s: 2989.438 1612002291.0040064
train: epoch 30, iter 2000, loss: 3.168023, top_1: 0.483555, top_k: 0.722656, samples/s: 2965.091 1612002299.6378732
train: epoch 30, iter 2100, loss: 3.142062, top_1: 0.486953, top_k: 0.724609, samples/s: 2943.258 1612002308.3357172
train: epoch 30, iter 2200, loss: 3.097285, top_1: 0.485742, top_k: 0.727031, samples/s: 2966.431 1612002316.9656224
train: epoch 30, iter 2300, loss: 3.033669, top_1: 0.488438, top_k: 0.726133, samples/s: 2983.656 1612002325.5457413
train: epoch 30, iter 2400, loss: 3.260990, top_1: 0.484844, top_k: 0.730586, samples/s: 2997.859 1612002334.085117
train: epoch 30, iter 2500, loss: 3.152336, top_1: 0.481172, top_k: 0.720898, samples/s: 2896.405 1612002342.9236453
train: epoch 30, iter 2600, loss: 3.264517, top_1: 0.483984, top_k: 0.723359, samples/s: 2986.278 1612002351.4961991
train: epoch 30, iter 2700, loss: 3.246438, top_1: 0.476875, top_k: 0.720117, samples/s: 2983.228 1612002360.0774605
train: epoch 30, iter 2800, loss: 3.078077, top_1: 0.481875, top_k: 0.725117, samples/s: 2983.415 1612002368.6583576
train: epoch 30, iter 2900, loss: 3.071991, top_1: 0.479883, top_k: 0.722383, samples/s: 3036.932 1612002377.0877836
train: epoch 30, iter 3000, loss: 3.194589, top_1: 0.479375, top_k: 0.719336, samples/s: 2997.451 1612002385.6283803
train: epoch 30, iter 3100, loss: 3.048005, top_1: 0.482734, top_k: 0.721836, samples/s: 2935.071 1612002394.3505085
train: epoch 30, iter 3200, loss: 3.370478, top_1: 0.478867, top_k: 0.722930, samples/s: 2880.579 1612002403.237583
train: epoch 30, iter 3300, loss: 3.049834, top_1: 0.481875, top_k: 0.716914, samples/s: 2884.612 1612002412.1124132
train: epoch 30, iter 3400, loss: 3.062443, top_1: 0.477383, top_k: 0.719375, samples/s: 2976.840 1612002420.7119904
train: epoch 30, iter 3500, loss: 3.172214, top_1: 0.479609, top_k: 0.721250, samples/s: 2974.037 1612002429.319769
train: epoch 30, iter 3600, loss: 3.276886, top_1: 0.476289, top_k: 0.720117, samples/s: 2990.510 1612002437.8802955
train: epoch 30, iter 3700, loss: 3.106336, top_1: 0.482148, top_k: 0.726680, samples/s: 2986.338 1612002446.4526029
train: epoch 30, iter 3800, loss: 3.210818, top_1: 0.483320, top_k: 0.721914, samples/s: 2937.990 1612002455.1673625
train: epoch 30, iter 3900, loss: 3.326014, top_1: 0.484570, top_k: 0.728164, samples/s: 2960.893 1612002463.8121026
train: epoch 30, iter 4000, loss: 3.071086, top_1: 0.484883, top_k: 0.722070, samples/s: 2895.138 1612002472.6549468
train: epoch 30, iter 4100, loss: 3.168672, top_1: 0.483242, top_k: 0.726914, samples/s: 2951.233 1612002481.328821
train: epoch 30, iter 4200, loss: 3.085545, top_1: 0.480430, top_k: 0.721055, samples/s: 2967.557 1612002489.9555016
train: epoch 30, iter 4300, loss: 3.264471, top_1: 0.478828, top_k: 0.719883, samples/s: 2939.111 1612002498.665714
train: epoch 30, iter 4400, loss: 3.174003, top_1: 0.482344, top_k: 0.718633, samples/s: 2992.521 1612002507.2202172
train: epoch 30, iter 4500, loss: 3.171827, top_1: 0.482578, top_k: 0.723125, samples/s: 2976.138 1612002515.8219895
train: epoch 30, iter 4600, loss: 3.184777, top_1: 0.482109, top_k: 0.720078, samples/s: 2941.091 1612002524.5262976
train: epoch 30, iter 4700, loss: 3.199441, top_1: 0.485625, top_k: 0.722852, samples/s: 2936.696 1612002533.243582
train: epoch 30, iter 4800, loss: 2.968965, top_1: 0.484219, top_k: 0.725703, samples/s: 2987.721 1612002541.8119078
train: epoch 30, iter 4900, loss: 3.317481, top_1: 0.483242, top_k: 0.721836, samples/s: 2963.031 1612002550.451765
train: epoch 30, iter 5000, loss: 3.146708, top_1: 0.483477, top_k: 0.720586, samples/s: 2994.438 1612002559.000921
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_30.
validation: epoch 30, iter 195, top_1: 0.525881, top_k: 0.777784, samples/s: 2944.443 1612002576.2060924
train: epoch 31, iter 100, loss: 3.234073, top_1: 0.487305, top_k: 0.728125, samples/s: 2826.005 1612002601.3771713
train: epoch 31, iter 200, loss: 3.183454, top_1: 0.492773, top_k: 0.730117, samples/s: 3009.464 1612002609.8837624
train: epoch 31, iter 300, loss: 3.152095, top_1: 0.487891, top_k: 0.733320, samples/s: 2993.445 1612002618.4357233
train: epoch 31, iter 400, loss: 3.215252, top_1: 0.485664, top_k: 0.723320, samples/s: 2980.070 1612002627.0264947
train: epoch 31, iter 500, loss: 2.977316, top_1: 0.486836, top_k: 0.728008, samples/s: 2997.781 1612002635.5657437
train: epoch 31, iter 600, loss: 3.048224, top_1: 0.488555, top_k: 0.726992, samples/s: 3001.190 1612002644.0956688
train: epoch 31, iter 700, loss: 3.150782, top_1: 0.485742, top_k: 0.729492, samples/s: 2978.674 1612002652.6901023
train: epoch 31, iter 800, loss: 3.243731, top_1: 0.487109, top_k: 0.730898, samples/s: 3020.217 1612002661.1663113
train: epoch 31, iter 900, loss: 3.264193, top_1: 0.487734, top_k: 0.728086, samples/s: 2880.567 1612002670.0534515
train: epoch 31, iter 1000, loss: 3.053889, top_1: 0.485781, top_k: 0.728398, samples/s: 3007.222 1612002678.5663733
train: epoch 31, iter 1100, loss: 3.041534, top_1: 0.490234, top_k: 0.727422, samples/s: 2921.189 1612002687.329909
train: epoch 31, iter 1200, loss: 3.116439, top_1: 0.480078, top_k: 0.722266, samples/s: 2988.037 1612002695.8973238
train: epoch 31, iter 1300, loss: 3.232301, top_1: 0.481797, top_k: 0.728555, samples/s: 2998.180 1612002704.4358127
train: epoch 31, iter 1400, loss: 3.132571, top_1: 0.487227, top_k: 0.727422, samples/s: 2959.112 1612002713.0870872
train: epoch 31, iter 1500, loss: 3.114697, top_1: 0.484258, top_k: 0.723437, samples/s: 2875.644 1612002721.9894783
train: epoch 31, iter 1600, loss: 3.146727, top_1: 0.489023, top_k: 0.729883, samples/s: 3011.676 1612002730.4897304
train: epoch 31, iter 1700, loss: 3.148387, top_1: 0.489141, top_k: 0.728164, samples/s: 2959.550 1612002739.1399927
train: epoch 31, iter 1800, loss: 3.120656, top_1: 0.486602, top_k: 0.723867, samples/s: 3013.163 1612002747.6357837
train: epoch 31, iter 1900, loss: 2.999804, top_1: 0.477969, top_k: 0.726094, samples/s: 2794.593 1612002756.79636
train: epoch 31, iter 2000, loss: 3.094259, top_1: 0.485117, top_k: 0.726836, samples/s: 3009.850 1612002765.3016691
train: epoch 31, iter 2100, loss: 3.175271, top_1: 0.482773, top_k: 0.723437, samples/s: 2968.565 1612002773.9255888
train: epoch 31, iter 2200, loss: 3.063001, top_1: 0.485312, top_k: 0.719180, samples/s: 2976.044 1612002782.5274546
train: epoch 31, iter 2300, loss: 3.342328, top_1: 0.485742, top_k: 0.725156, samples/s: 2895.386 1612002791.3690841
train: epoch 31, iter 2400, loss: 3.161335, top_1: 0.480703, top_k: 0.722656, samples/s: 2944.092 1612002800.0644293
train: epoch 31, iter 2500, loss: 3.073649, top_1: 0.490625, top_k: 0.729531, samples/s: 2930.310 1612002808.8007228
train: epoch 31, iter 2600, loss: 3.189661, top_1: 0.486836, top_k: 0.727656, samples/s: 2965.517 1612002817.4332168
train: epoch 31, iter 2700, loss: 3.262578, top_1: 0.484375, top_k: 0.724961, samples/s: 2912.848 1612002826.2219172
train: epoch 31, iter 2800, loss: 3.172704, top_1: 0.488750, top_k: 0.721992, samples/s: 2960.791 1612002834.868348
train: epoch 31, iter 2900, loss: 2.835150, top_1: 0.484687, top_k: 0.725664, samples/s: 2954.087 1612002843.5342572
train: epoch 31, iter 3000, loss: 3.334239, top_1: 0.487500, top_k: 0.724648, samples/s: 2961.128 1612002852.1795886
train: epoch 31, iter 3100, loss: 3.289339, top_1: 0.485508, top_k: 0.728516, samples/s: 2983.490 1612002860.760104
train: epoch 31, iter 3200, loss: 3.045577, top_1: 0.484414, top_k: 0.723555, samples/s: 3006.211 1612002869.275845
train: epoch 31, iter 3300, loss: 3.215488, top_1: 0.483555, top_k: 0.721680, samples/s: 2949.761 1612002877.9545608
train: epoch 31, iter 3400, loss: 3.068757, top_1: 0.486250, top_k: 0.728633, samples/s: 2982.977 1612002886.5365267
train: epoch 31, iter 3500, loss: 3.112669, top_1: 0.482305, top_k: 0.722773, samples/s: 2975.245 1612002895.141058
train: epoch 31, iter 3600, loss: 3.283479, top_1: 0.486211, top_k: 0.728633, samples/s: 2964.917 1612002903.775299
train: epoch 31, iter 3700, loss: 3.200472, top_1: 0.478516, top_k: 0.721797, samples/s: 3001.567 1612002912.3042092
train: epoch 31, iter 3800, loss: 3.149797, top_1: 0.480000, top_k: 0.721406, samples/s: 2954.433 1612002920.9689906
train: epoch 31, iter 3900, loss: 3.223949, top_1: 0.485781, top_k: 0.726758, samples/s: 2965.796 1612002929.600736
train: epoch 31, iter 4000, loss: 3.210762, top_1: 0.485508, top_k: 0.730039, samples/s: 2897.612 1612002938.4356003
train: epoch 31, iter 4100, loss: 2.988745, top_1: 0.488984, top_k: 0.727461, samples/s: 3013.857 1612002946.929807
train: epoch 31, iter 4200, loss: 3.170919, top_1: 0.485391, top_k: 0.723086, samples/s: 2895.706 1612002955.7704148
train: epoch 31, iter 4300, loss: 3.076086, top_1: 0.487930, top_k: 0.726602, samples/s: 3011.759 1612002964.270439
train: epoch 31, iter 4400, loss: 3.265412, top_1: 0.479453, top_k: 0.720195, samples/s: 2966.595 1612002972.8998094
train: epoch 31, iter 4500, loss: 3.290039, top_1: 0.485117, top_k: 0.723594, samples/s: 2979.681 1612002981.4918444
train: epoch 31, iter 4600, loss: 3.211890, top_1: 0.486953, top_k: 0.726484, samples/s: 2923.504 1612002990.2480226
train: epoch 31, iter 4700, loss: 3.190418, top_1: 0.484141, top_k: 0.719258, samples/s: 2900.048 1612002999.0753744
train: epoch 31, iter 4800, loss: 3.012222, top_1: 0.489687, top_k: 0.728125, samples/s: 2975.215 1612003007.6798728
train: epoch 31, iter 4900, loss: 3.152032, top_1: 0.483984, top_k: 0.726523, samples/s: 2972.943 1612003016.2908967
train: epoch 31, iter 5000, loss: 3.219248, top_1: 0.483945, top_k: 0.727578, samples/s: 3024.097 1612003024.7570374
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_31.
validation: epoch 31, iter 195, top_1: 0.526502, top_k: 0.776843, samples/s: 2949.320 1612003041.899096
train: epoch 32, iter 100, loss: 3.089035, top_1: 0.495664, top_k: 0.736914, samples/s: 2961.492 1612003066.3371282
train: epoch 32, iter 200, loss: 3.106747, top_1: 0.488711, top_k: 0.730938, samples/s: 2993.997 1612003074.887578
train: epoch 32, iter 300, loss: 3.229029, top_1: 0.493320, top_k: 0.730508, samples/s: 2940.724 1612003083.5929365
train: epoch 32, iter 400, loss: 3.108219, top_1: 0.492344, top_k: 0.731641, samples/s: 3000.313 1612003092.1253128
train: epoch 32, iter 500, loss: 3.286781, top_1: 0.492109, top_k: 0.732539, samples/s: 3009.874 1612003100.63065
train: epoch 32, iter 600, loss: 3.029661, top_1: 0.487070, top_k: 0.729414, samples/s: 2929.235 1612003109.370163
train: epoch 32, iter 700, loss: 2.950957, top_1: 0.495430, top_k: 0.733320, samples/s: 2965.863 1612003118.0017366
train: epoch 32, iter 800, loss: 3.135155, top_1: 0.493984, top_k: 0.733555, samples/s: 3012.420 1612003126.4998155
train: epoch 32, iter 900, loss: 3.152869, top_1: 0.483789, top_k: 0.729531, samples/s: 2936.394 1612003135.2179515
train: epoch 32, iter 1000, loss: 3.150798, top_1: 0.489844, top_k: 0.727734, samples/s: 2976.134 1612003143.8197222
train: epoch 32, iter 1100, loss: 3.258134, top_1: 0.486016, top_k: 0.728477, samples/s: 2935.165 1612003152.541645
train: epoch 32, iter 1200, loss: 2.958549, top_1: 0.487578, top_k: 0.724063, samples/s: 2971.922 1612003161.15556
train: epoch 32, iter 1300, loss: 2.938493, top_1: 0.491211, top_k: 0.730117, samples/s: 2967.249 1612003169.783057
train: epoch 32, iter 1400, loss: 3.322172, top_1: 0.482695, top_k: 0.723477, samples/s: 2989.193 1612003178.347264
train: epoch 32, iter 1500, loss: 3.049643, top_1: 0.490273, top_k: 0.728164, samples/s: 2916.294 1612003187.1254828
train: epoch 32, iter 1600, loss: 3.201298, top_1: 0.488711, top_k: 0.731914, samples/s: 3004.558 1612003195.6459315
train: epoch 32, iter 1700, loss: 3.078666, top_1: 0.487070, top_k: 0.727773, samples/s: 2990.449 1612003204.2064564
train: epoch 32, iter 1800, loss: 3.071368, top_1: 0.488633, top_k: 0.728437, samples/s: 2930.615 1612003212.9419208
train: epoch 32, iter 1900, loss: 3.032997, top_1: 0.483789, top_k: 0.726484, samples/s: 2801.058 1612003222.0812292
train: epoch 32, iter 2000, loss: 3.111949, top_1: 0.479648, top_k: 0.723086, samples/s: 2939.521 1612003230.7901552
train: epoch 32, iter 2100, loss: 3.103391, top_1: 0.485938, top_k: 0.728789, samples/s: 3011.556 1612003239.2908022
train: epoch 32, iter 2200, loss: 3.351963, top_1: 0.494063, top_k: 0.734297, samples/s: 2935.147 1612003248.01261
train: epoch 32, iter 2300, loss: 3.223559, top_1: 0.484492, top_k: 0.727617, samples/s: 3015.329 1612003256.502584
train: epoch 32, iter 2400, loss: 3.002807, top_1: 0.488164, top_k: 0.723242, samples/s: 2982.303 1612003265.0865948
train: epoch 32, iter 2500, loss: 3.129675, top_1: 0.487695, top_k: 0.721797, samples/s: 2902.828 1612003273.9055588
train: epoch 32, iter 2600, loss: 3.053628, top_1: 0.489453, top_k: 0.730156, samples/s: 3009.935 1612003282.410691
train: epoch 32, iter 2700, loss: 3.231244, top_1: 0.485703, top_k: 0.724531, samples/s: 2980.070 1612003291.0010755
train: epoch 32, iter 2800, loss: 2.969554, top_1: 0.485078, top_k: 0.726836, samples/s: 2881.652 1612003299.8849318
train: epoch 32, iter 2900, loss: 3.222298, top_1: 0.485547, top_k: 0.723984, samples/s: 2996.010 1612003308.4296567
train: epoch 32, iter 3000, loss: 3.288985, top_1: 0.487930, top_k: 0.725625, samples/s: 2903.635 1612003317.2461367
train: epoch 32, iter 3100, loss: 3.139812, top_1: 0.480117, top_k: 0.726094, samples/s: 3005.780 1612003325.7631054
train: epoch 32, iter 3200, loss: 3.149535, top_1: 0.483516, top_k: 0.726758, samples/s: 2938.366 1612003334.4753802
train: epoch 32, iter 3300, loss: 3.180959, top_1: 0.484492, top_k: 0.723477, samples/s: 2969.965 1612003343.0950212
train: epoch 32, iter 3400, loss: 3.088162, top_1: 0.481602, top_k: 0.725820, samples/s: 2979.810 1612003351.6862917
train: epoch 32, iter 3500, loss: 2.870883, top_1: 0.486641, top_k: 0.726055, samples/s: 2992.495 1612003360.2408657
train: epoch 32, iter 3600, loss: 3.234752, top_1: 0.489375, top_k: 0.729688, samples/s: 2981.817 1612003368.8263943
train: epoch 32, iter 3700, loss: 3.076502, top_1: 0.491602, top_k: 0.728945, samples/s: 2937.676 1612003377.540665
train: epoch 32, iter 3800, loss: 3.163129, top_1: 0.488828, top_k: 0.727344, samples/s: 3035.894 1612003385.973126
train: epoch 32, iter 3900, loss: 3.084973, top_1: 0.484414, top_k: 0.721250, samples/s: 2940.583 1612003394.6788113
train: epoch 32, iter 4000, loss: 3.177867, top_1: 0.488633, top_k: 0.731563, samples/s: 2997.558 1612003403.2190735
train: epoch 32, iter 4100, loss: 3.046473, top_1: 0.487422, top_k: 0.721016, samples/s: 2940.854 1612003411.9240425
train: epoch 32, iter 4200, loss: 3.157555, top_1: 0.489570, top_k: 0.728828, samples/s: 2950.576 1612003420.600391
train: epoch 32, iter 4300, loss: 3.152022, top_1: 0.491992, top_k: 0.732227, samples/s: 2985.044 1612003429.1764252
train: epoch 32, iter 4400, loss: 3.275008, top_1: 0.483320, top_k: 0.726406, samples/s: 2978.756 1612003437.7705839
train: epoch 32, iter 4500, loss: 3.127090, top_1: 0.493008, top_k: 0.726680, samples/s: 2980.433 1612003446.3599858
train: epoch 32, iter 4600, loss: 3.189091, top_1: 0.485977, top_k: 0.725273, samples/s: 2862.662 1612003455.3027399
train: epoch 32, iter 4700, loss: 3.148439, top_1: 0.486563, top_k: 0.730625, samples/s: 2948.945 1612003463.9838696
train: epoch 32, iter 4800, loss: 3.144285, top_1: 0.485781, top_k: 0.728594, samples/s: 2970.026 1612003472.603248
train: epoch 32, iter 4900, loss: 3.161482, top_1: 0.486250, top_k: 0.724922, samples/s: 3024.325 1612003481.0680366
train: epoch 32, iter 5000, loss: 2.980852, top_1: 0.482656, top_k: 0.727773, samples/s: 2983.052 1612003489.6498353
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_32.
validation: epoch 32, iter 195, top_1: 0.534415, top_k: 0.781210, samples/s: 2965.619 1612003506.7434604
train: epoch 33, iter 100, loss: 3.007005, top_1: 0.490234, top_k: 0.735469, samples/s: 2965.769 1612003531.2962997
train: epoch 33, iter 200, loss: 3.057785, top_1: 0.494063, top_k: 0.733320, samples/s: 3000.500 1612003539.8282442
train: epoch 33, iter 300, loss: 3.153833, top_1: 0.497617, top_k: 0.730625, samples/s: 2952.289 1612003548.4994557
train: epoch 33, iter 400, loss: 3.298594, top_1: 0.502305, top_k: 0.738555, samples/s: 2836.428 1612003557.5250242
train: epoch 33, iter 500, loss: 3.000099, top_1: 0.491953, top_k: 0.732812, samples/s: 2975.423 1612003566.128716
train: epoch 33, iter 600, loss: 3.154565, top_1: 0.489492, top_k: 0.726289, samples/s: 3006.822 1612003574.6426969
train: epoch 33, iter 700, loss: 2.976015, top_1: 0.491602, top_k: 0.733672, samples/s: 2969.614 1612003583.2633522
train: epoch 33, iter 800, loss: 3.182478, top_1: 0.490156, top_k: 0.732383, samples/s: 3012.996 1612003591.7599013
train: epoch 33, iter 900, loss: 3.001843, top_1: 0.490352, top_k: 0.728242, samples/s: 2965.521 1612003600.3924303
train: epoch 33, iter 1000, loss: 3.090128, top_1: 0.492070, top_k: 0.731992, samples/s: 3018.280 1612003608.8741398
train: epoch 33, iter 1100, loss: 3.204157, top_1: 0.494805, top_k: 0.732344, samples/s: 2908.952 1612003617.674521
train: epoch 33, iter 1200, loss: 3.075324, top_1: 0.493086, top_k: 0.729492, samples/s: 3011.746 1612003626.1745772
train: epoch 33, iter 1300, loss: 3.064531, top_1: 0.493398, top_k: 0.726406, samples/s: 2918.573 1612003634.9459167
train: epoch 33, iter 1400, loss: 3.096099, top_1: 0.485859, top_k: 0.728672, samples/s: 2982.642 1612003643.5289948
train: epoch 33, iter 1500, loss: 3.305078, top_1: 0.489023, top_k: 0.727852, samples/s: 2940.723 1612003652.2342715
train: epoch 33, iter 1600, loss: 3.204570, top_1: 0.489141, top_k: 0.728633, samples/s: 2959.714 1612003660.8838458
train: epoch 33, iter 1700, loss: 3.267899, top_1: 0.488438, top_k: 0.730820, samples/s: 2955.047 1612003669.5469317
train: epoch 33, iter 1800, loss: 3.091014, top_1: 0.485938, top_k: 0.729141, samples/s: 2989.853 1612003678.109181
train: epoch 33, iter 1900, loss: 2.956669, top_1: 0.487891, top_k: 0.729414, samples/s: 2988.820 1612003686.6744637
train: epoch 33, iter 2000, loss: 3.123499, top_1: 0.485664, top_k: 0.728789, samples/s: 2988.676 1612003695.240119
train: epoch 33, iter 2100, loss: 3.259940, top_1: 0.486641, top_k: 0.728789, samples/s: 3013.797 1612003703.734379
train: epoch 33, iter 2200, loss: 3.167440, top_1: 0.487930, top_k: 0.727617, samples/s: 2962.497 1612003712.3758008
train: epoch 33, iter 2300, loss: 3.225873, top_1: 0.489609, top_k: 0.729141, samples/s: 2978.347 1612003720.9711242
train: epoch 33, iter 2400, loss: 3.316151, top_1: 0.485703, top_k: 0.725859, samples/s: 2974.165 1612003729.5785258
train: epoch 33, iter 2500, loss: 3.056226, top_1: 0.487734, top_k: 0.726172, samples/s: 2959.873 1612003738.2276943
train: epoch 33, iter 2600, loss: 3.161466, top_1: 0.489844, top_k: 0.731523, samples/s: 2842.080 1612003747.235886
train: epoch 33, iter 2700, loss: 3.020776, top_1: 0.490195, top_k: 0.729453, samples/s: 2996.513 1612003755.778396
train: epoch 33, iter 2800, loss: 3.202326, top_1: 0.485508, top_k: 0.724766, samples/s: 3026.395 1612003764.2377539
train: epoch 33, iter 2900, loss: 3.353626, top_1: 0.485234, top_k: 0.725430, samples/s: 2980.514 1612003772.8265426
train: epoch 33, iter 3000, loss: 3.231964, top_1: 0.489180, top_k: 0.725117, samples/s: 2975.039 1612003781.4313142
train: epoch 33, iter 3100, loss: 3.079004, top_1: 0.486563, top_k: 0.726289, samples/s: 2994.443 1612003789.9804904
train: epoch 33, iter 3200, loss: 3.023932, top_1: 0.492852, top_k: 0.730469, samples/s: 2980.387 1612003798.5700057
train: epoch 33, iter 3300, loss: 3.188456, top_1: 0.486836, top_k: 0.729023, samples/s: 2972.222 1612003807.1830003
train: epoch 33, iter 3400, loss: 3.166687, top_1: 0.494609, top_k: 0.732695, samples/s: 2967.307 1612003815.8103898
train: epoch 33, iter 3500, loss: 3.064689, top_1: 0.491016, top_k: 0.729180, samples/s: 3000.443 1612003824.3425746
train: epoch 33, iter 3600, loss: 3.145139, top_1: 0.487578, top_k: 0.726836, samples/s: 2925.143 1612003833.0941381
train: epoch 33, iter 3700, loss: 3.290634, top_1: 0.491172, top_k: 0.732148, samples/s: 2985.706 1612003841.6686044
train: epoch 33, iter 3800, loss: 2.959215, top_1: 0.483906, top_k: 0.726406, samples/s: 2986.444 1612003850.240578
train: epoch 33, iter 3900, loss: 2.984319, top_1: 0.488828, top_k: 0.723984, samples/s: 2981.623 1612003858.8263881
train: epoch 33, iter 4000, loss: 3.333079, top_1: 0.489727, top_k: 0.727109, samples/s: 2951.002 1612003867.5013754
train: epoch 33, iter 4100, loss: 3.191120, top_1: 0.485742, top_k: 0.728594, samples/s: 3000.489 1612003876.0333967
train: epoch 33, iter 4200, loss: 3.043814, top_1: 0.489961, top_k: 0.729414, samples/s: 2902.674 1612003884.852857
train: epoch 33, iter 4300, loss: 3.359952, top_1: 0.486211, top_k: 0.723437, samples/s: 2967.177 1612003893.4805062
train: epoch 33, iter 4400, loss: 3.277177, top_1: 0.492969, top_k: 0.732148, samples/s: 2977.872 1612003902.0772605
train: epoch 33, iter 4500, loss: 3.034722, top_1: 0.489687, top_k: 0.730234, samples/s: 2959.181 1612003910.728305
train: epoch 33, iter 4600, loss: 3.309921, top_1: 0.486836, top_k: 0.727617, samples/s: 2999.346 1612003919.2634788
train: epoch 33, iter 4700, loss: 2.927882, top_1: 0.486406, top_k: 0.726445, samples/s: 2996.022 1612003927.8081706
train: epoch 33, iter 4800, loss: 2.955297, top_1: 0.488398, top_k: 0.730117, samples/s: 2991.272 1612003936.3664172
train: epoch 33, iter 4900, loss: 3.021409, top_1: 0.488047, top_k: 0.728164, samples/s: 2936.171 1612003945.085189
train: epoch 33, iter 5000, loss: 2.949334, top_1: 0.488477, top_k: 0.727148, samples/s: 2982.769 1612003953.6679733
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_33.
validation: epoch 33, iter 195, top_1: 0.510797, top_k: 0.762800, samples/s: 2899.440 1612003971.1115365
train: epoch 34, iter 100, loss: 3.071718, top_1: 0.499570, top_k: 0.736367, samples/s: 2899.221 1612003995.81257
train: epoch 34, iter 200, loss: 3.000532, top_1: 0.497930, top_k: 0.736680, samples/s: 3014.698 1612004004.3042302
train: epoch 34, iter 300, loss: 3.021707, top_1: 0.495469, top_k: 0.737461, samples/s: 2965.625 1612004012.9364808
train: epoch 34, iter 400, loss: 3.049222, top_1: 0.495078, top_k: 0.739258, samples/s: 3011.982 1612004021.435852
train: epoch 34, iter 500, loss: 3.099744, top_1: 0.481016, top_k: 0.727070, samples/s: 2977.832 1612004030.0327766
train: epoch 34, iter 600, loss: 3.052018, top_1: 0.490352, top_k: 0.730586, samples/s: 2973.466 1612004038.6426275
train: epoch 34, iter 700, loss: 2.892075, top_1: 0.491953, top_k: 0.733203, samples/s: 2920.105 1612004047.4089386
train: epoch 34, iter 800, loss: 3.306912, top_1: 0.498594, top_k: 0.737656, samples/s: 3005.061 1612004055.9279478
train: epoch 34, iter 900, loss: 2.996650, top_1: 0.492617, top_k: 0.733672, samples/s: 2966.796 1612004064.556825
train: epoch 34, iter 1000, loss: 2.987446, top_1: 0.490547, top_k: 0.729258, samples/s: 2806.547 1612004073.6782942
train: epoch 34, iter 1100, loss: 3.492117, top_1: 0.495898, top_k: 0.733945, samples/s: 2999.490 1612004082.2131572
train: epoch 34, iter 1200, loss: 3.138902, top_1: 0.495117, top_k: 0.736953, samples/s: 2918.759 1612004090.983945
train: epoch 34, iter 1300, loss: 3.209552, top_1: 0.493047, top_k: 0.732969, samples/s: 2928.527 1612004099.725541
train: epoch 34, iter 1400, loss: 3.316186, top_1: 0.493437, top_k: 0.727773, samples/s: 2946.639 1612004108.4133997
train: epoch 34, iter 1500, loss: 2.895380, top_1: 0.493008, top_k: 0.733242, samples/s: 2997.994 1612004116.9525335
train: epoch 34, iter 1600, loss: 3.080721, top_1: 0.486328, top_k: 0.734180, samples/s: 2994.432 1612004125.5016556
train: epoch 34, iter 1700, loss: 2.952928, top_1: 0.484883, top_k: 0.727148, samples/s: 2920.102 1612004134.268569
train: epoch 34, iter 1800, loss: 3.063151, top_1: 0.499648, top_k: 0.734531, samples/s: 3030.242 1612004142.7166388
train: epoch 34, iter 1900, loss: 3.419436, top_1: 0.490312, top_k: 0.727305, samples/s: 2791.148 1612004151.8885224
train: epoch 34, iter 2000, loss: 3.075788, top_1: 0.484258, top_k: 0.727031, samples/s: 2955.037 1612004160.5516725
train: epoch 34, iter 2100, loss: 2.967438, top_1: 0.492461, top_k: 0.730117, samples/s: 2931.961 1612004169.2830963
train: epoch 34, iter 2200, loss: 3.188807, top_1: 0.488477, top_k: 0.730156, samples/s: 2968.911 1612004177.9057102
train: epoch 34, iter 2300, loss: 3.290995, top_1: 0.488438, top_k: 0.729062, samples/s: 2968.833 1612004186.528653
train: epoch 34, iter 2400, loss: 3.101810, top_1: 0.491914, top_k: 0.731953, samples/s: 2956.554 1612004195.1874413
train: epoch 34, iter 2500, loss: 2.967714, top_1: 0.491484, top_k: 0.731406, samples/s: 2964.139 1612004203.82398
train: epoch 34, iter 2600, loss: 3.262406, top_1: 0.491133, top_k: 0.727891, samples/s: 2943.534 1612004212.5209546
train: epoch 34, iter 2700, loss: 3.209929, top_1: 0.485352, top_k: 0.725195, samples/s: 2997.160 1612004221.0624943
train: epoch 34, iter 2800, loss: 3.113696, top_1: 0.489883, top_k: 0.733711, samples/s: 2942.776 1612004229.7616768
train: epoch 34, iter 2900, loss: 3.245418, top_1: 0.484492, top_k: 0.723867, samples/s: 2942.753 1612004238.460982
train: epoch 34, iter 3000, loss: 3.196347, top_1: 0.486914, top_k: 0.725781, samples/s: 2870.894 1612004247.3781312
train: epoch 34, iter 3100, loss: 3.042143, top_1: 0.486055, top_k: 0.728789, samples/s: 2991.187 1612004255.9365447
train: epoch 34, iter 3200, loss: 3.131808, top_1: 0.486328, top_k: 0.724844, samples/s: 3004.615 1612004264.4570265
train: epoch 34, iter 3300, loss: 2.964277, top_1: 0.493047, top_k: 0.728047, samples/s: 2956.739 1612004273.1149712
train: epoch 34, iter 3400, loss: 2.993856, top_1: 0.487656, top_k: 0.727031, samples/s: 2989.381 1612004281.6786075
train: epoch 34, iter 3500, loss: 2.814032, top_1: 0.486367, top_k: 0.729648, samples/s: 2966.729 1612004290.307646
train: epoch 34, iter 3600, loss: 3.111858, top_1: 0.489141, top_k: 0.725547, samples/s: 2977.604 1612004298.905117
train: epoch 34, iter 3700, loss: 3.399365, top_1: 0.487031, top_k: 0.730508, samples/s: 3021.807 1612004307.3769298
train: epoch 34, iter 3800, loss: 3.173584, top_1: 0.489609, top_k: 0.726562, samples/s: 2955.989 1612004316.0372486
train: epoch 34, iter 3900, loss: 3.133119, top_1: 0.490977, top_k: 0.731289, samples/s: 2929.136 1612004324.7771354
train: epoch 34, iter 4000, loss: 3.098669, top_1: 0.486133, top_k: 0.723359, samples/s: 3000.048 1612004333.3102975
train: epoch 34, iter 4100, loss: 3.029860, top_1: 0.495156, top_k: 0.728594, samples/s: 2919.507 1612004342.0789723
train: epoch 34, iter 4200, loss: 3.113850, top_1: 0.490000, top_k: 0.726758, samples/s: 2993.747 1612004350.6300733
train: epoch 34, iter 4300, loss: 3.235101, top_1: 0.484453, top_k: 0.724063, samples/s: 2975.357 1612004359.2341154
train: epoch 34, iter 4400, loss: 3.181962, top_1: 0.486719, top_k: 0.725664, samples/s: 2960.361 1612004367.8816695
train: epoch 34, iter 4500, loss: 3.174907, top_1: 0.484883, top_k: 0.729570, samples/s: 2974.957 1612004376.4867916
train: epoch 34, iter 4600, loss: 3.212362, top_1: 0.486172, top_k: 0.727891, samples/s: 2992.939 1612004385.0402143
train: epoch 34, iter 4700, loss: 3.314404, top_1: 0.484922, top_k: 0.724023, samples/s: 2966.415 1612004393.6702762
train: epoch 34, iter 4800, loss: 3.262216, top_1: 0.483125, top_k: 0.727266, samples/s: 3015.079 1612004402.1608422
train: epoch 34, iter 4900, loss: 3.131064, top_1: 0.486758, top_k: 0.731836, samples/s: 3000.497 1612004410.6928155
train: epoch 34, iter 5000, loss: 3.345852, top_1: 0.487344, top_k: 0.727109, samples/s: 2977.588 1612004419.2903302
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_34.
validation: epoch 34, iter 195, top_1: 0.529127, top_k: 0.777784, samples/s: 2952.837 1612004436.4887094
train: epoch 35, iter 100, loss: 3.174666, top_1: 0.504961, top_k: 0.741719, samples/s: 2970.649 1612004460.6548853
train: epoch 35, iter 200, loss: 3.089346, top_1: 0.493711, top_k: 0.733828, samples/s: 2970.771 1612004469.2721539
train: epoch 35, iter 300, loss: 3.152584, top_1: 0.495000, top_k: 0.738828, samples/s: 2983.213 1612004477.8535888
train: epoch 35, iter 400, loss: 3.183567, top_1: 0.494883, top_k: 0.731367, samples/s: 2993.896 1612004486.4041896
train: epoch 35, iter 500, loss: 3.149648, top_1: 0.496953, top_k: 0.738672, samples/s: 2914.268 1612004495.188611
train: epoch 35, iter 600, loss: 3.146190, top_1: 0.496484, top_k: 0.732461, samples/s: 3005.417 1612004503.7066615
train: epoch 35, iter 700, loss: 2.929656, top_1: 0.493281, top_k: 0.729492, samples/s: 2870.848 1612004512.6238241
train: epoch 35, iter 800, loss: 3.258881, top_1: 0.491445, top_k: 0.730508, samples/s: 3010.379 1612004521.127787
train: epoch 35, iter 900, loss: 3.190382, top_1: 0.494844, top_k: 0.733633, samples/s: 2950.977 1612004529.8028781
train: epoch 35, iter 1000, loss: 3.123254, top_1: 0.495000, top_k: 0.736602, samples/s: 3035.088 1612004538.2375283
train: epoch 35, iter 1100, loss: 3.126788, top_1: 0.497109, top_k: 0.735313, samples/s: 2991.043 1612004546.7963681
train: epoch 35, iter 1200, loss: 2.999300, top_1: 0.496172, top_k: 0.732812, samples/s: 2972.945 1612004555.4074018
train: epoch 35, iter 1300, loss: 2.853239, top_1: 0.494414, top_k: 0.736641, samples/s: 2985.296 1612004563.9827013
train: epoch 35, iter 1400, loss: 3.082116, top_1: 0.490820, top_k: 0.733594, samples/s: 2988.035 1612004572.5502205
train: epoch 35, iter 1500, loss: 3.242201, top_1: 0.497656, top_k: 0.733828, samples/s: 2980.958 1612004581.1380653
train: epoch 35, iter 1600, loss: 3.208081, top_1: 0.498945, top_k: 0.733281, samples/s: 3011.596 1612004589.638582
train: epoch 35, iter 1700, loss: 2.939438, top_1: 0.497656, top_k: 0.738125, samples/s: 2992.860 1612004598.192314
train: epoch 35, iter 1800, loss: 2.947731, top_1: 0.490195, top_k: 0.730547, samples/s: 2903.784 1612004607.0084178
train: epoch 35, iter 1900, loss: 3.184804, top_1: 0.487070, top_k: 0.726250, samples/s: 3013.193 1612004615.5043814
train: epoch 35, iter 2000, loss: 3.110935, top_1: 0.488906, top_k: 0.727891, samples/s: 2947.312 1612004624.190131
train: epoch 35, iter 2100, loss: 3.268806, top_1: 0.490703, top_k: 0.729961, samples/s: 2936.945 1612004632.9068177
train: epoch 35, iter 2200, loss: 3.275113, top_1: 0.486719, top_k: 0.727969, samples/s: 2834.819 1612004641.9372697
train: epoch 35, iter 2300, loss: 3.038485, top_1: 0.492812, top_k: 0.729727, samples/s: 2954.337 1612004650.6024857
train: epoch 35, iter 2400, loss: 3.029383, top_1: 0.491406, top_k: 0.728242, samples/s: 2911.935 1612004659.3938837
train: epoch 35, iter 2500, loss: 2.886283, top_1: 0.490820, top_k: 0.733906, samples/s: 2954.477 1612004668.058672
train: epoch 35, iter 2600, loss: 3.171753, top_1: 0.488633, top_k: 0.727773, samples/s: 3008.258 1612004676.5687287
train: epoch 35, iter 2700, loss: 3.126308, top_1: 0.493320, top_k: 0.738711, samples/s: 2952.917 1612004685.2380037
train: epoch 35, iter 2800, loss: 3.349998, top_1: 0.490781, top_k: 0.728437, samples/s: 3002.994 1612004693.762834
train: epoch 35, iter 2900, loss: 2.949915, top_1: 0.489180, top_k: 0.727461, samples/s: 3001.816 1612004702.2910511
train: epoch 35, iter 3000, loss: 2.997428, top_1: 0.496055, top_k: 0.736055, samples/s: 2910.219 1612004711.0875888
train: epoch 35, iter 3100, loss: 3.067919, top_1: 0.492852, top_k: 0.733164, samples/s: 2968.293 1612004719.7120922
train: epoch 35, iter 3200, loss: 3.023604, top_1: 0.496016, top_k: 0.730898, samples/s: 2972.262 1612004728.3250039
train: epoch 35, iter 3300, loss: 3.124750, top_1: 0.492695, top_k: 0.733984, samples/s: 2976.270 1612004736.9264145
train: epoch 35, iter 3400, loss: 3.200227, top_1: 0.491211, top_k: 0.730781, samples/s: 2998.673 1612004745.4635851
train: epoch 35, iter 3500, loss: 3.313752, top_1: 0.488398, top_k: 0.724570, samples/s: 2992.477 1612004754.0184076
train: epoch 35, iter 3600, loss: 3.109611, top_1: 0.493164, top_k: 0.728398, samples/s: 2980.844 1612004762.6064827
train: epoch 35, iter 3700, loss: 3.196116, top_1: 0.487383, top_k: 0.727891, samples/s: 3017.893 1612004771.0892293
train: epoch 35, iter 3800, loss: 2.973675, top_1: 0.488750, top_k: 0.727656, samples/s: 2909.939 1612004779.8866482
train: epoch 35, iter 3900, loss: 3.097539, top_1: 0.494492, top_k: 0.728281, samples/s: 2982.457 1612004788.4701355
train: epoch 35, iter 4000, loss: 3.115257, top_1: 0.491563, top_k: 0.734531, samples/s: 2946.252 1612004797.1592536
train: epoch 35, iter 4100, loss: 3.035920, top_1: 0.487773, top_k: 0.729492, samples/s: 2991.395 1612004805.717102
train: epoch 35, iter 4200, loss: 3.179923, top_1: 0.487539, top_k: 0.727422, samples/s: 2950.358 1612004814.3939817
train: epoch 35, iter 4300, loss: 3.229932, top_1: 0.485234, top_k: 0.729570, samples/s: 2996.260 1612004822.938178
train: epoch 35, iter 4400, loss: 3.221705, top_1: 0.495117, top_k: 0.734648, samples/s: 2944.147 1612004831.6331835
train: epoch 35, iter 4500, loss: 3.045576, top_1: 0.486484, top_k: 0.726445, samples/s: 2966.837 1612004840.2619064
train: epoch 35, iter 4600, loss: 3.257876, top_1: 0.493164, top_k: 0.730430, samples/s: 2938.100 1612004848.9751065
train: epoch 35, iter 4700, loss: 3.106542, top_1: 0.485703, top_k: 0.726250, samples/s: 2895.152 1612004857.8174083
train: epoch 35, iter 4800, loss: 3.102085, top_1: 0.491367, top_k: 0.731602, samples/s: 3000.112 1612004866.350409
train: epoch 35, iter 4900, loss: 2.965857, top_1: 0.489922, top_k: 0.730586, samples/s: 2965.219 1612004874.9838352
train: epoch 35, iter 5000, loss: 2.999605, top_1: 0.494688, top_k: 0.732070, samples/s: 2935.355 1612004883.705067
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_35.
validation: epoch 35, iter 195, top_1: 0.524419, top_k: 0.771254, samples/s: 2918.229 1612004900.9684699
train: epoch 36, iter 100, loss: 3.161150, top_1: 0.507812, top_k: 0.745859, samples/s: 2938.766 1612004925.9197066
train: epoch 36, iter 200, loss: 3.242914, top_1: 0.502188, top_k: 0.738086, samples/s: 2992.178 1612004934.4754207
train: epoch 36, iter 300, loss: 3.006341, top_1: 0.500820, top_k: 0.741211, samples/s: 2966.720 1612004943.1043787
train: epoch 36, iter 400, loss: 3.045374, top_1: 0.495742, top_k: 0.738164, samples/s: 3005.942 1612004951.6208768
train: epoch 36, iter 500, loss: 3.261758, top_1: 0.494297, top_k: 0.735273, samples/s: 2977.004 1612004960.220093
train: epoch 36, iter 600, loss: 2.891032, top_1: 0.498828, top_k: 0.734727, samples/s: 2907.682 1612004969.0245163
train: epoch 36, iter 700, loss: 2.956402, top_1: 0.500195, top_k: 0.738437, samples/s: 3012.617 1612004977.522036
train: epoch 36, iter 800, loss: 2.917875, top_1: 0.500313, top_k: 0.736523, samples/s: 2982.039 1612004986.10679
train: epoch 36, iter 900, loss: 2.920442, top_1: 0.495078, top_k: 0.730820, samples/s: 2975.378 1612004994.7107313
train: epoch 36, iter 1000, loss: 3.149521, top_1: 0.494141, top_k: 0.734414, samples/s: 2938.092 1612005003.4237747
train: epoch 36, iter 1100, loss: 3.167331, top_1: 0.492539, top_k: 0.729805, samples/s: 2994.349 1612005011.973238
train: epoch 36, iter 1200, loss: 3.244745, top_1: 0.497695, top_k: 0.736875, samples/s: 2948.590 1612005020.655279
train: epoch 36, iter 1300, loss: 3.005079, top_1: 0.499063, top_k: 0.732422, samples/s: 3013.141 1612005029.151649
train: epoch 36, iter 1400, loss: 3.117111, top_1: 0.497812, top_k: 0.736758, samples/s: 2978.860 1612005037.7453763
train: epoch 36, iter 1500, loss: 3.106879, top_1: 0.491055, top_k: 0.730078, samples/s: 2982.883 1612005046.3277066
train: epoch 36, iter 1600, loss: 3.140472, top_1: 0.493086, top_k: 0.731406, samples/s: 3009.004 1612005054.8354764
train: epoch 36, iter 1700, loss: 3.061773, top_1: 0.489648, top_k: 0.729688, samples/s: 3000.894 1612005063.36625
train: epoch 36, iter 1800, loss: 3.151609, top_1: 0.489180, top_k: 0.730820, samples/s: 2922.914 1612005072.1245644
train: epoch 36, iter 1900, loss: 3.188215, top_1: 0.489258, top_k: 0.731016, samples/s: 3005.868 1612005080.6413057
train: epoch 36, iter 2000, loss: 3.219576, top_1: 0.494805, top_k: 0.733164, samples/s: 2947.582 1612005089.3263807
train: epoch 36, iter 2100, loss: 3.065014, top_1: 0.486953, top_k: 0.728789, samples/s: 3020.194 1612005097.8026397
train: epoch 36, iter 2200, loss: 3.257105, top_1: 0.492031, top_k: 0.729219, samples/s: 2990.354 1612005106.3634791
train: epoch 36, iter 2300, loss: 3.105597, top_1: 0.495859, top_k: 0.739297, samples/s: 2974.210 1612005114.970868
train: epoch 36, iter 2400, loss: 3.039324, top_1: 0.492188, top_k: 0.732812, samples/s: 3001.847 1612005123.498927
train: epoch 36, iter 2500, loss: 3.139108, top_1: 0.485234, top_k: 0.725430, samples/s: 2998.537 1612005132.036601
train: epoch 36, iter 2600, loss: 3.166230, top_1: 0.491563, top_k: 0.733359, samples/s: 2906.894 1612005140.8431115
train: epoch 36, iter 2700, loss: 3.043915, top_1: 0.493086, top_k: 0.735156, samples/s: 2824.557 1612005149.9066052
train: epoch 36, iter 2800, loss: 3.070152, top_1: 0.491563, top_k: 0.730586, samples/s: 3007.031 1612005158.4197786
train: epoch 36, iter 2900, loss: 3.310020, top_1: 0.491484, top_k: 0.732187, samples/s: 2976.709 1612005167.019928
train: epoch 36, iter 3000, loss: 3.302260, top_1: 0.491016, top_k: 0.729531, samples/s: 2975.915 1612005175.6223829
train: epoch 36, iter 3100, loss: 3.123583, top_1: 0.489258, top_k: 0.730391, samples/s: 2989.007 1612005184.187147
train: epoch 36, iter 3200, loss: 3.159914, top_1: 0.491641, top_k: 0.727734, samples/s: 2909.309 1612005192.9864726
train: epoch 36, iter 3300, loss: 3.186694, top_1: 0.491484, top_k: 0.731094, samples/s: 2927.953 1612005201.7296987
train: epoch 36, iter 3400, loss: 3.049600, top_1: 0.495547, top_k: 0.733359, samples/s: 2956.061 1612005210.389937
train: epoch 36, iter 3500, loss: 3.260134, top_1: 0.487617, top_k: 0.727344, samples/s: 2999.694 1612005218.9240592
train: epoch 36, iter 3600, loss: 3.114766, top_1: 0.488477, top_k: 0.731367, samples/s: 3009.567 1612005227.4303796
train: epoch 36, iter 3700, loss: 3.297813, top_1: 0.488086, top_k: 0.731094, samples/s: 2933.965 1612005236.1556735
train: epoch 36, iter 3800, loss: 3.236716, top_1: 0.497109, top_k: 0.734336, samples/s: 3032.612 1612005244.597833
train: epoch 36, iter 3900, loss: 3.110046, top_1: 0.494570, top_k: 0.734648, samples/s: 2925.077 1612005253.349138
train: epoch 36, iter 4000, loss: 3.178304, top_1: 0.492773, top_k: 0.735039, samples/s: 2993.978 1612005261.9009693
train: epoch 36, iter 4100, loss: 3.105706, top_1: 0.489453, top_k: 0.729414, samples/s: 2831.435 1612005270.9412012
train: epoch 36, iter 4200, loss: 3.231513, top_1: 0.490391, top_k: 0.729727, samples/s: 2968.272 1612005279.5655322
train: epoch 36, iter 4300, loss: 3.135351, top_1: 0.488867, top_k: 0.728477, samples/s: 2967.233 1612005288.1932068
train: epoch 36, iter 4400, loss: 3.099199, top_1: 0.487930, top_k: 0.728359, samples/s: 2972.590 1612005296.8051171
train: epoch 36, iter 4500, loss: 3.289532, top_1: 0.486875, top_k: 0.727031, samples/s: 3000.490 1612005305.3370168
train: epoch 36, iter 4600, loss: 3.124403, top_1: 0.484687, top_k: 0.726641, samples/s: 2981.973 1612005313.9219778
train: epoch 36, iter 4700, loss: 3.186149, top_1: 0.488281, top_k: 0.728672, samples/s: 2870.910 1612005322.839148
train: epoch 36, iter 4800, loss: 3.054499, top_1: 0.495352, top_k: 0.731367, samples/s: 2972.947 1612005331.4499931
train: epoch 36, iter 4900, loss: 3.090469, top_1: 0.494102, top_k: 0.732461, samples/s: 2996.280 1612005339.9939218
train: epoch 36, iter 5000, loss: 3.076585, top_1: 0.490742, top_k: 0.730820, samples/s: 3006.020 1612005348.510184
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_36.
validation: epoch 36, iter 195, top_1: 0.538442, top_k: 0.784054, samples/s: 2976.136 1612005365.5514224
train: epoch 37, iter 100, loss: 3.071453, top_1: 0.499414, top_k: 0.735391, samples/s: 2922.518 1612005390.0993636
train: epoch 37, iter 200, loss: 3.086740, top_1: 0.499570, top_k: 0.738906, samples/s: 2919.452 1612005398.8681936
train: epoch 37, iter 300, loss: 3.078055, top_1: 0.501367, top_k: 0.740977, samples/s: 2933.626 1612005407.5943477
train: epoch 37, iter 400, loss: 3.059691, top_1: 0.499570, top_k: 0.740742, samples/s: 2993.192 1612005416.147527
train: epoch 37, iter 500, loss: 3.272065, top_1: 0.501914, top_k: 0.742031, samples/s: 3007.038 1612005424.660516
train: epoch 37, iter 600, loss: 3.191542, top_1: 0.499453, top_k: 0.734844, samples/s: 3003.615 1612005433.1835122
train: epoch 37, iter 700, loss: 3.142388, top_1: 0.499609, top_k: 0.737812, samples/s: 2995.794 1612005441.7288406
train: epoch 37, iter 800, loss: 3.090597, top_1: 0.495273, top_k: 0.732930, samples/s: 2973.112 1612005450.3393536
train: epoch 37, iter 900, loss: 3.249097, top_1: 0.495586, top_k: 0.734961, samples/s: 2980.987 1612005458.9277673
train: epoch 37, iter 1000, loss: 3.262002, top_1: 0.491797, top_k: 0.733750, samples/s: 2971.114 1612005467.5434253
train: epoch 37, iter 1100, loss: 3.290898, top_1: 0.496055, top_k: 0.730859, samples/s: 2961.683 1612005476.1870782
train: epoch 37, iter 1200, loss: 3.063490, top_1: 0.499023, top_k: 0.737109, samples/s: 2991.898 1612005484.743649
train: epoch 37, iter 1300, loss: 2.989156, top_1: 0.503047, top_k: 0.740898, samples/s: 2974.548 1612005493.3499262
train: epoch 37, iter 1400, loss: 3.028066, top_1: 0.492539, top_k: 0.731484, samples/s: 2946.342 1612005502.038934
train: epoch 37, iter 1500, loss: 2.852959, top_1: 0.492422, top_k: 0.733711, samples/s: 2930.009 1612005510.7758727
train: epoch 37, iter 1600, loss: 3.048703, top_1: 0.494023, top_k: 0.733672, samples/s: 2950.975 1612005519.4509268
train: epoch 37, iter 1700, loss: 3.146991, top_1: 0.494961, top_k: 0.729570, samples/s: 2954.766 1612005528.1149046
train: epoch 37, iter 1800, loss: 3.052789, top_1: 0.494336, top_k: 0.734961, samples/s: 3001.256 1612005536.644671
train: epoch 37, iter 1900, loss: 3.167613, top_1: 0.495664, top_k: 0.735664, samples/s: 2960.317 1612005545.2923317
train: epoch 37, iter 2000, loss: 3.109945, top_1: 0.496992, top_k: 0.734375, samples/s: 2957.905 1612005553.9475756
train: epoch 37, iter 2100, loss: 3.348605, top_1: 0.495000, top_k: 0.728477, samples/s: 2994.258 1612005562.4968653
train: epoch 37, iter 2200, loss: 3.211666, top_1: 0.493203, top_k: 0.734570, samples/s: 2974.023 1612005571.1047337
train: epoch 37, iter 2300, loss: 3.141611, top_1: 0.496563, top_k: 0.730625, samples/s: 2959.556 1612005579.754716
train: epoch 37, iter 2400, loss: 3.120536, top_1: 0.489531, top_k: 0.731445, samples/s: 2991.788 1612005588.312401
train: epoch 37, iter 2500, loss: 3.169680, top_1: 0.493125, top_k: 0.731250, samples/s: 2921.451 1612005597.0742474
train: epoch 37, iter 2600, loss: 3.127036, top_1: 0.487773, top_k: 0.729648, samples/s: 2970.968 1612005605.691253
train: epoch 37, iter 2700, loss: 3.312475, top_1: 0.492109, top_k: 0.730820, samples/s: 2997.114 1612005614.2324796
train: epoch 37, iter 2800, loss: 2.938769, top_1: 0.495078, top_k: 0.730742, samples/s: 2966.001 1612005622.8636506
train: epoch 37, iter 2900, loss: 3.116619, top_1: 0.494727, top_k: 0.733594, samples/s: 2999.747 1612005631.397617
train: epoch 37, iter 3000, loss: 3.211569, top_1: 0.490273, top_k: 0.734102, samples/s: 2934.691 1612005640.1209216
train: epoch 37, iter 3100, loss: 3.000673, top_1: 0.496758, top_k: 0.733711, samples/s: 2976.671 1612005648.721188
train: epoch 37, iter 3200, loss: 3.176909, top_1: 0.489961, top_k: 0.728516, samples/s: 2948.307 1612005657.404226
train: epoch 37, iter 3300, loss: 3.268202, top_1: 0.493867, top_k: 0.732656, samples/s: 2844.557 1612005666.4037075
train: epoch 37, iter 3400, loss: 3.034482, top_1: 0.492734, top_k: 0.731953, samples/s: 3042.444 1612005674.8180192
train: epoch 37, iter 3500, loss: 3.154379, top_1: 0.498281, top_k: 0.733320, samples/s: 2961.926 1612005683.4610317
train: epoch 37, iter 3600, loss: 3.244138, top_1: 0.490000, top_k: 0.725938, samples/s: 2911.328 1612005692.2542832
train: epoch 37, iter 3700, loss: 3.202769, top_1: 0.487773, top_k: 0.726836, samples/s: 2843.446 1612005701.2574255
train: epoch 37, iter 3800, loss: 3.103740, top_1: 0.491016, top_k: 0.729609, samples/s: 3008.874 1612005709.7656245
train: epoch 37, iter 3900, loss: 3.171978, top_1: 0.494688, top_k: 0.734805, samples/s: 2990.623 1612005718.3257308
train: epoch 37, iter 4000, loss: 3.333688, top_1: 0.492539, top_k: 0.736406, samples/s: 3003.261 1612005726.849737
train: epoch 37, iter 4100, loss: 3.112731, top_1: 0.493711, top_k: 0.738633, samples/s: 2989.785 1612005735.412231
train: epoch 37, iter 4200, loss: 3.170127, top_1: 0.491719, top_k: 0.728789, samples/s: 2970.940 1612005744.0290215
train: epoch 37, iter 4300, loss: 3.263986, top_1: 0.490039, top_k: 0.732031, samples/s: 2988.689 1612005752.5946596
train: epoch 37, iter 4400, loss: 3.195194, top_1: 0.494883, top_k: 0.734727, samples/s: 2985.488 1612005761.169424
train: epoch 37, iter 4500, loss: 3.309635, top_1: 0.495703, top_k: 0.735547, samples/s: 2981.058 1612005769.757051
train: epoch 37, iter 4600, loss: 3.140885, top_1: 0.488594, top_k: 0.730508, samples/s: 2979.949 1612005778.3479679
train: epoch 37, iter 4700, loss: 2.960278, top_1: 0.491367, top_k: 0.728984, samples/s: 2917.094 1612005787.1236467
train: epoch 37, iter 4800, loss: 3.230782, top_1: 0.485820, top_k: 0.730234, samples/s: 2991.060 1612005795.6824722
train: epoch 37, iter 4900, loss: 3.041689, top_1: 0.494492, top_k: 0.731523, samples/s: 3002.477 1612005804.208767
train: epoch 37, iter 5000, loss: 2.807549, top_1: 0.498281, top_k: 0.734492, samples/s: 2945.925 1612005812.8987978
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_37.
validation: epoch 37, iter 195, top_1: 0.529267, top_k: 0.776863, samples/s: 2963.980 1612005830.0007112
train: epoch 38, iter 100, loss: 3.072718, top_1: 0.503359, top_k: 0.744531, samples/s: 2879.252 1612005854.614563
train: epoch 38, iter 200, loss: 3.032043, top_1: 0.502656, top_k: 0.741055, samples/s: 3011.122 1612005863.1162899
train: epoch 38, iter 300, loss: 2.987566, top_1: 0.499688, top_k: 0.738750, samples/s: 2952.331 1612005871.7875974
train: epoch 38, iter 400, loss: 3.022940, top_1: 0.500508, top_k: 0.740273, samples/s: 3007.213 1612005880.3002644
train: epoch 38, iter 500, loss: 3.011077, top_1: 0.497227, top_k: 0.736055, samples/s: 2967.457 1612005888.9271286
train: epoch 38, iter 600, loss: 3.095906, top_1: 0.491719, top_k: 0.730352, samples/s: 2993.436 1612005897.4792826
train: epoch 38, iter 700, loss: 3.450369, top_1: 0.497812, top_k: 0.731914, samples/s: 2995.797 1612005906.024543
train: epoch 38, iter 800, loss: 3.259559, top_1: 0.497969, top_k: 0.736055, samples/s: 2904.175 1612005914.8394585
train: epoch 38, iter 900, loss: 3.241014, top_1: 0.500625, top_k: 0.741328, samples/s: 2957.921 1612005923.4942136
train: epoch 38, iter 1000, loss: 3.258302, top_1: 0.499766, top_k: 0.737227, samples/s: 2998.160 1612005932.0327985
train: epoch 38, iter 1100, loss: 3.125028, top_1: 0.496914, top_k: 0.736289, samples/s: 3009.909 1612005940.5379713
train: epoch 38, iter 1200, loss: 3.113816, top_1: 0.495078, top_k: 0.737422, samples/s: 2946.177 1612005949.227263
train: epoch 38, iter 1300, loss: 3.134480, top_1: 0.489336, top_k: 0.731914, samples/s: 2996.516 1612005957.7705262
train: epoch 38, iter 1400, loss: 3.072816, top_1: 0.498633, top_k: 0.737070, samples/s: 2919.299 1612005966.5396438
train: epoch 38, iter 1500, loss: 3.323456, top_1: 0.495586, top_k: 0.740938, samples/s: 2978.323 1612005975.1351306
train: epoch 38, iter 1600, loss: 3.139137, top_1: 0.493086, top_k: 0.733984, samples/s: 3014.913 1612005983.6262987
train: epoch 38, iter 1700, loss: 3.231707, top_1: 0.493867, top_k: 0.734023, samples/s: 2943.337 1612005992.3238544
train: epoch 38, iter 1800, loss: 3.221148, top_1: 0.496211, top_k: 0.733516, samples/s: 2944.537 1612006001.0179894
train: epoch 38, iter 1900, loss: 3.044391, top_1: 0.500781, top_k: 0.735703, samples/s: 2966.356 1612006009.6480443
train: epoch 38, iter 2000, loss: 3.137005, top_1: 0.501016, top_k: 0.737656, samples/s: 2955.753 1612006018.3091526
train: epoch 38, iter 2100, loss: 3.197911, top_1: 0.496680, top_k: 0.733555, samples/s: 3006.055 1612006026.8252664
train: epoch 38, iter 2200, loss: 2.993031, top_1: 0.494531, top_k: 0.733672, samples/s: 2970.572 1612006035.4430885
train: epoch 38, iter 2300, loss: 3.132647, top_1: 0.493164, top_k: 0.733047, samples/s: 2940.224 1612006044.1500378
train: epoch 38, iter 2400, loss: 3.173356, top_1: 0.495547, top_k: 0.733555, samples/s: 2967.562 1612006052.7766106
train: epoch 38, iter 2500, loss: 3.309954, top_1: 0.496523, top_k: 0.734102, samples/s: 3018.841 1612006061.2567465
train: epoch 38, iter 2600, loss: 3.003396, top_1: 0.488047, top_k: 0.730039, samples/s: 2990.711 1612006069.8177972
train: epoch 38, iter 2700, loss: 3.112232, top_1: 0.495039, top_k: 0.729961, samples/s: 2953.270 1612006078.4850175
train: epoch 38, iter 2800, loss: 2.974735, top_1: 0.497539, top_k: 0.735898, samples/s: 2962.352 1612006087.1270828
train: epoch 38, iter 2900, loss: 3.081673, top_1: 0.493477, top_k: 0.735781, samples/s: 3026.460 1612006095.585432
train: epoch 38, iter 3000, loss: 3.130347, top_1: 0.495078, top_k: 0.731953, samples/s: 2918.124 1612006104.3580465
train: epoch 38, iter 3100, loss: 3.257331, top_1: 0.495078, top_k: 0.735820, samples/s: 2983.726 1612006112.9380379
train: epoch 38, iter 3200, loss: 3.063880, top_1: 0.490234, top_k: 0.734609, samples/s: 2959.172 1612006121.5890307
train: epoch 38, iter 3300, loss: 3.096455, top_1: 0.489102, top_k: 0.732070, samples/s: 2922.098 1612006130.3498745
train: epoch 38, iter 3400, loss: 2.889711, top_1: 0.494219, top_k: 0.734844, samples/s: 2929.557 1612006139.08841
train: epoch 38, iter 3500, loss: 3.059632, top_1: 0.492773, top_k: 0.730469, samples/s: 2988.711 1612006147.6540518
train: epoch 38, iter 3600, loss: 3.247576, top_1: 0.497344, top_k: 0.736406, samples/s: 2978.911 1612006156.2477021
train: epoch 38, iter 3700, loss: 3.024674, top_1: 0.495586, top_k: 0.733828, samples/s: 2988.072 1612006164.815137
train: epoch 38, iter 3800, loss: 3.294159, top_1: 0.493516, top_k: 0.731055, samples/s: 3007.206 1612006173.3282154
train: epoch 38, iter 3900, loss: 3.193391, top_1: 0.488711, top_k: 0.728945, samples/s: 2962.002 1612006181.9708798
train: epoch 38, iter 4000, loss: 3.055231, top_1: 0.497617, top_k: 0.734336, samples/s: 2963.916 1612006190.6080105
train: epoch 38, iter 4100, loss: 3.185172, top_1: 0.493203, top_k: 0.731719, samples/s: 2984.422 1612006199.1859164
train: epoch 38, iter 4200, loss: 3.246673, top_1: 0.492539, top_k: 0.731094, samples/s: 2994.440 1612006207.7350523
train: epoch 38, iter 4300, loss: 3.103472, top_1: 0.493633, top_k: 0.734844, samples/s: 2963.028 1612006216.3748977
train: epoch 38, iter 4400, loss: 3.122182, top_1: 0.496445, top_k: 0.738242, samples/s: 3037.178 1612006224.8038056
train: epoch 38, iter 4500, loss: 3.287443, top_1: 0.493594, top_k: 0.733320, samples/s: 2976.825 1612006233.4035811
train: epoch 38, iter 4600, loss: 3.190358, top_1: 0.490625, top_k: 0.729570, samples/s: 2926.588 1612006242.1508853
train: epoch 38, iter 4700, loss: 3.202896, top_1: 0.499531, top_k: 0.735195, samples/s: 2978.540 1612006250.7457016
train: epoch 38, iter 4800, loss: 2.870608, top_1: 0.500938, top_k: 0.734961, samples/s: 2987.748 1612006259.3140674
train: epoch 38, iter 4900, loss: 2.806883, top_1: 0.493555, top_k: 0.730977, samples/s: 2986.559 1612006267.885773
train: epoch 38, iter 5000, loss: 3.063091, top_1: 0.493750, top_k: 0.730391, samples/s: 2989.345 1612006276.4495404
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_38.
validation: epoch 38, iter 195, top_1: 0.539663, top_k: 0.787881, samples/s: 2968.303 1612006293.4993646
train: epoch 39, iter 100, loss: 2.978777, top_1: 0.510469, top_k: 0.751445, samples/s: 2965.221 1612006317.7410853
train: epoch 39, iter 200, loss: 3.014125, top_1: 0.508320, top_k: 0.745703, samples/s: 2950.121 1612006326.4188962
train: epoch 39, iter 300, loss: 3.171289, top_1: 0.498516, top_k: 0.735195, samples/s: 2999.834 1612006334.9524853
train: epoch 39, iter 400, loss: 3.281786, top_1: 0.508086, top_k: 0.740820, samples/s: 3022.051 1612006343.4235592
train: epoch 39, iter 500, loss: 3.269901, top_1: 0.507109, top_k: 0.742695, samples/s: 2960.522 1612006352.070782
train: epoch 39, iter 600, loss: 3.053558, top_1: 0.500430, top_k: 0.733867, samples/s: 3021.441 1612006360.5434017
train: epoch 39, iter 700, loss: 3.241927, top_1: 0.504375, top_k: 0.739336, samples/s: 2934.998 1612006369.265824
train: epoch 39, iter 800, loss: 2.927043, top_1: 0.501211, top_k: 0.739336, samples/s: 2956.491 1612006377.924718
train: epoch 39, iter 900, loss: 2.939356, top_1: 0.497695, top_k: 0.735625, samples/s: 2996.940 1612006386.4667358
train: epoch 39, iter 1000, loss: 3.114596, top_1: 0.496328, top_k: 0.736328, samples/s: 3037.066 1612006394.895918
train: epoch 39, iter 1100, loss: 3.128475, top_1: 0.498203, top_k: 0.740430, samples/s: 2950.448 1612006403.5725915
train: epoch 39, iter 1200, loss: 3.246839, top_1: 0.500664, top_k: 0.735430, samples/s: 2950.193 1612006412.2500775
train: epoch 39, iter 1300, loss: 3.181387, top_1: 0.498242, top_k: 0.734336, samples/s: 3045.067 1612006420.657002
train: epoch 39, iter 1400, loss: 3.033652, top_1: 0.499766, top_k: 0.734531, samples/s: 3025.864 1612006429.1174057
train: epoch 39, iter 1500, loss: 2.916099, top_1: 0.498398, top_k: 0.734531, samples/s: 3003.414 1612006437.641089
train: epoch 39, iter 1600, loss: 3.055441, top_1: 0.499492, top_k: 0.737461, samples/s: 2979.144 1612006446.2340572
train: epoch 39, iter 1700, loss: 3.129188, top_1: 0.493125, top_k: 0.738047, samples/s: 2947.815 1612006454.9186406
train: epoch 39, iter 1800, loss: 3.098329, top_1: 0.493320, top_k: 0.735273, samples/s: 2996.017 1612006463.463177
train: epoch 39, iter 1900, loss: 3.152307, top_1: 0.495781, top_k: 0.732266, samples/s: 2956.966 1612006472.1207316
train: epoch 39, iter 2000, loss: 3.347944, top_1: 0.492461, top_k: 0.732773, samples/s: 2916.417 1612006480.8985758
train: epoch 39, iter 2100, loss: 3.080906, top_1: 0.494727, top_k: 0.733984, samples/s: 2925.263 1612006489.6499348
train: epoch 39, iter 2200, loss: 3.165585, top_1: 0.497070, top_k: 0.739219, samples/s: 2980.752 1612006498.2384274
train: epoch 39, iter 2300, loss: 3.280077, top_1: 0.496602, top_k: 0.732656, samples/s: 2933.750 1612006506.9644935
train: epoch 39, iter 2400, loss: 3.037554, top_1: 0.490938, top_k: 0.733672, samples/s: 2923.356 1612006515.7215753
train: epoch 39, iter 2500, loss: 3.065814, top_1: 0.498828, top_k: 0.739297, samples/s: 2960.215 1612006524.3697014
train: epoch 39, iter 2600, loss: 3.256204, top_1: 0.492852, top_k: 0.733047, samples/s: 2956.301 1612006533.029094
train: epoch 39, iter 2700, loss: 2.736069, top_1: 0.498828, top_k: 0.735781, samples/s: 2988.720 1612006541.5945182
train: epoch 39, iter 2800, loss: 3.181221, top_1: 0.492500, top_k: 0.732070, samples/s: 2931.040 1612006550.3286812
train: epoch 39, iter 2900, loss: 3.259237, top_1: 0.495000, top_k: 0.732539, samples/s: 3048.613 1612006558.7259016
train: epoch 39, iter 3000, loss: 3.139287, top_1: 0.496680, top_k: 0.737656, samples/s: 2961.846 1612006567.3691359
train: epoch 39, iter 3100, loss: 3.228768, top_1: 0.497070, top_k: 0.734570, samples/s: 2996.534 1612006575.9123442
train: epoch 39, iter 3200, loss: 3.166214, top_1: 0.495273, top_k: 0.732812, samples/s: 2903.572 1612006584.7292554
train: epoch 39, iter 3300, loss: 2.905105, top_1: 0.494648, top_k: 0.732109, samples/s: 2910.316 1612006593.5253654
train: epoch 39, iter 3400, loss: 3.193688, top_1: 0.493672, top_k: 0.736406, samples/s: 2929.323 1612006602.264667
train: epoch 39, iter 3500, loss: 3.132092, top_1: 0.500938, top_k: 0.738906, samples/s: 2985.094 1612006610.8406012
train: epoch 39, iter 3600, loss: 3.143059, top_1: 0.496445, top_k: 0.733789, samples/s: 2961.739 1612006619.4841073
train: epoch 39, iter 3700, loss: 3.059253, top_1: 0.497148, top_k: 0.731953, samples/s: 2974.583 1612006628.0903556
train: epoch 39, iter 3800, loss: 2.995600, top_1: 0.494727, top_k: 0.735625, samples/s: 2932.042 1612006636.8214645
train: epoch 39, iter 3900, loss: 3.359238, top_1: 0.498437, top_k: 0.731289, samples/s: 2998.928 1612006645.3579085
train: epoch 39, iter 4000, loss: 2.948117, top_1: 0.494609, top_k: 0.731133, samples/s: 2998.302 1612006653.8959942
train: epoch 39, iter 4100, loss: 3.149899, top_1: 0.492695, top_k: 0.731914, samples/s: 2978.086 1612006662.4920719
train: epoch 39, iter 4200, loss: 3.097861, top_1: 0.500313, top_k: 0.733867, samples/s: 2982.749 1612006671.0748198
train: epoch 39, iter 4300, loss: 3.261229, top_1: 0.497930, top_k: 0.733477, samples/s: 2956.109 1612006679.7350667
train: epoch 39, iter 4400, loss: 2.993015, top_1: 0.490859, top_k: 0.728906, samples/s: 2991.135 1612006688.2934632
train: epoch 39, iter 4500, loss: 3.075492, top_1: 0.490234, top_k: 0.735273, samples/s: 3000.611 1612006696.8250883
train: epoch 39, iter 4600, loss: 3.113410, top_1: 0.494063, top_k: 0.734727, samples/s: 3003.984 1612006705.3470771
train: epoch 39, iter 4700, loss: 3.133307, top_1: 0.495781, top_k: 0.735313, samples/s: 2986.817 1612006713.9181473
train: epoch 39, iter 4800, loss: 3.128923, top_1: 0.496094, top_k: 0.732539, samples/s: 2988.070 1612006722.4854956
train: epoch 39, iter 4900, loss: 2.973151, top_1: 0.499727, top_k: 0.737187, samples/s: 3013.234 1612006730.981281
train: epoch 39, iter 5000, loss: 3.072158, top_1: 0.493242, top_k: 0.735586, samples/s: 2920.961 1612006739.745639
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_39.
validation: epoch 39, iter 195, top_1: 0.535136, top_k: 0.782732, samples/s: 3024.639 1612006756.396361
train: epoch 40, iter 100, loss: 2.927799, top_1: 0.508242, top_k: 0.742930, samples/s: 2904.435 1612006781.4491518
train: epoch 40, iter 200, loss: 2.973917, top_1: 0.505078, top_k: 0.738086, samples/s: 2943.543 1612006790.1464908
train: epoch 40, iter 300, loss: 3.001663, top_1: 0.501016, top_k: 0.738867, samples/s: 3013.424 1612006798.641445
train: epoch 40, iter 400, loss: 2.913230, top_1: 0.502344, top_k: 0.740547, samples/s: 2902.614 1612006807.46104
train: epoch 40, iter 500, loss: 3.050787, top_1: 0.500977, top_k: 0.741719, samples/s: 3005.914 1612006815.977668
train: epoch 40, iter 600, loss: 2.971138, top_1: 0.501953, top_k: 0.740781, samples/s: 3007.775 1612006824.4888518
train: epoch 40, iter 700, loss: 3.227866, top_1: 0.497734, top_k: 0.740039, samples/s: 2932.674 1612006833.2180874
train: epoch 40, iter 800, loss: 3.212541, top_1: 0.495312, top_k: 0.739531, samples/s: 3012.802 1612006841.7151175
train: epoch 40, iter 900, loss: 3.140435, top_1: 0.501211, top_k: 0.740703, samples/s: 2997.065 1612006850.256863
train: epoch 40, iter 1000, loss: 3.160635, top_1: 0.502930, top_k: 0.741250, samples/s: 2963.844 1612006858.896946
train: epoch 40, iter 1100, loss: 3.053746, top_1: 0.501875, top_k: 0.740859, samples/s: 2994.404 1612006867.4436455
train: epoch 40, iter 1200, loss: 3.177371, top_1: 0.497500, top_k: 0.736836, samples/s: 2917.515 1612006876.2181857
train: epoch 40, iter 1300, loss: 3.142079, top_1: 0.503437, top_k: 0.740664, samples/s: 2965.173 1612006884.851736
train: epoch 40, iter 1400, loss: 3.224231, top_1: 0.495664, top_k: 0.735156, samples/s: 2864.222 1612006893.7896047
train: epoch 40, iter 1500, loss: 3.187405, top_1: 0.499023, top_k: 0.733945, samples/s: 2980.963 1612006902.3774858
train: epoch 40, iter 1600, loss: 2.973819, top_1: 0.496484, top_k: 0.735000, samples/s: 2943.787 1612006911.0737464
train: epoch 40, iter 1700, loss: 3.250605, top_1: 0.503359, top_k: 0.740664, samples/s: 2955.191 1612006919.7364767
train: epoch 40, iter 1800, loss: 3.083273, top_1: 0.507188, top_k: 0.741602, samples/s: 2908.188 1612006928.5391943
train: epoch 40, iter 1900, loss: 3.060443, top_1: 0.498828, top_k: 0.737227, samples/s: 2956.885 1612006937.1969278
train: epoch 40, iter 2000, loss: 3.085465, top_1: 0.504453, top_k: 0.739023, samples/s: 2960.191 1612006945.8449442
train: epoch 40, iter 2100, loss: 3.205430, top_1: 0.489766, top_k: 0.731289, samples/s: 2963.991 1612006954.4820027
train: epoch 40, iter 2200, loss: 3.158538, top_1: 0.492891, top_k: 0.731953, samples/s: 2947.852 1612006963.166292
train: epoch 40, iter 2300, loss: 2.980839, top_1: 0.499414, top_k: 0.737422, samples/s: 2995.520 1612006971.712421
train: epoch 40, iter 2400, loss: 3.105085, top_1: 0.498281, top_k: 0.739375, samples/s: 2960.869 1612006980.3585904
train: epoch 40, iter 2500, loss: 2.931760, top_1: 0.507109, top_k: 0.746328, samples/s: 2932.716 1612006989.0877652
train: epoch 40, iter 2600, loss: 3.057977, top_1: 0.500977, top_k: 0.736289, samples/s: 2988.840 1612006997.6528351
train: epoch 40, iter 2700, loss: 3.069143, top_1: 0.496680, top_k: 0.736055, samples/s: 2977.578 1612007006.2503805
train: epoch 40, iter 2800, loss: 2.995760, top_1: 0.501523, top_k: 0.743594, samples/s: 2969.491 1612007014.871413
train: epoch 40, iter 2900, loss: 2.947295, top_1: 0.499883, top_k: 0.744531, samples/s: 2938.716 1612007023.5827928
train: epoch 40, iter 3000, loss: 3.256698, top_1: 0.498086, top_k: 0.734336, samples/s: 2939.139 1612007032.2927105
train: epoch 40, iter 3100, loss: 3.202105, top_1: 0.497773, top_k: 0.734961, samples/s: 2973.592 1612007040.9018276
train: epoch 40, iter 3200, loss: 2.852620, top_1: 0.496797, top_k: 0.736172, samples/s: 2991.363 1612007049.4598398
train: epoch 40, iter 3300, loss: 3.064243, top_1: 0.496133, top_k: 0.736758, samples/s: 2935.351 1612007058.1810782
train: epoch 40, iter 3400, loss: 3.159520, top_1: 0.498086, top_k: 0.735977, samples/s: 2936.236 1612007066.8997118
train: epoch 40, iter 3500, loss: 3.181837, top_1: 0.496914, top_k: 0.736445, samples/s: 2961.225 1612007075.5447886
train: epoch 40, iter 3600, loss: 3.062089, top_1: 0.495234, top_k: 0.737930, samples/s: 2956.377 1612007084.2040668
train: epoch 40, iter 3700, loss: 3.264085, top_1: 0.500391, top_k: 0.734023, samples/s: 2964.976 1612007092.8381698
train: epoch 40, iter 3800, loss: 2.742092, top_1: 0.495352, top_k: 0.734609, samples/s: 2927.191 1612007101.583804
train: epoch 40, iter 3900, loss: 3.145428, top_1: 0.495078, top_k: 0.732227, samples/s: 2972.571 1612007110.1959596
train: epoch 40, iter 4000, loss: 3.004917, top_1: 0.495742, top_k: 0.729531, samples/s: 2944.551 1612007118.8898206
train: epoch 40, iter 4100, loss: 3.258350, top_1: 0.492656, top_k: 0.732852, samples/s: 2918.510 1612007127.6615286
train: epoch 40, iter 4200, loss: 3.288078, top_1: 0.494102, top_k: 0.735781, samples/s: 2972.819 1612007136.2728596
train: epoch 40, iter 4300, loss: 3.120018, top_1: 0.491602, top_k: 0.731797, samples/s: 2931.748 1612007145.004792
train: epoch 40, iter 4400, loss: 3.256574, top_1: 0.491719, top_k: 0.728437, samples/s: 2944.908 1612007153.6977935
train: epoch 40, iter 4500, loss: 3.224670, top_1: 0.501328, top_k: 0.739414, samples/s: 2978.991 1612007162.2912834
train: epoch 40, iter 4600, loss: 3.028566, top_1: 0.497734, top_k: 0.729805, samples/s: 2954.237 1612007170.956799
train: epoch 40, iter 4700, loss: 3.017965, top_1: 0.498555, top_k: 0.737656, samples/s: 2963.763 1612007179.5945582
train: epoch 40, iter 4800, loss: 2.988051, top_1: 0.498242, top_k: 0.735977, samples/s: 2983.385 1612007188.1753535
train: epoch 40, iter 4900, loss: 3.121048, top_1: 0.499961, top_k: 0.734766, samples/s: 2942.538 1612007196.8752942
train: epoch 40, iter 5000, loss: 3.008063, top_1: 0.498359, top_k: 0.736016, samples/s: 2983.736 1612007205.455228
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_40.
validation: epoch 40, iter 195, top_1: 0.534816, top_k: 0.781751, samples/s: 2968.552 1612007222.5897918
train: epoch 41, iter 100, loss: 2.865159, top_1: 0.503477, top_k: 0.737422, samples/s: 2975.887 1612007247.1531365
train: epoch 41, iter 200, loss: 3.140743, top_1: 0.503398, top_k: 0.742656, samples/s: 3008.493 1612007255.6627834
train: epoch 41, iter 300, loss: 3.141260, top_1: 0.501758, top_k: 0.739961, samples/s: 2927.027 1612007264.4086275
train: epoch 41, iter 400, loss: 3.173784, top_1: 0.501836, top_k: 0.738008, samples/s: 2926.289 1612007273.1566968
train: epoch 41, iter 500, loss: 3.004150, top_1: 0.502031, top_k: 0.736563, samples/s: 3010.947 1612007281.6590898
train: epoch 41, iter 600, loss: 2.958718, top_1: 0.506719, top_k: 0.741875, samples/s: 2995.494 1612007290.2051766
train: epoch 41, iter 700, loss: 3.334822, top_1: 0.505117, top_k: 0.739258, samples/s: 2958.422 1612007298.8585052
train: epoch 41, iter 800, loss: 3.217544, top_1: 0.501602, top_k: 0.739805, samples/s: 2989.333 1612007307.4224956
train: epoch 41, iter 900, loss: 3.322164, top_1: 0.503594, top_k: 0.739297, samples/s: 2919.946 1612007316.189571
train: epoch 41, iter 1000, loss: 2.979656, top_1: 0.506484, top_k: 0.742305, samples/s: 2979.344 1612007324.78289
train: epoch 41, iter 1100, loss: 2.860437, top_1: 0.501406, top_k: 0.738398, samples/s: 2932.399 1612007333.512127
train: epoch 41, iter 1200, loss: 3.195276, top_1: 0.506914, top_k: 0.743750, samples/s: 3000.011 1612007342.045308
train: epoch 41, iter 1300, loss: 3.016477, top_1: 0.500586, top_k: 0.734883, samples/s: 2970.744 1612007350.6627476
train: epoch 41, iter 1400, loss: 3.084416, top_1: 0.496289, top_k: 0.737617, samples/s: 2905.777 1612007359.472845
train: epoch 41, iter 1500, loss: 3.234033, top_1: 0.504102, top_k: 0.735586, samples/s: 2952.110 1612007368.1445534
train: epoch 41, iter 1600, loss: 3.084697, top_1: 0.498437, top_k: 0.737617, samples/s: 2973.716 1612007376.7532892
train: epoch 41, iter 1700, loss: 3.193602, top_1: 0.503047, top_k: 0.738984, samples/s: 2969.135 1612007385.3753493
train: epoch 41, iter 1800, loss: 2.849910, top_1: 0.504414, top_k: 0.744180, samples/s: 2996.301 1612007393.9191978
train: epoch 41, iter 1900, loss: 3.179387, top_1: 0.505586, top_k: 0.737500, samples/s: 2952.258 1612007402.5905287
train: epoch 41, iter 2000, loss: 3.042883, top_1: 0.503633, top_k: 0.741836, samples/s: 2954.638 1612007411.2548635
train: epoch 41, iter 2100, loss: 3.037184, top_1: 0.502109, top_k: 0.737187, samples/s: 2942.052 1612007419.9562745
train: epoch 41, iter 2200, loss: 3.139904, top_1: 0.496602, top_k: 0.738984, samples/s: 3006.167 1612007428.472109
train: epoch 41, iter 2300, loss: 3.004124, top_1: 0.501719, top_k: 0.733906, samples/s: 2941.066 1612007437.1764817
train: epoch 41, iter 2400, loss: 3.211723, top_1: 0.498555, top_k: 0.737070, samples/s: 2941.534 1612007445.8793159
train: epoch 41, iter 2500, loss: 3.265706, top_1: 0.500273, top_k: 0.737227, samples/s: 3007.263 1612007454.39209
train: epoch 41, iter 2600, loss: 3.177061, top_1: 0.497383, top_k: 0.735703, samples/s: 2913.749 1612007463.1779761
train: epoch 41, iter 2700, loss: 3.234344, top_1: 0.499180, top_k: 0.739102, samples/s: 2986.765 1612007471.7491722
train: epoch 41, iter 2800, loss: 3.092652, top_1: 0.496289, top_k: 0.737344, samples/s: 2967.239 1612007480.3768082
train: epoch 41, iter 2900, loss: 3.155400, top_1: 0.494609, top_k: 0.735664, samples/s: 2977.318 1612007488.975122
train: epoch 41, iter 3000, loss: 3.076733, top_1: 0.496992, top_k: 0.734727, samples/s: 2937.990 1612007497.688564
train: epoch 41, iter 3100, loss: 2.993114, top_1: 0.501328, top_k: 0.739688, samples/s: 2974.627 1612007506.2946272
train: epoch 41, iter 3200, loss: 3.154211, top_1: 0.494766, top_k: 0.733828, samples/s: 2984.811 1612007514.8713658
train: epoch 41, iter 3300, loss: 3.340084, top_1: 0.496484, top_k: 0.741445, samples/s: 2966.586 1612007523.5008423
train: epoch 41, iter 3400, loss: 3.211446, top_1: 0.501016, top_k: 0.735586, samples/s: 2960.673 1612007532.1475139
train: epoch 41, iter 3500, loss: 2.977840, top_1: 0.498633, top_k: 0.734688, samples/s: 2956.130 1612007540.8075347
train: epoch 41, iter 3600, loss: 2.959040, top_1: 0.499688, top_k: 0.737461, samples/s: 2967.574 1612007549.4341204
train: epoch 41, iter 3700, loss: 3.097588, top_1: 0.494766, top_k: 0.737187, samples/s: 2952.610 1612007558.1043534
train: epoch 41, iter 3800, loss: 3.339556, top_1: 0.492656, top_k: 0.735313, samples/s: 2963.953 1612007566.7414372
train: epoch 41, iter 3900, loss: 3.204831, top_1: 0.496094, top_k: 0.737734, samples/s: 3004.014 1612007575.2634103
train: epoch 41, iter 4000, loss: 3.176332, top_1: 0.494023, top_k: 0.734102, samples/s: 2928.813 1612007584.0041463
train: epoch 41, iter 4100, loss: 3.291775, top_1: 0.500039, top_k: 0.737969, samples/s: 2985.976 1612007592.5776038
train: epoch 41, iter 4200, loss: 3.120520, top_1: 0.501992, top_k: 0.736875, samples/s: 2982.962 1612007601.1596317
train: epoch 41, iter 4300, loss: 3.071000, top_1: 0.500586, top_k: 0.737812, samples/s: 2831.468 1612007610.200935
train: epoch 41, iter 4400, loss: 3.398341, top_1: 0.502188, top_k: 0.741992, samples/s: 2966.670 1612007618.8301897
train: epoch 41, iter 4500, loss: 3.271916, top_1: 0.498594, top_k: 0.735664, samples/s: 2973.395 1612007627.4397688
train: epoch 41, iter 4600, loss: 2.835076, top_1: 0.505156, top_k: 0.736016, samples/s: 2980.788 1612007636.0281134
train: epoch 41, iter 4700, loss: 3.366079, top_1: 0.503320, top_k: 0.741172, samples/s: 2889.167 1612007644.8888168
train: epoch 41, iter 4800, loss: 3.067408, top_1: 0.500508, top_k: 0.737500, samples/s: 2917.630 1612007653.6631334
train: epoch 41, iter 4900, loss: 3.039430, top_1: 0.495195, top_k: 0.735273, samples/s: 2875.006 1612007662.5673573
train: epoch 41, iter 5000, loss: 3.206426, top_1: 0.497812, top_k: 0.738164, samples/s: 2924.218 1612007671.3219306
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_41.
validation: epoch 41, iter 195, top_1: 0.545192, top_k: 0.789203, samples/s: 2983.972 1612007688.3430228
train: epoch 42, iter 100, loss: 3.078504, top_1: 0.509492, top_k: 0.745586, samples/s: 2938.112 1612007712.815661
train: epoch 42, iter 200, loss: 3.253639, top_1: 0.504414, top_k: 0.740859, samples/s: 2944.390 1612007721.5101786
train: epoch 42, iter 300, loss: 3.033144, top_1: 0.500547, top_k: 0.741836, samples/s: 2967.930 1612007730.1357572
train: epoch 42, iter 400, loss: 3.246104, top_1: 0.504727, top_k: 0.741875, samples/s: 3017.892 1612007738.6184232
train: epoch 42, iter 500, loss: 3.231434, top_1: 0.507109, top_k: 0.740625, samples/s: 2907.957 1612007747.4219112
train: epoch 42, iter 600, loss: 3.086476, top_1: 0.502422, top_k: 0.740313, samples/s: 2998.814 1612007755.9585872
train: epoch 42, iter 700, loss: 2.877778, top_1: 0.506328, top_k: 0.743086, samples/s: 2987.192 1612007764.5286572
train: epoch 42, iter 800, loss: 3.142612, top_1: 0.502695, top_k: 0.741367, samples/s: 2963.656 1612007773.1664991
train: epoch 42, iter 900, loss: 2.964550, top_1: 0.505391, top_k: 0.741055, samples/s: 2965.011 1612007781.8004901
train: epoch 42, iter 1000, loss: 3.154195, top_1: 0.499063, top_k: 0.734727, samples/s: 2998.027 1612007790.3394928
train: epoch 42, iter 1100, loss: 3.248619, top_1: 0.501992, top_k: 0.738750, samples/s: 3005.507 1612007798.8571799
train: epoch 42, iter 1200, loss: 3.099092, top_1: 0.507812, top_k: 0.744297, samples/s: 2970.231 1612007807.4760568
train: epoch 42, iter 1300, loss: 2.981666, top_1: 0.503320, top_k: 0.738750, samples/s: 2998.461 1612007816.013715
train: epoch 42, iter 1400, loss: 3.153154, top_1: 0.500742, top_k: 0.739414, samples/s: 2950.895 1612007824.6891286
train: epoch 42, iter 1500, loss: 3.266186, top_1: 0.504336, top_k: 0.737578, samples/s: 2913.701 1612007833.4751728
train: epoch 42, iter 1600, loss: 3.218217, top_1: 0.495156, top_k: 0.736836, samples/s: 2985.194 1612007842.0508475
train: epoch 42, iter 1700, loss: 3.253370, top_1: 0.504805, top_k: 0.740977, samples/s: 2944.719 1612007850.7443113
train: epoch 42, iter 1800, loss: 3.280156, top_1: 0.498750, top_k: 0.735898, samples/s: 2957.276 1612007859.4011467
train: epoch 42, iter 1900, loss: 3.371923, top_1: 0.509414, top_k: 0.742461, samples/s: 2962.795 1612007868.0415597
train: epoch 42, iter 2000, loss: 3.049066, top_1: 0.501953, top_k: 0.738750, samples/s: 2982.796 1612007876.624091
train: epoch 42, iter 2100, loss: 3.201079, top_1: 0.504766, top_k: 0.742383, samples/s: 2985.526 1612007885.1986203
train: epoch 42, iter 2200, loss: 3.138653, top_1: 0.501836, top_k: 0.734531, samples/s: 2980.083 1612007893.7890458
train: epoch 42, iter 2300, loss: 2.979523, top_1: 0.499414, top_k: 0.735625, samples/s: 2886.482 1612007902.6579714
train: epoch 42, iter 2400, loss: 3.119190, top_1: 0.493437, top_k: 0.735781, samples/s: 2953.788 1612007911.3248155
train: epoch 42, iter 2500, loss: 3.037789, top_1: 0.497227, top_k: 0.738750, samples/s: 2925.984 1612007920.074083
train: epoch 42, iter 2600, loss: 3.249157, top_1: 0.501680, top_k: 0.740234, samples/s: 3005.396 1612007928.592492
train: epoch 42, iter 2700, loss: 3.115854, top_1: 0.495781, top_k: 0.737656, samples/s: 2957.980 1612007937.2465656
train: epoch 42, iter 2800, loss: 3.183955, top_1: 0.502305, top_k: 0.739219, samples/s: 2957.168 1612007945.9039443
train: epoch 42, iter 2900, loss: 3.360539, top_1: 0.500977, top_k: 0.737852, samples/s: 2978.509 1612007954.4984155
train: epoch 42, iter 3000, loss: 2.995141, top_1: 0.500156, top_k: 0.736289, samples/s: 2950.449 1612007963.1750553
train: epoch 42, iter 3100, loss: 3.274554, top_1: 0.500703, top_k: 0.740234, samples/s: 2944.644 1612007971.868813
train: epoch 42, iter 3200, loss: 2.973568, top_1: 0.501992, top_k: 0.737383, samples/s: 2987.960 1612007980.436595
train: epoch 42, iter 3300, loss: 3.174332, top_1: 0.500781, top_k: 0.737422, samples/s: 2959.097 1612007989.087792
train: epoch 42, iter 3400, loss: 3.145256, top_1: 0.503281, top_k: 0.737617, samples/s: 2951.348 1612007997.761902
train: epoch 42, iter 3500, loss: 3.063669, top_1: 0.497109, top_k: 0.738320, samples/s: 2970.690 1612008006.3794127
train: epoch 42, iter 3600, loss: 2.971736, top_1: 0.498047, top_k: 0.737578, samples/s: 2975.425 1612008014.9831884
train: epoch 42, iter 3700, loss: 3.083789, top_1: 0.496328, top_k: 0.736250, samples/s: 2950.114 1612008023.660853
train: epoch 42, iter 3800, loss: 3.028903, top_1: 0.502422, top_k: 0.734570, samples/s: 2951.600 1612008032.334036
train: epoch 42, iter 3900, loss: 2.736937, top_1: 0.502344, top_k: 0.739805, samples/s: 2951.105 1612008041.0088782
train: epoch 42, iter 4000, loss: 3.324416, top_1: 0.497461, top_k: 0.736875, samples/s: 3002.562 1612008049.5348108
train: epoch 42, iter 4100, loss: 3.090374, top_1: 0.495508, top_k: 0.737187, samples/s: 2974.580 1612008058.1410348
train: epoch 42, iter 4200, loss: 3.047280, top_1: 0.500938, top_k: 0.738359, samples/s: 2968.473 1612008066.7650225
train: epoch 42, iter 4300, loss: 3.109896, top_1: 0.499570, top_k: 0.740039, samples/s: 2983.128 1612008075.3466191
train: epoch 42, iter 4400, loss: 3.325499, top_1: 0.501172, top_k: 0.738750, samples/s: 2972.271 1612008083.9595737
train: epoch 42, iter 4500, loss: 3.082111, top_1: 0.502227, top_k: 0.741406, samples/s: 2938.502 1612008092.671858
train: epoch 42, iter 4600, loss: 3.185061, top_1: 0.496523, top_k: 0.737891, samples/s: 2955.772 1612008101.332507
train: epoch 42, iter 4700, loss: 3.177069, top_1: 0.503008, top_k: 0.742812, samples/s: 2970.630 1612008109.950821
train: epoch 42, iter 4800, loss: 3.215977, top_1: 0.507109, top_k: 0.737812, samples/s: 2694.070 1612008119.45265
train: epoch 42, iter 4900, loss: 3.251905, top_1: 0.504570, top_k: 0.742578, samples/s: 2926.676 1612008128.1996763
train: epoch 42, iter 5000, loss: 3.082621, top_1: 0.500234, top_k: 0.736094, samples/s: 2918.972 1612008136.969894
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_42.
validation: epoch 42, iter 195, top_1: 0.538261, top_k: 0.785276, samples/s: 2982.669 1612008153.9979415
train: epoch 43, iter 100, loss: 3.198490, top_1: 0.509687, top_k: 0.743320, samples/s: 2921.276 1612008178.6907773
train: epoch 43, iter 200, loss: 2.991024, top_1: 0.508203, top_k: 0.747695, samples/s: 2962.752 1612008187.3311992
train: epoch 43, iter 300, loss: 3.209065, top_1: 0.514219, top_k: 0.748203, samples/s: 3000.016 1612008195.8644583
train: epoch 43, iter 400, loss: 3.087555, top_1: 0.508008, top_k: 0.742227, samples/s: 3001.156 1612008204.3945682
train: epoch 43, iter 500, loss: 3.046428, top_1: 0.508242, top_k: 0.741328, samples/s: 2923.971 1612008213.1497762
train: epoch 43, iter 600, loss: 3.101571, top_1: 0.506875, top_k: 0.742266, samples/s: 3007.121 1612008221.6632676
train: epoch 43, iter 700, loss: 3.065024, top_1: 0.508281, top_k: 0.744687, samples/s: 2996.232 1612008230.2069242
train: epoch 43, iter 800, loss: 3.003643, top_1: 0.500469, top_k: 0.743945, samples/s: 3015.041 1612008238.6981583
train: epoch 43, iter 900, loss: 2.996063, top_1: 0.505273, top_k: 0.742969, samples/s: 2982.228 1612008247.2819479
train: epoch 43, iter 1000, loss: 3.000166, top_1: 0.505977, top_k: 0.743008, samples/s: 3037.128 1612008255.7108803
train: epoch 43, iter 1100, loss: 3.208991, top_1: 0.504844, top_k: 0.740117, samples/s: 2954.111 1612008264.3787944
train: epoch 43, iter 1200, loss: 3.106945, top_1: 0.501992, top_k: 0.739414, samples/s: 2976.407 1612008272.9778128
train: epoch 43, iter 1300, loss: 3.142222, top_1: 0.503320, top_k: 0.744414, samples/s: 2969.571 1612008281.5985358
train: epoch 43, iter 1400, loss: 3.100475, top_1: 0.502500, top_k: 0.740195, samples/s: 2981.759 1612008290.1840804
train: epoch 43, iter 1500, loss: 3.103748, top_1: 0.497930, top_k: 0.740273, samples/s: 2999.750 1612008298.7181406
train: epoch 43, iter 1600, loss: 3.244668, top_1: 0.502422, top_k: 0.736602, samples/s: 2906.563 1612008307.5257475
train: epoch 43, iter 1700, loss: 2.831740, top_1: 0.499375, top_k: 0.742344, samples/s: 3019.792 1612008316.0032594
train: epoch 43, iter 1800, loss: 2.852204, top_1: 0.501563, top_k: 0.740117, samples/s: 2986.117 1612008324.5762856
train: epoch 43, iter 1900, loss: 2.960606, top_1: 0.500742, top_k: 0.741289, samples/s: 2944.893 1612008333.2691746
train: epoch 43, iter 2000, loss: 3.413052, top_1: 0.508789, top_k: 0.742617, samples/s: 2990.404 1612008341.8298926
train: epoch 43, iter 2100, loss: 2.911833, top_1: 0.502344, top_k: 0.741523, samples/s: 3000.871 1612008350.360789
train: epoch 43, iter 2200, loss: 2.982433, top_1: 0.502266, top_k: 0.743711, samples/s: 2936.374 1612008359.0790534
train: epoch 43, iter 2300, loss: 3.102580, top_1: 0.502812, top_k: 0.742852, samples/s: 2921.397 1612008367.8419166
train: epoch 43, iter 2400, loss: 3.120075, top_1: 0.500273, top_k: 0.739297, samples/s: 2977.569 1612008376.4395595
train: epoch 43, iter 2500, loss: 2.888311, top_1: 0.503437, top_k: 0.744375, samples/s: 2986.389 1612008385.0117471
train: epoch 43, iter 2600, loss: 3.209726, top_1: 0.506367, top_k: 0.741250, samples/s: 2953.948 1612008393.6781182
train: epoch 43, iter 2700, loss: 2.838980, top_1: 0.504375, top_k: 0.741406, samples/s: 2958.750 1612008402.3304281
train: epoch 43, iter 2800, loss: 2.997402, top_1: 0.503281, top_k: 0.738477, samples/s: 2974.609 1612008410.9366121
train: epoch 43, iter 2900, loss: 2.982911, top_1: 0.504336, top_k: 0.739258, samples/s: 2989.935 1612008419.4988556
train: epoch 43, iter 3000, loss: 3.020109, top_1: 0.502734, top_k: 0.741406, samples/s: 2953.717 1612008428.165791
train: epoch 43, iter 3100, loss: 3.179551, top_1: 0.497266, top_k: 0.739062, samples/s: 3008.139 1612008436.675939
train: epoch 43, iter 3200, loss: 3.026399, top_1: 0.497578, top_k: 0.738398, samples/s: 2952.358 1612008445.346949
train: epoch 43, iter 3300, loss: 3.080502, top_1: 0.497344, top_k: 0.736719, samples/s: 2999.718 1612008453.8811522
train: epoch 43, iter 3400, loss: 3.162230, top_1: 0.504414, top_k: 0.741680, samples/s: 2836.940 1612008462.9055247
train: epoch 43, iter 3500, loss: 3.161314, top_1: 0.503359, top_k: 0.738867, samples/s: 2971.728 1612008471.5194814
train: epoch 43, iter 3600, loss: 3.028405, top_1: 0.500742, top_k: 0.738594, samples/s: 2969.356 1612008480.141299
train: epoch 43, iter 3700, loss: 3.113043, top_1: 0.501797, top_k: 0.741328, samples/s: 2887.984 1612008489.0053837
train: epoch 43, iter 3800, loss: 3.103592, top_1: 0.501836, top_k: 0.738516, samples/s: 2967.191 1612008497.6328635
train: epoch 43, iter 3900, loss: 3.069836, top_1: 0.499883, top_k: 0.740391, samples/s: 3002.707 1612008506.1585124
train: epoch 43, iter 4000, loss: 3.034794, top_1: 0.496445, top_k: 0.736758, samples/s: 2983.378 1612008514.7393174
train: epoch 43, iter 4100, loss: 3.175322, top_1: 0.503047, top_k: 0.738437, samples/s: 2944.723 1612008523.432943
train: epoch 43, iter 4200, loss: 3.042171, top_1: 0.502578, top_k: 0.746328, samples/s: 2984.314 1612008532.011087
train: epoch 43, iter 4300, loss: 2.985690, top_1: 0.502969, top_k: 0.736055, samples/s: 2939.679 1612008540.7196243
train: epoch 43, iter 4400, loss: 3.105643, top_1: 0.506953, top_k: 0.741992, samples/s: 2998.327 1612008549.257676
train: epoch 43, iter 4500, loss: 3.029513, top_1: 0.503008, top_k: 0.737539, samples/s: 2989.469 1612008557.820993
train: epoch 43, iter 4600, loss: 3.221063, top_1: 0.499844, top_k: 0.736523, samples/s: 2912.918 1612008566.609428
train: epoch 43, iter 4700, loss: 3.021502, top_1: 0.499219, top_k: 0.738008, samples/s: 2995.221 1612008575.1563323
train: epoch 43, iter 4800, loss: 2.911807, top_1: 0.503516, top_k: 0.737852, samples/s: 2986.166 1612008583.7292569
train: epoch 43, iter 4900, loss: 3.044222, top_1: 0.500352, top_k: 0.736055, samples/s: 3001.013 1612008592.2597325
train: epoch 43, iter 5000, loss: 3.070866, top_1: 0.494648, top_k: 0.736680, samples/s: 2968.748 1612008600.8829453
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_43.
validation: epoch 43, iter 195, top_1: 0.550441, top_k: 0.794030, samples/s: 2962.134 1612008617.9050853
train: epoch 44, iter 100, loss: 3.074801, top_1: 0.503359, top_k: 0.745742, samples/s: 2964.284 1612008642.2989445
train: epoch 44, iter 200, loss: 3.225943, top_1: 0.506328, top_k: 0.747734, samples/s: 3021.314 1612008650.7720935
train: epoch 44, iter 300, loss: 3.172674, top_1: 0.508047, top_k: 0.743437, samples/s: 2942.966 1612008659.4712658
train: epoch 44, iter 400, loss: 2.941914, top_1: 0.511172, top_k: 0.745977, samples/s: 2930.286 1612008668.2070193
train: epoch 44, iter 500, loss: 3.229866, top_1: 0.503125, top_k: 0.738555, samples/s: 2992.703 1612008676.7615051
train: epoch 44, iter 600, loss: 2.961844, top_1: 0.506641, top_k: 0.746094, samples/s: 3013.428 1612008685.2564027
train: epoch 44, iter 700, loss: 3.262860, top_1: 0.502031, top_k: 0.742656, samples/s: 3000.332 1612008693.7888248
train: epoch 44, iter 800, loss: 3.240392, top_1: 0.510195, top_k: 0.742695, samples/s: 2931.507 1612008702.5215864
train: epoch 44, iter 900, loss: 3.132805, top_1: 0.509805, top_k: 0.749258, samples/s: 2993.370 1612008711.0737078
train: epoch 44, iter 1000, loss: 3.119637, top_1: 0.508320, top_k: 0.742266, samples/s: 2842.683 1612008720.0794234
train: epoch 44, iter 1100, loss: 3.203830, top_1: 0.507227, top_k: 0.744297, samples/s: 2999.313 1612008728.614598
train: epoch 44, iter 1200, loss: 2.860956, top_1: 0.505625, top_k: 0.744141, samples/s: 2959.334 1612008737.2652013
train: epoch 44, iter 1300, loss: 3.240350, top_1: 0.505781, top_k: 0.742891, samples/s: 2947.716 1612008745.9498923
train: epoch 44, iter 1400, loss: 2.993689, top_1: 0.502812, top_k: 0.739219, samples/s: 2880.832 1612008754.8362098
train: epoch 44, iter 1500, loss: 3.068652, top_1: 0.504180, top_k: 0.741094, samples/s: 2923.229 1612008763.5936594
train: epoch 44, iter 1600, loss: 3.023599, top_1: 0.507578, top_k: 0.742891, samples/s: 2994.236 1612008772.143545
train: epoch 44, iter 1700, loss: 3.023372, top_1: 0.507227, top_k: 0.743359, samples/s: 2939.480 1612008780.852451
train: epoch 44, iter 1800, loss: 3.188235, top_1: 0.500273, top_k: 0.739766, samples/s: 2993.443 1612008789.4046016
train: epoch 44, iter 1900, loss: 2.950702, top_1: 0.501367, top_k: 0.736563, samples/s: 3007.198 1612008797.9174416
train: epoch 44, iter 2000, loss: 3.201380, top_1: 0.503125, top_k: 0.741250, samples/s: 2973.136 1612008806.5278115
train: epoch 44, iter 2100, loss: 3.128841, top_1: 0.500938, top_k: 0.739062, samples/s: 2870.215 1612008815.4469461
train: epoch 44, iter 2200, loss: 3.145314, top_1: 0.500664, top_k: 0.736133, samples/s: 2924.295 1612008824.2013202
train: epoch 44, iter 2300, loss: 3.081155, top_1: 0.499883, top_k: 0.739570, samples/s: 3007.337 1612008832.713767
train: epoch 44, iter 2400, loss: 3.034850, top_1: 0.501211, top_k: 0.741445, samples/s: 2962.066 1612008841.3564994
train: epoch 44, iter 2500, loss: 3.036652, top_1: 0.503945, top_k: 0.740547, samples/s: 2997.074 1612008849.8981173
train: epoch 44, iter 2600, loss: 3.049701, top_1: 0.502031, top_k: 0.737578, samples/s: 2944.259 1612008858.5929317
train: epoch 44, iter 2700, loss: 3.053235, top_1: 0.505117, top_k: 0.746953, samples/s: 2982.614 1612008867.175999
train: epoch 44, iter 2800, loss: 3.228092, top_1: 0.508516, top_k: 0.745625, samples/s: 2987.906 1612008875.743887
train: epoch 44, iter 2900, loss: 3.264566, top_1: 0.503086, top_k: 0.738008, samples/s: 3005.051 1612008884.2628582
train: epoch 44, iter 3000, loss: 3.138338, top_1: 0.505820, top_k: 0.742188, samples/s: 2944.244 1612008892.9578488
train: epoch 44, iter 3100, loss: 3.207036, top_1: 0.506133, top_k: 0.742656, samples/s: 2966.578 1612008901.5872707
train: epoch 44, iter 3200, loss: 3.233641, top_1: 0.503633, top_k: 0.740820, samples/s: 2980.984 1612008910.1750429
train: epoch 44, iter 3300, loss: 3.139021, top_1: 0.505156, top_k: 0.737109, samples/s: 2931.268 1612008918.9084716
train: epoch 44, iter 3400, loss: 3.032972, top_1: 0.500000, top_k: 0.738516, samples/s: 2996.017 1612008927.4531257
train: epoch 44, iter 3500, loss: 3.083821, top_1: 0.503867, top_k: 0.739648, samples/s: 2962.454 1612008936.094612
train: epoch 44, iter 3600, loss: 3.185933, top_1: 0.500469, top_k: 0.736953, samples/s: 2997.572 1612008944.6348884
train: epoch 44, iter 3700, loss: 3.074314, top_1: 0.503047, top_k: 0.742773, samples/s: 2996.552 1612008953.1780593
train: epoch 44, iter 3800, loss: 3.203520, top_1: 0.503984, top_k: 0.741484, samples/s: 2992.619 1612008961.7324321
train: epoch 44, iter 3900, loss: 3.239250, top_1: 0.499258, top_k: 0.737187, samples/s: 3004.803 1612008970.2520754
train: epoch 44, iter 4000, loss: 3.164348, top_1: 0.507930, top_k: 0.741406, samples/s: 2996.497 1612008978.795386
train: epoch 44, iter 4100, loss: 3.228415, top_1: 0.500078, top_k: 0.734141, samples/s: 2963.562 1612008987.433655
train: epoch 44, iter 4200, loss: 3.061480, top_1: 0.500586, top_k: 0.737852, samples/s: 3000.956 1612008995.964334
train: epoch 44, iter 4300, loss: 3.237574, top_1: 0.498789, top_k: 0.741836, samples/s: 2999.723 1612009004.4984136
train: epoch 44, iter 4400, loss: 3.138802, top_1: 0.500586, top_k: 0.738516, samples/s: 2944.315 1612009013.193104
train: epoch 44, iter 4500, loss: 3.021913, top_1: 0.507461, top_k: 0.743555, samples/s: 2952.441 1612009021.8638926
train: epoch 44, iter 4600, loss: 3.033395, top_1: 0.503281, top_k: 0.739492, samples/s: 2991.321 1612009030.421984
train: epoch 44, iter 4700, loss: 2.950861, top_1: 0.499570, top_k: 0.738437, samples/s: 2828.104 1612009039.4739923
train: epoch 44, iter 4800, loss: 3.046596, top_1: 0.503789, top_k: 0.737734, samples/s: 2884.284 1612009048.349732
train: epoch 44, iter 4900, loss: 3.122932, top_1: 0.505234, top_k: 0.740234, samples/s: 2988.935 1612009056.9145968
train: epoch 44, iter 5000, loss: 2.946473, top_1: 0.498437, top_k: 0.740039, samples/s: 2996.177 1612009065.4588144
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_44.
validation: epoch 44, iter 195, top_1: 0.542448, top_k: 0.788001, samples/s: 2976.998 1612009082.4919171
train: epoch 45, iter 100, loss: 3.063893, top_1: 0.509922, top_k: 0.744766, samples/s: 2930.244 1612009107.3952432
train: epoch 45, iter 200, loss: 2.991576, top_1: 0.513359, top_k: 0.749297, samples/s: 2981.408 1612009115.9819593
train: epoch 45, iter 300, loss: 3.098729, top_1: 0.515352, top_k: 0.747031, samples/s: 2995.488 1612009124.528061
train: epoch 45, iter 400, loss: 3.080763, top_1: 0.509844, top_k: 0.748203, samples/s: 3010.389 1612009133.031825
train: epoch 45, iter 500, loss: 3.115789, top_1: 0.507773, top_k: 0.747695, samples/s: 3009.003 1612009141.5396006
train: epoch 45, iter 600, loss: 3.463034, top_1: 0.510938, top_k: 0.745625, samples/s: 2969.174 1612009150.161533
train: epoch 45, iter 700, loss: 3.056094, top_1: 0.512539, top_k: 0.747305, samples/s: 2960.691 1612009158.8081565
train: epoch 45, iter 800, loss: 3.140213, top_1: 0.509180, top_k: 0.745508, samples/s: 2911.994 1612009167.5993311
train: epoch 45, iter 900, loss: 3.028086, top_1: 0.505156, top_k: 0.741328, samples/s: 2960.739 1612009176.2459605
train: epoch 45, iter 1000, loss: 3.279000, top_1: 0.508164, top_k: 0.747305, samples/s: 2974.621 1612009184.8520367
train: epoch 45, iter 1100, loss: 3.033142, top_1: 0.508516, top_k: 0.744219, samples/s: 2974.465 1612009193.458619
train: epoch 45, iter 1200, loss: 3.188076, top_1: 0.506641, top_k: 0.743125, samples/s: 2932.028 1612009202.189946
train: epoch 45, iter 1300, loss: 2.901081, top_1: 0.504453, top_k: 0.740273, samples/s: 2966.014 1612009210.8208752
train: epoch 45, iter 1400, loss: 3.231099, top_1: 0.511836, top_k: 0.747734, samples/s: 2971.342 1612009219.4365363
train: epoch 45, iter 1500, loss: 3.111488, top_1: 0.505625, top_k: 0.747344, samples/s: 2945.322 1612009228.1283705
train: epoch 45, iter 1600, loss: 3.200876, top_1: 0.508945, top_k: 0.742695, samples/s: 2989.583 1612009236.6913202
train: epoch 45, iter 1700, loss: 2.928490, top_1: 0.505039, top_k: 0.745039, samples/s: 2965.336 1612009245.324438
train: epoch 45, iter 1800, loss: 2.832289, top_1: 0.504648, top_k: 0.740508, samples/s: 2920.972 1612009254.0886288
train: epoch 45, iter 1900, loss: 3.212636, top_1: 0.503281, top_k: 0.738750, samples/s: 2973.612 1612009262.6977305
train: epoch 45, iter 2000, loss: 3.055030, top_1: 0.504258, top_k: 0.741211, samples/s: 3017.940 1612009271.1802864
train: epoch 45, iter 2100, loss: 3.182755, top_1: 0.502266, top_k: 0.741250, samples/s: 2992.426 1612009279.7352567
train: epoch 45, iter 2200, loss: 3.070399, top_1: 0.504883, top_k: 0.741445, samples/s: 2974.489 1612009288.3416858
train: epoch 45, iter 2300, loss: 3.160971, top_1: 0.507031, top_k: 0.744883, samples/s: 2963.554 1612009296.9800596
train: epoch 45, iter 2400, loss: 3.109466, top_1: 0.502305, top_k: 0.742461, samples/s: 2947.609 1612009305.6650145
train: epoch 45, iter 2500, loss: 3.115055, top_1: 0.505156, top_k: 0.741250, samples/s: 2881.185 1612009314.550252
train: epoch 45, iter 2600, loss: 2.966354, top_1: 0.498867, top_k: 0.736563, samples/s: 2986.259 1612009323.1228466
train: epoch 45, iter 2700, loss: 3.174843, top_1: 0.499688, top_k: 0.742695, samples/s: 2956.645 1612009331.7813494
train: epoch 45, iter 2800, loss: 3.349166, top_1: 0.509023, top_k: 0.742422, samples/s: 2909.813 1612009340.579145
train: epoch 45, iter 2900, loss: 3.157144, top_1: 0.510430, top_k: 0.742656, samples/s: 2877.906 1612009349.4744759
train: epoch 45, iter 3000, loss: 3.180220, top_1: 0.503359, top_k: 0.743281, samples/s: 2933.006 1612009358.2027495
train: epoch 45, iter 3100, loss: 3.076767, top_1: 0.503125, top_k: 0.740391, samples/s: 2961.375 1612009366.8473268
train: epoch 45, iter 3200, loss: 3.310238, top_1: 0.508164, top_k: 0.743477, samples/s: 2966.968 1612009375.4757106
train: epoch 45, iter 3300, loss: 2.991641, top_1: 0.504102, top_k: 0.738945, samples/s: 2973.826 1612009384.0841367
train: epoch 45, iter 3400, loss: 2.999565, top_1: 0.501016, top_k: 0.738750, samples/s: 2942.440 1612009392.7844448
train: epoch 45, iter 3500, loss: 3.104608, top_1: 0.501055, top_k: 0.741055, samples/s: 2949.023 1612009401.4652438
train: epoch 45, iter 3600, loss: 3.077664, top_1: 0.507305, top_k: 0.744844, samples/s: 2943.963 1612009410.1610148
train: epoch 45, iter 3700, loss: 3.121256, top_1: 0.500508, top_k: 0.737617, samples/s: 2946.023 1612009418.8507347
train: epoch 45, iter 3800, loss: 3.129262, top_1: 0.502109, top_k: 0.740469, samples/s: 2973.694 1612009427.4596183
train: epoch 45, iter 3900, loss: 3.163424, top_1: 0.507852, top_k: 0.741406, samples/s: 3010.661 1612009435.9626024
train: epoch 45, iter 4000, loss: 2.742205, top_1: 0.504258, top_k: 0.741016, samples/s: 2964.383 1612009444.5984924
train: epoch 45, iter 4100, loss: 2.936290, top_1: 0.507070, top_k: 0.740859, samples/s: 3002.893 1612009453.1235955
train: epoch 45, iter 4200, loss: 3.208593, top_1: 0.495000, top_k: 0.737930, samples/s: 2975.616 1612009461.726937
train: epoch 45, iter 4300, loss: 3.022701, top_1: 0.497266, top_k: 0.737617, samples/s: 2874.110 1612009470.634002
train: epoch 45, iter 4400, loss: 3.161213, top_1: 0.502656, top_k: 0.743945, samples/s: 3023.812 1612009479.1000936
train: epoch 45, iter 4500, loss: 3.164904, top_1: 0.501797, top_k: 0.744414, samples/s: 2908.753 1612009487.9011505
train: epoch 45, iter 4600, loss: 3.158300, top_1: 0.500352, top_k: 0.740039, samples/s: 2919.376 1612009496.6701245
train: epoch 45, iter 4700, loss: 3.059423, top_1: 0.507930, top_k: 0.741250, samples/s: 2976.797 1612009505.270035
train: epoch 45, iter 4800, loss: 2.908513, top_1: 0.510938, top_k: 0.745938, samples/s: 2954.962 1612009513.9334214
train: epoch 45, iter 4900, loss: 3.113055, top_1: 0.505313, top_k: 0.739023, samples/s: 2991.818 1612009522.490093
train: epoch 45, iter 5000, loss: 3.128250, top_1: 0.507617, top_k: 0.744648, samples/s: 2976.734 1612009531.0904772
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_45.
validation: epoch 45, iter 195, top_1: 0.548237, top_k: 0.790966, samples/s: 2973.284 1612009548.1402438
train: epoch 46, iter 100, loss: 3.108198, top_1: 0.520156, top_k: 0.755078, samples/s: 2932.988 1612009578.9527822
train: epoch 46, iter 200, loss: 2.935569, top_1: 0.516016, top_k: 0.749570, samples/s: 2990.919 1612009587.5125225
train: epoch 46, iter 300, loss: 3.070564, top_1: 0.516836, top_k: 0.754727, samples/s: 3018.845 1612009595.992183
train: epoch 46, iter 400, loss: 2.983591, top_1: 0.511875, top_k: 0.749258, samples/s: 3013.940 1612009604.48638
train: epoch 46, iter 500, loss: 2.923567, top_1: 0.511484, top_k: 0.746680, samples/s: 2996.118 1612009613.0303218
train: epoch 46, iter 600, loss: 3.017891, top_1: 0.513125, top_k: 0.746563, samples/s: 3004.340 1612009621.5513113
train: epoch 46, iter 700, loss: 3.289318, top_1: 0.506406, top_k: 0.748437, samples/s: 2950.141 1612009630.2289734
train: epoch 46, iter 800, loss: 2.943907, top_1: 0.513750, top_k: 0.745195, samples/s: 2984.398 1612009638.806823
train: epoch 46, iter 900, loss: 3.043006, top_1: 0.515508, top_k: 0.749922, samples/s: 2950.293 1612009647.4846287
train: epoch 46, iter 1000, loss: 3.168763, top_1: 0.508711, top_k: 0.743437, samples/s: 3028.136 1612009655.937973
train: epoch 46, iter 1100, loss: 2.934145, top_1: 0.506563, top_k: 0.740625, samples/s: 2968.436 1612009664.562
train: epoch 46, iter 1200, loss: 2.923512, top_1: 0.505547, top_k: 0.743203, samples/s: 2939.397 1612009673.2713528
train: epoch 46, iter 1300, loss: 2.784235, top_1: 0.512109, top_k: 0.746211, samples/s: 2976.343 1612009681.872488
train: epoch 46, iter 1400, loss: 3.051060, top_1: 0.510625, top_k: 0.747109, samples/s: 2976.352 1612009690.4736824
train: epoch 46, iter 1500, loss: 3.021648, top_1: 0.509102, top_k: 0.743125, samples/s: 2962.616 1612009699.1146102
train: epoch 46, iter 1600, loss: 3.244287, top_1: 0.510703, top_k: 0.748828, samples/s: 2957.111 1612009707.7718341
train: epoch 46, iter 1700, loss: 3.106779, top_1: 0.503047, top_k: 0.748828, samples/s: 2966.707 1612009716.400931
train: epoch 46, iter 1800, loss: 3.094567, top_1: 0.507070, top_k: 0.747109, samples/s: 2990.348 1612009724.9616761
train: epoch 46, iter 1900, loss: 2.901130, top_1: 0.511758, top_k: 0.747969, samples/s: 2973.413 1612009733.571306
train: epoch 46, iter 2000, loss: 2.988520, top_1: 0.518203, top_k: 0.751094, samples/s: 2980.599 1612009742.1602163
train: epoch 46, iter 2100, loss: 3.152952, top_1: 0.505742, top_k: 0.741094, samples/s: 2970.082 1612009750.7794569
train: epoch 46, iter 2200, loss: 3.211290, top_1: 0.506875, top_k: 0.743398, samples/s: 2963.751 1612009759.4171934
train: epoch 46, iter 2300, loss: 3.143668, top_1: 0.496641, top_k: 0.738711, samples/s: 2957.195 1612009768.0740016
train: epoch 46, iter 2400, loss: 3.152702, top_1: 0.506875, top_k: 0.742891, samples/s: 2977.163 1612009776.672837
train: epoch 46, iter 2500, loss: 3.257714, top_1: 0.509141, top_k: 0.743789, samples/s: 2835.189 1612009785.7022464
train: epoch 46, iter 2600, loss: 3.006295, top_1: 0.508320, top_k: 0.742891, samples/s: 3001.791 1612009794.2304685
train: epoch 46, iter 2700, loss: 3.010356, top_1: 0.498984, top_k: 0.740000, samples/s: 2955.983 1612009802.8908594
train: epoch 46, iter 2800, loss: 2.970385, top_1: 0.501406, top_k: 0.742305, samples/s: 2930.878 1612009811.6255383
train: epoch 46, iter 2900, loss: 2.924380, top_1: 0.503516, top_k: 0.737656, samples/s: 2967.721 1612009820.2516024
train: epoch 46, iter 3000, loss: 3.053621, top_1: 0.508047, top_k: 0.743867, samples/s: 2993.229 1612009828.804374
train: epoch 46, iter 3100, loss: 3.198411, top_1: 0.501484, top_k: 0.740156, samples/s: 2897.638 1612009837.6390712
train: epoch 46, iter 3200, loss: 3.321934, top_1: 0.504531, top_k: 0.740664, samples/s: 2962.808 1612009846.2794592
train: epoch 46, iter 3300, loss: 2.946334, top_1: 0.503555, top_k: 0.742070, samples/s: 2947.411 1612009854.9651394
train: epoch 46, iter 3400, loss: 3.063412, top_1: 0.508789, top_k: 0.741719, samples/s: 2918.346 1612009863.737151
train: epoch 46, iter 3500, loss: 3.011562, top_1: 0.506445, top_k: 0.744531, samples/s: 2907.273 1612009872.54272
train: epoch 46, iter 3600, loss: 3.000944, top_1: 0.509453, top_k: 0.748203, samples/s: 2987.544 1612009881.1115806
train: epoch 46, iter 3700, loss: 3.003147, top_1: 0.504023, top_k: 0.741406, samples/s: 2933.723 1612009889.8377688
train: epoch 46, iter 3800, loss: 3.140875, top_1: 0.507969, top_k: 0.741680, samples/s: 2944.128 1612009898.533075
train: epoch 46, iter 3900, loss: 3.080675, top_1: 0.505352, top_k: 0.740664, samples/s: 2961.733 1612009907.176631
train: epoch 46, iter 4000, loss: 3.073647, top_1: 0.502070, top_k: 0.741758, samples/s: 2970.879 1612009915.793512
train: epoch 46, iter 4100, loss: 3.189445, top_1: 0.502227, top_k: 0.737578, samples/s: 2934.076 1612009924.5186021
train: epoch 46, iter 4200, loss: 2.950035, top_1: 0.505078, top_k: 0.742891, samples/s: 2988.586 1612009933.0845072
train: epoch 46, iter 4300, loss: 3.428187, top_1: 0.509219, top_k: 0.743555, samples/s: 2942.538 1612009941.7844706
train: epoch 46, iter 4400, loss: 3.111053, top_1: 0.497031, top_k: 0.737148, samples/s: 2932.096 1612009950.5154195
train: epoch 46, iter 4500, loss: 3.176663, top_1: 0.500078, top_k: 0.736602, samples/s: 2969.224 1612009959.13728
train: epoch 46, iter 4600, loss: 3.220590, top_1: 0.500000, top_k: 0.741953, samples/s: 2906.416 1612009967.9452982
train: epoch 46, iter 4700, loss: 3.062394, top_1: 0.506055, top_k: 0.742500, samples/s: 2986.764 1612009976.5164516
train: epoch 46, iter 4800, loss: 3.026837, top_1: 0.504141, top_k: 0.741133, samples/s: 2983.987 1612009985.0956671
train: epoch 46, iter 4900, loss: 2.974855, top_1: 0.504531, top_k: 0.739492, samples/s: 2898.517 1612009993.9276817
train: epoch 46, iter 5000, loss: 2.856598, top_1: 0.505781, top_k: 0.742266, samples/s: 2971.653 1612010002.5424745
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_46.
validation: epoch 46, iter 195, top_1: 0.551082, top_k: 0.796174, samples/s: 2975.631 1612010019.5963745
train: epoch 47, iter 100, loss: 3.244896, top_1: 0.514531, top_k: 0.751406, samples/s: 2968.885 1612010044.3375547
train: epoch 47, iter 200, loss: 3.097926, top_1: 0.516211, top_k: 0.750430, samples/s: 3000.414 1612010052.869761
train: epoch 47, iter 300, loss: 3.259020, top_1: 0.521133, top_k: 0.753984, samples/s: 2996.754 1612010061.412329
train: epoch 47, iter 400, loss: 3.082848, top_1: 0.510977, top_k: 0.750000, samples/s: 3012.698 1612010069.9098113
train: epoch 47, iter 500, loss: 3.094981, top_1: 0.511914, top_k: 0.748633, samples/s: 2931.793 1612010078.6415036
train: epoch 47, iter 600, loss: 3.078200, top_1: 0.507266, top_k: 0.744141, samples/s: 2925.561 1612010087.3919764
train: epoch 47, iter 700, loss: 3.092982, top_1: 0.511289, top_k: 0.746680, samples/s: 2828.661 1612010096.4423
train: epoch 47, iter 800, loss: 3.158303, top_1: 0.513437, top_k: 0.748828, samples/s: 3028.985 1612010104.8938496
train: epoch 47, iter 900, loss: 3.128054, top_1: 0.511094, top_k: 0.751797, samples/s: 2984.943 1612010113.4702563
train: epoch 47, iter 1000, loss: 2.972469, top_1: 0.513281, top_k: 0.745195, samples/s: 2911.379 1612010122.2633975
train: epoch 47, iter 1100, loss: 3.008973, top_1: 0.509727, top_k: 0.749609, samples/s: 2946.422 1612010130.9518132
train: epoch 47, iter 1200, loss: 3.220730, top_1: 0.509336, top_k: 0.742695, samples/s: 2962.107 1612010139.5943122
train: epoch 47, iter 1300, loss: 2.841098, top_1: 0.512109, top_k: 0.748672, samples/s: 2994.650 1612010148.1430128
train: epoch 47, iter 1400, loss: 3.129653, top_1: 0.504766, top_k: 0.743828, samples/s: 2941.400 1612010156.8462288
train: epoch 47, iter 1500, loss: 3.176744, top_1: 0.510664, top_k: 0.748711, samples/s: 2962.685 1612010165.4871562
train: epoch 47, iter 1600, loss: 3.148431, top_1: 0.508672, top_k: 0.745273, samples/s: 2891.601 1612010174.3403187
train: epoch 47, iter 1700, loss: 2.983255, top_1: 0.505859, top_k: 0.741367, samples/s: 2980.219 1612010182.930292
train: epoch 47, iter 1800, loss: 2.891782, top_1: 0.500820, top_k: 0.739727, samples/s: 2935.334 1612010191.6516223
train: epoch 47, iter 1900, loss: 3.077112, top_1: 0.502734, top_k: 0.741719, samples/s: 2956.190 1612010200.311358
train: epoch 47, iter 2000, loss: 2.987818, top_1: 0.509766, top_k: 0.749727, samples/s: 2988.096 1612010208.8789334
train: epoch 47, iter 2100, loss: 3.020194, top_1: 0.511445, top_k: 0.747617, samples/s: 2960.387 1612010217.5262206
train: epoch 47, iter 2200, loss: 3.004631, top_1: 0.506992, top_k: 0.745938, samples/s: 2925.241 1612010226.2776423
train: epoch 47, iter 2300, loss: 2.970524, top_1: 0.506172, top_k: 0.745234, samples/s: 2959.393 1612010234.9281344
train: epoch 47, iter 2400, loss: 3.150541, top_1: 0.510625, top_k: 0.745859, samples/s: 2939.988 1612010243.6355534
train: epoch 47, iter 2500, loss: 3.224062, top_1: 0.506250, top_k: 0.741406, samples/s: 2991.549 1612010252.1930273
train: epoch 47, iter 2600, loss: 3.164211, top_1: 0.507812, top_k: 0.745781, samples/s: 2958.554 1612010260.845879
train: epoch 47, iter 2700, loss: 3.082417, top_1: 0.506602, top_k: 0.739023, samples/s: 2960.148 1612010269.4940836
train: epoch 47, iter 2800, loss: 3.086924, top_1: 0.508398, top_k: 0.745234, samples/s: 2883.772 1612010278.3713875
train: epoch 47, iter 2900, loss: 3.162125, top_1: 0.509531, top_k: 0.744844, samples/s: 2952.304 1612010287.0426145
train: epoch 47, iter 3000, loss: 3.145293, top_1: 0.501563, top_k: 0.742969, samples/s: 2946.788 1612010295.7300427
train: epoch 47, iter 3100, loss: 2.979882, top_1: 0.506445, top_k: 0.742539, samples/s: 2962.370 1612010304.3717234
train: epoch 47, iter 3200, loss: 3.251571, top_1: 0.502109, top_k: 0.738203, samples/s: 2907.948 1612010313.1752458
train: epoch 47, iter 3300, loss: 3.209356, top_1: 0.505156, top_k: 0.745977, samples/s: 2972.892 1612010321.7863605
train: epoch 47, iter 3400, loss: 3.132028, top_1: 0.504687, top_k: 0.743789, samples/s: 2929.862 1612010330.5239553
train: epoch 47, iter 3500, loss: 2.963808, top_1: 0.503086, top_k: 0.743320, samples/s: 3014.390 1612010339.016587
train: epoch 47, iter 3600, loss: 3.285530, top_1: 0.502852, top_k: 0.741133, samples/s: 2979.635 1612010347.608297
train: epoch 47, iter 3700, loss: 2.984685, top_1: 0.510156, top_k: 0.742070, samples/s: 2973.724 1612010356.2169502
train: epoch 47, iter 3800, loss: 3.163723, top_1: 0.504336, top_k: 0.741211, samples/s: 3016.811 1612010364.7027109
train: epoch 47, iter 3900, loss: 3.047233, top_1: 0.501992, top_k: 0.740625, samples/s: 2951.364 1612010373.3767824
train: epoch 47, iter 4000, loss: 3.273299, top_1: 0.509023, top_k: 0.744023, samples/s: 2957.137 1612010382.0336652
train: epoch 47, iter 4100, loss: 3.365712, top_1: 0.506523, top_k: 0.745742, samples/s: 2969.560 1612010390.6544852
train: epoch 47, iter 4200, loss: 3.241877, top_1: 0.505273, top_k: 0.743750, samples/s: 2977.855 1612010399.251261
train: epoch 47, iter 4300, loss: 3.050355, top_1: 0.507578, top_k: 0.745430, samples/s: 2970.429 1612010407.8695717
train: epoch 47, iter 4400, loss: 3.023246, top_1: 0.512031, top_k: 0.744922, samples/s: 2971.402 1612010416.485006
train: epoch 47, iter 4500, loss: 2.893268, top_1: 0.506797, top_k: 0.739570, samples/s: 2981.744 1612010425.0706506
train: epoch 47, iter 4600, loss: 2.996576, top_1: 0.509727, top_k: 0.746094, samples/s: 2966.560 1612010433.7003438
train: epoch 47, iter 4700, loss: 3.012294, top_1: 0.510508, top_k: 0.745352, samples/s: 2933.454 1612010442.4270682
train: epoch 47, iter 4800, loss: 3.170619, top_1: 0.502031, top_k: 0.740625, samples/s: 2957.272 1612010451.0837765
train: epoch 47, iter 4900, loss: 2.984745, top_1: 0.507734, top_k: 0.744531, samples/s: 2976.765 1612010459.6835914
train: epoch 47, iter 5000, loss: 3.160031, top_1: 0.506172, top_k: 0.745156, samples/s: 2979.473 1612010468.2757156
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_47.
validation: epoch 47, iter 195, top_1: 0.547396, top_k: 0.794832, samples/s: 2967.170 1612010485.3579776
train: epoch 48, iter 100, loss: 2.910311, top_1: 0.517031, top_k: 0.753906, samples/s: 2888.213 1612010510.097815
train: epoch 48, iter 200, loss: 2.889611, top_1: 0.515625, top_k: 0.751992, samples/s: 3020.720 1612010518.572615
train: epoch 48, iter 300, loss: 3.071459, top_1: 0.512188, top_k: 0.750625, samples/s: 2994.009 1612010527.1230316
train: epoch 48, iter 400, loss: 3.026864, top_1: 0.516758, top_k: 0.751484, samples/s: 2926.392 1612010535.8710446
train: epoch 48, iter 500, loss: 3.125252, top_1: 0.509609, top_k: 0.748437, samples/s: 2974.621 1612010544.4771166
train: epoch 48, iter 600, loss: 3.102581, top_1: 0.512461, top_k: 0.748867, samples/s: 2930.061 1612010553.214134
train: epoch 48, iter 700, loss: 3.062428, top_1: 0.503945, top_k: 0.743633, samples/s: 3007.658 1612010561.725742
train: epoch 48, iter 800, loss: 3.149004, top_1: 0.509102, top_k: 0.745469, samples/s: 2936.403 1612010570.4439695
train: epoch 48, iter 900, loss: 3.143635, top_1: 0.509492, top_k: 0.742539, samples/s: 3015.406 1612010578.9336615
train: epoch 48, iter 1000, loss: 3.098454, top_1: 0.507930, top_k: 0.743281, samples/s: 3017.328 1612010587.418008
train: epoch 48, iter 1100, loss: 3.158819, top_1: 0.506602, top_k: 0.744141, samples/s: 2930.686 1612010596.15312
train: epoch 48, iter 1200, loss: 3.058660, top_1: 0.510781, top_k: 0.745352, samples/s: 3031.025 1612010604.5991066
train: epoch 48, iter 1300, loss: 2.910246, top_1: 0.505586, top_k: 0.744492, samples/s: 3010.846 1612010613.1017592
train: epoch 48, iter 1400, loss: 2.967390, top_1: 0.513945, top_k: 0.751758, samples/s: 2957.654 1612010621.7572248
train: epoch 48, iter 1500, loss: 2.983211, top_1: 0.507891, top_k: 0.744766, samples/s: 2952.077 1612010630.4291744
train: epoch 48, iter 1600, loss: 3.215215, top_1: 0.508086, top_k: 0.742344, samples/s: 2980.824 1612010639.0173633
train: epoch 48, iter 1700, loss: 2.994411, top_1: 0.508359, top_k: 0.743633, samples/s: 2894.797 1612010647.8607755
train: epoch 48, iter 1800, loss: 3.018368, top_1: 0.511172, top_k: 0.747539, samples/s: 2924.751 1612010656.6137285
train: epoch 48, iter 1900, loss: 3.073324, top_1: 0.502383, top_k: 0.743711, samples/s: 2822.585 1612010665.683383
train: epoch 48, iter 2000, loss: 3.277479, top_1: 0.514180, top_k: 0.748789, samples/s: 3010.908 1612010674.185842
train: epoch 48, iter 2100, loss: 2.929965, top_1: 0.506055, top_k: 0.744297, samples/s: 2943.902 1612010682.881698
train: epoch 48, iter 2200, loss: 3.026489, top_1: 0.509453, top_k: 0.747969, samples/s: 2996.994 1612010691.4235861
train: epoch 48, iter 2300, loss: 3.108733, top_1: 0.511953, top_k: 0.746836, samples/s: 2973.758 1612010700.0322251
train: epoch 48, iter 2400, loss: 3.044065, top_1: 0.505000, top_k: 0.746680, samples/s: 2964.702 1612010708.6672487
train: epoch 48, iter 2500, loss: 3.227971, top_1: 0.505664, top_k: 0.742930, samples/s: 2942.466 1612010717.3674216
train: epoch 48, iter 2600, loss: 3.024910, top_1: 0.504414, top_k: 0.743125, samples/s: 2944.835 1612010726.0605764
train: epoch 48, iter 2700, loss: 3.263312, top_1: 0.510312, top_k: 0.745547, samples/s: 2959.562 1612010734.710536
train: epoch 48, iter 2800, loss: 3.158741, top_1: 0.508047, top_k: 0.744883, samples/s: 3004.583 1612010743.230873
train: epoch 48, iter 2900, loss: 3.251673, top_1: 0.508984, top_k: 0.744961, samples/s: 2975.186 1612010751.8352838
train: epoch 48, iter 3000, loss: 3.071354, top_1: 0.511563, top_k: 0.746016, samples/s: 2967.892 1612010760.4609833
train: epoch 48, iter 3100, loss: 3.055017, top_1: 0.509766, top_k: 0.744961, samples/s: 3008.560 1612010768.9701154
train: epoch 48, iter 3200, loss: 3.105286, top_1: 0.506602, top_k: 0.743867, samples/s: 2928.337 1612010777.7122564
train: epoch 48, iter 3300, loss: 2.969615, top_1: 0.510000, top_k: 0.745430, samples/s: 2991.331 1612010786.2715278
train: epoch 48, iter 3400, loss: 3.059207, top_1: 0.509883, top_k: 0.746172, samples/s: 2907.124 1612010795.07618
train: epoch 48, iter 3500, loss: 3.046584, top_1: 0.511055, top_k: 0.745625, samples/s: 2976.687 1612010803.6763148
train: epoch 48, iter 3600, loss: 3.203003, top_1: 0.500938, top_k: 0.742734, samples/s: 2984.833 1612010812.253256
train: epoch 48, iter 3700, loss: 3.028162, top_1: 0.515469, top_k: 0.745625, samples/s: 2999.758 1612010820.7870703
train: epoch 48, iter 3800, loss: 2.994757, top_1: 0.506211, top_k: 0.744336, samples/s: 2948.252 1612010829.4707124
train: epoch 48, iter 3900, loss: 3.042069, top_1: 0.511406, top_k: 0.746406, samples/s: 2993.554 1612010838.0220032
train: epoch 48, iter 4000, loss: 3.011940, top_1: 0.509414, top_k: 0.742070, samples/s: 2919.144 1612010846.7915573
train: epoch 48, iter 4100, loss: 3.229963, top_1: 0.504023, top_k: 0.741992, samples/s: 2970.626 1612010855.4093306
train: epoch 48, iter 4200, loss: 3.165403, top_1: 0.511055, top_k: 0.748555, samples/s: 2988.962 1612010863.9741037
train: epoch 48, iter 4300, loss: 3.051386, top_1: 0.508437, top_k: 0.746797, samples/s: 2906.615 1612010872.7816381
train: epoch 48, iter 4400, loss: 3.076794, top_1: 0.516055, top_k: 0.747461, samples/s: 3030.860 1612010881.2283194
train: epoch 48, iter 4500, loss: 2.934576, top_1: 0.507148, top_k: 0.745625, samples/s: 2990.519 1612010889.7886407
train: epoch 48, iter 4600, loss: 3.315470, top_1: 0.506953, top_k: 0.741875, samples/s: 3000.962 1612010898.319073
train: epoch 48, iter 4700, loss: 3.117420, top_1: 0.507578, top_k: 0.746289, samples/s: 2882.475 1612010907.2009416
train: epoch 48, iter 4800, loss: 3.206460, top_1: 0.505117, top_k: 0.739805, samples/s: 2978.737 1612010915.794643
train: epoch 48, iter 4900, loss: 2.855728, top_1: 0.505469, top_k: 0.744180, samples/s: 2887.981 1612010924.6592968
train: epoch 48, iter 5000, loss: 3.031365, top_1: 0.509414, top_k: 0.746523, samples/s: 3008.959 1612010933.1667733
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_48.
validation: epoch 48, iter 195, top_1: 0.564303, top_k: 0.805889, samples/s: 3028.314 1612010949.9651809
train: epoch 49, iter 100, loss: 3.044479, top_1: 0.524102, top_k: 0.760547, samples/s: 2962.314 1612010974.7268505
train: epoch 49, iter 200, loss: 2.922009, top_1: 0.517813, top_k: 0.752070, samples/s: 2991.695 1612010983.2842982
train: epoch 49, iter 300, loss: 3.126536, top_1: 0.512656, top_k: 0.753437, samples/s: 3006.045 1612010991.8000443
train: epoch 49, iter 400, loss: 3.266433, top_1: 0.522227, top_k: 0.756719, samples/s: 2968.986 1612011000.422459
train: epoch 49, iter 500, loss: 3.020977, top_1: 0.521875, top_k: 0.751875, samples/s: 2937.246 1612011009.138314
train: epoch 49, iter 600, loss: 2.989606, top_1: 0.515664, top_k: 0.746758, samples/s: 3013.898 1612011017.6321166
train: epoch 49, iter 700, loss: 2.965440, top_1: 0.511367, top_k: 0.749336, samples/s: 2975.875 1612011026.2346146
train: epoch 49, iter 800, loss: 3.061054, top_1: 0.515898, top_k: 0.750000, samples/s: 3029.062 1612011034.6860619
train: epoch 49, iter 900, loss: 3.147546, top_1: 0.513203, top_k: 0.748984, samples/s: 2963.056 1612011043.325788
train: epoch 49, iter 1000, loss: 2.830760, top_1: 0.520156, top_k: 0.752461, samples/s: 2977.985 1612011051.9222646
train: epoch 49, iter 1100, loss: 3.182189, top_1: 0.511875, top_k: 0.747188, samples/s: 2979.265 1612011060.5149307
train: epoch 49, iter 1200, loss: 3.050655, top_1: 0.515039, top_k: 0.749414, samples/s: 2901.116 1612011069.3391252
train: epoch 49, iter 1300, loss: 3.198358, top_1: 0.521563, top_k: 0.750625, samples/s: 2938.053 1612011078.0523717
train: epoch 49, iter 1400, loss: 2.999511, top_1: 0.514023, top_k: 0.749922, samples/s: 2957.800 1612011086.7075152
train: epoch 49, iter 1500, loss: 2.990452, top_1: 0.511797, top_k: 0.742188, samples/s: 2970.464 1612011095.3258555
train: epoch 49, iter 1600, loss: 3.127910, top_1: 0.513125, top_k: 0.749336, samples/s: 2972.692 1612011103.9373872
train: epoch 49, iter 1700, loss: 3.193155, top_1: 0.511250, top_k: 0.748477, samples/s: 2955.353 1612011112.599607
train: epoch 49, iter 1800, loss: 3.260828, top_1: 0.514883, top_k: 0.749805, samples/s: 2998.312 1612011121.1378272
train: epoch 49, iter 1900, loss: 3.144995, top_1: 0.503633, top_k: 0.746445, samples/s: 2908.691 1612011129.9389808
train: epoch 49, iter 2000, loss: 2.748680, top_1: 0.508320, top_k: 0.749648, samples/s: 2908.037 1612011138.7422388
train: epoch 49, iter 2100, loss: 3.045394, top_1: 0.513047, top_k: 0.750430, samples/s: 2954.635 1612011147.4065068
train: epoch 49, iter 2200, loss: 3.073035, top_1: 0.509531, top_k: 0.747188, samples/s: 2957.871 1612011156.0613868
train: epoch 49, iter 2300, loss: 3.217378, top_1: 0.507500, top_k: 0.742227, samples/s: 2997.668 1612011164.6013484
train: epoch 49, iter 2400, loss: 2.868767, top_1: 0.517656, top_k: 0.752852, samples/s: 2986.624 1612011173.1729407
train: epoch 49, iter 2500, loss: 3.096540, top_1: 0.510586, top_k: 0.746797, samples/s: 2958.424 1612011181.8262043
train: epoch 49, iter 2600, loss: 3.211687, top_1: 0.508828, top_k: 0.745703, samples/s: 2986.942 1612011190.3968427
train: epoch 49, iter 2700, loss: 3.242975, top_1: 0.509922, top_k: 0.749141, samples/s: 2974.904 1612011199.0021956
train: epoch 49, iter 2800, loss: 3.302086, top_1: 0.509336, top_k: 0.745508, samples/s: 2947.658 1612011207.6869955
train: epoch 49, iter 2900, loss: 3.130059, top_1: 0.512461, top_k: 0.745547, samples/s: 2963.709 1612011216.324837
train: epoch 49, iter 3000, loss: 3.244050, top_1: 0.504180, top_k: 0.741406, samples/s: 2948.711 1612011225.0066216
train: epoch 49, iter 3100, loss: 3.072571, top_1: 0.511055, top_k: 0.746055, samples/s: 2969.248 1612011233.6282756
train: epoch 49, iter 3200, loss: 3.102616, top_1: 0.500938, top_k: 0.744023, samples/s: 2930.372 1612011242.3643646
train: epoch 49, iter 3300, loss: 3.070271, top_1: 0.506172, top_k: 0.745938, samples/s: 2918.201 1612011251.136918
train: epoch 49, iter 3400, loss: 3.255735, top_1: 0.508633, top_k: 0.743320, samples/s: 2955.515 1612011259.7986841
train: epoch 49, iter 3500, loss: 3.187460, top_1: 0.504219, top_k: 0.741016, samples/s: 2938.607 1612011268.5104856
train: epoch 49, iter 3600, loss: 3.012738, top_1: 0.502852, top_k: 0.742695, samples/s: 2940.746 1612011277.2156665
train: epoch 49, iter 3700, loss: 3.110896, top_1: 0.505430, top_k: 0.746680, samples/s: 3018.317 1612011285.6971133
train: epoch 49, iter 3800, loss: 3.118014, top_1: 0.505195, top_k: 0.740859, samples/s: 2939.269 1612011294.406786
train: epoch 49, iter 3900, loss: 3.006401, top_1: 0.513203, top_k: 0.746523, samples/s: 2965.760 1612011303.0386894
train: epoch 49, iter 4000, loss: 3.106130, top_1: 0.511172, top_k: 0.747852, samples/s: 2972.604 1612011311.6505888
train: epoch 49, iter 4100, loss: 3.151004, top_1: 0.505117, top_k: 0.743672, samples/s: 2988.164 1612011320.2178156
train: epoch 49, iter 4200, loss: 3.087105, top_1: 0.512109, top_k: 0.746719, samples/s: 2920.462 1612011328.9834173
train: epoch 49, iter 4300, loss: 3.073897, top_1: 0.507852, top_k: 0.747148, samples/s: 2970.657 1612011337.6010845
train: epoch 49, iter 4400, loss: 3.266431, top_1: 0.512422, top_k: 0.749883, samples/s: 3011.432 1612011346.101999
train: epoch 49, iter 4500, loss: 3.117076, top_1: 0.510703, top_k: 0.747578, samples/s: 3001.092 1612011354.6322474
train: epoch 49, iter 4600, loss: 2.967987, top_1: 0.509297, top_k: 0.749961, samples/s: 2939.221 1612011363.3421144
train: epoch 49, iter 4700, loss: 3.014036, top_1: 0.506484, top_k: 0.741875, samples/s: 3005.330 1612011371.8602345
train: epoch 49, iter 4800, loss: 2.920746, top_1: 0.505117, top_k: 0.743828, samples/s: 2885.143 1612011380.7332695
train: epoch 49, iter 4900, loss: 3.027839, top_1: 0.502383, top_k: 0.741680, samples/s: 3002.042 1612011389.260835
train: epoch 49, iter 5000, loss: 3.099019, top_1: 0.510117, top_k: 0.748789, samples/s: 2946.504 1612011397.949109
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_49.
validation: epoch 49, iter 195, top_1: 0.553526, top_k: 0.793890, samples/s: 2980.409 1612011414.945858
train: epoch 50, iter 100, loss: 2.890944, top_1: 0.519062, top_k: 0.757812, samples/s: 2966.454 1612011440.2601273
train: epoch 50, iter 200, loss: 3.219473, top_1: 0.518711, top_k: 0.750977, samples/s: 2958.259 1612011448.9136462
train: epoch 50, iter 300, loss: 3.031970, top_1: 0.525117, top_k: 0.752188, samples/s: 2982.097 1612011457.4982793
train: epoch 50, iter 400, loss: 2.980197, top_1: 0.518711, top_k: 0.752930, samples/s: 2968.865 1612011466.121154
train: epoch 50, iter 500, loss: 3.062057, top_1: 0.512578, top_k: 0.752461, samples/s: 2968.856 1612011474.744025
train: epoch 50, iter 600, loss: 2.905899, top_1: 0.511836, top_k: 0.746211, samples/s: 2976.576 1612011483.3444479
train: epoch 50, iter 700, loss: 3.229473, top_1: 0.517695, top_k: 0.752227, samples/s: 2972.818 1612011491.9559517
train: epoch 50, iter 800, loss: 3.261614, top_1: 0.509297, top_k: 0.747422, samples/s: 2970.489 1612011500.5739334
train: epoch 50, iter 900, loss: 3.058647, top_1: 0.512148, top_k: 0.745781, samples/s: 2998.037 1612011509.112752
train: epoch 50, iter 1000, loss: 2.944536, top_1: 0.513516, top_k: 0.749219, samples/s: 2996.334 1612011517.656637
train: epoch 50, iter 1100, loss: 3.097743, top_1: 0.514883, top_k: 0.749883, samples/s: 3001.829 1612011526.1847134
train: epoch 50, iter 1200, loss: 3.140139, top_1: 0.509414, top_k: 0.747812, samples/s: 3004.109 1612011534.7063556
train: epoch 50, iter 1300, loss: 3.237192, top_1: 0.513086, top_k: 0.751523, samples/s: 2974.793 1612011543.3120668
train: epoch 50, iter 1400, loss: 2.935236, top_1: 0.512383, top_k: 0.746016, samples/s: 2958.445 1612011551.965228
train: epoch 50, iter 1500, loss: 3.067406, top_1: 0.512578, top_k: 0.752070, samples/s: 2972.194 1612011560.5785165
train: epoch 50, iter 1600, loss: 2.850313, top_1: 0.513867, top_k: 0.750000, samples/s: 2868.914 1612011569.5016515
train: epoch 50, iter 1700, loss: 2.794964, top_1: 0.509922, top_k: 0.746016, samples/s: 2986.057 1612011578.0748727
train: epoch 50, iter 1800, loss: 2.890462, top_1: 0.516133, top_k: 0.749883, samples/s: 2918.825 1612011586.8455062
train: epoch 50, iter 1900, loss: 3.284617, top_1: 0.507930, top_k: 0.747461, samples/s: 3005.291 1612011595.3637943
train: epoch 50, iter 2000, loss: 3.172317, top_1: 0.508750, top_k: 0.745313, samples/s: 2973.221 1612011603.9739501
train: epoch 50, iter 2100, loss: 3.182127, top_1: 0.509375, top_k: 0.747383, samples/s: 2983.682 1612011612.553968
train: epoch 50, iter 2200, loss: 3.206216, top_1: 0.511367, top_k: 0.746406, samples/s: 2971.591 1612011621.168823
train: epoch 50, iter 2300, loss: 2.977419, top_1: 0.513320, top_k: 0.747422, samples/s: 2964.496 1612011629.8043904
train: epoch 50, iter 2400, loss: 3.017070, top_1: 0.519141, top_k: 0.754805, samples/s: 2975.287 1612011638.4086814
train: epoch 50, iter 2500, loss: 3.051692, top_1: 0.510977, top_k: 0.748945, samples/s: 2965.253 1612011647.041948
train: epoch 50, iter 2600, loss: 2.968495, top_1: 0.511523, top_k: 0.747734, samples/s: 2926.729 1612011655.78897
train: epoch 50, iter 2700, loss: 3.020391, top_1: 0.509375, top_k: 0.745234, samples/s: 2958.613 1612011664.4417048
train: epoch 50, iter 2800, loss: 3.083304, top_1: 0.505391, top_k: 0.745117, samples/s: 2859.547 1612011673.3940775
train: epoch 50, iter 2900, loss: 3.015235, top_1: 0.507227, top_k: 0.743789, samples/s: 2970.059 1612011682.0134273
train: epoch 50, iter 3000, loss: 2.871275, top_1: 0.505156, top_k: 0.747773, samples/s: 2974.306 1612011690.620482
train: epoch 50, iter 3100, loss: 3.074240, top_1: 0.516758, top_k: 0.753555, samples/s: 2913.028 1612011699.4087427
train: epoch 50, iter 3200, loss: 3.026610, top_1: 0.517852, top_k: 0.755508, samples/s: 2963.759 1612011708.0462635
train: epoch 50, iter 3300, loss: 2.867558, top_1: 0.510469, top_k: 0.750742, samples/s: 2871.843 1612011716.9604886
train: epoch 50, iter 3400, loss: 3.074522, top_1: 0.506016, top_k: 0.745859, samples/s: 2956.361 1612011725.619733
train: epoch 50, iter 3500, loss: 2.999828, top_1: 0.514180, top_k: 0.748008, samples/s: 2877.632 1612011734.5158873
train: epoch 50, iter 3600, loss: 2.995927, top_1: 0.505352, top_k: 0.747031, samples/s: 2965.605 1612011743.1482127
train: epoch 50, iter 3700, loss: 3.089927, top_1: 0.509609, top_k: 0.744687, samples/s: 2956.840 1612011751.8060951
train: epoch 50, iter 3800, loss: 3.186651, top_1: 0.507422, top_k: 0.746719, samples/s: 2967.187 1612011760.4337842
train: epoch 50, iter 3900, loss: 2.981514, top_1: 0.509180, top_k: 0.748047, samples/s: 2964.450 1612011769.0694628
train: epoch 50, iter 4000, loss: 3.043352, top_1: 0.508867, top_k: 0.748164, samples/s: 2948.960 1612011777.7505035
train: epoch 50, iter 4100, loss: 3.250905, top_1: 0.509180, top_k: 0.746719, samples/s: 2972.697 1612011786.3623013
train: epoch 50, iter 4200, loss: 3.106429, top_1: 0.507969, top_k: 0.743945, samples/s: 2990.795 1612011794.9218812
train: epoch 50, iter 4300, loss: 2.804563, top_1: 0.509023, top_k: 0.743711, samples/s: 2936.503 1612011803.639697
train: epoch 50, iter 4400, loss: 3.148800, top_1: 0.513633, top_k: 0.745430, samples/s: 2979.576 1612011812.2314596
train: epoch 50, iter 4500, loss: 3.216779, top_1: 0.502578, top_k: 0.741680, samples/s: 2893.231 1612011821.0798137
train: epoch 50, iter 4600, loss: 2.997774, top_1: 0.512070, top_k: 0.752578, samples/s: 2950.291 1612011829.7568119
train: epoch 50, iter 4700, loss: 3.226672, top_1: 0.517578, top_k: 0.745664, samples/s: 2988.340 1612011838.323547
train: epoch 50, iter 4800, loss: 2.990576, top_1: 0.510352, top_k: 0.745625, samples/s: 2977.662 1612011846.9207988
train: epoch 50, iter 4900, loss: 3.099977, top_1: 0.506758, top_k: 0.745586, samples/s: 2935.363 1612011855.6420624
train: epoch 50, iter 5000, loss: 3.069399, top_1: 0.514258, top_k: 0.744062, samples/s: 2975.739 1612011864.2449622
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_50.
validation: epoch 50, iter 195, top_1: 0.555008, top_k: 0.794411, samples/s: 2903.704 1612011881.7158024
train: epoch 51, iter 100, loss: 2.900368, top_1: 0.516719, top_k: 0.753906, samples/s: 2968.009 1612011906.4018736
train: epoch 51, iter 200, loss: 3.149740, top_1: 0.521289, top_k: 0.752578, samples/s: 2979.287 1612011914.99458
train: epoch 51, iter 300, loss: 3.006749, top_1: 0.512383, top_k: 0.748359, samples/s: 2965.762 1612011923.6263747
train: epoch 51, iter 400, loss: 3.031534, top_1: 0.517422, top_k: 0.754609, samples/s: 2992.140 1612011932.1821465
train: epoch 51, iter 500, loss: 2.996635, top_1: 0.519648, top_k: 0.755703, samples/s: 2970.298 1612011940.800836
train: epoch 51, iter 600, loss: 3.037082, top_1: 0.510859, top_k: 0.753086, samples/s: 2982.195 1612011949.3850837
train: epoch 51, iter 700, loss: 2.997094, top_1: 0.517305, top_k: 0.752461, samples/s: 2967.572 1612011958.011644
train: epoch 51, iter 800, loss: 3.021829, top_1: 0.517266, top_k: 0.753867, samples/s: 2866.941 1612011966.9410887
train: epoch 51, iter 900, loss: 2.996279, top_1: 0.517070, top_k: 0.752109, samples/s: 3031.632 1612011975.3853476
train: epoch 51, iter 1000, loss: 3.007010, top_1: 0.517852, top_k: 0.753242, samples/s: 2991.839 1612011983.9419377
train: epoch 51, iter 1100, loss: 2.999979, top_1: 0.512266, top_k: 0.747305, samples/s: 2991.564 1612011992.4993188
train: epoch 51, iter 1200, loss: 2.923794, top_1: 0.520977, top_k: 0.757539, samples/s: 2979.295 1612012001.091962
train: epoch 51, iter 1300, loss: 3.279658, top_1: 0.511289, top_k: 0.748203, samples/s: 2965.759 1612012009.7238123
train: epoch 51, iter 1400, loss: 3.197340, top_1: 0.516211, top_k: 0.749648, samples/s: 2936.262 1612012018.4425032
train: epoch 51, iter 1500, loss: 3.199150, top_1: 0.523750, top_k: 0.754453, samples/s: 2987.853 1612012027.0104218
train: epoch 51, iter 1600, loss: 2.881172, top_1: 0.511055, top_k: 0.742852, samples/s: 2986.285 1612012035.582973
train: epoch 51, iter 1700, loss: 3.049198, top_1: 0.517188, top_k: 0.747578, samples/s: 2893.839 1612012044.4293597
train: epoch 51, iter 1800, loss: 2.910414, top_1: 0.513086, top_k: 0.750391, samples/s: 2947.987 1612012053.113207
train: epoch 51, iter 1900, loss: 3.160378, top_1: 0.507344, top_k: 0.743828, samples/s: 2976.664 1612012061.7134347
train: epoch 51, iter 2000, loss: 3.079054, top_1: 0.513164, top_k: 0.752383, samples/s: 2953.696 1612012070.3806186
train: epoch 51, iter 2100, loss: 3.212618, top_1: 0.512695, top_k: 0.749414, samples/s: 2950.688 1612012079.0565338
train: epoch 51, iter 2200, loss: 2.885046, top_1: 0.519883, top_k: 0.751680, samples/s: 2997.597 1612012087.5967603
train: epoch 51, iter 2300, loss: 2.779273, top_1: 0.522852, top_k: 0.755664, samples/s: 2944.437 1612012096.2910664
train: epoch 51, iter 2400, loss: 3.103895, top_1: 0.509375, top_k: 0.747188, samples/s: 2952.770 1612012104.9608934
train: epoch 51, iter 2500, loss: 2.954535, top_1: 0.512969, top_k: 0.747227, samples/s: 2846.275 1612012113.955066
train: epoch 51, iter 2600, loss: 2.924449, top_1: 0.509023, top_k: 0.748125, samples/s: 2964.723 1612012122.5899348
train: epoch 51, iter 2700, loss: 3.257828, top_1: 0.511719, top_k: 0.744609, samples/s: 2966.285 1612012131.2202566
train: epoch 51, iter 2800, loss: 3.035427, top_1: 0.503281, top_k: 0.743008, samples/s: 2933.195 1612012139.9480808
train: epoch 51, iter 2900, loss: 3.019241, top_1: 0.512930, top_k: 0.747812, samples/s: 3006.691 1612012148.462471
train: epoch 51, iter 3000, loss: 2.950186, top_1: 0.508437, top_k: 0.745703, samples/s: 2976.641 1612012157.0626154
train: epoch 51, iter 3100, loss: 2.963618, top_1: 0.504141, top_k: 0.743320, samples/s: 2994.898 1612012165.6104472
train: epoch 51, iter 3200, loss: 3.046489, top_1: 0.511914, top_k: 0.747070, samples/s: 2992.934 1612012174.163985
train: epoch 51, iter 3300, loss: 3.213801, top_1: 0.507734, top_k: 0.746875, samples/s: 2866.364 1612012183.0952501
train: epoch 51, iter 3400, loss: 2.963246, top_1: 0.512109, top_k: 0.749883, samples/s: 2906.004 1612012191.9044454
train: epoch 51, iter 3500, loss: 3.098167, top_1: 0.517109, top_k: 0.750156, samples/s: 3001.418 1612012200.4337645
train: epoch 51, iter 3600, loss: 3.145198, top_1: 0.514922, top_k: 0.747461, samples/s: 2961.697 1612012209.077457
train: epoch 51, iter 3700, loss: 2.859731, top_1: 0.512578, top_k: 0.747109, samples/s: 2966.404 1612012217.7074404
train: epoch 51, iter 3800, loss: 2.860637, top_1: 0.507930, top_k: 0.750313, samples/s: 2998.511 1612012226.2450209
train: epoch 51, iter 3900, loss: 2.943023, top_1: 0.513242, top_k: 0.747461, samples/s: 2965.697 1612012234.8771293
train: epoch 51, iter 4000, loss: 3.061113, top_1: 0.517422, top_k: 0.752617, samples/s: 2904.180 1612012243.6919317
train: epoch 51, iter 4100, loss: 3.352852, top_1: 0.508984, top_k: 0.747305, samples/s: 2991.806 1612012252.2490902
train: epoch 51, iter 4200, loss: 3.129867, top_1: 0.510547, top_k: 0.747070, samples/s: 2965.927 1612012260.8799934
train: epoch 51, iter 4300, loss: 3.076895, top_1: 0.512344, top_k: 0.747031, samples/s: 2980.122 1612012269.4707098
train: epoch 51, iter 4400, loss: 2.990117, top_1: 0.502227, top_k: 0.746094, samples/s: 2990.314 1612012278.0312226
train: epoch 51, iter 4500, loss: 2.974931, top_1: 0.513125, top_k: 0.747344, samples/s: 2984.711 1612012286.6082847
train: epoch 51, iter 4600, loss: 3.012670, top_1: 0.511367, top_k: 0.747852, samples/s: 2991.759 1612012295.1652858
train: epoch 51, iter 4700, loss: 3.208964, top_1: 0.513477, top_k: 0.746953, samples/s: 2988.314 1612012303.731872
train: epoch 51, iter 4800, loss: 3.012626, top_1: 0.512578, top_k: 0.750039, samples/s: 2964.277 1612012312.3680308
train: epoch 51, iter 4900, loss: 2.919505, top_1: 0.512422, top_k: 0.747891, samples/s: 2970.003 1612012320.9875817
train: epoch 51, iter 5000, loss: 3.057230, top_1: 0.513398, top_k: 0.751094, samples/s: 2987.220 1612012329.5573614
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_51.
validation: epoch 51, iter 195, top_1: 0.534816, top_k: 0.781831, samples/s: 2949.306 1612012346.739621
train: epoch 52, iter 100, loss: 3.073688, top_1: 0.516172, top_k: 0.753164, samples/s: 2973.703 1612012371.2269218
train: epoch 52, iter 200, loss: 3.116008, top_1: 0.520312, top_k: 0.751914, samples/s: 3001.612 1612012379.755686
train: epoch 52, iter 300, loss: 3.050574, top_1: 0.524219, top_k: 0.755078, samples/s: 3007.338 1612012388.268269
train: epoch 52, iter 400, loss: 3.220795, top_1: 0.521563, top_k: 0.757031, samples/s: 2980.507 1612012396.8573675
train: epoch 52, iter 500, loss: 3.108849, top_1: 0.518047, top_k: 0.748945, samples/s: 2960.751 1612012405.5037954
train: epoch 52, iter 600, loss: 3.115491, top_1: 0.514648, top_k: 0.751836, samples/s: 3024.865 1612012413.9669466
train: epoch 52, iter 700, loss: 2.962039, top_1: 0.515547, top_k: 0.757969, samples/s: 2977.736 1612012422.5641325
train: epoch 52, iter 800, loss: 3.033641, top_1: 0.524375, top_k: 0.759336, samples/s: 2956.509 1612012431.2231402
train: epoch 52, iter 900, loss: 3.172656, top_1: 0.516328, top_k: 0.753008, samples/s: 3001.149 1612012439.7530413
train: epoch 52, iter 1000, loss: 2.950378, top_1: 0.515078, top_k: 0.752148, samples/s: 2873.033 1612012448.663498
train: epoch 52, iter 1100, loss: 3.064376, top_1: 0.512969, top_k: 0.748906, samples/s: 2987.834 1612012457.2316136
train: epoch 52, iter 1200, loss: 3.084612, top_1: 0.522383, top_k: 0.753281, samples/s: 2984.314 1612012465.8097336
train: epoch 52, iter 1300, loss: 2.963036, top_1: 0.519922, top_k: 0.750938, samples/s: 2975.437 1612012474.4135745
train: epoch 52, iter 1400, loss: 3.002315, top_1: 0.520352, top_k: 0.755391, samples/s: 2936.458 1612012483.1320891
train: epoch 52, iter 1500, loss: 3.064279, top_1: 0.507148, top_k: 0.746055, samples/s: 2968.710 1612012491.7548506
train: epoch 52, iter 1600, loss: 2.932148, top_1: 0.517383, top_k: 0.751602, samples/s: 2934.631 1612012500.478566
train: epoch 52, iter 1700, loss: 3.243692, top_1: 0.512227, top_k: 0.744141, samples/s: 3015.802 1612012508.9668214
train: epoch 52, iter 1800, loss: 2.992612, top_1: 0.512656, top_k: 0.753125, samples/s: 2943.493 1612012517.663994
train: epoch 52, iter 1900, loss: 2.995609, top_1: 0.516797, top_k: 0.751875, samples/s: 2932.130 1612012526.394839
train: epoch 52, iter 2000, loss: 2.924167, top_1: 0.511445, top_k: 0.745273, samples/s: 2989.845 1612012534.9571917
train: epoch 52, iter 2100, loss: 2.947407, top_1: 0.514766, top_k: 0.752891, samples/s: 2954.678 1612012543.6213777
train: epoch 52, iter 2200, loss: 3.106733, top_1: 0.516094, top_k: 0.751055, samples/s: 2936.259 1612012552.339978
train: epoch 52, iter 2300, loss: 3.041331, top_1: 0.510625, top_k: 0.749844, samples/s: 2939.434 1612012561.049146
train: epoch 52, iter 2400, loss: 3.094770, top_1: 0.514023, top_k: 0.746953, samples/s: 2907.479 1612012569.8539858
train: epoch 52, iter 2500, loss: 3.069853, top_1: 0.513047, top_k: 0.744570, samples/s: 2971.521 1612012578.4690962
train: epoch 52, iter 2600, loss: 2.943956, top_1: 0.515078, top_k: 0.751289, samples/s: 2968.318 1612012587.0935485
train: epoch 52, iter 2700, loss: 2.973841, top_1: 0.515078, top_k: 0.751641, samples/s: 2940.131 1612012595.8006608
train: epoch 52, iter 2800, loss: 3.088460, top_1: 0.514727, top_k: 0.747695, samples/s: 2878.851 1612012604.6930788
train: epoch 52, iter 2900, loss: 3.090961, top_1: 0.507695, top_k: 0.744023, samples/s: 2969.542 1612012613.3139033
train: epoch 52, iter 3000, loss: 3.038420, top_1: 0.519883, top_k: 0.753594, samples/s: 2913.925 1612012622.0993655
train: epoch 52, iter 3100, loss: 2.850173, top_1: 0.514375, top_k: 0.748750, samples/s: 2959.304 1612012630.749941
train: epoch 52, iter 3200, loss: 2.987068, top_1: 0.510703, top_k: 0.747266, samples/s: 2944.653 1612012639.4437582
train: epoch 52, iter 3300, loss: 2.982488, top_1: 0.514766, top_k: 0.749453, samples/s: 2957.903 1612012648.0984905
train: epoch 52, iter 3400, loss: 3.142885, top_1: 0.513594, top_k: 0.750547, samples/s: 2966.389 1612012656.728516
train: epoch 52, iter 3500, loss: 3.078626, top_1: 0.515195, top_k: 0.748711, samples/s: 2884.734 1612012665.6028464
train: epoch 52, iter 3600, loss: 3.036984, top_1: 0.516563, top_k: 0.749570, samples/s: 2947.945 1612012674.2869382
train: epoch 52, iter 3700, loss: 2.908621, top_1: 0.510977, top_k: 0.747969, samples/s: 2996.126 1612012682.8312125
train: epoch 52, iter 3800, loss: 3.184886, top_1: 0.514297, top_k: 0.750273, samples/s: 2972.994 1612012691.4419923
train: epoch 52, iter 3900, loss: 3.243886, top_1: 0.517891, top_k: 0.750820, samples/s: 2954.480 1612012700.1068552
train: epoch 52, iter 4000, loss: 2.890769, top_1: 0.515898, top_k: 0.749766, samples/s: 2935.058 1612012708.8290207
train: epoch 52, iter 4100, loss: 3.174802, top_1: 0.507539, top_k: 0.750078, samples/s: 3003.558 1612012717.3527582
train: epoch 52, iter 4200, loss: 3.098139, top_1: 0.511250, top_k: 0.750703, samples/s: 2917.450 1612012726.1271305
train: epoch 52, iter 4300, loss: 2.820696, top_1: 0.514805, top_k: 0.748672, samples/s: 2977.583 1612012734.7246132
train: epoch 52, iter 4400, loss: 3.028177, top_1: 0.517930, top_k: 0.746680, samples/s: 2991.861 1612012743.2815936
train: epoch 52, iter 4500, loss: 3.087747, top_1: 0.508945, top_k: 0.743672, samples/s: 2929.114 1612012752.020971
train: epoch 52, iter 4600, loss: 3.335430, top_1: 0.512969, top_k: 0.749492, samples/s: 2930.026 1612012760.7581878
train: epoch 52, iter 4700, loss: 2.919108, top_1: 0.510977, top_k: 0.750430, samples/s: 2984.636 1612012769.335357
train: epoch 52, iter 4800, loss: 2.997267, top_1: 0.509141, top_k: 0.744609, samples/s: 2991.815 1612012777.8921056
train: epoch 52, iter 4900, loss: 2.989338, top_1: 0.507852, top_k: 0.744219, samples/s: 2989.716 1612012786.4547174
train: epoch 52, iter 5000, loss: 3.002156, top_1: 0.518477, top_k: 0.754961, samples/s: 2948.097 1612012795.138423
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_52.
validation: epoch 52, iter 195, top_1: 0.552624, top_k: 0.797476, samples/s: 2902.518 1612012812.5826457
train: epoch 53, iter 100, loss: 3.333354, top_1: 0.520586, top_k: 0.757305, samples/s: 2969.527 1612012837.1554797
train: epoch 53, iter 200, loss: 2.999630, top_1: 0.524609, top_k: 0.759570, samples/s: 2987.566 1612012845.7242563
train: epoch 53, iter 300, loss: 2.953579, top_1: 0.519141, top_k: 0.757695, samples/s: 2974.261 1612012854.3315043
train: epoch 53, iter 400, loss: 3.012978, top_1: 0.515898, top_k: 0.753242, samples/s: 3010.881 1612012862.834105
train: epoch 53, iter 500, loss: 3.026533, top_1: 0.515625, top_k: 0.753086, samples/s: 2946.906 1612012871.5211046
train: epoch 53, iter 600, loss: 3.229367, top_1: 0.516016, top_k: 0.753281, samples/s: 2960.772 1612012880.1674552
train: epoch 53, iter 700, loss: 3.131773, top_1: 0.526992, top_k: 0.758320, samples/s: 2960.234 1612012888.8154173
train: epoch 53, iter 800, loss: 3.175937, top_1: 0.517930, top_k: 0.751914, samples/s: 3005.390 1612012897.3335292
train: epoch 53, iter 900, loss: 3.122412, top_1: 0.522344, top_k: 0.755938, samples/s: 2974.005 1612012905.9413805
train: epoch 53, iter 1000, loss: 2.983588, top_1: 0.515625, top_k: 0.750234, samples/s: 3029.096 1612012914.3927073
train: epoch 53, iter 1100, loss: 2.871146, top_1: 0.520781, top_k: 0.755859, samples/s: 3014.068 1612012922.886284
train: epoch 53, iter 1200, loss: 2.960256, top_1: 0.520586, top_k: 0.758320, samples/s: 2970.387 1612012931.5046475
train: epoch 53, iter 1300, loss: 3.282361, top_1: 0.515469, top_k: 0.753164, samples/s: 2983.146 1612012940.08624
train: epoch 53, iter 1400, loss: 2.957384, top_1: 0.514687, top_k: 0.749102, samples/s: 2988.254 1612012948.6530504
train: epoch 53, iter 1500, loss: 3.188140, top_1: 0.510625, top_k: 0.750820, samples/s: 2909.995 1612012957.450331
train: epoch 53, iter 1600, loss: 3.046877, top_1: 0.519961, top_k: 0.751523, samples/s: 2995.130 1612012965.997586
train: epoch 53, iter 1700, loss: 3.130253, top_1: 0.515195, top_k: 0.754961, samples/s: 2972.548 1612012974.609694
train: epoch 53, iter 1800, loss: 3.158524, top_1: 0.513711, top_k: 0.750547, samples/s: 2974.234 1612012983.2169394
train: epoch 53, iter 1900, loss: 3.118943, top_1: 0.520117, top_k: 0.753906, samples/s: 2934.283 1612012991.9413898
train: epoch 53, iter 2000, loss: 3.117107, top_1: 0.517539, top_k: 0.751914, samples/s: 2915.709 1612013000.7214665
train: epoch 53, iter 2100, loss: 3.060333, top_1: 0.520039, top_k: 0.748437, samples/s: 2968.281 1612013009.3459666
train: epoch 53, iter 2200, loss: 2.839130, top_1: 0.519961, top_k: 0.753711, samples/s: 3015.544 1612013017.835312
train: epoch 53, iter 2300, loss: 3.003820, top_1: 0.513594, top_k: 0.751484, samples/s: 2914.119 1612013026.6201031
train: epoch 53, iter 2400, loss: 2.899935, top_1: 0.519531, top_k: 0.752070, samples/s: 2916.534 1612013035.3976364
train: epoch 53, iter 2500, loss: 3.052670, top_1: 0.515508, top_k: 0.747383, samples/s: 2971.701 1612013044.0121925
train: epoch 53, iter 2600, loss: 3.121001, top_1: 0.515781, top_k: 0.750000, samples/s: 2893.277 1612013052.8604648
train: epoch 53, iter 2700, loss: 3.024343, top_1: 0.516992, top_k: 0.749570, samples/s: 2962.250 1612013061.5024037
train: epoch 53, iter 2800, loss: 2.821997, top_1: 0.513125, top_k: 0.746758, samples/s: 2944.425 1612013070.1967993
train: epoch 53, iter 2900, loss: 3.060468, top_1: 0.513711, top_k: 0.749922, samples/s: 2911.890 1612013078.9883575
train: epoch 53, iter 3000, loss: 3.026436, top_1: 0.513437, top_k: 0.748437, samples/s: 2922.640 1612013087.7476172
train: epoch 53, iter 3100, loss: 3.124856, top_1: 0.517695, top_k: 0.752500, samples/s: 2964.221 1612013096.3839035
train: epoch 53, iter 3200, loss: 3.199466, top_1: 0.515078, top_k: 0.749922, samples/s: 2944.496 1612013105.078111
train: epoch 53, iter 3300, loss: 3.037683, top_1: 0.517695, top_k: 0.751953, samples/s: 2991.513 1612013113.6356428
train: epoch 53, iter 3400, loss: 3.035000, top_1: 0.514141, top_k: 0.746563, samples/s: 2935.459 1612013122.3565688
train: epoch 53, iter 3500, loss: 3.204677, top_1: 0.514648, top_k: 0.750469, samples/s: 2980.079 1612013130.9471478
train: epoch 53, iter 3600, loss: 3.440547, top_1: 0.513711, top_k: 0.745781, samples/s: 2918.109 1612013139.7197528
train: epoch 53, iter 3700, loss: 3.356945, top_1: 0.515234, top_k: 0.750391, samples/s: 2917.510 1612013148.4943595
train: epoch 53, iter 3800, loss: 3.060356, top_1: 0.511133, top_k: 0.751055, samples/s: 2969.412 1612013157.1155574
train: epoch 53, iter 3900, loss: 3.208057, top_1: 0.512500, top_k: 0.750195, samples/s: 2989.830 1612013165.6779776
train: epoch 53, iter 4000, loss: 3.070310, top_1: 0.513281, top_k: 0.747578, samples/s: 2955.862 1612013174.3387249
train: epoch 53, iter 4100, loss: 2.997860, top_1: 0.512148, top_k: 0.746953, samples/s: 2946.076 1612013183.0282886
train: epoch 53, iter 4200, loss: 2.994452, top_1: 0.511680, top_k: 0.748398, samples/s: 2947.004 1612013191.71502
train: epoch 53, iter 4300, loss: 3.170966, top_1: 0.515898, top_k: 0.752422, samples/s: 2958.381 1612013200.3684597
train: epoch 53, iter 4400, loss: 3.069899, top_1: 0.511523, top_k: 0.748281, samples/s: 2953.623 1612013209.035792
train: epoch 53, iter 4500, loss: 3.000993, top_1: 0.515859, top_k: 0.754023, samples/s: 2955.024 1612013217.6989276
train: epoch 53, iter 4600, loss: 3.052041, top_1: 0.511602, top_k: 0.749883, samples/s: 2918.356 1612013226.4710982
train: epoch 53, iter 4700, loss: 2.754296, top_1: 0.509844, top_k: 0.741680, samples/s: 2984.330 1612013235.049196
train: epoch 53, iter 4800, loss: 3.040491, top_1: 0.516875, top_k: 0.750586, samples/s: 2955.460 1612013243.7110877
train: epoch 53, iter 4900, loss: 3.217044, top_1: 0.511758, top_k: 0.747734, samples/s: 2959.037 1612013252.362522
train: epoch 53, iter 5000, loss: 2.882612, top_1: 0.515586, top_k: 0.750352, samples/s: 2981.118 1612013260.9498951
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_53.
validation: epoch 53, iter 195, top_1: 0.562119, top_k: 0.802764, samples/s: 3018.217 1612013277.7274444
train: epoch 54, iter 100, loss: 2.917215, top_1: 0.534180, top_k: 0.762109, samples/s: 2946.067 1612013303.1106687
train: epoch 54, iter 200, loss: 2.970607, top_1: 0.528164, top_k: 0.763867, samples/s: 2935.246 1612013311.8323832
train: epoch 54, iter 300, loss: 3.011559, top_1: 0.517813, top_k: 0.751797, samples/s: 3031.046 1612013320.278155
train: epoch 54, iter 400, loss: 2.903296, top_1: 0.518047, top_k: 0.756133, samples/s: 2992.549 1612013328.8327181
train: epoch 54, iter 500, loss: 3.034717, top_1: 0.518164, top_k: 0.755234, samples/s: 2983.226 1612013337.4140513
train: epoch 54, iter 600, loss: 3.086157, top_1: 0.524570, top_k: 0.760117, samples/s: 2966.127 1612013346.0448306
train: epoch 54, iter 700, loss: 2.856458, top_1: 0.524336, top_k: 0.753516, samples/s: 2971.623 1612013354.6596236
train: epoch 54, iter 800, loss: 3.066799, top_1: 0.514687, top_k: 0.749609, samples/s: 2976.719 1612013363.2599266
train: epoch 54, iter 900, loss: 3.004837, top_1: 0.522930, top_k: 0.754922, samples/s: 2978.950 1612013371.8535657
train: epoch 54, iter 1000, loss: 2.900521, top_1: 0.520234, top_k: 0.752812, samples/s: 2809.807 1612013380.9642417
train: epoch 54, iter 1100, loss: 2.958381, top_1: 0.520469, top_k: 0.753750, samples/s: 2940.136 1612013389.6713617
train: epoch 54, iter 1200, loss: 3.060908, top_1: 0.516953, top_k: 0.750547, samples/s: 3031.620 1612013398.1157
train: epoch 54, iter 1300, loss: 3.125885, top_1: 0.513828, top_k: 0.751328, samples/s: 3009.024 1612013406.6234524
train: epoch 54, iter 1400, loss: 2.947621, top_1: 0.517383, top_k: 0.754375, samples/s: 2969.050 1612013415.246091
train: epoch 54, iter 1500, loss: 3.191408, top_1: 0.520000, top_k: 0.753203, samples/s: 2979.457 1612013423.8378742
train: epoch 54, iter 1600, loss: 3.040527, top_1: 0.516328, top_k: 0.749883, samples/s: 2969.578 1612013432.458669
train: epoch 54, iter 1700, loss: 2.977430, top_1: 0.521016, top_k: 0.754414, samples/s: 3000.239 1612013440.9919405
train: epoch 54, iter 1800, loss: 2.947855, top_1: 0.513984, top_k: 0.749687, samples/s: 3004.295 1612013449.5124533
train: epoch 54, iter 1900, loss: 2.970892, top_1: 0.520938, top_k: 0.754883, samples/s: 2959.268 1612013458.163937
train: epoch 54, iter 2000, loss: 3.168900, top_1: 0.516641, top_k: 0.752539, samples/s: 3008.061 1612013466.6737356
train: epoch 54, iter 2100, loss: 3.015058, top_1: 0.525859, top_k: 0.756680, samples/s: 2974.513 1612013475.2802145
train: epoch 54, iter 2200, loss: 3.062685, top_1: 0.519375, top_k: 0.753906, samples/s: 2943.033 1612013483.9786704
train: epoch 54, iter 2300, loss: 3.052870, top_1: 0.511367, top_k: 0.747305, samples/s: 2918.574 1612013492.750053
train: epoch 54, iter 2400, loss: 3.109494, top_1: 0.513906, top_k: 0.751914, samples/s: 2992.471 1612013501.3056448
train: epoch 54, iter 2500, loss: 3.082831, top_1: 0.514648, top_k: 0.750859, samples/s: 2921.770 1612013510.066766
train: epoch 54, iter 2600, loss: 2.903848, top_1: 0.514141, top_k: 0.752734, samples/s: 2993.396 1612013518.6188223
train: epoch 54, iter 2700, loss: 3.014542, top_1: 0.516914, top_k: 0.751641, samples/s: 2941.992 1612013527.32043
train: epoch 54, iter 2800, loss: 3.126479, top_1: 0.518750, top_k: 0.753828, samples/s: 3009.253 1612013535.8275409
train: epoch 54, iter 2900, loss: 2.961558, top_1: 0.518789, top_k: 0.750547, samples/s: 2879.436 1612013544.718317
train: epoch 54, iter 3000, loss: 3.070323, top_1: 0.511094, top_k: 0.749102, samples/s: 2991.742 1612013553.2750194
train: epoch 54, iter 3100, loss: 3.274619, top_1: 0.511797, top_k: 0.748281, samples/s: 2983.450 1612013561.855766
train: epoch 54, iter 3200, loss: 3.246660, top_1: 0.515117, top_k: 0.748750, samples/s: 2889.204 1612013570.7162838
train: epoch 54, iter 3300, loss: 3.163887, top_1: 0.513633, top_k: 0.748711, samples/s: 2989.197 1612013579.2807455
train: epoch 54, iter 3400, loss: 2.812138, top_1: 0.520352, top_k: 0.753164, samples/s: 2956.986 1612013587.9378545
train: epoch 54, iter 3500, loss: 3.133178, top_1: 0.511641, top_k: 0.746602, samples/s: 3004.865 1612013596.4574265
train: epoch 54, iter 3600, loss: 3.054072, top_1: 0.518789, top_k: 0.747344, samples/s: 2978.976 1612013605.0514207
train: epoch 54, iter 3700, loss: 2.834916, top_1: 0.513867, top_k: 0.747734, samples/s: 2944.827 1612013613.7442985
train: epoch 54, iter 3800, loss: 3.003845, top_1: 0.517930, top_k: 0.757422, samples/s: 3007.788 1612013622.2556396
train: epoch 54, iter 3900, loss: 2.938647, top_1: 0.516172, top_k: 0.752969, samples/s: 2991.848 1612013630.812059
train: epoch 54, iter 4000, loss: 3.181800, top_1: 0.518789, top_k: 0.751563, samples/s: 2902.465 1612013639.6321733
train: epoch 54, iter 4100, loss: 3.174845, top_1: 0.510508, top_k: 0.748359, samples/s: 2990.512 1612013648.1925492
train: epoch 54, iter 4200, loss: 3.067494, top_1: 0.506563, top_k: 0.749375, samples/s: 2942.411 1612013656.8928924
train: epoch 54, iter 4300, loss: 3.050697, top_1: 0.518398, top_k: 0.751406, samples/s: 2996.971 1612013665.4348154
train: epoch 54, iter 4400, loss: 3.231626, top_1: 0.514883, top_k: 0.748867, samples/s: 2990.688 1612013673.9947062
train: epoch 54, iter 4500, loss: 2.977668, top_1: 0.516914, top_k: 0.752656, samples/s: 3011.400 1612013682.4957814
train: epoch 54, iter 4600, loss: 3.001365, top_1: 0.519766, top_k: 0.751836, samples/s: 2886.568 1612013691.3645158
train: epoch 54, iter 4700, loss: 3.239420, top_1: 0.512383, top_k: 0.747383, samples/s: 2966.485 1612013699.9941807
train: epoch 54, iter 4800, loss: 3.258696, top_1: 0.514727, top_k: 0.748828, samples/s: 2995.206 1612013708.5411427
train: epoch 54, iter 4900, loss: 3.054884, top_1: 0.514844, top_k: 0.748867, samples/s: 2995.610 1612013717.087045
train: epoch 54, iter 5000, loss: 3.255380, top_1: 0.516641, top_k: 0.747539, samples/s: 2974.013 1612013725.694838
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_54.
validation: epoch 54, iter 195, top_1: 0.561498, top_k: 0.803205, samples/s: 2928.224 1612013742.9734454
train: epoch 55, iter 100, loss: 2.912745, top_1: 0.522227, top_k: 0.754219, samples/s: 2898.577 1612013767.5203404
train: epoch 55, iter 200, loss: 2.939542, top_1: 0.523164, top_k: 0.758242, samples/s: 2999.813 1612013776.0543487
train: epoch 55, iter 300, loss: 3.071203, top_1: 0.520938, top_k: 0.753320, samples/s: 3019.726 1612013784.5317912
train: epoch 55, iter 400, loss: 3.158475, top_1: 0.518047, top_k: 0.751680, samples/s: 2982.107 1612013793.1163797
train: epoch 55, iter 500, loss: 2.948582, top_1: 0.525781, top_k: 0.755820, samples/s: 2915.746 1612013801.896301
train: epoch 55, iter 600, loss: 2.877772, top_1: 0.531406, top_k: 0.761523, samples/s: 2999.231 1612013810.4317586
train: epoch 55, iter 700, loss: 2.936752, top_1: 0.524844, top_k: 0.758008, samples/s: 3000.070 1612013818.964825
train: epoch 55, iter 800, loss: 3.154804, top_1: 0.522266, top_k: 0.755352, samples/s: 2956.425 1612013827.623933
train: epoch 55, iter 900, loss: 3.149544, top_1: 0.514492, top_k: 0.755859, samples/s: 2994.017 1612013836.1743705
train: epoch 55, iter 1000, loss: 2.879411, top_1: 0.519961, top_k: 0.759727, samples/s: 2945.878 1612013844.8644702
train: epoch 55, iter 1100, loss: 2.936390, top_1: 0.518477, top_k: 0.753047, samples/s: 3008.406 1612013853.3739326
train: epoch 55, iter 1200, loss: 2.828956, top_1: 0.521797, top_k: 0.757070, samples/s: 2944.098 1612013862.0693414
train: epoch 55, iter 1300, loss: 2.849106, top_1: 0.515312, top_k: 0.753281, samples/s: 3011.765 1612013870.569331
train: epoch 55, iter 1400, loss: 2.942750, top_1: 0.516055, top_k: 0.754453, samples/s: 2955.028 1612013879.2325277
train: epoch 55, iter 1500, loss: 2.966603, top_1: 0.516094, top_k: 0.752695, samples/s: 2979.789 1612013887.8237402
train: epoch 55, iter 1600, loss: 2.886785, top_1: 0.520312, top_k: 0.753867, samples/s: 2986.144 1612013896.3966475
train: epoch 55, iter 1700, loss: 2.993296, top_1: 0.516563, top_k: 0.755742, samples/s: 2935.329 1612013905.1180549
train: epoch 55, iter 1800, loss: 3.002963, top_1: 0.516680, top_k: 0.749414, samples/s: 2994.978 1612013913.66568
train: epoch 55, iter 1900, loss: 3.110551, top_1: 0.516289, top_k: 0.754297, samples/s: 2903.854 1612013922.4816105
train: epoch 55, iter 2000, loss: 2.899498, top_1: 0.518398, top_k: 0.757070, samples/s: 2990.669 1612013931.0415308
train: epoch 55, iter 2100, loss: 2.978569, top_1: 0.517188, top_k: 0.753555, samples/s: 2976.018 1612013939.6435752
train: epoch 55, iter 2200, loss: 2.970722, top_1: 0.517422, top_k: 0.756211, samples/s: 2972.209 1612013948.2566888
train: epoch 55, iter 2300, loss: 3.270911, top_1: 0.517656, top_k: 0.753867, samples/s: 2985.229 1612013956.8323212
train: epoch 55, iter 2400, loss: 2.981071, top_1: 0.516797, top_k: 0.751602, samples/s: 3007.908 1612013965.343206
train: epoch 55, iter 2500, loss: 2.836638, top_1: 0.516719, top_k: 0.754336, samples/s: 2985.765 1612013973.9172375
train: epoch 55, iter 2600, loss: 3.095546, top_1: 0.516367, top_k: 0.750625, samples/s: 2948.917 1612013982.5983849
train: epoch 55, iter 2700, loss: 3.086415, top_1: 0.516211, top_k: 0.752930, samples/s: 3028.878 1612013991.050314
train: epoch 55, iter 2800, loss: 3.099110, top_1: 0.519062, top_k: 0.751836, samples/s: 2962.936 1612013999.690363
train: epoch 55, iter 2900, loss: 2.972340, top_1: 0.515547, top_k: 0.748242, samples/s: 2985.150 1612014008.266246
train: epoch 55, iter 3000, loss: 2.873176, top_1: 0.519336, top_k: 0.754453, samples/s: 3003.561 1612014016.7894497
train: epoch 55, iter 3100, loss: 2.995585, top_1: 0.514922, top_k: 0.751836, samples/s: 2969.676 1612014025.4098678
train: epoch 55, iter 3200, loss: 2.959964, top_1: 0.518750, top_k: 0.751953, samples/s: 2959.588 1612014034.0597696
train: epoch 55, iter 3300, loss: 3.156307, top_1: 0.518125, top_k: 0.749336, samples/s: 2958.617 1612014042.7124166
train: epoch 55, iter 3400, loss: 2.951180, top_1: 0.518789, top_k: 0.750391, samples/s: 2919.477 1612014051.4811857
train: epoch 55, iter 3500, loss: 2.950802, top_1: 0.515820, top_k: 0.752305, samples/s: 2951.463 1612014060.1547704
train: epoch 55, iter 3600, loss: 3.122841, top_1: 0.519727, top_k: 0.754336, samples/s: 2951.037 1612014068.8298302
train: epoch 55, iter 3700, loss: 3.215407, top_1: 0.513281, top_k: 0.749883, samples/s: 2963.001 1612014077.469592
train: epoch 55, iter 3800, loss: 2.846661, top_1: 0.521016, top_k: 0.754492, samples/s: 2966.994 1612014086.0978968
train: epoch 55, iter 3900, loss: 3.084069, top_1: 0.513633, top_k: 0.750547, samples/s: 2955.682 1612014094.7591143
train: epoch 55, iter 4000, loss: 3.104749, top_1: 0.514648, top_k: 0.751133, samples/s: 2958.362 1612014103.4126365
train: epoch 55, iter 4100, loss: 3.121967, top_1: 0.512813, top_k: 0.748906, samples/s: 2998.489 1612014111.95028
train: epoch 55, iter 4200, loss: 2.977440, top_1: 0.521406, top_k: 0.752500, samples/s: 2995.068 1612014120.4975548
train: epoch 55, iter 4300, loss: 3.027798, top_1: 0.512891, top_k: 0.751328, samples/s: 2966.954 1612014129.1259315
train: epoch 55, iter 4400, loss: 3.301682, top_1: 0.516289, top_k: 0.749219, samples/s: 2992.640 1612014137.6802614
train: epoch 55, iter 4500, loss: 3.051528, top_1: 0.514336, top_k: 0.748477, samples/s: 2899.345 1612014146.5098395
train: epoch 55, iter 4600, loss: 2.992201, top_1: 0.519375, top_k: 0.752969, samples/s: 3024.540 1612014154.973938
train: epoch 55, iter 4700, loss: 3.152756, top_1: 0.514023, top_k: 0.750977, samples/s: 2997.331 1612014163.5148726
train: epoch 55, iter 4800, loss: 3.167778, top_1: 0.518242, top_k: 0.751211, samples/s: 2922.379 1612014172.2748423
train: epoch 55, iter 4900, loss: 3.126225, top_1: 0.511719, top_k: 0.750820, samples/s: 2972.911 1612014180.8859348
train: epoch 55, iter 5000, loss: 2.829399, top_1: 0.520625, top_k: 0.750469, samples/s: 3003.356 1612014189.4097936
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_55.
validation: epoch 55, iter 195, top_1: 0.551122, top_k: 0.794972, samples/s: 2951.083 1612014206.6250944
train: epoch 56, iter 100, loss: 3.146023, top_1: 0.530352, top_k: 0.764805, samples/s: 2941.848 1612014231.36869
train: epoch 56, iter 200, loss: 3.015998, top_1: 0.528672, top_k: 0.759883, samples/s: 2934.028 1612014240.093907
train: epoch 56, iter 300, loss: 2.941188, top_1: 0.522148, top_k: 0.756875, samples/s: 3016.249 1612014248.5812776
train: epoch 56, iter 400, loss: 2.815698, top_1: 0.530195, top_k: 0.763711, samples/s: 2972.889 1612014257.1924198
train: epoch 56, iter 500, loss: 2.921912, top_1: 0.525703, top_k: 0.761758, samples/s: 2962.419 1612014265.8340068
train: epoch 56, iter 600, loss: 2.896672, top_1: 0.528672, top_k: 0.762852, samples/s: 3018.934 1612014274.3138018
train: epoch 56, iter 700, loss: 3.129656, top_1: 0.526953, top_k: 0.761406, samples/s: 2954.089 1612014282.9797955
train: epoch 56, iter 800, loss: 3.066215, top_1: 0.518047, top_k: 0.752148, samples/s: 2991.451 1612014291.53761
train: epoch 56, iter 900, loss: 3.121746, top_1: 0.524766, top_k: 0.756758, samples/s: 2998.046 1612014300.0764196
train: epoch 56, iter 1000, loss: 3.095485, top_1: 0.523125, top_k: 0.752852, samples/s: 2913.159 1612014308.864092
train: epoch 56, iter 1100, loss: 2.869871, top_1: 0.527227, top_k: 0.758008, samples/s: 3019.520 1612014317.3422663
train: epoch 56, iter 1200, loss: 2.803387, top_1: 0.518398, top_k: 0.750703, samples/s: 3010.208 1612014325.8466542
train: epoch 56, iter 1300, loss: 2.905123, top_1: 0.530547, top_k: 0.762773, samples/s: 2922.696 1612014334.6056943
train: epoch 56, iter 1400, loss: 2.996949, top_1: 0.517227, top_k: 0.756953, samples/s: 2950.749 1612014343.2814476
train: epoch 56, iter 1500, loss: 2.937629, top_1: 0.518633, top_k: 0.756133, samples/s: 3009.292 1612014351.788516
train: epoch 56, iter 1600, loss: 3.088629, top_1: 0.524141, top_k: 0.754297, samples/s: 2974.817 1612014360.3940094
train: epoch 56, iter 1700, loss: 2.793835, top_1: 0.519883, top_k: 0.752578, samples/s: 2894.055 1612014369.2398381
train: epoch 56, iter 1800, loss: 2.822844, top_1: 0.514492, top_k: 0.753750, samples/s: 2854.593 1612014378.2079391
train: epoch 56, iter 1900, loss: 2.825426, top_1: 0.521680, top_k: 0.752070, samples/s: 2957.465 1612014386.8638003
train: epoch 56, iter 2000, loss: 3.050755, top_1: 0.514883, top_k: 0.752461, samples/s: 2934.970 1612014395.5862026
train: epoch 56, iter 2100, loss: 3.008188, top_1: 0.518672, top_k: 0.749766, samples/s: 2941.211 1612014404.2901387
train: epoch 56, iter 2200, loss: 2.956475, top_1: 0.511953, top_k: 0.749883, samples/s: 2977.194 1612014412.8888607
train: epoch 56, iter 2300, loss: 2.950278, top_1: 0.515625, top_k: 0.753477, samples/s: 2942.101 1612014421.5900755
train: epoch 56, iter 2400, loss: 3.138654, top_1: 0.515391, top_k: 0.757578, samples/s: 2975.645 1612014430.1932414
train: epoch 56, iter 2500, loss: 2.872385, top_1: 0.514922, top_k: 0.749883, samples/s: 2968.556 1612014438.8170245
train: epoch 56, iter 2600, loss: 2.953785, top_1: 0.514375, top_k: 0.750664, samples/s: 2961.443 1612014447.4614038
train: epoch 56, iter 2700, loss: 3.101864, top_1: 0.519180, top_k: 0.754648, samples/s: 2969.345 1612014456.0828466
train: epoch 56, iter 2800, loss: 2.895586, top_1: 0.518633, top_k: 0.756328, samples/s: 2952.386 1612014464.7537892
train: epoch 56, iter 2900, loss: 3.098542, top_1: 0.518555, top_k: 0.753672, samples/s: 2972.824 1612014473.3651443
train: epoch 56, iter 3000, loss: 2.905614, top_1: 0.515781, top_k: 0.747227, samples/s: 2937.576 1612014482.079739
train: epoch 56, iter 3100, loss: 3.021900, top_1: 0.518320, top_k: 0.750156, samples/s: 2906.465 1612014490.8878126
train: epoch 56, iter 3200, loss: 3.194446, top_1: 0.518320, top_k: 0.751445, samples/s: 2985.541 1612014499.46241
train: epoch 56, iter 3300, loss: 2.963566, top_1: 0.516133, top_k: 0.754922, samples/s: 2967.612 1612014508.08893
train: epoch 56, iter 3400, loss: 2.880019, top_1: 0.520352, top_k: 0.750391, samples/s: 2912.723 1612014516.877899
train: epoch 56, iter 3500, loss: 2.983885, top_1: 0.523398, top_k: 0.758164, samples/s: 2951.422 1612014525.5516837
train: epoch 56, iter 3600, loss: 2.959049, top_1: 0.522813, top_k: 0.754922, samples/s: 2953.714 1612014534.21881
train: epoch 56, iter 3700, loss: 2.886856, top_1: 0.515195, top_k: 0.748945, samples/s: 2983.908 1612014542.798094
train: epoch 56, iter 3800, loss: 3.102543, top_1: 0.517930, top_k: 0.753945, samples/s: 2927.511 1612014551.5427427
train: epoch 56, iter 3900, loss: 2.899220, top_1: 0.514727, top_k: 0.757891, samples/s: 2937.613 1612014560.2572253
train: epoch 56, iter 4000, loss: 2.967573, top_1: 0.517734, top_k: 0.752617, samples/s: 2957.533 1612014568.9131355
train: epoch 56, iter 4100, loss: 3.087643, top_1: 0.513359, top_k: 0.749883, samples/s: 2930.806 1612014577.648003
train: epoch 56, iter 4200, loss: 2.883759, top_1: 0.523672, top_k: 0.757812, samples/s: 2974.719 1612014586.2537904
train: epoch 56, iter 4300, loss: 2.952101, top_1: 0.518047, top_k: 0.755547, samples/s: 2960.546 1612014594.9009087
train: epoch 56, iter 4400, loss: 2.775083, top_1: 0.522266, top_k: 0.755664, samples/s: 2979.031 1612014603.4942517
train: epoch 56, iter 4500, loss: 3.081962, top_1: 0.515820, top_k: 0.754531, samples/s: 2987.622 1612014612.0629246
train: epoch 56, iter 4600, loss: 3.125899, top_1: 0.522070, top_k: 0.755078, samples/s: 2948.681 1612014620.7447445
train: epoch 56, iter 4700, loss: 2.897020, top_1: 0.517031, top_k: 0.754922, samples/s: 3006.855 1612014629.2587197
train: epoch 56, iter 4800, loss: 3.091458, top_1: 0.513594, top_k: 0.750039, samples/s: 2950.646 1612014637.9348395
train: epoch 56, iter 4900, loss: 3.036346, top_1: 0.515703, top_k: 0.751680, samples/s: 2960.862 1612014646.5809562
train: epoch 56, iter 5000, loss: 3.106536, top_1: 0.516641, top_k: 0.756055, samples/s: 3004.991 1612014655.1000686
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_56.
validation: epoch 56, iter 195, top_1: 0.558534, top_k: 0.797857, samples/s: 2900.359 1612014672.535233
train: epoch 57, iter 100, loss: 2.971014, top_1: 0.525195, top_k: 0.759687, samples/s: 2838.298 1612014697.7995696
train: epoch 57, iter 200, loss: 3.012300, top_1: 0.528398, top_k: 0.762813, samples/s: 2992.371 1612014706.3547044
train: epoch 57, iter 300, loss: 2.993449, top_1: 0.523125, top_k: 0.755508, samples/s: 2940.606 1612014715.0603
train: epoch 57, iter 400, loss: 2.886037, top_1: 0.526484, top_k: 0.756016, samples/s: 2888.909 1612014723.9218082
train: epoch 57, iter 500, loss: 2.903207, top_1: 0.527070, top_k: 0.756914, samples/s: 3010.191 1612014732.4261963
train: epoch 57, iter 600, loss: 2.840403, top_1: 0.527891, top_k: 0.762031, samples/s: 3007.020 1612014740.9396136
train: epoch 57, iter 700, loss: 2.797717, top_1: 0.528086, top_k: 0.761680, samples/s: 2999.152 1612014749.4753492
train: epoch 57, iter 800, loss: 2.940978, top_1: 0.528672, top_k: 0.759141, samples/s: 2947.187 1612014758.1616204
train: epoch 57, iter 900, loss: 2.858509, top_1: 0.521523, top_k: 0.755117, samples/s: 2947.555 1612014766.846816
train: epoch 57, iter 1000, loss: 3.119331, top_1: 0.528555, top_k: 0.760508, samples/s: 2988.437 1612014775.4131439
train: epoch 57, iter 1100, loss: 3.052522, top_1: 0.515664, top_k: 0.752109, samples/s: 2996.074 1612014783.9576616
train: epoch 57, iter 1200, loss: 2.946143, top_1: 0.516602, top_k: 0.751992, samples/s: 2990.250 1612014792.5187905
train: epoch 57, iter 1300, loss: 2.999671, top_1: 0.519805, top_k: 0.757031, samples/s: 3001.890 1612014801.0468178
train: epoch 57, iter 1400, loss: 3.052948, top_1: 0.524883, top_k: 0.755547, samples/s: 2976.707 1612014809.6468678
train: epoch 57, iter 1500, loss: 3.184876, top_1: 0.523281, top_k: 0.757578, samples/s: 2934.144 1612014818.3717084
train: epoch 57, iter 1600, loss: 3.048172, top_1: 0.528359, top_k: 0.764414, samples/s: 2958.448 1612014827.024961
train: epoch 57, iter 1700, loss: 2.882957, top_1: 0.522695, top_k: 0.754883, samples/s: 2937.605 1612014835.739598
train: epoch 57, iter 1800, loss: 3.013387, top_1: 0.523594, top_k: 0.755625, samples/s: 2920.862 1612014844.5040798
train: epoch 57, iter 1900, loss: 2.950144, top_1: 0.524102, top_k: 0.755469, samples/s: 2865.424 1612014853.4382887
train: epoch 57, iter 2000, loss: 3.062916, top_1: 0.519453, top_k: 0.754102, samples/s: 2974.420 1612014862.0448477
train: epoch 57, iter 2100, loss: 3.218994, top_1: 0.516445, top_k: 0.752969, samples/s: 2961.105 1612014870.6902347
train: epoch 57, iter 2200, loss: 2.777630, top_1: 0.522383, top_k: 0.754141, samples/s: 2904.818 1612014879.5034065
train: epoch 57, iter 2300, loss: 3.115952, top_1: 0.515977, top_k: 0.754922, samples/s: 2967.185 1612014888.130912
train: epoch 57, iter 2400, loss: 2.707338, top_1: 0.524180, top_k: 0.759844, samples/s: 2979.070 1612014896.724213
train: epoch 57, iter 2500, loss: 2.833291, top_1: 0.519141, top_k: 0.753203, samples/s: 2959.749 1612014905.3735821
train: epoch 57, iter 2600, loss: 3.016569, top_1: 0.523047, top_k: 0.754570, samples/s: 2953.476 1612014914.0413322
train: epoch 57, iter 2700, loss: 2.838613, top_1: 0.523945, top_k: 0.757500, samples/s: 2955.802 1612014922.7022638
train: epoch 57, iter 2800, loss: 2.874356, top_1: 0.521836, top_k: 0.756602, samples/s: 2935.249 1612014931.4240012
train: epoch 57, iter 2900, loss: 2.955258, top_1: 0.521719, top_k: 0.752188, samples/s: 3025.284 1612014939.8859262
train: epoch 57, iter 3000, loss: 2.912761, top_1: 0.523906, top_k: 0.754062, samples/s: 2905.142 1612014948.6978166
train: epoch 57, iter 3100, loss: 3.053238, top_1: 0.517813, top_k: 0.751992, samples/s: 2966.266 1612014957.3282752
train: epoch 57, iter 3200, loss: 2.935491, top_1: 0.518086, top_k: 0.750000, samples/s: 2963.987 1612014965.9651546
train: epoch 57, iter 3300, loss: 3.212242, top_1: 0.518906, top_k: 0.751992, samples/s: 2980.830 1612014974.5534887
train: epoch 57, iter 3400, loss: 2.732767, top_1: 0.515742, top_k: 0.757383, samples/s: 3008.487 1612014983.062682
train: epoch 57, iter 3500, loss: 2.911358, top_1: 0.521055, top_k: 0.757852, samples/s: 2988.330 1612014991.6293423
train: epoch 57, iter 3600, loss: 3.071217, top_1: 0.521641, top_k: 0.755000, samples/s: 3001.609 1612015000.1580992
train: epoch 57, iter 3700, loss: 3.201736, top_1: 0.516719, top_k: 0.747070, samples/s: 3010.589 1612015008.6615007
train: epoch 57, iter 3800, loss: 2.857241, top_1: 0.516445, top_k: 0.755977, samples/s: 2991.101 1612015017.2201407
train: epoch 57, iter 3900, loss: 3.072819, top_1: 0.519922, top_k: 0.753711, samples/s: 2991.145 1612015025.7787325
train: epoch 57, iter 4000, loss: 2.999627, top_1: 0.517734, top_k: 0.751406, samples/s: 2988.046 1612015034.3462102
train: epoch 57, iter 4100, loss: 3.012386, top_1: 0.518906, top_k: 0.753125, samples/s: 2916.959 1612015043.122512
train: epoch 57, iter 4200, loss: 3.024732, top_1: 0.521367, top_k: 0.756563, samples/s: 2949.680 1612015051.8013756
train: epoch 57, iter 4300, loss: 3.111011, top_1: 0.513320, top_k: 0.751406, samples/s: 2936.834 1612015060.518242
train: epoch 57, iter 4400, loss: 2.986844, top_1: 0.521719, top_k: 0.756758, samples/s: 2987.806 1612015069.0863905
train: epoch 57, iter 4500, loss: 3.013063, top_1: 0.516523, top_k: 0.751289, samples/s: 3008.544 1612015077.5955591
train: epoch 57, iter 4600, loss: 3.300189, top_1: 0.519805, top_k: 0.753203, samples/s: 2847.906 1612015086.5846198
train: epoch 57, iter 4700, loss: 3.053549, top_1: 0.518945, top_k: 0.752695, samples/s: 2940.288 1612015095.2912545
train: epoch 57, iter 4800, loss: 2.943354, top_1: 0.524648, top_k: 0.757461, samples/s: 3015.211 1612015103.7815437
train: epoch 57, iter 4900, loss: 2.938711, top_1: 0.515039, top_k: 0.750547, samples/s: 2933.674 1612015112.507761
train: epoch 57, iter 5000, loss: 2.900883, top_1: 0.519102, top_k: 0.756992, samples/s: 2995.655 1612015121.0535505
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_57.
validation: epoch 57, iter 195, top_1: 0.560817, top_k: 0.804447, samples/s: 2985.210 1612015138.0237067
train: epoch 58, iter 100, loss: 3.191787, top_1: 0.536133, top_k: 0.765039, samples/s: 2965.128 1612015162.796406
train: epoch 58, iter 200, loss: 2.952768, top_1: 0.527734, top_k: 0.759922, samples/s: 3020.541 1612015171.271662
train: epoch 58, iter 300, loss: 3.086114, top_1: 0.527617, top_k: 0.761719, samples/s: 3009.241 1612015179.7787595
train: epoch 58, iter 400, loss: 2.961919, top_1: 0.525273, top_k: 0.756914, samples/s: 2991.421 1612015188.3366263
train: epoch 58, iter 500, loss: 3.032544, top_1: 0.526289, top_k: 0.761563, samples/s: 3006.766 1612015196.8507135
train: epoch 58, iter 600, loss: 2.962105, top_1: 0.529687, top_k: 0.761094, samples/s: 2912.779 1612015205.6395514
train: epoch 58, iter 700, loss: 2.988093, top_1: 0.521406, top_k: 0.757031, samples/s: 3011.756 1612015214.1398022
train: epoch 58, iter 800, loss: 2.907265, top_1: 0.528086, top_k: 0.758555, samples/s: 2963.957 1612015222.7768548
train: epoch 58, iter 900, loss: 2.775858, top_1: 0.524609, top_k: 0.758164, samples/s: 3005.683 1612015231.293891
train: epoch 58, iter 1000, loss: 3.031546, top_1: 0.525195, top_k: 0.754883, samples/s: 2916.835 1612015240.0705442
train: epoch 58, iter 1100, loss: 3.079896, top_1: 0.530664, top_k: 0.761016, samples/s: 2973.857 1612015248.6788497
train: epoch 58, iter 1200, loss: 3.073842, top_1: 0.526289, top_k: 0.755352, samples/s: 2992.801 1612015257.232735
train: epoch 58, iter 1300, loss: 3.080963, top_1: 0.519375, top_k: 0.755039, samples/s: 2964.184 1612015265.869209
train: epoch 58, iter 1400, loss: 2.850685, top_1: 0.523008, top_k: 0.759883, samples/s: 2964.254 1612015274.5056489
train: epoch 58, iter 1500, loss: 2.864449, top_1: 0.521328, top_k: 0.756602, samples/s: 2961.739 1612015283.149037
train: epoch 58, iter 1600, loss: 2.973313, top_1: 0.523633, top_k: 0.757500, samples/s: 2968.153 1612015291.7738922
train: epoch 58, iter 1700, loss: 3.091087, top_1: 0.521758, top_k: 0.756719, samples/s: 2931.059 1612015300.5080857
train: epoch 58, iter 1800, loss: 3.137029, top_1: 0.526992, top_k: 0.757656, samples/s: 2966.052 1612015309.1389709
train: epoch 58, iter 1900, loss: 2.978565, top_1: 0.522109, top_k: 0.756914, samples/s: 2916.063 1612015317.9180832
train: epoch 58, iter 2000, loss: 3.093761, top_1: 0.517344, top_k: 0.756133, samples/s: 2985.112 1612015326.4938614
train: epoch 58, iter 2100, loss: 2.947836, top_1: 0.521367, top_k: 0.757617, samples/s: 2948.858 1612015335.175062
train: epoch 58, iter 2200, loss: 2.942162, top_1: 0.521758, top_k: 0.753359, samples/s: 2924.086 1612015343.9300158
train: epoch 58, iter 2300, loss: 2.994376, top_1: 0.518086, top_k: 0.754570, samples/s: 2991.445 1612015352.487825
train: epoch 58, iter 2400, loss: 3.055035, top_1: 0.522383, top_k: 0.754648, samples/s: 2967.840 1612015361.11351
train: epoch 58, iter 2500, loss: 3.091602, top_1: 0.520312, top_k: 0.752539, samples/s: 2912.331 1612015369.9038923
train: epoch 58, iter 2600, loss: 2.830489, top_1: 0.514961, top_k: 0.749687, samples/s: 2959.408 1612015378.5540986
train: epoch 58, iter 2700, loss: 2.926830, top_1: 0.525000, top_k: 0.757695, samples/s: 2964.509 1612015387.1896305
train: epoch 58, iter 2800, loss: 3.015476, top_1: 0.525430, top_k: 0.754180, samples/s: 2927.190 1612015395.935514
train: epoch 58, iter 2900, loss: 3.156251, top_1: 0.523555, top_k: 0.756406, samples/s: 2972.071 1612015404.5488575
train: epoch 58, iter 3000, loss: 3.041856, top_1: 0.519258, top_k: 0.755664, samples/s: 2969.007 1612015413.1711445
train: epoch 58, iter 3100, loss: 3.128752, top_1: 0.523438, top_k: 0.755195, samples/s: 2950.438 1612015421.8478498
train: epoch 58, iter 3200, loss: 3.114852, top_1: 0.517578, top_k: 0.752969, samples/s: 2943.689 1612015430.544445
train: epoch 58, iter 3300, loss: 2.960457, top_1: 0.521914, top_k: 0.755742, samples/s: 2994.145 1612015439.094382
train: epoch 58, iter 3400, loss: 2.938754, top_1: 0.520938, top_k: 0.752930, samples/s: 2918.184 1612015447.8669705
train: epoch 58, iter 3500, loss: 3.167549, top_1: 0.518516, top_k: 0.756406, samples/s: 2912.138 1612015456.6577027
train: epoch 58, iter 3600, loss: 3.068123, top_1: 0.520625, top_k: 0.756172, samples/s: 2871.585 1612015465.572809
train: epoch 58, iter 3700, loss: 2.984434, top_1: 0.518906, top_k: 0.759570, samples/s: 2929.680 1612015474.310998
train: epoch 58, iter 3800, loss: 2.965308, top_1: 0.518711, top_k: 0.753125, samples/s: 3005.948 1612015482.8273695
train: epoch 58, iter 3900, loss: 3.067219, top_1: 0.518125, top_k: 0.751953, samples/s: 2909.331 1612015491.6265855
train: epoch 58, iter 4000, loss: 3.178255, top_1: 0.521172, top_k: 0.753945, samples/s: 2943.588 1612015500.3235142
train: epoch 58, iter 4100, loss: 3.079965, top_1: 0.523359, top_k: 0.757891, samples/s: 2962.746 1612015508.9640784
train: epoch 58, iter 4200, loss: 3.009814, top_1: 0.517461, top_k: 0.754883, samples/s: 2960.420 1612015517.6115222
train: epoch 58, iter 4300, loss: 3.051774, top_1: 0.513672, top_k: 0.751914, samples/s: 2954.468 1612015526.2763443
train: epoch 58, iter 4400, loss: 2.979399, top_1: 0.517773, top_k: 0.751914, samples/s: 2947.739 1612015534.961034
train: epoch 58, iter 4500, loss: 2.781930, top_1: 0.517266, top_k: 0.751758, samples/s: 2884.971 1612015543.8348227
train: epoch 58, iter 4600, loss: 2.982000, top_1: 0.525742, top_k: 0.753086, samples/s: 2916.879 1612015552.6111195
train: epoch 58, iter 4700, loss: 2.903127, top_1: 0.521328, top_k: 0.751836, samples/s: 2993.135 1612015561.1639943
train: epoch 58, iter 4800, loss: 3.007744, top_1: 0.522813, top_k: 0.757539, samples/s: 2893.318 1612015570.0119176
train: epoch 58, iter 4900, loss: 3.101643, top_1: 0.518359, top_k: 0.753125, samples/s: 2973.701 1612015578.620773
train: epoch 58, iter 5000, loss: 2.893886, top_1: 0.525117, top_k: 0.757969, samples/s: 2989.874 1612015587.1829782
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_58.
validation: epoch 58, iter 195, top_1: 0.571154, top_k: 0.811258, samples/s: 2994.864 1612015604.1283128
train: epoch 59, iter 100, loss: 3.142322, top_1: 0.529883, top_k: 0.759336, samples/s: 2911.301 1612015629.7361429
train: epoch 59, iter 200, loss: 2.985672, top_1: 0.525156, top_k: 0.760117, samples/s: 2987.189 1612015638.306156
train: epoch 59, iter 300, loss: 3.062173, top_1: 0.529687, top_k: 0.760586, samples/s: 2983.338 1612015646.8869867
train: epoch 59, iter 400, loss: 3.228999, top_1: 0.529687, top_k: 0.765273, samples/s: 3003.736 1612015655.409848
train: epoch 59, iter 500, loss: 2.877191, top_1: 0.533203, top_k: 0.763867, samples/s: 2987.146 1612015663.979712
train: epoch 59, iter 600, loss: 3.060642, top_1: 0.532500, top_k: 0.764219, samples/s: 2976.111 1612015672.5816479
train: epoch 59, iter 700, loss: 3.262637, top_1: 0.525664, top_k: 0.759180, samples/s: 2997.849 1612015681.1210842
train: epoch 59, iter 800, loss: 2.930924, top_1: 0.528281, top_k: 0.761055, samples/s: 2931.978 1612015689.8523433
train: epoch 59, iter 900, loss: 3.246282, top_1: 0.520156, top_k: 0.757734, samples/s: 2986.918 1612015698.4230967
train: epoch 59, iter 1000, loss: 3.122183, top_1: 0.519531, top_k: 0.757383, samples/s: 3032.382 1612015706.8652225
train: epoch 59, iter 1100, loss: 3.061259, top_1: 0.523867, top_k: 0.758437, samples/s: 2983.582 1612015715.445565
train: epoch 59, iter 1200, loss: 2.874787, top_1: 0.526133, top_k: 0.760703, samples/s: 2993.127 1612015723.9985795
train: epoch 59, iter 1300, loss: 3.035326, top_1: 0.524102, top_k: 0.760898, samples/s: 2982.606 1612015732.5815318
train: epoch 59, iter 1400, loss: 2.840786, top_1: 0.521680, top_k: 0.758359, samples/s: 2793.676 1612015741.7451994
train: epoch 59, iter 1500, loss: 2.847354, top_1: 0.528047, top_k: 0.761445, samples/s: 2910.847 1612015750.5398748
train: epoch 59, iter 1600, loss: 2.902865, top_1: 0.520820, top_k: 0.759023, samples/s: 2994.591 1612015759.0885797
train: epoch 59, iter 1700, loss: 2.850901, top_1: 0.527383, top_k: 0.760430, samples/s: 2988.701 1612015767.65419
train: epoch 59, iter 1800, loss: 3.150207, top_1: 0.526406, top_k: 0.759414, samples/s: 2942.737 1612015776.353552
train: epoch 59, iter 1900, loss: 3.052454, top_1: 0.523789, top_k: 0.754844, samples/s: 2957.412 1612015785.0098426
train: epoch 59, iter 2000, loss: 2.798178, top_1: 0.526445, top_k: 0.758008, samples/s: 2978.178 1612015793.6056564
train: epoch 59, iter 2100, loss: 2.957779, top_1: 0.526016, top_k: 0.761289, samples/s: 2911.694 1612015802.3977478
train: epoch 59, iter 2200, loss: 3.084291, top_1: 0.525430, top_k: 0.760664, samples/s: 2927.476 1612015811.1425815
train: epoch 59, iter 2300, loss: 3.072873, top_1: 0.519102, top_k: 0.756523, samples/s: 2911.318 1612015819.9358177
train: epoch 59, iter 2400, loss: 2.878782, top_1: 0.525078, top_k: 0.757461, samples/s: 2999.805 1612015828.4696555
train: epoch 59, iter 2500, loss: 2.952207, top_1: 0.520547, top_k: 0.752930, samples/s: 2946.255 1612015837.1586652
train: epoch 59, iter 2600, loss: 2.916260, top_1: 0.519570, top_k: 0.751836, samples/s: 2880.159 1612015846.0471554
train: epoch 59, iter 2700, loss: 2.990115, top_1: 0.519922, top_k: 0.754297, samples/s: 2983.554 1612015854.6274183
train: epoch 59, iter 2800, loss: 2.998220, top_1: 0.520195, top_k: 0.754727, samples/s: 2948.724 1612015863.3091385
train: epoch 59, iter 2900, loss: 3.026579, top_1: 0.526523, top_k: 0.760703, samples/s: 2935.329 1612015872.030488
train: epoch 59, iter 3000, loss: 3.144823, top_1: 0.521953, top_k: 0.756719, samples/s: 2968.560 1612015880.6541998
train: epoch 59, iter 3100, loss: 2.908485, top_1: 0.518359, top_k: 0.752891, samples/s: 2985.157 1612015889.229946
train: epoch 59, iter 3200, loss: 3.043645, top_1: 0.525078, top_k: 0.759375, samples/s: 2961.862 1612015897.8731952
train: epoch 59, iter 3300, loss: 2.984762, top_1: 0.518906, top_k: 0.752031, samples/s: 2904.167 1612015906.6880474
train: epoch 59, iter 3400, loss: 2.984488, top_1: 0.521055, top_k: 0.755000, samples/s: 2984.253 1612015915.2664423
train: epoch 59, iter 3500, loss: 2.992553, top_1: 0.519961, top_k: 0.751094, samples/s: 2921.303 1612015924.0297434
train: epoch 59, iter 3600, loss: 3.010013, top_1: 0.523633, top_k: 0.754961, samples/s: 2975.917 1612015932.6320512
train: epoch 59, iter 3700, loss: 2.987355, top_1: 0.522344, top_k: 0.756797, samples/s: 2858.644 1612015941.5873487
train: epoch 59, iter 3800, loss: 2.974206, top_1: 0.526680, top_k: 0.758906, samples/s: 2970.761 1612015950.2046638
train: epoch 59, iter 3900, loss: 3.037512, top_1: 0.523438, top_k: 0.753828, samples/s: 3004.775 1612015958.7244346
train: epoch 59, iter 4000, loss: 2.950616, top_1: 0.528789, top_k: 0.758711, samples/s: 2969.888 1612015967.3443034
train: epoch 59, iter 4100, loss: 2.813198, top_1: 0.519336, top_k: 0.750039, samples/s: 2971.191 1612015975.960455
train: epoch 59, iter 4200, loss: 3.086212, top_1: 0.525391, top_k: 0.760391, samples/s: 3016.126 1612015984.448025
train: epoch 59, iter 4300, loss: 3.042879, top_1: 0.519961, top_k: 0.760000, samples/s: 2954.435 1612015993.1130161
train: epoch 59, iter 4400, loss: 2.867455, top_1: 0.525195, top_k: 0.755859, samples/s: 2918.515 1612016001.8846047
train: epoch 59, iter 4500, loss: 3.267851, top_1: 0.519102, top_k: 0.749375, samples/s: 2984.342 1612016010.4628234
train: epoch 59, iter 4600, loss: 3.266551, top_1: 0.524141, top_k: 0.757344, samples/s: 2945.216 1612016019.1547482
train: epoch 59, iter 4700, loss: 3.252166, top_1: 0.524258, top_k: 0.756289, samples/s: 2994.333 1612016027.7042434
train: epoch 59, iter 4800, loss: 2.967827, top_1: 0.518477, top_k: 0.753359, samples/s: 2983.653 1612016036.2843938
train: epoch 59, iter 4900, loss: 2.855119, top_1: 0.519023, top_k: 0.750547, samples/s: 2914.511 1612016045.067985
train: epoch 59, iter 5000, loss: 3.054963, top_1: 0.523633, top_k: 0.754102, samples/s: 3010.141 1612016053.572574
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_59.
validation: epoch 59, iter 195, top_1: 0.578105, top_k: 0.811058, samples/s: 2968.432 1612016070.6444101
train: epoch 60, iter 100, loss: 3.078415, top_1: 0.532305, top_k: 0.765742, samples/s: 2876.469 1612016095.1181612
train: epoch 60, iter 200, loss: 2.866759, top_1: 0.527578, top_k: 0.761602, samples/s: 2992.426 1612016103.673088
train: epoch 60, iter 300, loss: 3.058023, top_1: 0.529180, top_k: 0.763789, samples/s: 3000.737 1612016112.2044158
train: epoch 60, iter 400, loss: 3.069696, top_1: 0.525859, top_k: 0.761914, samples/s: 3015.016 1612016120.695266
train: epoch 60, iter 500, loss: 3.031705, top_1: 0.531094, top_k: 0.766328, samples/s: 2924.644 1612016129.4484234
train: epoch 60, iter 600, loss: 2.987371, top_1: 0.525234, top_k: 0.760938, samples/s: 2969.434 1612016138.0695605
train: epoch 60, iter 700, loss: 2.976193, top_1: 0.528633, top_k: 0.759492, samples/s: 2985.550 1612016146.6441185
train: epoch 60, iter 800, loss: 2.960064, top_1: 0.528555, top_k: 0.761367, samples/s: 2953.664 1612016155.3114378
train: epoch 60, iter 900, loss: 3.120983, top_1: 0.532500, top_k: 0.761992, samples/s: 2979.820 1612016163.9025295
train: epoch 60, iter 1000, loss: 3.126256, top_1: 0.524258, top_k: 0.758945, samples/s: 2961.339 1612016172.547351
train: epoch 60, iter 1100, loss: 2.890293, top_1: 0.531094, top_k: 0.760781, samples/s: 2982.730 1612016181.1299663
train: epoch 60, iter 1200, loss: 3.180816, top_1: 0.521445, top_k: 0.757695, samples/s: 2994.702 1612016189.6784883
train: epoch 60, iter 1300, loss: 3.017944, top_1: 0.525234, top_k: 0.759336, samples/s: 2936.449 1612016198.3964558
train: epoch 60, iter 1400, loss: 2.870975, top_1: 0.528398, top_k: 0.760938, samples/s: 2993.824 1612016206.9473464
train: epoch 60, iter 1500, loss: 2.955467, top_1: 0.526445, top_k: 0.757734, samples/s: 3016.338 1612016215.4344842
train: epoch 60, iter 1600, loss: 3.064802, top_1: 0.524648, top_k: 0.759805, samples/s: 2944.197 1612016224.1296556
train: epoch 60, iter 1700, loss: 2.820395, top_1: 0.529727, top_k: 0.763984, samples/s: 2982.035 1612016232.7142801
train: epoch 60, iter 1800, loss: 2.805405, top_1: 0.526953, top_k: 0.759180, samples/s: 2938.240 1612016241.4269338
train: epoch 60, iter 1900, loss: 3.049859, top_1: 0.523828, top_k: 0.757617, samples/s: 2975.101 1612016250.0317416
train: epoch 60, iter 2000, loss: 2.912301, top_1: 0.528789, top_k: 0.760586, samples/s: 2938.938 1612016258.7423813
train: epoch 60, iter 2100, loss: 3.080828, top_1: 0.523633, top_k: 0.758984, samples/s: 2979.633 1612016267.3339984
train: epoch 60, iter 2200, loss: 2.946230, top_1: 0.531172, top_k: 0.761719, samples/s: 2966.860 1612016275.9627335
train: epoch 60, iter 2300, loss: 3.140115, top_1: 0.530469, top_k: 0.757969, samples/s: 2959.979 1612016284.6113987
train: epoch 60, iter 2400, loss: 3.175030, top_1: 0.529687, top_k: 0.760312, samples/s: 2965.135 1612016293.2451386
train: epoch 60, iter 2500, loss: 3.029194, top_1: 0.524258, top_k: 0.761445, samples/s: 2884.366 1612016302.1205494
train: epoch 60, iter 2600, loss: 2.923208, top_1: 0.522148, top_k: 0.756797, samples/s: 2984.068 1612016310.699938
train: epoch 60, iter 2700, loss: 3.092050, top_1: 0.524375, top_k: 0.757734, samples/s: 2987.931 1612016319.2672427
train: epoch 60, iter 2800, loss: 3.119988, top_1: 0.520156, top_k: 0.753125, samples/s: 2957.831 1612016327.9226668
train: epoch 60, iter 2900, loss: 3.139618, top_1: 0.523750, top_k: 0.756406, samples/s: 2960.237 1612016336.5701292
train: epoch 60, iter 3000, loss: 2.755816, top_1: 0.524570, top_k: 0.756289, samples/s: 3000.134 1612016345.103121
train: epoch 60, iter 3100, loss: 2.998345, top_1: 0.521211, top_k: 0.755039, samples/s: 2964.789 1612016353.7377493
train: epoch 60, iter 3200, loss: 3.075074, top_1: 0.523906, top_k: 0.758750, samples/s: 2957.047 1612016362.3951094
train: epoch 60, iter 3300, loss: 3.066918, top_1: 0.523945, top_k: 0.757578, samples/s: 2953.905 1612016371.061645
train: epoch 60, iter 3400, loss: 3.056352, top_1: 0.521406, top_k: 0.755625, samples/s: 2983.107 1612016379.6432583
train: epoch 60, iter 3500, loss: 2.954612, top_1: 0.529492, top_k: 0.758203, samples/s: 2928.602 1612016388.3847244
train: epoch 60, iter 3600, loss: 3.117677, top_1: 0.519219, top_k: 0.755586, samples/s: 2958.377 1612016397.0392473
train: epoch 60, iter 3700, loss: 2.867012, top_1: 0.522852, top_k: 0.757383, samples/s: 2960.872 1612016405.684121
train: epoch 60, iter 3800, loss: 2.816117, top_1: 0.519805, top_k: 0.753906, samples/s: 2959.609 1612016414.333864
train: epoch 60, iter 3900, loss: 2.936434, top_1: 0.521680, top_k: 0.755938, samples/s: 2956.540 1612016422.9927533
train: epoch 60, iter 4000, loss: 2.961392, top_1: 0.528320, top_k: 0.760312, samples/s: 2957.479 1612016431.6487465
train: epoch 60, iter 4100, loss: 2.831460, top_1: 0.521641, top_k: 0.755156, samples/s: 2994.550 1612016440.197525
train: epoch 60, iter 4200, loss: 2.850612, top_1: 0.519883, top_k: 0.759219, samples/s: 3012.655 1612016448.695482
train: epoch 60, iter 4300, loss: 3.014110, top_1: 0.529141, top_k: 0.761250, samples/s: 2963.151 1612016457.3344612
train: epoch 60, iter 4400, loss: 2.871490, top_1: 0.523828, top_k: 0.753750, samples/s: 2940.814 1612016466.0395246
train: epoch 60, iter 4500, loss: 2.897133, top_1: 0.524336, top_k: 0.759023, samples/s: 2963.607 1612016474.677764
train: epoch 60, iter 4600, loss: 2.901204, top_1: 0.528789, top_k: 0.761172, samples/s: 3048.089 1612016483.0764177
train: epoch 60, iter 4700, loss: 3.017036, top_1: 0.519297, top_k: 0.755938, samples/s: 2909.925 1612016491.87383
train: epoch 60, iter 4800, loss: 2.946633, top_1: 0.526563, top_k: 0.758633, samples/s: 2940.993 1612016500.5783699
train: epoch 60, iter 4900, loss: 2.958505, top_1: 0.522227, top_k: 0.751875, samples/s: 2928.617 1612016509.3196626
train: epoch 60, iter 5000, loss: 2.972183, top_1: 0.530937, top_k: 0.761094, samples/s: 2992.806 1612016517.8735385
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_60.
validation: epoch 60, iter 195, top_1: 0.576442, top_k: 0.813822, samples/s: 2968.954 1612016534.856588
train: epoch 61, iter 100, loss: 3.048679, top_1: 0.527852, top_k: 0.761563, samples/s: 2906.221 1612016559.4062946
train: epoch 61, iter 200, loss: 3.058869, top_1: 0.535547, top_k: 0.763789, samples/s: 2997.988 1612016567.9453444
train: epoch 61, iter 300, loss: 2.977929, top_1: 0.530039, top_k: 0.763789, samples/s: 2978.233 1612016576.5410225
train: epoch 61, iter 400, loss: 2.915772, top_1: 0.529180, top_k: 0.762656, samples/s: 2917.268 1612016585.3165147
train: epoch 61, iter 500, loss: 2.808170, top_1: 0.537734, top_k: 0.766211, samples/s: 3019.997 1612016593.7932286
train: epoch 61, iter 600, loss: 3.107797, top_1: 0.534609, top_k: 0.764805, samples/s: 2936.771 1612016602.5106065
train: epoch 61, iter 700, loss: 2.875892, top_1: 0.530625, top_k: 0.762305, samples/s: 3004.809 1612016611.029952
train: epoch 61, iter 800, loss: 2.915911, top_1: 0.533398, top_k: 0.762617, samples/s: 2978.266 1612016619.6255257
train: epoch 61, iter 900, loss: 2.794090, top_1: 0.529883, top_k: 0.767578, samples/s: 2952.771 1612016628.29545
train: epoch 61, iter 1000, loss: 3.024806, top_1: 0.537969, top_k: 0.765352, samples/s: 2997.399 1612016636.8361943
train: epoch 61, iter 1100, loss: 3.071861, top_1: 0.533320, top_k: 0.764727, samples/s: 2978.433 1612016645.431204
train: epoch 61, iter 1200, loss: 3.064510, top_1: 0.520781, top_k: 0.755078, samples/s: 2963.048 1612016654.071013
train: epoch 61, iter 1300, loss: 2.960396, top_1: 0.529141, top_k: 0.758867, samples/s: 2996.228 1612016662.6152363
train: epoch 61, iter 1400, loss: 2.906880, top_1: 0.531250, top_k: 0.761055, samples/s: 2983.093 1612016671.196734
train: epoch 61, iter 1500, loss: 3.038475, top_1: 0.525898, top_k: 0.763867, samples/s: 2989.632 1612016679.7596998
train: epoch 61, iter 1600, loss: 2.928206, top_1: 0.519961, top_k: 0.756641, samples/s: 2982.138 1612016688.3441277
train: epoch 61, iter 1700, loss: 2.934637, top_1: 0.529531, top_k: 0.759609, samples/s: 2986.209 1612016696.9169397
train: epoch 61, iter 1800, loss: 3.041872, top_1: 0.530859, top_k: 0.762656, samples/s: 2934.754 1612016705.6398687
train: epoch 61, iter 1900, loss: 3.027606, top_1: 0.526797, top_k: 0.758359, samples/s: 2982.469 1612016714.223606
train: epoch 61, iter 2000, loss: 2.991580, top_1: 0.529492, top_k: 0.760508, samples/s: 2967.190 1612016722.851143
train: epoch 61, iter 2100, loss: 3.123833, top_1: 0.519414, top_k: 0.752500, samples/s: 2978.579 1612016731.4458802
train: epoch 61, iter 2200, loss: 2.901222, top_1: 0.528789, top_k: 0.763008, samples/s: 2989.804 1612016740.0083158
train: epoch 61, iter 2300, loss: 3.063083, top_1: 0.523398, top_k: 0.761484, samples/s: 2972.654 1612016748.6200225
train: epoch 61, iter 2400, loss: 3.099913, top_1: 0.525469, top_k: 0.755898, samples/s: 2918.455 1612016757.3918314
train: epoch 61, iter 2500, loss: 2.937591, top_1: 0.523164, top_k: 0.757617, samples/s: 2953.396 1612016766.0598488
train: epoch 61, iter 2600, loss: 3.158720, top_1: 0.520820, top_k: 0.755313, samples/s: 2936.679 1612016774.777181
train: epoch 61, iter 2700, loss: 2.948170, top_1: 0.524844, top_k: 0.755039, samples/s: 2983.557 1612016783.35763
train: epoch 61, iter 2800, loss: 2.926249, top_1: 0.526367, top_k: 0.758320, samples/s: 2928.717 1612016792.098579
train: epoch 61, iter 2900, loss: 2.815745, top_1: 0.525352, top_k: 0.759258, samples/s: 3021.719 1612016800.5706503
train: epoch 61, iter 3000, loss: 3.125043, top_1: 0.523711, top_k: 0.753789, samples/s: 2972.482 1612016809.183026
train: epoch 61, iter 3100, loss: 2.943658, top_1: 0.528438, top_k: 0.762930, samples/s: 2985.735 1612016817.757
train: epoch 61, iter 3200, loss: 3.075080, top_1: 0.525391, top_k: 0.752031, samples/s: 2886.936 1612016826.624583
train: epoch 61, iter 3300, loss: 3.149761, top_1: 0.524531, top_k: 0.760000, samples/s: 2981.628 1612016835.2105618
train: epoch 61, iter 3400, loss: 2.952728, top_1: 0.530469, top_k: 0.764922, samples/s: 2915.305 1612016843.9917793
train: epoch 61, iter 3500, loss: 3.014975, top_1: 0.523555, top_k: 0.755625, samples/s: 2927.898 1612016852.7352092
train: epoch 61, iter 3600, loss: 3.101929, top_1: 0.523438, top_k: 0.759102, samples/s: 3006.337 1612016861.2504957
train: epoch 61, iter 3700, loss: 2.958992, top_1: 0.526797, top_k: 0.754336, samples/s: 2984.338 1612016869.8286412
train: epoch 61, iter 3800, loss: 3.035884, top_1: 0.524531, top_k: 0.758984, samples/s: 2988.050 1612016878.3961017
train: epoch 61, iter 3900, loss: 2.982784, top_1: 0.524062, top_k: 0.758164, samples/s: 3001.303 1612016886.92569
train: epoch 61, iter 4000, loss: 3.079142, top_1: 0.522188, top_k: 0.756016, samples/s: 2959.271 1612016895.5764878
train: epoch 61, iter 4100, loss: 2.872326, top_1: 0.526680, top_k: 0.760664, samples/s: 2996.492 1612016904.1201909
train: epoch 61, iter 4200, loss: 3.139608, top_1: 0.528477, top_k: 0.760273, samples/s: 2998.202 1612016912.658278
train: epoch 61, iter 4300, loss: 3.025290, top_1: 0.520547, top_k: 0.756055, samples/s: 2873.879 1612016921.5665429
train: epoch 61, iter 4400, loss: 2.890314, top_1: 0.524531, top_k: 0.760273, samples/s: 2944.874 1612016930.2591584
train: epoch 61, iter 4500, loss: 3.104003, top_1: 0.529453, top_k: 0.758047, samples/s: 2964.789 1612016938.8940446
train: epoch 61, iter 4600, loss: 3.173610, top_1: 0.520859, top_k: 0.753945, samples/s: 3010.953 1612016947.3961446
train: epoch 61, iter 4700, loss: 3.156722, top_1: 0.523359, top_k: 0.754062, samples/s: 2970.527 1612016956.0143383
train: epoch 61, iter 4800, loss: 2.855079, top_1: 0.525625, top_k: 0.756133, samples/s: 2939.915 1612016964.7219276
train: epoch 61, iter 4900, loss: 2.921370, top_1: 0.519531, top_k: 0.758125, samples/s: 2989.899 1612016973.2839725
train: epoch 61, iter 5000, loss: 3.072603, top_1: 0.523281, top_k: 0.758242, samples/s: 3002.215 1612016981.811163
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_61.
validation: epoch 61, iter 195, top_1: 0.579067, top_k: 0.816306, samples/s: 2848.352 1612016999.497673
train: epoch 62, iter 100, loss: 2.978283, top_1: 0.532344, top_k: 0.764219, samples/s: 2860.489 1612017030.0516434
train: epoch 62, iter 200, loss: 2.871430, top_1: 0.545312, top_k: 0.776445, samples/s: 2997.659 1612017038.5914714
train: epoch 62, iter 300, loss: 3.098285, top_1: 0.537461, top_k: 0.769141, samples/s: 2983.820 1612017047.1711297
train: epoch 62, iter 400, loss: 2.801109, top_1: 0.528281, top_k: 0.762266, samples/s: 2926.713 1612017055.9182549
train: epoch 62, iter 500, loss: 2.937782, top_1: 0.534219, top_k: 0.765586, samples/s: 2995.872 1612017064.463226
train: epoch 62, iter 600, loss: 2.978184, top_1: 0.532305, top_k: 0.765312, samples/s: 3008.487 1612017072.9725091
train: epoch 62, iter 700, loss: 2.954319, top_1: 0.533672, top_k: 0.768203, samples/s: 2933.219 1612017081.7000506
train: epoch 62, iter 800, loss: 2.992479, top_1: 0.530391, top_k: 0.761250, samples/s: 2956.665 1612017090.3585184
train: epoch 62, iter 900, loss: 2.860965, top_1: 0.530039, top_k: 0.761367, samples/s: 3023.485 1612017098.8255987
train: epoch 62, iter 1000, loss: 3.057263, top_1: 0.525977, top_k: 0.762969, samples/s: 2943.819 1612017107.521816
train: epoch 62, iter 1100, loss: 2.985121, top_1: 0.528945, top_k: 0.761445, samples/s: 2976.136 1612017116.1236327
train: epoch 62, iter 1200, loss: 2.814231, top_1: 0.535586, top_k: 0.769961, samples/s: 2976.646 1612017124.7237804
train: epoch 62, iter 1300, loss: 2.995002, top_1: 0.524219, top_k: 0.761367, samples/s: 2952.817 1612017133.393475
train: epoch 62, iter 1400, loss: 2.822295, top_1: 0.525586, top_k: 0.758281, samples/s: 2946.133 1612017142.082772
train: epoch 62, iter 1500, loss: 2.965591, top_1: 0.536133, top_k: 0.764258, samples/s: 2878.613 1612017150.976104
train: epoch 62, iter 1600, loss: 3.051169, top_1: 0.529805, top_k: 0.764297, samples/s: 3002.861 1612017159.5014267
train: epoch 62, iter 1700, loss: 3.097292, top_1: 0.530508, top_k: 0.761523, samples/s: 3001.001 1612017168.0317817
train: epoch 62, iter 1800, loss: 3.056401, top_1: 0.529727, top_k: 0.763477, samples/s: 2986.572 1612017176.603405
train: epoch 62, iter 1900, loss: 2.950513, top_1: 0.525742, top_k: 0.759766, samples/s: 2989.510 1612017185.166694
train: epoch 62, iter 2000, loss: 3.040454, top_1: 0.528359, top_k: 0.756914, samples/s: 2901.840 1612017193.988724
train: epoch 62, iter 2100, loss: 3.147814, top_1: 0.524805, top_k: 0.761875, samples/s: 2973.848 1612017202.5970502
train: epoch 62, iter 2200, loss: 2.985083, top_1: 0.523086, top_k: 0.757734, samples/s: 2979.511 1612017211.1890624
train: epoch 62, iter 2300, loss: 2.787867, top_1: 0.523984, top_k: 0.759258, samples/s: 2976.198 1612017219.7906654
train: epoch 62, iter 2400, loss: 2.890234, top_1: 0.532461, top_k: 0.758633, samples/s: 2857.952 1612017228.7480996
train: epoch 62, iter 2500, loss: 3.115610, top_1: 0.526563, top_k: 0.764062, samples/s: 2980.585 1612017237.337009
train: epoch 62, iter 2600, loss: 3.031665, top_1: 0.523828, top_k: 0.756836, samples/s: 2919.261 1612017246.106464
train: epoch 62, iter 2700, loss: 3.098198, top_1: 0.526914, top_k: 0.758281, samples/s: 3029.333 1612017254.557137
train: epoch 62, iter 2800, loss: 2.860097, top_1: 0.529375, top_k: 0.763672, samples/s: 2969.091 1612017263.1792483
train: epoch 62, iter 2900, loss: 3.169588, top_1: 0.526563, top_k: 0.755469, samples/s: 2960.877 1612017271.825351
train: epoch 62, iter 3000, loss: 2.973624, top_1: 0.527695, top_k: 0.757188, samples/s: 2981.950 1612017280.410252
train: epoch 62, iter 3100, loss: 2.969289, top_1: 0.525586, top_k: 0.758594, samples/s: 2982.746 1612017288.9930017
train: epoch 62, iter 3200, loss: 3.207783, top_1: 0.528438, top_k: 0.758867, samples/s: 2982.042 1612017297.5777605
train: epoch 62, iter 3300, loss: 3.212209, top_1: 0.526719, top_k: 0.757500, samples/s: 2980.807 1612017306.165977
train: epoch 62, iter 3400, loss: 3.196636, top_1: 0.526836, top_k: 0.756367, samples/s: 2951.102 1612017314.8408108
train: epoch 62, iter 3500, loss: 2.947560, top_1: 0.528320, top_k: 0.759062, samples/s: 2949.576 1612017323.5199103
train: epoch 62, iter 3600, loss: 3.090690, top_1: 0.524297, top_k: 0.755742, samples/s: 2956.516 1612017332.178808
train: epoch 62, iter 3700, loss: 2.920879, top_1: 0.527070, top_k: 0.758086, samples/s: 2982.241 1612017340.7629435
train: epoch 62, iter 3800, loss: 3.188870, top_1: 0.527070, top_k: 0.759531, samples/s: 2985.981 1612017349.3363156
train: epoch 62, iter 3900, loss: 3.180179, top_1: 0.524961, top_k: 0.753984, samples/s: 2978.346 1612017357.931797
train: epoch 62, iter 4000, loss: 3.093131, top_1: 0.526172, top_k: 0.757227, samples/s: 2937.411 1612017366.64685
train: epoch 62, iter 4100, loss: 3.143809, top_1: 0.523984, top_k: 0.758320, samples/s: 2941.461 1612017375.3500617
train: epoch 62, iter 4200, loss: 2.880666, top_1: 0.531875, top_k: 0.758906, samples/s: 2971.084 1612017383.966447
train: epoch 62, iter 4300, loss: 3.094250, top_1: 0.527109, top_k: 0.757812, samples/s: 2963.937 1612017392.603622
train: epoch 62, iter 4400, loss: 2.960244, top_1: 0.521563, top_k: 0.755742, samples/s: 2983.087 1612017401.185263
train: epoch 62, iter 4500, loss: 3.082135, top_1: 0.525547, top_k: 0.758984, samples/s: 2995.050 1612017409.7326546
train: epoch 62, iter 4600, loss: 3.003344, top_1: 0.523047, top_k: 0.759023, samples/s: 2972.239 1612017418.345727
train: epoch 62, iter 4700, loss: 3.106532, top_1: 0.530586, top_k: 0.765586, samples/s: 2967.168 1612017426.9734986
train: epoch 62, iter 4800, loss: 3.000413, top_1: 0.528945, top_k: 0.758477, samples/s: 2994.674 1612017435.5220258
train: epoch 62, iter 4900, loss: 3.196088, top_1: 0.524492, top_k: 0.756055, samples/s: 2964.898 1612017444.1567533
train: epoch 62, iter 5000, loss: 2.952249, top_1: 0.525508, top_k: 0.759062, samples/s: 2964.007 1612017452.7935495
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_62.
validation: epoch 62, iter 195, top_1: 0.572456, top_k: 0.811779, samples/s: 2970.380 1612017469.8200474
train: epoch 63, iter 100, loss: 3.082264, top_1: 0.535937, top_k: 0.763555, samples/s: 2891.448 1612017494.1890595
train: epoch 63, iter 200, loss: 3.035045, top_1: 0.544258, top_k: 0.773711, samples/s: 2963.568 1612017502.8268468
train: epoch 63, iter 300, loss: 3.046278, top_1: 0.535547, top_k: 0.767852, samples/s: 2957.935 1612017511.481551
train: epoch 63, iter 400, loss: 2.890764, top_1: 0.538594, top_k: 0.769219, samples/s: 2978.126 1612017520.0777395
train: epoch 63, iter 500, loss: 2.792126, top_1: 0.532617, top_k: 0.768398, samples/s: 3019.680 1612017528.5553205
train: epoch 63, iter 600, loss: 3.017682, top_1: 0.533945, top_k: 0.771133, samples/s: 2956.641 1612017537.2138538
train: epoch 63, iter 700, loss: 2.860368, top_1: 0.532305, top_k: 0.765039, samples/s: 3039.439 1612017545.636344
train: epoch 63, iter 800, loss: 2.864559, top_1: 0.527656, top_k: 0.764336, samples/s: 3015.325 1612017554.1263998
train: epoch 63, iter 900, loss: 2.922912, top_1: 0.532539, top_k: 0.761484, samples/s: 2991.936 1612017562.6826305
train: epoch 63, iter 1000, loss: 2.765469, top_1: 0.534609, top_k: 0.764414, samples/s: 3022.005 1612017571.1538277
train: epoch 63, iter 1100, loss: 2.968240, top_1: 0.529805, top_k: 0.762383, samples/s: 2964.584 1612017579.789209
train: epoch 63, iter 1200, loss: 3.062622, top_1: 0.530820, top_k: 0.763398, samples/s: 2971.387 1612017588.404694
train: epoch 63, iter 1300, loss: 2.680026, top_1: 0.522617, top_k: 0.757969, samples/s: 2950.679 1612017597.080595
train: epoch 63, iter 1400, loss: 3.181109, top_1: 0.535000, top_k: 0.764414, samples/s: 2998.737 1612017605.6175976
train: epoch 63, iter 1500, loss: 3.022381, top_1: 0.533633, top_k: 0.761133, samples/s: 3011.664 1612017614.1177845
train: epoch 63, iter 1600, loss: 3.041992, top_1: 0.533945, top_k: 0.764414, samples/s: 2961.690 1612017622.761527
train: epoch 63, iter 1700, loss: 2.997088, top_1: 0.527070, top_k: 0.758398, samples/s: 3005.383 1612017631.2796862
train: epoch 63, iter 1800, loss: 2.876894, top_1: 0.529648, top_k: 0.760000, samples/s: 2964.437 1612017639.9152877
train: epoch 63, iter 1900, loss: 2.963323, top_1: 0.524258, top_k: 0.761055, samples/s: 3014.578 1612017648.4073453
train: epoch 63, iter 2000, loss: 3.110917, top_1: 0.533750, top_k: 0.764141, samples/s: 2989.864 1612017656.9695902
train: epoch 63, iter 2100, loss: 2.859145, top_1: 0.524883, top_k: 0.761992, samples/s: 2982.668 1612017665.5525143
train: epoch 63, iter 2200, loss: 3.037984, top_1: 0.533477, top_k: 0.761602, samples/s: 2966.129 1612017674.1832867
train: epoch 63, iter 2300, loss: 2.797453, top_1: 0.532266, top_k: 0.766680, samples/s: 2988.099 1612017682.7506542
train: epoch 63, iter 2400, loss: 2.982994, top_1: 0.527227, top_k: 0.760625, samples/s: 2869.689 1612017691.6714678
train: epoch 63, iter 2500, loss: 2.769662, top_1: 0.533438, top_k: 0.762695, samples/s: 2897.349 1612017700.5071507
train: epoch 63, iter 2600, loss: 2.931503, top_1: 0.530547, top_k: 0.764922, samples/s: 2989.291 1612017709.0710616
train: epoch 63, iter 2700, loss: 2.900747, top_1: 0.526211, top_k: 0.761406, samples/s: 2965.576 1612017717.7033935
train: epoch 63, iter 2800, loss: 2.912338, top_1: 0.529805, top_k: 0.764531, samples/s: 3052.538 1612017726.0898728
train: epoch 63, iter 2900, loss: 2.958935, top_1: 0.526328, top_k: 0.761758, samples/s: 2986.514 1612017734.6617148
train: epoch 63, iter 3000, loss: 2.773147, top_1: 0.529219, top_k: 0.762227, samples/s: 2957.926 1612017743.3165052
train: epoch 63, iter 3100, loss: 2.915197, top_1: 0.526914, top_k: 0.760938, samples/s: 2976.444 1612017751.9173176
train: epoch 63, iter 3200, loss: 3.107474, top_1: 0.527500, top_k: 0.757695, samples/s: 2980.982 1612017760.5052106
train: epoch 63, iter 3300, loss: 3.019475, top_1: 0.522930, top_k: 0.761836, samples/s: 3009.091 1612017769.0126328
train: epoch 63, iter 3400, loss: 2.884645, top_1: 0.527969, top_k: 0.758555, samples/s: 2978.598 1612017777.6072853
train: epoch 63, iter 3500, loss: 3.003328, top_1: 0.522813, top_k: 0.757617, samples/s: 2969.362 1612017786.2287295
train: epoch 63, iter 3600, loss: 2.698607, top_1: 0.536250, top_k: 0.765117, samples/s: 2991.612 1612017794.7858608
train: epoch 63, iter 3700, loss: 2.977963, top_1: 0.528516, top_k: 0.762227, samples/s: 3009.421 1612017803.2925506
train: epoch 63, iter 3800, loss: 2.955439, top_1: 0.528984, top_k: 0.761445, samples/s: 2930.447 1612017812.028402
train: epoch 63, iter 3900, loss: 3.029727, top_1: 0.527070, top_k: 0.765156, samples/s: 2994.670 1612017820.5769432
train: epoch 63, iter 4000, loss: 2.956436, top_1: 0.531445, top_k: 0.762852, samples/s: 2965.584 1612017829.209298
train: epoch 63, iter 4100, loss: 3.120121, top_1: 0.527695, top_k: 0.757148, samples/s: 2854.590 1612017838.177313
train: epoch 63, iter 4200, loss: 3.158582, top_1: 0.529453, top_k: 0.758437, samples/s: 2959.553 1612017846.8274782
train: epoch 63, iter 4300, loss: 3.100598, top_1: 0.524844, top_k: 0.758242, samples/s: 2937.670 1612017855.5416446
train: epoch 63, iter 4400, loss: 3.080349, top_1: 0.527773, top_k: 0.756602, samples/s: 2994.033 1612017864.0920923
train: epoch 63, iter 4500, loss: 3.046063, top_1: 0.527266, top_k: 0.760781, samples/s: 2976.854 1612017872.691852
train: epoch 63, iter 4600, loss: 3.089598, top_1: 0.529570, top_k: 0.759492, samples/s: 2945.677 1612017881.3823202
train: epoch 63, iter 4700, loss: 2.929557, top_1: 0.527930, top_k: 0.759687, samples/s: 2936.419 1612017890.1004622
train: epoch 63, iter 4800, loss: 2.801136, top_1: 0.524062, top_k: 0.757773, samples/s: 2966.652 1612017898.729798
train: epoch 63, iter 4900, loss: 3.074725, top_1: 0.524258, top_k: 0.757344, samples/s: 2963.535 1612017907.3680708
train: epoch 63, iter 5000, loss: 2.969909, top_1: 0.525781, top_k: 0.760586, samples/s: 2954.906 1612017916.0316193
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_63.
validation: epoch 63, iter 195, top_1: 0.568550, top_k: 0.808273, samples/s: 3027.168 1612017932.7658367
train: epoch 64, iter 100, loss: 3.088222, top_1: 0.541836, top_k: 0.772109, samples/s: 2951.276 1612017957.0566285
train: epoch 64, iter 200, loss: 2.933090, top_1: 0.539687, top_k: 0.767188, samples/s: 3023.908 1612017965.5225089
train: epoch 64, iter 300, loss: 2.933305, top_1: 0.536445, top_k: 0.771523, samples/s: 3002.253 1612017974.0495324
train: epoch 64, iter 400, loss: 2.981622, top_1: 0.540391, top_k: 0.770781, samples/s: 2929.767 1612017982.787346
train: epoch 64, iter 500, loss: 2.733214, top_1: 0.532656, top_k: 0.762305, samples/s: 2916.571 1612017991.564773
train: epoch 64, iter 600, loss: 2.881904, top_1: 0.536172, top_k: 0.768008, samples/s: 2962.300 1612018000.2068226
train: epoch 64, iter 700, loss: 2.875845, top_1: 0.536133, top_k: 0.768203, samples/s: 2999.387 1612018008.7417874
train: epoch 64, iter 800, loss: 2.904893, top_1: 0.527695, top_k: 0.762539, samples/s: 2952.849 1612018017.411357
train: epoch 64, iter 900, loss: 2.834223, top_1: 0.534648, top_k: 0.767930, samples/s: 2992.632 1612018025.9657931
train: epoch 64, iter 1000, loss: 2.870729, top_1: 0.530273, top_k: 0.762656, samples/s: 2921.003 1612018034.7298362
train: epoch 64, iter 1100, loss: 3.100793, top_1: 0.535234, top_k: 0.764883, samples/s: 3001.605 1612018043.2586033
train: epoch 64, iter 1200, loss: 3.032288, top_1: 0.530898, top_k: 0.764961, samples/s: 2982.904 1612018051.8408952
train: epoch 64, iter 1300, loss: 2.898416, top_1: 0.533750, top_k: 0.764023, samples/s: 2981.139 1612018060.4281833
train: epoch 64, iter 1400, loss: 3.314903, top_1: 0.529102, top_k: 0.764062, samples/s: 2949.582 1612018069.107393
train: epoch 64, iter 1500, loss: 2.918261, top_1: 0.529609, top_k: 0.760039, samples/s: 2981.662 1612018077.693195
train: epoch 64, iter 1600, loss: 3.108352, top_1: 0.526055, top_k: 0.757656, samples/s: 2853.609 1612018086.6643758
train: epoch 64, iter 1700, loss: 2.959693, top_1: 0.528672, top_k: 0.763711, samples/s: 2926.977 1612018095.410495
train: epoch 64, iter 1800, loss: 3.239041, top_1: 0.528164, top_k: 0.759727, samples/s: 2857.755 1612018104.3685806
train: epoch 64, iter 1900, loss: 2.994246, top_1: 0.526289, top_k: 0.762930, samples/s: 2977.816 1612018112.9654894
train: epoch 64, iter 2000, loss: 2.823582, top_1: 0.530430, top_k: 0.761914, samples/s: 2997.993 1612018121.5046077
train: epoch 64, iter 2100, loss: 3.094923, top_1: 0.532773, top_k: 0.764141, samples/s: 2903.769 1612018130.3206449
train: epoch 64, iter 2200, loss: 3.108248, top_1: 0.535820, top_k: 0.766719, samples/s: 2968.343 1612018138.945087
train: epoch 64, iter 2300, loss: 2.852193, top_1: 0.534687, top_k: 0.764727, samples/s: 3035.776 1612018147.3777614
train: epoch 64, iter 2400, loss: 2.971172, top_1: 0.529102, top_k: 0.763477, samples/s: 2919.802 1612018156.145514
train: epoch 64, iter 2500, loss: 2.880364, top_1: 0.531758, top_k: 0.763320, samples/s: 2989.320 1612018164.7093
train: epoch 64, iter 2600, loss: 3.009870, top_1: 0.530859, top_k: 0.765547, samples/s: 2945.775 1612018173.3997314
train: epoch 64, iter 2700, loss: 2.955976, top_1: 0.529062, top_k: 0.762500, samples/s: 2968.440 1612018182.0237212
train: epoch 64, iter 2800, loss: 2.957043, top_1: 0.530977, top_k: 0.765117, samples/s: 3001.309 1612018190.553392
train: epoch 64, iter 2900, loss: 2.941472, top_1: 0.531289, top_k: 0.764141, samples/s: 2982.837 1612018199.1359491
train: epoch 64, iter 3000, loss: 3.069832, top_1: 0.530195, top_k: 0.762695, samples/s: 2971.006 1612018207.7524247
train: epoch 64, iter 3100, loss: 3.169490, top_1: 0.528477, top_k: 0.759375, samples/s: 2985.957 1612018216.3259172
train: epoch 64, iter 3200, loss: 3.130568, top_1: 0.530273, top_k: 0.762109, samples/s: 2965.407 1612018224.958745
train: epoch 64, iter 3300, loss: 2.749915, top_1: 0.527305, top_k: 0.758789, samples/s: 3015.772 1612018233.4475918
train: epoch 64, iter 3400, loss: 2.923271, top_1: 0.524375, top_k: 0.757344, samples/s: 2984.071 1612018242.0263653
train: epoch 64, iter 3500, loss: 2.820991, top_1: 0.525273, top_k: 0.761328, samples/s: 3020.068 1612018250.5031219
train: epoch 64, iter 3600, loss: 3.201014, top_1: 0.529805, top_k: 0.760312, samples/s: 2915.504 1612018259.2836747
train: epoch 64, iter 3700, loss: 2.917395, top_1: 0.529609, top_k: 0.759727, samples/s: 2940.700 1612018267.9890935
train: epoch 64, iter 3800, loss: 3.084190, top_1: 0.534844, top_k: 0.761992, samples/s: 2966.188 1612018276.6196501
train: epoch 64, iter 3900, loss: 2.902712, top_1: 0.525742, top_k: 0.760742, samples/s: 2979.191 1612018285.2125967
train: epoch 64, iter 4000, loss: 2.936115, top_1: 0.532734, top_k: 0.762461, samples/s: 2977.487 1612018293.810438
train: epoch 64, iter 4100, loss: 2.902889, top_1: 0.526094, top_k: 0.759258, samples/s: 3001.408 1612018302.3398864
train: epoch 64, iter 4200, loss: 3.023228, top_1: 0.531563, top_k: 0.764648, samples/s: 2972.987 1612018310.9505906
train: epoch 64, iter 4300, loss: 2.816788, top_1: 0.525977, top_k: 0.760000, samples/s: 3005.667 1612018319.4678838
train: epoch 64, iter 4400, loss: 2.837630, top_1: 0.531953, top_k: 0.760859, samples/s: 2959.979 1612018328.1165898
train: epoch 64, iter 4500, loss: 2.864043, top_1: 0.529336, top_k: 0.761016, samples/s: 2992.516 1612018336.671322
train: epoch 64, iter 4600, loss: 3.202983, top_1: 0.529922, top_k: 0.761484, samples/s: 2933.327 1612018345.398559
train: epoch 64, iter 4700, loss: 3.071773, top_1: 0.523750, top_k: 0.758789, samples/s: 2958.740 1612018354.0509121
train: epoch 64, iter 4800, loss: 2.967246, top_1: 0.529805, top_k: 0.761055, samples/s: 2903.539 1612018362.8677492
train: epoch 64, iter 4900, loss: 2.867718, top_1: 0.525469, top_k: 0.760938, samples/s: 2960.963 1612018371.51359
train: epoch 64, iter 5000, loss: 3.095094, top_1: 0.526641, top_k: 0.755859, samples/s: 2999.985 1612018380.0469325
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_64.
validation: epoch 64, iter 195, top_1: 0.576623, top_k: 0.815605, samples/s: 2979.419 1612018397.053519
train: epoch 65, iter 100, loss: 2.900596, top_1: 0.542500, top_k: 0.771289, samples/s: 2898.554 1612018421.6693342
train: epoch 65, iter 200, loss: 2.909546, top_1: 0.534258, top_k: 0.770430, samples/s: 2930.516 1612018430.404733
train: epoch 65, iter 300, loss: 2.957669, top_1: 0.542969, top_k: 0.772188, samples/s: 2999.938 1612018438.9382603
train: epoch 65, iter 400, loss: 3.138891, top_1: 0.532148, top_k: 0.769727, samples/s: 3022.225 1612018447.408843
train: epoch 65, iter 500, loss: 3.114550, top_1: 0.535430, top_k: 0.770938, samples/s: 2992.521 1612018455.963451
train: epoch 65, iter 600, loss: 2.832683, top_1: 0.537969, top_k: 0.770469, samples/s: 2870.319 1612018464.8823533
train: epoch 65, iter 700, loss: 3.037845, top_1: 0.539375, top_k: 0.771094, samples/s: 2959.605 1612018473.5321622
train: epoch 65, iter 800, loss: 2.928532, top_1: 0.536875, top_k: 0.766484, samples/s: 2943.491 1612018482.229378
train: epoch 65, iter 900, loss: 2.902269, top_1: 0.530664, top_k: 0.763203, samples/s: 2988.875 1612018490.794453
train: epoch 65, iter 1000, loss: 2.695883, top_1: 0.537383, top_k: 0.769453, samples/s: 3005.568 1612018499.311887
train: epoch 65, iter 1100, loss: 2.828017, top_1: 0.535117, top_k: 0.765391, samples/s: 3005.188 1612018507.8305376
train: epoch 65, iter 1200, loss: 2.990416, top_1: 0.538281, top_k: 0.770039, samples/s: 2953.961 1612018516.4969535
train: epoch 65, iter 1300, loss: 2.759713, top_1: 0.530742, top_k: 0.762148, samples/s: 2991.789 1612018525.053565
train: epoch 65, iter 1400, loss: 2.992070, top_1: 0.536172, top_k: 0.768281, samples/s: 2996.645 1612018533.5965152
train: epoch 65, iter 1500, loss: 3.007473, top_1: 0.534453, top_k: 0.765586, samples/s: 2938.942 1612018542.30712
train: epoch 65, iter 1600, loss: 2.943645, top_1: 0.531172, top_k: 0.762148, samples/s: 2979.908 1612018550.8980236
train: epoch 65, iter 1700, loss: 3.093680, top_1: 0.530273, top_k: 0.758242, samples/s: 2961.325 1612018559.5427618
train: epoch 65, iter 1800, loss: 2.821543, top_1: 0.539492, top_k: 0.771133, samples/s: 2933.734 1612018568.268844
train: epoch 65, iter 1900, loss: 2.843658, top_1: 0.533008, top_k: 0.764648, samples/s: 2953.796 1612018576.935682
train: epoch 65, iter 2000, loss: 2.964445, top_1: 0.539102, top_k: 0.768125, samples/s: 2927.984 1612018585.6789548
train: epoch 65, iter 2100, loss: 2.793846, top_1: 0.529570, top_k: 0.762500, samples/s: 2957.492 1612018594.3349276
train: epoch 65, iter 2200, loss: 3.061290, top_1: 0.532109, top_k: 0.759922, samples/s: 2920.781 1612018603.0996654
train: epoch 65, iter 2300, loss: 3.050469, top_1: 0.529531, top_k: 0.761367, samples/s: 2945.078 1612018611.7921586
train: epoch 65, iter 2400, loss: 2.973037, top_1: 0.527734, top_k: 0.761914, samples/s: 2983.557 1612018620.372547
train: epoch 65, iter 2500, loss: 2.870362, top_1: 0.529922, top_k: 0.762930, samples/s: 2896.777 1612018629.2099042
train: epoch 65, iter 2600, loss: 2.953200, top_1: 0.529336, top_k: 0.762773, samples/s: 2976.253 1612018637.811406
train: epoch 65, iter 2700, loss: 2.911694, top_1: 0.531602, top_k: 0.764062, samples/s: 2933.095 1612018646.539368
train: epoch 65, iter 2800, loss: 2.898442, top_1: 0.529961, top_k: 0.762383, samples/s: 2961.313 1612018655.1841178
train: epoch 65, iter 2900, loss: 3.007270, top_1: 0.532305, top_k: 0.762813, samples/s: 2899.426 1612018664.013445
train: epoch 65, iter 3000, loss: 2.968525, top_1: 0.536758, top_k: 0.763047, samples/s: 2945.885 1612018672.7035506
train: epoch 65, iter 3100, loss: 2.962940, top_1: 0.527461, top_k: 0.760664, samples/s: 2987.815 1612018681.2716231
train: epoch 65, iter 3200, loss: 2.905300, top_1: 0.533867, top_k: 0.764687, samples/s: 3026.325 1612018689.7307637
train: epoch 65, iter 3300, loss: 3.236145, top_1: 0.531016, top_k: 0.761563, samples/s: 2899.448 1612018698.5600328
train: epoch 65, iter 3400, loss: 2.737918, top_1: 0.529180, top_k: 0.763594, samples/s: 2984.627 1612018707.1373284
train: epoch 65, iter 3500, loss: 2.819775, top_1: 0.534062, top_k: 0.761563, samples/s: 2877.817 1612018716.032952
train: epoch 65, iter 3600, loss: 3.034497, top_1: 0.529336, top_k: 0.763203, samples/s: 2981.992 1612018724.6178098
train: epoch 65, iter 3700, loss: 2.903060, top_1: 0.531797, top_k: 0.759609, samples/s: 2986.740 1612018733.1890206
train: epoch 65, iter 3800, loss: 3.132730, top_1: 0.527891, top_k: 0.765820, samples/s: 2937.803 1612018741.9030495
train: epoch 65, iter 3900, loss: 2.936324, top_1: 0.529648, top_k: 0.759883, samples/s: 2990.236 1612018750.4642992
train: epoch 65, iter 4000, loss: 2.984313, top_1: 0.527852, top_k: 0.761133, samples/s: 2997.058 1612018759.005939
train: epoch 65, iter 4100, loss: 2.848149, top_1: 0.525937, top_k: 0.757812, samples/s: 2990.217 1612018767.5673072
train: epoch 65, iter 4200, loss: 3.043568, top_1: 0.527266, top_k: 0.757539, samples/s: 2999.084 1612018776.1031284
train: epoch 65, iter 4300, loss: 3.055981, top_1: 0.531641, top_k: 0.764258, samples/s: 2993.865 1612018784.6539602
train: epoch 65, iter 4400, loss: 3.066017, top_1: 0.531445, top_k: 0.762266, samples/s: 2946.426 1612018793.3424597
train: epoch 65, iter 4500, loss: 2.910037, top_1: 0.528398, top_k: 0.760156, samples/s: 3001.531 1612018801.8714073
train: epoch 65, iter 4600, loss: 3.117353, top_1: 0.532461, top_k: 0.764336, samples/s: 3003.603 1612018810.3945415
train: epoch 65, iter 4700, loss: 3.190507, top_1: 0.533125, top_k: 0.763477, samples/s: 2906.692 1612018819.2017791
train: epoch 65, iter 4800, loss: 2.914853, top_1: 0.532188, top_k: 0.765391, samples/s: 3002.597 1612018827.7277012
train: epoch 65, iter 4900, loss: 3.067095, top_1: 0.529492, top_k: 0.763320, samples/s: 2967.183 1612018836.3555572
train: epoch 65, iter 5000, loss: 2.797283, top_1: 0.530234, top_k: 0.764805, samples/s: 2890.296 1612018845.2126627
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_65.
validation: epoch 65, iter 195, top_1: 0.577264, top_k: 0.814363, samples/s: 2978.017 1612018862.2740524
train: epoch 66, iter 100, loss: 2.797040, top_1: 0.534805, top_k: 0.769687, samples/s: 2891.892 1612018887.0396538
train: epoch 66, iter 200, loss: 2.662939, top_1: 0.542617, top_k: 0.774258, samples/s: 2980.591 1612018895.6285362
train: epoch 66, iter 300, loss: 2.770725, top_1: 0.541758, top_k: 0.773477, samples/s: 2958.962 1612018904.2802594
train: epoch 66, iter 400, loss: 2.855089, top_1: 0.535664, top_k: 0.769336, samples/s: 2972.642 1612018912.892115
train: epoch 66, iter 500, loss: 2.889240, top_1: 0.534023, top_k: 0.765117, samples/s: 2911.253 1612018921.6855588
train: epoch 66, iter 600, loss: 2.928584, top_1: 0.541836, top_k: 0.772578, samples/s: 3013.000 1612018930.1821547
train: epoch 66, iter 700, loss: 2.998587, top_1: 0.538047, top_k: 0.771875, samples/s: 2993.455 1612018938.7340128
train: epoch 66, iter 800, loss: 3.031893, top_1: 0.540703, top_k: 0.769883, samples/s: 2922.987 1612018947.49223
train: epoch 66, iter 900, loss: 2.867754, top_1: 0.540703, top_k: 0.771914, samples/s: 2954.945 1612018956.1557162
train: epoch 66, iter 1000, loss: 2.984984, top_1: 0.531484, top_k: 0.763555, samples/s: 3005.892 1612018964.672279
train: epoch 66, iter 1100, loss: 3.095725, top_1: 0.535000, top_k: 0.766016, samples/s: 3016.220 1612018973.1596832
train: epoch 66, iter 1200, loss: 2.916074, top_1: 0.532891, top_k: 0.764102, samples/s: 2991.588 1612018981.7170577
train: epoch 66, iter 1300, loss: 2.940183, top_1: 0.535000, top_k: 0.763203, samples/s: 2952.989 1612018990.386468
train: epoch 66, iter 1400, loss: 2.855980, top_1: 0.537500, top_k: 0.765859, samples/s: 2929.153 1612018999.1259718
train: epoch 66, iter 1500, loss: 2.851097, top_1: 0.534727, top_k: 0.771602, samples/s: 2952.507 1612019007.796612
train: epoch 66, iter 1600, loss: 3.073057, top_1: 0.535039, top_k: 0.763516, samples/s: 2950.109 1612019016.4741845
train: epoch 66, iter 1700, loss: 2.878315, top_1: 0.536016, top_k: 0.765508, samples/s: 2948.491 1612019025.1566288
train: epoch 66, iter 1800, loss: 2.984496, top_1: 0.531914, top_k: 0.764023, samples/s: 2993.806 1612019033.707639
train: epoch 66, iter 1900, loss: 2.743786, top_1: 0.536992, top_k: 0.767227, samples/s: 2973.818 1612019042.316063
train: epoch 66, iter 2000, loss: 2.809495, top_1: 0.536523, top_k: 0.767969, samples/s: 2978.898 1612019050.9098992
train: epoch 66, iter 2100, loss: 2.901318, top_1: 0.524102, top_k: 0.760820, samples/s: 2981.505 1612019059.4961982
train: epoch 66, iter 2200, loss: 2.968857, top_1: 0.532344, top_k: 0.768398, samples/s: 2954.912 1612019068.1596355
train: epoch 66, iter 2300, loss: 3.166829, top_1: 0.534414, top_k: 0.762852, samples/s: 3004.506 1612019076.6801805
train: epoch 66, iter 2400, loss: 2.797312, top_1: 0.530547, top_k: 0.767539, samples/s: 2975.571 1612019085.2836854
train: epoch 66, iter 2500, loss: 2.829736, top_1: 0.539023, top_k: 0.769961, samples/s: 2975.442 1612019093.8873897
train: epoch 66, iter 2600, loss: 2.845681, top_1: 0.533477, top_k: 0.768437, samples/s: 2966.773 1612019102.516239
train: epoch 66, iter 2700, loss: 3.096837, top_1: 0.529414, top_k: 0.763672, samples/s: 2970.119 1612019111.1354036
train: epoch 66, iter 2800, loss: 2.979708, top_1: 0.534961, top_k: 0.766289, samples/s: 3006.284 1612019119.6509705
train: epoch 66, iter 2900, loss: 3.097922, top_1: 0.534766, top_k: 0.766250, samples/s: 2947.082 1612019128.3374991
train: epoch 66, iter 3000, loss: 2.926339, top_1: 0.535117, top_k: 0.767070, samples/s: 2993.998 1612019136.8882759
train: epoch 66, iter 3100, loss: 2.974389, top_1: 0.528516, top_k: 0.764336, samples/s: 2975.570 1612019145.4913163
train: epoch 66, iter 3200, loss: 3.155465, top_1: 0.525273, top_k: 0.761953, samples/s: 2976.681 1612019154.091604
train: epoch 66, iter 3300, loss: 2.891714, top_1: 0.533242, top_k: 0.763867, samples/s: 2994.568 1612019162.6406884
train: epoch 66, iter 3400, loss: 2.785503, top_1: 0.534531, top_k: 0.766680, samples/s: 2961.608 1612019171.2842815
train: epoch 66, iter 3500, loss: 3.039068, top_1: 0.532500, top_k: 0.763906, samples/s: 2958.481 1612019179.9378211
train: epoch 66, iter 3600, loss: 2.828428, top_1: 0.532266, top_k: 0.765273, samples/s: 2974.654 1612019188.5434027
train: epoch 66, iter 3700, loss: 3.119544, top_1: 0.531797, top_k: 0.763555, samples/s: 2988.785 1612019197.1088026
train: epoch 66, iter 3800, loss: 2.907010, top_1: 0.530195, top_k: 0.763086, samples/s: 2933.121 1612019205.836657
train: epoch 66, iter 3900, loss: 2.936778, top_1: 0.534727, top_k: 0.763437, samples/s: 2974.521 1612019214.4431329
train: epoch 66, iter 4000, loss: 2.853323, top_1: 0.524062, top_k: 0.756797, samples/s: 2990.881 1612019223.0025022
train: epoch 66, iter 4100, loss: 3.027957, top_1: 0.528398, top_k: 0.761719, samples/s: 2948.699 1612019231.6842637
train: epoch 66, iter 4200, loss: 3.038241, top_1: 0.531641, top_k: 0.764023, samples/s: 3009.527 1612019240.1909957
train: epoch 66, iter 4300, loss: 3.098584, top_1: 0.528203, top_k: 0.763828, samples/s: 2934.647 1612019248.9139183
train: epoch 66, iter 4400, loss: 2.836107, top_1: 0.529219, top_k: 0.766484, samples/s: 2995.612 1612019257.4597816
train: epoch 66, iter 4500, loss: 3.040815, top_1: 0.526445, top_k: 0.759844, samples/s: 2986.464 1612019266.0326505
train: epoch 66, iter 4600, loss: 3.164257, top_1: 0.525547, top_k: 0.761602, samples/s: 2996.442 1612019274.5752494
train: epoch 66, iter 4700, loss: 3.028074, top_1: 0.532148, top_k: 0.763555, samples/s: 2993.086 1612019283.128451
train: epoch 66, iter 4800, loss: 3.093749, top_1: 0.535664, top_k: 0.767305, samples/s: 2967.877 1612019291.7539592
train: epoch 66, iter 4900, loss: 2.924451, top_1: 0.527344, top_k: 0.759609, samples/s: 2931.518 1612019300.4866452
train: epoch 66, iter 5000, loss: 2.677963, top_1: 0.538203, top_k: 0.773398, samples/s: 2998.843 1612019309.023408
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_66.
validation: epoch 66, iter 195, top_1: 0.580369, top_k: 0.817107, samples/s: 2950.093 1612019326.2278953
train: epoch 67, iter 100, loss: 2.975391, top_1: 0.546367, top_k: 0.775352, samples/s: 2938.162 1612019351.1865983
train: epoch 67, iter 200, loss: 3.097693, top_1: 0.540469, top_k: 0.770195, samples/s: 2996.319 1612019359.730222
train: epoch 67, iter 300, loss: 2.920362, top_1: 0.540937, top_k: 0.772344, samples/s: 3051.425 1612019368.119865
train: epoch 67, iter 400, loss: 2.763945, top_1: 0.534492, top_k: 0.770859, samples/s: 2989.669 1612019376.6825738
train: epoch 67, iter 500, loss: 2.959413, top_1: 0.537773, top_k: 0.769453, samples/s: 2978.883 1612019385.2765105
train: epoch 67, iter 600, loss: 2.867099, top_1: 0.540859, top_k: 0.774180, samples/s: 3009.610 1612019393.7825184
train: epoch 67, iter 700, loss: 2.830556, top_1: 0.535352, top_k: 0.771211, samples/s: 2974.064 1612019402.3903298
train: epoch 67, iter 800, loss: 2.741260, top_1: 0.538281, top_k: 0.772773, samples/s: 3005.840 1612019410.9070249
train: epoch 67, iter 900, loss: 2.829276, top_1: 0.535586, top_k: 0.768008, samples/s: 2938.634 1612019419.618534
train: epoch 67, iter 1000, loss: 2.833373, top_1: 0.540391, top_k: 0.772266, samples/s: 3023.941 1612019428.0842848
train: epoch 67, iter 1100, loss: 3.065692, top_1: 0.538633, top_k: 0.769180, samples/s: 2980.732 1612019436.672903
train: epoch 67, iter 1200, loss: 2.982915, top_1: 0.544570, top_k: 0.771055, samples/s: 2972.711 1612019445.2845278
train: epoch 67, iter 1300, loss: 3.132724, top_1: 0.540820, top_k: 0.769609, samples/s: 2870.893 1612019454.20156
train: epoch 67, iter 1400, loss: 3.083062, top_1: 0.531719, top_k: 0.762266, samples/s: 2949.163 1612019462.881999
train: epoch 67, iter 1500, loss: 2.811455, top_1: 0.541484, top_k: 0.768281, samples/s: 3000.780 1612019471.4131007
train: epoch 67, iter 1600, loss: 3.084050, top_1: 0.530469, top_k: 0.763789, samples/s: 2999.203 1612019479.9487722
train: epoch 67, iter 1700, loss: 3.020954, top_1: 0.538711, top_k: 0.769102, samples/s: 3005.141 1612019488.467448
train: epoch 67, iter 1800, loss: 2.807632, top_1: 0.537422, top_k: 0.768125, samples/s: 2977.068 1612019497.0665278
train: epoch 67, iter 1900, loss: 3.059008, top_1: 0.536523, top_k: 0.768047, samples/s: 2950.358 1612019505.7433827
train: epoch 67, iter 2000, loss: 2.860746, top_1: 0.537461, top_k: 0.768906, samples/s: 2993.443 1612019514.2954764
train: epoch 67, iter 2100, loss: 2.959096, top_1: 0.537461, top_k: 0.769180, samples/s: 2977.276 1612019522.893897
train: epoch 67, iter 2200, loss: 3.104536, top_1: 0.532227, top_k: 0.766836, samples/s: 2971.874 1612019531.5081306
train: epoch 67, iter 2300, loss: 2.894332, top_1: 0.536563, top_k: 0.768008, samples/s: 3002.188 1612019540.0351963
train: epoch 67, iter 2400, loss: 2.941336, top_1: 0.533477, top_k: 0.766914, samples/s: 2944.180 1612019548.7303112
train: epoch 67, iter 2500, loss: 2.767222, top_1: 0.532969, top_k: 0.767734, samples/s: 2989.833 1612019557.2926006
train: epoch 67, iter 2600, loss: 3.023857, top_1: 0.531133, top_k: 0.764258, samples/s: 2978.028 1612019565.888891
train: epoch 67, iter 2700, loss: 3.025224, top_1: 0.535039, top_k: 0.765664, samples/s: 2966.214 1612019574.5193527
train: epoch 67, iter 2800, loss: 3.004213, top_1: 0.533672, top_k: 0.762852, samples/s: 2835.614 1612019583.5475023
train: epoch 67, iter 2900, loss: 2.788536, top_1: 0.532930, top_k: 0.765156, samples/s: 2960.506 1612019592.1946104
train: epoch 67, iter 3000, loss: 2.918478, top_1: 0.543828, top_k: 0.768203, samples/s: 2925.298 1612019600.94593
train: epoch 67, iter 3100, loss: 3.002299, top_1: 0.534609, top_k: 0.766563, samples/s: 2980.334 1612019609.535492
train: epoch 67, iter 3200, loss: 3.126056, top_1: 0.535156, top_k: 0.766797, samples/s: 2988.237 1612019618.1024442
train: epoch 67, iter 3300, loss: 2.674527, top_1: 0.536445, top_k: 0.764023, samples/s: 2926.641 1612019626.8496451
train: epoch 67, iter 3400, loss: 2.785303, top_1: 0.533398, top_k: 0.764258, samples/s: 2837.673 1612019635.871131
train: epoch 67, iter 3500, loss: 2.928160, top_1: 0.535977, top_k: 0.765195, samples/s: 2993.124 1612019644.424058
train: epoch 67, iter 3600, loss: 2.904133, top_1: 0.535859, top_k: 0.767773, samples/s: 2934.226 1612019653.1487162
train: epoch 67, iter 3700, loss: 3.045590, top_1: 0.532383, top_k: 0.764570, samples/s: 2985.835 1612019661.7224329
train: epoch 67, iter 3800, loss: 3.020237, top_1: 0.529414, top_k: 0.764922, samples/s: 2935.708 1612019670.4426975
train: epoch 67, iter 3900, loss: 2.890363, top_1: 0.526602, top_k: 0.760234, samples/s: 2986.161 1612019679.015599
train: epoch 67, iter 4000, loss: 2.893541, top_1: 0.538242, top_k: 0.769531, samples/s: 2986.876 1612019687.5864823
train: epoch 67, iter 4100, loss: 2.882644, top_1: 0.530703, top_k: 0.758047, samples/s: 2882.959 1612019696.466235
train: epoch 67, iter 4200, loss: 2.996580, top_1: 0.533516, top_k: 0.768125, samples/s: 3016.162 1612019704.9537938
train: epoch 67, iter 4300, loss: 2.937649, top_1: 0.534766, top_k: 0.764805, samples/s: 2969.125 1612019713.576092
train: epoch 67, iter 4400, loss: 2.877289, top_1: 0.533359, top_k: 0.767930, samples/s: 2949.103 1612019722.2564712
train: epoch 67, iter 4500, loss: 2.882787, top_1: 0.536484, top_k: 0.768398, samples/s: 2973.854 1612019730.864928
train: epoch 67, iter 4600, loss: 2.784754, top_1: 0.533008, top_k: 0.763398, samples/s: 2960.146 1612019739.5130546
train: epoch 67, iter 4700, loss: 3.011478, top_1: 0.531133, top_k: 0.766445, samples/s: 2986.685 1612019748.0845122
train: epoch 67, iter 4800, loss: 2.892916, top_1: 0.534375, top_k: 0.763164, samples/s: 2999.731 1612019756.618548
train: epoch 67, iter 4900, loss: 3.047975, top_1: 0.532734, top_k: 0.760508, samples/s: 2937.442 1612019765.3335626
train: epoch 67, iter 5000, loss: 2.783496, top_1: 0.536250, top_k: 0.768242, samples/s: 2992.652 1612019773.8878648
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_67.
validation: epoch 67, iter 195, top_1: 0.582913, top_k: 0.820373, samples/s: 2908.025 1612019791.3351378
train: epoch 68, iter 100, loss: 2.873598, top_1: 0.542070, top_k: 0.772539, samples/s: 2893.646 1612019816.4372373
train: epoch 68, iter 200, loss: 2.940999, top_1: 0.537344, top_k: 0.773320, samples/s: 3017.423 1612019824.9213347
train: epoch 68, iter 300, loss: 2.913910, top_1: 0.543945, top_k: 0.774609, samples/s: 2986.858 1612019833.4921875
train: epoch 68, iter 400, loss: 2.802470, top_1: 0.540195, top_k: 0.768516, samples/s: 2988.642 1612019842.0580015
train: epoch 68, iter 500, loss: 2.979017, top_1: 0.545469, top_k: 0.772500, samples/s: 2931.263 1612019850.7912242
train: epoch 68, iter 600, loss: 3.107096, top_1: 0.546328, top_k: 0.776172, samples/s: 3026.095 1612019859.2510114
train: epoch 68, iter 700, loss: 3.103700, top_1: 0.541562, top_k: 0.769648, samples/s: 3006.864 1612019867.7648818
train: epoch 68, iter 800, loss: 2.950330, top_1: 0.541523, top_k: 0.768008, samples/s: 2985.481 1612019876.3396552
train: epoch 68, iter 900, loss: 2.756094, top_1: 0.543516, top_k: 0.770938, samples/s: 2856.019 1612019885.3032422
train: epoch 68, iter 1000, loss: 2.949567, top_1: 0.534141, top_k: 0.766719, samples/s: 2978.652 1612019893.8977134
train: epoch 68, iter 1100, loss: 2.872913, top_1: 0.542500, top_k: 0.771289, samples/s: 2945.087 1612019902.5901184
train: epoch 68, iter 1200, loss: 2.923579, top_1: 0.531523, top_k: 0.765742, samples/s: 2966.716 1612019911.2193382
train: epoch 68, iter 1300, loss: 2.754744, top_1: 0.536719, top_k: 0.769180, samples/s: 2959.198 1612019919.8702366
train: epoch 68, iter 1400, loss: 2.967341, top_1: 0.535703, top_k: 0.764687, samples/s: 2999.683 1612019928.4045784
train: epoch 68, iter 1500, loss: 2.778994, top_1: 0.544297, top_k: 0.769687, samples/s: 2941.536 1612019937.1074557
train: epoch 68, iter 1600, loss: 2.844831, top_1: 0.539141, top_k: 0.769219, samples/s: 2959.135 1612019945.7585182
train: epoch 68, iter 1700, loss: 2.940377, top_1: 0.539023, top_k: 0.768555, samples/s: 3004.144 1612019954.2801259
train: epoch 68, iter 1800, loss: 3.078380, top_1: 0.538320, top_k: 0.767734, samples/s: 2990.731 1612019962.8399053
train: epoch 68, iter 1900, loss: 2.937121, top_1: 0.537500, top_k: 0.766406, samples/s: 3003.305 1612019971.3637955
train: epoch 68, iter 2000, loss: 2.808341, top_1: 0.537148, top_k: 0.766719, samples/s: 3009.517 1612019979.8702185
train: epoch 68, iter 2100, loss: 2.914093, top_1: 0.532500, top_k: 0.765195, samples/s: 2943.614 1612019988.567086
train: epoch 68, iter 2200, loss: 2.991839, top_1: 0.535625, top_k: 0.769102, samples/s: 2935.344 1612019997.2882912
train: epoch 68, iter 2300, loss: 3.018612, top_1: 0.535312, top_k: 0.767852, samples/s: 2981.294 1612020005.8752415
train: epoch 68, iter 2400, loss: 2.998121, top_1: 0.535742, top_k: 0.767422, samples/s: 2950.872 1612020014.5505805
train: epoch 68, iter 2500, loss: 3.026155, top_1: 0.531992, top_k: 0.765156, samples/s: 3022.494 1612020023.0204234
train: epoch 68, iter 2600, loss: 2.929440, top_1: 0.539336, top_k: 0.767422, samples/s: 2886.899 1612020031.888138
train: epoch 68, iter 2700, loss: 2.686036, top_1: 0.533633, top_k: 0.764258, samples/s: 3014.556 1612020040.3802748
train: epoch 68, iter 2800, loss: 2.944483, top_1: 0.537930, top_k: 0.771211, samples/s: 2878.041 1612020049.275177
train: epoch 68, iter 2900, loss: 2.771797, top_1: 0.534297, top_k: 0.764375, samples/s: 3060.871 1612020057.6387825
train: epoch 68, iter 3000, loss: 2.918017, top_1: 0.539609, top_k: 0.772656, samples/s: 2930.484 1612020066.3744996
train: epoch 68, iter 3100, loss: 2.910265, top_1: 0.533203, top_k: 0.765859, samples/s: 2933.842 1612020075.100257
train: epoch 68, iter 3200, loss: 2.792748, top_1: 0.539141, top_k: 0.770391, samples/s: 2979.737 1612020083.6916156
train: epoch 68, iter 3300, loss: 2.950773, top_1: 0.534219, top_k: 0.768711, samples/s: 2997.752 1612020092.2313008
train: epoch 68, iter 3400, loss: 2.934712, top_1: 0.536758, top_k: 0.765547, samples/s: 2952.750 1612020100.9013693
train: epoch 68, iter 3500, loss: 2.841912, top_1: 0.533125, top_k: 0.767344, samples/s: 2932.817 1612020109.6300385
train: epoch 68, iter 3600, loss: 3.095848, top_1: 0.538945, top_k: 0.766445, samples/s: 3001.523 1612020118.15905
train: epoch 68, iter 3700, loss: 2.958237, top_1: 0.537539, top_k: 0.767305, samples/s: 3009.795 1612020126.664683
train: epoch 68, iter 3800, loss: 3.126061, top_1: 0.531406, top_k: 0.766211, samples/s: 2981.772 1612020135.2501163
train: epoch 68, iter 3900, loss: 2.826591, top_1: 0.537461, top_k: 0.767656, samples/s: 2981.440 1612020143.8365684
train: epoch 68, iter 4000, loss: 2.767324, top_1: 0.533750, top_k: 0.767305, samples/s: 2966.429 1612020152.4664292
train: epoch 68, iter 4100, loss: 2.851972, top_1: 0.527656, top_k: 0.762266, samples/s: 2991.791 1612020161.0232217
train: epoch 68, iter 4200, loss: 2.753923, top_1: 0.533594, top_k: 0.765547, samples/s: 2972.302 1612020169.6361485
train: epoch 68, iter 4300, loss: 2.876477, top_1: 0.539609, top_k: 0.771094, samples/s: 2904.385 1612020178.450392
train: epoch 68, iter 4400, loss: 2.976549, top_1: 0.532070, top_k: 0.764062, samples/s: 2951.237 1612020187.124737
train: epoch 68, iter 4500, loss: 3.085978, top_1: 0.534883, top_k: 0.765625, samples/s: 2882.333 1612020196.0063784
train: epoch 68, iter 4600, loss: 3.002161, top_1: 0.536523, top_k: 0.764258, samples/s: 2978.224 1612020204.6021175
train: epoch 68, iter 4700, loss: 3.107930, top_1: 0.539453, top_k: 0.767578, samples/s: 2964.473 1612020213.2377264
train: epoch 68, iter 4800, loss: 2.806123, top_1: 0.532227, top_k: 0.764141, samples/s: 2900.974 1612020222.0623493
train: epoch 68, iter 4900, loss: 2.980221, top_1: 0.535000, top_k: 0.767500, samples/s: 2925.062 1612020230.8142562
train: epoch 68, iter 5000, loss: 3.110041, top_1: 0.536289, top_k: 0.764922, samples/s: 2986.142 1612020239.3871946
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_68.
validation: epoch 68, iter 195, top_1: 0.581571, top_k: 0.817127, samples/s: 2921.673 1612020256.7020838
train: epoch 69, iter 100, loss: 2.965271, top_1: 0.552344, top_k: 0.780352, samples/s: 2944.571 1612020281.8371136
train: epoch 69, iter 200, loss: 2.830028, top_1: 0.545469, top_k: 0.774258, samples/s: 3012.659 1612020290.3349695
train: epoch 69, iter 300, loss: 2.889482, top_1: 0.545391, top_k: 0.772383, samples/s: 2931.603 1612020299.0670936
train: epoch 69, iter 400, loss: 3.010797, top_1: 0.544570, top_k: 0.775859, samples/s: 2974.575 1612020307.6732962
train: epoch 69, iter 500, loss: 3.021082, top_1: 0.540430, top_k: 0.773398, samples/s: 3005.423 1612020316.1916761
train: epoch 69, iter 600, loss: 2.896288, top_1: 0.541289, top_k: 0.772734, samples/s: 2982.738 1612020324.7739239
train: epoch 69, iter 700, loss: 2.928137, top_1: 0.539297, top_k: 0.767969, samples/s: 3015.756 1612020333.2631009
train: epoch 69, iter 800, loss: 2.946036, top_1: 0.544141, top_k: 0.772031, samples/s: 2915.859 1612020342.0422623
train: epoch 69, iter 900, loss: 2.964731, top_1: 0.538867, top_k: 0.772656, samples/s: 3018.775 1612020350.5225382
train: epoch 69, iter 1000, loss: 3.000489, top_1: 0.546680, top_k: 0.770312, samples/s: 2965.224 1612020359.1559365
train: epoch 69, iter 1100, loss: 3.028701, top_1: 0.536094, top_k: 0.768086, samples/s: 3004.497 1612020367.6765335
train: epoch 69, iter 1200, loss: 3.022170, top_1: 0.533281, top_k: 0.768281, samples/s: 2936.266 1612020376.395036
train: epoch 69, iter 1300, loss: 2.935782, top_1: 0.540352, top_k: 0.772266, samples/s: 2942.659 1612020385.094651
train: epoch 69, iter 1400, loss: 3.170913, top_1: 0.538750, top_k: 0.767461, samples/s: 2974.918 1612020393.6999178
train: epoch 69, iter 1500, loss: 2.820888, top_1: 0.544805, top_k: 0.773711, samples/s: 2954.027 1612020402.3660975
train: epoch 69, iter 1600, loss: 3.085358, top_1: 0.531719, top_k: 0.766406, samples/s: 3015.379 1612020410.8559883
train: epoch 69, iter 1700, loss: 2.823298, top_1: 0.539375, top_k: 0.768711, samples/s: 2972.179 1612020419.4691494
train: epoch 69, iter 1800, loss: 3.011094, top_1: 0.535664, top_k: 0.767969, samples/s: 2895.842 1612020428.3093786
train: epoch 69, iter 1900, loss: 2.927205, top_1: 0.533750, top_k: 0.765469, samples/s: 2965.675 1612020436.941449
train: epoch 69, iter 2000, loss: 2.951577, top_1: 0.540195, top_k: 0.768437, samples/s: 2820.975 1612020446.0163894
train: epoch 69, iter 2100, loss: 2.974215, top_1: 0.537578, top_k: 0.766406, samples/s: 2948.882 1612020454.6975706
train: epoch 69, iter 2200, loss: 3.081312, top_1: 0.532422, top_k: 0.768789, samples/s: 2976.545 1612020463.2981517
train: epoch 69, iter 2300, loss: 3.050296, top_1: 0.532109, top_k: 0.764023, samples/s: 2938.490 1612020472.0101163
train: epoch 69, iter 2400, loss: 2.773091, top_1: 0.534727, top_k: 0.769414, samples/s: 2980.658 1612020480.5988486
train: epoch 69, iter 2500, loss: 2.690967, top_1: 0.539609, top_k: 0.768711, samples/s: 2925.442 1612020489.3497553
train: epoch 69, iter 2600, loss: 2.867062, top_1: 0.543672, top_k: 0.772969, samples/s: 2930.267 1612020498.0860841
train: epoch 69, iter 2700, loss: 2.961340, top_1: 0.535781, top_k: 0.767305, samples/s: 3003.013 1612020506.6107943
train: epoch 69, iter 2800, loss: 2.951807, top_1: 0.535703, top_k: 0.766484, samples/s: 2950.485 1612020515.2873201
train: epoch 69, iter 2900, loss: 2.874240, top_1: 0.537266, top_k: 0.768359, samples/s: 2943.165 1612020523.9854965
train: epoch 69, iter 3000, loss: 2.990901, top_1: 0.533945, top_k: 0.766016, samples/s: 2967.959 1612020532.6109188
train: epoch 69, iter 3100, loss: 3.025383, top_1: 0.531016, top_k: 0.763281, samples/s: 2967.045 1612020541.2390256
train: epoch 69, iter 3200, loss: 3.179127, top_1: 0.534258, top_k: 0.764219, samples/s: 2997.103 1612020549.7806125
train: epoch 69, iter 3300, loss: 3.091401, top_1: 0.529141, top_k: 0.761250, samples/s: 2975.691 1612020558.383709
train: epoch 69, iter 3400, loss: 3.143819, top_1: 0.538164, top_k: 0.769766, samples/s: 2961.077 1612020567.0291812
train: epoch 69, iter 3500, loss: 3.092569, top_1: 0.535820, top_k: 0.770820, samples/s: 2994.811 1612020575.5772448
train: epoch 69, iter 3600, loss: 2.901503, top_1: 0.536758, top_k: 0.768125, samples/s: 2975.704 1612020584.1802742
train: epoch 69, iter 3700, loss: 2.621786, top_1: 0.535937, top_k: 0.767656, samples/s: 2917.843 1612020592.9540348
train: epoch 69, iter 3800, loss: 2.977123, top_1: 0.536875, top_k: 0.765859, samples/s: 2987.177 1612020601.5239127
train: epoch 69, iter 3900, loss: 2.926780, top_1: 0.543984, top_k: 0.771523, samples/s: 2968.155 1612020610.1487298
train: epoch 69, iter 4000, loss: 2.805387, top_1: 0.536953, top_k: 0.768594, samples/s: 2941.653 1612020618.8514767
train: epoch 69, iter 4100, loss: 2.890008, top_1: 0.541484, top_k: 0.768125, samples/s: 2932.465 1612020627.5811825
train: epoch 69, iter 4200, loss: 2.707801, top_1: 0.534844, top_k: 0.766484, samples/s: 2924.020 1612020636.3363943
train: epoch 69, iter 4300, loss: 2.966396, top_1: 0.539297, top_k: 0.768164, samples/s: 2985.615 1612020644.9107554
train: epoch 69, iter 4400, loss: 2.925302, top_1: 0.539023, top_k: 0.769766, samples/s: 2968.784 1612020653.5337572
train: epoch 69, iter 4500, loss: 2.986840, top_1: 0.536563, top_k: 0.767852, samples/s: 3017.874 1612020662.0166118
train: epoch 69, iter 4600, loss: 2.924590, top_1: 0.534766, top_k: 0.765312, samples/s: 2997.268 1612020670.5578344
train: epoch 69, iter 4700, loss: 2.879637, top_1: 0.536953, top_k: 0.765117, samples/s: 2976.667 1612020679.157923
train: epoch 69, iter 4800, loss: 2.828676, top_1: 0.533281, top_k: 0.762461, samples/s: 2924.395 1612020687.911836
train: epoch 69, iter 4900, loss: 2.918682, top_1: 0.538359, top_k: 0.771641, samples/s: 3002.211 1612020696.438885
train: epoch 69, iter 5000, loss: 2.970842, top_1: 0.540586, top_k: 0.766211, samples/s: 3003.739 1612020704.9616199
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_69.
validation: epoch 69, iter 195, top_1: 0.582913, top_k: 0.819872, samples/s: 2977.579 1612020721.974758
train: epoch 70, iter 100, loss: 3.147591, top_1: 0.552266, top_k: 0.778906, samples/s: 2949.062 1612020747.2375379
train: epoch 70, iter 200, loss: 2.691789, top_1: 0.549219, top_k: 0.778281, samples/s: 2985.228 1612020755.8130138
train: epoch 70, iter 300, loss: 2.967683, top_1: 0.552344, top_k: 0.774922, samples/s: 2956.224 1612020764.472831
train: epoch 70, iter 400, loss: 3.010371, top_1: 0.547891, top_k: 0.775625, samples/s: 2959.904 1612020773.1215782
train: epoch 70, iter 500, loss: 2.892175, top_1: 0.539961, top_k: 0.768672, samples/s: 3010.065 1612020781.626367
train: epoch 70, iter 600, loss: 2.900090, top_1: 0.545898, top_k: 0.775469, samples/s: 2970.793 1612020790.2436244
train: epoch 70, iter 700, loss: 2.822586, top_1: 0.545312, top_k: 0.778320, samples/s: 3017.477 1612020798.7274964
train: epoch 70, iter 800, loss: 2.836489, top_1: 0.541875, top_k: 0.771172, samples/s: 2991.061 1612020807.2863808
train: epoch 70, iter 900, loss: 2.998270, top_1: 0.543633, top_k: 0.773594, samples/s: 2986.151 1612020815.8593009
train: epoch 70, iter 1000, loss: 2.811207, top_1: 0.542852, top_k: 0.772734, samples/s: 3000.892 1612020824.390077
train: epoch 70, iter 1100, loss: 2.841619, top_1: 0.541484, top_k: 0.773672, samples/s: 2958.907 1612020833.0418994
train: epoch 70, iter 1200, loss: 2.789886, top_1: 0.542500, top_k: 0.772031, samples/s: 3010.571 1612020841.5452585
train: epoch 70, iter 1300, loss: 2.980889, top_1: 0.543672, top_k: 0.772891, samples/s: 3001.260 1612020850.0750763
train: epoch 70, iter 1400, loss: 2.986540, top_1: 0.539141, top_k: 0.767227, samples/s: 2954.378 1612020858.7401602
train: epoch 70, iter 1500, loss: 2.752254, top_1: 0.537227, top_k: 0.770508, samples/s: 2954.251 1612020867.4057963
train: epoch 70, iter 1600, loss: 2.931539, top_1: 0.541992, top_k: 0.771602, samples/s: 2998.953 1612020875.9420187
train: epoch 70, iter 1700, loss: 2.968077, top_1: 0.539023, top_k: 0.767344, samples/s: 2922.410 1612020884.701842
train: epoch 70, iter 1800, loss: 3.139955, top_1: 0.542578, top_k: 0.771914, samples/s: 2919.418 1612020893.4706895
train: epoch 70, iter 1900, loss: 2.945404, top_1: 0.536953, top_k: 0.768086, samples/s: 2977.976 1612020902.067073
train: epoch 70, iter 2000, loss: 2.919120, top_1: 0.539805, top_k: 0.767539, samples/s: 2926.621 1612020910.814654
train: epoch 70, iter 2100, loss: 2.909120, top_1: 0.538672, top_k: 0.771367, samples/s: 2989.908 1612020919.3765454
train: epoch 70, iter 2200, loss: 2.957257, top_1: 0.544453, top_k: 0.776758, samples/s: 2989.781 1612020927.9390817
train: epoch 70, iter 2300, loss: 2.915202, top_1: 0.539453, top_k: 0.771094, samples/s: 2973.589 1612020936.5482657
train: epoch 70, iter 2400, loss: 2.964095, top_1: 0.537773, top_k: 0.770781, samples/s: 2990.986 1612020945.1072736
train: epoch 70, iter 2500, loss: 2.921552, top_1: 0.538164, top_k: 0.770352, samples/s: 2868.350 1612020954.0322113
train: epoch 70, iter 2600, loss: 2.765377, top_1: 0.543750, top_k: 0.772695, samples/s: 2949.822 1612020962.7107592
train: epoch 70, iter 2700, loss: 3.011490, top_1: 0.541719, top_k: 0.771875, samples/s: 2978.783 1612020971.3048317
train: epoch 70, iter 2800, loss: 2.749792, top_1: 0.539141, top_k: 0.767813, samples/s: 2974.308 1612020979.912
train: epoch 70, iter 2900, loss: 3.090741, top_1: 0.528594, top_k: 0.764336, samples/s: 2945.984 1612020988.6017256
train: epoch 70, iter 3000, loss: 3.013421, top_1: 0.531914, top_k: 0.763203, samples/s: 2875.823 1612020997.5036552
train: epoch 70, iter 3100, loss: 2.926707, top_1: 0.536445, top_k: 0.770391, samples/s: 3020.049 1612021005.9801779
train: epoch 70, iter 3200, loss: 3.021536, top_1: 0.537031, top_k: 0.767031, samples/s: 2994.575 1612021014.5289924
train: epoch 70, iter 3300, loss: 3.006894, top_1: 0.538438, top_k: 0.770352, samples/s: 2915.810 1612021023.3086586
train: epoch 70, iter 3400, loss: 2.924496, top_1: 0.536641, top_k: 0.765547, samples/s: 2990.286 1612021031.8697772
train: epoch 70, iter 3500, loss: 2.863735, top_1: 0.537148, top_k: 0.768086, samples/s: 2916.880 1612021040.6462939
train: epoch 70, iter 3600, loss: 2.955956, top_1: 0.537109, top_k: 0.771367, samples/s: 2940.978 1612021049.350805
train: epoch 70, iter 3700, loss: 2.828103, top_1: 0.537383, top_k: 0.768086, samples/s: 3018.236 1612021057.8326836
train: epoch 70, iter 3800, loss: 2.788114, top_1: 0.539297, top_k: 0.768711, samples/s: 2935.431 1612021066.553696
train: epoch 70, iter 3900, loss: 2.929178, top_1: 0.536016, top_k: 0.767227, samples/s: 3001.824 1612021075.0817633
train: epoch 70, iter 4000, loss: 2.860895, top_1: 0.542109, top_k: 0.768008, samples/s: 2923.011 1612021083.8398333
train: epoch 70, iter 4100, loss: 3.144477, top_1: 0.537813, top_k: 0.771250, samples/s: 2947.690 1612021092.524624
train: epoch 70, iter 4200, loss: 2.953520, top_1: 0.542305, top_k: 0.768672, samples/s: 2977.387 1612021101.1228652
train: epoch 70, iter 4300, loss: 3.227224, top_1: 0.533516, top_k: 0.767539, samples/s: 3018.646 1612021109.6034682
train: epoch 70, iter 4400, loss: 3.065404, top_1: 0.531797, top_k: 0.764023, samples/s: 2984.538 1612021118.1809359
train: epoch 70, iter 4500, loss: 2.798336, top_1: 0.533906, top_k: 0.769336, samples/s: 2971.465 1612021126.796321
train: epoch 70, iter 4600, loss: 2.952992, top_1: 0.540078, top_k: 0.768633, samples/s: 2989.819 1612021135.3585992
train: epoch 70, iter 4700, loss: 3.085379, top_1: 0.531094, top_k: 0.762578, samples/s: 2935.407 1612021144.0797107
train: epoch 70, iter 4800, loss: 2.969214, top_1: 0.541914, top_k: 0.772891, samples/s: 2992.165 1612021152.635383
train: epoch 70, iter 4900, loss: 2.897475, top_1: 0.535742, top_k: 0.765625, samples/s: 3007.436 1612021161.1476138
train: epoch 70, iter 5000, loss: 2.779982, top_1: 0.538477, top_k: 0.769453, samples/s: 2999.510 1612021169.6823685
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_70.
validation: epoch 70, iter 195, top_1: 0.577885, top_k: 0.814543, samples/s: 2900.080 1612021187.1922874
train: epoch 71, iter 100, loss: 2.870765, top_1: 0.552617, top_k: 0.781836, samples/s: 2964.874 1612021211.4584978
train: epoch 71, iter 200, loss: 2.762882, top_1: 0.546602, top_k: 0.773359, samples/s: 2964.397 1612021220.09431
train: epoch 71, iter 300, loss: 3.025027, top_1: 0.549336, top_k: 0.778320, samples/s: 2940.094 1612021228.8015058
train: epoch 71, iter 400, loss: 2.865299, top_1: 0.547109, top_k: 0.778086, samples/s: 2911.030 1612021237.5957475
train: epoch 71, iter 500, loss: 2.901786, top_1: 0.549961, top_k: 0.781953, samples/s: 2975.679 1612021246.1987758
train: epoch 71, iter 600, loss: 2.707077, top_1: 0.548789, top_k: 0.773047, samples/s: 3036.501 1612021254.6295524
train: epoch 71, iter 700, loss: 2.956059, top_1: 0.545977, top_k: 0.774219, samples/s: 2974.905 1612021263.234915
train: epoch 71, iter 800, loss: 3.132352, top_1: 0.540820, top_k: 0.770859, samples/s: 2980.662 1612021271.8235097
train: epoch 71, iter 900, loss: 2.892670, top_1: 0.542070, top_k: 0.771289, samples/s: 2999.668 1612021280.3578832
train: epoch 71, iter 1000, loss: 2.889544, top_1: 0.544102, top_k: 0.770078, samples/s: 2968.265 1612021288.9823382
train: epoch 71, iter 1100, loss: 2.890571, top_1: 0.538398, top_k: 0.772344, samples/s: 2973.932 1612021297.590481
train: epoch 71, iter 1200, loss: 3.087430, top_1: 0.551211, top_k: 0.775273, samples/s: 2999.209 1612021306.1261585
train: epoch 71, iter 1300, loss: 2.831935, top_1: 0.546992, top_k: 0.779141, samples/s: 2972.602 1612021314.738091
train: epoch 71, iter 1400, loss: 2.812246, top_1: 0.541953, top_k: 0.771406, samples/s: 2873.179 1612021323.648057
train: epoch 71, iter 1500, loss: 3.084658, top_1: 0.543984, top_k: 0.773047, samples/s: 2987.309 1612021332.2176256
train: epoch 71, iter 1600, loss: 2.830836, top_1: 0.539922, top_k: 0.767109, samples/s: 2920.780 1612021340.98241
train: epoch 71, iter 1700, loss: 2.790222, top_1: 0.548438, top_k: 0.775859, samples/s: 2987.340 1612021349.5519013
train: epoch 71, iter 1800, loss: 2.819754, top_1: 0.544102, top_k: 0.772617, samples/s: 2990.393 1612021358.1125948
train: epoch 71, iter 1900, loss: 2.789331, top_1: 0.547031, top_k: 0.770312, samples/s: 2997.033 1612021366.6544814
train: epoch 71, iter 2000, loss: 3.083698, top_1: 0.543828, top_k: 0.776094, samples/s: 3003.406 1612021375.1781483
train: epoch 71, iter 2100, loss: 2.594467, top_1: 0.542695, top_k: 0.771523, samples/s: 3005.930 1612021383.694585
train: epoch 71, iter 2200, loss: 2.880915, top_1: 0.543438, top_k: 0.770117, samples/s: 2925.171 1612021392.4461634
train: epoch 71, iter 2300, loss: 2.857976, top_1: 0.539297, top_k: 0.768633, samples/s: 2937.609 1612021401.1607792
train: epoch 71, iter 2400, loss: 2.850410, top_1: 0.538984, top_k: 0.765078, samples/s: 2998.983 1612021409.6970484
train: epoch 71, iter 2500, loss: 2.888481, top_1: 0.535156, top_k: 0.765391, samples/s: 2966.530 1612021418.3266284
train: epoch 71, iter 2600, loss: 3.112393, top_1: 0.545195, top_k: 0.772578, samples/s: 2953.185 1612021426.9953613
train: epoch 71, iter 2700, loss: 3.023772, top_1: 0.543672, top_k: 0.763984, samples/s: 2956.082 1612021435.6553555
train: epoch 71, iter 2800, loss: 2.869689, top_1: 0.539922, top_k: 0.769219, samples/s: 3025.165 1612021444.1177113
train: epoch 71, iter 2900, loss: 2.942380, top_1: 0.542031, top_k: 0.772109, samples/s: 2984.739 1612021452.6946764
train: epoch 71, iter 3000, loss: 2.820190, top_1: 0.544687, top_k: 0.772070, samples/s: 2980.797 1612021461.282978
train: epoch 71, iter 3100, loss: 3.005433, top_1: 0.533984, top_k: 0.766563, samples/s: 2997.959 1612021469.8221004
train: epoch 71, iter 3200, loss: 2.977064, top_1: 0.538633, top_k: 0.770039, samples/s: 2994.823 1612021478.3702245
train: epoch 71, iter 3300, loss: 2.956633, top_1: 0.538906, top_k: 0.774766, samples/s: 2948.734 1612021487.051948
train: epoch 71, iter 3400, loss: 2.964056, top_1: 0.539141, top_k: 0.767578, samples/s: 2954.275 1612021495.7172518
train: epoch 71, iter 3500, loss: 3.004475, top_1: 0.537969, top_k: 0.767734, samples/s: 2956.663 1612021504.3757694
train: epoch 71, iter 3600, loss: 2.967199, top_1: 0.534102, top_k: 0.770742, samples/s: 3005.481 1612021512.8939586
train: epoch 71, iter 3700, loss: 3.121885, top_1: 0.538320, top_k: 0.767109, samples/s: 2943.853 1612021521.5895596
train: epoch 71, iter 3800, loss: 2.972857, top_1: 0.538789, top_k: 0.772305, samples/s: 2968.439 1612021530.2137713
train: epoch 71, iter 3900, loss: 3.014472, top_1: 0.539297, top_k: 0.770039, samples/s: 2911.938 1612021539.0050268
train: epoch 71, iter 4000, loss: 2.988389, top_1: 0.540156, top_k: 0.773398, samples/s: 2976.431 1612021547.606366
train: epoch 71, iter 4100, loss: 3.056332, top_1: 0.537695, top_k: 0.770625, samples/s: 2976.001 1612021556.2080529
train: epoch 71, iter 4200, loss: 2.841653, top_1: 0.540195, top_k: 0.767695, samples/s: 2925.676 1612021564.9582014
train: epoch 71, iter 4300, loss: 2.963328, top_1: 0.540703, top_k: 0.770938, samples/s: 2997.705 1612021573.4983888
train: epoch 71, iter 4400, loss: 3.027663, top_1: 0.537070, top_k: 0.767344, samples/s: 3012.000 1612021581.997445
train: epoch 71, iter 4500, loss: 2.778809, top_1: 0.536523, top_k: 0.766719, samples/s: 2995.856 1612021590.5426762
train: epoch 71, iter 4600, loss: 2.864065, top_1: 0.536250, top_k: 0.765352, samples/s: 3010.528 1612021599.0462246
train: epoch 71, iter 4700, loss: 2.856241, top_1: 0.539336, top_k: 0.769727, samples/s: 3000.980 1612021607.5765998
train: epoch 71, iter 4800, loss: 3.002252, top_1: 0.535352, top_k: 0.765586, samples/s: 2970.183 1612021616.1955702
train: epoch 71, iter 4900, loss: 2.825894, top_1: 0.536445, top_k: 0.763867, samples/s: 3008.980 1612021624.7040658
train: epoch 71, iter 5000, loss: 2.930446, top_1: 0.540195, top_k: 0.768398, samples/s: 2985.172 1612021633.2792716
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_71.
validation: epoch 71, iter 195, top_1: 0.579107, top_k: 0.814884, samples/s: 3009.815 1612021650.1041703
train: epoch 72, iter 100, loss: 3.038477, top_1: 0.540391, top_k: 0.773945, samples/s: 2899.651 1612021674.5286274
train: epoch 72, iter 200, loss: 2.748205, top_1: 0.550234, top_k: 0.778945, samples/s: 3001.636 1612021683.057183
train: epoch 72, iter 300, loss: 2.888134, top_1: 0.547188, top_k: 0.779062, samples/s: 2940.479 1612021691.7633393
train: epoch 72, iter 400, loss: 2.971466, top_1: 0.550117, top_k: 0.773047, samples/s: 2993.408 1612021700.3154726
train: epoch 72, iter 500, loss: 2.668115, top_1: 0.545469, top_k: 0.775312, samples/s: 2988.529 1612021708.881453
train: epoch 72, iter 600, loss: 2.845804, top_1: 0.550859, top_k: 0.779297, samples/s: 3010.408 1612021717.3852556
train: epoch 72, iter 700, loss: 2.850359, top_1: 0.542539, top_k: 0.775664, samples/s: 2974.080 1612021725.9929621
train: epoch 72, iter 800, loss: 3.241971, top_1: 0.544687, top_k: 0.772266, samples/s: 2930.777 1612021734.7279143
train: epoch 72, iter 900, loss: 2.898587, top_1: 0.540703, top_k: 0.772305, samples/s: 2965.462 1612021743.3619437
train: epoch 72, iter 1000, loss: 2.935974, top_1: 0.549219, top_k: 0.774922, samples/s: 2996.676 1612021751.903379
train: epoch 72, iter 1100, loss: 2.954164, top_1: 0.544102, top_k: 0.778555, samples/s: 3019.086 1612021760.3832314
train: epoch 72, iter 1200, loss: 2.735104, top_1: 0.551836, top_k: 0.776641, samples/s: 2968.045 1612021769.007973
train: epoch 72, iter 1300, loss: 2.859553, top_1: 0.538281, top_k: 0.770352, samples/s: 2967.956 1612021777.6333592
train: epoch 72, iter 1400, loss: 2.927448, top_1: 0.549609, top_k: 0.778242, samples/s: 3018.302 1612021786.115065
train: epoch 72, iter 1500, loss: 2.868227, top_1: 0.548945, top_k: 0.774297, samples/s: 3000.554 1612021794.6468067
train: epoch 72, iter 1600, loss: 2.944620, top_1: 0.542930, top_k: 0.778359, samples/s: 2938.978 1612021803.3572605
train: epoch 72, iter 1700, loss: 3.035806, top_1: 0.544648, top_k: 0.774141, samples/s: 3008.614 1612021811.866106
train: epoch 72, iter 1800, loss: 3.028396, top_1: 0.540937, top_k: 0.772539, samples/s: 3016.514 1612021820.3528137
train: epoch 72, iter 1900, loss: 2.941907, top_1: 0.539883, top_k: 0.769141, samples/s: 2966.663 1612021828.9819973
train: epoch 72, iter 2000, loss: 2.953139, top_1: 0.545000, top_k: 0.773828, samples/s: 2925.182 1612021837.7335796
train: epoch 72, iter 2100, loss: 2.819078, top_1: 0.547031, top_k: 0.776992, samples/s: 2971.677 1612021846.3482609
train: epoch 72, iter 2200, loss: 2.815808, top_1: 0.541641, top_k: 0.773906, samples/s: 2903.207 1612021855.1661243
train: epoch 72, iter 2300, loss: 2.823246, top_1: 0.540977, top_k: 0.770469, samples/s: 2988.895 1612021863.7312183
train: epoch 72, iter 2400, loss: 3.024493, top_1: 0.545391, top_k: 0.772070, samples/s: 3006.810 1612021872.2451644
train: epoch 72, iter 2500, loss: 3.034688, top_1: 0.535742, top_k: 0.768750, samples/s: 2984.242 1612021880.823586
train: epoch 72, iter 2600, loss: 2.917209, top_1: 0.535234, top_k: 0.771445, samples/s: 2895.966 1612021889.6634066
train: epoch 72, iter 2700, loss: 3.025704, top_1: 0.543594, top_k: 0.773633, samples/s: 3001.681 1612021898.1920404
train: epoch 72, iter 2800, loss: 2.945406, top_1: 0.544414, top_k: 0.771875, samples/s: 2994.680 1612021906.7405586
train: epoch 72, iter 2900, loss: 2.739287, top_1: 0.540117, top_k: 0.766289, samples/s: 2937.194 1612021915.456255
train: epoch 72, iter 3000, loss: 3.018232, top_1: 0.542578, top_k: 0.770273, samples/s: 3009.930 1612021923.9614975
train: epoch 72, iter 3100, loss: 2.924123, top_1: 0.540586, top_k: 0.767930, samples/s: 2963.338 1612021932.6003819
train: epoch 72, iter 3200, loss: 2.926409, top_1: 0.535664, top_k: 0.768320, samples/s: 2988.777 1612021941.16575
train: epoch 72, iter 3300, loss: 2.884202, top_1: 0.543047, top_k: 0.773398, samples/s: 2985.526 1612021949.7405338
train: epoch 72, iter 3400, loss: 2.819844, top_1: 0.536875, top_k: 0.765586, samples/s: 2968.603 1612021958.364025
train: epoch 72, iter 3500, loss: 2.726748, top_1: 0.543359, top_k: 0.770781, samples/s: 2993.451 1612021966.9168475
train: epoch 72, iter 3600, loss: 2.860708, top_1: 0.541680, top_k: 0.770664, samples/s: 2994.554 1612021975.4648747
train: epoch 72, iter 3700, loss: 2.948455, top_1: 0.539336, top_k: 0.773984, samples/s: 2984.637 1612021984.0420923
train: epoch 72, iter 3800, loss: 2.776885, top_1: 0.542148, top_k: 0.776875, samples/s: 3022.447 1612021992.5126107
train: epoch 72, iter 3900, loss: 2.748390, top_1: 0.538945, top_k: 0.768789, samples/s: 2976.094 1612022001.1139534
train: epoch 72, iter 4000, loss: 3.098828, top_1: 0.536680, top_k: 0.767930, samples/s: 2955.769 1612022009.7749836
train: epoch 72, iter 4100, loss: 2.921431, top_1: 0.541719, top_k: 0.768711, samples/s: 2996.994 1612022018.316824
train: epoch 72, iter 4200, loss: 3.135179, top_1: 0.540586, top_k: 0.769141, samples/s: 2967.145 1612022026.9447286
train: epoch 72, iter 4300, loss: 3.041775, top_1: 0.543086, top_k: 0.768750, samples/s: 2953.756 1612022035.6117558
train: epoch 72, iter 4400, loss: 2.791507, top_1: 0.541172, top_k: 0.773594, samples/s: 2996.316 1612022044.1554852
train: epoch 72, iter 4500, loss: 2.793667, top_1: 0.540977, top_k: 0.772930, samples/s: 2957.577 1612022052.8113592
train: epoch 72, iter 4600, loss: 2.769444, top_1: 0.537617, top_k: 0.765273, samples/s: 2981.471 1612022061.3975139
train: epoch 72, iter 4700, loss: 2.842613, top_1: 0.538242, top_k: 0.769062, samples/s: 2910.753 1612022070.1926043
train: epoch 72, iter 4800, loss: 2.945587, top_1: 0.538711, top_k: 0.771406, samples/s: 2954.935 1612022078.8560348
train: epoch 72, iter 4900, loss: 2.975587, top_1: 0.538359, top_k: 0.763828, samples/s: 2983.674 1612022087.436102
train: epoch 72, iter 5000, loss: 2.946132, top_1: 0.546172, top_k: 0.773555, samples/s: 2999.879 1612022095.9698865
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_72.
validation: epoch 72, iter 195, top_1: 0.589143, top_k: 0.823458, samples/s: 2934.420 1612022113.244957
train: epoch 73, iter 100, loss: 3.048431, top_1: 0.553008, top_k: 0.780898, samples/s: 2833.777 1612022138.3217933
train: epoch 73, iter 200, loss: 2.815603, top_1: 0.545234, top_k: 0.771875, samples/s: 3022.370 1612022146.791893
train: epoch 73, iter 300, loss: 2.645043, top_1: 0.551758, top_k: 0.778906, samples/s: 2964.128 1612022155.4285033
train: epoch 73, iter 400, loss: 2.738113, top_1: 0.542695, top_k: 0.772148, samples/s: 2944.946 1612022164.1213636
train: epoch 73, iter 500, loss: 2.828954, top_1: 0.548984, top_k: 0.778242, samples/s: 2940.828 1612022172.8264887
train: epoch 73, iter 600, loss: 2.627674, top_1: 0.548633, top_k: 0.776094, samples/s: 3026.028 1612022181.286362
train: epoch 73, iter 700, loss: 2.952172, top_1: 0.543086, top_k: 0.774727, samples/s: 2948.556 1612022189.9686074
train: epoch 73, iter 800, loss: 2.883625, top_1: 0.548125, top_k: 0.778750, samples/s: 3015.471 1612022198.4582577
train: epoch 73, iter 900, loss: 2.889033, top_1: 0.550781, top_k: 0.779961, samples/s: 2998.198 1612022206.9966695
train: epoch 73, iter 1000, loss: 2.925540, top_1: 0.545781, top_k: 0.769609, samples/s: 3028.277 1612022215.4502327
train: epoch 73, iter 1100, loss: 2.859452, top_1: 0.544219, top_k: 0.771328, samples/s: 2987.748 1612022224.0185735
train: epoch 73, iter 1200, loss: 2.651573, top_1: 0.544336, top_k: 0.772852, samples/s: 2997.786 1612022232.558267
train: epoch 73, iter 1300, loss: 3.000540, top_1: 0.544141, top_k: 0.776406, samples/s: 2967.581 1612022241.184786
train: epoch 73, iter 1400, loss: 3.032959, top_1: 0.545000, top_k: 0.775117, samples/s: 2987.403 1612022249.7540836
train: epoch 73, iter 1500, loss: 2.902729, top_1: 0.548828, top_k: 0.773125, samples/s: 2934.871 1612022258.4767537
train: epoch 73, iter 1600, loss: 3.000851, top_1: 0.545078, top_k: 0.771953, samples/s: 2961.150 1612022267.1220994
train: epoch 73, iter 1700, loss: 2.980008, top_1: 0.546289, top_k: 0.776914, samples/s: 2970.580 1612022275.7399197
train: epoch 73, iter 1800, loss: 3.021752, top_1: 0.540312, top_k: 0.768633, samples/s: 2930.726 1612022284.4750798
train: epoch 73, iter 1900, loss: 2.893748, top_1: 0.544219, top_k: 0.772734, samples/s: 2897.686 1612022293.3095555
train: epoch 73, iter 2000, loss: 3.015628, top_1: 0.539648, top_k: 0.776367, samples/s: 2920.705 1612022302.0745769
train: epoch 73, iter 2100, loss: 2.895895, top_1: 0.547422, top_k: 0.773477, samples/s: 2975.413 1612022310.6784885
train: epoch 73, iter 2200, loss: 2.776453, top_1: 0.543633, top_k: 0.771719, samples/s: 2945.585 1612022319.369423
train: epoch 73, iter 2300, loss: 2.839242, top_1: 0.547969, top_k: 0.772305, samples/s: 2870.688 1612022328.2872105
train: epoch 73, iter 2400, loss: 2.881814, top_1: 0.540586, top_k: 0.772344, samples/s: 2942.482 1612022336.9872673
train: epoch 73, iter 2500, loss: 2.886763, top_1: 0.545508, top_k: 0.771523, samples/s: 2983.333 1612022345.5682685
train: epoch 73, iter 2600, loss: 2.905437, top_1: 0.546367, top_k: 0.773320, samples/s: 2964.999 1612022354.2023048
train: epoch 73, iter 2700, loss: 2.889496, top_1: 0.541914, top_k: 0.775078, samples/s: 2991.535 1612022362.7598946
train: epoch 73, iter 2800, loss: 2.936367, top_1: 0.543086, top_k: 0.774102, samples/s: 3008.968 1612022371.267811
train: epoch 73, iter 2900, loss: 2.658524, top_1: 0.541680, top_k: 0.770586, samples/s: 3002.451 1612022379.7940698
train: epoch 73, iter 3000, loss: 2.844812, top_1: 0.546289, top_k: 0.776367, samples/s: 2948.350 1612022388.4769073
train: epoch 73, iter 3100, loss: 2.797546, top_1: 0.538242, top_k: 0.773750, samples/s: 2948.956 1612022397.158029
train: epoch 73, iter 3200, loss: 2.909363, top_1: 0.545000, top_k: 0.772891, samples/s: 3008.225 1612022405.6679292
train: epoch 73, iter 3300, loss: 2.923221, top_1: 0.538633, top_k: 0.772109, samples/s: 2971.421 1612022414.2834566
train: epoch 73, iter 3400, loss: 2.981985, top_1: 0.538047, top_k: 0.771016, samples/s: 2979.533 1612022422.875304
train: epoch 73, iter 3500, loss: 2.844927, top_1: 0.541094, top_k: 0.771563, samples/s: 2964.934 1612022431.5096135
train: epoch 73, iter 3600, loss: 2.879673, top_1: 0.549648, top_k: 0.775742, samples/s: 3007.830 1612022440.0207472
train: epoch 73, iter 3700, loss: 3.033333, top_1: 0.545117, top_k: 0.768086, samples/s: 2984.386 1612022448.5986612
train: epoch 73, iter 3800, loss: 2.993231, top_1: 0.544961, top_k: 0.774336, samples/s: 3017.663 1612022457.0820062
train: epoch 73, iter 3900, loss: 2.821516, top_1: 0.542305, top_k: 0.771719, samples/s: 2987.322 1612022465.6516304
train: epoch 73, iter 4000, loss: 2.992262, top_1: 0.537539, top_k: 0.773555, samples/s: 2968.006 1612022474.2769299
train: epoch 73, iter 4100, loss: 2.791790, top_1: 0.540586, top_k: 0.767344, samples/s: 2955.807 1612022482.9378262
train: epoch 73, iter 4200, loss: 2.962461, top_1: 0.540977, top_k: 0.768242, samples/s: 3003.424 1612022491.461482
train: epoch 73, iter 4300, loss: 2.749555, top_1: 0.536836, top_k: 0.770156, samples/s: 2955.644 1612022500.1228192
train: epoch 73, iter 4400, loss: 2.903323, top_1: 0.543516, top_k: 0.772461, samples/s: 2985.033 1612022508.698934
train: epoch 73, iter 4500, loss: 3.058364, top_1: 0.545859, top_k: 0.772891, samples/s: 2975.181 1612022517.3033981
train: epoch 73, iter 4600, loss: 2.889210, top_1: 0.544648, top_k: 0.773906, samples/s: 3000.199 1612022525.8362877
train: epoch 73, iter 4700, loss: 3.100024, top_1: 0.544922, top_k: 0.772109, samples/s: 2994.599 1612022534.3849583
train: epoch 73, iter 4800, loss: 2.924671, top_1: 0.543477, top_k: 0.772070, samples/s: 2984.805 1612022542.962092
train: epoch 73, iter 4900, loss: 3.077573, top_1: 0.537148, top_k: 0.768125, samples/s: 2926.782 1612022551.7085588
train: epoch 73, iter 5000, loss: 2.863008, top_1: 0.541445, top_k: 0.768164, samples/s: 2907.274 1612022560.5144727
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_73.
validation: epoch 73, iter 195, top_1: 0.586458, top_k: 0.822035, samples/s: 2989.988 1612022577.3828716
train: epoch 74, iter 100, loss: 2.819197, top_1: 0.540742, top_k: 0.772500, samples/s: 2946.348 1612022601.9530177
train: epoch 74, iter 200, loss: 2.685576, top_1: 0.551680, top_k: 0.782148, samples/s: 2918.984 1612022610.723288
train: epoch 74, iter 300, loss: 2.936688, top_1: 0.550352, top_k: 0.779336, samples/s: 3002.741 1612022619.248784
train: epoch 74, iter 400, loss: 3.197352, top_1: 0.542891, top_k: 0.775078, samples/s: 2993.926 1612022627.7996464
train: epoch 74, iter 500, loss: 2.790926, top_1: 0.549961, top_k: 0.782344, samples/s: 2973.423 1612022636.4089873
train: epoch 74, iter 600, loss: 2.772103, top_1: 0.559336, top_k: 0.786602, samples/s: 2997.661 1612022644.9489334
train: epoch 74, iter 700, loss: 2.781039, top_1: 0.550156, top_k: 0.780195, samples/s: 3010.228 1612022653.453817
train: epoch 74, iter 800, loss: 2.944564, top_1: 0.555664, top_k: 0.779687, samples/s: 3012.638 1612022661.9508631
train: epoch 74, iter 900, loss: 2.964980, top_1: 0.551328, top_k: 0.777227, samples/s: 2984.301 1612022670.5291176
train: epoch 74, iter 1000, loss: 2.861433, top_1: 0.553594, top_k: 0.780273, samples/s: 2979.566 1612022679.120996
train: epoch 74, iter 1100, loss: 2.868393, top_1: 0.551133, top_k: 0.778242, samples/s: 2917.491 1612022687.8955863
train: epoch 74, iter 1200, loss: 3.020467, top_1: 0.544219, top_k: 0.776641, samples/s: 3013.633 1612022696.3902977
train: epoch 74, iter 1300, loss: 2.877679, top_1: 0.543633, top_k: 0.772930, samples/s: 2986.213 1612022704.9630616
train: epoch 74, iter 1400, loss: 2.866264, top_1: 0.550742, top_k: 0.777617, samples/s: 2969.912 1612022713.5828414
train: epoch 74, iter 1500, loss: 2.885897, top_1: 0.537500, top_k: 0.769531, samples/s: 3014.312 1612022722.0756419
train: epoch 74, iter 1600, loss: 2.865646, top_1: 0.551211, top_k: 0.775742, samples/s: 3002.024 1612022730.6032307
train: epoch 74, iter 1700, loss: 2.800540, top_1: 0.546055, top_k: 0.770547, samples/s: 2989.091 1612022739.16766
train: epoch 74, iter 1800, loss: 2.721619, top_1: 0.543477, top_k: 0.776211, samples/s: 2963.879 1612022747.8050928
train: epoch 74, iter 1900, loss: 3.036451, top_1: 0.541094, top_k: 0.772969, samples/s: 2966.600 1612022756.434471
train: epoch 74, iter 2000, loss: 3.009702, top_1: 0.548750, top_k: 0.772227, samples/s: 2968.693 1612022765.0578399
train: epoch 74, iter 2100, loss: 2.961317, top_1: 0.546953, top_k: 0.776094, samples/s: 2985.799 1612022773.6316667
train: epoch 74, iter 2200, loss: 2.985556, top_1: 0.552031, top_k: 0.781289, samples/s: 2897.569 1612022782.466666
train: epoch 74, iter 2300, loss: 2.832795, top_1: 0.547773, top_k: 0.775898, samples/s: 2939.634 1612022791.1752915
train: epoch 74, iter 2400, loss: 2.979617, top_1: 0.549805, top_k: 0.779648, samples/s: 2917.349 1612022799.9503856
train: epoch 74, iter 2500, loss: 2.867622, top_1: 0.549141, top_k: 0.779023, samples/s: 3000.222 1612022808.483128
train: epoch 74, iter 2600, loss: 3.194952, top_1: 0.548203, top_k: 0.779141, samples/s: 2997.664 1612022817.0230932
train: epoch 74, iter 2700, loss: 3.075518, top_1: 0.538789, top_k: 0.769492, samples/s: 2915.219 1612022825.804517
train: epoch 74, iter 2800, loss: 2.865308, top_1: 0.548164, top_k: 0.778125, samples/s: 2947.535 1612022834.4898112
train: epoch 74, iter 2900, loss: 2.782862, top_1: 0.542383, top_k: 0.773359, samples/s: 2940.991 1612022843.1943495
train: epoch 74, iter 3000, loss: 2.817672, top_1: 0.544570, top_k: 0.772773, samples/s: 2908.743 1612022851.9954035
train: epoch 74, iter 3100, loss: 3.006045, top_1: 0.546133, top_k: 0.771211, samples/s: 2980.588 1612022860.5842812
train: epoch 74, iter 3200, loss: 3.090567, top_1: 0.542109, top_k: 0.769336, samples/s: 2982.183 1612022869.1685643
train: epoch 74, iter 3300, loss: 2.876307, top_1: 0.543789, top_k: 0.771250, samples/s: 2972.099 1612022877.7820914
train: epoch 74, iter 3400, loss: 2.819209, top_1: 0.540781, top_k: 0.770703, samples/s: 2925.368 1612022886.5330698
train: epoch 74, iter 3500, loss: 2.844053, top_1: 0.544766, top_k: 0.774609, samples/s: 2969.736 1612022895.1533804
train: epoch 74, iter 3600, loss: 2.949902, top_1: 0.541133, top_k: 0.773164, samples/s: 2953.747 1612022903.8202548
train: epoch 74, iter 3700, loss: 2.858734, top_1: 0.548789, top_k: 0.777266, samples/s: 2930.640 1612022912.5556014
train: epoch 74, iter 3800, loss: 3.136507, top_1: 0.544492, top_k: 0.773086, samples/s: 2983.977 1612022921.1347442
train: epoch 74, iter 3900, loss: 2.692660, top_1: 0.549531, top_k: 0.778242, samples/s: 2934.458 1612022929.8586924
train: epoch 74, iter 4000, loss: 3.101318, top_1: 0.550781, top_k: 0.775039, samples/s: 2977.502 1612022938.456507
train: epoch 74, iter 4100, loss: 3.120329, top_1: 0.536055, top_k: 0.771250, samples/s: 3018.207 1612022946.9383566
train: epoch 74, iter 4200, loss: 2.742252, top_1: 0.544258, top_k: 0.771953, samples/s: 2966.767 1612022955.567372
train: epoch 74, iter 4300, loss: 2.877187, top_1: 0.541133, top_k: 0.767539, samples/s: 3006.291 1612022964.0827866
train: epoch 74, iter 4400, loss: 2.804090, top_1: 0.542891, top_k: 0.774883, samples/s: 2987.633 1612022972.6513896
train: epoch 74, iter 4500, loss: 2.744501, top_1: 0.550898, top_k: 0.779023, samples/s: 3009.167 1612022981.1587362
train: epoch 74, iter 4600, loss: 3.046482, top_1: 0.544492, top_k: 0.768750, samples/s: 2978.762 1612022989.7529209
train: epoch 74, iter 4700, loss: 2.915496, top_1: 0.544531, top_k: 0.774375, samples/s: 2970.442 1612022998.3711503
train: epoch 74, iter 4800, loss: 2.688804, top_1: 0.545937, top_k: 0.773086, samples/s: 2984.710 1612023006.9482076
train: epoch 74, iter 4900, loss: 3.011942, top_1: 0.545273, top_k: 0.776523, samples/s: 3003.247 1612023015.4722683
train: epoch 74, iter 5000, loss: 2.915394, top_1: 0.542148, top_k: 0.772734, samples/s: 2967.280 1612023024.0997515
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_74.
validation: epoch 74, iter 195, top_1: 0.583774, top_k: 0.819351, samples/s: 2904.314 1612023041.5513988
train: epoch 75, iter 100, loss: 3.003155, top_1: 0.550625, top_k: 0.776289, samples/s: 2910.886 1612023066.2500916
train: epoch 75, iter 200, loss: 2.838973, top_1: 0.549570, top_k: 0.781563, samples/s: 2896.373 1612023075.0887034
train: epoch 75, iter 300, loss: 2.703715, top_1: 0.547734, top_k: 0.780352, samples/s: 3026.517 1612023083.5473049
train: epoch 75, iter 400, loss: 2.868582, top_1: 0.555937, top_k: 0.783633, samples/s: 2917.422 1612023092.322221
train: epoch 75, iter 500, loss: 2.718449, top_1: 0.547539, top_k: 0.775195, samples/s: 2982.568 1612023100.9055965
train: epoch 75, iter 600, loss: 2.807858, top_1: 0.548398, top_k: 0.780898, samples/s: 2986.129 1612023109.4782622
train: epoch 75, iter 700, loss: 3.136172, top_1: 0.549609, top_k: 0.775625, samples/s: 2996.041 1612023118.0228612
train: epoch 75, iter 800, loss: 2.933295, top_1: 0.552734, top_k: 0.782656, samples/s: 3009.768 1612023126.5285614
train: epoch 75, iter 900, loss: 3.152709, top_1: 0.551719, top_k: 0.783008, samples/s: 2943.648 1612023135.225292
train: epoch 75, iter 1000, loss: 2.921635, top_1: 0.549492, top_k: 0.778242, samples/s: 2976.022 1612023143.8274076
train: epoch 75, iter 1100, loss: 2.770800, top_1: 0.546133, top_k: 0.777617, samples/s: 2841.992 1612023152.8350852
train: epoch 75, iter 1200, loss: 2.976690, top_1: 0.547461, top_k: 0.775742, samples/s: 3003.393 1612023161.358733
train: epoch 75, iter 1300, loss: 2.904464, top_1: 0.546758, top_k: 0.774375, samples/s: 2970.880 1612023169.975706
train: epoch 75, iter 1400, loss: 2.739810, top_1: 0.555977, top_k: 0.784102, samples/s: 3003.987 1612023178.497715
train: epoch 75, iter 1500, loss: 2.922211, top_1: 0.550625, top_k: 0.778594, samples/s: 2889.416 1612023187.357737
train: epoch 75, iter 1600, loss: 2.690597, top_1: 0.546758, top_k: 0.779648, samples/s: 2982.564 1612023195.9408524
train: epoch 75, iter 1700, loss: 2.822556, top_1: 0.548203, top_k: 0.777344, samples/s: 2987.738 1612023204.509254
train: epoch 75, iter 1800, loss: 2.789665, top_1: 0.548281, top_k: 0.781328, samples/s: 3000.392 1612023213.0414283
train: epoch 75, iter 1900, loss: 2.927309, top_1: 0.550391, top_k: 0.778164, samples/s: 2984.031 1612023221.6204364
train: epoch 75, iter 2000, loss: 2.988348, top_1: 0.545937, top_k: 0.774180, samples/s: 2994.498 1612023230.1694105
train: epoch 75, iter 2100, loss: 2.892664, top_1: 0.542422, top_k: 0.771016, samples/s: 2998.091 1612023238.7082253
train: epoch 75, iter 2200, loss: 2.933693, top_1: 0.549453, top_k: 0.777266, samples/s: 2894.697 1612023247.5519714
train: epoch 75, iter 2300, loss: 2.784939, top_1: 0.544805, top_k: 0.773320, samples/s: 3001.303 1612023256.0815578
train: epoch 75, iter 2400, loss: 2.910323, top_1: 0.548203, top_k: 0.776172, samples/s: 2880.193 1612023264.9700067
train: epoch 75, iter 2500, loss: 2.746721, top_1: 0.549063, top_k: 0.775547, samples/s: 2997.174 1612023273.511282
train: epoch 75, iter 2600, loss: 2.805874, top_1: 0.546250, top_k: 0.775547, samples/s: 2973.290 1612023282.1212983
train: epoch 75, iter 2700, loss: 3.007011, top_1: 0.546914, top_k: 0.780508, samples/s: 2979.878 1612023290.7122927
train: epoch 75, iter 2800, loss: 2.908301, top_1: 0.549531, top_k: 0.777148, samples/s: 3030.707 1612023299.1591027
train: epoch 75, iter 2900, loss: 2.754738, top_1: 0.541992, top_k: 0.772422, samples/s: 3013.829 1612023307.6532261
train: epoch 75, iter 3000, loss: 2.829061, top_1: 0.544687, top_k: 0.772969, samples/s: 2937.717 1612023316.3675392
train: epoch 75, iter 3100, loss: 2.716764, top_1: 0.548945, top_k: 0.778125, samples/s: 2988.211 1612023324.93452
train: epoch 75, iter 3200, loss: 3.034744, top_1: 0.542266, top_k: 0.772461, samples/s: 3007.665 1612023333.4461324
train: epoch 75, iter 3300, loss: 2.946283, top_1: 0.548320, top_k: 0.778750, samples/s: 2995.953 1612023341.9909692
train: epoch 75, iter 3400, loss: 2.828280, top_1: 0.548945, top_k: 0.777383, samples/s: 3001.294 1612023350.520646
train: epoch 75, iter 3500, loss: 2.882204, top_1: 0.543477, top_k: 0.776719, samples/s: 2908.758 1612023359.321691
train: epoch 75, iter 3600, loss: 2.746191, top_1: 0.547695, top_k: 0.776328, samples/s: 2999.759 1612023367.855611
train: epoch 75, iter 3700, loss: 2.806302, top_1: 0.546797, top_k: 0.776680, samples/s: 2956.158 1612023376.515546
train: epoch 75, iter 3800, loss: 2.875474, top_1: 0.545508, top_k: 0.773672, samples/s: 3009.224 1612023385.0228047
train: epoch 75, iter 3900, loss: 2.971790, top_1: 0.545664, top_k: 0.776172, samples/s: 2943.366 1612023393.721678
train: epoch 75, iter 4000, loss: 2.838588, top_1: 0.548867, top_k: 0.777422, samples/s: 2949.653 1612023402.399228
train: epoch 75, iter 4100, loss: 3.083277, top_1: 0.541289, top_k: 0.768555, samples/s: 3026.902 1612023410.8573399
train: epoch 75, iter 4200, loss: 2.954276, top_1: 0.548125, top_k: 0.776836, samples/s: 2936.361 1612023419.5750256
train: epoch 75, iter 4300, loss: 3.120868, top_1: 0.546484, top_k: 0.770430, samples/s: 2953.222 1612023428.2434897
train: epoch 75, iter 4400, loss: 2.786374, top_1: 0.543594, top_k: 0.772891, samples/s: 2921.903 1612023437.004902
train: epoch 75, iter 4500, loss: 2.913449, top_1: 0.546562, top_k: 0.774961, samples/s: 3037.916 1612023445.43173
train: epoch 75, iter 4600, loss: 2.785931, top_1: 0.545859, top_k: 0.774258, samples/s: 2979.558 1612023454.0236082
train: epoch 75, iter 4700, loss: 2.888944, top_1: 0.542266, top_k: 0.774258, samples/s: 2949.722 1612023462.7024982
train: epoch 75, iter 4800, loss: 2.761237, top_1: 0.545781, top_k: 0.776172, samples/s: 2957.511 1612023471.358315
train: epoch 75, iter 4900, loss: 2.914598, top_1: 0.540273, top_k: 0.773945, samples/s: 3022.774 1612023479.8286827
train: epoch 75, iter 5000, loss: 2.823808, top_1: 0.544336, top_k: 0.770273, samples/s: 2960.758 1612023488.4739285
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_75.
validation: epoch 75, iter 195, top_1: 0.585737, top_k: 0.820813, samples/s: 2945.394 1612023505.6977506
train: epoch 76, iter 100, loss: 2.742698, top_1: 0.558672, top_k: 0.784687, samples/s: 2946.016 1612023530.084006
train: epoch 76, iter 200, loss: 2.952982, top_1: 0.553789, top_k: 0.780352, samples/s: 2973.383 1612023538.6937861
train: epoch 76, iter 300, loss: 2.953981, top_1: 0.551445, top_k: 0.779453, samples/s: 2985.278 1612023547.2691538
train: epoch 76, iter 400, loss: 2.767811, top_1: 0.554961, top_k: 0.782070, samples/s: 2911.751 1612023556.0610898
train: epoch 76, iter 500, loss: 2.995553, top_1: 0.556797, top_k: 0.780273, samples/s: 2974.651 1612023564.6675024
train: epoch 76, iter 600, loss: 2.914841, top_1: 0.553047, top_k: 0.778711, samples/s: 3019.122 1612023573.1465886
train: epoch 76, iter 700, loss: 2.804614, top_1: 0.549531, top_k: 0.782266, samples/s: 2965.403 1612023581.7793167
train: epoch 76, iter 800, loss: 3.055604, top_1: 0.547969, top_k: 0.777266, samples/s: 2999.586 1612023590.313784
train: epoch 76, iter 900, loss: 2.988980, top_1: 0.554688, top_k: 0.780742, samples/s: 2957.652 1612023598.9693422
train: epoch 76, iter 1000, loss: 2.898299, top_1: 0.549336, top_k: 0.776641, samples/s: 3015.023 1612023607.4601614
train: epoch 76, iter 1100, loss: 2.878641, top_1: 0.547422, top_k: 0.774102, samples/s: 2923.886 1612023616.2156367
train: epoch 76, iter 1200, loss: 3.113760, top_1: 0.553086, top_k: 0.778750, samples/s: 2949.063 1612023624.89648
train: epoch 76, iter 1300, loss: 2.756241, top_1: 0.546328, top_k: 0.777930, samples/s: 2951.646 1612023633.569506
train: epoch 76, iter 1400, loss: 2.864659, top_1: 0.547383, top_k: 0.776875, samples/s: 3000.129 1612023642.1024551
train: epoch 76, iter 1500, loss: 2.764630, top_1: 0.552656, top_k: 0.779570, samples/s: 2991.658 1612023650.659575
train: epoch 76, iter 1600, loss: 3.012985, top_1: 0.550625, top_k: 0.780312, samples/s: 2954.752 1612023659.323636
train: epoch 76, iter 1700, loss: 2.869449, top_1: 0.550039, top_k: 0.778555, samples/s: 2964.935 1612023667.9578753
train: epoch 76, iter 1800, loss: 2.931726, top_1: 0.547617, top_k: 0.777344, samples/s: 2955.493 1612023676.6197796
train: epoch 76, iter 1900, loss: 2.895823, top_1: 0.550664, top_k: 0.778477, samples/s: 2952.033 1612023685.2917438
train: epoch 76, iter 2000, loss: 2.875082, top_1: 0.551914, top_k: 0.781250, samples/s: 2981.325 1612023693.8785686
train: epoch 76, iter 2100, loss: 2.961706, top_1: 0.553008, top_k: 0.773828, samples/s: 2920.701 1612023702.6435232
train: epoch 76, iter 2200, loss: 2.817383, top_1: 0.544570, top_k: 0.773320, samples/s: 2983.806 1612023711.2230873
train: epoch 76, iter 2300, loss: 2.790213, top_1: 0.550586, top_k: 0.776992, samples/s: 2978.191 1612023719.8189352
train: epoch 76, iter 2400, loss: 2.962642, top_1: 0.548477, top_k: 0.775781, samples/s: 2936.468 1612023728.5368943
train: epoch 76, iter 2500, loss: 2.854297, top_1: 0.546680, top_k: 0.774062, samples/s: 2932.279 1612023737.2673168
train: epoch 76, iter 2600, loss: 2.931183, top_1: 0.548945, top_k: 0.777773, samples/s: 2964.973 1612023745.9015331
train: epoch 76, iter 2700, loss: 2.909580, top_1: 0.549570, top_k: 0.777578, samples/s: 2981.795 1612023754.486923
train: epoch 76, iter 2800, loss: 3.024258, top_1: 0.550117, top_k: 0.777930, samples/s: 2961.511 1612023763.131111
train: epoch 76, iter 2900, loss: 2.779213, top_1: 0.557187, top_k: 0.779297, samples/s: 2987.462 1612023771.700319
train: epoch 76, iter 3000, loss: 3.071900, top_1: 0.551797, top_k: 0.777773, samples/s: 2980.324 1612023780.2901642
train: epoch 76, iter 3100, loss: 3.197468, top_1: 0.546797, top_k: 0.774727, samples/s: 3002.756 1612023788.8153737
train: epoch 76, iter 3200, loss: 3.038469, top_1: 0.547305, top_k: 0.774414, samples/s: 2962.576 1612023797.4566298
train: epoch 76, iter 3300, loss: 2.893707, top_1: 0.545039, top_k: 0.773398, samples/s: 2965.884 1612023806.0881202
train: epoch 76, iter 3400, loss: 2.877619, top_1: 0.547422, top_k: 0.773867, samples/s: 2961.664 1612023814.7319286
train: epoch 76, iter 3500, loss: 2.873098, top_1: 0.551602, top_k: 0.779141, samples/s: 2936.621 1612023823.4494374
train: epoch 76, iter 3600, loss: 2.723256, top_1: 0.543516, top_k: 0.770664, samples/s: 2990.520 1612023832.0097296
train: epoch 76, iter 3700, loss: 2.790859, top_1: 0.546016, top_k: 0.776719, samples/s: 2988.633 1612023840.5755265
train: epoch 76, iter 3800, loss: 2.801932, top_1: 0.549453, top_k: 0.776641, samples/s: 3015.416 1612023849.0653148
train: epoch 76, iter 3900, loss: 3.002128, top_1: 0.549766, top_k: 0.771719, samples/s: 2958.747 1612023857.7175488
train: epoch 76, iter 4000, loss: 2.959851, top_1: 0.547188, top_k: 0.776016, samples/s: 2963.872 1612023866.3550375
train: epoch 76, iter 4100, loss: 2.777678, top_1: 0.546445, top_k: 0.774844, samples/s: 2958.097 1612023875.009094
train: epoch 76, iter 4200, loss: 2.962893, top_1: 0.547813, top_k: 0.776680, samples/s: 2983.684 1612023883.589092
train: epoch 76, iter 4300, loss: 3.077206, top_1: 0.547188, top_k: 0.775312, samples/s: 3001.659 1612023892.1177485
train: epoch 76, iter 4400, loss: 2.688848, top_1: 0.551602, top_k: 0.775664, samples/s: 2952.078 1612023900.789609
train: epoch 76, iter 4500, loss: 2.927656, top_1: 0.548320, top_k: 0.773477, samples/s: 2984.033 1612023909.3685837
train: epoch 76, iter 4600, loss: 3.102068, top_1: 0.548750, top_k: 0.777344, samples/s: 2978.693 1612023917.962894
train: epoch 76, iter 4700, loss: 2.822104, top_1: 0.545742, top_k: 0.774375, samples/s: 2969.090 1612023926.585183
train: epoch 76, iter 4800, loss: 2.783868, top_1: 0.549805, top_k: 0.775156, samples/s: 2984.688 1612023935.1623316
train: epoch 76, iter 4900, loss: 2.982746, top_1: 0.546172, top_k: 0.774453, samples/s: 2937.574 1612023943.8768833
train: epoch 76, iter 5000, loss: 2.844830, top_1: 0.552891, top_k: 0.777695, samples/s: 2992.234 1612023952.4324453
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_76.
validation: epoch 76, iter 195, top_1: 0.590946, top_k: 0.826623, samples/s: 2879.185 1612023970.0370848
train: epoch 77, iter 100, loss: 2.938573, top_1: 0.555352, top_k: 0.782383, samples/s: 2949.948 1612023994.799117
train: epoch 77, iter 200, loss: 2.937406, top_1: 0.565117, top_k: 0.785000, samples/s: 2942.938 1612024003.4983568
train: epoch 77, iter 300, loss: 2.975129, top_1: 0.552031, top_k: 0.780469, samples/s: 2917.786 1612024012.2718024
train: epoch 77, iter 400, loss: 2.942222, top_1: 0.555039, top_k: 0.777852, samples/s: 2999.235 1612024020.8072317
train: epoch 77, iter 500, loss: 2.955380, top_1: 0.550859, top_k: 0.781563, samples/s: 2917.770 1612024029.5810094
train: epoch 77, iter 600, loss: 2.873741, top_1: 0.554141, top_k: 0.781484, samples/s: 2962.761 1612024038.2217116
train: epoch 77, iter 700, loss: 2.940139, top_1: 0.556797, top_k: 0.784102, samples/s: 3008.115 1612024046.7319133
train: epoch 77, iter 800, loss: 2.853691, top_1: 0.552656, top_k: 0.781094, samples/s: 3004.243 1612024055.253202
train: epoch 77, iter 900, loss: 3.026189, top_1: 0.552891, top_k: 0.779141, samples/s: 2952.343 1612024063.9242685
train: epoch 77, iter 1000, loss: 2.871683, top_1: 0.546445, top_k: 0.778477, samples/s: 3026.744 1612024072.3822138
train: epoch 77, iter 1100, loss: 2.658589, top_1: 0.558750, top_k: 0.784687, samples/s: 2981.162 1612024080.969465
train: epoch 77, iter 1200, loss: 3.020156, top_1: 0.553477, top_k: 0.778125, samples/s: 3009.316 1612024089.4763746
train: epoch 77, iter 1300, loss: 2.887486, top_1: 0.553281, top_k: 0.780664, samples/s: 2977.068 1612024098.0755475
train: epoch 77, iter 1400, loss: 2.743159, top_1: 0.554141, top_k: 0.779922, samples/s: 3005.083 1612024106.5944881
train: epoch 77, iter 1500, loss: 2.932290, top_1: 0.553281, top_k: 0.777773, samples/s: 2989.846 1612024115.1566975
train: epoch 77, iter 1600, loss: 2.773279, top_1: 0.548047, top_k: 0.780820, samples/s: 2996.352 1612024123.700334
train: epoch 77, iter 1700, loss: 2.781507, top_1: 0.547305, top_k: 0.776680, samples/s: 2989.962 1612024132.2625074
train: epoch 77, iter 1800, loss: 2.782921, top_1: 0.552070, top_k: 0.775547, samples/s: 2983.895 1612024140.8417563
train: epoch 77, iter 1900, loss: 2.673188, top_1: 0.548984, top_k: 0.780234, samples/s: 2934.364 1612024149.5659618
train: epoch 77, iter 2000, loss: 2.935226, top_1: 0.548984, top_k: 0.775508, samples/s: 2933.342 1612024158.2932427
train: epoch 77, iter 2100, loss: 2.993715, top_1: 0.552500, top_k: 0.780469, samples/s: 2978.295 1612024166.8898025
train: epoch 77, iter 2200, loss: 2.816922, top_1: 0.544648, top_k: 0.775000, samples/s: 2988.359 1612024175.455311
train: epoch 77, iter 2300, loss: 2.761012, top_1: 0.552109, top_k: 0.777578, samples/s: 2928.323 1612024184.197481
train: epoch 77, iter 2400, loss: 2.947822, top_1: 0.550078, top_k: 0.780586, samples/s: 2980.074 1612024192.7879968
train: epoch 77, iter 2500, loss: 2.746995, top_1: 0.550508, top_k: 0.775703, samples/s: 2959.522 1612024201.4379435
train: epoch 77, iter 2600, loss: 2.888959, top_1: 0.549805, top_k: 0.777148, samples/s: 2985.108 1612024210.0142257
train: epoch 77, iter 2700, loss: 2.852392, top_1: 0.548828, top_k: 0.777344, samples/s: 2981.347 1612024218.6007342
train: epoch 77, iter 2800, loss: 2.889420, top_1: 0.547188, top_k: 0.776133, samples/s: 2969.391 1612024227.2218843
train: epoch 77, iter 2900, loss: 2.984354, top_1: 0.549609, top_k: 0.777813, samples/s: 2975.292 1612024235.8260908
train: epoch 77, iter 3000, loss: 2.941955, top_1: 0.553750, top_k: 0.777266, samples/s: 3019.886 1612024244.3031943
train: epoch 77, iter 3100, loss: 3.163171, top_1: 0.554180, top_k: 0.781289, samples/s: 2983.183 1612024252.884605
train: epoch 77, iter 3200, loss: 2.938441, top_1: 0.545937, top_k: 0.772617, samples/s: 2944.834 1612024261.5778663
train: epoch 77, iter 3300, loss: 2.975476, top_1: 0.544063, top_k: 0.773633, samples/s: 3019.344 1612024270.0566728
train: epoch 77, iter 3400, loss: 2.916403, top_1: 0.547500, top_k: 0.776602, samples/s: 2949.988 1612024278.7344668
train: epoch 77, iter 3500, loss: 2.956494, top_1: 0.544375, top_k: 0.773828, samples/s: 2943.393 1612024287.431942
train: epoch 77, iter 3600, loss: 3.190383, top_1: 0.553516, top_k: 0.779961, samples/s: 2999.472 1612024295.966878
train: epoch 77, iter 3700, loss: 3.024179, top_1: 0.546328, top_k: 0.775625, samples/s: 2945.698 1612024304.6574278
train: epoch 77, iter 3800, loss: 3.004236, top_1: 0.545078, top_k: 0.774062, samples/s: 2897.746 1612024313.4919748
train: epoch 77, iter 3900, loss: 2.754072, top_1: 0.552383, top_k: 0.776953, samples/s: 3003.695 1612024322.0147934
train: epoch 77, iter 4000, loss: 2.838666, top_1: 0.555156, top_k: 0.781211, samples/s: 2962.619 1612024330.6558003
train: epoch 77, iter 4100, loss: 2.898579, top_1: 0.543203, top_k: 0.776914, samples/s: 2966.720 1612024339.2848523
train: epoch 77, iter 4200, loss: 2.770690, top_1: 0.548477, top_k: 0.779414, samples/s: 2957.194 1612024347.941624
train: epoch 77, iter 4300, loss: 3.157088, top_1: 0.546133, top_k: 0.773125, samples/s: 2988.750 1612024356.5070784
train: epoch 77, iter 4400, loss: 2.866849, top_1: 0.549453, top_k: 0.777305, samples/s: 2981.477 1612024365.09343
train: epoch 77, iter 4500, loss: 2.865492, top_1: 0.548984, top_k: 0.778555, samples/s: 2985.528 1612024373.6681452
train: epoch 77, iter 4600, loss: 2.825567, top_1: 0.547109, top_k: 0.773633, samples/s: 3006.848 1612024382.1820703
train: epoch 77, iter 4700, loss: 2.977113, top_1: 0.551250, top_k: 0.782422, samples/s: 2948.275 1612024390.8651843
train: epoch 77, iter 4800, loss: 2.838892, top_1: 0.551484, top_k: 0.780039, samples/s: 3049.074 1612024399.2610693
train: epoch 77, iter 4900, loss: 3.000705, top_1: 0.548828, top_k: 0.777578, samples/s: 2999.055 1612024407.7970817
train: epoch 77, iter 5000, loss: 2.836254, top_1: 0.549844, top_k: 0.778008, samples/s: 2942.904 1612024416.4962144
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_77.
validation: epoch 77, iter 195, top_1: 0.595673, top_k: 0.831050, samples/s: 2961.779 1612024433.555649
train: epoch 78, iter 100, loss: 2.943689, top_1: 0.562148, top_k: 0.792031, samples/s: 2889.140 1612024464.2531207
train: epoch 78, iter 200, loss: 2.743452, top_1: 0.558867, top_k: 0.785820, samples/s: 3023.698 1612024472.7195861
train: epoch 78, iter 300, loss: 2.837942, top_1: 0.560195, top_k: 0.787031, samples/s: 2984.575 1612024481.29712
train: epoch 78, iter 400, loss: 2.763096, top_1: 0.556172, top_k: 0.785117, samples/s: 2975.168 1612024489.9016073
train: epoch 78, iter 500, loss: 2.822366, top_1: 0.555352, top_k: 0.785508, samples/s: 2997.893 1612024498.4409702
train: epoch 78, iter 600, loss: 2.770546, top_1: 0.550820, top_k: 0.780273, samples/s: 2992.543 1612024506.995507
train: epoch 78, iter 700, loss: 2.748710, top_1: 0.553672, top_k: 0.780312, samples/s: 3020.615 1612024515.47069
train: epoch 78, iter 800, loss: 2.715612, top_1: 0.556719, top_k: 0.781328, samples/s: 2996.673 1612024524.0133822
train: epoch 78, iter 900, loss: 2.805826, top_1: 0.556641, top_k: 0.784727, samples/s: 2996.135 1612024532.5577455
train: epoch 78, iter 1000, loss: 2.924671, top_1: 0.558789, top_k: 0.785781, samples/s: 2993.052 1612024541.1108937
train: epoch 78, iter 1100, loss: 2.799131, top_1: 0.555469, top_k: 0.781055, samples/s: 2908.960 1612024549.9112825
train: epoch 78, iter 1200, loss: 2.743232, top_1: 0.556641, top_k: 0.782070, samples/s: 2937.138 1612024558.6273239
train: epoch 78, iter 1300, loss: 2.928504, top_1: 0.551602, top_k: 0.775898, samples/s: 2991.785 1612024567.1840189
train: epoch 78, iter 1400, loss: 2.932211, top_1: 0.552500, top_k: 0.776719, samples/s: 2933.715 1612024575.9101257
train: epoch 78, iter 1500, loss: 2.758786, top_1: 0.550039, top_k: 0.778555, samples/s: 2946.356 1612024584.5989559
train: epoch 78, iter 1600, loss: 2.963209, top_1: 0.553398, top_k: 0.780977, samples/s: 2980.438 1612024593.1883705
train: epoch 78, iter 1700, loss: 2.922421, top_1: 0.559648, top_k: 0.783047, samples/s: 2966.376 1612024601.8182573
train: epoch 78, iter 1800, loss: 2.920803, top_1: 0.549648, top_k: 0.777578, samples/s: 2950.518 1612024610.4946926
train: epoch 78, iter 1900, loss: 2.820249, top_1: 0.555352, top_k: 0.781797, samples/s: 2981.845 1612024619.0800118
train: epoch 78, iter 2000, loss: 2.766364, top_1: 0.550547, top_k: 0.775703, samples/s: 2933.543 1612024627.8070521
train: epoch 78, iter 2100, loss: 2.746818, top_1: 0.554844, top_k: 0.780703, samples/s: 2956.703 1612024636.4649377
train: epoch 78, iter 2200, loss: 2.799722, top_1: 0.547930, top_k: 0.779648, samples/s: 3018.954 1612024644.9447777
train: epoch 78, iter 2300, loss: 2.938934, top_1: 0.551016, top_k: 0.771523, samples/s: 2943.497 1612024653.64183
train: epoch 78, iter 2400, loss: 2.941416, top_1: 0.553633, top_k: 0.777656, samples/s: 2972.935 1612024662.2528474
train: epoch 78, iter 2500, loss: 2.917917, top_1: 0.543086, top_k: 0.771289, samples/s: 2977.325 1612024670.8517249
train: epoch 78, iter 2600, loss: 2.866801, top_1: 0.551367, top_k: 0.777617, samples/s: 3004.552 1612024679.3715768
train: epoch 78, iter 2700, loss: 2.881896, top_1: 0.550664, top_k: 0.781484, samples/s: 2989.977 1612024687.9334593
train: epoch 78, iter 2800, loss: 2.853172, top_1: 0.553242, top_k: 0.777969, samples/s: 2980.346 1612024696.52315
train: epoch 78, iter 2900, loss: 2.785432, top_1: 0.551016, top_k: 0.778438, samples/s: 2969.782 1612024705.1432915
train: epoch 78, iter 3000, loss: 2.841008, top_1: 0.546016, top_k: 0.771758, samples/s: 2969.115 1612024713.765427
train: epoch 78, iter 3100, loss: 3.071556, top_1: 0.556641, top_k: 0.780547, samples/s: 3008.414 1612024722.2748554
train: epoch 78, iter 3200, loss: 2.689268, top_1: 0.553203, top_k: 0.780937, samples/s: 2985.709 1612024730.849097
train: epoch 78, iter 3300, loss: 2.930320, top_1: 0.555430, top_k: 0.779180, samples/s: 2911.545 1612024739.6416752
train: epoch 78, iter 3400, loss: 2.847278, top_1: 0.551055, top_k: 0.779062, samples/s: 2984.078 1612024748.2206566
train: epoch 78, iter 3500, loss: 2.849951, top_1: 0.547734, top_k: 0.776406, samples/s: 2928.392 1612024756.9625316
train: epoch 78, iter 3600, loss: 2.920606, top_1: 0.554063, top_k: 0.775391, samples/s: 2982.586 1612024765.5456204
train: epoch 78, iter 3700, loss: 2.885889, top_1: 0.549180, top_k: 0.779922, samples/s: 2963.553 1612024774.1839075
train: epoch 78, iter 3800, loss: 2.990092, top_1: 0.551523, top_k: 0.780781, samples/s: 2957.717 1612024782.8393452
train: epoch 78, iter 3900, loss: 2.901930, top_1: 0.551641, top_k: 0.778789, samples/s: 2876.825 1612024791.7378697
train: epoch 78, iter 4000, loss: 2.803174, top_1: 0.551484, top_k: 0.775039, samples/s: 2953.822 1612024800.4046845
train: epoch 78, iter 4100, loss: 2.841822, top_1: 0.551992, top_k: 0.778906, samples/s: 2981.618 1612024808.990672
train: epoch 78, iter 4200, loss: 2.974383, top_1: 0.542930, top_k: 0.775352, samples/s: 2953.312 1612024817.6588352
train: epoch 78, iter 4300, loss: 2.736595, top_1: 0.551016, top_k: 0.778828, samples/s: 2967.582 1612024826.2853882
train: epoch 78, iter 4400, loss: 2.908288, top_1: 0.552734, top_k: 0.778672, samples/s: 3029.083 1612024834.736816
train: epoch 78, iter 4500, loss: 3.119619, top_1: 0.553867, top_k: 0.784531, samples/s: 2975.561 1612024843.3402543
train: epoch 78, iter 4600, loss: 3.009824, top_1: 0.553398, top_k: 0.777070, samples/s: 2950.565 1612024852.016548
train: epoch 78, iter 4700, loss: 2.920618, top_1: 0.550937, top_k: 0.779180, samples/s: 2903.130 1612024860.8346105
train: epoch 78, iter 4800, loss: 3.158864, top_1: 0.550469, top_k: 0.779141, samples/s: 2950.325 1612024869.5117419
train: epoch 78, iter 4900, loss: 2.752095, top_1: 0.545781, top_k: 0.774844, samples/s: 2962.941 1612024878.151733
train: epoch 78, iter 5000, loss: 2.790794, top_1: 0.556914, top_k: 0.781641, samples/s: 2960.911 1612024886.79766
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_78.
validation: epoch 78, iter 195, top_1: 0.595072, top_k: 0.825641, samples/s: 2935.575 1612024904.0789795
train: epoch 79, iter 100, loss: 2.791515, top_1: 0.557852, top_k: 0.788164, samples/s: 2976.796 1612024928.7848742
train: epoch 79, iter 200, loss: 2.886905, top_1: 0.560898, top_k: 0.783906, samples/s: 3002.939 1612024937.309897
train: epoch 79, iter 300, loss: 2.850466, top_1: 0.563789, top_k: 0.785742, samples/s: 3026.114 1612024945.7695613
train: epoch 79, iter 400, loss: 2.765917, top_1: 0.562891, top_k: 0.783516, samples/s: 2928.943 1612024954.5099988
train: epoch 79, iter 500, loss: 2.749508, top_1: 0.558398, top_k: 0.785156, samples/s: 2989.009 1612024963.07456
train: epoch 79, iter 600, loss: 2.774051, top_1: 0.555352, top_k: 0.781172, samples/s: 3015.832 1612024971.5631385
train: epoch 79, iter 700, loss: 2.961901, top_1: 0.565742, top_k: 0.793086, samples/s: 3019.309 1612024980.0419173
train: epoch 79, iter 800, loss: 2.721547, top_1: 0.555898, top_k: 0.785273, samples/s: 3013.667 1612024988.5365353
train: epoch 79, iter 900, loss: 2.868739, top_1: 0.560352, top_k: 0.786016, samples/s: 2949.415 1612024997.2163377
train: epoch 79, iter 1000, loss: 2.904898, top_1: 0.557813, top_k: 0.781484, samples/s: 3000.874 1612025005.747094
train: epoch 79, iter 1100, loss: 2.987097, top_1: 0.557031, top_k: 0.785703, samples/s: 2935.802 1612025014.4670365
train: epoch 79, iter 1200, loss: 2.792410, top_1: 0.554531, top_k: 0.783281, samples/s: 2876.681 1612025023.3661566
train: epoch 79, iter 1300, loss: 2.783342, top_1: 0.551914, top_k: 0.779375, samples/s: 3009.737 1612025031.8718803
train: epoch 79, iter 1400, loss: 2.923154, top_1: 0.558398, top_k: 0.782852, samples/s: 2965.102 1612025040.505826
train: epoch 79, iter 1500, loss: 2.759358, top_1: 0.548984, top_k: 0.778945, samples/s: 2896.897 1612025049.3427393
train: epoch 79, iter 1600, loss: 2.920132, top_1: 0.553438, top_k: 0.780703, samples/s: 2977.494 1612025057.9405298
train: epoch 79, iter 1700, loss: 2.844232, top_1: 0.557891, top_k: 0.784922, samples/s: 2979.781 1612025066.5320597
train: epoch 79, iter 1800, loss: 3.039386, top_1: 0.552539, top_k: 0.778594, samples/s: 2955.670 1612025075.1932247
train: epoch 79, iter 1900, loss: 2.786112, top_1: 0.556289, top_k: 0.783633, samples/s: 2962.679 1612025083.8338804
train: epoch 79, iter 2000, loss: 2.768391, top_1: 0.557344, top_k: 0.783164, samples/s: 2971.424 1612025092.4493709
train: epoch 79, iter 2100, loss: 2.986875, top_1: 0.561875, top_k: 0.785859, samples/s: 2976.036 1612025101.0517123
train: epoch 79, iter 2200, loss: 2.916036, top_1: 0.554023, top_k: 0.777109, samples/s: 2953.488 1612025109.719197
train: epoch 79, iter 2300, loss: 2.917829, top_1: 0.552734, top_k: 0.779922, samples/s: 3009.196 1612025118.226363
train: epoch 79, iter 2400, loss: 2.792541, top_1: 0.553906, top_k: 0.781094, samples/s: 2993.112 1612025126.7793198
train: epoch 79, iter 2500, loss: 3.130537, top_1: 0.551172, top_k: 0.775625, samples/s: 2980.485 1612025135.3684914
train: epoch 79, iter 2600, loss: 3.043032, top_1: 0.555391, top_k: 0.784961, samples/s: 2981.230 1612025143.955637
train: epoch 79, iter 2700, loss: 2.829153, top_1: 0.552539, top_k: 0.781406, samples/s: 3011.187 1612025152.457194
train: epoch 79, iter 2800, loss: 2.964846, top_1: 0.555625, top_k: 0.778398, samples/s: 2975.585 1612025161.0605953
train: epoch 79, iter 2900, loss: 2.764022, top_1: 0.554688, top_k: 0.777617, samples/s: 2965.131 1612025169.6942387
train: epoch 79, iter 3000, loss: 2.872823, top_1: 0.549063, top_k: 0.779297, samples/s: 2916.216 1612025178.472717
train: epoch 79, iter 3100, loss: 2.814666, top_1: 0.547344, top_k: 0.781289, samples/s: 2889.571 1612025187.3321834
train: epoch 79, iter 3200, loss: 2.928817, top_1: 0.551133, top_k: 0.780469, samples/s: 2910.072 1612025196.129217
train: epoch 79, iter 3300, loss: 2.868305, top_1: 0.552891, top_k: 0.781250, samples/s: 2996.256 1612025204.673228
train: epoch 79, iter 3400, loss: 2.984473, top_1: 0.556484, top_k: 0.781836, samples/s: 2952.515 1612025213.3437161
train: epoch 79, iter 3500, loss: 2.875212, top_1: 0.548945, top_k: 0.776172, samples/s: 2954.998 1612025222.0070453
train: epoch 79, iter 3600, loss: 2.775858, top_1: 0.551797, top_k: 0.780977, samples/s: 3016.367 1612025230.4941213
train: epoch 79, iter 3700, loss: 2.865138, top_1: 0.548008, top_k: 0.780195, samples/s: 2997.949 1612025239.033259
train: epoch 79, iter 3800, loss: 2.946884, top_1: 0.555625, top_k: 0.779336, samples/s: 2924.518 1612025247.78684
train: epoch 79, iter 3900, loss: 2.758756, top_1: 0.545273, top_k: 0.776797, samples/s: 3048.811 1612025256.1835623
train: epoch 79, iter 4000, loss: 2.774304, top_1: 0.554297, top_k: 0.781602, samples/s: 2967.600 1612025264.8100502
train: epoch 79, iter 4100, loss: 2.969609, top_1: 0.545625, top_k: 0.774609, samples/s: 2977.898 1612025273.4068677
train: epoch 79, iter 4200, loss: 2.778109, top_1: 0.546836, top_k: 0.778828, samples/s: 2866.424 1612025282.3377383
train: epoch 79, iter 4300, loss: 2.781147, top_1: 0.552969, top_k: 0.780703, samples/s: 2954.160 1612025291.0034575
train: epoch 79, iter 4400, loss: 2.694422, top_1: 0.551328, top_k: 0.780078, samples/s: 2975.767 1612025299.6063762
train: epoch 79, iter 4500, loss: 2.750711, top_1: 0.548555, top_k: 0.774531, samples/s: 2968.149 1612025308.2312832
train: epoch 79, iter 4600, loss: 2.826740, top_1: 0.551641, top_k: 0.778008, samples/s: 2964.979 1612025316.8653376
train: epoch 79, iter 4700, loss: 3.038057, top_1: 0.550039, top_k: 0.774102, samples/s: 3003.125 1612025325.3899546
train: epoch 79, iter 4800, loss: 2.825186, top_1: 0.552656, top_k: 0.781250, samples/s: 2982.167 1612025333.9741437
train: epoch 79, iter 4900, loss: 3.094624, top_1: 0.554961, top_k: 0.779336, samples/s: 2881.978 1612025342.856911
train: epoch 79, iter 5000, loss: 2.893594, top_1: 0.554375, top_k: 0.780312, samples/s: 2988.506 1612025351.4232936
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_79.
validation: epoch 79, iter 195, top_1: 0.598337, top_k: 0.830429, samples/s: 2978.855 1612025368.4966972
train: epoch 80, iter 100, loss: 3.003984, top_1: 0.560820, top_k: 0.787344, samples/s: 2952.146 1612025392.8479598
train: epoch 80, iter 200, loss: 2.774836, top_1: 0.562461, top_k: 0.786445, samples/s: 3025.648 1612025401.3089614
train: epoch 80, iter 300, loss: 2.822523, top_1: 0.564844, top_k: 0.790352, samples/s: 2962.849 1612025409.949217
train: epoch 80, iter 400, loss: 2.731577, top_1: 0.553320, top_k: 0.784102, samples/s: 2960.973 1612025418.5949812
train: epoch 80, iter 500, loss: 2.696927, top_1: 0.560273, top_k: 0.786406, samples/s: 3013.867 1612025427.0891137
train: epoch 80, iter 600, loss: 2.984781, top_1: 0.562187, top_k: 0.785352, samples/s: 3004.532 1612025435.609611
train: epoch 80, iter 700, loss: 2.853801, top_1: 0.561445, top_k: 0.789219, samples/s: 2984.790 1612025444.1863477
train: epoch 80, iter 800, loss: 2.865301, top_1: 0.564922, top_k: 0.788398, samples/s: 2968.903 1612025452.809078
train: epoch 80, iter 900, loss: 2.981049, top_1: 0.556406, top_k: 0.782344, samples/s: 2995.803 1612025461.3543968
train: epoch 80, iter 1000, loss: 2.907111, top_1: 0.560352, top_k: 0.785625, samples/s: 2953.631 1612025470.0216599
train: epoch 80, iter 1100, loss: 2.943276, top_1: 0.554219, top_k: 0.781914, samples/s: 2999.747 1612025478.5556705
train: epoch 80, iter 1200, loss: 2.879375, top_1: 0.557930, top_k: 0.781758, samples/s: 2970.104 1612025487.1749444
train: epoch 80, iter 1300, loss: 3.058626, top_1: 0.556914, top_k: 0.785000, samples/s: 3000.961 1612025495.7055566
train: epoch 80, iter 1400, loss: 3.081420, top_1: 0.558633, top_k: 0.786133, samples/s: 2904.812 1612025504.5185394
train: epoch 80, iter 1500, loss: 2.649331, top_1: 0.555508, top_k: 0.783867, samples/s: 2979.520 1612025513.1105077
train: epoch 80, iter 1600, loss: 2.978911, top_1: 0.559727, top_k: 0.783672, samples/s: 2986.391 1612025521.682718
train: epoch 80, iter 1700, loss: 2.767506, top_1: 0.554805, top_k: 0.782852, samples/s: 2915.296 1612025530.4639955
train: epoch 80, iter 1800, loss: 2.817798, top_1: 0.556289, top_k: 0.784883, samples/s: 3011.354 1612025538.9651487
train: epoch 80, iter 1900, loss: 2.795933, top_1: 0.558281, top_k: 0.787188, samples/s: 2998.131 1612025547.5038764
train: epoch 80, iter 2000, loss: 2.820274, top_1: 0.556836, top_k: 0.782383, samples/s: 2998.231 1612025556.0421731
train: epoch 80, iter 2100, loss: 2.934496, top_1: 0.554336, top_k: 0.784375, samples/s: 2982.059 1612025564.6268327
train: epoch 80, iter 2200, loss: 2.818495, top_1: 0.556992, top_k: 0.779922, samples/s: 3006.047 1612025573.1430855
train: epoch 80, iter 2300, loss: 2.934100, top_1: 0.551758, top_k: 0.781133, samples/s: 3001.460 1612025581.6722412
train: epoch 80, iter 2400, loss: 2.944729, top_1: 0.559766, top_k: 0.786641, samples/s: 2977.928 1612025590.2688015
train: epoch 80, iter 2500, loss: 2.987472, top_1: 0.552109, top_k: 0.782539, samples/s: 2907.877 1612025599.0725372
train: epoch 80, iter 2600, loss: 2.903281, top_1: 0.550625, top_k: 0.779141, samples/s: 2984.956 1612025607.6488068
train: epoch 80, iter 2700, loss: 2.874913, top_1: 0.555859, top_k: 0.784141, samples/s: 2945.222 1612025616.3408408
train: epoch 80, iter 2800, loss: 2.929598, top_1: 0.552617, top_k: 0.779609, samples/s: 2973.411 1612025624.9505262
train: epoch 80, iter 2900, loss: 2.731471, top_1: 0.553711, top_k: 0.781602, samples/s: 2954.321 1612025633.6157484
train: epoch 80, iter 3000, loss: 2.907745, top_1: 0.558672, top_k: 0.779609, samples/s: 2978.371 1612025642.2110865
train: epoch 80, iter 3100, loss: 2.739965, top_1: 0.553320, top_k: 0.779141, samples/s: 2959.813 1612025650.8606215
train: epoch 80, iter 3200, loss: 2.997992, top_1: 0.558398, top_k: 0.782734, samples/s: 2999.348 1612025659.3954382
train: epoch 80, iter 3300, loss: 2.970187, top_1: 0.552305, top_k: 0.781523, samples/s: 2952.147 1612025668.068515
train: epoch 80, iter 3400, loss: 2.826173, top_1: 0.555430, top_k: 0.784648, samples/s: 2903.256 1612025676.8848448
train: epoch 80, iter 3500, loss: 2.830438, top_1: 0.549922, top_k: 0.777695, samples/s: 2970.437 1612025685.503078
train: epoch 80, iter 3600, loss: 2.853153, top_1: 0.557148, top_k: 0.779258, samples/s: 2955.624 1612025694.1647112
train: epoch 80, iter 3700, loss: 2.950668, top_1: 0.555078, top_k: 0.782891, samples/s: 2984.746 1612025702.74144
train: epoch 80, iter 3800, loss: 3.007504, top_1: 0.554688, top_k: 0.779609, samples/s: 2965.628 1612025711.3737552
train: epoch 80, iter 3900, loss: 2.830930, top_1: 0.549609, top_k: 0.776523, samples/s: 2900.615 1612025720.1993318
train: epoch 80, iter 4000, loss: 2.845230, top_1: 0.557969, top_k: 0.781250, samples/s: 2954.508 1612025728.8641179
train: epoch 80, iter 4100, loss: 2.673348, top_1: 0.552578, top_k: 0.779062, samples/s: 2977.085 1612025737.4631345
train: epoch 80, iter 4200, loss: 2.860215, top_1: 0.559805, top_k: 0.784102, samples/s: 2977.747 1612025746.060341
train: epoch 80, iter 4300, loss: 2.901508, top_1: 0.551953, top_k: 0.779141, samples/s: 2916.219 1612025754.838759
train: epoch 80, iter 4400, loss: 2.799893, top_1: 0.552852, top_k: 0.784922, samples/s: 2997.582 1612025763.3789287
train: epoch 80, iter 4500, loss: 2.903066, top_1: 0.553398, top_k: 0.783477, samples/s: 2980.240 1612025771.9688275
train: epoch 80, iter 4600, loss: 2.789007, top_1: 0.550195, top_k: 0.784336, samples/s: 3000.903 1612025780.4996305
train: epoch 80, iter 4700, loss: 2.860040, top_1: 0.557891, top_k: 0.785117, samples/s: 2936.531 1612025789.2174923
train: epoch 80, iter 4800, loss: 3.148530, top_1: 0.551250, top_k: 0.775156, samples/s: 2966.382 1612025797.8475254
train: epoch 80, iter 4900, loss: 2.747028, top_1: 0.548789, top_k: 0.775352, samples/s: 2950.202 1612025806.5248504
train: epoch 80, iter 5000, loss: 2.795961, top_1: 0.555469, top_k: 0.781836, samples/s: 2975.182 1612025815.129315
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_80.
validation: epoch 80, iter 195, top_1: 0.592849, top_k: 0.826002, samples/s: 2883.125 1612025832.7190635
train: epoch 81, iter 100, loss: 2.620653, top_1: 0.566328, top_k: 0.793906, samples/s: 2922.616 1612025857.7349188
train: epoch 81, iter 200, loss: 2.604822, top_1: 0.559961, top_k: 0.789687, samples/s: 2927.471 1612025866.4796805
train: epoch 81, iter 300, loss: 2.792084, top_1: 0.555742, top_k: 0.785937, samples/s: 2955.404 1612025875.1417754
train: epoch 81, iter 400, loss: 2.958668, top_1: 0.566133, top_k: 0.791133, samples/s: 2934.954 1612025883.8642333
train: epoch 81, iter 500, loss: 2.937413, top_1: 0.568867, top_k: 0.791133, samples/s: 2998.037 1612025892.403219
train: epoch 81, iter 600, loss: 2.839794, top_1: 0.564023, top_k: 0.790312, samples/s: 3002.248 1612025900.930258
train: epoch 81, iter 700, loss: 2.805926, top_1: 0.563242, top_k: 0.790000, samples/s: 3020.054 1612025909.4067526
train: epoch 81, iter 800, loss: 2.772154, top_1: 0.558711, top_k: 0.785000, samples/s: 2982.917 1612025917.9889371
train: epoch 81, iter 900, loss: 2.937732, top_1: 0.559570, top_k: 0.785156, samples/s: 2953.144 1612025926.6576886
train: epoch 81, iter 1000, loss: 2.762009, top_1: 0.552539, top_k: 0.777617, samples/s: 2959.845 1612025935.3067865
train: epoch 81, iter 1100, loss: 2.967419, top_1: 0.557070, top_k: 0.785117, samples/s: 2995.404 1612025943.8532228
train: epoch 81, iter 1200, loss: 2.893797, top_1: 0.557266, top_k: 0.782891, samples/s: 2965.695 1612025952.4853094
train: epoch 81, iter 1300, loss: 2.951289, top_1: 0.560508, top_k: 0.785547, samples/s: 3020.008 1612025960.9620702
train: epoch 81, iter 1400, loss: 2.837088, top_1: 0.558477, top_k: 0.788438, samples/s: 2915.762 1612025969.7419124
train: epoch 81, iter 1500, loss: 2.731538, top_1: 0.564258, top_k: 0.788633, samples/s: 2972.711 1612025978.353585
train: epoch 81, iter 1600, loss: 2.918061, top_1: 0.555742, top_k: 0.777813, samples/s: 2972.841 1612025986.964885
train: epoch 81, iter 1700, loss: 2.760551, top_1: 0.559180, top_k: 0.789453, samples/s: 2957.337 1612025995.6213233
train: epoch 81, iter 1800, loss: 2.891370, top_1: 0.558945, top_k: 0.788594, samples/s: 2914.264 1612026004.4057946
train: epoch 81, iter 1900, loss: 2.809484, top_1: 0.556250, top_k: 0.782891, samples/s: 2979.487 1612026012.997771
train: epoch 81, iter 2000, loss: 2.693239, top_1: 0.554688, top_k: 0.782461, samples/s: 2989.900 1612026021.5599613
train: epoch 81, iter 2100, loss: 2.968990, top_1: 0.557734, top_k: 0.780469, samples/s: 2855.167 1612026030.5261612
train: epoch 81, iter 2200, loss: 2.892660, top_1: 0.553711, top_k: 0.782148, samples/s: 2958.987 1612026039.1777892
train: epoch 81, iter 2300, loss: 2.976274, top_1: 0.554023, top_k: 0.780547, samples/s: 2960.087 1612026047.8261406
train: epoch 81, iter 2400, loss: 3.035944, top_1: 0.554492, top_k: 0.781641, samples/s: 2985.457 1612026056.4010015
train: epoch 81, iter 2500, loss: 2.731980, top_1: 0.549727, top_k: 0.781719, samples/s: 2982.693 1612026064.9838836
train: epoch 81, iter 2600, loss: 2.873878, top_1: 0.558750, top_k: 0.788086, samples/s: 2945.550 1612026073.6749587
train: epoch 81, iter 2700, loss: 2.872515, top_1: 0.557148, top_k: 0.783633, samples/s: 2972.143 1612026082.288295
train: epoch 81, iter 2800, loss: 2.635565, top_1: 0.559805, top_k: 0.784219, samples/s: 2954.272 1612026090.9537964
train: epoch 81, iter 2900, loss: 2.803973, top_1: 0.558867, top_k: 0.783906, samples/s: 2974.328 1612026099.5607295
train: epoch 81, iter 3000, loss: 2.710163, top_1: 0.551836, top_k: 0.781094, samples/s: 2900.996 1612026108.3852434
train: epoch 81, iter 3100, loss: 2.756409, top_1: 0.557344, top_k: 0.781719, samples/s: 2891.283 1612026117.2394786
train: epoch 81, iter 3200, loss: 2.926061, top_1: 0.556562, top_k: 0.779961, samples/s: 2939.865 1612026125.9473221
train: epoch 81, iter 3300, loss: 2.678644, top_1: 0.553438, top_k: 0.777734, samples/s: 2978.653 1612026134.5418053
train: epoch 81, iter 3400, loss: 3.010634, top_1: 0.554102, top_k: 0.783711, samples/s: 2918.293 1612026143.3140585
train: epoch 81, iter 3500, loss: 2.897932, top_1: 0.552344, top_k: 0.779219, samples/s: 2969.436 1612026151.9352856
train: epoch 81, iter 3600, loss: 2.911315, top_1: 0.552539, top_k: 0.781914, samples/s: 2985.477 1612026160.5100675
train: epoch 81, iter 3700, loss: 2.813106, top_1: 0.559023, top_k: 0.783984, samples/s: 2928.149 1612026169.2527962
train: epoch 81, iter 3800, loss: 2.718618, top_1: 0.561445, top_k: 0.782188, samples/s: 2881.932 1612026178.135801
train: epoch 81, iter 3900, loss: 2.783867, top_1: 0.557070, top_k: 0.785234, samples/s: 2974.080 1612026186.7435353
train: epoch 81, iter 4000, loss: 2.889117, top_1: 0.553711, top_k: 0.778594, samples/s: 2965.558 1612026195.375875
train: epoch 81, iter 4100, loss: 2.880884, top_1: 0.558008, top_k: 0.785039, samples/s: 2856.549 1612026204.3377213
train: epoch 81, iter 4200, loss: 2.905367, top_1: 0.553398, top_k: 0.777930, samples/s: 2970.978 1612026212.9544113
train: epoch 81, iter 4300, loss: 2.754087, top_1: 0.556797, top_k: 0.782383, samples/s: 2933.486 1612026221.6812792
train: epoch 81, iter 4400, loss: 2.765540, top_1: 0.557227, top_k: 0.782266, samples/s: 2975.329 1612026230.2852745
train: epoch 81, iter 4500, loss: 2.760191, top_1: 0.550000, top_k: 0.779258, samples/s: 2961.115 1612026238.9307177
train: epoch 81, iter 4600, loss: 2.987730, top_1: 0.555977, top_k: 0.780000, samples/s: 2962.656 1612026247.5716171
train: epoch 81, iter 4700, loss: 2.931086, top_1: 0.550508, top_k: 0.780625, samples/s: 2908.541 1612026256.3732848
train: epoch 81, iter 4800, loss: 2.980040, top_1: 0.554336, top_k: 0.781602, samples/s: 3003.067 1612026264.897887
train: epoch 81, iter 4900, loss: 2.772300, top_1: 0.556836, top_k: 0.784141, samples/s: 2964.046 1612026273.5347705
train: epoch 81, iter 5000, loss: 2.805865, top_1: 0.560469, top_k: 0.786133, samples/s: 2938.418 1612026282.246906
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_81.
validation: epoch 81, iter 195, top_1: 0.603826, top_k: 0.831470, samples/s: 2955.581 1612026299.3292375
train: epoch 82, iter 100, loss: 2.869898, top_1: 0.557852, top_k: 0.784414, samples/s: 2986.823 1612026323.6779976
train: epoch 82, iter 200, loss: 2.957984, top_1: 0.562109, top_k: 0.787070, samples/s: 2987.514 1612026332.2470117
train: epoch 82, iter 300, loss: 2.665693, top_1: 0.559258, top_k: 0.785703, samples/s: 2999.947 1612026340.780508
train: epoch 82, iter 400, loss: 2.774689, top_1: 0.568672, top_k: 0.793516, samples/s: 2985.704 1612026349.3547509
train: epoch 82, iter 500, loss: 2.886551, top_1: 0.567031, top_k: 0.788242, samples/s: 2953.513 1612026358.0223272
train: epoch 82, iter 600, loss: 2.847860, top_1: 0.562266, top_k: 0.789727, samples/s: 2963.191 1612026366.6617866
train: epoch 82, iter 700, loss: 2.928699, top_1: 0.562695, top_k: 0.783398, samples/s: 2902.912 1612026375.4805222
train: epoch 82, iter 800, loss: 2.850467, top_1: 0.559492, top_k: 0.786563, samples/s: 2975.570 1612026384.083762
train: epoch 82, iter 900, loss: 2.809292, top_1: 0.563008, top_k: 0.788359, samples/s: 3006.079 1612026392.5999265
train: epoch 82, iter 1000, loss: 3.017452, top_1: 0.554648, top_k: 0.783828, samples/s: 3021.401 1612026401.0727608
train: epoch 82, iter 1100, loss: 2.775565, top_1: 0.561523, top_k: 0.784727, samples/s: 2928.147 1612026409.8155825
train: epoch 82, iter 1200, loss: 2.768920, top_1: 0.560078, top_k: 0.787266, samples/s: 3033.672 1612026418.2541094
train: epoch 82, iter 1300, loss: 2.729451, top_1: 0.563164, top_k: 0.789531, samples/s: 2942.544 1612026426.9542198
train: epoch 82, iter 1400, loss: 2.941933, top_1: 0.563203, top_k: 0.786328, samples/s: 2891.006 1612026435.8091137
train: epoch 82, iter 1500, loss: 2.826583, top_1: 0.562891, top_k: 0.787539, samples/s: 2992.421 1612026444.3640645
train: epoch 82, iter 1600, loss: 2.726565, top_1: 0.555312, top_k: 0.784375, samples/s: 2942.548 1612026453.0639927
train: epoch 82, iter 1700, loss: 3.109975, top_1: 0.556641, top_k: 0.786758, samples/s: 2988.825 1612026461.6292818
train: epoch 82, iter 1800, loss: 2.948960, top_1: 0.557148, top_k: 0.780117, samples/s: 2990.530 1612026470.189593
train: epoch 82, iter 1900, loss: 2.667977, top_1: 0.557422, top_k: 0.785547, samples/s: 2879.111 1612026479.0812337
train: epoch 82, iter 2000, loss: 3.049331, top_1: 0.556758, top_k: 0.787070, samples/s: 2954.225 1612026487.7467847
train: epoch 82, iter 2100, loss: 2.702766, top_1: 0.563008, top_k: 0.785859, samples/s: 2954.281 1612026496.4121754
train: epoch 82, iter 2200, loss: 2.710313, top_1: 0.556797, top_k: 0.785312, samples/s: 3033.800 1612026504.850389
train: epoch 82, iter 2300, loss: 2.941967, top_1: 0.565898, top_k: 0.788711, samples/s: 2964.416 1612026513.4862044
train: epoch 82, iter 2400, loss: 2.827037, top_1: 0.553711, top_k: 0.785586, samples/s: 2946.360 1612026522.1748853
train: epoch 82, iter 2500, loss: 2.770952, top_1: 0.559844, top_k: 0.782734, samples/s: 2942.409 1612026530.8752406
train: epoch 82, iter 2600, loss: 2.787625, top_1: 0.556992, top_k: 0.782500, samples/s: 2929.861 1612026539.61285
train: epoch 82, iter 2700, loss: 2.827972, top_1: 0.555977, top_k: 0.781719, samples/s: 2893.631 1612026548.45995
train: epoch 82, iter 2800, loss: 2.970542, top_1: 0.561406, top_k: 0.785742, samples/s: 2922.262 1612026557.2202291
train: epoch 82, iter 2900, loss: 2.891199, top_1: 0.557852, top_k: 0.785273, samples/s: 3016.642 1612026565.7064428
train: epoch 82, iter 3000, loss: 2.944172, top_1: 0.551797, top_k: 0.782344, samples/s: 2927.868 1612026574.4500523
train: epoch 82, iter 3100, loss: 2.972309, top_1: 0.559141, top_k: 0.780312, samples/s: 2991.232 1612026583.0084152
train: epoch 82, iter 3200, loss: 2.880633, top_1: 0.557422, top_k: 0.782578, samples/s: 2954.692 1612026591.6726522
train: epoch 82, iter 3300, loss: 2.640886, top_1: 0.561562, top_k: 0.785234, samples/s: 2943.394 1612026600.3700097
train: epoch 82, iter 3400, loss: 2.955691, top_1: 0.558359, top_k: 0.786211, samples/s: 2973.280 1612026608.9800665
train: epoch 82, iter 3500, loss: 2.914766, top_1: 0.559570, top_k: 0.782227, samples/s: 2906.556 1612026617.7877693
train: epoch 82, iter 3600, loss: 2.931558, top_1: 0.554375, top_k: 0.784258, samples/s: 2969.358 1612026626.409087
train: epoch 82, iter 3700, loss: 2.882563, top_1: 0.555859, top_k: 0.781875, samples/s: 2876.175 1612026635.309847
train: epoch 82, iter 3800, loss: 2.871467, top_1: 0.556445, top_k: 0.778672, samples/s: 2989.646 1612026643.872703
train: epoch 82, iter 3900, loss: 2.986581, top_1: 0.557461, top_k: 0.782578, samples/s: 2955.707 1612026652.5339072
train: epoch 82, iter 4000, loss: 2.862072, top_1: 0.562969, top_k: 0.783789, samples/s: 2976.664 1612026661.1341226
train: epoch 82, iter 4100, loss: 2.727336, top_1: 0.555352, top_k: 0.782461, samples/s: 2944.835 1612026669.827303
train: epoch 82, iter 4200, loss: 2.950708, top_1: 0.560547, top_k: 0.784180, samples/s: 2914.611 1612026678.6106787
train: epoch 82, iter 4300, loss: 2.769038, top_1: 0.554102, top_k: 0.778047, samples/s: 2966.331 1612026687.2408595
train: epoch 82, iter 4400, loss: 2.869478, top_1: 0.553594, top_k: 0.779805, samples/s: 2898.314 1612026696.0736957
train: epoch 82, iter 4500, loss: 2.768229, top_1: 0.559102, top_k: 0.782227, samples/s: 2948.439 1612026704.7561467
train: epoch 82, iter 4600, loss: 2.875903, top_1: 0.553555, top_k: 0.782969, samples/s: 2978.588 1612026713.3510256
train: epoch 82, iter 4700, loss: 2.601682, top_1: 0.560273, top_k: 0.781680, samples/s: 2996.278 1612026721.8947396
train: epoch 82, iter 4800, loss: 2.736126, top_1: 0.551445, top_k: 0.780469, samples/s: 2948.711 1612026730.5766623
train: epoch 82, iter 4900, loss: 2.793232, top_1: 0.554375, top_k: 0.780586, samples/s: 2951.167 1612026739.2509897
train: epoch 82, iter 5000, loss: 2.864392, top_1: 0.562383, top_k: 0.789297, samples/s: 2983.584 1612026747.8313105
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_82.
validation: epoch 82, iter 195, top_1: 0.604908, top_k: 0.831571, samples/s: 3034.234 1612026764.4905539
train: epoch 83, iter 100, loss: 2.801023, top_1: 0.566797, top_k: 0.792461, samples/s: 2935.342 1612026788.8393435
train: epoch 83, iter 200, loss: 2.718887, top_1: 0.562891, top_k: 0.786563, samples/s: 2973.805 1612026797.4478104
train: epoch 83, iter 300, loss: 2.711030, top_1: 0.566406, top_k: 0.790430, samples/s: 2901.156 1612026806.2719567
train: epoch 83, iter 400, loss: 2.901684, top_1: 0.560742, top_k: 0.788594, samples/s: 2973.995 1612026814.8798206
train: epoch 83, iter 500, loss: 2.971545, top_1: 0.565039, top_k: 0.791406, samples/s: 3016.388 1612026823.3668654
train: epoch 83, iter 600, loss: 2.571905, top_1: 0.562187, top_k: 0.787656, samples/s: 2942.736 1612026832.066211
train: epoch 83, iter 700, loss: 2.785246, top_1: 0.570234, top_k: 0.795156, samples/s: 2983.451 1612026840.6468487
train: epoch 83, iter 800, loss: 2.854699, top_1: 0.569414, top_k: 0.793750, samples/s: 3005.460 1612026849.164741
train: epoch 83, iter 900, loss: 2.758995, top_1: 0.560117, top_k: 0.785820, samples/s: 2978.051 1612026857.760944
train: epoch 83, iter 1000, loss: 2.750339, top_1: 0.565312, top_k: 0.786914, samples/s: 2982.710 1612026866.3437064
train: epoch 83, iter 1100, loss: 2.673787, top_1: 0.566680, top_k: 0.788594, samples/s: 2968.145 1612026874.9686468
train: epoch 83, iter 1200, loss: 2.714398, top_1: 0.563359, top_k: 0.784922, samples/s: 2963.108 1612026883.6082554
train: epoch 83, iter 1300, loss: 2.682698, top_1: 0.561719, top_k: 0.787188, samples/s: 2907.495 1612026892.413088
train: epoch 83, iter 1400, loss: 2.901861, top_1: 0.556289, top_k: 0.783594, samples/s: 2955.089 1612026901.0761116
train: epoch 83, iter 1500, loss: 2.861768, top_1: 0.562539, top_k: 0.786016, samples/s: 2963.902 1612026909.7133152
train: epoch 83, iter 1600, loss: 2.872858, top_1: 0.557734, top_k: 0.785625, samples/s: 2991.151 1612026918.272088
train: epoch 83, iter 1700, loss: 2.659655, top_1: 0.564258, top_k: 0.787148, samples/s: 2941.971 1612026926.9735203
train: epoch 83, iter 1800, loss: 2.959232, top_1: 0.560859, top_k: 0.789336, samples/s: 2975.091 1612026935.5783575
train: epoch 83, iter 1900, loss: 2.825087, top_1: 0.554727, top_k: 0.781367, samples/s: 2942.169 1612026944.2793927
train: epoch 83, iter 2000, loss: 2.997603, top_1: 0.554453, top_k: 0.783164, samples/s: 2966.807 1612026952.9081638
train: epoch 83, iter 2100, loss: 2.714485, top_1: 0.566797, top_k: 0.790586, samples/s: 2963.282 1612026961.5486786
train: epoch 83, iter 2200, loss: 3.011924, top_1: 0.555781, top_k: 0.785273, samples/s: 2965.447 1612026970.1800287
train: epoch 83, iter 2300, loss: 2.698272, top_1: 0.566055, top_k: 0.789414, samples/s: 2953.964 1612026978.8468213
train: epoch 83, iter 2400, loss: 2.683594, top_1: 0.562734, top_k: 0.787969, samples/s: 2949.781 1612026987.5250068
train: epoch 83, iter 2500, loss: 2.780381, top_1: 0.563398, top_k: 0.786211, samples/s: 2944.081 1612026996.220538
train: epoch 83, iter 2600, loss: 2.926220, top_1: 0.558164, top_k: 0.786680, samples/s: 2868.148 1612027005.1461146
train: epoch 83, iter 2700, loss: 2.733978, top_1: 0.565508, top_k: 0.790039, samples/s: 2972.585 1612027013.75802
train: epoch 83, iter 2800, loss: 2.841903, top_1: 0.565742, top_k: 0.788203, samples/s: 2971.859 1612027022.3721752
train: epoch 83, iter 2900, loss: 2.850613, top_1: 0.558828, top_k: 0.779805, samples/s: 2897.733 1612027031.2067294
train: epoch 83, iter 3000, loss: 2.793106, top_1: 0.552539, top_k: 0.779727, samples/s: 2982.246 1612027039.7907863
train: epoch 83, iter 3100, loss: 2.937953, top_1: 0.555352, top_k: 0.787227, samples/s: 2966.786 1612027048.4196458
train: epoch 83, iter 3200, loss: 2.899917, top_1: 0.552188, top_k: 0.780586, samples/s: 2915.261 1612027057.2012098
train: epoch 83, iter 3300, loss: 2.870650, top_1: 0.563672, top_k: 0.784961, samples/s: 2889.380 1612027066.06112
train: epoch 83, iter 3400, loss: 2.710842, top_1: 0.560117, top_k: 0.787695, samples/s: 2913.611 1612027074.8475058
train: epoch 83, iter 3500, loss: 2.997265, top_1: 0.558320, top_k: 0.788008, samples/s: 3018.527 1612027083.3283684
train: epoch 83, iter 3600, loss: 2.670140, top_1: 0.556562, top_k: 0.779844, samples/s: 2928.327 1612027092.0705373
train: epoch 83, iter 3700, loss: 2.995776, top_1: 0.560977, top_k: 0.784453, samples/s: 2906.062 1612027100.879708
train: epoch 83, iter 3800, loss: 2.862328, top_1: 0.552070, top_k: 0.779648, samples/s: 2966.621 1612027109.5090704
train: epoch 83, iter 3900, loss: 2.676923, top_1: 0.558477, top_k: 0.787227, samples/s: 2953.381 1612027118.1771038
train: epoch 83, iter 4000, loss: 2.588476, top_1: 0.561250, top_k: 0.788398, samples/s: 2981.547 1612027126.7632854
train: epoch 83, iter 4100, loss: 2.731285, top_1: 0.557930, top_k: 0.784648, samples/s: 2976.985 1612027135.3625567
train: epoch 83, iter 4200, loss: 2.937190, top_1: 0.561641, top_k: 0.787578, samples/s: 2985.779 1612027143.936536
train: epoch 83, iter 4300, loss: 2.887185, top_1: 0.556172, top_k: 0.784961, samples/s: 2910.935 1612027152.7309647
train: epoch 83, iter 4400, loss: 2.905133, top_1: 0.552422, top_k: 0.784844, samples/s: 2912.724 1612027161.5199845
train: epoch 83, iter 4500, loss: 2.880779, top_1: 0.558047, top_k: 0.782578, samples/s: 2939.335 1612027170.229433
train: epoch 83, iter 4600, loss: 2.886842, top_1: 0.560078, top_k: 0.783242, samples/s: 2951.333 1612027178.903496
train: epoch 83, iter 4700, loss: 2.780911, top_1: 0.556289, top_k: 0.781953, samples/s: 2935.641 1612027187.6238947
train: epoch 83, iter 4800, loss: 2.842889, top_1: 0.555625, top_k: 0.781133, samples/s: 2974.964 1612027196.2291372
train: epoch 83, iter 4900, loss: 2.679720, top_1: 0.556172, top_k: 0.783594, samples/s: 2958.186 1612027204.8829875
train: epoch 83, iter 5000, loss: 2.844343, top_1: 0.560508, top_k: 0.784023, samples/s: 2925.222 1612027213.634459
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_83.
validation: epoch 83, iter 195, top_1: 0.600220, top_k: 0.832232, samples/s: 2961.632 1612027230.7406254
train: epoch 84, iter 100, loss: 2.931855, top_1: 0.570664, top_k: 0.794375, samples/s: 2930.021 1612027255.2537534
train: epoch 84, iter 200, loss: 2.759555, top_1: 0.573359, top_k: 0.793477, samples/s: 3006.499 1612027263.7686362
train: epoch 84, iter 300, loss: 2.843464, top_1: 0.561094, top_k: 0.786602, samples/s: 2953.315 1612027272.4368126
train: epoch 84, iter 400, loss: 2.823076, top_1: 0.567930, top_k: 0.790430, samples/s: 2872.139 1612027281.3501875
train: epoch 84, iter 500, loss: 2.779932, top_1: 0.564492, top_k: 0.790508, samples/s: 3037.501 1612027289.7780585
train: epoch 84, iter 600, loss: 2.512881, top_1: 0.571250, top_k: 0.792305, samples/s: 2890.894 1612027298.6335964
train: epoch 84, iter 700, loss: 2.748300, top_1: 0.567383, top_k: 0.789648, samples/s: 2993.449 1612027307.1854806
train: epoch 84, iter 800, loss: 2.883111, top_1: 0.566328, top_k: 0.790391, samples/s: 3017.981 1612027315.6679769
train: epoch 84, iter 900, loss: 2.892350, top_1: 0.558477, top_k: 0.784648, samples/s: 2975.844 1612027324.270549
train: epoch 84, iter 1000, loss: 2.708257, top_1: 0.563008, top_k: 0.790937, samples/s: 3005.693 1612027332.7877836
train: epoch 84, iter 1100, loss: 2.643903, top_1: 0.570977, top_k: 0.791797, samples/s: 2945.516 1612027341.4789035
train: epoch 84, iter 1200, loss: 2.702014, top_1: 0.569492, top_k: 0.793594, samples/s: 2984.754 1612027350.0558627
train: epoch 84, iter 1300, loss: 2.835901, top_1: 0.558867, top_k: 0.785391, samples/s: 2984.671 1612027358.6329813
train: epoch 84, iter 1400, loss: 2.979326, top_1: 0.566836, top_k: 0.792422, samples/s: 2954.726 1612027367.297135
train: epoch 84, iter 1500, loss: 2.908486, top_1: 0.566836, top_k: 0.793398, samples/s: 2971.531 1612027375.9122038
train: epoch 84, iter 1600, loss: 2.675388, top_1: 0.559141, top_k: 0.782539, samples/s: 2964.439 1612027384.547855
train: epoch 84, iter 1700, loss: 2.865442, top_1: 0.561094, top_k: 0.785508, samples/s: 2957.385 1612027393.2041457
train: epoch 84, iter 1800, loss: 2.967703, top_1: 0.557656, top_k: 0.784102, samples/s: 2942.997 1612027401.9028916
train: epoch 84, iter 1900, loss: 2.733593, top_1: 0.561953, top_k: 0.785625, samples/s: 2959.571 1612027410.5526695
train: epoch 84, iter 2000, loss: 2.632592, top_1: 0.564648, top_k: 0.790430, samples/s: 2950.316 1612027419.2297072
train: epoch 84, iter 2100, loss: 2.800100, top_1: 0.557734, top_k: 0.782266, samples/s: 2998.148 1612027427.7683136
train: epoch 84, iter 2200, loss: 2.831051, top_1: 0.557383, top_k: 0.785156, samples/s: 2946.318 1612027436.4573011
train: epoch 84, iter 2300, loss: 2.774078, top_1: 0.564219, top_k: 0.788828, samples/s: 2977.506 1612027445.0550408
train: epoch 84, iter 2400, loss: 2.871563, top_1: 0.558125, top_k: 0.782773, samples/s: 2920.973 1612027453.8191442
train: epoch 84, iter 2500, loss: 2.793991, top_1: 0.562773, top_k: 0.785586, samples/s: 2969.715 1612027462.4394846
train: epoch 84, iter 2600, loss: 2.779536, top_1: 0.560000, top_k: 0.786094, samples/s: 2954.087 1612027471.1054544
train: epoch 84, iter 2700, loss: 2.739753, top_1: 0.557109, top_k: 0.786328, samples/s: 2905.306 1612027479.9169147
train: epoch 84, iter 2800, loss: 2.995261, top_1: 0.562305, top_k: 0.785078, samples/s: 2979.198 1612027488.5097978
train: epoch 84, iter 2900, loss: 2.706780, top_1: 0.561523, top_k: 0.789531, samples/s: 2939.076 1612027497.2200418
train: epoch 84, iter 3000, loss: 3.019441, top_1: 0.558086, top_k: 0.781719, samples/s: 2992.024 1612027505.7761254
train: epoch 84, iter 3100, loss: 2.877120, top_1: 0.561992, top_k: 0.788203, samples/s: 2977.576 1612027514.3737555
train: epoch 84, iter 3200, loss: 2.869404, top_1: 0.558984, top_k: 0.785352, samples/s: 2908.076 1612027523.176858
train: epoch 84, iter 3300, loss: 2.764492, top_1: 0.555937, top_k: 0.782617, samples/s: 2925.045 1612027531.9288871
train: epoch 84, iter 3400, loss: 2.802353, top_1: 0.562852, top_k: 0.786016, samples/s: 2977.402 1612027540.5268948
train: epoch 84, iter 3500, loss: 2.888786, top_1: 0.564258, top_k: 0.783633, samples/s: 2953.556 1612027549.194403
train: epoch 84, iter 3600, loss: 2.515220, top_1: 0.562773, top_k: 0.785742, samples/s: 2941.614 1612027557.8971229
train: epoch 84, iter 3700, loss: 2.965465, top_1: 0.555703, top_k: 0.785781, samples/s: 2948.424 1612027566.5797799
train: epoch 84, iter 3800, loss: 2.982686, top_1: 0.562227, top_k: 0.786289, samples/s: 2941.487 1612027575.2829115
train: epoch 84, iter 3900, loss: 2.824599, top_1: 0.558711, top_k: 0.784258, samples/s: 2965.150 1612027583.9163835
train: epoch 84, iter 4000, loss: 2.669550, top_1: 0.567305, top_k: 0.788047, samples/s: 2978.384 1612027592.511729
train: epoch 84, iter 4100, loss: 2.856282, top_1: 0.560898, top_k: 0.786094, samples/s: 2978.809 1612027601.105742
train: epoch 84, iter 4200, loss: 2.895466, top_1: 0.562422, top_k: 0.784766, samples/s: 2978.550 1612027609.7005188
train: epoch 84, iter 4300, loss: 2.965042, top_1: 0.557109, top_k: 0.788125, samples/s: 2893.607 1612027618.5476792
train: epoch 84, iter 4400, loss: 2.780641, top_1: 0.559688, top_k: 0.784922, samples/s: 2940.764 1612027627.2528965
train: epoch 84, iter 4500, loss: 2.780695, top_1: 0.562266, top_k: 0.787813, samples/s: 2959.983 1612027635.901529
train: epoch 84, iter 4600, loss: 3.070654, top_1: 0.560352, top_k: 0.781211, samples/s: 2980.064 1612027644.4919527
train: epoch 84, iter 4700, loss: 2.877569, top_1: 0.558281, top_k: 0.783711, samples/s: 2942.714 1612027653.1913967
train: epoch 84, iter 4800, loss: 2.702860, top_1: 0.561016, top_k: 0.785469, samples/s: 2903.032 1612027662.009801
train: epoch 84, iter 4900, loss: 2.767730, top_1: 0.558984, top_k: 0.781680, samples/s: 2977.837 1612027670.606602
train: epoch 84, iter 5000, loss: 2.871919, top_1: 0.563984, top_k: 0.789492, samples/s: 2962.771 1612027679.2471795
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_84.
validation: epoch 84, iter 195, top_1: 0.602985, top_k: 0.835477, samples/s: 2999.428 1612027696.1498713
train: epoch 85, iter 100, loss: 2.988096, top_1: 0.571875, top_k: 0.790117, samples/s: 2957.021 1612027720.5710204
train: epoch 85, iter 200, loss: 2.746128, top_1: 0.569492, top_k: 0.793008, samples/s: 3021.572 1612027729.0434358
train: epoch 85, iter 300, loss: 2.839934, top_1: 0.572344, top_k: 0.789961, samples/s: 3000.159 1612027737.5762768
train: epoch 85, iter 400, loss: 2.936899, top_1: 0.564648, top_k: 0.785820, samples/s: 2942.536 1612027746.2763033
train: epoch 85, iter 500, loss: 2.720742, top_1: 0.569492, top_k: 0.795039, samples/s: 2982.513 1612027754.8595555
train: epoch 85, iter 600, loss: 2.854570, top_1: 0.566406, top_k: 0.789062, samples/s: 3015.748 1612027763.3484623
train: epoch 85, iter 700, loss: 2.872646, top_1: 0.570312, top_k: 0.794141, samples/s: 2995.595 1612027771.894263
train: epoch 85, iter 800, loss: 2.939019, top_1: 0.567539, top_k: 0.792305, samples/s: 2941.646 1612027780.5968945
train: epoch 85, iter 900, loss: 2.747630, top_1: 0.568828, top_k: 0.788125, samples/s: 2982.301 1612027789.1809182
train: epoch 85, iter 1000, loss: 2.861208, top_1: 0.565937, top_k: 0.793555, samples/s: 2987.902 1612027797.7487311
train: epoch 85, iter 1100, loss: 2.726669, top_1: 0.568945, top_k: 0.792188, samples/s: 3020.209 1612027806.2249985
train: epoch 85, iter 1200, loss: 2.673575, top_1: 0.564961, top_k: 0.791094, samples/s: 2988.075 1612027814.7924466
train: epoch 85, iter 1300, loss: 2.950234, top_1: 0.561328, top_k: 0.791172, samples/s: 2937.442 1612027823.5074456
train: epoch 85, iter 1400, loss: 2.864625, top_1: 0.561133, top_k: 0.786563, samples/s: 2951.039 1612027832.1823308
train: epoch 85, iter 1500, loss: 2.935148, top_1: 0.567734, top_k: 0.790977, samples/s: 2965.462 1612027840.8150387
train: epoch 85, iter 1600, loss: 2.916241, top_1: 0.565508, top_k: 0.789922, samples/s: 2971.315 1612027849.4307628
train: epoch 85, iter 1700, loss: 2.520292, top_1: 0.564414, top_k: 0.788633, samples/s: 2967.548 1612027858.0574114
train: epoch 85, iter 1800, loss: 2.777673, top_1: 0.560859, top_k: 0.786641, samples/s: 2939.901 1612027866.765203
train: epoch 85, iter 1900, loss: 2.916962, top_1: 0.563320, top_k: 0.788789, samples/s: 2974.106 1612027875.3728979
train: epoch 85, iter 2000, loss: 2.876607, top_1: 0.562187, top_k: 0.788242, samples/s: 2964.696 1612027884.007781
train: epoch 85, iter 2100, loss: 3.027564, top_1: 0.566094, top_k: 0.788750, samples/s: 2961.567 1612027892.651856
train: epoch 85, iter 2200, loss: 2.832044, top_1: 0.566836, top_k: 0.789609, samples/s: 3024.091 1612027901.1171982
train: epoch 85, iter 2300, loss: 2.759939, top_1: 0.565781, top_k: 0.785039, samples/s: 2949.901 1612027909.795549
train: epoch 85, iter 2400, loss: 2.829558, top_1: 0.563281, top_k: 0.786055, samples/s: 2904.154 1612027918.6104145
train: epoch 85, iter 2500, loss: 2.622001, top_1: 0.566016, top_k: 0.790859, samples/s: 2891.118 1612027927.4650872
train: epoch 85, iter 2600, loss: 2.890064, top_1: 0.557031, top_k: 0.784961, samples/s: 2982.981 1612027936.0471528
train: epoch 85, iter 2700, loss: 2.818149, top_1: 0.564258, top_k: 0.786016, samples/s: 2985.668 1612027944.6215212
train: epoch 85, iter 2800, loss: 2.766266, top_1: 0.561992, top_k: 0.785312, samples/s: 2980.661 1612027953.21013
train: epoch 85, iter 2900, loss: 2.977012, top_1: 0.564336, top_k: 0.787383, samples/s: 2979.670 1612027961.80175
train: epoch 85, iter 3000, loss: 2.766839, top_1: 0.565859, top_k: 0.786641, samples/s: 2901.756 1612027970.6239376
train: epoch 85, iter 3100, loss: 2.809396, top_1: 0.566953, top_k: 0.792773, samples/s: 2961.229 1612027979.2690175
train: epoch 85, iter 3200, loss: 3.010314, top_1: 0.560859, top_k: 0.786914, samples/s: 2986.145 1612027987.8419595
train: epoch 85, iter 3300, loss: 2.804175, top_1: 0.563164, top_k: 0.788398, samples/s: 2940.880 1612027996.546786
train: epoch 85, iter 3400, loss: 3.073864, top_1: 0.563984, top_k: 0.790156, samples/s: 3011.785 1612028005.0466871
train: epoch 85, iter 3500, loss: 2.670111, top_1: 0.562187, top_k: 0.787422, samples/s: 2934.934 1612028013.769261
train: epoch 85, iter 3600, loss: 2.739047, top_1: 0.564648, top_k: 0.786055, samples/s: 2874.188 1612028022.6763036
train: epoch 85, iter 3700, loss: 2.715870, top_1: 0.563398, top_k: 0.788203, samples/s: 3009.200 1612028031.1835852
train: epoch 85, iter 3800, loss: 2.967898, top_1: 0.564219, top_k: 0.790508, samples/s: 2998.127 1612028039.7220697
train: epoch 85, iter 3900, loss: 2.803641, top_1: 0.561758, top_k: 0.788242, samples/s: 2969.410 1612028048.343287
train: epoch 85, iter 4000, loss: 2.771106, top_1: 0.560820, top_k: 0.783438, samples/s: 2997.255 1612028056.8844109
train: epoch 85, iter 4100, loss: 2.735764, top_1: 0.562695, top_k: 0.788047, samples/s: 2960.258 1612028065.532301
train: epoch 85, iter 4200, loss: 2.918329, top_1: 0.564102, top_k: 0.786602, samples/s: 2995.880 1612028074.0774353
train: epoch 85, iter 4300, loss: 2.864624, top_1: 0.555820, top_k: 0.784492, samples/s: 2959.503 1612028082.7274497
train: epoch 85, iter 4400, loss: 2.807258, top_1: 0.563594, top_k: 0.785781, samples/s: 2941.867 1612028091.4294243
train: epoch 85, iter 4500, loss: 2.759608, top_1: 0.558125, top_k: 0.782891, samples/s: 2963.533 1612028100.0678332
train: epoch 85, iter 4600, loss: 2.819971, top_1: 0.559609, top_k: 0.784023, samples/s: 2936.323 1612028108.786245
train: epoch 85, iter 4700, loss: 2.706724, top_1: 0.560195, top_k: 0.784258, samples/s: 2981.942 1612028117.3711228
train: epoch 85, iter 4800, loss: 2.749161, top_1: 0.552891, top_k: 0.783203, samples/s: 3012.333 1612028125.8696005
train: epoch 85, iter 4900, loss: 2.665544, top_1: 0.564648, top_k: 0.786875, samples/s: 2978.005 1612028134.4658656
train: epoch 85, iter 5000, loss: 2.628573, top_1: 0.569180, top_k: 0.790664, samples/s: 2998.632 1612028143.00315
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_85.
validation: epoch 85, iter 195, top_1: 0.608053, top_k: 0.835437, samples/s: 2978.967 1612028160.0252185
train: epoch 86, iter 100, loss: 2.915127, top_1: 0.564453, top_k: 0.792617, samples/s: 2868.736 1612028184.488863
train: epoch 86, iter 200, loss: 2.912967, top_1: 0.570195, top_k: 0.790352, samples/s: 3006.162 1612028193.0045867
train: epoch 86, iter 300, loss: 2.591573, top_1: 0.572852, top_k: 0.800000, samples/s: 2997.846 1612028201.54409
train: epoch 86, iter 400, loss: 2.663056, top_1: 0.573242, top_k: 0.796719, samples/s: 2958.966 1612028210.1957803
train: epoch 86, iter 500, loss: 2.737257, top_1: 0.573203, top_k: 0.797852, samples/s: 3005.152 1612028218.714505
train: epoch 86, iter 600, loss: 3.090626, top_1: 0.566719, top_k: 0.792773, samples/s: 2938.373 1612028227.4268873
train: epoch 86, iter 700, loss: 2.894779, top_1: 0.569023, top_k: 0.793320, samples/s: 2934.668 1612028236.150057
train: epoch 86, iter 800, loss: 2.650317, top_1: 0.571055, top_k: 0.795273, samples/s: 2938.287 1612028244.8627143
train: epoch 86, iter 900, loss: 2.680560, top_1: 0.572266, top_k: 0.793594, samples/s: 2997.133 1612028253.4041286
train: epoch 86, iter 1000, loss: 2.683897, top_1: 0.570430, top_k: 0.794023, samples/s: 2981.180 1612028261.9913664
train: epoch 86, iter 1100, loss: 2.642753, top_1: 0.566289, top_k: 0.788672, samples/s: 2958.714 1612028270.643957
train: epoch 86, iter 1200, loss: 2.880497, top_1: 0.569023, top_k: 0.792930, samples/s: 3002.003 1612028279.1713889
train: epoch 86, iter 1300, loss: 2.807976, top_1: 0.566172, top_k: 0.792852, samples/s: 2944.917 1612028287.8642733
train: epoch 86, iter 1400, loss: 2.657431, top_1: 0.570352, top_k: 0.788828, samples/s: 2953.585 1612028296.5317504
train: epoch 86, iter 1500, loss: 2.916947, top_1: 0.562383, top_k: 0.786758, samples/s: 2995.542 1612028305.0777678
train: epoch 86, iter 1600, loss: 3.031139, top_1: 0.570898, top_k: 0.790078, samples/s: 2984.780 1612028313.654589
train: epoch 86, iter 1700, loss: 2.858171, top_1: 0.563516, top_k: 0.791797, samples/s: 2942.499 1612028322.3547335
train: epoch 86, iter 1800, loss: 2.793120, top_1: 0.564688, top_k: 0.791172, samples/s: 2955.209 1612028331.01743
train: epoch 86, iter 1900, loss: 2.735495, top_1: 0.571680, top_k: 0.792813, samples/s: 2946.814 1612028339.7047615
train: epoch 86, iter 2000, loss: 2.905706, top_1: 0.563477, top_k: 0.791445, samples/s: 2964.895 1612028348.3391283
train: epoch 86, iter 2100, loss: 2.703905, top_1: 0.569766, top_k: 0.791250, samples/s: 2986.549 1612028356.9108763
train: epoch 86, iter 2200, loss: 2.901820, top_1: 0.567656, top_k: 0.793984, samples/s: 2914.477 1612028365.6946094
train: epoch 86, iter 2300, loss: 2.796962, top_1: 0.563359, top_k: 0.785781, samples/s: 2948.248 1612028374.377734
train: epoch 86, iter 2400, loss: 3.047160, top_1: 0.566836, top_k: 0.790000, samples/s: 2957.859 1612028383.0326421
train: epoch 86, iter 2500, loss: 2.786601, top_1: 0.559141, top_k: 0.788594, samples/s: 2952.745 1612028391.7025225
train: epoch 86, iter 2600, loss: 2.838361, top_1: 0.567187, top_k: 0.790391, samples/s: 2989.678 1612028400.2653677
train: epoch 86, iter 2700, loss: 2.789257, top_1: 0.562031, top_k: 0.786875, samples/s: 2942.161 1612028408.966436
train: epoch 86, iter 2800, loss: 2.654117, top_1: 0.561523, top_k: 0.788320, samples/s: 2978.513 1612028417.5613678
train: epoch 86, iter 2900, loss: 2.690918, top_1: 0.561523, top_k: 0.787656, samples/s: 2905.595 1612028426.371969
train: epoch 86, iter 3000, loss: 2.987407, top_1: 0.562930, top_k: 0.788086, samples/s: 2941.568 1612028435.074827
train: epoch 86, iter 3100, loss: 2.846101, top_1: 0.562148, top_k: 0.790625, samples/s: 2943.447 1612028443.7720962
train: epoch 86, iter 3200, loss: 2.772576, top_1: 0.561367, top_k: 0.786094, samples/s: 2915.324 1612028452.5532856
train: epoch 86, iter 3300, loss: 2.861463, top_1: 0.566211, top_k: 0.791914, samples/s: 2978.375 1612028461.1485066
train: epoch 86, iter 3400, loss: 2.953447, top_1: 0.567187, top_k: 0.787813, samples/s: 2966.516 1612028469.778174
train: epoch 86, iter 3500, loss: 2.816037, top_1: 0.564336, top_k: 0.790469, samples/s: 2986.683 1612028478.349538
train: epoch 86, iter 3600, loss: 3.047901, top_1: 0.563516, top_k: 0.789805, samples/s: 2993.183 1612028486.9023316
train: epoch 86, iter 3700, loss: 2.879279, top_1: 0.564531, top_k: 0.790430, samples/s: 2963.217 1612028495.5415814
train: epoch 86, iter 3800, loss: 2.864990, top_1: 0.565000, top_k: 0.787500, samples/s: 2964.051 1612028504.1783907
train: epoch 86, iter 3900, loss: 2.734688, top_1: 0.557070, top_k: 0.789141, samples/s: 2955.718 1612028512.8395724
train: epoch 86, iter 4000, loss: 2.764957, top_1: 0.563984, top_k: 0.786602, samples/s: 2948.522 1612028521.5219793
train: epoch 86, iter 4100, loss: 2.823712, top_1: 0.559648, top_k: 0.784531, samples/s: 2974.608 1612028530.128092
train: epoch 86, iter 4200, loss: 2.690927, top_1: 0.563320, top_k: 0.789062, samples/s: 2968.837 1612028538.7509758
train: epoch 86, iter 4300, loss: 2.700951, top_1: 0.557734, top_k: 0.784023, samples/s: 2890.424 1612028547.6078744
train: epoch 86, iter 4400, loss: 2.726823, top_1: 0.564023, top_k: 0.785859, samples/s: 2850.655 1612028556.588199
train: epoch 86, iter 4500, loss: 2.889657, top_1: 0.560391, top_k: 0.785469, samples/s: 2966.907 1612028565.216763
train: epoch 86, iter 4600, loss: 2.852632, top_1: 0.564180, top_k: 0.785391, samples/s: 2896.036 1612028574.056416
train: epoch 86, iter 4700, loss: 2.777870, top_1: 0.569961, top_k: 0.791523, samples/s: 2974.319 1612028582.6633875
train: epoch 86, iter 4800, loss: 2.790240, top_1: 0.557539, top_k: 0.783945, samples/s: 2891.609 1612028591.516613
train: epoch 86, iter 4900, loss: 2.826684, top_1: 0.561406, top_k: 0.788477, samples/s: 2981.691 1612028600.1023242
train: epoch 86, iter 5000, loss: 2.512203, top_1: 0.568164, top_k: 0.794336, samples/s: 2955.220 1612028608.7650156
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_86.
validation: epoch 86, iter 195, top_1: 0.606631, top_k: 0.832572, samples/s: 2930.201 1612028626.0607517
train: epoch 87, iter 100, loss: 2.895535, top_1: 0.579570, top_k: 0.799336, samples/s: 2898.562 1612028650.4824061
train: epoch 87, iter 200, loss: 2.867356, top_1: 0.570391, top_k: 0.796133, samples/s: 3006.341 1612028658.997728
train: epoch 87, iter 300, loss: 2.862994, top_1: 0.570508, top_k: 0.791172, samples/s: 2992.493 1612028667.5526729
train: epoch 87, iter 400, loss: 2.945869, top_1: 0.574883, top_k: 0.796914, samples/s: 2954.368 1612028676.217552
train: epoch 87, iter 500, loss: 2.869411, top_1: 0.575508, top_k: 0.795273, samples/s: 2966.917 1612028684.8460822
train: epoch 87, iter 600, loss: 2.575496, top_1: 0.571914, top_k: 0.792266, samples/s: 2989.773 1612028693.408612
train: epoch 87, iter 700, loss: 2.808128, top_1: 0.571992, top_k: 0.794727, samples/s: 2985.882 1612028701.9823039
train: epoch 87, iter 800, loss: 2.821247, top_1: 0.567227, top_k: 0.792930, samples/s: 2985.115 1612028710.5582201
train: epoch 87, iter 900, loss: 2.829017, top_1: 0.574961, top_k: 0.798438, samples/s: 3007.811 1612028719.0693684
train: epoch 87, iter 1000, loss: 2.848018, top_1: 0.566641, top_k: 0.791602, samples/s: 2991.540 1612028727.6269765
train: epoch 87, iter 1100, loss: 2.756184, top_1: 0.564102, top_k: 0.790000, samples/s: 2857.861 1612028736.5845613
train: epoch 87, iter 1200, loss: 2.799503, top_1: 0.570977, top_k: 0.790547, samples/s: 3000.017 1612028745.1178453
train: epoch 87, iter 1300, loss: 2.735171, top_1: 0.567852, top_k: 0.794297, samples/s: 2969.780 1612028753.7380617
train: epoch 87, iter 1400, loss: 2.991085, top_1: 0.568711, top_k: 0.786836, samples/s: 2978.558 1612028762.3327842
train: epoch 87, iter 1500, loss: 2.799641, top_1: 0.572852, top_k: 0.794883, samples/s: 2927.931 1612028771.0761926
train: epoch 87, iter 1600, loss: 2.790121, top_1: 0.567852, top_k: 0.789492, samples/s: 2961.756 1612028779.7196934
train: epoch 87, iter 1700, loss: 2.831410, top_1: 0.569414, top_k: 0.791836, samples/s: 2963.988 1612028788.3567338
train: epoch 87, iter 1800, loss: 2.770162, top_1: 0.571445, top_k: 0.790859, samples/s: 2979.752 1612028796.9480155
train: epoch 87, iter 1900, loss: 2.723475, top_1: 0.569609, top_k: 0.790664, samples/s: 2922.405 1612028805.7079723
train: epoch 87, iter 2000, loss: 2.760783, top_1: 0.569883, top_k: 0.792617, samples/s: 2944.086 1612028814.4033136
train: epoch 87, iter 2100, loss: 2.732930, top_1: 0.570156, top_k: 0.790234, samples/s: 2958.330 1612028823.0568473
train: epoch 87, iter 2200, loss: 2.648576, top_1: 0.572266, top_k: 0.794063, samples/s: 2960.066 1612028831.7053003
train: epoch 87, iter 2300, loss: 2.752040, top_1: 0.566641, top_k: 0.789023, samples/s: 2932.033 1612028840.436436
train: epoch 87, iter 2400, loss: 2.819181, top_1: 0.573008, top_k: 0.793125, samples/s: 2980.914 1612028849.024458
train: epoch 87, iter 2500, loss: 2.920792, top_1: 0.565195, top_k: 0.790469, samples/s: 2964.858 1612028857.658895
train: epoch 87, iter 2600, loss: 2.844670, top_1: 0.567227, top_k: 0.792344, samples/s: 2961.705 1612028866.3025656
train: epoch 87, iter 2700, loss: 2.766488, top_1: 0.564883, top_k: 0.788594, samples/s: 2982.838 1612028874.8850486
train: epoch 87, iter 2800, loss: 2.881009, top_1: 0.565312, top_k: 0.791016, samples/s: 2950.072 1612028883.5627518
train: epoch 87, iter 2900, loss: 2.733797, top_1: 0.576211, top_k: 0.796641, samples/s: 2983.542 1612028892.143155
train: epoch 87, iter 3000, loss: 2.701029, top_1: 0.565742, top_k: 0.787070, samples/s: 2952.335 1612028900.8142955
train: epoch 87, iter 3100, loss: 2.743897, top_1: 0.565430, top_k: 0.791992, samples/s: 2917.363 1612028909.589314
train: epoch 87, iter 3200, loss: 2.903279, top_1: 0.565547, top_k: 0.793125, samples/s: 2875.852 1612028918.4910388
train: epoch 87, iter 3300, loss: 2.691201, top_1: 0.563086, top_k: 0.789414, samples/s: 2878.077 1612028927.3858662
train: epoch 87, iter 3400, loss: 2.810312, top_1: 0.565391, top_k: 0.790859, samples/s: 2952.576 1612028936.0562642
train: epoch 87, iter 3500, loss: 2.804885, top_1: 0.565078, top_k: 0.788125, samples/s: 2948.054 1612028944.7399292
train: epoch 87, iter 3600, loss: 2.840872, top_1: 0.567930, top_k: 0.789062, samples/s: 2985.615 1612028953.3144805
train: epoch 87, iter 3700, loss: 2.753993, top_1: 0.568242, top_k: 0.791055, samples/s: 2988.035 1612028961.8819563
train: epoch 87, iter 3800, loss: 2.907888, top_1: 0.567891, top_k: 0.789492, samples/s: 2961.078 1612028970.5274918
train: epoch 87, iter 3900, loss: 2.960464, top_1: 0.555234, top_k: 0.786094, samples/s: 2866.810 1612028979.4571974
train: epoch 87, iter 4000, loss: 2.813979, top_1: 0.561133, top_k: 0.784805, samples/s: 2995.445 1612028988.0034933
train: epoch 87, iter 4100, loss: 3.024942, top_1: 0.568008, top_k: 0.791211, samples/s: 2814.977 1612028997.0977793
train: epoch 87, iter 4200, loss: 2.913183, top_1: 0.568203, top_k: 0.789141, samples/s: 2965.737 1612029005.7296338
train: epoch 87, iter 4300, loss: 2.692390, top_1: 0.562695, top_k: 0.789492, samples/s: 2935.335 1612029014.4509578
train: epoch 87, iter 4400, loss: 2.954806, top_1: 0.565625, top_k: 0.784258, samples/s: 2947.879 1612029023.135187
train: epoch 87, iter 4500, loss: 2.613416, top_1: 0.563242, top_k: 0.788320, samples/s: 3007.162 1612029031.6481733
train: epoch 87, iter 4600, loss: 2.854401, top_1: 0.573008, top_k: 0.794375, samples/s: 3001.499 1612029040.177322
train: epoch 87, iter 4700, loss: 2.739510, top_1: 0.569102, top_k: 0.787500, samples/s: 2970.853 1612029048.794283
train: epoch 87, iter 4800, loss: 2.743493, top_1: 0.559648, top_k: 0.789922, samples/s: 2960.828 1612029057.4405355
train: epoch 87, iter 4900, loss: 2.878450, top_1: 0.562695, top_k: 0.784648, samples/s: 2969.612 1612029066.0612316
train: epoch 87, iter 5000, loss: 2.932235, top_1: 0.566406, top_k: 0.789727, samples/s: 2912.902 1612029074.8497841
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_87.
validation: epoch 87, iter 195, top_1: 0.609736, top_k: 0.837560, samples/s: 2993.562 1612029091.689736
train: epoch 88, iter 100, loss: 2.699151, top_1: 0.580820, top_k: 0.800117, samples/s: 2901.399 1612029116.1430504
train: epoch 88, iter 200, loss: 2.805553, top_1: 0.574766, top_k: 0.799180, samples/s: 2991.963 1612029124.6993744
train: epoch 88, iter 300, loss: 2.769401, top_1: 0.578945, top_k: 0.801953, samples/s: 2988.805 1612029133.2645175
train: epoch 88, iter 400, loss: 2.813661, top_1: 0.575937, top_k: 0.799453, samples/s: 2973.088 1612029141.8751202
train: epoch 88, iter 500, loss: 2.755129, top_1: 0.571172, top_k: 0.794570, samples/s: 3043.503 1612029150.2864795
train: epoch 88, iter 600, loss: 2.884146, top_1: 0.576523, top_k: 0.792813, samples/s: 2990.744 1612029158.8462365
train: epoch 88, iter 700, loss: 2.858193, top_1: 0.575547, top_k: 0.795195, samples/s: 2988.232 1612029167.4132476
train: epoch 88, iter 800, loss: 2.623070, top_1: 0.576523, top_k: 0.799766, samples/s: 2948.345 1612029176.0959735
train: epoch 88, iter 900, loss: 2.804889, top_1: 0.574141, top_k: 0.791641, samples/s: 2943.028 1612029184.7945454
train: epoch 88, iter 1000, loss: 2.884890, top_1: 0.574531, top_k: 0.797617, samples/s: 2974.855 1612029193.3999345
train: epoch 88, iter 1100, loss: 2.877509, top_1: 0.565781, top_k: 0.791953, samples/s: 2985.771 1612029201.9739993
train: epoch 88, iter 1200, loss: 2.702438, top_1: 0.575273, top_k: 0.797656, samples/s: 2991.404 1612029210.5318427
train: epoch 88, iter 1300, loss: 2.734156, top_1: 0.573203, top_k: 0.793047, samples/s: 2906.417 1612029219.3399644
train: epoch 88, iter 1400, loss: 2.993212, top_1: 0.571719, top_k: 0.791367, samples/s: 3025.170 1612029227.8022707
train: epoch 88, iter 1500, loss: 2.874821, top_1: 0.569258, top_k: 0.793516, samples/s: 2953.606 1612029236.4696417
train: epoch 88, iter 1600, loss: 2.777098, top_1: 0.567187, top_k: 0.791797, samples/s: 2967.317 1612029245.0969646
train: epoch 88, iter 1700, loss: 2.856837, top_1: 0.571914, top_k: 0.795859, samples/s: 2964.071 1612029253.7337353
train: epoch 88, iter 1800, loss: 2.747793, top_1: 0.568789, top_k: 0.793477, samples/s: 2970.795 1612029262.3509629
train: epoch 88, iter 1900, loss: 2.818792, top_1: 0.569023, top_k: 0.795352, samples/s: 2892.734 1612029271.2007606
train: epoch 88, iter 2000, loss: 2.726628, top_1: 0.573477, top_k: 0.796406, samples/s: 2930.505 1612029279.9364395
train: epoch 88, iter 2100, loss: 2.846050, top_1: 0.568008, top_k: 0.794336, samples/s: 2958.569 1612029288.5892086
train: epoch 88, iter 2200, loss: 2.889085, top_1: 0.567266, top_k: 0.793125, samples/s: 2983.016 1612029297.1711943
train: epoch 88, iter 2300, loss: 2.811113, top_1: 0.567148, top_k: 0.788281, samples/s: 2986.130 1612029305.7445595
train: epoch 88, iter 2400, loss: 2.997961, top_1: 0.567930, top_k: 0.788477, samples/s: 2909.051 1612029314.5442965
train: epoch 88, iter 2500, loss: 2.639781, top_1: 0.570273, top_k: 0.795273, samples/s: 2941.406 1612029323.247585
train: epoch 88, iter 2600, loss: 2.991477, top_1: 0.561875, top_k: 0.790469, samples/s: 2968.960 1612029331.8701396
train: epoch 88, iter 2700, loss: 2.855486, top_1: 0.568438, top_k: 0.790742, samples/s: 2908.732 1612029340.6711853
train: epoch 88, iter 2800, loss: 2.729801, top_1: 0.571250, top_k: 0.793984, samples/s: 2897.259 1612029349.5071838
train: epoch 88, iter 2900, loss: 2.582601, top_1: 0.569258, top_k: 0.794609, samples/s: 2956.768 1612029358.165798
train: epoch 88, iter 3000, loss: 2.849344, top_1: 0.569453, top_k: 0.794102, samples/s: 2976.861 1612029366.764876
train: epoch 88, iter 3100, loss: 2.858155, top_1: 0.566758, top_k: 0.787969, samples/s: 2929.416 1612029375.503894
train: epoch 88, iter 3200, loss: 2.791334, top_1: 0.571250, top_k: 0.793945, samples/s: 2897.579 1612029384.338896
train: epoch 88, iter 3300, loss: 2.840705, top_1: 0.567734, top_k: 0.792227, samples/s: 2906.326 1612029393.1471906
train: epoch 88, iter 3400, loss: 2.720158, top_1: 0.562930, top_k: 0.791992, samples/s: 2996.197 1612029401.6914105
train: epoch 88, iter 3500, loss: 2.640946, top_1: 0.566016, top_k: 0.790781, samples/s: 2863.829 1612029410.6305194
train: epoch 88, iter 3600, loss: 2.906149, top_1: 0.564531, top_k: 0.789766, samples/s: 2974.609 1612029419.2366
train: epoch 88, iter 3700, loss: 2.580976, top_1: 0.567031, top_k: 0.792305, samples/s: 2961.309 1612029427.88145
train: epoch 88, iter 3800, loss: 2.733189, top_1: 0.566953, top_k: 0.793789, samples/s: 2997.209 1612029436.4226809
train: epoch 88, iter 3900, loss: 2.690920, top_1: 0.565703, top_k: 0.790859, samples/s: 3004.943 1612029444.9420106
train: epoch 88, iter 4000, loss: 2.779039, top_1: 0.569297, top_k: 0.794648, samples/s: 2973.778 1612029453.5505834
train: epoch 88, iter 4100, loss: 2.775411, top_1: 0.569258, top_k: 0.790430, samples/s: 2938.207 1612029462.2633786
train: epoch 88, iter 4200, loss: 2.754337, top_1: 0.570391, top_k: 0.791172, samples/s: 3010.876 1612029470.7660568
train: epoch 88, iter 4300, loss: 2.674512, top_1: 0.561602, top_k: 0.793867, samples/s: 2972.948 1612029479.3768954
train: epoch 88, iter 4400, loss: 2.823988, top_1: 0.564180, top_k: 0.789727, samples/s: 3017.470 1612029487.8608794
train: epoch 88, iter 4500, loss: 2.804292, top_1: 0.568867, top_k: 0.793984, samples/s: 2989.494 1612029496.4242356
train: epoch 88, iter 4600, loss: 2.823426, top_1: 0.570469, top_k: 0.785234, samples/s: 2943.372 1612029505.121712
train: epoch 88, iter 4700, loss: 2.735645, top_1: 0.564805, top_k: 0.791719, samples/s: 2996.017 1612029513.6663265
train: epoch 88, iter 4800, loss: 2.613307, top_1: 0.566445, top_k: 0.787578, samples/s: 3003.691 1612029522.1896627
train: epoch 88, iter 4900, loss: 2.930882, top_1: 0.570781, top_k: 0.792695, samples/s: 2935.380 1612029530.9103208
train: epoch 88, iter 5000, loss: 2.590152, top_1: 0.569258, top_k: 0.793672, samples/s: 3008.591 1612029539.419328
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_88.
validation: epoch 88, iter 195, top_1: 0.616927, top_k: 0.843229, samples/s: 2925.956 1612029556.7051911
train: epoch 89, iter 100, loss: 2.819988, top_1: 0.577383, top_k: 0.800977, samples/s: 2985.721 1612029581.1630356
train: epoch 89, iter 200, loss: 2.824003, top_1: 0.570000, top_k: 0.795078, samples/s: 2978.770 1612029589.7577577
train: epoch 89, iter 300, loss: 2.777417, top_1: 0.572578, top_k: 0.796797, samples/s: 3036.021 1612029598.1888916
train: epoch 89, iter 400, loss: 2.672530, top_1: 0.579492, top_k: 0.794297, samples/s: 2921.772 1612029606.9507072
train: epoch 89, iter 500, loss: 2.643154, top_1: 0.575937, top_k: 0.795937, samples/s: 2986.633 1612029615.5222027
train: epoch 89, iter 600, loss: 2.911067, top_1: 0.581289, top_k: 0.798516, samples/s: 2990.532 1612029624.0826242
train: epoch 89, iter 700, loss: 2.696319, top_1: 0.574023, top_k: 0.792461, samples/s: 2839.839 1612029633.097317
train: epoch 89, iter 800, loss: 2.732132, top_1: 0.573477, top_k: 0.794648, samples/s: 2914.229 1612029641.8817215
train: epoch 89, iter 900, loss: 2.978928, top_1: 0.571445, top_k: 0.794180, samples/s: 2990.056 1612029650.4433622
train: epoch 89, iter 1000, loss: 2.764332, top_1: 0.576680, top_k: 0.798438, samples/s: 2992.829 1612029658.9971597
train: epoch 89, iter 1100, loss: 2.761899, top_1: 0.571680, top_k: 0.794766, samples/s: 3002.528 1612029667.5232658
train: epoch 89, iter 1200, loss: 2.829804, top_1: 0.570195, top_k: 0.797773, samples/s: 2959.045 1612029676.1748037
train: epoch 89, iter 1300, loss: 2.893155, top_1: 0.571406, top_k: 0.795703, samples/s: 2986.461 1612029684.7468152
train: epoch 89, iter 1400, loss: 3.008702, top_1: 0.575664, top_k: 0.796172, samples/s: 2982.332 1612029693.3306737
train: epoch 89, iter 1500, loss: 2.799251, top_1: 0.573867, top_k: 0.793477, samples/s: 2962.046 1612029701.9733806
train: epoch 89, iter 1600, loss: 2.818313, top_1: 0.578281, top_k: 0.799844, samples/s: 2939.155 1612029710.6833
train: epoch 89, iter 1700, loss: 2.739718, top_1: 0.574102, top_k: 0.798008, samples/s: 2990.342 1612029719.2441964
train: epoch 89, iter 1800, loss: 2.702091, top_1: 0.570156, top_k: 0.793750, samples/s: 2965.553 1612029727.8766482
train: epoch 89, iter 1900, loss: 2.716180, top_1: 0.575859, top_k: 0.795195, samples/s: 2978.925 1612029736.4703574
train: epoch 89, iter 2000, loss: 2.822372, top_1: 0.577109, top_k: 0.792656, samples/s: 2943.398 1612029745.1677969
train: epoch 89, iter 2100, loss: 2.652549, top_1: 0.573906, top_k: 0.798047, samples/s: 2980.432 1612029753.757192
train: epoch 89, iter 2200, loss: 2.669950, top_1: 0.573125, top_k: 0.795469, samples/s: 2931.037 1612029762.4912958
train: epoch 89, iter 2300, loss: 2.813781, top_1: 0.575625, top_k: 0.796680, samples/s: 2955.509 1612029771.1530359
train: epoch 89, iter 2400, loss: 2.685641, top_1: 0.570742, top_k: 0.798516, samples/s: 2996.647 1612029779.695914
train: epoch 89, iter 2500, loss: 2.753422, top_1: 0.574453, top_k: 0.793711, samples/s: 2831.037 1612029788.7385433
train: epoch 89, iter 2600, loss: 2.744341, top_1: 0.569102, top_k: 0.790664, samples/s: 2988.316 1612029797.3052437
train: epoch 89, iter 2700, loss: 2.802906, top_1: 0.570586, top_k: 0.792891, samples/s: 2959.650 1612029805.9549668
train: epoch 89, iter 2800, loss: 2.637919, top_1: 0.569219, top_k: 0.793086, samples/s: 2961.433 1612029814.5993779
train: epoch 89, iter 2900, loss: 2.768873, top_1: 0.567305, top_k: 0.793750, samples/s: 2940.708 1612029823.304758
train: epoch 89, iter 3000, loss: 2.758440, top_1: 0.569141, top_k: 0.794648, samples/s: 2945.576 1612029831.9957829
train: epoch 89, iter 3100, loss: 2.785161, top_1: 0.565078, top_k: 0.791445, samples/s: 2992.053 1612029840.551835
train: epoch 89, iter 3200, loss: 2.850188, top_1: 0.572930, top_k: 0.797109, samples/s: 2932.900 1612029849.280369
train: epoch 89, iter 3300, loss: 2.707341, top_1: 0.562266, top_k: 0.790117, samples/s: 2930.889 1612029858.0148757
train: epoch 89, iter 3400, loss: 2.685928, top_1: 0.568086, top_k: 0.793242, samples/s: 2968.025 1612029866.6402373
train: epoch 89, iter 3500, loss: 2.865644, top_1: 0.572187, top_k: 0.794609, samples/s: 2955.659 1612029875.3015187
train: epoch 89, iter 3600, loss: 2.980154, top_1: 0.565508, top_k: 0.789492, samples/s: 2917.973 1612029884.0746894
train: epoch 89, iter 3700, loss: 2.806710, top_1: 0.570469, top_k: 0.792148, samples/s: 2929.350 1612029892.8139372
train: epoch 89, iter 3800, loss: 2.666563, top_1: 0.573711, top_k: 0.795547, samples/s: 2975.244 1612029901.41819
train: epoch 89, iter 3900, loss: 3.129775, top_1: 0.567617, top_k: 0.788477, samples/s: 2889.904 1612029910.2766194
train: epoch 89, iter 4000, loss: 2.722305, top_1: 0.569102, top_k: 0.796016, samples/s: 2974.932 1612029918.8819468
train: epoch 89, iter 4100, loss: 2.778669, top_1: 0.573672, top_k: 0.797109, samples/s: 2991.212 1612029927.440329
train: epoch 89, iter 4200, loss: 2.964041, top_1: 0.568945, top_k: 0.793516, samples/s: 2935.330 1612029936.1616752
train: epoch 89, iter 4300, loss: 2.849543, top_1: 0.569219, top_k: 0.792969, samples/s: 2946.991 1612029944.8484042
train: epoch 89, iter 4400, loss: 2.686879, top_1: 0.565547, top_k: 0.791172, samples/s: 2907.445 1612029953.653405
train: epoch 89, iter 4500, loss: 2.739288, top_1: 0.570977, top_k: 0.795273, samples/s: 2943.500 1612029962.350592
train: epoch 89, iter 4600, loss: 2.835439, top_1: 0.566914, top_k: 0.786953, samples/s: 2938.841 1612029971.0614343
train: epoch 89, iter 4700, loss: 3.022180, top_1: 0.567461, top_k: 0.789023, samples/s: 2951.373 1612029979.735363
train: epoch 89, iter 4800, loss: 2.825896, top_1: 0.566250, top_k: 0.791133, samples/s: 2942.930 1612029988.43415
train: epoch 89, iter 4900, loss: 2.685134, top_1: 0.570937, top_k: 0.790625, samples/s: 2984.457 1612029997.0120006
train: epoch 89, iter 5000, loss: 2.629237, top_1: 0.577031, top_k: 0.797461, samples/s: 2956.979 1612030005.6694338
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_89.
validation: epoch 89, iter 195, top_1: 0.615685, top_k: 0.840946, samples/s: 2918.678 1612030023.0131295
train: epoch 90, iter 100, loss: 2.852830, top_1: 0.581016, top_k: 0.801055, samples/s: 2946.045 1612030047.6354442
train: epoch 90, iter 200, loss: 2.704027, top_1: 0.577070, top_k: 0.801172, samples/s: 2988.917 1612030056.2003949
train: epoch 90, iter 300, loss: 2.802208, top_1: 0.578008, top_k: 0.797891, samples/s: 3010.354 1612030064.7043684
train: epoch 90, iter 400, loss: 2.648709, top_1: 0.576289, top_k: 0.796484, samples/s: 2922.356 1612030073.464399
train: epoch 90, iter 500, loss: 2.758678, top_1: 0.586133, top_k: 0.804453, samples/s: 2975.350 1612030082.0684538
train: epoch 90, iter 600, loss: 2.522009, top_1: 0.572305, top_k: 0.796094, samples/s: 2952.903 1612030090.7378554
train: epoch 90, iter 700, loss: 2.929079, top_1: 0.574648, top_k: 0.796797, samples/s: 2976.536 1612030099.338573
train: epoch 90, iter 800, loss: 2.720051, top_1: 0.576016, top_k: 0.797109, samples/s: 3028.017 1612030107.7928748
train: epoch 90, iter 900, loss: 2.675617, top_1: 0.581914, top_k: 0.802695, samples/s: 3004.426 1612030116.3136508
train: epoch 90, iter 1000, loss: 2.732797, top_1: 0.580469, top_k: 0.801406, samples/s: 2988.837 1612030124.8788724
train: epoch 90, iter 1100, loss: 2.767112, top_1: 0.571914, top_k: 0.795312, samples/s: 2963.505 1612030133.5173135
train: epoch 90, iter 1200, loss: 2.782622, top_1: 0.565508, top_k: 0.791602, samples/s: 2973.483 1612030142.1268196
train: epoch 90, iter 1300, loss: 2.829252, top_1: 0.574727, top_k: 0.798203, samples/s: 2977.882 1612030150.723514
train: epoch 90, iter 1400, loss: 2.818582, top_1: 0.572344, top_k: 0.796172, samples/s: 2940.000 1612030159.4308867
train: epoch 90, iter 1500, loss: 2.641912, top_1: 0.574688, top_k: 0.798711, samples/s: 2974.911 1612030168.0361924
train: epoch 90, iter 1600, loss: 2.817766, top_1: 0.576211, top_k: 0.799609, samples/s: 2992.936 1612030176.5896528
train: epoch 90, iter 1700, loss: 2.701935, top_1: 0.576094, top_k: 0.802305, samples/s: 2933.781 1612030185.3156173
train: epoch 90, iter 1800, loss: 2.762153, top_1: 0.571055, top_k: 0.791953, samples/s: 2942.881 1612030194.0146122
train: epoch 90, iter 1900, loss: 2.619713, top_1: 0.570742, top_k: 0.791250, samples/s: 2929.757 1612030202.7524843
train: epoch 90, iter 2000, loss: 2.848446, top_1: 0.571914, top_k: 0.793086, samples/s: 2996.841 1612030211.294861
train: epoch 90, iter 2100, loss: 2.728106, top_1: 0.572383, top_k: 0.794297, samples/s: 2875.018 1612030220.1991012
train: epoch 90, iter 2200, loss: 2.938669, top_1: 0.574219, top_k: 0.793281, samples/s: 2995.121 1612030228.7463467
train: epoch 90, iter 2300, loss: 2.875746, top_1: 0.572148, top_k: 0.794023, samples/s: 2940.362 1612030237.4529266
train: epoch 90, iter 2400, loss: 2.736373, top_1: 0.571602, top_k: 0.795078, samples/s: 2944.224 1612030246.1477442
train: epoch 90, iter 2500, loss: 2.714229, top_1: 0.580703, top_k: 0.797344, samples/s: 2940.732 1612030254.8531117
train: epoch 90, iter 2600, loss: 2.816366, top_1: 0.575273, top_k: 0.796562, samples/s: 2959.594 1612030263.5030143
train: epoch 90, iter 2700, loss: 2.877991, top_1: 0.574844, top_k: 0.795000, samples/s: 2993.474 1612030272.0549617
train: epoch 90, iter 2800, loss: 2.990174, top_1: 0.574531, top_k: 0.795742, samples/s: 2944.652 1612030280.7486126
train: epoch 90, iter 2900, loss: 2.696138, top_1: 0.570742, top_k: 0.796875, samples/s: 2950.425 1612030289.4253
train: epoch 90, iter 3000, loss: 2.685017, top_1: 0.568750, top_k: 0.790586, samples/s: 2971.051 1612030298.0426803
train: epoch 90, iter 3100, loss: 2.708238, top_1: 0.572578, top_k: 0.796562, samples/s: 2931.139 1612030306.7755747
train: epoch 90, iter 3200, loss: 2.752401, top_1: 0.573125, top_k: 0.796016, samples/s: 2961.527 1612030315.4201882
train: epoch 90, iter 3300, loss: 2.891615, top_1: 0.571133, top_k: 0.795977, samples/s: 2968.453 1612030324.0437875
train: epoch 90, iter 3400, loss: 2.991778, top_1: 0.571914, top_k: 0.792148, samples/s: 2941.012 1612030332.7482753
train: epoch 90, iter 3500, loss: 2.781574, top_1: 0.569141, top_k: 0.793594, samples/s: 2947.961 1612030341.432241
train: epoch 90, iter 3600, loss: 2.907175, top_1: 0.576055, top_k: 0.796914, samples/s: 2980.962 1612030350.0200584
train: epoch 90, iter 3700, loss: 2.759620, top_1: 0.571836, top_k: 0.796172, samples/s: 2954.681 1612030358.6843371
train: epoch 90, iter 3800, loss: 2.794408, top_1: 0.573789, top_k: 0.796289, samples/s: 2969.184 1612030367.306132
train: epoch 90, iter 3900, loss: 2.722047, top_1: 0.571680, top_k: 0.796250, samples/s: 2951.821 1612030375.9788272
train: epoch 90, iter 4000, loss: 2.842509, top_1: 0.566953, top_k: 0.788906, samples/s: 2971.042 1612030384.5953074
train: epoch 90, iter 4100, loss: 2.968447, top_1: 0.571406, top_k: 0.793828, samples/s: 2879.245 1612030393.4865339
train: epoch 90, iter 4200, loss: 3.023860, top_1: 0.568828, top_k: 0.792969, samples/s: 2983.966 1612030402.0657203
train: epoch 90, iter 4300, loss: 2.844030, top_1: 0.568945, top_k: 0.792461, samples/s: 2911.459 1612030410.8585372
train: epoch 90, iter 4400, loss: 2.791345, top_1: 0.569063, top_k: 0.793984, samples/s: 2949.668 1612030419.5375042
train: epoch 90, iter 4500, loss: 2.737917, top_1: 0.570586, top_k: 0.793984, samples/s: 2974.876 1612030428.1428876
train: epoch 90, iter 4600, loss: 2.697988, top_1: 0.572852, top_k: 0.793320, samples/s: 2963.720 1612030436.7806814
train: epoch 90, iter 4700, loss: 2.662626, top_1: 0.574180, top_k: 0.795391, samples/s: 2952.705 1612030445.4506953
train: epoch 90, iter 4800, loss: 2.729666, top_1: 0.575625, top_k: 0.794805, samples/s: 2984.393 1612030454.0286837
train: epoch 90, iter 4900, loss: 2.873720, top_1: 0.572227, top_k: 0.793711, samples/s: 2809.088 1612030463.141936
train: epoch 90, iter 5000, loss: 2.882505, top_1: 0.579609, top_k: 0.800273, samples/s: 3017.261 1612030471.6264513
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_90.
validation: epoch 90, iter 195, top_1: 0.618189, top_k: 0.841366, samples/s: 3030.408 1612030488.4169302
train: epoch 91, iter 100, loss: 2.932344, top_1: 0.577266, top_k: 0.800078, samples/s: 2947.642 1612030513.4469104
train: epoch 91, iter 200, loss: 2.945885, top_1: 0.573047, top_k: 0.797500, samples/s: 3022.680 1612030521.9163105
train: epoch 91, iter 300, loss: 2.867528, top_1: 0.580508, top_k: 0.804766, samples/s: 3012.509 1612030530.414049
train: epoch 91, iter 400, loss: 2.720462, top_1: 0.581602, top_k: 0.802422, samples/s: 3018.108 1612030538.8961625
train: epoch 91, iter 500, loss: 3.125161, top_1: 0.578242, top_k: 0.800937, samples/s: 2969.479 1612030547.517224
train: epoch 91, iter 600, loss: 2.770345, top_1: 0.580977, top_k: 0.800937, samples/s: 2968.483 1612030556.141176
train: epoch 91, iter 700, loss: 2.763676, top_1: 0.582891, top_k: 0.802422, samples/s: 2969.147 1612030564.7631807
train: epoch 91, iter 800, loss: 2.735639, top_1: 0.578984, top_k: 0.800078, samples/s: 3005.354 1612030573.2813463
train: epoch 91, iter 900, loss: 2.644518, top_1: 0.576445, top_k: 0.797266, samples/s: 2999.381 1612030581.8163855
train: epoch 91, iter 1000, loss: 2.605437, top_1: 0.573398, top_k: 0.791211, samples/s: 3005.812 1612030590.3333225
train: epoch 91, iter 1100, loss: 2.783112, top_1: 0.573281, top_k: 0.799414, samples/s: 2960.772 1612030598.9796212
train: epoch 91, iter 1200, loss: 2.773856, top_1: 0.576680, top_k: 0.797539, samples/s: 2969.852 1612030607.5995848
train: epoch 91, iter 1300, loss: 2.766792, top_1: 0.575469, top_k: 0.798047, samples/s: 2957.055 1612030616.256851
train: epoch 91, iter 1400, loss: 2.855645, top_1: 0.575313, top_k: 0.799023, samples/s: 2943.031 1612030624.955363
train: epoch 91, iter 1500, loss: 2.891702, top_1: 0.581211, top_k: 0.799727, samples/s: 2974.737 1612030633.5611231
train: epoch 91, iter 1600, loss: 2.615465, top_1: 0.578125, top_k: 0.798633, samples/s: 2903.589 1612030642.3778853
train: epoch 91, iter 1700, loss: 2.746655, top_1: 0.566367, top_k: 0.795078, samples/s: 2982.186 1612030650.9622288
train: epoch 91, iter 1800, loss: 2.796389, top_1: 0.578047, top_k: 0.797969, samples/s: 3014.465 1612030659.454536
train: epoch 91, iter 1900, loss: 2.692227, top_1: 0.570859, top_k: 0.792891, samples/s: 2898.070 1612030668.288022
train: epoch 91, iter 2000, loss: 2.560004, top_1: 0.576367, top_k: 0.797070, samples/s: 2955.126 1612030676.9508832
train: epoch 91, iter 2100, loss: 2.723265, top_1: 0.579336, top_k: 0.801133, samples/s: 2917.379 1612030685.7259088
train: epoch 91, iter 2200, loss: 2.647093, top_1: 0.580586, top_k: 0.795664, samples/s: 2944.558 1612030694.4199183
train: epoch 91, iter 2300, loss: 2.715345, top_1: 0.577969, top_k: 0.798516, samples/s: 2931.077 1612030703.1538663
train: epoch 91, iter 2400, loss: 2.713240, top_1: 0.573555, top_k: 0.798672, samples/s: 2946.499 1612030711.8422801
train: epoch 91, iter 2500, loss: 2.874431, top_1: 0.573477, top_k: 0.792617, samples/s: 2979.099 1612030720.4354372
train: epoch 91, iter 2600, loss: 2.618456, top_1: 0.579336, top_k: 0.798438, samples/s: 2965.802 1612030729.0670693
train: epoch 91, iter 2700, loss: 2.944286, top_1: 0.581094, top_k: 0.799492, samples/s: 2964.532 1612030737.702544
train: epoch 91, iter 2800, loss: 2.668163, top_1: 0.576758, top_k: 0.799258, samples/s: 2966.586 1612030746.3319886
train: epoch 91, iter 2900, loss: 2.803912, top_1: 0.577695, top_k: 0.797188, samples/s: 2926.441 1612030755.0798156
train: epoch 91, iter 3000, loss: 2.716516, top_1: 0.574492, top_k: 0.794687, samples/s: 2949.635 1612030763.7588913
train: epoch 91, iter 3100, loss: 2.872238, top_1: 0.572266, top_k: 0.792813, samples/s: 2932.546 1612030772.488514
train: epoch 91, iter 3200, loss: 2.894460, top_1: 0.575313, top_k: 0.796172, samples/s: 2874.032 1612030781.395838
train: epoch 91, iter 3300, loss: 2.671027, top_1: 0.578672, top_k: 0.798398, samples/s: 2904.777 1612030790.208892
train: epoch 91, iter 3400, loss: 2.506783, top_1: 0.574258, top_k: 0.799766, samples/s: 2966.835 1612030798.837572
train: epoch 91, iter 3500, loss: 2.772687, top_1: 0.570156, top_k: 0.794102, samples/s: 2956.946 1612030807.49526
train: epoch 91, iter 3600, loss: 2.774863, top_1: 0.574766, top_k: 0.794805, samples/s: 2963.205 1612030816.1344886
train: epoch 91, iter 3700, loss: 2.839557, top_1: 0.571094, top_k: 0.791406, samples/s: 2979.613 1612030824.7262146
train: epoch 91, iter 3800, loss: 2.675538, top_1: 0.575859, top_k: 0.796719, samples/s: 2898.339 1612030833.5588543
train: epoch 91, iter 3900, loss: 2.617392, top_1: 0.567813, top_k: 0.795195, samples/s: 2912.160 1612030842.3496184
train: epoch 91, iter 4000, loss: 2.781119, top_1: 0.570039, top_k: 0.792539, samples/s: 2977.085 1612030850.9486163
train: epoch 91, iter 4100, loss: 2.593044, top_1: 0.574453, top_k: 0.793633, samples/s: 2931.613 1612030859.680996
train: epoch 91, iter 4200, loss: 2.693913, top_1: 0.578359, top_k: 0.794219, samples/s: 2965.444 1612030868.3138
train: epoch 91, iter 4300, loss: 2.720586, top_1: 0.578477, top_k: 0.795234, samples/s: 2967.524 1612030876.9406092
train: epoch 91, iter 4400, loss: 2.721348, top_1: 0.573359, top_k: 0.792656, samples/s: 2977.991 1612030885.5368795
train: epoch 91, iter 4500, loss: 2.911113, top_1: 0.574453, top_k: 0.792227, samples/s: 2998.974 1612030894.073138
train: epoch 91, iter 4600, loss: 2.793577, top_1: 0.576094, top_k: 0.795859, samples/s: 2922.541 1612030902.8326712
train: epoch 91, iter 4700, loss: 2.933472, top_1: 0.575664, top_k: 0.797188, samples/s: 2999.774 1612030911.3665712
train: epoch 91, iter 4800, loss: 2.823978, top_1: 0.569023, top_k: 0.794102, samples/s: 2939.178 1612030920.0765562
train: epoch 91, iter 4900, loss: 2.740612, top_1: 0.576680, top_k: 0.795898, samples/s: 2949.335 1612030928.7564778
train: epoch 91, iter 5000, loss: 2.668166, top_1: 0.575820, top_k: 0.800937, samples/s: 2952.940 1612030937.4258301
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_91.
validation: epoch 91, iter 195, top_1: 0.615425, top_k: 0.840645, samples/s: 2992.022 1612030954.4234726
train: epoch 92, iter 100, loss: 2.742386, top_1: 0.578711, top_k: 0.801641, samples/s: 2969.439 1612030979.0989187
train: epoch 92, iter 200, loss: 2.792490, top_1: 0.578242, top_k: 0.799883, samples/s: 2997.198 1612030987.6402397
train: epoch 92, iter 300, loss: 2.944556, top_1: 0.583242, top_k: 0.806055, samples/s: 2929.266 1612030996.3795853
train: epoch 92, iter 400, loss: 2.938572, top_1: 0.589258, top_k: 0.803320, samples/s: 2979.364 1612031004.9720562
train: epoch 92, iter 500, loss: 2.829385, top_1: 0.584414, top_k: 0.801562, samples/s: 2964.184 1612031013.6084876
train: epoch 92, iter 600, loss: 2.859796, top_1: 0.582969, top_k: 0.803672, samples/s: 2913.487 1612031022.395208
train: epoch 92, iter 700, loss: 2.787319, top_1: 0.581602, top_k: 0.799805, samples/s: 2944.087 1612031031.090559
train: epoch 92, iter 800, loss: 2.427658, top_1: 0.582266, top_k: 0.801641, samples/s: 2994.238 1612031039.6403344
train: epoch 92, iter 900, loss: 2.879097, top_1: 0.575781, top_k: 0.798008, samples/s: 2999.296 1612031048.175645
train: epoch 92, iter 1000, loss: 2.575432, top_1: 0.585547, top_k: 0.802422, samples/s: 3023.850 1612031056.6416776
train: epoch 92, iter 1100, loss: 2.905658, top_1: 0.580391, top_k: 0.800703, samples/s: 2986.720 1612031065.212953
train: epoch 92, iter 1200, loss: 2.688101, top_1: 0.581836, top_k: 0.800117, samples/s: 2947.253 1612031073.8990097
train: epoch 92, iter 1300, loss: 2.650409, top_1: 0.580820, top_k: 0.799492, samples/s: 3004.800 1612031082.4187083
train: epoch 92, iter 1400, loss: 2.671700, top_1: 0.580391, top_k: 0.802031, samples/s: 2939.225 1612031091.128545
train: epoch 92, iter 1500, loss: 2.778763, top_1: 0.573008, top_k: 0.794687, samples/s: 2982.668 1612031099.711434
train: epoch 92, iter 1600, loss: 2.644973, top_1: 0.579531, top_k: 0.800391, samples/s: 2940.963 1612031108.4160514
train: epoch 92, iter 1700, loss: 2.737686, top_1: 0.577773, top_k: 0.798906, samples/s: 2986.998 1612031116.9864933
train: epoch 92, iter 1800, loss: 2.729933, top_1: 0.571523, top_k: 0.797813, samples/s: 2982.243 1612031125.570741
train: epoch 92, iter 1900, loss: 2.838304, top_1: 0.579766, top_k: 0.802773, samples/s: 2970.252 1612031134.189488
train: epoch 92, iter 2000, loss: 2.653246, top_1: 0.582812, top_k: 0.801406, samples/s: 2975.602 1612031142.79276
train: epoch 92, iter 2100, loss: 2.866097, top_1: 0.575117, top_k: 0.800781, samples/s: 2949.795 1612031151.4713051
train: epoch 92, iter 2200, loss: 2.860520, top_1: 0.576016, top_k: 0.796602, samples/s: 2899.092 1612031160.3016891
train: epoch 92, iter 2300, loss: 2.679508, top_1: 0.571016, top_k: 0.794336, samples/s: 2874.090 1612031169.208853
train: epoch 92, iter 2400, loss: 2.764407, top_1: 0.575742, top_k: 0.799219, samples/s: 2965.490 1612031177.841484
train: epoch 92, iter 2500, loss: 2.472598, top_1: 0.580273, top_k: 0.798906, samples/s: 2897.915 1612031186.6754131
train: epoch 92, iter 2600, loss: 2.768863, top_1: 0.579609, top_k: 0.798398, samples/s: 2983.276 1612031195.256618
train: epoch 92, iter 2700, loss: 2.718162, top_1: 0.579375, top_k: 0.801562, samples/s: 2888.747 1612031204.1185684
train: epoch 92, iter 2800, loss: 2.538782, top_1: 0.573008, top_k: 0.794492, samples/s: 2934.820 1612031212.8414114
train: epoch 92, iter 2900, loss: 2.733855, top_1: 0.575352, top_k: 0.795664, samples/s: 3012.357 1612031221.339742
train: epoch 92, iter 3000, loss: 2.768723, top_1: 0.577852, top_k: 0.800703, samples/s: 2952.914 1612031230.0092406
train: epoch 92, iter 3100, loss: 2.750584, top_1: 0.578203, top_k: 0.799414, samples/s: 2946.823 1612031238.6964717
train: epoch 92, iter 3200, loss: 2.793506, top_1: 0.569883, top_k: 0.790000, samples/s: 2957.458 1612031247.3525846
train: epoch 92, iter 3300, loss: 2.656822, top_1: 0.574844, top_k: 0.797305, samples/s: 2921.004 1612031256.1166599
train: epoch 92, iter 3400, loss: 2.752666, top_1: 0.575352, top_k: 0.797695, samples/s: 2946.660 1612031264.804581
train: epoch 92, iter 3500, loss: 2.633864, top_1: 0.569414, top_k: 0.795195, samples/s: 2912.453 1612031273.594315
train: epoch 92, iter 3600, loss: 2.805316, top_1: 0.569219, top_k: 0.793867, samples/s: 2958.260 1612031282.2482462
train: epoch 92, iter 3700, loss: 2.814948, top_1: 0.579531, top_k: 0.798281, samples/s: 2955.932 1612031290.9086063
train: epoch 92, iter 3800, loss: 2.958201, top_1: 0.579336, top_k: 0.795781, samples/s: 2968.958 1612031299.5312836
train: epoch 92, iter 3900, loss: 2.741484, top_1: 0.574609, top_k: 0.795430, samples/s: 2915.434 1612031308.3120067
train: epoch 92, iter 4000, loss: 2.800707, top_1: 0.574727, top_k: 0.796719, samples/s: 3001.236 1612031316.8418176
train: epoch 92, iter 4100, loss: 2.780891, top_1: 0.571914, top_k: 0.793203, samples/s: 2941.110 1612031325.546045
train: epoch 92, iter 4200, loss: 2.837310, top_1: 0.573828, top_k: 0.796797, samples/s: 2951.979 1612031334.2181842
train: epoch 92, iter 4300, loss: 2.795038, top_1: 0.572969, top_k: 0.798281, samples/s: 2963.948 1612031342.8553946
train: epoch 92, iter 4400, loss: 2.828240, top_1: 0.573320, top_k: 0.800117, samples/s: 2880.261 1612031351.7434402
train: epoch 92, iter 4500, loss: 2.523170, top_1: 0.571836, top_k: 0.794883, samples/s: 2972.383 1612031360.3559456
train: epoch 92, iter 4600, loss: 2.686265, top_1: 0.573789, top_k: 0.794023, samples/s: 2941.305 1612031369.0596106
train: epoch 92, iter 4700, loss: 2.610408, top_1: 0.576484, top_k: 0.795430, samples/s: 2906.119 1612031377.868722
train: epoch 92, iter 4800, loss: 2.760314, top_1: 0.573945, top_k: 0.795000, samples/s: 2962.838 1612031386.5090392
train: epoch 92, iter 4900, loss: 2.522768, top_1: 0.573516, top_k: 0.796094, samples/s: 2934.971 1612031395.231378
train: epoch 92, iter 5000, loss: 2.712697, top_1: 0.579063, top_k: 0.797539, samples/s: 2997.957 1612031403.7705276
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_92.
validation: epoch 92, iter 195, top_1: 0.615505, top_k: 0.837520, samples/s: 2992.680 1612031420.656956
train: epoch 93, iter 100, loss: 2.749684, top_1: 0.586836, top_k: 0.804844, samples/s: 2978.779 1612031449.8536327
train: epoch 93, iter 200, loss: 2.707253, top_1: 0.583594, top_k: 0.804492, samples/s: 2991.707 1612031458.4105678
train: epoch 93, iter 300, loss: 2.715907, top_1: 0.590703, top_k: 0.804492, samples/s: 2932.035 1612031467.1417449
train: epoch 93, iter 400, loss: 2.676012, top_1: 0.585625, top_k: 0.808203, samples/s: 3050.952 1612031475.5325308
train: epoch 93, iter 500, loss: 2.669862, top_1: 0.583750, top_k: 0.801055, samples/s: 2846.736 1612031484.5254028
train: epoch 93, iter 600, loss: 2.650566, top_1: 0.583789, top_k: 0.802969, samples/s: 2914.278 1612031493.309769
train: epoch 93, iter 700, loss: 2.749360, top_1: 0.585391, top_k: 0.804063, samples/s: 2988.917 1612031501.8746314
train: epoch 93, iter 800, loss: 2.818875, top_1: 0.576992, top_k: 0.800820, samples/s: 2941.974 1612031510.576252
train: epoch 93, iter 900, loss: 2.683904, top_1: 0.582930, top_k: 0.804375, samples/s: 3030.448 1612031519.0238345
train: epoch 93, iter 1000, loss: 2.526319, top_1: 0.589102, top_k: 0.807852, samples/s: 2951.067 1612031527.69867
train: epoch 93, iter 1100, loss: 2.730526, top_1: 0.578281, top_k: 0.800156, samples/s: 3043.859 1612031536.109105
train: epoch 93, iter 1200, loss: 2.736836, top_1: 0.581055, top_k: 0.801484, samples/s: 2968.267 1612031544.7336822
train: epoch 93, iter 1300, loss: 2.664997, top_1: 0.585000, top_k: 0.802891, samples/s: 2953.548 1612031553.4011366
train: epoch 93, iter 1400, loss: 2.815193, top_1: 0.580586, top_k: 0.802930, samples/s: 2930.026 1612031562.13835
train: epoch 93, iter 1500, loss: 3.110882, top_1: 0.576016, top_k: 0.799687, samples/s: 2989.966 1612031570.7004125
train: epoch 93, iter 1600, loss: 2.726337, top_1: 0.582227, top_k: 0.804141, samples/s: 2889.245 1612031579.5606334
train: epoch 93, iter 1700, loss: 2.717554, top_1: 0.573945, top_k: 0.792852, samples/s: 2939.999 1612031588.2683156
train: epoch 93, iter 1800, loss: 2.575116, top_1: 0.576484, top_k: 0.793984, samples/s: 2959.909 1612031596.917086
train: epoch 93, iter 1900, loss: 2.754525, top_1: 0.575195, top_k: 0.798984, samples/s: 3005.636 1612031605.4344866
train: epoch 93, iter 2000, loss: 2.725794, top_1: 0.574727, top_k: 0.800039, samples/s: 2891.987 1612031614.2864616
train: epoch 93, iter 2100, loss: 2.778776, top_1: 0.576133, top_k: 0.795430, samples/s: 2966.620 1612031622.9158478
train: epoch 93, iter 2200, loss: 3.019110, top_1: 0.579570, top_k: 0.797656, samples/s: 2978.161 1612031631.511734
train: epoch 93, iter 2300, loss: 2.773318, top_1: 0.580273, top_k: 0.800234, samples/s: 2997.662 1612031640.0517325
train: epoch 93, iter 2400, loss: 2.553320, top_1: 0.578945, top_k: 0.796016, samples/s: 2972.933 1612031648.6627731
train: epoch 93, iter 2500, loss: 2.737268, top_1: 0.573008, top_k: 0.797578, samples/s: 3017.498 1612031657.1465528
train: epoch 93, iter 2600, loss: 2.751966, top_1: 0.584492, top_k: 0.801836, samples/s: 2959.668 1612031665.7963226
train: epoch 93, iter 2700, loss: 2.785448, top_1: 0.579648, top_k: 0.799883, samples/s: 2987.253 1612031674.3660226
train: epoch 93, iter 2800, loss: 2.736844, top_1: 0.575391, top_k: 0.801133, samples/s: 2996.812 1612031682.908444
train: epoch 93, iter 2900, loss: 2.788568, top_1: 0.574727, top_k: 0.797305, samples/s: 2975.959 1612031691.5106242
train: epoch 93, iter 3000, loss: 2.830332, top_1: 0.576484, top_k: 0.801523, samples/s: 2983.422 1612031700.0914438
train: epoch 93, iter 3100, loss: 2.714709, top_1: 0.575703, top_k: 0.795391, samples/s: 2968.701 1612031708.714663
train: epoch 93, iter 3200, loss: 2.814212, top_1: 0.578477, top_k: 0.801797, samples/s: 2980.854 1612031717.3030381
train: epoch 93, iter 3300, loss: 2.598495, top_1: 0.582305, top_k: 0.798672, samples/s: 2941.961 1612031726.0045557
train: epoch 93, iter 3400, loss: 2.801122, top_1: 0.574961, top_k: 0.797383, samples/s: 3014.473 1612031734.496871
train: epoch 93, iter 3500, loss: 2.743811, top_1: 0.576172, top_k: 0.796602, samples/s: 2874.094 1612031743.4040344
train: epoch 93, iter 3600, loss: 2.699100, top_1: 0.582617, top_k: 0.800937, samples/s: 2965.289 1612031752.0372596
train: epoch 93, iter 3700, loss: 2.763839, top_1: 0.572539, top_k: 0.798906, samples/s: 2920.015 1612031760.8043246
train: epoch 93, iter 3800, loss: 2.686288, top_1: 0.578945, top_k: 0.797266, samples/s: 2963.812 1612031769.4420147
train: epoch 93, iter 3900, loss: 2.728762, top_1: 0.577891, top_k: 0.796992, samples/s: 2968.104 1612031778.0669096
train: epoch 93, iter 4000, loss: 2.612659, top_1: 0.574336, top_k: 0.795742, samples/s: 2982.885 1612031786.6492925
train: epoch 93, iter 4100, loss: 2.736862, top_1: 0.580156, top_k: 0.798047, samples/s: 2929.810 1612031795.386951
train: epoch 93, iter 4200, loss: 2.645461, top_1: 0.575391, top_k: 0.798320, samples/s: 2945.858 1612031804.0771313
train: epoch 93, iter 4300, loss: 2.853968, top_1: 0.582461, top_k: 0.798828, samples/s: 2983.264 1612031812.658345
train: epoch 93, iter 4400, loss: 2.719894, top_1: 0.575937, top_k: 0.798633, samples/s: 2979.957 1612031821.2490635
train: epoch 93, iter 4500, loss: 2.636993, top_1: 0.568047, top_k: 0.795898, samples/s: 2987.014 1612031829.8194513
train: epoch 93, iter 4600, loss: 2.759064, top_1: 0.578047, top_k: 0.799258, samples/s: 2983.645 1612031838.3996542
train: epoch 93, iter 4700, loss: 2.643539, top_1: 0.575664, top_k: 0.797695, samples/s: 2972.236 1612031847.0127518
train: epoch 93, iter 4800, loss: 2.748091, top_1: 0.577422, top_k: 0.795273, samples/s: 2970.325 1612031855.6312249
train: epoch 93, iter 4900, loss: 2.772605, top_1: 0.579961, top_k: 0.801836, samples/s: 3004.609 1612031864.1515074
train: epoch 93, iter 5000, loss: 2.832938, top_1: 0.576133, top_k: 0.799297, samples/s: 3015.284 1612031872.6415622
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_93.
validation: epoch 93, iter 195, top_1: 0.622436, top_k: 0.843830, samples/s: 2966.607 1612031889.7437212
train: epoch 94, iter 100, loss: 2.747310, top_1: 0.586055, top_k: 0.802930, samples/s: 2923.555 1612031914.6117234
train: epoch 94, iter 200, loss: 2.691373, top_1: 0.585352, top_k: 0.807227, samples/s: 3000.368 1612031923.1440146
train: epoch 94, iter 300, loss: 2.792298, top_1: 0.579570, top_k: 0.802852, samples/s: 2982.084 1612031931.7286732
train: epoch 94, iter 400, loss: 2.836559, top_1: 0.585391, top_k: 0.801914, samples/s: 2984.164 1612031940.3072846
train: epoch 94, iter 500, loss: 2.749364, top_1: 0.588750, top_k: 0.811562, samples/s: 3003.897 1612031948.8295116
train: epoch 94, iter 600, loss: 2.827642, top_1: 0.585273, top_k: 0.806016, samples/s: 2981.764 1612031957.4150367
train: epoch 94, iter 700, loss: 2.777279, top_1: 0.587383, top_k: 0.802969, samples/s: 2944.073 1612031966.1106362
train: epoch 94, iter 800, loss: 2.608201, top_1: 0.581758, top_k: 0.801875, samples/s: 2982.009 1612031974.6952817
train: epoch 94, iter 900, loss: 2.758408, top_1: 0.591680, top_k: 0.806250, samples/s: 2992.716 1612031983.2493966
train: epoch 94, iter 1000, loss: 2.593561, top_1: 0.587773, top_k: 0.805312, samples/s: 3009.004 1612031991.7571836
train: epoch 94, iter 1100, loss: 2.586449, top_1: 0.583398, top_k: 0.804883, samples/s: 2986.787 1612032000.3282526
train: epoch 94, iter 1200, loss: 2.736574, top_1: 0.580078, top_k: 0.800898, samples/s: 2988.165 1612032008.8954463
train: epoch 94, iter 1300, loss: 2.822483, top_1: 0.582227, top_k: 0.801562, samples/s: 2943.216 1612032017.5934055
train: epoch 94, iter 1400, loss: 2.681896, top_1: 0.581211, top_k: 0.801016, samples/s: 2986.299 1612032026.1658728
train: epoch 94, iter 1500, loss: 2.800757, top_1: 0.587266, top_k: 0.802422, samples/s: 2999.720 1612032034.6999645
train: epoch 94, iter 1600, loss: 2.820471, top_1: 0.582070, top_k: 0.800195, samples/s: 2997.778 1612032043.2396228
train: epoch 94, iter 1700, loss: 2.659428, top_1: 0.577461, top_k: 0.801172, samples/s: 2957.580 1612032051.8953779
train: epoch 94, iter 1800, loss: 2.809211, top_1: 0.583750, top_k: 0.800820, samples/s: 2838.847 1612032060.9130783
train: epoch 94, iter 1900, loss: 2.681913, top_1: 0.578320, top_k: 0.800469, samples/s: 3024.126 1612032069.3783658
train: epoch 94, iter 2000, loss: 2.713528, top_1: 0.580117, top_k: 0.804688, samples/s: 2969.014 1612032078.0007389
train: epoch 94, iter 2100, loss: 2.740187, top_1: 0.577383, top_k: 0.797734, samples/s: 3026.286 1612032086.4600048
train: epoch 94, iter 2200, loss: 2.795477, top_1: 0.577656, top_k: 0.797617, samples/s: 3014.816 1612032094.951311
train: epoch 94, iter 2300, loss: 2.749895, top_1: 0.582656, top_k: 0.800234, samples/s: 2943.607 1612032103.648187
train: epoch 94, iter 2400, loss: 2.689817, top_1: 0.587422, top_k: 0.806523, samples/s: 3016.660 1612032112.1343706
train: epoch 94, iter 2500, loss: 2.783234, top_1: 0.579648, top_k: 0.799766, samples/s: 3002.851 1612032120.659607
train: epoch 94, iter 2600, loss: 2.742310, top_1: 0.578867, top_k: 0.804648, samples/s: 2979.326 1612032129.2522025
train: epoch 94, iter 2700, loss: 2.781051, top_1: 0.578867, top_k: 0.802461, samples/s: 3017.710 1612032137.7354133
train: epoch 94, iter 2800, loss: 2.994653, top_1: 0.580234, top_k: 0.798242, samples/s: 2943.401 1612032146.4329011
train: epoch 94, iter 2900, loss: 2.798109, top_1: 0.576250, top_k: 0.798594, samples/s: 2933.909 1612032155.1583936
train: epoch 94, iter 3000, loss: 2.712866, top_1: 0.576836, top_k: 0.801055, samples/s: 2963.493 1612032163.7968452
train: epoch 94, iter 3100, loss: 2.737451, top_1: 0.569023, top_k: 0.794531, samples/s: 2964.889 1612032172.4312441
train: epoch 94, iter 3200, loss: 2.978075, top_1: 0.583984, top_k: 0.802109, samples/s: 3036.424 1612032180.8622043
train: epoch 94, iter 3300, loss: 2.692319, top_1: 0.580156, top_k: 0.798555, samples/s: 2932.138 1612032189.5930214
train: epoch 94, iter 3400, loss: 2.719515, top_1: 0.576094, top_k: 0.796328, samples/s: 3009.762 1612032198.0986867
train: epoch 94, iter 3500, loss: 2.735109, top_1: 0.578359, top_k: 0.800859, samples/s: 2883.880 1612032206.975631
train: epoch 94, iter 3600, loss: 2.884338, top_1: 0.575664, top_k: 0.799727, samples/s: 2967.546 1612032215.6022809
train: epoch 94, iter 3700, loss: 2.944799, top_1: 0.573789, top_k: 0.795625, samples/s: 2962.455 1612032224.2437618
train: epoch 94, iter 3800, loss: 2.882311, top_1: 0.577461, top_k: 0.796016, samples/s: 2969.280 1612032232.865376
train: epoch 94, iter 3900, loss: 2.761369, top_1: 0.576797, top_k: 0.794453, samples/s: 2995.264 1612032241.4122202
train: epoch 94, iter 4000, loss: 2.762399, top_1: 0.575508, top_k: 0.795664, samples/s: 2981.131 1612032249.9995313
train: epoch 94, iter 4100, loss: 3.053845, top_1: 0.583281, top_k: 0.803203, samples/s: 2947.032 1612032258.6862738
train: epoch 94, iter 4200, loss: 2.794576, top_1: 0.580625, top_k: 0.800703, samples/s: 2946.268 1612032267.3752108
train: epoch 94, iter 4300, loss: 2.789892, top_1: 0.579102, top_k: 0.799844, samples/s: 2987.727 1612032275.9436185
train: epoch 94, iter 4400, loss: 2.919974, top_1: 0.583477, top_k: 0.799375, samples/s: 2952.604 1612032284.6139965
train: epoch 94, iter 4500, loss: 2.694795, top_1: 0.580977, top_k: 0.800156, samples/s: 2979.914 1612032293.204838
train: epoch 94, iter 4600, loss: 2.675886, top_1: 0.578242, top_k: 0.799375, samples/s: 2985.058 1612032301.7808313
train: epoch 94, iter 4700, loss: 2.788442, top_1: 0.579453, top_k: 0.801250, samples/s: 2978.177 1612032310.3766704
train: epoch 94, iter 4800, loss: 2.865952, top_1: 0.575859, top_k: 0.798359, samples/s: 2923.570 1612032319.133038
train: epoch 94, iter 4900, loss: 2.722098, top_1: 0.575000, top_k: 0.799727, samples/s: 3019.809 1612032327.610441
train: epoch 94, iter 5000, loss: 2.787843, top_1: 0.582812, top_k: 0.802617, samples/s: 3001.231 1612032336.1403751
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_94.
validation: epoch 94, iter 195, top_1: 0.623458, top_k: 0.849058, samples/s: 2940.253 1612032353.362977
train: epoch 95, iter 100, loss: 2.592380, top_1: 0.594180, top_k: 0.812266, samples/s: 2935.490 1612032378.155102
train: epoch 95, iter 200, loss: 2.585238, top_1: 0.589219, top_k: 0.807148, samples/s: 2969.993 1612032386.7746813
train: epoch 95, iter 300, loss: 2.715836, top_1: 0.590000, top_k: 0.808242, samples/s: 2999.667 1612032395.3090005
train: epoch 95, iter 400, loss: 2.574526, top_1: 0.583086, top_k: 0.804609, samples/s: 2962.532 1612032403.950212
train: epoch 95, iter 500, loss: 2.634750, top_1: 0.583555, top_k: 0.803477, samples/s: 2970.321 1612032412.5687752
train: epoch 95, iter 600, loss: 2.586903, top_1: 0.584492, top_k: 0.803945, samples/s: 2916.267 1612032421.3477423
train: epoch 95, iter 700, loss: 2.840471, top_1: 0.585977, top_k: 0.806914, samples/s: 3029.212 1612032429.7982168
train: epoch 95, iter 800, loss: 2.735885, top_1: 0.586758, top_k: 0.807031, samples/s: 3000.517 1612032438.330057
train: epoch 95, iter 900, loss: 2.657712, top_1: 0.585898, top_k: 0.805156, samples/s: 3001.645 1612032446.8587098
train: epoch 95, iter 1000, loss: 2.580921, top_1: 0.589609, top_k: 0.807227, samples/s: 2982.541 1612032455.4421406
train: epoch 95, iter 1100, loss: 2.885323, top_1: 0.587031, top_k: 0.803750, samples/s: 3031.467 1612032463.8867767
train: epoch 95, iter 1200, loss: 2.717952, top_1: 0.586562, top_k: 0.806875, samples/s: 3001.808 1612032472.414919
train: epoch 95, iter 1300, loss: 3.007300, top_1: 0.584844, top_k: 0.804180, samples/s: 2957.089 1612032481.0720882
train: epoch 95, iter 1400, loss: 2.717574, top_1: 0.588633, top_k: 0.807969, samples/s: 2968.487 1612032489.6959713
train: epoch 95, iter 1500, loss: 2.914087, top_1: 0.577891, top_k: 0.799922, samples/s: 2942.610 1612032498.3964832
train: epoch 95, iter 1600, loss: 2.807327, top_1: 0.581094, top_k: 0.798164, samples/s: 2975.222 1612032507.0001855
train: epoch 95, iter 1700, loss: 2.736753, top_1: 0.579258, top_k: 0.800273, samples/s: 2888.444 1612032515.8630686
train: epoch 95, iter 1800, loss: 2.501676, top_1: 0.585078, top_k: 0.806250, samples/s: 2997.536 1612032524.403414
train: epoch 95, iter 1900, loss: 2.432752, top_1: 0.587578, top_k: 0.804688, samples/s: 2981.217 1612032532.9911454
train: epoch 95, iter 2000, loss: 2.767822, top_1: 0.578008, top_k: 0.798594, samples/s: 2908.403 1612032541.7926223
train: epoch 95, iter 2100, loss: 2.615483, top_1: 0.583164, top_k: 0.800898, samples/s: 2976.339 1612032550.3937538
train: epoch 95, iter 2200, loss: 2.757152, top_1: 0.588828, top_k: 0.803359, samples/s: 2945.794 1612032559.0842392
train: epoch 95, iter 2300, loss: 2.632164, top_1: 0.583164, top_k: 0.802422, samples/s: 3004.091 1612032567.6059184
train: epoch 95, iter 2400, loss: 2.791510, top_1: 0.584141, top_k: 0.800039, samples/s: 2969.857 1612032576.2257917
train: epoch 95, iter 2500, loss: 2.697984, top_1: 0.579648, top_k: 0.799336, samples/s: 3013.136 1612032584.721961
train: epoch 95, iter 2600, loss: 2.877379, top_1: 0.583320, top_k: 0.803398, samples/s: 2980.458 1612032593.311186
train: epoch 95, iter 2700, loss: 2.726507, top_1: 0.585078, top_k: 0.797891, samples/s: 2958.838 1612032601.9633062
train: epoch 95, iter 2800, loss: 2.747202, top_1: 0.581797, top_k: 0.802813, samples/s: 2947.389 1612032610.648913
train: epoch 95, iter 2900, loss: 2.689262, top_1: 0.581953, top_k: 0.800742, samples/s: 2938.812 1612032619.3599553
train: epoch 95, iter 3000, loss: 2.724298, top_1: 0.585625, top_k: 0.802773, samples/s: 2956.238 1612032628.019542
train: epoch 95, iter 3100, loss: 2.916246, top_1: 0.586719, top_k: 0.804102, samples/s: 2957.423 1612032636.6757069
train: epoch 95, iter 3200, loss: 2.706556, top_1: 0.581836, top_k: 0.803203, samples/s: 3024.745 1612032645.1394074
train: epoch 95, iter 3300, loss: 2.730615, top_1: 0.578828, top_k: 0.797930, samples/s: 2973.284 1612032653.7493968
train: epoch 95, iter 3400, loss: 2.641289, top_1: 0.587422, top_k: 0.801562, samples/s: 2946.124 1612032662.4387488
train: epoch 95, iter 3500, loss: 2.650420, top_1: 0.580039, top_k: 0.801953, samples/s: 2959.555 1612032671.0886836
train: epoch 95, iter 3600, loss: 2.878545, top_1: 0.576836, top_k: 0.798047, samples/s: 2975.521 1612032679.6921406
train: epoch 95, iter 3700, loss: 2.608821, top_1: 0.579492, top_k: 0.799609, samples/s: 2998.697 1612032688.2291548
train: epoch 95, iter 3800, loss: 2.832876, top_1: 0.579492, top_k: 0.801484, samples/s: 2950.667 1612032696.9051745
train: epoch 95, iter 3900, loss: 2.737415, top_1: 0.579453, top_k: 0.802656, samples/s: 2986.265 1612032705.4777648
train: epoch 95, iter 4000, loss: 2.581892, top_1: 0.581602, top_k: 0.799727, samples/s: 2989.865 1612032714.0400875
train: epoch 95, iter 4100, loss: 2.757219, top_1: 0.577695, top_k: 0.797109, samples/s: 2967.944 1612032722.6655283
train: epoch 95, iter 4200, loss: 2.734434, top_1: 0.582109, top_k: 0.803047, samples/s: 2987.846 1612032731.2336109
train: epoch 95, iter 4300, loss: 2.853430, top_1: 0.583711, top_k: 0.801289, samples/s: 2972.616 1612032739.845512
train: epoch 95, iter 4400, loss: 2.724290, top_1: 0.578711, top_k: 0.799805, samples/s: 2996.851 1612032748.3878083
train: epoch 95, iter 4500, loss: 2.812490, top_1: 0.578281, top_k: 0.796992, samples/s: 2994.610 1612032756.9365392
train: epoch 95, iter 4600, loss: 2.699036, top_1: 0.583359, top_k: 0.801445, samples/s: 2996.740 1612032765.4790933
train: epoch 95, iter 4700, loss: 2.658990, top_1: 0.578047, top_k: 0.798555, samples/s: 2930.915 1612032774.2137172
train: epoch 95, iter 4800, loss: 2.822573, top_1: 0.574727, top_k: 0.796133, samples/s: 2915.047 1612032782.9956522
train: epoch 95, iter 4900, loss: 2.594211, top_1: 0.577344, top_k: 0.798438, samples/s: 2939.063 1612032791.7058785
train: epoch 95, iter 5000, loss: 2.672582, top_1: 0.580664, top_k: 0.803086, samples/s: 3026.990 1612032800.1631057
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_95.
validation: epoch 95, iter 195, top_1: 0.614623, top_k: 0.841587, samples/s: 2904.215 1612032817.60137
train: epoch 96, iter 100, loss: 2.858385, top_1: 0.590352, top_k: 0.808555, samples/s: 2937.806 1612032842.0577972
train: epoch 96, iter 200, loss: 2.541076, top_1: 0.597500, top_k: 0.809375, samples/s: 2978.174 1612032850.6535265
train: epoch 96, iter 300, loss: 2.660859, top_1: 0.592930, top_k: 0.809961, samples/s: 2880.994 1612032859.5394313
train: epoch 96, iter 400, loss: 2.471172, top_1: 0.590938, top_k: 0.806914, samples/s: 2997.372 1612032868.080234
train: epoch 96, iter 500, loss: 2.699656, top_1: 0.589922, top_k: 0.806289, samples/s: 2996.876 1612032876.622418
train: epoch 96, iter 600, loss: 2.681366, top_1: 0.581055, top_k: 0.803203, samples/s: 2980.410 1612032885.2122018
train: epoch 96, iter 700, loss: 2.565231, top_1: 0.592031, top_k: 0.810898, samples/s: 3044.812 1612032893.6195989
train: epoch 96, iter 800, loss: 2.774397, top_1: 0.585859, top_k: 0.802344, samples/s: 3011.172 1612032902.1217308
train: epoch 96, iter 900, loss: 2.823348, top_1: 0.588242, top_k: 0.806055, samples/s: 2940.538 1612032910.8271618
train: epoch 96, iter 1000, loss: 2.952716, top_1: 0.582344, top_k: 0.805000, samples/s: 2859.687 1612032919.7792256
train: epoch 96, iter 1100, loss: 2.928223, top_1: 0.588828, top_k: 0.805156, samples/s: 2935.203 1612032928.5010228
train: epoch 96, iter 1200, loss: 2.698303, top_1: 0.588867, top_k: 0.805898, samples/s: 2967.534 1612032937.1276357
train: epoch 96, iter 1300, loss: 2.727034, top_1: 0.590977, top_k: 0.810469, samples/s: 2962.193 1612032945.7698529
train: epoch 96, iter 1400, loss: 2.516801, top_1: 0.591719, top_k: 0.808711, samples/s: 2951.998 1612032954.4419408
train: epoch 96, iter 1500, loss: 2.630325, top_1: 0.591328, top_k: 0.805312, samples/s: 2860.765 1612032963.3905997
train: epoch 96, iter 1600, loss: 2.579148, top_1: 0.585273, top_k: 0.805937, samples/s: 3036.951 1612032971.8201041
train: epoch 96, iter 1700, loss: 2.621027, top_1: 0.588437, top_k: 0.804766, samples/s: 2978.844 1612032980.4140341
train: epoch 96, iter 1800, loss: 2.549959, top_1: 0.587187, top_k: 0.809219, samples/s: 2985.880 1612032988.9877927
train: epoch 96, iter 1900, loss: 2.688158, top_1: 0.586758, top_k: 0.803281, samples/s: 2984.443 1612032997.565555
train: epoch 96, iter 2000, loss: 2.843661, top_1: 0.586836, top_k: 0.803555, samples/s: 2978.023 1612033006.1619105
train: epoch 96, iter 2100, loss: 2.725109, top_1: 0.588359, top_k: 0.806367, samples/s: 2978.545 1612033014.7567177
train: epoch 96, iter 2200, loss: 2.686029, top_1: 0.584531, top_k: 0.803984, samples/s: 3002.620 1612033023.2825236
train: epoch 96, iter 2300, loss: 2.677562, top_1: 0.585938, top_k: 0.803320, samples/s: 2983.584 1612033031.8628078
train: epoch 96, iter 2400, loss: 2.935011, top_1: 0.582891, top_k: 0.802461, samples/s: 2988.588 1612033040.4287174
train: epoch 96, iter 2500, loss: 2.880033, top_1: 0.579648, top_k: 0.802656, samples/s: 2968.998 1612033049.0511813
train: epoch 96, iter 2600, loss: 2.632027, top_1: 0.585000, top_k: 0.802656, samples/s: 2968.232 1612033057.6759176
train: epoch 96, iter 2700, loss: 2.680084, top_1: 0.586914, top_k: 0.806094, samples/s: 2990.842 1612033066.2352939
train: epoch 96, iter 2800, loss: 2.789714, top_1: 0.584844, top_k: 0.800820, samples/s: 2996.791 1612033074.7777715
train: epoch 96, iter 2900, loss: 2.667631, top_1: 0.582422, top_k: 0.800664, samples/s: 2985.022 1612033083.3539195
train: epoch 96, iter 3000, loss: 2.807719, top_1: 0.577617, top_k: 0.797031, samples/s: 2945.640 1612033092.0447583
train: epoch 96, iter 3100, loss: 2.758609, top_1: 0.581836, top_k: 0.803789, samples/s: 2944.630 1612033100.738513
train: epoch 96, iter 3200, loss: 2.518626, top_1: 0.585391, top_k: 0.806055, samples/s: 3003.238 1612033109.2626188
train: epoch 96, iter 3300, loss: 2.926514, top_1: 0.584141, top_k: 0.801719, samples/s: 2974.505 1612033117.869118
train: epoch 96, iter 3400, loss: 2.634212, top_1: 0.588750, top_k: 0.804531, samples/s: 2957.303 1612033126.5257473
train: epoch 96, iter 3500, loss: 2.766028, top_1: 0.584063, top_k: 0.799961, samples/s: 2967.234 1612033135.1533256
train: epoch 96, iter 3600, loss: 2.704083, top_1: 0.576719, top_k: 0.798711, samples/s: 2980.577 1612033143.7421947
train: epoch 96, iter 3700, loss: 2.559244, top_1: 0.581328, top_k: 0.805703, samples/s: 2871.094 1612033152.6586182
train: epoch 96, iter 3800, loss: 2.847265, top_1: 0.577148, top_k: 0.801211, samples/s: 2996.818 1612033161.2010524
train: epoch 96, iter 3900, loss: 2.918300, top_1: 0.578984, top_k: 0.804258, samples/s: 2970.167 1612033169.8200588
train: epoch 96, iter 4000, loss: 2.616713, top_1: 0.581953, top_k: 0.803320, samples/s: 3008.098 1612033178.3304112
train: epoch 96, iter 4100, loss: 2.669953, top_1: 0.580195, top_k: 0.802266, samples/s: 2975.736 1612033186.9334357
train: epoch 96, iter 4200, loss: 2.646529, top_1: 0.579727, top_k: 0.797070, samples/s: 2957.262 1612033195.5899885
train: epoch 96, iter 4300, loss: 2.642093, top_1: 0.584766, top_k: 0.803945, samples/s: 2965.368 1612033204.223017
train: epoch 96, iter 4400, loss: 2.928643, top_1: 0.585898, top_k: 0.802461, samples/s: 2986.695 1612033212.7944312
train: epoch 96, iter 4500, loss: 2.744201, top_1: 0.580586, top_k: 0.800391, samples/s: 2985.059 1612033221.3703966
train: epoch 96, iter 4600, loss: 2.818154, top_1: 0.578867, top_k: 0.800430, samples/s: 2969.334 1612033229.99191
train: epoch 96, iter 4700, loss: 2.943577, top_1: 0.582539, top_k: 0.801562, samples/s: 3020.593 1612033238.4670072
train: epoch 96, iter 4800, loss: 2.697301, top_1: 0.579414, top_k: 0.798281, samples/s: 3005.223 1612033246.9855533
train: epoch 96, iter 4900, loss: 2.735689, top_1: 0.579492, top_k: 0.800547, samples/s: 2979.051 1612033255.5789254
train: epoch 96, iter 5000, loss: 2.824457, top_1: 0.592891, top_k: 0.807148, samples/s: 2957.391 1612033264.2352977
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_96.
validation: epoch 96, iter 195, top_1: 0.629828, top_k: 0.849700, samples/s: 2934.688 1612033281.505999
train: epoch 97, iter 100, loss: 2.820644, top_1: 0.594766, top_k: 0.809883, samples/s: 2943.613 1612033306.1917481
train: epoch 97, iter 200, loss: 2.673706, top_1: 0.589883, top_k: 0.806133, samples/s: 2981.849 1612033314.776926
train: epoch 97, iter 300, loss: 2.723951, top_1: 0.585586, top_k: 0.805352, samples/s: 3010.667 1612033323.2801807
train: epoch 97, iter 400, loss: 2.839328, top_1: 0.592656, top_k: 0.804258, samples/s: 3025.979 1612033331.7405176
train: epoch 97, iter 500, loss: 2.568673, top_1: 0.595352, top_k: 0.812109, samples/s: 3007.139 1612033340.2533724
train: epoch 97, iter 600, loss: 2.703098, top_1: 0.590859, top_k: 0.808398, samples/s: 2990.142 1612033348.8146942
train: epoch 97, iter 700, loss: 2.744385, top_1: 0.593320, top_k: 0.808672, samples/s: 2924.032 1612033357.569724
train: epoch 97, iter 800, loss: 2.697499, top_1: 0.592734, top_k: 0.809766, samples/s: 3005.077 1612033366.0886471
train: epoch 97, iter 900, loss: 2.792471, top_1: 0.592070, top_k: 0.808164, samples/s: 3008.074 1612033374.5990777
train: epoch 97, iter 1000, loss: 2.853876, top_1: 0.584414, top_k: 0.801211, samples/s: 2922.574 1612033383.3584664
train: epoch 97, iter 1100, loss: 2.765477, top_1: 0.591250, top_k: 0.806250, samples/s: 2943.649 1612033392.055176
train: epoch 97, iter 1200, loss: 2.634711, top_1: 0.587656, top_k: 0.808672, samples/s: 2947.686 1612033400.740075
train: epoch 97, iter 1300, loss: 2.631830, top_1: 0.585859, top_k: 0.806445, samples/s: 2954.852 1612033409.4036267
train: epoch 97, iter 1400, loss: 2.693192, top_1: 0.586211, top_k: 0.804219, samples/s: 2977.384 1612033418.001811
train: epoch 97, iter 1500, loss: 2.517109, top_1: 0.585508, top_k: 0.804609, samples/s: 2840.766 1612033427.013546
train: epoch 97, iter 1600, loss: 2.648638, top_1: 0.584180, top_k: 0.799180, samples/s: 3025.451 1612033435.4750276
train: epoch 97, iter 1700, loss: 2.678553, top_1: 0.585000, top_k: 0.805273, samples/s: 2996.599 1612033444.018022
train: epoch 97, iter 1800, loss: 2.661186, top_1: 0.591133, top_k: 0.812734, samples/s: 2971.576 1612033452.6331623
train: epoch 97, iter 1900, loss: 2.710645, top_1: 0.588789, top_k: 0.808555, samples/s: 2997.427 1612033461.1736443
train: epoch 97, iter 2000, loss: 2.740355, top_1: 0.588711, top_k: 0.807227, samples/s: 2994.247 1612033469.723431
train: epoch 97, iter 2100, loss: 2.687891, top_1: 0.591797, top_k: 0.807031, samples/s: 2978.158 1612033478.3192968
train: epoch 97, iter 2200, loss: 2.734029, top_1: 0.588242, top_k: 0.807969, samples/s: 3008.566 1612033486.82833
train: epoch 97, iter 2300, loss: 2.737730, top_1: 0.587031, top_k: 0.807773, samples/s: 2976.666 1612033495.428557
train: epoch 97, iter 2400, loss: 2.640128, top_1: 0.584844, top_k: 0.803750, samples/s: 2930.978 1612033504.1628385
train: epoch 97, iter 2500, loss: 2.579452, top_1: 0.587187, top_k: 0.805898, samples/s: 2972.813 1612033512.7742293
train: epoch 97, iter 2600, loss: 2.728428, top_1: 0.581836, top_k: 0.800508, samples/s: 2982.566 1612033521.3579981
train: epoch 97, iter 2700, loss: 2.936423, top_1: 0.593633, top_k: 0.808203, samples/s: 2940.145 1612033530.064516
train: epoch 97, iter 2800, loss: 2.764840, top_1: 0.585078, top_k: 0.802539, samples/s: 3001.947 1612033538.5923958
train: epoch 97, iter 2900, loss: 2.702365, top_1: 0.581445, top_k: 0.802930, samples/s: 2896.547 1612033547.430486
train: epoch 97, iter 3000, loss: 2.779667, top_1: 0.590195, top_k: 0.806211, samples/s: 3024.342 1612033555.895541
train: epoch 97, iter 3100, loss: 2.823607, top_1: 0.587656, top_k: 0.805195, samples/s: 2989.739 1612033564.4576948
train: epoch 97, iter 3200, loss: 2.730931, top_1: 0.581719, top_k: 0.803359, samples/s: 2977.317 1612033573.0560837
train: epoch 97, iter 3300, loss: 2.744874, top_1: 0.588242, top_k: 0.801719, samples/s: 2927.090 1612033581.8021138
train: epoch 97, iter 3400, loss: 2.761476, top_1: 0.584727, top_k: 0.801211, samples/s: 2986.332 1612033590.3742883
train: epoch 97, iter 3500, loss: 2.902504, top_1: 0.583633, top_k: 0.802461, samples/s: 2957.009 1612033599.0316927
train: epoch 97, iter 3600, loss: 2.778036, top_1: 0.582969, top_k: 0.801719, samples/s: 2964.056 1612033607.6684928
train: epoch 97, iter 3700, loss: 2.679380, top_1: 0.589922, top_k: 0.804414, samples/s: 3004.292 1612033616.18971
train: epoch 97, iter 3800, loss: 2.745770, top_1: 0.587187, top_k: 0.805078, samples/s: 3006.246 1612033624.705342
train: epoch 97, iter 3900, loss: 2.975725, top_1: 0.584609, top_k: 0.804414, samples/s: 2930.463 1612033633.4411857
train: epoch 97, iter 4000, loss: 2.506549, top_1: 0.587891, top_k: 0.805703, samples/s: 3009.628 1612033641.9471588
train: epoch 97, iter 4100, loss: 2.680970, top_1: 0.583906, top_k: 0.804453, samples/s: 2944.285 1612033650.6419177
train: epoch 97, iter 4200, loss: 2.672470, top_1: 0.585000, top_k: 0.802266, samples/s: 3029.216 1612033659.093359
train: epoch 97, iter 4300, loss: 2.590334, top_1: 0.584219, top_k: 0.801172, samples/s: 2984.168 1612033667.6715436
train: epoch 97, iter 4400, loss: 2.567053, top_1: 0.582383, top_k: 0.805117, samples/s: 2943.992 1612033676.3672884
train: epoch 97, iter 4500, loss: 2.800314, top_1: 0.581289, top_k: 0.798672, samples/s: 2992.300 1612033684.9225538
train: epoch 97, iter 4600, loss: 2.928748, top_1: 0.587070, top_k: 0.804492, samples/s: 2956.891 1612033693.580701
train: epoch 97, iter 4700, loss: 2.594505, top_1: 0.579922, top_k: 0.801406, samples/s: 3005.747 1612033702.0972908
train: epoch 97, iter 4800, loss: 2.778721, top_1: 0.584883, top_k: 0.806445, samples/s: 2976.086 1612033710.6991744
train: epoch 97, iter 4900, loss: 2.866392, top_1: 0.581641, top_k: 0.802500, samples/s: 2987.945 1612033719.2672408
train: epoch 97, iter 5000, loss: 2.522990, top_1: 0.585234, top_k: 0.803438, samples/s: 2918.568 1612033728.0383995
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_97.
validation: epoch 97, iter 195, top_1: 0.627003, top_k: 0.848257, samples/s: 3052.459 1612033744.63282
train: epoch 98, iter 100, loss: 2.494536, top_1: 0.597539, top_k: 0.815156, samples/s: 2944.613 1612033769.2988002
train: epoch 98, iter 200, loss: 2.807754, top_1: 0.585469, top_k: 0.805312, samples/s: 2962.801 1612033777.9392822
train: epoch 98, iter 300, loss: 2.703432, top_1: 0.588711, top_k: 0.810195, samples/s: 3013.988 1612033786.4330027
train: epoch 98, iter 400, loss: 2.784061, top_1: 0.599805, top_k: 0.813359, samples/s: 2941.531 1612033795.1360407
train: epoch 98, iter 500, loss: 2.813036, top_1: 0.590156, top_k: 0.807266, samples/s: 2956.569 1612033803.794666
train: epoch 98, iter 600, loss: 2.717916, top_1: 0.591602, top_k: 0.809805, samples/s: 2984.767 1612033812.3715334
train: epoch 98, iter 700, loss: 2.688021, top_1: 0.594258, top_k: 0.807305, samples/s: 3013.784 1612033820.865897
train: epoch 98, iter 800, loss: 2.795677, top_1: 0.587500, top_k: 0.804453, samples/s: 2972.192 1612033829.4790237
train: epoch 98, iter 900, loss: 2.632284, top_1: 0.594297, top_k: 0.810430, samples/s: 2951.653 1612033838.1520622
train: epoch 98, iter 1000, loss: 2.631743, top_1: 0.591367, top_k: 0.804219, samples/s: 3002.025 1612033846.6797636
train: epoch 98, iter 1100, loss: 2.586653, top_1: 0.592109, top_k: 0.808828, samples/s: 2983.253 1612033855.2609336
train: epoch 98, iter 1200, loss: 2.466297, top_1: 0.591211, top_k: 0.810195, samples/s: 2964.376 1612033863.8968124
train: epoch 98, iter 1300, loss: 2.681289, top_1: 0.596719, top_k: 0.815273, samples/s: 2949.444 1612033872.576416
train: epoch 98, iter 1400, loss: 2.756227, top_1: 0.594219, top_k: 0.809570, samples/s: 2982.509 1612033881.1598034
train: epoch 98, iter 1500, loss: 2.665070, top_1: 0.591875, top_k: 0.806680, samples/s: 2881.224 1612033890.0449417
train: epoch 98, iter 1600, loss: 2.857384, top_1: 0.587383, top_k: 0.807891, samples/s: 3036.201 1612033898.476521
train: epoch 98, iter 1700, loss: 2.686865, top_1: 0.588437, top_k: 0.803320, samples/s: 2970.982 1612033907.0932045
train: epoch 98, iter 1800, loss: 2.760210, top_1: 0.584336, top_k: 0.803398, samples/s: 2965.565 1612033915.7256012
train: epoch 98, iter 1900, loss: 2.807533, top_1: 0.592070, top_k: 0.806367, samples/s: 2961.708 1612033924.369379
train: epoch 98, iter 2000, loss: 2.775317, top_1: 0.588203, top_k: 0.807148, samples/s: 2988.090 1612033932.9365993
train: epoch 98, iter 2100, loss: 2.663589, top_1: 0.592344, top_k: 0.809844, samples/s: 3000.588 1612033941.468387
train: epoch 98, iter 2200, loss: 2.903927, top_1: 0.587539, top_k: 0.804727, samples/s: 2980.713 1612033950.0567997
train: epoch 98, iter 2300, loss: 2.691579, top_1: 0.588008, top_k: 0.805117, samples/s: 2965.114 1612033958.6905692
train: epoch 98, iter 2400, loss: 2.651470, top_1: 0.589180, top_k: 0.806367, samples/s: 2941.331 1612033967.3941312
train: epoch 98, iter 2500, loss: 2.686893, top_1: 0.590781, top_k: 0.807734, samples/s: 2979.392 1612033975.9864283
train: epoch 98, iter 2600, loss: 2.776507, top_1: 0.582930, top_k: 0.803828, samples/s: 2984.614 1612033984.5638258
train: epoch 98, iter 2700, loss: 2.718979, top_1: 0.588672, top_k: 0.806406, samples/s: 2923.246 1612033993.3213656
train: epoch 98, iter 2800, loss: 2.943755, top_1: 0.592500, top_k: 0.808438, samples/s: 3039.137 1612034001.7445958
train: epoch 98, iter 2900, loss: 2.885005, top_1: 0.584805, top_k: 0.805703, samples/s: 2965.986 1612034010.3758128
train: epoch 98, iter 3000, loss: 2.922038, top_1: 0.592031, top_k: 0.805078, samples/s: 3005.192 1612034018.8943644
train: epoch 98, iter 3100, loss: 2.657227, top_1: 0.591602, top_k: 0.807031, samples/s: 2982.435 1612034027.4780328
train: epoch 98, iter 3200, loss: 2.770871, top_1: 0.582305, top_k: 0.805547, samples/s: 2940.873 1612034036.1828766
train: epoch 98, iter 3300, loss: 2.663673, top_1: 0.588750, top_k: 0.806055, samples/s: 2965.791 1612034044.8146524
train: epoch 98, iter 3400, loss: 2.624915, top_1: 0.590781, top_k: 0.811250, samples/s: 2965.841 1612034053.4463031
train: epoch 98, iter 3500, loss: 2.875950, top_1: 0.583164, top_k: 0.803320, samples/s: 2981.444 1612034062.0326734
train: epoch 98, iter 3600, loss: 2.577941, top_1: 0.584336, top_k: 0.810000, samples/s: 3026.920 1612034070.4901166
train: epoch 98, iter 3700, loss: 2.717302, top_1: 0.591328, top_k: 0.809688, samples/s: 2997.222 1612034079.031395
train: epoch 98, iter 3800, loss: 2.715673, top_1: 0.587070, top_k: 0.805586, samples/s: 2946.290 1612034087.7203078
train: epoch 98, iter 3900, loss: 2.722150, top_1: 0.580039, top_k: 0.804961, samples/s: 2982.485 1612034096.3037105
train: epoch 98, iter 4000, loss: 2.773460, top_1: 0.586836, top_k: 0.806836, samples/s: 2989.916 1612034104.8658183
train: epoch 98, iter 4100, loss: 2.828055, top_1: 0.586562, top_k: 0.802109, samples/s: 2946.578 1612034113.5539346
train: epoch 98, iter 4200, loss: 2.714675, top_1: 0.581250, top_k: 0.804922, samples/s: 2991.517 1612034122.1113985
train: epoch 98, iter 4300, loss: 2.614493, top_1: 0.587344, top_k: 0.804844, samples/s: 2969.446 1612034130.7325494
train: epoch 98, iter 4400, loss: 2.774492, top_1: 0.584922, top_k: 0.804375, samples/s: 2943.840 1612034139.4286544
train: epoch 98, iter 4500, loss: 2.722677, top_1: 0.585273, top_k: 0.798398, samples/s: 2914.408 1612034148.212673
train: epoch 98, iter 4600, loss: 2.713066, top_1: 0.587812, top_k: 0.805625, samples/s: 3000.776 1612034156.743741
train: epoch 98, iter 4700, loss: 3.004137, top_1: 0.582617, top_k: 0.803906, samples/s: 2975.921 1612034165.346112
train: epoch 98, iter 4800, loss: 2.578755, top_1: 0.585586, top_k: 0.805898, samples/s: 2888.292 1612034174.2095034
train: epoch 98, iter 4900, loss: 2.731732, top_1: 0.586562, top_k: 0.803164, samples/s: 2972.468 1612034182.8218637
train: epoch 98, iter 5000, loss: 2.595227, top_1: 0.594648, top_k: 0.812500, samples/s: 2902.361 1612034191.642337
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_98.
validation: epoch 98, iter 195, top_1: 0.627664, top_k: 0.850541, samples/s: 2992.658 1612034208.5365345
train: epoch 99, iter 100, loss: 2.438377, top_1: 0.602891, top_k: 0.815117, samples/s: 2983.122 1612034233.0693333
train: epoch 99, iter 200, loss: 2.747000, top_1: 0.599336, top_k: 0.812930, samples/s: 3016.057 1612034241.5573025
train: epoch 99, iter 300, loss: 2.646435, top_1: 0.597969, top_k: 0.811602, samples/s: 2849.856 1612034250.540093
train: epoch 99, iter 400, loss: 2.826738, top_1: 0.599336, top_k: 0.812070, samples/s: 2961.804 1612034259.183576
train: epoch 99, iter 500, loss: 2.657804, top_1: 0.586914, top_k: 0.802070, samples/s: 3020.310 1612034267.6597896
train: epoch 99, iter 600, loss: 2.649426, top_1: 0.598398, top_k: 0.810742, samples/s: 2975.010 1612034276.2644584
train: epoch 99, iter 700, loss: 2.755782, top_1: 0.598516, top_k: 0.811133, samples/s: 3004.711 1612034284.7844334
train: epoch 99, iter 800, loss: 2.578260, top_1: 0.590117, top_k: 0.808125, samples/s: 2989.402 1612034293.3479707
train: epoch 99, iter 900, loss: 2.613054, top_1: 0.593945, top_k: 0.813164, samples/s: 3006.564 1612034301.8626695
train: epoch 99, iter 1000, loss: 2.797111, top_1: 0.587734, top_k: 0.806602, samples/s: 3000.682 1612034310.3940413
train: epoch 99, iter 1100, loss: 2.674129, top_1: 0.595039, top_k: 0.811562, samples/s: 2976.688 1612034318.9942603
train: epoch 99, iter 1200, loss: 2.728378, top_1: 0.589844, top_k: 0.810234, samples/s: 2999.304 1612034327.5296104
train: epoch 99, iter 1300, loss: 2.588188, top_1: 0.590430, top_k: 0.808555, samples/s: 2891.960 1612034336.3816736
train: epoch 99, iter 1400, loss: 2.731864, top_1: 0.592344, top_k: 0.807070, samples/s: 3015.227 1612034344.8719873
train: epoch 99, iter 1500, loss: 2.783288, top_1: 0.587539, top_k: 0.808359, samples/s: 2989.816 1612034353.4343772
train: epoch 99, iter 1600, loss: 2.760480, top_1: 0.591211, top_k: 0.806133, samples/s: 2957.256 1612034362.0910068
train: epoch 99, iter 1700, loss: 2.805239, top_1: 0.589609, top_k: 0.804766, samples/s: 3007.749 1612034370.6023378
train: epoch 99, iter 1800, loss: 2.783098, top_1: 0.590469, top_k: 0.808438, samples/s: 3002.805 1612034379.1276648
train: epoch 99, iter 1900, loss: 2.621478, top_1: 0.589297, top_k: 0.806992, samples/s: 2954.250 1612034387.7933621
train: epoch 99, iter 2000, loss: 2.548771, top_1: 0.589336, top_k: 0.805820, samples/s: 3018.512 1612034396.2741816
train: epoch 99, iter 2100, loss: 2.691060, top_1: 0.592812, top_k: 0.806758, samples/s: 2945.363 1612034404.965756
train: epoch 99, iter 2200, loss: 2.700268, top_1: 0.594648, top_k: 0.808711, samples/s: 3011.153 1612034413.4675746
train: epoch 99, iter 2300, loss: 2.635506, top_1: 0.597305, top_k: 0.813594, samples/s: 2882.812 1612034422.3478255
train: epoch 99, iter 2400, loss: 2.517658, top_1: 0.595586, top_k: 0.812617, samples/s: 2983.506 1612034430.9282568
train: epoch 99, iter 2500, loss: 2.718320, top_1: 0.590000, top_k: 0.807344, samples/s: 2976.091 1612034439.5301445
train: epoch 99, iter 2600, loss: 2.730121, top_1: 0.589609, top_k: 0.805586, samples/s: 2981.555 1612034448.1162806
train: epoch 99, iter 2700, loss: 2.664530, top_1: 0.590820, top_k: 0.808438, samples/s: 2955.110 1612034456.779237
train: epoch 99, iter 2800, loss: 2.631752, top_1: 0.590273, top_k: 0.807344, samples/s: 2991.743 1612034465.3361635
train: epoch 99, iter 2900, loss: 2.701498, top_1: 0.590508, top_k: 0.806719, samples/s: 3002.785 1612034473.8616233
train: epoch 99, iter 3000, loss: 2.863212, top_1: 0.589102, top_k: 0.805000, samples/s: 2953.990 1612034482.5277636
train: epoch 99, iter 3100, loss: 2.794961, top_1: 0.586289, top_k: 0.802813, samples/s: 2991.183 1612034491.0863528
train: epoch 99, iter 3200, loss: 2.704279, top_1: 0.583633, top_k: 0.801367, samples/s: 2953.748 1612034499.753235
train: epoch 99, iter 3300, loss: 2.664175, top_1: 0.589766, top_k: 0.807344, samples/s: 2977.707 1612034508.3504436
train: epoch 99, iter 3400, loss: 2.837926, top_1: 0.589219, top_k: 0.805859, samples/s: 2962.919 1612034516.9905808
train: epoch 99, iter 3500, loss: 2.860673, top_1: 0.586680, top_k: 0.804258, samples/s: 2904.990 1612034525.802994
train: epoch 99, iter 3600, loss: 2.574465, top_1: 0.587305, top_k: 0.807187, samples/s: 2944.309 1612034534.4978814
train: epoch 99, iter 3700, loss: 2.626610, top_1: 0.586719, top_k: 0.804414, samples/s: 2966.124 1612034543.1285274
train: epoch 99, iter 3800, loss: 2.774432, top_1: 0.589102, top_k: 0.806094, samples/s: 2928.606 1612034551.8698812
train: epoch 99, iter 3900, loss: 2.768795, top_1: 0.585547, top_k: 0.808047, samples/s: 3030.005 1612034560.3187308
train: epoch 99, iter 4000, loss: 2.764274, top_1: 0.582539, top_k: 0.803320, samples/s: 2996.469 1612034568.8621855
train: epoch 99, iter 4100, loss: 2.646647, top_1: 0.592461, top_k: 0.806758, samples/s: 2920.632 1612034577.6273446
train: epoch 99, iter 4200, loss: 2.788590, top_1: 0.589766, top_k: 0.805234, samples/s: 2971.481 1612034586.2425601
train: epoch 99, iter 4300, loss: 2.856984, top_1: 0.586406, top_k: 0.805469, samples/s: 2898.960 1612034595.0733936
train: epoch 99, iter 4400, loss: 2.666238, top_1: 0.587891, top_k: 0.805312, samples/s: 2990.834 1612034603.6327984
train: epoch 99, iter 4500, loss: 2.766918, top_1: 0.588086, top_k: 0.808242, samples/s: 2979.253 1612034612.2255523
train: epoch 99, iter 4600, loss: 2.674539, top_1: 0.593203, top_k: 0.805820, samples/s: 2982.818 1612034620.8080435
train: epoch 99, iter 4700, loss: 2.718554, top_1: 0.586992, top_k: 0.805664, samples/s: 2995.567 1612034629.353996
train: epoch 99, iter 4800, loss: 2.738303, top_1: 0.588516, top_k: 0.808086, samples/s: 2979.686 1612034637.9455285
train: epoch 99, iter 4900, loss: 2.829189, top_1: 0.583711, top_k: 0.805586, samples/s: 2925.197 1612034646.6970904
train: epoch 99, iter 5000, loss: 2.753326, top_1: 0.591523, top_k: 0.809805, samples/s: 3009.998 1612034655.2020168
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_99.
validation: epoch 99, iter 195, top_1: 0.632232, top_k: 0.853466, samples/s: 2927.105 1612034672.5373533
train: epoch 100, iter 100, loss: 2.528865, top_1: 0.597383, top_k: 0.811445, samples/s: 2928.690 1612034697.0070736
train: epoch 100, iter 200, loss: 2.618096, top_1: 0.597852, top_k: 0.812031, samples/s: 2862.001 1612034705.9518821
train: epoch 100, iter 300, loss: 2.569070, top_1: 0.600781, top_k: 0.816953, samples/s: 3039.097 1612034714.3754458
train: epoch 100, iter 400, loss: 2.796839, top_1: 0.600469, top_k: 0.815352, samples/s: 3003.810 1612034722.8981886
train: epoch 100, iter 500, loss: 2.568301, top_1: 0.594492, top_k: 0.810508, samples/s: 2947.209 1612034731.5842216
train: epoch 100, iter 600, loss: 2.556305, top_1: 0.592656, top_k: 0.810937, samples/s: 3003.265 1612034740.1082292
train: epoch 100, iter 700, loss: 2.669104, top_1: 0.603320, top_k: 0.817891, samples/s: 2960.765 1612034748.7547069
train: epoch 100, iter 800, loss: 2.774455, top_1: 0.596914, top_k: 0.811641, samples/s: 2969.314 1612034757.3773258
train: epoch 100, iter 900, loss: 2.794793, top_1: 0.593008, top_k: 0.809492, samples/s: 2989.656 1612034765.938876
train: epoch 100, iter 1000, loss: 2.628301, top_1: 0.598750, top_k: 0.816094, samples/s: 2948.897 1612034774.6201296
train: epoch 100, iter 1100, loss: 2.740681, top_1: 0.596289, top_k: 0.810977, samples/s: 2996.709 1612034783.1629856
train: epoch 100, iter 1200, loss: 2.629308, top_1: 0.587461, top_k: 0.807500, samples/s: 2971.983 1612034791.7766986
train: epoch 100, iter 1300, loss: 2.722969, top_1: 0.593633, top_k: 0.810664, samples/s: 3004.413 1612034800.2973542
train: epoch 100, iter 1400, loss: 2.736166, top_1: 0.591016, top_k: 0.809492, samples/s: 2993.865 1612034808.8483772
train: epoch 100, iter 1500, loss: 2.813762, top_1: 0.593125, top_k: 0.808633, samples/s: 2946.649 1612034817.5360522
train: epoch 100, iter 1600, loss: 2.718644, top_1: 0.596914, top_k: 0.811367, samples/s: 3007.464 1612034826.048356
train: epoch 100, iter 1700, loss: 2.670934, top_1: 0.594141, top_k: 0.813477, samples/s: 2932.542 1612034834.7781396
train: epoch 100, iter 1800, loss: 2.700733, top_1: 0.595625, top_k: 0.810234, samples/s: 2982.108 1612034843.3624086
train: epoch 100, iter 1900, loss: 2.664150, top_1: 0.594375, top_k: 0.811602, samples/s: 2933.264 1612034852.089862
train: epoch 100, iter 2000, loss: 2.664192, top_1: 0.595820, top_k: 0.811523, samples/s: 2850.091 1612034861.0720859
train: epoch 100, iter 2100, loss: 2.545451, top_1: 0.589805, top_k: 0.809258, samples/s: 2980.586 1612034869.6609452
train: epoch 100, iter 2200, loss: 2.668176, top_1: 0.589102, top_k: 0.809180, samples/s: 2934.477 1612034878.3848512
train: epoch 100, iter 2300, loss: 2.650949, top_1: 0.588672, top_k: 0.808086, samples/s: 2967.993 1612034887.0101714
train: epoch 100, iter 2400, loss: 2.750011, top_1: 0.598516, top_k: 0.811836, samples/s: 2959.289 1612034895.6609247
train: epoch 100, iter 2500, loss: 2.866066, top_1: 0.591562, top_k: 0.808320, samples/s: 2924.737 1612034904.413819
train: epoch 100, iter 2600, loss: 2.780631, top_1: 0.593828, top_k: 0.811367, samples/s: 2952.071 1612034913.0856855
train: epoch 100, iter 2700, loss: 2.483656, top_1: 0.595117, top_k: 0.814414, samples/s: 2980.637 1612034921.6745267
train: epoch 100, iter 2800, loss: 2.649734, top_1: 0.586836, top_k: 0.808047, samples/s: 2977.770 1612034930.2715013
train: epoch 100, iter 2900, loss: 2.688935, top_1: 0.597187, top_k: 0.810195, samples/s: 2956.918 1612034938.9291854
train: epoch 100, iter 3000, loss: 2.736046, top_1: 0.595000, top_k: 0.810859, samples/s: 2993.860 1612034947.4800062
train: epoch 100, iter 3100, loss: 2.609114, top_1: 0.591289, top_k: 0.809258, samples/s: 2966.400 1612034956.109991
train: epoch 100, iter 3200, loss: 2.783498, top_1: 0.592422, top_k: 0.812578, samples/s: 2997.509 1612034964.6504261
train: epoch 100, iter 3300, loss: 2.609744, top_1: 0.584492, top_k: 0.805664, samples/s: 2991.606 1612034973.2076602
train: epoch 100, iter 3400, loss: 2.783546, top_1: 0.588711, top_k: 0.808477, samples/s: 2890.314 1612034982.064912
train: epoch 100, iter 3500, loss: 2.831408, top_1: 0.592227, top_k: 0.807695, samples/s: 3012.610 1612034990.5624804
train: epoch 100, iter 3600, loss: 2.808317, top_1: 0.598398, top_k: 0.815312, samples/s: 2959.668 1612034999.2120903
train: epoch 100, iter 3700, loss: 2.677614, top_1: 0.592734, top_k: 0.810117, samples/s: 2949.042 1612035007.8928926
train: epoch 100, iter 3800, loss: 2.647085, top_1: 0.590234, top_k: 0.809219, samples/s: 2975.826 1612035016.4956062
train: epoch 100, iter 3900, loss: 2.834743, top_1: 0.594258, top_k: 0.813516, samples/s: 2954.322 1612035025.1608002
train: epoch 100, iter 4000, loss: 2.735946, top_1: 0.592070, top_k: 0.809688, samples/s: 2980.067 1612035033.7512443
train: epoch 100, iter 4100, loss: 2.702072, top_1: 0.594219, top_k: 0.805781, samples/s: 2954.020 1612035042.417417
train: epoch 100, iter 4200, loss: 2.967679, top_1: 0.589102, top_k: 0.807539, samples/s: 3002.071 1612035050.9448845
train: epoch 100, iter 4300, loss: 2.744514, top_1: 0.595820, top_k: 0.810000, samples/s: 2911.760 1612035059.7367413
train: epoch 100, iter 4400, loss: 2.590576, top_1: 0.591406, top_k: 0.806836, samples/s: 2968.677 1612035068.360131
train: epoch 100, iter 4500, loss: 2.612731, top_1: 0.587227, top_k: 0.805117, samples/s: 2991.329 1612035076.9181972
train: epoch 100, iter 4600, loss: 2.640413, top_1: 0.587539, top_k: 0.806289, samples/s: 2973.603 1612035085.5273218
train: epoch 100, iter 4700, loss: 2.826404, top_1: 0.591094, top_k: 0.810820, samples/s: 2898.830 1612035094.3584845
train: epoch 100, iter 4800, loss: 2.662176, top_1: 0.591016, top_k: 0.804766, samples/s: 2976.418 1612035102.9593835
train: epoch 100, iter 4900, loss: 2.644803, top_1: 0.591445, top_k: 0.807109, samples/s: 2997.144 1612035111.5008173
train: epoch 100, iter 5000, loss: 2.519813, top_1: 0.596289, top_k: 0.808672, samples/s: 2977.422 1612035120.0990465
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_100.
validation: epoch 100, iter 195, top_1: 0.634295, top_k: 0.852604, samples/s: 3029.731 1612035136.8602324
train: epoch 101, iter 100, loss: 2.654638, top_1: 0.602266, top_k: 0.818477, samples/s: 2973.501 1612035161.3015532
train: epoch 101, iter 200, loss: 2.769543, top_1: 0.603477, top_k: 0.820039, samples/s: 3012.748 1612035169.7988074
train: epoch 101, iter 300, loss: 2.715734, top_1: 0.598633, top_k: 0.814336, samples/s: 2984.851 1612035178.375448
train: epoch 101, iter 400, loss: 2.604187, top_1: 0.598789, top_k: 0.814688, samples/s: 3005.135 1612035186.894229
train: epoch 101, iter 500, loss: 2.622025, top_1: 0.600156, top_k: 0.814805, samples/s: 2998.263 1612035195.432535
train: epoch 101, iter 600, loss: 2.766363, top_1: 0.599766, top_k: 0.813906, samples/s: 3006.992 1612035203.9459941
train: epoch 101, iter 700, loss: 2.782412, top_1: 0.596055, top_k: 0.811484, samples/s: 2988.518 1612035212.5120718
train: epoch 101, iter 800, loss: 2.557908, top_1: 0.600820, top_k: 0.812656, samples/s: 2936.983 1612035221.2284873
train: epoch 101, iter 900, loss: 2.710358, top_1: 0.590078, top_k: 0.806797, samples/s: 3006.877 1612035229.7423084
train: epoch 101, iter 1000, loss: 2.743290, top_1: 0.598125, top_k: 0.815820, samples/s: 2942.744 1612035238.4416895
train: epoch 101, iter 1100, loss: 2.623510, top_1: 0.593281, top_k: 0.810312, samples/s: 2998.912 1612035246.978129
train: epoch 101, iter 1200, loss: 2.744884, top_1: 0.592891, top_k: 0.812266, samples/s: 3001.014 1612035255.5085535
train: epoch 101, iter 1300, loss: 2.906023, top_1: 0.592500, top_k: 0.811094, samples/s: 2965.044 1612035264.1425037
train: epoch 101, iter 1400, loss: 2.571978, top_1: 0.601328, top_k: 0.814023, samples/s: 2950.463 1612035272.8190894
train: epoch 101, iter 1500, loss: 2.652290, top_1: 0.593828, top_k: 0.810664, samples/s: 2980.417 1612035281.4085498
train: epoch 101, iter 1600, loss: 2.798358, top_1: 0.589883, top_k: 0.809258, samples/s: 2948.627 1612035290.0905282
train: epoch 101, iter 1700, loss: 2.685732, top_1: 0.599336, top_k: 0.814883, samples/s: 2938.862 1612035298.8013582
train: epoch 101, iter 1800, loss: 2.731823, top_1: 0.594102, top_k: 0.810742, samples/s: 2943.853 1612035307.4975257
train: epoch 101, iter 1900, loss: 2.617638, top_1: 0.595703, top_k: 0.812422, samples/s: 2924.174 1612035316.25212
train: epoch 101, iter 2000, loss: 2.822205, top_1: 0.598047, top_k: 0.813984, samples/s: 2999.636 1612035324.786473
train: epoch 101, iter 2100, loss: 2.641260, top_1: 0.589414, top_k: 0.804922, samples/s: 2941.262 1612035333.4901953
train: epoch 101, iter 2200, loss: 2.669294, top_1: 0.594453, top_k: 0.812266, samples/s: 2944.358 1612035342.1847844
train: epoch 101, iter 2300, loss: 2.606839, top_1: 0.598594, top_k: 0.812148, samples/s: 2989.848 1612035350.7470815
train: epoch 101, iter 2400, loss: 2.650012, top_1: 0.591055, top_k: 0.810508, samples/s: 2870.435 1612035359.6656082
train: epoch 101, iter 2500, loss: 2.725019, top_1: 0.597227, top_k: 0.810703, samples/s: 2923.273 1612035368.422986
train: epoch 101, iter 2600, loss: 2.640186, top_1: 0.591133, top_k: 0.809102, samples/s: 2991.429 1612035376.9807358
train: epoch 101, iter 2700, loss: 2.668260, top_1: 0.590938, top_k: 0.804766, samples/s: 2994.603 1612035385.52949
train: epoch 101, iter 2800, loss: 2.767179, top_1: 0.600273, top_k: 0.813125, samples/s: 2915.495 1612035394.3100524
train: epoch 101, iter 2900, loss: 2.587974, top_1: 0.594492, top_k: 0.814414, samples/s: 3024.770 1612035402.7735043
train: epoch 101, iter 3000, loss: 2.587990, top_1: 0.594063, top_k: 0.808945, samples/s: 2911.469 1612035411.5663664
train: epoch 101, iter 3100, loss: 2.535372, top_1: 0.597656, top_k: 0.813633, samples/s: 3009.929 1612035420.0715597
train: epoch 101, iter 3200, loss: 2.625418, top_1: 0.588672, top_k: 0.806133, samples/s: 2958.150 1612035428.7255576
train: epoch 101, iter 3300, loss: 2.876692, top_1: 0.592187, top_k: 0.808906, samples/s: 3006.893 1612035437.2393339
train: epoch 101, iter 3400, loss: 2.788658, top_1: 0.594023, top_k: 0.809023, samples/s: 3008.430 1612035445.748871
train: epoch 101, iter 3500, loss: 2.627800, top_1: 0.598945, top_k: 0.810234, samples/s: 2848.574 1612035454.7358124
train: epoch 101, iter 3600, loss: 2.712823, top_1: 0.587734, top_k: 0.807227, samples/s: 3032.934 1612035463.17658
train: epoch 101, iter 3700, loss: 2.674114, top_1: 0.593633, top_k: 0.811055, samples/s: 2981.245 1612035471.7633893
train: epoch 101, iter 3800, loss: 2.771316, top_1: 0.591797, top_k: 0.810352, samples/s: 2970.969 1612035480.3801765
train: epoch 101, iter 3900, loss: 2.855168, top_1: 0.590664, top_k: 0.810820, samples/s: 3001.465 1612035488.9092915
train: epoch 101, iter 4000, loss: 2.536492, top_1: 0.591289, top_k: 0.808906, samples/s: 2988.516 1612035497.4755368
train: epoch 101, iter 4100, loss: 2.848230, top_1: 0.595039, top_k: 0.813125, samples/s: 2998.721 1612035506.012521
train: epoch 101, iter 4200, loss: 2.670589, top_1: 0.593906, top_k: 0.807813, samples/s: 2994.535 1612035514.5613148
train: epoch 101, iter 4300, loss: 2.468692, top_1: 0.597500, top_k: 0.809961, samples/s: 2957.846 1612035523.2162411
train: epoch 101, iter 4400, loss: 2.754376, top_1: 0.593555, top_k: 0.809414, samples/s: 3002.411 1612035531.7427258
train: epoch 101, iter 4500, loss: 2.649684, top_1: 0.591562, top_k: 0.806836, samples/s: 2960.732 1612035540.3893452
train: epoch 101, iter 4600, loss: 2.550075, top_1: 0.594336, top_k: 0.811602, samples/s: 2980.318 1612035548.9789221
train: epoch 101, iter 4700, loss: 2.705101, top_1: 0.597344, top_k: 0.811133, samples/s: 2942.464 1612035557.6791503
train: epoch 101, iter 4800, loss: 2.762953, top_1: 0.589258, top_k: 0.807031, samples/s: 2976.331 1612035566.2803304
train: epoch 101, iter 4900, loss: 2.988414, top_1: 0.593711, top_k: 0.810781, samples/s: 2955.759 1612035574.941522
train: epoch 101, iter 5000, loss: 2.690174, top_1: 0.593867, top_k: 0.811680, samples/s: 2961.353 1612035583.586331
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_101.
validation: epoch 101, iter 195, top_1: 0.634796, top_k: 0.852384, samples/s: 2965.818 1612035600.6013045
train: epoch 102, iter 100, loss: 2.632869, top_1: 0.607383, top_k: 0.814648, samples/s: 2942.835 1612035625.0772429
train: epoch 102, iter 200, loss: 2.664480, top_1: 0.607539, top_k: 0.816914, samples/s: 2994.892 1612035633.6250527
train: epoch 102, iter 300, loss: 2.593846, top_1: 0.603945, top_k: 0.818398, samples/s: 2991.444 1612035642.182784
train: epoch 102, iter 400, loss: 2.647561, top_1: 0.600352, top_k: 0.818047, samples/s: 2998.201 1612035650.7212152
train: epoch 102, iter 500, loss: 2.785191, top_1: 0.597695, top_k: 0.813672, samples/s: 2972.733 1612035659.33293
train: epoch 102, iter 600, loss: 2.671720, top_1: 0.601289, top_k: 0.817383, samples/s: 2953.891 1612035667.9995143
train: epoch 102, iter 700, loss: 2.631096, top_1: 0.607422, top_k: 0.819180, samples/s: 3004.495 1612035676.5199049
train: epoch 102, iter 800, loss: 2.680510, top_1: 0.600547, top_k: 0.815781, samples/s: 2986.402 1612035685.092214
train: epoch 102, iter 900, loss: 2.399969, top_1: 0.600039, top_k: 0.816250, samples/s: 2975.744 1612035693.6950405
train: epoch 102, iter 1000, loss: 2.601645, top_1: 0.595508, top_k: 0.813789, samples/s: 3024.526 1612035702.1591125
train: epoch 102, iter 1100, loss: 2.635973, top_1: 0.598867, top_k: 0.811328, samples/s: 3003.259 1612035710.6832037
train: epoch 102, iter 1200, loss: 2.557663, top_1: 0.598125, top_k: 0.815391, samples/s: 2913.240 1612035719.4706736
train: epoch 102, iter 1300, loss: 2.652474, top_1: 0.603203, top_k: 0.811992, samples/s: 2910.968 1612035728.2649899
train: epoch 102, iter 1400, loss: 2.596870, top_1: 0.600547, top_k: 0.811719, samples/s: 2926.350 1612035737.0130823
train: epoch 102, iter 1500, loss: 2.864563, top_1: 0.591367, top_k: 0.808945, samples/s: 2978.804 1612035745.607117
train: epoch 102, iter 1600, loss: 2.520037, top_1: 0.598750, top_k: 0.810430, samples/s: 2988.907 1612035754.1721833
train: epoch 102, iter 1700, loss: 2.711516, top_1: 0.601797, top_k: 0.816094, samples/s: 2911.094 1612035762.966108
train: epoch 102, iter 1800, loss: 2.499315, top_1: 0.595469, top_k: 0.815781, samples/s: 2959.151 1612035771.617312
train: epoch 102, iter 1900, loss: 2.515935, top_1: 0.605625, top_k: 0.819766, samples/s: 2986.135 1612035780.1902173
train: epoch 102, iter 2000, loss: 2.585371, top_1: 0.595156, top_k: 0.812187, samples/s: 3016.864 1612035788.6758518
train: epoch 102, iter 2100, loss: 2.737411, top_1: 0.599375, top_k: 0.813711, samples/s: 2963.769 1612035797.3134573
train: epoch 102, iter 2200, loss: 2.790851, top_1: 0.595039, top_k: 0.813867, samples/s: 3026.605 1612035805.7717774
train: epoch 102, iter 2300, loss: 2.642841, top_1: 0.594805, top_k: 0.809102, samples/s: 2909.051 1612035814.5720315
train: epoch 102, iter 2400, loss: 2.634322, top_1: 0.598008, top_k: 0.815312, samples/s: 2974.735 1612035823.1777065
train: epoch 102, iter 2500, loss: 2.684617, top_1: 0.600352, top_k: 0.816914, samples/s: 2888.283 1612035832.0411549
train: epoch 102, iter 2600, loss: 2.694528, top_1: 0.590000, top_k: 0.806484, samples/s: 2934.039 1612035840.7662833
train: epoch 102, iter 2700, loss: 2.567594, top_1: 0.597656, top_k: 0.812539, samples/s: 2979.185 1612035849.3591921
train: epoch 102, iter 2800, loss: 2.599950, top_1: 0.595625, top_k: 0.808320, samples/s: 3014.949 1612035857.8503182
train: epoch 102, iter 2900, loss: 2.769131, top_1: 0.600430, top_k: 0.812070, samples/s: 2958.225 1612035866.5041542
train: epoch 102, iter 3000, loss: 2.606962, top_1: 0.585781, top_k: 0.805391, samples/s: 3011.109 1612035875.0059636
train: epoch 102, iter 3100, loss: 2.694822, top_1: 0.593477, top_k: 0.810195, samples/s: 2997.680 1612035883.545886
train: epoch 102, iter 3200, loss: 2.720420, top_1: 0.595117, top_k: 0.809336, samples/s: 2944.722 1612035892.2394526
train: epoch 102, iter 3300, loss: 2.836396, top_1: 0.597500, top_k: 0.815469, samples/s: 2978.945 1612035900.8331392
train: epoch 102, iter 3400, loss: 2.557663, top_1: 0.595430, top_k: 0.810156, samples/s: 2954.335 1612035909.4983218
train: epoch 102, iter 3500, loss: 2.739017, top_1: 0.596523, top_k: 0.813242, samples/s: 2978.789 1612035918.0924735
train: epoch 102, iter 3600, loss: 2.813363, top_1: 0.596758, top_k: 0.812695, samples/s: 2991.363 1612035926.650334
train: epoch 102, iter 3700, loss: 2.797598, top_1: 0.591797, top_k: 0.810156, samples/s: 2968.063 1612035935.2757282
train: epoch 102, iter 3800, loss: 2.662863, top_1: 0.593398, top_k: 0.811484, samples/s: 2940.703 1612035943.980939
train: epoch 102, iter 3900, loss: 2.555602, top_1: 0.594453, top_k: 0.809063, samples/s: 3000.066 1612035952.514037
train: epoch 102, iter 4000, loss: 2.682443, top_1: 0.588594, top_k: 0.807578, samples/s: 2946.942 1612035961.2010045
train: epoch 102, iter 4100, loss: 2.615668, top_1: 0.596953, top_k: 0.808867, samples/s: 3008.972 1612035969.7088625
train: epoch 102, iter 4200, loss: 2.784437, top_1: 0.597148, top_k: 0.808789, samples/s: 2953.564 1612035978.3764088
train: epoch 102, iter 4300, loss: 2.706933, top_1: 0.590508, top_k: 0.810391, samples/s: 2969.873 1612035986.9964297
train: epoch 102, iter 4400, loss: 2.461670, top_1: 0.596992, top_k: 0.807617, samples/s: 3000.940 1612035995.527011
train: epoch 102, iter 4500, loss: 2.608584, top_1: 0.597109, top_k: 0.810430, samples/s: 3008.325 1612036004.0366166
train: epoch 102, iter 4600, loss: 2.828897, top_1: 0.596641, top_k: 0.810312, samples/s: 2937.307 1612036012.752133
train: epoch 102, iter 4700, loss: 2.652913, top_1: 0.595391, top_k: 0.813008, samples/s: 2972.552 1612036021.3643782
train: epoch 102, iter 4800, loss: 2.597564, top_1: 0.592227, top_k: 0.807461, samples/s: 2990.881 1612036029.9236426
train: epoch 102, iter 4900, loss: 2.736786, top_1: 0.596211, top_k: 0.811953, samples/s: 3009.104 1612036038.4312015
train: epoch 102, iter 5000, loss: 2.803706, top_1: 0.598008, top_k: 0.813281, samples/s: 3012.505 1612036046.9290395
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_102.
validation: epoch 102, iter 195, top_1: 0.634195, top_k: 0.853105, samples/s: 2935.490 1612036064.2263694
train: epoch 103, iter 100, loss: 2.729857, top_1: 0.600000, top_k: 0.818633, samples/s: 2943.138 1612036088.8568318
train: epoch 103, iter 200, loss: 2.604614, top_1: 0.603516, top_k: 0.812734, samples/s: 3001.321 1612036097.3863018
train: epoch 103, iter 300, loss: 2.468393, top_1: 0.603711, top_k: 0.819219, samples/s: 2948.383 1612036106.068973
train: epoch 103, iter 400, loss: 2.570013, top_1: 0.612695, top_k: 0.823242, samples/s: 2984.555 1612036114.6465213
train: epoch 103, iter 500, loss: 2.632582, top_1: 0.606328, top_k: 0.817148, samples/s: 2958.763 1612036123.2987244
train: epoch 103, iter 600, loss: 2.586756, top_1: 0.602773, top_k: 0.812773, samples/s: 3013.807 1612036131.7930202
train: epoch 103, iter 700, loss: 2.878244, top_1: 0.600273, top_k: 0.813789, samples/s: 3013.100 1612036140.289263
train: epoch 103, iter 800, loss: 2.801287, top_1: 0.603594, top_k: 0.815430, samples/s: 2933.848 1612036149.0149868
train: epoch 103, iter 900, loss: 2.561293, top_1: 0.606367, top_k: 0.820312, samples/s: 3005.973 1612036157.5313685
train: epoch 103, iter 1000, loss: 2.502596, top_1: 0.601719, top_k: 0.816445, samples/s: 2984.026 1612036166.1103814
train: epoch 103, iter 1100, loss: 2.453315, top_1: 0.601953, top_k: 0.815859, samples/s: 3029.139 1612036174.5617115
train: epoch 103, iter 1200, loss: 2.683235, top_1: 0.602773, top_k: 0.811484, samples/s: 3020.576 1612036183.0368557
train: epoch 103, iter 1300, loss: 2.806854, top_1: 0.595742, top_k: 0.811602, samples/s: 2963.712 1612036191.6746917
train: epoch 103, iter 1400, loss: 2.654169, top_1: 0.605742, top_k: 0.817266, samples/s: 2953.217 1612036200.3432586
train: epoch 103, iter 1500, loss: 2.614911, top_1: 0.608281, top_k: 0.816367, samples/s: 3007.910 1612036208.854026
train: epoch 103, iter 1600, loss: 2.656186, top_1: 0.601641, top_k: 0.815586, samples/s: 2977.397 1612036217.4521782
train: epoch 103, iter 1700, loss: 2.751280, top_1: 0.603828, top_k: 0.817305, samples/s: 2967.664 1612036226.0784936
train: epoch 103, iter 1800, loss: 2.591534, top_1: 0.598125, top_k: 0.812617, samples/s: 3008.376 1612036234.5880713
train: epoch 103, iter 1900, loss: 2.658205, top_1: 0.601875, top_k: 0.816523, samples/s: 2915.440 1612036243.368923
train: epoch 103, iter 2000, loss: 2.517221, top_1: 0.599570, top_k: 0.815586, samples/s: 2914.841 1612036252.1516302
train: epoch 103, iter 2100, loss: 2.744876, top_1: 0.604531, top_k: 0.813477, samples/s: 3003.905 1612036260.6738043
train: epoch 103, iter 2200, loss: 2.606712, top_1: 0.602383, top_k: 0.816133, samples/s: 2964.993 1612036269.3079135
train: epoch 103, iter 2300, loss: 2.841372, top_1: 0.596914, top_k: 0.815156, samples/s: 2896.411 1612036278.1464267
train: epoch 103, iter 2400, loss: 2.707886, top_1: 0.601992, top_k: 0.814961, samples/s: 2960.054 1612036286.7949336
train: epoch 103, iter 2500, loss: 2.640278, top_1: 0.598633, top_k: 0.819258, samples/s: 2914.821 1612036295.5775638
train: epoch 103, iter 2600, loss: 2.780098, top_1: 0.597656, top_k: 0.811133, samples/s: 2959.424 1612036304.2279952
train: epoch 103, iter 2700, loss: 2.798969, top_1: 0.604688, top_k: 0.814141, samples/s: 2975.837 1612036312.8305418
train: epoch 103, iter 2800, loss: 2.637741, top_1: 0.604609, top_k: 0.817969, samples/s: 2951.313 1612036321.5046341
train: epoch 103, iter 2900, loss: 2.645603, top_1: 0.601602, top_k: 0.816953, samples/s: 2989.646 1612036330.0675263
train: epoch 103, iter 3000, loss: 2.776816, top_1: 0.596094, top_k: 0.815547, samples/s: 2985.400 1612036338.6426194
train: epoch 103, iter 3100, loss: 2.541705, top_1: 0.603555, top_k: 0.818008, samples/s: 2961.713 1612036347.2862442
train: epoch 103, iter 3200, loss: 2.617142, top_1: 0.602930, top_k: 0.816602, samples/s: 3016.124 1612036355.7739887
train: epoch 103, iter 3300, loss: 2.578142, top_1: 0.600547, top_k: 0.813828, samples/s: 2996.189 1612036364.3181424
train: epoch 103, iter 3400, loss: 2.623476, top_1: 0.606992, top_k: 0.818516, samples/s: 2939.690 1612036373.026544
train: epoch 103, iter 3500, loss: 2.585875, top_1: 0.594219, top_k: 0.817187, samples/s: 2990.883 1612036381.5859098
train: epoch 103, iter 3600, loss: 2.648673, top_1: 0.598047, top_k: 0.812773, samples/s: 2975.372 1612036390.1899378
train: epoch 103, iter 3700, loss: 2.667708, top_1: 0.596562, top_k: 0.808086, samples/s: 2904.627 1612036399.0033689
train: epoch 103, iter 3800, loss: 3.053245, top_1: 0.599063, top_k: 0.816055, samples/s: 2865.469 1612036407.937433
train: epoch 103, iter 3900, loss: 2.475932, top_1: 0.596094, top_k: 0.811562, samples/s: 2957.884 1612036416.5922222
train: epoch 103, iter 4000, loss: 2.547953, top_1: 0.591367, top_k: 0.806953, samples/s: 2952.243 1612036425.263545
train: epoch 103, iter 4100, loss: 2.577510, top_1: 0.595391, top_k: 0.807891, samples/s: 2955.401 1612036433.925742
train: epoch 103, iter 4200, loss: 2.697422, top_1: 0.601875, top_k: 0.817461, samples/s: 2996.290 1612036442.4695632
train: epoch 103, iter 4300, loss: 2.664258, top_1: 0.598984, top_k: 0.813867, samples/s: 2985.655 1612036451.0438964
train: epoch 103, iter 4400, loss: 2.597379, top_1: 0.595547, top_k: 0.814336, samples/s: 2986.277 1612036459.616432
train: epoch 103, iter 4500, loss: 2.551529, top_1: 0.601094, top_k: 0.816992, samples/s: 2966.136 1612036468.2472441
train: epoch 103, iter 4600, loss: 2.727546, top_1: 0.600156, top_k: 0.816641, samples/s: 3014.572 1612036476.73928
train: epoch 103, iter 4700, loss: 2.674972, top_1: 0.596992, top_k: 0.815195, samples/s: 2998.676 1612036485.276331
train: epoch 103, iter 4800, loss: 2.645653, top_1: 0.594648, top_k: 0.810234, samples/s: 2952.282 1612036493.9477022
train: epoch 103, iter 4900, loss: 2.628295, top_1: 0.599375, top_k: 0.809609, samples/s: 2960.378 1612036502.5951858
train: epoch 103, iter 5000, loss: 2.444880, top_1: 0.597344, top_k: 0.813008, samples/s: 2998.242 1612036511.1334522
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_103.
validation: epoch 103, iter 195, top_1: 0.637240, top_k: 0.855168, samples/s: 2950.742 1612036528.2775578
train: epoch 104, iter 100, loss: 2.620659, top_1: 0.614180, top_k: 0.825234, samples/s: 2903.352 1612036552.9159806
train: epoch 104, iter 200, loss: 2.628827, top_1: 0.607852, top_k: 0.820273, samples/s: 3031.644 1612036561.3604236
train: epoch 104, iter 300, loss: 2.711400, top_1: 0.609492, top_k: 0.822227, samples/s: 2995.628 1612036569.9060571
train: epoch 104, iter 400, loss: 2.576102, top_1: 0.606484, top_k: 0.821445, samples/s: 3007.013 1612036578.4194899
train: epoch 104, iter 500, loss: 2.669482, top_1: 0.609336, top_k: 0.819805, samples/s: 2986.210 1612036586.9923203
train: epoch 104, iter 600, loss: 2.565320, top_1: 0.599102, top_k: 0.814063, samples/s: 2965.194 1612036595.6257336
train: epoch 104, iter 700, loss: 2.620983, top_1: 0.606250, top_k: 0.820937, samples/s: 2980.266 1612036604.215539
train: epoch 104, iter 800, loss: 2.625063, top_1: 0.601953, top_k: 0.815859, samples/s: 2986.295 1612036612.7879622
train: epoch 104, iter 900, loss: 2.766501, top_1: 0.598555, top_k: 0.816094, samples/s: 3022.075 1612036621.2590826
train: epoch 104, iter 1000, loss: 2.498066, top_1: 0.598672, top_k: 0.818750, samples/s: 2978.130 1612036629.8551517
train: epoch 104, iter 1100, loss: 2.618443, top_1: 0.606094, top_k: 0.818359, samples/s: 2993.915 1612036638.4056695
train: epoch 104, iter 1200, loss: 2.693024, top_1: 0.604609, top_k: 0.819766, samples/s: 2975.795 1612036647.0084274
train: epoch 104, iter 1300, loss: 2.553331, top_1: 0.603164, top_k: 0.815508, samples/s: 2922.809 1612036655.767125
train: epoch 104, iter 1400, loss: 2.733690, top_1: 0.606680, top_k: 0.818750, samples/s: 2995.097 1612036664.3144877
train: epoch 104, iter 1500, loss: 2.424698, top_1: 0.604141, top_k: 0.817695, samples/s: 2984.093 1612036672.893337
train: epoch 104, iter 1600, loss: 2.508525, top_1: 0.603672, top_k: 0.816719, samples/s: 2975.604 1612036681.496557
train: epoch 104, iter 1700, loss: 2.574211, top_1: 0.605195, top_k: 0.823906, samples/s: 2938.926 1612036690.2073424
train: epoch 104, iter 1800, loss: 2.693848, top_1: 0.606836, top_k: 0.820273, samples/s: 2978.511 1612036698.8022516
train: epoch 104, iter 1900, loss: 2.698477, top_1: 0.603086, top_k: 0.817383, samples/s: 2914.375 1612036707.5862272
train: epoch 104, iter 2000, loss: 2.542949, top_1: 0.601914, top_k: 0.818281, samples/s: 3010.408 1612036716.0900178
train: epoch 104, iter 2100, loss: 2.567657, top_1: 0.602109, top_k: 0.816680, samples/s: 2999.768 1612036724.624032
train: epoch 104, iter 2200, loss: 2.662048, top_1: 0.605000, top_k: 0.821289, samples/s: 2968.198 1612036733.2488174
train: epoch 104, iter 2300, loss: 2.399649, top_1: 0.600195, top_k: 0.819063, samples/s: 2964.909 1612036741.883068
train: epoch 104, iter 2400, loss: 2.728797, top_1: 0.598633, top_k: 0.813281, samples/s: 2925.234 1612036750.6345127
train: epoch 104, iter 2500, loss: 2.604362, top_1: 0.601367, top_k: 0.812266, samples/s: 2961.296 1612036759.2793663
train: epoch 104, iter 2600, loss: 2.683530, top_1: 0.597734, top_k: 0.815898, samples/s: 2992.645 1612036767.8336732
train: epoch 104, iter 2700, loss: 2.797364, top_1: 0.598398, top_k: 0.813008, samples/s: 2991.448 1612036776.3914118
train: epoch 104, iter 2800, loss: 2.944462, top_1: 0.594688, top_k: 0.812031, samples/s: 2966.293 1612036785.0216765
train: epoch 104, iter 2900, loss: 2.696477, top_1: 0.601328, top_k: 0.812500, samples/s: 2921.159 1612036793.7853987
train: epoch 104, iter 3000, loss: 2.523484, top_1: 0.603984, top_k: 0.818984, samples/s: 2981.643 1612036802.371224
train: epoch 104, iter 3100, loss: 2.666336, top_1: 0.595039, top_k: 0.814297, samples/s: 2960.307 1612036811.0190752
train: epoch 104, iter 3200, loss: 2.517365, top_1: 0.604531, top_k: 0.819688, samples/s: 2993.612 1612036819.5705626
train: epoch 104, iter 3300, loss: 2.512097, top_1: 0.605664, top_k: 0.816602, samples/s: 2997.337 1612036828.111451
train: epoch 104, iter 3400, loss: 2.791185, top_1: 0.601719, top_k: 0.813945, samples/s: 3014.951 1612036836.602506
train: epoch 104, iter 3500, loss: 2.798674, top_1: 0.601641, top_k: 0.816172, samples/s: 2995.246 1612036845.1493492
train: epoch 104, iter 3600, loss: 2.699407, top_1: 0.602891, top_k: 0.816484, samples/s: 2928.933 1612036853.8899238
train: epoch 104, iter 3700, loss: 2.677942, top_1: 0.605820, top_k: 0.815898, samples/s: 2972.881 1612036862.5009546
train: epoch 104, iter 3800, loss: 2.774729, top_1: 0.601211, top_k: 0.814023, samples/s: 2953.294 1612036871.169245
train: epoch 104, iter 3900, loss: 2.632850, top_1: 0.602187, top_k: 0.813711, samples/s: 2961.648 1612036879.8129864
train: epoch 104, iter 4000, loss: 2.613646, top_1: 0.596133, top_k: 0.814961, samples/s: 3006.360 1612036888.328414
train: epoch 104, iter 4100, loss: 2.610930, top_1: 0.591680, top_k: 0.809922, samples/s: 2985.971 1612036896.9017136
train: epoch 104, iter 4200, loss: 2.928474, top_1: 0.600273, top_k: 0.813438, samples/s: 2951.687 1612036905.574771
train: epoch 104, iter 4300, loss: 2.498773, top_1: 0.601211, top_k: 0.815039, samples/s: 2955.778 1612036914.2357588
train: epoch 104, iter 4400, loss: 2.615467, top_1: 0.598086, top_k: 0.809727, samples/s: 3007.472 1612036922.7478487
train: epoch 104, iter 4500, loss: 2.632191, top_1: 0.602930, top_k: 0.816484, samples/s: 2940.626 1612036931.4535384
train: epoch 104, iter 4600, loss: 2.539988, top_1: 0.589922, top_k: 0.807695, samples/s: 2956.962 1612036940.1110382
train: epoch 104, iter 4700, loss: 2.518300, top_1: 0.595469, top_k: 0.811133, samples/s: 2911.349 1612036948.9042637
train: epoch 104, iter 4800, loss: 2.552386, top_1: 0.599219, top_k: 0.812656, samples/s: 2918.245 1612036957.6765978
train: epoch 104, iter 4900, loss: 2.802277, top_1: 0.605195, top_k: 0.814063, samples/s: 3033.386 1612036966.1160228
train: epoch 104, iter 5000, loss: 2.499404, top_1: 0.603437, top_k: 0.818008, samples/s: 2957.812 1612036974.7710752
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_104.
validation: epoch 104, iter 195, top_1: 0.645693, top_k: 0.860156, samples/s: 2937.098 1612036992.0094817
train: epoch 105, iter 100, loss: 2.671306, top_1: 0.608242, top_k: 0.820547, samples/s: 2949.585 1612037016.6641855
train: epoch 105, iter 200, loss: 2.741899, top_1: 0.611484, top_k: 0.825508, samples/s: 3012.925 1612037025.1608784
train: epoch 105, iter 300, loss: 2.727371, top_1: 0.604844, top_k: 0.819844, samples/s: 2971.515 1612037033.7759895
train: epoch 105, iter 400, loss: 2.537563, top_1: 0.610938, top_k: 0.823359, samples/s: 2950.869 1612037042.4514678
train: epoch 105, iter 500, loss: 2.563238, top_1: 0.612891, top_k: 0.824023, samples/s: 2991.080 1612037051.0102134
train: epoch 105, iter 600, loss: 2.472425, top_1: 0.613672, top_k: 0.823203, samples/s: 2970.388 1612037059.6288633
train: epoch 105, iter 700, loss: 2.559263, top_1: 0.606836, top_k: 0.819844, samples/s: 2982.037 1612037068.2133348
train: epoch 105, iter 800, loss: 2.634400, top_1: 0.600703, top_k: 0.813750, samples/s: 2990.621 1612037076.7734423
train: epoch 105, iter 900, loss: 2.602308, top_1: 0.611953, top_k: 0.820469, samples/s: 2976.956 1612037085.3729517
train: epoch 105, iter 1000, loss: 2.568398, top_1: 0.606406, top_k: 0.818984, samples/s: 3009.373 1612037093.8797805
train: epoch 105, iter 1100, loss: 2.637936, top_1: 0.602500, top_k: 0.817500, samples/s: 2989.241 1612037102.4437351
train: epoch 105, iter 1200, loss: 2.778472, top_1: 0.607266, top_k: 0.819922, samples/s: 3011.516 1612037110.94448
train: epoch 105, iter 1300, loss: 2.621447, top_1: 0.603789, top_k: 0.820937, samples/s: 2960.124 1612037119.5926282
train: epoch 105, iter 1400, loss: 2.835812, top_1: 0.608516, top_k: 0.820625, samples/s: 2980.926 1612037128.1805265
train: epoch 105, iter 1500, loss: 2.636809, top_1: 0.604922, top_k: 0.818164, samples/s: 2967.705 1612037136.8067942
train: epoch 105, iter 1600, loss: 2.693531, top_1: 0.604453, top_k: 0.818008, samples/s: 2874.989 1612037145.7111325
train: epoch 105, iter 1700, loss: 2.651492, top_1: 0.609688, top_k: 0.818516, samples/s: 2996.551 1612037154.2543585
train: epoch 105, iter 1800, loss: 2.504187, top_1: 0.601914, top_k: 0.816797, samples/s: 2940.125 1612037162.9614305
train: epoch 105, iter 1900, loss: 2.676934, top_1: 0.602266, top_k: 0.820117, samples/s: 2970.086 1612037171.580705
train: epoch 105, iter 2000, loss: 2.573032, top_1: 0.597930, top_k: 0.814922, samples/s: 3008.012 1612037180.0913198
train: epoch 105, iter 2100, loss: 2.622362, top_1: 0.601875, top_k: 0.815625, samples/s: 2989.970 1612037188.6532538
train: epoch 105, iter 2200, loss: 2.656106, top_1: 0.607734, top_k: 0.816680, samples/s: 2951.927 1612037197.325537
train: epoch 105, iter 2300, loss: 2.637457, top_1: 0.608555, top_k: 0.817813, samples/s: 3025.921 1612037205.7857914
train: epoch 105, iter 2400, loss: 2.718161, top_1: 0.603672, top_k: 0.817617, samples/s: 2948.637 1612037214.4677563
train: epoch 105, iter 2500, loss: 2.545244, top_1: 0.599023, top_k: 0.814414, samples/s: 2955.135 1612037223.1307223
train: epoch 105, iter 2600, loss: 2.748309, top_1: 0.601094, top_k: 0.818945, samples/s: 2997.321 1612037231.671567
train: epoch 105, iter 2700, loss: 2.608870, top_1: 0.602891, top_k: 0.816094, samples/s: 2878.057 1612037240.5664992
train: epoch 105, iter 2800, loss: 2.704558, top_1: 0.602695, top_k: 0.816367, samples/s: 2990.612 1612037249.1272092
train: epoch 105, iter 2900, loss: 2.535106, top_1: 0.604336, top_k: 0.822266, samples/s: 2986.580 1612037257.6983094
train: epoch 105, iter 3000, loss: 2.620463, top_1: 0.603437, top_k: 0.814766, samples/s: 2985.428 1612037266.2747061
train: epoch 105, iter 3100, loss: 2.696765, top_1: 0.601445, top_k: 0.816289, samples/s: 2895.775 1612037275.1137447
train: epoch 105, iter 3200, loss: 2.453650, top_1: 0.605742, top_k: 0.815000, samples/s: 2967.639 1612037283.7401574
train: epoch 105, iter 3300, loss: 2.803508, top_1: 0.600078, top_k: 0.814844, samples/s: 2912.870 1612037292.5287316
train: epoch 105, iter 3400, loss: 2.533661, top_1: 0.604727, top_k: 0.817461, samples/s: 2959.186 1612037301.1800685
train: epoch 105, iter 3500, loss: 2.563511, top_1: 0.606758, top_k: 0.815859, samples/s: 2959.110 1612037309.8310275
train: epoch 105, iter 3600, loss: 2.657696, top_1: 0.600703, top_k: 0.816484, samples/s: 2940.416 1612037318.5372195
train: epoch 105, iter 3700, loss: 2.695396, top_1: 0.603242, top_k: 0.809297, samples/s: 3022.190 1612037327.0079074
train: epoch 105, iter 3800, loss: 2.481603, top_1: 0.597422, top_k: 0.813984, samples/s: 2957.216 1612037335.664704
train: epoch 105, iter 3900, loss: 2.556860, top_1: 0.599375, top_k: 0.814727, samples/s: 2908.046 1612037344.4678905
train: epoch 105, iter 4000, loss: 2.534413, top_1: 0.602930, top_k: 0.814180, samples/s: 2988.428 1612037353.0342536
train: epoch 105, iter 4100, loss: 2.766151, top_1: 0.604805, top_k: 0.819063, samples/s: 2963.046 1612037361.674037
train: epoch 105, iter 4200, loss: 2.831592, top_1: 0.603555, top_k: 0.819648, samples/s: 3001.980 1612037370.2017627
train: epoch 105, iter 4300, loss: 2.515762, top_1: 0.597109, top_k: 0.814023, samples/s: 2966.408 1612037378.8317497
train: epoch 105, iter 4400, loss: 2.626086, top_1: 0.604688, top_k: 0.816953, samples/s: 2995.710 1612037387.3772368
train: epoch 105, iter 4500, loss: 2.639227, top_1: 0.602266, top_k: 0.816094, samples/s: 2987.345 1612037395.9467356
train: epoch 105, iter 4600, loss: 2.618208, top_1: 0.605859, top_k: 0.821758, samples/s: 2955.835 1612037404.6075137
train: epoch 105, iter 4700, loss: 2.752520, top_1: 0.600313, top_k: 0.816055, samples/s: 3005.502 1612037413.1253214
train: epoch 105, iter 4800, loss: 2.659361, top_1: 0.605078, top_k: 0.817305, samples/s: 3007.110 1612037421.638423
train: epoch 105, iter 4900, loss: 2.596277, top_1: 0.600234, top_k: 0.815937, samples/s: 2939.729 1612037430.3467288
train: epoch 105, iter 5000, loss: 2.555911, top_1: 0.605547, top_k: 0.824258, samples/s: 2933.485 1612037439.0735314
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_105.
validation: epoch 105, iter 195, top_1: 0.639323, top_k: 0.859175, samples/s: 3006.410 1612037455.935634
train: epoch 106, iter 100, loss: 2.683885, top_1: 0.614531, top_k: 0.826484, samples/s: 2914.878 1612037480.7210848
train: epoch 106, iter 200, loss: 2.532338, top_1: 0.611406, top_k: 0.818125, samples/s: 2997.890 1612037489.260435
train: epoch 106, iter 300, loss: 2.689932, top_1: 0.613242, top_k: 0.822344, samples/s: 2921.380 1612037498.0233512
train: epoch 106, iter 400, loss: 2.749312, top_1: 0.606953, top_k: 0.821836, samples/s: 3017.688 1612037506.506751
train: epoch 106, iter 500, loss: 2.538963, top_1: 0.611563, top_k: 0.820430, samples/s: 2954.788 1612037515.1706383
train: epoch 106, iter 600, loss: 2.695095, top_1: 0.606836, top_k: 0.823047, samples/s: 2984.595 1612037523.7480128
train: epoch 106, iter 700, loss: 2.505834, top_1: 0.608984, top_k: 0.822227, samples/s: 2994.816 1612037532.2960515
train: epoch 106, iter 800, loss: 2.836963, top_1: 0.602461, top_k: 0.819336, samples/s: 2950.964 1612037540.971246
train: epoch 106, iter 900, loss: 2.851650, top_1: 0.609453, top_k: 0.816406, samples/s: 3001.007 1612037549.5017054
train: epoch 106, iter 1000, loss: 2.539923, top_1: 0.609297, top_k: 0.821406, samples/s: 3023.504 1612037557.9689436
train: epoch 106, iter 1100, loss: 2.787917, top_1: 0.605859, top_k: 0.817734, samples/s: 2994.362 1612037566.5182679
train: epoch 106, iter 1200, loss: 2.602958, top_1: 0.605586, top_k: 0.818242, samples/s: 2929.651 1612037575.2565455
train: epoch 106, iter 1300, loss: 2.711170, top_1: 0.610781, top_k: 0.823164, samples/s: 2998.251 1612037583.794664
train: epoch 106, iter 1400, loss: 2.570793, top_1: 0.614531, top_k: 0.821641, samples/s: 2986.034 1612037592.3678896
train: epoch 106, iter 1500, loss: 2.592080, top_1: 0.610625, top_k: 0.824688, samples/s: 2958.153 1612037601.0220153
train: epoch 106, iter 1600, loss: 2.738017, top_1: 0.610430, top_k: 0.822617, samples/s: 2980.332 1612037609.6117117
train: epoch 106, iter 1700, loss: 2.465559, top_1: 0.600000, top_k: 0.817031, samples/s: 2971.595 1612037618.2265077
train: epoch 106, iter 1800, loss: 2.649754, top_1: 0.603320, top_k: 0.815469, samples/s: 2936.914 1612037626.9431345
train: epoch 106, iter 1900, loss: 2.492834, top_1: 0.604648, top_k: 0.819453, samples/s: 2967.584 1612037635.5697398
train: epoch 106, iter 2000, loss: 2.568812, top_1: 0.602461, top_k: 0.813672, samples/s: 2931.514 1612037644.3023646
train: epoch 106, iter 2100, loss: 2.842494, top_1: 0.606094, top_k: 0.817344, samples/s: 2980.176 1612037652.892466
train: epoch 106, iter 2200, loss: 2.501731, top_1: 0.607617, top_k: 0.819141, samples/s: 2968.564 1612037661.5162437
train: epoch 106, iter 2300, loss: 2.630644, top_1: 0.599453, top_k: 0.816289, samples/s: 3001.449 1612037670.0453763
train: epoch 106, iter 2400, loss: 2.577975, top_1: 0.601719, top_k: 0.817227, samples/s: 3002.303 1612037678.5722048
train: epoch 106, iter 2500, loss: 2.629133, top_1: 0.607969, top_k: 0.816523, samples/s: 2979.177 1612037687.1651473
train: epoch 106, iter 2600, loss: 2.361193, top_1: 0.606641, top_k: 0.819883, samples/s: 2987.760 1612037695.7334394
train: epoch 106, iter 2700, loss: 2.633879, top_1: 0.600742, top_k: 0.814688, samples/s: 2979.388 1612037704.325877
train: epoch 106, iter 2800, loss: 2.721687, top_1: 0.605977, top_k: 0.820703, samples/s: 2952.829 1612037712.9954443
train: epoch 106, iter 2900, loss: 2.603626, top_1: 0.605938, top_k: 0.817539, samples/s: 2986.539 1612037721.5672536
train: epoch 106, iter 3000, loss: 2.740770, top_1: 0.604531, top_k: 0.819180, samples/s: 2963.142 1612037730.2067242
train: epoch 106, iter 3100, loss: 2.635646, top_1: 0.606758, top_k: 0.815703, samples/s: 2925.823 1612037738.9564047
train: epoch 106, iter 3200, loss: 2.610063, top_1: 0.604844, top_k: 0.818945, samples/s: 3016.156 1612037747.4440186
train: epoch 106, iter 3300, loss: 2.783982, top_1: 0.601914, top_k: 0.813984, samples/s: 2981.049 1612037756.0316458
train: epoch 106, iter 3400, loss: 2.414045, top_1: 0.607852, top_k: 0.818789, samples/s: 2943.545 1612037764.7286253
train: epoch 106, iter 3500, loss: 2.808481, top_1: 0.608086, top_k: 0.819141, samples/s: 3006.337 1612037773.2440002
train: epoch 106, iter 3600, loss: 2.748306, top_1: 0.603203, top_k: 0.817305, samples/s: 2982.150 1612037781.8283525
train: epoch 106, iter 3700, loss: 2.581992, top_1: 0.602305, top_k: 0.816172, samples/s: 2976.859 1612037790.428176
train: epoch 106, iter 3800, loss: 2.573915, top_1: 0.604805, top_k: 0.817891, samples/s: 3004.228 1612037798.9493773
train: epoch 106, iter 3900, loss: 2.678639, top_1: 0.602656, top_k: 0.821680, samples/s: 2984.512 1612037807.5270207
train: epoch 106, iter 4000, loss: 2.693592, top_1: 0.602773, top_k: 0.818789, samples/s: 2954.592 1612037816.1915324
train: epoch 106, iter 4100, loss: 2.734218, top_1: 0.608437, top_k: 0.820703, samples/s: 2988.949 1612037824.7563655
train: epoch 106, iter 4200, loss: 2.613657, top_1: 0.601992, top_k: 0.815078, samples/s: 2971.325 1612037833.3721209
train: epoch 106, iter 4300, loss: 2.739642, top_1: 0.603008, top_k: 0.819531, samples/s: 2969.105 1612037841.9941373
train: epoch 106, iter 4400, loss: 2.621855, top_1: 0.605000, top_k: 0.821367, samples/s: 2897.339 1612037850.829832
train: epoch 106, iter 4500, loss: 2.550632, top_1: 0.604023, top_k: 0.819570, samples/s: 2933.349 1612037859.5570729
train: epoch 106, iter 4600, loss: 2.681516, top_1: 0.604531, top_k: 0.819336, samples/s: 2996.683 1612037868.099851
train: epoch 106, iter 4700, loss: 2.667608, top_1: 0.605625, top_k: 0.816250, samples/s: 3006.531 1612037876.6146386
train: epoch 106, iter 4800, loss: 2.831532, top_1: 0.601562, top_k: 0.816367, samples/s: 3000.359 1612037885.1469376
train: epoch 106, iter 4900, loss: 2.639183, top_1: 0.607187, top_k: 0.817070, samples/s: 2990.023 1612037893.7087479
train: epoch 106, iter 5000, loss: 2.693074, top_1: 0.601406, top_k: 0.817539, samples/s: 2961.561 1612037902.3528378
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_106.
validation: epoch 106, iter 195, top_1: 0.641006, top_k: 0.856991, samples/s: 2909.330 1612037919.813402
train: epoch 107, iter 100, loss: 2.722622, top_1: 0.614883, top_k: 0.823828, samples/s: 2940.292 1612037944.9949243
train: epoch 107, iter 200, loss: 2.492184, top_1: 0.611797, top_k: 0.823711, samples/s: 2988.690 1612037953.5605004
train: epoch 107, iter 300, loss: 2.642154, top_1: 0.614180, top_k: 0.825937, samples/s: 2968.146 1612037962.1854417
train: epoch 107, iter 400, loss: 2.665730, top_1: 0.614102, top_k: 0.822734, samples/s: 2992.339 1612037970.7405612
train: epoch 107, iter 500, loss: 2.686932, top_1: 0.613242, top_k: 0.823086, samples/s: 2996.427 1612037979.2841609
train: epoch 107, iter 600, loss: 2.896375, top_1: 0.609453, top_k: 0.821758, samples/s: 2986.067 1612037987.857174
train: epoch 107, iter 700, loss: 2.403241, top_1: 0.604961, top_k: 0.817031, samples/s: 2873.453 1612037996.7664094
train: epoch 107, iter 800, loss: 2.427190, top_1: 0.615273, top_k: 0.824180, samples/s: 2974.761 1612038005.3720994
train: epoch 107, iter 900, loss: 2.625422, top_1: 0.609453, top_k: 0.819570, samples/s: 3023.306 1612038013.8396263
train: epoch 107, iter 1000, loss: 2.740252, top_1: 0.613750, top_k: 0.825820, samples/s: 3011.049 1612038022.3417032
train: epoch 107, iter 1100, loss: 2.653765, top_1: 0.612383, top_k: 0.824297, samples/s: 2922.469 1612038031.1014314
train: epoch 107, iter 1200, loss: 2.674901, top_1: 0.614453, top_k: 0.822148, samples/s: 3005.653 1612038039.618798
train: epoch 107, iter 1300, loss: 2.507337, top_1: 0.614336, top_k: 0.822187, samples/s: 2991.122 1612038048.177319
train: epoch 107, iter 1400, loss: 2.625579, top_1: 0.611602, top_k: 0.820273, samples/s: 2936.960 1612038056.8938613
train: epoch 107, iter 1500, loss: 2.547101, top_1: 0.607266, top_k: 0.819297, samples/s: 2953.787 1612038065.560719
train: epoch 107, iter 1600, loss: 2.599041, top_1: 0.606641, top_k: 0.817578, samples/s: 2903.816 1612038074.3766987
train: epoch 107, iter 1700, loss: 2.509046, top_1: 0.611211, top_k: 0.820664, samples/s: 2979.206 1612038082.969531
train: epoch 107, iter 1800, loss: 2.741460, top_1: 0.608828, top_k: 0.822227, samples/s: 2945.716 1612038091.6602254
train: epoch 107, iter 1900, loss: 2.648213, top_1: 0.610898, top_k: 0.824258, samples/s: 2921.114 1612038100.4238832
train: epoch 107, iter 2000, loss: 2.680215, top_1: 0.609922, top_k: 0.820469, samples/s: 2956.862 1612038109.0817466
train: epoch 107, iter 2100, loss: 2.809203, top_1: 0.611953, top_k: 0.820898, samples/s: 2950.279 1612038117.758866
train: epoch 107, iter 2200, loss: 2.586692, top_1: 0.604492, top_k: 0.816914, samples/s: 2981.025 1612038126.3464644
train: epoch 107, iter 2300, loss: 2.773591, top_1: 0.608047, top_k: 0.819063, samples/s: 3019.806 1612038134.8239574
train: epoch 107, iter 2400, loss: 2.649139, top_1: 0.606445, top_k: 0.820625, samples/s: 2908.326 1612038143.6262739
train: epoch 107, iter 2500, loss: 2.753420, top_1: 0.604531, top_k: 0.820391, samples/s: 2985.147 1612038152.2019901
train: epoch 107, iter 2600, loss: 2.455263, top_1: 0.609492, top_k: 0.820039, samples/s: 2926.461 1612038160.9498768
train: epoch 107, iter 2700, loss: 2.550305, top_1: 0.604414, top_k: 0.822187, samples/s: 2996.494 1612038169.4930816
train: epoch 107, iter 2800, loss: 2.633018, top_1: 0.605000, top_k: 0.816211, samples/s: 2980.680 1612038178.0817063
train: epoch 107, iter 2900, loss: 2.498661, top_1: 0.605820, top_k: 0.820586, samples/s: 2974.826 1612038186.6874013
train: epoch 107, iter 3000, loss: 2.612333, top_1: 0.610938, top_k: 0.821641, samples/s: 2952.508 1612038195.3578584
train: epoch 107, iter 3100, loss: 2.493504, top_1: 0.613125, top_k: 0.820625, samples/s: 2955.134 1612038204.0207527
train: epoch 107, iter 3200, loss: 2.600601, top_1: 0.610586, top_k: 0.820703, samples/s: 2952.432 1612038212.6916103
train: epoch 107, iter 3300, loss: 2.752500, top_1: 0.602031, top_k: 0.816445, samples/s: 2952.119 1612038221.3632991
train: epoch 107, iter 3400, loss: 2.470955, top_1: 0.608164, top_k: 0.821289, samples/s: 2992.708 1612038229.9175594
train: epoch 107, iter 3500, loss: 2.607613, top_1: 0.606445, top_k: 0.818438, samples/s: 3006.265 1612038238.432984
train: epoch 107, iter 3600, loss: 2.612141, top_1: 0.602969, top_k: 0.814375, samples/s: 2985.401 1612038247.0080714
train: epoch 107, iter 3700, loss: 2.740018, top_1: 0.602031, top_k: 0.814570, samples/s: 2969.215 1612038255.6298535
train: epoch 107, iter 3800, loss: 2.615560, top_1: 0.602266, top_k: 0.815000, samples/s: 2979.222 1612038264.222825
train: epoch 107, iter 3900, loss: 2.615597, top_1: 0.601680, top_k: 0.819766, samples/s: 3022.039 1612038272.693772
train: epoch 107, iter 4000, loss: 2.518235, top_1: 0.609727, top_k: 0.822891, samples/s: 2982.988 1612038281.2758408
train: epoch 107, iter 4100, loss: 2.629972, top_1: 0.611523, top_k: 0.821406, samples/s: 2975.217 1612038289.8802452
train: epoch 107, iter 4200, loss: 2.660676, top_1: 0.603945, top_k: 0.819180, samples/s: 2969.826 1612038298.5003755
train: epoch 107, iter 4300, loss: 2.737580, top_1: 0.604414, top_k: 0.815156, samples/s: 2996.542 1612038307.043424
train: epoch 107, iter 4400, loss: 2.526795, top_1: 0.605859, top_k: 0.820195, samples/s: 2942.154 1612038315.744538
train: epoch 107, iter 4500, loss: 2.630914, top_1: 0.608086, top_k: 0.818086, samples/s: 2967.505 1612038324.3713663
train: epoch 107, iter 4600, loss: 2.740367, top_1: 0.604766, top_k: 0.819102, samples/s: 2942.698 1612038333.0708046
train: epoch 107, iter 4700, loss: 2.723927, top_1: 0.602383, top_k: 0.819414, samples/s: 2970.377 1612038341.689271
train: epoch 107, iter 4800, loss: 2.611094, top_1: 0.607344, top_k: 0.818281, samples/s: 2963.258 1612038350.3283808
train: epoch 107, iter 4900, loss: 2.536490, top_1: 0.608242, top_k: 0.819258, samples/s: 2977.416 1612038358.9264505
train: epoch 107, iter 5000, loss: 2.578680, top_1: 0.616875, top_k: 0.823828, samples/s: 2946.393 1612038367.615034
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_107.
validation: epoch 107, iter 195, top_1: 0.650541, top_k: 0.861859, samples/s: 2994.119 1612038384.4408822
train: epoch 108, iter 100, loss: 2.406250, top_1: 0.614531, top_k: 0.825820, samples/s: 2953.036 1612038409.5254223
train: epoch 108, iter 200, loss: 2.675817, top_1: 0.613203, top_k: 0.826406, samples/s: 2920.216 1612038418.2918258
train: epoch 108, iter 300, loss: 2.647759, top_1: 0.616133, top_k: 0.826250, samples/s: 2980.900 1612038426.8798041
train: epoch 108, iter 400, loss: 2.594342, top_1: 0.615508, top_k: 0.825313, samples/s: 2985.565 1612038435.4543595
train: epoch 108, iter 500, loss: 2.731285, top_1: 0.609961, top_k: 0.822578, samples/s: 2943.674 1612038444.1510181
train: epoch 108, iter 600, loss: 2.729184, top_1: 0.608437, top_k: 0.819688, samples/s: 3000.578 1612038452.6826675
train: epoch 108, iter 700, loss: 2.725630, top_1: 0.608828, top_k: 0.820234, samples/s: 3009.337 1612038461.1895924
train: epoch 108, iter 800, loss: 2.493134, top_1: 0.611875, top_k: 0.822344, samples/s: 2988.982 1612038469.7545083
train: epoch 108, iter 900, loss: 2.705350, top_1: 0.616484, top_k: 0.824883, samples/s: 2962.302 1612038478.3962412
train: epoch 108, iter 1000, loss: 2.588677, top_1: 0.616172, top_k: 0.826562, samples/s: 2970.826 1612038487.013489
train: epoch 108, iter 1100, loss: 2.714744, top_1: 0.614492, top_k: 0.823633, samples/s: 2970.191 1612038495.6324131
train: epoch 108, iter 1200, loss: 2.698464, top_1: 0.610938, top_k: 0.820859, samples/s: 2990.202 1612038504.193645
train: epoch 108, iter 1300, loss: 2.727977, top_1: 0.612734, top_k: 0.825117, samples/s: 2858.934 1612038513.1481848
train: epoch 108, iter 1400, loss: 2.613478, top_1: 0.612422, top_k: 0.822852, samples/s: 2994.751 1612038521.6963172
train: epoch 108, iter 1500, loss: 2.465161, top_1: 0.610078, top_k: 0.822148, samples/s: 2956.298 1612038530.3558667
train: epoch 108, iter 1600, loss: 2.537587, top_1: 0.612266, top_k: 0.822266, samples/s: 2977.202 1612038538.954471
train: epoch 108, iter 1700, loss: 2.713059, top_1: 0.610078, top_k: 0.821758, samples/s: 2948.249 1612038547.6375918
train: epoch 108, iter 1800, loss: 2.839642, top_1: 0.610000, top_k: 0.820234, samples/s: 3004.642 1612038556.1578445
train: epoch 108, iter 1900, loss: 2.621046, top_1: 0.614492, top_k: 0.822383, samples/s: 2977.140 1612038564.7566607
train: epoch 108, iter 2000, loss: 2.653524, top_1: 0.605898, top_k: 0.816445, samples/s: 2945.347 1612038573.4483085
train: epoch 108, iter 2100, loss: 2.796758, top_1: 0.613359, top_k: 0.824063, samples/s: 2945.689 1612038582.1390493
train: epoch 108, iter 2200, loss: 2.478014, top_1: 0.610000, top_k: 0.823047, samples/s: 2988.961 1612038590.7037883
train: epoch 108, iter 2300, loss: 2.569662, top_1: 0.608984, top_k: 0.821328, samples/s: 2960.040 1612038599.3523393
train: epoch 108, iter 2400, loss: 2.596470, top_1: 0.610313, top_k: 0.822695, samples/s: 2979.282 1612038607.9450111
train: epoch 108, iter 2500, loss: 2.562085, top_1: 0.615039, top_k: 0.825820, samples/s: 2998.611 1612038616.482318
train: epoch 108, iter 2600, loss: 2.682470, top_1: 0.613945, top_k: 0.824492, samples/s: 2975.421 1612038625.0860736
train: epoch 108, iter 2700, loss: 2.492996, top_1: 0.608086, top_k: 0.822227, samples/s: 2951.918 1612038633.758453
train: epoch 108, iter 2800, loss: 2.688706, top_1: 0.604375, top_k: 0.818906, samples/s: 2953.325 1612038642.4266293
train: epoch 108, iter 2900, loss: 2.676768, top_1: 0.613984, top_k: 0.823086, samples/s: 3033.171 1612038650.8666437
train: epoch 108, iter 3000, loss: 2.769582, top_1: 0.610625, top_k: 0.820195, samples/s: 2962.701 1612038659.5075126
train: epoch 108, iter 3100, loss: 2.597353, top_1: 0.612852, top_k: 0.822578, samples/s: 2978.017 1612038668.103741
train: epoch 108, iter 3200, loss: 2.773067, top_1: 0.610156, top_k: 0.822891, samples/s: 3001.750 1612038676.6320374
train: epoch 108, iter 3300, loss: 2.535420, top_1: 0.612656, top_k: 0.822305, samples/s: 2925.146 1612038685.3838656
train: epoch 108, iter 3400, loss: 2.692276, top_1: 0.614453, top_k: 0.823398, samples/s: 3009.404 1612038693.8904905
train: epoch 108, iter 3500, loss: 2.794339, top_1: 0.606914, top_k: 0.819922, samples/s: 2932.124 1612038702.6213396
train: epoch 108, iter 3600, loss: 2.543551, top_1: 0.607930, top_k: 0.819453, samples/s: 2922.644 1612038711.3805985
train: epoch 108, iter 3700, loss: 2.683863, top_1: 0.607266, top_k: 0.821055, samples/s: 2997.904 1612038719.9198167
train: epoch 108, iter 3800, loss: 2.705480, top_1: 0.607187, top_k: 0.820547, samples/s: 2997.282 1612038728.4608948
train: epoch 108, iter 3900, loss: 2.640751, top_1: 0.611367, top_k: 0.820937, samples/s: 2953.898 1612038737.127433
train: epoch 108, iter 4000, loss: 2.576469, top_1: 0.609141, top_k: 0.821602, samples/s: 2936.731 1612038745.8446498
train: epoch 108, iter 4100, loss: 2.700219, top_1: 0.610039, top_k: 0.822656, samples/s: 2989.577 1612038754.407667
train: epoch 108, iter 4200, loss: 2.583379, top_1: 0.609531, top_k: 0.823086, samples/s: 3000.190 1612038762.940458
train: epoch 108, iter 4300, loss: 2.594604, top_1: 0.610195, top_k: 0.820469, samples/s: 2994.746 1612038771.4887867
train: epoch 108, iter 4400, loss: 2.572019, top_1: 0.610625, top_k: 0.822227, samples/s: 2979.374 1612038780.0813074
train: epoch 108, iter 4500, loss: 2.538827, top_1: 0.613867, top_k: 0.821328, samples/s: 2992.026 1612038788.6372344
train: epoch 108, iter 4600, loss: 2.734031, top_1: 0.607109, top_k: 0.819922, samples/s: 2955.023 1612038797.3004787
train: epoch 108, iter 4700, loss: 2.611837, top_1: 0.609570, top_k: 0.824180, samples/s: 2965.143 1612038805.9341109
train: epoch 108, iter 4800, loss: 2.521218, top_1: 0.608984, top_k: 0.818047, samples/s: 2974.123 1612038814.5417163
train: epoch 108, iter 4900, loss: 2.605757, top_1: 0.608047, top_k: 0.822422, samples/s: 2971.271 1612038823.157543
train: epoch 108, iter 5000, loss: 2.493905, top_1: 0.611406, top_k: 0.821992, samples/s: 2924.994 1612038831.9097836
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_108.
validation: epoch 108, iter 195, top_1: 0.650100, top_k: 0.863542, samples/s: 2936.302 1612038849.1338089
train: epoch 109, iter 100, loss: 2.666398, top_1: 0.622812, top_k: 0.828984, samples/s: 2964.452 1612038879.195738
train: epoch 109, iter 200, loss: 2.625560, top_1: 0.614844, top_k: 0.826797, samples/s: 2925.703 1612038887.9457726
train: epoch 109, iter 300, loss: 2.545893, top_1: 0.616055, top_k: 0.825117, samples/s: 3004.777 1612038896.4655645
train: epoch 109, iter 400, loss: 2.557962, top_1: 0.619023, top_k: 0.828008, samples/s: 2971.934 1612038905.07953
train: epoch 109, iter 500, loss: 2.305053, top_1: 0.618125, top_k: 0.825820, samples/s: 3001.993 1612038913.6072683
train: epoch 109, iter 600, loss: 2.471407, top_1: 0.616250, top_k: 0.830156, samples/s: 2989.575 1612038922.170355
train: epoch 109, iter 700, loss: 2.716809, top_1: 0.617578, top_k: 0.825430, samples/s: 3020.911 1612038930.6444893
train: epoch 109, iter 800, loss: 2.436349, top_1: 0.616055, top_k: 0.828750, samples/s: 2962.901 1612038939.2846868
train: epoch 109, iter 900, loss: 2.648229, top_1: 0.617812, top_k: 0.823945, samples/s: 2995.550 1612038947.8307302
train: epoch 109, iter 1000, loss: 2.658188, top_1: 0.608437, top_k: 0.822187, samples/s: 2954.764 1612038956.494716
train: epoch 109, iter 1100, loss: 2.575031, top_1: 0.616055, top_k: 0.825937, samples/s: 2958.297 1612038965.1483164
train: epoch 109, iter 1200, loss: 2.709661, top_1: 0.616250, top_k: 0.827187, samples/s: 2907.765 1612038973.9523745
train: epoch 109, iter 1300, loss: 2.474468, top_1: 0.617539, top_k: 0.824141, samples/s: 2985.601 1612038982.5269032
train: epoch 109, iter 1400, loss: 2.571551, top_1: 0.612148, top_k: 0.825234, samples/s: 2963.085 1612038991.1666126
train: epoch 109, iter 1500, loss: 2.448158, top_1: 0.610625, top_k: 0.825508, samples/s: 2912.087 1612038999.9573784
train: epoch 109, iter 1600, loss: 2.559329, top_1: 0.611328, top_k: 0.821992, samples/s: 2986.211 1612039008.5301077
train: epoch 109, iter 1700, loss: 2.723520, top_1: 0.610430, top_k: 0.825781, samples/s: 2996.589 1612039017.0731487
train: epoch 109, iter 1800, loss: 2.702392, top_1: 0.613203, top_k: 0.827305, samples/s: 3003.094 1612039025.5977027
train: epoch 109, iter 1900, loss: 2.497406, top_1: 0.618555, top_k: 0.825117, samples/s: 2986.435 1612039034.1698086
train: epoch 109, iter 2000, loss: 2.539030, top_1: 0.613789, top_k: 0.822930, samples/s: 2970.113 1612039042.7889915
train: epoch 109, iter 2100, loss: 2.543114, top_1: 0.615195, top_k: 0.824727, samples/s: 2942.091 1612039051.4903104
train: epoch 109, iter 2200, loss: 2.730325, top_1: 0.609531, top_k: 0.820742, samples/s: 2978.011 1612039060.0866303
train: epoch 109, iter 2300, loss: 2.546916, top_1: 0.612422, top_k: 0.819063, samples/s: 2982.351 1612039068.6706073
train: epoch 109, iter 2400, loss: 2.663482, top_1: 0.613320, top_k: 0.826172, samples/s: 2987.835 1612039077.2385492
train: epoch 109, iter 2500, loss: 2.735868, top_1: 0.610234, top_k: 0.824805, samples/s: 2936.399 1612039085.9566956
train: epoch 109, iter 2600, loss: 2.697856, top_1: 0.612227, top_k: 0.821289, samples/s: 3013.328 1612039094.4524024
train: epoch 109, iter 2700, loss: 2.663596, top_1: 0.612031, top_k: 0.823867, samples/s: 2995.089 1612039102.9998512
train: epoch 109, iter 2800, loss: 2.792953, top_1: 0.614727, top_k: 0.819922, samples/s: 2989.684 1612039111.5623968
train: epoch 109, iter 2900, loss: 2.747835, top_1: 0.615781, top_k: 0.824844, samples/s: 2965.830 1612039120.1941178
train: epoch 109, iter 3000, loss: 2.503665, top_1: 0.612461, top_k: 0.825469, samples/s: 2986.180 1612039128.7668552
train: epoch 109, iter 3100, loss: 2.571926, top_1: 0.608672, top_k: 0.820039, samples/s: 2993.501 1612039137.318734
train: epoch 109, iter 3200, loss: 2.755515, top_1: 0.610313, top_k: 0.823047, samples/s: 2952.044 1612039145.9910367
train: epoch 109, iter 3300, loss: 2.576786, top_1: 0.616289, top_k: 0.824961, samples/s: 2996.900 1612039154.532842
train: epoch 109, iter 3400, loss: 2.791027, top_1: 0.608164, top_k: 0.817031, samples/s: 3006.359 1612039163.0481255
train: epoch 109, iter 3500, loss: 2.667837, top_1: 0.607734, top_k: 0.819648, samples/s: 2997.086 1612039171.590444
train: epoch 109, iter 3600, loss: 2.366158, top_1: 0.615625, top_k: 0.824180, samples/s: 2939.464 1612039180.2988272
train: epoch 109, iter 3700, loss: 2.732141, top_1: 0.611406, top_k: 0.820586, samples/s: 2922.601 1612039189.0581486
train: epoch 109, iter 3800, loss: 2.730676, top_1: 0.613477, top_k: 0.820742, samples/s: 2972.958 1612039197.669136
train: epoch 109, iter 3900, loss: 2.701809, top_1: 0.606016, top_k: 0.819531, samples/s: 2974.308 1612039206.276267
train: epoch 109, iter 4000, loss: 2.696780, top_1: 0.611797, top_k: 0.821875, samples/s: 2919.584 1612039215.0445654
train: epoch 109, iter 4100, loss: 2.352569, top_1: 0.612617, top_k: 0.825391, samples/s: 2932.278 1612039223.7749243
train: epoch 109, iter 4200, loss: 2.684046, top_1: 0.608320, top_k: 0.824375, samples/s: 2978.686 1612039232.3693202
train: epoch 109, iter 4300, loss: 2.686631, top_1: 0.604375, top_k: 0.819141, samples/s: 2980.227 1612039240.9593954
train: epoch 109, iter 4400, loss: 2.755562, top_1: 0.612383, top_k: 0.821836, samples/s: 2993.616 1612039249.5108604
train: epoch 109, iter 4500, loss: 2.681526, top_1: 0.609297, top_k: 0.818945, samples/s: 2964.702 1612039258.1457741
train: epoch 109, iter 4600, loss: 2.480690, top_1: 0.606484, top_k: 0.821562, samples/s: 2976.385 1612039266.7467208
train: epoch 109, iter 4700, loss: 2.686440, top_1: 0.610117, top_k: 0.822461, samples/s: 3008.092 1612039275.2571702
train: epoch 109, iter 4800, loss: 2.388078, top_1: 0.608711, top_k: 0.820469, samples/s: 2966.362 1612039283.8872745
train: epoch 109, iter 4900, loss: 2.584025, top_1: 0.614883, top_k: 0.824063, samples/s: 2974.176 1612039292.4948065
train: epoch 109, iter 5000, loss: 2.633313, top_1: 0.613516, top_k: 0.826445, samples/s: 2948.350 1612039301.177535
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_109.
validation: epoch 109, iter 195, top_1: 0.648618, top_k: 0.861999, samples/s: 2953.363 1612039318.3503296
train: epoch 110, iter 100, loss: 2.596205, top_1: 0.617891, top_k: 0.825078, samples/s: 2930.553 1612039342.929418
train: epoch 110, iter 200, loss: 2.483829, top_1: 0.622852, top_k: 0.832695, samples/s: 2954.440 1612039351.5943537
train: epoch 110, iter 300, loss: 2.638032, top_1: 0.623867, top_k: 0.829805, samples/s: 2943.171 1612039360.292474
train: epoch 110, iter 400, loss: 2.631906, top_1: 0.622383, top_k: 0.828750, samples/s: 3012.591 1612039368.7900991
train: epoch 110, iter 500, loss: 2.614278, top_1: 0.617695, top_k: 0.827891, samples/s: 2982.973 1612039377.3721461
train: epoch 110, iter 600, loss: 2.669770, top_1: 0.613477, top_k: 0.825156, samples/s: 3030.831 1612039385.8187206
train: epoch 110, iter 700, loss: 2.479747, top_1: 0.626719, top_k: 0.833203, samples/s: 2983.455 1612039394.3993125
train: epoch 110, iter 800, loss: 2.589476, top_1: 0.621992, top_k: 0.829766, samples/s: 2982.860 1612039402.9816482
train: epoch 110, iter 900, loss: 2.602076, top_1: 0.619336, top_k: 0.829336, samples/s: 2964.814 1612039411.6162536
train: epoch 110, iter 1000, loss: 2.615614, top_1: 0.618633, top_k: 0.826797, samples/s: 3006.826 1612039420.1302166
train: epoch 110, iter 1100, loss: 2.709390, top_1: 0.620625, top_k: 0.827930, samples/s: 3007.322 1612039428.6427798
train: epoch 110, iter 1200, loss: 2.572281, top_1: 0.622656, top_k: 0.830820, samples/s: 2990.719 1612039437.2026548
train: epoch 110, iter 1300, loss: 2.651278, top_1: 0.614648, top_k: 0.823711, samples/s: 2965.014 1612039445.836615
train: epoch 110, iter 1400, loss: 2.566113, top_1: 0.612695, top_k: 0.824141, samples/s: 2860.065 1612039454.787449
train: epoch 110, iter 1500, loss: 2.676758, top_1: 0.614688, top_k: 0.825352, samples/s: 3019.681 1612039463.2652638
train: epoch 110, iter 1600, loss: 2.527124, top_1: 0.613281, top_k: 0.823867, samples/s: 2972.806 1612039471.8766925
train: epoch 110, iter 1700, loss: 2.504770, top_1: 0.611992, top_k: 0.825898, samples/s: 2914.714 1612039480.6595986
train: epoch 110, iter 1800, loss: 2.487499, top_1: 0.613984, top_k: 0.822656, samples/s: 2961.356 1612039489.3042283
train: epoch 110, iter 1900, loss: 2.629349, top_1: 0.611875, top_k: 0.825078, samples/s: 2941.864 1612039498.0065901
train: epoch 110, iter 2000, loss: 2.792813, top_1: 0.616484, top_k: 0.828438, samples/s: 3002.932 1612039506.5312834
train: epoch 110, iter 2100, loss: 2.665602, top_1: 0.616289, top_k: 0.823281, samples/s: 2983.334 1612039515.112258
train: epoch 110, iter 2200, loss: 2.543110, top_1: 0.609922, top_k: 0.825039, samples/s: 2962.866 1612039523.752532
train: epoch 110, iter 2300, loss: 2.652553, top_1: 0.616680, top_k: 0.826250, samples/s: 2993.001 1612039532.3062134
train: epoch 110, iter 2400, loss: 2.656089, top_1: 0.614922, top_k: 0.823203, samples/s: 2938.785 1612039541.0170321
train: epoch 110, iter 2500, loss: 2.454444, top_1: 0.614844, top_k: 0.827148, samples/s: 2962.700 1612039549.6576953
train: epoch 110, iter 2600, loss: 2.641129, top_1: 0.617930, top_k: 0.822148, samples/s: 2950.987 1612039558.3327184
train: epoch 110, iter 2700, loss: 2.441566, top_1: 0.616055, top_k: 0.825742, samples/s: 2966.249 1612039566.9631581
train: epoch 110, iter 2800, loss: 2.522225, top_1: 0.609844, top_k: 0.822578, samples/s: 3000.139 1612039575.4962208
train: epoch 110, iter 2900, loss: 2.522453, top_1: 0.611328, top_k: 0.824063, samples/s: 2978.012 1612039584.0924385
train: epoch 110, iter 3000, loss: 2.680363, top_1: 0.606172, top_k: 0.819336, samples/s: 2913.383 1612039592.8794856
train: epoch 110, iter 3100, loss: 2.558161, top_1: 0.608672, top_k: 0.819492, samples/s: 2976.464 1612039601.480326
train: epoch 110, iter 3200, loss: 2.695584, top_1: 0.617695, top_k: 0.825273, samples/s: 2997.882 1612039610.0197265
train: epoch 110, iter 3300, loss: 2.559770, top_1: 0.616758, top_k: 0.823398, samples/s: 3007.613 1612039618.5313761
train: epoch 110, iter 3400, loss: 2.638392, top_1: 0.612070, top_k: 0.823711, samples/s: 2979.872 1612039627.1223414
train: epoch 110, iter 3500, loss: 2.615160, top_1: 0.610156, top_k: 0.820352, samples/s: 2983.015 1612039635.7043276
train: epoch 110, iter 3600, loss: 2.475034, top_1: 0.617656, top_k: 0.824688, samples/s: 2983.313 1612039644.285367
train: epoch 110, iter 3700, loss: 2.635083, top_1: 0.609141, top_k: 0.822148, samples/s: 3006.682 1612039652.7996895
train: epoch 110, iter 3800, loss: 2.786441, top_1: 0.612539, top_k: 0.825664, samples/s: 2981.752 1612039661.385274
train: epoch 110, iter 3900, loss: 2.741811, top_1: 0.614062, top_k: 0.825859, samples/s: 2975.948 1612039669.9875576
train: epoch 110, iter 4000, loss: 2.699483, top_1: 0.611953, top_k: 0.818789, samples/s: 2980.951 1612039678.5754592
train: epoch 110, iter 4100, loss: 2.546164, top_1: 0.609062, top_k: 0.819922, samples/s: 2942.517 1612039687.2756522
train: epoch 110, iter 4200, loss: 2.481222, top_1: 0.614844, top_k: 0.825430, samples/s: 2947.321 1612039695.9613314
train: epoch 110, iter 4300, loss: 2.434013, top_1: 0.614688, top_k: 0.823164, samples/s: 3038.659 1612039704.3860834
train: epoch 110, iter 4400, loss: 2.651648, top_1: 0.611563, top_k: 0.822461, samples/s: 2936.325 1612039713.1044893
train: epoch 110, iter 4500, loss: 2.745966, top_1: 0.611445, top_k: 0.825195, samples/s: 2990.397 1612039721.6652462
train: epoch 110, iter 4600, loss: 2.628035, top_1: 0.616680, top_k: 0.825859, samples/s: 2954.237 1612039730.330733
train: epoch 110, iter 4700, loss: 2.405114, top_1: 0.614336, top_k: 0.822148, samples/s: 2959.744 1612039738.9801912
train: epoch 110, iter 4800, loss: 2.497872, top_1: 0.612070, top_k: 0.819063, samples/s: 2980.028 1612039747.570647
train: epoch 110, iter 4900, loss: 2.572110, top_1: 0.614922, top_k: 0.823359, samples/s: 2951.332 1612039756.244708
train: epoch 110, iter 5000, loss: 2.478391, top_1: 0.619961, top_k: 0.828711, samples/s: 2982.011 1612039764.8295014
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_110.
validation: epoch 110, iter 195, top_1: 0.650921, top_k: 0.864383, samples/s: 3002.102 1612039781.6826806
train: epoch 111, iter 100, loss: 2.552268, top_1: 0.616719, top_k: 0.826719, samples/s: 2962.989 1612039806.1161177
train: epoch 111, iter 200, loss: 2.576259, top_1: 0.622461, top_k: 0.830859, samples/s: 2965.967 1612039814.747394
train: epoch 111, iter 300, loss: 2.635962, top_1: 0.623477, top_k: 0.831016, samples/s: 3004.459 1612039823.2679875
train: epoch 111, iter 400, loss: 2.507933, top_1: 0.623750, top_k: 0.829961, samples/s: 2950.579 1612039831.9443152
train: epoch 111, iter 500, loss: 2.634052, top_1: 0.626133, top_k: 0.835586, samples/s: 3032.598 1612039840.3858423
train: epoch 111, iter 600, loss: 2.724024, top_1: 0.617812, top_k: 0.824883, samples/s: 3004.431 1612039848.9066157
train: epoch 111, iter 700, loss: 2.675247, top_1: 0.622656, top_k: 0.831484, samples/s: 2970.246 1612039857.5254247
train: epoch 111, iter 800, loss: 2.614424, top_1: 0.619961, top_k: 0.831719, samples/s: 3004.400 1612039866.0462844
train: epoch 111, iter 900, loss: 2.620633, top_1: 0.625898, top_k: 0.830391, samples/s: 2994.249 1612039874.5959654
train: epoch 111, iter 1000, loss: 2.493235, top_1: 0.623242, top_k: 0.830078, samples/s: 2967.015 1612039883.2242007
train: epoch 111, iter 1100, loss: 2.622573, top_1: 0.617148, top_k: 0.823438, samples/s: 2996.553 1612039891.7675533
train: epoch 111, iter 1200, loss: 2.608613, top_1: 0.623789, top_k: 0.825781, samples/s: 2949.765 1612039900.4460196
train: epoch 111, iter 1300, loss: 2.583687, top_1: 0.620469, top_k: 0.830078, samples/s: 2964.062 1612039909.0827746
train: epoch 111, iter 1400, loss: 2.590009, top_1: 0.621914, top_k: 0.827070, samples/s: 3007.273 1612039917.5955358
train: epoch 111, iter 1500, loss: 2.590323, top_1: 0.612617, top_k: 0.825156, samples/s: 2999.943 1612039926.1291084
train: epoch 111, iter 1600, loss: 2.547023, top_1: 0.617148, top_k: 0.827812, samples/s: 3019.392 1612039934.60752
train: epoch 111, iter 1700, loss: 2.462830, top_1: 0.626094, top_k: 0.828867, samples/s: 2983.581 1612039943.1878054
train: epoch 111, iter 1800, loss: 2.767864, top_1: 0.617500, top_k: 0.827187, samples/s: 2965.603 1612039951.8201308
train: epoch 111, iter 1900, loss: 2.670655, top_1: 0.623398, top_k: 0.831484, samples/s: 2904.747 1612039960.6332965
train: epoch 111, iter 2000, loss: 2.640553, top_1: 0.619141, top_k: 0.824922, samples/s: 2984.008 1612039969.2125266
train: epoch 111, iter 2100, loss: 2.609043, top_1: 0.620547, top_k: 0.829375, samples/s: 3006.535 1612039977.7273846
train: epoch 111, iter 2200, loss: 2.579959, top_1: 0.615664, top_k: 0.826250, samples/s: 2919.247 1612039986.4966178
train: epoch 111, iter 2300, loss: 2.385418, top_1: 0.615352, top_k: 0.827383, samples/s: 2978.530 1612039995.0913484
train: epoch 111, iter 2400, loss: 2.627222, top_1: 0.620977, top_k: 0.828359, samples/s: 2959.086 1612040003.7426689
train: epoch 111, iter 2500, loss: 2.571916, top_1: 0.617188, top_k: 0.825352, samples/s: 2964.934 1612040012.3769126
train: epoch 111, iter 2600, loss: 2.721129, top_1: 0.616563, top_k: 0.827812, samples/s: 2964.361 1612040021.0128386
train: epoch 111, iter 2700, loss: 2.636481, top_1: 0.617617, top_k: 0.828242, samples/s: 2916.155 1612040029.7915108
train: epoch 111, iter 2800, loss: 2.503198, top_1: 0.621172, top_k: 0.828164, samples/s: 2975.583 1612040038.394882
train: epoch 111, iter 2900, loss: 2.576523, top_1: 0.614492, top_k: 0.823711, samples/s: 2919.596 1612040047.163315
train: epoch 111, iter 3000, loss: 2.602695, top_1: 0.615820, top_k: 0.827070, samples/s: 2983.409 1612040055.7440114
train: epoch 111, iter 3100, loss: 2.525171, top_1: 0.614727, top_k: 0.828438, samples/s: 2957.454 1612040064.400188
train: epoch 111, iter 3200, loss: 2.508859, top_1: 0.620313, top_k: 0.828164, samples/s: 2988.560 1612040072.9661062
train: epoch 111, iter 3300, loss: 2.591173, top_1: 0.615078, top_k: 0.827187, samples/s: 2999.583 1612040081.5007403
train: epoch 111, iter 3400, loss: 2.711458, top_1: 0.613359, top_k: 0.823203, samples/s: 3006.500 1612040090.0156221
train: epoch 111, iter 3500, loss: 2.601483, top_1: 0.623906, top_k: 0.826055, samples/s: 2942.928 1612040098.714355
train: epoch 111, iter 3600, loss: 2.687577, top_1: 0.616992, top_k: 0.826836, samples/s: 2961.838 1612040107.3576825
train: epoch 111, iter 3700, loss: 2.593096, top_1: 0.622930, top_k: 0.829648, samples/s: 2965.971 1612040115.9888382
train: epoch 111, iter 3800, loss: 2.510021, top_1: 0.616484, top_k: 0.827500, samples/s: 3008.194 1612040124.4988818
train: epoch 111, iter 3900, loss: 2.437263, top_1: 0.616836, top_k: 0.825391, samples/s: 2908.689 1612040133.3001494
train: epoch 111, iter 4000, loss: 2.692943, top_1: 0.616680, top_k: 0.827500, samples/s: 2955.810 1612040141.96107
train: epoch 111, iter 4100, loss: 2.629607, top_1: 0.615547, top_k: 0.826172, samples/s: 2962.458 1612040150.6025202
train: epoch 111, iter 4200, loss: 2.524021, top_1: 0.614609, top_k: 0.822500, samples/s: 2991.946 1612040159.1588283
train: epoch 111, iter 4300, loss: 2.425315, top_1: 0.616758, top_k: 0.827734, samples/s: 2975.733 1612040167.761835
train: epoch 111, iter 4400, loss: 2.587010, top_1: 0.613437, top_k: 0.824727, samples/s: 2934.592 1612040176.485469
train: epoch 111, iter 4500, loss: 2.642742, top_1: 0.616836, top_k: 0.826289, samples/s: 2952.163 1612040185.1569107
train: epoch 111, iter 4600, loss: 2.636803, top_1: 0.613828, top_k: 0.823086, samples/s: 2982.916 1612040193.7391589
train: epoch 111, iter 4700, loss: 2.490056, top_1: 0.615977, top_k: 0.822266, samples/s: 2936.477 1612040202.4570336
train: epoch 111, iter 4800, loss: 2.563811, top_1: 0.613203, top_k: 0.823242, samples/s: 2994.820 1612040211.0052013
train: epoch 111, iter 4900, loss: 2.487352, top_1: 0.616602, top_k: 0.825273, samples/s: 2881.815 1612040219.8884106
train: epoch 111, iter 5000, loss: 2.555653, top_1: 0.614219, top_k: 0.824648, samples/s: 2992.632 1612040228.4427567
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_111.
validation: epoch 111, iter 195, top_1: 0.653926, top_k: 0.864002, samples/s: 3007.395 1612040245.248348
train: epoch 112, iter 100, loss: 2.636684, top_1: 0.624727, top_k: 0.829961, samples/s: 2825.203 1612040270.5131161
train: epoch 112, iter 200, loss: 2.633556, top_1: 0.620273, top_k: 0.830000, samples/s: 2981.831 1612040279.0985768
train: epoch 112, iter 300, loss: 2.563810, top_1: 0.621602, top_k: 0.829219, samples/s: 2968.819 1612040287.7213886
train: epoch 112, iter 400, loss: 2.732954, top_1: 0.620703, top_k: 0.831758, samples/s: 2978.636 1612040296.315971
train: epoch 112, iter 500, loss: 2.731437, top_1: 0.627773, top_k: 0.836641, samples/s: 2953.134 1612040304.9846492
train: epoch 112, iter 600, loss: 2.874173, top_1: 0.621758, top_k: 0.832461, samples/s: 2909.212 1612040313.7842805
train: epoch 112, iter 700, loss: 2.594099, top_1: 0.624805, top_k: 0.830781, samples/s: 2954.322 1612040322.4496357
train: epoch 112, iter 800, loss: 2.530490, top_1: 0.616641, top_k: 0.829063, samples/s: 2978.427 1612040331.0446994
train: epoch 112, iter 900, loss: 2.375808, top_1: 0.624180, top_k: 0.833750, samples/s: 2986.372 1612040339.6169658
train: epoch 112, iter 1000, loss: 2.522005, top_1: 0.624336, top_k: 0.827422, samples/s: 3008.258 1612040348.126953
train: epoch 112, iter 1100, loss: 2.512172, top_1: 0.622891, top_k: 0.829570, samples/s: 2959.606 1612040356.7767136
train: epoch 112, iter 1200, loss: 2.575176, top_1: 0.623789, top_k: 0.827305, samples/s: 3022.423 1612040365.2467382
train: epoch 112, iter 1300, loss: 2.549950, top_1: 0.624062, top_k: 0.827969, samples/s: 2926.667 1612040373.9939146
train: epoch 112, iter 1400, loss: 2.580976, top_1: 0.620430, top_k: 0.828398, samples/s: 3002.017 1612040382.5214481
train: epoch 112, iter 1500, loss: 2.723116, top_1: 0.620078, top_k: 0.827227, samples/s: 2979.941 1612040391.1123574
train: epoch 112, iter 1600, loss: 2.462455, top_1: 0.619062, top_k: 0.830586, samples/s: 2905.713 1612040399.922462
train: epoch 112, iter 1700, loss: 2.657744, top_1: 0.623320, top_k: 0.829531, samples/s: 2935.114 1612040408.6444333
train: epoch 112, iter 1800, loss: 2.642558, top_1: 0.622578, top_k: 0.827773, samples/s: 2978.915 1612040417.238182
train: epoch 112, iter 1900, loss: 2.657876, top_1: 0.626523, top_k: 0.833398, samples/s: 2937.499 1612040425.9530144
train: epoch 112, iter 2000, loss: 2.559416, top_1: 0.621602, top_k: 0.831992, samples/s: 3000.755 1612040434.4842637
train: epoch 112, iter 2100, loss: 2.618254, top_1: 0.614688, top_k: 0.823633, samples/s: 2978.638 1612040443.0788105
train: epoch 112, iter 2200, loss: 2.624607, top_1: 0.617930, top_k: 0.829531, samples/s: 2958.165 1612040451.7328591
train: epoch 112, iter 2300, loss: 2.566291, top_1: 0.624531, top_k: 0.832500, samples/s: 2949.228 1612040460.4132242
train: epoch 112, iter 2400, loss: 2.682292, top_1: 0.617617, top_k: 0.828633, samples/s: 2879.361 1612040469.3039334
train: epoch 112, iter 2500, loss: 2.601611, top_1: 0.617734, top_k: 0.829805, samples/s: 2972.694 1612040477.9158707
train: epoch 112, iter 2600, loss: 2.718129, top_1: 0.617031, top_k: 0.827187, samples/s: 2986.613 1612040486.4883897
train: epoch 112, iter 2700, loss: 2.635713, top_1: 0.622617, top_k: 0.831523, samples/s: 3011.636 1612040494.987561
train: epoch 112, iter 2800, loss: 2.537817, top_1: 0.621602, top_k: 0.826016, samples/s: 2978.975 1612040503.5816755
train: epoch 112, iter 2900, loss: 2.438748, top_1: 0.618633, top_k: 0.828359, samples/s: 2995.002 1612040512.1286952
train: epoch 112, iter 3000, loss: 2.471016, top_1: 0.621523, top_k: 0.829492, samples/s: 2973.668 1612040520.7375917
train: epoch 112, iter 3100, loss: 2.502155, top_1: 0.618086, top_k: 0.825430, samples/s: 2887.650 1612040529.602967
train: epoch 112, iter 3200, loss: 2.666909, top_1: 0.616602, top_k: 0.829102, samples/s: 2964.124 1612040538.2395446
train: epoch 112, iter 3300, loss: 2.505848, top_1: 0.620234, top_k: 0.825977, samples/s: 2988.397 1612040546.8060079
train: epoch 112, iter 3400, loss: 2.621950, top_1: 0.619922, top_k: 0.830352, samples/s: 2953.696 1612040555.4732037
train: epoch 112, iter 3500, loss: 2.573523, top_1: 0.621953, top_k: 0.827109, samples/s: 2985.821 1612040564.0470235
train: epoch 112, iter 3600, loss: 2.697892, top_1: 0.619766, top_k: 0.826250, samples/s: 2914.604 1612040572.8303885
train: epoch 112, iter 3700, loss: 2.612501, top_1: 0.623281, top_k: 0.832617, samples/s: 2998.069 1612040581.3691244
train: epoch 112, iter 3800, loss: 2.735041, top_1: 0.620234, top_k: 0.826289, samples/s: 2966.290 1612040589.99947
train: epoch 112, iter 3900, loss: 2.495506, top_1: 0.613984, top_k: 0.821484, samples/s: 3004.023 1612040598.5213652
train: epoch 112, iter 4000, loss: 2.513687, top_1: 0.620469, top_k: 0.830469, samples/s: 2972.921 1612040607.1324298
train: epoch 112, iter 4100, loss: 2.777090, top_1: 0.618633, top_k: 0.826641, samples/s: 2970.327 1612040615.7510808
train: epoch 112, iter 4200, loss: 2.468376, top_1: 0.613789, top_k: 0.824219, samples/s: 2981.154 1612040624.339524
train: epoch 112, iter 4300, loss: 2.643012, top_1: 0.623008, top_k: 0.830078, samples/s: 2989.670 1612040632.9011936
train: epoch 112, iter 4400, loss: 2.747984, top_1: 0.618242, top_k: 0.825977, samples/s: 2996.131 1612040641.4463537
train: epoch 112, iter 4500, loss: 2.447216, top_1: 0.618867, top_k: 0.826641, samples/s: 2975.393 1612040650.0494158
train: epoch 112, iter 4600, loss: 2.763707, top_1: 0.618320, top_k: 0.829180, samples/s: 2959.580 1612040658.69925
train: epoch 112, iter 4700, loss: 2.805169, top_1: 0.614414, top_k: 0.826055, samples/s: 2949.833 1612040667.3777213
train: epoch 112, iter 4800, loss: 2.594397, top_1: 0.622695, top_k: 0.827383, samples/s: 2979.348 1612040675.9702244
train: epoch 112, iter 4900, loss: 2.601628, top_1: 0.616211, top_k: 0.828047, samples/s: 2964.589 1612040684.6055183
train: epoch 112, iter 5000, loss: 2.378802, top_1: 0.618945, top_k: 0.826484, samples/s: 3002.643 1612040693.1312785
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_112.
validation: epoch 112, iter 195, top_1: 0.660236, top_k: 0.868590, samples/s: 3016.584 1612040709.9305196
train: epoch 113, iter 100, loss: 2.527085, top_1: 0.633398, top_k: 0.837773, samples/s: 2935.241 1612040734.581085
train: epoch 113, iter 200, loss: 2.469966, top_1: 0.629648, top_k: 0.838008, samples/s: 2948.691 1612040743.2631066
train: epoch 113, iter 300, loss: 2.619410, top_1: 0.635664, top_k: 0.839219, samples/s: 2990.837 1612040751.8223915
train: epoch 113, iter 400, loss: 2.676549, top_1: 0.627070, top_k: 0.832578, samples/s: 3003.213 1612040760.3466926
train: epoch 113, iter 500, loss: 2.499363, top_1: 0.632070, top_k: 0.836484, samples/s: 2944.056 1612040769.0420506
train: epoch 113, iter 600, loss: 2.607862, top_1: 0.623828, top_k: 0.833008, samples/s: 3006.163 1612040777.5578969
train: epoch 113, iter 700, loss: 2.347928, top_1: 0.623398, top_k: 0.830820, samples/s: 2919.105 1612040786.327732
train: epoch 113, iter 800, loss: 2.514978, top_1: 0.625469, top_k: 0.833398, samples/s: 2992.103 1612040794.8835952
train: epoch 113, iter 900, loss: 2.639992, top_1: 0.627031, top_k: 0.835234, samples/s: 3027.267 1612040803.3401272
train: epoch 113, iter 1000, loss: 2.484433, top_1: 0.625820, top_k: 0.831953, samples/s: 2875.576 1612040812.2430136
train: epoch 113, iter 1100, loss: 2.350643, top_1: 0.623359, top_k: 0.831562, samples/s: 2928.863 1612040820.983333
train: epoch 113, iter 1200, loss: 2.695151, top_1: 0.619766, top_k: 0.829570, samples/s: 3007.374 1612040829.495655
train: epoch 113, iter 1300, loss: 2.625134, top_1: 0.625547, top_k: 0.827812, samples/s: 2965.414 1612040838.128484
train: epoch 113, iter 1400, loss: 2.611111, top_1: 0.630039, top_k: 0.829414, samples/s: 2986.726 1612040846.699719
train: epoch 113, iter 1500, loss: 2.408994, top_1: 0.615938, top_k: 0.826641, samples/s: 2891.221 1612040855.5544965
train: epoch 113, iter 1600, loss: 2.529367, top_1: 0.617148, top_k: 0.830586, samples/s: 2923.539 1612040864.310637
train: epoch 113, iter 1700, loss: 2.445880, top_1: 0.626250, top_k: 0.833242, samples/s: 2893.009 1612040873.1596136
train: epoch 113, iter 1800, loss: 2.420103, top_1: 0.620703, top_k: 0.831680, samples/s: 2958.871 1612040881.8114855
train: epoch 113, iter 1900, loss: 2.413751, top_1: 0.621992, top_k: 0.827227, samples/s: 2979.645 1612040890.4031308
train: epoch 113, iter 2000, loss: 2.498488, top_1: 0.621484, top_k: 0.831445, samples/s: 2992.219 1612040898.9586546
train: epoch 113, iter 2100, loss: 2.701316, top_1: 0.620664, top_k: 0.828008, samples/s: 2996.432 1612040907.5021648
train: epoch 113, iter 2200, loss: 2.459906, top_1: 0.622344, top_k: 0.828672, samples/s: 2942.125 1612040916.2033262
train: epoch 113, iter 2300, loss: 2.624400, top_1: 0.621836, top_k: 0.829414, samples/s: 3018.025 1612040924.6856425
train: epoch 113, iter 2400, loss: 2.473814, top_1: 0.627266, top_k: 0.831719, samples/s: 2934.441 1612040933.4098122
train: epoch 113, iter 2500, loss: 2.650603, top_1: 0.617578, top_k: 0.828086, samples/s: 2893.701 1612040942.2564788
train: epoch 113, iter 2600, loss: 2.439178, top_1: 0.622773, top_k: 0.831133, samples/s: 2989.229 1612040950.8205638
train: epoch 113, iter 2700, loss: 2.439742, top_1: 0.620664, top_k: 0.831211, samples/s: 3000.541 1612040959.35235
train: epoch 113, iter 2800, loss: 2.648047, top_1: 0.623906, top_k: 0.830664, samples/s: 2879.274 1612040968.2434707
train: epoch 113, iter 2900, loss: 2.436346, top_1: 0.619219, top_k: 0.826719, samples/s: 2998.846 1612040976.7801502
train: epoch 113, iter 3000, loss: 2.673412, top_1: 0.617461, top_k: 0.824531, samples/s: 2927.319 1612040985.525332
train: epoch 113, iter 3100, loss: 2.669503, top_1: 0.621406, top_k: 0.828281, samples/s: 2913.716 1612040994.3114011
train: epoch 113, iter 3200, loss: 2.784357, top_1: 0.615625, top_k: 0.827578, samples/s: 2977.009 1612041002.9105926
train: epoch 113, iter 3300, loss: 2.550425, top_1: 0.623281, top_k: 0.827148, samples/s: 2932.335 1612041011.6408653
train: epoch 113, iter 3400, loss: 2.686097, top_1: 0.618906, top_k: 0.828789, samples/s: 3018.136 1612041020.1229422
train: epoch 113, iter 3500, loss: 2.786692, top_1: 0.619922, top_k: 0.829219, samples/s: 2966.088 1612041028.7537704
train: epoch 113, iter 3600, loss: 2.555767, top_1: 0.624297, top_k: 0.831680, samples/s: 2939.681 1612041037.4623222
train: epoch 113, iter 3700, loss: 2.703990, top_1: 0.624180, top_k: 0.832734, samples/s: 2969.505 1612041046.083288
train: epoch 113, iter 3800, loss: 2.537262, top_1: 0.622344, top_k: 0.830195, samples/s: 2950.448 1612041054.7598035
train: epoch 113, iter 3900, loss: 2.460893, top_1: 0.619141, top_k: 0.827852, samples/s: 2918.041 1612041063.532828
train: epoch 113, iter 4000, loss: 2.511639, top_1: 0.618477, top_k: 0.828320, samples/s: 2987.263 1612041072.1027184
train: epoch 113, iter 4100, loss: 2.537735, top_1: 0.614766, top_k: 0.828398, samples/s: 2936.641 1612041080.819981
train: epoch 113, iter 4200, loss: 2.582340, top_1: 0.619531, top_k: 0.826641, samples/s: 2998.005 1612041089.3589823
train: epoch 113, iter 4300, loss: 2.397373, top_1: 0.620742, top_k: 0.827852, samples/s: 3000.069 1612041097.8921125
train: epoch 113, iter 4400, loss: 2.745597, top_1: 0.622734, top_k: 0.830000, samples/s: 2992.216 1612041106.447657
train: epoch 113, iter 4500, loss: 2.483042, top_1: 0.619023, top_k: 0.828047, samples/s: 2970.147 1612041115.0667422
train: epoch 113, iter 4600, loss: 2.573529, top_1: 0.618711, top_k: 0.828086, samples/s: 2976.064 1612041123.6687205
train: epoch 113, iter 4700, loss: 2.572602, top_1: 0.620664, top_k: 0.826719, samples/s: 2955.178 1612041132.3314555
train: epoch 113, iter 4800, loss: 2.632573, top_1: 0.619023, top_k: 0.825547, samples/s: 3004.633 1612041140.851706
train: epoch 113, iter 4900, loss: 2.522524, top_1: 0.620547, top_k: 0.825742, samples/s: 2980.636 1612041149.4404533
train: epoch 113, iter 5000, loss: 2.633221, top_1: 0.628516, top_k: 0.834102, samples/s: 2926.358 1612041158.1885076
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_113.
validation: epoch 113, iter 195, top_1: 0.659175, top_k: 0.869351, samples/s: 2874.227 1612041175.801315
train: epoch 114, iter 100, loss: 2.433890, top_1: 0.630352, top_k: 0.834570, samples/s: 2976.215 1612041200.5792594
train: epoch 114, iter 200, loss: 2.912017, top_1: 0.633125, top_k: 0.837422, samples/s: 2998.655 1612041209.1164021
train: epoch 114, iter 300, loss: 2.668931, top_1: 0.630508, top_k: 0.838672, samples/s: 2940.115 1612041217.8236535
train: epoch 114, iter 400, loss: 2.376772, top_1: 0.629883, top_k: 0.831445, samples/s: 3001.214 1612041226.3534384
train: epoch 114, iter 500, loss: 2.619860, top_1: 0.627656, top_k: 0.833672, samples/s: 2958.302 1612041235.007147
train: epoch 114, iter 600, loss: 2.610697, top_1: 0.626953, top_k: 0.836211, samples/s: 3001.976 1612041243.534716
train: epoch 114, iter 700, loss: 2.652577, top_1: 0.625273, top_k: 0.833945, samples/s: 2938.971 1612041252.2453039
train: epoch 114, iter 800, loss: 2.590947, top_1: 0.629961, top_k: 0.835195, samples/s: 2918.797 1612041261.0160258
train: epoch 114, iter 900, loss: 2.621104, top_1: 0.633437, top_k: 0.835078, samples/s: 2986.221 1612041269.5887449
train: epoch 114, iter 1000, loss: 2.528997, top_1: 0.631406, top_k: 0.836055, samples/s: 2929.687 1612041278.3269413
train: epoch 114, iter 1100, loss: 2.616921, top_1: 0.631484, top_k: 0.834648, samples/s: 2994.318 1612041286.876415
train: epoch 114, iter 1200, loss: 2.683343, top_1: 0.624922, top_k: 0.832109, samples/s: 2934.862 1612041295.5992036
train: epoch 114, iter 1300, loss: 2.588407, top_1: 0.626328, top_k: 0.834609, samples/s: 2924.572 1612041304.3526082
train: epoch 114, iter 1400, loss: 2.619990, top_1: 0.630703, top_k: 0.834180, samples/s: 2963.982 1612041312.9897897
train: epoch 114, iter 1500, loss: 2.521385, top_1: 0.627891, top_k: 0.833047, samples/s: 2972.862 1612041321.6008255
train: epoch 114, iter 1600, loss: 2.609193, top_1: 0.625039, top_k: 0.829883, samples/s: 2942.208 1612041330.301852
train: epoch 114, iter 1700, loss: 2.685981, top_1: 0.624102, top_k: 0.829648, samples/s: 3002.161 1612041338.8290029
train: epoch 114, iter 1800, loss: 2.557003, top_1: 0.618828, top_k: 0.828750, samples/s: 2973.050 1612041347.4396293
train: epoch 114, iter 1900, loss: 2.404087, top_1: 0.619297, top_k: 0.832070, samples/s: 2907.810 1612041356.243513
train: epoch 114, iter 2000, loss: 2.411614, top_1: 0.626758, top_k: 0.834180, samples/s: 2995.664 1612041364.7893445
train: epoch 114, iter 2100, loss: 2.797562, top_1: 0.621250, top_k: 0.829375, samples/s: 2961.410 1612041373.4338663
train: epoch 114, iter 2200, loss: 2.705655, top_1: 0.623867, top_k: 0.829883, samples/s: 2969.913 1612041382.053512
train: epoch 114, iter 2300, loss: 2.652006, top_1: 0.626484, top_k: 0.833750, samples/s: 2924.765 1612041390.806377
train: epoch 114, iter 2400, loss: 2.651562, top_1: 0.631992, top_k: 0.832969, samples/s: 2982.149 1612041399.3907824
train: epoch 114, iter 2500, loss: 2.650773, top_1: 0.632109, top_k: 0.836758, samples/s: 3019.438 1612041407.8691828
train: epoch 114, iter 2600, loss: 2.701542, top_1: 0.624023, top_k: 0.829414, samples/s: 2987.635 1612041416.4377713
train: epoch 114, iter 2700, loss: 2.765803, top_1: 0.620586, top_k: 0.827461, samples/s: 3006.318 1612041424.9533029
train: epoch 114, iter 2800, loss: 2.543426, top_1: 0.622578, top_k: 0.828672, samples/s: 3003.794 1612041433.4757986
train: epoch 114, iter 2900, loss: 2.400652, top_1: 0.626367, top_k: 0.832305, samples/s: 2989.925 1612041442.0378923
train: epoch 114, iter 3000, loss: 2.494418, top_1: 0.622539, top_k: 0.829766, samples/s: 2941.339 1612041450.7413702
train: epoch 114, iter 3100, loss: 2.472452, top_1: 0.627109, top_k: 0.833398, samples/s: 3002.968 1612041459.266323
train: epoch 114, iter 3200, loss: 2.513401, top_1: 0.627969, top_k: 0.835664, samples/s: 2927.900 1612041468.0097501
train: epoch 114, iter 3300, loss: 2.568310, top_1: 0.623750, top_k: 0.826133, samples/s: 3005.131 1612041476.5285132
train: epoch 114, iter 3400, loss: 2.436997, top_1: 0.625273, top_k: 0.833320, samples/s: 2972.567 1612041485.1405947
train: epoch 114, iter 3500, loss: 2.478107, top_1: 0.621484, top_k: 0.830937, samples/s: 2956.011 1612041493.8011463
train: epoch 114, iter 3600, loss: 2.724100, top_1: 0.621719, top_k: 0.828555, samples/s: 2963.211 1612041502.4401953
train: epoch 114, iter 3700, loss: 2.488105, top_1: 0.621680, top_k: 0.832422, samples/s: 3004.879 1612041510.9598155
train: epoch 114, iter 3800, loss: 2.654751, top_1: 0.628359, top_k: 0.833398, samples/s: 2989.887 1612041519.52194
train: epoch 114, iter 3900, loss: 2.577785, top_1: 0.623008, top_k: 0.828516, samples/s: 2973.428 1612041528.1315024
train: epoch 114, iter 4000, loss: 2.659379, top_1: 0.624180, top_k: 0.831055, samples/s: 3024.390 1612041536.5960395
train: epoch 114, iter 4100, loss: 2.611861, top_1: 0.619453, top_k: 0.828438, samples/s: 2999.108 1612041545.1319184
train: epoch 114, iter 4200, loss: 2.685351, top_1: 0.619648, top_k: 0.832461, samples/s: 2965.276 1612041553.7651024
train: epoch 114, iter 4300, loss: 2.530290, top_1: 0.619297, top_k: 0.830078, samples/s: 2996.727 1612041562.3077364
train: epoch 114, iter 4400, loss: 2.480764, top_1: 0.626250, top_k: 0.828906, samples/s: 2881.773 1612041571.1911867
train: epoch 114, iter 4500, loss: 2.629169, top_1: 0.623398, top_k: 0.826680, samples/s: 2978.116 1612041579.7872226
train: epoch 114, iter 4600, loss: 2.700006, top_1: 0.626641, top_k: 0.827344, samples/s: 2974.269 1612041588.394644
train: epoch 114, iter 4700, loss: 2.626419, top_1: 0.623437, top_k: 0.827852, samples/s: 2865.954 1612041597.326878
train: epoch 114, iter 4800, loss: 2.625943, top_1: 0.627031, top_k: 0.833438, samples/s: 2959.466 1612041605.9771543
train: epoch 114, iter 4900, loss: 2.642009, top_1: 0.626875, top_k: 0.832109, samples/s: 2996.411 1612041614.520586
train: epoch 114, iter 5000, loss: 2.622464, top_1: 0.628945, top_k: 0.833672, samples/s: 2933.378 1612041623.2477195
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_114.
validation: epoch 114, iter 195, top_1: 0.663442, top_k: 0.869151, samples/s: 3022.611 1612041639.934568
train: epoch 115, iter 100, loss: 2.409636, top_1: 0.631602, top_k: 0.836055, samples/s: 2992.065 1612041664.3321464
train: epoch 115, iter 200, loss: 2.664757, top_1: 0.634023, top_k: 0.838008, samples/s: 2989.039 1612041672.8970888
train: epoch 115, iter 300, loss: 2.672279, top_1: 0.635430, top_k: 0.839141, samples/s: 3003.667 1612041681.4196937
train: epoch 115, iter 400, loss: 2.428435, top_1: 0.635781, top_k: 0.837656, samples/s: 3006.394 1612041689.9349873
train: epoch 115, iter 500, loss: 2.557936, top_1: 0.634336, top_k: 0.836680, samples/s: 2796.840 1612041699.0880888
train: epoch 115, iter 600, loss: 2.768275, top_1: 0.628516, top_k: 0.834609, samples/s: 3008.059 1612041707.5986185
train: epoch 115, iter 700, loss: 2.444545, top_1: 0.629531, top_k: 0.835117, samples/s: 2970.275 1612041716.2173119
train: epoch 115, iter 800, loss: 2.477124, top_1: 0.628984, top_k: 0.836016, samples/s: 2992.994 1612041724.7707224
train: epoch 115, iter 900, loss: 2.651024, top_1: 0.633555, top_k: 0.837148, samples/s: 3012.122 1612041733.2696419
train: epoch 115, iter 1000, loss: 2.606674, top_1: 0.628398, top_k: 0.835313, samples/s: 2971.564 1612041741.884538
train: epoch 115, iter 1100, loss: 2.570884, top_1: 0.630703, top_k: 0.836094, samples/s: 2960.509 1612041750.5317419
train: epoch 115, iter 1200, loss: 2.603072, top_1: 0.630234, top_k: 0.831836, samples/s: 3005.483 1612041759.0494769
train: epoch 115, iter 1300, loss: 2.548995, top_1: 0.633359, top_k: 0.831562, samples/s: 2836.766 1612041768.0738509
train: epoch 115, iter 1400, loss: 2.500010, top_1: 0.630859, top_k: 0.838047, samples/s: 2987.365 1612041776.643272
train: epoch 115, iter 1500, loss: 2.424955, top_1: 0.629609, top_k: 0.832539, samples/s: 2934.784 1612041785.3663085
train: epoch 115, iter 1600, loss: 2.562469, top_1: 0.628008, top_k: 0.835977, samples/s: 3025.324 1612041793.8280883
train: epoch 115, iter 1700, loss: 2.309430, top_1: 0.625313, top_k: 0.832031, samples/s: 2967.796 1612041802.4540703
train: epoch 115, iter 1800, loss: 2.651121, top_1: 0.630117, top_k: 0.837031, samples/s: 2986.946 1612041811.0246747
train: epoch 115, iter 1900, loss: 2.466068, top_1: 0.629531, top_k: 0.835508, samples/s: 2996.370 1612041819.5683892
train: epoch 115, iter 2000, loss: 2.578286, top_1: 0.624258, top_k: 0.832891, samples/s: 2940.298 1612041828.2749455
train: epoch 115, iter 2100, loss: 2.479057, top_1: 0.627773, top_k: 0.830977, samples/s: 2908.290 1612041837.077424
train: epoch 115, iter 2200, loss: 2.549205, top_1: 0.628086, top_k: 0.837930, samples/s: 3025.184 1612041845.539686
train: epoch 115, iter 2300, loss: 2.437677, top_1: 0.626797, top_k: 0.833203, samples/s: 3001.217 1612041854.0696974
train: epoch 115, iter 2400, loss: 2.361129, top_1: 0.627852, top_k: 0.832422, samples/s: 2974.932 1612041862.674824
train: epoch 115, iter 2500, loss: 2.564122, top_1: 0.633906, top_k: 0.835117, samples/s: 2947.328 1612041871.3606603
train: epoch 115, iter 2600, loss: 2.459778, top_1: 0.625430, top_k: 0.833047, samples/s: 2976.901 1612041879.9602559
train: epoch 115, iter 2700, loss: 2.539407, top_1: 0.629766, top_k: 0.834883, samples/s: 2956.989 1612041888.6175601
train: epoch 115, iter 2800, loss: 2.790832, top_1: 0.628320, top_k: 0.834141, samples/s: 3006.745 1612041897.1320155
train: epoch 115, iter 2900, loss: 2.513273, top_1: 0.630742, top_k: 0.836992, samples/s: 2983.048 1612041905.7135887
train: epoch 115, iter 3000, loss: 2.582741, top_1: 0.628633, top_k: 0.835625, samples/s: 2971.722 1612041914.3282535
train: epoch 115, iter 3100, loss: 2.612154, top_1: 0.625586, top_k: 0.829766, samples/s: 2992.222 1612041922.8837175
train: epoch 115, iter 3200, loss: 2.698859, top_1: 0.629141, top_k: 0.834219, samples/s: 2997.058 1612041931.425386
train: epoch 115, iter 3300, loss: 2.517351, top_1: 0.622578, top_k: 0.833047, samples/s: 2985.448 1612041940.000361
train: epoch 115, iter 3400, loss: 2.625957, top_1: 0.625938, top_k: 0.830469, samples/s: 3007.027 1612041948.513712
train: epoch 115, iter 3500, loss: 2.456020, top_1: 0.628555, top_k: 0.833047, samples/s: 2983.705 1612041957.093726
train: epoch 115, iter 3600, loss: 2.550261, top_1: 0.628281, top_k: 0.833945, samples/s: 3000.840 1612041965.624618
train: epoch 115, iter 3700, loss: 2.410190, top_1: 0.628906, top_k: 0.833086, samples/s: 2900.304 1612041974.45125
train: epoch 115, iter 3800, loss: 2.664283, top_1: 0.627188, top_k: 0.832031, samples/s: 2842.483 1612041983.4574723
train: epoch 115, iter 3900, loss: 2.610284, top_1: 0.626289, top_k: 0.830195, samples/s: 2949.086 1612041992.138193
train: epoch 115, iter 4000, loss: 2.412120, top_1: 0.618906, top_k: 0.827187, samples/s: 2999.256 1612042000.6735854
train: epoch 115, iter 4100, loss: 2.591951, top_1: 0.627148, top_k: 0.831719, samples/s: 2938.685 1612042009.3849523
train: epoch 115, iter 4200, loss: 2.506655, top_1: 0.623867, top_k: 0.831523, samples/s: 2924.520 1612042018.1385212
train: epoch 115, iter 4300, loss: 2.704029, top_1: 0.616953, top_k: 0.826875, samples/s: 3010.070 1612042026.6433039
train: epoch 115, iter 4400, loss: 2.808532, top_1: 0.622188, top_k: 0.830625, samples/s: 2918.792 1612042035.414055
train: epoch 115, iter 4500, loss: 2.586711, top_1: 0.626680, top_k: 0.832656, samples/s: 2991.577 1612042043.9716232
train: epoch 115, iter 4600, loss: 2.457447, top_1: 0.625625, top_k: 0.830039, samples/s: 2952.212 1612042052.6428826
train: epoch 115, iter 4700, loss: 2.758417, top_1: 0.621406, top_k: 0.829922, samples/s: 2979.319 1612042061.2354243
train: epoch 115, iter 4800, loss: 2.387626, top_1: 0.626133, top_k: 0.829844, samples/s: 2982.487 1612042069.8188918
train: epoch 115, iter 4900, loss: 2.420271, top_1: 0.624922, top_k: 0.834180, samples/s: 2958.259 1612042078.4727733
train: epoch 115, iter 5000, loss: 2.595289, top_1: 0.631992, top_k: 0.837773, samples/s: 2971.447 1612042087.0879705
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_115.
validation: epoch 115, iter 195, top_1: 0.663161, top_k: 0.869752, samples/s: 2948.948 1612042104.3598094
train: epoch 116, iter 100, loss: 2.526123, top_1: 0.645312, top_k: 0.843984, samples/s: 2946.564 1612042129.1993232
train: epoch 116, iter 200, loss: 2.403058, top_1: 0.641250, top_k: 0.841055, samples/s: 2941.246 1612042137.9028783
train: epoch 116, iter 300, loss: 2.471782, top_1: 0.632188, top_k: 0.837344, samples/s: 2981.362 1612042146.4897482
train: epoch 116, iter 400, loss: 2.684632, top_1: 0.631641, top_k: 0.836328, samples/s: 3008.629 1612042154.9984124
train: epoch 116, iter 500, loss: 2.569814, top_1: 0.636641, top_k: 0.836602, samples/s: 2993.458 1612042163.5503898
train: epoch 116, iter 600, loss: 2.484695, top_1: 0.629375, top_k: 0.833086, samples/s: 2931.308 1612042172.2837024
train: epoch 116, iter 700, loss: 2.504925, top_1: 0.633906, top_k: 0.834688, samples/s: 3009.089 1612042180.7913005
train: epoch 116, iter 800, loss: 2.562247, top_1: 0.625781, top_k: 0.831875, samples/s: 2828.744 1612042189.8412347
train: epoch 116, iter 900, loss: 2.475748, top_1: 0.634062, top_k: 0.837773, samples/s: 3011.515 1612042198.3419511
train: epoch 116, iter 1000, loss: 2.533796, top_1: 0.635625, top_k: 0.838008, samples/s: 3000.877 1612042206.872762
train: epoch 116, iter 1100, loss: 2.497401, top_1: 0.633828, top_k: 0.839453, samples/s: 2998.952 1612042215.4090385
train: epoch 116, iter 1200, loss: 2.692504, top_1: 0.631875, top_k: 0.837070, samples/s: 2989.575 1612042223.9721744
train: epoch 116, iter 1300, loss: 2.501060, top_1: 0.635938, top_k: 0.838984, samples/s: 2958.074 1612042232.6264462
train: epoch 116, iter 1400, loss: 2.569349, top_1: 0.635352, top_k: 0.835977, samples/s: 2991.065 1612042241.1852841
train: epoch 116, iter 1500, loss: 2.559289, top_1: 0.631172, top_k: 0.835977, samples/s: 2983.738 1612042249.7652256
train: epoch 116, iter 1600, loss: 2.475027, top_1: 0.635117, top_k: 0.836172, samples/s: 2935.289 1612042258.4882765
train: epoch 116, iter 1700, loss: 2.580892, top_1: 0.630273, top_k: 0.832930, samples/s: 2995.218 1612042267.0335255
train: epoch 116, iter 1800, loss: 2.662788, top_1: 0.625625, top_k: 0.835234, samples/s: 2927.524 1612042275.7784479
train: epoch 116, iter 1900, loss: 2.463886, top_1: 0.630703, top_k: 0.830508, samples/s: 2978.900 1612042284.3719423
train: epoch 116, iter 2000, loss: 2.558181, top_1: 0.630273, top_k: 0.832773, samples/s: 3010.048 1612042292.876772
train: epoch 116, iter 2100, loss: 2.391968, top_1: 0.632656, top_k: 0.836992, samples/s: 2919.130 1612042301.64647
train: epoch 116, iter 2200, loss: 2.659777, top_1: 0.629922, top_k: 0.832109, samples/s: 2982.419 1612042310.2301052
train: epoch 116, iter 2300, loss: 2.512579, top_1: 0.636484, top_k: 0.837891, samples/s: 2950.522 1612042318.9066334
train: epoch 116, iter 2400, loss: 2.268911, top_1: 0.627109, top_k: 0.834531, samples/s: 2958.442 1612042327.559801
train: epoch 116, iter 2500, loss: 2.415229, top_1: 0.628867, top_k: 0.832500, samples/s: 2977.811 1612042336.1566534
train: epoch 116, iter 2600, loss: 2.696033, top_1: 0.624883, top_k: 0.834766, samples/s: 3002.459 1612042344.683002
train: epoch 116, iter 2700, loss: 2.593333, top_1: 0.631641, top_k: 0.835078, samples/s: 3022.984 1612042353.1514575
train: epoch 116, iter 2800, loss: 2.459049, top_1: 0.633750, top_k: 0.838984, samples/s: 2986.716 1612042361.722804
train: epoch 116, iter 2900, loss: 2.584886, top_1: 0.630508, top_k: 0.837539, samples/s: 2934.996 1612042370.4450922
train: epoch 116, iter 3000, loss: 2.601442, top_1: 0.626602, top_k: 0.834805, samples/s: 3012.300 1612042378.943566
train: epoch 116, iter 3100, loss: 2.529872, top_1: 0.627773, top_k: 0.832461, samples/s: 2932.131 1612042387.6743777
train: epoch 116, iter 3200, loss: 2.528452, top_1: 0.631289, top_k: 0.836914, samples/s: 2964.628 1612042396.3096578
train: epoch 116, iter 3300, loss: 2.388908, top_1: 0.634336, top_k: 0.838398, samples/s: 2919.496 1612042405.0782003
train: epoch 116, iter 3400, loss: 2.556982, top_1: 0.627500, top_k: 0.832500, samples/s: 2976.110 1612042413.680039
train: epoch 116, iter 3500, loss: 2.496911, top_1: 0.629102, top_k: 0.836562, samples/s: 2946.637 1612042422.3679762
train: epoch 116, iter 3600, loss: 2.422079, top_1: 0.629141, top_k: 0.831367, samples/s: 2930.456 1612042431.1037543
train: epoch 116, iter 3700, loss: 2.426723, top_1: 0.630352, top_k: 0.836797, samples/s: 2925.303 1612042439.8549757
train: epoch 116, iter 3800, loss: 2.418236, top_1: 0.628867, top_k: 0.835195, samples/s: 2968.646 1612042448.478628
train: epoch 116, iter 3900, loss: 2.665318, top_1: 0.627344, top_k: 0.834688, samples/s: 2939.793 1612042457.1866527
train: epoch 116, iter 4000, loss: 2.675240, top_1: 0.623555, top_k: 0.833320, samples/s: 2987.313 1612042465.7561564
train: epoch 116, iter 4100, loss: 2.411397, top_1: 0.628555, top_k: 0.830430, samples/s: 2934.038 1612042474.4814072
train: epoch 116, iter 4200, loss: 2.594883, top_1: 0.632305, top_k: 0.833047, samples/s: 2989.008 1612042483.04596
train: epoch 116, iter 4300, loss: 2.589248, top_1: 0.626250, top_k: 0.834961, samples/s: 2966.997 1612042491.6742904
train: epoch 116, iter 4400, loss: 2.470092, top_1: 0.626523, top_k: 0.831992, samples/s: 2964.309 1612042500.3103087
train: epoch 116, iter 4500, loss: 2.692461, top_1: 0.623516, top_k: 0.833047, samples/s: 2985.541 1612042508.8849967
train: epoch 116, iter 4600, loss: 2.496508, top_1: 0.625313, top_k: 0.833203, samples/s: 2979.299 1612042517.477832
train: epoch 116, iter 4700, loss: 2.562865, top_1: 0.628945, top_k: 0.835195, samples/s: 2981.923 1612042526.0627022
train: epoch 116, iter 4800, loss: 2.589297, top_1: 0.632734, top_k: 0.834844, samples/s: 2986.498 1612042534.6347098
train: epoch 116, iter 4900, loss: 2.572151, top_1: 0.629766, top_k: 0.833203, samples/s: 2977.856 1612042543.2313845
train: epoch 116, iter 5000, loss: 2.669711, top_1: 0.641719, top_k: 0.841094, samples/s: 3005.436 1612042551.7492788
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_116.
validation: epoch 116, iter 195, top_1: 0.662921, top_k: 0.870192, samples/s: 3054.921 1612042568.3244936
train: epoch 117, iter 100, loss: 2.411798, top_1: 0.645781, top_k: 0.841875, samples/s: 2918.842 1612042592.6465273
train: epoch 117, iter 200, loss: 2.393831, top_1: 0.640898, top_k: 0.843633, samples/s: 3027.435 1612042601.1025314
train: epoch 117, iter 300, loss: 2.541619, top_1: 0.641797, top_k: 0.841484, samples/s: 2983.836 1612042609.6820998
train: epoch 117, iter 400, loss: 2.383325, top_1: 0.637266, top_k: 0.843906, samples/s: 2971.700 1612042618.2967408
train: epoch 117, iter 500, loss: 2.531360, top_1: 0.630547, top_k: 0.839414, samples/s: 2950.229 1612042626.9740057
train: epoch 117, iter 600, loss: 2.499427, top_1: 0.635586, top_k: 0.837344, samples/s: 2980.916 1612042635.5619097
train: epoch 117, iter 700, loss: 2.481608, top_1: 0.634180, top_k: 0.840625, samples/s: 3019.136 1612042644.0411875
train: epoch 117, iter 800, loss: 2.512026, top_1: 0.633750, top_k: 0.835859, samples/s: 2935.721 1612042652.7613456
train: epoch 117, iter 900, loss: 2.535687, top_1: 0.634766, top_k: 0.836133, samples/s: 2971.856 1612042661.3756132
train: epoch 117, iter 1000, loss: 2.563517, top_1: 0.635391, top_k: 0.840742, samples/s: 2952.813 1612042670.0451965
train: epoch 117, iter 1100, loss: 2.575526, top_1: 0.634180, top_k: 0.839570, samples/s: 2995.064 1612042678.5926816
train: epoch 117, iter 1200, loss: 2.646841, top_1: 0.635352, top_k: 0.841094, samples/s: 2946.939 1612042687.2797017
train: epoch 117, iter 1300, loss: 2.448472, top_1: 0.633633, top_k: 0.836445, samples/s: 2997.154 1612042695.8210237
train: epoch 117, iter 1400, loss: 2.653345, top_1: 0.634414, top_k: 0.835195, samples/s: 2940.948 1612042704.525743
train: epoch 117, iter 1500, loss: 2.591684, top_1: 0.634687, top_k: 0.840000, samples/s: 2980.248 1612042713.1156232
train: epoch 117, iter 1600, loss: 2.438413, top_1: 0.637500, top_k: 0.839414, samples/s: 3002.118 1612042721.6428838
train: epoch 117, iter 1700, loss: 2.496568, top_1: 0.632578, top_k: 0.835703, samples/s: 3005.824 1612042730.1596804
train: epoch 117, iter 1800, loss: 2.517246, top_1: 0.628477, top_k: 0.833750, samples/s: 2979.410 1612042738.7519984
train: epoch 117, iter 1900, loss: 2.636146, top_1: 0.637031, top_k: 0.841836, samples/s: 2979.523 1612042747.3440244
train: epoch 117, iter 2000, loss: 2.471417, top_1: 0.629023, top_k: 0.836172, samples/s: 3009.770 1612042755.849598
train: epoch 117, iter 2100, loss: 2.528390, top_1: 0.635312, top_k: 0.839844, samples/s: 2980.101 1612042764.439928
train: epoch 117, iter 2200, loss: 2.593766, top_1: 0.628906, top_k: 0.835781, samples/s: 2982.325 1612042773.0238178
train: epoch 117, iter 2300, loss: 2.533408, top_1: 0.632383, top_k: 0.835508, samples/s: 2986.021 1612042781.597054
train: epoch 117, iter 2400, loss: 2.778452, top_1: 0.634062, top_k: 0.834453, samples/s: 2962.722 1612042790.2378073
train: epoch 117, iter 2500, loss: 2.601502, top_1: 0.631016, top_k: 0.834297, samples/s: 2991.790 1612042798.7945657
train: epoch 117, iter 2600, loss: 2.500530, top_1: 0.629336, top_k: 0.836836, samples/s: 2959.273 1612042807.4454248
train: epoch 117, iter 2700, loss: 2.554345, top_1: 0.630469, top_k: 0.831758, samples/s: 2996.656 1612042815.988193
train: epoch 117, iter 2800, loss: 2.724199, top_1: 0.630703, top_k: 0.832266, samples/s: 2910.312 1612042824.784488
train: epoch 117, iter 2900, loss: 2.575761, top_1: 0.632266, top_k: 0.832695, samples/s: 2981.966 1612042833.3694327
train: epoch 117, iter 3000, loss: 2.682543, top_1: 0.632930, top_k: 0.835508, samples/s: 2936.644 1612042842.0869675
train: epoch 117, iter 3100, loss: 2.573321, top_1: 0.631914, top_k: 0.834570, samples/s: 2966.024 1612042850.7179487
train: epoch 117, iter 3200, loss: 2.438370, top_1: 0.634375, top_k: 0.839258, samples/s: 2991.042 1612042859.276831
train: epoch 117, iter 3300, loss: 2.492642, top_1: 0.627383, top_k: 0.833555, samples/s: 2973.590 1612042867.8860173
train: epoch 117, iter 3400, loss: 2.714969, top_1: 0.628555, top_k: 0.833242, samples/s: 2990.968 1612042876.4450667
train: epoch 117, iter 3500, loss: 2.297548, top_1: 0.630977, top_k: 0.838359, samples/s: 3017.086 1612042884.9300551
train: epoch 117, iter 3600, loss: 2.410949, top_1: 0.626289, top_k: 0.832695, samples/s: 2956.060 1612042893.5903788
train: epoch 117, iter 3700, loss: 2.416832, top_1: 0.631953, top_k: 0.834492, samples/s: 3011.689 1612042902.090555
train: epoch 117, iter 3800, loss: 2.544084, top_1: 0.632617, top_k: 0.833711, samples/s: 3000.424 1612042910.6225889
train: epoch 117, iter 3900, loss: 2.569898, top_1: 0.636055, top_k: 0.837148, samples/s: 2991.478 1612042919.1802392
train: epoch 117, iter 4000, loss: 2.343384, top_1: 0.639766, top_k: 0.840977, samples/s: 2981.460 1612042927.7666545
train: epoch 117, iter 4100, loss: 2.442997, top_1: 0.631250, top_k: 0.836445, samples/s: 2964.721 1612042936.4015043
train: epoch 117, iter 4200, loss: 2.442490, top_1: 0.630898, top_k: 0.833203, samples/s: 2877.657 1612042945.2976823
train: epoch 117, iter 4300, loss: 2.515203, top_1: 0.627656, top_k: 0.833789, samples/s: 2989.698 1612042953.8603864
train: epoch 117, iter 4400, loss: 2.548854, top_1: 0.634141, top_k: 0.836328, samples/s: 2994.782 1612042962.4085746
train: epoch 117, iter 4500, loss: 2.432245, top_1: 0.628711, top_k: 0.832656, samples/s: 2986.044 1612042970.9818225
train: epoch 117, iter 4600, loss: 2.453185, top_1: 0.630977, top_k: 0.839766, samples/s: 2983.774 1612042979.5615363
train: epoch 117, iter 4700, loss: 2.515934, top_1: 0.633320, top_k: 0.836562, samples/s: 2904.140 1612042988.3765929
train: epoch 117, iter 4800, loss: 2.489424, top_1: 0.630781, top_k: 0.830898, samples/s: 2984.551 1612042996.9541266
train: epoch 117, iter 4900, loss: 2.548826, top_1: 0.628437, top_k: 0.831602, samples/s: 2924.382 1612043005.7081459
train: epoch 117, iter 5000, loss: 2.457426, top_1: 0.637617, top_k: 0.842461, samples/s: 2967.386 1612043014.3352542
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_117.
validation: epoch 117, iter 195, top_1: 0.668309, top_k: 0.874439, samples/s: 3031.745 1612043031.0510855
train: epoch 118, iter 100, loss: 2.455606, top_1: 0.646445, top_k: 0.848945, samples/s: 2893.996 1612043055.325293
train: epoch 118, iter 200, loss: 2.633786, top_1: 0.644883, top_k: 0.846172, samples/s: 3019.329 1612043063.803973
train: epoch 118, iter 300, loss: 2.423638, top_1: 0.639766, top_k: 0.841367, samples/s: 2998.062 1612043072.3428152
train: epoch 118, iter 400, loss: 2.645352, top_1: 0.638437, top_k: 0.841875, samples/s: 2950.435 1612043081.0194871
train: epoch 118, iter 500, loss: 2.435418, top_1: 0.639180, top_k: 0.840078, samples/s: 3042.097 1612043089.4348118
train: epoch 118, iter 600, loss: 2.600987, top_1: 0.639727, top_k: 0.840703, samples/s: 2941.727 1612043098.1371403
train: epoch 118, iter 700, loss: 2.524857, top_1: 0.635312, top_k: 0.836484, samples/s: 3002.953 1612043106.6620831
train: epoch 118, iter 800, loss: 2.673769, top_1: 0.631953, top_k: 0.834453, samples/s: 2908.038 1612043115.4652438
train: epoch 118, iter 900, loss: 2.414680, top_1: 0.641563, top_k: 0.840625, samples/s: 2987.451 1612043124.0344253
train: epoch 118, iter 1000, loss: 2.697871, top_1: 0.639570, top_k: 0.843828, samples/s: 2920.075 1612043132.8013382
train: epoch 118, iter 1100, loss: 2.623539, top_1: 0.640898, top_k: 0.842734, samples/s: 3006.782 1612043141.3154163
train: epoch 118, iter 1200, loss: 2.528237, top_1: 0.637344, top_k: 0.840625, samples/s: 2964.256 1612043149.9516613
train: epoch 118, iter 1300, loss: 2.446045, top_1: 0.636523, top_k: 0.837891, samples/s: 3012.222 1612043158.4503632
train: epoch 118, iter 1400, loss: 2.569612, top_1: 0.637930, top_k: 0.840586, samples/s: 2992.085 1612043167.0062745
train: epoch 118, iter 1500, loss: 2.436172, top_1: 0.632500, top_k: 0.836562, samples/s: 2978.082 1612043175.602389
train: epoch 118, iter 1600, loss: 2.558847, top_1: 0.636250, top_k: 0.841133, samples/s: 2998.842 1612043184.139009
train: epoch 118, iter 1700, loss: 2.439703, top_1: 0.634922, top_k: 0.839375, samples/s: 2959.526 1612043192.7890716
train: epoch 118, iter 1800, loss: 2.647071, top_1: 0.630703, top_k: 0.835508, samples/s: 2946.533 1612043201.4773366
train: epoch 118, iter 1900, loss: 2.546904, top_1: 0.637773, top_k: 0.840039, samples/s: 2999.532 1612043210.011891
train: epoch 118, iter 2000, loss: 2.545665, top_1: 0.638672, top_k: 0.837930, samples/s: 2954.700 1612043218.67605
train: epoch 118, iter 2100, loss: 2.522633, top_1: 0.634258, top_k: 0.836641, samples/s: 2969.089 1612043227.2983184
train: epoch 118, iter 2200, loss: 2.359056, top_1: 0.632422, top_k: 0.837227, samples/s: 2992.946 1612043235.8516958
train: epoch 118, iter 2300, loss: 2.527429, top_1: 0.636328, top_k: 0.841719, samples/s: 2958.002 1612043244.5061607
train: epoch 118, iter 2400, loss: 2.508307, top_1: 0.638594, top_k: 0.840508, samples/s: 2987.802 1612043253.0743923
train: epoch 118, iter 2500, loss: 2.440248, top_1: 0.638203, top_k: 0.839727, samples/s: 2968.377 1612043261.6986542
train: epoch 118, iter 2600, loss: 2.567900, top_1: 0.635664, top_k: 0.836562, samples/s: 2958.793 1612043270.3509064
train: epoch 118, iter 2700, loss: 2.748387, top_1: 0.638242, top_k: 0.838750, samples/s: 2952.035 1612043279.0227375
train: epoch 118, iter 2800, loss: 2.686491, top_1: 0.639961, top_k: 0.839961, samples/s: 2972.184 1612043287.6360085
train: epoch 118, iter 2900, loss: 2.610285, top_1: 0.631211, top_k: 0.837734, samples/s: 2974.585 1612043296.2422624
train: epoch 118, iter 3000, loss: 2.376943, top_1: 0.636719, top_k: 0.841250, samples/s: 2988.470 1612043304.8084645
train: epoch 118, iter 3100, loss: 2.486355, top_1: 0.628008, top_k: 0.835273, samples/s: 2971.749 1612043313.4228597
train: epoch 118, iter 3200, loss: 2.517335, top_1: 0.629609, top_k: 0.839805, samples/s: 2999.986 1612043321.956268
train: epoch 118, iter 3300, loss: 2.418618, top_1: 0.640273, top_k: 0.838711, samples/s: 2953.906 1612043330.622793
train: epoch 118, iter 3400, loss: 2.735715, top_1: 0.631758, top_k: 0.832070, samples/s: 2970.312 1612043339.2413719
train: epoch 118, iter 3500, loss: 2.381841, top_1: 0.637422, top_k: 0.836641, samples/s: 2970.032 1612043347.8607993
train: epoch 118, iter 3600, loss: 2.322947, top_1: 0.639414, top_k: 0.838320, samples/s: 2974.311 1612043356.4678473
train: epoch 118, iter 3700, loss: 2.436074, top_1: 0.627969, top_k: 0.836094, samples/s: 2986.853 1612043365.0387511
train: epoch 118, iter 3800, loss: 2.542566, top_1: 0.638555, top_k: 0.840547, samples/s: 2975.909 1612043373.6413047
train: epoch 118, iter 3900, loss: 2.573779, top_1: 0.627539, top_k: 0.836953, samples/s: 2967.200 1612043382.268801
train: epoch 118, iter 4000, loss: 2.481072, top_1: 0.635039, top_k: 0.838086, samples/s: 2944.575 1612043390.9627962
train: epoch 118, iter 4100, loss: 2.416595, top_1: 0.635273, top_k: 0.836836, samples/s: 2948.399 1612043399.6454532
train: epoch 118, iter 4200, loss: 2.505075, top_1: 0.633633, top_k: 0.836250, samples/s: 2986.233 1612043408.21813
train: epoch 118, iter 4300, loss: 2.583621, top_1: 0.632383, top_k: 0.837344, samples/s: 2986.987 1612043416.7886293
train: epoch 118, iter 4400, loss: 2.520790, top_1: 0.632148, top_k: 0.838750, samples/s: 3013.810 1612043425.2828789
train: epoch 118, iter 4500, loss: 2.628674, top_1: 0.636836, top_k: 0.838281, samples/s: 2962.581 1612043433.9240565
train: epoch 118, iter 4600, loss: 2.576939, top_1: 0.633320, top_k: 0.837070, samples/s: 2990.780 1612043442.4836185
train: epoch 118, iter 4700, loss: 2.540221, top_1: 0.633828, top_k: 0.836641, samples/s: 2972.454 1612043451.0960524
train: epoch 118, iter 4800, loss: 2.588984, top_1: 0.639141, top_k: 0.840508, samples/s: 2937.443 1612043459.8110828
train: epoch 118, iter 4900, loss: 2.575974, top_1: 0.636250, top_k: 0.839648, samples/s: 2985.754 1612043468.3851995
train: epoch 118, iter 5000, loss: 2.480866, top_1: 0.638711, top_k: 0.839375, samples/s: 2961.961 1612043477.0281136
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_118.
validation: epoch 118, iter 195, top_1: 0.669912, top_k: 0.876202, samples/s: 3095.054 1612043493.396744
train: epoch 119, iter 100, loss: 2.526085, top_1: 0.644102, top_k: 0.844688, samples/s: 2960.385 1612043518.1163623
train: epoch 119, iter 200, loss: 2.749068, top_1: 0.641602, top_k: 0.842266, samples/s: 3024.011 1612043526.5819561
train: epoch 119, iter 300, loss: 2.311267, top_1: 0.637695, top_k: 0.840625, samples/s: 2981.398 1612043535.1685479
train: epoch 119, iter 400, loss: 2.681011, top_1: 0.637344, top_k: 0.839570, samples/s: 2967.228 1612043543.7960799
train: epoch 119, iter 500, loss: 2.453097, top_1: 0.643672, top_k: 0.845742, samples/s: 3002.397 1612043552.322703
train: epoch 119, iter 600, loss: 2.390405, top_1: 0.636953, top_k: 0.837187, samples/s: 2996.237 1612043560.866663
train: epoch 119, iter 700, loss: 2.488147, top_1: 0.644375, top_k: 0.843828, samples/s: 3017.362 1612043569.3509052
train: epoch 119, iter 800, loss: 2.545705, top_1: 0.637344, top_k: 0.844258, samples/s: 3026.604 1612043577.8093233
train: epoch 119, iter 900, loss: 2.432453, top_1: 0.642031, top_k: 0.846055, samples/s: 2931.604 1612043586.5416505
train: epoch 119, iter 1000, loss: 2.478444, top_1: 0.639766, top_k: 0.841289, samples/s: 3002.745 1612043595.0672379
train: epoch 119, iter 1100, loss: 2.484939, top_1: 0.637930, top_k: 0.840039, samples/s: 3021.745 1612043603.5392015
train: epoch 119, iter 1200, loss: 2.476492, top_1: 0.644531, top_k: 0.845234, samples/s: 2960.279 1612043612.1869876
train: epoch 119, iter 1300, loss: 2.727334, top_1: 0.642813, top_k: 0.840859, samples/s: 2939.416 1612043620.8961494
train: epoch 119, iter 1400, loss: 2.609942, top_1: 0.636367, top_k: 0.840195, samples/s: 2926.855 1612043629.642772
train: epoch 119, iter 1500, loss: 2.405381, top_1: 0.642617, top_k: 0.843516, samples/s: 2943.194 1612043638.3408513
train: epoch 119, iter 1600, loss: 2.681701, top_1: 0.639883, top_k: 0.843945, samples/s: 2954.226 1612043647.006451
train: epoch 119, iter 1700, loss: 2.497507, top_1: 0.642031, top_k: 0.843789, samples/s: 3018.381 1612043655.4877074
train: epoch 119, iter 1800, loss: 2.396819, top_1: 0.639219, top_k: 0.842852, samples/s: 3006.924 1612043664.0013907
train: epoch 119, iter 1900, loss: 2.528050, top_1: 0.638711, top_k: 0.840977, samples/s: 2941.473 1612043672.704513
train: epoch 119, iter 2000, loss: 2.321454, top_1: 0.637773, top_k: 0.841211, samples/s: 2973.746 1612043681.3131824
train: epoch 119, iter 2100, loss: 2.643762, top_1: 0.637227, top_k: 0.841289, samples/s: 2988.224 1612043689.8801467
train: epoch 119, iter 2200, loss: 2.680898, top_1: 0.638828, top_k: 0.841953, samples/s: 2978.481 1612043698.4751172
train: epoch 119, iter 2300, loss: 2.554423, top_1: 0.640352, top_k: 0.841992, samples/s: 2982.716 1612043707.0578966
train: epoch 119, iter 2400, loss: 2.544837, top_1: 0.634609, top_k: 0.840625, samples/s: 2959.675 1612043715.7075748
train: epoch 119, iter 2500, loss: 2.493580, top_1: 0.636055, top_k: 0.839219, samples/s: 2979.253 1612043724.3002946
train: epoch 119, iter 2600, loss: 2.547742, top_1: 0.638398, top_k: 0.843086, samples/s: 2969.948 1612043732.919978
train: epoch 119, iter 2700, loss: 2.591388, top_1: 0.638008, top_k: 0.838750, samples/s: 2983.201 1612043741.501391
train: epoch 119, iter 2800, loss: 2.380167, top_1: 0.635078, top_k: 0.837930, samples/s: 2967.240 1612043750.1288626
train: epoch 119, iter 2900, loss: 2.499022, top_1: 0.639961, top_k: 0.840352, samples/s: 2910.270 1612043758.9253094
train: epoch 119, iter 3000, loss: 2.610512, top_1: 0.644648, top_k: 0.843086, samples/s: 2984.081 1612043767.5041625
train: epoch 119, iter 3100, loss: 2.749194, top_1: 0.636094, top_k: 0.839063, samples/s: 2936.358 1612043776.2224443
train: epoch 119, iter 3200, loss: 2.560466, top_1: 0.638437, top_k: 0.841797, samples/s: 2942.043 1612043784.9239075
train: epoch 119, iter 3300, loss: 2.448431, top_1: 0.637539, top_k: 0.838516, samples/s: 2970.106 1612043793.5431166
train: epoch 119, iter 3400, loss: 2.479431, top_1: 0.636445, top_k: 0.835859, samples/s: 2947.021 1612043802.2298436
train: epoch 119, iter 3500, loss: 2.404113, top_1: 0.637148, top_k: 0.840703, samples/s: 2980.683 1612043810.8185737
train: epoch 119, iter 3600, loss: 2.616822, top_1: 0.635859, top_k: 0.839141, samples/s: 2992.905 1612043819.3720412
train: epoch 119, iter 3700, loss: 2.391225, top_1: 0.637852, top_k: 0.836445, samples/s: 2957.220 1612043828.028975
train: epoch 119, iter 3800, loss: 2.382549, top_1: 0.638437, top_k: 0.839219, samples/s: 2967.671 1612043836.6562974
train: epoch 119, iter 3900, loss: 2.470953, top_1: 0.637305, top_k: 0.841250, samples/s: 2956.357 1612043845.3144171
train: epoch 119, iter 4000, loss: 2.485678, top_1: 0.635898, top_k: 0.839023, samples/s: 2988.536 1612043853.880893
train: epoch 119, iter 4100, loss: 2.458974, top_1: 0.638359, top_k: 0.841289, samples/s: 2993.906 1612043862.431214
train: epoch 119, iter 4200, loss: 2.454162, top_1: 0.635078, top_k: 0.838750, samples/s: 2976.616 1612043871.0315244
train: epoch 119, iter 4300, loss: 2.445355, top_1: 0.640625, top_k: 0.841562, samples/s: 2995.526 1612043879.5777006
train: epoch 119, iter 4400, loss: 2.547262, top_1: 0.631523, top_k: 0.839414, samples/s: 2888.420 1612043888.440615
train: epoch 119, iter 4500, loss: 2.636958, top_1: 0.637578, top_k: 0.839609, samples/s: 2994.898 1612043896.9884913
train: epoch 119, iter 4600, loss: 2.658567, top_1: 0.636445, top_k: 0.841836, samples/s: 2989.844 1612043905.5508015
train: epoch 119, iter 4700, loss: 2.480706, top_1: 0.635312, top_k: 0.841797, samples/s: 2969.931 1612043914.170524
train: epoch 119, iter 4800, loss: 2.734256, top_1: 0.636914, top_k: 0.841875, samples/s: 3013.023 1612043922.6669557
train: epoch 119, iter 4900, loss: 2.646804, top_1: 0.636523, top_k: 0.838945, samples/s: 2965.275 1612043931.3003018
train: epoch 119, iter 5000, loss: 2.430076, top_1: 0.640781, top_k: 0.843281, samples/s: 2917.852 1612043940.07385
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_119.
validation: epoch 119, iter 195, top_1: 0.666987, top_k: 0.873057, samples/s: 3044.214 1612043956.695816
train: epoch 120, iter 100, loss: 2.415010, top_1: 0.645898, top_k: 0.848242, samples/s: 2959.397 1612043981.7415142
train: epoch 120, iter 200, loss: 2.337720, top_1: 0.649687, top_k: 0.849258, samples/s: 2978.444 1612043990.336538
train: epoch 120, iter 300, loss: 2.376940, top_1: 0.645234, top_k: 0.843906, samples/s: 2888.399 1612043999.1996543
train: epoch 120, iter 400, loss: 2.242267, top_1: 0.645391, top_k: 0.843047, samples/s: 2958.513 1612044007.85272
train: epoch 120, iter 500, loss: 2.361335, top_1: 0.645039, top_k: 0.845391, samples/s: 3013.736 1612044016.3470109
train: epoch 120, iter 600, loss: 2.715918, top_1: 0.648789, top_k: 0.845352, samples/s: 2997.953 1612044024.8862336
train: epoch 120, iter 700, loss: 2.472521, top_1: 0.643633, top_k: 0.840000, samples/s: 2994.416 1612044033.4355426
train: epoch 120, iter 800, loss: 2.422824, top_1: 0.642344, top_k: 0.842305, samples/s: 3026.450 1612044041.8943424
train: epoch 120, iter 900, loss: 2.640359, top_1: 0.644141, top_k: 0.841875, samples/s: 2945.582 1612044050.5853581
train: epoch 120, iter 1000, loss: 2.302338, top_1: 0.639141, top_k: 0.841992, samples/s: 2937.911 1612044059.298883
train: epoch 120, iter 1100, loss: 2.434521, top_1: 0.644336, top_k: 0.841836, samples/s: 2987.652 1612044067.867491
train: epoch 120, iter 1200, loss: 2.556574, top_1: 0.646680, top_k: 0.844141, samples/s: 3016.433 1612044076.354447
train: epoch 120, iter 1300, loss: 2.562459, top_1: 0.638984, top_k: 0.839922, samples/s: 2948.975 1612044085.0353343
train: epoch 120, iter 1400, loss: 2.580036, top_1: 0.638594, top_k: 0.845781, samples/s: 2971.020 1612044093.6519198
train: epoch 120, iter 1500, loss: 2.477386, top_1: 0.645156, top_k: 0.843437, samples/s: 2965.253 1612044102.2852395
train: epoch 120, iter 1600, loss: 2.301346, top_1: 0.643945, top_k: 0.845195, samples/s: 2952.722 1612044110.9551892
train: epoch 120, iter 1700, loss: 2.423267, top_1: 0.636016, top_k: 0.844258, samples/s: 2959.726 1612044119.6047122
train: epoch 120, iter 1800, loss: 2.379437, top_1: 0.640430, top_k: 0.840664, samples/s: 2887.531 1612044128.4703274
train: epoch 120, iter 1900, loss: 2.546799, top_1: 0.637773, top_k: 0.839336, samples/s: 2853.594 1612044137.4415
train: epoch 120, iter 2000, loss: 2.419300, top_1: 0.643125, top_k: 0.843320, samples/s: 2984.448 1612044146.0193913
train: epoch 120, iter 2100, loss: 2.419321, top_1: 0.638203, top_k: 0.842266, samples/s: 2921.348 1612044154.7823627
train: epoch 120, iter 2200, loss: 2.396832, top_1: 0.644102, top_k: 0.843789, samples/s: 2926.220 1612044163.5309548
train: epoch 120, iter 2300, loss: 2.360175, top_1: 0.640273, top_k: 0.843516, samples/s: 3030.968 1612044171.9769907
train: epoch 120, iter 2400, loss: 2.548291, top_1: 0.638789, top_k: 0.839883, samples/s: 2883.295 1612044180.8557253
train: epoch 120, iter 2500, loss: 2.578614, top_1: 0.639375, top_k: 0.839805, samples/s: 2910.819 1612044189.650524
train: epoch 120, iter 2600, loss: 2.453144, top_1: 0.643320, top_k: 0.844727, samples/s: 2975.276 1612044198.2548134
train: epoch 120, iter 2700, loss: 2.405151, top_1: 0.638242, top_k: 0.842852, samples/s: 2980.480 1612044206.8441188
train: epoch 120, iter 2800, loss: 2.437010, top_1: 0.639727, top_k: 0.844961, samples/s: 2977.922 1612044215.4405508
train: epoch 120, iter 2900, loss: 2.498333, top_1: 0.642305, top_k: 0.842422, samples/s: 2999.185 1612044223.9762475
train: epoch 120, iter 3000, loss: 2.577513, top_1: 0.642109, top_k: 0.843477, samples/s: 2945.723 1612044232.66678
train: epoch 120, iter 3100, loss: 2.500669, top_1: 0.637773, top_k: 0.843242, samples/s: 2995.989 1612044241.2115545
train: epoch 120, iter 3200, loss: 2.555874, top_1: 0.636953, top_k: 0.836914, samples/s: 3012.342 1612044249.7099712
train: epoch 120, iter 3300, loss: 2.601677, top_1: 0.639492, top_k: 0.843047, samples/s: 2958.667 1612044258.3625178
train: epoch 120, iter 3400, loss: 2.607033, top_1: 0.639180, top_k: 0.843594, samples/s: 3004.606 1612044266.882763
train: epoch 120, iter 3500, loss: 2.510722, top_1: 0.637578, top_k: 0.839023, samples/s: 2983.639 1612044275.4628303
train: epoch 120, iter 3600, loss: 2.559129, top_1: 0.634844, top_k: 0.843047, samples/s: 2977.613 1612044284.060327
train: epoch 120, iter 3700, loss: 2.661794, top_1: 0.637930, top_k: 0.840586, samples/s: 2949.700 1612044292.7392204
train: epoch 120, iter 3800, loss: 2.625254, top_1: 0.634961, top_k: 0.839727, samples/s: 2997.177 1612044301.2806466
train: epoch 120, iter 3900, loss: 2.397350, top_1: 0.640547, top_k: 0.843047, samples/s: 2950.446 1612044309.9572966
train: epoch 120, iter 4000, loss: 2.354170, top_1: 0.639141, top_k: 0.842031, samples/s: 2936.118 1612044318.6762316
train: epoch 120, iter 4100, loss: 2.423263, top_1: 0.637031, top_k: 0.840039, samples/s: 2989.688 1612044327.2389324
train: epoch 120, iter 4200, loss: 2.343864, top_1: 0.643008, top_k: 0.844180, samples/s: 2983.154 1612044335.8204923
train: epoch 120, iter 4300, loss: 2.471860, top_1: 0.637500, top_k: 0.841211, samples/s: 2960.338 1612044344.4681923
train: epoch 120, iter 4400, loss: 2.417583, top_1: 0.641172, top_k: 0.839844, samples/s: 2987.024 1612044353.0385485
train: epoch 120, iter 4500, loss: 2.520375, top_1: 0.639219, top_k: 0.837344, samples/s: 2976.664 1612044361.6387818
train: epoch 120, iter 4600, loss: 2.423260, top_1: 0.643711, top_k: 0.842422, samples/s: 2983.286 1612044370.2199488
train: epoch 120, iter 4700, loss: 2.558228, top_1: 0.644102, top_k: 0.845742, samples/s: 2928.567 1612044378.9614096
train: epoch 120, iter 4800, loss: 2.495689, top_1: 0.632109, top_k: 0.837930, samples/s: 2988.382 1612044387.5279832
train: epoch 120, iter 4900, loss: 2.452992, top_1: 0.640898, top_k: 0.841523, samples/s: 2914.885 1612044396.310401
train: epoch 120, iter 5000, loss: 2.486714, top_1: 0.643359, top_k: 0.843320, samples/s: 2983.771 1612044404.8902347
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_120.
validation: epoch 120, iter 195, top_1: 0.673698, top_k: 0.877845, samples/s: 2959.014 1612044421.9542315
train: epoch 121, iter 100, loss: 2.568049, top_1: 0.648438, top_k: 0.844648, samples/s: 2960.177 1612044446.4937994
train: epoch 121, iter 200, loss: 2.429892, top_1: 0.649844, top_k: 0.851211, samples/s: 2998.712 1612044455.0306845
train: epoch 121, iter 300, loss: 2.395887, top_1: 0.653594, top_k: 0.848086, samples/s: 2979.220 1612044463.6235504
train: epoch 121, iter 400, loss: 2.457903, top_1: 0.646484, top_k: 0.845703, samples/s: 2991.329 1612044472.1816924
train: epoch 121, iter 500, loss: 2.500623, top_1: 0.646523, top_k: 0.846250, samples/s: 3030.956 1612044480.6278794
train: epoch 121, iter 600, loss: 2.575025, top_1: 0.648242, top_k: 0.847383, samples/s: 2918.148 1612044489.4004884
train: epoch 121, iter 700, loss: 2.553462, top_1: 0.649297, top_k: 0.847734, samples/s: 3015.584 1612044497.8900087
train: epoch 121, iter 800, loss: 2.440134, top_1: 0.648359, top_k: 0.849570, samples/s: 3000.707 1612044506.421036
train: epoch 121, iter 900, loss: 2.637468, top_1: 0.647930, top_k: 0.846602, samples/s: 2979.257 1612044515.0142229
train: epoch 121, iter 1000, loss: 2.576213, top_1: 0.651758, top_k: 0.843750, samples/s: 2989.608 1612044523.5767913
train: epoch 121, iter 1100, loss: 2.338336, top_1: 0.641445, top_k: 0.840469, samples/s: 2940.431 1612044532.2839644
train: epoch 121, iter 1200, loss: 2.579599, top_1: 0.647578, top_k: 0.844336, samples/s: 2989.197 1612044540.8472226
train: epoch 121, iter 1300, loss: 2.598570, top_1: 0.649062, top_k: 0.846914, samples/s: 2971.898 1612044549.4616659
train: epoch 121, iter 1400, loss: 2.439877, top_1: 0.645273, top_k: 0.843477, samples/s: 2996.635 1612044558.004114
train: epoch 121, iter 1500, loss: 2.428243, top_1: 0.647109, top_k: 0.846641, samples/s: 2992.721 1612044566.5582576
train: epoch 121, iter 1600, loss: 2.391277, top_1: 0.646328, top_k: 0.846328, samples/s: 2991.794 1612044575.1148572
train: epoch 121, iter 1700, loss: 2.602516, top_1: 0.640977, top_k: 0.842500, samples/s: 3025.219 1612044583.5771074
train: epoch 121, iter 1800, loss: 2.561091, top_1: 0.646133, top_k: 0.844297, samples/s: 2992.620 1612044592.1314847
train: epoch 121, iter 1900, loss: 2.476539, top_1: 0.647695, top_k: 0.848320, samples/s: 2960.597 1612044600.778421
train: epoch 121, iter 2000, loss: 2.456059, top_1: 0.639883, top_k: 0.841094, samples/s: 2997.846 1612044609.3179474
train: epoch 121, iter 2100, loss: 2.474072, top_1: 0.641836, top_k: 0.845039, samples/s: 2988.614 1612044617.8838315
train: epoch 121, iter 2200, loss: 2.391274, top_1: 0.640508, top_k: 0.842891, samples/s: 2973.895 1612044626.4920232
train: epoch 121, iter 2300, loss: 2.404544, top_1: 0.640977, top_k: 0.842734, samples/s: 2961.423 1612044635.1364398
train: epoch 121, iter 2400, loss: 2.534978, top_1: 0.642539, top_k: 0.845586, samples/s: 2943.187 1612044643.8346136
train: epoch 121, iter 2500, loss: 2.539683, top_1: 0.647539, top_k: 0.843828, samples/s: 3019.254 1612044652.3134036
train: epoch 121, iter 2600, loss: 2.461598, top_1: 0.647422, top_k: 0.846758, samples/s: 2981.527 1612044660.8996167
train: epoch 121, iter 2700, loss: 2.544827, top_1: 0.642617, top_k: 0.840547, samples/s: 2969.850 1612044669.5195873
train: epoch 121, iter 2800, loss: 2.762464, top_1: 0.640781, top_k: 0.839492, samples/s: 2975.382 1612044678.1235054
train: epoch 121, iter 2900, loss: 2.569722, top_1: 0.642773, top_k: 0.841797, samples/s: 3000.582 1612044686.6552367
train: epoch 121, iter 3000, loss: 2.627343, top_1: 0.645898, top_k: 0.844141, samples/s: 2956.580 1612044695.3139327
train: epoch 121, iter 3100, loss: 2.566595, top_1: 0.641992, top_k: 0.845664, samples/s: 2974.002 1612044703.921903
train: epoch 121, iter 3200, loss: 2.472507, top_1: 0.642422, top_k: 0.843945, samples/s: 2975.580 1612044712.5252712
train: epoch 121, iter 3300, loss: 2.586096, top_1: 0.638320, top_k: 0.844453, samples/s: 3014.740 1612044721.0167537
train: epoch 121, iter 3400, loss: 2.475445, top_1: 0.640625, top_k: 0.843633, samples/s: 2958.049 1612044729.6710973
train: epoch 121, iter 3500, loss: 2.410899, top_1: 0.635430, top_k: 0.841641, samples/s: 2939.907 1612044738.378993
train: epoch 121, iter 3600, loss: 2.419411, top_1: 0.644492, top_k: 0.841953, samples/s: 2997.072 1612044746.920701
train: epoch 121, iter 3700, loss: 2.668929, top_1: 0.645586, top_k: 0.845234, samples/s: 2966.452 1612044755.5504725
train: epoch 121, iter 3800, loss: 2.524417, top_1: 0.641680, top_k: 0.841836, samples/s: 2918.803 1612044764.3211837
train: epoch 121, iter 3900, loss: 2.535761, top_1: 0.643125, top_k: 0.842812, samples/s: 3005.518 1612044772.8387828
train: epoch 121, iter 4000, loss: 2.541184, top_1: 0.641523, top_k: 0.843945, samples/s: 2982.265 1612044781.4228618
train: epoch 121, iter 4100, loss: 2.519171, top_1: 0.639609, top_k: 0.842539, samples/s: 2936.141 1612044790.1418095
train: epoch 121, iter 4200, loss: 2.427285, top_1: 0.644375, top_k: 0.846758, samples/s: 2921.808 1612044798.903491
train: epoch 121, iter 4300, loss: 2.580210, top_1: 0.632500, top_k: 0.838398, samples/s: 2951.107 1612044807.5781808
train: epoch 121, iter 4400, loss: 2.362076, top_1: 0.644375, top_k: 0.845117, samples/s: 2991.101 1612044816.1368897
train: epoch 121, iter 4500, loss: 2.421130, top_1: 0.642852, top_k: 0.842422, samples/s: 2990.828 1612044824.6964917
train: epoch 121, iter 4600, loss: 2.811679, top_1: 0.647852, top_k: 0.843711, samples/s: 2946.238 1612044833.3854465
train: epoch 121, iter 4700, loss: 2.505531, top_1: 0.645469, top_k: 0.843281, samples/s: 2999.444 1612044841.920751
train: epoch 121, iter 4800, loss: 2.495949, top_1: 0.637930, top_k: 0.840938, samples/s: 2912.090 1612044850.7112925
train: epoch 121, iter 4900, loss: 2.520616, top_1: 0.641992, top_k: 0.840117, samples/s: 2857.825 1612044859.6692605
train: epoch 121, iter 5000, loss: 2.374386, top_1: 0.649648, top_k: 0.844023, samples/s: 2923.412 1612044868.4260318
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_121.
validation: epoch 121, iter 195, top_1: 0.674119, top_k: 0.877865, samples/s: 3069.816 1612044884.9286392
train: epoch 122, iter 100, loss: 2.414912, top_1: 0.650820, top_k: 0.850352, samples/s: 2969.432 1612044909.9326959
train: epoch 122, iter 200, loss: 2.486343, top_1: 0.649766, top_k: 0.845664, samples/s: 2987.961 1612044918.5004575
train: epoch 122, iter 300, loss: 2.501308, top_1: 0.649961, top_k: 0.848437, samples/s: 2968.514 1612044927.1242514
train: epoch 122, iter 400, loss: 2.410776, top_1: 0.652305, top_k: 0.849570, samples/s: 3004.944 1612044935.6435194
train: epoch 122, iter 500, loss: 2.575666, top_1: 0.652617, top_k: 0.851367, samples/s: 2954.892 1612044944.307217
train: epoch 122, iter 600, loss: 2.527720, top_1: 0.647266, top_k: 0.846328, samples/s: 2993.537 1612044952.8589017
train: epoch 122, iter 700, loss: 2.368904, top_1: 0.643398, top_k: 0.846992, samples/s: 3002.601 1612044961.384824
train: epoch 122, iter 800, loss: 2.434542, top_1: 0.653516, top_k: 0.849492, samples/s: 2975.754 1612044969.9881644
train: epoch 122, iter 900, loss: 2.492688, top_1: 0.646641, top_k: 0.844883, samples/s: 3010.636 1612044978.4909024
train: epoch 122, iter 1000, loss: 2.537044, top_1: 0.642969, top_k: 0.842148, samples/s: 3013.852 1612044986.9849777
train: epoch 122, iter 1100, loss: 2.623046, top_1: 0.646680, top_k: 0.841367, samples/s: 2907.604 1612044995.7895808
train: epoch 122, iter 1200, loss: 2.569016, top_1: 0.647656, top_k: 0.844805, samples/s: 2987.035 1612045004.3598595
train: epoch 122, iter 1300, loss: 2.464083, top_1: 0.648242, top_k: 0.845703, samples/s: 3009.613 1612045012.8659265
train: epoch 122, iter 1400, loss: 2.713177, top_1: 0.645234, top_k: 0.846016, samples/s: 2977.696 1612045021.4631748
train: epoch 122, iter 1500, loss: 2.401758, top_1: 0.644961, top_k: 0.846289, samples/s: 2996.959 1612045030.0052018
train: epoch 122, iter 1600, loss: 2.345934, top_1: 0.645078, top_k: 0.847266, samples/s: 2979.644 1612045038.596802
train: epoch 122, iter 1700, loss: 2.502743, top_1: 0.648828, top_k: 0.846680, samples/s: 2980.068 1612045047.1872807
train: epoch 122, iter 1800, loss: 2.701052, top_1: 0.642813, top_k: 0.844766, samples/s: 2891.504 1612045056.0408163
train: epoch 122, iter 1900, loss: 2.319397, top_1: 0.652383, top_k: 0.851602, samples/s: 2991.811 1612045064.5974567
train: epoch 122, iter 2000, loss: 2.487082, top_1: 0.645000, top_k: 0.846562, samples/s: 2985.518 1612045073.1723406
train: epoch 122, iter 2100, loss: 2.421988, top_1: 0.648711, top_k: 0.846953, samples/s: 2985.536 1612045081.7468197
train: epoch 122, iter 2200, loss: 2.562359, top_1: 0.651641, top_k: 0.848359, samples/s: 2943.539 1612045090.4438653
train: epoch 122, iter 2300, loss: 2.384301, top_1: 0.653047, top_k: 0.846953, samples/s: 2962.384 1612045099.0855255
train: epoch 122, iter 2400, loss: 2.784039, top_1: 0.643164, top_k: 0.846094, samples/s: 2991.003 1612045107.6445272
train: epoch 122, iter 2500, loss: 2.411397, top_1: 0.647109, top_k: 0.847070, samples/s: 2942.065 1612045116.3459322
train: epoch 122, iter 2600, loss: 2.345238, top_1: 0.645977, top_k: 0.847695, samples/s: 2976.342 1612045124.9470696
train: epoch 122, iter 2700, loss: 2.491877, top_1: 0.642930, top_k: 0.846602, samples/s: 2998.418 1612045133.4849014
train: epoch 122, iter 2800, loss: 2.611581, top_1: 0.647773, top_k: 0.846641, samples/s: 2986.446 1612045142.0571482
train: epoch 122, iter 2900, loss: 2.410159, top_1: 0.645195, top_k: 0.846914, samples/s: 2895.301 1612045150.8988822
train: epoch 122, iter 3000, loss: 2.524925, top_1: 0.648906, top_k: 0.850703, samples/s: 2995.357 1612045159.4454503
train: epoch 122, iter 3100, loss: 2.567882, top_1: 0.643086, top_k: 0.845625, samples/s: 2985.586 1612045168.0199995
train: epoch 122, iter 3200, loss: 2.637268, top_1: 0.646328, top_k: 0.845742, samples/s: 3000.688 1612045176.5513701
train: epoch 122, iter 3300, loss: 2.524031, top_1: 0.641914, top_k: 0.848086, samples/s: 2938.775 1612045185.2625122
train: epoch 122, iter 3400, loss: 2.726823, top_1: 0.642578, top_k: 0.845859, samples/s: 2984.970 1612045193.8387413
train: epoch 122, iter 3500, loss: 2.243311, top_1: 0.647500, top_k: 0.845391, samples/s: 2994.114 1612045202.3889296
train: epoch 122, iter 3600, loss: 2.347832, top_1: 0.644023, top_k: 0.844688, samples/s: 2985.844 1612045210.9626746
train: epoch 122, iter 3700, loss: 2.344709, top_1: 0.643711, top_k: 0.844375, samples/s: 2961.616 1612045219.6065261
train: epoch 122, iter 3800, loss: 2.383580, top_1: 0.646523, top_k: 0.844648, samples/s: 2910.872 1612045228.4012053
train: epoch 122, iter 3900, loss: 2.577559, top_1: 0.641211, top_k: 0.843594, samples/s: 2985.751 1612045236.975366
train: epoch 122, iter 4000, loss: 2.594910, top_1: 0.643242, top_k: 0.844258, samples/s: 2944.928 1612045245.6682193
train: epoch 122, iter 4100, loss: 2.301494, top_1: 0.642930, top_k: 0.843437, samples/s: 2959.999 1612045254.3168113
train: epoch 122, iter 4200, loss: 2.535028, top_1: 0.643203, top_k: 0.845469, samples/s: 2961.269 1612045262.9617698
train: epoch 122, iter 4300, loss: 2.410231, top_1: 0.645117, top_k: 0.841367, samples/s: 2993.903 1612045271.5124583
train: epoch 122, iter 4400, loss: 2.333968, top_1: 0.649375, top_k: 0.846133, samples/s: 2908.609 1612045280.3139265
train: epoch 122, iter 4500, loss: 2.492132, top_1: 0.646484, top_k: 0.841523, samples/s: 2974.633 1612045288.9201236
train: epoch 122, iter 4600, loss: 2.460091, top_1: 0.645000, top_k: 0.840508, samples/s: 2962.193 1612045297.5622976
train: epoch 122, iter 4700, loss: 2.648903, top_1: 0.643906, top_k: 0.840430, samples/s: 2973.145 1612045306.1727424
train: epoch 122, iter 4800, loss: 2.473731, top_1: 0.647344, top_k: 0.843555, samples/s: 2984.779 1612045314.7495842
train: epoch 122, iter 4900, loss: 2.491627, top_1: 0.642031, top_k: 0.844258, samples/s: 2949.495 1612045323.4289994
train: epoch 122, iter 5000, loss: 2.580287, top_1: 0.645117, top_k: 0.845898, samples/s: 2974.369 1612045332.0358765
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_122.
validation: epoch 122, iter 195, top_1: 0.675821, top_k: 0.880028, samples/s: 2899.476 1612045349.5232637
train: epoch 123, iter 100, loss: 2.454878, top_1: 0.652305, top_k: 0.851172, samples/s: 2987.153 1612045374.137018
train: epoch 123, iter 200, loss: 2.450051, top_1: 0.653516, top_k: 0.851992, samples/s: 2951.571 1612045382.8107026
train: epoch 123, iter 300, loss: 2.453312, top_1: 0.644375, top_k: 0.844453, samples/s: 2965.302 1612045391.443537
train: epoch 123, iter 400, loss: 2.406705, top_1: 0.651211, top_k: 0.850781, samples/s: 2997.711 1612045399.9834661
train: epoch 123, iter 500, loss: 2.424510, top_1: 0.652656, top_k: 0.845156, samples/s: 2907.328 1612045408.7888098
train: epoch 123, iter 600, loss: 2.535543, top_1: 0.654219, top_k: 0.850742, samples/s: 2877.041 1612045417.6867585
train: epoch 123, iter 700, loss: 2.495790, top_1: 0.649648, top_k: 0.851328, samples/s: 2984.198 1612045426.2652674
train: epoch 123, iter 800, loss: 2.375340, top_1: 0.654844, top_k: 0.852031, samples/s: 2981.851 1612045434.8506367
train: epoch 123, iter 900, loss: 2.479885, top_1: 0.658398, top_k: 0.854414, samples/s: 3038.106 1612045443.276854
train: epoch 123, iter 1000, loss: 2.353250, top_1: 0.653906, top_k: 0.849648, samples/s: 2989.834 1612045451.839274
train: epoch 123, iter 1100, loss: 2.391930, top_1: 0.653359, top_k: 0.852227, samples/s: 3016.274 1612045460.3264773
train: epoch 123, iter 1200, loss: 2.511274, top_1: 0.650352, top_k: 0.849336, samples/s: 2950.898 1612045469.001795
train: epoch 123, iter 1300, loss: 2.358447, top_1: 0.649766, top_k: 0.851562, samples/s: 2943.219 1612045477.699766
train: epoch 123, iter 1400, loss: 2.442621, top_1: 0.648438, top_k: 0.848672, samples/s: 2993.282 1612045486.252432
train: epoch 123, iter 1500, loss: 2.513428, top_1: 0.653672, top_k: 0.849414, samples/s: 2951.283 1612045494.9264476
train: epoch 123, iter 1600, loss: 2.371961, top_1: 0.648516, top_k: 0.845586, samples/s: 2915.472 1612045503.707189
train: epoch 123, iter 1700, loss: 2.481761, top_1: 0.656211, top_k: 0.850469, samples/s: 2895.177 1612045512.5496862
train: epoch 123, iter 1800, loss: 2.418206, top_1: 0.654023, top_k: 0.846992, samples/s: 2990.427 1612045521.1102128
train: epoch 123, iter 1900, loss: 2.535618, top_1: 0.652148, top_k: 0.851406, samples/s: 2972.697 1612045529.7218435
train: epoch 123, iter 2000, loss: 2.361654, top_1: 0.648594, top_k: 0.847773, samples/s: 2992.820 1612045538.2756443
train: epoch 123, iter 2100, loss: 2.462627, top_1: 0.649492, top_k: 0.850156, samples/s: 2979.858 1612045546.8667648
train: epoch 123, iter 2200, loss: 2.373628, top_1: 0.653828, top_k: 0.852227, samples/s: 2981.621 1612045555.452665
train: epoch 123, iter 2300, loss: 2.589094, top_1: 0.648516, top_k: 0.847070, samples/s: 2930.382 1612045564.188658
train: epoch 123, iter 2400, loss: 2.579475, top_1: 0.649453, top_k: 0.846914, samples/s: 2936.481 1612045572.9069402
train: epoch 123, iter 2500, loss: 2.481435, top_1: 0.647734, top_k: 0.847773, samples/s: 2968.504 1612045581.5304031
train: epoch 123, iter 2600, loss: 2.517164, top_1: 0.649062, top_k: 0.849609, samples/s: 2958.692 1612045590.182952
train: epoch 123, iter 2700, loss: 2.503499, top_1: 0.648320, top_k: 0.846094, samples/s: 3015.778 1612045598.6716027
train: epoch 123, iter 2800, loss: 2.546819, top_1: 0.645352, top_k: 0.843281, samples/s: 2946.534 1612045607.3597832
train: epoch 123, iter 2900, loss: 2.382045, top_1: 0.653359, top_k: 0.851328, samples/s: 2957.959 1612045616.0148048
train: epoch 123, iter 3000, loss: 2.483021, top_1: 0.649883, top_k: 0.850313, samples/s: 2969.631 1612045624.6350853
train: epoch 123, iter 3100, loss: 2.432496, top_1: 0.649727, top_k: 0.847422, samples/s: 2893.498 1612045633.4825184
train: epoch 123, iter 3200, loss: 2.388566, top_1: 0.645508, top_k: 0.848125, samples/s: 2905.076 1612045642.2945933
train: epoch 123, iter 3300, loss: 2.526384, top_1: 0.644258, top_k: 0.846641, samples/s: 2972.681 1612045650.9063962
train: epoch 123, iter 3400, loss: 2.582037, top_1: 0.645977, top_k: 0.848203, samples/s: 2933.004 1612045659.6346538
train: epoch 123, iter 3500, loss: 2.448705, top_1: 0.648242, top_k: 0.848906, samples/s: 3041.493 1612045668.0515122
train: epoch 123, iter 3600, loss: 2.482465, top_1: 0.651016, top_k: 0.848516, samples/s: 2990.803 1612045676.6110759
train: epoch 123, iter 3700, loss: 2.597165, top_1: 0.649414, top_k: 0.843867, samples/s: 2894.743 1612045685.4546864
train: epoch 123, iter 3800, loss: 2.407634, top_1: 0.643984, top_k: 0.845352, samples/s: 2948.127 1612045694.1381645
train: epoch 123, iter 3900, loss: 2.603599, top_1: 0.650469, top_k: 0.847148, samples/s: 2956.109 1612045702.798236
train: epoch 123, iter 4000, loss: 2.551164, top_1: 0.645703, top_k: 0.845273, samples/s: 2914.963 1612045711.580474
train: epoch 123, iter 4100, loss: 2.433425, top_1: 0.643359, top_k: 0.847930, samples/s: 3000.633 1612045720.1121516
train: epoch 123, iter 4200, loss: 2.519822, top_1: 0.648594, top_k: 0.846836, samples/s: 2972.317 1612045728.7248385
train: epoch 123, iter 4300, loss: 2.511559, top_1: 0.652773, top_k: 0.850117, samples/s: 2986.071 1612045737.2979994
train: epoch 123, iter 4400, loss: 2.525983, top_1: 0.650742, top_k: 0.850352, samples/s: 2994.062 1612045745.8482325
train: epoch 123, iter 4500, loss: 2.405006, top_1: 0.650156, top_k: 0.851523, samples/s: 2972.494 1612045754.4605122
train: epoch 123, iter 4600, loss: 2.391695, top_1: 0.646328, top_k: 0.843359, samples/s: 2973.370 1612045763.070493
train: epoch 123, iter 4700, loss: 2.315941, top_1: 0.644375, top_k: 0.846250, samples/s: 2929.568 1612045771.8087578
train: epoch 123, iter 4800, loss: 2.402544, top_1: 0.646484, top_k: 0.846250, samples/s: 2976.585 1612045780.4092247
train: epoch 123, iter 4900, loss: 2.477984, top_1: 0.646523, top_k: 0.844961, samples/s: 2956.743 1612045789.0673869
train: epoch 123, iter 5000, loss: 2.448809, top_1: 0.650312, top_k: 0.843281, samples/s: 2932.781 1612045797.7963016
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_123.
validation: epoch 123, iter 195, top_1: 0.682171, top_k: 0.884696, samples/s: 3079.283 1612045814.2589111
train: epoch 124, iter 100, loss: 2.559375, top_1: 0.659102, top_k: 0.853789, samples/s: 2910.698 1612045838.9369848
train: epoch 124, iter 200, loss: 2.311007, top_1: 0.659258, top_k: 0.857734, samples/s: 2974.909 1612045847.542381
train: epoch 124, iter 300, loss: 2.426011, top_1: 0.655469, top_k: 0.851445, samples/s: 2994.629 1612045856.0910776
train: epoch 124, iter 400, loss: 2.590198, top_1: 0.658672, top_k: 0.853203, samples/s: 2991.503 1612045864.6484923
train: epoch 124, iter 500, loss: 2.237505, top_1: 0.659961, top_k: 0.853750, samples/s: 3001.714 1612045873.1770363
train: epoch 124, iter 600, loss: 2.502830, top_1: 0.648750, top_k: 0.846953, samples/s: 2954.134 1612045881.8429751
train: epoch 124, iter 700, loss: 2.533536, top_1: 0.650039, top_k: 0.846914, samples/s: 2947.592 1612045890.527851
train: epoch 124, iter 800, loss: 2.395679, top_1: 0.650000, top_k: 0.849414, samples/s: 2902.469 1612045899.3481457
train: epoch 124, iter 900, loss: 2.427296, top_1: 0.657695, top_k: 0.851016, samples/s: 2942.913 1612045908.0467627
train: epoch 124, iter 1000, loss: 2.517672, top_1: 0.655781, top_k: 0.850820, samples/s: 3021.648 1612045916.5189757
train: epoch 124, iter 1100, loss: 2.457966, top_1: 0.654922, top_k: 0.849961, samples/s: 2992.433 1612045925.0739408
train: epoch 124, iter 1200, loss: 2.667205, top_1: 0.657383, top_k: 0.853672, samples/s: 3009.945 1612045933.579079
train: epoch 124, iter 1300, loss: 2.516905, top_1: 0.649375, top_k: 0.850781, samples/s: 2956.906 1612045942.2367089
train: epoch 124, iter 1400, loss: 2.519451, top_1: 0.649062, top_k: 0.849727, samples/s: 2907.499 1612045951.0415409
train: epoch 124, iter 1500, loss: 2.530090, top_1: 0.654805, top_k: 0.852969, samples/s: 2964.729 1612045959.676438
train: epoch 124, iter 1600, loss: 2.481465, top_1: 0.650937, top_k: 0.847773, samples/s: 2995.133 1612045968.223576
train: epoch 124, iter 1700, loss: 2.371642, top_1: 0.651875, top_k: 0.849844, samples/s: 2959.158 1612045976.8747053
train: epoch 124, iter 1800, loss: 2.340169, top_1: 0.650234, top_k: 0.848711, samples/s: 2963.931 1612045985.5118678
train: epoch 124, iter 1900, loss: 2.554186, top_1: 0.652266, top_k: 0.846953, samples/s: 2930.746 1612045994.2468688
train: epoch 124, iter 2000, loss: 2.269732, top_1: 0.654727, top_k: 0.852070, samples/s: 3019.709 1612046002.7245247
train: epoch 124, iter 2100, loss: 2.381127, top_1: 0.652695, top_k: 0.849102, samples/s: 2968.985 1612046011.3470838
train: epoch 124, iter 2200, loss: 2.435058, top_1: 0.647461, top_k: 0.846797, samples/s: 3004.557 1612046019.8673544
train: epoch 124, iter 2300, loss: 2.474970, top_1: 0.652148, top_k: 0.851562, samples/s: 2958.245 1612046028.521121
train: epoch 124, iter 2400, loss: 2.635180, top_1: 0.646523, top_k: 0.842187, samples/s: 2955.072 1612046037.1841915
train: epoch 124, iter 2500, loss: 2.502376, top_1: 0.652422, top_k: 0.852930, samples/s: 2981.677 1612046045.769978
train: epoch 124, iter 2600, loss: 2.424106, top_1: 0.652344, top_k: 0.849414, samples/s: 2999.225 1612046054.305551
train: epoch 124, iter 2700, loss: 2.615983, top_1: 0.649336, top_k: 0.848750, samples/s: 2974.593 1612046062.9117458
train: epoch 124, iter 2800, loss: 2.495177, top_1: 0.651719, top_k: 0.848516, samples/s: 2964.603 1612046071.547025
train: epoch 124, iter 2900, loss: 2.339017, top_1: 0.654336, top_k: 0.853398, samples/s: 2997.341 1612046080.087879
train: epoch 124, iter 3000, loss: 2.504458, top_1: 0.651211, top_k: 0.848789, samples/s: 3003.562 1612046088.6111064
train: epoch 124, iter 3100, loss: 2.510448, top_1: 0.648672, top_k: 0.845273, samples/s: 2947.158 1612046097.2974458
train: epoch 124, iter 3200, loss: 2.549997, top_1: 0.651289, top_k: 0.847461, samples/s: 2951.850 1612046105.9699156
train: epoch 124, iter 3300, loss: 2.394928, top_1: 0.653047, top_k: 0.849102, samples/s: 2857.427 1612046114.9290383
train: epoch 124, iter 3400, loss: 2.300797, top_1: 0.651211, top_k: 0.850586, samples/s: 3029.349 1612046123.3797069
train: epoch 124, iter 3500, loss: 2.551813, top_1: 0.648828, top_k: 0.849180, samples/s: 2979.584 1612046131.9714954
train: epoch 124, iter 3600, loss: 2.613902, top_1: 0.651328, top_k: 0.848984, samples/s: 2989.049 1612046140.5361633
train: epoch 124, iter 3700, loss: 2.566685, top_1: 0.649023, top_k: 0.846094, samples/s: 2940.613 1612046149.2418015
train: epoch 124, iter 3800, loss: 2.614505, top_1: 0.650508, top_k: 0.847305, samples/s: 2971.678 1612046157.8563867
train: epoch 124, iter 3900, loss: 2.408148, top_1: 0.653164, top_k: 0.847266, samples/s: 2975.703 1612046166.4594352
train: epoch 124, iter 4000, loss: 2.590421, top_1: 0.650937, top_k: 0.846523, samples/s: 2998.138 1612046174.99807
train: epoch 124, iter 4100, loss: 2.408017, top_1: 0.651641, top_k: 0.846992, samples/s: 2925.221 1612046183.7495532
train: epoch 124, iter 4200, loss: 2.352055, top_1: 0.651602, top_k: 0.848164, samples/s: 2931.058 1612046192.4836931
train: epoch 124, iter 4300, loss: 2.501600, top_1: 0.650117, top_k: 0.846016, samples/s: 2994.011 1612046201.0340123
train: epoch 124, iter 4400, loss: 2.614138, top_1: 0.642500, top_k: 0.845898, samples/s: 2952.812 1612046209.703698
train: epoch 124, iter 4500, loss: 2.503431, top_1: 0.649531, top_k: 0.852969, samples/s: 3028.062 1612046218.1579661
train: epoch 124, iter 4600, loss: 2.445487, top_1: 0.643164, top_k: 0.844258, samples/s: 3006.589 1612046226.672738
train: epoch 124, iter 4700, loss: 2.342367, top_1: 0.653750, top_k: 0.847383, samples/s: 2989.397 1612046235.2362673
train: epoch 124, iter 4800, loss: 2.507684, top_1: 0.648867, top_k: 0.846797, samples/s: 2917.397 1612046244.0112257
train: epoch 124, iter 4900, loss: 2.333015, top_1: 0.648594, top_k: 0.843750, samples/s: 2936.706 1612046252.7284837
train: epoch 124, iter 5000, loss: 2.444417, top_1: 0.657461, top_k: 0.853359, samples/s: 2998.082 1612046261.2671552
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_124.
validation: epoch 124, iter 195, top_1: 0.677744, top_k: 0.880549, samples/s: 2944.660 1612046278.498283
train: epoch 125, iter 100, loss: 2.548813, top_1: 0.662813, top_k: 0.856211, samples/s: 2914.702 1612046308.6017265
train: epoch 125, iter 200, loss: 2.397807, top_1: 0.662617, top_k: 0.858828, samples/s: 2910.105 1612046317.3987443
train: epoch 125, iter 300, loss: 2.520075, top_1: 0.659180, top_k: 0.853711, samples/s: 3004.654 1612046325.9187908
train: epoch 125, iter 400, loss: 2.480733, top_1: 0.656719, top_k: 0.855391, samples/s: 3023.423 1612046334.385952
train: epoch 125, iter 500, loss: 2.432212, top_1: 0.657500, top_k: 0.850820, samples/s: 2964.875 1612046343.020447
train: epoch 125, iter 600, loss: 2.290062, top_1: 0.654414, top_k: 0.850664, samples/s: 2994.974 1612046351.5680194
train: epoch 125, iter 700, loss: 2.397451, top_1: 0.657266, top_k: 0.851680, samples/s: 2970.727 1612046360.1854181
train: epoch 125, iter 800, loss: 2.245155, top_1: 0.659531, top_k: 0.855508, samples/s: 2996.410 1612046368.7291625
train: epoch 125, iter 900, loss: 2.584039, top_1: 0.653711, top_k: 0.849844, samples/s: 2991.982 1612046377.285203
train: epoch 125, iter 1000, loss: 2.487792, top_1: 0.652500, top_k: 0.847617, samples/s: 2896.493 1612046386.1234818
train: epoch 125, iter 1100, loss: 2.448373, top_1: 0.650391, top_k: 0.848477, samples/s: 2964.931 1612046394.7578135
train: epoch 125, iter 1200, loss: 2.497118, top_1: 0.656211, top_k: 0.851289, samples/s: 2946.492 1612046403.446038
train: epoch 125, iter 1300, loss: 2.502839, top_1: 0.658047, top_k: 0.850664, samples/s: 3022.113 1612046411.9169817
train: epoch 125, iter 1400, loss: 2.394964, top_1: 0.656250, top_k: 0.850391, samples/s: 2985.211 1612046420.4926014
train: epoch 125, iter 1500, loss: 2.465914, top_1: 0.657734, top_k: 0.849688, samples/s: 2865.639 1612046429.4259765
train: epoch 125, iter 1600, loss: 2.536432, top_1: 0.650898, top_k: 0.848672, samples/s: 2978.535 1612046438.0207973
train: epoch 125, iter 1700, loss: 2.394320, top_1: 0.653945, top_k: 0.850547, samples/s: 2986.437 1612046446.592913
train: epoch 125, iter 1800, loss: 2.556871, top_1: 0.655195, top_k: 0.850117, samples/s: 2994.515 1612046455.1418748
train: epoch 125, iter 1900, loss: 2.383025, top_1: 0.659258, top_k: 0.851250, samples/s: 2868.256 1612046464.0671272
train: epoch 125, iter 2000, loss: 2.601978, top_1: 0.657344, top_k: 0.851406, samples/s: 2992.954 1612046472.620565
train: epoch 125, iter 2100, loss: 2.354639, top_1: 0.652578, top_k: 0.854531, samples/s: 2979.273 1612046481.2133446
train: epoch 125, iter 2200, loss: 2.389367, top_1: 0.652305, top_k: 0.846406, samples/s: 2922.915 1612046489.9716332
train: epoch 125, iter 2300, loss: 2.311759, top_1: 0.654141, top_k: 0.852148, samples/s: 2927.847 1612046498.7153902
train: epoch 125, iter 2400, loss: 2.378360, top_1: 0.654219, top_k: 0.850078, samples/s: 2905.608 1612046507.525829
train: epoch 125, iter 2500, loss: 2.518382, top_1: 0.657266, top_k: 0.852812, samples/s: 2984.726 1612046516.1028075
train: epoch 125, iter 2600, loss: 2.415608, top_1: 0.660391, top_k: 0.853750, samples/s: 2993.762 1612046524.6538773
train: epoch 125, iter 2700, loss: 2.374015, top_1: 0.656133, top_k: 0.852812, samples/s: 2941.534 1612046533.3569496
train: epoch 125, iter 2800, loss: 2.532486, top_1: 0.661992, top_k: 0.854375, samples/s: 2942.998 1612046542.0555253
train: epoch 125, iter 2900, loss: 2.587162, top_1: 0.660273, top_k: 0.855430, samples/s: 2946.755 1612046550.743027
train: epoch 125, iter 3000, loss: 2.438884, top_1: 0.651797, top_k: 0.850586, samples/s: 2996.427 1612046559.2865193
train: epoch 125, iter 3100, loss: 2.539709, top_1: 0.651133, top_k: 0.851289, samples/s: 2972.193 1612046567.8996825
train: epoch 125, iter 3200, loss: 2.372872, top_1: 0.651797, top_k: 0.849883, samples/s: 2965.546 1612046576.5321474
train: epoch 125, iter 3300, loss: 2.390482, top_1: 0.655898, top_k: 0.852070, samples/s: 3002.826 1612046585.0575643
train: epoch 125, iter 3400, loss: 2.493672, top_1: 0.652305, top_k: 0.850625, samples/s: 2967.285 1612046593.6849632
train: epoch 125, iter 3500, loss: 2.536087, top_1: 0.653516, top_k: 0.848477, samples/s: 2984.473 1612046602.262669
train: epoch 125, iter 3600, loss: 2.540886, top_1: 0.652422, top_k: 0.850352, samples/s: 2941.760 1612046610.9648855
train: epoch 125, iter 3700, loss: 2.504827, top_1: 0.658594, top_k: 0.853359, samples/s: 2977.753 1612046619.562102
train: epoch 125, iter 3800, loss: 2.408188, top_1: 0.656523, top_k: 0.851289, samples/s: 3024.897 1612046628.0251625
train: epoch 125, iter 3900, loss: 2.110967, top_1: 0.654570, top_k: 0.851680, samples/s: 2967.568 1612046636.651718
train: epoch 125, iter 4000, loss: 2.497723, top_1: 0.656328, top_k: 0.853516, samples/s: 2979.927 1612046645.2424674
train: epoch 125, iter 4100, loss: 2.306295, top_1: 0.653164, top_k: 0.851992, samples/s: 3014.101 1612046653.7359204
train: epoch 125, iter 4200, loss: 2.446856, top_1: 0.651406, top_k: 0.850508, samples/s: 2980.425 1612046662.325298
train: epoch 125, iter 4300, loss: 2.363494, top_1: 0.655781, top_k: 0.851367, samples/s: 2992.923 1612046670.878766
train: epoch 125, iter 4400, loss: 2.408272, top_1: 0.655977, top_k: 0.852344, samples/s: 2988.370 1612046679.4453514
train: epoch 125, iter 4500, loss: 2.538697, top_1: 0.656758, top_k: 0.851133, samples/s: 2999.126 1612046687.9811423
train: epoch 125, iter 4600, loss: 2.553705, top_1: 0.656758, top_k: 0.852852, samples/s: 2973.152 1612046696.5915208
train: epoch 125, iter 4700, loss: 2.514942, top_1: 0.646680, top_k: 0.843984, samples/s: 2927.597 1612046705.3359082
train: epoch 125, iter 4800, loss: 2.560102, top_1: 0.651680, top_k: 0.848125, samples/s: 2987.918 1612046713.9037764
train: epoch 125, iter 4900, loss: 2.558429, top_1: 0.648438, top_k: 0.848086, samples/s: 2977.831 1612046722.5005956
train: epoch 125, iter 5000, loss: 2.338614, top_1: 0.660508, top_k: 0.853125, samples/s: 2992.730 1612046731.054715
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_125.
validation: epoch 125, iter 195, top_1: 0.678986, top_k: 0.881230, samples/s: 2897.314 1612046748.5534122
train: epoch 126, iter 100, loss: 2.452158, top_1: 0.665078, top_k: 0.855742, samples/s: 2930.775 1612046773.3621898
train: epoch 126, iter 200, loss: 2.367596, top_1: 0.660273, top_k: 0.855117, samples/s: 3022.991 1612046781.8302798
train: epoch 126, iter 300, loss: 2.264012, top_1: 0.657266, top_k: 0.852383, samples/s: 3001.748 1612046790.358466
train: epoch 126, iter 400, loss: 2.191688, top_1: 0.655742, top_k: 0.854414, samples/s: 3002.915 1612046798.88368
train: epoch 126, iter 500, loss: 2.604304, top_1: 0.663359, top_k: 0.857734, samples/s: 2984.701 1612046807.4610124
train: epoch 126, iter 600, loss: 2.431195, top_1: 0.658203, top_k: 0.850859, samples/s: 2974.971 1612046816.0657275
train: epoch 126, iter 700, loss: 2.315634, top_1: 0.664961, top_k: 0.857578, samples/s: 2973.295 1612046824.675719
train: epoch 126, iter 800, loss: 2.362956, top_1: 0.666328, top_k: 0.857227, samples/s: 2950.250 1612046833.3529978
train: epoch 126, iter 900, loss: 2.486882, top_1: 0.661172, top_k: 0.855977, samples/s: 2915.131 1612046842.1346865
train: epoch 126, iter 1000, loss: 2.397286, top_1: 0.662930, top_k: 0.854648, samples/s: 2951.098 1612046850.8095202
train: epoch 126, iter 1100, loss: 2.399744, top_1: 0.664609, top_k: 0.852891, samples/s: 2996.473 1612046859.3528757
train: epoch 126, iter 1200, loss: 2.586232, top_1: 0.655937, top_k: 0.851484, samples/s: 2919.541 1612046868.1213202
train: epoch 126, iter 1300, loss: 2.226573, top_1: 0.656797, top_k: 0.854414, samples/s: 2997.220 1612046876.6625602
train: epoch 126, iter 1400, loss: 2.401376, top_1: 0.655586, top_k: 0.856094, samples/s: 2936.953 1612046885.3791187
train: epoch 126, iter 1500, loss: 2.370511, top_1: 0.663828, top_k: 0.859258, samples/s: 3023.682 1612046893.8455849
train: epoch 126, iter 1600, loss: 2.632090, top_1: 0.661250, top_k: 0.853555, samples/s: 2963.215 1612046902.4848378
train: epoch 126, iter 1700, loss: 2.545142, top_1: 0.658281, top_k: 0.855234, samples/s: 2981.620 1612046911.070771
train: epoch 126, iter 1800, loss: 2.607692, top_1: 0.655469, top_k: 0.852656, samples/s: 2976.228 1612046919.672377
train: epoch 126, iter 1900, loss: 2.552502, top_1: 0.658398, top_k: 0.856055, samples/s: 2995.778 1612046928.217804
train: epoch 126, iter 2000, loss: 2.415511, top_1: 0.654102, top_k: 0.852656, samples/s: 2855.035 1612046937.184211
train: epoch 126, iter 2100, loss: 2.312962, top_1: 0.657891, top_k: 0.852695, samples/s: 2963.633 1612046945.8222978
train: epoch 126, iter 2200, loss: 2.497615, top_1: 0.658984, top_k: 0.848906, samples/s: 2869.271 1612046954.7444649
train: epoch 126, iter 2300, loss: 2.456648, top_1: 0.658086, top_k: 0.851836, samples/s: 2977.173 1612046963.3432093
train: epoch 126, iter 2400, loss: 2.477769, top_1: 0.657500, top_k: 0.852812, samples/s: 2962.655 1612046971.9841027
train: epoch 126, iter 2500, loss: 2.371758, top_1: 0.660391, top_k: 0.854102, samples/s: 2970.195 1612046980.603012
train: epoch 126, iter 2600, loss: 2.367190, top_1: 0.656836, top_k: 0.853906, samples/s: 2976.940 1612046989.2024586
train: epoch 126, iter 2700, loss: 2.509232, top_1: 0.657578, top_k: 0.853633, samples/s: 2959.616 1612046997.852284
train: epoch 126, iter 2800, loss: 2.610637, top_1: 0.654375, top_k: 0.851133, samples/s: 2969.613 1612047006.4729495
train: epoch 126, iter 2900, loss: 2.335775, top_1: 0.658672, top_k: 0.856328, samples/s: 3029.684 1612047014.9227722
train: epoch 126, iter 3000, loss: 2.583922, top_1: 0.655195, top_k: 0.852422, samples/s: 2924.595 1612047023.675928
train: epoch 126, iter 3100, loss: 2.558846, top_1: 0.661641, top_k: 0.855781, samples/s: 2987.101 1612047032.2461739
train: epoch 126, iter 3200, loss: 2.260550, top_1: 0.654805, top_k: 0.852070, samples/s: 2944.787 1612047040.9394765
train: epoch 126, iter 3300, loss: 2.449743, top_1: 0.657109, top_k: 0.852773, samples/s: 2949.431 1612047049.6191227
train: epoch 126, iter 3400, loss: 2.446828, top_1: 0.657500, top_k: 0.853828, samples/s: 2955.734 1612047058.2802591
train: epoch 126, iter 3500, loss: 2.475210, top_1: 0.654414, top_k: 0.850586, samples/s: 2999.963 1612047066.8136768
train: epoch 126, iter 3600, loss: 2.385031, top_1: 0.660078, top_k: 0.853867, samples/s: 2977.827 1612047075.4105527
train: epoch 126, iter 3700, loss: 2.509541, top_1: 0.657148, top_k: 0.850781, samples/s: 3005.934 1612047083.9270349
train: epoch 126, iter 3800, loss: 2.401712, top_1: 0.662227, top_k: 0.852734, samples/s: 2945.407 1612047092.618602
train: epoch 126, iter 3900, loss: 2.373948, top_1: 0.663828, top_k: 0.852266, samples/s: 3002.418 1612047101.1450138
train: epoch 126, iter 4000, loss: 2.366657, top_1: 0.651523, top_k: 0.851016, samples/s: 2973.107 1612047109.755597
train: epoch 126, iter 4100, loss: 2.284935, top_1: 0.652305, top_k: 0.851250, samples/s: 2982.050 1612047118.3402185
train: epoch 126, iter 4200, loss: 2.542272, top_1: 0.655703, top_k: 0.851055, samples/s: 2997.655 1612047126.880242
train: epoch 126, iter 4300, loss: 2.476108, top_1: 0.653086, top_k: 0.850313, samples/s: 2986.854 1612047135.4512637
train: epoch 126, iter 4400, loss: 2.548178, top_1: 0.652969, top_k: 0.852070, samples/s: 2919.101 1612047144.2209408
train: epoch 126, iter 4500, loss: 2.416178, top_1: 0.653789, top_k: 0.852773, samples/s: 3000.380 1612047152.753223
train: epoch 126, iter 4600, loss: 2.460329, top_1: 0.658867, top_k: 0.853281, samples/s: 2975.414 1612047161.35703
train: epoch 126, iter 4700, loss: 2.647569, top_1: 0.654883, top_k: 0.851602, samples/s: 2983.312 1612047169.9380531
train: epoch 126, iter 4800, loss: 2.256462, top_1: 0.659414, top_k: 0.855586, samples/s: 2955.934 1612047178.5987487
train: epoch 126, iter 4900, loss: 2.443518, top_1: 0.651992, top_k: 0.848984, samples/s: 2999.946 1612047187.1321244
train: epoch 126, iter 5000, loss: 2.272736, top_1: 0.662656, top_k: 0.854648, samples/s: 2965.290 1612047195.765554
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_126.
validation: epoch 126, iter 195, top_1: 0.688201, top_k: 0.886298, samples/s: 2935.619 1612047213.056971
train: epoch 127, iter 100, loss: 2.448714, top_1: 0.665586, top_k: 0.861680, samples/s: 2946.177 1612047237.960414
train: epoch 127, iter 200, loss: 2.409204, top_1: 0.662656, top_k: 0.859688, samples/s: 2971.292 1612047246.5760155
train: epoch 127, iter 300, loss: 2.369654, top_1: 0.662617, top_k: 0.854805, samples/s: 2966.583 1612047255.2055378
train: epoch 127, iter 400, loss: 2.411683, top_1: 0.661563, top_k: 0.858789, samples/s: 2843.543 1612047264.2083287
train: epoch 127, iter 500, loss: 2.357675, top_1: 0.665391, top_k: 0.856992, samples/s: 2995.076 1612047272.7556756
train: epoch 127, iter 600, loss: 2.274548, top_1: 0.664805, top_k: 0.854844, samples/s: 3017.666 1612047281.2390532
train: epoch 127, iter 700, loss: 2.119542, top_1: 0.668594, top_k: 0.860000, samples/s: 3006.607 1612047289.7537358
train: epoch 127, iter 800, loss: 2.446691, top_1: 0.664180, top_k: 0.856523, samples/s: 2965.647 1612047298.3858197
train: epoch 127, iter 900, loss: 2.462270, top_1: 0.663789, top_k: 0.850664, samples/s: 2928.322 1612047307.1280246
train: epoch 127, iter 1000, loss: 2.487281, top_1: 0.660273, top_k: 0.854375, samples/s: 2975.360 1612047315.7320476
train: epoch 127, iter 1100, loss: 2.411443, top_1: 0.660391, top_k: 0.855820, samples/s: 3019.288 1612047324.210846
train: epoch 127, iter 1200, loss: 2.469649, top_1: 0.664180, top_k: 0.854922, samples/s: 2958.224 1612047332.864734
train: epoch 127, iter 1300, loss: 2.477636, top_1: 0.662969, top_k: 0.855898, samples/s: 3012.084 1612047341.3637536
train: epoch 127, iter 1400, loss: 2.557259, top_1: 0.655430, top_k: 0.854531, samples/s: 2955.964 1612047350.024316
train: epoch 127, iter 1500, loss: 2.474818, top_1: 0.657227, top_k: 0.853633, samples/s: 2977.599 1612047358.6217766
train: epoch 127, iter 1600, loss: 2.441679, top_1: 0.667070, top_k: 0.861250, samples/s: 2991.771 1612047367.1785975
train: epoch 127, iter 1700, loss: 2.464852, top_1: 0.663242, top_k: 0.856992, samples/s: 2873.727 1612047376.086987
train: epoch 127, iter 1800, loss: 2.516937, top_1: 0.658125, top_k: 0.853047, samples/s: 2977.560 1612047384.6846132
train: epoch 127, iter 1900, loss: 2.556840, top_1: 0.659453, top_k: 0.855234, samples/s: 2981.911 1612047393.2696195
train: epoch 127, iter 2000, loss: 2.510278, top_1: 0.663945, top_k: 0.858203, samples/s: 2915.399 1612047402.0506306
train: epoch 127, iter 2100, loss: 2.370837, top_1: 0.655859, top_k: 0.850352, samples/s: 2991.082 1612047410.609358
train: epoch 127, iter 2200, loss: 2.301696, top_1: 0.657500, top_k: 0.853789, samples/s: 3012.516 1612047419.1072743
train: epoch 127, iter 2300, loss: 2.576725, top_1: 0.655078, top_k: 0.851250, samples/s: 2988.195 1612047427.674441
train: epoch 127, iter 2400, loss: 2.399648, top_1: 0.660664, top_k: 0.854375, samples/s: 2947.525 1612047436.3595207
train: epoch 127, iter 2500, loss: 2.256395, top_1: 0.659805, top_k: 0.857305, samples/s: 2951.013 1612047445.0345297
train: epoch 127, iter 2600, loss: 2.502629, top_1: 0.661094, top_k: 0.852578, samples/s: 2939.738 1612047453.7428133
train: epoch 127, iter 2700, loss: 2.427661, top_1: 0.662656, top_k: 0.857383, samples/s: 2965.001 1612047462.376926
train: epoch 127, iter 2800, loss: 2.426754, top_1: 0.657891, top_k: 0.852031, samples/s: 3024.459 1612047470.8411865
train: epoch 127, iter 2900, loss: 2.265159, top_1: 0.657422, top_k: 0.852930, samples/s: 2926.886 1612047479.5877385
train: epoch 127, iter 3000, loss: 2.579306, top_1: 0.651680, top_k: 0.854141, samples/s: 3005.925 1612047488.1042764
train: epoch 127, iter 3100, loss: 2.453412, top_1: 0.658242, top_k: 0.855586, samples/s: 2949.193 1612047496.7846355
train: epoch 127, iter 3200, loss: 2.251279, top_1: 0.658789, top_k: 0.855234, samples/s: 3022.715 1612047505.2537618
train: epoch 127, iter 3300, loss: 2.396196, top_1: 0.661484, top_k: 0.855195, samples/s: 2962.646 1612047513.894666
train: epoch 127, iter 3400, loss: 2.323443, top_1: 0.658555, top_k: 0.855781, samples/s: 2974.001 1612047522.5026426
train: epoch 127, iter 3500, loss: 2.388856, top_1: 0.658125, top_k: 0.854102, samples/s: 2939.415 1612047531.2118287
train: epoch 127, iter 3600, loss: 2.450523, top_1: 0.655117, top_k: 0.848789, samples/s: 2992.285 1612047539.7673056
train: epoch 127, iter 3700, loss: 2.275253, top_1: 0.659102, top_k: 0.853711, samples/s: 2976.058 1612047548.3690753
train: epoch 127, iter 3800, loss: 2.264024, top_1: 0.658125, top_k: 0.855664, samples/s: 2995.056 1612047556.9165378
train: epoch 127, iter 3900, loss: 2.320727, top_1: 0.664062, top_k: 0.855469, samples/s: 2931.992 1612047565.6477892
train: epoch 127, iter 4000, loss: 2.422977, top_1: 0.656484, top_k: 0.854492, samples/s: 3014.833 1612047574.1391635
train: epoch 127, iter 4100, loss: 2.335251, top_1: 0.665898, top_k: 0.860273, samples/s: 3019.711 1612047582.6168327
train: epoch 127, iter 4200, loss: 2.449228, top_1: 0.655234, top_k: 0.850117, samples/s: 2894.183 1612047591.4621193
train: epoch 127, iter 4300, loss: 2.555905, top_1: 0.660234, top_k: 0.854766, samples/s: 2978.088 1612047600.0582259
train: epoch 127, iter 4400, loss: 2.600760, top_1: 0.658594, top_k: 0.852070, samples/s: 2994.038 1612047608.6086006
train: epoch 127, iter 4500, loss: 2.577527, top_1: 0.664648, top_k: 0.855352, samples/s: 2958.507 1612047617.2615697
train: epoch 127, iter 4600, loss: 2.314339, top_1: 0.654922, top_k: 0.852773, samples/s: 2961.285 1612047625.9065218
train: epoch 127, iter 4700, loss: 2.608654, top_1: 0.654258, top_k: 0.849727, samples/s: 2952.593 1612047634.576809
train: epoch 127, iter 4800, loss: 2.368394, top_1: 0.656094, top_k: 0.851562, samples/s: 2970.922 1612047643.1936715
train: epoch 127, iter 4900, loss: 2.685901, top_1: 0.658477, top_k: 0.854805, samples/s: 2935.312 1612047651.9150603
train: epoch 127, iter 5000, loss: 2.414100, top_1: 0.666094, top_k: 0.854023, samples/s: 2998.791 1612047660.4518297
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_127.
validation: epoch 127, iter 195, top_1: 0.687941, top_k: 0.886398, samples/s: 2918.095 1612047677.8446229
train: epoch 128, iter 100, loss: 2.622999, top_1: 0.667148, top_k: 0.859922, samples/s: 2986.153 1612047702.389507
train: epoch 128, iter 200, loss: 2.212910, top_1: 0.668555, top_k: 0.860625, samples/s: 2944.415 1612047711.0839124
train: epoch 128, iter 300, loss: 2.332536, top_1: 0.672656, top_k: 0.861680, samples/s: 2991.038 1612047719.6428196
train: epoch 128, iter 400, loss: 2.444590, top_1: 0.670039, top_k: 0.860820, samples/s: 2998.815 1612047728.1796298
train: epoch 128, iter 500, loss: 2.533240, top_1: 0.668555, top_k: 0.861289, samples/s: 2980.715 1612047736.768197
train: epoch 128, iter 600, loss: 2.360588, top_1: 0.666328, top_k: 0.861211, samples/s: 2947.292 1612047745.454104
train: epoch 128, iter 700, loss: 2.504725, top_1: 0.666211, top_k: 0.857656, samples/s: 2926.046 1612047754.2030566
train: epoch 128, iter 800, loss: 2.386157, top_1: 0.667578, top_k: 0.859219, samples/s: 3000.840 1612047762.733986
train: epoch 128, iter 900, loss: 2.320141, top_1: 0.662578, top_k: 0.859023, samples/s: 2979.335 1612047771.3266408
train: epoch 128, iter 1000, loss: 2.251513, top_1: 0.667461, top_k: 0.859609, samples/s: 2994.472 1612047779.8757644
train: epoch 128, iter 1100, loss: 2.498821, top_1: 0.660469, top_k: 0.859375, samples/s: 2892.526 1612047788.7259634
train: epoch 128, iter 1200, loss: 2.278600, top_1: 0.663828, top_k: 0.855977, samples/s: 2993.815 1612047797.2769804
train: epoch 128, iter 1300, loss: 2.578908, top_1: 0.666367, top_k: 0.860703, samples/s: 2964.131 1612047805.9135435
train: epoch 128, iter 1400, loss: 2.462934, top_1: 0.659023, top_k: 0.852930, samples/s: 2933.569 1612047814.6400986
train: epoch 128, iter 1500, loss: 2.402349, top_1: 0.666211, top_k: 0.857930, samples/s: 2950.710 1612047823.3159556
train: epoch 128, iter 1600, loss: 2.351770, top_1: 0.661523, top_k: 0.854180, samples/s: 2969.178 1612047831.937882
train: epoch 128, iter 1700, loss: 2.375538, top_1: 0.667500, top_k: 0.861758, samples/s: 2955.203 1612047840.600581
train: epoch 128, iter 1800, loss: 2.481050, top_1: 0.668711, top_k: 0.858594, samples/s: 2990.031 1612047849.1623118
train: epoch 128, iter 1900, loss: 2.493597, top_1: 0.664375, top_k: 0.855586, samples/s: 2973.645 1612047857.7713265
train: epoch 128, iter 2000, loss: 2.415339, top_1: 0.662773, top_k: 0.852930, samples/s: 2986.384 1612047866.3435614
train: epoch 128, iter 2100, loss: 2.384406, top_1: 0.659570, top_k: 0.855977, samples/s: 2979.384 1612047874.9359448
train: epoch 128, iter 2200, loss: 2.418490, top_1: 0.659844, top_k: 0.854531, samples/s: 2943.704 1612047883.6326067
train: epoch 128, iter 2300, loss: 2.523145, top_1: 0.662031, top_k: 0.853945, samples/s: 2994.952 1612047892.180235
train: epoch 128, iter 2400, loss: 2.279593, top_1: 0.663633, top_k: 0.858555, samples/s: 2916.818 1612047900.9568665
train: epoch 128, iter 2500, loss: 2.254422, top_1: 0.664844, top_k: 0.855352, samples/s: 2963.238 1612047909.596068
train: epoch 128, iter 2600, loss: 2.358908, top_1: 0.659609, top_k: 0.850742, samples/s: 2893.490 1612047918.4435308
train: epoch 128, iter 2700, loss: 2.535331, top_1: 0.660937, top_k: 0.857305, samples/s: 2938.294 1612047927.156314
train: epoch 128, iter 2800, loss: 2.313536, top_1: 0.655508, top_k: 0.856719, samples/s: 2962.500 1612047935.7974098
train: epoch 128, iter 2900, loss: 2.536319, top_1: 0.663164, top_k: 0.854766, samples/s: 2904.345 1612047944.611779
train: epoch 128, iter 3000, loss: 2.388954, top_1: 0.661836, top_k: 0.855195, samples/s: 2865.998 1612047953.5441716
train: epoch 128, iter 3100, loss: 2.515964, top_1: 0.662109, top_k: 0.859961, samples/s: 3011.890 1612047962.0438216
train: epoch 128, iter 3200, loss: 2.488787, top_1: 0.662305, top_k: 0.856094, samples/s: 2966.494 1612047970.6734629
train: epoch 128, iter 3300, loss: 2.511874, top_1: 0.663906, top_k: 0.857266, samples/s: 2944.277 1612047979.3683321
train: epoch 128, iter 3400, loss: 2.416432, top_1: 0.666328, top_k: 0.856406, samples/s: 3023.898 1612047987.834261
train: epoch 128, iter 3500, loss: 2.492894, top_1: 0.665742, top_k: 0.855703, samples/s: 2971.976 1612047996.4479902
train: epoch 128, iter 3600, loss: 2.378404, top_1: 0.656641, top_k: 0.853398, samples/s: 3013.949 1612048004.9418302
train: epoch 128, iter 3700, loss: 2.356764, top_1: 0.657773, top_k: 0.850273, samples/s: 2913.068 1612048013.7298448
train: epoch 128, iter 3800, loss: 2.442350, top_1: 0.670625, top_k: 0.859922, samples/s: 2989.731 1612048022.2925465
train: epoch 128, iter 3900, loss: 2.622283, top_1: 0.665195, top_k: 0.860938, samples/s: 2972.148 1612048030.9057689
train: epoch 128, iter 4000, loss: 2.366895, top_1: 0.662148, top_k: 0.854258, samples/s: 2951.929 1612048039.5780578
train: epoch 128, iter 4100, loss: 2.366360, top_1: 0.661289, top_k: 0.855000, samples/s: 2958.454 1612048048.2313547
train: epoch 128, iter 4200, loss: 2.362067, top_1: 0.667383, top_k: 0.861406, samples/s: 2969.810 1612048056.8513532
train: epoch 128, iter 4300, loss: 2.330930, top_1: 0.659922, top_k: 0.855703, samples/s: 2986.778 1612048065.4224167
train: epoch 128, iter 4400, loss: 2.524611, top_1: 0.657266, top_k: 0.856289, samples/s: 2975.606 1612048074.0259123
train: epoch 128, iter 4500, loss: 2.323534, top_1: 0.663008, top_k: 0.856719, samples/s: 2980.640 1612048082.6145444
train: epoch 128, iter 4600, loss: 2.268616, top_1: 0.664336, top_k: 0.858789, samples/s: 3011.103 1612048091.1163368
train: epoch 128, iter 4700, loss: 2.260009, top_1: 0.661211, top_k: 0.856797, samples/s: 2991.642 1612048099.6736581
train: epoch 128, iter 4800, loss: 2.417887, top_1: 0.663203, top_k: 0.854844, samples/s: 2951.622 1612048108.3467042
train: epoch 128, iter 4900, loss: 2.407525, top_1: 0.658203, top_k: 0.852930, samples/s: 2975.169 1612048116.9512146
train: epoch 128, iter 5000, loss: 2.585241, top_1: 0.665586, top_k: 0.858789, samples/s: 2922.592 1612048125.7107708
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_128.
validation: epoch 128, iter 195, top_1: 0.694792, top_k: 0.889002, samples/s: 3012.652 1612048142.5255241
train: epoch 129, iter 100, loss: 2.330592, top_1: 0.669258, top_k: 0.859375, samples/s: 2915.609 1612048167.198713
train: epoch 129, iter 200, loss: 2.378134, top_1: 0.670508, top_k: 0.862305, samples/s: 2995.834 1612048175.7438087
train: epoch 129, iter 300, loss: 2.448806, top_1: 0.672148, top_k: 0.862852, samples/s: 3023.954 1612048184.2094007
train: epoch 129, iter 400, loss: 2.360275, top_1: 0.670898, top_k: 0.861680, samples/s: 2941.833 1612048192.911507
train: epoch 129, iter 500, loss: 2.386164, top_1: 0.669805, top_k: 0.858828, samples/s: 2997.643 1612048201.4517612
train: epoch 129, iter 600, loss: 2.411263, top_1: 0.667656, top_k: 0.863008, samples/s: 2998.869 1612048209.9881892
train: epoch 129, iter 700, loss: 2.597280, top_1: 0.669414, top_k: 0.860508, samples/s: 2955.984 1612048218.6484973
train: epoch 129, iter 800, loss: 2.195743, top_1: 0.666328, top_k: 0.859180, samples/s: 3011.341 1612048227.149744
train: epoch 129, iter 900, loss: 2.358314, top_1: 0.671445, top_k: 0.862422, samples/s: 2950.471 1612048235.8262837
train: epoch 129, iter 1000, loss: 2.419185, top_1: 0.666836, top_k: 0.859688, samples/s: 2968.945 1612048244.4488842
train: epoch 129, iter 1100, loss: 2.338023, top_1: 0.671055, top_k: 0.861719, samples/s: 2956.519 1612048253.1077561
train: epoch 129, iter 1200, loss: 2.393403, top_1: 0.669102, top_k: 0.858242, samples/s: 3018.623 1612048261.5883863
train: epoch 129, iter 1300, loss: 2.472290, top_1: 0.670937, top_k: 0.859883, samples/s: 2979.644 1612048270.1800277
train: epoch 129, iter 1400, loss: 2.426813, top_1: 0.670117, top_k: 0.860039, samples/s: 2998.767 1612048278.716865
train: epoch 129, iter 1500, loss: 2.365510, top_1: 0.662852, top_k: 0.857422, samples/s: 2887.911 1612048287.581439
train: epoch 129, iter 1600, loss: 2.260512, top_1: 0.663672, top_k: 0.857930, samples/s: 2988.098 1612048296.1487184
train: epoch 129, iter 1700, loss: 2.407972, top_1: 0.670898, top_k: 0.858281, samples/s: 2982.934 1612048304.7308798
train: epoch 129, iter 1800, loss: 2.445745, top_1: 0.661016, top_k: 0.856094, samples/s: 2919.787 1612048313.4986298
train: epoch 129, iter 1900, loss: 2.299100, top_1: 0.671562, top_k: 0.859219, samples/s: 2959.870 1612048322.1477005
train: epoch 129, iter 2000, loss: 2.465953, top_1: 0.667617, top_k: 0.859062, samples/s: 2970.002 1612048330.767313
train: epoch 129, iter 2100, loss: 2.233169, top_1: 0.666016, top_k: 0.858906, samples/s: 2994.925 1612048339.3150358
train: epoch 129, iter 2200, loss: 2.451932, top_1: 0.670039, top_k: 0.859258, samples/s: 2948.554 1612048347.9972425
train: epoch 129, iter 2300, loss: 2.442940, top_1: 0.666016, top_k: 0.858359, samples/s: 2951.472 1612048356.670854
train: epoch 129, iter 2400, loss: 2.504736, top_1: 0.668281, top_k: 0.860078, samples/s: 2974.956 1612048365.2760243
train: epoch 129, iter 2500, loss: 2.493883, top_1: 0.663281, top_k: 0.855195, samples/s: 2994.290 1612048373.8255835
train: epoch 129, iter 2600, loss: 2.326657, top_1: 0.671875, top_k: 0.861836, samples/s: 2982.988 1612048382.4077039
train: epoch 129, iter 2700, loss: 2.425378, top_1: 0.665391, top_k: 0.859570, samples/s: 2922.386 1612048391.1675634
train: epoch 129, iter 2800, loss: 2.387699, top_1: 0.662578, top_k: 0.857656, samples/s: 2927.119 1612048399.9134285
train: epoch 129, iter 2900, loss: 2.411800, top_1: 0.662852, top_k: 0.854805, samples/s: 2890.161 1612048408.771082
train: epoch 129, iter 3000, loss: 2.445191, top_1: 0.668945, top_k: 0.860781, samples/s: 2955.156 1612048417.4340088
train: epoch 129, iter 3100, loss: 2.311429, top_1: 0.664414, top_k: 0.857148, samples/s: 3006.972 1612048425.9474905
train: epoch 129, iter 3200, loss: 2.372788, top_1: 0.663672, top_k: 0.854648, samples/s: 2994.582 1612048434.496198
train: epoch 129, iter 3300, loss: 2.276921, top_1: 0.667266, top_k: 0.859570, samples/s: 2981.838 1612048443.0815222
train: epoch 129, iter 3400, loss: 2.519413, top_1: 0.660234, top_k: 0.854609, samples/s: 2971.369 1612048451.6970835
train: epoch 129, iter 3500, loss: 2.492727, top_1: 0.664180, top_k: 0.859766, samples/s: 2997.676 1612048460.237031
train: epoch 129, iter 3600, loss: 2.406399, top_1: 0.662109, top_k: 0.857852, samples/s: 2900.237 1612048469.0638373
train: epoch 129, iter 3700, loss: 2.521019, top_1: 0.665312, top_k: 0.856211, samples/s: 2884.022 1612048477.9404197
train: epoch 129, iter 3800, loss: 2.490337, top_1: 0.670859, top_k: 0.859531, samples/s: 2973.924 1612048486.5485225
train: epoch 129, iter 3900, loss: 2.355768, top_1: 0.665547, top_k: 0.856953, samples/s: 2949.610 1612048495.2277129
train: epoch 129, iter 4000, loss: 2.610645, top_1: 0.666992, top_k: 0.855469, samples/s: 2954.517 1612048503.892347
train: epoch 129, iter 4100, loss: 2.389909, top_1: 0.662773, top_k: 0.855586, samples/s: 2944.833 1612048512.5855777
train: epoch 129, iter 4200, loss: 2.360125, top_1: 0.661914, top_k: 0.856367, samples/s: 2975.022 1612048521.1905477
train: epoch 129, iter 4300, loss: 2.355291, top_1: 0.662266, top_k: 0.854688, samples/s: 2985.102 1612048529.766454
train: epoch 129, iter 4400, loss: 2.360219, top_1: 0.662188, top_k: 0.857461, samples/s: 2972.757 1612048538.3780272
train: epoch 129, iter 4500, loss: 2.336314, top_1: 0.664258, top_k: 0.857734, samples/s: 2961.297 1612048547.0228052
train: epoch 129, iter 4600, loss: 2.413648, top_1: 0.666445, top_k: 0.858867, samples/s: 2986.345 1612048555.5954947
train: epoch 129, iter 4700, loss: 2.315307, top_1: 0.667070, top_k: 0.857109, samples/s: 2996.853 1612048564.1374092
train: epoch 129, iter 4800, loss: 2.539971, top_1: 0.665273, top_k: 0.857461, samples/s: 2934.978 1612048572.8598433
train: epoch 129, iter 4900, loss: 2.388080, top_1: 0.668438, top_k: 0.860117, samples/s: 2952.904 1612048581.5293803
train: epoch 129, iter 5000, loss: 2.411584, top_1: 0.674883, top_k: 0.859180, samples/s: 2944.262 1612048590.224736
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_129.
validation: epoch 129, iter 195, top_1: 0.692508, top_k: 0.890505, samples/s: 2973.637 1612048607.2714305
train: epoch 130, iter 100, loss: 2.213177, top_1: 0.669414, top_k: 0.859609, samples/s: 2922.466 1612048632.0656958
train: epoch 130, iter 200, loss: 2.258195, top_1: 0.673594, top_k: 0.866172, samples/s: 2933.366 1612048640.7929358
train: epoch 130, iter 300, loss: 2.433512, top_1: 0.668047, top_k: 0.861133, samples/s: 3000.855 1612048649.3237524
train: epoch 130, iter 400, loss: 2.378724, top_1: 0.673164, top_k: 0.863711, samples/s: 2976.733 1612048657.9238133
train: epoch 130, iter 500, loss: 2.352342, top_1: 0.675898, top_k: 0.865664, samples/s: 2998.098 1612048666.4625466
train: epoch 130, iter 600, loss: 2.491727, top_1: 0.670937, top_k: 0.863398, samples/s: 3005.870 1612048674.979226
train: epoch 130, iter 700, loss: 2.466832, top_1: 0.672813, top_k: 0.865703, samples/s: 3001.732 1612048683.5076606
train: epoch 130, iter 800, loss: 2.318861, top_1: 0.669648, top_k: 0.859805, samples/s: 2929.372 1612048692.2467937
train: epoch 130, iter 900, loss: 2.208111, top_1: 0.677656, top_k: 0.864453, samples/s: 3030.792 1612048700.6933556
train: epoch 130, iter 1000, loss: 2.123750, top_1: 0.671484, top_k: 0.863242, samples/s: 3010.709 1612048709.1964574
train: epoch 130, iter 1100, loss: 2.459795, top_1: 0.672852, top_k: 0.861133, samples/s: 3004.225 1612048717.7176573
train: epoch 130, iter 1200, loss: 2.258286, top_1: 0.667305, top_k: 0.859766, samples/s: 2901.315 1612048726.5412686
train: epoch 130, iter 1300, loss: 2.309859, top_1: 0.673594, top_k: 0.861211, samples/s: 3014.875 1612048735.032469
train: epoch 130, iter 1400, loss: 2.279762, top_1: 0.671992, top_k: 0.861602, samples/s: 3004.447 1612048743.5532484
train: epoch 130, iter 1500, loss: 2.197335, top_1: 0.671289, top_k: 0.862734, samples/s: 2981.217 1612048752.1402764
train: epoch 130, iter 1600, loss: 2.488388, top_1: 0.666250, top_k: 0.858984, samples/s: 2963.550 1612048760.7785752
train: epoch 130, iter 1700, loss: 2.383988, top_1: 0.670312, top_k: 0.861875, samples/s: 2947.763 1612048769.4632316
train: epoch 130, iter 1800, loss: 2.359042, top_1: 0.671016, top_k: 0.858008, samples/s: 2994.725 1612048778.011494
train: epoch 130, iter 1900, loss: 2.526794, top_1: 0.673242, top_k: 0.862773, samples/s: 3002.482 1612048786.5377526
train: epoch 130, iter 2000, loss: 2.311344, top_1: 0.672344, top_k: 0.861953, samples/s: 2985.456 1612048795.1126432
train: epoch 130, iter 2100, loss: 2.590366, top_1: 0.669570, top_k: 0.858711, samples/s: 2938.273 1612048803.825377
train: epoch 130, iter 2200, loss: 2.318909, top_1: 0.668789, top_k: 0.857578, samples/s: 2930.217 1612048812.561898
train: epoch 130, iter 2300, loss: 2.280713, top_1: 0.661016, top_k: 0.858750, samples/s: 2993.673 1612048821.1131814
train: epoch 130, iter 2400, loss: 2.343506, top_1: 0.667383, top_k: 0.857109, samples/s: 2975.226 1612048829.7175913
train: epoch 130, iter 2500, loss: 2.399297, top_1: 0.669883, top_k: 0.859961, samples/s: 2970.160 1612048838.3367012
train: epoch 130, iter 2600, loss: 2.471328, top_1: 0.670547, top_k: 0.863789, samples/s: 3002.803 1612048846.862484
train: epoch 130, iter 2700, loss: 2.377554, top_1: 0.669883, top_k: 0.862109, samples/s: 2961.912 1612048855.505226
train: epoch 130, iter 2800, loss: 2.393755, top_1: 0.667500, top_k: 0.858789, samples/s: 2976.271 1612048864.1064353
train: epoch 130, iter 2900, loss: 2.553835, top_1: 0.675547, top_k: 0.862812, samples/s: 2898.599 1612048872.9383407
train: epoch 130, iter 3000, loss: 2.468734, top_1: 0.672656, top_k: 0.860977, samples/s: 2983.567 1612048881.518631
train: epoch 130, iter 3100, loss: 2.458472, top_1: 0.672617, top_k: 0.859570, samples/s: 2972.290 1612048890.1320398
train: epoch 130, iter 3200, loss: 2.521301, top_1: 0.672500, top_k: 0.863359, samples/s: 3001.845 1612048898.6596024
train: epoch 130, iter 3300, loss: 2.596794, top_1: 0.669414, top_k: 0.863477, samples/s: 2986.482 1612048907.2316482
train: epoch 130, iter 3400, loss: 2.361561, top_1: 0.670078, top_k: 0.858477, samples/s: 2966.744 1612048915.8605876
train: epoch 130, iter 3500, loss: 2.460081, top_1: 0.670781, top_k: 0.860625, samples/s: 2984.194 1612048924.4391093
train: epoch 130, iter 3600, loss: 2.453003, top_1: 0.667461, top_k: 0.858242, samples/s: 3014.753 1612048932.9306724
train: epoch 130, iter 3700, loss: 2.433034, top_1: 0.664180, top_k: 0.855977, samples/s: 3003.528 1612048941.453978
train: epoch 130, iter 3800, loss: 2.503098, top_1: 0.666680, top_k: 0.856367, samples/s: 2892.258 1612048950.3052897
train: epoch 130, iter 3900, loss: 2.428897, top_1: 0.668164, top_k: 0.858437, samples/s: 2980.636 1612048958.8939912
train: epoch 130, iter 4000, loss: 2.497729, top_1: 0.668984, top_k: 0.863008, samples/s: 2991.608 1612048967.451224
train: epoch 130, iter 4100, loss: 2.162211, top_1: 0.666992, top_k: 0.857578, samples/s: 3015.928 1612048975.939526
train: epoch 130, iter 4200, loss: 2.546924, top_1: 0.664023, top_k: 0.856992, samples/s: 2958.755 1612048984.591823
train: epoch 130, iter 4300, loss: 2.360132, top_1: 0.667500, top_k: 0.859883, samples/s: 2977.931 1612048993.1883855
train: epoch 130, iter 4400, loss: 2.181331, top_1: 0.678164, top_k: 0.865391, samples/s: 2935.054 1612049001.9104998
train: epoch 130, iter 4500, loss: 2.243068, top_1: 0.667383, top_k: 0.860039, samples/s: 3003.857 1612049010.432864
train: epoch 130, iter 4600, loss: 2.623411, top_1: 0.669141, top_k: 0.862109, samples/s: 2984.379 1612049019.0108716
train: epoch 130, iter 4700, loss: 2.351753, top_1: 0.671992, top_k: 0.861680, samples/s: 2906.011 1612049027.8202267
train: epoch 130, iter 4800, loss: 2.275188, top_1: 0.667695, top_k: 0.859375, samples/s: 2940.297 1612049036.5268147
train: epoch 130, iter 4900, loss: 2.331204, top_1: 0.668945, top_k: 0.860820, samples/s: 2992.463 1612049045.081693
train: epoch 130, iter 5000, loss: 2.371401, top_1: 0.674297, top_k: 0.862070, samples/s: 2934.067 1612049053.8067777
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_130.
validation: epoch 130, iter 195, top_1: 0.694451, top_k: 0.888682, samples/s: 2985.574 1612049070.7530432
train: epoch 131, iter 100, loss: 2.168741, top_1: 0.679219, top_k: 0.867812, samples/s: 2934.420 1612049095.7307653
train: epoch 131, iter 200, loss: 2.279865, top_1: 0.682344, top_k: 0.868633, samples/s: 2975.345 1612049104.3347929
train: epoch 131, iter 300, loss: 2.360537, top_1: 0.678242, top_k: 0.863594, samples/s: 3010.517 1612049112.83836
train: epoch 131, iter 400, loss: 2.479833, top_1: 0.669727, top_k: 0.860742, samples/s: 3004.170 1612049121.3598359
train: epoch 131, iter 500, loss: 2.272624, top_1: 0.675117, top_k: 0.862852, samples/s: 3009.850 1612049129.8652942
train: epoch 131, iter 600, loss: 2.343543, top_1: 0.674883, top_k: 0.858555, samples/s: 2941.692 1612049138.5677106
train: epoch 131, iter 700, loss: 2.330511, top_1: 0.678438, top_k: 0.868984, samples/s: 3004.094 1612049147.089444
train: epoch 131, iter 800, loss: 2.283003, top_1: 0.673984, top_k: 0.861797, samples/s: 2911.181 1612049155.8831003
train: epoch 131, iter 900, loss: 2.427946, top_1: 0.672227, top_k: 0.862422, samples/s: 2996.870 1612049164.4254582
train: epoch 131, iter 1000, loss: 2.334966, top_1: 0.674805, top_k: 0.861836, samples/s: 2961.367 1612049173.0700307
train: epoch 131, iter 1100, loss: 2.402130, top_1: 0.675391, top_k: 0.859141, samples/s: 3001.481 1612049181.599208
train: epoch 131, iter 1200, loss: 2.406270, top_1: 0.678633, top_k: 0.867422, samples/s: 2863.243 1612049190.540011
train: epoch 131, iter 1300, loss: 2.547291, top_1: 0.675742, top_k: 0.862656, samples/s: 2994.925 1612049199.0878022
train: epoch 131, iter 1400, loss: 2.481683, top_1: 0.675820, top_k: 0.862227, samples/s: 3008.807 1612049207.5961728
train: epoch 131, iter 1500, loss: 2.270627, top_1: 0.669141, top_k: 0.862109, samples/s: 2965.065 1612049216.2301052
train: epoch 131, iter 1600, loss: 2.307625, top_1: 0.669297, top_k: 0.860234, samples/s: 2916.340 1612049225.0081618
train: epoch 131, iter 1700, loss: 2.362599, top_1: 0.672617, top_k: 0.859023, samples/s: 2987.453 1612049233.5774364
train: epoch 131, iter 1800, loss: 2.232407, top_1: 0.672891, top_k: 0.864219, samples/s: 2966.240 1612049242.2078602
train: epoch 131, iter 1900, loss: 2.421776, top_1: 0.671445, top_k: 0.861445, samples/s: 2987.200 1612049250.7776983
train: epoch 131, iter 2000, loss: 2.435947, top_1: 0.669609, top_k: 0.858789, samples/s: 2967.791 1612049259.4037693
train: epoch 131, iter 2100, loss: 2.453015, top_1: 0.669023, top_k: 0.860117, samples/s: 2965.428 1612049268.0364401
train: epoch 131, iter 2200, loss: 2.252396, top_1: 0.672578, top_k: 0.861680, samples/s: 2925.358 1612049276.787623
train: epoch 131, iter 2300, loss: 2.380247, top_1: 0.670703, top_k: 0.861016, samples/s: 2969.498 1612049285.408637
train: epoch 131, iter 2400, loss: 2.526285, top_1: 0.676094, top_k: 0.861523, samples/s: 2956.920 1612049294.0663292
train: epoch 131, iter 2500, loss: 2.333922, top_1: 0.672188, top_k: 0.861133, samples/s: 2956.718 1612049302.724499
train: epoch 131, iter 2600, loss: 2.316554, top_1: 0.674531, top_k: 0.859258, samples/s: 2940.827 1612049311.4294705
train: epoch 131, iter 2700, loss: 2.522785, top_1: 0.671133, top_k: 0.863398, samples/s: 2963.143 1612049320.0690897
train: epoch 131, iter 2800, loss: 2.528930, top_1: 0.674375, top_k: 0.865313, samples/s: 2950.266 1612049328.7461853
train: epoch 131, iter 2900, loss: 2.406549, top_1: 0.671562, top_k: 0.861836, samples/s: 2975.998 1612049337.348428
train: epoch 131, iter 3000, loss: 2.153682, top_1: 0.673945, top_k: 0.860391, samples/s: 2956.830 1612049346.0062463
train: epoch 131, iter 3100, loss: 2.477833, top_1: 0.667344, top_k: 0.859414, samples/s: 2990.437 1612049354.5668082
train: epoch 131, iter 3200, loss: 2.318855, top_1: 0.672969, top_k: 0.862422, samples/s: 2891.349 1612049363.4208238
train: epoch 131, iter 3300, loss: 2.445922, top_1: 0.671094, top_k: 0.863242, samples/s: 3014.658 1612049371.9133341
train: epoch 131, iter 3400, loss: 2.309712, top_1: 0.673789, top_k: 0.861875, samples/s: 3002.337 1612049380.4393482
train: epoch 131, iter 3500, loss: 2.293584, top_1: 0.667500, top_k: 0.858477, samples/s: 2909.571 1612049389.237895
train: epoch 131, iter 3600, loss: 2.281877, top_1: 0.674570, top_k: 0.861797, samples/s: 2970.014 1612049397.8574483
train: epoch 131, iter 3700, loss: 2.327345, top_1: 0.675820, top_k: 0.863906, samples/s: 2966.962 1612049406.4857779
train: epoch 131, iter 3800, loss: 2.309271, top_1: 0.668867, top_k: 0.860781, samples/s: 2954.242 1612049415.1512432
train: epoch 131, iter 3900, loss: 2.488542, top_1: 0.673477, top_k: 0.863516, samples/s: 2917.197 1612049423.9268184
train: epoch 131, iter 4000, loss: 2.201337, top_1: 0.673398, top_k: 0.861992, samples/s: 3004.506 1612049432.4473176
train: epoch 131, iter 4100, loss: 2.294667, top_1: 0.671641, top_k: 0.861914, samples/s: 2995.015 1612049440.994859
train: epoch 131, iter 4200, loss: 2.412123, top_1: 0.668047, top_k: 0.859375, samples/s: 2945.248 1612049449.6868875
train: epoch 131, iter 4300, loss: 2.274726, top_1: 0.668398, top_k: 0.861094, samples/s: 2916.430 1612049458.4646733
train: epoch 131, iter 4400, loss: 2.348849, top_1: 0.671094, top_k: 0.860664, samples/s: 2951.909 1612049467.1374218
train: epoch 131, iter 4500, loss: 2.213844, top_1: 0.674219, top_k: 0.863672, samples/s: 2987.345 1612049475.7065265
train: epoch 131, iter 4600, loss: 2.500310, top_1: 0.673281, top_k: 0.862852, samples/s: 2985.568 1612049484.2810686
train: epoch 131, iter 4700, loss: 2.455940, top_1: 0.668555, top_k: 0.862344, samples/s: 2982.607 1612049492.8643684
train: epoch 131, iter 4800, loss: 2.384000, top_1: 0.674375, top_k: 0.863711, samples/s: 3001.701 1612049501.3926945
train: epoch 131, iter 4900, loss: 2.387419, top_1: 0.666992, top_k: 0.857305, samples/s: 2990.120 1612049509.9546444
train: epoch 131, iter 5000, loss: 2.256821, top_1: 0.679570, top_k: 0.866836, samples/s: 3007.636 1612049518.465885
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_131.
validation: epoch 131, iter 195, top_1: 0.697536, top_k: 0.891827, samples/s: 2921.644 1612049535.8219893
train: epoch 132, iter 100, loss: 2.334649, top_1: 0.680117, top_k: 0.869258, samples/s: 2982.524 1612049560.3895578
train: epoch 132, iter 200, loss: 2.220267, top_1: 0.680820, top_k: 0.868398, samples/s: 2947.732 1612049569.07416
train: epoch 132, iter 300, loss: 2.381412, top_1: 0.679844, top_k: 0.862773, samples/s: 2943.388 1612049577.771647
train: epoch 132, iter 400, loss: 2.374941, top_1: 0.677188, top_k: 0.866797, samples/s: 3002.704 1612049586.29741
train: epoch 132, iter 500, loss: 2.408795, top_1: 0.677148, top_k: 0.865352, samples/s: 2961.709 1612049594.9409347
train: epoch 132, iter 600, loss: 2.395428, top_1: 0.680469, top_k: 0.865547, samples/s: 2975.609 1612049603.544217
train: epoch 132, iter 700, loss: 2.408142, top_1: 0.678750, top_k: 0.869180, samples/s: 3013.243 1612049612.0401325
train: epoch 132, iter 800, loss: 2.540772, top_1: 0.671484, top_k: 0.863125, samples/s: 2974.615 1612049620.6465216
train: epoch 132, iter 900, loss: 2.393987, top_1: 0.674805, top_k: 0.863633, samples/s: 2958.492 1612049629.2992628
train: epoch 132, iter 1000, loss: 2.399917, top_1: 0.671562, top_k: 0.859609, samples/s: 2975.063 1612049637.9046984
train: epoch 132, iter 1100, loss: 2.368086, top_1: 0.676016, top_k: 0.864258, samples/s: 2984.788 1612049646.4809866
train: epoch 132, iter 1200, loss: 2.427833, top_1: 0.675742, top_k: 0.865430, samples/s: 3014.916 1612049654.9720478
train: epoch 132, iter 1300, loss: 2.261948, top_1: 0.675547, top_k: 0.864375, samples/s: 2976.035 1612049663.5742018
train: epoch 132, iter 1400, loss: 2.565487, top_1: 0.671211, top_k: 0.863477, samples/s: 2966.798 1612049672.2029314
train: epoch 132, iter 1500, loss: 2.223504, top_1: 0.678711, top_k: 0.864648, samples/s: 3004.491 1612049680.7235312
train: epoch 132, iter 1600, loss: 2.505291, top_1: 0.676797, top_k: 0.864531, samples/s: 2953.691 1612049689.3907425
train: epoch 132, iter 1700, loss: 2.611464, top_1: 0.675469, top_k: 0.865156, samples/s: 3006.468 1612049697.905614
train: epoch 132, iter 1800, loss: 2.246127, top_1: 0.681055, top_k: 0.864375, samples/s: 2988.804 1612049706.470923
train: epoch 132, iter 1900, loss: 2.354225, top_1: 0.674922, top_k: 0.864727, samples/s: 2834.515 1612049715.5024621
train: epoch 132, iter 2000, loss: 2.373431, top_1: 0.681797, top_k: 0.870781, samples/s: 2932.618 1612049724.231855
train: epoch 132, iter 2100, loss: 2.476248, top_1: 0.675898, top_k: 0.862656, samples/s: 2902.371 1612049733.0523586
train: epoch 132, iter 2200, loss: 2.411965, top_1: 0.675547, top_k: 0.867930, samples/s: 2948.808 1612049741.7336822
train: epoch 132, iter 2300, loss: 2.400132, top_1: 0.679102, top_k: 0.860586, samples/s: 2945.446 1612049750.4251037
train: epoch 132, iter 2400, loss: 2.287398, top_1: 0.671484, top_k: 0.861055, samples/s: 2939.939 1612049759.1327696
train: epoch 132, iter 2500, loss: 2.328429, top_1: 0.673516, top_k: 0.863750, samples/s: 2975.874 1612049767.735341
train: epoch 132, iter 2600, loss: 2.375899, top_1: 0.671172, top_k: 0.863984, samples/s: 2972.135 1612049776.3485985
train: epoch 132, iter 2700, loss: 2.324238, top_1: 0.670430, top_k: 0.862852, samples/s: 2978.984 1612049784.9421878
train: epoch 132, iter 2800, loss: 2.403375, top_1: 0.676133, top_k: 0.867539, samples/s: 2968.803 1612049793.5651648
train: epoch 132, iter 2900, loss: 2.317101, top_1: 0.674883, top_k: 0.866445, samples/s: 2948.031 1612049802.2488976
train: epoch 132, iter 3000, loss: 2.170191, top_1: 0.676328, top_k: 0.861211, samples/s: 2980.693 1612049810.8374841
train: epoch 132, iter 3100, loss: 2.306436, top_1: 0.676953, top_k: 0.866328, samples/s: 2942.050 1612049819.5389514
train: epoch 132, iter 3200, loss: 2.398097, top_1: 0.671094, top_k: 0.860742, samples/s: 3017.986 1612049828.0213947
train: epoch 132, iter 3300, loss: 2.391485, top_1: 0.676914, top_k: 0.867461, samples/s: 2972.851 1612049836.6326573
train: epoch 132, iter 3400, loss: 2.465797, top_1: 0.673633, top_k: 0.862227, samples/s: 2998.394 1612049845.170547
train: epoch 132, iter 3500, loss: 2.415379, top_1: 0.673633, top_k: 0.866523, samples/s: 2970.431 1612049853.7888224
train: epoch 132, iter 3600, loss: 2.377260, top_1: 0.675273, top_k: 0.862812, samples/s: 2981.087 1612049862.3763723
train: epoch 132, iter 3700, loss: 2.261541, top_1: 0.674180, top_k: 0.860820, samples/s: 2973.843 1612049870.9846895
train: epoch 132, iter 3800, loss: 2.373118, top_1: 0.673594, top_k: 0.861367, samples/s: 2973.191 1612049879.5950928
train: epoch 132, iter 3900, loss: 2.304437, top_1: 0.676758, top_k: 0.863906, samples/s: 3008.387 1612049888.1045182
train: epoch 132, iter 4000, loss: 2.371799, top_1: 0.676133, top_k: 0.862891, samples/s: 2949.497 1612049896.7839882
train: epoch 132, iter 4100, loss: 2.269047, top_1: 0.673047, top_k: 0.860234, samples/s: 2979.090 1612049905.3771484
train: epoch 132, iter 4200, loss: 2.541854, top_1: 0.678242, top_k: 0.864414, samples/s: 2964.787 1612049914.0118804
train: epoch 132, iter 4300, loss: 2.405974, top_1: 0.674180, top_k: 0.863555, samples/s: 2990.693 1612049922.5718179
train: epoch 132, iter 4400, loss: 2.414902, top_1: 0.675195, top_k: 0.863437, samples/s: 2915.635 1612049931.352005
train: epoch 132, iter 4500, loss: 2.358560, top_1: 0.671484, top_k: 0.859883, samples/s: 2964.626 1612049939.987281
train: epoch 132, iter 4600, loss: 2.451535, top_1: 0.672656, top_k: 0.863594, samples/s: 2992.288 1612049948.5425394
train: epoch 132, iter 4700, loss: 2.293228, top_1: 0.678398, top_k: 0.866445, samples/s: 2999.220 1612049957.078224
train: epoch 132, iter 4800, loss: 2.401108, top_1: 0.674453, top_k: 0.862695, samples/s: 3011.676 1612049965.578304
train: epoch 132, iter 4900, loss: 2.380473, top_1: 0.673789, top_k: 0.861133, samples/s: 2970.834 1612049974.195389
train: epoch 132, iter 5000, loss: 2.324261, top_1: 0.679453, top_k: 0.867539, samples/s: 2962.419 1612049982.8370154
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_132.
validation: epoch 132, iter 195, top_1: 0.701262, top_k: 0.894071, samples/s: 2966.831 1612049999.916429
train: epoch 133, iter 100, loss: 2.495481, top_1: 0.687617, top_k: 0.866328, samples/s: 2933.565 1612050024.5858274
train: epoch 133, iter 200, loss: 2.228497, top_1: 0.676680, top_k: 0.864023, samples/s: 3007.479 1612050033.0979931
train: epoch 133, iter 300, loss: 2.351931, top_1: 0.681406, top_k: 0.867969, samples/s: 2896.772 1612050041.9353454
train: epoch 133, iter 400, loss: 2.347655, top_1: 0.683516, top_k: 0.866953, samples/s: 2995.743 1612050050.480847
train: epoch 133, iter 500, loss: 2.471760, top_1: 0.678711, top_k: 0.868359, samples/s: 3010.399 1612050058.9846597
train: epoch 133, iter 600, loss: 2.200529, top_1: 0.681641, top_k: 0.870195, samples/s: 2972.639 1612050067.5966423
train: epoch 133, iter 700, loss: 2.306338, top_1: 0.682109, top_k: 0.868477, samples/s: 3002.563 1612050076.1226282
train: epoch 133, iter 800, loss: 2.454980, top_1: 0.681914, top_k: 0.866250, samples/s: 2918.411 1612050084.8944888
train: epoch 133, iter 900, loss: 2.211863, top_1: 0.683672, top_k: 0.866172, samples/s: 2938.987 1612050093.6050258
train: epoch 133, iter 1000, loss: 2.482222, top_1: 0.682461, top_k: 0.865859, samples/s: 3002.553 1612050102.1310527
train: epoch 133, iter 1100, loss: 2.298125, top_1: 0.673359, top_k: 0.863906, samples/s: 2938.173 1612050110.844046
train: epoch 133, iter 1200, loss: 2.410519, top_1: 0.682227, top_k: 0.865352, samples/s: 3004.896 1612050119.3633778
train: epoch 133, iter 1300, loss: 2.417255, top_1: 0.683906, top_k: 0.870430, samples/s: 3003.696 1612050127.8862913
train: epoch 133, iter 1400, loss: 2.156662, top_1: 0.670859, top_k: 0.865391, samples/s: 2988.467 1612050136.4524996
train: epoch 133, iter 1500, loss: 2.288007, top_1: 0.681641, top_k: 0.869570, samples/s: 2938.757 1612050145.1642656
train: epoch 133, iter 1600, loss: 2.290663, top_1: 0.683711, top_k: 0.866445, samples/s: 2987.897 1612050153.7315788
train: epoch 133, iter 1700, loss: 2.089126, top_1: 0.684727, top_k: 0.872734, samples/s: 2992.673 1612050162.2857823
train: epoch 133, iter 1800, loss: 2.300583, top_1: 0.677031, top_k: 0.864023, samples/s: 2863.442 1612050171.2265162
train: epoch 133, iter 1900, loss: 2.401984, top_1: 0.681328, top_k: 0.866445, samples/s: 3045.465 1612050179.6319919
train: epoch 133, iter 2000, loss: 2.307266, top_1: 0.678594, top_k: 0.866680, samples/s: 2971.846 1612050188.2461889
train: epoch 133, iter 2100, loss: 2.382547, top_1: 0.674297, top_k: 0.862734, samples/s: 2948.412 1612050196.9288075
train: epoch 133, iter 2200, loss: 2.247539, top_1: 0.678086, top_k: 0.863203, samples/s: 2974.567 1612050205.535156
train: epoch 133, iter 2300, loss: 2.269392, top_1: 0.672930, top_k: 0.863437, samples/s: 2933.954 1612050214.260613
train: epoch 133, iter 2400, loss: 2.603165, top_1: 0.681172, top_k: 0.866875, samples/s: 2915.000 1612050223.042867
train: epoch 133, iter 2500, loss: 2.394723, top_1: 0.675703, top_k: 0.864883, samples/s: 2931.085 1612050231.7766545
train: epoch 133, iter 2600, loss: 2.127322, top_1: 0.680937, top_k: 0.866172, samples/s: 2994.861 1612050240.3247192
train: epoch 133, iter 2700, loss: 2.338834, top_1: 0.679297, top_k: 0.869023, samples/s: 2972.189 1612050248.9378319
train: epoch 133, iter 2800, loss: 2.566705, top_1: 0.677617, top_k: 0.864648, samples/s: 2911.994 1612050257.7290492
train: epoch 133, iter 2900, loss: 2.326243, top_1: 0.675977, top_k: 0.864062, samples/s: 2978.326 1612050266.3245187
train: epoch 133, iter 3000, loss: 2.270025, top_1: 0.675508, top_k: 0.864375, samples/s: 2952.305 1612050274.9956641
train: epoch 133, iter 3100, loss: 2.437635, top_1: 0.671250, top_k: 0.862070, samples/s: 2959.325 1612050283.6463485
train: epoch 133, iter 3200, loss: 2.360111, top_1: 0.679609, top_k: 0.866602, samples/s: 2973.699 1612050292.2551029
train: epoch 133, iter 3300, loss: 2.339368, top_1: 0.679961, top_k: 0.865391, samples/s: 2979.333 1612050300.847626
train: epoch 133, iter 3400, loss: 2.394448, top_1: 0.674687, top_k: 0.864414, samples/s: 3001.857 1612050309.3757188
train: epoch 133, iter 3500, loss: 2.371587, top_1: 0.675508, top_k: 0.867500, samples/s: 2985.785 1612050317.9496448
train: epoch 133, iter 3600, loss: 2.538318, top_1: 0.674766, top_k: 0.865508, samples/s: 2985.248 1612050326.5251544
train: epoch 133, iter 3700, loss: 2.268355, top_1: 0.677227, top_k: 0.868789, samples/s: 2957.182 1612050335.1820378
train: epoch 133, iter 3800, loss: 2.238929, top_1: 0.678047, top_k: 0.867148, samples/s: 3021.277 1612050343.6552818
train: epoch 133, iter 3900, loss: 2.321664, top_1: 0.676758, top_k: 0.865234, samples/s: 2850.614 1612050352.6358058
train: epoch 133, iter 4000, loss: 2.315446, top_1: 0.672500, top_k: 0.863437, samples/s: 2953.136 1612050361.3045552
train: epoch 133, iter 4100, loss: 2.335494, top_1: 0.677344, top_k: 0.865391, samples/s: 3034.212 1612050369.7416852
train: epoch 133, iter 4200, loss: 2.312024, top_1: 0.679727, top_k: 0.861875, samples/s: 3006.725 1612050378.2559385
train: epoch 133, iter 4300, loss: 2.097436, top_1: 0.679375, top_k: 0.866211, samples/s: 2936.464 1612050386.9738822
train: epoch 133, iter 4400, loss: 2.420933, top_1: 0.676211, top_k: 0.867070, samples/s: 2984.535 1612050395.5514386
train: epoch 133, iter 4500, loss: 2.484735, top_1: 0.677461, top_k: 0.863555, samples/s: 2892.846 1612050404.400881
train: epoch 133, iter 4600, loss: 2.202923, top_1: 0.683867, top_k: 0.865859, samples/s: 2995.562 1612050412.9468095
train: epoch 133, iter 4700, loss: 2.226214, top_1: 0.678438, top_k: 0.865664, samples/s: 3003.907 1612050421.4690495
train: epoch 133, iter 4800, loss: 2.429165, top_1: 0.680312, top_k: 0.867188, samples/s: 2961.908 1612050430.1122608
train: epoch 133, iter 4900, loss: 2.280256, top_1: 0.678008, top_k: 0.865898, samples/s: 3013.782 1612050438.6064305
train: epoch 133, iter 5000, loss: 2.436533, top_1: 0.678633, top_k: 0.864180, samples/s: 3006.783 1612050447.1206117
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_133.
validation: epoch 133, iter 195, top_1: 0.703125, top_k: 0.894772, samples/s: 3001.082 1612050464.087413
train: epoch 134, iter 100, loss: 2.324912, top_1: 0.687930, top_k: 0.872266, samples/s: 2978.933 1612050488.7842138
train: epoch 134, iter 200, loss: 2.514991, top_1: 0.685859, top_k: 0.868633, samples/s: 2919.537 1612050497.5527077
train: epoch 134, iter 300, loss: 2.407428, top_1: 0.685391, top_k: 0.870234, samples/s: 3003.321 1612050506.0766218
train: epoch 134, iter 400, loss: 2.318828, top_1: 0.686719, top_k: 0.870234, samples/s: 3009.106 1612050514.584217
train: epoch 134, iter 500, loss: 2.284143, top_1: 0.678242, top_k: 0.868516, samples/s: 2987.907 1612050523.1519809
train: epoch 134, iter 600, loss: 2.091314, top_1: 0.685977, top_k: 0.870898, samples/s: 2972.119 1612050531.7653787
train: epoch 134, iter 700, loss: 2.345868, top_1: 0.688633, top_k: 0.872656, samples/s: 3011.151 1612050540.2671018
train: epoch 134, iter 800, loss: 2.329414, top_1: 0.684570, top_k: 0.870938, samples/s: 2896.066 1612050549.1067617
train: epoch 134, iter 900, loss: 2.426816, top_1: 0.689414, top_k: 0.871719, samples/s: 2996.920 1612050557.6487803
train: epoch 134, iter 1000, loss: 2.220308, top_1: 0.679609, top_k: 0.868828, samples/s: 2948.675 1612050566.3306346
train: epoch 134, iter 1100, loss: 2.363293, top_1: 0.683516, top_k: 0.871719, samples/s: 2987.315 1612050574.9003422
train: epoch 134, iter 1200, loss: 2.466045, top_1: 0.678828, top_k: 0.866641, samples/s: 3000.813 1612050583.431238
train: epoch 134, iter 1300, loss: 2.362626, top_1: 0.684023, top_k: 0.867461, samples/s: 2961.477 1612050592.0755625
train: epoch 134, iter 1400, loss: 2.147377, top_1: 0.686602, top_k: 0.868203, samples/s: 2993.028 1612050600.628781
train: epoch 134, iter 1500, loss: 2.262600, top_1: 0.681523, top_k: 0.868789, samples/s: 2992.973 1612050609.1821485
train: epoch 134, iter 1600, loss: 2.324688, top_1: 0.679805, top_k: 0.867031, samples/s: 2894.734 1612050618.0257895
train: epoch 134, iter 1700, loss: 2.506734, top_1: 0.680937, top_k: 0.865430, samples/s: 3011.694 1612050626.5260105
train: epoch 134, iter 1800, loss: 2.414552, top_1: 0.684297, top_k: 0.870859, samples/s: 2993.797 1612050635.0774379
train: epoch 134, iter 1900, loss: 2.431155, top_1: 0.677227, top_k: 0.867344, samples/s: 2973.710 1612050643.6857865
train: epoch 134, iter 2000, loss: 2.391873, top_1: 0.680703, top_k: 0.870586, samples/s: 2970.229 1612050652.3046563
train: epoch 134, iter 2100, loss: 2.480937, top_1: 0.681016, top_k: 0.868867, samples/s: 2971.984 1612050660.9183953
train: epoch 134, iter 2200, loss: 2.414393, top_1: 0.686211, top_k: 0.871641, samples/s: 2995.187 1612050669.465615
train: epoch 134, iter 2300, loss: 2.282933, top_1: 0.680664, top_k: 0.865977, samples/s: 2982.639 1612050678.0484767
train: epoch 134, iter 2400, loss: 2.380208, top_1: 0.684258, top_k: 0.867812, samples/s: 2978.291 1612050686.6440618
train: epoch 134, iter 2500, loss: 2.384778, top_1: 0.678672, top_k: 0.866328, samples/s: 2928.424 1612050695.3859797
train: epoch 134, iter 2600, loss: 2.374676, top_1: 0.685703, top_k: 0.869648, samples/s: 2994.469 1612050703.9350328
train: epoch 134, iter 2700, loss: 2.321729, top_1: 0.684141, top_k: 0.868594, samples/s: 2908.704 1612050712.7362123
train: epoch 134, iter 2800, loss: 2.214797, top_1: 0.678906, top_k: 0.865703, samples/s: 2887.231 1612050721.6028073
train: epoch 134, iter 2900, loss: 2.370513, top_1: 0.681094, top_k: 0.864297, samples/s: 2956.391 1612050730.2620091
train: epoch 134, iter 3000, loss: 2.325942, top_1: 0.682187, top_k: 0.869219, samples/s: 2994.073 1612050738.8127117
train: epoch 134, iter 3100, loss: 2.350618, top_1: 0.685000, top_k: 0.867266, samples/s: 2962.036 1612050747.4550009
train: epoch 134, iter 3200, loss: 2.359432, top_1: 0.683828, top_k: 0.867852, samples/s: 2972.739 1612050756.066645
train: epoch 134, iter 3300, loss: 2.149592, top_1: 0.685586, top_k: 0.871055, samples/s: 2965.797 1612050764.698272
train: epoch 134, iter 3400, loss: 2.269416, top_1: 0.674180, top_k: 0.863437, samples/s: 2977.387 1612050773.2964673
train: epoch 134, iter 3500, loss: 2.326655, top_1: 0.677734, top_k: 0.865391, samples/s: 2916.463 1612050782.0741518
train: epoch 134, iter 3600, loss: 2.565188, top_1: 0.681055, top_k: 0.868164, samples/s: 2992.289 1612050790.6294653
train: epoch 134, iter 3700, loss: 2.326390, top_1: 0.681445, top_k: 0.866406, samples/s: 2962.717 1612050799.2702243
train: epoch 134, iter 3800, loss: 2.380453, top_1: 0.682656, top_k: 0.867852, samples/s: 2969.430 1612050807.891422
train: epoch 134, iter 3900, loss: 2.435408, top_1: 0.678281, top_k: 0.863281, samples/s: 2957.532 1612050816.5472658
train: epoch 134, iter 4000, loss: 2.265507, top_1: 0.678516, top_k: 0.869883, samples/s: 3008.022 1612050825.057829
train: epoch 134, iter 4100, loss: 2.361866, top_1: 0.681328, top_k: 0.865508, samples/s: 2936.789 1612050833.774826
train: epoch 134, iter 4200, loss: 2.411890, top_1: 0.678516, top_k: 0.870234, samples/s: 3011.892 1612050842.2744663
train: epoch 134, iter 4300, loss: 2.240825, top_1: 0.678477, top_k: 0.862891, samples/s: 2807.421 1612050851.39338
train: epoch 134, iter 4400, loss: 2.207745, top_1: 0.683750, top_k: 0.869805, samples/s: 2981.300 1612050859.9800177
train: epoch 134, iter 4500, loss: 2.488469, top_1: 0.680391, top_k: 0.867695, samples/s: 2909.726 1612050868.7780716
train: epoch 134, iter 4600, loss: 2.313521, top_1: 0.683203, top_k: 0.867070, samples/s: 3010.907 1612050877.2805727
train: epoch 134, iter 4700, loss: 2.494690, top_1: 0.680312, top_k: 0.865352, samples/s: 2945.172 1612050885.9727135
train: epoch 134, iter 4800, loss: 2.339532, top_1: 0.677305, top_k: 0.869609, samples/s: 2980.357 1612050894.5622869
train: epoch 134, iter 4900, loss: 2.163017, top_1: 0.681094, top_k: 0.867578, samples/s: 2980.695 1612050903.1508775
train: epoch 134, iter 5000, loss: 2.379657, top_1: 0.682656, top_k: 0.868711, samples/s: 2980.379 1612050911.740447
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_134.
validation: epoch 134, iter 195, top_1: 0.702845, top_k: 0.895312, samples/s: 3005.290 1612050928.6171272
train: epoch 135, iter 100, loss: 2.353649, top_1: 0.690977, top_k: 0.871328, samples/s: 2990.829 1612050952.7780783
train: epoch 135, iter 200, loss: 2.196565, top_1: 0.684766, top_k: 0.872461, samples/s: 2890.322 1612050961.6351473
train: epoch 135, iter 300, loss: 2.410465, top_1: 0.686250, top_k: 0.873164, samples/s: 3034.625 1612050970.0712068
train: epoch 135, iter 400, loss: 2.349022, top_1: 0.685352, top_k: 0.872500, samples/s: 2991.729 1612050978.6281922
train: epoch 135, iter 500, loss: 2.321523, top_1: 0.684609, top_k: 0.871367, samples/s: 3021.059 1612050987.1019654
train: epoch 135, iter 600, loss: 2.167023, top_1: 0.685000, top_k: 0.871289, samples/s: 2983.236 1612050995.6832716
train: epoch 135, iter 700, loss: 2.474759, top_1: 0.682930, top_k: 0.870703, samples/s: 3009.023 1612051004.191083
train: epoch 135, iter 800, loss: 2.341321, top_1: 0.683320, top_k: 0.868125, samples/s: 3003.977 1612051012.7130263
train: epoch 135, iter 900, loss: 2.257064, top_1: 0.684844, top_k: 0.869922, samples/s: 2962.128 1612051021.355481
train: epoch 135, iter 1000, loss: 2.336126, top_1: 0.688633, top_k: 0.869922, samples/s: 3039.361 1612051029.7782562
train: epoch 135, iter 1100, loss: 2.501855, top_1: 0.681953, top_k: 0.870117, samples/s: 2960.983 1612051038.4241138
train: epoch 135, iter 1200, loss: 2.256166, top_1: 0.683359, top_k: 0.872500, samples/s: 2936.788 1612051047.1411035
train: epoch 135, iter 1300, loss: 2.369935, top_1: 0.683984, top_k: 0.868828, samples/s: 2962.007 1612051055.7838144
train: epoch 135, iter 1400, loss: 2.370754, top_1: 0.686445, top_k: 0.868125, samples/s: 3042.178 1612051064.1988509
train: epoch 135, iter 1500, loss: 2.111497, top_1: 0.679219, top_k: 0.866953, samples/s: 2892.791 1612051073.0484776
train: epoch 135, iter 1600, loss: 2.360098, top_1: 0.685117, top_k: 0.867734, samples/s: 2931.711 1612051081.780618
train: epoch 135, iter 1700, loss: 2.483217, top_1: 0.688125, top_k: 0.871328, samples/s: 2927.784 1612051090.5243466
train: epoch 135, iter 1800, loss: 2.438990, top_1: 0.690273, top_k: 0.873047, samples/s: 2947.954 1612051099.2082942
train: epoch 135, iter 1900, loss: 2.336550, top_1: 0.683477, top_k: 0.870508, samples/s: 2978.302 1612051107.8038805
train: epoch 135, iter 2000, loss: 2.149409, top_1: 0.685977, top_k: 0.870625, samples/s: 2873.778 1612051116.711984
train: epoch 135, iter 2100, loss: 2.449577, top_1: 0.681875, top_k: 0.869023, samples/s: 3014.863 1612051125.2032437
train: epoch 135, iter 2200, loss: 2.283413, top_1: 0.686094, top_k: 0.869453, samples/s: 2969.376 1612051133.824637
train: epoch 135, iter 2300, loss: 2.277306, top_1: 0.687461, top_k: 0.867188, samples/s: 2985.047 1612051142.4007661
train: epoch 135, iter 2400, loss: 2.312388, top_1: 0.687422, top_k: 0.869609, samples/s: 2947.995 1612051151.084641
train: epoch 135, iter 2500, loss: 2.393568, top_1: 0.682734, top_k: 0.867344, samples/s: 3009.159 1612051159.5919113
train: epoch 135, iter 2600, loss: 2.504296, top_1: 0.683203, top_k: 0.871445, samples/s: 2969.660 1612051168.212512
train: epoch 135, iter 2700, loss: 2.404154, top_1: 0.682578, top_k: 0.868437, samples/s: 2954.592 1612051176.8768933
train: epoch 135, iter 2800, loss: 2.364461, top_1: 0.684648, top_k: 0.871406, samples/s: 2931.195 1612051185.6105607
train: epoch 135, iter 2900, loss: 2.498607, top_1: 0.684570, top_k: 0.869492, samples/s: 3007.105 1612051194.1237018
train: epoch 135, iter 3000, loss: 2.490288, top_1: 0.683750, top_k: 0.868125, samples/s: 2889.683 1612051202.982927
train: epoch 135, iter 3100, loss: 2.287478, top_1: 0.687148, top_k: 0.870977, samples/s: 2987.365 1612051211.5523446
train: epoch 135, iter 3200, loss: 2.333015, top_1: 0.685078, top_k: 0.865938, samples/s: 3005.974 1612051220.0687134
train: epoch 135, iter 3300, loss: 2.025504, top_1: 0.685703, top_k: 0.868516, samples/s: 2903.333 1612051228.8861563
train: epoch 135, iter 3400, loss: 2.540749, top_1: 0.685508, top_k: 0.869805, samples/s: 2961.855 1612051237.529299
train: epoch 135, iter 3500, loss: 2.309044, top_1: 0.684727, top_k: 0.869102, samples/s: 2991.164 1612051246.0878356
train: epoch 135, iter 3600, loss: 2.362122, top_1: 0.680078, top_k: 0.870117, samples/s: 2974.283 1612051254.6949518
train: epoch 135, iter 3700, loss: 2.322958, top_1: 0.683359, top_k: 0.868594, samples/s: 2981.148 1612051263.2822406
train: epoch 135, iter 3800, loss: 2.391990, top_1: 0.678047, top_k: 0.865039, samples/s: 2960.560 1612051271.9292653
train: epoch 135, iter 3900, loss: 2.512409, top_1: 0.681797, top_k: 0.867227, samples/s: 3001.712 1612051280.4578547
train: epoch 135, iter 4000, loss: 2.239435, top_1: 0.688711, top_k: 0.871445, samples/s: 2943.033 1612051289.1562705
train: epoch 135, iter 4100, loss: 2.280270, top_1: 0.688008, top_k: 0.869141, samples/s: 2963.596 1612051297.7944474
train: epoch 135, iter 4200, loss: 2.343004, top_1: 0.680742, top_k: 0.865820, samples/s: 2968.828 1612051306.4173987
train: epoch 135, iter 4300, loss: 2.374393, top_1: 0.688086, top_k: 0.872539, samples/s: 2975.296 1612051315.0215735
train: epoch 135, iter 4400, loss: 2.398036, top_1: 0.683789, top_k: 0.870078, samples/s: 2993.698 1612051323.5728161
train: epoch 135, iter 4500, loss: 2.399080, top_1: 0.683984, top_k: 0.870195, samples/s: 2948.070 1612051332.2564602
train: epoch 135, iter 4600, loss: 2.327937, top_1: 0.683086, top_k: 0.869922, samples/s: 2974.536 1612051340.8628528
train: epoch 135, iter 4700, loss: 2.343950, top_1: 0.690820, top_k: 0.870156, samples/s: 2955.176 1612051349.525634
train: epoch 135, iter 4800, loss: 2.328806, top_1: 0.686641, top_k: 0.871914, samples/s: 2964.678 1612051358.160616
train: epoch 135, iter 4900, loss: 2.325972, top_1: 0.686211, top_k: 0.871406, samples/s: 2948.083 1612051366.8442304
train: epoch 135, iter 5000, loss: 2.131956, top_1: 0.691406, top_k: 0.873828, samples/s: 2989.770 1612051375.406751
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_135.
validation: epoch 135, iter 195, top_1: 0.704888, top_k: 0.896675, samples/s: 3066.591 1612051391.940611
train: epoch 136, iter 100, loss: 2.328469, top_1: 0.692695, top_k: 0.873047, samples/s: 2918.125 1612051416.5501997
train: epoch 136, iter 200, loss: 2.436104, top_1: 0.695391, top_k: 0.873477, samples/s: 3021.858 1612051425.0216901
train: epoch 136, iter 300, loss: 2.282231, top_1: 0.689375, top_k: 0.872383, samples/s: 2999.296 1612051433.5571074
train: epoch 136, iter 400, loss: 2.268459, top_1: 0.688359, top_k: 0.869219, samples/s: 2985.249 1612051442.1325872
train: epoch 136, iter 500, loss: 2.152480, top_1: 0.683125, top_k: 0.869141, samples/s: 2962.440 1612051450.7740924
train: epoch 136, iter 600, loss: 2.338782, top_1: 0.690586, top_k: 0.873008, samples/s: 2980.103 1612051459.364594
train: epoch 136, iter 700, loss: 2.264859, top_1: 0.686016, top_k: 0.871602, samples/s: 2995.854 1612051467.9095137
train: epoch 136, iter 800, loss: 2.234942, top_1: 0.689961, top_k: 0.870977, samples/s: 2964.402 1612051476.5453088
train: epoch 136, iter 900, loss: 2.381912, top_1: 0.691562, top_k: 0.870625, samples/s: 2987.564 1612051485.1143718
train: epoch 136, iter 1000, loss: 2.415394, top_1: 0.684844, top_k: 0.872109, samples/s: 2974.035 1612051493.7220168
train: epoch 136, iter 1100, loss: 2.337591, top_1: 0.684102, top_k: 0.867734, samples/s: 3009.823 1612051502.227535
train: epoch 136, iter 1200, loss: 2.252959, top_1: 0.690703, top_k: 0.872578, samples/s: 2896.064 1612051511.0670698
train: epoch 136, iter 1300, loss: 2.256113, top_1: 0.681914, top_k: 0.872500, samples/s: 2919.443 1612051519.8358974
train: epoch 136, iter 1400, loss: 2.160669, top_1: 0.689297, top_k: 0.872227, samples/s: 2929.332 1612051528.5750556
train: epoch 136, iter 1500, loss: 2.233881, top_1: 0.689141, top_k: 0.870625, samples/s: 2971.697 1612051537.1896477
train: epoch 136, iter 1600, loss: 2.399001, top_1: 0.687617, top_k: 0.870664, samples/s: 2970.063 1612051545.809082
train: epoch 136, iter 1700, loss: 2.300497, top_1: 0.687070, top_k: 0.871445, samples/s: 2998.207 1612051554.3474166
train: epoch 136, iter 1800, loss: 2.251417, top_1: 0.693203, top_k: 0.872539, samples/s: 2968.598 1612051562.9710476
train: epoch 136, iter 1900, loss: 2.318011, top_1: 0.691953, top_k: 0.871445, samples/s: 2936.215 1612051571.6897511
train: epoch 136, iter 2000, loss: 2.315848, top_1: 0.686797, top_k: 0.868203, samples/s: 2952.240 1612051580.3611941
train: epoch 136, iter 2100, loss: 2.346065, top_1: 0.691133, top_k: 0.874336, samples/s: 2991.950 1612051588.9174194
train: epoch 136, iter 2200, loss: 2.166118, top_1: 0.690039, top_k: 0.873281, samples/s: 2958.812 1612051597.5695481
train: epoch 136, iter 2300, loss: 2.485871, top_1: 0.685781, top_k: 0.874258, samples/s: 2980.102 1612051606.15985
train: epoch 136, iter 2400, loss: 2.237388, top_1: 0.686328, top_k: 0.869180, samples/s: 2946.916 1612051614.846947
train: epoch 136, iter 2500, loss: 2.412488, top_1: 0.684688, top_k: 0.870938, samples/s: 2983.430 1612051623.427674
train: epoch 136, iter 2600, loss: 2.509756, top_1: 0.690586, top_k: 0.877109, samples/s: 2897.051 1612051632.2642117
train: epoch 136, iter 2700, loss: 2.251696, top_1: 0.685234, top_k: 0.870820, samples/s: 3007.528 1612051640.7761893
train: epoch 136, iter 2800, loss: 2.311099, top_1: 0.687461, top_k: 0.868945, samples/s: 2935.462 1612051649.4971178
train: epoch 136, iter 2900, loss: 2.437216, top_1: 0.686406, top_k: 0.868516, samples/s: 2990.537 1612051658.0574758
train: epoch 136, iter 3000, loss: 2.396420, top_1: 0.685430, top_k: 0.869453, samples/s: 2984.960 1612051666.635114
train: epoch 136, iter 3100, loss: 2.262923, top_1: 0.688438, top_k: 0.867695, samples/s: 2936.652 1612051675.3512115
train: epoch 136, iter 3200, loss: 2.343802, top_1: 0.690898, top_k: 0.867188, samples/s: 2962.647 1612051683.99286
train: epoch 136, iter 3300, loss: 2.399904, top_1: 0.685039, top_k: 0.870430, samples/s: 2994.034 1612051692.5424705
train: epoch 136, iter 3400, loss: 2.440268, top_1: 0.687187, top_k: 0.870234, samples/s: 2916.309 1612051701.320688
train: epoch 136, iter 3500, loss: 2.410102, top_1: 0.688320, top_k: 0.873086, samples/s: 2934.475 1612051710.0445716
train: epoch 136, iter 3600, loss: 2.269108, top_1: 0.686445, top_k: 0.868828, samples/s: 2948.253 1612051718.72787
train: epoch 136, iter 3700, loss: 2.300642, top_1: 0.689883, top_k: 0.870859, samples/s: 2959.536 1612051727.3776548
train: epoch 136, iter 3800, loss: 2.198457, top_1: 0.683867, top_k: 0.871875, samples/s: 2990.049 1612051735.9393935
train: epoch 136, iter 3900, loss: 2.322489, top_1: 0.693086, top_k: 0.871680, samples/s: 2952.590 1612051744.609897
train: epoch 136, iter 4000, loss: 2.420717, top_1: 0.684531, top_k: 0.870664, samples/s: 2953.722 1612051753.276887
train: epoch 136, iter 4100, loss: 2.259418, top_1: 0.688750, top_k: 0.873867, samples/s: 2994.791 1612051761.8249495
train: epoch 136, iter 4200, loss: 2.352552, top_1: 0.687227, top_k: 0.869687, samples/s: 2966.726 1612051770.4540386
train: epoch 136, iter 4300, loss: 2.199869, top_1: 0.681680, top_k: 0.871055, samples/s: 3020.051 1612051778.9306726
train: epoch 136, iter 4400, loss: 2.340928, top_1: 0.687383, top_k: 0.873477, samples/s: 2955.804 1612051787.5915966
train: epoch 136, iter 4500, loss: 2.440316, top_1: 0.689141, top_k: 0.872930, samples/s: 2935.859 1612051796.3113682
train: epoch 136, iter 4600, loss: 2.171460, top_1: 0.682109, top_k: 0.869297, samples/s: 2943.953 1612051805.0071552
train: epoch 136, iter 4700, loss: 2.420869, top_1: 0.683359, top_k: 0.869922, samples/s: 2926.015 1612051813.7562354
train: epoch 136, iter 4800, loss: 2.380640, top_1: 0.687070, top_k: 0.870781, samples/s: 2997.477 1612051822.296765
train: epoch 136, iter 4900, loss: 2.311880, top_1: 0.690156, top_k: 0.871914, samples/s: 3005.732 1612051830.8138614
train: epoch 136, iter 5000, loss: 2.257516, top_1: 0.690234, top_k: 0.871680, samples/s: 2953.821 1612051839.4805255
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_136.
validation: epoch 136, iter 195, top_1: 0.705669, top_k: 0.896274, samples/s: 2956.368 1612051856.5141428
train: epoch 137, iter 100, loss: 2.220766, top_1: 0.692891, top_k: 0.872109, samples/s: 2968.026 1612051881.2132509
train: epoch 137, iter 200, loss: 2.245288, top_1: 0.689648, top_k: 0.872383, samples/s: 3010.333 1612051889.7173815
train: epoch 137, iter 300, loss: 2.250978, top_1: 0.698906, top_k: 0.877227, samples/s: 2971.745 1612051898.3317091
train: epoch 137, iter 400, loss: 2.292465, top_1: 0.692539, top_k: 0.872578, samples/s: 3029.113 1612051906.7830238
train: epoch 137, iter 500, loss: 2.386528, top_1: 0.695977, top_k: 0.875898, samples/s: 2968.845 1612051915.405905
train: epoch 137, iter 600, loss: 2.255775, top_1: 0.690586, top_k: 0.873164, samples/s: 2960.144 1612051924.0541048
train: epoch 137, iter 700, loss: 2.446496, top_1: 0.693516, top_k: 0.872812, samples/s: 2991.912 1612051932.6106818
train: epoch 137, iter 800, loss: 2.177081, top_1: 0.690391, top_k: 0.873516, samples/s: 2984.214 1612051941.1891282
train: epoch 137, iter 900, loss: 2.175651, top_1: 0.693672, top_k: 0.875820, samples/s: 2984.881 1612051949.76565
train: epoch 137, iter 1000, loss: 2.275124, top_1: 0.686914, top_k: 0.870664, samples/s: 2946.846 1612051958.4528368
train: epoch 137, iter 1100, loss: 2.465011, top_1: 0.688164, top_k: 0.874023, samples/s: 2961.041 1612051967.098492
train: epoch 137, iter 1200, loss: 2.236230, top_1: 0.691914, top_k: 0.874258, samples/s: 2853.451 1612051976.0700154
train: epoch 137, iter 1300, loss: 2.338414, top_1: 0.693477, top_k: 0.872070, samples/s: 2976.890 1612051984.6695986
train: epoch 137, iter 1400, loss: 2.318843, top_1: 0.687852, top_k: 0.870938, samples/s: 2959.029 1612051993.321149
train: epoch 137, iter 1500, loss: 2.323783, top_1: 0.695664, top_k: 0.874570, samples/s: 2997.841 1612052001.8605638
train: epoch 137, iter 1600, loss: 2.291386, top_1: 0.690586, top_k: 0.871992, samples/s: 2970.572 1612052010.4784446
train: epoch 137, iter 1700, loss: 2.307451, top_1: 0.692344, top_k: 0.876367, samples/s: 3004.650 1612052018.998592
train: epoch 137, iter 1800, loss: 2.277216, top_1: 0.689414, top_k: 0.871367, samples/s: 2965.237 1612052027.631993
train: epoch 137, iter 1900, loss: 2.303998, top_1: 0.690937, top_k: 0.873906, samples/s: 2958.784 1612052036.2841372
train: epoch 137, iter 2000, loss: 2.340637, top_1: 0.690273, top_k: 0.874531, samples/s: 2940.840 1612052044.989151
train: epoch 137, iter 2100, loss: 2.250228, top_1: 0.687109, top_k: 0.871055, samples/s: 2931.399 1612052053.7223735
train: epoch 137, iter 2200, loss: 2.259761, top_1: 0.693047, top_k: 0.875195, samples/s: 3023.262 1612052062.189838
train: epoch 137, iter 2300, loss: 2.328094, top_1: 0.690117, top_k: 0.870586, samples/s: 2967.202 1612052070.8174918
train: epoch 137, iter 2400, loss: 2.387519, top_1: 0.693125, top_k: 0.874922, samples/s: 3002.047 1612052079.345035
train: epoch 137, iter 2500, loss: 2.294946, top_1: 0.689844, top_k: 0.870742, samples/s: 2974.209 1612052087.952425
train: epoch 137, iter 2600, loss: 2.315295, top_1: 0.692148, top_k: 0.872070, samples/s: 2843.027 1612052096.9568632
train: epoch 137, iter 2700, loss: 2.135476, top_1: 0.689141, top_k: 0.872461, samples/s: 2966.202 1612052105.5874062
train: epoch 137, iter 2800, loss: 2.462548, top_1: 0.691523, top_k: 0.873828, samples/s: 2959.569 1612052114.2373476
train: epoch 137, iter 2900, loss: 2.304245, top_1: 0.688164, top_k: 0.872500, samples/s: 2979.312 1612052122.8299177
train: epoch 137, iter 3000, loss: 2.381515, top_1: 0.692500, top_k: 0.874141, samples/s: 2959.920 1612052131.4787762
train: epoch 137, iter 3100, loss: 2.220689, top_1: 0.692305, top_k: 0.875391, samples/s: 2991.048 1612052140.0376098
train: epoch 137, iter 3200, loss: 2.329883, top_1: 0.690430, top_k: 0.872969, samples/s: 2955.131 1612052148.7005374
train: epoch 137, iter 3300, loss: 2.324094, top_1: 0.692109, top_k: 0.873867, samples/s: 2966.605 1612052157.329996
train: epoch 137, iter 3400, loss: 2.128518, top_1: 0.695000, top_k: 0.875430, samples/s: 2899.763 1612052166.1582708
train: epoch 137, iter 3500, loss: 2.145295, top_1: 0.693008, top_k: 0.876172, samples/s: 2981.596 1612052174.7442527
train: epoch 137, iter 3600, loss: 2.131463, top_1: 0.692539, top_k: 0.874766, samples/s: 2983.762 1612052183.324146
train: epoch 137, iter 3700, loss: 2.223385, top_1: 0.685508, top_k: 0.872461, samples/s: 2881.515 1612052192.2082572
train: epoch 137, iter 3800, loss: 2.294844, top_1: 0.695391, top_k: 0.871367, samples/s: 2961.057 1612052200.8538272
train: epoch 137, iter 3900, loss: 2.309262, top_1: 0.690977, top_k: 0.872891, samples/s: 2969.388 1612052209.475241
train: epoch 137, iter 4000, loss: 2.490034, top_1: 0.688164, top_k: 0.869297, samples/s: 2985.091 1612052218.051033
train: epoch 137, iter 4100, loss: 2.387732, top_1: 0.685195, top_k: 0.870195, samples/s: 2943.916 1612052226.746979
train: epoch 137, iter 4200, loss: 2.262012, top_1: 0.691055, top_k: 0.872734, samples/s: 3014.435 1612052235.239509
train: epoch 137, iter 4300, loss: 2.335746, top_1: 0.691914, top_k: 0.875078, samples/s: 2976.344 1612052243.8406835
train: epoch 137, iter 4400, loss: 2.317838, top_1: 0.688516, top_k: 0.869844, samples/s: 2907.457 1612052252.6455894
train: epoch 137, iter 4500, loss: 2.270116, top_1: 0.688125, top_k: 0.868594, samples/s: 2996.437 1612052261.189101
train: epoch 137, iter 4600, loss: 2.207824, top_1: 0.686055, top_k: 0.867969, samples/s: 2987.935 1612052269.7569091
train: epoch 137, iter 4700, loss: 2.546509, top_1: 0.689766, top_k: 0.869258, samples/s: 2960.771 1612052278.403245
train: epoch 137, iter 4800, loss: 2.177480, top_1: 0.692305, top_k: 0.872266, samples/s: 3038.214 1612052286.8292246
train: epoch 137, iter 4900, loss: 2.382467, top_1: 0.692148, top_k: 0.873398, samples/s: 2979.926 1612052295.4200215
train: epoch 137, iter 5000, loss: 2.328208, top_1: 0.696211, top_k: 0.877148, samples/s: 2949.108 1612052304.100563
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_137.
validation: epoch 137, iter 195, top_1: 0.708614, top_k: 0.897175, samples/s: 2964.841 1612052321.4054906
train: epoch 138, iter 100, loss: 2.273691, top_1: 0.695820, top_k: 0.873086, samples/s: 2936.147 1612052345.992719
train: epoch 138, iter 200, loss: 2.191089, top_1: 0.695547, top_k: 0.876836, samples/s: 2999.955 1612052354.526142
train: epoch 138, iter 300, loss: 2.228340, top_1: 0.699297, top_k: 0.877109, samples/s: 2988.951 1612052363.0909963
train: epoch 138, iter 400, loss: 2.353797, top_1: 0.693047, top_k: 0.873711, samples/s: 2921.400 1612052371.8539696
train: epoch 138, iter 500, loss: 2.324386, top_1: 0.691953, top_k: 0.871094, samples/s: 3020.262 1612052380.330065
train: epoch 138, iter 600, loss: 2.259105, top_1: 0.693906, top_k: 0.872070, samples/s: 2934.557 1612052389.0536752
train: epoch 138, iter 700, loss: 2.249812, top_1: 0.691836, top_k: 0.873086, samples/s: 2982.566 1612052397.6371193
train: epoch 138, iter 800, loss: 2.273214, top_1: 0.692617, top_k: 0.874453, samples/s: 2961.680 1612052406.2806787
train: epoch 138, iter 900, loss: 2.194815, top_1: 0.696523, top_k: 0.875273, samples/s: 2806.348 1612052415.4028254
train: epoch 138, iter 1000, loss: 2.315814, top_1: 0.694570, top_k: 0.874687, samples/s: 3024.635 1612052423.8666673
train: epoch 138, iter 1100, loss: 2.499397, top_1: 0.694102, top_k: 0.872773, samples/s: 2925.742 1612052432.616563
train: epoch 138, iter 1200, loss: 2.312599, top_1: 0.691953, top_k: 0.875352, samples/s: 3012.456 1612052441.1149883
train: epoch 138, iter 1300, loss: 2.190166, top_1: 0.699727, top_k: 0.876523, samples/s: 2933.650 1612052449.8409328
train: epoch 138, iter 1400, loss: 2.150399, top_1: 0.694063, top_k: 0.873672, samples/s: 2920.246 1612052458.6073372
train: epoch 138, iter 1500, loss: 2.441087, top_1: 0.697617, top_k: 0.877734, samples/s: 2960.574 1612052467.2544725
train: epoch 138, iter 1600, loss: 2.273535, top_1: 0.691875, top_k: 0.869844, samples/s: 2956.970 1612052475.911837
train: epoch 138, iter 1700, loss: 2.228890, top_1: 0.695195, top_k: 0.873633, samples/s: 3004.772 1612052484.4316056
train: epoch 138, iter 1800, loss: 2.158877, top_1: 0.697422, top_k: 0.876992, samples/s: 2968.620 1612052493.0555089
train: epoch 138, iter 1900, loss: 2.240556, top_1: 0.693750, top_k: 0.875195, samples/s: 2972.201 1612052501.6683164
train: epoch 138, iter 2000, loss: 2.531622, top_1: 0.691172, top_k: 0.873555, samples/s: 2976.955 1612052510.2676578
train: epoch 138, iter 2100, loss: 2.279784, top_1: 0.696758, top_k: 0.877383, samples/s: 2937.780 1612052518.981702
train: epoch 138, iter 2200, loss: 2.324419, top_1: 0.694453, top_k: 0.873984, samples/s: 2993.612 1612052527.533253
train: epoch 138, iter 2300, loss: 2.285740, top_1: 0.688477, top_k: 0.873437, samples/s: 2930.819 1612052536.2680178
train: epoch 138, iter 2400, loss: 2.290223, top_1: 0.695547, top_k: 0.876797, samples/s: 2953.310 1612052544.9362593
train: epoch 138, iter 2500, loss: 2.429452, top_1: 0.690430, top_k: 0.873359, samples/s: 3005.670 1612052553.453484
train: epoch 138, iter 2600, loss: 2.345786, top_1: 0.691211, top_k: 0.877109, samples/s: 2946.363 1612052562.1421716
train: epoch 138, iter 2700, loss: 2.263756, top_1: 0.691328, top_k: 0.873281, samples/s: 2968.375 1612052570.7665055
train: epoch 138, iter 2800, loss: 2.404168, top_1: 0.695977, top_k: 0.877578, samples/s: 2971.546 1612052579.381401
train: epoch 138, iter 2900, loss: 2.215848, top_1: 0.689805, top_k: 0.872188, samples/s: 2989.133 1612052587.9458945
train: epoch 138, iter 3000, loss: 2.528913, top_1: 0.687227, top_k: 0.872969, samples/s: 2985.171 1612052596.5215275
train: epoch 138, iter 3100, loss: 2.240944, top_1: 0.693633, top_k: 0.871992, samples/s: 2985.591 1612052605.096046
train: epoch 138, iter 3200, loss: 2.251635, top_1: 0.689414, top_k: 0.871602, samples/s: 2917.686 1612052613.8701768
train: epoch 138, iter 3300, loss: 2.358745, top_1: 0.690898, top_k: 0.873086, samples/s: 3021.180 1612052622.3437247
train: epoch 138, iter 3400, loss: 2.218029, top_1: 0.693555, top_k: 0.874297, samples/s: 2994.013 1612052630.8940368
train: epoch 138, iter 3500, loss: 2.414643, top_1: 0.691680, top_k: 0.874023, samples/s: 2967.878 1612052639.5198543
train: epoch 138, iter 3600, loss: 2.259648, top_1: 0.695469, top_k: 0.876406, samples/s: 2964.173 1612052648.1562898
train: epoch 138, iter 3700, loss: 2.336265, top_1: 0.695430, top_k: 0.876211, samples/s: 2978.104 1612052656.7522805
train: epoch 138, iter 3800, loss: 2.328006, top_1: 0.696602, top_k: 0.876602, samples/s: 2889.845 1612052665.6108923
train: epoch 138, iter 3900, loss: 2.279479, top_1: 0.690312, top_k: 0.872500, samples/s: 2930.901 1612052674.3455167
train: epoch 138, iter 4000, loss: 2.303949, top_1: 0.693203, top_k: 0.877031, samples/s: 2962.679 1612052682.9862423
train: epoch 138, iter 4100, loss: 2.223721, top_1: 0.694141, top_k: 0.874766, samples/s: 2994.158 1612052691.5363994
train: epoch 138, iter 4200, loss: 2.226048, top_1: 0.689805, top_k: 0.871094, samples/s: 2919.495 1612052700.304961
train: epoch 138, iter 4300, loss: 2.234245, top_1: 0.693281, top_k: 0.877305, samples/s: 2979.916 1612052708.8957083
train: epoch 138, iter 4400, loss: 2.367348, top_1: 0.691680, top_k: 0.872969, samples/s: 3000.806 1612052717.4267542
train: epoch 138, iter 4500, loss: 2.433813, top_1: 0.689375, top_k: 0.873906, samples/s: 2964.651 1612052726.0618083
train: epoch 138, iter 4600, loss: 2.238931, top_1: 0.691445, top_k: 0.871914, samples/s: 2962.143 1612052734.7042825
train: epoch 138, iter 4700, loss: 2.257235, top_1: 0.694844, top_k: 0.874180, samples/s: 2998.602 1612052743.2415874
train: epoch 138, iter 4800, loss: 2.064077, top_1: 0.694141, top_k: 0.873594, samples/s: 2949.517 1612052751.9209592
train: epoch 138, iter 4900, loss: 2.414310, top_1: 0.689063, top_k: 0.872031, samples/s: 2901.261 1612052760.7446995
train: epoch 138, iter 5000, loss: 2.131216, top_1: 0.701523, top_k: 0.875781, samples/s: 2979.353 1612052769.3371394
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_138.
validation: epoch 138, iter 195, top_1: 0.709215, top_k: 0.899018, samples/s: 2988.984 1612052786.3050692
train: epoch 139, iter 100, loss: 2.225147, top_1: 0.705156, top_k: 0.880313, samples/s: 2965.268 1612052810.8841028
train: epoch 139, iter 200, loss: 2.137634, top_1: 0.696562, top_k: 0.878711, samples/s: 2987.843 1612052819.4521494
train: epoch 139, iter 300, loss: 2.353466, top_1: 0.698750, top_k: 0.877500, samples/s: 3017.142 1612052827.9370232
train: epoch 139, iter 400, loss: 2.273447, top_1: 0.695312, top_k: 0.877227, samples/s: 3007.323 1612052836.4496102
train: epoch 139, iter 500, loss: 2.439926, top_1: 0.697617, top_k: 0.878555, samples/s: 2972.379 1612052845.062351
train: epoch 139, iter 600, loss: 2.232431, top_1: 0.698398, top_k: 0.878477, samples/s: 2978.458 1612052853.6572337
train: epoch 139, iter 700, loss: 2.354528, top_1: 0.697930, top_k: 0.877461, samples/s: 3008.127 1612052862.1676047
train: epoch 139, iter 800, loss: 2.348248, top_1: 0.692969, top_k: 0.876484, samples/s: 2999.485 1612052870.7023656
train: epoch 139, iter 900, loss: 2.073275, top_1: 0.696289, top_k: 0.879883, samples/s: 2920.263 1612052879.4688053
train: epoch 139, iter 1000, loss: 2.275279, top_1: 0.697422, top_k: 0.877344, samples/s: 2953.109 1612052888.1375408
train: epoch 139, iter 1100, loss: 2.239459, top_1: 0.693398, top_k: 0.875820, samples/s: 2989.292 1612052896.7015212
train: epoch 139, iter 1200, loss: 2.224706, top_1: 0.698477, top_k: 0.877383, samples/s: 3006.632 1612052905.216053
train: epoch 139, iter 1300, loss: 2.316500, top_1: 0.693984, top_k: 0.875508, samples/s: 2939.770 1612052913.9241192
train: epoch 139, iter 1400, loss: 2.137050, top_1: 0.700781, top_k: 0.878477, samples/s: 3003.711 1612052922.4468963
train: epoch 139, iter 1500, loss: 2.274473, top_1: 0.694336, top_k: 0.873086, samples/s: 2967.373 1612052931.074029
train: epoch 139, iter 1600, loss: 2.164648, top_1: 0.698047, top_k: 0.877148, samples/s: 2807.078 1612052940.1938546
train: epoch 139, iter 1700, loss: 2.453713, top_1: 0.696211, top_k: 0.874531, samples/s: 2893.497 1612052949.0412655
train: epoch 139, iter 1800, loss: 2.100593, top_1: 0.696875, top_k: 0.877422, samples/s: 2961.778 1612052957.6848447
train: epoch 139, iter 1900, loss: 2.377010, top_1: 0.698828, top_k: 0.877266, samples/s: 2967.236 1612052966.312394
train: epoch 139, iter 2000, loss: 2.276007, top_1: 0.693086, top_k: 0.874609, samples/s: 3033.923 1612052974.7501905
train: epoch 139, iter 2100, loss: 2.308837, top_1: 0.695391, top_k: 0.874766, samples/s: 2956.759 1612052983.4083261
train: epoch 139, iter 2200, loss: 2.356713, top_1: 0.696055, top_k: 0.877266, samples/s: 2971.662 1612052992.0230238
train: epoch 139, iter 2300, loss: 2.344390, top_1: 0.695078, top_k: 0.876484, samples/s: 2963.228 1612053000.6623886
train: epoch 139, iter 2400, loss: 2.227130, top_1: 0.695078, top_k: 0.876289, samples/s: 2954.019 1612053009.3285625
train: epoch 139, iter 2500, loss: 2.339717, top_1: 0.700937, top_k: 0.878633, samples/s: 2990.922 1612053017.8876557
train: epoch 139, iter 2600, loss: 2.275436, top_1: 0.690898, top_k: 0.875430, samples/s: 2865.256 1612053026.822412
train: epoch 139, iter 2700, loss: 2.378314, top_1: 0.691758, top_k: 0.877305, samples/s: 2976.844 1612053035.4220726
train: epoch 139, iter 2800, loss: 2.428485, top_1: 0.695937, top_k: 0.872656, samples/s: 2988.984 1612053043.9869306
train: epoch 139, iter 2900, loss: 2.326295, top_1: 0.698359, top_k: 0.876602, samples/s: 2965.619 1612053052.6190264
train: epoch 139, iter 3000, loss: 2.205214, top_1: 0.691484, top_k: 0.870469, samples/s: 2988.321 1612053061.1857233
train: epoch 139, iter 3100, loss: 2.436961, top_1: 0.699063, top_k: 0.877305, samples/s: 2973.717 1612053069.794519
train: epoch 139, iter 3200, loss: 2.482248, top_1: 0.700781, top_k: 0.877852, samples/s: 3013.650 1612053078.2891846
train: epoch 139, iter 3300, loss: 2.405012, top_1: 0.697305, top_k: 0.875938, samples/s: 2901.085 1612053087.1136968
train: epoch 139, iter 3400, loss: 2.274588, top_1: 0.691992, top_k: 0.872852, samples/s: 2954.085 1612053095.7794547
train: epoch 139, iter 3500, loss: 2.104726, top_1: 0.693242, top_k: 0.875820, samples/s: 3012.664 1612053104.2768652
train: epoch 139, iter 3600, loss: 2.282630, top_1: 0.694102, top_k: 0.876641, samples/s: 2898.956 1612053113.1076102
train: epoch 139, iter 3700, loss: 2.162995, top_1: 0.694570, top_k: 0.877227, samples/s: 2970.656 1612053121.7254324
train: epoch 139, iter 3800, loss: 2.291652, top_1: 0.699414, top_k: 0.875938, samples/s: 2983.867 1612053130.3047996
train: epoch 139, iter 3900, loss: 2.265085, top_1: 0.699453, top_k: 0.882578, samples/s: 2992.471 1612053138.859596
train: epoch 139, iter 4000, loss: 2.286509, top_1: 0.698359, top_k: 0.876602, samples/s: 2976.532 1612053147.460179
train: epoch 139, iter 4100, loss: 2.492628, top_1: 0.696797, top_k: 0.875469, samples/s: 2995.112 1612053156.0074065
train: epoch 139, iter 4200, loss: 2.219489, top_1: 0.691562, top_k: 0.872969, samples/s: 2915.463 1612053164.7881637
train: epoch 139, iter 4300, loss: 2.179215, top_1: 0.694141, top_k: 0.874453, samples/s: 2991.081 1612053173.3469622
train: epoch 139, iter 4400, loss: 2.229573, top_1: 0.699805, top_k: 0.876094, samples/s: 2865.285 1612053182.2815108
train: epoch 139, iter 4500, loss: 2.200045, top_1: 0.689180, top_k: 0.873906, samples/s: 3013.545 1612053190.7765727
train: epoch 139, iter 4600, loss: 2.226144, top_1: 0.694258, top_k: 0.875820, samples/s: 3019.117 1612053199.255787
train: epoch 139, iter 4700, loss: 2.316549, top_1: 0.696602, top_k: 0.876094, samples/s: 2957.201 1612053207.9126127
train: epoch 139, iter 4800, loss: 2.362356, top_1: 0.697930, top_k: 0.874141, samples/s: 2999.292 1612053216.4479725
train: epoch 139, iter 4900, loss: 2.365350, top_1: 0.698438, top_k: 0.876055, samples/s: 2965.047 1612053225.0818837
train: epoch 139, iter 5000, loss: 2.311746, top_1: 0.699922, top_k: 0.877148, samples/s: 2956.350 1612053233.7413068
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_139.
validation: epoch 139, iter 195, top_1: 0.712780, top_k: 0.900681, samples/s: 3012.935 1612053250.5488794
train: epoch 140, iter 100, loss: 2.304501, top_1: 0.704844, top_k: 0.878516, samples/s: 2974.480 1612053275.5138159
train: epoch 140, iter 200, loss: 2.296049, top_1: 0.697773, top_k: 0.877500, samples/s: 2955.313 1612053284.17626
train: epoch 140, iter 300, loss: 2.176935, top_1: 0.702891, top_k: 0.881680, samples/s: 2981.293 1612053292.763044
train: epoch 140, iter 400, loss: 2.162638, top_1: 0.703008, top_k: 0.879297, samples/s: 3033.122 1612053301.2031724
train: epoch 140, iter 500, loss: 2.282778, top_1: 0.697734, top_k: 0.875781, samples/s: 2955.249 1612053309.865734
train: epoch 140, iter 600, loss: 2.431765, top_1: 0.696289, top_k: 0.875703, samples/s: 3033.355 1612053318.305341
train: epoch 140, iter 700, loss: 2.353626, top_1: 0.705156, top_k: 0.878906, samples/s: 2988.869 1612053326.8703735
train: epoch 140, iter 800, loss: 2.326557, top_1: 0.701602, top_k: 0.878828, samples/s: 2998.842 1612053335.4069333
train: epoch 140, iter 900, loss: 2.363562, top_1: 0.700586, top_k: 0.878008, samples/s: 3005.348 1612053343.9251451
train: epoch 140, iter 1000, loss: 2.345282, top_1: 0.698594, top_k: 0.878477, samples/s: 2954.157 1612053352.5909288
train: epoch 140, iter 1100, loss: 2.324393, top_1: 0.696953, top_k: 0.878359, samples/s: 3022.482 1612053361.0607893
train: epoch 140, iter 1200, loss: 2.272108, top_1: 0.699102, top_k: 0.878398, samples/s: 2993.465 1612053369.6126974
train: epoch 140, iter 1300, loss: 2.275289, top_1: 0.698359, top_k: 0.878750, samples/s: 2999.725 1612053378.146888
train: epoch 140, iter 1400, loss: 2.210356, top_1: 0.701016, top_k: 0.879570, samples/s: 2983.444 1612053386.727504
train: epoch 140, iter 1500, loss: 2.297243, top_1: 0.698203, top_k: 0.877852, samples/s: 2976.014 1612053395.3296285
train: epoch 140, iter 1600, loss: 2.310054, top_1: 0.695664, top_k: 0.876328, samples/s: 2990.958 1612053403.8887393
train: epoch 140, iter 1700, loss: 2.264848, top_1: 0.692031, top_k: 0.877188, samples/s: 2974.390 1612053412.4955418
train: epoch 140, iter 1800, loss: 2.239385, top_1: 0.697656, top_k: 0.878633, samples/s: 2962.657 1612053421.1364632
train: epoch 140, iter 1900, loss: 2.427841, top_1: 0.701406, top_k: 0.880469, samples/s: 2971.537 1612053429.7515428
train: epoch 140, iter 2000, loss: 2.493173, top_1: 0.701836, top_k: 0.880898, samples/s: 3013.029 1612053438.2479975
train: epoch 140, iter 2100, loss: 2.252184, top_1: 0.702773, top_k: 0.878789, samples/s: 3004.378 1612053446.768854
train: epoch 140, iter 2200, loss: 2.260507, top_1: 0.705781, top_k: 0.880195, samples/s: 2958.437 1612053455.4220746
train: epoch 140, iter 2300, loss: 2.179870, top_1: 0.696289, top_k: 0.877227, samples/s: 2885.045 1612053464.2954712
train: epoch 140, iter 2400, loss: 2.338499, top_1: 0.695703, top_k: 0.876250, samples/s: 2943.655 1612053472.9921474
train: epoch 140, iter 2500, loss: 2.268574, top_1: 0.695273, top_k: 0.875938, samples/s: 2912.365 1612053481.7822213
train: epoch 140, iter 2600, loss: 2.332595, top_1: 0.707812, top_k: 0.884219, samples/s: 2990.769 1612053490.3418734
train: epoch 140, iter 2700, loss: 2.378479, top_1: 0.701406, top_k: 0.879102, samples/s: 2970.786 1612053498.9591064
train: epoch 140, iter 2800, loss: 2.183817, top_1: 0.694922, top_k: 0.875313, samples/s: 2998.123 1612053507.497805
train: epoch 140, iter 2900, loss: 2.386629, top_1: 0.696055, top_k: 0.878555, samples/s: 2984.038 1612053516.076745
train: epoch 140, iter 3000, loss: 2.179523, top_1: 0.702187, top_k: 0.878594, samples/s: 2983.750 1612053524.6565723
train: epoch 140, iter 3100, loss: 2.284159, top_1: 0.695430, top_k: 0.875039, samples/s: 2982.509 1612053533.2399504
train: epoch 140, iter 3200, loss: 2.201601, top_1: 0.695664, top_k: 0.876797, samples/s: 2931.485 1612053541.9727092
train: epoch 140, iter 3300, loss: 2.329812, top_1: 0.697227, top_k: 0.875547, samples/s: 2990.262 1612053550.5338619
train: epoch 140, iter 3400, loss: 2.237126, top_1: 0.699648, top_k: 0.875469, samples/s: 2918.614 1612053559.3051276
train: epoch 140, iter 3500, loss: 2.235074, top_1: 0.698477, top_k: 0.877734, samples/s: 2899.748 1612053568.1335952
train: epoch 140, iter 3600, loss: 2.251979, top_1: 0.697266, top_k: 0.877070, samples/s: 3002.915 1612053576.6585834
train: epoch 140, iter 3700, loss: 2.246874, top_1: 0.693047, top_k: 0.871992, samples/s: 2990.913 1612053585.217773
train: epoch 140, iter 3800, loss: 2.076749, top_1: 0.698477, top_k: 0.876289, samples/s: 2982.206 1612053593.8020015
train: epoch 140, iter 3900, loss: 2.018082, top_1: 0.701484, top_k: 0.879727, samples/s: 2981.817 1612053602.3874266
train: epoch 140, iter 4000, loss: 2.185291, top_1: 0.699805, top_k: 0.876641, samples/s: 2889.590 1612053611.246787
train: epoch 140, iter 4100, loss: 2.278686, top_1: 0.701914, top_k: 0.879492, samples/s: 3032.897 1612053619.6876683
train: epoch 140, iter 4200, loss: 2.447616, top_1: 0.697070, top_k: 0.879141, samples/s: 3015.539 1612053628.1768913
train: epoch 140, iter 4300, loss: 2.175514, top_1: 0.698594, top_k: 0.877500, samples/s: 2977.083 1612053636.7760348
train: epoch 140, iter 4400, loss: 2.281948, top_1: 0.695273, top_k: 0.876758, samples/s: 2980.979 1612053645.3638208
train: epoch 140, iter 4500, loss: 2.265669, top_1: 0.696523, top_k: 0.876523, samples/s: 2969.964 1612053653.9834223
train: epoch 140, iter 4600, loss: 2.303003, top_1: 0.699297, top_k: 0.876289, samples/s: 2919.674 1612053662.751462
train: epoch 140, iter 4700, loss: 2.299214, top_1: 0.699180, top_k: 0.877734, samples/s: 2953.542 1612053671.419183
train: epoch 140, iter 4800, loss: 2.354547, top_1: 0.699492, top_k: 0.877188, samples/s: 2947.987 1612053680.1029637
train: epoch 140, iter 4900, loss: 2.298903, top_1: 0.694258, top_k: 0.875195, samples/s: 2982.425 1612053688.686561
train: epoch 140, iter 5000, loss: 2.135737, top_1: 0.704219, top_k: 0.881172, samples/s: 2994.523 1612053697.2355363
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_140.
validation: epoch 140, iter 195, top_1: 0.713502, top_k: 0.901062, samples/s: 2910.040 1612053714.6605976
train: epoch 141, iter 100, loss: 2.190774, top_1: 0.709492, top_k: 0.882656, samples/s: 2936.651 1612053745.2472804
train: epoch 141, iter 200, loss: 2.174061, top_1: 0.703906, top_k: 0.883633, samples/s: 3012.502 1612053753.7450614
train: epoch 141, iter 300, loss: 2.258914, top_1: 0.704180, top_k: 0.878828, samples/s: 2948.642 1612053762.427185
train: epoch 141, iter 400, loss: 2.183140, top_1: 0.704336, top_k: 0.880508, samples/s: 2994.881 1612053770.974989
train: epoch 141, iter 500, loss: 2.309104, top_1: 0.707578, top_k: 0.880430, samples/s: 2968.706 1612053779.5982792
train: epoch 141, iter 600, loss: 2.174114, top_1: 0.709844, top_k: 0.884727, samples/s: 3025.790 1612053788.0589864
train: epoch 141, iter 700, loss: 2.230557, top_1: 0.699766, top_k: 0.877930, samples/s: 2980.954 1612053796.6467319
train: epoch 141, iter 800, loss: 2.084826, top_1: 0.702109, top_k: 0.879570, samples/s: 2887.340 1612053805.51315
train: epoch 141, iter 900, loss: 2.175004, top_1: 0.697227, top_k: 0.875000, samples/s: 2941.174 1612053814.2170398
train: epoch 141, iter 1000, loss: 2.287891, top_1: 0.706133, top_k: 0.882227, samples/s: 3000.657 1612053822.7485054
train: epoch 141, iter 1100, loss: 2.170041, top_1: 0.702109, top_k: 0.879805, samples/s: 2961.982 1612053831.3913805
train: epoch 141, iter 1200, loss: 2.157155, top_1: 0.704648, top_k: 0.882344, samples/s: 2983.818 1612053839.9710088
train: epoch 141, iter 1300, loss: 2.424129, top_1: 0.702422, top_k: 0.879531, samples/s: 2979.310 1612053848.5635123
train: epoch 141, iter 1400, loss: 2.176641, top_1: 0.700273, top_k: 0.879766, samples/s: 2984.075 1612053857.1425135
train: epoch 141, iter 1500, loss: 2.237756, top_1: 0.701680, top_k: 0.879453, samples/s: 2962.824 1612053865.7828715
train: epoch 141, iter 1600, loss: 2.145910, top_1: 0.702227, top_k: 0.878320, samples/s: 2977.508 1612053874.380782
train: epoch 141, iter 1700, loss: 2.197452, top_1: 0.702187, top_k: 0.880195, samples/s: 2970.084 1612053882.9999542
train: epoch 141, iter 1800, loss: 2.487632, top_1: 0.703828, top_k: 0.879805, samples/s: 2923.847 1612053891.7556362
train: epoch 141, iter 1900, loss: 2.340756, top_1: 0.704648, top_k: 0.881914, samples/s: 2961.798 1612053900.3988554
train: epoch 141, iter 2000, loss: 2.262996, top_1: 0.704688, top_k: 0.879062, samples/s: 2937.654 1612053909.1133385
train: epoch 141, iter 2100, loss: 2.279166, top_1: 0.701836, top_k: 0.877891, samples/s: 3035.107 1612053917.5479846
train: epoch 141, iter 2200, loss: 2.321329, top_1: 0.698125, top_k: 0.879531, samples/s: 2984.756 1612053926.1248503
train: epoch 141, iter 2300, loss: 2.268193, top_1: 0.701250, top_k: 0.880781, samples/s: 2962.582 1612053934.7660208
train: epoch 141, iter 2400, loss: 2.259782, top_1: 0.701992, top_k: 0.882617, samples/s: 2992.778 1612053943.319946
train: epoch 141, iter 2500, loss: 2.201509, top_1: 0.703906, top_k: 0.877852, samples/s: 3000.802 1612053951.8509936
train: epoch 141, iter 2600, loss: 2.215724, top_1: 0.703789, top_k: 0.878203, samples/s: 2979.946 1612053960.4417784
train: epoch 141, iter 2700, loss: 2.228836, top_1: 0.703828, top_k: 0.881133, samples/s: 2999.784 1612053968.9757023
train: epoch 141, iter 2800, loss: 2.253983, top_1: 0.699023, top_k: 0.878203, samples/s: 2965.282 1612053977.609007
train: epoch 141, iter 2900, loss: 2.144669, top_1: 0.699922, top_k: 0.880039, samples/s: 2953.083 1612053986.277869
train: epoch 141, iter 3000, loss: 2.286672, top_1: 0.700664, top_k: 0.878711, samples/s: 2971.389 1612053994.8934
train: epoch 141, iter 3100, loss: 2.243887, top_1: 0.702695, top_k: 0.882930, samples/s: 2979.833 1612054003.4844217
train: epoch 141, iter 3200, loss: 2.167144, top_1: 0.700742, top_k: 0.877891, samples/s: 2980.436 1612054012.0737514
train: epoch 141, iter 3300, loss: 2.272743, top_1: 0.700937, top_k: 0.878711, samples/s: 2985.874 1612054020.6475947
train: epoch 141, iter 3400, loss: 2.223730, top_1: 0.699727, top_k: 0.879414, samples/s: 2934.722 1612054029.370653
train: epoch 141, iter 3500, loss: 2.105678, top_1: 0.700469, top_k: 0.876563, samples/s: 2937.931 1612054038.0846307
train: epoch 141, iter 3600, loss: 2.205424, top_1: 0.703828, top_k: 0.879102, samples/s: 2975.819 1612054046.6870174
train: epoch 141, iter 3700, loss: 2.222980, top_1: 0.698125, top_k: 0.876914, samples/s: 2948.375 1612054055.370198
train: epoch 141, iter 3800, loss: 2.183153, top_1: 0.701523, top_k: 0.880859, samples/s: 2987.266 1612054063.939397
train: epoch 141, iter 3900, loss: 2.237247, top_1: 0.704297, top_k: 0.882617, samples/s: 2966.660 1612054072.5685854
train: epoch 141, iter 4000, loss: 2.194586, top_1: 0.704492, top_k: 0.877383, samples/s: 3019.148 1612054081.0478387
train: epoch 141, iter 4100, loss: 2.308060, top_1: 0.696562, top_k: 0.877500, samples/s: 2955.033 1612054089.7109516
train: epoch 141, iter 4200, loss: 2.166406, top_1: 0.702148, top_k: 0.880938, samples/s: 2794.925 1612054098.8704734
train: epoch 141, iter 4300, loss: 2.336534, top_1: 0.702266, top_k: 0.879844, samples/s: 3011.681 1612054107.3708572
train: epoch 141, iter 4400, loss: 2.261622, top_1: 0.697109, top_k: 0.879922, samples/s: 2971.856 1612054115.9848464
train: epoch 141, iter 4500, loss: 2.307206, top_1: 0.703711, top_k: 0.882344, samples/s: 2888.562 1612054124.8473248
train: epoch 141, iter 4600, loss: 2.241477, top_1: 0.698359, top_k: 0.879844, samples/s: 2985.352 1612054133.4225893
train: epoch 141, iter 4700, loss: 2.192625, top_1: 0.700586, top_k: 0.883828, samples/s: 2990.645 1612054141.9826927
train: epoch 141, iter 4800, loss: 2.282119, top_1: 0.705430, top_k: 0.880273, samples/s: 2880.351 1612054150.87043
train: epoch 141, iter 4900, loss: 2.176558, top_1: 0.697812, top_k: 0.875195, samples/s: 2991.974 1612054159.4266813
train: epoch 141, iter 5000, loss: 2.336705, top_1: 0.702266, top_k: 0.879141, samples/s: 2983.631 1612054168.0067797
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_141.
validation: epoch 141, iter 195, top_1: 0.716326, top_k: 0.902684, samples/s: 2925.117 1612054185.3137343
train: epoch 142, iter 100, loss: 2.274019, top_1: 0.707266, top_k: 0.881484, samples/s: 2938.402 1612054210.35042
train: epoch 142, iter 200, loss: 2.089126, top_1: 0.701562, top_k: 0.880703, samples/s: 2998.206 1612054218.8887959
train: epoch 142, iter 300, loss: 2.293602, top_1: 0.705469, top_k: 0.882148, samples/s: 2946.159 1612054227.5782597
train: epoch 142, iter 400, loss: 2.111481, top_1: 0.705859, top_k: 0.879844, samples/s: 2998.599 1612054236.1154099
train: epoch 142, iter 500, loss: 2.242519, top_1: 0.707617, top_k: 0.880508, samples/s: 2947.632 1612054244.800288
train: epoch 142, iter 600, loss: 2.341057, top_1: 0.705000, top_k: 0.880039, samples/s: 3005.034 1612054253.3193696
train: epoch 142, iter 700, loss: 2.187657, top_1: 0.704922, top_k: 0.881602, samples/s: 2935.470 1612054262.040356
train: epoch 142, iter 800, loss: 2.165804, top_1: 0.702109, top_k: 0.880313, samples/s: 3006.430 1612054270.555464
train: epoch 142, iter 900, loss: 2.300153, top_1: 0.703984, top_k: 0.880508, samples/s: 2920.395 1612054279.3217459
train: epoch 142, iter 1000, loss: 2.358545, top_1: 0.701875, top_k: 0.879687, samples/s: 2918.964 1612054288.091545
train: epoch 142, iter 1100, loss: 2.379642, top_1: 0.705039, top_k: 0.881055, samples/s: 3006.167 1612054296.609658
train: epoch 142, iter 1200, loss: 2.304148, top_1: 0.704609, top_k: 0.880625, samples/s: 3006.941 1612054305.1209993
train: epoch 142, iter 1300, loss: 2.169041, top_1: 0.702461, top_k: 0.882461, samples/s: 2988.625 1612054313.686761
train: epoch 142, iter 1400, loss: 2.035725, top_1: 0.706875, top_k: 0.881563, samples/s: 3019.390 1612054322.1655004
train: epoch 142, iter 1500, loss: 2.306809, top_1: 0.702812, top_k: 0.878984, samples/s: 3006.267 1612054330.6809056
train: epoch 142, iter 1600, loss: 2.441201, top_1: 0.705820, top_k: 0.882148, samples/s: 2979.733 1612054339.2723236
train: epoch 142, iter 1700, loss: 2.168906, top_1: 0.706016, top_k: 0.883750, samples/s: 2978.921 1612054347.8661168
train: epoch 142, iter 1800, loss: 2.404579, top_1: 0.710000, top_k: 0.882695, samples/s: 2949.182 1612054356.5463765
train: epoch 142, iter 1900, loss: 2.346473, top_1: 0.701602, top_k: 0.878984, samples/s: 2995.586 1612054365.0922258
train: epoch 142, iter 2000, loss: 2.304072, top_1: 0.712031, top_k: 0.884687, samples/s: 2974.503 1612054373.6987555
train: epoch 142, iter 2100, loss: 2.092197, top_1: 0.711211, top_k: 0.884766, samples/s: 2899.724 1612054382.5271723
train: epoch 142, iter 2200, loss: 2.236407, top_1: 0.701445, top_k: 0.882539, samples/s: 2974.865 1612054391.132651
train: epoch 142, iter 2300, loss: 2.293306, top_1: 0.702852, top_k: 0.878594, samples/s: 2983.142 1612054399.7141628
train: epoch 142, iter 2400, loss: 2.296595, top_1: 0.703906, top_k: 0.880078, samples/s: 2977.214 1612054408.312805
train: epoch 142, iter 2500, loss: 2.189130, top_1: 0.700937, top_k: 0.878047, samples/s: 2957.333 1612054416.9692674
train: epoch 142, iter 2600, loss: 2.265293, top_1: 0.705117, top_k: 0.881016, samples/s: 2982.440 1612054425.5528333
train: epoch 142, iter 2700, loss: 2.132277, top_1: 0.708906, top_k: 0.883203, samples/s: 2925.145 1612054434.3045406
train: epoch 142, iter 2800, loss: 2.263055, top_1: 0.707305, top_k: 0.880625, samples/s: 2925.287 1612054443.0558321
train: epoch 142, iter 2900, loss: 2.198114, top_1: 0.705117, top_k: 0.879492, samples/s: 3015.702 1612054451.5447075
train: epoch 142, iter 3000, loss: 2.211374, top_1: 0.702969, top_k: 0.878711, samples/s: 2773.903 1612054460.7736037
train: epoch 142, iter 3100, loss: 2.261013, top_1: 0.701914, top_k: 0.879141, samples/s: 3011.324 1612054469.2748454
train: epoch 142, iter 3200, loss: 2.231837, top_1: 0.701758, top_k: 0.880234, samples/s: 2976.625 1612054477.8753057
train: epoch 142, iter 3300, loss: 2.269342, top_1: 0.702734, top_k: 0.880664, samples/s: 2929.047 1612054486.6152256
train: epoch 142, iter 3400, loss: 2.297338, top_1: 0.708086, top_k: 0.881719, samples/s: 3011.658 1612054495.1155162
train: epoch 142, iter 3500, loss: 2.246228, top_1: 0.702812, top_k: 0.882891, samples/s: 2974.598 1612054503.7217662
train: epoch 142, iter 3600, loss: 2.265664, top_1: 0.704922, top_k: 0.878359, samples/s: 2951.870 1612054512.394154
train: epoch 142, iter 3700, loss: 2.356435, top_1: 0.704961, top_k: 0.885430, samples/s: 2927.440 1612054521.1390622
train: epoch 142, iter 3800, loss: 2.195731, top_1: 0.705430, top_k: 0.882227, samples/s: 2995.619 1612054529.6849198
train: epoch 142, iter 3900, loss: 2.256231, top_1: 0.708203, top_k: 0.881992, samples/s: 2981.983 1612054538.2698233
train: epoch 142, iter 4000, loss: 2.262989, top_1: 0.706797, top_k: 0.880117, samples/s: 2960.904 1612054546.9157617
train: epoch 142, iter 4100, loss: 2.158901, top_1: 0.701953, top_k: 0.878750, samples/s: 2951.047 1612054555.5906613
train: epoch 142, iter 4200, loss: 2.092779, top_1: 0.702500, top_k: 0.882148, samples/s: 2958.792 1612054564.2428584
train: epoch 142, iter 4300, loss: 2.329776, top_1: 0.700742, top_k: 0.880039, samples/s: 2982.419 1612054572.8264596
train: epoch 142, iter 4400, loss: 2.192196, top_1: 0.703359, top_k: 0.878789, samples/s: 2937.993 1612054581.5399473
train: epoch 142, iter 4500, loss: 2.189802, top_1: 0.705352, top_k: 0.881797, samples/s: 2950.799 1612054590.215498
train: epoch 142, iter 4600, loss: 2.136584, top_1: 0.707070, top_k: 0.879570, samples/s: 2999.694 1612054598.749716
train: epoch 142, iter 4700, loss: 2.052429, top_1: 0.711523, top_k: 0.884648, samples/s: 2967.964 1612054607.375159
train: epoch 142, iter 4800, loss: 2.145795, top_1: 0.704805, top_k: 0.880156, samples/s: 2935.481 1612054616.09608
train: epoch 142, iter 4900, loss: 2.209501, top_1: 0.704258, top_k: 0.880977, samples/s: 2851.727 1612054625.0731332
train: epoch 142, iter 5000, loss: 2.263821, top_1: 0.702539, top_k: 0.879219, samples/s: 2921.186 1612054633.8366358
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_142.
validation: epoch 142, iter 195, top_1: 0.717788, top_k: 0.903666, samples/s: 3006.942 1612054650.6591618
train: epoch 143, iter 100, loss: 2.160670, top_1: 0.705352, top_k: 0.883906, samples/s: 2939.421 1612054675.172414
train: epoch 143, iter 200, loss: 2.152514, top_1: 0.709453, top_k: 0.884297, samples/s: 3006.357 1612054683.6877346
train: epoch 143, iter 300, loss: 2.230879, top_1: 0.710508, top_k: 0.885508, samples/s: 3012.090 1612054692.1869674
train: epoch 143, iter 400, loss: 2.267716, top_1: 0.708750, top_k: 0.880313, samples/s: 2980.917 1612054700.774855
train: epoch 143, iter 500, loss: 2.232418, top_1: 0.706875, top_k: 0.883750, samples/s: 3000.522 1612054709.3066735
train: epoch 143, iter 600, loss: 2.284201, top_1: 0.709805, top_k: 0.883164, samples/s: 3019.078 1612054717.7860074
train: epoch 143, iter 700, loss: 2.240528, top_1: 0.710352, top_k: 0.883125, samples/s: 2969.836 1612054726.4060419
train: epoch 143, iter 800, loss: 2.274071, top_1: 0.712422, top_k: 0.884961, samples/s: 3043.678 1612054734.8168428
train: epoch 143, iter 900, loss: 2.206175, top_1: 0.712812, top_k: 0.886602, samples/s: 2916.618 1612054743.594265
train: epoch 143, iter 1000, loss: 2.262745, top_1: 0.709492, top_k: 0.884062, samples/s: 2965.392 1612054752.227068
train: epoch 143, iter 1100, loss: 2.454499, top_1: 0.707734, top_k: 0.881445, samples/s: 2930.916 1612054760.9615753
train: epoch 143, iter 1200, loss: 2.143132, top_1: 0.701992, top_k: 0.881016, samples/s: 2989.601 1612054769.524846
train: epoch 143, iter 1300, loss: 2.161270, top_1: 0.709727, top_k: 0.885000, samples/s: 3000.972 1612054778.055154
train: epoch 143, iter 1400, loss: 2.326939, top_1: 0.704180, top_k: 0.880859, samples/s: 2964.943 1612054786.6898715
train: epoch 143, iter 1500, loss: 2.346556, top_1: 0.706562, top_k: 0.880820, samples/s: 2931.252 1612054795.4228702
train: epoch 143, iter 1600, loss: 2.350287, top_1: 0.708633, top_k: 0.880195, samples/s: 2951.886 1612054804.0960157
train: epoch 143, iter 1700, loss: 2.250002, top_1: 0.706289, top_k: 0.880742, samples/s: 2985.734 1612054812.6693954
train: epoch 143, iter 1800, loss: 2.123633, top_1: 0.705430, top_k: 0.883242, samples/s: 2958.339 1612054821.3228917
train: epoch 143, iter 1900, loss: 2.219520, top_1: 0.707109, top_k: 0.881250, samples/s: 2935.361 1612054830.0441165
train: epoch 143, iter 2000, loss: 2.213838, top_1: 0.707031, top_k: 0.882773, samples/s: 2966.182 1612054838.6748033
train: epoch 143, iter 2100, loss: 2.116924, top_1: 0.703945, top_k: 0.881992, samples/s: 2992.489 1612054847.229503
train: epoch 143, iter 2200, loss: 2.129091, top_1: 0.703164, top_k: 0.879336, samples/s: 2941.674 1612054855.932035
train: epoch 143, iter 2300, loss: 2.315589, top_1: 0.708750, top_k: 0.881797, samples/s: 3032.684 1612054864.3733635
train: epoch 143, iter 2400, loss: 2.330283, top_1: 0.702461, top_k: 0.879531, samples/s: 2955.569 1612054873.0350838
train: epoch 143, iter 2500, loss: 2.153115, top_1: 0.707578, top_k: 0.880273, samples/s: 2980.037 1612054881.6255612
train: epoch 143, iter 2600, loss: 2.495498, top_1: 0.705586, top_k: 0.880508, samples/s: 2974.049 1612054890.2333252
train: epoch 143, iter 2700, loss: 2.228326, top_1: 0.707539, top_k: 0.882578, samples/s: 3000.360 1612054898.7658033
train: epoch 143, iter 2800, loss: 2.274317, top_1: 0.706055, top_k: 0.881328, samples/s: 2981.558 1612054907.3517869
train: epoch 143, iter 2900, loss: 2.218914, top_1: 0.706953, top_k: 0.881602, samples/s: 2971.845 1612054915.965909
train: epoch 143, iter 3000, loss: 2.315069, top_1: 0.703672, top_k: 0.881289, samples/s: 2968.855 1612054924.5889637
train: epoch 143, iter 3100, loss: 2.244506, top_1: 0.708672, top_k: 0.884922, samples/s: 2944.839 1612054933.281965
train: epoch 143, iter 3200, loss: 2.258600, top_1: 0.714063, top_k: 0.885352, samples/s: 3055.033 1612054941.6614902
train: epoch 143, iter 3300, loss: 2.293593, top_1: 0.705195, top_k: 0.881445, samples/s: 2916.851 1612054950.438212
train: epoch 143, iter 3400, loss: 2.303451, top_1: 0.709492, top_k: 0.881328, samples/s: 2934.271 1612054959.1626244
train: epoch 143, iter 3500, loss: 2.230736, top_1: 0.709102, top_k: 0.884297, samples/s: 2913.743 1612054967.9486485
train: epoch 143, iter 3600, loss: 2.243128, top_1: 0.707578, top_k: 0.881250, samples/s: 2967.248 1612054976.576077
train: epoch 143, iter 3700, loss: 2.113210, top_1: 0.708789, top_k: 0.884805, samples/s: 2928.661 1612054985.3172877
train: epoch 143, iter 3800, loss: 2.223619, top_1: 0.706406, top_k: 0.879180, samples/s: 2927.980 1612054994.0605886
train: epoch 143, iter 3900, loss: 2.120643, top_1: 0.700039, top_k: 0.879023, samples/s: 2972.193 1612055002.6736736
train: epoch 143, iter 4000, loss: 2.226269, top_1: 0.702422, top_k: 0.880391, samples/s: 2913.185 1612055011.4613764
train: epoch 143, iter 4100, loss: 2.167367, top_1: 0.710469, top_k: 0.885703, samples/s: 2974.317 1612055020.0683827
train: epoch 143, iter 4200, loss: 2.354454, top_1: 0.704023, top_k: 0.880508, samples/s: 2907.832 1612055028.8721352
train: epoch 143, iter 4300, loss: 2.279981, top_1: 0.707930, top_k: 0.882773, samples/s: 2914.728 1612055037.655128
train: epoch 143, iter 4400, loss: 2.114072, top_1: 0.711133, top_k: 0.883555, samples/s: 3007.312 1612055046.1677713
train: epoch 143, iter 4500, loss: 2.311766, top_1: 0.703906, top_k: 0.881523, samples/s: 2955.485 1612055054.829585
train: epoch 143, iter 4600, loss: 2.235842, top_1: 0.702539, top_k: 0.879805, samples/s: 2904.340 1612055063.6439474
train: epoch 143, iter 4700, loss: 2.246928, top_1: 0.703984, top_k: 0.883789, samples/s: 2946.733 1612055072.3318107
train: epoch 143, iter 4800, loss: 2.419934, top_1: 0.708828, top_k: 0.880195, samples/s: 2963.010 1612055080.971408
train: epoch 143, iter 4900, loss: 2.280542, top_1: 0.714844, top_k: 0.886563, samples/s: 2954.395 1612055089.6365738
train: epoch 143, iter 5000, loss: 2.346722, top_1: 0.711836, top_k: 0.887656, samples/s: 3038.749 1612055098.0610948
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_143.
validation: epoch 143, iter 195, top_1: 0.717688, top_k: 0.904187, samples/s: 2988.226 1612055115.013243
train: epoch 144, iter 100, loss: 2.151659, top_1: 0.712461, top_k: 0.885938, samples/s: 2944.159 1612055139.701401
train: epoch 144, iter 200, loss: 2.362784, top_1: 0.713008, top_k: 0.887188, samples/s: 2970.581 1612055148.3194346
train: epoch 144, iter 300, loss: 2.219961, top_1: 0.710977, top_k: 0.882812, samples/s: 2983.775 1612055156.8989174
train: epoch 144, iter 400, loss: 2.078053, top_1: 0.709648, top_k: 0.882539, samples/s: 3017.574 1612055165.3824635
train: epoch 144, iter 500, loss: 2.314016, top_1: 0.709023, top_k: 0.882695, samples/s: 2930.087 1612055174.1194413
train: epoch 144, iter 600, loss: 2.407023, top_1: 0.709844, top_k: 0.883672, samples/s: 3016.394 1612055182.6063898
train: epoch 144, iter 700, loss: 2.360722, top_1: 0.710234, top_k: 0.883047, samples/s: 2935.711 1612055191.3267055
train: epoch 144, iter 800, loss: 2.307467, top_1: 0.706445, top_k: 0.880781, samples/s: 2889.564 1612055200.1861408
train: epoch 144, iter 900, loss: 2.148402, top_1: 0.709258, top_k: 0.883242, samples/s: 2960.599 1612055208.8329887
train: epoch 144, iter 1000, loss: 2.353725, top_1: 0.706680, top_k: 0.883945, samples/s: 2961.799 1612055217.4763544
train: epoch 144, iter 1100, loss: 2.146605, top_1: 0.712031, top_k: 0.883125, samples/s: 2954.846 1612055226.140078
train: epoch 144, iter 1200, loss: 2.214035, top_1: 0.711484, top_k: 0.883359, samples/s: 2888.458 1612055235.0030766
train: epoch 144, iter 1300, loss: 2.095098, top_1: 0.710977, top_k: 0.883984, samples/s: 2996.015 1612055243.547661
train: epoch 144, iter 1400, loss: 2.176679, top_1: 0.707305, top_k: 0.886328, samples/s: 2984.385 1612055252.1255972
train: epoch 144, iter 1500, loss: 2.107643, top_1: 0.711172, top_k: 0.883633, samples/s: 2920.871 1612055260.8901322
train: epoch 144, iter 1600, loss: 2.216282, top_1: 0.711484, top_k: 0.881836, samples/s: 2956.256 1612055269.5498102
train: epoch 144, iter 1700, loss: 2.115190, top_1: 0.715664, top_k: 0.885859, samples/s: 2964.532 1612055278.1852372
train: epoch 144, iter 1800, loss: 2.421774, top_1: 0.709453, top_k: 0.884219, samples/s: 3000.101 1612055286.7195268
train: epoch 144, iter 1900, loss: 2.438462, top_1: 0.708242, top_k: 0.883555, samples/s: 2928.460 1612055295.4600239
train: epoch 144, iter 2000, loss: 2.101403, top_1: 0.703008, top_k: 0.881797, samples/s: 2903.173 1612055304.2779286
train: epoch 144, iter 2100, loss: 2.306333, top_1: 0.707695, top_k: 0.880586, samples/s: 2978.948 1612055312.8715231
train: epoch 144, iter 2200, loss: 2.212358, top_1: 0.717070, top_k: 0.887422, samples/s: 2978.574 1612055321.4663641
train: epoch 144, iter 2300, loss: 2.246722, top_1: 0.715391, top_k: 0.885625, samples/s: 2975.487 1612055330.0703511
train: epoch 144, iter 2400, loss: 2.133153, top_1: 0.712187, top_k: 0.885195, samples/s: 2946.494 1612055338.7582593
train: epoch 144, iter 2500, loss: 2.337826, top_1: 0.708555, top_k: 0.880859, samples/s: 2992.541 1612055347.3130765
train: epoch 144, iter 2600, loss: 2.186693, top_1: 0.711523, top_k: 0.885391, samples/s: 2942.463 1612055356.0130105
train: epoch 144, iter 2700, loss: 2.210135, top_1: 0.707500, top_k: 0.881758, samples/s: 3006.411 1612055364.5285988
train: epoch 144, iter 2800, loss: 2.308574, top_1: 0.709063, top_k: 0.884492, samples/s: 3008.913 1612055373.0362086
train: epoch 144, iter 2900, loss: 2.233159, top_1: 0.713047, top_k: 0.883750, samples/s: 2961.020 1612055381.6819513
train: epoch 144, iter 3000, loss: 2.150028, top_1: 0.710859, top_k: 0.885898, samples/s: 2978.673 1612055390.2762594
train: epoch 144, iter 3100, loss: 2.182087, top_1: 0.711914, top_k: 0.885195, samples/s: 2989.016 1612055398.840996
train: epoch 144, iter 3200, loss: 2.462870, top_1: 0.707656, top_k: 0.884453, samples/s: 2987.315 1612055407.4105594
train: epoch 144, iter 3300, loss: 2.271990, top_1: 0.706953, top_k: 0.883008, samples/s: 2981.635 1612055415.9965885
train: epoch 144, iter 3400, loss: 2.218153, top_1: 0.708359, top_k: 0.882539, samples/s: 3011.877 1612055424.4960885
train: epoch 144, iter 3500, loss: 2.340289, top_1: 0.706289, top_k: 0.884922, samples/s: 3018.066 1612055432.9783967
train: epoch 144, iter 3600, loss: 2.185262, top_1: 0.704063, top_k: 0.883086, samples/s: 2937.296 1612055441.6939325
train: epoch 144, iter 3700, loss: 2.152750, top_1: 0.708281, top_k: 0.883750, samples/s: 2970.844 1612055450.3109715
train: epoch 144, iter 3800, loss: 2.267830, top_1: 0.711914, top_k: 0.884102, samples/s: 2964.296 1612055458.9470935
train: epoch 144, iter 3900, loss: 2.279620, top_1: 0.706406, top_k: 0.882539, samples/s: 3001.893 1612055467.475063
train: epoch 144, iter 4000, loss: 2.268489, top_1: 0.711016, top_k: 0.885898, samples/s: 2947.217 1612055476.1612656
train: epoch 144, iter 4100, loss: 2.298899, top_1: 0.710859, top_k: 0.885859, samples/s: 2834.169 1612055485.1939263
train: epoch 144, iter 4200, loss: 2.185051, top_1: 0.707148, top_k: 0.882305, samples/s: 2885.011 1612055494.067282
train: epoch 144, iter 4300, loss: 2.359697, top_1: 0.711836, top_k: 0.882500, samples/s: 2976.813 1612055502.6670935
train: epoch 144, iter 4400, loss: 2.126822, top_1: 0.710352, top_k: 0.886914, samples/s: 2981.444 1612055511.253584
train: epoch 144, iter 4500, loss: 2.277165, top_1: 0.711680, top_k: 0.882422, samples/s: 3012.671 1612055519.750977
train: epoch 144, iter 4600, loss: 2.302381, top_1: 0.711016, top_k: 0.884805, samples/s: 3018.012 1612055528.2334454
train: epoch 144, iter 4700, loss: 2.209318, top_1: 0.709961, top_k: 0.885234, samples/s: 2950.493 1612055536.909913
train: epoch 144, iter 4800, loss: 2.212172, top_1: 0.704102, top_k: 0.879258, samples/s: 2980.368 1612055545.4994378
train: epoch 144, iter 4900, loss: 2.017188, top_1: 0.716211, top_k: 0.885859, samples/s: 2936.682 1612055554.2167375
train: epoch 144, iter 5000, loss: 2.215116, top_1: 0.711719, top_k: 0.885977, samples/s: 2995.244 1612055562.7636268
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_144.
validation: epoch 144, iter 195, top_1: 0.721575, top_k: 0.905489, samples/s: 2818.486 1612055580.7620194
train: epoch 145, iter 100, loss: 2.357776, top_1: 0.713125, top_k: 0.885508, samples/s: 2937.823 1612055605.407497
train: epoch 145, iter 200, loss: 2.159394, top_1: 0.717891, top_k: 0.888398, samples/s: 2952.189 1612055614.0789723
train: epoch 145, iter 300, loss: 2.171569, top_1: 0.715469, top_k: 0.883398, samples/s: 2956.514 1612055622.7378826
train: epoch 145, iter 400, loss: 1.954027, top_1: 0.714805, top_k: 0.889062, samples/s: 2994.169 1612055631.2880414
train: epoch 145, iter 500, loss: 2.102368, top_1: 0.711992, top_k: 0.883242, samples/s: 2943.387 1612055639.9852958
train: epoch 145, iter 600, loss: 2.191885, top_1: 0.712109, top_k: 0.886016, samples/s: 2919.734 1612055648.7532525
train: epoch 145, iter 700, loss: 2.181213, top_1: 0.712422, top_k: 0.886133, samples/s: 2974.222 1612055657.3604522
train: epoch 145, iter 800, loss: 2.007980, top_1: 0.711445, top_k: 0.883477, samples/s: 2936.952 1612055666.0771182
train: epoch 145, iter 900, loss: 2.254553, top_1: 0.709727, top_k: 0.888477, samples/s: 2989.777 1612055674.6396828
train: epoch 145, iter 1000, loss: 2.200839, top_1: 0.706055, top_k: 0.883828, samples/s: 2917.584 1612055683.4138818
train: epoch 145, iter 1100, loss: 2.243888, top_1: 0.710703, top_k: 0.885586, samples/s: 2958.658 1612055692.0664582
train: epoch 145, iter 1200, loss: 2.092055, top_1: 0.713516, top_k: 0.885508, samples/s: 2966.494 1612055700.6961937
train: epoch 145, iter 1300, loss: 2.150334, top_1: 0.714453, top_k: 0.885742, samples/s: 3026.381 1612055709.155151
train: epoch 145, iter 1400, loss: 2.299137, top_1: 0.713477, top_k: 0.883867, samples/s: 2930.546 1612055717.8906882
train: epoch 145, iter 1500, loss: 2.167644, top_1: 0.715938, top_k: 0.885586, samples/s: 2948.190 1612055726.57408
train: epoch 145, iter 1600, loss: 2.326842, top_1: 0.713594, top_k: 0.886133, samples/s: 2911.461 1612055735.3669505
train: epoch 145, iter 1700, loss: 2.259679, top_1: 0.714180, top_k: 0.885586, samples/s: 2972.736 1612055743.9784496
train: epoch 145, iter 1800, loss: 2.168020, top_1: 0.714297, top_k: 0.886992, samples/s: 2966.916 1612055752.6069572
train: epoch 145, iter 1900, loss: 2.194488, top_1: 0.714961, top_k: 0.887070, samples/s: 2944.833 1612055761.3001251
train: epoch 145, iter 2000, loss: 2.058287, top_1: 0.717109, top_k: 0.888047, samples/s: 2966.926 1612055769.9286625
train: epoch 145, iter 2100, loss: 2.195623, top_1: 0.716133, top_k: 0.886367, samples/s: 2925.187 1612055778.6801512
train: epoch 145, iter 2200, loss: 2.258174, top_1: 0.714180, top_k: 0.887695, samples/s: 3004.786 1612055787.1999016
train: epoch 145, iter 2300, loss: 2.086500, top_1: 0.713906, top_k: 0.886992, samples/s: 2921.869 1612055795.9615161
train: epoch 145, iter 2400, loss: 2.387239, top_1: 0.708867, top_k: 0.884375, samples/s: 3020.760 1612055804.4361079
train: epoch 145, iter 2500, loss: 2.128883, top_1: 0.713125, top_k: 0.885117, samples/s: 2993.623 1612055812.9876018
train: epoch 145, iter 2600, loss: 2.193252, top_1: 0.713750, top_k: 0.885508, samples/s: 2953.974 1612055821.6539407
train: epoch 145, iter 2700, loss: 2.100748, top_1: 0.710820, top_k: 0.886953, samples/s: 2975.315 1612055830.258038
train: epoch 145, iter 2800, loss: 2.257880, top_1: 0.714219, top_k: 0.885156, samples/s: 2973.121 1612055838.86854
train: epoch 145, iter 2900, loss: 2.305487, top_1: 0.712422, top_k: 0.883906, samples/s: 2897.535 1612055847.7036085
train: epoch 145, iter 3000, loss: 2.358898, top_1: 0.709922, top_k: 0.884023, samples/s: 2946.531 1612055856.3918085
train: epoch 145, iter 3100, loss: 2.170645, top_1: 0.711523, top_k: 0.885430, samples/s: 2942.306 1612055865.0923965
train: epoch 145, iter 3200, loss: 2.145483, top_1: 0.708438, top_k: 0.882852, samples/s: 3001.358 1612055873.6219878
train: epoch 145, iter 3300, loss: 2.205273, top_1: 0.713711, top_k: 0.884258, samples/s: 2885.888 1612055882.492666
train: epoch 145, iter 3400, loss: 2.211275, top_1: 0.713906, top_k: 0.886836, samples/s: 2975.353 1612055891.0967526
train: epoch 145, iter 3500, loss: 2.205695, top_1: 0.715508, top_k: 0.885039, samples/s: 2961.446 1612055899.7411754
train: epoch 145, iter 3600, loss: 2.120720, top_1: 0.707656, top_k: 0.886406, samples/s: 2987.221 1612055908.310957
train: epoch 145, iter 3700, loss: 2.121501, top_1: 0.713398, top_k: 0.884336, samples/s: 2947.893 1612055916.995215
train: epoch 145, iter 3800, loss: 2.244335, top_1: 0.706641, top_k: 0.882422, samples/s: 2935.100 1612055925.7172089
train: epoch 145, iter 3900, loss: 2.263429, top_1: 0.705039, top_k: 0.881211, samples/s: 2933.006 1612055934.445425
train: epoch 145, iter 4000, loss: 2.213608, top_1: 0.709141, top_k: 0.884375, samples/s: 2941.991 1612055943.1470892
train: epoch 145, iter 4100, loss: 2.143373, top_1: 0.708320, top_k: 0.883242, samples/s: 3032.121 1612055951.58992
train: epoch 145, iter 4200, loss: 2.211343, top_1: 0.711016, top_k: 0.883320, samples/s: 2993.452 1612055960.1419978
train: epoch 145, iter 4300, loss: 2.220849, top_1: 0.712148, top_k: 0.883711, samples/s: 2967.683 1612055968.7682447
train: epoch 145, iter 4400, loss: 2.245168, top_1: 0.710586, top_k: 0.884531, samples/s: 2990.674 1612055977.3280694
train: epoch 145, iter 4500, loss: 2.282533, top_1: 0.706719, top_k: 0.884766, samples/s: 2990.304 1612055985.8891957
train: epoch 145, iter 4600, loss: 2.112915, top_1: 0.711641, top_k: 0.881719, samples/s: 2995.546 1612055994.4352224
train: epoch 145, iter 4700, loss: 2.232917, top_1: 0.714453, top_k: 0.884570, samples/s: 2911.183 1612056003.2288516
train: epoch 145, iter 4800, loss: 2.161670, top_1: 0.708672, top_k: 0.883594, samples/s: 3010.422 1612056011.7330446
train: epoch 145, iter 4900, loss: 2.300225, top_1: 0.712305, top_k: 0.885352, samples/s: 2986.690 1612056020.3039749
train: epoch 145, iter 5000, loss: 2.118212, top_1: 0.714648, top_k: 0.885586, samples/s: 2742.156 1612056029.640112
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_145.
validation: epoch 145, iter 195, top_1: 0.719812, top_k: 0.904147, samples/s: 2882.249 1612056047.277686
train: epoch 146, iter 100, loss: 2.207674, top_1: 0.716328, top_k: 0.887227, samples/s: 2978.446 1612056071.6668332
train: epoch 146, iter 200, loss: 2.131044, top_1: 0.714375, top_k: 0.887695, samples/s: 2999.761 1612056080.2008612
train: epoch 146, iter 300, loss: 2.320941, top_1: 0.710703, top_k: 0.886563, samples/s: 2979.875 1612056088.7916372
train: epoch 146, iter 400, loss: 2.243973, top_1: 0.720195, top_k: 0.889375, samples/s: 2986.474 1612056097.3636327
train: epoch 146, iter 500, loss: 2.154104, top_1: 0.717930, top_k: 0.887539, samples/s: 2910.367 1612056106.1598036
train: epoch 146, iter 600, loss: 2.175637, top_1: 0.719805, top_k: 0.887656, samples/s: 2956.003 1612056114.8205721
train: epoch 146, iter 700, loss: 1.979902, top_1: 0.715156, top_k: 0.884609, samples/s: 3003.584 1612056123.3433855
train: epoch 146, iter 800, loss: 2.233020, top_1: 0.710703, top_k: 0.886602, samples/s: 2966.892 1612056131.9731314
train: epoch 146, iter 900, loss: 2.367555, top_1: 0.711094, top_k: 0.886758, samples/s: 2941.659 1612056140.674439
train: epoch 146, iter 1000, loss: 2.089791, top_1: 0.715156, top_k: 0.889570, samples/s: 2966.890 1612056149.302962
train: epoch 146, iter 1100, loss: 2.355798, top_1: 0.715938, top_k: 0.886680, samples/s: 2966.512 1612056157.9326162
train: epoch 146, iter 1200, loss: 2.201203, top_1: 0.714570, top_k: 0.885820, samples/s: 3000.604 1612056166.4643185
train: epoch 146, iter 1300, loss: 2.244383, top_1: 0.716836, top_k: 0.889180, samples/s: 2998.799 1612056175.0013907
train: epoch 146, iter 1400, loss: 2.274718, top_1: 0.715234, top_k: 0.890430, samples/s: 2944.902 1612056183.6940854
train: epoch 146, iter 1500, loss: 2.213835, top_1: 0.710000, top_k: 0.884414, samples/s: 2924.824 1612056192.4471104
train: epoch 146, iter 1600, loss: 2.405576, top_1: 0.717461, top_k: 0.884336, samples/s: 2963.763 1612056201.0843248
train: epoch 146, iter 1700, loss: 2.207362, top_1: 0.716992, top_k: 0.888594, samples/s: 2991.505 1612056209.641885
train: epoch 146, iter 1800, loss: 2.234341, top_1: 0.714805, top_k: 0.887891, samples/s: 2993.395 1612056218.194117
train: epoch 146, iter 1900, loss: 2.280613, top_1: 0.711172, top_k: 0.883711, samples/s: 3008.624 1612056226.7029078
train: epoch 146, iter 2000, loss: 2.282631, top_1: 0.715742, top_k: 0.884062, samples/s: 2947.363 1612056235.3886776
train: epoch 146, iter 2100, loss: 2.292660, top_1: 0.712930, top_k: 0.883984, samples/s: 2925.938 1612056244.1379623
train: epoch 146, iter 2200, loss: 2.233439, top_1: 0.711211, top_k: 0.884258, samples/s: 2946.842 1612056252.825291
train: epoch 146, iter 2300, loss: 2.251395, top_1: 0.712227, top_k: 0.886445, samples/s: 2743.853 1612056262.1552267
train: epoch 146, iter 2400, loss: 2.285603, top_1: 0.712266, top_k: 0.884648, samples/s: 3003.726 1612056270.6780846
train: epoch 146, iter 2500, loss: 2.161400, top_1: 0.714375, top_k: 0.881719, samples/s: 2992.181 1612056279.2336724
train: epoch 146, iter 2600, loss: 2.174555, top_1: 0.713281, top_k: 0.883359, samples/s: 3003.601 1612056287.756669
train: epoch 146, iter 2700, loss: 2.291462, top_1: 0.717344, top_k: 0.885234, samples/s: 3001.166 1612056296.2866821
train: epoch 146, iter 2800, loss: 2.260066, top_1: 0.709922, top_k: 0.884727, samples/s: 3008.759 1612056304.7951431
train: epoch 146, iter 2900, loss: 2.113546, top_1: 0.713984, top_k: 0.885312, samples/s: 2959.404 1612056313.44556
train: epoch 146, iter 3000, loss: 2.298722, top_1: 0.711562, top_k: 0.883477, samples/s: 3013.020 1612056321.9420292
train: epoch 146, iter 3100, loss: 2.110698, top_1: 0.718828, top_k: 0.886719, samples/s: 2954.750 1612056330.6060538
train: epoch 146, iter 3200, loss: 2.244890, top_1: 0.713281, top_k: 0.885039, samples/s: 2982.350 1612056339.1900995
train: epoch 146, iter 3300, loss: 2.088655, top_1: 0.711641, top_k: 0.882617, samples/s: 2940.155 1612056347.8969002
train: epoch 146, iter 3400, loss: 2.102494, top_1: 0.714648, top_k: 0.883164, samples/s: 2974.444 1612056356.5036328
train: epoch 146, iter 3500, loss: 2.278502, top_1: 0.715859, top_k: 0.887539, samples/s: 2967.790 1612056365.1295063
train: epoch 146, iter 3600, loss: 2.156501, top_1: 0.714258, top_k: 0.884180, samples/s: 2929.026 1612056373.869601
train: epoch 146, iter 3700, loss: 2.186767, top_1: 0.709063, top_k: 0.886289, samples/s: 2972.799 1612056382.4810326
train: epoch 146, iter 3800, loss: 2.300640, top_1: 0.712031, top_k: 0.884961, samples/s: 2955.802 1612056391.1422892
train: epoch 146, iter 3900, loss: 2.438636, top_1: 0.715547, top_k: 0.885391, samples/s: 2982.793 1612056399.7245564
train: epoch 146, iter 4000, loss: 2.286248, top_1: 0.714766, top_k: 0.885820, samples/s: 2967.566 1612056408.351467
train: epoch 146, iter 4100, loss: 2.250077, top_1: 0.717969, top_k: 0.887188, samples/s: 2933.808 1612056417.076946
train: epoch 146, iter 4200, loss: 2.310210, top_1: 0.713320, top_k: 0.886641, samples/s: 2980.131 1612056425.6671991
train: epoch 146, iter 4300, loss: 2.228816, top_1: 0.714141, top_k: 0.891094, samples/s: 2978.567 1612056434.261987
train: epoch 146, iter 4400, loss: 2.103430, top_1: 0.713906, top_k: 0.884102, samples/s: 2967.200 1612056442.8897111
train: epoch 146, iter 4500, loss: 2.239510, top_1: 0.712187, top_k: 0.885078, samples/s: 3021.321 1612056451.3627331
train: epoch 146, iter 4600, loss: 2.289640, top_1: 0.719141, top_k: 0.890117, samples/s: 2872.582 1612056460.2746365
train: epoch 146, iter 4700, loss: 2.282353, top_1: 0.714258, top_k: 0.885859, samples/s: 2987.574 1612056468.843368
train: epoch 146, iter 4800, loss: 2.124028, top_1: 0.719336, top_k: 0.889805, samples/s: 2951.125 1612056477.5180483
train: epoch 146, iter 4900, loss: 2.279674, top_1: 0.711289, top_k: 0.883086, samples/s: 2934.825 1612056486.2409165
train: epoch 146, iter 5000, loss: 2.212834, top_1: 0.711797, top_k: 0.886992, samples/s: 3002.101 1612056494.7682319
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_146.
validation: epoch 146, iter 195, top_1: 0.721655, top_k: 0.906230, samples/s: 2893.019 1612056512.375273
train: epoch 147, iter 100, loss: 2.130832, top_1: 0.719492, top_k: 0.890117, samples/s: 2948.172 1612056537.3495767
train: epoch 147, iter 200, loss: 2.266717, top_1: 0.719648, top_k: 0.887188, samples/s: 2970.236 1612056545.9683855
train: epoch 147, iter 300, loss: 2.267797, top_1: 0.714648, top_k: 0.886953, samples/s: 2989.793 1612056554.5308251
train: epoch 147, iter 400, loss: 2.030638, top_1: 0.717266, top_k: 0.886797, samples/s: 3003.488 1612056563.0542748
train: epoch 147, iter 500, loss: 2.248091, top_1: 0.719727, top_k: 0.885234, samples/s: 2987.235 1612056571.6240003
train: epoch 147, iter 600, loss: 2.200011, top_1: 0.715625, top_k: 0.884609, samples/s: 2918.299 1612056580.3963175
train: epoch 147, iter 700, loss: 2.209763, top_1: 0.712148, top_k: 0.885742, samples/s: 2973.830 1612056589.004915
train: epoch 147, iter 800, loss: 2.182723, top_1: 0.719805, top_k: 0.889102, samples/s: 3009.119 1612056597.512207
train: epoch 147, iter 900, loss: 2.255296, top_1: 0.714063, top_k: 0.884922, samples/s: 2964.265 1612056606.1483889
train: epoch 147, iter 1000, loss: 2.293226, top_1: 0.717500, top_k: 0.888906, samples/s: 3012.387 1612056614.6466653
train: epoch 147, iter 1100, loss: 2.272397, top_1: 0.716719, top_k: 0.887773, samples/s: 2928.262 1612056623.389016
train: epoch 147, iter 1200, loss: 2.156292, top_1: 0.715586, top_k: 0.887930, samples/s: 2983.750 1612056631.968797
train: epoch 147, iter 1300, loss: 2.295050, top_1: 0.708398, top_k: 0.884258, samples/s: 2939.731 1612056640.677164
train: epoch 147, iter 1400, loss: 2.118074, top_1: 0.718437, top_k: 0.888203, samples/s: 2951.296 1612056649.3512704
train: epoch 147, iter 1500, loss: 2.168727, top_1: 0.714180, top_k: 0.886250, samples/s: 2959.588 1612056658.0011165
train: epoch 147, iter 1600, loss: 2.171392, top_1: 0.717461, top_k: 0.889336, samples/s: 2998.719 1612056666.5381095
train: epoch 147, iter 1700, loss: 2.179361, top_1: 0.712617, top_k: 0.889062, samples/s: 3029.086 1612056674.9895208
train: epoch 147, iter 1800, loss: 2.365967, top_1: 0.720430, top_k: 0.889922, samples/s: 2997.120 1612056683.531021
train: epoch 147, iter 1900, loss: 2.242461, top_1: 0.715820, top_k: 0.887773, samples/s: 2968.570 1612056692.1547313
train: epoch 147, iter 2000, loss: 2.291052, top_1: 0.712578, top_k: 0.886523, samples/s: 3030.070 1612056700.603454
train: epoch 147, iter 2100, loss: 2.231654, top_1: 0.718750, top_k: 0.885312, samples/s: 2949.660 1612056709.2822855
train: epoch 147, iter 2200, loss: 2.165324, top_1: 0.713320, top_k: 0.888320, samples/s: 2967.579 1612056717.9088972
train: epoch 147, iter 2300, loss: 2.332718, top_1: 0.720898, top_k: 0.891797, samples/s: 2951.472 1612056726.5825593
train: epoch 147, iter 2400, loss: 2.205539, top_1: 0.716797, top_k: 0.889531, samples/s: 2981.303 1612056735.1693964
train: epoch 147, iter 2500, loss: 2.245373, top_1: 0.723828, top_k: 0.891367, samples/s: 2989.744 1612056743.7319968
train: epoch 147, iter 2600, loss: 2.120621, top_1: 0.717500, top_k: 0.890078, samples/s: 2993.303 1612056752.2844014
train: epoch 147, iter 2700, loss: 2.170993, top_1: 0.713437, top_k: 0.888047, samples/s: 2984.070 1612056760.8633728
train: epoch 147, iter 2800, loss: 2.241834, top_1: 0.715820, top_k: 0.886758, samples/s: 2867.432 1612056769.7911406
train: epoch 147, iter 2900, loss: 2.243274, top_1: 0.710000, top_k: 0.883633, samples/s: 2949.146 1612056778.4716418
train: epoch 147, iter 3000, loss: 2.136000, top_1: 0.712148, top_k: 0.887031, samples/s: 3002.567 1612056786.997662
train: epoch 147, iter 3100, loss: 2.329054, top_1: 0.714961, top_k: 0.886563, samples/s: 2996.298 1612056795.5416265
train: epoch 147, iter 3200, loss: 2.251773, top_1: 0.719609, top_k: 0.890508, samples/s: 2948.175 1612056804.2249532
train: epoch 147, iter 3300, loss: 2.295152, top_1: 0.711836, top_k: 0.886211, samples/s: 2949.888 1612056812.9031985
train: epoch 147, iter 3400, loss: 2.227865, top_1: 0.713828, top_k: 0.885703, samples/s: 2932.094 1612056821.6341078
train: epoch 147, iter 3500, loss: 2.299849, top_1: 0.717734, top_k: 0.885859, samples/s: 2979.476 1612056830.2262766
train: epoch 147, iter 3600, loss: 2.063950, top_1: 0.716016, top_k: 0.890742, samples/s: 2992.225 1612056838.7817435
train: epoch 147, iter 3700, loss: 2.307412, top_1: 0.712148, top_k: 0.889062, samples/s: 2988.600 1612056847.3476403
train: epoch 147, iter 3800, loss: 2.273695, top_1: 0.713672, top_k: 0.888242, samples/s: 2960.353 1612056855.9953606
train: epoch 147, iter 3900, loss: 2.214332, top_1: 0.713750, top_k: 0.886758, samples/s: 2992.651 1612056864.549546
train: epoch 147, iter 4000, loss: 2.149325, top_1: 0.716562, top_k: 0.890977, samples/s: 2898.920 1612056873.38063
train: epoch 147, iter 4100, loss: 2.179132, top_1: 0.715664, top_k: 0.889062, samples/s: 3006.515 1612056881.8953247
train: epoch 147, iter 4200, loss: 2.192938, top_1: 0.717461, top_k: 0.889297, samples/s: 2995.043 1612056890.4427495
train: epoch 147, iter 4300, loss: 2.284698, top_1: 0.712148, top_k: 0.886250, samples/s: 2942.317 1612056899.14332
train: epoch 147, iter 4400, loss: 2.235095, top_1: 0.720742, top_k: 0.888984, samples/s: 2910.106 1612056907.9403934
train: epoch 147, iter 4500, loss: 2.238555, top_1: 0.713437, top_k: 0.886719, samples/s: 2965.471 1612056916.5730395
train: epoch 147, iter 4600, loss: 2.019593, top_1: 0.714102, top_k: 0.887148, samples/s: 2992.002 1612056925.1291082
train: epoch 147, iter 4700, loss: 2.200720, top_1: 0.715000, top_k: 0.885977, samples/s: 2943.230 1612056933.8270276
train: epoch 147, iter 4800, loss: 2.093060, top_1: 0.707734, top_k: 0.884141, samples/s: 2856.794 1612056942.7881606
train: epoch 147, iter 4900, loss: 2.135151, top_1: 0.716172, top_k: 0.890117, samples/s: 2956.206 1612056951.4480007
train: epoch 147, iter 5000, loss: 2.188921, top_1: 0.716250, top_k: 0.888164, samples/s: 2991.180 1612056960.006363
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_147.
validation: epoch 147, iter 195, top_1: 0.724199, top_k: 0.907792, samples/s: 2870.828 1612056977.692894
train: epoch 148, iter 100, loss: 2.257112, top_1: 0.719414, top_k: 0.888516, samples/s: 2964.927 1612057002.2516868
train: epoch 148, iter 200, loss: 2.007293, top_1: 0.719375, top_k: 0.888867, samples/s: 2964.090 1612057010.88838
train: epoch 148, iter 300, loss: 2.114067, top_1: 0.715664, top_k: 0.888906, samples/s: 2953.371 1612057019.5565104
train: epoch 148, iter 400, loss: 2.196084, top_1: 0.718008, top_k: 0.888555, samples/s: 2969.299 1612057028.178071
train: epoch 148, iter 500, loss: 2.041395, top_1: 0.721328, top_k: 0.889727, samples/s: 2960.410 1612057036.8254359
train: epoch 148, iter 600, loss: 2.201348, top_1: 0.718750, top_k: 0.889531, samples/s: 2916.384 1612057045.6034112
train: epoch 148, iter 700, loss: 2.210132, top_1: 0.716094, top_k: 0.885391, samples/s: 3040.702 1612057054.022548
train: epoch 148, iter 800, loss: 2.206462, top_1: 0.721602, top_k: 0.888359, samples/s: 2977.443 1612057062.6205146
train: epoch 148, iter 900, loss: 2.322678, top_1: 0.715313, top_k: 0.887617, samples/s: 2944.677 1612057071.3142385
train: epoch 148, iter 1000, loss: 2.292999, top_1: 0.721836, top_k: 0.889062, samples/s: 2982.948 1612057079.8962836
train: epoch 148, iter 1100, loss: 2.280823, top_1: 0.717578, top_k: 0.887422, samples/s: 3003.876 1612057088.4186015
train: epoch 148, iter 1200, loss: 1.928216, top_1: 0.715352, top_k: 0.887422, samples/s: 2999.512 1612057096.9533813
train: epoch 148, iter 1300, loss: 2.206292, top_1: 0.712969, top_k: 0.886211, samples/s: 2975.714 1612057105.5563889
train: epoch 148, iter 1400, loss: 2.284675, top_1: 0.717656, top_k: 0.892344, samples/s: 2958.309 1612057114.2098658
train: epoch 148, iter 1500, loss: 2.338361, top_1: 0.714180, top_k: 0.886602, samples/s: 2979.378 1612057122.802346
train: epoch 148, iter 1600, loss: 2.159662, top_1: 0.711914, top_k: 0.886914, samples/s: 2959.942 1612057131.4513264
train: epoch 148, iter 1700, loss: 2.091114, top_1: 0.716289, top_k: 0.890586, samples/s: 2974.849 1612057140.0565903
train: epoch 148, iter 1800, loss: 2.025836, top_1: 0.714492, top_k: 0.887227, samples/s: 2921.981 1612057148.8177705
train: epoch 148, iter 1900, loss: 1.974488, top_1: 0.716289, top_k: 0.889727, samples/s: 2978.928 1612057157.4114516
train: epoch 148, iter 2000, loss: 2.176784, top_1: 0.718477, top_k: 0.887109, samples/s: 2960.984 1612057166.0572457
train: epoch 148, iter 2100, loss: 2.147785, top_1: 0.713984, top_k: 0.885781, samples/s: 2904.681 1612057174.870678
train: epoch 148, iter 2200, loss: 2.318424, top_1: 0.718750, top_k: 0.889180, samples/s: 3020.700 1612057183.3455048
train: epoch 148, iter 2300, loss: 2.250663, top_1: 0.715273, top_k: 0.887188, samples/s: 3014.722 1612057191.8371892
train: epoch 148, iter 2400, loss: 2.256211, top_1: 0.714336, top_k: 0.887813, samples/s: 2814.703 1612057200.9322252
train: epoch 148, iter 2500, loss: 2.358407, top_1: 0.718437, top_k: 0.888320, samples/s: 2998.339 1612057209.4703355
train: epoch 148, iter 2600, loss: 2.196055, top_1: 0.718945, top_k: 0.888359, samples/s: 2927.266 1612057218.2158344
train: epoch 148, iter 2700, loss: 2.199077, top_1: 0.715352, top_k: 0.886836, samples/s: 2948.046 1612057226.8993661
train: epoch 148, iter 2800, loss: 2.341868, top_1: 0.716367, top_k: 0.887188, samples/s: 2966.667 1612057235.5285745
train: epoch 148, iter 2900, loss: 2.344204, top_1: 0.716562, top_k: 0.888320, samples/s: 2973.738 1612057244.1372612
train: epoch 148, iter 3000, loss: 2.014523, top_1: 0.715039, top_k: 0.885898, samples/s: 2912.925 1612057252.925677
train: epoch 148, iter 3100, loss: 2.153889, top_1: 0.717617, top_k: 0.886406, samples/s: 2963.374 1612057261.564665
train: epoch 148, iter 3200, loss: 2.186150, top_1: 0.723477, top_k: 0.889609, samples/s: 2775.761 1612057270.7871733
train: epoch 148, iter 3300, loss: 2.141370, top_1: 0.714141, top_k: 0.889883, samples/s: 2963.296 1612057279.4262762
train: epoch 148, iter 3400, loss: 2.285132, top_1: 0.718164, top_k: 0.888320, samples/s: 2953.668 1612057288.0934799
train: epoch 148, iter 3500, loss: 2.075255, top_1: 0.712969, top_k: 0.886250, samples/s: 3012.528 1612057296.5912423
train: epoch 148, iter 3600, loss: 2.251913, top_1: 0.715898, top_k: 0.887305, samples/s: 2957.963 1612057305.2458186
train: epoch 148, iter 3700, loss: 2.390814, top_1: 0.716875, top_k: 0.889883, samples/s: 2967.790 1612057313.8717895
train: epoch 148, iter 3800, loss: 2.156695, top_1: 0.721094, top_k: 0.891328, samples/s: 2955.656 1612057322.5332158
train: epoch 148, iter 3900, loss: 2.355782, top_1: 0.717383, top_k: 0.886563, samples/s: 2958.884 1612057331.1850588
train: epoch 148, iter 4000, loss: 2.292977, top_1: 0.720000, top_k: 0.891328, samples/s: 2993.553 1612057339.7367847
train: epoch 148, iter 4100, loss: 2.197618, top_1: 0.717969, top_k: 0.887617, samples/s: 2940.510 1612057348.4427755
train: epoch 148, iter 4200, loss: 2.263486, top_1: 0.715273, top_k: 0.889180, samples/s: 2992.826 1612057356.9965353
train: epoch 148, iter 4300, loss: 2.252228, top_1: 0.709844, top_k: 0.885938, samples/s: 2953.640 1612057365.6640067
train: epoch 148, iter 4400, loss: 2.069377, top_1: 0.716719, top_k: 0.889961, samples/s: 2945.179 1612057374.3559923
train: epoch 148, iter 4500, loss: 2.266321, top_1: 0.714219, top_k: 0.885742, samples/s: 2992.781 1612057382.9098723
train: epoch 148, iter 4600, loss: 2.135653, top_1: 0.716211, top_k: 0.888086, samples/s: 2942.037 1612057391.6113405
train: epoch 148, iter 4700, loss: 2.172441, top_1: 0.714063, top_k: 0.885508, samples/s: 2973.320 1612057400.2214365
train: epoch 148, iter 4800, loss: 2.386678, top_1: 0.716797, top_k: 0.889453, samples/s: 3003.175 1612057408.7455902
train: epoch 148, iter 4900, loss: 2.118287, top_1: 0.715117, top_k: 0.889258, samples/s: 2911.407 1612057417.5385625
train: epoch 148, iter 5000, loss: 2.048275, top_1: 0.719453, top_k: 0.892422, samples/s: 2950.346 1612057426.2155375
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_148.
validation: epoch 148, iter 195, top_1: 0.723978, top_k: 0.907452, samples/s: 2889.887 1612057443.6727648
train: epoch 149, iter 100, loss: 2.231231, top_1: 0.714883, top_k: 0.889180, samples/s: 2972.018 1612057468.3850913
train: epoch 149, iter 200, loss: 2.271723, top_1: 0.718672, top_k: 0.888945, samples/s: 2994.923 1612057476.9328187
train: epoch 149, iter 300, loss: 2.208063, top_1: 0.714102, top_k: 0.887930, samples/s: 2963.428 1612057485.5715144
train: epoch 149, iter 400, loss: 2.219633, top_1: 0.716445, top_k: 0.890508, samples/s: 3014.659 1612057494.0633085
train: epoch 149, iter 500, loss: 2.166124, top_1: 0.719727, top_k: 0.889570, samples/s: 2961.453 1612057502.7078872
train: epoch 149, iter 600, loss: 2.224406, top_1: 0.717656, top_k: 0.888320, samples/s: 3014.013 1612057511.2014737
train: epoch 149, iter 700, loss: 2.182109, top_1: 0.714648, top_k: 0.886172, samples/s: 2964.158 1612057519.8380103
train: epoch 149, iter 800, loss: 2.012991, top_1: 0.717930, top_k: 0.887031, samples/s: 2982.554 1612057528.4211826
train: epoch 149, iter 900, loss: 2.197240, top_1: 0.719609, top_k: 0.891914, samples/s: 2989.834 1612057536.983586
train: epoch 149, iter 1000, loss: 2.091074, top_1: 0.720273, top_k: 0.890312, samples/s: 2971.972 1612057545.597347
train: epoch 149, iter 1100, loss: 2.262218, top_1: 0.718398, top_k: 0.889219, samples/s: 2963.273 1612057554.2364266
train: epoch 149, iter 1200, loss: 2.329398, top_1: 0.714688, top_k: 0.889219, samples/s: 2991.111 1612057562.7951503
train: epoch 149, iter 1300, loss: 2.332734, top_1: 0.718477, top_k: 0.888945, samples/s: 3001.781 1612057571.323436
train: epoch 149, iter 1400, loss: 2.074640, top_1: 0.719219, top_k: 0.888242, samples/s: 2953.419 1612057579.991322
train: epoch 149, iter 1500, loss: 2.392611, top_1: 0.724063, top_k: 0.888086, samples/s: 2966.696 1612057588.620451
train: epoch 149, iter 1600, loss: 2.209437, top_1: 0.724570, top_k: 0.893359, samples/s: 2975.466 1612057597.224146
train: epoch 149, iter 1700, loss: 2.181776, top_1: 0.723164, top_k: 0.893281, samples/s: 2958.549 1612057605.877026
train: epoch 149, iter 1800, loss: 2.190288, top_1: 0.717969, top_k: 0.889375, samples/s: 2971.138 1612057614.4932506
train: epoch 149, iter 1900, loss: 2.051014, top_1: 0.721523, top_k: 0.889922, samples/s: 2965.213 1612057623.126769
train: epoch 149, iter 2000, loss: 2.312277, top_1: 0.720156, top_k: 0.891289, samples/s: 2944.128 1612057631.8219757
train: epoch 149, iter 2100, loss: 2.312101, top_1: 0.718906, top_k: 0.890859, samples/s: 2888.457 1612057640.684837
train: epoch 149, iter 2200, loss: 2.252146, top_1: 0.720742, top_k: 0.889727, samples/s: 2981.694 1612057649.2705705
train: epoch 149, iter 2300, loss: 2.145609, top_1: 0.721719, top_k: 0.889883, samples/s: 2966.041 1612057657.9015899
train: epoch 149, iter 2400, loss: 2.246014, top_1: 0.720352, top_k: 0.889219, samples/s: 2990.674 1612057666.4616215
train: epoch 149, iter 2500, loss: 2.230718, top_1: 0.717187, top_k: 0.886914, samples/s: 2928.142 1612057675.2043452
train: epoch 149, iter 2600, loss: 2.124245, top_1: 0.721680, top_k: 0.888906, samples/s: 2978.141 1612057683.800266
train: epoch 149, iter 2700, loss: 2.212062, top_1: 0.716836, top_k: 0.890273, samples/s: 2927.870 1612057692.5438166
train: epoch 149, iter 2800, loss: 2.180504, top_1: 0.717695, top_k: 0.887266, samples/s: 2964.350 1612057701.1797605
train: epoch 149, iter 2900, loss: 2.343510, top_1: 0.715117, top_k: 0.886055, samples/s: 2924.378 1612057709.933794
train: epoch 149, iter 3000, loss: 2.193442, top_1: 0.717227, top_k: 0.888359, samples/s: 2938.719 1612057718.645139
train: epoch 149, iter 3100, loss: 2.020419, top_1: 0.718906, top_k: 0.890664, samples/s: 2945.587 1612057727.3360143
train: epoch 149, iter 3200, loss: 2.309025, top_1: 0.719297, top_k: 0.889766, samples/s: 3035.073 1612057735.7715392
train: epoch 149, iter 3300, loss: 2.162722, top_1: 0.720273, top_k: 0.889492, samples/s: 2911.669 1612057744.5630457
train: epoch 149, iter 3400, loss: 2.251507, top_1: 0.716758, top_k: 0.889922, samples/s: 2996.638 1612057753.1058652
train: epoch 149, iter 3500, loss: 2.136584, top_1: 0.716641, top_k: 0.886484, samples/s: 2973.687 1612057761.7147841
train: epoch 149, iter 3600, loss: 2.271222, top_1: 0.716289, top_k: 0.888711, samples/s: 2959.386 1612057770.365358
train: epoch 149, iter 3700, loss: 2.212060, top_1: 0.719063, top_k: 0.887539, samples/s: 2992.301 1612057778.920495
train: epoch 149, iter 3800, loss: 2.324139, top_1: 0.714453, top_k: 0.887969, samples/s: 2956.981 1612057787.5779047
train: epoch 149, iter 3900, loss: 2.243252, top_1: 0.720742, top_k: 0.891875, samples/s: 2942.704 1612057796.2774472
train: epoch 149, iter 4000, loss: 2.234266, top_1: 0.719844, top_k: 0.890430, samples/s: 2963.353 1612057804.9162476
train: epoch 149, iter 4100, loss: 2.274678, top_1: 0.718477, top_k: 0.888281, samples/s: 2981.875 1612057813.5014455
train: epoch 149, iter 4200, loss: 2.261445, top_1: 0.722891, top_k: 0.889648, samples/s: 2976.034 1612057822.103556
train: epoch 149, iter 4300, loss: 2.183740, top_1: 0.722617, top_k: 0.889883, samples/s: 2968.980 1612057830.7259982
train: epoch 149, iter 4400, loss: 2.223661, top_1: 0.715586, top_k: 0.887344, samples/s: 2970.811 1612057839.3431997
train: epoch 149, iter 4500, loss: 1.929754, top_1: 0.719297, top_k: 0.888516, samples/s: 2951.843 1612057848.0166206
train: epoch 149, iter 4600, loss: 2.152493, top_1: 0.718047, top_k: 0.888437, samples/s: 2912.157 1612057856.8065238
train: epoch 149, iter 4700, loss: 2.191470, top_1: 0.717227, top_k: 0.889297, samples/s: 2885.163 1612057865.6809378
train: epoch 149, iter 4800, loss: 2.338863, top_1: 0.719297, top_k: 0.888789, samples/s: 2975.757 1612057874.2823405
train: epoch 149, iter 4900, loss: 2.079185, top_1: 0.721094, top_k: 0.890312, samples/s: 3001.644 1612057882.8109586
train: epoch 149, iter 5000, loss: 2.291553, top_1: 0.720859, top_k: 0.892383, samples/s: 2947.411 1612057891.4965
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_149.
validation: epoch 149, iter 195, top_1: 0.724519, top_k: 0.907953, samples/s: 2900.071 1612057909.0470195
train: epoch 150, iter 100, loss: 2.129036, top_1: 0.717969, top_k: 0.887773, samples/s: 2966.282 1612057933.4856865
train: epoch 150, iter 200, loss: 2.237457, top_1: 0.717852, top_k: 0.888086, samples/s: 2937.230 1612057942.201355
train: epoch 150, iter 300, loss: 2.105639, top_1: 0.722461, top_k: 0.888555, samples/s: 3011.243 1612057950.7028613
train: epoch 150, iter 400, loss: 2.011017, top_1: 0.720430, top_k: 0.888984, samples/s: 2975.575 1612057959.3062022
train: epoch 150, iter 500, loss: 2.169380, top_1: 0.713203, top_k: 0.886797, samples/s: 2961.933 1612057967.949206
train: epoch 150, iter 600, loss: 2.234661, top_1: 0.720977, top_k: 0.887891, samples/s: 2945.779 1612057976.639666
train: epoch 150, iter 700, loss: 1.999460, top_1: 0.716719, top_k: 0.887578, samples/s: 2938.970 1612057985.350278
train: epoch 150, iter 800, loss: 2.232198, top_1: 0.725898, top_k: 0.891719, samples/s: 3013.537 1612057993.8452308
train: epoch 150, iter 900, loss: 2.190315, top_1: 0.715859, top_k: 0.888711, samples/s: 2974.862 1612058002.4505947
train: epoch 150, iter 1000, loss: 2.112122, top_1: 0.719531, top_k: 0.886797, samples/s: 2974.060 1612058011.0583498
train: epoch 150, iter 1100, loss: 2.263770, top_1: 0.716914, top_k: 0.888945, samples/s: 2987.432 1612058019.6276364
train: epoch 150, iter 1200, loss: 2.216902, top_1: 0.718711, top_k: 0.890469, samples/s: 2991.583 1612058028.184917
train: epoch 150, iter 1300, loss: 2.071099, top_1: 0.719766, top_k: 0.890859, samples/s: 2998.352 1612058036.7229302
train: epoch 150, iter 1400, loss: 2.276623, top_1: 0.721328, top_k: 0.887813, samples/s: 2986.833 1612058045.293889
train: epoch 150, iter 1500, loss: 2.129364, top_1: 0.718398, top_k: 0.890625, samples/s: 2928.625 1612058054.0352252
train: epoch 150, iter 1600, loss: 2.188636, top_1: 0.717578, top_k: 0.887852, samples/s: 2951.196 1612058062.7095926
train: epoch 150, iter 1700, loss: 2.277125, top_1: 0.720781, top_k: 0.888398, samples/s: 2895.530 1612058071.5508695
train: epoch 150, iter 1800, loss: 2.090459, top_1: 0.716445, top_k: 0.887500, samples/s: 3001.413 1612058080.080208
train: epoch 150, iter 1900, loss: 2.062306, top_1: 0.720586, top_k: 0.888398, samples/s: 2985.217 1612058088.6558044
train: epoch 150, iter 2000, loss: 2.237082, top_1: 0.716211, top_k: 0.887852, samples/s: 2915.688 1612058097.4358268
train: epoch 150, iter 2100, loss: 2.203287, top_1: 0.723711, top_k: 0.894492, samples/s: 2830.236 1612058106.481071
train: epoch 150, iter 2200, loss: 2.259913, top_1: 0.727422, top_k: 0.893125, samples/s: 3001.023 1612058115.0114565
train: epoch 150, iter 2300, loss: 2.199271, top_1: 0.718906, top_k: 0.887305, samples/s: 2928.684 1612058123.7526824
train: epoch 150, iter 2400, loss: 2.298584, top_1: 0.720000, top_k: 0.887617, samples/s: 2908.792 1612058132.553475
train: epoch 150, iter 2500, loss: 2.164874, top_1: 0.720391, top_k: 0.892461, samples/s: 3000.080 1612058141.0865963
train: epoch 150, iter 2600, loss: 2.302694, top_1: 0.721875, top_k: 0.889531, samples/s: 2984.884 1612058149.663143
train: epoch 150, iter 2700, loss: 2.124465, top_1: 0.723125, top_k: 0.890078, samples/s: 3018.960 1612058158.1428945
train: epoch 150, iter 2800, loss: 2.168715, top_1: 0.725703, top_k: 0.892930, samples/s: 2916.712 1612058166.9198983
train: epoch 150, iter 2900, loss: 2.248219, top_1: 0.719453, top_k: 0.887188, samples/s: 2934.977 1612058175.6423035
train: epoch 150, iter 3000, loss: 2.248764, top_1: 0.720430, top_k: 0.889375, samples/s: 2974.800 1612058184.2479742
train: epoch 150, iter 3100, loss: 2.266437, top_1: 0.725664, top_k: 0.892617, samples/s: 3016.453 1612058192.734729
train: epoch 150, iter 3200, loss: 2.246570, top_1: 0.717305, top_k: 0.885977, samples/s: 2933.391 1612058201.4617453
train: epoch 150, iter 3300, loss: 2.265035, top_1: 0.721055, top_k: 0.892695, samples/s: 2969.829 1612058210.0818346
train: epoch 150, iter 3400, loss: 2.328621, top_1: 0.722969, top_k: 0.889531, samples/s: 2963.981 1612058218.7192729
train: epoch 150, iter 3500, loss: 2.113570, top_1: 0.718984, top_k: 0.889922, samples/s: 3001.907 1612058227.246714
train: epoch 150, iter 3600, loss: 2.103394, top_1: 0.723555, top_k: 0.890547, samples/s: 2980.349 1612058235.836388
train: epoch 150, iter 3700, loss: 2.220919, top_1: 0.719023, top_k: 0.892148, samples/s: 2906.931 1612058244.6433918
train: epoch 150, iter 3800, loss: 2.063797, top_1: 0.716328, top_k: 0.887383, samples/s: 2981.781 1612058253.228436
train: epoch 150, iter 3900, loss: 2.273474, top_1: 0.719688, top_k: 0.887695, samples/s: 2968.085 1612058261.8534765
train: epoch 150, iter 4000, loss: 2.174437, top_1: 0.719531, top_k: 0.888203, samples/s: 2984.108 1612058270.4322467
train: epoch 150, iter 4100, loss: 2.231203, top_1: 0.715078, top_k: 0.888594, samples/s: 2967.500 1612058279.059018
train: epoch 150, iter 4200, loss: 2.190521, top_1: 0.724961, top_k: 0.893906, samples/s: 2956.488 1612058287.7180433
train: epoch 150, iter 4300, loss: 2.044310, top_1: 0.721641, top_k: 0.890000, samples/s: 2996.824 1612058296.2604048
train: epoch 150, iter 4400, loss: 2.167503, top_1: 0.716797, top_k: 0.888047, samples/s: 2977.816 1612058304.8572378
train: epoch 150, iter 4500, loss: 2.197179, top_1: 0.717187, top_k: 0.885234, samples/s: 2927.677 1612058313.601508
train: epoch 150, iter 4600, loss: 2.280148, top_1: 0.722656, top_k: 0.889922, samples/s: 2995.251 1612058322.1482291
train: epoch 150, iter 4700, loss: 2.224615, top_1: 0.722461, top_k: 0.892695, samples/s: 2995.532 1612058330.6942468
train: epoch 150, iter 4800, loss: 2.194319, top_1: 0.720977, top_k: 0.892383, samples/s: 2979.242 1612058339.2871425
train: epoch 150, iter 4900, loss: 2.152144, top_1: 0.719180, top_k: 0.888789, samples/s: 2985.934 1612058347.8606753
train: epoch 150, iter 5000, loss: 2.169219, top_1: 0.724570, top_k: 0.896328, samples/s: 2932.347 1612058356.5908115
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_150.
validation: epoch 150, iter 195, top_1: 0.723658, top_k: 0.906490, samples/s: 2971.223 1612058373.6078446
train: epoch 151, iter 100, loss: 2.322468, top_1: 0.716016, top_k: 0.886406, samples/s: 2945.868 1612058397.9138913
train: epoch 151, iter 200, loss: 2.327884, top_1: 0.724727, top_k: 0.894883, samples/s: 2982.236 1612058406.4980707
train: epoch 151, iter 300, loss: 2.171590, top_1: 0.721836, top_k: 0.891445, samples/s: 3012.933 1612058414.994766
train: epoch 151, iter 400, loss: 2.065503, top_1: 0.723398, top_k: 0.891641, samples/s: 2975.921 1612058423.5971868
train: epoch 151, iter 500, loss: 2.075762, top_1: 0.719023, top_k: 0.890078, samples/s: 2952.083 1612058432.268982
train: epoch 151, iter 600, loss: 2.064343, top_1: 0.722305, top_k: 0.889492, samples/s: 2936.811 1612058440.9859476
train: epoch 151, iter 700, loss: 2.191271, top_1: 0.722148, top_k: 0.888594, samples/s: 2972.275 1612058449.599037
train: epoch 151, iter 800, loss: 2.174955, top_1: 0.721602, top_k: 0.889453, samples/s: 2919.901 1612058458.3664057
train: epoch 151, iter 900, loss: 2.292704, top_1: 0.721406, top_k: 0.890078, samples/s: 3015.406 1612058466.856215
train: epoch 151, iter 1000, loss: 2.280612, top_1: 0.720898, top_k: 0.891563, samples/s: 2965.514 1612058475.4886336
train: epoch 151, iter 1100, loss: 2.286943, top_1: 0.721602, top_k: 0.892109, samples/s: 2957.321 1612058484.1450691
train: epoch 151, iter 1200, loss: 1.984785, top_1: 0.720703, top_k: 0.888047, samples/s: 2944.768 1612058492.8384311
train: epoch 151, iter 1300, loss: 2.145061, top_1: 0.720234, top_k: 0.888008, samples/s: 2930.771 1612058501.5737014
train: epoch 151, iter 1400, loss: 2.164221, top_1: 0.722148, top_k: 0.891523, samples/s: 2941.644 1612058510.275962
train: epoch 151, iter 1500, loss: 2.253875, top_1: 0.718164, top_k: 0.889922, samples/s: 3011.766 1612058518.7764492
train: epoch 151, iter 1600, loss: 2.313045, top_1: 0.717812, top_k: 0.889609, samples/s: 2907.731 1612058527.5800703
train: epoch 151, iter 1700, loss: 2.118392, top_1: 0.721250, top_k: 0.889141, samples/s: 2986.415 1612058536.1522243
train: epoch 151, iter 1800, loss: 2.309990, top_1: 0.721445, top_k: 0.891367, samples/s: 2962.225 1612058544.7945404
train: epoch 151, iter 1900, loss: 2.093583, top_1: 0.719727, top_k: 0.889609, samples/s: 2993.295 1612058553.346917
train: epoch 151, iter 2000, loss: 2.084405, top_1: 0.719414, top_k: 0.890312, samples/s: 2926.252 1612058562.0952437
train: epoch 151, iter 2100, loss: 2.223950, top_1: 0.720977, top_k: 0.890312, samples/s: 2944.087 1612058570.7906961
train: epoch 151, iter 2200, loss: 2.094650, top_1: 0.719375, top_k: 0.888516, samples/s: 2854.264 1612058579.759665
train: epoch 151, iter 2300, loss: 2.102104, top_1: 0.724531, top_k: 0.891602, samples/s: 2940.351 1612058588.4661477
train: epoch 151, iter 2400, loss: 2.282395, top_1: 0.719023, top_k: 0.889141, samples/s: 2898.665 1612058597.2977226
train: epoch 151, iter 2500, loss: 2.140808, top_1: 0.723516, top_k: 0.891719, samples/s: 2804.959 1612058606.4244645
train: epoch 151, iter 2600, loss: 2.214404, top_1: 0.717812, top_k: 0.887578, samples/s: 2954.898 1612058615.0881474
train: epoch 151, iter 2700, loss: 2.189631, top_1: 0.724844, top_k: 0.892773, samples/s: 3027.916 1612058623.5427341
train: epoch 151, iter 2800, loss: 2.095337, top_1: 0.717695, top_k: 0.888828, samples/s: 2957.929 1612058632.1974506
train: epoch 151, iter 2900, loss: 2.212142, top_1: 0.720625, top_k: 0.889648, samples/s: 2927.098 1612058640.943272
train: epoch 151, iter 3000, loss: 2.222740, top_1: 0.722812, top_k: 0.890664, samples/s: 2978.725 1612058649.5375595
train: epoch 151, iter 3100, loss: 2.096076, top_1: 0.726250, top_k: 0.891953, samples/s: 2992.081 1612058658.093456
train: epoch 151, iter 3200, loss: 2.274948, top_1: 0.718672, top_k: 0.888047, samples/s: 2969.093 1612058666.7155988
train: epoch 151, iter 3300, loss: 2.339334, top_1: 0.728359, top_k: 0.890898, samples/s: 2990.117 1612058675.2771466
train: epoch 151, iter 3400, loss: 2.055945, top_1: 0.722773, top_k: 0.889805, samples/s: 2999.102 1612058683.8130972
train: epoch 151, iter 3500, loss: 2.083591, top_1: 0.725781, top_k: 0.892969, samples/s: 2976.802 1612058692.4130807
train: epoch 151, iter 3600, loss: 2.195378, top_1: 0.718047, top_k: 0.892148, samples/s: 2994.673 1612058700.9613743
train: epoch 151, iter 3700, loss: 2.187926, top_1: 0.720664, top_k: 0.888672, samples/s: 3006.225 1612058709.477064
train: epoch 151, iter 3800, loss: 2.340796, top_1: 0.714805, top_k: 0.885938, samples/s: 2936.066 1612058718.1963
train: epoch 151, iter 3900, loss: 2.210514, top_1: 0.720352, top_k: 0.890156, samples/s: 2990.460 1612058726.756752
train: epoch 151, iter 4000, loss: 1.956784, top_1: 0.719297, top_k: 0.888750, samples/s: 2965.844 1612058735.3883753
train: epoch 151, iter 4100, loss: 2.068860, top_1: 0.718203, top_k: 0.890352, samples/s: 2988.572 1612058743.954331
train: epoch 151, iter 4200, loss: 2.112957, top_1: 0.719414, top_k: 0.890352, samples/s: 2944.254 1612058752.6492257
train: epoch 151, iter 4300, loss: 2.119708, top_1: 0.723516, top_k: 0.889414, samples/s: 2921.561 1612058761.4116786
train: epoch 151, iter 4400, loss: 2.175726, top_1: 0.723555, top_k: 0.891133, samples/s: 2984.688 1612058769.9888217
train: epoch 151, iter 4500, loss: 2.266724, top_1: 0.726367, top_k: 0.894258, samples/s: 2990.624 1612058778.5489223
train: epoch 151, iter 4600, loss: 2.020871, top_1: 0.720664, top_k: 0.890859, samples/s: 2988.236 1612058787.1158686
train: epoch 151, iter 4700, loss: 2.296183, top_1: 0.718086, top_k: 0.890273, samples/s: 2963.587 1612058795.7539737
train: epoch 151, iter 4800, loss: 2.227621, top_1: 0.720313, top_k: 0.888242, samples/s: 3007.309 1612058804.2665687
train: epoch 151, iter 4900, loss: 2.257184, top_1: 0.721016, top_k: 0.887344, samples/s: 2926.652 1612058813.013808
train: epoch 151, iter 5000, loss: 2.171632, top_1: 0.715039, top_k: 0.890039, samples/s: 2981.641 1612058821.599691
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_151.
validation: epoch 151, iter 195, top_1: 0.723618, top_k: 0.907392, samples/s: 2959.941 1612058838.7770681
train: epoch 152, iter 100, loss: 2.130396, top_1: 0.720547, top_k: 0.889648, samples/s: 2940.722 1612058863.2258985
train: epoch 152, iter 200, loss: 2.191994, top_1: 0.725234, top_k: 0.892461, samples/s: 3005.842 1612058871.7426193
train: epoch 152, iter 300, loss: 2.233826, top_1: 0.725820, top_k: 0.892734, samples/s: 2984.935 1612058880.3190434
train: epoch 152, iter 400, loss: 2.054476, top_1: 0.725195, top_k: 0.890156, samples/s: 2970.078 1612058888.9384134
train: epoch 152, iter 500, loss: 2.111531, top_1: 0.717812, top_k: 0.889453, samples/s: 2999.264 1612058897.4737859
train: epoch 152, iter 600, loss: 2.124660, top_1: 0.723008, top_k: 0.889531, samples/s: 2864.226 1612058906.4116333
train: epoch 152, iter 700, loss: 2.205489, top_1: 0.718750, top_k: 0.892188, samples/s: 2939.564 1612058915.1203883
train: epoch 152, iter 800, loss: 2.217717, top_1: 0.718437, top_k: 0.889687, samples/s: 2982.011 1612058923.7051468
train: epoch 152, iter 900, loss: 2.107824, top_1: 0.725820, top_k: 0.893594, samples/s: 3001.362 1612058932.2346952
train: epoch 152, iter 1000, loss: 2.135115, top_1: 0.723633, top_k: 0.890625, samples/s: 2953.688 1612058940.901795
train: epoch 152, iter 1100, loss: 2.218337, top_1: 0.721875, top_k: 0.891172, samples/s: 2972.697 1612058949.5134377
train: epoch 152, iter 1200, loss: 2.202266, top_1: 0.724570, top_k: 0.890977, samples/s: 3003.043 1612058958.0382178
train: epoch 152, iter 1300, loss: 2.300378, top_1: 0.719961, top_k: 0.890039, samples/s: 2979.286 1612058966.63096
train: epoch 152, iter 1400, loss: 2.256271, top_1: 0.717109, top_k: 0.892148, samples/s: 2977.097 1612058975.229801
train: epoch 152, iter 1500, loss: 2.357656, top_1: 0.721953, top_k: 0.890938, samples/s: 2933.507 1612058983.9566689
train: epoch 152, iter 1600, loss: 2.035180, top_1: 0.726094, top_k: 0.891602, samples/s: 2978.858 1612058992.5506768
train: epoch 152, iter 1700, loss: 2.216394, top_1: 0.718164, top_k: 0.890156, samples/s: 2977.177 1612059001.1492467
train: epoch 152, iter 1800, loss: 2.160157, top_1: 0.719180, top_k: 0.892539, samples/s: 2968.497 1612059009.7731764
train: epoch 152, iter 1900, loss: 2.253054, top_1: 0.719375, top_k: 0.889570, samples/s: 2971.601 1612059018.3879962
train: epoch 152, iter 2000, loss: 2.050029, top_1: 0.723750, top_k: 0.891758, samples/s: 2968.087 1612059027.0131922
train: epoch 152, iter 2100, loss: 2.212789, top_1: 0.719883, top_k: 0.889375, samples/s: 2960.287 1612059035.661014
train: epoch 152, iter 2200, loss: 2.289425, top_1: 0.722422, top_k: 0.892578, samples/s: 3003.441 1612059044.184454
train: epoch 152, iter 2300, loss: 2.304146, top_1: 0.722266, top_k: 0.892148, samples/s: 2984.060 1612059052.7633588
train: epoch 152, iter 2400, loss: 1.960849, top_1: 0.720000, top_k: 0.891055, samples/s: 2949.890 1612059061.4416523
train: epoch 152, iter 2500, loss: 2.169826, top_1: 0.716758, top_k: 0.886016, samples/s: 3021.053 1612059069.9155111
train: epoch 152, iter 2600, loss: 2.119510, top_1: 0.723594, top_k: 0.889336, samples/s: 2965.666 1612059078.5476558
train: epoch 152, iter 2700, loss: 2.209829, top_1: 0.723398, top_k: 0.892773, samples/s: 2992.062 1612059087.103608
train: epoch 152, iter 2800, loss: 1.988201, top_1: 0.723008, top_k: 0.890664, samples/s: 2982.663 1612059095.6865566
train: epoch 152, iter 2900, loss: 2.095430, top_1: 0.721992, top_k: 0.888359, samples/s: 2973.097 1612059104.297058
train: epoch 152, iter 3000, loss: 2.158483, top_1: 0.724531, top_k: 0.892109, samples/s: 2996.327 1612059112.8408628
train: epoch 152, iter 3100, loss: 2.296031, top_1: 0.721133, top_k: 0.893594, samples/s: 2991.661 1612059121.3982155
train: epoch 152, iter 3200, loss: 2.193507, top_1: 0.721367, top_k: 0.890195, samples/s: 2899.152 1612059130.2281747
train: epoch 152, iter 3300, loss: 2.263315, top_1: 0.720898, top_k: 0.889766, samples/s: 2978.857 1612059138.822097
train: epoch 152, iter 3400, loss: 2.288808, top_1: 0.723711, top_k: 0.890703, samples/s: 2977.512 1612059147.4198697
train: epoch 152, iter 3500, loss: 2.321829, top_1: 0.722266, top_k: 0.889023, samples/s: 2963.974 1612059156.0569596
train: epoch 152, iter 3600, loss: 2.299101, top_1: 0.716797, top_k: 0.887773, samples/s: 2923.235 1612059164.8143063
train: epoch 152, iter 3700, loss: 2.250309, top_1: 0.718711, top_k: 0.888164, samples/s: 2949.526 1612059173.4936776
train: epoch 152, iter 3800, loss: 2.319314, top_1: 0.720586, top_k: 0.890156, samples/s: 2908.001 1612059182.2970772
train: epoch 152, iter 3900, loss: 2.116577, top_1: 0.722969, top_k: 0.888984, samples/s: 2993.887 1612059190.8477395
train: epoch 152, iter 4000, loss: 2.238885, top_1: 0.727656, top_k: 0.894062, samples/s: 2966.850 1612059199.4764411
train: epoch 152, iter 4100, loss: 2.394284, top_1: 0.720938, top_k: 0.888516, samples/s: 2854.725 1612059208.4440148
train: epoch 152, iter 4200, loss: 2.189140, top_1: 0.717383, top_k: 0.888164, samples/s: 2919.182 1612059217.2135403
train: epoch 152, iter 4300, loss: 2.119133, top_1: 0.720352, top_k: 0.888398, samples/s: 3018.959 1612059225.693345
train: epoch 152, iter 4400, loss: 2.223184, top_1: 0.717070, top_k: 0.889570, samples/s: 2976.742 1612059234.293473
train: epoch 152, iter 4500, loss: 2.368565, top_1: 0.724609, top_k: 0.892500, samples/s: 2954.181 1612059242.9591868
train: epoch 152, iter 4600, loss: 2.158037, top_1: 0.717383, top_k: 0.891758, samples/s: 3033.251 1612059251.3988986
train: epoch 152, iter 4700, loss: 2.311529, top_1: 0.718047, top_k: 0.889531, samples/s: 2897.465 1612059260.2341795
train: epoch 152, iter 4800, loss: 2.287060, top_1: 0.720195, top_k: 0.885664, samples/s: 3035.017 1612059268.6690588
train: epoch 152, iter 4900, loss: 2.138571, top_1: 0.718672, top_k: 0.888789, samples/s: 2964.882 1612059277.3033652
train: epoch 152, iter 5000, loss: 2.141730, top_1: 0.722539, top_k: 0.892656, samples/s: 2960.864 1612059285.9495296
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_152.
validation: epoch 152, iter 195, top_1: 0.725761, top_k: 0.908774, samples/s: 3003.113 1612059302.831867
train: epoch 153, iter 100, loss: 2.097959, top_1: 0.722656, top_k: 0.889102, samples/s: 2932.656 1612059327.063272
train: epoch 153, iter 200, loss: 2.249836, top_1: 0.725977, top_k: 0.889922, samples/s: 2983.422 1612059335.6439173
train: epoch 153, iter 300, loss: 2.148698, top_1: 0.729062, top_k: 0.895898, samples/s: 3028.066 1612059344.0982697
train: epoch 153, iter 400, loss: 2.285832, top_1: 0.724102, top_k: 0.889922, samples/s: 3008.445 1612059352.6074853
train: epoch 153, iter 500, loss: 2.333534, top_1: 0.721680, top_k: 0.888984, samples/s: 3010.815 1612059361.1102424
train: epoch 153, iter 600, loss: 2.189240, top_1: 0.728281, top_k: 0.892188, samples/s: 2993.272 1612059369.6627343
train: epoch 153, iter 700, loss: 2.270901, top_1: 0.721836, top_k: 0.891211, samples/s: 2965.229 1612059378.2961383
train: epoch 153, iter 800, loss: 2.180461, top_1: 0.723203, top_k: 0.891680, samples/s: 3000.458 1612059386.828193
train: epoch 153, iter 900, loss: 2.130553, top_1: 0.720977, top_k: 0.891641, samples/s: 2938.587 1612059395.5397904
train: epoch 153, iter 1000, loss: 2.267473, top_1: 0.726875, top_k: 0.893906, samples/s: 3001.427 1612059404.0691116
train: epoch 153, iter 1100, loss: 2.351669, top_1: 0.727031, top_k: 0.892383, samples/s: 3001.972 1612059412.5969381
train: epoch 153, iter 1200, loss: 2.178443, top_1: 0.719570, top_k: 0.890000, samples/s: 2849.789 1612059421.5799828
train: epoch 153, iter 1300, loss: 2.198206, top_1: 0.722305, top_k: 0.890859, samples/s: 2983.011 1612059430.161911
train: epoch 153, iter 1400, loss: 2.187194, top_1: 0.724492, top_k: 0.889687, samples/s: 3001.923 1612059438.6898155
train: epoch 153, iter 1500, loss: 2.040812, top_1: 0.724688, top_k: 0.894414, samples/s: 2960.764 1612059447.3361392
train: epoch 153, iter 1600, loss: 2.240662, top_1: 0.728242, top_k: 0.891758, samples/s: 2988.106 1612059455.903598
train: epoch 153, iter 1700, loss: 2.342561, top_1: 0.717617, top_k: 0.891484, samples/s: 2940.035 1612059464.6109228
train: epoch 153, iter 1800, loss: 2.071100, top_1: 0.723750, top_k: 0.892305, samples/s: 2956.436 1612059473.2699318
train: epoch 153, iter 1900, loss: 2.301252, top_1: 0.720898, top_k: 0.891445, samples/s: 2927.208 1612059482.0155277
train: epoch 153, iter 2000, loss: 2.212721, top_1: 0.718555, top_k: 0.889336, samples/s: 2939.174 1612059490.7260737
train: epoch 153, iter 2100, loss: 2.261582, top_1: 0.714102, top_k: 0.885273, samples/s: 2984.530 1612059499.3029952
train: epoch 153, iter 2200, loss: 2.307917, top_1: 0.723047, top_k: 0.890742, samples/s: 2918.863 1612059508.073501
train: epoch 153, iter 2300, loss: 2.109734, top_1: 0.717930, top_k: 0.888086, samples/s: 2858.375 1612059517.0301957
train: epoch 153, iter 2400, loss: 2.243777, top_1: 0.719492, top_k: 0.886523, samples/s: 3000.562 1612059525.5613782
train: epoch 153, iter 2500, loss: 2.004086, top_1: 0.719258, top_k: 0.890391, samples/s: 2908.966 1612059534.3617387
train: epoch 153, iter 2600, loss: 2.070333, top_1: 0.725703, top_k: 0.892148, samples/s: 3004.406 1612059542.8825963
train: epoch 153, iter 2700, loss: 2.078449, top_1: 0.719805, top_k: 0.887930, samples/s: 2963.798 1612059551.5202112
train: epoch 153, iter 2800, loss: 2.311327, top_1: 0.721914, top_k: 0.890781, samples/s: 2979.790 1612059560.1113508
train: epoch 153, iter 2900, loss: 2.201854, top_1: 0.721914, top_k: 0.892695, samples/s: 2958.344 1612059568.7647858
train: epoch 153, iter 3000, loss: 2.198516, top_1: 0.721367, top_k: 0.890859, samples/s: 2956.938 1612059577.4226067
train: epoch 153, iter 3100, loss: 2.201403, top_1: 0.717227, top_k: 0.891563, samples/s: 2925.049 1612059586.1744852
train: epoch 153, iter 3200, loss: 2.091887, top_1: 0.725234, top_k: 0.890117, samples/s: 2969.707 1612059594.7948334
train: epoch 153, iter 3300, loss: 2.402207, top_1: 0.721875, top_k: 0.887383, samples/s: 2965.589 1612059603.4272592
train: epoch 153, iter 3400, loss: 2.159755, top_1: 0.726719, top_k: 0.891680, samples/s: 2966.013 1612059612.0582247
train: epoch 153, iter 3500, loss: 2.019448, top_1: 0.718281, top_k: 0.892656, samples/s: 2992.195 1612059620.613861
train: epoch 153, iter 3600, loss: 2.066701, top_1: 0.725313, top_k: 0.893984, samples/s: 2942.124 1612059629.3150613
train: epoch 153, iter 3700, loss: 2.250858, top_1: 0.722500, top_k: 0.888945, samples/s: 2963.252 1612059637.9542286
train: epoch 153, iter 3800, loss: 2.230369, top_1: 0.722187, top_k: 0.890625, samples/s: 2999.703 1612059646.4884918
train: epoch 153, iter 3900, loss: 2.262112, top_1: 0.721680, top_k: 0.890586, samples/s: 2968.011 1612059655.1137695
train: epoch 153, iter 4000, loss: 2.285356, top_1: 0.719336, top_k: 0.888203, samples/s: 3002.497 1612059663.6399362
train: epoch 153, iter 4100, loss: 2.049658, top_1: 0.722344, top_k: 0.891406, samples/s: 2961.046 1612059672.2856827
train: epoch 153, iter 4200, loss: 2.088767, top_1: 0.722930, top_k: 0.890977, samples/s: 2944.329 1612059680.980251
train: epoch 153, iter 4300, loss: 2.354544, top_1: 0.722070, top_k: 0.888906, samples/s: 2989.312 1612059689.5441632
train: epoch 153, iter 4400, loss: 2.408377, top_1: 0.722578, top_k: 0.890781, samples/s: 2976.695 1612059698.1442533
train: epoch 153, iter 4500, loss: 2.311587, top_1: 0.721602, top_k: 0.890820, samples/s: 2950.935 1612059706.8194091
train: epoch 153, iter 4600, loss: 2.167069, top_1: 0.719063, top_k: 0.890117, samples/s: 3035.406 1612059715.2531948
train: epoch 153, iter 4700, loss: 2.231981, top_1: 0.723906, top_k: 0.891523, samples/s: 3005.744 1612059723.7702444
train: epoch 153, iter 4800, loss: 1.950989, top_1: 0.720938, top_k: 0.891328, samples/s: 3002.734 1612059732.2957664
train: epoch 153, iter 4900, loss: 2.213483, top_1: 0.723828, top_k: 0.891602, samples/s: 2977.121 1612059740.8948956
train: epoch 153, iter 5000, loss: 2.205394, top_1: 0.724688, top_k: 0.893750, samples/s: 2934.004 1612059749.620065
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_153.
validation: epoch 153, iter 195, top_1: 0.725260, top_k: 0.908794, samples/s: 2982.482 1612059766.6191082
train: epoch 154, iter 100, loss: 2.091113, top_1: 0.727344, top_k: 0.893242, samples/s: 2994.821 1612059791.2819316
train: epoch 154, iter 200, loss: 2.099076, top_1: 0.724844, top_k: 0.889258, samples/s: 3004.066 1612059799.8036087
train: epoch 154, iter 300, loss: 2.070586, top_1: 0.718711, top_k: 0.891328, samples/s: 2817.917 1612059808.8884492
train: epoch 154, iter 400, loss: 2.165852, top_1: 0.720977, top_k: 0.891055, samples/s: 3014.711 1612059817.3800752
train: epoch 154, iter 500, loss: 2.292433, top_1: 0.722695, top_k: 0.888477, samples/s: 3019.218 1612059825.8590991
train: epoch 154, iter 600, loss: 2.135777, top_1: 0.721445, top_k: 0.889258, samples/s: 2975.674 1612059834.4622078
train: epoch 154, iter 700, loss: 2.040238, top_1: 0.725234, top_k: 0.891406, samples/s: 2858.878 1612059843.4166977
train: epoch 154, iter 800, loss: 2.255451, top_1: 0.720430, top_k: 0.891133, samples/s: 2951.235 1612059852.0911572
train: epoch 154, iter 900, loss: 2.165696, top_1: 0.722812, top_k: 0.889570, samples/s: 2990.520 1612059860.6514199
train: epoch 154, iter 1000, loss: 2.096132, top_1: 0.723516, top_k: 0.894375, samples/s: 2948.533 1612059869.3337488
train: epoch 154, iter 1100, loss: 2.271324, top_1: 0.722539, top_k: 0.888750, samples/s: 3032.165 1612059877.7765467
train: epoch 154, iter 1200, loss: 2.045551, top_1: 0.724922, top_k: 0.891523, samples/s: 2984.769 1612059886.3536057
train: epoch 154, iter 1300, loss: 2.298941, top_1: 0.727891, top_k: 0.889375, samples/s: 2993.769 1612059894.9046166
train: epoch 154, iter 1400, loss: 2.104151, top_1: 0.720859, top_k: 0.889883, samples/s: 2970.190 1612059903.5236254
train: epoch 154, iter 1500, loss: 2.023951, top_1: 0.722109, top_k: 0.890977, samples/s: 3021.063 1612059911.997369
train: epoch 154, iter 1600, loss: 2.241276, top_1: 0.715977, top_k: 0.889023, samples/s: 2949.643 1612059920.6764145
train: epoch 154, iter 1700, loss: 2.150216, top_1: 0.721211, top_k: 0.887109, samples/s: 2957.173 1612059929.3337965
train: epoch 154, iter 1800, loss: 2.127711, top_1: 0.718516, top_k: 0.889297, samples/s: 2983.993 1612059937.9123447
train: epoch 154, iter 1900, loss: 2.180424, top_1: 0.724492, top_k: 0.889648, samples/s: 2993.994 1612059946.4631076
train: epoch 154, iter 2000, loss: 2.111099, top_1: 0.718984, top_k: 0.885977, samples/s: 3005.556 1612059954.9803865
train: epoch 154, iter 2100, loss: 2.244925, top_1: 0.725469, top_k: 0.892148, samples/s: 3003.492 1612059963.5042999
train: epoch 154, iter 2200, loss: 2.121547, top_1: 0.721484, top_k: 0.891250, samples/s: 2904.877 1612059972.3166852
train: epoch 154, iter 2300, loss: 1.984195, top_1: 0.723125, top_k: 0.892617, samples/s: 2987.075 1612059980.8868892
train: epoch 154, iter 2400, loss: 2.191468, top_1: 0.726641, top_k: 0.889687, samples/s: 2950.485 1612059989.5633836
train: epoch 154, iter 2500, loss: 2.153642, top_1: 0.727148, top_k: 0.893906, samples/s: 2976.707 1612059998.1639411
train: epoch 154, iter 2600, loss: 1.960220, top_1: 0.721562, top_k: 0.888164, samples/s: 2915.140 1612060006.9452286
train: epoch 154, iter 2700, loss: 2.234541, top_1: 0.722852, top_k: 0.894180, samples/s: 2965.926 1612060015.5767143
train: epoch 154, iter 2800, loss: 2.372068, top_1: 0.722344, top_k: 0.891523, samples/s: 2917.111 1612060024.3524485
train: epoch 154, iter 2900, loss: 2.119769, top_1: 0.724688, top_k: 0.892266, samples/s: 3025.463 1612060032.8138537
train: epoch 154, iter 3000, loss: 1.919074, top_1: 0.726328, top_k: 0.893867, samples/s: 2905.424 1612060041.6251614
train: epoch 154, iter 3100, loss: 2.236840, top_1: 0.719023, top_k: 0.887734, samples/s: 3017.218 1612060050.1096456
train: epoch 154, iter 3200, loss: 2.304215, top_1: 0.723789, top_k: 0.894141, samples/s: 2954.338 1612060058.7753499
train: epoch 154, iter 3300, loss: 2.049904, top_1: 0.723672, top_k: 0.891172, samples/s: 2992.869 1612060067.328594
train: epoch 154, iter 3400, loss: 2.432931, top_1: 0.726484, top_k: 0.892422, samples/s: 3016.306 1612060075.8157635
train: epoch 154, iter 3500, loss: 2.081700, top_1: 0.721289, top_k: 0.892422, samples/s: 2990.061 1612060084.377411
train: epoch 154, iter 3600, loss: 2.253023, top_1: 0.716484, top_k: 0.890703, samples/s: 2997.527 1612060092.9178176
train: epoch 154, iter 3700, loss: 2.176463, top_1: 0.714727, top_k: 0.888008, samples/s: 2930.623 1612060101.6532204
train: epoch 154, iter 3800, loss: 2.132087, top_1: 0.722734, top_k: 0.889727, samples/s: 2967.296 1612060110.280558
train: epoch 154, iter 3900, loss: 2.141912, top_1: 0.724023, top_k: 0.891094, samples/s: 2954.446 1612060118.9455454
train: epoch 154, iter 4000, loss: 2.260395, top_1: 0.722539, top_k: 0.892188, samples/s: 2914.818 1612060127.7281497
train: epoch 154, iter 4100, loss: 2.186983, top_1: 0.722422, top_k: 0.890312, samples/s: 2979.502 1612060136.3201988
train: epoch 154, iter 4200, loss: 2.282010, top_1: 0.724844, top_k: 0.892188, samples/s: 2981.320 1612060144.9069922
train: epoch 154, iter 4300, loss: 2.206619, top_1: 0.721836, top_k: 0.889727, samples/s: 2977.187 1612060153.505787
train: epoch 154, iter 4400, loss: 2.142049, top_1: 0.722539, top_k: 0.891055, samples/s: 2975.424 1612060162.1096087
train: epoch 154, iter 4500, loss: 1.979277, top_1: 0.719688, top_k: 0.890586, samples/s: 2932.187 1612060170.8402503
train: epoch 154, iter 4600, loss: 2.209565, top_1: 0.722266, top_k: 0.894531, samples/s: 2871.466 1612060179.7555895
train: epoch 154, iter 4700, loss: 2.214984, top_1: 0.721641, top_k: 0.894023, samples/s: 3009.377 1612060188.262278
train: epoch 154, iter 4800, loss: 2.298222, top_1: 0.719102, top_k: 0.889141, samples/s: 2963.902 1612060196.8994832
train: epoch 154, iter 4900, loss: 2.202257, top_1: 0.726406, top_k: 0.889258, samples/s: 2986.424 1612060205.471687
train: epoch 154, iter 5000, loss: 2.281780, top_1: 0.727656, top_k: 0.890898, samples/s: 2966.481 1612060214.1014187
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_154.
validation: epoch 154, iter 195, top_1: 0.726002, top_k: 0.909575, samples/s: 2957.157 1612060231.2379005
train: epoch 155, iter 100, loss: 2.259257, top_1: 0.723008, top_k: 0.890703, samples/s: 2970.099 1612060256.0951931
train: epoch 155, iter 200, loss: 2.082734, top_1: 0.722695, top_k: 0.888867, samples/s: 2933.849 1612060264.8208776
train: epoch 155, iter 300, loss: 2.219738, top_1: 0.722148, top_k: 0.890234, samples/s: 2977.720 1612060273.4180913
train: epoch 155, iter 400, loss: 2.299956, top_1: 0.723008, top_k: 0.891094, samples/s: 3012.293 1612060281.916659
train: epoch 155, iter 500, loss: 2.049316, top_1: 0.719844, top_k: 0.889961, samples/s: 3011.007 1612060290.4187117
train: epoch 155, iter 600, loss: 2.071090, top_1: 0.726016, top_k: 0.892109, samples/s: 2940.129 1612060299.1257703
train: epoch 155, iter 700, loss: 2.124121, top_1: 0.717344, top_k: 0.886836, samples/s: 2977.559 1612060307.723449
train: epoch 155, iter 800, loss: 2.040102, top_1: 0.722656, top_k: 0.895781, samples/s: 3013.502 1612060316.218552
train: epoch 155, iter 900, loss: 2.010331, top_1: 0.724609, top_k: 0.890195, samples/s: 3001.743 1612060324.7470505
train: epoch 155, iter 1000, loss: 2.289708, top_1: 0.726641, top_k: 0.892930, samples/s: 2952.602 1612060333.4173062
train: epoch 155, iter 1100, loss: 2.140412, top_1: 0.718828, top_k: 0.889102, samples/s: 3010.319 1612060341.9214246
train: epoch 155, iter 1200, loss: 2.236515, top_1: 0.720781, top_k: 0.887930, samples/s: 2995.453 1612060350.4676514
train: epoch 155, iter 1300, loss: 2.139628, top_1: 0.719531, top_k: 0.888867, samples/s: 2988.256 1612060359.0344923
train: epoch 155, iter 1400, loss: 2.123243, top_1: 0.727344, top_k: 0.892070, samples/s: 2970.696 1612060367.6520197
train: epoch 155, iter 1500, loss: 2.067688, top_1: 0.724492, top_k: 0.888789, samples/s: 2937.228 1612060376.3677495
train: epoch 155, iter 1600, loss: 2.039372, top_1: 0.725859, top_k: 0.892188, samples/s: 2934.128 1612060385.0925822
train: epoch 155, iter 1700, loss: 2.242525, top_1: 0.723437, top_k: 0.889297, samples/s: 2929.433 1612060393.8315392
train: epoch 155, iter 1800, loss: 2.220731, top_1: 0.722344, top_k: 0.888281, samples/s: 2957.951 1612060402.4861603
train: epoch 155, iter 1900, loss: 2.048535, top_1: 0.722656, top_k: 0.892148, samples/s: 2929.274 1612060411.2256117
train: epoch 155, iter 2000, loss: 1.874235, top_1: 0.726055, top_k: 0.891328, samples/s: 2962.080 1612060419.8680973
train: epoch 155, iter 2100, loss: 2.310321, top_1: 0.718242, top_k: 0.891211, samples/s: 2996.016 1612060428.4127564
train: epoch 155, iter 2200, loss: 2.084787, top_1: 0.722773, top_k: 0.892148, samples/s: 2939.252 1612060437.1225164
train: epoch 155, iter 2300, loss: 2.257329, top_1: 0.726211, top_k: 0.892734, samples/s: 3007.568 1612060445.6343288
train: epoch 155, iter 2400, loss: 2.380167, top_1: 0.726289, top_k: 0.893125, samples/s: 3001.313 1612060454.1638844
train: epoch 155, iter 2500, loss: 2.212764, top_1: 0.723164, top_k: 0.891914, samples/s: 2964.948 1612060462.7981536
train: epoch 155, iter 2600, loss: 2.194494, top_1: 0.725508, top_k: 0.891133, samples/s: 2961.986 1612060471.44109
train: epoch 155, iter 2700, loss: 2.100271, top_1: 0.725117, top_k: 0.893281, samples/s: 2981.032 1612060480.0287285
train: epoch 155, iter 2800, loss: 2.241329, top_1: 0.722148, top_k: 0.894180, samples/s: 3007.294 1612060488.5414279
train: epoch 155, iter 2900, loss: 2.261124, top_1: 0.721094, top_k: 0.889727, samples/s: 2911.254 1612060497.3349
train: epoch 155, iter 3000, loss: 2.271121, top_1: 0.726328, top_k: 0.892188, samples/s: 3004.784 1612060505.8547485
train: epoch 155, iter 3100, loss: 2.256270, top_1: 0.722812, top_k: 0.889180, samples/s: 2987.682 1612060514.4231126
train: epoch 155, iter 3200, loss: 2.049052, top_1: 0.724688, top_k: 0.891406, samples/s: 2896.611 1612060523.2609606
train: epoch 155, iter 3300, loss: 2.215974, top_1: 0.725195, top_k: 0.893711, samples/s: 2963.196 1612060531.9003267
train: epoch 155, iter 3400, loss: 2.266094, top_1: 0.716367, top_k: 0.891445, samples/s: 2949.307 1612060540.5802171
train: epoch 155, iter 3500, loss: 2.190535, top_1: 0.720547, top_k: 0.891211, samples/s: 2985.958 1612060549.1536872
train: epoch 155, iter 3600, loss: 2.203817, top_1: 0.720195, top_k: 0.890156, samples/s: 2983.418 1612060557.734451
train: epoch 155, iter 3700, loss: 2.172412, top_1: 0.721055, top_k: 0.891758, samples/s: 2925.426 1612060566.4853427
train: epoch 155, iter 3800, loss: 2.094939, top_1: 0.725234, top_k: 0.890195, samples/s: 2973.634 1612060575.0942914
train: epoch 155, iter 3900, loss: 2.328640, top_1: 0.720313, top_k: 0.892461, samples/s: 2982.258 1612060583.6784203
train: epoch 155, iter 4000, loss: 2.064342, top_1: 0.720859, top_k: 0.890391, samples/s: 2950.182 1612060592.35593
train: epoch 155, iter 4100, loss: 2.187935, top_1: 0.726641, top_k: 0.890625, samples/s: 3021.351 1612060600.8288736
train: epoch 155, iter 4200, loss: 2.343249, top_1: 0.727773, top_k: 0.890469, samples/s: 2945.945 1612060609.518758
train: epoch 155, iter 4300, loss: 2.171221, top_1: 0.723555, top_k: 0.890781, samples/s: 2921.867 1612060618.2802956
train: epoch 155, iter 4400, loss: 2.071996, top_1: 0.726367, top_k: 0.890820, samples/s: 2989.374 1612060626.8440046
train: epoch 155, iter 4500, loss: 2.334771, top_1: 0.724727, top_k: 0.889922, samples/s: 2938.287 1612060635.5565417
train: epoch 155, iter 4600, loss: 2.198592, top_1: 0.725273, top_k: 0.893359, samples/s: 2990.787 1612060644.1161494
train: epoch 155, iter 4700, loss: 2.187351, top_1: 0.721172, top_k: 0.892461, samples/s: 2950.374 1612060652.7929666
train: epoch 155, iter 4800, loss: 2.193581, top_1: 0.723008, top_k: 0.892656, samples/s: 3005.888 1612060661.309687
train: epoch 155, iter 4900, loss: 2.070049, top_1: 0.722109, top_k: 0.888594, samples/s: 2993.647 1612060669.8610857
train: epoch 155, iter 5000, loss: 2.170852, top_1: 0.720469, top_k: 0.891758, samples/s: 2985.959 1612060678.434693
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_155.
validation: epoch 155, iter 195, top_1: 0.725701, top_k: 0.909255, samples/s: 2924.073 1612060695.805244
train: epoch 156, iter 100, loss: 2.099264, top_1: 0.727109, top_k: 0.893711, samples/s: 2958.114 1612060720.8755863
train: epoch 156, iter 200, loss: 2.149496, top_1: 0.725273, top_k: 0.892148, samples/s: 2967.873 1612060729.501569
train: epoch 156, iter 300, loss: 2.148636, top_1: 0.720117, top_k: 0.890820, samples/s: 3011.502 1612060738.0019617
train: epoch 156, iter 400, loss: 2.056718, top_1: 0.718594, top_k: 0.888047, samples/s: 2997.582 1612060746.5422359
train: epoch 156, iter 500, loss: 2.273205, top_1: 0.723555, top_k: 0.891250, samples/s: 2974.374 1612060755.149518
train: epoch 156, iter 600, loss: 2.293811, top_1: 0.719258, top_k: 0.891797, samples/s: 2898.062 1612060763.9826896
train: epoch 156, iter 700, loss: 2.296897, top_1: 0.718516, top_k: 0.889727, samples/s: 2918.770 1612060772.753406
train: epoch 156, iter 800, loss: 2.087820, top_1: 0.723477, top_k: 0.892852, samples/s: 2958.394 1612060781.406807
train: epoch 156, iter 900, loss: 2.299855, top_1: 0.720156, top_k: 0.889297, samples/s: 2981.285 1612060789.9936779
train: epoch 156, iter 1000, loss: 2.244057, top_1: 0.719180, top_k: 0.889062, samples/s: 2991.630 1612060798.5507953
train: epoch 156, iter 1100, loss: 2.261941, top_1: 0.722930, top_k: 0.891133, samples/s: 3011.983 1612060807.050326
train: epoch 156, iter 1200, loss: 2.141464, top_1: 0.719453, top_k: 0.892148, samples/s: 2942.818 1612060815.7493649
train: epoch 156, iter 1300, loss: 2.186546, top_1: 0.723437, top_k: 0.890586, samples/s: 3016.730 1612060824.2353547
train: epoch 156, iter 1400, loss: 1.881615, top_1: 0.724648, top_k: 0.896250, samples/s: 3005.391 1612060832.7534127
train: epoch 156, iter 1500, loss: 1.916623, top_1: 0.725039, top_k: 0.894727, samples/s: 3001.498 1612060841.2824783
train: epoch 156, iter 1600, loss: 2.170251, top_1: 0.720313, top_k: 0.890430, samples/s: 2906.478 1612060850.0904357
train: epoch 156, iter 1700, loss: 2.260138, top_1: 0.721797, top_k: 0.890312, samples/s: 3003.289 1612060858.614392
train: epoch 156, iter 1800, loss: 2.015671, top_1: 0.723906, top_k: 0.892969, samples/s: 2926.687 1612060867.3614829
train: epoch 156, iter 1900, loss: 2.410227, top_1: 0.722109, top_k: 0.887813, samples/s: 2993.783 1612060875.9125245
train: epoch 156, iter 2000, loss: 2.132463, top_1: 0.720469, top_k: 0.890859, samples/s: 2976.094 1612060884.5144196
train: epoch 156, iter 2100, loss: 2.261475, top_1: 0.724727, top_k: 0.890938, samples/s: 2914.808 1612060893.2973447
train: epoch 156, iter 2200, loss: 1.957784, top_1: 0.720156, top_k: 0.889062, samples/s: 3016.817 1612060901.7829053
train: epoch 156, iter 2300, loss: 2.385332, top_1: 0.721445, top_k: 0.890117, samples/s: 2983.609 1612060910.3631122
train: epoch 156, iter 2400, loss: 2.170116, top_1: 0.718477, top_k: 0.892930, samples/s: 2941.731 1612060919.065429
train: epoch 156, iter 2500, loss: 2.190373, top_1: 0.720898, top_k: 0.893008, samples/s: 2979.369 1612060927.658034
train: epoch 156, iter 2600, loss: 2.117544, top_1: 0.722383, top_k: 0.890039, samples/s: 2975.620 1612060936.2611642
train: epoch 156, iter 2700, loss: 2.412582, top_1: 0.718125, top_k: 0.890859, samples/s: 2960.762 1612060944.9075942
train: epoch 156, iter 2800, loss: 2.103351, top_1: 0.715156, top_k: 0.887813, samples/s: 2946.704 1612060953.5952902
train: epoch 156, iter 2900, loss: 2.235339, top_1: 0.721133, top_k: 0.892109, samples/s: 2940.030 1612060962.30272
train: epoch 156, iter 3000, loss: 2.134877, top_1: 0.723867, top_k: 0.892422, samples/s: 2981.399 1612060970.8892226
train: epoch 156, iter 3100, loss: 2.077034, top_1: 0.722578, top_k: 0.891563, samples/s: 2897.738 1612060979.724072
train: epoch 156, iter 3200, loss: 2.180825, top_1: 0.720430, top_k: 0.890781, samples/s: 3013.417 1612060988.2189825
train: epoch 156, iter 3300, loss: 2.144797, top_1: 0.727578, top_k: 0.891992, samples/s: 2982.298 1612060996.8030822
train: epoch 156, iter 3400, loss: 2.249987, top_1: 0.726719, top_k: 0.894805, samples/s: 2994.804 1612061005.351157
train: epoch 156, iter 3500, loss: 2.200032, top_1: 0.721992, top_k: 0.890898, samples/s: 2998.661 1612061013.8888304
train: epoch 156, iter 3600, loss: 2.194757, top_1: 0.721445, top_k: 0.888750, samples/s: 2980.541 1612061022.477496
train: epoch 156, iter 3700, loss: 2.257555, top_1: 0.726836, top_k: 0.889648, samples/s: 3000.157 1612061031.0102859
train: epoch 156, iter 3800, loss: 2.305455, top_1: 0.722773, top_k: 0.892500, samples/s: 2967.640 1612061039.6366262
train: epoch 156, iter 3900, loss: 2.144186, top_1: 0.724219, top_k: 0.890000, samples/s: 3001.435 1612061048.1658792
train: epoch 156, iter 4000, loss: 2.202374, top_1: 0.721367, top_k: 0.889648, samples/s: 2956.747 1612061056.8241065
train: epoch 156, iter 4100, loss: 2.216045, top_1: 0.723281, top_k: 0.890000, samples/s: 2980.942 1612061065.4119253
train: epoch 156, iter 4200, loss: 2.312252, top_1: 0.719375, top_k: 0.889883, samples/s: 2992.120 1612061073.9677327
train: epoch 156, iter 4300, loss: 2.371405, top_1: 0.723086, top_k: 0.891211, samples/s: 2890.427 1612061082.824658
train: epoch 156, iter 4400, loss: 2.108029, top_1: 0.722344, top_k: 0.887227, samples/s: 2957.528 1612061091.4804251
train: epoch 156, iter 4500, loss: 2.169333, top_1: 0.718633, top_k: 0.889375, samples/s: 2950.025 1612061100.158326
train: epoch 156, iter 4600, loss: 2.076716, top_1: 0.716523, top_k: 0.887148, samples/s: 2963.464 1612061108.7968702
train: epoch 156, iter 4700, loss: 2.219417, top_1: 0.723125, top_k: 0.890781, samples/s: 3012.309 1612061117.2953744
train: epoch 156, iter 4800, loss: 2.127484, top_1: 0.724180, top_k: 0.891211, samples/s: 2949.179 1612061125.9757514
train: epoch 156, iter 4900, loss: 2.235296, top_1: 0.720977, top_k: 0.887813, samples/s: 2866.330 1612061134.90702
train: epoch 156, iter 5000, loss: 2.297979, top_1: 0.719609, top_k: 0.888984, samples/s: 2962.021 1612061143.5496986
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_156.
validation: epoch 156, iter 195, top_1: 0.725841, top_k: 0.908694, samples/s: 2995.157 1612061160.4759512
train: epoch 157, iter 100, loss: 2.323371, top_1: 0.723477, top_k: 0.890469, samples/s: 2957.579 1612061191.1057706
train: epoch 157, iter 200, loss: 2.062757, top_1: 0.720781, top_k: 0.891680, samples/s: 3002.694 1612061199.6314943
train: epoch 157, iter 300, loss: 1.921261, top_1: 0.723945, top_k: 0.891758, samples/s: 2927.784 1612061208.3754337
train: epoch 157, iter 400, loss: 2.097348, top_1: 0.729531, top_k: 0.890820, samples/s: 2974.631 1612061216.9814222
train: epoch 157, iter 500, loss: 2.227512, top_1: 0.718555, top_k: 0.891055, samples/s: 2938.391 1612061225.6937447
train: epoch 157, iter 600, loss: 2.102642, top_1: 0.722344, top_k: 0.889570, samples/s: 2933.071 1612061234.4216583
train: epoch 157, iter 700, loss: 2.207202, top_1: 0.722539, top_k: 0.892227, samples/s: 2930.337 1612061243.1578813
train: epoch 157, iter 800, loss: 2.206820, top_1: 0.724336, top_k: 0.891914, samples/s: 2893.656 1612061252.0049272
train: epoch 157, iter 900, loss: 2.220337, top_1: 0.713242, top_k: 0.888594, samples/s: 2998.959 1612061260.5411303
train: epoch 157, iter 1000, loss: 2.205199, top_1: 0.718594, top_k: 0.890156, samples/s: 2955.448 1612061269.2030654
train: epoch 157, iter 1100, loss: 2.083478, top_1: 0.724609, top_k: 0.891680, samples/s: 2998.620 1612061277.7403235
train: epoch 157, iter 1200, loss: 2.238475, top_1: 0.720430, top_k: 0.891211, samples/s: 2943.050 1612061286.4388437
train: epoch 157, iter 1300, loss: 2.242905, top_1: 0.725820, top_k: 0.891406, samples/s: 2992.689 1612061294.9929662
train: epoch 157, iter 1400, loss: 2.021567, top_1: 0.723984, top_k: 0.890820, samples/s: 2939.096 1612061303.7031293
train: epoch 157, iter 1500, loss: 2.268315, top_1: 0.720469, top_k: 0.888047, samples/s: 2990.537 1612061312.263443
train: epoch 157, iter 1600, loss: 2.293858, top_1: 0.721602, top_k: 0.886719, samples/s: 2848.937 1612061321.2495563
train: epoch 157, iter 1700, loss: 2.107884, top_1: 0.722812, top_k: 0.889844, samples/s: 2988.531 1612061329.8152947
train: epoch 157, iter 1800, loss: 2.215459, top_1: 0.725273, top_k: 0.892266, samples/s: 2967.940 1612061338.4409332
train: epoch 157, iter 1900, loss: 2.153198, top_1: 0.723125, top_k: 0.888008, samples/s: 2902.243 1612061347.2617216
train: epoch 157, iter 2000, loss: 2.163519, top_1: 0.723203, top_k: 0.890859, samples/s: 3039.556 1612061355.683938
train: epoch 157, iter 2100, loss: 2.256509, top_1: 0.725664, top_k: 0.893594, samples/s: 2914.166 1612061364.4687037
train: epoch 157, iter 2200, loss: 2.160137, top_1: 0.722266, top_k: 0.889687, samples/s: 2999.387 1612061373.0037677
train: epoch 157, iter 2300, loss: 2.077762, top_1: 0.727383, top_k: 0.893203, samples/s: 2940.824 1612061381.708704
train: epoch 157, iter 2400, loss: 2.287685, top_1: 0.723750, top_k: 0.890781, samples/s: 3018.450 1612061390.1898766
train: epoch 157, iter 2500, loss: 2.089640, top_1: 0.720273, top_k: 0.891250, samples/s: 2974.744 1612061398.7958312
train: epoch 157, iter 2600, loss: 2.153230, top_1: 0.726523, top_k: 0.889727, samples/s: 2936.326 1612061407.514274
train: epoch 157, iter 2700, loss: 2.188424, top_1: 0.723594, top_k: 0.889766, samples/s: 3009.669 1612061416.0199857
train: epoch 157, iter 2800, loss: 2.340034, top_1: 0.721484, top_k: 0.892891, samples/s: 2936.743 1612061424.7370965
train: epoch 157, iter 2900, loss: 2.184458, top_1: 0.724258, top_k: 0.891602, samples/s: 3042.900 1612061433.1501207
train: epoch 157, iter 3000, loss: 2.087262, top_1: 0.724102, top_k: 0.892578, samples/s: 2967.772 1612061441.7765284
train: epoch 157, iter 3100, loss: 2.180947, top_1: 0.726367, top_k: 0.892656, samples/s: 2964.797 1612061450.4108
train: epoch 157, iter 3200, loss: 2.164287, top_1: 0.723828, top_k: 0.889414, samples/s: 3009.473 1612061458.917373
train: epoch 157, iter 3300, loss: 2.088152, top_1: 0.728008, top_k: 0.895117, samples/s: 2962.296 1612061467.5592558
train: epoch 157, iter 3400, loss: 2.105846, top_1: 0.721367, top_k: 0.890977, samples/s: 2888.267 1612061476.4226475
train: epoch 157, iter 3500, loss: 2.269857, top_1: 0.722305, top_k: 0.888906, samples/s: 2970.010 1612061485.0423784
train: epoch 157, iter 3600, loss: 2.219231, top_1: 0.723594, top_k: 0.894492, samples/s: 3000.417 1612061493.5742757
train: epoch 157, iter 3700, loss: 2.203204, top_1: 0.722891, top_k: 0.889102, samples/s: 2994.917 1612061502.122143
train: epoch 157, iter 3800, loss: 2.014844, top_1: 0.721758, top_k: 0.888867, samples/s: 2958.127 1612061510.7762275
train: epoch 157, iter 3900, loss: 2.320209, top_1: 0.720781, top_k: 0.889727, samples/s: 3004.103 1612061519.2978508
train: epoch 157, iter 4000, loss: 2.416002, top_1: 0.715898, top_k: 0.886914, samples/s: 2973.420 1612061527.9075332
train: epoch 157, iter 4100, loss: 2.138323, top_1: 0.723711, top_k: 0.891992, samples/s: 2936.781 1612061536.6245334
train: epoch 157, iter 4200, loss: 2.165604, top_1: 0.723711, top_k: 0.891797, samples/s: 2982.035 1612061545.2093053
train: epoch 157, iter 4300, loss: 2.070135, top_1: 0.723906, top_k: 0.892461, samples/s: 2957.411 1612061553.8654895
train: epoch 157, iter 4400, loss: 2.055194, top_1: 0.722773, top_k: 0.893984, samples/s: 2970.054 1612061562.4848967
train: epoch 157, iter 4500, loss: 2.140246, top_1: 0.726328, top_k: 0.891914, samples/s: 2989.729 1612061571.0475335
train: epoch 157, iter 4600, loss: 2.067067, top_1: 0.720234, top_k: 0.890508, samples/s: 2978.395 1612061579.6427515
train: epoch 157, iter 4700, loss: 2.306172, top_1: 0.718906, top_k: 0.890586, samples/s: 2993.347 1612061588.1951637
train: epoch 157, iter 4800, loss: 2.206239, top_1: 0.722461, top_k: 0.893320, samples/s: 2945.500 1612061596.8863535
train: epoch 157, iter 4900, loss: 2.024964, top_1: 0.726016, top_k: 0.892188, samples/s: 2935.182 1612061605.6080678
train: epoch 157, iter 5000, loss: 2.028902, top_1: 0.722578, top_k: 0.890742, samples/s: 2951.857 1612061614.2805476
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_157.
validation: epoch 157, iter 195, top_1: 0.726302, top_k: 0.909295, samples/s: 2864.020 1612061631.9117582
train: epoch 158, iter 100, loss: 2.143066, top_1: 0.725781, top_k: 0.891914, samples/s: 2926.631 1612061657.1247795
train: epoch 158, iter 200, loss: 2.088356, top_1: 0.725508, top_k: 0.890547, samples/s: 2964.718 1612061665.7595239
train: epoch 158, iter 300, loss: 2.043823, top_1: 0.728359, top_k: 0.889844, samples/s: 2998.704 1612061674.2965865
train: epoch 158, iter 400, loss: 2.155526, top_1: 0.723789, top_k: 0.890625, samples/s: 2939.502 1612061683.0060225
train: epoch 158, iter 500, loss: 2.174220, top_1: 0.721875, top_k: 0.890625, samples/s: 2897.532 1612061691.8406942
train: epoch 158, iter 600, loss: 2.329849, top_1: 0.724492, top_k: 0.893398, samples/s: 2998.368 1612061700.379216
train: epoch 158, iter 700, loss: 2.237028, top_1: 0.721172, top_k: 0.893320, samples/s: 2917.998 1612061709.1517622
train: epoch 158, iter 800, loss: 2.269716, top_1: 0.718125, top_k: 0.889219, samples/s: 2984.075 1612061717.7307177
train: epoch 158, iter 900, loss: 2.150370, top_1: 0.724219, top_k: 0.892070, samples/s: 2949.495 1612061726.4101093
train: epoch 158, iter 1000, loss: 2.221757, top_1: 0.721445, top_k: 0.889648, samples/s: 2992.163 1612061734.9657664
train: epoch 158, iter 1100, loss: 2.172714, top_1: 0.722812, top_k: 0.893125, samples/s: 2989.839 1612061743.5282564
train: epoch 158, iter 1200, loss: 2.054094, top_1: 0.726797, top_k: 0.895234, samples/s: 2970.837 1612061752.1452231
train: epoch 158, iter 1300, loss: 2.063386, top_1: 0.721211, top_k: 0.890352, samples/s: 2949.118 1612061760.8257613
train: epoch 158, iter 1400, loss: 2.018632, top_1: 0.718672, top_k: 0.892539, samples/s: 2956.771 1612061769.483901
train: epoch 158, iter 1500, loss: 2.327688, top_1: 0.726797, top_k: 0.894492, samples/s: 3024.017 1612061777.9495938
train: epoch 158, iter 1600, loss: 2.300486, top_1: 0.722344, top_k: 0.887148, samples/s: 2996.955 1612061786.4914446
train: epoch 158, iter 1700, loss: 2.222716, top_1: 0.721953, top_k: 0.892188, samples/s: 2921.979 1612061795.252711
train: epoch 158, iter 1800, loss: 2.144507, top_1: 0.722031, top_k: 0.889922, samples/s: 2973.379 1612061803.8623438
train: epoch 158, iter 1900, loss: 2.247034, top_1: 0.724531, top_k: 0.888984, samples/s: 2968.868 1612061812.4851007
train: epoch 158, iter 2000, loss: 2.220979, top_1: 0.725977, top_k: 0.886875, samples/s: 3003.138 1612061821.0096555
train: epoch 158, iter 2100, loss: 2.079428, top_1: 0.721875, top_k: 0.889219, samples/s: 2945.700 1612061829.700212
train: epoch 158, iter 2200, loss: 2.155185, top_1: 0.721289, top_k: 0.890078, samples/s: 2935.701 1612061838.42057
train: epoch 158, iter 2300, loss: 2.172438, top_1: 0.722539, top_k: 0.889609, samples/s: 3001.487 1612061846.9495778
train: epoch 158, iter 2400, loss: 2.246112, top_1: 0.725781, top_k: 0.893750, samples/s: 2944.549 1612061855.6435544
train: epoch 158, iter 2500, loss: 2.160519, top_1: 0.726836, top_k: 0.891289, samples/s: 2989.781 1612061864.2060897
train: epoch 158, iter 2600, loss: 2.234365, top_1: 0.721328, top_k: 0.890781, samples/s: 2954.679 1612061872.8703318
train: epoch 158, iter 2700, loss: 2.134015, top_1: 0.718477, top_k: 0.889336, samples/s: 2959.749 1612061881.5196836
train: epoch 158, iter 2800, loss: 2.235100, top_1: 0.723437, top_k: 0.894453, samples/s: 2991.454 1612061890.0773852
train: epoch 158, iter 2900, loss: 2.152072, top_1: 0.725234, top_k: 0.891406, samples/s: 2993.024 1612061898.6306047
train: epoch 158, iter 3000, loss: 2.207139, top_1: 0.727891, top_k: 0.894102, samples/s: 2918.244 1612061907.4030104
train: epoch 158, iter 3100, loss: 2.131217, top_1: 0.722969, top_k: 0.891055, samples/s: 2978.584 1612061915.9978015
train: epoch 158, iter 3200, loss: 2.135327, top_1: 0.726172, top_k: 0.893867, samples/s: 2952.935 1612061924.6670845
train: epoch 158, iter 3300, loss: 2.276377, top_1: 0.719961, top_k: 0.889023, samples/s: 3000.031 1612061933.200422
train: epoch 158, iter 3400, loss: 2.035206, top_1: 0.722617, top_k: 0.895742, samples/s: 2885.208 1612061942.073246
train: epoch 158, iter 3500, loss: 2.352510, top_1: 0.724922, top_k: 0.889531, samples/s: 2897.498 1612061950.908466
train: epoch 158, iter 3600, loss: 2.017953, top_1: 0.725547, top_k: 0.894062, samples/s: 2960.278 1612061959.5561812
train: epoch 158, iter 3700, loss: 2.230618, top_1: 0.719219, top_k: 0.890156, samples/s: 3011.589 1612061968.056705
train: epoch 158, iter 3800, loss: 2.040325, top_1: 0.723711, top_k: 0.890859, samples/s: 2927.018 1612061976.8028195
train: epoch 158, iter 3900, loss: 2.208163, top_1: 0.720586, top_k: 0.889844, samples/s: 2980.741 1612061985.391315
train: epoch 158, iter 4000, loss: 2.119993, top_1: 0.721836, top_k: 0.889883, samples/s: 2967.986 1612061994.0166929
train: epoch 158, iter 4100, loss: 2.133375, top_1: 0.720586, top_k: 0.890195, samples/s: 2957.550 1612062002.672421
train: epoch 158, iter 4200, loss: 2.128339, top_1: 0.721094, top_k: 0.888906, samples/s: 2997.778 1612062011.2122247
train: epoch 158, iter 4300, loss: 2.140276, top_1: 0.724102, top_k: 0.891172, samples/s: 2979.547 1612062019.8040092
train: epoch 158, iter 4400, loss: 2.226134, top_1: 0.725781, top_k: 0.893672, samples/s: 2944.705 1612062028.4975743
train: epoch 158, iter 4500, loss: 2.121482, top_1: 0.724063, top_k: 0.893516, samples/s: 2997.298 1612062037.0385845
train: epoch 158, iter 4600, loss: 2.125845, top_1: 0.725664, top_k: 0.893867, samples/s: 2966.785 1612062045.667504
train: epoch 158, iter 4700, loss: 2.007406, top_1: 0.720938, top_k: 0.889414, samples/s: 2991.631 1612062054.2246666
train: epoch 158, iter 4800, loss: 2.136542, top_1: 0.721094, top_k: 0.891914, samples/s: 3003.513 1612062062.747986
train: epoch 158, iter 4900, loss: 2.185917, top_1: 0.723828, top_k: 0.891055, samples/s: 2965.095 1612062071.3817995
train: epoch 158, iter 5000, loss: 2.296232, top_1: 0.721680, top_k: 0.890039, samples/s: 2944.238 1612062080.0767975
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_158.
validation: epoch 158, iter 195, top_1: 0.725661, top_k: 0.908854, samples/s: 3034.589 1612062096.8157408
train: epoch 159, iter 100, loss: 2.110624, top_1: 0.721211, top_k: 0.893828, samples/s: 2866.448 1612062121.6673338
train: epoch 159, iter 200, loss: 2.140559, top_1: 0.718359, top_k: 0.883320, samples/s: 2991.310 1612062130.225617
train: epoch 159, iter 300, loss: 2.164433, top_1: 0.722656, top_k: 0.890820, samples/s: 2999.939 1612062138.7589338
train: epoch 159, iter 400, loss: 2.186280, top_1: 0.722930, top_k: 0.891719, samples/s: 3005.340 1612062147.2772286
train: epoch 159, iter 500, loss: 2.098514, top_1: 0.722227, top_k: 0.892734, samples/s: 2995.973 1612062155.8219388
train: epoch 159, iter 600, loss: 2.235830, top_1: 0.721602, top_k: 0.892461, samples/s: 2988.466 1612062164.388218
train: epoch 159, iter 700, loss: 2.242661, top_1: 0.720352, top_k: 0.889375, samples/s: 3026.842 1612062172.845911
train: epoch 159, iter 800, loss: 2.190114, top_1: 0.725273, top_k: 0.892656, samples/s: 2928.373 1612062181.5879424
train: epoch 159, iter 900, loss: 2.310981, top_1: 0.727187, top_k: 0.891797, samples/s: 3008.196 1612062190.0980783
train: epoch 159, iter 1000, loss: 2.074646, top_1: 0.721367, top_k: 0.890742, samples/s: 2999.446 1612062198.632909
train: epoch 159, iter 1100, loss: 2.114857, top_1: 0.722891, top_k: 0.893086, samples/s: 2989.782 1612062207.1954877
train: epoch 159, iter 1200, loss: 2.130899, top_1: 0.724492, top_k: 0.890117, samples/s: 2940.985 1612062215.9000058
train: epoch 159, iter 1300, loss: 2.114430, top_1: 0.722500, top_k: 0.893359, samples/s: 2921.265 1612062224.664125
train: epoch 159, iter 1400, loss: 2.163152, top_1: 0.720977, top_k: 0.891094, samples/s: 2997.098 1612062233.2049265
train: epoch 159, iter 1500, loss: 2.124235, top_1: 0.723789, top_k: 0.892266, samples/s: 2966.587 1612062241.835663
train: epoch 159, iter 1600, loss: 2.296210, top_1: 0.723242, top_k: 0.890781, samples/s: 2972.436 1612062250.446813
train: epoch 159, iter 1700, loss: 2.095379, top_1: 0.727422, top_k: 0.889453, samples/s: 2998.394 1612062258.9847157
train: epoch 159, iter 1800, loss: 2.061760, top_1: 0.722344, top_k: 0.889258, samples/s: 3003.585 1612062267.5078695
train: epoch 159, iter 1900, loss: 2.280787, top_1: 0.724883, top_k: 0.891016, samples/s: 2945.693 1612062276.1985383
train: epoch 159, iter 2000, loss: 2.288765, top_1: 0.718516, top_k: 0.889531, samples/s: 2991.821 1612062284.7551334
train: epoch 159, iter 2100, loss: 2.204793, top_1: 0.730234, top_k: 0.894609, samples/s: 2998.304 1612062293.2933671
train: epoch 159, iter 2200, loss: 2.257988, top_1: 0.720625, top_k: 0.892227, samples/s: 2994.695 1612062301.8417888
train: epoch 159, iter 2300, loss: 2.183548, top_1: 0.724258, top_k: 0.889609, samples/s: 2953.858 1612062310.5084393
train: epoch 159, iter 2400, loss: 2.320118, top_1: 0.720781, top_k: 0.890234, samples/s: 2944.200 1612062319.2035587
train: epoch 159, iter 2500, loss: 2.119325, top_1: 0.721875, top_k: 0.892188, samples/s: 3010.894 1612062327.705981
train: epoch 159, iter 2600, loss: 2.119205, top_1: 0.718789, top_k: 0.889609, samples/s: 2997.522 1612062336.2463577
train: epoch 159, iter 2700, loss: 2.202926, top_1: 0.720703, top_k: 0.889062, samples/s: 2912.603 1612062345.0357819
train: epoch 159, iter 2800, loss: 2.262134, top_1: 0.723086, top_k: 0.892617, samples/s: 2970.909 1612062353.6526868
train: epoch 159, iter 2900, loss: 2.153080, top_1: 0.726055, top_k: 0.892656, samples/s: 2951.478 1612062362.3262413
train: epoch 159, iter 3000, loss: 2.209731, top_1: 0.725313, top_k: 0.890508, samples/s: 2957.111 1612062370.9833388
train: epoch 159, iter 3100, loss: 2.294327, top_1: 0.725586, top_k: 0.891953, samples/s: 2963.386 1612062379.6220498
train: epoch 159, iter 3200, loss: 2.061645, top_1: 0.721875, top_k: 0.891016, samples/s: 2969.451 1612062388.243311
train: epoch 159, iter 3300, loss: 2.110599, top_1: 0.724336, top_k: 0.888711, samples/s: 2946.731 1612062396.930819
train: epoch 159, iter 3400, loss: 2.080848, top_1: 0.726602, top_k: 0.893086, samples/s: 3001.239 1612062405.460677
train: epoch 159, iter 3500, loss: 2.073076, top_1: 0.726914, top_k: 0.893672, samples/s: 2992.768 1612062414.014618
train: epoch 159, iter 3600, loss: 2.232252, top_1: 0.723164, top_k: 0.891719, samples/s: 2969.333 1612062422.6360915
train: epoch 159, iter 3700, loss: 2.223528, top_1: 0.723477, top_k: 0.890117, samples/s: 2956.729 1612062431.2942638
train: epoch 159, iter 3800, loss: 2.143508, top_1: 0.720820, top_k: 0.889336, samples/s: 2953.707 1612062439.9613602
train: epoch 159, iter 3900, loss: 2.048700, top_1: 0.718398, top_k: 0.890625, samples/s: 2933.461 1612062448.6882443
train: epoch 159, iter 4000, loss: 2.283140, top_1: 0.719258, top_k: 0.892070, samples/s: 2970.364 1612062457.3067377
train: epoch 159, iter 4100, loss: 2.223277, top_1: 0.725898, top_k: 0.893516, samples/s: 2962.653 1612062465.9476416
train: epoch 159, iter 4200, loss: 2.173212, top_1: 0.717852, top_k: 0.890508, samples/s: 2996.665 1612062474.4905224
train: epoch 159, iter 4300, loss: 2.056038, top_1: 0.720664, top_k: 0.886523, samples/s: 2948.289 1612062483.1733992
train: epoch 159, iter 4400, loss: 2.204631, top_1: 0.724648, top_k: 0.892617, samples/s: 3007.007 1612062491.686899
train: epoch 159, iter 4500, loss: 2.111986, top_1: 0.722383, top_k: 0.890703, samples/s: 2940.984 1612062500.3914926
train: epoch 159, iter 4600, loss: 2.106708, top_1: 0.723320, top_k: 0.891875, samples/s: 2944.195 1612062509.0865502
train: epoch 159, iter 4700, loss: 2.117685, top_1: 0.718945, top_k: 0.890352, samples/s: 2983.652 1612062517.6666489
train: epoch 159, iter 4800, loss: 2.307483, top_1: 0.720234, top_k: 0.891445, samples/s: 2999.030 1612062526.2028112
train: epoch 159, iter 4900, loss: 2.014089, top_1: 0.724805, top_k: 0.893320, samples/s: 2942.958 1612062534.9014528
train: epoch 159, iter 5000, loss: 2.241309, top_1: 0.724219, top_k: 0.892383, samples/s: 2965.170 1612062543.5350504
Saving model to ./output/snapshots/model_save-20210130142727/snapshot_epoch_159.
validation: epoch 159, iter 195, top_1: 0.726022, top_k: 0.909235, samples/s: 2960.833 1612062560.610115
