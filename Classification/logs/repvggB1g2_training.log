==================================================================
Running repvggB1g2: num_gpu_per_node = 4, num_nodes = 1.
==================================================================
dtype = float32
gpu_num_per_node = 4
num_nodes = 1
node_ips = ['192.168.1.13', '192.168.1.14']
ctrl_port = 50051
model = repvggB1g2
mixup = False
use_fp16 = None
use_xla = None
channel_last = False
pad_output = None
num_epochs = 160
model_load_dir = None
batch_size_per_device = 64
val_batch_size_per_device = 64
nccl_fusion_threshold_mb = 16
nccl_fusion_max_ops = 24
fuse_bn_relu = True
fuse_bn_add_relu = True
gpu_image_decoder = True
image_path = test_img/tiger.jpg
num_classes = 1000
num_examples = 1281167
num_val_examples = 50000
rgb_mean = [123.68, 116.779, 103.939]
rgb_std = [58.393, 57.12, 57.375]
image_shape = [3, 224, 224]
label_smoothing = 0.1
model_save_dir = ./repvggB1g2/snapshots/model_save/
log_dir = ./output
loss_print_every_n_iter = 100
image_size = 224
resize_shorter = 256
train_data_dir = /DATA/disk1/ImageNet/ofrecord/train
train_data_part_num = 256
val_data_dir = /DATA/disk1/ImageNet/ofrecord/validation
val_data_part_num = 256
optimizer = sgd
learning_rate = 0.1
wd = 3.0517578125e-05
momentum = 0.9
lr_decay = cosine
lr_decay_rate = 0.94
lr_decay_epochs = 2
warmup_epochs = 5
decay_rate = 0.9
epsilon = 1.0
gradient_clipping = 0.0
------------------------------------------------------------------
Time stamp: 2021-02-13-19:18:57
!!!!!===!!!! ./repvggB1g2/snapshots/model_save/
[1mWARNING: 'flow.train.CheckPoint' is deprecated. Please use the new API:[0m
flow.train.CheckPoint().save(path) => [1m[92mflow.checkpoint.save(path)[0m
flow.train.CheckPoint().load(path) => [1m[92mflow.load_variables(flow.checkpoint.get(path))[0m
flow.train.CheckPoint().init() is not needed any more.

Loading data from /DATA/disk1/ImageNet/ofrecord/train
No MixUp
Here is RepVGG B1G2
loss.shape (1,)
predictions:  (256, 1000)
Optimizer:  SGD
Loading data from /DATA/disk1/ImageNet/ofrecord/validation
Here is RepVGG B1G2
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_initial_model.
Init model on demand.
train: epoch 0, iter 100, loss: 6.852528, top_1: 0.002539, top_k: 0.010156, samples/s: 798.033 1613215321.8296692
train: epoch 0, iter 200, loss: 6.786531, top_1: 0.004844, top_k: 0.018711, samples/s: 796.729 1613215353.9608445
train: epoch 0, iter 300, loss: 6.660310, top_1: 0.006641, top_k: 0.026758, samples/s: 805.118 1613215385.7574108
train: epoch 0, iter 400, loss: 6.515892, top_1: 0.008672, top_k: 0.034766, samples/s: 803.236 1613215417.628485
train: epoch 0, iter 500, loss: 6.441515, top_1: 0.011719, top_k: 0.043633, samples/s: 804.197 1613215449.4614913
train: epoch 0, iter 600, loss: 6.431040, top_1: 0.014375, top_k: 0.052305, samples/s: 804.163 1613215481.2958133
train: epoch 0, iter 700, loss: 6.339745, top_1: 0.017891, top_k: 0.061914, samples/s: 802.562 1613215513.1936998
train: epoch 0, iter 800, loss: 6.350578, top_1: 0.019414, top_k: 0.070234, samples/s: 795.275 1613215545.3838038
train: epoch 0, iter 900, loss: 6.219349, top_1: 0.024258, top_k: 0.079570, samples/s: 790.438 1613215577.770865
train: epoch 0, iter 1000, loss: 6.131949, top_1: 0.026250, top_k: 0.088438, samples/s: 789.225 1613215610.2077575
train: epoch 0, iter 1100, loss: 6.123019, top_1: 0.031406, top_k: 0.104063, samples/s: 788.931 1613215642.6567626
train: epoch 0, iter 1200, loss: 6.094867, top_1: 0.034102, top_k: 0.110117, samples/s: 787.074 1613215675.1823747
train: epoch 0, iter 1300, loss: 5.853143, top_1: 0.038398, top_k: 0.121289, samples/s: 785.195 1613215707.7861447
train: epoch 0, iter 1400, loss: 5.774244, top_1: 0.040313, top_k: 0.127461, samples/s: 785.765 1613215740.3653839
train: epoch 0, iter 1500, loss: 5.952795, top_1: 0.044922, top_k: 0.139648, samples/s: 783.073 1613215773.0570998
train: epoch 0, iter 1600, loss: 5.797766, top_1: 0.051914, top_k: 0.156289, samples/s: 781.411 1613215805.818406
train: epoch 0, iter 1700, loss: 5.637420, top_1: 0.057070, top_k: 0.165977, samples/s: 783.247 1613215838.5027776
train: epoch 0, iter 1800, loss: 5.627373, top_1: 0.056211, top_k: 0.170508, samples/s: 782.492 1613215871.218763
train: epoch 0, iter 1900, loss: 5.689647, top_1: 0.064648, top_k: 0.184766, samples/s: 780.058 1613215904.036844
train: epoch 0, iter 2000, loss: 5.446277, top_1: 0.069219, top_k: 0.192188, samples/s: 784.373 1613215936.6744602
train: epoch 0, iter 2100, loss: 5.692895, top_1: 0.072734, top_k: 0.199922, samples/s: 780.265 1613215969.4838011
train: epoch 0, iter 2200, loss: 5.451453, top_1: 0.078008, top_k: 0.211133, samples/s: 781.462 1613216002.2428741
train: epoch 0, iter 2300, loss: 5.507584, top_1: 0.084062, top_k: 0.223750, samples/s: 782.443 1613216034.9609492
train: epoch 0, iter 2400, loss: 5.367463, top_1: 0.084961, top_k: 0.229141, samples/s: 777.644 1613216067.8809104
train: epoch 0, iter 2500, loss: 5.561607, top_1: 0.089492, top_k: 0.238125, samples/s: 781.821 1613216100.6249995
train: epoch 0, iter 2600, loss: 5.172533, top_1: 0.092969, top_k: 0.248594, samples/s: 778.001 1613216133.5298216
train: epoch 0, iter 2700, loss: 5.232003, top_1: 0.099219, top_k: 0.252109, samples/s: 780.437 1613216166.331959
train: epoch 0, iter 2800, loss: 5.262254, top_1: 0.108281, top_k: 0.269688, samples/s: 779.140 1613216199.1886759
train: epoch 0, iter 2900, loss: 5.179875, top_1: 0.112227, top_k: 0.276953, samples/s: 781.274 1613216231.955675
train: epoch 0, iter 3000, loss: 5.231276, top_1: 0.112539, top_k: 0.283359, samples/s: 779.336 1613216264.804136
train: epoch 0, iter 3100, loss: 4.937963, top_1: 0.119844, top_k: 0.295820, samples/s: 775.736 1613216297.805086
train: epoch 0, iter 3200, loss: 5.253164, top_1: 0.119844, top_k: 0.293984, samples/s: 780.522 1613216330.6036015
train: epoch 0, iter 3300, loss: 5.048674, top_1: 0.128750, top_k: 0.306758, samples/s: 781.338 1613216363.367874
train: epoch 0, iter 3400, loss: 5.069278, top_1: 0.131836, top_k: 0.314453, samples/s: 777.791 1613216396.281643
train: epoch 0, iter 3500, loss: 5.102909, top_1: 0.132109, top_k: 0.317773, samples/s: 780.300 1613216429.0894876
train: epoch 0, iter 3600, loss: 5.109620, top_1: 0.140508, top_k: 0.323047, samples/s: 778.301 1613216461.9816244
train: epoch 0, iter 3700, loss: 4.953816, top_1: 0.146992, top_k: 0.335508, samples/s: 777.713 1613216494.898739
train: epoch 0, iter 3800, loss: 4.889843, top_1: 0.148555, top_k: 0.345078, samples/s: 776.037 1613216527.8867593
train: epoch 0, iter 3900, loss: 4.915888, top_1: 0.152070, top_k: 0.349844, samples/s: 778.166 1613216560.784732
train: epoch 0, iter 4000, loss: 4.864665, top_1: 0.163164, top_k: 0.360742, samples/s: 779.154 1613216593.640816
train: epoch 0, iter 4100, loss: 4.834824, top_1: 0.163711, top_k: 0.366328, samples/s: 775.989 1613216626.6310182
train: epoch 0, iter 4200, loss: 4.699677, top_1: 0.165430, top_k: 0.364766, samples/s: 782.153 1613216659.3611383
train: epoch 0, iter 4300, loss: 4.792021, top_1: 0.168164, top_k: 0.372578, samples/s: 778.040 1613216692.2643335
train: epoch 0, iter 4400, loss: 4.675130, top_1: 0.171836, top_k: 0.381563, samples/s: 776.705 1613216725.2241573
train: epoch 0, iter 4500, loss: 4.772642, top_1: 0.177930, top_k: 0.388633, samples/s: 775.843 1613216758.22046
train: epoch 0, iter 4600, loss: 4.675025, top_1: 0.185039, top_k: 0.395977, samples/s: 781.714 1613216790.9690564
train: epoch 0, iter 4700, loss: 4.604799, top_1: 0.185273, top_k: 0.398789, samples/s: 777.650 1613216823.8887446
train: epoch 0, iter 4800, loss: 4.575721, top_1: 0.190781, top_k: 0.400859, samples/s: 777.464 1613216856.8162313
train: epoch 0, iter 4900, loss: 4.553926, top_1: 0.192852, top_k: 0.407500, samples/s: 779.646 1613216889.6517313
train: epoch 0, iter 5000, loss: 4.763819, top_1: 0.194453, top_k: 0.412227, samples/s: 780.104 1613216922.4678159
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_0.
validation: epoch 0, iter 195, top_1: 0.211358, top_k: 0.441326, samples/s: 2344.629 1613216944.7246351
train: epoch 1, iter 100, loss: 4.569464, top_1: 0.198594, top_k: 0.422148, samples/s: 804.011 1613216997.4353132
train: epoch 1, iter 200, loss: 4.547972, top_1: 0.206094, top_k: 0.428125, samples/s: 799.031 1613217029.4742188
train: epoch 1, iter 300, loss: 4.424494, top_1: 0.209102, top_k: 0.433789, samples/s: 779.342 1613217062.3223274
train: epoch 1, iter 400, loss: 4.530406, top_1: 0.215273, top_k: 0.438281, samples/s: 778.133 1613217095.221522
train: epoch 1, iter 500, loss: 4.447841, top_1: 0.215000, top_k: 0.442461, samples/s: 778.138 1613217128.1206095
train: epoch 1, iter 600, loss: 4.474016, top_1: 0.223750, top_k: 0.444805, samples/s: 778.079 1613217161.0221763
train: epoch 1, iter 700, loss: 4.517753, top_1: 0.224375, top_k: 0.452344, samples/s: 780.515 1613217193.8210967
train: epoch 1, iter 800, loss: 4.420401, top_1: 0.221758, top_k: 0.448828, samples/s: 777.459 1613217226.7487915
train: epoch 1, iter 900, loss: 4.606910, top_1: 0.223398, top_k: 0.450625, samples/s: 779.213 1613217259.6024356
train: epoch 1, iter 1000, loss: 4.457203, top_1: 0.230664, top_k: 0.460000, samples/s: 776.966 1613217292.5512297
train: epoch 1, iter 1100, loss: 4.446429, top_1: 0.231758, top_k: 0.466172, samples/s: 777.750 1613217325.4667099
train: epoch 1, iter 1200, loss: 4.468633, top_1: 0.239492, top_k: 0.473125, samples/s: 778.995 1613217358.3295133
train: epoch 1, iter 1300, loss: 4.426068, top_1: 0.234805, top_k: 0.466133, samples/s: 777.618 1613217391.2505155
train: epoch 1, iter 1400, loss: 4.182676, top_1: 0.240977, top_k: 0.477539, samples/s: 777.429 1613217424.1796534
train: epoch 1, iter 1500, loss: 4.288938, top_1: 0.248477, top_k: 0.484570, samples/s: 781.098 1613217456.9539518
train: epoch 1, iter 1600, loss: 4.276476, top_1: 0.243516, top_k: 0.482031, samples/s: 779.551 1613217489.7933855
train: epoch 1, iter 1700, loss: 4.246584, top_1: 0.256328, top_k: 0.489883, samples/s: 772.263 1613217522.942798
train: epoch 1, iter 1800, loss: 4.392809, top_1: 0.248086, top_k: 0.487148, samples/s: 783.529 1613217555.6154177
train: epoch 1, iter 1900, loss: 4.131628, top_1: 0.257344, top_k: 0.490117, samples/s: 779.549 1613217588.4548998
train: epoch 1, iter 2000, loss: 4.132904, top_1: 0.257734, top_k: 0.492500, samples/s: 779.093 1613217621.313693
train: epoch 1, iter 2100, loss: 4.191879, top_1: 0.259219, top_k: 0.499844, samples/s: 780.351 1613217654.1194122
train: epoch 1, iter 2200, loss: 4.275002, top_1: 0.265352, top_k: 0.501641, samples/s: 779.422 1613217686.964249
train: epoch 1, iter 2300, loss: 4.204602, top_1: 0.267031, top_k: 0.506172, samples/s: 781.006 1613217719.7425065
train: epoch 1, iter 2400, loss: 4.331069, top_1: 0.273086, top_k: 0.512578, samples/s: 780.831 1613217752.5280159
train: epoch 1, iter 2500, loss: 4.407368, top_1: 0.267891, top_k: 0.508867, samples/s: 778.011 1613217785.4324472
train: epoch 1, iter 2600, loss: 4.298856, top_1: 0.270625, top_k: 0.513984, samples/s: 779.657 1613217818.2674215
train: epoch 1, iter 2700, loss: 4.117003, top_1: 0.275625, top_k: 0.514492, samples/s: 780.390 1613217851.0715177
train: epoch 1, iter 2800, loss: 4.206752, top_1: 0.272500, top_k: 0.517266, samples/s: 778.055 1613217883.9741642
train: epoch 1, iter 2900, loss: 4.092235, top_1: 0.281875, top_k: 0.519531, samples/s: 782.689 1613217916.6818237
train: epoch 1, iter 3000, loss: 4.010581, top_1: 0.283398, top_k: 0.525586, samples/s: 776.588 1613217949.6465101
train: epoch 1, iter 3100, loss: 4.027139, top_1: 0.282109, top_k: 0.532656, samples/s: 779.666 1613217982.481163
train: epoch 1, iter 3200, loss: 4.106081, top_1: 0.282813, top_k: 0.526836, samples/s: 777.308 1613218015.4153862
train: epoch 1, iter 3300, loss: 3.897235, top_1: 0.281445, top_k: 0.524492, samples/s: 778.891 1613218048.2826107
train: epoch 1, iter 3400, loss: 4.239084, top_1: 0.290547, top_k: 0.535312, samples/s: 779.831 1613218081.1102517
train: epoch 1, iter 3500, loss: 4.227312, top_1: 0.293945, top_k: 0.544297, samples/s: 780.529 1613218113.908447
train: epoch 1, iter 3600, loss: 4.102925, top_1: 0.292578, top_k: 0.541367, samples/s: 779.826 1613218146.7362444
train: epoch 1, iter 3700, loss: 4.039105, top_1: 0.296641, top_k: 0.545703, samples/s: 780.466 1613218179.5372076
train: epoch 1, iter 3800, loss: 4.123811, top_1: 0.297578, top_k: 0.546836, samples/s: 780.512 1613218212.3361905
train: epoch 1, iter 3900, loss: 3.984760, top_1: 0.298086, top_k: 0.544219, samples/s: 777.680 1613218245.2545464
train: epoch 1, iter 4000, loss: 4.152193, top_1: 0.301289, top_k: 0.548164, samples/s: 779.936 1613218278.07782
train: epoch 1, iter 4100, loss: 4.049592, top_1: 0.305430, top_k: 0.552891, samples/s: 779.662 1613218310.9125068
train: epoch 1, iter 4200, loss: 3.990757, top_1: 0.300820, top_k: 0.547891, samples/s: 780.966 1613218343.6924047
train: epoch 1, iter 4300, loss: 3.846141, top_1: 0.303633, top_k: 0.553516, samples/s: 777.559 1613218376.6159441
train: epoch 1, iter 4400, loss: 4.155744, top_1: 0.309492, top_k: 0.555547, samples/s: 780.408 1613218409.4194045
train: epoch 1, iter 4500, loss: 4.273843, top_1: 0.310469, top_k: 0.560234, samples/s: 777.505 1613218442.3450928
train: epoch 1, iter 4600, loss: 4.141293, top_1: 0.310820, top_k: 0.560078, samples/s: 779.433 1613218475.1894994
train: epoch 1, iter 4700, loss: 4.218983, top_1: 0.310625, top_k: 0.562422, samples/s: 780.374 1613218507.9943247
train: epoch 1, iter 4800, loss: 4.072902, top_1: 0.317188, top_k: 0.566523, samples/s: 781.125 1613218540.7675278
train: epoch 1, iter 4900, loss: 3.901499, top_1: 0.315586, top_k: 0.562734, samples/s: 779.762 1613218573.598082
train: epoch 1, iter 5000, loss: 4.141927, top_1: 0.317383, top_k: 0.566758, samples/s: 780.479 1613218606.3984537
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_1.
validation: epoch 1, iter 195, top_1: 0.358233, top_k: 0.623818, samples/s: 2341.431 1613218628.8001406
train: epoch 2, iter 100, loss: 3.879108, top_1: 0.330977, top_k: 0.578828, samples/s: 803.626 1613218681.7185907
train: epoch 2, iter 200, loss: 3.842040, top_1: 0.328633, top_k: 0.579063, samples/s: 796.848 1613218713.8449984
train: epoch 2, iter 300, loss: 3.812791, top_1: 0.329844, top_k: 0.580195, samples/s: 781.106 1613218746.6191475
train: epoch 2, iter 400, loss: 3.937889, top_1: 0.330234, top_k: 0.583750, samples/s: 778.890 1613218779.486371
train: epoch 2, iter 500, loss: 3.777641, top_1: 0.331016, top_k: 0.581836, samples/s: 779.845 1613218812.3134615
train: epoch 2, iter 600, loss: 3.910668, top_1: 0.328711, top_k: 0.580937, samples/s: 776.447 1613218845.2841167
train: epoch 2, iter 700, loss: 4.011437, top_1: 0.334258, top_k: 0.585547, samples/s: 776.264 1613218878.2626212
train: epoch 2, iter 800, loss: 3.777225, top_1: 0.332422, top_k: 0.589063, samples/s: 779.611 1613218911.0995522
train: epoch 2, iter 900, loss: 4.102960, top_1: 0.333320, top_k: 0.583086, samples/s: 777.559 1613218944.0229976
train: epoch 2, iter 1000, loss: 3.945928, top_1: 0.335938, top_k: 0.591328, samples/s: 778.223 1613218976.9185166
train: epoch 2, iter 1100, loss: 3.705916, top_1: 0.340898, top_k: 0.591055, samples/s: 777.399 1613219009.8487742
train: epoch 2, iter 1200, loss: 3.979371, top_1: 0.337656, top_k: 0.589609, samples/s: 776.597 1613219042.8131106
train: epoch 2, iter 1300, loss: 3.912508, top_1: 0.336602, top_k: 0.595352, samples/s: 781.900 1613219075.5538929
train: epoch 2, iter 1400, loss: 3.764074, top_1: 0.342344, top_k: 0.591445, samples/s: 777.315 1613219108.4877164
train: epoch 2, iter 1500, loss: 3.927162, top_1: 0.344531, top_k: 0.592422, samples/s: 776.936 1613219141.4376595
train: epoch 2, iter 1600, loss: 3.840188, top_1: 0.342461, top_k: 0.595742, samples/s: 780.750 1613219174.2267048
train: epoch 2, iter 1700, loss: 3.849725, top_1: 0.348242, top_k: 0.597891, samples/s: 776.538 1613219207.1935298
train: epoch 2, iter 1800, loss: 3.573429, top_1: 0.346211, top_k: 0.599805, samples/s: 780.467 1613219239.9944007
train: epoch 2, iter 1900, loss: 3.626723, top_1: 0.347187, top_k: 0.595977, samples/s: 775.879 1613219272.989202
train: epoch 2, iter 2000, loss: 3.983592, top_1: 0.352852, top_k: 0.605117, samples/s: 776.384 1613219305.9625883
train: epoch 2, iter 2100, loss: 3.962948, top_1: 0.350313, top_k: 0.604844, samples/s: 782.115 1613219338.694374
train: epoch 2, iter 2200, loss: 4.046597, top_1: 0.355352, top_k: 0.606016, samples/s: 777.386 1613219371.6251535
train: epoch 2, iter 2300, loss: 3.887206, top_1: 0.351836, top_k: 0.603672, samples/s: 779.380 1613219404.4717786
train: epoch 2, iter 2400, loss: 3.825545, top_1: 0.355039, top_k: 0.612187, samples/s: 777.643 1613219437.3917658
train: epoch 2, iter 2500, loss: 3.758662, top_1: 0.351797, top_k: 0.601445, samples/s: 778.728 1613219470.2659328
train: epoch 2, iter 2600, loss: 3.866046, top_1: 0.360312, top_k: 0.604922, samples/s: 779.225 1613219503.11911
train: epoch 2, iter 2700, loss: 3.920860, top_1: 0.361719, top_k: 0.609531, samples/s: 778.098 1613219536.019838
train: epoch 2, iter 2800, loss: 3.616024, top_1: 0.359570, top_k: 0.616016, samples/s: 779.353 1613219568.867506
train: epoch 2, iter 2900, loss: 3.654946, top_1: 0.366719, top_k: 0.615703, samples/s: 778.759 1613219601.740425
train: epoch 2, iter 3000, loss: 3.777712, top_1: 0.363867, top_k: 0.614961, samples/s: 780.334 1613219634.5467942
train: epoch 2, iter 3100, loss: 3.650630, top_1: 0.361719, top_k: 0.614570, samples/s: 776.785 1613219667.5032423
train: epoch 2, iter 3200, loss: 3.694937, top_1: 0.365430, top_k: 0.615977, samples/s: 780.884 1613219700.2866018
train: epoch 2, iter 3300, loss: 3.707779, top_1: 0.363828, top_k: 0.618008, samples/s: 777.568 1613219733.2096682
train: epoch 2, iter 3400, loss: 3.685037, top_1: 0.367695, top_k: 0.622109, samples/s: 778.900 1613219766.076649
train: epoch 2, iter 3500, loss: 3.727163, top_1: 0.366211, top_k: 0.615078, samples/s: 782.479 1613219798.793073
train: epoch 2, iter 3600, loss: 3.360094, top_1: 0.369648, top_k: 0.621055, samples/s: 777.608 1613219831.7146754
train: epoch 2, iter 3700, loss: 3.756793, top_1: 0.374102, top_k: 0.626914, samples/s: 776.755 1613219864.6722116
train: epoch 2, iter 3800, loss: 3.859914, top_1: 0.365195, top_k: 0.622539, samples/s: 780.295 1613219897.4804
train: epoch 2, iter 3900, loss: 3.629556, top_1: 0.370781, top_k: 0.624687, samples/s: 782.891 1613219930.1796882
train: epoch 2, iter 4000, loss: 3.582562, top_1: 0.375195, top_k: 0.629727, samples/s: 777.399 1613219963.109955
train: epoch 2, iter 4100, loss: 3.834238, top_1: 0.371406, top_k: 0.625820, samples/s: 775.447 1613219996.123163
train: epoch 2, iter 4200, loss: 3.737410, top_1: 0.374297, top_k: 0.627969, samples/s: 778.919 1613220028.9892118
train: epoch 2, iter 4300, loss: 3.526999, top_1: 0.375039, top_k: 0.626367, samples/s: 781.013 1613220061.7672675
train: epoch 2, iter 4400, loss: 3.714592, top_1: 0.374336, top_k: 0.626484, samples/s: 777.463 1613220094.6948137
train: epoch 2, iter 4500, loss: 3.671695, top_1: 0.377695, top_k: 0.627500, samples/s: 780.862 1613220127.4790936
train: epoch 2, iter 4600, loss: 3.760437, top_1: 0.383086, top_k: 0.637461, samples/s: 780.469 1613220160.2798471
train: epoch 2, iter 4700, loss: 3.649850, top_1: 0.377383, top_k: 0.631602, samples/s: 781.860 1613220193.0222464
train: epoch 2, iter 4800, loss: 3.855914, top_1: 0.380977, top_k: 0.633945, samples/s: 777.661 1613220225.9415872
train: epoch 2, iter 4900, loss: 3.703307, top_1: 0.381367, top_k: 0.636953, samples/s: 777.967 1613220258.847818
train: epoch 2, iter 5000, loss: 3.578972, top_1: 0.383828, top_k: 0.632383, samples/s: 781.009 1613220291.6260011
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_2.
validation: epoch 2, iter 195, top_1: 0.436779, top_k: 0.700982, samples/s: 2370.590 1613220313.6663187
train: epoch 3, iter 100, loss: 3.510657, top_1: 0.396133, top_k: 0.645312, samples/s: 803.310 1613220366.3224788
train: epoch 3, iter 200, loss: 3.833737, top_1: 0.384688, top_k: 0.640664, samples/s: 796.771 1613220398.4523628
train: epoch 3, iter 300, loss: 3.735352, top_1: 0.395117, top_k: 0.651563, samples/s: 779.256 1613220431.303965
train: epoch 3, iter 400, loss: 3.561933, top_1: 0.393516, top_k: 0.647930, samples/s: 776.858 1613220464.2573137
train: epoch 3, iter 500, loss: 3.485991, top_1: 0.390937, top_k: 0.642891, samples/s: 778.046 1613220497.160302
train: epoch 3, iter 600, loss: 3.806857, top_1: 0.395469, top_k: 0.650820, samples/s: 774.438 1613220530.2164295
train: epoch 3, iter 700, loss: 3.663966, top_1: 0.386094, top_k: 0.644844, samples/s: 779.216 1613220563.069944
train: epoch 3, iter 800, loss: 3.523746, top_1: 0.395234, top_k: 0.646445, samples/s: 775.214 1613220596.093116
train: epoch 3, iter 900, loss: 3.569452, top_1: 0.390078, top_k: 0.645234, samples/s: 779.428 1613220628.9377759
train: epoch 3, iter 1000, loss: 3.420522, top_1: 0.398008, top_k: 0.649609, samples/s: 777.325 1613220661.8712578
train: epoch 3, iter 1100, loss: 3.515915, top_1: 0.395625, top_k: 0.642891, samples/s: 780.123 1613220694.6866071
train: epoch 3, iter 1200, loss: 3.548850, top_1: 0.397070, top_k: 0.649531, samples/s: 776.426 1613220727.6581173
train: epoch 3, iter 1300, loss: 3.448434, top_1: 0.395742, top_k: 0.648711, samples/s: 777.281 1613220760.5935762
train: epoch 3, iter 1400, loss: 3.299804, top_1: 0.399687, top_k: 0.650234, samples/s: 778.050 1613220793.4962478
train: epoch 3, iter 1500, loss: 3.514974, top_1: 0.393320, top_k: 0.646719, samples/s: 780.688 1613220826.2878056
train: epoch 3, iter 1600, loss: 3.546969, top_1: 0.398867, top_k: 0.647344, samples/s: 777.528 1613220859.2127147
train: epoch 3, iter 1700, loss: 3.284516, top_1: 0.399766, top_k: 0.651758, samples/s: 778.463 1613220892.0979607
train: epoch 3, iter 1800, loss: 3.486619, top_1: 0.402773, top_k: 0.647344, samples/s: 779.621 1613220924.9345126
train: epoch 3, iter 1900, loss: 3.710227, top_1: 0.400508, top_k: 0.652656, samples/s: 777.428 1613220957.8635073
train: epoch 3, iter 2000, loss: 3.566690, top_1: 0.399414, top_k: 0.649375, samples/s: 780.690 1613220990.6550639
train: epoch 3, iter 2100, loss: 3.617978, top_1: 0.405977, top_k: 0.653945, samples/s: 775.564 1613221023.6632931
train: epoch 3, iter 2200, loss: 3.544548, top_1: 0.406562, top_k: 0.657383, samples/s: 781.097 1613221056.437806
train: epoch 3, iter 2300, loss: 3.592179, top_1: 0.406406, top_k: 0.658398, samples/s: 775.477 1613221089.4497108
train: epoch 3, iter 2400, loss: 3.414955, top_1: 0.403906, top_k: 0.658047, samples/s: 778.524 1613221122.3324337
train: epoch 3, iter 2500, loss: 3.583477, top_1: 0.402500, top_k: 0.655781, samples/s: 780.505 1613221155.131713
train: epoch 3, iter 2600, loss: 3.675444, top_1: 0.402344, top_k: 0.655820, samples/s: 778.137 1613221188.030797
train: epoch 3, iter 2700, loss: 3.477843, top_1: 0.404141, top_k: 0.656133, samples/s: 779.296 1613221220.880983
train: epoch 3, iter 2800, loss: 3.427462, top_1: 0.407305, top_k: 0.659687, samples/s: 781.383 1613221253.6433885
train: epoch 3, iter 2900, loss: 3.613356, top_1: 0.413633, top_k: 0.661797, samples/s: 780.835 1613221286.4288616
train: epoch 3, iter 3000, loss: 3.359910, top_1: 0.406562, top_k: 0.656719, samples/s: 777.942 1613221319.3361626
train: epoch 3, iter 3100, loss: 3.402828, top_1: 0.407734, top_k: 0.656797, samples/s: 780.548 1613221352.1337047
train: epoch 3, iter 3200, loss: 3.545461, top_1: 0.408867, top_k: 0.656602, samples/s: 779.778 1613221384.9634821
train: epoch 3, iter 3300, loss: 3.383884, top_1: 0.408203, top_k: 0.656602, samples/s: 780.409 1613221417.766802
train: epoch 3, iter 3400, loss: 3.618476, top_1: 0.404648, top_k: 0.653086, samples/s: 778.963 1613221450.6309097
train: epoch 3, iter 3500, loss: 3.624918, top_1: 0.402109, top_k: 0.656211, samples/s: 778.153 1613221483.529325
train: epoch 3, iter 3600, loss: 3.522849, top_1: 0.407891, top_k: 0.658750, samples/s: 781.024 1613221516.3068526
train: epoch 3, iter 3700, loss: 3.458325, top_1: 0.409492, top_k: 0.660781, samples/s: 777.734 1613221549.2229614
train: epoch 3, iter 3800, loss: 3.479821, top_1: 0.408008, top_k: 0.661602, samples/s: 780.685 1613221582.0147002
train: epoch 3, iter 3900, loss: 3.422276, top_1: 0.407500, top_k: 0.660391, samples/s: 779.993 1613221614.8354921
train: epoch 3, iter 4000, loss: 3.552165, top_1: 0.402930, top_k: 0.652109, samples/s: 780.455 1613221647.6369064
train: epoch 3, iter 4100, loss: 3.674805, top_1: 0.405195, top_k: 0.659023, samples/s: 778.258 1613221680.5308583
train: epoch 3, iter 4200, loss: 3.535469, top_1: 0.410898, top_k: 0.659062, samples/s: 781.435 1613221713.2912154
train: epoch 3, iter 4300, loss: 3.427532, top_1: 0.402617, top_k: 0.659492, samples/s: 779.535 1613221746.1311913
train: epoch 3, iter 4400, loss: 3.545279, top_1: 0.411953, top_k: 0.665312, samples/s: 778.817 1613221779.001685
train: epoch 3, iter 4500, loss: 3.501826, top_1: 0.414531, top_k: 0.665820, samples/s: 780.363 1613221811.8067951
train: epoch 3, iter 4600, loss: 3.423256, top_1: 0.413398, top_k: 0.662578, samples/s: 780.919 1613221844.5887718
train: epoch 3, iter 4700, loss: 3.453665, top_1: 0.417734, top_k: 0.667031, samples/s: 780.529 1613221877.386963
train: epoch 3, iter 4800, loss: 3.441727, top_1: 0.413828, top_k: 0.668086, samples/s: 776.386 1613221910.3603656
train: epoch 3, iter 4900, loss: 3.587627, top_1: 0.418867, top_k: 0.668828, samples/s: 780.506 1613221943.159566
train: epoch 3, iter 5000, loss: 3.360086, top_1: 0.420234, top_k: 0.667617, samples/s: 778.504 1613221976.0431097
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_3.
validation: epoch 3, iter 195, top_1: 0.457432, top_k: 0.721635, samples/s: 2345.528 1613221998.3022933
train: epoch 4, iter 100, loss: 3.317995, top_1: 0.422187, top_k: 0.674727, samples/s: 805.189 1613222051.0920308
train: epoch 4, iter 200, loss: 3.499570, top_1: 0.427187, top_k: 0.674648, samples/s: 797.611 1613222083.1879122
train: epoch 4, iter 300, loss: 3.453396, top_1: 0.417695, top_k: 0.670625, samples/s: 778.931 1613222116.0535054
train: epoch 4, iter 400, loss: 3.393689, top_1: 0.421563, top_k: 0.672188, samples/s: 777.215 1613222148.9919748
train: epoch 4, iter 500, loss: 3.378090, top_1: 0.425234, top_k: 0.674961, samples/s: 777.715 1613222181.9085867
train: epoch 4, iter 600, loss: 3.458286, top_1: 0.429258, top_k: 0.680781, samples/s: 778.536 1613222214.7908897
train: epoch 4, iter 700, loss: 3.501671, top_1: 0.422930, top_k: 0.672031, samples/s: 778.935 1613222247.656118
train: epoch 4, iter 800, loss: 3.462229, top_1: 0.421563, top_k: 0.674883, samples/s: 774.834 1613222280.6955218
train: epoch 4, iter 900, loss: 3.288141, top_1: 0.422070, top_k: 0.672617, samples/s: 779.836 1613222313.5228677
train: epoch 4, iter 1000, loss: 3.503225, top_1: 0.420352, top_k: 0.672930, samples/s: 776.631 1613222346.4858398
train: epoch 4, iter 1100, loss: 3.272241, top_1: 0.426680, top_k: 0.678398, samples/s: 780.115 1613222379.3014593
train: epoch 4, iter 1200, loss: 3.489642, top_1: 0.422812, top_k: 0.675469, samples/s: 778.206 1613222412.1977081
train: epoch 4, iter 1300, loss: 3.402308, top_1: 0.425625, top_k: 0.676133, samples/s: 779.458 1613222445.040971
train: epoch 4, iter 1400, loss: 3.587829, top_1: 0.423320, top_k: 0.678594, samples/s: 779.664 1613222477.8756087
train: epoch 4, iter 1500, loss: 3.413332, top_1: 0.426055, top_k: 0.672852, samples/s: 779.006 1613222510.7380986
train: epoch 4, iter 1600, loss: 3.493571, top_1: 0.432617, top_k: 0.679375, samples/s: 780.806 1613222543.5246475
train: epoch 4, iter 1700, loss: 3.252988, top_1: 0.423945, top_k: 0.675742, samples/s: 779.239 1613222576.3772354
train: epoch 4, iter 1800, loss: 3.451612, top_1: 0.428633, top_k: 0.677656, samples/s: 781.355 1613222609.1409326
train: epoch 4, iter 1900, loss: 3.317389, top_1: 0.426875, top_k: 0.674258, samples/s: 777.104 1613222642.0836778
train: epoch 4, iter 2000, loss: 3.581504, top_1: 0.426680, top_k: 0.675859, samples/s: 779.388 1613222674.9300005
train: epoch 4, iter 2100, loss: 3.446840, top_1: 0.422187, top_k: 0.676680, samples/s: 778.850 1613222707.7989128
train: epoch 4, iter 2200, loss: 3.475281, top_1: 0.426875, top_k: 0.675234, samples/s: 781.909 1613222740.539312
train: epoch 4, iter 2300, loss: 3.529368, top_1: 0.428320, top_k: 0.678008, samples/s: 778.660 1613222773.4163754
train: epoch 4, iter 2400, loss: 3.265663, top_1: 0.429805, top_k: 0.676953, samples/s: 776.846 1613222806.3700624
train: epoch 4, iter 2500, loss: 3.406606, top_1: 0.423789, top_k: 0.677461, samples/s: 782.285 1613222839.0946546
train: epoch 4, iter 2600, loss: 3.256063, top_1: 0.427852, top_k: 0.682344, samples/s: 778.325 1613222871.9859192
train: epoch 4, iter 2700, loss: 3.431760, top_1: 0.426406, top_k: 0.677305, samples/s: 779.794 1613222904.8150923
train: epoch 4, iter 2800, loss: 3.394603, top_1: 0.432773, top_k: 0.682070, samples/s: 780.581 1613222937.6111906
train: epoch 4, iter 2900, loss: 3.371189, top_1: 0.421445, top_k: 0.671758, samples/s: 778.757 1613222970.483979
train: epoch 4, iter 3000, loss: 3.452635, top_1: 0.428359, top_k: 0.676875, samples/s: 780.662 1613223003.2767205
train: epoch 4, iter 3100, loss: 3.427113, top_1: 0.433984, top_k: 0.680508, samples/s: 780.838 1613223036.0619605
train: epoch 4, iter 3200, loss: 3.287865, top_1: 0.433086, top_k: 0.679141, samples/s: 779.889 1613223068.887222
train: epoch 4, iter 3300, loss: 3.356610, top_1: 0.434492, top_k: 0.684883, samples/s: 779.794 1613223101.7163107
train: epoch 4, iter 3400, loss: 3.320349, top_1: 0.430664, top_k: 0.678984, samples/s: 777.505 1613223134.6421814
train: epoch 4, iter 3500, loss: 3.211196, top_1: 0.426953, top_k: 0.680898, samples/s: 782.046 1613223167.3767798
train: epoch 4, iter 3600, loss: 3.356172, top_1: 0.435078, top_k: 0.688086, samples/s: 778.438 1613223200.2632315
train: epoch 4, iter 3700, loss: 3.305290, top_1: 0.438125, top_k: 0.683438, samples/s: 779.204 1613223233.117197
train: epoch 4, iter 3800, loss: 3.584688, top_1: 0.425820, top_k: 0.676719, samples/s: 781.727 1613223265.8653283
train: epoch 4, iter 3900, loss: 3.294282, top_1: 0.427422, top_k: 0.675039, samples/s: 778.838 1613223298.7347274
train: epoch 4, iter 4000, loss: 3.455016, top_1: 0.435195, top_k: 0.683398, samples/s: 780.118 1613223331.5502658
train: epoch 4, iter 4100, loss: 3.468373, top_1: 0.428711, top_k: 0.678867, samples/s: 780.172 1613223364.3634818
train: epoch 4, iter 4200, loss: 3.430106, top_1: 0.434805, top_k: 0.686523, samples/s: 780.917 1613223397.1454656
train: epoch 4, iter 4300, loss: 3.322267, top_1: 0.433398, top_k: 0.683789, samples/s: 779.753 1613223429.9763854
train: epoch 4, iter 4400, loss: 3.348590, top_1: 0.437969, top_k: 0.685937, samples/s: 778.653 1613223462.8537326
train: epoch 4, iter 4500, loss: 3.359232, top_1: 0.436484, top_k: 0.687070, samples/s: 778.521 1613223495.7365758
train: epoch 4, iter 4600, loss: 3.416728, top_1: 0.438008, top_k: 0.683750, samples/s: 779.371 1613223528.58356
train: epoch 4, iter 4700, loss: 3.401763, top_1: 0.435039, top_k: 0.683984, samples/s: 778.559 1613223561.464889
train: epoch 4, iter 4800, loss: 3.385404, top_1: 0.436289, top_k: 0.686562, samples/s: 782.016 1613223594.200692
train: epoch 4, iter 4900, loss: 3.209442, top_1: 0.434219, top_k: 0.684961, samples/s: 778.173 1613223627.0983765
train: epoch 4, iter 5000, loss: 3.226812, top_1: 0.434102, top_k: 0.684492, samples/s: 779.016 1613223659.9603477
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_4.
validation: epoch 4, iter 195, top_1: 0.492328, top_k: 0.752925, samples/s: 2384.313 1613223681.8910258
train: epoch 5, iter 100, loss: 3.391286, top_1: 0.443555, top_k: 0.694453, samples/s: 802.914 1613223735.4312313
train: epoch 5, iter 200, loss: 3.106844, top_1: 0.438789, top_k: 0.691406, samples/s: 800.524 1613223767.4102397
train: epoch 5, iter 300, loss: 3.407890, top_1: 0.439063, top_k: 0.684219, samples/s: 781.959 1613223800.1485896
train: epoch 5, iter 400, loss: 3.315145, top_1: 0.439531, top_k: 0.692187, samples/s: 780.118 1613223832.964141
train: epoch 5, iter 500, loss: 3.272669, top_1: 0.447227, top_k: 0.694688, samples/s: 780.219 1613223865.7753763
train: epoch 5, iter 600, loss: 3.248028, top_1: 0.442578, top_k: 0.693438, samples/s: 776.872 1613223898.7280393
train: epoch 5, iter 700, loss: 3.340199, top_1: 0.447109, top_k: 0.697461, samples/s: 780.740 1613223931.517407
train: epoch 5, iter 800, loss: 3.474484, top_1: 0.445781, top_k: 0.691133, samples/s: 780.222 1613223964.328623
train: epoch 5, iter 900, loss: 3.310399, top_1: 0.442383, top_k: 0.694180, samples/s: 777.935 1613223997.236255
train: epoch 5, iter 1000, loss: 3.425466, top_1: 0.443008, top_k: 0.694453, samples/s: 778.123 1613224030.1359348
train: epoch 5, iter 1100, loss: 3.321013, top_1: 0.445859, top_k: 0.692695, samples/s: 779.435 1613224062.9802349
train: epoch 5, iter 1200, loss: 3.445558, top_1: 0.446445, top_k: 0.692031, samples/s: 775.901 1613224095.9742343
train: epoch 5, iter 1300, loss: 3.383380, top_1: 0.449844, top_k: 0.699766, samples/s: 781.147 1613224128.7465057
train: epoch 5, iter 1400, loss: 3.293671, top_1: 0.451836, top_k: 0.699805, samples/s: 778.915 1613224161.6128073
train: epoch 5, iter 1500, loss: 3.435362, top_1: 0.447852, top_k: 0.698594, samples/s: 783.290 1613224194.2953835
train: epoch 5, iter 1600, loss: 3.247322, top_1: 0.439141, top_k: 0.696133, samples/s: 778.240 1613224227.1901355
train: epoch 5, iter 1700, loss: 3.330577, top_1: 0.448242, top_k: 0.696016, samples/s: 783.452 1613224259.8660216
train: epoch 5, iter 1800, loss: 3.172372, top_1: 0.452031, top_k: 0.699141, samples/s: 779.529 1613224292.7063708
train: epoch 5, iter 1900, loss: 3.423748, top_1: 0.446953, top_k: 0.698164, samples/s: 779.007 1613224325.5687149
train: epoch 5, iter 2000, loss: 3.281229, top_1: 0.448828, top_k: 0.692852, samples/s: 782.668 1613224358.2773411
train: epoch 5, iter 2100, loss: 3.334517, top_1: 0.448789, top_k: 0.694258, samples/s: 777.422 1613224391.2066977
train: epoch 5, iter 2200, loss: 3.442271, top_1: 0.448828, top_k: 0.700313, samples/s: 781.381 1613224423.9691617
train: epoch 5, iter 2300, loss: 3.415053, top_1: 0.445000, top_k: 0.693125, samples/s: 779.972 1613224456.7908459
train: epoch 5, iter 2400, loss: 3.325798, top_1: 0.448633, top_k: 0.701523, samples/s: 781.958 1613224489.529185
train: epoch 5, iter 2500, loss: 3.229364, top_1: 0.454883, top_k: 0.699219, samples/s: 782.035 1613224522.2643461
train: epoch 5, iter 2600, loss: 3.352080, top_1: 0.452070, top_k: 0.702812, samples/s: 778.180 1613224555.1615827
train: epoch 5, iter 2700, loss: 3.219982, top_1: 0.452578, top_k: 0.703047, samples/s: 781.788 1613224587.907064
train: epoch 5, iter 2800, loss: 3.409155, top_1: 0.453633, top_k: 0.697461, samples/s: 781.352 1613224620.6707144
train: epoch 5, iter 2900, loss: 3.328033, top_1: 0.452852, top_k: 0.700000, samples/s: 778.164 1613224653.5687003
train: epoch 5, iter 3000, loss: 3.383750, top_1: 0.453594, top_k: 0.700469, samples/s: 780.069 1613224686.3863614
train: epoch 5, iter 3100, loss: 3.271592, top_1: 0.451641, top_k: 0.699570, samples/s: 781.079 1613224719.161497
train: epoch 5, iter 3200, loss: 3.295191, top_1: 0.448242, top_k: 0.696289, samples/s: 780.352 1613224751.9671617
train: epoch 5, iter 3300, loss: 3.167571, top_1: 0.447500, top_k: 0.696055, samples/s: 781.216 1613224784.7366004
train: epoch 5, iter 3400, loss: 3.433575, top_1: 0.453945, top_k: 0.701602, samples/s: 779.263 1613224817.588099
train: epoch 5, iter 3500, loss: 3.274819, top_1: 0.457383, top_k: 0.705391, samples/s: 781.785 1613224850.3336992
train: epoch 5, iter 3600, loss: 3.091074, top_1: 0.457461, top_k: 0.706016, samples/s: 777.935 1613224883.2413082
train: epoch 5, iter 3700, loss: 3.167763, top_1: 0.461133, top_k: 0.707539, samples/s: 781.676 1613224915.9914753
train: epoch 5, iter 3800, loss: 3.310915, top_1: 0.449727, top_k: 0.697852, samples/s: 783.715 1613224948.6564748
train: epoch 5, iter 3900, loss: 3.168241, top_1: 0.449648, top_k: 0.698398, samples/s: 779.333 1613224981.505095
train: epoch 5, iter 4000, loss: 3.400151, top_1: 0.453047, top_k: 0.698320, samples/s: 779.065 1613225014.3648965
train: epoch 5, iter 4100, loss: 3.438066, top_1: 0.450078, top_k: 0.702344, samples/s: 781.547 1613225047.1204932
train: epoch 5, iter 4200, loss: 3.167456, top_1: 0.454727, top_k: 0.704414, samples/s: 780.717 1613225079.9108863
train: epoch 5, iter 4300, loss: 3.391850, top_1: 0.457188, top_k: 0.706797, samples/s: 777.838 1613225112.8226066
train: epoch 5, iter 4400, loss: 3.503925, top_1: 0.454336, top_k: 0.703047, samples/s: 782.520 1613225145.5374856
train: epoch 5, iter 4500, loss: 3.524931, top_1: 0.458828, top_k: 0.702812, samples/s: 779.569 1613225178.3761415
train: epoch 5, iter 4600, loss: 3.418694, top_1: 0.461133, top_k: 0.706328, samples/s: 778.815 1613225211.2465036
train: epoch 5, iter 4700, loss: 3.506713, top_1: 0.458633, top_k: 0.701250, samples/s: 779.764 1613225244.076945
train: epoch 5, iter 4800, loss: 3.345863, top_1: 0.466836, top_k: 0.709297, samples/s: 780.431 1613225276.8793585
train: epoch 5, iter 4900, loss: 3.225084, top_1: 0.455859, top_k: 0.700469, samples/s: 781.214 1613225309.6488428
train: epoch 5, iter 5000, loss: 3.302007, top_1: 0.463555, top_k: 0.709844, samples/s: 780.683 1613225342.4407043
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_5.
validation: epoch 5, iter 195, top_1: 0.508113, top_k: 0.765425, samples/s: 2377.495 1613225364.4489145
train: epoch 6, iter 100, loss: 3.199457, top_1: 0.468008, top_k: 0.718789, samples/s: 805.021 1613225416.9039564
train: epoch 6, iter 200, loss: 3.148288, top_1: 0.472031, top_k: 0.713789, samples/s: 797.255 1613225449.0141332
train: epoch 6, iter 300, loss: 3.275522, top_1: 0.463047, top_k: 0.702930, samples/s: 780.571 1613225481.8106995
train: epoch 6, iter 400, loss: 3.200486, top_1: 0.468711, top_k: 0.713320, samples/s: 778.572 1613225514.6916485
train: epoch 6, iter 500, loss: 3.353465, top_1: 0.462461, top_k: 0.705937, samples/s: 778.380 1613225547.5802584
train: epoch 6, iter 600, loss: 3.242202, top_1: 0.463516, top_k: 0.715859, samples/s: 778.414 1613225580.4676402
train: epoch 6, iter 700, loss: 3.233815, top_1: 0.469609, top_k: 0.713633, samples/s: 779.998 1613225613.288196
train: epoch 6, iter 800, loss: 3.397306, top_1: 0.460820, top_k: 0.708477, samples/s: 776.328 1613225646.26396
train: epoch 6, iter 900, loss: 3.169061, top_1: 0.465703, top_k: 0.714688, samples/s: 780.421 1613225679.0667787
train: epoch 6, iter 1000, loss: 3.356939, top_1: 0.467773, top_k: 0.714844, samples/s: 780.388 1613225711.870977
train: epoch 6, iter 1100, loss: 3.404703, top_1: 0.466133, top_k: 0.716602, samples/s: 778.185 1613225744.7680469
train: epoch 6, iter 1200, loss: 3.234809, top_1: 0.472539, top_k: 0.718008, samples/s: 777.513 1613225777.6935194
train: epoch 6, iter 1300, loss: 3.318996, top_1: 0.470039, top_k: 0.714727, samples/s: 778.877 1613225810.561336
train: epoch 6, iter 1400, loss: 3.070291, top_1: 0.468672, top_k: 0.718359, samples/s: 779.681 1613225843.3954148
train: epoch 6, iter 1500, loss: 3.181724, top_1: 0.469141, top_k: 0.709609, samples/s: 779.783 1613225876.2250144
train: epoch 6, iter 1600, loss: 3.260222, top_1: 0.468086, top_k: 0.716875, samples/s: 780.051 1613225909.0433843
train: epoch 6, iter 1700, loss: 3.374093, top_1: 0.464336, top_k: 0.713906, samples/s: 778.631 1613225941.9216123
train: epoch 6, iter 1800, loss: 3.154519, top_1: 0.465430, top_k: 0.715039, samples/s: 783.801 1613225974.5829115
train: epoch 6, iter 1900, loss: 3.255895, top_1: 0.464805, top_k: 0.710586, samples/s: 778.202 1613226007.4791944
train: epoch 6, iter 2000, loss: 3.008602, top_1: 0.469844, top_k: 0.716523, samples/s: 779.393 1613226040.3253736
train: epoch 6, iter 2100, loss: 3.212905, top_1: 0.465547, top_k: 0.709375, samples/s: 778.164 1613226073.2232764
train: epoch 6, iter 2200, loss: 3.040630, top_1: 0.469414, top_k: 0.714531, samples/s: 779.092 1613226106.0820181
train: epoch 6, iter 2300, loss: 3.143390, top_1: 0.464883, top_k: 0.710742, samples/s: 780.776 1613226138.869911
train: epoch 6, iter 2400, loss: 3.368880, top_1: 0.467109, top_k: 0.712617, samples/s: 779.894 1613226171.6949437
train: epoch 6, iter 2500, loss: 3.149859, top_1: 0.467461, top_k: 0.713555, samples/s: 780.052 1613226204.5132544
train: epoch 6, iter 2600, loss: 3.196260, top_1: 0.467422, top_k: 0.713047, samples/s: 779.106 1613226237.3713741
train: epoch 6, iter 2700, loss: 3.213099, top_1: 0.467070, top_k: 0.710313, samples/s: 782.494 1613226270.0873613
train: epoch 6, iter 2800, loss: 3.327769, top_1: 0.474492, top_k: 0.719805, samples/s: 777.989 1613226302.9926672
train: epoch 6, iter 2900, loss: 3.070950, top_1: 0.469961, top_k: 0.716172, samples/s: 778.279 1613226335.8864067
train: epoch 6, iter 3000, loss: 3.277990, top_1: 0.470313, top_k: 0.711875, samples/s: 780.763 1613226368.6741745
train: epoch 6, iter 3100, loss: 3.161505, top_1: 0.474102, top_k: 0.715938, samples/s: 778.318 1613226401.5660844
train: epoch 6, iter 3200, loss: 3.180873, top_1: 0.467266, top_k: 0.711523, samples/s: 779.892 1613226434.390618
train: epoch 6, iter 3300, loss: 3.334250, top_1: 0.467305, top_k: 0.715195, samples/s: 781.308 1613226467.1562257
train: epoch 6, iter 3400, loss: 3.217146, top_1: 0.472539, top_k: 0.716289, samples/s: 779.628 1613226499.9924428
train: epoch 6, iter 3500, loss: 3.207715, top_1: 0.474570, top_k: 0.721016, samples/s: 780.198 1613226532.8045647
train: epoch 6, iter 3600, loss: 3.242064, top_1: 0.471875, top_k: 0.722070, samples/s: 781.182 1613226565.575695
train: epoch 6, iter 3700, loss: 3.306602, top_1: 0.474844, top_k: 0.721367, samples/s: 778.222 1613226598.4709003
train: epoch 6, iter 3800, loss: 3.326897, top_1: 0.470703, top_k: 0.719141, samples/s: 781.385 1613226631.2337434
train: epoch 6, iter 3900, loss: 3.318919, top_1: 0.467344, top_k: 0.714141, samples/s: 779.134 1613226664.0902476
train: epoch 6, iter 4000, loss: 3.031121, top_1: 0.471953, top_k: 0.714805, samples/s: 783.058 1613226696.7825422
train: epoch 6, iter 4100, loss: 3.238945, top_1: 0.469141, top_k: 0.716680, samples/s: 778.604 1613226729.6620111
train: epoch 6, iter 4200, loss: 3.388624, top_1: 0.474766, top_k: 0.718125, samples/s: 779.608 1613226762.4989693
train: epoch 6, iter 4300, loss: 3.267155, top_1: 0.476211, top_k: 0.718555, samples/s: 779.993 1613226795.31983
train: epoch 6, iter 4400, loss: 3.262655, top_1: 0.467969, top_k: 0.712969, samples/s: 780.260 1613226828.1294222
train: epoch 6, iter 4500, loss: 3.035258, top_1: 0.468984, top_k: 0.719141, samples/s: 780.784 1613226860.9169495
train: epoch 6, iter 4600, loss: 3.319307, top_1: 0.472227, top_k: 0.716328, samples/s: 779.532 1613226893.7572646
train: epoch 6, iter 4700, loss: 3.144225, top_1: 0.481289, top_k: 0.724258, samples/s: 779.149 1613226926.6135676
train: epoch 6, iter 4800, loss: 3.341645, top_1: 0.473008, top_k: 0.719727, samples/s: 783.305 1613226959.2957263
train: epoch 6, iter 4900, loss: 3.249234, top_1: 0.476836, top_k: 0.718242, samples/s: 779.940 1613226992.118636
train: epoch 6, iter 5000, loss: 3.063388, top_1: 0.473984, top_k: 0.716172, samples/s: 779.728 1613227024.9506404
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_6.
validation: epoch 6, iter 195, top_1: 0.521194, top_k: 0.776603, samples/s: 2363.372 1613227047.065696
train: epoch 7, iter 100, loss: 3.121791, top_1: 0.477500, top_k: 0.723789, samples/s: 805.126 1613227099.5990748
train: epoch 7, iter 200, loss: 3.312218, top_1: 0.482891, top_k: 0.730313, samples/s: 798.646 1613227131.6533117
train: epoch 7, iter 300, loss: 3.169413, top_1: 0.481797, top_k: 0.724453, samples/s: 779.265 1613227164.504884
train: epoch 7, iter 400, loss: 3.365366, top_1: 0.483945, top_k: 0.725977, samples/s: 778.293 1613227197.397276
train: epoch 7, iter 500, loss: 3.350302, top_1: 0.486797, top_k: 0.728477, samples/s: 778.039 1613227230.3005173
train: epoch 7, iter 600, loss: 3.123015, top_1: 0.484961, top_k: 0.727500, samples/s: 780.511 1613227263.099515
train: epoch 7, iter 700, loss: 3.002885, top_1: 0.475547, top_k: 0.721094, samples/s: 778.948 1613227295.9643743
train: epoch 7, iter 800, loss: 3.061297, top_1: 0.479570, top_k: 0.727695, samples/s: 775.299 1613227328.9838722
train: epoch 7, iter 900, loss: 2.998829, top_1: 0.486289, top_k: 0.726094, samples/s: 778.659 1613227361.8609383
train: epoch 7, iter 1000, loss: 3.132899, top_1: 0.480781, top_k: 0.725117, samples/s: 779.576 1613227394.6993587
train: epoch 7, iter 1100, loss: 3.047946, top_1: 0.478750, top_k: 0.723398, samples/s: 780.365 1613227427.504465
train: epoch 7, iter 1200, loss: 3.297626, top_1: 0.478320, top_k: 0.724063, samples/s: 779.015 1613227460.3665493
train: epoch 7, iter 1300, loss: 3.177174, top_1: 0.484609, top_k: 0.725352, samples/s: 778.819 1613227493.236805
train: epoch 7, iter 1400, loss: 3.300296, top_1: 0.486289, top_k: 0.730117, samples/s: 780.836 1613227526.0220819
train: epoch 7, iter 1500, loss: 3.179918, top_1: 0.478516, top_k: 0.722031, samples/s: 777.628 1613227558.9427028
train: epoch 7, iter 1600, loss: 3.257885, top_1: 0.482773, top_k: 0.727070, samples/s: 778.185 1613227591.839756
train: epoch 7, iter 1700, loss: 3.114459, top_1: 0.478867, top_k: 0.722266, samples/s: 782.046 1613227624.5744047
train: epoch 7, iter 1800, loss: 3.174978, top_1: 0.476133, top_k: 0.723867, samples/s: 781.312 1613227657.3398507
train: epoch 7, iter 1900, loss: 3.229144, top_1: 0.484687, top_k: 0.726680, samples/s: 779.976 1613227690.1614466
train: epoch 7, iter 2000, loss: 3.064189, top_1: 0.486133, top_k: 0.731914, samples/s: 780.484 1613227722.9616394
train: epoch 7, iter 2100, loss: 3.144443, top_1: 0.477266, top_k: 0.724492, samples/s: 780.157 1613227755.7754905
train: epoch 7, iter 2200, loss: 3.198754, top_1: 0.480977, top_k: 0.726250, samples/s: 781.184 1613227788.546221
train: epoch 7, iter 2300, loss: 3.202534, top_1: 0.479258, top_k: 0.725898, samples/s: 781.506 1613227821.3035436
train: epoch 7, iter 2400, loss: 3.256767, top_1: 0.478047, top_k: 0.722812, samples/s: 781.359 1613227854.066977
train: epoch 7, iter 2500, loss: 3.267515, top_1: 0.479180, top_k: 0.724297, samples/s: 777.464 1613227886.994456
train: epoch 7, iter 2600, loss: 3.531713, top_1: 0.482383, top_k: 0.725234, samples/s: 780.242 1613227919.80487
train: epoch 7, iter 2700, loss: 3.364961, top_1: 0.483320, top_k: 0.725234, samples/s: 781.435 1613227952.5650403
train: epoch 7, iter 2800, loss: 3.065605, top_1: 0.488398, top_k: 0.728437, samples/s: 780.598 1613227985.3604314
train: epoch 7, iter 2900, loss: 3.315901, top_1: 0.474883, top_k: 0.723281, samples/s: 777.997 1613228018.265411
train: epoch 7, iter 3000, loss: 3.257784, top_1: 0.481641, top_k: 0.730117, samples/s: 780.200 1613228051.0775564
train: epoch 7, iter 3100, loss: 3.145696, top_1: 0.477930, top_k: 0.724688, samples/s: 779.499 1613228083.9190965
train: epoch 7, iter 3200, loss: 3.102473, top_1: 0.483242, top_k: 0.727734, samples/s: 780.439 1613228116.7212656
train: epoch 7, iter 3300, loss: 3.255355, top_1: 0.480742, top_k: 0.723633, samples/s: 780.463 1613228149.5222464
train: epoch 7, iter 3400, loss: 3.233620, top_1: 0.483203, top_k: 0.724531, samples/s: 776.431 1613228182.4936159
train: epoch 7, iter 3500, loss: 3.187382, top_1: 0.488633, top_k: 0.731016, samples/s: 780.437 1613228215.295763
train: epoch 7, iter 3600, loss: 3.000013, top_1: 0.483789, top_k: 0.725898, samples/s: 781.181 1613228248.066865
train: epoch 7, iter 3700, loss: 3.130759, top_1: 0.483203, top_k: 0.726406, samples/s: 778.889 1613228280.934003
train: epoch 7, iter 3800, loss: 3.201625, top_1: 0.478633, top_k: 0.721406, samples/s: 782.002 1613228313.6703618
train: epoch 7, iter 3900, loss: 2.983989, top_1: 0.481172, top_k: 0.724414, samples/s: 780.108 1613228346.4868839
train: epoch 7, iter 4000, loss: 2.935908, top_1: 0.479961, top_k: 0.726992, samples/s: 779.933 1613228379.309667
train: epoch 7, iter 4100, loss: 3.225063, top_1: 0.484961, top_k: 0.727344, samples/s: 780.080 1613228412.126841
train: epoch 7, iter 4200, loss: 3.330682, top_1: 0.482773, top_k: 0.724102, samples/s: 781.497 1613228444.884607
train: epoch 7, iter 4300, loss: 3.369146, top_1: 0.481328, top_k: 0.727187, samples/s: 782.077 1613228477.6178236
train: epoch 7, iter 4400, loss: 3.149969, top_1: 0.480430, top_k: 0.723789, samples/s: 777.970 1613228510.524037
train: epoch 7, iter 4500, loss: 3.234378, top_1: 0.482617, top_k: 0.727969, samples/s: 779.760 1613228543.3546805
train: epoch 7, iter 4600, loss: 3.240351, top_1: 0.479141, top_k: 0.723984, samples/s: 780.172 1613228576.1679792
train: epoch 7, iter 4700, loss: 3.123856, top_1: 0.485898, top_k: 0.730586, samples/s: 780.444 1613228608.9698045
train: epoch 7, iter 4800, loss: 3.014812, top_1: 0.486602, top_k: 0.732305, samples/s: 779.030 1613228641.8311152
train: epoch 7, iter 4900, loss: 3.336165, top_1: 0.483711, top_k: 0.728164, samples/s: 779.847 1613228674.6580637
train: epoch 7, iter 5000, loss: 3.227524, top_1: 0.492930, top_k: 0.731563, samples/s: 779.527 1613228707.498527
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_7.
validation: epoch 7, iter 195, top_1: 0.533654, top_k: 0.782913, samples/s: 2335.894 1613228729.8372812
train: epoch 8, iter 100, loss: 3.077230, top_1: 0.498555, top_k: 0.740039, samples/s: 803.549 1613228782.0729387
train: epoch 8, iter 200, loss: 3.112660, top_1: 0.497617, top_k: 0.737930, samples/s: 797.618 1613228814.1687741
train: epoch 8, iter 300, loss: 3.134614, top_1: 0.486367, top_k: 0.733047, samples/s: 778.621 1613228847.047037
train: epoch 8, iter 400, loss: 3.192494, top_1: 0.492461, top_k: 0.729883, samples/s: 776.472 1613228880.0167806
train: epoch 8, iter 500, loss: 3.070758, top_1: 0.498320, top_k: 0.732969, samples/s: 779.873 1613228912.8424964
train: epoch 8, iter 600, loss: 3.059109, top_1: 0.490586, top_k: 0.736211, samples/s: 776.895 1613228945.7943094
train: epoch 8, iter 700, loss: 3.309258, top_1: 0.491250, top_k: 0.735586, samples/s: 780.800 1613228978.5811024
train: epoch 8, iter 800, loss: 3.142579, top_1: 0.489453, top_k: 0.735977, samples/s: 779.683 1613229011.4149945
train: epoch 8, iter 900, loss: 3.091276, top_1: 0.491367, top_k: 0.734922, samples/s: 778.882 1613229044.2826376
train: epoch 8, iter 1000, loss: 3.165442, top_1: 0.486953, top_k: 0.730625, samples/s: 777.368 1613229077.214182
train: epoch 8, iter 1100, loss: 3.177919, top_1: 0.485234, top_k: 0.729570, samples/s: 777.351 1613229110.1466048
train: epoch 8, iter 1200, loss: 2.994670, top_1: 0.489570, top_k: 0.731797, samples/s: 784.523 1613229142.777816
train: epoch 8, iter 1300, loss: 3.239146, top_1: 0.486719, top_k: 0.726719, samples/s: 778.475 1613229175.662635
train: epoch 8, iter 1400, loss: 3.113297, top_1: 0.488906, top_k: 0.734805, samples/s: 780.996 1613229208.4412599
train: epoch 8, iter 1500, loss: 3.085611, top_1: 0.491406, top_k: 0.729570, samples/s: 777.755 1613229241.35652
train: epoch 8, iter 1600, loss: 3.088635, top_1: 0.486992, top_k: 0.729883, samples/s: 781.928 1613229274.096193
train: epoch 8, iter 1700, loss: 3.172410, top_1: 0.488281, top_k: 0.733594, samples/s: 777.817 1613229307.0087929
train: epoch 8, iter 1800, loss: 2.917152, top_1: 0.491484, top_k: 0.732109, samples/s: 778.743 1613229339.882289
train: epoch 8, iter 1900, loss: 3.199144, top_1: 0.491914, top_k: 0.734453, samples/s: 780.838 1613229372.6676004
train: epoch 8, iter 2000, loss: 3.185861, top_1: 0.489375, top_k: 0.733594, samples/s: 777.850 1613229405.5791297
train: epoch 8, iter 2100, loss: 3.115388, top_1: 0.494180, top_k: 0.736055, samples/s: 782.671 1613229438.2872794
train: epoch 8, iter 2200, loss: 3.155978, top_1: 0.490625, top_k: 0.733203, samples/s: 779.525 1613229471.1281207
train: epoch 8, iter 2300, loss: 3.190954, top_1: 0.489219, top_k: 0.733984, samples/s: 778.360 1613229504.0174797
train: epoch 8, iter 2400, loss: 3.069596, top_1: 0.493477, top_k: 0.735742, samples/s: 777.646 1613229536.9373715
train: epoch 8, iter 2500, loss: 3.036939, top_1: 0.486289, top_k: 0.732305, samples/s: 779.059 1613229569.7974212
train: epoch 8, iter 2600, loss: 3.173432, top_1: 0.493750, top_k: 0.732539, samples/s: 779.655 1613229602.6324863
train: epoch 8, iter 2700, loss: 2.984340, top_1: 0.491406, top_k: 0.733828, samples/s: 778.017 1613229635.5366776
train: epoch 8, iter 2800, loss: 3.028908, top_1: 0.495625, top_k: 0.736758, samples/s: 781.883 1613229668.2781744
train: epoch 8, iter 2900, loss: 3.176077, top_1: 0.488750, top_k: 0.735938, samples/s: 776.299 1613229701.2551925
train: epoch 8, iter 3000, loss: 3.026176, top_1: 0.489141, top_k: 0.733828, samples/s: 778.492 1613229734.1391637
train: epoch 8, iter 3100, loss: 3.090691, top_1: 0.491289, top_k: 0.734023, samples/s: 778.618 1613229767.0180452
train: epoch 8, iter 3200, loss: 3.164986, top_1: 0.497578, top_k: 0.735781, samples/s: 778.322 1613229799.9093285
train: epoch 8, iter 3300, loss: 3.030003, top_1: 0.488867, top_k: 0.733906, samples/s: 779.268 1613229832.7605968
train: epoch 8, iter 3400, loss: 3.205043, top_1: 0.489844, top_k: 0.735234, samples/s: 778.725 1613229865.6348364
train: epoch 8, iter 3500, loss: 3.147072, top_1: 0.493359, top_k: 0.736328, samples/s: 777.368 1613229898.5665464
train: epoch 8, iter 3600, loss: 3.197023, top_1: 0.489766, top_k: 0.736445, samples/s: 778.556 1613229931.4478445
train: epoch 8, iter 3700, loss: 3.238483, top_1: 0.490312, top_k: 0.736992, samples/s: 781.183 1613229964.2186615
train: epoch 8, iter 3800, loss: 3.025938, top_1: 0.496016, top_k: 0.736094, samples/s: 777.517 1613229997.1440463
train: epoch 8, iter 3900, loss: 2.904908, top_1: 0.490742, top_k: 0.736211, samples/s: 781.148 1613230029.9162738
train: epoch 8, iter 4000, loss: 3.160247, top_1: 0.485977, top_k: 0.729102, samples/s: 778.297 1613230062.8086743
train: epoch 8, iter 4100, loss: 2.880268, top_1: 0.497773, top_k: 0.735781, samples/s: 778.316 1613230095.7002099
train: epoch 8, iter 4200, loss: 2.985491, top_1: 0.493281, top_k: 0.736602, samples/s: 778.554 1613230128.581652
train: epoch 8, iter 4300, loss: 2.978420, top_1: 0.491406, top_k: 0.738516, samples/s: 777.677 1613230161.5002232
train: epoch 8, iter 4400, loss: 3.235561, top_1: 0.490742, top_k: 0.733516, samples/s: 779.944 1613230194.3230896
train: epoch 8, iter 4500, loss: 3.045563, top_1: 0.493047, top_k: 0.735508, samples/s: 776.167 1613230227.3057313
train: epoch 8, iter 4600, loss: 3.193468, top_1: 0.492070, top_k: 0.739297, samples/s: 782.629 1613230260.015937
train: epoch 8, iter 4700, loss: 2.997342, top_1: 0.498984, top_k: 0.738672, samples/s: 779.634 1613230292.851851
train: epoch 8, iter 4800, loss: 3.184071, top_1: 0.490625, top_k: 0.733750, samples/s: 779.924 1613230325.6755307
train: epoch 8, iter 4900, loss: 3.078503, top_1: 0.492617, top_k: 0.735430, samples/s: 780.060 1613230358.4935875
train: epoch 8, iter 5000, loss: 2.824803, top_1: 0.495977, top_k: 0.735781, samples/s: 779.212 1613230391.3472233
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_8.
validation: epoch 8, iter 195, top_1: 0.536679, top_k: 0.789323, samples/s: 2368.809 1613230413.404488
train: epoch 9, iter 100, loss: 3.238235, top_1: 0.509844, top_k: 0.747695, samples/s: 800.857 1613230466.5222762
train: epoch 9, iter 200, loss: 3.262324, top_1: 0.503594, top_k: 0.745742, samples/s: 801.717 1613230498.4536514
train: epoch 9, iter 300, loss: 2.832153, top_1: 0.509297, top_k: 0.751445, samples/s: 779.954 1613230531.2762039
train: epoch 9, iter 400, loss: 2.941340, top_1: 0.502773, top_k: 0.743828, samples/s: 777.290 1613230564.2110493
train: epoch 9, iter 500, loss: 2.969449, top_1: 0.493477, top_k: 0.744219, samples/s: 779.566 1613230597.0498483
train: epoch 9, iter 600, loss: 3.029407, top_1: 0.501289, top_k: 0.740547, samples/s: 780.246 1613230629.8599627
train: epoch 9, iter 700, loss: 3.064219, top_1: 0.498320, top_k: 0.742617, samples/s: 777.593 1613230662.7820485
train: epoch 9, iter 800, loss: 3.019086, top_1: 0.504258, top_k: 0.746563, samples/s: 777.741 1613230695.697959
train: epoch 9, iter 900, loss: 3.373763, top_1: 0.495547, top_k: 0.737148, samples/s: 778.963 1613230728.5621917
train: epoch 9, iter 1000, loss: 3.131920, top_1: 0.502305, top_k: 0.742266, samples/s: 777.052 1613230761.5071847
train: epoch 9, iter 1100, loss: 3.222589, top_1: 0.505703, top_k: 0.742656, samples/s: 783.009 1613230794.20152
train: epoch 9, iter 1200, loss: 3.106005, top_1: 0.498672, top_k: 0.740156, samples/s: 777.902 1613230827.1105602
train: epoch 9, iter 1300, loss: 3.210805, top_1: 0.499336, top_k: 0.737383, samples/s: 784.309 1613230859.7507546
train: epoch 9, iter 1400, loss: 2.968436, top_1: 0.502109, top_k: 0.740898, samples/s: 776.810 1613230892.7060513
train: epoch 9, iter 1500, loss: 2.916955, top_1: 0.499805, top_k: 0.743047, samples/s: 778.969 1613230925.5700176
train: epoch 9, iter 1600, loss: 3.025641, top_1: 0.500508, top_k: 0.738789, samples/s: 781.045 1613230958.3466008
train: epoch 9, iter 1700, loss: 3.064755, top_1: 0.496289, top_k: 0.740000, samples/s: 778.962 1613230991.2108445
train: epoch 9, iter 1800, loss: 3.125454, top_1: 0.493008, top_k: 0.737734, samples/s: 782.573 1613231023.9234338
train: epoch 9, iter 1900, loss: 2.965764, top_1: 0.498125, top_k: 0.744023, samples/s: 778.360 1613231056.81312
train: epoch 9, iter 2000, loss: 3.176406, top_1: 0.493281, top_k: 0.736641, samples/s: 781.437 1613231089.573271
train: epoch 9, iter 2100, loss: 3.214376, top_1: 0.497227, top_k: 0.738555, samples/s: 779.707 1613231122.4061396
train: epoch 9, iter 2200, loss: 3.109579, top_1: 0.504336, top_k: 0.744570, samples/s: 780.655 1613231155.1992428
train: epoch 9, iter 2300, loss: 3.276729, top_1: 0.504102, top_k: 0.743164, samples/s: 780.727 1613231187.9890683
train: epoch 9, iter 2400, loss: 2.964371, top_1: 0.502188, top_k: 0.739648, samples/s: 778.504 1613231220.8731122
train: epoch 9, iter 2500, loss: 2.830877, top_1: 0.500781, top_k: 0.745313, samples/s: 780.908 1613231253.6549938
train: epoch 9, iter 2600, loss: 3.033490, top_1: 0.506758, top_k: 0.742148, samples/s: 783.211 1613231286.3413491
train: epoch 9, iter 2700, loss: 3.150492, top_1: 0.505664, top_k: 0.740547, samples/s: 780.628 1613231319.1349952
train: epoch 9, iter 2800, loss: 3.256989, top_1: 0.495937, top_k: 0.734922, samples/s: 778.992 1613231351.9980361
train: epoch 9, iter 2900, loss: 3.115601, top_1: 0.496641, top_k: 0.740664, samples/s: 780.782 1613231384.7856095
train: epoch 9, iter 3000, loss: 3.054764, top_1: 0.499805, top_k: 0.741484, samples/s: 781.122 1613231417.5590088
train: epoch 9, iter 3100, loss: 3.086696, top_1: 0.498437, top_k: 0.743398, samples/s: 776.447 1613231450.529726
train: epoch 9, iter 3200, loss: 3.133308, top_1: 0.492812, top_k: 0.736875, samples/s: 786.818 1613231483.065862
train: epoch 9, iter 3300, loss: 2.954268, top_1: 0.498242, top_k: 0.743242, samples/s: 781.547 1613231515.8214123
train: epoch 9, iter 3400, loss: 2.945417, top_1: 0.503906, top_k: 0.743281, samples/s: 781.076 1613231548.5967097
train: epoch 9, iter 3500, loss: 2.896204, top_1: 0.495156, top_k: 0.739492, samples/s: 780.520 1613231581.395403
train: epoch 9, iter 3600, loss: 3.139191, top_1: 0.498672, top_k: 0.739844, samples/s: 780.670 1613231614.1877315
train: epoch 9, iter 3700, loss: 2.999775, top_1: 0.503594, top_k: 0.742656, samples/s: 779.575 1613231647.0261905
train: epoch 9, iter 3800, loss: 3.081964, top_1: 0.497305, top_k: 0.741055, samples/s: 781.713 1613231679.774737
train: epoch 9, iter 3900, loss: 2.997795, top_1: 0.501484, top_k: 0.746875, samples/s: 779.176 1613231712.6299872
train: epoch 9, iter 4000, loss: 3.156487, top_1: 0.500195, top_k: 0.739297, samples/s: 779.526 1613231745.470434
train: epoch 9, iter 4100, loss: 3.241095, top_1: 0.498555, top_k: 0.739766, samples/s: 783.194 1613231778.1570227
train: epoch 9, iter 4200, loss: 3.222069, top_1: 0.497422, top_k: 0.742734, samples/s: 780.458 1613231810.958379
train: epoch 9, iter 4300, loss: 3.050502, top_1: 0.501289, top_k: 0.739727, samples/s: 780.518 1613231843.7570128
train: epoch 9, iter 4400, loss: 3.161256, top_1: 0.498711, top_k: 0.741250, samples/s: 780.930 1613231876.5384226
train: epoch 9, iter 4500, loss: 2.931036, top_1: 0.497539, top_k: 0.739336, samples/s: 779.865 1613231909.3646839
train: epoch 9, iter 4600, loss: 3.197243, top_1: 0.495508, top_k: 0.741602, samples/s: 782.152 1613231942.0949595
train: epoch 9, iter 4700, loss: 3.159387, top_1: 0.498203, top_k: 0.737148, samples/s: 778.421 1613231974.9819508
train: epoch 9, iter 4800, loss: 3.134987, top_1: 0.503984, top_k: 0.743750, samples/s: 780.898 1613232007.764792
train: epoch 9, iter 4900, loss: 2.990474, top_1: 0.503555, top_k: 0.745508, samples/s: 780.489 1613232040.5647213
train: epoch 9, iter 5000, loss: 3.099779, top_1: 0.511953, top_k: 0.749531, samples/s: 780.994 1613232073.3433971
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_9.
validation: epoch 9, iter 195, top_1: 0.551542, top_k: 0.800080, samples/s: 2355.874 1613232095.4778645
train: epoch 10, iter 100, loss: 3.138389, top_1: 0.515508, top_k: 0.752031, samples/s: 805.270 1613232153.2734604
train: epoch 10, iter 200, loss: 3.022171, top_1: 0.512500, top_k: 0.754453, samples/s: 801.220 1613232185.2247028
train: epoch 10, iter 300, loss: 3.004096, top_1: 0.508398, top_k: 0.749727, samples/s: 783.905 1613232217.8817258
train: epoch 10, iter 400, loss: 3.018376, top_1: 0.506484, top_k: 0.750039, samples/s: 779.485 1613232250.7240174
train: epoch 10, iter 500, loss: 3.207615, top_1: 0.505625, top_k: 0.748633, samples/s: 779.800 1613232283.5529237
train: epoch 10, iter 600, loss: 3.127089, top_1: 0.507539, top_k: 0.745508, samples/s: 779.352 1613232316.4006689
train: epoch 10, iter 700, loss: 2.974235, top_1: 0.506445, top_k: 0.744062, samples/s: 778.328 1613232349.2916534
train: epoch 10, iter 800, loss: 3.231646, top_1: 0.515234, top_k: 0.751563, samples/s: 778.374 1613232382.180827
train: epoch 10, iter 900, loss: 3.028055, top_1: 0.507109, top_k: 0.749297, samples/s: 779.452 1613232415.0244145
train: epoch 10, iter 1000, loss: 3.202600, top_1: 0.505234, top_k: 0.746914, samples/s: 778.977 1613232447.8879287
train: epoch 10, iter 1100, loss: 2.949018, top_1: 0.505664, top_k: 0.744844, samples/s: 778.594 1613232480.7677376
train: epoch 10, iter 1200, loss: 2.885784, top_1: 0.507461, top_k: 0.749727, samples/s: 779.676 1613232513.6018302
train: epoch 10, iter 1300, loss: 3.074609, top_1: 0.508398, top_k: 0.746367, samples/s: 776.982 1613232546.5498624
train: epoch 10, iter 1400, loss: 2.959522, top_1: 0.510469, top_k: 0.750547, samples/s: 780.847 1613232579.3347223
train: epoch 10, iter 1500, loss: 2.964669, top_1: 0.507734, top_k: 0.749062, samples/s: 778.097 1613232612.2355993
train: epoch 10, iter 1600, loss: 2.895746, top_1: 0.508477, top_k: 0.749648, samples/s: 778.913 1613232645.1019278
train: epoch 10, iter 1700, loss: 3.032986, top_1: 0.497695, top_k: 0.745547, samples/s: 780.419 1613232677.9047184
train: epoch 10, iter 1800, loss: 3.025472, top_1: 0.499688, top_k: 0.748945, samples/s: 779.166 1613232710.7604628
train: epoch 10, iter 1900, loss: 2.996663, top_1: 0.508594, top_k: 0.750664, samples/s: 777.167 1613232743.7005875
train: epoch 10, iter 2000, loss: 3.158106, top_1: 0.503945, top_k: 0.746563, samples/s: 779.681 1613232776.5345445
train: epoch 10, iter 2100, loss: 3.133495, top_1: 0.508008, top_k: 0.744219, samples/s: 781.209 1613232809.3042727
train: epoch 10, iter 2200, loss: 3.106950, top_1: 0.504805, top_k: 0.740313, samples/s: 777.412 1613232842.234035
train: epoch 10, iter 2300, loss: 2.849228, top_1: 0.507891, top_k: 0.749570, samples/s: 782.505 1613232874.9494135
train: epoch 10, iter 2400, loss: 3.034855, top_1: 0.506133, top_k: 0.745078, samples/s: 778.287 1613232907.8421593
train: epoch 10, iter 2500, loss: 3.004455, top_1: 0.504531, top_k: 0.744062, samples/s: 779.133 1613232940.69964
train: epoch 10, iter 2600, loss: 3.165106, top_1: 0.507930, top_k: 0.746992, samples/s: 781.621 1613232973.4517074
train: epoch 10, iter 2700, loss: 3.199864, top_1: 0.507773, top_k: 0.747109, samples/s: 778.444 1613233006.337818
train: epoch 10, iter 2800, loss: 3.096187, top_1: 0.507969, top_k: 0.749336, samples/s: 780.673 1613233039.1300673
train: epoch 10, iter 2900, loss: 2.976094, top_1: 0.505703, top_k: 0.743711, samples/s: 783.819 1613233071.7909405
train: epoch 10, iter 3000, loss: 2.876809, top_1: 0.505898, top_k: 0.749844, samples/s: 776.855 1613233104.7439625
train: epoch 10, iter 3100, loss: 2.959796, top_1: 0.504570, top_k: 0.743906, samples/s: 778.190 1613233137.6408772
train: epoch 10, iter 3200, loss: 3.179904, top_1: 0.504492, top_k: 0.746719, samples/s: 782.056 1613233170.3750396
train: epoch 10, iter 3300, loss: 3.000732, top_1: 0.503945, top_k: 0.747852, samples/s: 776.911 1613233203.326143
train: epoch 10, iter 3400, loss: 3.032565, top_1: 0.509961, top_k: 0.748516, samples/s: 780.192 1613233236.1385272
train: epoch 10, iter 3500, loss: 2.946251, top_1: 0.507773, top_k: 0.743867, samples/s: 779.289 1613233268.9889653
train: epoch 10, iter 3600, loss: 3.172588, top_1: 0.507031, top_k: 0.747500, samples/s: 776.495 1613233301.9576983
train: epoch 10, iter 3700, loss: 2.966213, top_1: 0.511211, top_k: 0.750039, samples/s: 781.296 1613233334.7241733
train: epoch 10, iter 3800, loss: 2.903839, top_1: 0.506641, top_k: 0.748672, samples/s: 777.646 1613233367.643603
train: epoch 10, iter 3900, loss: 3.154855, top_1: 0.506016, top_k: 0.744961, samples/s: 783.222 1613233400.3294318
train: epoch 10, iter 4000, loss: 3.095015, top_1: 0.502656, top_k: 0.745938, samples/s: 777.842 1613233433.240597
train: epoch 10, iter 4100, loss: 3.021552, top_1: 0.506797, top_k: 0.746836, samples/s: 778.979 1613233466.1041298
train: epoch 10, iter 4200, loss: 3.024446, top_1: 0.507461, top_k: 0.747617, samples/s: 777.814 1613233499.0169523
train: epoch 10, iter 4300, loss: 3.005995, top_1: 0.509687, top_k: 0.748281, samples/s: 781.300 1613233531.7828221
train: epoch 10, iter 4400, loss: 2.969959, top_1: 0.508047, top_k: 0.750352, samples/s: 780.730 1613233564.572667
train: epoch 10, iter 4500, loss: 3.268452, top_1: 0.498594, top_k: 0.741758, samples/s: 780.034 1613233597.3917952
train: epoch 10, iter 4600, loss: 3.099998, top_1: 0.505078, top_k: 0.743633, samples/s: 780.803 1613233630.1785622
train: epoch 10, iter 4700, loss: 2.986215, top_1: 0.501055, top_k: 0.743516, samples/s: 777.728 1613233663.0949664
train: epoch 10, iter 4800, loss: 3.024640, top_1: 0.513594, top_k: 0.746445, samples/s: 782.778 1613233695.7989833
train: epoch 10, iter 4900, loss: 2.852587, top_1: 0.506289, top_k: 0.750078, samples/s: 781.651 1613233728.5501318
train: epoch 10, iter 5000, loss: 2.866812, top_1: 0.511328, top_k: 0.750703, samples/s: 780.989 1613233761.3290465
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_10.
validation: epoch 10, iter 195, top_1: 0.559395, top_k: 0.803065, samples/s: 2360.671 1613233783.4678733
train: epoch 11, iter 100, loss: 3.093068, top_1: 0.513047, top_k: 0.752109, samples/s: 804.306 1613233836.5829682
train: epoch 11, iter 200, loss: 3.017761, top_1: 0.513359, top_k: 0.752266, samples/s: 799.731 1613233868.5936046
train: epoch 11, iter 300, loss: 3.077539, top_1: 0.519453, top_k: 0.754375, samples/s: 781.397 1613233901.3555224
train: epoch 11, iter 400, loss: 2.994873, top_1: 0.514023, top_k: 0.755234, samples/s: 776.498 1613233934.3239968
train: epoch 11, iter 500, loss: 3.097918, top_1: 0.518516, top_k: 0.756914, samples/s: 778.260 1613233967.217958
train: epoch 11, iter 600, loss: 3.147536, top_1: 0.517109, top_k: 0.752695, samples/s: 780.080 1613234000.0351107
train: epoch 11, iter 700, loss: 2.912185, top_1: 0.518437, top_k: 0.752812, samples/s: 777.122 1613234032.9771984
train: epoch 11, iter 800, loss: 2.935169, top_1: 0.511484, top_k: 0.751719, samples/s: 782.657 1613234065.686187
train: epoch 11, iter 900, loss: 2.999835, top_1: 0.510625, top_k: 0.749844, samples/s: 775.599 1613234098.6929908
train: epoch 11, iter 1000, loss: 3.017099, top_1: 0.512578, top_k: 0.750391, samples/s: 780.302 1613234131.5007505
train: epoch 11, iter 1100, loss: 2.929126, top_1: 0.514531, top_k: 0.749961, samples/s: 780.516 1613234164.299613
train: epoch 11, iter 1200, loss: 3.166648, top_1: 0.511289, top_k: 0.750000, samples/s: 781.398 1613234197.0614014
train: epoch 11, iter 1300, loss: 3.075093, top_1: 0.512734, top_k: 0.754922, samples/s: 780.115 1613234229.8770618
train: epoch 11, iter 1400, loss: 3.130321, top_1: 0.509766, top_k: 0.750781, samples/s: 778.857 1613234262.745729
train: epoch 11, iter 1500, loss: 3.132871, top_1: 0.516172, top_k: 0.754297, samples/s: 779.965 1613234295.5677276
train: epoch 11, iter 1600, loss: 3.196204, top_1: 0.513867, top_k: 0.754414, samples/s: 777.139 1613234328.5090528
train: epoch 11, iter 1700, loss: 2.940413, top_1: 0.512695, top_k: 0.750273, samples/s: 781.460 1613234361.26831
train: epoch 11, iter 1800, loss: 2.963402, top_1: 0.520117, top_k: 0.754180, samples/s: 779.384 1613234394.1147308
train: epoch 11, iter 1900, loss: 3.062011, top_1: 0.505430, top_k: 0.746211, samples/s: 779.063 1613234426.9747405
train: epoch 11, iter 2000, loss: 3.154605, top_1: 0.510742, top_k: 0.751563, samples/s: 777.029 1613234459.9206276
train: epoch 11, iter 2100, loss: 2.913523, top_1: 0.514570, top_k: 0.752422, samples/s: 779.499 1613234492.7622457
train: epoch 11, iter 2200, loss: 3.105367, top_1: 0.513789, top_k: 0.750430, samples/s: 781.416 1613234525.5233207
train: epoch 11, iter 2300, loss: 3.070720, top_1: 0.506797, top_k: 0.746367, samples/s: 778.822 1613234558.3939838
train: epoch 11, iter 2400, loss: 2.987126, top_1: 0.516992, top_k: 0.754531, samples/s: 779.420 1613234591.2384624
train: epoch 11, iter 2500, loss: 3.022788, top_1: 0.513594, top_k: 0.750859, samples/s: 778.571 1613234624.119662
train: epoch 11, iter 2600, loss: 3.020292, top_1: 0.512891, top_k: 0.755156, samples/s: 782.089 1613234656.852098
train: epoch 11, iter 2700, loss: 3.088276, top_1: 0.516758, top_k: 0.753047, samples/s: 778.246 1613234689.7465782
train: epoch 11, iter 2800, loss: 2.954507, top_1: 0.518984, top_k: 0.755508, samples/s: 782.201 1613234722.4746883
train: epoch 11, iter 2900, loss: 3.052578, top_1: 0.517148, top_k: 0.752891, samples/s: 778.583 1613234755.355065
train: epoch 11, iter 3000, loss: 3.012519, top_1: 0.510000, top_k: 0.748594, samples/s: 779.739 1613234788.1864438
train: epoch 11, iter 3100, loss: 3.106977, top_1: 0.512930, top_k: 0.749062, samples/s: 781.093 1613234820.9610474
train: epoch 11, iter 3200, loss: 3.007997, top_1: 0.513828, top_k: 0.745781, samples/s: 779.405 1613234853.8065696
train: epoch 11, iter 3300, loss: 3.030607, top_1: 0.512617, top_k: 0.754062, samples/s: 778.578 1613234886.687095
train: epoch 11, iter 3400, loss: 2.958931, top_1: 0.511563, top_k: 0.746289, samples/s: 781.447 1613234919.4469445
train: epoch 11, iter 3500, loss: 3.100091, top_1: 0.509805, top_k: 0.749922, samples/s: 778.164 1613234952.3448305
train: epoch 11, iter 3600, loss: 2.850433, top_1: 0.515664, top_k: 0.751211, samples/s: 782.588 1613234985.0567973
train: epoch 11, iter 3700, loss: 2.902758, top_1: 0.509766, top_k: 0.749492, samples/s: 781.580 1613235017.810963
train: epoch 11, iter 3800, loss: 2.734281, top_1: 0.514375, top_k: 0.751875, samples/s: 779.976 1613235050.6324663
train: epoch 11, iter 3900, loss: 3.023076, top_1: 0.508164, top_k: 0.752812, samples/s: 778.896 1613235083.49949
train: epoch 11, iter 4000, loss: 3.082453, top_1: 0.507578, top_k: 0.752500, samples/s: 780.160 1613235116.3131516
train: epoch 11, iter 4100, loss: 3.086343, top_1: 0.510938, top_k: 0.750234, samples/s: 780.990 1613235149.092053
train: epoch 11, iter 4200, loss: 3.234963, top_1: 0.511641, top_k: 0.746992, samples/s: 780.838 1613235181.8773446
train: epoch 11, iter 4300, loss: 3.170963, top_1: 0.509531, top_k: 0.751563, samples/s: 780.512 1613235214.6763823
train: epoch 11, iter 4400, loss: 3.178833, top_1: 0.511484, top_k: 0.748672, samples/s: 781.120 1613235247.4498136
train: epoch 11, iter 4500, loss: 2.888794, top_1: 0.514805, top_k: 0.753516, samples/s: 780.832 1613235280.235354
train: epoch 11, iter 4600, loss: 3.065850, top_1: 0.512266, top_k: 0.747773, samples/s: 781.097 1613235313.0098338
train: epoch 11, iter 4700, loss: 3.123769, top_1: 0.512891, top_k: 0.753750, samples/s: 780.629 1613235345.8039014
train: epoch 11, iter 4800, loss: 3.027711, top_1: 0.510430, top_k: 0.750508, samples/s: 784.263 1613235378.4460123
train: epoch 11, iter 4900, loss: 3.055176, top_1: 0.509531, top_k: 0.748555, samples/s: 780.233 1613235411.2567077
train: epoch 11, iter 5000, loss: 2.999049, top_1: 0.511680, top_k: 0.751719, samples/s: 779.578 1613235444.0949361
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_11.
validation: epoch 11, iter 195, top_1: 0.566867, top_k: 0.810597, samples/s: 2318.862 1613235466.579061
train: epoch 12, iter 100, loss: 2.948202, top_1: 0.521172, top_k: 0.760156, samples/s: 804.856 1613235519.5500164
train: epoch 12, iter 200, loss: 2.890743, top_1: 0.526953, top_k: 0.766797, samples/s: 798.676 1613235551.602862
train: epoch 12, iter 300, loss: 3.068597, top_1: 0.518437, top_k: 0.758008, samples/s: 780.412 1613235584.4063158
train: epoch 12, iter 400, loss: 2.909157, top_1: 0.522734, top_k: 0.758008, samples/s: 780.939 1613235617.1871247
train: epoch 12, iter 500, loss: 2.976991, top_1: 0.518867, top_k: 0.756602, samples/s: 777.955 1613235650.0939534
train: epoch 12, iter 600, loss: 2.993734, top_1: 0.523633, top_k: 0.757031, samples/s: 777.584 1613235683.0164547
train: epoch 12, iter 700, loss: 3.041846, top_1: 0.525898, top_k: 0.762578, samples/s: 777.436 1613235715.9451106
train: epoch 12, iter 800, loss: 3.040566, top_1: 0.524023, top_k: 0.755273, samples/s: 778.478 1613235748.8297682
train: epoch 12, iter 900, loss: 2.936556, top_1: 0.523945, top_k: 0.759453, samples/s: 779.097 1613235781.6884277
train: epoch 12, iter 1000, loss: 3.009311, top_1: 0.520234, top_k: 0.762344, samples/s: 778.554 1613235814.5699668
train: epoch 12, iter 1100, loss: 3.070213, top_1: 0.514219, top_k: 0.753125, samples/s: 778.027 1613235847.4735572
train: epoch 12, iter 1200, loss: 2.898164, top_1: 0.514844, top_k: 0.754414, samples/s: 779.362 1613235880.3209968
train: epoch 12, iter 1300, loss: 2.908330, top_1: 0.517695, top_k: 0.754258, samples/s: 781.302 1613235913.0867908
train: epoch 12, iter 1400, loss: 2.912918, top_1: 0.519453, top_k: 0.755625, samples/s: 777.656 1613235946.0061896
train: epoch 12, iter 1500, loss: 3.093846, top_1: 0.515625, top_k: 0.755430, samples/s: 779.179 1613235978.861343
train: epoch 12, iter 1600, loss: 3.280958, top_1: 0.516953, top_k: 0.752930, samples/s: 779.121 1613236011.7188644
train: epoch 12, iter 1700, loss: 3.060274, top_1: 0.521602, top_k: 0.760586, samples/s: 780.360 1613236044.5242422
train: epoch 12, iter 1800, loss: 2.960058, top_1: 0.516758, top_k: 0.753047, samples/s: 780.209 1613236077.336021
train: epoch 12, iter 1900, loss: 2.849797, top_1: 0.516367, top_k: 0.752422, samples/s: 780.053 1613236110.154258
train: epoch 12, iter 2000, loss: 2.868123, top_1: 0.517383, top_k: 0.758320, samples/s: 781.288 1613236142.9207025
train: epoch 12, iter 2100, loss: 2.910714, top_1: 0.516172, top_k: 0.752695, samples/s: 780.870 1613236175.7045743
train: epoch 12, iter 2200, loss: 3.101319, top_1: 0.518008, top_k: 0.756758, samples/s: 781.750 1613236208.4517262
train: epoch 12, iter 2300, loss: 3.133161, top_1: 0.519375, top_k: 0.757539, samples/s: 780.295 1613236241.2597206
train: epoch 12, iter 2400, loss: 3.067932, top_1: 0.515547, top_k: 0.755273, samples/s: 783.178 1613236273.947151
train: epoch 12, iter 2500, loss: 2.972224, top_1: 0.517930, top_k: 0.752969, samples/s: 780.455 1613236306.748443
train: epoch 12, iter 2600, loss: 3.002700, top_1: 0.517695, top_k: 0.754687, samples/s: 782.180 1613236339.4775457
train: epoch 12, iter 2700, loss: 2.920729, top_1: 0.516484, top_k: 0.756289, samples/s: 782.370 1613236372.198643
train: epoch 12, iter 2800, loss: 2.967502, top_1: 0.510195, top_k: 0.750156, samples/s: 780.094 1613236405.0150928
train: epoch 12, iter 2900, loss: 3.328749, top_1: 0.516484, top_k: 0.757578, samples/s: 781.946 1613236437.753993
train: epoch 12, iter 3000, loss: 3.006045, top_1: 0.519414, top_k: 0.755586, samples/s: 782.365 1613236470.4752133
train: epoch 12, iter 3100, loss: 3.227244, top_1: 0.518828, top_k: 0.756563, samples/s: 781.980 1613236503.212695
train: epoch 12, iter 3200, loss: 3.032339, top_1: 0.521953, top_k: 0.758711, samples/s: 783.946 1613236535.8679876
train: epoch 12, iter 3300, loss: 2.946082, top_1: 0.518828, top_k: 0.755313, samples/s: 780.925 1613236568.649566
train: epoch 12, iter 3400, loss: 3.136153, top_1: 0.517734, top_k: 0.756133, samples/s: 784.149 1613236601.2965224
train: epoch 12, iter 3500, loss: 3.100281, top_1: 0.512031, top_k: 0.751563, samples/s: 782.705 1613236634.0035934
train: epoch 12, iter 3600, loss: 3.277771, top_1: 0.517109, top_k: 0.753984, samples/s: 780.466 1613236666.804505
train: epoch 12, iter 3700, loss: 2.878317, top_1: 0.511602, top_k: 0.752422, samples/s: 781.751 1613236699.5514038
train: epoch 12, iter 3800, loss: 3.135009, top_1: 0.512031, top_k: 0.749805, samples/s: 780.673 1613236732.343676
train: epoch 12, iter 3900, loss: 3.341991, top_1: 0.515938, top_k: 0.752383, samples/s: 781.796 1613236765.0887454
train: epoch 12, iter 4000, loss: 2.912968, top_1: 0.515938, top_k: 0.756211, samples/s: 781.827 1613236797.832583
train: epoch 12, iter 4100, loss: 2.999673, top_1: 0.515195, top_k: 0.755195, samples/s: 783.964 1613236830.4871147
train: epoch 12, iter 4200, loss: 3.245674, top_1: 0.509805, top_k: 0.747383, samples/s: 781.714 1613236863.2356942
train: epoch 12, iter 4300, loss: 2.964259, top_1: 0.521875, top_k: 0.759570, samples/s: 781.118 1613236896.0092542
train: epoch 12, iter 4400, loss: 3.202121, top_1: 0.515312, top_k: 0.755195, samples/s: 785.446 1613236928.6021957
train: epoch 12, iter 4500, loss: 3.159885, top_1: 0.519844, top_k: 0.758633, samples/s: 782.704 1613236961.3093975
train: epoch 12, iter 4600, loss: 3.115103, top_1: 0.515156, top_k: 0.756602, samples/s: 782.389 1613236994.0296204
train: epoch 12, iter 4700, loss: 3.104985, top_1: 0.511836, top_k: 0.749805, samples/s: 780.953 1613237026.8101203
train: epoch 12, iter 4800, loss: 3.171656, top_1: 0.512344, top_k: 0.751641, samples/s: 782.537 1613237059.5242023
train: epoch 12, iter 4900, loss: 3.048351, top_1: 0.521836, top_k: 0.757891, samples/s: 782.272 1613237092.2494607
train: epoch 12, iter 5000, loss: 2.996478, top_1: 0.513477, top_k: 0.751445, samples/s: 779.873 1613237125.0752797
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_12.
validation: epoch 12, iter 195, top_1: 0.568189, top_k: 0.814183, samples/s: 2324.626 1613237147.5250652
train: epoch 13, iter 100, loss: 3.087788, top_1: 0.527539, top_k: 0.763555, samples/s: 804.191 1613237200.1957932
train: epoch 13, iter 200, loss: 2.952250, top_1: 0.524141, top_k: 0.761172, samples/s: 800.224 1613237232.1869516
train: epoch 13, iter 300, loss: 2.963986, top_1: 0.523359, top_k: 0.761797, samples/s: 781.172 1613237264.957939
train: epoch 13, iter 400, loss: 2.857564, top_1: 0.521758, top_k: 0.762305, samples/s: 780.263 1613237297.767708
train: epoch 13, iter 500, loss: 3.087112, top_1: 0.523164, top_k: 0.758828, samples/s: 780.171 1613237330.5807314
train: epoch 13, iter 600, loss: 3.096563, top_1: 0.525391, top_k: 0.761563, samples/s: 782.635 1613237363.2907574
train: epoch 13, iter 700, loss: 3.025618, top_1: 0.524453, top_k: 0.762344, samples/s: 778.929 1613237396.1564271
train: epoch 13, iter 800, loss: 3.181169, top_1: 0.526875, top_k: 0.764180, samples/s: 781.607 1613237428.9093866
train: epoch 13, iter 900, loss: 2.899373, top_1: 0.528164, top_k: 0.764062, samples/s: 778.790 1613237461.7808428
train: epoch 13, iter 1000, loss: 2.805438, top_1: 0.522852, top_k: 0.762461, samples/s: 784.249 1613237494.4235358
train: epoch 13, iter 1100, loss: 3.152639, top_1: 0.523633, top_k: 0.757109, samples/s: 780.890 1613237527.2067533
train: epoch 13, iter 1200, loss: 3.098255, top_1: 0.524414, top_k: 0.762813, samples/s: 778.502 1613237560.0903833
train: epoch 13, iter 1300, loss: 2.813195, top_1: 0.529727, top_k: 0.768242, samples/s: 780.193 1613237592.902789
train: epoch 13, iter 1400, loss: 2.808642, top_1: 0.525430, top_k: 0.757617, samples/s: 781.053 1613237625.6790612
train: epoch 13, iter 1500, loss: 3.045701, top_1: 0.518867, top_k: 0.755859, samples/s: 782.487 1613237658.3952136
train: epoch 13, iter 1600, loss: 2.968286, top_1: 0.514687, top_k: 0.752344, samples/s: 781.464 1613237691.154208
train: epoch 13, iter 1700, loss: 3.075696, top_1: 0.526836, top_k: 0.762031, samples/s: 781.516 1613237723.9111342
train: epoch 13, iter 1800, loss: 2.882206, top_1: 0.520039, top_k: 0.757578, samples/s: 779.677 1613237756.7451897
train: epoch 13, iter 1900, loss: 2.756865, top_1: 0.519453, top_k: 0.756484, samples/s: 783.105 1613237789.4355497
train: epoch 13, iter 2000, loss: 3.151723, top_1: 0.519531, top_k: 0.759023, samples/s: 781.488 1613237822.1935997
train: epoch 13, iter 2100, loss: 2.962935, top_1: 0.524180, top_k: 0.763945, samples/s: 781.055 1613237854.969798
train: epoch 13, iter 2200, loss: 3.016730, top_1: 0.520469, top_k: 0.760898, samples/s: 783.870 1613237887.6282446
train: epoch 13, iter 2300, loss: 2.792390, top_1: 0.525625, top_k: 0.761523, samples/s: 781.128 1613237920.4014108
train: epoch 13, iter 2400, loss: 3.105918, top_1: 0.519375, top_k: 0.759297, samples/s: 782.538 1613237953.1154099
train: epoch 13, iter 2500, loss: 2.902876, top_1: 0.528398, top_k: 0.762539, samples/s: 785.096 1613237985.7228868
train: epoch 13, iter 2600, loss: 2.923990, top_1: 0.521758, top_k: 0.763398, samples/s: 779.450 1613238018.5666153
train: epoch 13, iter 2700, loss: 2.807544, top_1: 0.521289, top_k: 0.760859, samples/s: 784.455 1613238051.2007544
train: epoch 13, iter 2800, loss: 2.935720, top_1: 0.523594, top_k: 0.759570, samples/s: 781.671 1613238083.9510677
train: epoch 13, iter 2900, loss: 3.212334, top_1: 0.522930, top_k: 0.758750, samples/s: 781.347 1613238116.7149904
train: epoch 13, iter 3000, loss: 2.959081, top_1: 0.519883, top_k: 0.757969, samples/s: 782.631 1613238149.425398
train: epoch 13, iter 3100, loss: 3.020181, top_1: 0.519180, top_k: 0.758203, samples/s: 784.422 1613238182.0606406
train: epoch 13, iter 3200, loss: 3.159393, top_1: 0.522617, top_k: 0.759180, samples/s: 781.654 1613238214.8116596
train: epoch 13, iter 3300, loss: 3.030251, top_1: 0.521563, top_k: 0.759492, samples/s: 781.854 1613238247.5543694
train: epoch 13, iter 3400, loss: 2.968008, top_1: 0.522227, top_k: 0.760156, samples/s: 782.653 1613238280.2637248
train: epoch 13, iter 3500, loss: 3.231946, top_1: 0.523047, top_k: 0.758047, samples/s: 780.241 1613238313.0741036
train: epoch 13, iter 3600, loss: 3.005391, top_1: 0.525664, top_k: 0.759219, samples/s: 781.790 1613238345.8194191
train: epoch 13, iter 3700, loss: 2.940369, top_1: 0.519609, top_k: 0.757656, samples/s: 783.932 1613238378.4754112
train: epoch 13, iter 3800, loss: 2.946089, top_1: 0.521367, top_k: 0.761211, samples/s: 782.844 1613238411.1766613
train: epoch 13, iter 3900, loss: 2.988523, top_1: 0.517852, top_k: 0.760469, samples/s: 783.405 1613238443.8545191
train: epoch 13, iter 4000, loss: 2.929981, top_1: 0.523672, top_k: 0.762539, samples/s: 779.136 1613238476.7113903
train: epoch 13, iter 4100, loss: 3.011109, top_1: 0.522539, top_k: 0.759414, samples/s: 782.652 1613238509.4207346
train: epoch 13, iter 4200, loss: 2.822713, top_1: 0.522383, top_k: 0.760234, samples/s: 783.771 1613238542.083266
train: epoch 13, iter 4300, loss: 3.054686, top_1: 0.525000, top_k: 0.762539, samples/s: 779.812 1613238574.9117908
train: epoch 13, iter 4400, loss: 3.056842, top_1: 0.518750, top_k: 0.753477, samples/s: 782.534 1613238607.6259713
train: epoch 13, iter 4500, loss: 2.925254, top_1: 0.527070, top_k: 0.760117, samples/s: 782.895 1613238640.3252022
train: epoch 13, iter 4600, loss: 3.017613, top_1: 0.517813, top_k: 0.754648, samples/s: 782.073 1613238673.0586028
train: epoch 13, iter 4700, loss: 3.001978, top_1: 0.526602, top_k: 0.762344, samples/s: 782.662 1613238705.7674444
train: epoch 13, iter 4800, loss: 2.994143, top_1: 0.523867, top_k: 0.759531, samples/s: 782.345 1613238738.4896169
train: epoch 13, iter 4900, loss: 2.837904, top_1: 0.518828, top_k: 0.758555, samples/s: 783.357 1613238771.1695683
train: epoch 13, iter 5000, loss: 2.916362, top_1: 0.530352, top_k: 0.766094, samples/s: 783.277 1613238803.852744
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_13.
validation: epoch 13, iter 195, top_1: 0.575621, top_k: 0.819471, samples/s: 2368.409 1613238825.8864138
train: epoch 14, iter 100, loss: 3.096102, top_1: 0.535312, top_k: 0.770469, samples/s: 803.986 1613238878.7757754
train: epoch 14, iter 200, loss: 2.987028, top_1: 0.528555, top_k: 0.766289, samples/s: 800.906 1613238910.7398129
train: epoch 14, iter 300, loss: 2.917124, top_1: 0.531055, top_k: 0.764102, samples/s: 784.855 1613238943.357109
train: epoch 14, iter 400, loss: 3.063522, top_1: 0.524570, top_k: 0.761953, samples/s: 779.084 1613238976.2162635
train: epoch 14, iter 500, loss: 2.731749, top_1: 0.540000, top_k: 0.771289, samples/s: 780.964 1613239008.996198
train: epoch 14, iter 600, loss: 3.055412, top_1: 0.527969, top_k: 0.764883, samples/s: 780.382 1613239041.8006191
train: epoch 14, iter 700, loss: 3.089674, top_1: 0.526953, top_k: 0.766016, samples/s: 783.903 1613239074.4577014
train: epoch 14, iter 800, loss: 2.937169, top_1: 0.527617, top_k: 0.763008, samples/s: 777.777 1613239107.3725204
train: epoch 14, iter 900, loss: 2.941098, top_1: 0.527383, top_k: 0.766836, samples/s: 782.175 1613239140.1013377
train: epoch 14, iter 1000, loss: 2.965487, top_1: 0.528984, top_k: 0.765664, samples/s: 779.059 1613239172.961439
train: epoch 14, iter 1100, loss: 2.837857, top_1: 0.522891, top_k: 0.765273, samples/s: 780.888 1613239205.7446136
train: epoch 14, iter 1200, loss: 3.015687, top_1: 0.529297, top_k: 0.764258, samples/s: 785.383 1613239238.3402214
train: epoch 14, iter 1300, loss: 2.997597, top_1: 0.526836, top_k: 0.763320, samples/s: 780.904 1613239271.123066
train: epoch 14, iter 1400, loss: 3.120179, top_1: 0.519336, top_k: 0.762305, samples/s: 784.715 1613239303.7460704
train: epoch 14, iter 1500, loss: 2.922283, top_1: 0.531836, top_k: 0.765273, samples/s: 780.873 1613239336.5298862
train: epoch 14, iter 1600, loss: 2.734684, top_1: 0.527031, top_k: 0.761172, samples/s: 782.945 1613239369.2268891
train: epoch 14, iter 1700, loss: 3.031852, top_1: 0.531836, top_k: 0.765156, samples/s: 784.630 1613239401.853824
train: epoch 14, iter 1800, loss: 2.997427, top_1: 0.526289, top_k: 0.760547, samples/s: 781.274 1613239434.6207952
train: epoch 14, iter 1900, loss: 3.103537, top_1: 0.526719, top_k: 0.759883, samples/s: 781.395 1613239467.3826096
train: epoch 14, iter 2000, loss: 2.895643, top_1: 0.528984, top_k: 0.761211, samples/s: 783.934 1613239500.0384731
train: epoch 14, iter 2100, loss: 3.099729, top_1: 0.530703, top_k: 0.762422, samples/s: 780.318 1613239532.8455985
train: epoch 14, iter 2200, loss: 3.010029, top_1: 0.525859, top_k: 0.765859, samples/s: 786.330 1613239565.4019156
train: epoch 14, iter 2300, loss: 2.833457, top_1: 0.530664, top_k: 0.764102, samples/s: 781.253 1613239598.16985
train: epoch 14, iter 2400, loss: 2.856227, top_1: 0.526133, top_k: 0.759492, samples/s: 781.485 1613239630.9279377
train: epoch 14, iter 2500, loss: 3.062489, top_1: 0.525625, top_k: 0.762305, samples/s: 780.804 1613239663.7146924
train: epoch 14, iter 2600, loss: 3.020996, top_1: 0.527344, top_k: 0.765039, samples/s: 784.531 1613239696.345613
train: epoch 14, iter 2700, loss: 2.914829, top_1: 0.529062, top_k: 0.763359, samples/s: 782.264 1613239729.0711493
train: epoch 14, iter 2800, loss: 2.981375, top_1: 0.527773, top_k: 0.765625, samples/s: 782.546 1613239761.7848384
train: epoch 14, iter 2900, loss: 3.127665, top_1: 0.525625, top_k: 0.761523, samples/s: 781.331 1613239794.54947
train: epoch 14, iter 3000, loss: 3.086878, top_1: 0.524883, top_k: 0.759492, samples/s: 784.668 1613239827.1747627
train: epoch 14, iter 3100, loss: 2.969564, top_1: 0.526250, top_k: 0.761797, samples/s: 781.982 1613239859.912099
train: epoch 14, iter 3200, loss: 3.069673, top_1: 0.524062, top_k: 0.762148, samples/s: 784.143 1613239892.5592136
train: epoch 14, iter 3300, loss: 2.792656, top_1: 0.519648, top_k: 0.760273, samples/s: 780.881 1613239925.3427074
train: epoch 14, iter 3400, loss: 2.957369, top_1: 0.538164, top_k: 0.766875, samples/s: 781.801 1613239958.08764
train: epoch 14, iter 3500, loss: 2.956244, top_1: 0.527227, top_k: 0.761953, samples/s: 781.377 1613239990.8501525
train: epoch 14, iter 3600, loss: 3.088276, top_1: 0.522109, top_k: 0.758359, samples/s: 786.132 1613240023.4147425
train: epoch 14, iter 3700, loss: 2.914178, top_1: 0.521797, top_k: 0.760000, samples/s: 781.801 1613240056.159588
train: epoch 14, iter 3800, loss: 3.057500, top_1: 0.529883, top_k: 0.764609, samples/s: 782.287 1613240088.8841908
train: epoch 14, iter 3900, loss: 2.951158, top_1: 0.518789, top_k: 0.758945, samples/s: 784.597 1613240121.5123098
train: epoch 14, iter 4000, loss: 3.029737, top_1: 0.523477, top_k: 0.761406, samples/s: 781.555 1613240154.2676132
train: epoch 14, iter 4100, loss: 3.065861, top_1: 0.521133, top_k: 0.761328, samples/s: 782.483 1613240186.9839413
train: epoch 14, iter 4200, loss: 3.183464, top_1: 0.525742, top_k: 0.762617, samples/s: 781.049 1613240219.7603157
train: epoch 14, iter 4300, loss: 3.088529, top_1: 0.528008, top_k: 0.767266, samples/s: 783.116 1613240252.450407
train: epoch 14, iter 4400, loss: 2.890650, top_1: 0.522656, top_k: 0.758906, samples/s: 780.264 1613240285.2597702
train: epoch 14, iter 4500, loss: 3.023602, top_1: 0.527813, top_k: 0.761523, samples/s: 783.402 1613240317.9376733
train: epoch 14, iter 4600, loss: 3.038090, top_1: 0.526602, top_k: 0.764648, samples/s: 781.225 1613240350.7067375
train: epoch 14, iter 4700, loss: 3.274241, top_1: 0.523164, top_k: 0.758047, samples/s: 784.162 1613240383.3530707
train: epoch 14, iter 4800, loss: 3.186867, top_1: 0.526523, top_k: 0.762617, samples/s: 783.070 1613240416.044899
train: epoch 14, iter 4900, loss: 2.900389, top_1: 0.530664, top_k: 0.763477, samples/s: 783.525 1613240448.7177904
train: epoch 14, iter 5000, loss: 2.889421, top_1: 0.530937, top_k: 0.766445, samples/s: 781.168 1613240481.4891438
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_14.
validation: epoch 14, iter 195, top_1: 0.571234, top_k: 0.815625, samples/s: 2347.647 1613240503.7366083
train: epoch 15, iter 100, loss: 2.978991, top_1: 0.538047, top_k: 0.768984, samples/s: 805.499 1613240556.1313317
train: epoch 15, iter 200, loss: 2.912561, top_1: 0.528320, top_k: 0.767656, samples/s: 799.358 1613240588.1569684
train: epoch 15, iter 300, loss: 2.979178, top_1: 0.536484, top_k: 0.767891, samples/s: 785.251 1613240620.7582126
train: epoch 15, iter 400, loss: 3.171242, top_1: 0.533906, top_k: 0.763594, samples/s: 779.414 1613240653.6032643
train: epoch 15, iter 500, loss: 2.935079, top_1: 0.540391, top_k: 0.774414, samples/s: 782.837 1613240686.3047354
train: epoch 15, iter 600, loss: 2.837745, top_1: 0.539609, top_k: 0.775039, samples/s: 778.979 1613240719.1682887
train: epoch 15, iter 700, loss: 2.851816, top_1: 0.528516, top_k: 0.763516, samples/s: 780.349 1613240751.9740996
train: epoch 15, iter 800, loss: 2.792833, top_1: 0.524297, top_k: 0.762617, samples/s: 784.028 1613240784.6260939
train: epoch 15, iter 900, loss: 2.851307, top_1: 0.533320, top_k: 0.768828, samples/s: 780.285 1613240817.434601
train: epoch 15, iter 1000, loss: 2.904386, top_1: 0.532617, top_k: 0.767891, samples/s: 782.063 1613240850.1685317
train: epoch 15, iter 1100, loss: 2.892030, top_1: 0.535273, top_k: 0.770859, samples/s: 780.270 1613240882.9775786
train: epoch 15, iter 1200, loss: 2.876444, top_1: 0.530586, top_k: 0.769805, samples/s: 781.000 1613240915.7561321
train: epoch 15, iter 1300, loss: 3.004272, top_1: 0.533867, top_k: 0.768594, samples/s: 783.784 1613240948.4181166
train: epoch 15, iter 1400, loss: 2.926349, top_1: 0.532227, top_k: 0.767695, samples/s: 779.166 1613240981.2738612
train: epoch 15, iter 1500, loss: 2.814276, top_1: 0.529766, top_k: 0.766992, samples/s: 780.940 1613241014.0548337
train: epoch 15, iter 1600, loss: 3.098500, top_1: 0.532461, top_k: 0.767891, samples/s: 782.381 1613241046.7754772
train: epoch 15, iter 1700, loss: 2.861691, top_1: 0.528398, top_k: 0.765391, samples/s: 783.562 1613241079.446773
train: epoch 15, iter 1800, loss: 3.163267, top_1: 0.529023, top_k: 0.765430, samples/s: 781.145 1613241112.2191167
train: epoch 15, iter 1900, loss: 3.113366, top_1: 0.525156, top_k: 0.761250, samples/s: 783.046 1613241144.912024
train: epoch 15, iter 2000, loss: 2.856899, top_1: 0.528047, top_k: 0.763984, samples/s: 780.397 1613241177.7157917
train: epoch 15, iter 2100, loss: 2.925567, top_1: 0.536953, top_k: 0.769766, samples/s: 783.698 1613241210.3815114
train: epoch 15, iter 2200, loss: 3.057324, top_1: 0.531094, top_k: 0.767539, samples/s: 780.161 1613241243.1951962
train: epoch 15, iter 2300, loss: 3.000896, top_1: 0.529414, top_k: 0.765625, samples/s: 783.458 1613241275.870918
train: epoch 15, iter 2400, loss: 2.826853, top_1: 0.525625, top_k: 0.762930, samples/s: 783.472 1613241308.5460043
train: epoch 15, iter 2500, loss: 2.969080, top_1: 0.523477, top_k: 0.761914, samples/s: 782.704 1613241341.2531917
train: epoch 15, iter 2600, loss: 2.892052, top_1: 0.533477, top_k: 0.766406, samples/s: 780.749 1613241374.0422163
train: epoch 15, iter 2700, loss: 2.833165, top_1: 0.529062, top_k: 0.768672, samples/s: 783.820 1613241406.7027397
train: epoch 15, iter 2800, loss: 3.345196, top_1: 0.530352, top_k: 0.763047, samples/s: 782.125 1613241439.4340336
train: epoch 15, iter 2900, loss: 2.944013, top_1: 0.524219, top_k: 0.764727, samples/s: 782.468 1613241472.151035
train: epoch 15, iter 3000, loss: 2.815951, top_1: 0.526641, top_k: 0.761367, samples/s: 781.419 1613241504.9119277
train: epoch 15, iter 3100, loss: 3.245814, top_1: 0.531289, top_k: 0.764062, samples/s: 779.749 1613241537.7431087
train: epoch 15, iter 3200, loss: 2.873032, top_1: 0.530273, top_k: 0.766875, samples/s: 783.876 1613241570.4013608
train: epoch 15, iter 3300, loss: 2.909538, top_1: 0.532422, top_k: 0.768633, samples/s: 782.460 1613241603.118607
train: epoch 15, iter 3400, loss: 2.836411, top_1: 0.528633, top_k: 0.763125, samples/s: 780.472 1613241635.9192643
train: epoch 15, iter 3500, loss: 2.865221, top_1: 0.519141, top_k: 0.762891, samples/s: 782.392 1613241668.6394794
train: epoch 15, iter 3600, loss: 2.877022, top_1: 0.528594, top_k: 0.764922, samples/s: 781.608 1613241701.3924682
train: epoch 15, iter 3700, loss: 2.857794, top_1: 0.529219, top_k: 0.764102, samples/s: 783.795 1613241734.0540376
train: epoch 15, iter 3800, loss: 2.904658, top_1: 0.524922, top_k: 0.761836, samples/s: 781.513 1613241766.810993
train: epoch 15, iter 3900, loss: 2.961668, top_1: 0.527852, top_k: 0.762227, samples/s: 780.333 1613241799.6174974
train: epoch 15, iter 4000, loss: 2.827682, top_1: 0.529258, top_k: 0.763359, samples/s: 782.435 1613241832.3359528
train: epoch 15, iter 4100, loss: 2.809523, top_1: 0.527852, top_k: 0.766523, samples/s: 784.306 1613241864.9762719
train: epoch 15, iter 4200, loss: 2.897903, top_1: 0.525977, top_k: 0.765977, samples/s: 780.481 1613241897.776531
train: epoch 15, iter 4300, loss: 2.892028, top_1: 0.526875, top_k: 0.765859, samples/s: 779.538 1613241930.6165323
train: epoch 15, iter 4400, loss: 2.833703, top_1: 0.529844, top_k: 0.763164, samples/s: 782.468 1613241963.3335292
train: epoch 15, iter 4500, loss: 2.831681, top_1: 0.528477, top_k: 0.765469, samples/s: 784.048 1613241995.9845424
train: epoch 15, iter 4600, loss: 2.843015, top_1: 0.524023, top_k: 0.763555, samples/s: 777.754 1613242028.899794
train: epoch 15, iter 4700, loss: 2.928377, top_1: 0.527031, top_k: 0.761953, samples/s: 783.901 1613242061.5570745
train: epoch 15, iter 4800, loss: 3.033953, top_1: 0.530156, top_k: 0.764844, samples/s: 781.695 1613242094.3064194
train: epoch 15, iter 4900, loss: 2.978136, top_1: 0.524180, top_k: 0.761523, samples/s: 781.884 1613242127.0477748
train: epoch 15, iter 5000, loss: 2.854885, top_1: 0.532500, top_k: 0.768008, samples/s: 781.270 1613242159.8149853
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_15.
validation: epoch 15, iter 195, top_1: 0.575641, top_k: 0.818530, samples/s: 2340.737 1613242182.1117494
train: epoch 16, iter 100, loss: 2.891888, top_1: 0.548047, top_k: 0.780039, samples/s: 803.674 1613242234.5474663
train: epoch 16, iter 200, loss: 2.937041, top_1: 0.543477, top_k: 0.774922, samples/s: 800.614 1613242266.5230448
train: epoch 16, iter 300, loss: 2.870081, top_1: 0.538516, top_k: 0.772695, samples/s: 785.461 1613242299.1151104
train: epoch 16, iter 400, loss: 2.986872, top_1: 0.539648, top_k: 0.769648, samples/s: 776.353 1613242332.089724
train: epoch 16, iter 500, loss: 2.947635, top_1: 0.537891, top_k: 0.771172, samples/s: 779.849 1613242364.9167035
train: epoch 16, iter 600, loss: 2.954162, top_1: 0.539375, top_k: 0.774687, samples/s: 782.323 1613242397.639743
train: epoch 16, iter 700, loss: 2.962093, top_1: 0.532734, top_k: 0.766602, samples/s: 781.115 1613242430.413652
train: epoch 16, iter 800, loss: 2.867236, top_1: 0.531211, top_k: 0.770625, samples/s: 778.600 1613242463.2929616
train: epoch 16, iter 900, loss: 3.057013, top_1: 0.545586, top_k: 0.773086, samples/s: 784.857 1613242495.9108295
train: epoch 16, iter 1000, loss: 2.792263, top_1: 0.539570, top_k: 0.772188, samples/s: 779.655 1613242528.7454467
train: epoch 16, iter 1100, loss: 2.855381, top_1: 0.540742, top_k: 0.770469, samples/s: 780.245 1613242561.5556464
train: epoch 16, iter 1200, loss: 3.121106, top_1: 0.539336, top_k: 0.775078, samples/s: 779.048 1613242594.416241
train: epoch 16, iter 1300, loss: 2.858864, top_1: 0.535117, top_k: 0.767930, samples/s: 781.605 1613242627.1693826
train: epoch 16, iter 1400, loss: 2.970942, top_1: 0.528359, top_k: 0.763086, samples/s: 781.352 1613242659.9330516
train: epoch 16, iter 1500, loss: 2.927112, top_1: 0.533047, top_k: 0.768437, samples/s: 779.280 1613242692.7839456
train: epoch 16, iter 1600, loss: 2.881055, top_1: 0.529922, top_k: 0.767109, samples/s: 780.864 1613242725.5680382
train: epoch 16, iter 1700, loss: 3.140748, top_1: 0.530898, top_k: 0.767383, samples/s: 780.667 1613242758.360574
train: epoch 16, iter 1800, loss: 3.100312, top_1: 0.529922, top_k: 0.769258, samples/s: 781.532 1613242791.1172013
train: epoch 16, iter 1900, loss: 3.113279, top_1: 0.533281, top_k: 0.768437, samples/s: 782.174 1613242823.8460426
train: epoch 16, iter 2000, loss: 2.927795, top_1: 0.536133, top_k: 0.769492, samples/s: 779.003 1613242856.7089097
train: epoch 16, iter 2100, loss: 3.099484, top_1: 0.533047, top_k: 0.768516, samples/s: 781.354 1613242889.4721892
train: epoch 16, iter 2200, loss: 3.049986, top_1: 0.535937, top_k: 0.770664, samples/s: 782.124 1613242922.2035706
train: epoch 16, iter 2300, loss: 2.806509, top_1: 0.530469, top_k: 0.768242, samples/s: 781.767 1613242954.9499505
train: epoch 16, iter 2400, loss: 2.957934, top_1: 0.529492, top_k: 0.763750, samples/s: 781.581 1613242987.7040832
train: epoch 16, iter 2500, loss: 2.996402, top_1: 0.528047, top_k: 0.767148, samples/s: 781.288 1613243020.4704216
train: epoch 16, iter 2600, loss: 2.883995, top_1: 0.534609, top_k: 0.767148, samples/s: 781.198 1613243053.2406366
train: epoch 16, iter 2700, loss: 3.031013, top_1: 0.531055, top_k: 0.766250, samples/s: 782.402 1613243085.9603224
train: epoch 16, iter 2800, loss: 2.885874, top_1: 0.526328, top_k: 0.766328, samples/s: 781.710 1613243118.7091253
train: epoch 16, iter 2900, loss: 2.991480, top_1: 0.537422, top_k: 0.766797, samples/s: 778.703 1613243151.5843828
train: epoch 16, iter 3000, loss: 2.899404, top_1: 0.535742, top_k: 0.770000, samples/s: 783.414 1613243184.2618532
train: epoch 16, iter 3100, loss: 2.815871, top_1: 0.529648, top_k: 0.768242, samples/s: 782.467 1613243216.978809
train: epoch 16, iter 3200, loss: 3.022521, top_1: 0.538477, top_k: 0.770820, samples/s: 781.259 1613243249.7464855
train: epoch 16, iter 3300, loss: 3.024114, top_1: 0.531719, top_k: 0.763789, samples/s: 781.433 1613243282.506748
train: epoch 16, iter 3400, loss: 2.801071, top_1: 0.536680, top_k: 0.770508, samples/s: 785.063 1613243315.115593
train: epoch 16, iter 3500, loss: 3.099165, top_1: 0.532734, top_k: 0.770664, samples/s: 778.893 1613243347.982803
train: epoch 16, iter 3600, loss: 3.020152, top_1: 0.527383, top_k: 0.765039, samples/s: 783.151 1613243380.6712253
train: epoch 16, iter 3700, loss: 2.957390, top_1: 0.533320, top_k: 0.763164, samples/s: 782.336 1613243413.3937397
train: epoch 16, iter 3800, loss: 2.914104, top_1: 0.523945, top_k: 0.761289, samples/s: 780.860 1613243446.178559
train: epoch 16, iter 3900, loss: 2.845213, top_1: 0.534141, top_k: 0.766289, samples/s: 781.909 1613243478.91856
train: epoch 16, iter 4000, loss: 2.831506, top_1: 0.530352, top_k: 0.769961, samples/s: 782.653 1613243511.6283038
train: epoch 16, iter 4100, loss: 2.985749, top_1: 0.529258, top_k: 0.761563, samples/s: 782.442 1613243544.3458498
train: epoch 16, iter 4200, loss: 2.849695, top_1: 0.531680, top_k: 0.765117, samples/s: 782.236 1613243577.0725052
train: epoch 16, iter 4300, loss: 2.993611, top_1: 0.534805, top_k: 0.764414, samples/s: 780.983 1613243609.851777
train: epoch 16, iter 4400, loss: 2.986085, top_1: 0.530469, top_k: 0.765195, samples/s: 781.526 1613243642.6082249
train: epoch 16, iter 4500, loss: 2.854615, top_1: 0.533594, top_k: 0.768945, samples/s: 781.086 1613243675.3829858
train: epoch 16, iter 4600, loss: 2.879061, top_1: 0.527578, top_k: 0.763750, samples/s: 780.010 1613243708.2031944
train: epoch 16, iter 4700, loss: 2.832083, top_1: 0.533945, top_k: 0.770234, samples/s: 782.825 1613243740.9052553
train: epoch 16, iter 4800, loss: 3.029393, top_1: 0.534883, top_k: 0.767539, samples/s: 779.098 1613243773.7637758
train: epoch 16, iter 4900, loss: 3.012083, top_1: 0.533203, top_k: 0.765195, samples/s: 784.141 1613243806.4109478
train: epoch 16, iter 5000, loss: 2.936035, top_1: 0.532539, top_k: 0.766133, samples/s: 779.796 1613243839.2400172
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_16.
validation: epoch 16, iter 195, top_1: 0.588962, top_k: 0.827704, samples/s: 2326.149 1613243861.6741378
train: epoch 17, iter 100, loss: 3.072766, top_1: 0.538516, top_k: 0.773203, samples/s: 803.990 1613243915.1346982
train: epoch 17, iter 200, loss: 2.876147, top_1: 0.548242, top_k: 0.776445, samples/s: 801.442 1613243947.0770063
train: epoch 17, iter 300, loss: 3.035438, top_1: 0.540781, top_k: 0.775586, samples/s: 785.685 1613243979.6601274
train: epoch 17, iter 400, loss: 2.729432, top_1: 0.536602, top_k: 0.772031, samples/s: 779.921 1613244012.483878
train: epoch 17, iter 500, loss: 3.038993, top_1: 0.542188, top_k: 0.774141, samples/s: 779.876 1613244045.3095887
train: epoch 17, iter 600, loss: 3.061877, top_1: 0.537070, top_k: 0.767227, samples/s: 781.893 1613244078.050743
train: epoch 17, iter 700, loss: 3.112293, top_1: 0.537930, top_k: 0.770000, samples/s: 779.600 1613244110.8880203
train: epoch 17, iter 800, loss: 2.915469, top_1: 0.535273, top_k: 0.769531, samples/s: 784.156 1613244143.5346582
train: epoch 17, iter 900, loss: 2.880321, top_1: 0.539375, top_k: 0.774687, samples/s: 781.043 1613244176.3112829
train: epoch 17, iter 1000, loss: 2.828165, top_1: 0.536367, top_k: 0.771211, samples/s: 779.442 1613244209.1552994
train: epoch 17, iter 1100, loss: 2.874861, top_1: 0.542617, top_k: 0.772930, samples/s: 780.428 1613244241.9578183
train: epoch 17, iter 1200, loss: 3.032708, top_1: 0.538320, top_k: 0.773125, samples/s: 783.379 1613244274.636738
train: epoch 17, iter 1300, loss: 3.024097, top_1: 0.538828, top_k: 0.769297, samples/s: 779.841 1613244307.4640043
train: epoch 17, iter 1400, loss: 2.806994, top_1: 0.535664, top_k: 0.771641, samples/s: 780.493 1613244340.2637033
train: epoch 17, iter 1500, loss: 2.936052, top_1: 0.539844, top_k: 0.770156, samples/s: 783.391 1613244372.9422524
train: epoch 17, iter 1600, loss: 3.023969, top_1: 0.538633, top_k: 0.773359, samples/s: 782.254 1613244405.6681898
train: epoch 17, iter 1700, loss: 3.138488, top_1: 0.536758, top_k: 0.767578, samples/s: 780.985 1613244438.4473088
train: epoch 17, iter 1800, loss: 2.987898, top_1: 0.533906, top_k: 0.772148, samples/s: 779.458 1613244471.290601
train: epoch 17, iter 1900, loss: 2.763699, top_1: 0.535273, top_k: 0.772422, samples/s: 779.673 1613244504.125357
train: epoch 17, iter 2000, loss: 3.068535, top_1: 0.540586, top_k: 0.771445, samples/s: 782.939 1613244536.8222039
train: epoch 17, iter 2100, loss: 3.055494, top_1: 0.536055, top_k: 0.772305, samples/s: 783.065 1613244569.5145743
train: epoch 17, iter 2200, loss: 2.933625, top_1: 0.540547, top_k: 0.770820, samples/s: 781.135 1613244602.2870836
train: epoch 17, iter 2300, loss: 2.718745, top_1: 0.535859, top_k: 0.770391, samples/s: 781.308 1613244635.0526383
train: epoch 17, iter 2400, loss: 3.041473, top_1: 0.545312, top_k: 0.775859, samples/s: 782.717 1613244667.7591848
train: epoch 17, iter 2500, loss: 2.905993, top_1: 0.535742, top_k: 0.767852, samples/s: 776.548 1613244700.725609
train: epoch 17, iter 2600, loss: 2.979832, top_1: 0.536094, top_k: 0.768047, samples/s: 782.355 1613244733.4472954
train: epoch 17, iter 2700, loss: 2.678785, top_1: 0.536680, top_k: 0.771992, samples/s: 779.157 1613244766.3034046
train: epoch 17, iter 2800, loss: 2.768550, top_1: 0.537852, top_k: 0.770859, samples/s: 781.494 1613244799.0610645
train: epoch 17, iter 2900, loss: 3.053478, top_1: 0.535078, top_k: 0.770117, samples/s: 780.502 1613244831.8605525
train: epoch 17, iter 3000, loss: 2.892586, top_1: 0.538594, top_k: 0.768477, samples/s: 781.348 1613244864.6244166
train: epoch 17, iter 3100, loss: 2.803071, top_1: 0.534727, top_k: 0.769570, samples/s: 779.883 1613244897.4498696
train: epoch 17, iter 3200, loss: 2.977505, top_1: 0.535000, top_k: 0.768594, samples/s: 781.637 1613244930.2015498
train: epoch 17, iter 3300, loss: 2.861057, top_1: 0.535859, top_k: 0.768047, samples/s: 780.299 1613244963.0095646
train: epoch 17, iter 3400, loss: 2.667320, top_1: 0.539570, top_k: 0.771719, samples/s: 783.484 1613244995.6840942
train: epoch 17, iter 3500, loss: 2.805116, top_1: 0.533984, top_k: 0.767773, samples/s: 780.195 1613245028.4964814
train: epoch 17, iter 3600, loss: 2.817741, top_1: 0.536836, top_k: 0.771328, samples/s: 781.970 1613245061.2342446
train: epoch 17, iter 3700, loss: 2.694508, top_1: 0.537148, top_k: 0.771719, samples/s: 781.376 1613245093.9968896
train: epoch 17, iter 3800, loss: 2.858616, top_1: 0.535664, top_k: 0.770508, samples/s: 781.604 1613245126.7500994
train: epoch 17, iter 3900, loss: 3.026418, top_1: 0.533281, top_k: 0.769844, samples/s: 781.113 1613245159.5237732
train: epoch 17, iter 4000, loss: 3.029139, top_1: 0.532813, top_k: 0.765859, samples/s: 782.099 1613245192.2562416
train: epoch 17, iter 4100, loss: 2.964241, top_1: 0.541406, top_k: 0.771875, samples/s: 782.861 1613245224.9567602
train: epoch 17, iter 4200, loss: 2.928990, top_1: 0.535586, top_k: 0.767031, samples/s: 780.981 1613245257.7361574
train: epoch 17, iter 4300, loss: 3.010171, top_1: 0.534727, top_k: 0.770234, samples/s: 781.014 1613245290.5139208
train: epoch 17, iter 4400, loss: 3.099831, top_1: 0.533281, top_k: 0.769297, samples/s: 779.866 1613245323.3400865
train: epoch 17, iter 4500, loss: 2.830024, top_1: 0.535625, top_k: 0.768281, samples/s: 780.928 1613245356.1216724
train: epoch 17, iter 4600, loss: 3.005596, top_1: 0.535273, top_k: 0.773047, samples/s: 781.459 1613245388.8808079
train: epoch 17, iter 4700, loss: 2.967652, top_1: 0.538867, top_k: 0.768789, samples/s: 782.287 1613245421.6054392
train: epoch 17, iter 4800, loss: 2.931851, top_1: 0.534727, top_k: 0.770273, samples/s: 780.161 1613245454.419208
train: epoch 17, iter 4900, loss: 3.054091, top_1: 0.537734, top_k: 0.771758, samples/s: 780.100 1613245487.2354774
train: epoch 17, iter 5000, loss: 2.992932, top_1: 0.533008, top_k: 0.768320, samples/s: 784.080 1613245519.8852205
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_17.
validation: epoch 17, iter 195, top_1: 0.589724, top_k: 0.825381, samples/s: 2397.274 1613245541.6842675
train: epoch 18, iter 100, loss: 2.909447, top_1: 0.545352, top_k: 0.774648, samples/s: 804.720 1613245594.1823545
train: epoch 18, iter 200, loss: 2.877845, top_1: 0.542656, top_k: 0.778281, samples/s: 799.245 1613245626.2126036
train: epoch 18, iter 300, loss: 3.018213, top_1: 0.538047, top_k: 0.770469, samples/s: 781.923 1613245658.9523218
train: epoch 18, iter 400, loss: 2.977625, top_1: 0.545664, top_k: 0.774570, samples/s: 778.583 1613245691.8325696
train: epoch 18, iter 500, loss: 2.866993, top_1: 0.546328, top_k: 0.777500, samples/s: 781.672 1613245724.582862
train: epoch 18, iter 600, loss: 2.884169, top_1: 0.543516, top_k: 0.779297, samples/s: 779.273 1613245757.4340413
train: epoch 18, iter 700, loss: 2.910133, top_1: 0.540820, top_k: 0.776602, samples/s: 777.836 1613245790.3463278
train: epoch 18, iter 800, loss: 3.045029, top_1: 0.539453, top_k: 0.771914, samples/s: 783.180 1613245823.0331564
train: epoch 18, iter 900, loss: 2.989108, top_1: 0.540391, top_k: 0.776016, samples/s: 776.598 1613245855.9977717
train: epoch 18, iter 1000, loss: 2.696996, top_1: 0.542734, top_k: 0.780508, samples/s: 780.947 1613245888.7781358
train: epoch 18, iter 1100, loss: 2.802486, top_1: 0.548477, top_k: 0.775039, samples/s: 779.242 1613245921.6305523
train: epoch 18, iter 1200, loss: 2.931947, top_1: 0.540156, top_k: 0.776211, samples/s: 779.618 1613245954.467105
train: epoch 18, iter 1300, loss: 2.805931, top_1: 0.538672, top_k: 0.770977, samples/s: 781.826 1613245987.2109754
train: epoch 18, iter 1400, loss: 3.113127, top_1: 0.531016, top_k: 0.770781, samples/s: 778.075 1613246020.1126966
train: epoch 18, iter 1500, loss: 2.962330, top_1: 0.548281, top_k: 0.776289, samples/s: 779.764 1613246052.9430723
train: epoch 18, iter 1600, loss: 2.913251, top_1: 0.546211, top_k: 0.778086, samples/s: 782.045 1613246085.677779
train: epoch 18, iter 1700, loss: 2.991822, top_1: 0.542539, top_k: 0.771289, samples/s: 783.649 1613246118.345484
train: epoch 18, iter 1800, loss: 2.974535, top_1: 0.539102, top_k: 0.771914, samples/s: 782.567 1613246151.0584092
train: epoch 18, iter 1900, loss: 2.797737, top_1: 0.538594, top_k: 0.769453, samples/s: 780.150 1613246183.8725665
train: epoch 18, iter 2000, loss: 2.838645, top_1: 0.546641, top_k: 0.773203, samples/s: 781.928 1613246216.6121132
train: epoch 18, iter 2100, loss: 2.864321, top_1: 0.541797, top_k: 0.774766, samples/s: 782.920 1613246249.310129
train: epoch 18, iter 2200, loss: 2.856399, top_1: 0.535156, top_k: 0.771055, samples/s: 780.652 1613246282.103341
train: epoch 18, iter 2300, loss: 2.753701, top_1: 0.535508, top_k: 0.770430, samples/s: 782.856 1613246314.8040245
train: epoch 18, iter 2400, loss: 2.907835, top_1: 0.535391, top_k: 0.769102, samples/s: 780.295 1613246347.612317
train: epoch 18, iter 2500, loss: 2.947481, top_1: 0.543711, top_k: 0.777813, samples/s: 780.190 1613246380.4246643
train: epoch 18, iter 2600, loss: 2.947802, top_1: 0.541719, top_k: 0.773906, samples/s: 779.678 1613246413.2587755
train: epoch 18, iter 2700, loss: 3.040675, top_1: 0.542500, top_k: 0.776250, samples/s: 780.951 1613246446.039367
train: epoch 18, iter 2800, loss: 3.053705, top_1: 0.539414, top_k: 0.774375, samples/s: 779.982 1613246478.860622
train: epoch 18, iter 2900, loss: 2.766866, top_1: 0.543438, top_k: 0.769922, samples/s: 783.067 1613246511.5525584
train: epoch 18, iter 3000, loss: 2.820416, top_1: 0.543555, top_k: 0.774023, samples/s: 780.471 1613246544.3532717
train: epoch 18, iter 3100, loss: 3.138894, top_1: 0.541445, top_k: 0.777383, samples/s: 780.229 1613246577.1642158
train: epoch 18, iter 3200, loss: 3.108918, top_1: 0.543750, top_k: 0.772617, samples/s: 783.551 1613246609.8359098
train: epoch 18, iter 3300, loss: 3.053090, top_1: 0.536875, top_k: 0.773945, samples/s: 779.697 1613246642.6692576
train: epoch 18, iter 3400, loss: 3.130412, top_1: 0.536250, top_k: 0.771758, samples/s: 781.141 1613246675.4417493
train: epoch 18, iter 3500, loss: 2.952564, top_1: 0.539453, top_k: 0.770742, samples/s: 782.649 1613246708.1511567
train: epoch 18, iter 3600, loss: 2.778809, top_1: 0.545273, top_k: 0.775352, samples/s: 781.445 1613246740.910951
train: epoch 18, iter 3700, loss: 2.778443, top_1: 0.542383, top_k: 0.778320, samples/s: 782.274 1613246773.6360962
train: epoch 18, iter 3800, loss: 2.961400, top_1: 0.539570, top_k: 0.776055, samples/s: 779.837 1613246806.4635258
train: epoch 18, iter 3900, loss: 2.974249, top_1: 0.538008, top_k: 0.773789, samples/s: 780.380 1613246839.2679532
train: epoch 18, iter 4000, loss: 2.992437, top_1: 0.539687, top_k: 0.773281, samples/s: 781.305 1613246872.0337548
train: epoch 18, iter 4100, loss: 2.877025, top_1: 0.536055, top_k: 0.768125, samples/s: 779.626 1613246904.8700078
train: epoch 18, iter 4200, loss: 3.003666, top_1: 0.537188, top_k: 0.770781, samples/s: 784.228 1613246937.5135715
train: epoch 18, iter 4300, loss: 2.923230, top_1: 0.537500, top_k: 0.771289, samples/s: 782.152 1613246970.243724
train: epoch 18, iter 4400, loss: 2.942305, top_1: 0.534492, top_k: 0.773164, samples/s: 781.030 1613247003.0210364
train: epoch 18, iter 4500, loss: 2.766811, top_1: 0.542617, top_k: 0.776172, samples/s: 782.169 1613247035.7505248
train: epoch 18, iter 4600, loss: 3.201585, top_1: 0.537891, top_k: 0.774375, samples/s: 779.425 1613247068.595311
train: epoch 18, iter 4700, loss: 2.868672, top_1: 0.539453, top_k: 0.767617, samples/s: 779.774 1613247101.4257736
train: epoch 18, iter 4800, loss: 2.836970, top_1: 0.540586, top_k: 0.773320, samples/s: 784.799 1613247134.045099
train: epoch 18, iter 4900, loss: 2.883975, top_1: 0.536641, top_k: 0.770195, samples/s: 780.190 1613247166.857993
train: epoch 18, iter 5000, loss: 2.950758, top_1: 0.544219, top_k: 0.775820, samples/s: 782.425 1613247199.5764925
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_18.
validation: epoch 18, iter 195, top_1: 0.587580, top_k: 0.827624, samples/s: 2380.430 1613247221.5281184
train: epoch 19, iter 100, loss: 2.919761, top_1: 0.550195, top_k: 0.778320, samples/s: 805.328 1613247273.8594508
train: epoch 19, iter 200, loss: 3.096533, top_1: 0.549258, top_k: 0.778320, samples/s: 799.297 1613247305.8875408
train: epoch 19, iter 300, loss: 3.175140, top_1: 0.544727, top_k: 0.775469, samples/s: 783.676 1613247338.5541031
train: epoch 19, iter 400, loss: 3.071201, top_1: 0.548125, top_k: 0.779609, samples/s: 780.741 1613247371.343754
train: epoch 19, iter 500, loss: 2.885746, top_1: 0.549180, top_k: 0.779766, samples/s: 778.235 1613247404.2383847
train: epoch 19, iter 600, loss: 2.883635, top_1: 0.549258, top_k: 0.782773, samples/s: 780.254 1613247437.0482552
train: epoch 19, iter 700, loss: 2.859967, top_1: 0.540977, top_k: 0.776797, samples/s: 778.904 1613247469.914871
train: epoch 19, iter 800, loss: 2.762484, top_1: 0.546406, top_k: 0.777500, samples/s: 780.285 1613247502.723493
train: epoch 19, iter 900, loss: 2.956423, top_1: 0.547031, top_k: 0.774180, samples/s: 782.222 1613247535.4506986
train: epoch 19, iter 1000, loss: 2.884177, top_1: 0.549453, top_k: 0.779219, samples/s: 778.782 1613247568.3225687
train: epoch 19, iter 1100, loss: 2.899625, top_1: 0.540547, top_k: 0.775742, samples/s: 783.007 1613247601.0170734
train: epoch 19, iter 1200, loss: 2.851058, top_1: 0.543398, top_k: 0.779727, samples/s: 780.441 1613247633.8190076
train: epoch 19, iter 1300, loss: 2.763858, top_1: 0.547148, top_k: 0.778008, samples/s: 781.509 1613247666.5762322
train: epoch 19, iter 1400, loss: 2.752554, top_1: 0.536133, top_k: 0.771914, samples/s: 779.853 1613247699.4028797
train: epoch 19, iter 1500, loss: 2.925733, top_1: 0.543203, top_k: 0.775117, samples/s: 782.338 1613247732.1252766
train: epoch 19, iter 1600, loss: 2.988315, top_1: 0.543594, top_k: 0.775820, samples/s: 777.376 1613247765.0566015
train: epoch 19, iter 1700, loss: 2.873082, top_1: 0.541211, top_k: 0.772383, samples/s: 784.226 1613247797.7002087
train: epoch 19, iter 1800, loss: 3.083587, top_1: 0.537773, top_k: 0.774570, samples/s: 783.501 1613247830.374071
train: epoch 19, iter 1900, loss: 2.888979, top_1: 0.542188, top_k: 0.776875, samples/s: 780.532 1613247863.1721892
train: epoch 19, iter 2000, loss: 2.930589, top_1: 0.537070, top_k: 0.773203, samples/s: 780.610 1613247895.9671087
train: epoch 19, iter 2100, loss: 2.743496, top_1: 0.540078, top_k: 0.771289, samples/s: 781.888 1613247928.7083738
train: epoch 19, iter 2200, loss: 2.907169, top_1: 0.547773, top_k: 0.777656, samples/s: 781.462 1613247961.4674113
train: epoch 19, iter 2300, loss: 2.823894, top_1: 0.549609, top_k: 0.777578, samples/s: 781.424 1613247994.2281086
train: epoch 19, iter 2400, loss: 2.839034, top_1: 0.542891, top_k: 0.777773, samples/s: 781.100 1613248027.0024009
train: epoch 19, iter 2500, loss: 2.994801, top_1: 0.538945, top_k: 0.773789, samples/s: 781.082 1613248059.7774582
train: epoch 19, iter 2600, loss: 2.941494, top_1: 0.537500, top_k: 0.771211, samples/s: 784.151 1613248092.4243162
train: epoch 19, iter 2700, loss: 2.760903, top_1: 0.542148, top_k: 0.772227, samples/s: 780.565 1613248125.2209938
train: epoch 19, iter 2800, loss: 2.894515, top_1: 0.543398, top_k: 0.774336, samples/s: 780.041 1613248158.039853
train: epoch 19, iter 2900, loss: 2.959710, top_1: 0.541445, top_k: 0.774258, samples/s: 781.848 1613248190.7832727
train: epoch 19, iter 3000, loss: 2.977124, top_1: 0.539141, top_k: 0.773047, samples/s: 780.135 1613248223.5975368
train: epoch 19, iter 3100, loss: 2.920646, top_1: 0.535430, top_k: 0.773633, samples/s: 782.972 1613248256.2935083
train: epoch 19, iter 3200, loss: 2.850521, top_1: 0.538867, top_k: 0.771758, samples/s: 778.775 1613248289.165577
train: epoch 19, iter 3300, loss: 2.823813, top_1: 0.535547, top_k: 0.772188, samples/s: 781.489 1613248321.9236038
train: epoch 19, iter 3400, loss: 2.835603, top_1: 0.542109, top_k: 0.777344, samples/s: 780.819 1613248354.7096832
train: epoch 19, iter 3500, loss: 2.977014, top_1: 0.542930, top_k: 0.773477, samples/s: 781.283 1613248387.4766316
train: epoch 19, iter 3600, loss: 2.766137, top_1: 0.543281, top_k: 0.776836, samples/s: 781.495 1613248420.2339551
train: epoch 19, iter 3700, loss: 2.807638, top_1: 0.545625, top_k: 0.778281, samples/s: 780.803 1613248453.0207624
train: epoch 19, iter 3800, loss: 3.001028, top_1: 0.536211, top_k: 0.770273, samples/s: 783.015 1613248485.714947
train: epoch 19, iter 3900, loss: 2.948323, top_1: 0.540273, top_k: 0.772656, samples/s: 777.632 1613248518.635388
train: epoch 19, iter 4000, loss: 2.988138, top_1: 0.546016, top_k: 0.778984, samples/s: 782.344 1613248551.3575513
train: epoch 19, iter 4100, loss: 2.894577, top_1: 0.532031, top_k: 0.768750, samples/s: 782.233 1613248584.0843909
train: epoch 19, iter 4200, loss: 2.983388, top_1: 0.541797, top_k: 0.775781, samples/s: 782.485 1613248616.8006256
train: epoch 19, iter 4300, loss: 2.796238, top_1: 0.543594, top_k: 0.774062, samples/s: 780.794 1613248649.5877845
train: epoch 19, iter 4400, loss: 3.061309, top_1: 0.539297, top_k: 0.775586, samples/s: 781.729 1613248682.3357139
train: epoch 19, iter 4500, loss: 2.946539, top_1: 0.539258, top_k: 0.772227, samples/s: 784.599 1613248714.963787
train: epoch 19, iter 4600, loss: 2.822882, top_1: 0.545937, top_k: 0.776133, samples/s: 779.703 1613248747.796837
train: epoch 19, iter 4700, loss: 2.878358, top_1: 0.545625, top_k: 0.778281, samples/s: 780.922 1613248780.5786412
train: epoch 19, iter 4800, loss: 2.896689, top_1: 0.543398, top_k: 0.772539, samples/s: 780.664 1613248813.3711238
train: epoch 19, iter 4900, loss: 2.963681, top_1: 0.541719, top_k: 0.769844, samples/s: 782.182 1613248846.1000888
train: epoch 19, iter 5000, loss: 2.879538, top_1: 0.540469, top_k: 0.773242, samples/s: 780.651 1613248878.8933094
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_19.
validation: epoch 19, iter 195, top_1: 0.585717, top_k: 0.825921, samples/s: 2340.204 1613248901.201869
train: epoch 20, iter 100, loss: 2.831476, top_1: 0.545977, top_k: 0.780469, samples/s: 803.906 1613248953.792564
train: epoch 20, iter 200, loss: 2.846604, top_1: 0.554844, top_k: 0.781602, samples/s: 800.344 1613248985.7788887
train: epoch 20, iter 300, loss: 2.827306, top_1: 0.554258, top_k: 0.785937, samples/s: 782.992 1613249018.4738336
train: epoch 20, iter 400, loss: 2.972469, top_1: 0.542422, top_k: 0.776641, samples/s: 775.059 1613249051.5035744
train: epoch 20, iter 500, loss: 2.715857, top_1: 0.558828, top_k: 0.783086, samples/s: 783.856 1613249084.1626096
train: epoch 20, iter 600, loss: 2.941195, top_1: 0.555937, top_k: 0.778711, samples/s: 779.421 1613249117.0075152
train: epoch 20, iter 700, loss: 2.784609, top_1: 0.546562, top_k: 0.778945, samples/s: 780.544 1613249149.80524
train: epoch 20, iter 800, loss: 3.040516, top_1: 0.555273, top_k: 0.783398, samples/s: 781.557 1613249182.5603445
train: epoch 20, iter 900, loss: 3.004759, top_1: 0.551992, top_k: 0.782891, samples/s: 780.151 1613249215.3745308
train: epoch 20, iter 1000, loss: 2.600821, top_1: 0.550937, top_k: 0.779180, samples/s: 781.196 1613249248.144713
train: epoch 20, iter 1100, loss: 2.815944, top_1: 0.550039, top_k: 0.780078, samples/s: 780.298 1613249280.9527557
train: epoch 20, iter 1200, loss: 2.836933, top_1: 0.543516, top_k: 0.780000, samples/s: 780.981 1613249313.7320044
train: epoch 20, iter 1300, loss: 2.915942, top_1: 0.543281, top_k: 0.776719, samples/s: 780.306 1613249346.5397553
train: epoch 20, iter 1400, loss: 2.709673, top_1: 0.541875, top_k: 0.775820, samples/s: 782.844 1613249379.2409852
train: epoch 20, iter 1500, loss: 2.926759, top_1: 0.543945, top_k: 0.775547, samples/s: 778.297 1613249412.133256
train: epoch 20, iter 1600, loss: 2.744695, top_1: 0.547656, top_k: 0.776797, samples/s: 783.618 1613249444.802288
train: epoch 20, iter 1700, loss: 3.017550, top_1: 0.542422, top_k: 0.773984, samples/s: 781.758 1613249477.54894
train: epoch 20, iter 1800, loss: 2.852992, top_1: 0.543516, top_k: 0.778477, samples/s: 782.312 1613249510.2725477
train: epoch 20, iter 1900, loss: 3.006357, top_1: 0.550273, top_k: 0.780664, samples/s: 779.345 1613249543.1206295
train: epoch 20, iter 2000, loss: 2.863820, top_1: 0.544648, top_k: 0.779336, samples/s: 780.133 1613249575.9355457
train: epoch 20, iter 2100, loss: 2.893145, top_1: 0.544883, top_k: 0.780117, samples/s: 781.834 1613249608.6790714
train: epoch 20, iter 2200, loss: 2.665665, top_1: 0.545000, top_k: 0.778945, samples/s: 782.042 1613249641.4139204
train: epoch 20, iter 2300, loss: 2.753115, top_1: 0.546289, top_k: 0.776836, samples/s: 782.393 1613249674.1339254
train: epoch 20, iter 2400, loss: 2.931888, top_1: 0.546250, top_k: 0.776289, samples/s: 777.832 1613249707.0459864
train: epoch 20, iter 2500, loss: 2.742530, top_1: 0.550742, top_k: 0.777656, samples/s: 782.961 1613249739.7423258
train: epoch 20, iter 2600, loss: 2.808101, top_1: 0.545859, top_k: 0.778867, samples/s: 783.299 1613249772.424644
train: epoch 20, iter 2700, loss: 2.658232, top_1: 0.546406, top_k: 0.781641, samples/s: 781.211 1613249805.1943283
train: epoch 20, iter 2800, loss: 2.739842, top_1: 0.539414, top_k: 0.775391, samples/s: 781.397 1613249837.9560971
train: epoch 20, iter 2900, loss: 2.949276, top_1: 0.544727, top_k: 0.774336, samples/s: 783.261 1613249870.63997
train: epoch 20, iter 3000, loss: 2.839363, top_1: 0.545000, top_k: 0.778906, samples/s: 779.988 1613249903.461023
train: epoch 20, iter 3100, loss: 2.915473, top_1: 0.546562, top_k: 0.778164, samples/s: 780.596 1613249936.2564168
train: epoch 20, iter 3200, loss: 2.946048, top_1: 0.543359, top_k: 0.779531, samples/s: 781.065 1613249969.0321982
train: epoch 20, iter 3300, loss: 2.992027, top_1: 0.542578, top_k: 0.773945, samples/s: 781.288 1613250001.7986484
train: epoch 20, iter 3400, loss: 2.681255, top_1: 0.537344, top_k: 0.776836, samples/s: 782.698 1613250034.5059524
train: epoch 20, iter 3500, loss: 2.827599, top_1: 0.546250, top_k: 0.777383, samples/s: 780.884 1613250067.28931
train: epoch 20, iter 3600, loss: 3.172481, top_1: 0.542578, top_k: 0.778242, samples/s: 783.228 1613250099.974616
train: epoch 20, iter 3700, loss: 2.896060, top_1: 0.537188, top_k: 0.769336, samples/s: 779.510 1613250132.815772
train: epoch 20, iter 3800, loss: 2.666972, top_1: 0.545547, top_k: 0.769492, samples/s: 781.827 1613250165.5595572
train: epoch 20, iter 3900, loss: 2.919082, top_1: 0.543047, top_k: 0.776094, samples/s: 781.977 1613250198.2971246
train: epoch 20, iter 4000, loss: 2.638433, top_1: 0.541367, top_k: 0.773672, samples/s: 780.817 1613250231.0831854
train: epoch 20, iter 4100, loss: 2.869603, top_1: 0.546406, top_k: 0.776641, samples/s: 780.747 1613250263.8723385
train: epoch 20, iter 4200, loss: 3.092487, top_1: 0.542031, top_k: 0.778398, samples/s: 780.769 1613250296.6608617
train: epoch 20, iter 4300, loss: 3.307530, top_1: 0.521523, top_k: 0.757852, samples/s: 784.694 1613250329.2846835
train: epoch 20, iter 4400, loss: 2.921968, top_1: 0.526797, top_k: 0.760469, samples/s: 781.329 1613250362.0493667
train: epoch 20, iter 4500, loss: 2.644379, top_1: 0.531953, top_k: 0.766289, samples/s: 779.157 1613250394.905358
train: epoch 20, iter 4600, loss: 3.042776, top_1: 0.535469, top_k: 0.768008, samples/s: 783.109 1613250427.5956264
train: epoch 20, iter 4700, loss: 2.991745, top_1: 0.540547, top_k: 0.771055, samples/s: 780.708 1613250460.386812
train: epoch 20, iter 4800, loss: 2.748977, top_1: 0.535859, top_k: 0.769219, samples/s: 781.798 1613250493.131361
train: epoch 20, iter 4900, loss: 2.914290, top_1: 0.535000, top_k: 0.771602, samples/s: 783.914 1613250525.7879329
train: epoch 20, iter 5000, loss: 2.872109, top_1: 0.540508, top_k: 0.771367, samples/s: 782.641 1613250558.4976768
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_20.
validation: epoch 20, iter 195, top_1: 0.593129, top_k: 0.831230, samples/s: 2354.178 1613250580.7007058
train: epoch 21, iter 100, loss: 2.767372, top_1: 0.558867, top_k: 0.791094, samples/s: 805.288 1613250633.2456455
train: epoch 21, iter 200, loss: 2.840424, top_1: 0.563672, top_k: 0.790937, samples/s: 800.198 1613250665.2380247
train: epoch 21, iter 300, loss: 2.764913, top_1: 0.553164, top_k: 0.784844, samples/s: 782.604 1613250697.9490385
train: epoch 21, iter 400, loss: 2.977386, top_1: 0.554688, top_k: 0.782227, samples/s: 781.290 1613250730.715417
train: epoch 21, iter 500, loss: 2.963619, top_1: 0.550820, top_k: 0.784414, samples/s: 778.468 1613250763.6005356
train: epoch 21, iter 600, loss: 2.685243, top_1: 0.553242, top_k: 0.785039, samples/s: 784.115 1613250796.248661
train: epoch 21, iter 700, loss: 2.973504, top_1: 0.550117, top_k: 0.779609, samples/s: 779.615 1613250829.0854864
train: epoch 21, iter 800, loss: 2.805628, top_1: 0.546914, top_k: 0.781563, samples/s: 779.436 1613250861.9297242
train: epoch 21, iter 900, loss: 2.842698, top_1: 0.550078, top_k: 0.779375, samples/s: 780.537 1613250894.7276433
train: epoch 21, iter 1000, loss: 2.904029, top_1: 0.543477, top_k: 0.777930, samples/s: 781.432 1613250927.487943
train: epoch 21, iter 1100, loss: 3.060560, top_1: 0.547188, top_k: 0.778203, samples/s: 782.753 1613250960.1929986
train: epoch 21, iter 1200, loss: 2.865729, top_1: 0.549961, top_k: 0.783672, samples/s: 781.014 1613250992.9709475
train: epoch 21, iter 1300, loss: 2.947670, top_1: 0.543359, top_k: 0.777461, samples/s: 782.335 1613251025.6935446
train: epoch 21, iter 1400, loss: 2.995962, top_1: 0.541602, top_k: 0.775937, samples/s: 780.380 1613251058.4980812
train: epoch 21, iter 1500, loss: 2.911962, top_1: 0.547852, top_k: 0.778281, samples/s: 781.666 1613251091.2486222
train: epoch 21, iter 1600, loss: 2.895066, top_1: 0.543789, top_k: 0.775469, samples/s: 782.311 1613251123.9722066
train: epoch 21, iter 1700, loss: 2.672194, top_1: 0.545312, top_k: 0.778906, samples/s: 780.076 1613251156.7894602
train: epoch 21, iter 1800, loss: 2.795874, top_1: 0.545625, top_k: 0.778867, samples/s: 780.354 1613251189.5951233
train: epoch 21, iter 1900, loss: 2.883588, top_1: 0.549687, top_k: 0.782383, samples/s: 780.935 1613251222.3767138
train: epoch 21, iter 2000, loss: 2.837931, top_1: 0.544727, top_k: 0.776758, samples/s: 781.294 1613251255.14249
train: epoch 21, iter 2100, loss: 2.909318, top_1: 0.546641, top_k: 0.777266, samples/s: 779.408 1613251287.9884503
train: epoch 21, iter 2200, loss: 2.826174, top_1: 0.547617, top_k: 0.778555, samples/s: 781.402 1613251320.749503
train: epoch 21, iter 2300, loss: 2.909858, top_1: 0.546172, top_k: 0.774805, samples/s: 782.194 1613251353.4779782
train: epoch 21, iter 2400, loss: 3.077134, top_1: 0.547969, top_k: 0.778672, samples/s: 779.458 1613251386.3213239
train: epoch 21, iter 2500, loss: 2.631339, top_1: 0.552031, top_k: 0.780937, samples/s: 782.776 1613251419.0254812
train: epoch 21, iter 2600, loss: 3.099886, top_1: 0.540273, top_k: 0.770820, samples/s: 782.748 1613251451.730709
train: epoch 21, iter 2700, loss: 2.776444, top_1: 0.555703, top_k: 0.784805, samples/s: 780.182 1613251484.5436757
train: epoch 21, iter 2800, loss: 2.717433, top_1: 0.547773, top_k: 0.780234, samples/s: 781.700 1613251517.2928274
train: epoch 21, iter 2900, loss: 2.931192, top_1: 0.546250, top_k: 0.777109, samples/s: 781.334 1613251550.0572326
train: epoch 21, iter 3000, loss: 3.035155, top_1: 0.543164, top_k: 0.774805, samples/s: 783.060 1613251582.749464
train: epoch 21, iter 3100, loss: 2.838206, top_1: 0.545117, top_k: 0.779805, samples/s: 782.603 1613251615.4608712
train: epoch 21, iter 3200, loss: 2.999814, top_1: 0.543047, top_k: 0.777422, samples/s: 780.932 1613251648.2422533
train: epoch 21, iter 3300, loss: 2.843424, top_1: 0.544609, top_k: 0.775547, samples/s: 782.987 1613251680.9375265
train: epoch 21, iter 3400, loss: 2.757322, top_1: 0.548594, top_k: 0.778398, samples/s: 782.200 1613251713.6656811
train: epoch 21, iter 3500, loss: 3.263606, top_1: 0.542891, top_k: 0.770469, samples/s: 781.509 1613251746.4228551
train: epoch 21, iter 3600, loss: 2.957692, top_1: 0.547383, top_k: 0.778828, samples/s: 780.434 1613251779.225113
train: epoch 21, iter 3700, loss: 2.933084, top_1: 0.543828, top_k: 0.778594, samples/s: 780.045 1613251812.044179
train: epoch 21, iter 3800, loss: 2.979496, top_1: 0.549297, top_k: 0.780195, samples/s: 784.384 1613251844.6807985
train: epoch 21, iter 3900, loss: 2.674344, top_1: 0.543164, top_k: 0.777109, samples/s: 781.518 1613251877.4379206
train: epoch 21, iter 4000, loss: 3.078620, top_1: 0.542695, top_k: 0.778320, samples/s: 781.544 1613251910.193238
train: epoch 21, iter 4100, loss: 2.860849, top_1: 0.543906, top_k: 0.775859, samples/s: 779.930 1613251943.0166976
train: epoch 21, iter 4200, loss: 2.992453, top_1: 0.540898, top_k: 0.776563, samples/s: 782.679 1613251975.7248375
train: epoch 21, iter 4300, loss: 3.027294, top_1: 0.543945, top_k: 0.773594, samples/s: 781.904 1613252008.4654272
train: epoch 21, iter 4400, loss: 2.851527, top_1: 0.546953, top_k: 0.779258, samples/s: 779.923 1613252041.2891476
train: epoch 21, iter 4500, loss: 2.936136, top_1: 0.543477, top_k: 0.777305, samples/s: 779.123 1613252074.1466777
train: epoch 21, iter 4600, loss: 2.721334, top_1: 0.544258, top_k: 0.770391, samples/s: 781.287 1613252106.913085
train: epoch 21, iter 4700, loss: 2.864450, top_1: 0.539453, top_k: 0.773320, samples/s: 784.012 1613252139.565676
train: epoch 21, iter 4800, loss: 2.960461, top_1: 0.545625, top_k: 0.777500, samples/s: 780.249 1613252172.375672
train: epoch 21, iter 4900, loss: 2.666898, top_1: 0.544023, top_k: 0.779180, samples/s: 782.342 1613252205.098019
train: epoch 21, iter 5000, loss: 2.816419, top_1: 0.547695, top_k: 0.780391, samples/s: 781.121 1613252237.8713684
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_21.
validation: epoch 21, iter 195, top_1: 0.598017, top_k: 0.835176, samples/s: 2355.355 1613252260.0309954
train: epoch 22, iter 100, loss: 3.009779, top_1: 0.569922, top_k: 0.792578, samples/s: 805.131 1613252313.4626231
train: epoch 22, iter 200, loss: 3.045719, top_1: 0.548164, top_k: 0.778281, samples/s: 801.333 1613252345.4093738
train: epoch 22, iter 300, loss: 2.854874, top_1: 0.552109, top_k: 0.784336, samples/s: 785.553 1613252377.9979525
train: epoch 22, iter 400, loss: 2.898193, top_1: 0.552188, top_k: 0.780820, samples/s: 781.345 1613252410.7620227
train: epoch 22, iter 500, loss: 2.922393, top_1: 0.553242, top_k: 0.787305, samples/s: 780.779 1613252443.5496671
train: epoch 22, iter 600, loss: 3.072806, top_1: 0.556289, top_k: 0.785898, samples/s: 782.153 1613252476.2798853
train: epoch 22, iter 700, loss: 2.969894, top_1: 0.552891, top_k: 0.783867, samples/s: 781.972 1613252509.0176592
train: epoch 22, iter 800, loss: 2.900433, top_1: 0.553672, top_k: 0.786055, samples/s: 779.350 1613252541.8660102
train: epoch 22, iter 900, loss: 2.887609, top_1: 0.555039, top_k: 0.786992, samples/s: 781.771 1613252574.6117153
train: epoch 22, iter 1000, loss: 2.759186, top_1: 0.554023, top_k: 0.784219, samples/s: 781.741 1613252607.3593187
train: epoch 22, iter 1100, loss: 2.801623, top_1: 0.553125, top_k: 0.780898, samples/s: 779.031 1613252640.2203858
train: epoch 22, iter 1200, loss: 2.902244, top_1: 0.546562, top_k: 0.779961, samples/s: 780.326 1613252673.0271835
train: epoch 22, iter 1300, loss: 2.777956, top_1: 0.552344, top_k: 0.783281, samples/s: 785.102 1613252705.6344337
train: epoch 22, iter 1400, loss: 2.928202, top_1: 0.550156, top_k: 0.782461, samples/s: 778.663 1613252738.5113373
train: epoch 22, iter 1500, loss: 2.853487, top_1: 0.553945, top_k: 0.783750, samples/s: 782.971 1613252771.2072988
train: epoch 22, iter 1600, loss: 2.861758, top_1: 0.556523, top_k: 0.785000, samples/s: 781.677 1613252803.9573514
train: epoch 22, iter 1700, loss: 2.762102, top_1: 0.549805, top_k: 0.780117, samples/s: 783.002 1613252836.6520066
train: epoch 22, iter 1800, loss: 2.896368, top_1: 0.552305, top_k: 0.787188, samples/s: 780.780 1613252869.4398284
train: epoch 22, iter 1900, loss: 2.653798, top_1: 0.557148, top_k: 0.782891, samples/s: 785.850 1613252902.0159357
train: epoch 22, iter 2000, loss: 2.891787, top_1: 0.550273, top_k: 0.783906, samples/s: 784.297 1613252934.6566744
train: epoch 22, iter 2100, loss: 2.946232, top_1: 0.555391, top_k: 0.781914, samples/s: 781.714 1613252967.40526
train: epoch 22, iter 2200, loss: 2.753175, top_1: 0.547813, top_k: 0.778438, samples/s: 783.820 1613253000.0656962
train: epoch 22, iter 2300, loss: 2.596234, top_1: 0.547305, top_k: 0.780547, samples/s: 783.289 1613253032.748458
train: epoch 22, iter 2400, loss: 3.005086, top_1: 0.548281, top_k: 0.782773, samples/s: 785.260 1613253065.3491864
train: epoch 22, iter 2500, loss: 2.850496, top_1: 0.550195, top_k: 0.779141, samples/s: 780.014 1613253098.169082
train: epoch 22, iter 2600, loss: 2.873416, top_1: 0.552109, top_k: 0.780703, samples/s: 784.866 1613253130.7860832
train: epoch 22, iter 2700, loss: 2.937800, top_1: 0.544063, top_k: 0.779570, samples/s: 784.053 1613253163.4369376
train: epoch 22, iter 2800, loss: 2.944247, top_1: 0.551055, top_k: 0.781211, samples/s: 781.757 1613253196.1836464
train: epoch 22, iter 2900, loss: 2.860843, top_1: 0.549805, top_k: 0.779492, samples/s: 785.538 1613253228.7728655
train: epoch 22, iter 3000, loss: 2.869803, top_1: 0.546055, top_k: 0.776328, samples/s: 782.677 1613253261.4810965
train: epoch 22, iter 3100, loss: 2.979988, top_1: 0.544766, top_k: 0.778867, samples/s: 781.166 1613253294.2526515
train: epoch 22, iter 3200, loss: 2.743546, top_1: 0.547773, top_k: 0.778633, samples/s: 787.263 1613253326.7702603
train: epoch 22, iter 3300, loss: 2.777446, top_1: 0.546328, top_k: 0.779609, samples/s: 782.147 1613253359.500683
train: epoch 22, iter 3400, loss: 2.934779, top_1: 0.548203, top_k: 0.781055, samples/s: 781.342 1613253392.2648678
train: epoch 22, iter 3500, loss: 2.827255, top_1: 0.547500, top_k: 0.779219, samples/s: 783.594 1613253424.934891
train: epoch 22, iter 3600, loss: 3.037056, top_1: 0.540234, top_k: 0.773789, samples/s: 785.714 1613253457.517185
train: epoch 22, iter 3700, loss: 2.998260, top_1: 0.543242, top_k: 0.779492, samples/s: 781.629 1613253490.268721
train: epoch 22, iter 3800, loss: 2.814349, top_1: 0.553633, top_k: 0.782539, samples/s: 782.324 1613253522.9917994
train: epoch 22, iter 3900, loss: 2.958771, top_1: 0.549687, top_k: 0.781211, samples/s: 783.170 1613253555.6793876
train: epoch 22, iter 4000, loss: 2.713654, top_1: 0.549648, top_k: 0.777617, samples/s: 785.040 1613253588.2896028
train: epoch 22, iter 4100, loss: 2.851095, top_1: 0.546211, top_k: 0.778398, samples/s: 783.970 1613253620.9435935
train: epoch 22, iter 4200, loss: 2.886264, top_1: 0.548906, top_k: 0.779727, samples/s: 782.567 1613253653.656436
train: epoch 22, iter 4300, loss: 2.821397, top_1: 0.547422, top_k: 0.778516, samples/s: 780.396 1613253686.4602268
train: epoch 22, iter 4400, loss: 2.845567, top_1: 0.545234, top_k: 0.773359, samples/s: 787.539 1613253718.9665751
train: epoch 22, iter 4500, loss: 2.791673, top_1: 0.546914, top_k: 0.778906, samples/s: 781.838 1613253751.7098355
train: epoch 22, iter 4600, loss: 3.001893, top_1: 0.546367, top_k: 0.781484, samples/s: 786.142 1613253784.2740045
train: epoch 22, iter 4700, loss: 2.907463, top_1: 0.538750, top_k: 0.771602, samples/s: 785.073 1613253816.8824449
train: epoch 22, iter 4800, loss: 2.972743, top_1: 0.552773, top_k: 0.779492, samples/s: 785.093 1613253849.489943
train: epoch 22, iter 4900, loss: 3.037241, top_1: 0.546992, top_k: 0.774648, samples/s: 784.217 1613253882.1340652
train: epoch 22, iter 5000, loss: 2.862222, top_1: 0.551367, top_k: 0.784062, samples/s: 784.741 1613253914.7561889
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_22.
validation: epoch 22, iter 195, top_1: 0.595072, top_k: 0.833133, samples/s: 2369.189 1613253936.8088963
train: epoch 23, iter 100, loss: 2.648102, top_1: 0.562461, top_k: 0.789062, samples/s: 805.095 1613253994.3746934
train: epoch 23, iter 200, loss: 2.954935, top_1: 0.562813, top_k: 0.788008, samples/s: 801.337 1613254026.3212419
train: epoch 23, iter 300, loss: 2.855588, top_1: 0.558867, top_k: 0.785664, samples/s: 788.102 1613254058.80456
train: epoch 23, iter 400, loss: 2.915699, top_1: 0.560469, top_k: 0.790742, samples/s: 780.821 1613254091.5902863
train: epoch 23, iter 500, loss: 2.822337, top_1: 0.550625, top_k: 0.783086, samples/s: 782.546 1613254124.304532
train: epoch 23, iter 600, loss: 3.003583, top_1: 0.551250, top_k: 0.785937, samples/s: 782.752 1613254157.0091045
train: epoch 23, iter 700, loss: 2.949350, top_1: 0.546953, top_k: 0.782500, samples/s: 782.890 1613254189.708549
train: epoch 23, iter 800, loss: 2.777738, top_1: 0.560039, top_k: 0.786094, samples/s: 783.156 1613254222.3973234
train: epoch 23, iter 900, loss: 2.662737, top_1: 0.554805, top_k: 0.785273, samples/s: 781.688 1613254255.1464953
train: epoch 23, iter 1000, loss: 2.829214, top_1: 0.552422, top_k: 0.786055, samples/s: 780.914 1613254287.9285057
train: epoch 23, iter 1100, loss: 2.859002, top_1: 0.555391, top_k: 0.783555, samples/s: 784.991 1613254320.5403507
train: epoch 23, iter 1200, loss: 2.923556, top_1: 0.554531, top_k: 0.785937, samples/s: 783.328 1613254353.2219715
train: epoch 23, iter 1300, loss: 2.867431, top_1: 0.554922, top_k: 0.783711, samples/s: 784.469 1613254385.855054
train: epoch 23, iter 1400, loss: 2.852805, top_1: 0.554258, top_k: 0.783711, samples/s: 782.291 1613254418.5793328
train: epoch 23, iter 1500, loss: 2.589558, top_1: 0.549570, top_k: 0.783945, samples/s: 782.456 1613254451.2971246
train: epoch 23, iter 1600, loss: 2.852203, top_1: 0.553906, top_k: 0.785039, samples/s: 780.574 1613254484.0933223
train: epoch 23, iter 1700, loss: 2.985699, top_1: 0.552266, top_k: 0.781914, samples/s: 781.266 1613254516.8605406
train: epoch 23, iter 1800, loss: 2.847552, top_1: 0.548711, top_k: 0.779883, samples/s: 781.236 1613254549.6291487
train: epoch 23, iter 1900, loss: 2.828804, top_1: 0.553086, top_k: 0.781875, samples/s: 785.306 1613254582.227958
train: epoch 23, iter 2000, loss: 2.943433, top_1: 0.547773, top_k: 0.780508, samples/s: 781.997 1613254614.9645982
train: epoch 23, iter 2100, loss: 3.045156, top_1: 0.552773, top_k: 0.781172, samples/s: 785.515 1613254647.5552118
train: epoch 23, iter 2200, loss: 3.089127, top_1: 0.557930, top_k: 0.784297, samples/s: 782.995 1613254680.2496274
train: epoch 23, iter 2300, loss: 3.004698, top_1: 0.548125, top_k: 0.780898, samples/s: 784.210 1613254712.8939135
train: epoch 23, iter 2400, loss: 2.930522, top_1: 0.552383, top_k: 0.781055, samples/s: 781.408 1613254745.6553948
train: epoch 23, iter 2500, loss: 2.721287, top_1: 0.554961, top_k: 0.782109, samples/s: 783.532 1613254778.3278873
train: epoch 23, iter 2600, loss: 2.635706, top_1: 0.549492, top_k: 0.783125, samples/s: 783.452 1613254811.0037606
train: epoch 23, iter 2700, loss: 2.947478, top_1: 0.555508, top_k: 0.783711, samples/s: 783.564 1613254843.674971
train: epoch 23, iter 2800, loss: 2.933557, top_1: 0.551992, top_k: 0.784844, samples/s: 784.234 1613254876.3182743
train: epoch 23, iter 2900, loss: 2.930396, top_1: 0.551445, top_k: 0.779844, samples/s: 781.378 1613254909.0809965
train: epoch 23, iter 3000, loss: 2.891673, top_1: 0.558242, top_k: 0.786016, samples/s: 783.275 1613254941.7642605
train: epoch 23, iter 3100, loss: 2.937144, top_1: 0.553594, top_k: 0.784727, samples/s: 783.565 1613254974.435396
train: epoch 23, iter 3200, loss: 2.947165, top_1: 0.551562, top_k: 0.782695, samples/s: 784.551 1613255007.0655093
train: epoch 23, iter 3300, loss: 2.698728, top_1: 0.550430, top_k: 0.779023, samples/s: 780.538 1613255039.8633997
train: epoch 23, iter 3400, loss: 2.851624, top_1: 0.549648, top_k: 0.780000, samples/s: 783.854 1613255072.5225375
train: epoch 23, iter 3500, loss: 2.606381, top_1: 0.547109, top_k: 0.781016, samples/s: 782.853 1613255105.2234478
train: epoch 23, iter 3600, loss: 2.642453, top_1: 0.543906, top_k: 0.778594, samples/s: 783.333 1613255137.904392
train: epoch 23, iter 3700, loss: 2.750485, top_1: 0.547734, top_k: 0.780273, samples/s: 783.638 1613255170.572447
train: epoch 23, iter 3800, loss: 2.949085, top_1: 0.549883, top_k: 0.782422, samples/s: 782.662 1613255203.2813623
train: epoch 23, iter 3900, loss: 2.849098, top_1: 0.551250, top_k: 0.782930, samples/s: 787.137 1613255235.8043096
train: epoch 23, iter 4000, loss: 2.861346, top_1: 0.549766, top_k: 0.781289, samples/s: 780.406 1613255268.6077428
train: epoch 23, iter 4100, loss: 2.963758, top_1: 0.547461, top_k: 0.781172, samples/s: 787.721 1613255301.1064668
train: epoch 23, iter 4200, loss: 2.977732, top_1: 0.548008, top_k: 0.780469, samples/s: 784.039 1613255333.757903
train: epoch 23, iter 4300, loss: 2.868470, top_1: 0.550156, top_k: 0.780508, samples/s: 783.032 1613255366.4513605
train: epoch 23, iter 4400, loss: 2.940514, top_1: 0.545039, top_k: 0.780000, samples/s: 784.901 1613255399.0669668
train: epoch 23, iter 4500, loss: 2.622910, top_1: 0.554180, top_k: 0.782227, samples/s: 786.854 1613255431.6015532
train: epoch 23, iter 4600, loss: 2.679366, top_1: 0.549844, top_k: 0.778242, samples/s: 783.848 1613255464.26098
train: epoch 23, iter 4700, loss: 2.630240, top_1: 0.550312, top_k: 0.780430, samples/s: 783.169 1613255496.9486969
train: epoch 23, iter 4800, loss: 2.860098, top_1: 0.553359, top_k: 0.784453, samples/s: 781.335 1613255529.713129
train: epoch 23, iter 4900, loss: 2.759344, top_1: 0.553320, top_k: 0.781094, samples/s: 785.741 1613255562.2938728
train: epoch 23, iter 5000, loss: 2.717062, top_1: 0.544805, top_k: 0.778750, samples/s: 781.716 1613255595.0423005
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_23.
validation: epoch 23, iter 195, top_1: 0.605128, top_k: 0.839704, samples/s: 2404.784 1613255616.7831297
train: epoch 24, iter 100, loss: 2.932266, top_1: 0.556914, top_k: 0.788711, samples/s: 804.723 1613255669.386627
train: epoch 24, iter 200, loss: 2.711403, top_1: 0.565195, top_k: 0.793359, samples/s: 801.119 1613255701.3419077
train: epoch 24, iter 300, loss: 2.811941, top_1: 0.555742, top_k: 0.782656, samples/s: 787.262 1613255733.8597379
train: epoch 24, iter 400, loss: 2.810381, top_1: 0.558789, top_k: 0.787422, samples/s: 779.730 1613255766.6916769
train: epoch 24, iter 500, loss: 3.048779, top_1: 0.560000, top_k: 0.791328, samples/s: 783.492 1613255799.3659735
train: epoch 24, iter 600, loss: 2.777010, top_1: 0.558750, top_k: 0.784687, samples/s: 779.904 1613255832.1904678
train: epoch 24, iter 700, loss: 2.947286, top_1: 0.550156, top_k: 0.783789, samples/s: 781.777 1613255864.9364076
train: epoch 24, iter 800, loss: 2.780145, top_1: 0.555234, top_k: 0.785430, samples/s: 782.127 1613255897.6676688
train: epoch 24, iter 900, loss: 2.789715, top_1: 0.552891, top_k: 0.784727, samples/s: 783.251 1613255930.3519282
train: epoch 24, iter 1000, loss: 3.113153, top_1: 0.558047, top_k: 0.785391, samples/s: 781.033 1613255963.1290822
train: epoch 24, iter 1100, loss: 3.021264, top_1: 0.548711, top_k: 0.783828, samples/s: 782.911 1613255995.827538
train: epoch 24, iter 1200, loss: 2.651134, top_1: 0.554844, top_k: 0.786484, samples/s: 783.477 1613256028.502328
train: epoch 24, iter 1300, loss: 2.851855, top_1: 0.561445, top_k: 0.786719, samples/s: 783.115 1613256061.1923916
train: epoch 24, iter 1400, loss: 2.972708, top_1: 0.550977, top_k: 0.782969, samples/s: 783.225 1613256093.877765
train: epoch 24, iter 1500, loss: 2.920651, top_1: 0.554219, top_k: 0.786641, samples/s: 783.163 1613256126.5656364
train: epoch 24, iter 1600, loss: 2.676837, top_1: 0.558125, top_k: 0.789102, samples/s: 782.078 1613256159.2989786
train: epoch 24, iter 1700, loss: 2.803021, top_1: 0.558828, top_k: 0.792266, samples/s: 784.382 1613256191.9360824
train: epoch 24, iter 1800, loss: 2.744106, top_1: 0.556250, top_k: 0.785742, samples/s: 781.827 1613256224.6798804
train: epoch 24, iter 1900, loss: 2.912741, top_1: 0.555859, top_k: 0.783438, samples/s: 784.690 1613256257.3042836
train: epoch 24, iter 2000, loss: 2.884964, top_1: 0.553242, top_k: 0.787695, samples/s: 784.730 1613256289.927034
train: epoch 24, iter 2100, loss: 2.709592, top_1: 0.558242, top_k: 0.786523, samples/s: 781.359 1613256322.6904514
train: epoch 24, iter 2200, loss: 2.973803, top_1: 0.557852, top_k: 0.786523, samples/s: 783.890 1613256355.348097
train: epoch 24, iter 2300, loss: 3.011554, top_1: 0.553750, top_k: 0.788438, samples/s: 780.267 1613256388.1574125
train: epoch 24, iter 2400, loss: 2.781626, top_1: 0.553281, top_k: 0.781914, samples/s: 785.133 1613256420.7632797
train: epoch 24, iter 2500, loss: 2.926165, top_1: 0.556484, top_k: 0.786211, samples/s: 782.382 1613256453.4838727
train: epoch 24, iter 2600, loss: 2.957627, top_1: 0.545977, top_k: 0.782109, samples/s: 783.312 1613256486.1656709
train: epoch 24, iter 2700, loss: 2.824565, top_1: 0.561133, top_k: 0.786055, samples/s: 785.242 1613256518.7670743
train: epoch 24, iter 2800, loss: 2.887003, top_1: 0.551836, top_k: 0.782539, samples/s: 784.817 1613256551.386232
train: epoch 24, iter 2900, loss: 2.788792, top_1: 0.559609, top_k: 0.788633, samples/s: 786.963 1613256583.9163392
train: epoch 24, iter 3000, loss: 2.705516, top_1: 0.557578, top_k: 0.786094, samples/s: 783.410 1613256616.5940135
train: epoch 24, iter 3100, loss: 2.828815, top_1: 0.545352, top_k: 0.776953, samples/s: 785.823 1613256649.171276
train: epoch 24, iter 3200, loss: 3.012618, top_1: 0.547734, top_k: 0.777227, samples/s: 785.202 1613256681.774342
train: epoch 24, iter 3300, loss: 2.769560, top_1: 0.557813, top_k: 0.783438, samples/s: 785.292 1613256714.3737173
train: epoch 24, iter 3400, loss: 2.986451, top_1: 0.553047, top_k: 0.785586, samples/s: 784.992 1613256746.9854615
train: epoch 24, iter 3500, loss: 2.893181, top_1: 0.548828, top_k: 0.779258, samples/s: 783.705 1613256779.6508307
train: epoch 24, iter 3600, loss: 2.980885, top_1: 0.547031, top_k: 0.781133, samples/s: 784.118 1613256812.2989902
train: epoch 24, iter 3700, loss: 2.835351, top_1: 0.552656, top_k: 0.784414, samples/s: 787.632 1613256844.8014293
train: epoch 24, iter 3800, loss: 2.840413, top_1: 0.555469, top_k: 0.785625, samples/s: 784.277 1613256877.4430065
train: epoch 24, iter 3900, loss: 2.751793, top_1: 0.554531, top_k: 0.781836, samples/s: 784.441 1613256910.077676
train: epoch 24, iter 4000, loss: 2.735326, top_1: 0.550273, top_k: 0.780312, samples/s: 784.568 1613256942.7071438
train: epoch 24, iter 4100, loss: 2.817096, top_1: 0.551602, top_k: 0.780000, samples/s: 783.237 1613256975.3920038
train: epoch 24, iter 4200, loss: 2.925027, top_1: 0.558086, top_k: 0.781914, samples/s: 784.863 1613257008.0091867
train: epoch 24, iter 4300, loss: 2.841623, top_1: 0.551328, top_k: 0.780000, samples/s: 784.103 1613257040.6580358
train: epoch 24, iter 4400, loss: 3.014028, top_1: 0.551836, top_k: 0.780508, samples/s: 783.404 1613257073.3358073
train: epoch 24, iter 4500, loss: 2.942807, top_1: 0.549883, top_k: 0.781719, samples/s: 785.835 1613257105.9126437
train: epoch 24, iter 4600, loss: 2.696043, top_1: 0.555039, top_k: 0.787148, samples/s: 783.068 1613257138.6045868
train: epoch 24, iter 4700, loss: 3.013518, top_1: 0.550898, top_k: 0.780703, samples/s: 783.687 1613257171.270646
train: epoch 24, iter 4800, loss: 2.880411, top_1: 0.550586, top_k: 0.782305, samples/s: 786.667 1613257203.8131113
train: epoch 24, iter 4900, loss: 2.874451, top_1: 0.554219, top_k: 0.783867, samples/s: 783.156 1613257236.501358
train: epoch 24, iter 5000, loss: 2.682567, top_1: 0.550937, top_k: 0.781172, samples/s: 782.301 1613257269.2252765
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_24.
validation: epoch 24, iter 195, top_1: 0.594651, top_k: 0.831891, samples/s: 2332.969 1613257291.6010485
train: epoch 25, iter 100, loss: 2.782370, top_1: 0.572500, top_k: 0.800586, samples/s: 803.398 1613257343.7119331
train: epoch 25, iter 200, loss: 2.919179, top_1: 0.562031, top_k: 0.792148, samples/s: 800.102 1613257375.7079604
train: epoch 25, iter 300, loss: 2.913781, top_1: 0.564219, top_k: 0.790273, samples/s: 786.963 1613257408.237932
train: epoch 25, iter 400, loss: 2.922266, top_1: 0.561641, top_k: 0.786758, samples/s: 784.157 1613257440.8844883
train: epoch 25, iter 500, loss: 2.862908, top_1: 0.560664, top_k: 0.790586, samples/s: 784.264 1613257473.5265205
train: epoch 25, iter 600, loss: 2.739863, top_1: 0.563008, top_k: 0.788594, samples/s: 781.480 1613257506.2848258
train: epoch 25, iter 700, loss: 2.684256, top_1: 0.555898, top_k: 0.784961, samples/s: 783.329 1613257538.9659185
train: epoch 25, iter 800, loss: 2.821307, top_1: 0.563945, top_k: 0.791055, samples/s: 782.948 1613257571.662888
train: epoch 25, iter 900, loss: 2.716060, top_1: 0.550430, top_k: 0.786445, samples/s: 782.821 1613257604.3651948
train: epoch 25, iter 1000, loss: 2.825718, top_1: 0.559531, top_k: 0.787266, samples/s: 783.051 1613257637.057745
train: epoch 25, iter 1100, loss: 3.017315, top_1: 0.554258, top_k: 0.788086, samples/s: 785.163 1613257669.6623895
train: epoch 25, iter 1200, loss: 2.775885, top_1: 0.562109, top_k: 0.790273, samples/s: 783.674 1613257702.3290393
train: epoch 25, iter 1300, loss: 2.810242, top_1: 0.560156, top_k: 0.787109, samples/s: 781.967 1613257735.0670826
train: epoch 25, iter 1400, loss: 2.769553, top_1: 0.553750, top_k: 0.782148, samples/s: 784.110 1613257767.7155092
train: epoch 25, iter 1500, loss: 2.989747, top_1: 0.554922, top_k: 0.786055, samples/s: 782.067 1613257800.4492888
train: epoch 25, iter 1600, loss: 2.817596, top_1: 0.557109, top_k: 0.787070, samples/s: 784.367 1613257833.087072
train: epoch 25, iter 1700, loss: 3.051370, top_1: 0.562930, top_k: 0.788672, samples/s: 784.543 1613257865.7175777
train: epoch 25, iter 1800, loss: 2.783323, top_1: 0.556953, top_k: 0.788711, samples/s: 785.821 1613257898.2948499
train: epoch 25, iter 1900, loss: 2.768642, top_1: 0.557383, top_k: 0.792305, samples/s: 780.943 1613257931.0757499
train: epoch 25, iter 2000, loss: 2.824665, top_1: 0.555859, top_k: 0.787930, samples/s: 784.569 1613257963.7052088
train: epoch 25, iter 2100, loss: 2.810764, top_1: 0.549961, top_k: 0.781367, samples/s: 784.892 1613257996.3211112
train: epoch 25, iter 2200, loss: 2.902925, top_1: 0.551992, top_k: 0.784609, samples/s: 782.355 1613258029.0428848
train: epoch 25, iter 2300, loss: 2.797021, top_1: 0.550586, top_k: 0.786211, samples/s: 784.028 1613258061.6947184
train: epoch 25, iter 2400, loss: 2.707682, top_1: 0.560508, top_k: 0.788047, samples/s: 784.862 1613258094.3119175
train: epoch 25, iter 2500, loss: 2.855897, top_1: 0.556016, top_k: 0.788438, samples/s: 782.965 1613258127.0081403
train: epoch 25, iter 2600, loss: 2.897230, top_1: 0.555664, top_k: 0.786250, samples/s: 784.031 1613258159.659905
train: epoch 25, iter 2700, loss: 2.691391, top_1: 0.559727, top_k: 0.789883, samples/s: 783.635 1613258192.3282397
train: epoch 25, iter 2800, loss: 2.661674, top_1: 0.558789, top_k: 0.786016, samples/s: 782.323 1613258225.0512922
train: epoch 25, iter 2900, loss: 3.024995, top_1: 0.553281, top_k: 0.781250, samples/s: 782.823 1613258257.753411
train: epoch 25, iter 3000, loss: 2.722572, top_1: 0.556953, top_k: 0.784922, samples/s: 783.325 1613258290.4345648
train: epoch 25, iter 3100, loss: 3.079529, top_1: 0.555195, top_k: 0.783125, samples/s: 781.872 1613258323.1765769
train: epoch 25, iter 3200, loss: 2.834019, top_1: 0.554180, top_k: 0.788594, samples/s: 783.402 1613258355.8545628
train: epoch 25, iter 3300, loss: 2.987353, top_1: 0.552148, top_k: 0.781914, samples/s: 782.209 1613258388.5823882
train: epoch 25, iter 3400, loss: 2.781826, top_1: 0.558008, top_k: 0.784258, samples/s: 786.374 1613258421.1369276
train: epoch 25, iter 3500, loss: 2.858171, top_1: 0.555977, top_k: 0.781719, samples/s: 782.761 1613258453.841694
train: epoch 25, iter 3600, loss: 2.797470, top_1: 0.546484, top_k: 0.781602, samples/s: 780.296 1613258486.6496851
train: epoch 25, iter 3700, loss: 2.864796, top_1: 0.551484, top_k: 0.785195, samples/s: 785.692 1613258519.232526
train: epoch 25, iter 3800, loss: 2.903224, top_1: 0.554805, top_k: 0.783672, samples/s: 785.221 1613258551.8348014
train: epoch 25, iter 3900, loss: 2.749269, top_1: 0.559336, top_k: 0.786641, samples/s: 783.429 1613258584.5115924
train: epoch 25, iter 4000, loss: 3.053523, top_1: 0.561641, top_k: 0.789492, samples/s: 784.586 1613258617.1403544
train: epoch 25, iter 4100, loss: 2.994498, top_1: 0.554922, top_k: 0.783672, samples/s: 782.131 1613258649.8714533
train: epoch 25, iter 4200, loss: 2.953432, top_1: 0.552344, top_k: 0.783086, samples/s: 785.110 1613258682.478331
train: epoch 25, iter 4300, loss: 2.919766, top_1: 0.556328, top_k: 0.783555, samples/s: 782.394 1613258715.1983771
train: epoch 25, iter 4400, loss: 3.053636, top_1: 0.551172, top_k: 0.786367, samples/s: 783.816 1613258747.8591032
train: epoch 25, iter 4500, loss: 2.726769, top_1: 0.551406, top_k: 0.781719, samples/s: 782.141 1613258780.5897968
train: epoch 25, iter 4600, loss: 2.710616, top_1: 0.552266, top_k: 0.782539, samples/s: 780.536 1613258813.387824
train: epoch 25, iter 4700, loss: 2.980755, top_1: 0.545352, top_k: 0.776133, samples/s: 785.941 1613258845.960235
train: epoch 25, iter 4800, loss: 2.945049, top_1: 0.558125, top_k: 0.785820, samples/s: 783.098 1613258878.650935
train: epoch 25, iter 4900, loss: 2.674856, top_1: 0.554414, top_k: 0.787109, samples/s: 782.036 1613258911.3859792
train: epoch 25, iter 5000, loss: 2.889323, top_1: 0.552773, top_k: 0.785273, samples/s: 782.979 1613258944.0816371
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_25.
validation: epoch 25, iter 195, top_1: 0.600300, top_k: 0.839243, samples/s: 2361.352 1613258966.202765
train: epoch 26, iter 100, loss: 2.886882, top_1: 0.567031, top_k: 0.792344, samples/s: 803.343 1613259019.1103292
train: epoch 26, iter 200, loss: 3.015956, top_1: 0.561406, top_k: 0.793438, samples/s: 801.589 1613259051.0468316
train: epoch 26, iter 300, loss: 2.809842, top_1: 0.559414, top_k: 0.785859, samples/s: 786.103 1613259083.6125245
train: epoch 26, iter 400, loss: 2.850852, top_1: 0.565156, top_k: 0.793477, samples/s: 780.953 1613259116.3930817
train: epoch 26, iter 500, loss: 2.871389, top_1: 0.564766, top_k: 0.796289, samples/s: 782.924 1613259149.090873
train: epoch 26, iter 600, loss: 2.722461, top_1: 0.558281, top_k: 0.787852, samples/s: 784.153 1613259181.7375388
train: epoch 26, iter 700, loss: 2.931523, top_1: 0.564570, top_k: 0.791211, samples/s: 779.944 1613259214.5605085
train: epoch 26, iter 800, loss: 2.697788, top_1: 0.561406, top_k: 0.792070, samples/s: 781.990 1613259247.297407
train: epoch 26, iter 900, loss: 2.686489, top_1: 0.564727, top_k: 0.790234, samples/s: 782.899 1613259279.9964652
train: epoch 26, iter 1000, loss: 2.855745, top_1: 0.556914, top_k: 0.788750, samples/s: 782.669 1613259312.7050247
train: epoch 26, iter 1100, loss: 2.635052, top_1: 0.564375, top_k: 0.793008, samples/s: 782.881 1613259345.404726
train: epoch 26, iter 1200, loss: 2.776394, top_1: 0.557461, top_k: 0.786016, samples/s: 782.087 1613259378.1376746
train: epoch 26, iter 1300, loss: 2.827810, top_1: 0.557578, top_k: 0.788672, samples/s: 782.896 1613259410.8367867
train: epoch 26, iter 1400, loss: 2.756317, top_1: 0.556836, top_k: 0.784922, samples/s: 781.911 1613259443.5771422
train: epoch 26, iter 1500, loss: 2.642531, top_1: 0.553945, top_k: 0.786016, samples/s: 780.109 1613259476.3930383
train: epoch 26, iter 1600, loss: 2.903310, top_1: 0.556055, top_k: 0.785508, samples/s: 784.141 1613259509.040224
train: epoch 26, iter 1700, loss: 2.741565, top_1: 0.556172, top_k: 0.783438, samples/s: 784.680 1613259541.6649837
train: epoch 26, iter 1800, loss: 2.945461, top_1: 0.554844, top_k: 0.786719, samples/s: 781.725 1613259574.412976
train: epoch 26, iter 1900, loss: 2.797875, top_1: 0.558398, top_k: 0.785352, samples/s: 786.236 1613259606.9731936
train: epoch 26, iter 2000, loss: 2.838927, top_1: 0.562539, top_k: 0.785820, samples/s: 781.731 1613259639.7210982
train: epoch 26, iter 2100, loss: 2.786906, top_1: 0.552813, top_k: 0.783750, samples/s: 783.234 1613259672.4060972
train: epoch 26, iter 2200, loss: 2.899063, top_1: 0.554492, top_k: 0.783828, samples/s: 783.038 1613259705.0993485
train: epoch 26, iter 2300, loss: 2.810417, top_1: 0.561484, top_k: 0.786055, samples/s: 780.396 1613259737.903214
train: epoch 26, iter 2400, loss: 2.701831, top_1: 0.564023, top_k: 0.789766, samples/s: 784.450 1613259770.5374324
train: epoch 26, iter 2500, loss: 2.869053, top_1: 0.556641, top_k: 0.787227, samples/s: 782.693 1613259803.245051
train: epoch 26, iter 2600, loss: 2.704504, top_1: 0.556055, top_k: 0.790352, samples/s: 782.457 1613259835.962479
train: epoch 26, iter 2700, loss: 2.652550, top_1: 0.561875, top_k: 0.789922, samples/s: 782.480 1613259868.6790657
train: epoch 26, iter 2800, loss: 2.911118, top_1: 0.554414, top_k: 0.787930, samples/s: 781.756 1613259901.425796
train: epoch 26, iter 2900, loss: 2.696664, top_1: 0.554258, top_k: 0.785273, samples/s: 784.022 1613259934.078022
train: epoch 26, iter 3000, loss: 2.845407, top_1: 0.561367, top_k: 0.787227, samples/s: 782.099 1613259966.8103654
train: epoch 26, iter 3100, loss: 2.711487, top_1: 0.556602, top_k: 0.783945, samples/s: 783.295 1613259999.4928858
train: epoch 26, iter 3200, loss: 2.780587, top_1: 0.557852, top_k: 0.784023, samples/s: 779.759 1613260032.323575
train: epoch 26, iter 3300, loss: 2.881525, top_1: 0.556875, top_k: 0.784883, samples/s: 783.434 1613260065.0002081
train: epoch 26, iter 3400, loss: 2.882953, top_1: 0.557695, top_k: 0.783320, samples/s: 779.417 1613260097.8452396
train: epoch 26, iter 3500, loss: 2.870306, top_1: 0.557148, top_k: 0.784062, samples/s: 783.608 1613260130.5146375
train: epoch 26, iter 3600, loss: 2.867745, top_1: 0.552383, top_k: 0.785352, samples/s: 783.317 1613260163.1961308
train: epoch 26, iter 3700, loss: 2.794637, top_1: 0.556797, top_k: 0.782344, samples/s: 784.538 1613260195.826793
train: epoch 26, iter 3800, loss: 2.607289, top_1: 0.560156, top_k: 0.787031, samples/s: 783.802 1613260228.4882302
train: epoch 26, iter 3900, loss: 2.671943, top_1: 0.553984, top_k: 0.787344, samples/s: 783.198 1613260261.174596
train: epoch 26, iter 4000, loss: 2.861228, top_1: 0.552305, top_k: 0.783477, samples/s: 783.721 1613260293.8393855
train: epoch 26, iter 4100, loss: 2.984752, top_1: 0.553203, top_k: 0.783008, samples/s: 780.161 1613260326.6530988
train: epoch 26, iter 4200, loss: 2.812566, top_1: 0.554102, top_k: 0.785312, samples/s: 784.993 1613260359.264758
train: epoch 26, iter 4300, loss: 2.754883, top_1: 0.558242, top_k: 0.786211, samples/s: 781.622 1613260392.0171628
train: epoch 26, iter 4400, loss: 2.815876, top_1: 0.556484, top_k: 0.783008, samples/s: 783.321 1613260424.6985307
train: epoch 26, iter 4500, loss: 2.685310, top_1: 0.557617, top_k: 0.786719, samples/s: 782.274 1613260457.4236639
train: epoch 26, iter 4600, loss: 2.879500, top_1: 0.555195, top_k: 0.783633, samples/s: 782.434 1613260490.1421268
train: epoch 26, iter 4700, loss: 3.013421, top_1: 0.551641, top_k: 0.780039, samples/s: 782.056 1613260522.8762999
train: epoch 26, iter 4800, loss: 3.055564, top_1: 0.554883, top_k: 0.783008, samples/s: 782.417 1613260555.5954263
train: epoch 26, iter 4900, loss: 3.045675, top_1: 0.551250, top_k: 0.782969, samples/s: 782.952 1613260588.2921546
train: epoch 26, iter 5000, loss: 2.797493, top_1: 0.555937, top_k: 0.782656, samples/s: 781.645 1613260621.043606
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_26.
validation: epoch 26, iter 195, top_1: 0.604868, top_k: 0.837961, samples/s: 2377.905 1613260643.047975
train: epoch 27, iter 100, loss: 2.636712, top_1: 0.568945, top_k: 0.799102, samples/s: 805.092 1613260695.374272
train: epoch 27, iter 200, loss: 2.742563, top_1: 0.569375, top_k: 0.794883, samples/s: 800.608 1613260727.349949
train: epoch 27, iter 300, loss: 2.642392, top_1: 0.567891, top_k: 0.792852, samples/s: 785.602 1613260759.9364197
train: epoch 27, iter 400, loss: 2.787329, top_1: 0.561094, top_k: 0.790469, samples/s: 780.841 1613260792.7215846
train: epoch 27, iter 500, loss: 2.751068, top_1: 0.565000, top_k: 0.793750, samples/s: 780.738 1613260825.5110507
train: epoch 27, iter 600, loss: 2.770139, top_1: 0.564570, top_k: 0.791836, samples/s: 781.200 1613260858.2814817
train: epoch 27, iter 700, loss: 2.688192, top_1: 0.561328, top_k: 0.788008, samples/s: 781.586 1613260891.0350456
train: epoch 27, iter 800, loss: 2.665773, top_1: 0.567305, top_k: 0.788906, samples/s: 781.030 1613260923.8122928
train: epoch 27, iter 900, loss: 2.714654, top_1: 0.553984, top_k: 0.786289, samples/s: 782.839 1613260956.5137691
train: epoch 27, iter 1000, loss: 2.929554, top_1: 0.566094, top_k: 0.797539, samples/s: 781.842 1613260989.2569735
train: epoch 27, iter 1100, loss: 2.915076, top_1: 0.558594, top_k: 0.787070, samples/s: 783.288 1613261021.9397662
train: epoch 27, iter 1200, loss: 2.652406, top_1: 0.558203, top_k: 0.783281, samples/s: 784.527 1613261054.570827
train: epoch 27, iter 1300, loss: 3.037380, top_1: 0.566094, top_k: 0.788945, samples/s: 780.668 1613261087.3632789
train: epoch 27, iter 1400, loss: 2.706627, top_1: 0.561758, top_k: 0.787656, samples/s: 782.239 1613261120.0898373
train: epoch 27, iter 1500, loss: 2.878624, top_1: 0.561797, top_k: 0.787773, samples/s: 781.454 1613261152.8492205
train: epoch 27, iter 1600, loss: 2.755498, top_1: 0.557891, top_k: 0.787266, samples/s: 783.475 1613261185.5241766
train: epoch 27, iter 1700, loss: 2.744540, top_1: 0.558633, top_k: 0.785469, samples/s: 783.795 1613261218.185814
train: epoch 27, iter 1800, loss: 2.728556, top_1: 0.563945, top_k: 0.791719, samples/s: 780.722 1613261250.9759254
train: epoch 27, iter 1900, loss: 2.774588, top_1: 0.553008, top_k: 0.788828, samples/s: 782.193 1613261283.7044175
train: epoch 27, iter 2000, loss: 2.961417, top_1: 0.560781, top_k: 0.793047, samples/s: 782.378 1613261316.4251525
train: epoch 27, iter 2100, loss: 2.837603, top_1: 0.555430, top_k: 0.791289, samples/s: 781.978 1613261349.1627495
train: epoch 27, iter 2200, loss: 2.830497, top_1: 0.556914, top_k: 0.789922, samples/s: 783.284 1613261381.8456202
train: epoch 27, iter 2300, loss: 2.836151, top_1: 0.558242, top_k: 0.787969, samples/s: 783.260 1613261414.5295322
train: epoch 27, iter 2400, loss: 2.834563, top_1: 0.556797, top_k: 0.788477, samples/s: 782.741 1613261447.2351494
train: epoch 27, iter 2500, loss: 2.870269, top_1: 0.563125, top_k: 0.790195, samples/s: 780.351 1613261480.040812
train: epoch 27, iter 2600, loss: 2.654320, top_1: 0.557344, top_k: 0.786797, samples/s: 784.609 1613261512.668551
train: epoch 27, iter 2700, loss: 2.764155, top_1: 0.560547, top_k: 0.788906, samples/s: 781.562 1613261545.4234993
train: epoch 27, iter 2800, loss: 2.737283, top_1: 0.557695, top_k: 0.790742, samples/s: 784.294 1613261578.0643435
train: epoch 27, iter 2900, loss: 2.937507, top_1: 0.559492, top_k: 0.790039, samples/s: 784.625 1613261610.6913295
train: epoch 27, iter 3000, loss: 2.960771, top_1: 0.554688, top_k: 0.785156, samples/s: 781.599 1613261643.4447322
train: epoch 27, iter 3100, loss: 2.823881, top_1: 0.554492, top_k: 0.787148, samples/s: 782.148 1613261676.1751454
train: epoch 27, iter 3200, loss: 2.796307, top_1: 0.560234, top_k: 0.788906, samples/s: 784.040 1613261708.826417
train: epoch 27, iter 3300, loss: 3.010244, top_1: 0.561719, top_k: 0.788789, samples/s: 781.406 1613261741.587867
train: epoch 27, iter 3400, loss: 2.796137, top_1: 0.563047, top_k: 0.788633, samples/s: 783.138 1613261774.2768862
train: epoch 27, iter 3500, loss: 2.832174, top_1: 0.561602, top_k: 0.787891, samples/s: 783.571 1613261806.9478521
train: epoch 27, iter 3600, loss: 2.830387, top_1: 0.561016, top_k: 0.789219, samples/s: 782.446 1613261839.6657572
train: epoch 27, iter 3700, loss: 2.646586, top_1: 0.553242, top_k: 0.783125, samples/s: 783.399 1613261872.343869
train: epoch 27, iter 3800, loss: 2.741369, top_1: 0.561758, top_k: 0.786328, samples/s: 780.836 1613261905.129194
train: epoch 27, iter 3900, loss: 2.802145, top_1: 0.558672, top_k: 0.785547, samples/s: 784.462 1613261937.7630675
train: epoch 27, iter 4000, loss: 2.853258, top_1: 0.556094, top_k: 0.785195, samples/s: 783.854 1613261970.4222312
train: epoch 27, iter 4100, loss: 2.651209, top_1: 0.553945, top_k: 0.783711, samples/s: 781.037 1613262003.19914
train: epoch 27, iter 4200, loss: 2.819550, top_1: 0.556680, top_k: 0.790312, samples/s: 783.004 1613262035.893794
train: epoch 27, iter 4300, loss: 2.692818, top_1: 0.554297, top_k: 0.780898, samples/s: 781.971 1613262068.631548
train: epoch 27, iter 4400, loss: 2.874411, top_1: 0.555547, top_k: 0.782188, samples/s: 784.471 1613262101.2649393
train: epoch 27, iter 4500, loss: 2.815223, top_1: 0.556992, top_k: 0.785469, samples/s: 782.635 1613262133.9749691
train: epoch 27, iter 4600, loss: 2.779737, top_1: 0.565937, top_k: 0.789062, samples/s: 781.838 1613262166.7184093
train: epoch 27, iter 4700, loss: 2.754733, top_1: 0.557109, top_k: 0.786953, samples/s: 781.140 1613262199.4909365
train: epoch 27, iter 4800, loss: 2.952064, top_1: 0.557148, top_k: 0.785547, samples/s: 783.109 1613262232.1811738
train: epoch 27, iter 4900, loss: 2.715547, top_1: 0.556406, top_k: 0.785547, samples/s: 782.988 1613262264.876413
train: epoch 27, iter 5000, loss: 2.822264, top_1: 0.564297, top_k: 0.791680, samples/s: 783.304 1613262297.558572
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_27.
validation: epoch 27, iter 195, top_1: 0.606751, top_k: 0.840365, samples/s: 2346.097 1613262319.8100233
train: epoch 28, iter 100, loss: 2.693262, top_1: 0.570430, top_k: 0.798281, samples/s: 803.921 1613262372.3674822
train: epoch 28, iter 200, loss: 2.822899, top_1: 0.574453, top_k: 0.794766, samples/s: 800.908 1613262404.3314207
train: epoch 28, iter 300, loss: 2.742793, top_1: 0.564023, top_k: 0.795312, samples/s: 784.604 1613262436.959073
train: epoch 28, iter 400, loss: 2.726864, top_1: 0.569648, top_k: 0.797695, samples/s: 783.665 1613262469.6260247
train: epoch 28, iter 500, loss: 2.647350, top_1: 0.564102, top_k: 0.794727, samples/s: 781.824 1613262502.37007
train: epoch 28, iter 600, loss: 2.748946, top_1: 0.560781, top_k: 0.787305, samples/s: 780.247 1613262535.1802592
train: epoch 28, iter 700, loss: 2.742712, top_1: 0.569805, top_k: 0.794336, samples/s: 783.042 1613262567.8731387
train: epoch 28, iter 800, loss: 2.754137, top_1: 0.564492, top_k: 0.794102, samples/s: 780.857 1613262600.6576512
train: epoch 28, iter 900, loss: 2.782205, top_1: 0.562187, top_k: 0.789883, samples/s: 780.846 1613262633.4427044
train: epoch 28, iter 1000, loss: 2.720031, top_1: 0.560977, top_k: 0.794687, samples/s: 782.344 1613262666.164878
train: epoch 28, iter 1100, loss: 2.576647, top_1: 0.566602, top_k: 0.790156, samples/s: 782.852 1613262698.8658364
train: epoch 28, iter 1200, loss: 2.678324, top_1: 0.563516, top_k: 0.791250, samples/s: 780.731 1613262731.655527
train: epoch 28, iter 1300, loss: 2.799306, top_1: 0.562891, top_k: 0.788672, samples/s: 782.512 1613262764.3707237
train: epoch 28, iter 1400, loss: 2.508706, top_1: 0.565508, top_k: 0.791836, samples/s: 783.429 1613262797.0476353
train: epoch 28, iter 1500, loss: 2.763725, top_1: 0.558516, top_k: 0.789805, samples/s: 783.488 1613262829.7220418
train: epoch 28, iter 1600, loss: 2.857863, top_1: 0.560898, top_k: 0.789297, samples/s: 778.885 1613262862.5894334
train: epoch 28, iter 1700, loss: 2.745420, top_1: 0.557813, top_k: 0.787031, samples/s: 782.052 1613262895.3237884
train: epoch 28, iter 1800, loss: 2.757234, top_1: 0.561094, top_k: 0.786211, samples/s: 782.805 1613262928.0267131
train: epoch 28, iter 1900, loss: 3.025850, top_1: 0.560781, top_k: 0.790273, samples/s: 780.974 1613262960.8063102
train: epoch 28, iter 2000, loss: 2.709543, top_1: 0.560391, top_k: 0.792930, samples/s: 782.403 1613262993.5259585
train: epoch 28, iter 2100, loss: 2.985177, top_1: 0.560664, top_k: 0.787500, samples/s: 783.581 1613263026.1965113
train: epoch 28, iter 2200, loss: 2.926522, top_1: 0.561992, top_k: 0.791289, samples/s: 779.495 1613263059.0383623
train: epoch 28, iter 2300, loss: 2.909496, top_1: 0.560586, top_k: 0.792969, samples/s: 783.453 1613263091.7142088
train: epoch 28, iter 2400, loss: 2.766216, top_1: 0.558438, top_k: 0.790156, samples/s: 784.451 1613263124.3483956
train: epoch 28, iter 2500, loss: 2.830536, top_1: 0.556133, top_k: 0.784180, samples/s: 779.991 1613263157.169305
train: epoch 28, iter 2600, loss: 2.780172, top_1: 0.559453, top_k: 0.791680, samples/s: 782.678 1613263189.8774893
train: epoch 28, iter 2700, loss: 2.821806, top_1: 0.562656, top_k: 0.788320, samples/s: 780.629 1613263222.671575
train: epoch 28, iter 2800, loss: 2.769259, top_1: 0.562070, top_k: 0.787109, samples/s: 784.469 1613263255.305094
train: epoch 28, iter 2900, loss: 2.885715, top_1: 0.560430, top_k: 0.786523, samples/s: 780.639 1613263288.0987904
train: epoch 28, iter 3000, loss: 2.722272, top_1: 0.565820, top_k: 0.791328, samples/s: 785.659 1613263320.6828897
train: epoch 28, iter 3100, loss: 2.936272, top_1: 0.558242, top_k: 0.790039, samples/s: 783.137 1613263353.3718998
train: epoch 28, iter 3200, loss: 2.972898, top_1: 0.557266, top_k: 0.785234, samples/s: 783.060 1613263386.0642347
train: epoch 28, iter 3300, loss: 2.814625, top_1: 0.559375, top_k: 0.789883, samples/s: 782.553 1613263418.7776427
train: epoch 28, iter 3400, loss: 2.947224, top_1: 0.560312, top_k: 0.790547, samples/s: 780.586 1613263451.573627
train: epoch 28, iter 3500, loss: 2.893380, top_1: 0.563945, top_k: 0.788633, samples/s: 785.305 1613263484.17239
train: epoch 28, iter 3600, loss: 2.805149, top_1: 0.561211, top_k: 0.789648, samples/s: 783.122 1613263516.8620477
train: epoch 28, iter 3700, loss: 2.849304, top_1: 0.569023, top_k: 0.794141, samples/s: 783.594 1613263549.532043
train: epoch 28, iter 3800, loss: 2.856158, top_1: 0.558984, top_k: 0.788984, samples/s: 785.594 1613263582.1189008
train: epoch 28, iter 3900, loss: 2.927382, top_1: 0.560859, top_k: 0.787070, samples/s: 784.445 1613263614.753389
train: epoch 28, iter 4000, loss: 2.643657, top_1: 0.561211, top_k: 0.787695, samples/s: 782.436 1613263647.471712
train: epoch 28, iter 4100, loss: 2.928290, top_1: 0.560898, top_k: 0.788750, samples/s: 782.647 1613263680.1812406
train: epoch 28, iter 4200, loss: 2.882981, top_1: 0.553711, top_k: 0.781875, samples/s: 783.655 1613263712.8486905
train: epoch 28, iter 4300, loss: 2.783084, top_1: 0.551836, top_k: 0.783438, samples/s: 784.539 1613263745.4792967
train: epoch 28, iter 4400, loss: 3.012898, top_1: 0.558867, top_k: 0.789336, samples/s: 782.770 1613263778.183608
train: epoch 28, iter 4500, loss: 2.783884, top_1: 0.558945, top_k: 0.788086, samples/s: 780.960 1613263810.9638252
train: epoch 28, iter 4600, loss: 2.987743, top_1: 0.561211, top_k: 0.789062, samples/s: 783.920 1613263843.6201723
train: epoch 28, iter 4700, loss: 2.784717, top_1: 0.560234, top_k: 0.785312, samples/s: 781.720 1613263876.3685207
train: epoch 28, iter 4800, loss: 2.735347, top_1: 0.562852, top_k: 0.789961, samples/s: 783.141 1613263909.0574024
train: epoch 28, iter 4900, loss: 2.914261, top_1: 0.555000, top_k: 0.789023, samples/s: 783.406 1613263941.7352107
train: epoch 28, iter 5000, loss: 2.694681, top_1: 0.561094, top_k: 0.787227, samples/s: 782.390 1613263974.4553452
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_28.
validation: epoch 28, iter 195, top_1: 0.611098, top_k: 0.840725, samples/s: 2364.772 1613263996.5965118
train: epoch 29, iter 100, loss: 2.531191, top_1: 0.569336, top_k: 0.792188, samples/s: 803.675 1613264049.0823462
train: epoch 29, iter 200, loss: 2.678111, top_1: 0.572383, top_k: 0.797266, samples/s: 801.251 1613264081.0324337
train: epoch 29, iter 300, loss: 2.646390, top_1: 0.570625, top_k: 0.794805, samples/s: 786.073 1613264113.5993757
train: epoch 29, iter 400, loss: 2.806041, top_1: 0.574922, top_k: 0.801641, samples/s: 779.918 1613264146.4236124
train: epoch 29, iter 500, loss: 2.829103, top_1: 0.566328, top_k: 0.794609, samples/s: 783.020 1613264179.1171806
train: epoch 29, iter 600, loss: 2.912801, top_1: 0.562969, top_k: 0.789961, samples/s: 787.051 1613264211.6437812
train: epoch 29, iter 700, loss: 2.785314, top_1: 0.564336, top_k: 0.795430, samples/s: 780.766 1613264244.4320822
train: epoch 29, iter 800, loss: 2.833294, top_1: 0.569375, top_k: 0.792109, samples/s: 782.947 1613264277.1289766
train: epoch 29, iter 900, loss: 2.867727, top_1: 0.567148, top_k: 0.793359, samples/s: 782.469 1613264309.8459253
train: epoch 29, iter 1000, loss: 2.843987, top_1: 0.570039, top_k: 0.797578, samples/s: 782.373 1613264342.5669675
train: epoch 29, iter 1100, loss: 2.682680, top_1: 0.568789, top_k: 0.797383, samples/s: 783.995 1613264375.2202275
train: epoch 29, iter 1200, loss: 2.776145, top_1: 0.563633, top_k: 0.794727, samples/s: 784.625 1613264407.8472188
train: epoch 29, iter 1300, loss: 2.760042, top_1: 0.567773, top_k: 0.794766, samples/s: 782.769 1613264440.551645
train: epoch 29, iter 1400, loss: 2.822046, top_1: 0.565430, top_k: 0.790586, samples/s: 782.336 1613264473.2742405
train: epoch 29, iter 1500, loss: 2.847587, top_1: 0.561914, top_k: 0.786875, samples/s: 786.442 1613264505.8258333
train: epoch 29, iter 1600, loss: 2.709151, top_1: 0.573672, top_k: 0.797773, samples/s: 779.718 1613264538.6583083
train: epoch 29, iter 1700, loss: 2.949281, top_1: 0.568359, top_k: 0.795000, samples/s: 784.702 1613264571.2820942
train: epoch 29, iter 1800, loss: 2.811224, top_1: 0.562383, top_k: 0.790469, samples/s: 782.515 1613264603.9970975
train: epoch 29, iter 1900, loss: 2.932105, top_1: 0.566211, top_k: 0.794609, samples/s: 784.833 1613264636.6155047
train: epoch 29, iter 2000, loss: 2.932476, top_1: 0.564727, top_k: 0.791797, samples/s: 783.922 1613264669.271829
train: epoch 29, iter 2100, loss: 2.703600, top_1: 0.564609, top_k: 0.793047, samples/s: 781.952 1613264702.0104666
train: epoch 29, iter 2200, loss: 2.790333, top_1: 0.565234, top_k: 0.792461, samples/s: 783.835 1613264734.6703854
train: epoch 29, iter 2300, loss: 2.777113, top_1: 0.567695, top_k: 0.792422, samples/s: 784.734 1613264767.2929304
train: epoch 29, iter 2400, loss: 2.739429, top_1: 0.564883, top_k: 0.791016, samples/s: 782.444 1613264800.01094
train: epoch 29, iter 2500, loss: 2.859073, top_1: 0.562539, top_k: 0.793320, samples/s: 784.164 1613264832.65713
train: epoch 29, iter 2600, loss: 3.057338, top_1: 0.563555, top_k: 0.787500, samples/s: 782.518 1613264865.3720088
train: epoch 29, iter 2700, loss: 2.733177, top_1: 0.563281, top_k: 0.787539, samples/s: 782.610 1613264898.083113
train: epoch 29, iter 2800, loss: 2.737283, top_1: 0.565312, top_k: 0.792969, samples/s: 782.615 1613264930.7939577
train: epoch 29, iter 2900, loss: 3.079418, top_1: 0.559180, top_k: 0.791758, samples/s: 785.590 1613264963.380883
train: epoch 29, iter 3000, loss: 2.834040, top_1: 0.562344, top_k: 0.790937, samples/s: 779.771 1613264996.21101
train: epoch 29, iter 3100, loss: 2.838060, top_1: 0.558906, top_k: 0.789023, samples/s: 784.064 1613265028.8614385
train: epoch 29, iter 3200, loss: 2.762344, top_1: 0.560781, top_k: 0.786836, samples/s: 783.266 1613265061.5451734
train: epoch 29, iter 3300, loss: 2.948524, top_1: 0.560391, top_k: 0.787891, samples/s: 784.988 1613265094.1570647
train: epoch 29, iter 3400, loss: 2.731555, top_1: 0.565312, top_k: 0.794414, samples/s: 782.579 1613265126.8693674
train: epoch 29, iter 3500, loss: 2.771030, top_1: 0.559727, top_k: 0.789023, samples/s: 783.737 1613265159.5334594
train: epoch 29, iter 3600, loss: 2.818064, top_1: 0.557852, top_k: 0.788242, samples/s: 782.933 1613265192.2309728
train: epoch 29, iter 3700, loss: 2.771932, top_1: 0.559453, top_k: 0.787070, samples/s: 783.384 1613265224.9096925
train: epoch 29, iter 3800, loss: 2.660980, top_1: 0.562070, top_k: 0.790000, samples/s: 783.673 1613265257.5764043
train: epoch 29, iter 3900, loss: 2.685075, top_1: 0.565664, top_k: 0.790352, samples/s: 783.963 1613265290.2309442
train: epoch 29, iter 4000, loss: 2.918932, top_1: 0.566641, top_k: 0.791445, samples/s: 785.206 1613265322.8338852
train: epoch 29, iter 4100, loss: 2.776005, top_1: 0.558516, top_k: 0.787070, samples/s: 782.962 1613265355.53031
train: epoch 29, iter 4200, loss: 2.879396, top_1: 0.560898, top_k: 0.786680, samples/s: 784.258 1613265388.1726086
train: epoch 29, iter 4300, loss: 2.622937, top_1: 0.563789, top_k: 0.790898, samples/s: 782.072 1613265420.9062233
train: epoch 29, iter 4400, loss: 2.739791, top_1: 0.555820, top_k: 0.787031, samples/s: 783.832 1613265453.5662181
train: epoch 29, iter 4500, loss: 2.767681, top_1: 0.561406, top_k: 0.787617, samples/s: 781.310 1613265486.3317618
train: epoch 29, iter 4600, loss: 2.807310, top_1: 0.563633, top_k: 0.787773, samples/s: 784.236 1613265518.9749753
train: epoch 29, iter 4700, loss: 3.014519, top_1: 0.560586, top_k: 0.785547, samples/s: 782.619 1613265551.6855621
train: epoch 29, iter 4800, loss: 2.756758, top_1: 0.561680, top_k: 0.790625, samples/s: 784.324 1613265584.3252616
train: epoch 29, iter 4900, loss: 2.854705, top_1: 0.558867, top_k: 0.787109, samples/s: 783.334 1613265617.0060287
train: epoch 29, iter 5000, loss: 2.814999, top_1: 0.556797, top_k: 0.787188, samples/s: 781.104 1613265649.780189
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_29.
validation: epoch 29, iter 195, top_1: 0.616727, top_k: 0.848037, samples/s: 2326.189 1613265672.2063706
train: epoch 30, iter 100, loss: 2.771475, top_1: 0.570859, top_k: 0.798789, samples/s: 804.006 1613265724.588704
train: epoch 30, iter 200, loss: 2.732663, top_1: 0.567539, top_k: 0.800547, samples/s: 800.729 1613265756.559662
train: epoch 30, iter 300, loss: 2.682370, top_1: 0.575664, top_k: 0.802148, samples/s: 782.996 1613265789.2544453
train: epoch 30, iter 400, loss: 2.989182, top_1: 0.572539, top_k: 0.795312, samples/s: 781.596 1613265822.0079756
train: epoch 30, iter 500, loss: 2.769221, top_1: 0.565039, top_k: 0.793945, samples/s: 780.879 1613265854.7914512
train: epoch 30, iter 600, loss: 2.853541, top_1: 0.564492, top_k: 0.796289, samples/s: 780.676 1613265887.5835657
train: epoch 30, iter 700, loss: 2.916848, top_1: 0.571953, top_k: 0.796562, samples/s: 781.757 1613265920.330333
train: epoch 30, iter 800, loss: 2.942896, top_1: 0.563438, top_k: 0.792891, samples/s: 780.798 1613265953.117315
train: epoch 30, iter 900, loss: 2.684912, top_1: 0.568750, top_k: 0.799336, samples/s: 781.147 1613265985.8896203
train: epoch 30, iter 1000, loss: 2.839304, top_1: 0.568203, top_k: 0.796094, samples/s: 780.314 1613266018.6969173
train: epoch 30, iter 1100, loss: 2.851043, top_1: 0.573242, top_k: 0.795820, samples/s: 781.887 1613266051.4381967
train: epoch 30, iter 1200, loss: 2.795080, top_1: 0.573047, top_k: 0.797617, samples/s: 783.237 1613266084.123148
train: epoch 30, iter 1300, loss: 2.775680, top_1: 0.563984, top_k: 0.796289, samples/s: 782.935 1613266116.8205783
train: epoch 30, iter 1400, loss: 2.948861, top_1: 0.566562, top_k: 0.793984, samples/s: 781.782 1613266149.5664701
train: epoch 30, iter 1500, loss: 2.872541, top_1: 0.564023, top_k: 0.794336, samples/s: 783.656 1613266182.2337356
train: epoch 30, iter 1600, loss: 2.883289, top_1: 0.564961, top_k: 0.791836, samples/s: 783.510 1613266214.9071138
train: epoch 30, iter 1700, loss: 2.892589, top_1: 0.566328, top_k: 0.792266, samples/s: 781.943 1613266247.646091
train: epoch 30, iter 1800, loss: 2.678275, top_1: 0.568633, top_k: 0.793008, samples/s: 784.638 1613266280.2726088
train: epoch 30, iter 1900, loss: 2.624580, top_1: 0.564727, top_k: 0.793359, samples/s: 782.264 1613266312.9982333
train: epoch 30, iter 2000, loss: 2.814353, top_1: 0.559766, top_k: 0.786445, samples/s: 783.700 1613266345.663729
train: epoch 30, iter 2100, loss: 2.736012, top_1: 0.564023, top_k: 0.793164, samples/s: 779.989 1613266378.4847178
train: epoch 30, iter 2200, loss: 3.013046, top_1: 0.572187, top_k: 0.796992, samples/s: 785.704 1613266411.066945
train: epoch 30, iter 2300, loss: 2.662926, top_1: 0.570508, top_k: 0.797930, samples/s: 780.917 1613266443.8489158
train: epoch 30, iter 2400, loss: 2.738386, top_1: 0.565703, top_k: 0.793438, samples/s: 784.401 1613266476.4853492
train: epoch 30, iter 2500, loss: 2.757573, top_1: 0.561211, top_k: 0.790547, samples/s: 781.280 1613266509.2520838
train: epoch 30, iter 2600, loss: 2.722588, top_1: 0.564648, top_k: 0.793008, samples/s: 782.987 1613266541.9473133
train: epoch 30, iter 2700, loss: 2.652763, top_1: 0.554414, top_k: 0.785039, samples/s: 781.841 1613266574.6905434
train: epoch 30, iter 2800, loss: 2.762019, top_1: 0.561445, top_k: 0.792734, samples/s: 784.694 1613266607.3147488
train: epoch 30, iter 2900, loss: 2.524448, top_1: 0.568281, top_k: 0.793320, samples/s: 781.705 1613266640.0636232
train: epoch 30, iter 3000, loss: 2.678471, top_1: 0.560508, top_k: 0.790820, samples/s: 783.370 1613266672.7429433
train: epoch 30, iter 3100, loss: 3.016988, top_1: 0.561836, top_k: 0.792148, samples/s: 786.046 1613266705.3110135
train: epoch 30, iter 3200, loss: 2.765812, top_1: 0.563594, top_k: 0.793398, samples/s: 781.862 1613266738.053394
train: epoch 30, iter 3300, loss: 2.847306, top_1: 0.560391, top_k: 0.786250, samples/s: 784.198 1613266770.6982052
train: epoch 30, iter 3400, loss: 2.747671, top_1: 0.566484, top_k: 0.791328, samples/s: 780.780 1613266803.4859276
train: epoch 30, iter 3500, loss: 2.911681, top_1: 0.559531, top_k: 0.790312, samples/s: 783.123 1613266836.1755831
train: epoch 30, iter 3600, loss: 2.707404, top_1: 0.561016, top_k: 0.790391, samples/s: 782.623 1613266868.8860455
train: epoch 30, iter 3700, loss: 2.700391, top_1: 0.561719, top_k: 0.794492, samples/s: 782.340 1613266901.6084776
train: epoch 30, iter 3800, loss: 2.782420, top_1: 0.564180, top_k: 0.788945, samples/s: 783.616 1613266934.2775722
train: epoch 30, iter 3900, loss: 2.936170, top_1: 0.560312, top_k: 0.792734, samples/s: 782.141 1613266967.008207
train: epoch 30, iter 4000, loss: 2.862787, top_1: 0.563320, top_k: 0.787422, samples/s: 783.220 1613266999.6937542
train: epoch 30, iter 4100, loss: 2.826253, top_1: 0.564727, top_k: 0.789766, samples/s: 782.880 1613267032.3935013
train: epoch 30, iter 4200, loss: 2.846123, top_1: 0.559805, top_k: 0.791836, samples/s: 781.241 1613267065.1618948
train: epoch 30, iter 4300, loss: 2.987972, top_1: 0.561992, top_k: 0.787578, samples/s: 783.249 1613267097.8462815
train: epoch 30, iter 4400, loss: 2.713564, top_1: 0.563828, top_k: 0.789883, samples/s: 782.795 1613267130.5495427
train: epoch 30, iter 4500, loss: 2.925547, top_1: 0.559219, top_k: 0.788984, samples/s: 783.246 1613267163.2340558
train: epoch 30, iter 4600, loss: 2.846341, top_1: 0.557930, top_k: 0.785820, samples/s: 781.986 1613267195.9713273
train: epoch 30, iter 4700, loss: 2.889070, top_1: 0.561875, top_k: 0.789648, samples/s: 782.143 1613267228.7018538
train: epoch 30, iter 4800, loss: 2.980752, top_1: 0.563398, top_k: 0.792227, samples/s: 784.021 1613267261.3541133
train: epoch 30, iter 4900, loss: 2.812333, top_1: 0.562852, top_k: 0.791992, samples/s: 782.635 1613267294.0640998
train: epoch 30, iter 5000, loss: 2.905984, top_1: 0.565312, top_k: 0.790937, samples/s: 779.171 1613267326.9195626
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_30.
validation: epoch 30, iter 195, top_1: 0.608173, top_k: 0.840565, samples/s: 2370.215 1613267348.8997915
train: epoch 31, iter 100, loss: 2.907820, top_1: 0.566719, top_k: 0.797695, samples/s: 803.395 1613267401.1486793
train: epoch 31, iter 200, loss: 2.773939, top_1: 0.575469, top_k: 0.803672, samples/s: 798.837 1613267433.1953652
train: epoch 31, iter 300, loss: 2.780256, top_1: 0.573906, top_k: 0.799219, samples/s: 781.355 1613267465.9588416
train: epoch 31, iter 400, loss: 2.848749, top_1: 0.567695, top_k: 0.792500, samples/s: 781.117 1613267498.732507
train: epoch 31, iter 500, loss: 2.771147, top_1: 0.572852, top_k: 0.798594, samples/s: 781.384 1613267531.4948044
train: epoch 31, iter 600, loss: 2.867065, top_1: 0.575508, top_k: 0.798086, samples/s: 781.118 1613267564.2683628
train: epoch 31, iter 700, loss: 2.698512, top_1: 0.568281, top_k: 0.798906, samples/s: 782.569 1613267596.981218
train: epoch 31, iter 800, loss: 2.681525, top_1: 0.569688, top_k: 0.799492, samples/s: 780.691 1613267629.7726178
train: epoch 31, iter 900, loss: 2.828182, top_1: 0.568984, top_k: 0.799531, samples/s: 780.612 1613267662.567443
train: epoch 31, iter 1000, loss: 2.755044, top_1: 0.570664, top_k: 0.801250, samples/s: 782.433 1613267695.2858326
train: epoch 31, iter 1100, loss: 2.818429, top_1: 0.571562, top_k: 0.793398, samples/s: 781.643 1613267728.0374231
train: epoch 31, iter 1200, loss: 2.709538, top_1: 0.570703, top_k: 0.798242, samples/s: 783.009 1613267760.7318249
train: epoch 31, iter 1300, loss: 2.814806, top_1: 0.565859, top_k: 0.795352, samples/s: 783.252 1613267793.4160495
train: epoch 31, iter 1400, loss: 2.695708, top_1: 0.568906, top_k: 0.796758, samples/s: 779.468 1613267826.2589445
train: epoch 31, iter 1500, loss: 2.749927, top_1: 0.566523, top_k: 0.791250, samples/s: 782.436 1613267858.9773538
train: epoch 31, iter 1600, loss: 2.834594, top_1: 0.565742, top_k: 0.793359, samples/s: 784.634 1613267891.603992
train: epoch 31, iter 1700, loss: 2.602095, top_1: 0.570664, top_k: 0.799805, samples/s: 780.754 1613267924.3928454
train: epoch 31, iter 1800, loss: 2.901150, top_1: 0.563711, top_k: 0.784727, samples/s: 782.851 1613267957.0937405
train: epoch 31, iter 1900, loss: 2.902453, top_1: 0.563008, top_k: 0.790469, samples/s: 783.315 1613267989.7753987
train: epoch 31, iter 2000, loss: 2.641775, top_1: 0.559531, top_k: 0.796992, samples/s: 784.068 1613268022.4256365
train: epoch 31, iter 2100, loss: 2.919194, top_1: 0.558164, top_k: 0.791328, samples/s: 784.914 1613268055.0406618
train: epoch 31, iter 2200, loss: 2.911470, top_1: 0.572344, top_k: 0.791523, samples/s: 783.734 1613268087.704885
train: epoch 31, iter 2300, loss: 2.909623, top_1: 0.567031, top_k: 0.791641, samples/s: 782.197 1613268120.4332392
train: epoch 31, iter 2400, loss: 2.822564, top_1: 0.568555, top_k: 0.797734, samples/s: 781.398 1613268153.1950076
train: epoch 31, iter 2500, loss: 3.023874, top_1: 0.564063, top_k: 0.795273, samples/s: 783.058 1613268185.887354
train: epoch 31, iter 2600, loss: 2.755661, top_1: 0.566445, top_k: 0.797813, samples/s: 784.195 1613268218.5323455
train: epoch 31, iter 2700, loss: 2.808558, top_1: 0.564727, top_k: 0.793750, samples/s: 779.611 1613268251.3692117
train: epoch 31, iter 2800, loss: 2.798695, top_1: 0.568828, top_k: 0.799844, samples/s: 783.350 1613268284.0493612
train: epoch 31, iter 2900, loss: 2.884507, top_1: 0.568086, top_k: 0.792813, samples/s: 784.707 1613268316.6729732
train: epoch 31, iter 3000, loss: 2.999021, top_1: 0.567187, top_k: 0.794063, samples/s: 784.203 1613268349.3176475
train: epoch 31, iter 3100, loss: 2.790543, top_1: 0.567891, top_k: 0.794531, samples/s: 781.717 1613268382.0660117
train: epoch 31, iter 3200, loss: 2.752089, top_1: 0.560234, top_k: 0.791562, samples/s: 782.314 1613268414.7894342
train: epoch 31, iter 3300, loss: 2.846784, top_1: 0.559453, top_k: 0.787344, samples/s: 779.573 1613268447.6280122
train: epoch 31, iter 3400, loss: 2.813574, top_1: 0.563242, top_k: 0.793125, samples/s: 785.455 1613268480.2205975
train: epoch 31, iter 3500, loss: 2.898048, top_1: 0.564258, top_k: 0.790781, samples/s: 783.484 1613268512.8951437
train: epoch 31, iter 3600, loss: 3.022958, top_1: 0.563398, top_k: 0.792578, samples/s: 782.088 1613268545.6280267
train: epoch 31, iter 3700, loss: 2.745189, top_1: 0.565273, top_k: 0.795586, samples/s: 784.486 1613268578.2608445
train: epoch 31, iter 3800, loss: 2.740866, top_1: 0.564648, top_k: 0.792188, samples/s: 782.106 1613268610.9929779
train: epoch 31, iter 3900, loss: 2.699555, top_1: 0.568242, top_k: 0.792734, samples/s: 781.749 1613268643.740032
train: epoch 31, iter 4000, loss: 2.824468, top_1: 0.566719, top_k: 0.788750, samples/s: 783.457 1613268676.415827
train: epoch 31, iter 4100, loss: 2.719413, top_1: 0.565469, top_k: 0.795937, samples/s: 781.365 1613268709.1788576
train: epoch 31, iter 4200, loss: 2.801563, top_1: 0.563516, top_k: 0.787461, samples/s: 784.682 1613268741.8036387
train: epoch 31, iter 4300, loss: 2.865435, top_1: 0.561484, top_k: 0.787148, samples/s: 783.844 1613268774.4632285
train: epoch 31, iter 4400, loss: 2.855974, top_1: 0.562305, top_k: 0.793516, samples/s: 780.774 1613268807.2510908
train: epoch 31, iter 4500, loss: 3.020568, top_1: 0.561094, top_k: 0.790586, samples/s: 783.834 1613268839.9110603
train: epoch 31, iter 4600, loss: 2.693550, top_1: 0.566250, top_k: 0.797266, samples/s: 781.209 1613268872.6808586
train: epoch 31, iter 4700, loss: 2.710038, top_1: 0.566719, top_k: 0.792500, samples/s: 785.013 1613268905.2917902
train: epoch 31, iter 4800, loss: 2.708730, top_1: 0.566484, top_k: 0.795547, samples/s: 780.873 1613268938.0755484
train: epoch 31, iter 4900, loss: 2.674696, top_1: 0.568438, top_k: 0.789297, samples/s: 783.635 1613268970.7437785
train: epoch 31, iter 5000, loss: 2.540879, top_1: 0.569102, top_k: 0.793047, samples/s: 783.275 1613269003.427077
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_31.
validation: epoch 31, iter 195, top_1: 0.617007, top_k: 0.846595, samples/s: 2349.108 1613269025.655131
train: epoch 32, iter 100, loss: 2.709884, top_1: 0.577344, top_k: 0.804883, samples/s: 803.755 1613269078.2538025
train: epoch 32, iter 200, loss: 2.821373, top_1: 0.575781, top_k: 0.802227, samples/s: 799.962 1613269110.255534
train: epoch 32, iter 300, loss: 2.774837, top_1: 0.573945, top_k: 0.800586, samples/s: 785.871 1613269142.83066
train: epoch 32, iter 400, loss: 2.618663, top_1: 0.576875, top_k: 0.801797, samples/s: 779.372 1613269175.6776261
train: epoch 32, iter 500, loss: 2.710591, top_1: 0.575117, top_k: 0.796914, samples/s: 774.143 1613269208.7464283
train: epoch 32, iter 600, loss: 2.697793, top_1: 0.569141, top_k: 0.794883, samples/s: 787.731 1613269241.244814
train: epoch 32, iter 700, loss: 2.718079, top_1: 0.574688, top_k: 0.796602, samples/s: 780.690 1613269274.0363655
train: epoch 32, iter 800, loss: 2.722572, top_1: 0.570078, top_k: 0.798789, samples/s: 779.393 1613269306.8823683
train: epoch 32, iter 900, loss: 2.901860, top_1: 0.566641, top_k: 0.792383, samples/s: 781.786 1613269339.6279464
train: epoch 32, iter 1000, loss: 2.619284, top_1: 0.568789, top_k: 0.793906, samples/s: 781.889 1613269372.3692074
train: epoch 32, iter 1100, loss: 2.754275, top_1: 0.573516, top_k: 0.800703, samples/s: 781.317 1613269405.1344378
train: epoch 32, iter 1200, loss: 2.940128, top_1: 0.567891, top_k: 0.796055, samples/s: 782.213 1613269437.8620448
train: epoch 32, iter 1300, loss: 2.705295, top_1: 0.571523, top_k: 0.799531, samples/s: 784.384 1613269470.4990568
train: epoch 32, iter 1400, loss: 2.574520, top_1: 0.564570, top_k: 0.792578, samples/s: 780.625 1613269503.2933822
train: epoch 32, iter 1500, loss: 2.833716, top_1: 0.571523, top_k: 0.793945, samples/s: 781.713 1613269536.0419512
train: epoch 32, iter 1600, loss: 2.759223, top_1: 0.568711, top_k: 0.795352, samples/s: 781.558 1613269568.7970471
train: epoch 32, iter 1700, loss: 2.655543, top_1: 0.563359, top_k: 0.794961, samples/s: 782.435 1613269601.5154
train: epoch 32, iter 1800, loss: 2.533755, top_1: 0.566523, top_k: 0.793867, samples/s: 784.538 1613269634.1459928
train: epoch 32, iter 1900, loss: 3.108322, top_1: 0.566055, top_k: 0.790469, samples/s: 780.937 1613269666.927176
train: epoch 32, iter 2000, loss: 2.846202, top_1: 0.561445, top_k: 0.793945, samples/s: 783.473 1613269699.602245
train: epoch 32, iter 2100, loss: 2.639089, top_1: 0.565312, top_k: 0.796172, samples/s: 783.705 1613269732.2675366
train: epoch 32, iter 2200, loss: 2.680021, top_1: 0.568555, top_k: 0.796016, samples/s: 783.262 1613269764.9513392
train: epoch 32, iter 2300, loss: 2.822068, top_1: 0.569922, top_k: 0.794102, samples/s: 781.873 1613269797.6932127
train: epoch 32, iter 2400, loss: 2.811422, top_1: 0.568125, top_k: 0.794609, samples/s: 781.811 1613269830.4378061
train: epoch 32, iter 2500, loss: 2.649158, top_1: 0.566328, top_k: 0.794687, samples/s: 783.070 1613269863.1295376
train: epoch 32, iter 2600, loss: 2.779556, top_1: 0.565508, top_k: 0.796641, samples/s: 783.062 1613269895.821781
train: epoch 32, iter 2700, loss: 2.812750, top_1: 0.564219, top_k: 0.788516, samples/s: 782.956 1613269928.5184112
train: epoch 32, iter 2800, loss: 2.752295, top_1: 0.565898, top_k: 0.793828, samples/s: 781.599 1613269961.271719
train: epoch 32, iter 2900, loss: 2.902364, top_1: 0.559766, top_k: 0.790312, samples/s: 782.527 1613269993.9863126
train: epoch 32, iter 3000, loss: 2.814504, top_1: 0.563281, top_k: 0.794844, samples/s: 783.020 1613270026.680146
train: epoch 32, iter 3100, loss: 2.769223, top_1: 0.555898, top_k: 0.790273, samples/s: 784.198 1613270059.3250139
train: epoch 32, iter 3200, loss: 2.920434, top_1: 0.562617, top_k: 0.787578, samples/s: 781.275 1613270092.0920038
train: epoch 32, iter 3300, loss: 2.939792, top_1: 0.564023, top_k: 0.791445, samples/s: 785.127 1613270124.6982105
train: epoch 32, iter 3400, loss: 2.915201, top_1: 0.559922, top_k: 0.787500, samples/s: 782.356 1613270157.4198127
train: epoch 32, iter 3500, loss: 2.797934, top_1: 0.567930, top_k: 0.794961, samples/s: 782.307 1613270190.1435945
train: epoch 32, iter 3600, loss: 2.641150, top_1: 0.570234, top_k: 0.799180, samples/s: 783.309 1613270222.8255222
train: epoch 32, iter 3700, loss: 2.672412, top_1: 0.563828, top_k: 0.792617, samples/s: 782.831 1613270255.5273614
train: epoch 32, iter 3800, loss: 2.646224, top_1: 0.569883, top_k: 0.798203, samples/s: 783.953 1613270288.1823318
train: epoch 32, iter 3900, loss: 2.957044, top_1: 0.567109, top_k: 0.793477, samples/s: 783.047 1613270320.8751411
train: epoch 32, iter 4000, loss: 2.841203, top_1: 0.570195, top_k: 0.794453, samples/s: 779.214 1613270353.7287633
train: epoch 32, iter 4100, loss: 2.850155, top_1: 0.562305, top_k: 0.794961, samples/s: 783.706 1613270386.3939915
train: epoch 32, iter 4200, loss: 2.857921, top_1: 0.567070, top_k: 0.794805, samples/s: 784.032 1613270419.0458045
train: epoch 32, iter 4300, loss: 3.059503, top_1: 0.569805, top_k: 0.796641, samples/s: 782.622 1613270451.75632
train: epoch 32, iter 4400, loss: 2.587038, top_1: 0.563984, top_k: 0.794453, samples/s: 782.527 1613270484.470885
train: epoch 32, iter 4500, loss: 2.809902, top_1: 0.565859, top_k: 0.790430, samples/s: 783.342 1613270517.1513038
train: epoch 32, iter 4600, loss: 2.750357, top_1: 0.564766, top_k: 0.790781, samples/s: 778.115 1613270550.0513074
train: epoch 32, iter 4700, loss: 2.729367, top_1: 0.565156, top_k: 0.791172, samples/s: 783.603 1613270582.7209396
train: epoch 32, iter 4800, loss: 2.852068, top_1: 0.563516, top_k: 0.791211, samples/s: 782.659 1613270615.4300187
train: epoch 32, iter 4900, loss: 2.794246, top_1: 0.568711, top_k: 0.790859, samples/s: 780.660 1613270648.2227817
train: epoch 32, iter 5000, loss: 2.657171, top_1: 0.558984, top_k: 0.789570, samples/s: 782.323 1613270680.9458165
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_32.
validation: epoch 32, iter 195, top_1: 0.606991, top_k: 0.839022, samples/s: 2370.592 1613270702.9761295
train: epoch 33, iter 100, loss: 2.797674, top_1: 0.579336, top_k: 0.807461, samples/s: 803.678 1613270755.9697378
train: epoch 33, iter 200, loss: 2.763590, top_1: 0.578633, top_k: 0.801016, samples/s: 799.356 1613270787.9957335
train: epoch 33, iter 300, loss: 2.606251, top_1: 0.578945, top_k: 0.798047, samples/s: 783.500 1613270820.6693428
train: epoch 33, iter 400, loss: 2.789619, top_1: 0.578047, top_k: 0.808281, samples/s: 780.247 1613270853.479511
train: epoch 33, iter 500, loss: 3.036962, top_1: 0.577930, top_k: 0.801641, samples/s: 781.253 1613270886.247414
train: epoch 33, iter 600, loss: 2.824577, top_1: 0.572031, top_k: 0.793633, samples/s: 781.153 1613270919.0194664
train: epoch 33, iter 700, loss: 2.843885, top_1: 0.570703, top_k: 0.799258, samples/s: 782.054 1613270951.7537358
train: epoch 33, iter 800, loss: 2.880630, top_1: 0.572656, top_k: 0.800312, samples/s: 779.395 1613270984.5997298
train: epoch 33, iter 900, loss: 2.809485, top_1: 0.575273, top_k: 0.800703, samples/s: 779.258 1613271017.4515488
train: epoch 33, iter 1000, loss: 2.742723, top_1: 0.575898, top_k: 0.804453, samples/s: 779.633 1613271050.2875128
train: epoch 33, iter 1100, loss: 2.679222, top_1: 0.578320, top_k: 0.798594, samples/s: 784.837 1613271082.9056952
train: epoch 33, iter 1200, loss: 2.895088, top_1: 0.570117, top_k: 0.799766, samples/s: 779.770 1613271115.735879
train: epoch 33, iter 1300, loss: 2.737892, top_1: 0.567891, top_k: 0.795117, samples/s: 783.740 1613271148.39977
train: epoch 33, iter 1400, loss: 2.715135, top_1: 0.569961, top_k: 0.795625, samples/s: 780.274 1613271181.2088025
train: epoch 33, iter 1500, loss: 2.635327, top_1: 0.572187, top_k: 0.799063, samples/s: 778.894 1613271214.075969
train: epoch 33, iter 1600, loss: 2.718958, top_1: 0.572500, top_k: 0.795625, samples/s: 783.261 1613271246.7597475
train: epoch 33, iter 1700, loss: 2.717314, top_1: 0.567813, top_k: 0.794375, samples/s: 779.419 1613271279.604823
train: epoch 33, iter 1800, loss: 2.819964, top_1: 0.574336, top_k: 0.799375, samples/s: 782.941 1613271312.3019423
train: epoch 33, iter 1900, loss: 2.903958, top_1: 0.571328, top_k: 0.798555, samples/s: 780.420 1613271345.1047719
train: epoch 33, iter 2000, loss: 2.720448, top_1: 0.570742, top_k: 0.798438, samples/s: 782.845 1613271377.806018
train: epoch 33, iter 2100, loss: 2.943005, top_1: 0.567383, top_k: 0.793867, samples/s: 779.361 1613271410.6535072
train: epoch 33, iter 2200, loss: 2.625864, top_1: 0.566172, top_k: 0.793828, samples/s: 782.009 1613271443.3896952
train: epoch 33, iter 2300, loss: 2.633792, top_1: 0.567930, top_k: 0.792813, samples/s: 782.041 1613271476.1245644
train: epoch 33, iter 2400, loss: 2.909751, top_1: 0.564258, top_k: 0.792344, samples/s: 783.684 1613271508.7907546
train: epoch 33, iter 2500, loss: 2.888675, top_1: 0.568320, top_k: 0.794492, samples/s: 781.962 1613271541.5288804
train: epoch 33, iter 2600, loss: 2.913450, top_1: 0.570977, top_k: 0.795391, samples/s: 782.001 1613271574.2653966
train: epoch 33, iter 2700, loss: 2.813034, top_1: 0.568789, top_k: 0.797891, samples/s: 783.045 1613271606.9583442
train: epoch 33, iter 2800, loss: 2.984807, top_1: 0.568828, top_k: 0.795234, samples/s: 781.757 1613271639.7049656
train: epoch 33, iter 2900, loss: 2.490034, top_1: 0.564844, top_k: 0.794609, samples/s: 780.838 1613271672.4902916
train: epoch 33, iter 3000, loss: 2.820812, top_1: 0.566133, top_k: 0.788711, samples/s: 782.345 1613271705.2123654
train: epoch 33, iter 3100, loss: 2.782702, top_1: 0.569336, top_k: 0.797617, samples/s: 781.663 1613271737.963154
train: epoch 33, iter 3200, loss: 2.865245, top_1: 0.570234, top_k: 0.795234, samples/s: 782.280 1613271770.6880033
train: epoch 33, iter 3300, loss: 2.546095, top_1: 0.571758, top_k: 0.797070, samples/s: 783.407 1613271803.3658137
train: epoch 33, iter 3400, loss: 2.790111, top_1: 0.574492, top_k: 0.799531, samples/s: 783.946 1613271836.021065
train: epoch 33, iter 3500, loss: 2.737408, top_1: 0.566836, top_k: 0.793984, samples/s: 780.153 1613271868.835177
train: epoch 33, iter 3600, loss: 2.587549, top_1: 0.572344, top_k: 0.795820, samples/s: 784.874 1613271901.4518292
train: epoch 33, iter 3700, loss: 2.696798, top_1: 0.569922, top_k: 0.794883, samples/s: 781.801 1613271934.1968338
train: epoch 33, iter 3800, loss: 2.839113, top_1: 0.566445, top_k: 0.794727, samples/s: 781.401 1613271966.958819
train: epoch 33, iter 3900, loss: 2.824129, top_1: 0.573633, top_k: 0.798086, samples/s: 781.434 1613271999.7187047
train: epoch 33, iter 4000, loss: 2.869536, top_1: 0.574336, top_k: 0.801406, samples/s: 786.290 1613272032.2770422
train: epoch 33, iter 4100, loss: 2.673633, top_1: 0.560781, top_k: 0.793320, samples/s: 782.632 1613272064.986807
train: epoch 33, iter 4200, loss: 2.914691, top_1: 0.568008, top_k: 0.792617, samples/s: 780.442 1613272097.7887223
train: epoch 33, iter 4300, loss: 2.715453, top_1: 0.563125, top_k: 0.788906, samples/s: 783.136 1613272130.4779048
train: epoch 33, iter 4400, loss: 2.669112, top_1: 0.565273, top_k: 0.790469, samples/s: 781.215 1613272163.2473903
train: epoch 33, iter 4500, loss: 2.755223, top_1: 0.566445, top_k: 0.796055, samples/s: 782.249 1613272195.9734297
train: epoch 33, iter 4600, loss: 2.714780, top_1: 0.568047, top_k: 0.794531, samples/s: 781.085 1613272228.748463
train: epoch 33, iter 4700, loss: 2.718755, top_1: 0.571172, top_k: 0.795195, samples/s: 781.400 1613272261.5101538
train: epoch 33, iter 4800, loss: 2.772839, top_1: 0.563867, top_k: 0.790430, samples/s: 781.281 1613272294.2768548
train: epoch 33, iter 4900, loss: 2.905145, top_1: 0.565156, top_k: 0.794492, samples/s: 782.933 1613272326.97441
train: epoch 33, iter 5000, loss: 2.555003, top_1: 0.569336, top_k: 0.788750, samples/s: 782.740 1613272359.6800146
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_33.
validation: epoch 33, iter 195, top_1: 0.623377, top_k: 0.851342, samples/s: 2342.821 1613272381.9819753
train: epoch 34, iter 100, loss: 2.798995, top_1: 0.584336, top_k: 0.805586, samples/s: 804.837 1613272434.2785683
train: epoch 34, iter 200, loss: 2.750161, top_1: 0.578008, top_k: 0.800547, samples/s: 801.123 1613272466.2336986
train: epoch 34, iter 300, loss: 2.895669, top_1: 0.577969, top_k: 0.801016, samples/s: 782.894 1613272498.9329548
train: epoch 34, iter 400, loss: 2.834948, top_1: 0.580156, top_k: 0.807383, samples/s: 779.276 1613272531.7838142
train: epoch 34, iter 500, loss: 2.700578, top_1: 0.573008, top_k: 0.802188, samples/s: 780.366 1613272564.5889616
train: epoch 34, iter 600, loss: 2.772857, top_1: 0.575156, top_k: 0.803477, samples/s: 780.974 1613272597.3685515
train: epoch 34, iter 700, loss: 2.506138, top_1: 0.575234, top_k: 0.803984, samples/s: 781.669 1613272630.1189058
train: epoch 34, iter 800, loss: 2.496262, top_1: 0.583125, top_k: 0.804141, samples/s: 780.613 1613272662.913722
train: epoch 34, iter 900, loss: 2.706539, top_1: 0.575313, top_k: 0.798594, samples/s: 781.528 1613272695.6700618
train: epoch 34, iter 1000, loss: 2.760483, top_1: 0.575273, top_k: 0.797383, samples/s: 780.249 1613272728.4800508
train: epoch 34, iter 1100, loss: 2.803865, top_1: 0.576523, top_k: 0.799414, samples/s: 782.991 1613272761.1751504
train: epoch 34, iter 1200, loss: 2.863707, top_1: 0.575000, top_k: 0.800664, samples/s: 781.562 1613272793.930038
train: epoch 34, iter 1300, loss: 3.079345, top_1: 0.574297, top_k: 0.800156, samples/s: 781.177 1613272826.7011185
train: epoch 34, iter 1400, loss: 2.834996, top_1: 0.567266, top_k: 0.795430, samples/s: 780.277 1613272859.5100155
train: epoch 34, iter 1500, loss: 2.822826, top_1: 0.575000, top_k: 0.799492, samples/s: 783.328 1613272892.1910834
train: epoch 34, iter 1600, loss: 2.777340, top_1: 0.572617, top_k: 0.800000, samples/s: 781.889 1613272924.9323936
train: epoch 34, iter 1700, loss: 2.875515, top_1: 0.571484, top_k: 0.790937, samples/s: 780.212 1613272957.743965
train: epoch 34, iter 1800, loss: 2.826260, top_1: 0.574531, top_k: 0.797109, samples/s: 781.577 1613272990.4982655
train: epoch 34, iter 1900, loss: 2.914208, top_1: 0.570039, top_k: 0.795898, samples/s: 781.885 1613273023.2395797
train: epoch 34, iter 2000, loss: 2.601412, top_1: 0.572031, top_k: 0.796133, samples/s: 781.633 1613273055.9915705
train: epoch 34, iter 2100, loss: 2.901481, top_1: 0.564883, top_k: 0.792188, samples/s: 781.217 1613273088.7609854
train: epoch 34, iter 2200, loss: 2.797494, top_1: 0.569492, top_k: 0.800273, samples/s: 782.435 1613273121.4793537
train: epoch 34, iter 2300, loss: 2.710491, top_1: 0.573008, top_k: 0.800977, samples/s: 779.821 1613273154.307303
train: epoch 34, iter 2400, loss: 2.815683, top_1: 0.563125, top_k: 0.792422, samples/s: 781.450 1613273187.0670094
train: epoch 34, iter 2500, loss: 2.860737, top_1: 0.578555, top_k: 0.799375, samples/s: 780.124 1613273219.8822587
train: epoch 34, iter 2600, loss: 2.838813, top_1: 0.570508, top_k: 0.795937, samples/s: 779.984 1613273252.7034073
train: epoch 34, iter 2700, loss: 2.660503, top_1: 0.572148, top_k: 0.795977, samples/s: 779.694 1613273285.53684
train: epoch 34, iter 2800, loss: 2.698524, top_1: 0.568203, top_k: 0.794844, samples/s: 782.110 1613273318.2688377
train: epoch 34, iter 2900, loss: 2.824343, top_1: 0.568164, top_k: 0.797773, samples/s: 781.884 1613273351.0103061
train: epoch 34, iter 3000, loss: 2.629824, top_1: 0.562969, top_k: 0.791797, samples/s: 781.164 1613273383.7818816
train: epoch 34, iter 3100, loss: 2.809403, top_1: 0.568594, top_k: 0.791172, samples/s: 780.566 1613273416.5785487
train: epoch 34, iter 3200, loss: 2.858186, top_1: 0.570312, top_k: 0.792930, samples/s: 782.047 1613273449.3131285
train: epoch 34, iter 3300, loss: 2.668198, top_1: 0.572461, top_k: 0.796289, samples/s: 783.832 1613273481.973247
train: epoch 34, iter 3400, loss: 2.812996, top_1: 0.568750, top_k: 0.796758, samples/s: 782.001 1613273514.7097702
train: epoch 34, iter 3500, loss: 2.786883, top_1: 0.569766, top_k: 0.795117, samples/s: 780.571 1613273547.506324
train: epoch 34, iter 3600, loss: 2.573026, top_1: 0.573086, top_k: 0.797617, samples/s: 781.322 1613273580.2712882
train: epoch 34, iter 3700, loss: 2.972922, top_1: 0.565586, top_k: 0.794297, samples/s: 782.208 1613273612.999071
train: epoch 34, iter 3800, loss: 2.902247, top_1: 0.568633, top_k: 0.794297, samples/s: 782.468 1613273645.7160985
train: epoch 34, iter 3900, loss: 2.664071, top_1: 0.568164, top_k: 0.794297, samples/s: 780.082 1613273678.5331876
train: epoch 34, iter 4000, loss: 2.955935, top_1: 0.565273, top_k: 0.795156, samples/s: 781.504 1613273711.2904656
train: epoch 34, iter 4100, loss: 2.821317, top_1: 0.570703, top_k: 0.793906, samples/s: 781.523 1613273744.047107
train: epoch 34, iter 4200, loss: 3.144056, top_1: 0.568984, top_k: 0.791953, samples/s: 782.476 1613273776.763672
train: epoch 34, iter 4300, loss: 3.205903, top_1: 0.562656, top_k: 0.790312, samples/s: 779.486 1613273809.6059315
train: epoch 34, iter 4400, loss: 2.938255, top_1: 0.566055, top_k: 0.791797, samples/s: 780.885 1613273842.3892565
train: epoch 34, iter 4500, loss: 2.991377, top_1: 0.563945, top_k: 0.791445, samples/s: 784.312 1613273875.0293205
train: epoch 34, iter 4600, loss: 2.608215, top_1: 0.570430, top_k: 0.797773, samples/s: 780.319 1613273907.83644
train: epoch 34, iter 4700, loss: 2.849116, top_1: 0.565430, top_k: 0.794531, samples/s: 782.532 1613273940.550676
train: epoch 34, iter 4800, loss: 2.645593, top_1: 0.568828, top_k: 0.793164, samples/s: 781.916 1613273973.29079
train: epoch 34, iter 4900, loss: 2.703380, top_1: 0.568438, top_k: 0.799336, samples/s: 781.087 1613274006.0656881
train: epoch 34, iter 5000, loss: 2.754552, top_1: 0.571250, top_k: 0.795625, samples/s: 783.352 1613274038.7457588
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_34.
validation: epoch 34, iter 195, top_1: 0.619852, top_k: 0.852444, samples/s: 2356.351 1613274060.8896253
train: epoch 35, iter 100, loss: 2.574781, top_1: 0.591719, top_k: 0.813477, samples/s: 805.594 1613274119.5681112
train: epoch 35, iter 200, loss: 2.738782, top_1: 0.583398, top_k: 0.804141, samples/s: 802.684 1613274151.4613895
train: epoch 35, iter 300, loss: 2.576988, top_1: 0.577852, top_k: 0.808750, samples/s: 786.928 1613274183.9926822
train: epoch 35, iter 400, loss: 2.669316, top_1: 0.585469, top_k: 0.807578, samples/s: 782.597 1613274216.7042584
train: epoch 35, iter 500, loss: 2.735482, top_1: 0.578203, top_k: 0.802695, samples/s: 781.847 1613274249.447228
train: epoch 35, iter 600, loss: 2.729109, top_1: 0.568945, top_k: 0.797305, samples/s: 776.441 1613274282.4182136
train: epoch 35, iter 700, loss: 2.603039, top_1: 0.575664, top_k: 0.797891, samples/s: 778.815 1613274315.288627
train: epoch 35, iter 800, loss: 2.760655, top_1: 0.573242, top_k: 0.799922, samples/s: 779.801 1613274348.1175563
train: epoch 35, iter 900, loss: 2.632139, top_1: 0.573203, top_k: 0.798242, samples/s: 780.478 1613274380.9179769
train: epoch 35, iter 1000, loss: 2.826510, top_1: 0.575352, top_k: 0.804453, samples/s: 778.172 1613274413.8155396
train: epoch 35, iter 1100, loss: 2.690115, top_1: 0.578125, top_k: 0.802461, samples/s: 781.087 1613274446.5904534
train: epoch 35, iter 1200, loss: 2.626466, top_1: 0.575078, top_k: 0.799766, samples/s: 778.994 1613274479.4532926
train: epoch 35, iter 1300, loss: 2.685068, top_1: 0.573633, top_k: 0.798555, samples/s: 780.806 1613274512.2399735
train: epoch 35, iter 1400, loss: 2.919757, top_1: 0.574453, top_k: 0.802500, samples/s: 782.864 1613274544.9404178
train: epoch 35, iter 1500, loss: 2.805837, top_1: 0.576758, top_k: 0.800312, samples/s: 778.051 1613274577.843121
train: epoch 35, iter 1600, loss: 2.883510, top_1: 0.572773, top_k: 0.793242, samples/s: 783.518 1613274610.5162027
train: epoch 35, iter 1700, loss: 2.925362, top_1: 0.574648, top_k: 0.801445, samples/s: 780.301 1613274643.3240657
train: epoch 35, iter 1800, loss: 2.941494, top_1: 0.575117, top_k: 0.803242, samples/s: 778.985 1613274676.1873977
train: epoch 35, iter 1900, loss: 2.678159, top_1: 0.569727, top_k: 0.792148, samples/s: 784.802 1613274708.8070917
train: epoch 35, iter 2000, loss: 3.034385, top_1: 0.570625, top_k: 0.795781, samples/s: 779.602 1613274741.644296
train: epoch 35, iter 2100, loss: 2.915095, top_1: 0.571172, top_k: 0.796094, samples/s: 781.786 1613274774.389817
train: epoch 35, iter 2200, loss: 2.847479, top_1: 0.567969, top_k: 0.794531, samples/s: 778.659 1613274807.2667823
train: epoch 35, iter 2300, loss: 2.673819, top_1: 0.569531, top_k: 0.795625, samples/s: 785.294 1613274839.866044
train: epoch 35, iter 2400, loss: 2.813373, top_1: 0.571172, top_k: 0.797031, samples/s: 782.676 1613274872.5743885
train: epoch 35, iter 2500, loss: 2.829801, top_1: 0.569844, top_k: 0.795781, samples/s: 780.513 1613274905.373405
train: epoch 35, iter 2600, loss: 2.805616, top_1: 0.567578, top_k: 0.793867, samples/s: 782.854 1613274938.074427
train: epoch 35, iter 2700, loss: 2.795027, top_1: 0.578242, top_k: 0.803516, samples/s: 783.294 1613274970.7566497
train: epoch 35, iter 2800, loss: 2.795161, top_1: 0.567383, top_k: 0.795352, samples/s: 781.714 1613275003.5055425
train: epoch 35, iter 2900, loss: 2.759238, top_1: 0.573594, top_k: 0.793008, samples/s: 782.009 1613275036.2414796
train: epoch 35, iter 3000, loss: 2.751458, top_1: 0.571953, top_k: 0.797500, samples/s: 780.281 1613275069.0500588
train: epoch 35, iter 3100, loss: 2.823792, top_1: 0.571445, top_k: 0.791523, samples/s: 783.065 1613275101.7422032
train: epoch 35, iter 3200, loss: 2.982155, top_1: 0.573516, top_k: 0.797891, samples/s: 781.194 1613275134.512516
train: epoch 35, iter 3300, loss: 2.853312, top_1: 0.570664, top_k: 0.797617, samples/s: 782.210 1613275167.2402577
train: epoch 35, iter 3400, loss: 2.650461, top_1: 0.575273, top_k: 0.796680, samples/s: 780.044 1613275200.0590272
train: epoch 35, iter 3500, loss: 2.803236, top_1: 0.570234, top_k: 0.794922, samples/s: 782.501 1613275232.7745755
train: epoch 35, iter 3600, loss: 2.733027, top_1: 0.561680, top_k: 0.793633, samples/s: 781.536 1613275265.530573
train: epoch 35, iter 3700, loss: 2.918840, top_1: 0.570547, top_k: 0.798633, samples/s: 781.783 1613275298.2762268
train: epoch 35, iter 3800, loss: 2.690038, top_1: 0.567852, top_k: 0.794141, samples/s: 779.515 1613275331.117296
train: epoch 35, iter 3900, loss: 2.737568, top_1: 0.571562, top_k: 0.797227, samples/s: 783.292 1613275363.7998154
train: epoch 35, iter 4000, loss: 2.586749, top_1: 0.567539, top_k: 0.792383, samples/s: 783.518 1613275396.47293
train: epoch 35, iter 4100, loss: 2.915463, top_1: 0.562031, top_k: 0.796602, samples/s: 780.388 1613275429.2771773
train: epoch 35, iter 4200, loss: 2.787383, top_1: 0.568945, top_k: 0.795508, samples/s: 782.358 1613275461.998683
train: epoch 35, iter 4300, loss: 2.810238, top_1: 0.569648, top_k: 0.800117, samples/s: 780.939 1613275494.7797642
train: epoch 35, iter 4400, loss: 2.557070, top_1: 0.570508, top_k: 0.795664, samples/s: 781.013 1613275527.5577245
train: epoch 35, iter 4500, loss: 3.062785, top_1: 0.573828, top_k: 0.793164, samples/s: 781.773 1613275560.3038454
train: epoch 35, iter 4600, loss: 2.910456, top_1: 0.569453, top_k: 0.797344, samples/s: 780.770 1613275593.091904
train: epoch 35, iter 4700, loss: 2.826092, top_1: 0.567656, top_k: 0.793398, samples/s: 781.879 1613275625.8336122
train: epoch 35, iter 4800, loss: 2.849548, top_1: 0.566211, top_k: 0.792578, samples/s: 781.597 1613275658.5869906
train: epoch 35, iter 4900, loss: 2.647202, top_1: 0.569648, top_k: 0.798906, samples/s: 782.657 1613275691.2960622
train: epoch 35, iter 5000, loss: 2.754875, top_1: 0.564961, top_k: 0.787813, samples/s: 778.709 1613275724.1710787
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_35.
validation: epoch 35, iter 195, top_1: 0.587740, top_k: 0.823638, samples/s: 2381.549 1613275746.1152277
train: epoch 36, iter 100, loss: 2.735856, top_1: 0.568555, top_k: 0.795234, samples/s: 805.083 1613275798.749416
train: epoch 36, iter 200, loss: 2.739862, top_1: 0.576797, top_k: 0.801719, samples/s: 799.490 1613275830.7697458
train: epoch 36, iter 300, loss: 2.701867, top_1: 0.582461, top_k: 0.804766, samples/s: 785.327 1613275863.367709
train: epoch 36, iter 400, loss: 2.800222, top_1: 0.576289, top_k: 0.800898, samples/s: 778.896 1613275896.234697
train: epoch 36, iter 500, loss: 2.728781, top_1: 0.576289, top_k: 0.799297, samples/s: 779.393 1613275929.0807724
train: epoch 36, iter 600, loss: 2.911230, top_1: 0.573320, top_k: 0.800078, samples/s: 781.703 1613275961.829741
train: epoch 36, iter 700, loss: 2.831465, top_1: 0.582422, top_k: 0.805312, samples/s: 780.815 1613275994.6159856
train: epoch 36, iter 800, loss: 2.769046, top_1: 0.572812, top_k: 0.801133, samples/s: 778.854 1613276027.484782
train: epoch 36, iter 900, loss: 2.708313, top_1: 0.573320, top_k: 0.799727, samples/s: 781.828 1613276060.2286487
train: epoch 36, iter 1000, loss: 2.753156, top_1: 0.574805, top_k: 0.803008, samples/s: 782.938 1613276092.9259632
train: epoch 36, iter 1100, loss: 2.820382, top_1: 0.572539, top_k: 0.797656, samples/s: 780.406 1613276125.7294626
train: epoch 36, iter 1200, loss: 2.656497, top_1: 0.572148, top_k: 0.797422, samples/s: 781.587 1613276158.4832816
train: epoch 36, iter 1300, loss: 2.558315, top_1: 0.576211, top_k: 0.798281, samples/s: 779.090 1613276191.3422325
train: epoch 36, iter 1400, loss: 2.732920, top_1: 0.581797, top_k: 0.804727, samples/s: 780.783 1613276224.1297965
train: epoch 36, iter 1500, loss: 2.667276, top_1: 0.572734, top_k: 0.798828, samples/s: 780.660 1613276256.9224975
train: epoch 36, iter 1600, loss: 2.785892, top_1: 0.577266, top_k: 0.805547, samples/s: 781.477 1613276289.6809545
train: epoch 36, iter 1700, loss: 2.651489, top_1: 0.573750, top_k: 0.800391, samples/s: 781.394 1613276322.442991
train: epoch 36, iter 1800, loss: 2.734086, top_1: 0.571055, top_k: 0.797813, samples/s: 780.103 1613276355.2591374
train: epoch 36, iter 1900, loss: 2.638352, top_1: 0.574922, top_k: 0.798672, samples/s: 780.829 1613276388.0447404
train: epoch 36, iter 2000, loss: 2.685215, top_1: 0.578047, top_k: 0.800781, samples/s: 781.388 1613276420.8069916
train: epoch 36, iter 2100, loss: 2.821661, top_1: 0.568164, top_k: 0.794063, samples/s: 785.121 1613276453.4135253
train: epoch 36, iter 2200, loss: 3.024798, top_1: 0.572148, top_k: 0.798008, samples/s: 778.004 1613276486.318261
train: epoch 36, iter 2300, loss: 2.756891, top_1: 0.576211, top_k: 0.800312, samples/s: 780.795 1613276519.105376
train: epoch 36, iter 2400, loss: 2.822676, top_1: 0.570898, top_k: 0.793750, samples/s: 779.383 1613276551.9517903
train: epoch 36, iter 2500, loss: 2.726173, top_1: 0.567656, top_k: 0.793633, samples/s: 783.559 1613276584.6232133
train: epoch 36, iter 2600, loss: 2.619920, top_1: 0.570547, top_k: 0.797031, samples/s: 780.610 1613276617.418111
train: epoch 36, iter 2700, loss: 2.761200, top_1: 0.570273, top_k: 0.796484, samples/s: 782.776 1613276650.1221917
train: epoch 36, iter 2800, loss: 2.755562, top_1: 0.567539, top_k: 0.795977, samples/s: 780.944 1613276682.902992
train: epoch 36, iter 2900, loss: 2.805900, top_1: 0.574258, top_k: 0.801445, samples/s: 780.121 1613276715.718493
train: epoch 36, iter 3000, loss: 2.886958, top_1: 0.572187, top_k: 0.799453, samples/s: 782.170 1613276748.4479277
train: epoch 36, iter 3100, loss: 2.759144, top_1: 0.570273, top_k: 0.795391, samples/s: 780.752 1613276781.23682
train: epoch 36, iter 3200, loss: 2.803231, top_1: 0.573281, top_k: 0.794297, samples/s: 782.828 1613276813.9387095
train: epoch 36, iter 3300, loss: 2.650284, top_1: 0.574336, top_k: 0.799180, samples/s: 781.644 1613276846.6902585
train: epoch 36, iter 3400, loss: 2.666511, top_1: 0.574609, top_k: 0.797461, samples/s: 779.851 1613276879.5169513
train: epoch 36, iter 3500, loss: 2.835523, top_1: 0.569141, top_k: 0.795195, samples/s: 780.958 1613276912.297278
train: epoch 36, iter 3600, loss: 2.975278, top_1: 0.566562, top_k: 0.795195, samples/s: 781.563 1613276945.052127
train: epoch 36, iter 3700, loss: 2.559926, top_1: 0.574375, top_k: 0.799531, samples/s: 783.140 1613276977.7410111
train: epoch 36, iter 3800, loss: 2.727869, top_1: 0.569766, top_k: 0.798516, samples/s: 779.653 1613277010.5762038
train: epoch 36, iter 3900, loss: 2.552994, top_1: 0.571367, top_k: 0.799805, samples/s: 780.754 1613277043.3649085
train: epoch 36, iter 4000, loss: 2.689703, top_1: 0.572266, top_k: 0.797930, samples/s: 783.191 1613277076.051731
train: epoch 36, iter 4100, loss: 2.735579, top_1: 0.574219, top_k: 0.798906, samples/s: 780.660 1613277108.8444743
train: epoch 36, iter 4200, loss: 2.820990, top_1: 0.565781, top_k: 0.792539, samples/s: 782.675 1613277141.55287
train: epoch 36, iter 4300, loss: 2.861867, top_1: 0.567969, top_k: 0.795508, samples/s: 779.084 1613277174.4119594
train: epoch 36, iter 4400, loss: 2.818545, top_1: 0.572266, top_k: 0.800117, samples/s: 783.050 1613277207.1046371
train: epoch 36, iter 4500, loss: 2.804253, top_1: 0.567617, top_k: 0.796289, samples/s: 780.214 1613277239.916093
train: epoch 36, iter 4600, loss: 2.680880, top_1: 0.565469, top_k: 0.792891, samples/s: 781.754 1613277272.663052
train: epoch 36, iter 4700, loss: 2.738247, top_1: 0.571484, top_k: 0.795664, samples/s: 782.014 1613277305.3989575
train: epoch 36, iter 4800, loss: 2.695177, top_1: 0.575703, top_k: 0.794805, samples/s: 781.983 1613277338.1363232
train: epoch 36, iter 4900, loss: 2.492283, top_1: 0.573633, top_k: 0.796484, samples/s: 781.720 1613277370.8845706
train: epoch 36, iter 5000, loss: 2.957011, top_1: 0.571328, top_k: 0.798945, samples/s: 782.141 1613277403.6152837
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_36.
validation: epoch 36, iter 195, top_1: 0.630829, top_k: 0.854207, samples/s: 2387.120 1613277425.4941545
train: epoch 37, iter 100, loss: 2.578573, top_1: 0.582148, top_k: 0.805898, samples/s: 805.190 1613277477.8134336
train: epoch 37, iter 200, loss: 2.760143, top_1: 0.583164, top_k: 0.807070, samples/s: 798.598 1613277509.8696804
train: epoch 37, iter 300, loss: 2.707236, top_1: 0.584844, top_k: 0.808125, samples/s: 785.013 1613277542.4804478
train: epoch 37, iter 400, loss: 2.808743, top_1: 0.584102, top_k: 0.807969, samples/s: 782.841 1613277575.1819255
train: epoch 37, iter 500, loss: 2.858167, top_1: 0.585781, top_k: 0.809453, samples/s: 779.703 1613277608.0148678
train: epoch 37, iter 600, loss: 2.761483, top_1: 0.578281, top_k: 0.804219, samples/s: 780.888 1613277640.7980866
train: epoch 37, iter 700, loss: 2.483451, top_1: 0.578711, top_k: 0.804961, samples/s: 780.484 1613277673.5982966
train: epoch 37, iter 800, loss: 2.698234, top_1: 0.578945, top_k: 0.801250, samples/s: 778.812 1613277706.4689057
train: epoch 37, iter 900, loss: 2.731169, top_1: 0.574883, top_k: 0.800000, samples/s: 781.939 1613277739.2079751
train: epoch 37, iter 1000, loss: 2.921187, top_1: 0.572617, top_k: 0.800664, samples/s: 780.702 1613277771.9989123
train: epoch 37, iter 1100, loss: 2.760523, top_1: 0.573789, top_k: 0.798789, samples/s: 781.496 1613277804.7566187
train: epoch 37, iter 1200, loss: 2.613096, top_1: 0.575742, top_k: 0.802813, samples/s: 779.664 1613277837.5912747
train: epoch 37, iter 1300, loss: 2.755393, top_1: 0.580313, top_k: 0.805273, samples/s: 783.241 1613277870.2759721
train: epoch 37, iter 1400, loss: 2.600657, top_1: 0.573047, top_k: 0.803398, samples/s: 782.168 1613277903.0055506
train: epoch 37, iter 1500, loss: 2.763929, top_1: 0.573984, top_k: 0.798750, samples/s: 780.769 1613277935.793732
train: epoch 37, iter 1600, loss: 2.949540, top_1: 0.573984, top_k: 0.804180, samples/s: 780.815 1613277968.5800035
train: epoch 37, iter 1700, loss: 2.908284, top_1: 0.571250, top_k: 0.797305, samples/s: 782.841 1613278001.281429
train: epoch 37, iter 1800, loss: 2.824963, top_1: 0.577656, top_k: 0.801367, samples/s: 784.352 1613278033.919813
train: epoch 37, iter 1900, loss: 2.863871, top_1: 0.572695, top_k: 0.800312, samples/s: 782.154 1613278066.6498814
train: epoch 37, iter 2000, loss: 2.772979, top_1: 0.576094, top_k: 0.801211, samples/s: 779.555 1613278099.4891977
train: epoch 37, iter 2100, loss: 2.769458, top_1: 0.574648, top_k: 0.799609, samples/s: 781.519 1613278132.245871
train: epoch 37, iter 2200, loss: 2.758658, top_1: 0.572187, top_k: 0.802500, samples/s: 785.273 1613278164.8459523
train: epoch 37, iter 2300, loss: 2.654773, top_1: 0.578750, top_k: 0.801211, samples/s: 780.477 1613278197.646461
train: epoch 37, iter 2400, loss: 2.703123, top_1: 0.574258, top_k: 0.798750, samples/s: 782.910 1613278230.3449323
train: epoch 37, iter 2500, loss: 2.659340, top_1: 0.571133, top_k: 0.797539, samples/s: 779.581 1613278263.183049
train: epoch 37, iter 2600, loss: 2.683541, top_1: 0.576172, top_k: 0.800352, samples/s: 780.201 1613278295.9951465
train: epoch 37, iter 2700, loss: 2.794209, top_1: 0.571797, top_k: 0.797539, samples/s: 784.630 1613278328.6218936
train: epoch 37, iter 2800, loss: 2.904961, top_1: 0.575703, top_k: 0.795820, samples/s: 778.895 1613278361.4889936
train: epoch 37, iter 2900, loss: 2.499326, top_1: 0.576289, top_k: 0.801055, samples/s: 782.362 1613278394.2105048
train: epoch 37, iter 3000, loss: 2.949730, top_1: 0.575586, top_k: 0.800625, samples/s: 781.055 1613278426.9866252
train: epoch 37, iter 3100, loss: 2.720753, top_1: 0.573203, top_k: 0.799961, samples/s: 782.279 1613278459.7115598
train: epoch 37, iter 3200, loss: 2.565572, top_1: 0.576445, top_k: 0.800703, samples/s: 782.389 1613278492.4318476
train: epoch 37, iter 3300, loss: 2.689001, top_1: 0.568164, top_k: 0.795469, samples/s: 780.932 1613278525.2131507
train: epoch 37, iter 3400, loss: 2.840836, top_1: 0.577461, top_k: 0.799961, samples/s: 781.001 1613278557.9915953
train: epoch 37, iter 3500, loss: 2.740062, top_1: 0.574414, top_k: 0.798867, samples/s: 781.939 1613278590.730732
train: epoch 37, iter 3600, loss: 2.748820, top_1: 0.567344, top_k: 0.793945, samples/s: 783.202 1613278623.4170887
train: epoch 37, iter 3700, loss: 2.619182, top_1: 0.571992, top_k: 0.794766, samples/s: 782.064 1613278656.1509607
train: epoch 37, iter 3800, loss: 2.808967, top_1: 0.569844, top_k: 0.796172, samples/s: 780.295 1613278688.9590566
train: epoch 37, iter 3900, loss: 2.798733, top_1: 0.576328, top_k: 0.796719, samples/s: 782.679 1613278721.6673172
train: epoch 37, iter 4000, loss: 2.719074, top_1: 0.568594, top_k: 0.794414, samples/s: 780.941 1613278754.4482274
train: epoch 37, iter 4100, loss: 2.811541, top_1: 0.573945, top_k: 0.800352, samples/s: 781.383 1613278787.2106085
train: epoch 37, iter 4200, loss: 2.794440, top_1: 0.574219, top_k: 0.800508, samples/s: 780.894 1613278819.9935348
train: epoch 37, iter 4300, loss: 2.817646, top_1: 0.574180, top_k: 0.798008, samples/s: 783.210 1613278852.6796489
train: epoch 37, iter 4400, loss: 2.791590, top_1: 0.574453, top_k: 0.799609, samples/s: 781.963 1613278885.4176624
train: epoch 37, iter 4500, loss: 2.811021, top_1: 0.569805, top_k: 0.796016, samples/s: 783.125 1613278918.10732
train: epoch 37, iter 4600, loss: 2.589315, top_1: 0.571367, top_k: 0.795430, samples/s: 783.580 1613278950.7778862
train: epoch 37, iter 4700, loss: 2.854632, top_1: 0.577695, top_k: 0.797617, samples/s: 779.076 1613278983.6372378
train: epoch 37, iter 4800, loss: 2.955346, top_1: 0.566250, top_k: 0.793789, samples/s: 782.184 1613279016.3661268
train: epoch 37, iter 4900, loss: 2.838565, top_1: 0.570898, top_k: 0.795391, samples/s: 781.799 1613279049.1111138
train: epoch 37, iter 5000, loss: 2.724703, top_1: 0.578477, top_k: 0.801875, samples/s: 783.108 1613279081.8014593
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_37.
validation: epoch 37, iter 195, top_1: 0.624900, top_k: 0.854667, samples/s: 2331.353 1613279104.1853936
train: epoch 38, iter 100, loss: 2.662571, top_1: 0.586953, top_k: 0.813633, samples/s: 804.203 1613279156.892595
train: epoch 38, iter 200, loss: 2.759837, top_1: 0.586914, top_k: 0.804648, samples/s: 799.365 1613279188.9182413
train: epoch 38, iter 300, loss: 2.686483, top_1: 0.586133, top_k: 0.808945, samples/s: 781.212 1613279221.6875865
train: epoch 38, iter 400, loss: 2.656923, top_1: 0.580977, top_k: 0.804922, samples/s: 782.847 1613279254.3886352
train: epoch 38, iter 500, loss: 2.621898, top_1: 0.586016, top_k: 0.807930, samples/s: 778.295 1613279287.2811224
train: epoch 38, iter 600, loss: 2.790413, top_1: 0.573789, top_k: 0.801094, samples/s: 781.599 1613279320.034461
train: epoch 38, iter 700, loss: 2.885000, top_1: 0.577266, top_k: 0.799727, samples/s: 778.877 1613279352.9023168
train: epoch 38, iter 800, loss: 2.787751, top_1: 0.576367, top_k: 0.798750, samples/s: 778.846 1613279385.7714815
train: epoch 38, iter 900, loss: 2.759995, top_1: 0.578750, top_k: 0.801797, samples/s: 779.824 1613279418.5993161
train: epoch 38, iter 1000, loss: 2.771738, top_1: 0.578906, top_k: 0.802578, samples/s: 781.195 1613279451.36958
train: epoch 38, iter 1100, loss: 2.616212, top_1: 0.574922, top_k: 0.801172, samples/s: 779.128 1613279484.226854
train: epoch 38, iter 1200, loss: 2.629340, top_1: 0.575508, top_k: 0.799453, samples/s: 780.563 1613279517.0237598
train: epoch 38, iter 1300, loss: 2.781170, top_1: 0.577500, top_k: 0.803008, samples/s: 781.353 1613279549.7874322
train: epoch 38, iter 1400, loss: 2.499155, top_1: 0.579375, top_k: 0.803516, samples/s: 780.692 1613279582.5788052
train: epoch 38, iter 1500, loss: 2.627579, top_1: 0.588828, top_k: 0.809648, samples/s: 782.258 1613279615.304617
train: epoch 38, iter 1600, loss: 2.673497, top_1: 0.584258, top_k: 0.804219, samples/s: 780.051 1613279648.1230311
train: epoch 38, iter 1700, loss: 2.969972, top_1: 0.579180, top_k: 0.799648, samples/s: 781.099 1613279680.8972893
train: epoch 38, iter 1800, loss: 2.858408, top_1: 0.573125, top_k: 0.801250, samples/s: 783.406 1613279713.5751863
train: epoch 38, iter 1900, loss: 2.814137, top_1: 0.578086, top_k: 0.802227, samples/s: 781.048 1613279746.3516192
train: epoch 38, iter 2000, loss: 2.725691, top_1: 0.578672, top_k: 0.804961, samples/s: 781.243 1613279779.1200216
train: epoch 38, iter 2100, loss: 2.434530, top_1: 0.577109, top_k: 0.801836, samples/s: 778.212 1613279812.015814
train: epoch 38, iter 2200, loss: 2.667437, top_1: 0.578555, top_k: 0.801953, samples/s: 784.482 1613279844.648798
train: epoch 38, iter 2300, loss: 2.597868, top_1: 0.574648, top_k: 0.800430, samples/s: 779.686 1613279877.4825668
train: epoch 38, iter 2400, loss: 2.712026, top_1: 0.578516, top_k: 0.800078, samples/s: 777.578 1613279910.4052234
train: epoch 38, iter 2500, loss: 2.740417, top_1: 0.572891, top_k: 0.798984, samples/s: 781.112 1613279943.1790283
train: epoch 38, iter 2600, loss: 2.858433, top_1: 0.572578, top_k: 0.795820, samples/s: 779.358 1613279976.0265684
train: epoch 38, iter 2700, loss: 2.654599, top_1: 0.573516, top_k: 0.798008, samples/s: 782.264 1613280008.752071
train: epoch 38, iter 2800, loss: 2.643580, top_1: 0.576016, top_k: 0.798828, samples/s: 778.396 1613280041.6402097
train: epoch 38, iter 2900, loss: 2.712025, top_1: 0.576875, top_k: 0.801328, samples/s: 783.067 1613280074.3322024
train: epoch 38, iter 3000, loss: 2.928751, top_1: 0.569570, top_k: 0.798594, samples/s: 779.219 1613280107.1855948
train: epoch 38, iter 3100, loss: 2.629845, top_1: 0.580195, top_k: 0.800078, samples/s: 781.409 1613280139.9470062
train: epoch 38, iter 3200, loss: 2.791223, top_1: 0.571250, top_k: 0.798633, samples/s: 779.307 1613280172.7966387
train: epoch 38, iter 3300, loss: 2.716150, top_1: 0.573125, top_k: 0.800937, samples/s: 780.989 1613280205.575633
train: epoch 38, iter 3400, loss: 2.640505, top_1: 0.571484, top_k: 0.801602, samples/s: 780.860 1613280238.360041
train: epoch 38, iter 3500, loss: 2.741847, top_1: 0.575586, top_k: 0.802500, samples/s: 780.146 1613280271.1743665
train: epoch 38, iter 3600, loss: 2.690557, top_1: 0.576445, top_k: 0.802070, samples/s: 780.965 1613280303.9542716
train: epoch 38, iter 3700, loss: 2.657763, top_1: 0.574766, top_k: 0.799570, samples/s: 782.370 1613280336.6754603
train: epoch 38, iter 3800, loss: 2.698870, top_1: 0.572070, top_k: 0.793281, samples/s: 778.653 1613280369.552615
train: epoch 38, iter 3900, loss: 2.835223, top_1: 0.573359, top_k: 0.798555, samples/s: 782.830 1613280402.2545862
train: epoch 38, iter 4000, loss: 2.759898, top_1: 0.577773, top_k: 0.802266, samples/s: 779.940 1613280435.0776289
train: epoch 38, iter 4100, loss: 2.773711, top_1: 0.574844, top_k: 0.803359, samples/s: 782.127 1613280467.8088112
train: epoch 38, iter 4200, loss: 2.685603, top_1: 0.573086, top_k: 0.798555, samples/s: 781.692 1613280500.5583649
train: epoch 38, iter 4300, loss: 2.817624, top_1: 0.573281, top_k: 0.798867, samples/s: 780.300 1613280533.3663015
train: epoch 38, iter 4400, loss: 2.690256, top_1: 0.571602, top_k: 0.797188, samples/s: 779.933 1613280566.1894815
train: epoch 38, iter 4500, loss: 2.903659, top_1: 0.571055, top_k: 0.797773, samples/s: 782.945 1613280598.886533
train: epoch 38, iter 4600, loss: 2.656644, top_1: 0.573008, top_k: 0.792969, samples/s: 778.970 1613280631.7504194
train: epoch 38, iter 4700, loss: 2.853207, top_1: 0.577109, top_k: 0.799336, samples/s: 783.048 1613280664.4432003
train: epoch 38, iter 4800, loss: 2.849068, top_1: 0.574375, top_k: 0.801406, samples/s: 779.001 1613280697.3058596
train: epoch 38, iter 4900, loss: 2.582985, top_1: 0.575039, top_k: 0.799570, samples/s: 777.817 1613280730.2183957
train: epoch 38, iter 5000, loss: 2.714154, top_1: 0.573438, top_k: 0.793867, samples/s: 781.281 1613280762.9851332
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_38.
validation: epoch 38, iter 195, top_1: 0.631991, top_k: 0.858734, samples/s: 2371.455 1613280785.0078154
train: epoch 39, iter 100, loss: 2.790377, top_1: 0.596406, top_k: 0.815234, samples/s: 804.171 1613280837.7458823
train: epoch 39, iter 200, loss: 2.906618, top_1: 0.587227, top_k: 0.808516, samples/s: 799.710 1613280869.7573369
train: epoch 39, iter 300, loss: 2.758699, top_1: 0.580508, top_k: 0.805273, samples/s: 780.621 1613280902.5519204
train: epoch 39, iter 400, loss: 2.768377, top_1: 0.589336, top_k: 0.807852, samples/s: 781.725 1613280935.299926
train: epoch 39, iter 500, loss: 2.518343, top_1: 0.590703, top_k: 0.812109, samples/s: 777.800 1613280968.2132623
train: epoch 39, iter 600, loss: 2.865079, top_1: 0.583633, top_k: 0.807383, samples/s: 781.115 1613281000.9868398
train: epoch 39, iter 700, loss: 2.800610, top_1: 0.578828, top_k: 0.802930, samples/s: 779.057 1613281033.8470955
train: epoch 39, iter 800, loss: 2.714379, top_1: 0.582930, top_k: 0.803516, samples/s: 780.055 1613281066.6653697
train: epoch 39, iter 900, loss: 2.875778, top_1: 0.576797, top_k: 0.804961, samples/s: 781.590 1613281099.4191222
train: epoch 39, iter 1000, loss: 2.780932, top_1: 0.584336, top_k: 0.806523, samples/s: 778.799 1613281132.290164
train: epoch 39, iter 1100, loss: 2.817735, top_1: 0.585703, top_k: 0.807109, samples/s: 779.201 1613281165.144384
train: epoch 39, iter 1200, loss: 2.605906, top_1: 0.579414, top_k: 0.805078, samples/s: 781.171 1613281197.9156382
train: epoch 39, iter 1300, loss: 2.901738, top_1: 0.572187, top_k: 0.798320, samples/s: 780.297 1613281230.7236712
train: epoch 39, iter 1400, loss: 2.815404, top_1: 0.579492, top_k: 0.799570, samples/s: 778.573 1613281263.604374
train: epoch 39, iter 1500, loss: 2.894167, top_1: 0.580000, top_k: 0.805625, samples/s: 782.538 1613281296.3184059
train: epoch 39, iter 1600, loss: 2.654097, top_1: 0.581992, top_k: 0.803867, samples/s: 779.017 1613281329.180319
train: epoch 39, iter 1700, loss: 2.867786, top_1: 0.574570, top_k: 0.801602, samples/s: 779.246 1613281362.0326567
train: epoch 39, iter 1800, loss: 2.757736, top_1: 0.575859, top_k: 0.807227, samples/s: 780.552 1613281394.8299303
train: epoch 39, iter 1900, loss: 2.764440, top_1: 0.581289, top_k: 0.803594, samples/s: 778.977 1613281427.6935563
train: epoch 39, iter 2000, loss: 2.675607, top_1: 0.572187, top_k: 0.800781, samples/s: 779.994 1613281460.5142984
train: epoch 39, iter 2100, loss: 2.853325, top_1: 0.580117, top_k: 0.804531, samples/s: 781.142 1613281493.2867603
train: epoch 39, iter 2200, loss: 2.670286, top_1: 0.575586, top_k: 0.799609, samples/s: 779.435 1613281526.1311595
train: epoch 39, iter 2300, loss: 2.940067, top_1: 0.569102, top_k: 0.792813, samples/s: 780.991 1613281558.9100103
train: epoch 39, iter 2400, loss: 2.860735, top_1: 0.577578, top_k: 0.798633, samples/s: 782.694 1613281591.6178505
train: epoch 39, iter 2500, loss: 2.672002, top_1: 0.578086, top_k: 0.800977, samples/s: 778.530 1613281624.5000753
train: epoch 39, iter 2600, loss: 2.770225, top_1: 0.569844, top_k: 0.795742, samples/s: 780.495 1613281657.3000479
train: epoch 39, iter 2700, loss: 2.775802, top_1: 0.582656, top_k: 0.806328, samples/s: 781.430 1613281690.0603182
train: epoch 39, iter 2800, loss: 2.947438, top_1: 0.577695, top_k: 0.802031, samples/s: 780.067 1613281722.8779054
train: epoch 39, iter 2900, loss: 2.729940, top_1: 0.579453, top_k: 0.802773, samples/s: 779.755 1613281755.708753
train: epoch 39, iter 3000, loss: 2.834747, top_1: 0.579375, top_k: 0.803750, samples/s: 779.505 1613281788.5500638
train: epoch 39, iter 3100, loss: 2.775362, top_1: 0.578438, top_k: 0.802500, samples/s: 780.149 1613281821.364295
train: epoch 39, iter 3200, loss: 2.633375, top_1: 0.579922, top_k: 0.802656, samples/s: 782.562 1613281854.0774596
train: epoch 39, iter 3300, loss: 2.849504, top_1: 0.573125, top_k: 0.798008, samples/s: 778.277 1613281886.9711452
train: epoch 39, iter 3400, loss: 2.711053, top_1: 0.575625, top_k: 0.800547, samples/s: 782.728 1613281919.6766994
train: epoch 39, iter 3500, loss: 2.742909, top_1: 0.576719, top_k: 0.797734, samples/s: 778.438 1613281952.563515
train: epoch 39, iter 3600, loss: 2.641105, top_1: 0.574844, top_k: 0.799023, samples/s: 782.151 1613281985.2932909
train: epoch 39, iter 3700, loss: 2.615749, top_1: 0.581680, top_k: 0.802031, samples/s: 779.308 1613282018.1430116
train: epoch 39, iter 3800, loss: 2.694173, top_1: 0.577500, top_k: 0.801758, samples/s: 781.188 1613282050.9136744
train: epoch 39, iter 3900, loss: 2.694195, top_1: 0.570742, top_k: 0.798398, samples/s: 779.665 1613282083.7481925
train: epoch 39, iter 4000, loss: 2.815143, top_1: 0.571875, top_k: 0.797266, samples/s: 783.040 1613282116.441377
train: epoch 39, iter 4100, loss: 2.707351, top_1: 0.575352, top_k: 0.796953, samples/s: 779.718 1613282149.2737608
train: epoch 39, iter 4200, loss: 2.836928, top_1: 0.583398, top_k: 0.802539, samples/s: 781.646 1613282182.0251377
train: epoch 39, iter 4300, loss: 2.649166, top_1: 0.574883, top_k: 0.798242, samples/s: 780.141 1613282214.8397129
train: epoch 39, iter 4400, loss: 2.889581, top_1: 0.576250, top_k: 0.795742, samples/s: 779.365 1613282247.6869957
train: epoch 39, iter 4500, loss: 2.839834, top_1: 0.572734, top_k: 0.799102, samples/s: 779.891 1613282280.5120766
train: epoch 39, iter 4600, loss: 2.732178, top_1: 0.575273, top_k: 0.800312, samples/s: 782.236 1613282313.2387109
train: epoch 39, iter 4700, loss: 2.686061, top_1: 0.573320, top_k: 0.796992, samples/s: 784.479 1613282345.8718412
train: epoch 39, iter 4800, loss: 2.736208, top_1: 0.576602, top_k: 0.805039, samples/s: 780.524 1613282378.6703827
train: epoch 39, iter 4900, loss: 2.683199, top_1: 0.580039, top_k: 0.804141, samples/s: 780.084 1613282411.4874368
train: epoch 39, iter 5000, loss: 2.553743, top_1: 0.580039, top_k: 0.800703, samples/s: 780.633 1613282444.2812474
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_39.
validation: epoch 39, iter 195, top_1: 0.622135, top_k: 0.850381, samples/s: 2350.439 1613282466.5151875
train: epoch 40, iter 100, loss: 2.881469, top_1: 0.586641, top_k: 0.806211, samples/s: 804.272 1613282518.715995
train: epoch 40, iter 200, loss: 2.746409, top_1: 0.584961, top_k: 0.802539, samples/s: 799.399 1613282550.7401881
train: epoch 40, iter 300, loss: 2.761106, top_1: 0.577070, top_k: 0.804961, samples/s: 781.725 1613282583.488184
train: epoch 40, iter 400, loss: 2.460042, top_1: 0.591211, top_k: 0.811250, samples/s: 777.493 1613282616.4145133
train: epoch 40, iter 500, loss: 2.867330, top_1: 0.580742, top_k: 0.804922, samples/s: 778.926 1613282649.2802393
train: epoch 40, iter 600, loss: 2.657193, top_1: 0.583281, top_k: 0.805273, samples/s: 780.126 1613282682.0953882
train: epoch 40, iter 700, loss: 2.753934, top_1: 0.584102, top_k: 0.807227, samples/s: 779.053 1613282714.9557998
train: epoch 40, iter 800, loss: 2.800286, top_1: 0.577656, top_k: 0.804258, samples/s: 777.550 1613282747.8797317
train: epoch 40, iter 900, loss: 2.623749, top_1: 0.586914, top_k: 0.807344, samples/s: 778.088 1613282780.7810318
train: epoch 40, iter 1000, loss: 2.784112, top_1: 0.577383, top_k: 0.803945, samples/s: 780.672 1613282813.573267
train: epoch 40, iter 1100, loss: 2.751347, top_1: 0.586172, top_k: 0.806211, samples/s: 780.124 1613282846.3885603
train: epoch 40, iter 1200, loss: 2.903558, top_1: 0.579805, top_k: 0.803867, samples/s: 781.781 1613282879.1343522
train: epoch 40, iter 1300, loss: 2.862309, top_1: 0.582031, top_k: 0.805898, samples/s: 777.384 1613282912.0653894
train: epoch 40, iter 1400, loss: 2.854105, top_1: 0.577734, top_k: 0.799219, samples/s: 781.185 1613282944.835974
train: epoch 40, iter 1500, loss: 2.687737, top_1: 0.580469, top_k: 0.802695, samples/s: 780.752 1613282977.6248374
train: epoch 40, iter 1600, loss: 2.776004, top_1: 0.582461, top_k: 0.802656, samples/s: 776.711 1613283010.5843794
train: epoch 40, iter 1700, loss: 2.618873, top_1: 0.577070, top_k: 0.800000, samples/s: 782.734 1613283043.2902038
train: epoch 40, iter 1800, loss: 2.679544, top_1: 0.585156, top_k: 0.802852, samples/s: 778.119 1613283076.1901326
train: epoch 40, iter 1900, loss: 2.699421, top_1: 0.583477, top_k: 0.806211, samples/s: 779.910 1613283109.0143945
train: epoch 40, iter 2000, loss: 2.705722, top_1: 0.581406, top_k: 0.806133, samples/s: 781.169 1613283141.7857022
train: epoch 40, iter 2100, loss: 2.877444, top_1: 0.574648, top_k: 0.799570, samples/s: 781.577 1613283174.5401125
train: epoch 40, iter 2200, loss: 2.520960, top_1: 0.572305, top_k: 0.796484, samples/s: 781.472 1613283207.2987962
train: epoch 40, iter 2300, loss: 2.479102, top_1: 0.575547, top_k: 0.804102, samples/s: 780.109 1613283240.114616
train: epoch 40, iter 2400, loss: 2.817382, top_1: 0.570937, top_k: 0.802227, samples/s: 780.875 1613283272.8983903
train: epoch 40, iter 2500, loss: 2.755535, top_1: 0.583711, top_k: 0.806289, samples/s: 779.449 1613283305.742098
train: epoch 40, iter 2600, loss: 2.962813, top_1: 0.579883, top_k: 0.803867, samples/s: 780.032 1613283338.5612755
train: epoch 40, iter 2700, loss: 2.635516, top_1: 0.580703, top_k: 0.804023, samples/s: 780.611 1613283371.3561108
train: epoch 40, iter 2800, loss: 2.697843, top_1: 0.581641, top_k: 0.802969, samples/s: 781.679 1613283404.1061633
train: epoch 40, iter 2900, loss: 2.655455, top_1: 0.578438, top_k: 0.804922, samples/s: 780.915 1613283436.88815
train: epoch 40, iter 3000, loss: 2.745623, top_1: 0.581172, top_k: 0.804883, samples/s: 780.262 1613283469.6976361
train: epoch 40, iter 3100, loss: 2.795378, top_1: 0.577031, top_k: 0.804531, samples/s: 783.795 1613283502.359304
train: epoch 40, iter 3200, loss: 2.579823, top_1: 0.576797, top_k: 0.800039, samples/s: 777.623 1613283535.2802122
train: epoch 40, iter 3300, loss: 2.751263, top_1: 0.578516, top_k: 0.803711, samples/s: 780.229 1613283568.0910592
train: epoch 40, iter 3400, loss: 2.860409, top_1: 0.582187, top_k: 0.804414, samples/s: 780.021 1613283600.9106386
train: epoch 40, iter 3500, loss: 2.751933, top_1: 0.572930, top_k: 0.803047, samples/s: 780.456 1613283633.711964
train: epoch 40, iter 3600, loss: 2.945813, top_1: 0.572305, top_k: 0.798516, samples/s: 781.597 1613283666.4653938
train: epoch 40, iter 3700, loss: 2.740345, top_1: 0.576445, top_k: 0.800977, samples/s: 780.988 1613283699.244414
train: epoch 40, iter 3800, loss: 2.649963, top_1: 0.574648, top_k: 0.799883, samples/s: 781.644 1613283731.995924
train: epoch 40, iter 3900, loss: 2.695691, top_1: 0.580859, top_k: 0.803047, samples/s: 780.886 1613283764.7792985
train: epoch 40, iter 4000, loss: 2.866279, top_1: 0.571133, top_k: 0.794961, samples/s: 781.601 1613283797.5325086
train: epoch 40, iter 4100, loss: 2.878119, top_1: 0.577695, top_k: 0.802656, samples/s: 778.100 1613283830.433137
train: epoch 40, iter 4200, loss: 2.757274, top_1: 0.575000, top_k: 0.796562, samples/s: 782.853 1613283863.1340568
train: epoch 40, iter 4300, loss: 2.766093, top_1: 0.570430, top_k: 0.798047, samples/s: 781.396 1613283895.8959541
train: epoch 40, iter 4400, loss: 2.799025, top_1: 0.574414, top_k: 0.800000, samples/s: 778.610 1613283928.77508
train: epoch 40, iter 4500, loss: 2.813318, top_1: 0.578203, top_k: 0.807031, samples/s: 782.683 1613283961.4830942
train: epoch 40, iter 4600, loss: 2.706328, top_1: 0.578320, top_k: 0.799453, samples/s: 778.102 1613283994.3835967
train: epoch 40, iter 4700, loss: 2.833148, top_1: 0.576758, top_k: 0.800039, samples/s: 778.753 1613284027.2567294
train: epoch 40, iter 4800, loss: 2.700305, top_1: 0.578906, top_k: 0.806875, samples/s: 780.708 1613284060.0475001
train: epoch 40, iter 4900, loss: 2.656027, top_1: 0.577617, top_k: 0.801875, samples/s: 781.189 1613284092.818059
train: epoch 40, iter 5000, loss: 2.681585, top_1: 0.580391, top_k: 0.803359, samples/s: 780.749 1613284125.6070557
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_40.
validation: epoch 40, iter 195, top_1: 0.631390, top_k: 0.854728, samples/s: 2329.031 1613284148.0241334
train: epoch 41, iter 100, loss: 2.632574, top_1: 0.585547, top_k: 0.809180, samples/s: 805.767 1613284200.3702128
train: epoch 41, iter 200, loss: 2.707897, top_1: 0.589141, top_k: 0.807500, samples/s: 798.660 1613284232.4240634
train: epoch 41, iter 300, loss: 2.767251, top_1: 0.585430, top_k: 0.811602, samples/s: 780.969 1613284265.203571
train: epoch 41, iter 400, loss: 2.627851, top_1: 0.584336, top_k: 0.802305, samples/s: 781.161 1613284297.9757273
train: epoch 41, iter 500, loss: 2.834255, top_1: 0.581953, top_k: 0.804258, samples/s: 779.775 1613284330.8053644
train: epoch 41, iter 600, loss: 2.826159, top_1: 0.591641, top_k: 0.810195, samples/s: 775.917 1613284363.7988532
train: epoch 41, iter 700, loss: 2.814394, top_1: 0.584570, top_k: 0.807930, samples/s: 780.353 1613284396.604247
train: epoch 41, iter 800, loss: 2.661208, top_1: 0.582500, top_k: 0.804648, samples/s: 776.284 1613284429.5818317
train: epoch 41, iter 900, loss: 2.967294, top_1: 0.582969, top_k: 0.806445, samples/s: 779.503 1613284462.4232304
train: epoch 41, iter 1000, loss: 2.680538, top_1: 0.584922, top_k: 0.805586, samples/s: 777.926 1613284495.3312101
train: epoch 41, iter 1100, loss: 2.669257, top_1: 0.579727, top_k: 0.805156, samples/s: 778.342 1613284528.2216682
train: epoch 41, iter 1200, loss: 2.566307, top_1: 0.589141, top_k: 0.809141, samples/s: 783.488 1613284560.8960207
train: epoch 41, iter 1300, loss: 2.966700, top_1: 0.581055, top_k: 0.807070, samples/s: 774.298 1613284593.9583004
train: epoch 41, iter 1400, loss: 2.776772, top_1: 0.587500, top_k: 0.803906, samples/s: 783.118 1613284626.648126
train: epoch 41, iter 1500, loss: 2.593733, top_1: 0.580352, top_k: 0.804766, samples/s: 776.913 1613284659.5990307
train: epoch 41, iter 1600, loss: 2.683290, top_1: 0.579297, top_k: 0.809180, samples/s: 780.270 1613284692.4081202
train: epoch 41, iter 1700, loss: 2.533031, top_1: 0.586211, top_k: 0.807852, samples/s: 778.378 1613284725.2971225
train: epoch 41, iter 1800, loss: 2.728538, top_1: 0.587070, top_k: 0.809648, samples/s: 779.908 1613284758.121517
train: epoch 41, iter 1900, loss: 2.758696, top_1: 0.584219, top_k: 0.804102, samples/s: 779.400 1613284790.9672573
train: epoch 41, iter 2000, loss: 2.595054, top_1: 0.583203, top_k: 0.805273, samples/s: 780.706 1613284823.758122
train: epoch 41, iter 2100, loss: 2.540341, top_1: 0.582148, top_k: 0.803828, samples/s: 779.764 1613284856.5884535
train: epoch 41, iter 2200, loss: 2.597827, top_1: 0.578906, top_k: 0.804023, samples/s: 779.094 1613284889.4471712
train: epoch 41, iter 2300, loss: 2.743870, top_1: 0.584336, top_k: 0.804766, samples/s: 777.763 1613284922.3621335
train: epoch 41, iter 2400, loss: 2.968669, top_1: 0.579336, top_k: 0.800742, samples/s: 783.406 1613284955.0399334
train: epoch 41, iter 2500, loss: 2.736302, top_1: 0.579336, top_k: 0.804805, samples/s: 779.156 1613284987.8960218
train: epoch 41, iter 2600, loss: 2.810366, top_1: 0.580898, top_k: 0.808594, samples/s: 778.557 1613285020.7774336
train: epoch 41, iter 2700, loss: 2.856272, top_1: 0.580078, top_k: 0.802344, samples/s: 781.123 1613285053.550775
train: epoch 41, iter 2800, loss: 2.839778, top_1: 0.577578, top_k: 0.804570, samples/s: 781.582 1613285086.304858
train: epoch 41, iter 2900, loss: 2.828779, top_1: 0.578203, top_k: 0.803047, samples/s: 779.752 1613285119.135725
train: epoch 41, iter 3000, loss: 2.869425, top_1: 0.579531, top_k: 0.802227, samples/s: 778.821 1613285152.0060155
train: epoch 41, iter 3100, loss: 2.560125, top_1: 0.580508, top_k: 0.802266, samples/s: 779.553 1613285184.8452792
train: epoch 41, iter 3200, loss: 2.814755, top_1: 0.576367, top_k: 0.800117, samples/s: 780.944 1613285217.6260862
train: epoch 41, iter 3300, loss: 2.808596, top_1: 0.581445, top_k: 0.805156, samples/s: 780.762 1613285250.4145834
train: epoch 41, iter 3400, loss: 2.546094, top_1: 0.580898, top_k: 0.806992, samples/s: 779.344 1613285283.2628155
train: epoch 41, iter 3500, loss: 2.642135, top_1: 0.577344, top_k: 0.801758, samples/s: 779.759 1613285316.0934765
train: epoch 41, iter 3600, loss: 2.808977, top_1: 0.578203, top_k: 0.802461, samples/s: 782.443 1613285348.8114493
train: epoch 41, iter 3700, loss: 2.455204, top_1: 0.570508, top_k: 0.796953, samples/s: 777.567 1613285381.7346017
train: epoch 41, iter 3800, loss: 2.703831, top_1: 0.576836, top_k: 0.799805, samples/s: 779.445 1613285414.5785604
train: epoch 41, iter 3900, loss: 2.744942, top_1: 0.572812, top_k: 0.800039, samples/s: 778.994 1613285447.4414313
train: epoch 41, iter 4000, loss: 2.416578, top_1: 0.574102, top_k: 0.802422, samples/s: 782.065 1613285480.1753094
train: epoch 41, iter 4100, loss: 2.857422, top_1: 0.571445, top_k: 0.799648, samples/s: 777.146 1613285513.116329
train: epoch 41, iter 4200, loss: 2.731762, top_1: 0.584414, top_k: 0.804258, samples/s: 781.754 1613285545.8632612
train: epoch 41, iter 4300, loss: 2.847126, top_1: 0.582383, top_k: 0.804570, samples/s: 781.025 1613285578.6406655
train: epoch 41, iter 4400, loss: 2.870886, top_1: 0.583242, top_k: 0.806523, samples/s: 777.591 1613285611.5627792
train: epoch 41, iter 4500, loss: 2.863464, top_1: 0.574961, top_k: 0.802383, samples/s: 778.727 1613285644.436999
train: epoch 41, iter 4600, loss: 2.776046, top_1: 0.582539, top_k: 0.798203, samples/s: 779.059 1613285677.297106
train: epoch 41, iter 4700, loss: 2.922862, top_1: 0.581367, top_k: 0.802578, samples/s: 780.323 1613285710.1040542
train: epoch 41, iter 4800, loss: 2.684294, top_1: 0.577422, top_k: 0.801680, samples/s: 778.110 1613285743.0042331
train: epoch 41, iter 4900, loss: 2.634151, top_1: 0.576289, top_k: 0.799180, samples/s: 780.657 1613285775.7971933
train: epoch 41, iter 5000, loss: 2.510794, top_1: 0.583594, top_k: 0.801992, samples/s: 778.830 1613285808.6669924
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_41.
validation: epoch 41, iter 195, top_1: 0.632111, top_k: 0.857612, samples/s: 2371.942 1613285830.7149012
train: epoch 42, iter 100, loss: 2.540867, top_1: 0.594961, top_k: 0.813047, samples/s: 805.445 1613285883.673657
train: epoch 42, iter 200, loss: 2.599610, top_1: 0.588711, top_k: 0.809648, samples/s: 797.401 1613285915.7781425
train: epoch 42, iter 300, loss: 2.768006, top_1: 0.590391, top_k: 0.812031, samples/s: 781.802 1613285948.5228474
train: epoch 42, iter 400, loss: 2.807291, top_1: 0.585234, top_k: 0.807891, samples/s: 779.233 1613285981.3755558
train: epoch 42, iter 500, loss: 2.902953, top_1: 0.590000, top_k: 0.806406, samples/s: 780.435 1613286014.1778357
train: epoch 42, iter 600, loss: 2.748101, top_1: 0.581914, top_k: 0.806289, samples/s: 775.959 1613286047.1692357
train: epoch 42, iter 700, loss: 2.542388, top_1: 0.589609, top_k: 0.809648, samples/s: 781.876 1613286079.910998
train: epoch 42, iter 800, loss: 2.973296, top_1: 0.583398, top_k: 0.808867, samples/s: 778.236 1613286112.805878
train: epoch 42, iter 900, loss: 2.681303, top_1: 0.579844, top_k: 0.804844, samples/s: 778.709 1613286145.6807923
train: epoch 42, iter 1000, loss: 2.828165, top_1: 0.584414, top_k: 0.801914, samples/s: 781.701 1613286178.429946
train: epoch 42, iter 1100, loss: 2.849430, top_1: 0.582539, top_k: 0.803789, samples/s: 777.920 1613286211.3382976
train: epoch 42, iter 1200, loss: 2.703982, top_1: 0.586211, top_k: 0.803555, samples/s: 780.289 1613286244.1465805
train: epoch 42, iter 1300, loss: 2.655361, top_1: 0.579375, top_k: 0.803398, samples/s: 777.968 1613286277.0527682
train: epoch 42, iter 1400, loss: 2.754340, top_1: 0.577500, top_k: 0.802734, samples/s: 778.457 1613286309.9384172
train: epoch 42, iter 1500, loss: 2.788630, top_1: 0.587969, top_k: 0.807773, samples/s: 780.702 1613286342.729471
train: epoch 42, iter 1600, loss: 2.627175, top_1: 0.583359, top_k: 0.806172, samples/s: 778.015 1613286375.633588
train: epoch 42, iter 1700, loss: 2.763930, top_1: 0.580859, top_k: 0.806367, samples/s: 780.424 1613286408.4363844
train: epoch 42, iter 1800, loss: 2.805617, top_1: 0.579766, top_k: 0.803398, samples/s: 781.655 1613286441.1873786
train: epoch 42, iter 1900, loss: 2.678058, top_1: 0.586797, top_k: 0.804531, samples/s: 782.217 1613286473.9149332
train: epoch 42, iter 2000, loss: 2.671381, top_1: 0.583672, top_k: 0.803672, samples/s: 777.412 1613286506.844637
train: epoch 42, iter 2100, loss: 2.712254, top_1: 0.582891, top_k: 0.802383, samples/s: 780.944 1613286539.625448
train: epoch 42, iter 2200, loss: 2.705402, top_1: 0.584023, top_k: 0.808750, samples/s: 778.166 1613286572.5233767
train: epoch 42, iter 2300, loss: 2.726053, top_1: 0.583555, top_k: 0.806797, samples/s: 781.184 1613286605.2941976
train: epoch 42, iter 2400, loss: 2.862164, top_1: 0.581016, top_k: 0.803516, samples/s: 779.482 1613286638.1364212
train: epoch 42, iter 2500, loss: 2.770661, top_1: 0.582305, top_k: 0.808555, samples/s: 779.607 1613286670.973491
train: epoch 42, iter 2600, loss: 2.650106, top_1: 0.583789, top_k: 0.807852, samples/s: 779.139 1613286703.8303323
train: epoch 42, iter 2700, loss: 2.750074, top_1: 0.579531, top_k: 0.800703, samples/s: 779.849 1613286736.657149
train: epoch 42, iter 2800, loss: 2.592398, top_1: 0.579766, top_k: 0.802695, samples/s: 777.792 1613286769.5708258
train: epoch 42, iter 2900, loss: 2.677735, top_1: 0.587461, top_k: 0.805781, samples/s: 781.320 1613286802.3359022
train: epoch 42, iter 3000, loss: 2.610318, top_1: 0.581758, top_k: 0.801367, samples/s: 781.336 1613286835.1003342
train: epoch 42, iter 3100, loss: 2.565456, top_1: 0.581953, top_k: 0.804063, samples/s: 779.796 1613286867.9293945
train: epoch 42, iter 3200, loss: 2.781993, top_1: 0.581367, top_k: 0.802891, samples/s: 777.360 1613286900.861386
train: epoch 42, iter 3300, loss: 2.719712, top_1: 0.577617, top_k: 0.805234, samples/s: 782.131 1613286933.5924418
train: epoch 42, iter 3400, loss: 2.921617, top_1: 0.577656, top_k: 0.803086, samples/s: 777.561 1613286966.5160322
train: epoch 42, iter 3500, loss: 2.883083, top_1: 0.576992, top_k: 0.800781, samples/s: 779.418 1613286999.3610265
train: epoch 42, iter 3600, loss: 2.757864, top_1: 0.579023, top_k: 0.803203, samples/s: 779.688 1613287032.19462
train: epoch 42, iter 3700, loss: 2.723131, top_1: 0.577891, top_k: 0.802539, samples/s: 778.321 1613287065.0858889
train: epoch 42, iter 3800, loss: 2.857590, top_1: 0.576484, top_k: 0.799922, samples/s: 779.913 1613287097.9100897
train: epoch 42, iter 3900, loss: 2.841613, top_1: 0.581836, top_k: 0.804844, samples/s: 779.186 1613287130.7649848
train: epoch 42, iter 4000, loss: 2.606930, top_1: 0.578750, top_k: 0.801758, samples/s: 778.407 1613287163.6526299
train: epoch 42, iter 4100, loss: 2.970412, top_1: 0.580586, top_k: 0.801445, samples/s: 779.308 1613287196.5023036
train: epoch 42, iter 4200, loss: 2.602376, top_1: 0.580156, top_k: 0.804063, samples/s: 779.544 1613287229.3420465
train: epoch 42, iter 4300, loss: 2.755230, top_1: 0.582773, top_k: 0.806914, samples/s: 779.051 1613287262.2025244
train: epoch 42, iter 4400, loss: 2.726771, top_1: 0.583203, top_k: 0.803125, samples/s: 779.921 1613287295.0263126
train: epoch 42, iter 4500, loss: 2.874765, top_1: 0.580586, top_k: 0.803984, samples/s: 778.315 1613287327.9178238
train: epoch 42, iter 4600, loss: 2.694032, top_1: 0.578750, top_k: 0.800430, samples/s: 777.286 1613287360.853012
train: epoch 42, iter 4700, loss: 2.723452, top_1: 0.581367, top_k: 0.809023, samples/s: 781.561 1613287393.607948
train: epoch 42, iter 4800, loss: 2.770111, top_1: 0.575273, top_k: 0.800273, samples/s: 777.840 1613287426.519639
train: epoch 42, iter 4900, loss: 2.709814, top_1: 0.583438, top_k: 0.806406, samples/s: 778.354 1613287459.4096165
train: epoch 42, iter 5000, loss: 2.743494, top_1: 0.575586, top_k: 0.802070, samples/s: 782.414 1613287492.1287773
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_42.
validation: epoch 42, iter 195, top_1: 0.632111, top_k: 0.859475, samples/s: 2356.815 1613287514.2970793
train: epoch 43, iter 100, loss: 2.644552, top_1: 0.589219, top_k: 0.808945, samples/s: 803.007 1613287567.5962257
train: epoch 43, iter 200, loss: 2.556532, top_1: 0.596562, top_k: 0.812695, samples/s: 799.590 1613287599.6126547
train: epoch 43, iter 300, loss: 2.909332, top_1: 0.597812, top_k: 0.813281, samples/s: 782.153 1613287632.3428538
train: epoch 43, iter 400, loss: 2.585426, top_1: 0.586641, top_k: 0.809727, samples/s: 777.035 1613287665.2885833
train: epoch 43, iter 500, loss: 2.687885, top_1: 0.586484, top_k: 0.808906, samples/s: 779.143 1613287698.1452467
train: epoch 43, iter 600, loss: 2.671731, top_1: 0.589531, top_k: 0.813125, samples/s: 779.684 1613287730.9790328
train: epoch 43, iter 700, loss: 2.919580, top_1: 0.584023, top_k: 0.804922, samples/s: 776.770 1613287763.9360094
train: epoch 43, iter 800, loss: 2.644340, top_1: 0.586641, top_k: 0.810352, samples/s: 781.484 1613287796.6942122
train: epoch 43, iter 900, loss: 2.655888, top_1: 0.583516, top_k: 0.807383, samples/s: 779.597 1613287829.5315907
train: epoch 43, iter 1000, loss: 2.785189, top_1: 0.591953, top_k: 0.812539, samples/s: 779.040 1613287862.3925452
train: epoch 43, iter 1100, loss: 2.681486, top_1: 0.584375, top_k: 0.804766, samples/s: 777.811 1613287895.3053944
train: epoch 43, iter 1200, loss: 2.743226, top_1: 0.582109, top_k: 0.807187, samples/s: 783.440 1613287927.981851
train: epoch 43, iter 1300, loss: 2.764767, top_1: 0.581680, top_k: 0.803125, samples/s: 779.261 1613287960.8335614
train: epoch 43, iter 1400, loss: 2.721003, top_1: 0.585234, top_k: 0.808242, samples/s: 780.754 1613287993.6222713
train: epoch 43, iter 1500, loss: 2.562768, top_1: 0.584180, top_k: 0.806523, samples/s: 778.140 1613288026.5212815
train: epoch 43, iter 1600, loss: 2.572018, top_1: 0.580703, top_k: 0.805586, samples/s: 781.869 1613288059.2632782
train: epoch 43, iter 1700, loss: 2.738932, top_1: 0.583750, top_k: 0.806445, samples/s: 776.572 1613288092.2286482
train: epoch 43, iter 1800, loss: 2.754060, top_1: 0.583828, top_k: 0.805781, samples/s: 779.471 1613288125.071549
train: epoch 43, iter 1900, loss: 2.968906, top_1: 0.587109, top_k: 0.809766, samples/s: 778.229 1613288157.966714
train: epoch 43, iter 2000, loss: 2.767896, top_1: 0.587187, top_k: 0.809453, samples/s: 783.115 1613288190.6567235
train: epoch 43, iter 2100, loss: 2.686418, top_1: 0.582461, top_k: 0.807305, samples/s: 777.750 1613288223.572193
train: epoch 43, iter 2200, loss: 2.676974, top_1: 0.584023, top_k: 0.806484, samples/s: 779.916 1613288256.3962576
train: epoch 43, iter 2300, loss: 2.478632, top_1: 0.586445, top_k: 0.807930, samples/s: 783.122 1613288289.0858371
train: epoch 43, iter 2400, loss: 2.904296, top_1: 0.579219, top_k: 0.804336, samples/s: 780.053 1613288321.9041476
train: epoch 43, iter 2500, loss: 2.736508, top_1: 0.583633, top_k: 0.806172, samples/s: 779.121 1613288354.7616947
train: epoch 43, iter 2600, loss: 2.735132, top_1: 0.584844, top_k: 0.805898, samples/s: 780.131 1613288387.5767758
train: epoch 43, iter 2700, loss: 2.720449, top_1: 0.585273, top_k: 0.806992, samples/s: 779.974 1613288420.3983405
train: epoch 43, iter 2800, loss: 2.643367, top_1: 0.584375, top_k: 0.806133, samples/s: 779.605 1613288453.2353864
train: epoch 43, iter 2900, loss: 2.693136, top_1: 0.587031, top_k: 0.804297, samples/s: 778.078 1613288486.137005
train: epoch 43, iter 3000, loss: 2.711388, top_1: 0.580859, top_k: 0.804141, samples/s: 781.902 1613288518.877762
train: epoch 43, iter 3100, loss: 2.713028, top_1: 0.582969, top_k: 0.803672, samples/s: 780.580 1613288551.6738355
train: epoch 43, iter 3200, loss: 2.644268, top_1: 0.578672, top_k: 0.802891, samples/s: 777.790 1613288584.587606
train: epoch 43, iter 3300, loss: 2.752567, top_1: 0.583281, top_k: 0.802930, samples/s: 783.271 1613288617.2710092
train: epoch 43, iter 3400, loss: 2.843845, top_1: 0.582617, top_k: 0.803359, samples/s: 777.432 1613288650.1999412
train: epoch 43, iter 3500, loss: 2.990588, top_1: 0.579766, top_k: 0.802383, samples/s: 779.362 1613288683.0473979
train: epoch 43, iter 3600, loss: 2.796983, top_1: 0.578164, top_k: 0.801758, samples/s: 778.722 1613288715.921666
train: epoch 43, iter 3700, loss: 2.805744, top_1: 0.587852, top_k: 0.809141, samples/s: 780.967 1613288748.7016463
train: epoch 43, iter 3800, loss: 2.739157, top_1: 0.577422, top_k: 0.802695, samples/s: 778.987 1613288781.564813
train: epoch 43, iter 3900, loss: 2.643998, top_1: 0.580352, top_k: 0.808242, samples/s: 778.334 1613288814.4555633
train: epoch 43, iter 4000, loss: 2.501200, top_1: 0.579766, top_k: 0.805625, samples/s: 779.577 1613288847.2938845
train: epoch 43, iter 4100, loss: 2.810223, top_1: 0.586680, top_k: 0.807773, samples/s: 776.525 1613288880.261295
train: epoch 43, iter 4200, loss: 2.935387, top_1: 0.582852, top_k: 0.803320, samples/s: 782.523 1613288912.9759095
train: epoch 43, iter 4300, loss: 2.818836, top_1: 0.580234, top_k: 0.802969, samples/s: 779.780 1613288945.8057196
train: epoch 43, iter 4400, loss: 2.870139, top_1: 0.585625, top_k: 0.806328, samples/s: 778.748 1613288978.6790154
train: epoch 43, iter 4500, loss: 2.739599, top_1: 0.579414, top_k: 0.803398, samples/s: 778.938 1613289011.5442786
train: epoch 43, iter 4600, loss: 2.676938, top_1: 0.575664, top_k: 0.804609, samples/s: 780.277 1613289044.353214
train: epoch 43, iter 4700, loss: 2.672802, top_1: 0.586484, top_k: 0.806914, samples/s: 780.965 1613289077.1330771
train: epoch 43, iter 4800, loss: 2.817895, top_1: 0.579609, top_k: 0.805742, samples/s: 778.816 1613289110.0035112
train: epoch 43, iter 4900, loss: 2.828612, top_1: 0.575273, top_k: 0.801758, samples/s: 779.316 1613289142.8528795
train: epoch 43, iter 5000, loss: 2.658549, top_1: 0.575898, top_k: 0.800469, samples/s: 778.993 1613289175.7157514
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_43.
validation: epoch 43, iter 195, top_1: 0.634535, top_k: 0.858173, samples/s: 2360.636 1613289197.833146
train: epoch 44, iter 100, loss: 2.742367, top_1: 0.597617, top_k: 0.814961, samples/s: 804.801 1613289250.3405464
train: epoch 44, iter 200, loss: 2.728965, top_1: 0.586992, top_k: 0.810625, samples/s: 799.023 1613289282.3799205
train: epoch 44, iter 300, loss: 2.665081, top_1: 0.592812, top_k: 0.816367, samples/s: 777.807 1613289315.292774
train: epoch 44, iter 400, loss: 2.733510, top_1: 0.590664, top_k: 0.808789, samples/s: 780.608 1613289348.0877748
train: epoch 44, iter 500, loss: 2.626969, top_1: 0.588828, top_k: 0.808125, samples/s: 775.443 1613289381.1010897
train: epoch 44, iter 600, loss: 2.745870, top_1: 0.589297, top_k: 0.807383, samples/s: 779.165 1613289413.9568374
train: epoch 44, iter 700, loss: 2.721297, top_1: 0.586055, top_k: 0.807813, samples/s: 777.774 1613289446.8712435
train: epoch 44, iter 800, loss: 2.694264, top_1: 0.591562, top_k: 0.812930, samples/s: 779.035 1613289479.732421
train: epoch 44, iter 900, loss: 2.796887, top_1: 0.593633, top_k: 0.818242, samples/s: 778.275 1613289512.6256366
train: epoch 44, iter 1000, loss: 2.600755, top_1: 0.584336, top_k: 0.806797, samples/s: 778.278 1613289545.5187848
train: epoch 44, iter 1100, loss: 2.726015, top_1: 0.587773, top_k: 0.810234, samples/s: 777.756 1613289578.4339337
train: epoch 44, iter 1200, loss: 2.926622, top_1: 0.587852, top_k: 0.807656, samples/s: 780.279 1613289611.2426918
train: epoch 44, iter 1300, loss: 2.543685, top_1: 0.582812, top_k: 0.809648, samples/s: 777.992 1613289644.1480343
train: epoch 44, iter 1400, loss: 2.712881, top_1: 0.584023, top_k: 0.807891, samples/s: 777.766 1613289677.062787
train: epoch 44, iter 1500, loss: 2.570305, top_1: 0.586016, top_k: 0.808477, samples/s: 778.220 1613289709.958398
train: epoch 44, iter 1600, loss: 2.718145, top_1: 0.582070, top_k: 0.810000, samples/s: 778.619 1613289742.8370914
train: epoch 44, iter 1700, loss: 2.697252, top_1: 0.589023, top_k: 0.809414, samples/s: 776.656 1613289775.7989063
train: epoch 44, iter 1800, loss: 2.645384, top_1: 0.581953, top_k: 0.806602, samples/s: 778.728 1613289808.6730347
train: epoch 44, iter 1900, loss: 2.683518, top_1: 0.581484, top_k: 0.806914, samples/s: 776.131 1613289841.6571639
train: epoch 44, iter 2000, loss: 2.700610, top_1: 0.578828, top_k: 0.802266, samples/s: 777.211 1613289874.5954928
train: epoch 44, iter 2100, loss: 2.622736, top_1: 0.585156, top_k: 0.805664, samples/s: 779.963 1613289907.417502
train: epoch 44, iter 2200, loss: 2.904665, top_1: 0.579492, top_k: 0.803516, samples/s: 779.018 1613289940.2794454
train: epoch 44, iter 2300, loss: 2.704200, top_1: 0.586797, top_k: 0.806523, samples/s: 779.390 1613289973.1256306
train: epoch 44, iter 2400, loss: 2.935816, top_1: 0.581094, top_k: 0.803672, samples/s: 778.188 1613290006.022591
train: epoch 44, iter 2500, loss: 2.470243, top_1: 0.587266, top_k: 0.805078, samples/s: 779.820 1613290038.850599
train: epoch 44, iter 2600, loss: 2.559505, top_1: 0.590352, top_k: 0.807070, samples/s: 781.344 1613290071.6146934
train: epoch 44, iter 2700, loss: 2.685539, top_1: 0.586562, top_k: 0.805391, samples/s: 777.739 1613290104.5305572
train: epoch 44, iter 2800, loss: 2.625157, top_1: 0.586211, top_k: 0.811406, samples/s: 780.173 1613290137.343867
train: epoch 44, iter 2900, loss: 2.634600, top_1: 0.585430, top_k: 0.805781, samples/s: 780.072 1613290170.1612976
train: epoch 44, iter 3000, loss: 2.786917, top_1: 0.584609, top_k: 0.806289, samples/s: 778.412 1613290203.0488384
train: epoch 44, iter 3100, loss: 2.702219, top_1: 0.582344, top_k: 0.808008, samples/s: 778.214 1613290235.9445841
train: epoch 44, iter 3200, loss: 2.785430, top_1: 0.584961, top_k: 0.803555, samples/s: 779.136 1613290268.8015573
train: epoch 44, iter 3300, loss: 2.815604, top_1: 0.590820, top_k: 0.805937, samples/s: 780.652 1613290301.5946763
train: epoch 44, iter 3400, loss: 2.642334, top_1: 0.581445, top_k: 0.805273, samples/s: 778.896 1613290334.4616892
train: epoch 44, iter 3500, loss: 2.635581, top_1: 0.584531, top_k: 0.805391, samples/s: 780.108 1613290367.2775872
train: epoch 44, iter 3600, loss: 2.614244, top_1: 0.578750, top_k: 0.802891, samples/s: 781.133 1613290400.050539
train: epoch 44, iter 3700, loss: 2.682335, top_1: 0.580430, top_k: 0.804570, samples/s: 781.149 1613290432.8227026
train: epoch 44, iter 3800, loss: 2.704082, top_1: 0.583125, top_k: 0.806602, samples/s: 777.136 1613290465.7642977
train: epoch 44, iter 3900, loss: 2.710304, top_1: 0.581602, top_k: 0.807109, samples/s: 782.145 1613290498.4947097
train: epoch 44, iter 4000, loss: 2.673356, top_1: 0.580977, top_k: 0.808320, samples/s: 777.925 1613290531.402752
train: epoch 44, iter 4100, loss: 2.738629, top_1: 0.587227, top_k: 0.803086, samples/s: 779.971 1613290564.224564
train: epoch 44, iter 4200, loss: 2.799311, top_1: 0.578398, top_k: 0.803711, samples/s: 781.737 1613290596.9721053
train: epoch 44, iter 4300, loss: 2.815399, top_1: 0.584023, top_k: 0.806172, samples/s: 783.614 1613290629.6412308
train: epoch 44, iter 4400, loss: 2.552985, top_1: 0.582656, top_k: 0.806016, samples/s: 779.860 1613290662.4676836
train: epoch 44, iter 4500, loss: 2.807008, top_1: 0.588828, top_k: 0.805117, samples/s: 778.383 1613290695.3564398
train: epoch 44, iter 4600, loss: 2.820679, top_1: 0.579531, top_k: 0.805156, samples/s: 782.571 1613290728.0690312
train: epoch 44, iter 4700, loss: 2.923418, top_1: 0.577539, top_k: 0.801836, samples/s: 780.948 1613290760.849724
train: epoch 44, iter 4800, loss: 2.670465, top_1: 0.586875, top_k: 0.803477, samples/s: 779.787 1613290793.6792758
train: epoch 44, iter 4900, loss: 2.712879, top_1: 0.579922, top_k: 0.803750, samples/s: 780.976 1613290826.4587395
train: epoch 44, iter 5000, loss: 2.637000, top_1: 0.582109, top_k: 0.807852, samples/s: 779.331 1613290859.307446
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_44.
validation: epoch 44, iter 195, top_1: 0.635296, top_k: 0.859215, samples/s: 2326.391 1613290881.7380111
train: epoch 45, iter 100, loss: 2.559118, top_1: 0.590547, top_k: 0.811602, samples/s: 804.644 1613290934.1156664
train: epoch 45, iter 200, loss: 2.687244, top_1: 0.597734, top_k: 0.816953, samples/s: 799.116 1613290966.1510165
train: epoch 45, iter 300, loss: 2.802887, top_1: 0.591797, top_k: 0.813164, samples/s: 783.683 1613290998.817155
train: epoch 45, iter 400, loss: 2.717169, top_1: 0.594141, top_k: 0.807930, samples/s: 779.739 1613291031.6487923
train: epoch 45, iter 500, loss: 2.778564, top_1: 0.594219, top_k: 0.809648, samples/s: 774.952 1613291064.6829884
train: epoch 45, iter 600, loss: 2.599429, top_1: 0.592148, top_k: 0.814336, samples/s: 780.255 1613291097.4928238
train: epoch 45, iter 700, loss: 2.752310, top_1: 0.597461, top_k: 0.813477, samples/s: 782.390 1613291130.2130527
train: epoch 45, iter 800, loss: 2.640414, top_1: 0.592969, top_k: 0.809297, samples/s: 781.066 1613291162.9887745
train: epoch 45, iter 900, loss: 2.742770, top_1: 0.592227, top_k: 0.808828, samples/s: 778.434 1613291195.8753438
train: epoch 45, iter 1000, loss: 2.695490, top_1: 0.592578, top_k: 0.812695, samples/s: 779.656 1613291228.7103841
train: epoch 45, iter 1100, loss: 2.707652, top_1: 0.588398, top_k: 0.809922, samples/s: 781.262 1613291261.4778302
train: epoch 45, iter 1200, loss: 2.794195, top_1: 0.587500, top_k: 0.806875, samples/s: 778.638 1613291294.3557508
train: epoch 45, iter 1300, loss: 2.843640, top_1: 0.582305, top_k: 0.808555, samples/s: 783.523 1613291327.0286903
train: epoch 45, iter 1400, loss: 2.781162, top_1: 0.592461, top_k: 0.810547, samples/s: 778.633 1613291359.906803
train: epoch 45, iter 1500, loss: 2.699170, top_1: 0.589336, top_k: 0.809492, samples/s: 782.814 1613291392.6093838
train: epoch 45, iter 1600, loss: 2.601682, top_1: 0.593359, top_k: 0.807813, samples/s: 779.322 1613291425.4585044
train: epoch 45, iter 1700, loss: 2.686509, top_1: 0.588398, top_k: 0.807148, samples/s: 779.304 1613291458.3082662
train: epoch 45, iter 1800, loss: 2.743147, top_1: 0.584883, top_k: 0.805352, samples/s: 779.923 1613291491.131994
train: epoch 45, iter 1900, loss: 2.691519, top_1: 0.582656, top_k: 0.806289, samples/s: 778.773 1613291524.0043187
train: epoch 45, iter 2000, loss: 2.757913, top_1: 0.587031, top_k: 0.811719, samples/s: 782.345 1613291556.726349
train: epoch 45, iter 2100, loss: 2.809252, top_1: 0.577070, top_k: 0.804180, samples/s: 778.422 1613291589.6134045
train: epoch 45, iter 2200, loss: 2.594823, top_1: 0.577891, top_k: 0.805117, samples/s: 781.003 1613291622.391764
train: epoch 45, iter 2300, loss: 2.593235, top_1: 0.587656, top_k: 0.811445, samples/s: 781.046 1613291655.1683958
train: epoch 45, iter 2400, loss: 2.503353, top_1: 0.585820, top_k: 0.808242, samples/s: 781.639 1613291687.9200423
train: epoch 45, iter 2500, loss: 2.822770, top_1: 0.586250, top_k: 0.812266, samples/s: 781.929 1613291720.6595833
train: epoch 45, iter 2600, loss: 2.866263, top_1: 0.580625, top_k: 0.805117, samples/s: 782.277 1613291753.384545
train: epoch 45, iter 2700, loss: 2.631786, top_1: 0.579961, top_k: 0.804805, samples/s: 778.105 1613291786.2849665
train: epoch 45, iter 2800, loss: 2.709658, top_1: 0.585625, top_k: 0.805391, samples/s: 781.617 1613291819.0376046
train: epoch 45, iter 2900, loss: 2.678159, top_1: 0.583711, top_k: 0.803984, samples/s: 779.454 1613291851.8811233
train: epoch 45, iter 3000, loss: 2.705528, top_1: 0.585938, top_k: 0.805664, samples/s: 779.702 1613291884.7141583
train: epoch 45, iter 3100, loss: 2.631980, top_1: 0.587148, top_k: 0.807734, samples/s: 780.551 1613291917.511536
train: epoch 45, iter 3200, loss: 2.634409, top_1: 0.591016, top_k: 0.808828, samples/s: 782.107 1613291950.243679
train: epoch 45, iter 3300, loss: 2.872579, top_1: 0.580039, top_k: 0.805781, samples/s: 778.904 1613291983.1103642
train: epoch 45, iter 3400, loss: 2.685390, top_1: 0.585547, top_k: 0.804688, samples/s: 779.310 1613292015.959925
train: epoch 45, iter 3500, loss: 2.581452, top_1: 0.584180, top_k: 0.809258, samples/s: 779.906 1613292048.7844274
train: epoch 45, iter 3600, loss: 2.650136, top_1: 0.579766, top_k: 0.798242, samples/s: 780.630 1613292081.5784087
train: epoch 45, iter 3700, loss: 2.628982, top_1: 0.585195, top_k: 0.810781, samples/s: 779.386 1613292114.424708
train: epoch 45, iter 3800, loss: 2.609672, top_1: 0.588555, top_k: 0.807969, samples/s: 778.976 1613292147.288366
train: epoch 45, iter 3900, loss: 2.718674, top_1: 0.585195, top_k: 0.809531, samples/s: 782.241 1613292180.0149243
train: epoch 45, iter 4000, loss: 2.590594, top_1: 0.591562, top_k: 0.814063, samples/s: 781.590 1613292212.7686613
train: epoch 45, iter 4100, loss: 2.718134, top_1: 0.584961, top_k: 0.806094, samples/s: 779.282 1613292245.61938
train: epoch 45, iter 4200, loss: 2.790455, top_1: 0.577773, top_k: 0.799492, samples/s: 781.156 1613292278.3912845
train: epoch 45, iter 4300, loss: 2.860405, top_1: 0.584766, top_k: 0.805156, samples/s: 780.667 1613292311.1838033
train: epoch 45, iter 4400, loss: 2.717458, top_1: 0.583906, top_k: 0.804766, samples/s: 780.017 1613292344.0035095
train: epoch 45, iter 4500, loss: 2.803145, top_1: 0.579063, top_k: 0.805352, samples/s: 782.912 1613292376.7020648
train: epoch 45, iter 4600, loss: 2.839273, top_1: 0.582070, top_k: 0.805664, samples/s: 777.818 1613292409.6146014
train: epoch 45, iter 4700, loss: 2.949105, top_1: 0.580273, top_k: 0.806797, samples/s: 780.305 1613292442.4223928
train: epoch 45, iter 4800, loss: 2.618992, top_1: 0.586211, top_k: 0.809453, samples/s: 779.154 1613292475.2784543
train: epoch 45, iter 4900, loss: 2.514406, top_1: 0.583281, top_k: 0.805352, samples/s: 780.095 1613292508.094916
train: epoch 45, iter 5000, loss: 2.661632, top_1: 0.590898, top_k: 0.812422, samples/s: 779.509 1613292540.9361799
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_45.
validation: epoch 45, iter 195, top_1: 0.643670, top_k: 0.862019, samples/s: 2356.753 1613292563.076799
train: epoch 46, iter 100, loss: 2.601956, top_1: 0.604688, top_k: 0.822422, samples/s: 805.349 1613292615.147331
train: epoch 46, iter 200, loss: 2.561385, top_1: 0.592695, top_k: 0.810391, samples/s: 798.135 1613292647.2222373
train: epoch 46, iter 300, loss: 2.662676, top_1: 0.605859, top_k: 0.821797, samples/s: 781.381 1613292679.9845865
train: epoch 46, iter 400, loss: 2.676602, top_1: 0.600313, top_k: 0.814336, samples/s: 777.183 1613292712.9239752
train: epoch 46, iter 500, loss: 2.608339, top_1: 0.593359, top_k: 0.816719, samples/s: 778.143 1613292745.8228989
train: epoch 46, iter 600, loss: 2.614580, top_1: 0.590078, top_k: 0.812734, samples/s: 778.935 1613292778.6881623
train: epoch 46, iter 700, loss: 2.606659, top_1: 0.592500, top_k: 0.810937, samples/s: 777.702 1613292811.605668
train: epoch 46, iter 800, loss: 2.713548, top_1: 0.589922, top_k: 0.811250, samples/s: 779.191 1613292844.460261
train: epoch 46, iter 900, loss: 2.651547, top_1: 0.595273, top_k: 0.815664, samples/s: 777.026 1613292877.4064991
train: epoch 46, iter 1000, loss: 3.014321, top_1: 0.589258, top_k: 0.808555, samples/s: 782.142 1613292910.137023
train: epoch 46, iter 1100, loss: 2.688946, top_1: 0.584023, top_k: 0.808672, samples/s: 777.433 1613292943.0659094
train: epoch 46, iter 1200, loss: 2.802932, top_1: 0.586133, top_k: 0.807461, samples/s: 779.241 1613292975.918363
train: epoch 46, iter 1300, loss: 2.780165, top_1: 0.590313, top_k: 0.812891, samples/s: 777.290 1613293008.8533773
train: epoch 46, iter 1400, loss: 2.754102, top_1: 0.591367, top_k: 0.810117, samples/s: 778.644 1613293041.731038
train: epoch 46, iter 1500, loss: 2.479558, top_1: 0.583320, top_k: 0.806953, samples/s: 780.645 1613293074.5244205
train: epoch 46, iter 1600, loss: 2.745228, top_1: 0.595430, top_k: 0.817773, samples/s: 775.648 1613293107.5290022
train: epoch 46, iter 1700, loss: 2.709882, top_1: 0.585508, top_k: 0.808633, samples/s: 780.081 1613293140.3461428
train: epoch 46, iter 1800, loss: 2.603099, top_1: 0.586094, top_k: 0.809102, samples/s: 776.222 1613293173.326361
train: epoch 46, iter 1900, loss: 2.815137, top_1: 0.587578, top_k: 0.812773, samples/s: 780.133 1613293206.1412845
train: epoch 46, iter 2000, loss: 2.594938, top_1: 0.592539, top_k: 0.812617, samples/s: 779.531 1613293238.981542
train: epoch 46, iter 2100, loss: 2.883069, top_1: 0.583438, top_k: 0.805508, samples/s: 778.254 1613293271.8757663
train: epoch 46, iter 2200, loss: 2.741883, top_1: 0.588203, top_k: 0.808789, samples/s: 781.723 1613293304.6238587
train: epoch 46, iter 2300, loss: 2.627447, top_1: 0.582227, top_k: 0.805898, samples/s: 778.827 1613293337.4938278
train: epoch 46, iter 2400, loss: 2.589795, top_1: 0.589648, top_k: 0.808008, samples/s: 780.021 1613293370.3134086
train: epoch 46, iter 2500, loss: 2.841564, top_1: 0.590352, top_k: 0.813281, samples/s: 777.640 1613293403.2335184
train: epoch 46, iter 2600, loss: 2.663075, top_1: 0.588984, top_k: 0.807109, samples/s: 780.458 1613293436.034879
train: epoch 46, iter 2700, loss: 2.617930, top_1: 0.593437, top_k: 0.811172, samples/s: 778.121 1613293468.9346623
train: epoch 46, iter 2800, loss: 2.510228, top_1: 0.588398, top_k: 0.811016, samples/s: 778.966 1613293501.7986665
train: epoch 46, iter 2900, loss: 2.758455, top_1: 0.587617, top_k: 0.809141, samples/s: 778.181 1613293534.6959574
train: epoch 46, iter 3000, loss: 2.798276, top_1: 0.583750, top_k: 0.805039, samples/s: 779.371 1613293567.5429711
train: epoch 46, iter 3100, loss: 2.607014, top_1: 0.584531, top_k: 0.805430, samples/s: 780.007 1613293600.3631382
train: epoch 46, iter 3200, loss: 2.917315, top_1: 0.580820, top_k: 0.800898, samples/s: 778.915 1613293633.2293766
train: epoch 46, iter 3300, loss: 2.888576, top_1: 0.580625, top_k: 0.804961, samples/s: 780.580 1613293666.0254815
train: epoch 46, iter 3400, loss: 2.742399, top_1: 0.579844, top_k: 0.804258, samples/s: 779.738 1613293698.857022
train: epoch 46, iter 3500, loss: 2.709294, top_1: 0.585195, top_k: 0.808711, samples/s: 778.778 1613293731.7289822
train: epoch 46, iter 3600, loss: 2.690809, top_1: 0.592539, top_k: 0.811328, samples/s: 778.541 1613293764.6110342
train: epoch 46, iter 3700, loss: 2.550869, top_1: 0.585039, top_k: 0.807109, samples/s: 777.843 1613293797.5226347
train: epoch 46, iter 3800, loss: 2.670840, top_1: 0.589219, top_k: 0.810000, samples/s: 778.583 1613293830.4027853
train: epoch 46, iter 3900, loss: 2.569067, top_1: 0.587852, top_k: 0.809453, samples/s: 779.460 1613293863.2461064
train: epoch 46, iter 4000, loss: 2.747631, top_1: 0.581758, top_k: 0.804492, samples/s: 780.512 1613293896.0450096
train: epoch 46, iter 4100, loss: 2.510485, top_1: 0.583633, top_k: 0.806914, samples/s: 777.414 1613293928.9747963
train: epoch 46, iter 4200, loss: 2.771650, top_1: 0.581289, top_k: 0.802930, samples/s: 777.272 1613293961.9104793
train: epoch 46, iter 4300, loss: 2.414153, top_1: 0.589688, top_k: 0.808438, samples/s: 781.591 1613293994.664114
train: epoch 46, iter 4400, loss: 2.841865, top_1: 0.580273, top_k: 0.802617, samples/s: 778.818 1613294027.5343978
train: epoch 46, iter 4500, loss: 2.669405, top_1: 0.584688, top_k: 0.803477, samples/s: 778.675 1613294060.4107716
train: epoch 46, iter 4600, loss: 2.865531, top_1: 0.585352, top_k: 0.803711, samples/s: 781.217 1613294093.1801853
train: epoch 46, iter 4700, loss: 2.646560, top_1: 0.582344, top_k: 0.806680, samples/s: 779.594 1613294126.0177267
train: epoch 46, iter 4800, loss: 2.573959, top_1: 0.582266, top_k: 0.807617, samples/s: 778.267 1613294158.9113362
train: epoch 46, iter 4900, loss: 2.737525, top_1: 0.584375, top_k: 0.805625, samples/s: 781.446 1613294191.6711013
train: epoch 46, iter 5000, loss: 2.625764, top_1: 0.584141, top_k: 0.807383, samples/s: 776.792 1613294224.6271975
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_46.
validation: epoch 46, iter 195, top_1: 0.635877, top_k: 0.856811, samples/s: 2362.217 1613294246.6989539
train: epoch 47, iter 100, loss: 2.608824, top_1: 0.598164, top_k: 0.815391, samples/s: 804.732 1613294304.5557425
train: epoch 47, iter 200, loss: 2.731318, top_1: 0.600195, top_k: 0.819570, samples/s: 800.266 1613294336.5449715
train: epoch 47, iter 300, loss: 2.667746, top_1: 0.600938, top_k: 0.818047, samples/s: 785.135 1613294369.15101
train: epoch 47, iter 400, loss: 2.441930, top_1: 0.591836, top_k: 0.810391, samples/s: 776.361 1613294402.125125
train: epoch 47, iter 500, loss: 2.591687, top_1: 0.593984, top_k: 0.811680, samples/s: 774.145 1613294435.1938999
train: epoch 47, iter 600, loss: 2.621744, top_1: 0.592578, top_k: 0.815586, samples/s: 783.387 1613294467.8726172
train: epoch 47, iter 700, loss: 2.939152, top_1: 0.595234, top_k: 0.812187, samples/s: 779.756 1613294500.7033854
train: epoch 47, iter 800, loss: 2.589329, top_1: 0.593945, top_k: 0.812422, samples/s: 779.855 1613294533.5300071
train: epoch 47, iter 900, loss: 2.749229, top_1: 0.594922, top_k: 0.813086, samples/s: 777.261 1613294566.4661794
train: epoch 47, iter 1000, loss: 2.680927, top_1: 0.591445, top_k: 0.814805, samples/s: 781.766 1613294599.2125206
train: epoch 47, iter 1100, loss: 2.604738, top_1: 0.594766, top_k: 0.811719, samples/s: 778.248 1613294632.1068501
train: epoch 47, iter 1200, loss: 2.621728, top_1: 0.589883, top_k: 0.810039, samples/s: 777.327 1613294665.0403416
train: epoch 47, iter 1300, loss: 2.740319, top_1: 0.599805, top_k: 0.815508, samples/s: 779.789 1613294697.8696363
train: epoch 47, iter 1400, loss: 2.709208, top_1: 0.591836, top_k: 0.814375, samples/s: 779.585 1613294730.7075942
train: epoch 47, iter 1500, loss: 3.000753, top_1: 0.587031, top_k: 0.809297, samples/s: 779.826 1613294763.5354521
train: epoch 47, iter 1600, loss: 2.641314, top_1: 0.589766, top_k: 0.809570, samples/s: 777.275 1613294796.471077
train: epoch 47, iter 1700, loss: 2.741607, top_1: 0.582461, top_k: 0.805703, samples/s: 781.021 1613294829.2485962
train: epoch 47, iter 1800, loss: 2.636170, top_1: 0.595352, top_k: 0.810000, samples/s: 780.074 1613294862.066069
train: epoch 47, iter 1900, loss: 2.431175, top_1: 0.584063, top_k: 0.808906, samples/s: 777.328 1613294894.9993987
train: epoch 47, iter 2000, loss: 2.746783, top_1: 0.591328, top_k: 0.805234, samples/s: 782.005 1613294927.7358055
train: epoch 47, iter 2100, loss: 2.712954, top_1: 0.590195, top_k: 0.810352, samples/s: 778.108 1613294960.6360316
train: epoch 47, iter 2200, loss: 2.647294, top_1: 0.584766, top_k: 0.805586, samples/s: 775.890 1613294993.6304624
train: epoch 47, iter 2300, loss: 2.572948, top_1: 0.583438, top_k: 0.807695, samples/s: 781.850 1613295026.37332
train: epoch 47, iter 2400, loss: 2.613169, top_1: 0.585664, top_k: 0.807969, samples/s: 779.240 1613295059.225763
train: epoch 47, iter 2500, loss: 2.650574, top_1: 0.591211, top_k: 0.811836, samples/s: 779.328 1613295092.0745845
train: epoch 47, iter 2600, loss: 2.747862, top_1: 0.590625, top_k: 0.810703, samples/s: 779.303 1613295124.9245725
train: epoch 47, iter 2700, loss: 2.542472, top_1: 0.588125, top_k: 0.810937, samples/s: 781.208 1613295157.6943176
train: epoch 47, iter 2800, loss: 2.841543, top_1: 0.589688, top_k: 0.808477, samples/s: 779.269 1613295190.545597
train: epoch 47, iter 2900, loss: 2.913038, top_1: 0.586367, top_k: 0.809531, samples/s: 781.578 1613295223.299744
train: epoch 47, iter 3000, loss: 2.865978, top_1: 0.588125, top_k: 0.808672, samples/s: 778.428 1613295256.1865532
train: epoch 47, iter 3100, loss: 2.721239, top_1: 0.591719, top_k: 0.809023, samples/s: 778.169 1613295289.084304
train: epoch 47, iter 3200, loss: 2.720760, top_1: 0.582461, top_k: 0.805312, samples/s: 783.791 1613295321.7460423
train: epoch 47, iter 3300, loss: 2.534626, top_1: 0.588086, top_k: 0.811328, samples/s: 778.897 1613295354.613039
train: epoch 47, iter 3400, loss: 2.690436, top_1: 0.583750, top_k: 0.806680, samples/s: 779.947 1613295387.435839
train: epoch 47, iter 3500, loss: 2.803583, top_1: 0.582656, top_k: 0.808047, samples/s: 780.476 1613295420.2363176
train: epoch 47, iter 3600, loss: 2.431173, top_1: 0.584609, top_k: 0.809727, samples/s: 778.185 1613295453.1333926
train: epoch 47, iter 3700, loss: 2.828825, top_1: 0.583750, top_k: 0.807578, samples/s: 781.203 1613295485.9033303
train: epoch 47, iter 3800, loss: 2.603373, top_1: 0.586055, top_k: 0.804805, samples/s: 781.061 1613295518.6792128
train: epoch 47, iter 3900, loss: 2.845187, top_1: 0.586758, top_k: 0.808281, samples/s: 780.822 1613295551.4653
train: epoch 47, iter 4000, loss: 2.765046, top_1: 0.582422, top_k: 0.808672, samples/s: 781.234 1613295584.233988
train: epoch 47, iter 4100, loss: 2.835296, top_1: 0.586094, top_k: 0.807070, samples/s: 779.722 1613295617.0660756
train: epoch 47, iter 4200, loss: 2.681629, top_1: 0.583984, top_k: 0.807344, samples/s: 777.821 1613295649.9785645
train: epoch 47, iter 4300, loss: 2.740536, top_1: 0.593203, top_k: 0.809063, samples/s: 780.168 1613295682.7920656
train: epoch 47, iter 4400, loss: 2.665854, top_1: 0.593242, top_k: 0.812148, samples/s: 780.922 1613295715.5738528
train: epoch 47, iter 4500, loss: 2.699594, top_1: 0.586406, top_k: 0.810312, samples/s: 779.084 1613295748.4329798
train: epoch 47, iter 4600, loss: 2.839335, top_1: 0.592227, top_k: 0.810078, samples/s: 779.528 1613295781.2733016
train: epoch 47, iter 4700, loss: 2.740398, top_1: 0.586094, top_k: 0.806602, samples/s: 779.903 1613295814.097936
train: epoch 47, iter 4800, loss: 2.761335, top_1: 0.579102, top_k: 0.803008, samples/s: 782.314 1613295846.8213403
train: epoch 47, iter 4900, loss: 2.591716, top_1: 0.581719, top_k: 0.804063, samples/s: 778.674 1613295879.6976886
train: epoch 47, iter 5000, loss: 2.466064, top_1: 0.588828, top_k: 0.812852, samples/s: 778.506 1613295912.5812848
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_47.
validation: epoch 47, iter 195, top_1: 0.637981, top_k: 0.863261, samples/s: 2375.136 1613295934.5754187
train: epoch 48, iter 100, loss: 2.494539, top_1: 0.598984, top_k: 0.816055, samples/s: 805.721 1613295986.8150878
train: epoch 48, iter 200, loss: 2.722816, top_1: 0.600469, top_k: 0.813203, samples/s: 798.025 1613296018.8945408
train: epoch 48, iter 300, loss: 2.696253, top_1: 0.593633, top_k: 0.815391, samples/s: 778.672 1613296051.770657
train: epoch 48, iter 400, loss: 2.672141, top_1: 0.596289, top_k: 0.818555, samples/s: 777.918 1613296084.679514
train: epoch 48, iter 500, loss: 2.703428, top_1: 0.593516, top_k: 0.812969, samples/s: 778.390 1613296117.5674248
train: epoch 48, iter 600, loss: 2.666978, top_1: 0.595508, top_k: 0.816328, samples/s: 776.370 1613296150.541376
train: epoch 48, iter 700, loss: 2.707722, top_1: 0.595703, top_k: 0.814570, samples/s: 780.039 1613296183.3603258
train: epoch 48, iter 800, loss: 2.407866, top_1: 0.592734, top_k: 0.812305, samples/s: 777.849 1613296216.271618
train: epoch 48, iter 900, loss: 2.681738, top_1: 0.590430, top_k: 0.813477, samples/s: 779.529 1613296249.1118455
train: epoch 48, iter 1000, loss: 2.844088, top_1: 0.589648, top_k: 0.808047, samples/s: 780.017 1613296281.9316373
train: epoch 48, iter 1100, loss: 2.590564, top_1: 0.594609, top_k: 0.813320, samples/s: 777.318 1613296314.8654666
train: epoch 48, iter 1200, loss: 2.631267, top_1: 0.593867, top_k: 0.815859, samples/s: 777.988 1613296347.7708142
train: epoch 48, iter 1300, loss: 2.641725, top_1: 0.591094, top_k: 0.809688, samples/s: 780.000 1613296380.5913072
train: epoch 48, iter 1400, loss: 2.812628, top_1: 0.587773, top_k: 0.813945, samples/s: 777.284 1613296413.5265021
train: epoch 48, iter 1500, loss: 2.718146, top_1: 0.596523, top_k: 0.815273, samples/s: 782.013 1613296446.262594
train: epoch 48, iter 1600, loss: 2.556287, top_1: 0.590977, top_k: 0.810273, samples/s: 778.151 1613296479.1611137
train: epoch 48, iter 1700, loss: 2.719842, top_1: 0.590000, top_k: 0.812773, samples/s: 778.668 1613296512.037732
train: epoch 48, iter 1800, loss: 2.564788, top_1: 0.591328, top_k: 0.807813, samples/s: 778.005 1613296544.9424593
train: epoch 48, iter 1900, loss: 2.784466, top_1: 0.585508, top_k: 0.810547, samples/s: 780.042 1613296577.7611532
train: epoch 48, iter 2000, loss: 2.752462, top_1: 0.594180, top_k: 0.812852, samples/s: 778.451 1613296610.647073
train: epoch 48, iter 2100, loss: 2.629749, top_1: 0.593398, top_k: 0.811094, samples/s: 779.205 1613296643.5010266
train: epoch 48, iter 2200, loss: 2.705252, top_1: 0.594102, top_k: 0.809531, samples/s: 779.604 1613296676.3381035
train: epoch 48, iter 2300, loss: 2.608863, top_1: 0.589570, top_k: 0.813672, samples/s: 778.918 1613296709.2042227
train: epoch 48, iter 2400, loss: 2.832776, top_1: 0.588125, top_k: 0.811367, samples/s: 781.925 1613296741.9439988
train: epoch 48, iter 2500, loss: 2.862873, top_1: 0.583359, top_k: 0.811211, samples/s: 776.578 1613296774.9091372
train: epoch 48, iter 2600, loss: 2.639282, top_1: 0.589297, top_k: 0.807305, samples/s: 780.417 1613296807.7121835
train: epoch 48, iter 2700, loss: 2.648007, top_1: 0.587539, top_k: 0.810664, samples/s: 779.155 1613296840.5682387
train: epoch 48, iter 2800, loss: 2.837232, top_1: 0.587969, top_k: 0.808789, samples/s: 780.230 1613296873.3791611
train: epoch 48, iter 2900, loss: 2.766944, top_1: 0.585391, top_k: 0.808086, samples/s: 782.444 1613296906.0971422
train: epoch 48, iter 3000, loss: 2.880538, top_1: 0.591211, top_k: 0.809219, samples/s: 778.014 1613296939.0013547
train: epoch 48, iter 3100, loss: 2.679547, top_1: 0.588633, top_k: 0.808555, samples/s: 780.196 1613296971.813721
train: epoch 48, iter 3200, loss: 2.700943, top_1: 0.590547, top_k: 0.812070, samples/s: 779.341 1613297004.662024
train: epoch 48, iter 3300, loss: 2.736362, top_1: 0.589688, top_k: 0.810703, samples/s: 779.603 1613297037.499228
train: epoch 48, iter 3400, loss: 2.793451, top_1: 0.588945, top_k: 0.811367, samples/s: 781.972 1613297070.236864
train: epoch 48, iter 3500, loss: 2.702797, top_1: 0.588594, top_k: 0.810156, samples/s: 781.366 1613297102.999978
train: epoch 48, iter 3600, loss: 2.784636, top_1: 0.588437, top_k: 0.810547, samples/s: 779.191 1613297135.8546348
train: epoch 48, iter 3700, loss: 2.587206, top_1: 0.595195, top_k: 0.811055, samples/s: 779.345 1613297168.7027566
train: epoch 48, iter 3800, loss: 2.763235, top_1: 0.591484, top_k: 0.807305, samples/s: 778.884 1613297201.570343
train: epoch 48, iter 3900, loss: 2.686463, top_1: 0.593750, top_k: 0.811719, samples/s: 780.438 1613297234.3724372
train: epoch 48, iter 4000, loss: 2.687597, top_1: 0.586641, top_k: 0.805781, samples/s: 780.685 1613297267.1640778
train: epoch 48, iter 4100, loss: 2.662898, top_1: 0.586484, top_k: 0.808359, samples/s: 778.055 1613297300.0666232
train: epoch 48, iter 4200, loss: 2.569881, top_1: 0.589297, top_k: 0.811641, samples/s: 780.250 1613297332.8765676
train: epoch 48, iter 4300, loss: 2.765527, top_1: 0.591367, top_k: 0.811875, samples/s: 779.037 1613297365.737659
train: epoch 48, iter 4400, loss: 2.556268, top_1: 0.588477, top_k: 0.810898, samples/s: 778.402 1613297398.6255574
train: epoch 48, iter 4500, loss: 2.602169, top_1: 0.587148, top_k: 0.811953, samples/s: 779.009 1613297431.4877744
train: epoch 48, iter 4600, loss: 2.654123, top_1: 0.582695, top_k: 0.810234, samples/s: 781.037 1613297464.2647803
train: epoch 48, iter 4700, loss: 2.604922, top_1: 0.586289, top_k: 0.808906, samples/s: 779.810 1613297497.0932043
train: epoch 48, iter 4800, loss: 2.693932, top_1: 0.585859, top_k: 0.807656, samples/s: 782.023 1613297529.828819
train: epoch 48, iter 4900, loss: 2.845099, top_1: 0.587773, top_k: 0.806094, samples/s: 777.775 1613297562.7433245
train: epoch 48, iter 5000, loss: 2.763190, top_1: 0.590820, top_k: 0.812813, samples/s: 778.699 1613297595.6186478
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_48.
validation: epoch 48, iter 195, top_1: 0.643009, top_k: 0.864363, samples/s: 2381.194 1613297617.5733202
train: epoch 49, iter 100, loss: 2.817770, top_1: 0.610781, top_k: 0.829219, samples/s: 802.457 1613297670.7218635
train: epoch 49, iter 200, loss: 2.649879, top_1: 0.596055, top_k: 0.815898, samples/s: 800.115 1613297702.7172308
train: epoch 49, iter 300, loss: 2.638980, top_1: 0.598281, top_k: 0.815625, samples/s: 781.712 1613297735.4657786
train: epoch 49, iter 400, loss: 2.680981, top_1: 0.605469, top_k: 0.821055, samples/s: 778.021 1613297768.369869
train: epoch 49, iter 500, loss: 2.516591, top_1: 0.604375, top_k: 0.818672, samples/s: 778.490 1613297801.2540603
train: epoch 49, iter 600, loss: 2.835480, top_1: 0.599063, top_k: 0.813438, samples/s: 780.930 1613297834.0353663
train: epoch 49, iter 700, loss: 2.754953, top_1: 0.590898, top_k: 0.812461, samples/s: 780.030 1613297866.8545973
train: epoch 49, iter 800, loss: 2.743220, top_1: 0.593125, top_k: 0.815898, samples/s: 779.544 1613297899.6943867
train: epoch 49, iter 900, loss: 2.603319, top_1: 0.594570, top_k: 0.812891, samples/s: 781.429 1613297932.4548068
train: epoch 49, iter 1000, loss: 2.650369, top_1: 0.596602, top_k: 0.816484, samples/s: 778.855 1613297965.323656
train: epoch 49, iter 1100, loss: 2.772914, top_1: 0.588164, top_k: 0.812578, samples/s: 780.526 1613297998.121976
train: epoch 49, iter 1200, loss: 2.689926, top_1: 0.593672, top_k: 0.811602, samples/s: 781.072 1613298030.8975053
train: epoch 49, iter 1300, loss: 2.763616, top_1: 0.595508, top_k: 0.815039, samples/s: 778.515 1613298063.7806585
train: epoch 49, iter 1400, loss: 2.643262, top_1: 0.595195, top_k: 0.816680, samples/s: 780.347 1613298096.5865767
train: epoch 49, iter 1500, loss: 2.547546, top_1: 0.593086, top_k: 0.814883, samples/s: 781.151 1613298129.3586245
train: epoch 49, iter 1600, loss: 2.759340, top_1: 0.592422, top_k: 0.815273, samples/s: 778.113 1613298162.2588189
train: epoch 49, iter 1700, loss: 2.621025, top_1: 0.588047, top_k: 0.808750, samples/s: 781.632 1613298195.0107648
train: epoch 49, iter 1800, loss: 2.621174, top_1: 0.595156, top_k: 0.815508, samples/s: 780.042 1613298227.8294892
train: epoch 49, iter 1900, loss: 2.705256, top_1: 0.590977, top_k: 0.812422, samples/s: 778.103 1613298260.729987
train: epoch 49, iter 2000, loss: 2.587822, top_1: 0.591523, top_k: 0.814570, samples/s: 780.805 1613298293.5167887
train: epoch 49, iter 2100, loss: 2.623200, top_1: 0.593555, top_k: 0.811562, samples/s: 780.028 1613298326.336098
train: epoch 49, iter 2200, loss: 2.564315, top_1: 0.588437, top_k: 0.816680, samples/s: 782.298 1613298359.060103
train: epoch 49, iter 2300, loss: 2.651931, top_1: 0.592969, top_k: 0.812656, samples/s: 780.746 1613298391.8493917
train: epoch 49, iter 2400, loss: 2.568908, top_1: 0.593437, top_k: 0.812969, samples/s: 779.329 1613298424.6981068
train: epoch 49, iter 2500, loss: 2.519242, top_1: 0.587852, top_k: 0.812266, samples/s: 781.144 1613298457.470489
train: epoch 49, iter 2600, loss: 2.667892, top_1: 0.590117, top_k: 0.810000, samples/s: 782.971 1613298490.166506
train: epoch 49, iter 2700, loss: 2.660788, top_1: 0.593789, top_k: 0.816562, samples/s: 781.295 1613298522.932682
train: epoch 49, iter 2800, loss: 2.738379, top_1: 0.589727, top_k: 0.815742, samples/s: 780.865 1613298555.7168186
train: epoch 49, iter 2900, loss: 2.793721, top_1: 0.586758, top_k: 0.806758, samples/s: 780.494 1613298588.516521
train: epoch 49, iter 3000, loss: 2.786604, top_1: 0.584258, top_k: 0.804609, samples/s: 783.254 1613298621.2006774
train: epoch 49, iter 3100, loss: 2.868722, top_1: 0.591836, top_k: 0.812266, samples/s: 782.364 1613298653.922075
train: epoch 49, iter 3200, loss: 2.848463, top_1: 0.584258, top_k: 0.807383, samples/s: 782.041 1613298686.6568944
train: epoch 49, iter 3300, loss: 2.860758, top_1: 0.591836, top_k: 0.809180, samples/s: 779.611 1613298719.493811
train: epoch 49, iter 3400, loss: 2.781719, top_1: 0.591133, top_k: 0.809258, samples/s: 780.332 1613298752.3004029
train: epoch 49, iter 3500, loss: 2.631936, top_1: 0.587812, top_k: 0.810781, samples/s: 778.527 1613298785.182985
train: epoch 49, iter 3600, loss: 2.691524, top_1: 0.586641, top_k: 0.806719, samples/s: 782.746 1613298817.8882983
train: epoch 49, iter 3700, loss: 2.634975, top_1: 0.588516, top_k: 0.809141, samples/s: 779.586 1613298850.7263174
train: epoch 49, iter 3800, loss: 2.679815, top_1: 0.593672, top_k: 0.811016, samples/s: 783.190 1613298883.4130745
train: epoch 49, iter 3900, loss: 2.816162, top_1: 0.584609, top_k: 0.807578, samples/s: 778.839 1613298916.2825065
train: epoch 49, iter 4000, loss: 2.698334, top_1: 0.593633, top_k: 0.813164, samples/s: 780.072 1613298949.1000535
train: epoch 49, iter 4100, loss: 2.718366, top_1: 0.587578, top_k: 0.810898, samples/s: 782.203 1613298981.828078
train: epoch 49, iter 4200, loss: 2.533017, top_1: 0.589023, top_k: 0.809063, samples/s: 779.942 1613299014.651042
train: epoch 49, iter 4300, loss: 2.561324, top_1: 0.587773, top_k: 0.808594, samples/s: 780.302 1613299047.4589093
train: epoch 49, iter 4400, loss: 2.823719, top_1: 0.593125, top_k: 0.813164, samples/s: 780.462 1613299080.2599814
train: epoch 49, iter 4500, loss: 2.736135, top_1: 0.592070, top_k: 0.811562, samples/s: 780.672 1613299113.0523317
train: epoch 49, iter 4600, loss: 2.653421, top_1: 0.588125, top_k: 0.811484, samples/s: 782.179 1613299145.7812948
train: epoch 49, iter 4700, loss: 2.562625, top_1: 0.590742, top_k: 0.812852, samples/s: 779.760 1613299178.6119418
train: epoch 49, iter 4800, loss: 2.813656, top_1: 0.586914, top_k: 0.809922, samples/s: 780.302 1613299211.4197612
train: epoch 49, iter 4900, loss: 2.817661, top_1: 0.583398, top_k: 0.809180, samples/s: 780.638 1613299244.213484
train: epoch 49, iter 5000, loss: 2.538727, top_1: 0.587305, top_k: 0.806328, samples/s: 780.422 1613299277.0161948
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_49.
validation: epoch 49, iter 195, top_1: 0.639503, top_k: 0.862079, samples/s: 2386.465 1613299298.9205906
train: epoch 50, iter 100, loss: 2.799842, top_1: 0.608320, top_k: 0.823516, samples/s: 804.941 1613299351.924944
train: epoch 50, iter 200, loss: 2.643640, top_1: 0.603164, top_k: 0.819570, samples/s: 799.599 1613299383.9411354
train: epoch 50, iter 300, loss: 2.493114, top_1: 0.604375, top_k: 0.823242, samples/s: 780.723 1613299416.7310562
train: epoch 50, iter 400, loss: 2.779062, top_1: 0.597344, top_k: 0.817344, samples/s: 781.446 1613299449.4908795
train: epoch 50, iter 500, loss: 2.592418, top_1: 0.601914, top_k: 0.820547, samples/s: 780.417 1613299482.2943358
train: epoch 50, iter 600, loss: 2.827632, top_1: 0.595625, top_k: 0.813789, samples/s: 780.228 1613299515.1048534
train: epoch 50, iter 700, loss: 2.690362, top_1: 0.594844, top_k: 0.813828, samples/s: 778.048 1613299548.008062
train: epoch 50, iter 800, loss: 2.748865, top_1: 0.594766, top_k: 0.815039, samples/s: 780.024 1613299580.8271344
train: epoch 50, iter 900, loss: 2.914480, top_1: 0.591406, top_k: 0.812539, samples/s: 780.085 1613299613.6441052
train: epoch 50, iter 1000, loss: 2.647224, top_1: 0.598281, top_k: 0.818242, samples/s: 782.617 1613299646.354829
train: epoch 50, iter 1100, loss: 2.772246, top_1: 0.595508, top_k: 0.815430, samples/s: 774.560 1613299679.405988
train: epoch 50, iter 1200, loss: 2.656510, top_1: 0.592266, top_k: 0.816211, samples/s: 781.557 1613299712.1609914
train: epoch 50, iter 1300, loss: 2.752219, top_1: 0.594141, top_k: 0.815898, samples/s: 781.245 1613299744.9292393
train: epoch 50, iter 1400, loss: 2.693801, top_1: 0.596172, top_k: 0.815664, samples/s: 781.395 1613299777.6911595
train: epoch 50, iter 1500, loss: 2.615506, top_1: 0.593398, top_k: 0.816836, samples/s: 779.647 1613299810.5264587
train: epoch 50, iter 1600, loss: 2.795837, top_1: 0.592930, top_k: 0.811797, samples/s: 777.898 1613299843.4356797
train: epoch 50, iter 1700, loss: 2.733786, top_1: 0.588633, top_k: 0.809063, samples/s: 781.053 1613299876.2119908
train: epoch 50, iter 1800, loss: 2.525557, top_1: 0.600469, top_k: 0.816094, samples/s: 778.467 1613299909.0971057
train: epoch 50, iter 1900, loss: 2.566735, top_1: 0.591602, top_k: 0.812500, samples/s: 780.593 1613299941.8926466
train: epoch 50, iter 2000, loss: 2.801281, top_1: 0.591719, top_k: 0.813633, samples/s: 780.699 1613299974.6837897
train: epoch 50, iter 2100, loss: 2.557027, top_1: 0.590195, top_k: 0.810703, samples/s: 780.425 1613300007.4864686
train: epoch 50, iter 2200, loss: 2.657313, top_1: 0.591523, top_k: 0.810312, samples/s: 780.634 1613300040.2803361
train: epoch 50, iter 2300, loss: 2.615555, top_1: 0.594648, top_k: 0.813008, samples/s: 780.905 1613300073.062693
train: epoch 50, iter 2400, loss: 2.617905, top_1: 0.591875, top_k: 0.815352, samples/s: 779.612 1613300105.8996081
train: epoch 50, iter 2500, loss: 2.577650, top_1: 0.590039, top_k: 0.810742, samples/s: 777.357 1613300138.831645
train: epoch 50, iter 2600, loss: 2.814311, top_1: 0.599414, top_k: 0.817695, samples/s: 781.408 1613300171.5930474
train: epoch 50, iter 2700, loss: 2.623573, top_1: 0.590039, top_k: 0.810586, samples/s: 778.498 1613300204.4768965
train: epoch 50, iter 2800, loss: 2.603189, top_1: 0.587930, top_k: 0.810430, samples/s: 779.112 1613300237.334745
train: epoch 50, iter 2900, loss: 2.629609, top_1: 0.589414, top_k: 0.810273, samples/s: 782.477 1613300270.0513816
train: epoch 50, iter 3000, loss: 2.560678, top_1: 0.593398, top_k: 0.812656, samples/s: 776.830 1613300303.005807
train: epoch 50, iter 3100, loss: 2.826012, top_1: 0.591875, top_k: 0.810625, samples/s: 780.336 1613300335.8122606
train: epoch 50, iter 3200, loss: 2.786993, top_1: 0.596133, top_k: 0.818008, samples/s: 780.443 1613300368.61408
train: epoch 50, iter 3300, loss: 2.687441, top_1: 0.592734, top_k: 0.812344, samples/s: 778.457 1613300401.4997272
train: epoch 50, iter 3400, loss: 2.708340, top_1: 0.586562, top_k: 0.810000, samples/s: 781.366 1613300434.2627904
train: epoch 50, iter 3500, loss: 2.773960, top_1: 0.588594, top_k: 0.808438, samples/s: 780.748 1613300467.0519116
train: epoch 50, iter 3600, loss: 2.838519, top_1: 0.590898, top_k: 0.810937, samples/s: 777.397 1613300499.9822373
train: epoch 50, iter 3700, loss: 2.738660, top_1: 0.593437, top_k: 0.811914, samples/s: 779.026 1613300532.8439145
train: epoch 50, iter 3800, loss: 2.641989, top_1: 0.590781, top_k: 0.812852, samples/s: 780.057 1613300565.661944
train: epoch 50, iter 3900, loss: 2.765135, top_1: 0.591289, top_k: 0.814023, samples/s: 781.870 1613300598.4040375
train: epoch 50, iter 4000, loss: 2.652248, top_1: 0.592227, top_k: 0.808555, samples/s: 780.228 1613300631.2149599
train: epoch 50, iter 4100, loss: 2.761991, top_1: 0.586719, top_k: 0.814180, samples/s: 778.143 1613300664.1137495
train: epoch 50, iter 4200, loss: 2.542469, top_1: 0.589609, top_k: 0.808594, samples/s: 783.066 1613300696.8057775
train: epoch 50, iter 4300, loss: 2.699191, top_1: 0.591328, top_k: 0.808516, samples/s: 780.750 1613300729.594695
train: epoch 50, iter 4400, loss: 2.648585, top_1: 0.596016, top_k: 0.813086, samples/s: 777.591 1613300762.5169265
train: epoch 50, iter 4500, loss: 2.654133, top_1: 0.594570, top_k: 0.813711, samples/s: 782.265 1613300795.242376
train: epoch 50, iter 4600, loss: 2.778329, top_1: 0.588125, top_k: 0.808711, samples/s: 777.079 1613300828.18632
train: epoch 50, iter 4700, loss: 2.629923, top_1: 0.588398, top_k: 0.811328, samples/s: 780.830 1613300860.971972
train: epoch 50, iter 4800, loss: 2.401387, top_1: 0.593867, top_k: 0.813945, samples/s: 776.391 1613300893.9450698
train: epoch 50, iter 4900, loss: 2.754778, top_1: 0.591211, top_k: 0.808867, samples/s: 781.970 1613300926.6828172
train: epoch 50, iter 5000, loss: 2.770581, top_1: 0.594531, top_k: 0.814492, samples/s: 780.562 1613300959.47972
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_50.
validation: epoch 50, iter 195, top_1: 0.637099, top_k: 0.858273, samples/s: 2349.090 1613300981.7183151
train: epoch 51, iter 100, loss: 2.658773, top_1: 0.602500, top_k: 0.819648, samples/s: 804.430 1613301033.971799
train: epoch 51, iter 200, loss: 2.759341, top_1: 0.597500, top_k: 0.815742, samples/s: 798.111 1613301066.047466
train: epoch 51, iter 300, loss: 2.683945, top_1: 0.593828, top_k: 0.811523, samples/s: 778.448 1613301098.933565
train: epoch 51, iter 400, loss: 2.707880, top_1: 0.599453, top_k: 0.817148, samples/s: 780.597 1613301131.7288878
train: epoch 51, iter 500, loss: 2.635968, top_1: 0.605273, top_k: 0.820078, samples/s: 778.959 1613301164.5932527
train: epoch 51, iter 600, loss: 2.683139, top_1: 0.596641, top_k: 0.816289, samples/s: 777.402 1613301197.5233595
train: epoch 51, iter 700, loss: 2.806007, top_1: 0.602500, top_k: 0.816875, samples/s: 778.885 1613301230.3909657
train: epoch 51, iter 800, loss: 2.769107, top_1: 0.595547, top_k: 0.819531, samples/s: 778.971 1613301263.254861
train: epoch 51, iter 900, loss: 2.595161, top_1: 0.598828, top_k: 0.820508, samples/s: 779.052 1613301296.115211
train: epoch 51, iter 1000, loss: 2.558414, top_1: 0.602422, top_k: 0.821211, samples/s: 778.914 1613301328.981417
train: epoch 51, iter 1100, loss: 2.828440, top_1: 0.592305, top_k: 0.814883, samples/s: 779.525 1613301361.8219547
train: epoch 51, iter 1200, loss: 2.694548, top_1: 0.602852, top_k: 0.817109, samples/s: 779.651 1613301394.6571898
train: epoch 51, iter 1300, loss: 2.609856, top_1: 0.598711, top_k: 0.815977, samples/s: 779.924 1613301427.4808614
train: epoch 51, iter 1400, loss: 2.619822, top_1: 0.594883, top_k: 0.814570, samples/s: 782.955 1613301460.1775887
train: epoch 51, iter 1500, loss: 2.415135, top_1: 0.596602, top_k: 0.816055, samples/s: 778.886 1613301493.0450451
train: epoch 51, iter 1600, loss: 2.881136, top_1: 0.589180, top_k: 0.807891, samples/s: 775.556 1613301526.0535214
train: epoch 51, iter 1700, loss: 2.588166, top_1: 0.600273, top_k: 0.814922, samples/s: 781.421 1613301558.8143995
train: epoch 51, iter 1800, loss: 2.593112, top_1: 0.595859, top_k: 0.816172, samples/s: 778.549 1613301591.6962862
train: epoch 51, iter 1900, loss: 2.848210, top_1: 0.589844, top_k: 0.812773, samples/s: 780.087 1613301624.5128806
train: epoch 51, iter 2000, loss: 2.716982, top_1: 0.594375, top_k: 0.813594, samples/s: 778.446 1613301657.3989592
train: epoch 51, iter 2100, loss: 2.761724, top_1: 0.596758, top_k: 0.813047, samples/s: 780.224 1613301690.2100263
train: epoch 51, iter 2200, loss: 2.491647, top_1: 0.599844, top_k: 0.817070, samples/s: 779.332 1613301723.0587425
train: epoch 51, iter 2300, loss: 2.835806, top_1: 0.600703, top_k: 0.816953, samples/s: 782.574 1613301755.7713032
train: epoch 51, iter 2400, loss: 2.674120, top_1: 0.597461, top_k: 0.812344, samples/s: 780.781 1613301788.5589497
train: epoch 51, iter 2500, loss: 2.657974, top_1: 0.595977, top_k: 0.810859, samples/s: 779.859 1613301821.38545
train: epoch 51, iter 2600, loss: 2.859243, top_1: 0.596367, top_k: 0.814336, samples/s: 779.199 1613301854.2396557
train: epoch 51, iter 2700, loss: 2.767862, top_1: 0.589141, top_k: 0.811797, samples/s: 781.013 1613301887.0177047
train: epoch 51, iter 2800, loss: 2.652906, top_1: 0.586680, top_k: 0.810859, samples/s: 780.916 1613301919.79973
train: epoch 51, iter 2900, loss: 2.704821, top_1: 0.590938, top_k: 0.812461, samples/s: 779.030 1613301952.6611269
train: epoch 51, iter 3000, loss: 2.643888, top_1: 0.584453, top_k: 0.808281, samples/s: 784.046 1613301985.3121774
train: epoch 51, iter 3100, loss: 2.668837, top_1: 0.592969, top_k: 0.812031, samples/s: 778.275 1613302018.2054396
train: epoch 51, iter 3200, loss: 2.832731, top_1: 0.588945, top_k: 0.812070, samples/s: 779.670 1613302051.0398772
train: epoch 51, iter 3300, loss: 2.663529, top_1: 0.587852, top_k: 0.809141, samples/s: 783.654 1613302083.7073154
train: epoch 51, iter 3400, loss: 2.640967, top_1: 0.593437, top_k: 0.810547, samples/s: 779.370 1613302116.5543592
train: epoch 51, iter 3500, loss: 2.649210, top_1: 0.596172, top_k: 0.815156, samples/s: 779.368 1613302149.401454
train: epoch 51, iter 3600, loss: 2.592850, top_1: 0.598203, top_k: 0.814883, samples/s: 778.897 1613302182.2684777
train: epoch 51, iter 3700, loss: 2.780715, top_1: 0.591875, top_k: 0.811523, samples/s: 779.894 1613302215.093385
train: epoch 51, iter 3800, loss: 2.584651, top_1: 0.589141, top_k: 0.811680, samples/s: 782.460 1613302247.810746
train: epoch 51, iter 3900, loss: 2.457280, top_1: 0.588867, top_k: 0.808750, samples/s: 780.577 1613302280.607007
train: epoch 51, iter 4000, loss: 2.710841, top_1: 0.592773, top_k: 0.810586, samples/s: 781.188 1613302313.3776264
train: epoch 51, iter 4100, loss: 2.650563, top_1: 0.590547, top_k: 0.814883, samples/s: 779.206 1613302346.231532
train: epoch 51, iter 4200, loss: 2.680652, top_1: 0.592383, top_k: 0.812344, samples/s: 780.781 1613302379.0192513
train: epoch 51, iter 4300, loss: 2.527449, top_1: 0.584766, top_k: 0.808477, samples/s: 780.668 1613302411.8116887
train: epoch 51, iter 4400, loss: 2.748425, top_1: 0.591289, top_k: 0.812773, samples/s: 780.969 1613302444.5914354
train: epoch 51, iter 4500, loss: 2.539782, top_1: 0.597031, top_k: 0.813438, samples/s: 781.174 1613302477.362702
train: epoch 51, iter 4600, loss: 2.815748, top_1: 0.596484, top_k: 0.813125, samples/s: 778.749 1613302510.235866
train: epoch 51, iter 4700, loss: 2.785442, top_1: 0.594141, top_k: 0.813750, samples/s: 780.937 1613302543.0171287
train: epoch 51, iter 4800, loss: 2.696294, top_1: 0.590977, top_k: 0.811094, samples/s: 780.490 1613302575.8170016
train: epoch 51, iter 4900, loss: 2.591312, top_1: 0.591211, top_k: 0.810508, samples/s: 780.496 1613302608.6166894
train: epoch 51, iter 5000, loss: 2.727926, top_1: 0.592187, top_k: 0.810742, samples/s: 783.573 1613302641.287466
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_51.
validation: epoch 51, iter 195, top_1: 0.646955, top_k: 0.865665, samples/s: 2357.601 1613302663.4619474
train: epoch 52, iter 100, loss: 2.526648, top_1: 0.597695, top_k: 0.821172, samples/s: 804.962 1613302715.8154209
train: epoch 52, iter 200, loss: 2.708676, top_1: 0.600000, top_k: 0.818633, samples/s: 798.148 1613302747.8898993
train: epoch 52, iter 300, loss: 2.600059, top_1: 0.605039, top_k: 0.822266, samples/s: 781.581 1613302780.6438043
train: epoch 52, iter 400, loss: 2.416152, top_1: 0.609023, top_k: 0.824648, samples/s: 778.588 1613302813.5237942
train: epoch 52, iter 500, loss: 2.570776, top_1: 0.599063, top_k: 0.815898, samples/s: 781.097 1613302846.29824
train: epoch 52, iter 600, loss: 2.698750, top_1: 0.597812, top_k: 0.818633, samples/s: 776.131 1613302879.2822437
train: epoch 52, iter 700, loss: 2.737749, top_1: 0.603320, top_k: 0.821875, samples/s: 776.521 1613302912.2498214
train: epoch 52, iter 800, loss: 2.597738, top_1: 0.602539, top_k: 0.820586, samples/s: 780.018 1613302945.0695622
train: epoch 52, iter 900, loss: 2.729942, top_1: 0.599648, top_k: 0.814844, samples/s: 782.837 1613302977.771249
train: epoch 52, iter 1000, loss: 2.577983, top_1: 0.592031, top_k: 0.811797, samples/s: 777.973 1613303010.6772008
train: epoch 52, iter 1100, loss: 2.396138, top_1: 0.597852, top_k: 0.817383, samples/s: 776.377 1613303043.650855
train: epoch 52, iter 1200, loss: 2.608468, top_1: 0.603945, top_k: 0.821641, samples/s: 780.319 1613303076.458006
train: epoch 52, iter 1300, loss: 2.560273, top_1: 0.602031, top_k: 0.817734, samples/s: 777.920 1613303109.3662667
train: epoch 52, iter 1400, loss: 2.834149, top_1: 0.595469, top_k: 0.814961, samples/s: 779.512 1613303142.2072635
train: epoch 52, iter 1500, loss: 2.665469, top_1: 0.592539, top_k: 0.810156, samples/s: 778.755 1613303175.080288
train: epoch 52, iter 1600, loss: 2.654145, top_1: 0.593359, top_k: 0.815898, samples/s: 779.925 1613303207.9039142
train: epoch 52, iter 1700, loss: 2.507790, top_1: 0.591875, top_k: 0.807617, samples/s: 778.848 1613303240.773002
train: epoch 52, iter 1800, loss: 2.606774, top_1: 0.596055, top_k: 0.817305, samples/s: 780.895 1613303273.5559814
train: epoch 52, iter 1900, loss: 2.603041, top_1: 0.592695, top_k: 0.814648, samples/s: 781.350 1613303306.3197625
train: epoch 52, iter 2000, loss: 2.755155, top_1: 0.591758, top_k: 0.813008, samples/s: 776.305 1613303339.2964163
train: epoch 52, iter 2100, loss: 2.636578, top_1: 0.595547, top_k: 0.818203, samples/s: 779.369 1613303372.143582
train: epoch 52, iter 2200, loss: 2.680993, top_1: 0.588633, top_k: 0.812734, samples/s: 781.506 1613303404.900763
train: epoch 52, iter 2300, loss: 2.734428, top_1: 0.593672, top_k: 0.817148, samples/s: 780.074 1613303437.7182627
train: epoch 52, iter 2400, loss: 2.703276, top_1: 0.593633, top_k: 0.809609, samples/s: 779.155 1613303470.5743213
train: epoch 52, iter 2500, loss: 2.521717, top_1: 0.595391, top_k: 0.816562, samples/s: 776.520 1613303503.5418885
train: epoch 52, iter 2600, loss: 2.672756, top_1: 0.594492, top_k: 0.816367, samples/s: 778.313 1613303536.4335876
train: epoch 52, iter 2700, loss: 2.661576, top_1: 0.602734, top_k: 0.819063, samples/s: 779.881 1613303569.2590685
train: epoch 52, iter 2800, loss: 2.830201, top_1: 0.590859, top_k: 0.812266, samples/s: 779.630 1613303602.0951746
train: epoch 52, iter 2900, loss: 2.784858, top_1: 0.576602, top_k: 0.797656, samples/s: 780.145 1613303634.9095733
train: epoch 52, iter 3000, loss: 2.660599, top_1: 0.588086, top_k: 0.809414, samples/s: 781.388 1613303667.6717873
train: epoch 52, iter 3100, loss: 2.625603, top_1: 0.588008, top_k: 0.809219, samples/s: 778.629 1613303700.5500712
train: epoch 52, iter 3200, loss: 2.477674, top_1: 0.592187, top_k: 0.808359, samples/s: 781.021 1613303733.3276875
train: epoch 52, iter 3300, loss: 2.687769, top_1: 0.590313, top_k: 0.811406, samples/s: 776.831 1613303766.2821128
train: epoch 52, iter 3400, loss: 2.765519, top_1: 0.599688, top_k: 0.816523, samples/s: 780.365 1613303799.087282
train: epoch 52, iter 3500, loss: 2.758299, top_1: 0.591367, top_k: 0.807656, samples/s: 777.845 1613303831.9987497
train: epoch 52, iter 3600, loss: 2.507238, top_1: 0.592383, top_k: 0.816758, samples/s: 780.872 1613303864.7825446
train: epoch 52, iter 3700, loss: 2.545931, top_1: 0.588281, top_k: 0.813984, samples/s: 779.184 1613303897.6374915
train: epoch 52, iter 3800, loss: 2.708229, top_1: 0.593633, top_k: 0.813867, samples/s: 779.159 1613303930.4935062
train: epoch 52, iter 3900, loss: 2.583507, top_1: 0.593477, top_k: 0.815000, samples/s: 780.608 1613303963.2884648
train: epoch 52, iter 4000, loss: 2.705404, top_1: 0.592969, top_k: 0.813516, samples/s: 779.720 1613303996.1207106
train: epoch 52, iter 4100, loss: 2.629391, top_1: 0.592109, top_k: 0.814414, samples/s: 777.449 1613304029.0489495
train: epoch 52, iter 4200, loss: 2.787399, top_1: 0.592344, top_k: 0.811562, samples/s: 780.998 1613304061.8274412
train: epoch 52, iter 4300, loss: 2.543108, top_1: 0.590703, top_k: 0.813867, samples/s: 776.816 1613304094.7825766
train: epoch 52, iter 4400, loss: 2.817403, top_1: 0.594219, top_k: 0.811992, samples/s: 779.032 1613304127.6437979
train: epoch 52, iter 4500, loss: 2.915750, top_1: 0.592617, top_k: 0.809492, samples/s: 781.197 1613304160.4139557
train: epoch 52, iter 4600, loss: 2.666101, top_1: 0.590703, top_k: 0.812891, samples/s: 778.210 1613304193.3100033
train: epoch 52, iter 4700, loss: 2.654209, top_1: 0.591133, top_k: 0.809063, samples/s: 778.605 1613304226.1893392
train: epoch 52, iter 4800, loss: 2.701201, top_1: 0.589727, top_k: 0.810820, samples/s: 782.083 1613304258.922451
train: epoch 52, iter 4900, loss: 2.793434, top_1: 0.585430, top_k: 0.805000, samples/s: 780.188 1613304291.7349796
train: epoch 52, iter 5000, loss: 2.662250, top_1: 0.595117, top_k: 0.815391, samples/s: 779.648 1613304324.5703876
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_52.
validation: epoch 52, iter 195, top_1: 0.639243, top_k: 0.861659, samples/s: 2347.758 1613304346.7879896
train: epoch 53, iter 100, loss: 2.788384, top_1: 0.602852, top_k: 0.817773, samples/s: 803.961 1613304399.7871366
train: epoch 53, iter 200, loss: 2.701944, top_1: 0.604961, top_k: 0.821758, samples/s: 800.239 1613304431.7776377
train: epoch 53, iter 300, loss: 2.711015, top_1: 0.603906, top_k: 0.823242, samples/s: 781.464 1613304464.5365567
train: epoch 53, iter 400, loss: 2.538045, top_1: 0.603203, top_k: 0.822070, samples/s: 781.014 1613304497.314669
train: epoch 53, iter 500, loss: 2.520174, top_1: 0.599336, top_k: 0.816523, samples/s: 776.342 1613304530.2896981
train: epoch 53, iter 600, loss: 2.542745, top_1: 0.602969, top_k: 0.820625, samples/s: 776.866 1613304563.242515
train: epoch 53, iter 700, loss: 2.605640, top_1: 0.603281, top_k: 0.821797, samples/s: 781.016 1613304596.020446
train: epoch 53, iter 800, loss: 2.713981, top_1: 0.598750, top_k: 0.813164, samples/s: 777.911 1613304628.929027
train: epoch 53, iter 900, loss: 2.379023, top_1: 0.596602, top_k: 0.817695, samples/s: 779.605 1613304661.7662063
train: epoch 53, iter 1000, loss: 2.626538, top_1: 0.606563, top_k: 0.821445, samples/s: 778.317 1613304694.6576908
train: epoch 53, iter 1100, loss: 2.613905, top_1: 0.599805, top_k: 0.814844, samples/s: 778.016 1613304727.561878
train: epoch 53, iter 1200, loss: 2.408028, top_1: 0.599336, top_k: 0.819844, samples/s: 781.578 1613304760.3160832
train: epoch 53, iter 1300, loss: 2.741125, top_1: 0.600625, top_k: 0.818555, samples/s: 780.015 1613304793.1359127
train: epoch 53, iter 1400, loss: 2.735526, top_1: 0.594766, top_k: 0.812813, samples/s: 779.961 1613304825.9581342
train: epoch 53, iter 1500, loss: 2.697448, top_1: 0.597383, top_k: 0.818047, samples/s: 779.918 1613304858.7820952
train: epoch 53, iter 1600, loss: 2.547236, top_1: 0.602070, top_k: 0.820703, samples/s: 778.194 1613304891.6787987
train: epoch 53, iter 1700, loss: 2.622068, top_1: 0.598750, top_k: 0.819727, samples/s: 779.509 1613304924.5199623
train: epoch 53, iter 1800, loss: 2.781468, top_1: 0.597656, top_k: 0.815820, samples/s: 781.099 1613304957.2942746
train: epoch 53, iter 1900, loss: 2.741247, top_1: 0.603516, top_k: 0.818242, samples/s: 777.707 1613304990.2115397
train: epoch 53, iter 2000, loss: 2.704731, top_1: 0.595820, top_k: 0.816641, samples/s: 781.391 1613305022.973676
train: epoch 53, iter 2100, loss: 2.789748, top_1: 0.595078, top_k: 0.816758, samples/s: 780.906 1613305055.756141
train: epoch 53, iter 2200, loss: 2.592728, top_1: 0.597578, top_k: 0.815117, samples/s: 779.648 1613305088.5914922
train: epoch 53, iter 2300, loss: 2.650475, top_1: 0.594688, top_k: 0.815586, samples/s: 781.014 1613305121.3692732
train: epoch 53, iter 2400, loss: 2.620215, top_1: 0.596172, top_k: 0.818828, samples/s: 779.034 1613305154.23056
train: epoch 53, iter 2500, loss: 2.991997, top_1: 0.592148, top_k: 0.812734, samples/s: 780.052 1613305187.048824
train: epoch 53, iter 2600, loss: 2.735947, top_1: 0.592383, top_k: 0.807187, samples/s: 782.979 1613305219.7444425
train: epoch 53, iter 2700, loss: 2.672081, top_1: 0.586172, top_k: 0.810352, samples/s: 781.757 1613305252.4911969
train: epoch 53, iter 2800, loss: 2.739038, top_1: 0.593867, top_k: 0.816211, samples/s: 778.397 1613305285.3792994
train: epoch 53, iter 2900, loss: 2.572957, top_1: 0.597227, top_k: 0.813203, samples/s: 779.316 1613305318.2286181
train: epoch 53, iter 3000, loss: 2.565408, top_1: 0.594961, top_k: 0.816211, samples/s: 781.098 1613305351.0030055
train: epoch 53, iter 3100, loss: 2.703300, top_1: 0.595781, top_k: 0.814492, samples/s: 770.893 1613305384.2112792
train: epoch 53, iter 3200, loss: 2.693892, top_1: 0.599180, top_k: 0.815742, samples/s: 787.475 1613305416.7202802
train: epoch 53, iter 3300, loss: 2.408117, top_1: 0.595781, top_k: 0.817656, samples/s: 782.055 1613305449.454448
train: epoch 53, iter 3400, loss: 2.792207, top_1: 0.589531, top_k: 0.811328, samples/s: 779.363 1613305482.3018632
train: epoch 53, iter 3500, loss: 2.785504, top_1: 0.591914, top_k: 0.812461, samples/s: 777.998 1613305515.2068496
train: epoch 53, iter 3600, loss: 2.648941, top_1: 0.594492, top_k: 0.810078, samples/s: 780.661 1613305547.9995685
train: epoch 53, iter 3700, loss: 2.785586, top_1: 0.589141, top_k: 0.816016, samples/s: 783.164 1613305580.6874843
train: epoch 53, iter 3800, loss: 2.617673, top_1: 0.594688, top_k: 0.812695, samples/s: 779.999 1613305613.5079489
train: epoch 53, iter 3900, loss: 2.592886, top_1: 0.595430, top_k: 0.811953, samples/s: 777.526 1613305646.432899
train: epoch 53, iter 4000, loss: 2.639349, top_1: 0.594063, top_k: 0.813594, samples/s: 780.215 1613305679.2444167
train: epoch 53, iter 4100, loss: 2.761733, top_1: 0.590039, top_k: 0.811406, samples/s: 780.364 1613305712.0496697
train: epoch 53, iter 4200, loss: 2.691881, top_1: 0.595781, top_k: 0.815508, samples/s: 779.142 1613305744.9062862
train: epoch 53, iter 4300, loss: 2.745683, top_1: 0.596914, top_k: 0.816367, samples/s: 780.915 1613305777.6883771
train: epoch 53, iter 4400, loss: 2.728667, top_1: 0.595742, top_k: 0.811523, samples/s: 780.689 1613305810.479953
train: epoch 53, iter 4500, loss: 2.687726, top_1: 0.598164, top_k: 0.816562, samples/s: 782.388 1613305843.2002497
train: epoch 53, iter 4600, loss: 2.920716, top_1: 0.590938, top_k: 0.808398, samples/s: 779.763 1613305876.0306542
train: epoch 53, iter 4700, loss: 2.660402, top_1: 0.590508, top_k: 0.811094, samples/s: 778.138 1613305908.9296944
train: epoch 53, iter 4800, loss: 2.706342, top_1: 0.592539, top_k: 0.813906, samples/s: 779.550 1613305941.769207
train: epoch 53, iter 4900, loss: 2.657757, top_1: 0.595508, top_k: 0.812617, samples/s: 780.636 1613305974.562959
train: epoch 53, iter 5000, loss: 2.409803, top_1: 0.595430, top_k: 0.814766, samples/s: 781.188 1613306007.333552
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_53.
validation: epoch 53, iter 195, top_1: 0.645533, top_k: 0.867448, samples/s: 2368.349 1613306029.393873
train: epoch 54, iter 100, loss: 2.430377, top_1: 0.614766, top_k: 0.828047, samples/s: 804.559 1613306082.1132102
train: epoch 54, iter 200, loss: 2.545678, top_1: 0.602187, top_k: 0.821797, samples/s: 798.690 1613306114.1658754
train: epoch 54, iter 300, loss: 2.678560, top_1: 0.605469, top_k: 0.819375, samples/s: 783.088 1613306146.8567743
train: epoch 54, iter 400, loss: 2.698381, top_1: 0.601016, top_k: 0.818828, samples/s: 778.443 1613306179.742933
train: epoch 54, iter 500, loss: 2.810393, top_1: 0.600938, top_k: 0.818906, samples/s: 776.299 1613306212.7198234
train: epoch 54, iter 600, loss: 2.674337, top_1: 0.609336, top_k: 0.821914, samples/s: 777.694 1613306245.6377149
train: epoch 54, iter 700, loss: 2.646331, top_1: 0.603711, top_k: 0.817734, samples/s: 776.358 1613306278.6121435
train: epoch 54, iter 800, loss: 2.618525, top_1: 0.600625, top_k: 0.819648, samples/s: 779.654 1613306311.4472444
train: epoch 54, iter 900, loss: 2.677444, top_1: 0.600664, top_k: 0.816211, samples/s: 779.912 1613306344.271439
train: epoch 54, iter 1000, loss: 2.697891, top_1: 0.597695, top_k: 0.816992, samples/s: 778.483 1613306377.1559486
train: epoch 54, iter 1100, loss: 2.765891, top_1: 0.599141, top_k: 0.814453, samples/s: 780.417 1613306409.958932
train: epoch 54, iter 1200, loss: 2.695778, top_1: 0.600039, top_k: 0.811836, samples/s: 776.879 1613306442.911276
train: epoch 54, iter 1300, loss: 2.595300, top_1: 0.595313, top_k: 0.815156, samples/s: 781.601 1613306475.6645749
train: epoch 54, iter 1400, loss: 2.548139, top_1: 0.604297, top_k: 0.821445, samples/s: 778.584 1613306508.5446873
train: epoch 54, iter 1500, loss: 2.732285, top_1: 0.602109, top_k: 0.820898, samples/s: 779.271 1613306541.3959048
train: epoch 54, iter 1600, loss: 2.641386, top_1: 0.599453, top_k: 0.816680, samples/s: 778.792 1613306574.2673779
train: epoch 54, iter 1700, loss: 2.617630, top_1: 0.597383, top_k: 0.817891, samples/s: 780.824 1613306607.0532234
train: epoch 54, iter 1800, loss: 2.676607, top_1: 0.596484, top_k: 0.817148, samples/s: 781.050 1613306639.8296392
train: epoch 54, iter 1900, loss: 2.716484, top_1: 0.597031, top_k: 0.815977, samples/s: 778.985 1613306672.6929216
train: epoch 54, iter 2000, loss: 2.651450, top_1: 0.602344, top_k: 0.819336, samples/s: 781.188 1613306705.4634979
train: epoch 54, iter 2100, loss: 2.696456, top_1: 0.607695, top_k: 0.825625, samples/s: 782.116 1613306738.1952739
train: epoch 54, iter 2200, loss: 2.743119, top_1: 0.600625, top_k: 0.817656, samples/s: 777.699 1613306771.1128354
train: epoch 54, iter 2300, loss: 2.757785, top_1: 0.596289, top_k: 0.813164, samples/s: 779.000 1613306803.9755347
train: epoch 54, iter 2400, loss: 2.637066, top_1: 0.600078, top_k: 0.818359, samples/s: 778.642 1613306836.8532963
train: epoch 54, iter 2500, loss: 2.688311, top_1: 0.594414, top_k: 0.814688, samples/s: 778.724 1613306869.7275245
train: epoch 54, iter 2600, loss: 2.757359, top_1: 0.593750, top_k: 0.813281, samples/s: 779.361 1613306902.5750208
train: epoch 54, iter 2700, loss: 2.694876, top_1: 0.593789, top_k: 0.814297, samples/s: 779.048 1613306935.435522
train: epoch 54, iter 2800, loss: 2.785083, top_1: 0.601992, top_k: 0.817539, samples/s: 777.483 1613306968.362293
train: epoch 54, iter 2900, loss: 2.531018, top_1: 0.592500, top_k: 0.813984, samples/s: 779.712 1613307001.194932
train: epoch 54, iter 3000, loss: 2.459327, top_1: 0.592461, top_k: 0.814453, samples/s: 777.860 1613307034.1058204
train: epoch 54, iter 3100, loss: 2.591463, top_1: 0.592070, top_k: 0.811602, samples/s: 781.200 1613307066.8758483
train: epoch 54, iter 3200, loss: 2.677738, top_1: 0.591328, top_k: 0.810547, samples/s: 780.478 1613307099.676353
train: epoch 54, iter 3300, loss: 2.618506, top_1: 0.595977, top_k: 0.812187, samples/s: 777.302 1613307132.6106977
train: epoch 54, iter 3400, loss: 2.583792, top_1: 0.598398, top_k: 0.816562, samples/s: 778.524 1613307165.4934826
train: epoch 54, iter 3500, loss: 2.841787, top_1: 0.600039, top_k: 0.816133, samples/s: 779.811 1613307198.3219018
train: epoch 54, iter 3600, loss: 2.713796, top_1: 0.598477, top_k: 0.815547, samples/s: 781.333 1613307231.0864913
train: epoch 54, iter 3700, loss: 2.559277, top_1: 0.591523, top_k: 0.815664, samples/s: 777.602 1613307264.008116
train: epoch 54, iter 3800, loss: 2.749479, top_1: 0.600430, top_k: 0.818672, samples/s: 780.138 1613307296.8228955
train: epoch 54, iter 3900, loss: 2.837243, top_1: 0.597734, top_k: 0.816992, samples/s: 779.237 1613307329.6755533
train: epoch 54, iter 4000, loss: 2.594724, top_1: 0.594570, top_k: 0.812070, samples/s: 779.157 1613307362.531547
train: epoch 54, iter 4100, loss: 2.746541, top_1: 0.598789, top_k: 0.814570, samples/s: 780.326 1613307395.3383517
train: epoch 54, iter 4200, loss: 2.641952, top_1: 0.595430, top_k: 0.814766, samples/s: 776.944 1613307428.2879784
train: epoch 54, iter 4300, loss: 2.784495, top_1: 0.597461, top_k: 0.816016, samples/s: 779.356 1613307461.1355553
train: epoch 54, iter 4400, loss: 2.676666, top_1: 0.591328, top_k: 0.814883, samples/s: 778.681 1613307494.0117233
train: epoch 54, iter 4500, loss: 2.792728, top_1: 0.593359, top_k: 0.814531, samples/s: 778.247 1613307526.9060986
train: epoch 54, iter 4600, loss: 2.660792, top_1: 0.595664, top_k: 0.818281, samples/s: 781.621 1613307559.6585183
train: epoch 54, iter 4700, loss: 2.536756, top_1: 0.597734, top_k: 0.814531, samples/s: 781.422 1613307592.4193482
train: epoch 54, iter 4800, loss: 2.538771, top_1: 0.589453, top_k: 0.809219, samples/s: 777.497 1613307625.3455727
train: epoch 54, iter 4900, loss: 2.659503, top_1: 0.596016, top_k: 0.814063, samples/s: 780.426 1613307658.1481628
train: epoch 54, iter 5000, loss: 2.706890, top_1: 0.592500, top_k: 0.810391, samples/s: 782.582 1613307690.8603063
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_54.
validation: epoch 54, iter 195, top_1: 0.652544, top_k: 0.868970, samples/s: 2350.630 1613307713.0683281
train: epoch 55, iter 100, loss: 2.748848, top_1: 0.606914, top_k: 0.822930, samples/s: 802.087 1613307765.9949253
train: epoch 55, iter 200, loss: 2.866389, top_1: 0.604297, top_k: 0.820937, samples/s: 798.573 1613307798.0520449
train: epoch 55, iter 300, loss: 2.627981, top_1: 0.604727, top_k: 0.821172, samples/s: 779.636 1613307830.8879492
train: epoch 55, iter 400, loss: 2.474779, top_1: 0.606289, top_k: 0.826094, samples/s: 777.643 1613307863.8079848
train: epoch 55, iter 500, loss: 2.638481, top_1: 0.614883, top_k: 0.823828, samples/s: 780.645 1613307896.6013536
train: epoch 55, iter 600, loss: 2.686987, top_1: 0.610938, top_k: 0.824844, samples/s: 777.320 1613307929.5350635
train: epoch 55, iter 700, loss: 2.738321, top_1: 0.609102, top_k: 0.825703, samples/s: 778.890 1613307962.4023852
train: epoch 55, iter 800, loss: 2.646861, top_1: 0.597031, top_k: 0.814883, samples/s: 776.665 1613307995.3637106
train: epoch 55, iter 900, loss: 2.678958, top_1: 0.606758, top_k: 0.820586, samples/s: 779.708 1613308028.1965783
train: epoch 55, iter 1000, loss: 2.563013, top_1: 0.598789, top_k: 0.817813, samples/s: 778.952 1613308061.0611644
train: epoch 55, iter 1100, loss: 2.627766, top_1: 0.600078, top_k: 0.817305, samples/s: 780.338 1613308093.8675148
train: epoch 55, iter 1200, loss: 2.795705, top_1: 0.601797, top_k: 0.818242, samples/s: 778.080 1613308126.769018
train: epoch 55, iter 1300, loss: 2.572335, top_1: 0.599727, top_k: 0.818398, samples/s: 780.163 1613308159.582617
train: epoch 55, iter 1400, loss: 2.571943, top_1: 0.601172, top_k: 0.819023, samples/s: 778.368 1613308192.4719353
train: epoch 55, iter 1500, loss: 2.473543, top_1: 0.603555, top_k: 0.822266, samples/s: 777.640 1613308225.392105
train: epoch 55, iter 1600, loss: 2.703806, top_1: 0.593437, top_k: 0.814570, samples/s: 778.370 1613308258.2813263
train: epoch 55, iter 1700, loss: 2.826085, top_1: 0.594023, top_k: 0.813672, samples/s: 780.842 1613308291.0664914
train: epoch 55, iter 1800, loss: 2.509666, top_1: 0.602148, top_k: 0.813047, samples/s: 776.648 1613308324.0286415
train: epoch 55, iter 1900, loss: 2.482450, top_1: 0.599258, top_k: 0.820391, samples/s: 779.089 1613308356.8875346
train: epoch 55, iter 2000, loss: 2.622334, top_1: 0.602812, top_k: 0.818516, samples/s: 779.565 1613308389.7262855
train: epoch 55, iter 2100, loss: 2.634859, top_1: 0.602422, top_k: 0.818242, samples/s: 781.388 1613308422.4885335
train: epoch 55, iter 2200, loss: 2.603203, top_1: 0.605703, top_k: 0.823555, samples/s: 779.497 1613308455.3302164
train: epoch 55, iter 2300, loss: 2.534229, top_1: 0.598086, top_k: 0.817969, samples/s: 780.788 1613308488.117557
train: epoch 55, iter 2400, loss: 2.597354, top_1: 0.598594, top_k: 0.817227, samples/s: 781.204 1613308520.8875122
train: epoch 55, iter 2500, loss: 2.694364, top_1: 0.597148, top_k: 0.816914, samples/s: 779.800 1613308553.7164388
train: epoch 55, iter 2600, loss: 2.587441, top_1: 0.601719, top_k: 0.817813, samples/s: 782.086 1613308586.4495292
train: epoch 55, iter 2700, loss: 2.748945, top_1: 0.594492, top_k: 0.814922, samples/s: 779.173 1613308619.3047721
train: epoch 55, iter 2800, loss: 2.747904, top_1: 0.597969, top_k: 0.814180, samples/s: 781.655 1613308652.0558484
train: epoch 55, iter 2900, loss: 2.684818, top_1: 0.603008, top_k: 0.818398, samples/s: 779.859 1613308684.8822615
train: epoch 55, iter 3000, loss: 2.480879, top_1: 0.602070, top_k: 0.820156, samples/s: 782.411 1613308717.6015751
train: epoch 55, iter 3100, loss: 2.657791, top_1: 0.602305, top_k: 0.817813, samples/s: 779.242 1613308750.4541101
train: epoch 55, iter 3200, loss: 2.660813, top_1: 0.599453, top_k: 0.813359, samples/s: 782.991 1613308783.1493459
train: epoch 55, iter 3300, loss: 2.601848, top_1: 0.595156, top_k: 0.812617, samples/s: 780.799 1613308815.9361384
train: epoch 55, iter 3400, loss: 2.643098, top_1: 0.595703, top_k: 0.811875, samples/s: 782.255 1613308848.6620502
train: epoch 55, iter 3500, loss: 2.626288, top_1: 0.602266, top_k: 0.817344, samples/s: 780.441 1613308881.4640238
train: epoch 55, iter 3600, loss: 2.697176, top_1: 0.602539, top_k: 0.815937, samples/s: 782.936 1613308914.1614337
train: epoch 55, iter 3700, loss: 2.582753, top_1: 0.598711, top_k: 0.818125, samples/s: 783.678 1613308946.827932
train: epoch 55, iter 3800, loss: 2.774862, top_1: 0.599297, top_k: 0.819297, samples/s: 783.866 1613308979.4865828
train: epoch 55, iter 3900, loss: 2.619012, top_1: 0.591328, top_k: 0.813320, samples/s: 781.561 1613309012.2416177
train: epoch 55, iter 4000, loss: 2.514734, top_1: 0.599492, top_k: 0.815039, samples/s: 783.088 1613309044.9327145
train: epoch 55, iter 4100, loss: 2.582641, top_1: 0.596523, top_k: 0.814531, samples/s: 783.503 1613309077.6065218
train: epoch 55, iter 4200, loss: 2.701765, top_1: 0.598477, top_k: 0.817305, samples/s: 782.917 1613309110.304688
train: epoch 55, iter 4300, loss: 2.585220, top_1: 0.595234, top_k: 0.815508, samples/s: 781.314 1613309143.070033
train: epoch 55, iter 4400, loss: 2.695017, top_1: 0.598555, top_k: 0.816289, samples/s: 785.857 1613309175.645917
train: epoch 55, iter 4500, loss: 2.835419, top_1: 0.595430, top_k: 0.815859, samples/s: 783.527 1613309208.3186164
train: epoch 55, iter 4600, loss: 2.765710, top_1: 0.595078, top_k: 0.815156, samples/s: 786.041 1613309240.8868818
train: epoch 55, iter 4700, loss: 2.512661, top_1: 0.596094, top_k: 0.815547, samples/s: 783.876 1613309273.5450895
train: epoch 55, iter 4800, loss: 2.793684, top_1: 0.597734, top_k: 0.816172, samples/s: 782.531 1613309306.2595153
train: epoch 55, iter 4900, loss: 2.629165, top_1: 0.595039, top_k: 0.817695, samples/s: 785.994 1613309338.829668
train: epoch 55, iter 5000, loss: 2.531782, top_1: 0.601641, top_k: 0.820391, samples/s: 782.250 1613309371.5558403
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_55.
validation: epoch 55, iter 195, top_1: 0.652764, top_k: 0.871294, samples/s: 2373.177 1613309393.5644858
train: epoch 56, iter 100, loss: 2.571226, top_1: 0.610195, top_k: 0.826016, samples/s: 804.163 1613309446.5325377
train: epoch 56, iter 200, loss: 2.539874, top_1: 0.608867, top_k: 0.825156, samples/s: 801.520 1613309478.4717853
train: epoch 56, iter 300, loss: 2.823152, top_1: 0.605469, top_k: 0.822461, samples/s: 785.818 1613309511.0494082
train: epoch 56, iter 400, loss: 2.651649, top_1: 0.608828, top_k: 0.824492, samples/s: 784.570 1613309543.6787052
train: epoch 56, iter 500, loss: 2.463002, top_1: 0.610781, top_k: 0.823750, samples/s: 780.434 1613309576.480961
train: epoch 56, iter 600, loss: 2.660496, top_1: 0.609688, top_k: 0.825352, samples/s: 784.193 1613309609.1260526
train: epoch 56, iter 700, loss: 2.851320, top_1: 0.612734, top_k: 0.827500, samples/s: 779.065 1613309641.985884
train: epoch 56, iter 800, loss: 2.740453, top_1: 0.601914, top_k: 0.818633, samples/s: 787.456 1613309674.4956686
train: epoch 56, iter 900, loss: 2.627755, top_1: 0.602656, top_k: 0.818281, samples/s: 781.883 1613309707.2371087
train: epoch 56, iter 1000, loss: 2.631347, top_1: 0.605195, top_k: 0.820234, samples/s: 785.919 1613309739.8103926
train: epoch 56, iter 1100, loss: 2.713648, top_1: 0.606055, top_k: 0.824844, samples/s: 779.830 1613309772.6381195
train: epoch 56, iter 1200, loss: 2.440183, top_1: 0.606914, top_k: 0.817617, samples/s: 784.832 1613309805.2566097
train: epoch 56, iter 1300, loss: 2.461974, top_1: 0.606602, top_k: 0.820977, samples/s: 782.850 1613309837.9575648
train: epoch 56, iter 1400, loss: 2.529665, top_1: 0.601016, top_k: 0.821445, samples/s: 782.068 1613309870.691396
train: epoch 56, iter 1500, loss: 2.822136, top_1: 0.601250, top_k: 0.820117, samples/s: 782.019 1613309903.4271538
train: epoch 56, iter 1600, loss: 2.871943, top_1: 0.603008, top_k: 0.821055, samples/s: 783.672 1613309936.0938888
train: epoch 56, iter 1700, loss: 2.503386, top_1: 0.600625, top_k: 0.818711, samples/s: 783.738 1613309968.7578816
train: epoch 56, iter 1800, loss: 2.844037, top_1: 0.596172, top_k: 0.815625, samples/s: 781.923 1613310001.49759
train: epoch 56, iter 1900, loss: 2.653119, top_1: 0.598281, top_k: 0.816641, samples/s: 783.856 1613310034.1567216
train: epoch 56, iter 2000, loss: 2.433594, top_1: 0.602734, top_k: 0.817969, samples/s: 783.185 1613310066.8438346
train: epoch 56, iter 2100, loss: 2.691430, top_1: 0.596367, top_k: 0.811758, samples/s: 779.933 1613310099.667191
train: epoch 56, iter 2200, loss: 2.989228, top_1: 0.595078, top_k: 0.817422, samples/s: 785.470 1613310132.2590914
train: epoch 56, iter 2300, loss: 2.628863, top_1: 0.599023, top_k: 0.817773, samples/s: 779.336 1613310165.1075478
train: epoch 56, iter 2400, loss: 2.728552, top_1: 0.603164, top_k: 0.822383, samples/s: 780.527 1613310197.9058986
train: epoch 56, iter 2500, loss: 2.715838, top_1: 0.601914, top_k: 0.817773, samples/s: 783.975 1613310230.5600088
train: epoch 56, iter 2600, loss: 2.661982, top_1: 0.598398, top_k: 0.819219, samples/s: 781.105 1613310263.3342338
train: epoch 56, iter 2700, loss: 2.484818, top_1: 0.601211, top_k: 0.818477, samples/s: 782.667 1613310296.0427997
train: epoch 56, iter 2800, loss: 3.273679, top_1: 0.558164, top_k: 0.778750, samples/s: 779.397 1613310328.8886821
train: epoch 56, iter 2900, loss: 2.953958, top_1: 0.519258, top_k: 0.753164, samples/s: 782.247 1613310361.614968
train: epoch 56, iter 3000, loss: 2.745687, top_1: 0.558008, top_k: 0.783164, samples/s: 782.398 1613310394.3348656
train: epoch 56, iter 3100, loss: 2.858886, top_1: 0.572539, top_k: 0.795078, samples/s: 780.349 1613310427.1406448
train: epoch 56, iter 3200, loss: 2.700687, top_1: 0.575117, top_k: 0.799492, samples/s: 782.827 1613310459.842702
train: epoch 56, iter 3300, loss: 2.742504, top_1: 0.576680, top_k: 0.803477, samples/s: 781.576 1613310492.597065
train: epoch 56, iter 3400, loss: 2.816822, top_1: 0.582031, top_k: 0.803203, samples/s: 781.875 1613310525.3388448
train: epoch 56, iter 3500, loss: 2.832952, top_1: 0.583477, top_k: 0.804688, samples/s: 781.809 1613310558.0834925
train: epoch 56, iter 3600, loss: 2.753706, top_1: 0.586602, top_k: 0.807617, samples/s: 783.581 1613310590.7539616
train: epoch 56, iter 3700, loss: 2.817091, top_1: 0.586406, top_k: 0.802891, samples/s: 780.210 1613310623.5656312
train: epoch 56, iter 3800, loss: 2.580696, top_1: 0.585039, top_k: 0.809609, samples/s: 782.412 1613310656.2849412
train: epoch 56, iter 3900, loss: 2.744446, top_1: 0.587812, top_k: 0.806367, samples/s: 782.585 1613310688.997145
train: epoch 56, iter 4000, loss: 2.820880, top_1: 0.581719, top_k: 0.805742, samples/s: 782.024 1613310721.7326589
train: epoch 56, iter 4100, loss: 2.673696, top_1: 0.589805, top_k: 0.810391, samples/s: 781.696 1613310754.481937
train: epoch 56, iter 4200, loss: 2.390719, top_1: 0.590859, top_k: 0.809727, samples/s: 784.666 1613310787.1073527
train: epoch 56, iter 4300, loss: 2.596366, top_1: 0.587109, top_k: 0.807148, samples/s: 783.436 1613310819.7838595
train: epoch 56, iter 4400, loss: 2.766832, top_1: 0.588320, top_k: 0.813047, samples/s: 783.242 1613310852.46855
train: epoch 56, iter 4500, loss: 2.693733, top_1: 0.590156, top_k: 0.805742, samples/s: 783.160 1613310885.1565804
train: epoch 56, iter 4600, loss: 2.706269, top_1: 0.591250, top_k: 0.810547, samples/s: 779.298 1613310918.006739
train: epoch 56, iter 4700, loss: 2.581175, top_1: 0.591992, top_k: 0.811680, samples/s: 781.976 1613310950.7442849
train: epoch 56, iter 4800, loss: 2.874004, top_1: 0.588984, top_k: 0.809922, samples/s: 781.720 1613310983.4926412
train: epoch 56, iter 4900, loss: 2.710136, top_1: 0.594219, top_k: 0.810898, samples/s: 781.940 1613311016.2317088
train: epoch 56, iter 5000, loss: 2.738420, top_1: 0.588906, top_k: 0.810625, samples/s: 781.452 1613311048.991268
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_56.
validation: epoch 56, iter 195, top_1: 0.647256, top_k: 0.867428, samples/s: 2305.181 1613311071.6445827
train: epoch 57, iter 100, loss: 2.598978, top_1: 0.608320, top_k: 0.824844, samples/s: 804.419 1613311123.970513
train: epoch 57, iter 200, loss: 2.768799, top_1: 0.607773, top_k: 0.822148, samples/s: 799.886 1613311155.9749277
train: epoch 57, iter 300, loss: 2.699747, top_1: 0.599258, top_k: 0.815039, samples/s: 782.369 1613311188.6961198
train: epoch 57, iter 400, loss: 2.778152, top_1: 0.602227, top_k: 0.818945, samples/s: 781.314 1613311221.4615085
train: epoch 57, iter 500, loss: 2.604338, top_1: 0.605664, top_k: 0.818320, samples/s: 783.856 1613311254.1204393
train: epoch 57, iter 600, loss: 2.690728, top_1: 0.606328, top_k: 0.821758, samples/s: 780.282 1613311286.9291992
train: epoch 57, iter 700, loss: 2.604023, top_1: 0.605508, top_k: 0.821680, samples/s: 780.799 1613311319.7161033
train: epoch 57, iter 800, loss: 2.589835, top_1: 0.604844, top_k: 0.820039, samples/s: 783.785 1613311352.3781185
train: epoch 57, iter 900, loss: 2.747347, top_1: 0.600938, top_k: 0.815352, samples/s: 779.035 1613311385.2392519
train: epoch 57, iter 1000, loss: 2.559007, top_1: 0.605508, top_k: 0.822695, samples/s: 780.734 1613311418.0289278
train: epoch 57, iter 1100, loss: 2.687457, top_1: 0.601484, top_k: 0.818086, samples/s: 783.168 1613311450.7167087
train: epoch 57, iter 1200, loss: 2.671298, top_1: 0.599727, top_k: 0.817109, samples/s: 783.173 1613311483.404134
train: epoch 57, iter 1300, loss: 2.685197, top_1: 0.598906, top_k: 0.813477, samples/s: 779.623 1613311516.2405586
train: epoch 57, iter 1400, loss: 2.811958, top_1: 0.606875, top_k: 0.818281, samples/s: 780.668 1613311549.0330558
train: epoch 57, iter 1500, loss: 2.673696, top_1: 0.601211, top_k: 0.813984, samples/s: 783.124 1613311581.7225664
train: epoch 57, iter 1600, loss: 2.792252, top_1: 0.610938, top_k: 0.823477, samples/s: 782.501 1613311614.4382753
train: epoch 57, iter 1700, loss: 2.725110, top_1: 0.598203, top_k: 0.817344, samples/s: 783.628 1613311647.1068447
train: epoch 57, iter 1800, loss: 2.576431, top_1: 0.596914, top_k: 0.817578, samples/s: 781.698 1613311679.8564346
train: epoch 57, iter 1900, loss: 2.817059, top_1: 0.604414, top_k: 0.818984, samples/s: 781.431 1613311712.6164584
train: epoch 57, iter 2000, loss: 2.461488, top_1: 0.593203, top_k: 0.814805, samples/s: 783.030 1613311745.3102682
train: epoch 57, iter 2100, loss: 2.754063, top_1: 0.599727, top_k: 0.818594, samples/s: 778.419 1613311778.19713
train: epoch 57, iter 2200, loss: 2.678510, top_1: 0.601875, top_k: 0.815703, samples/s: 782.418 1613311810.9163043
train: epoch 57, iter 2300, loss: 2.823771, top_1: 0.600156, top_k: 0.819805, samples/s: 782.657 1613311843.6253662
train: epoch 57, iter 2400, loss: 2.584259, top_1: 0.599531, top_k: 0.821172, samples/s: 782.721 1613311876.3316963
train: epoch 57, iter 2500, loss: 2.739239, top_1: 0.594844, top_k: 0.813242, samples/s: 783.418 1613311909.0090795
train: epoch 57, iter 2600, loss: 2.519666, top_1: 0.603398, top_k: 0.816875, samples/s: 783.592 1613311941.6795697
train: epoch 57, iter 2700, loss: 2.617214, top_1: 0.600898, top_k: 0.818359, samples/s: 781.831 1613311974.4227724
train: epoch 57, iter 2800, loss: 2.692282, top_1: 0.598437, top_k: 0.815117, samples/s: 783.084 1613312007.114569
train: epoch 57, iter 2900, loss: 2.580037, top_1: 0.599688, top_k: 0.817344, samples/s: 782.370 1613312039.835183
train: epoch 57, iter 3000, loss: 2.539229, top_1: 0.599492, top_k: 0.815430, samples/s: 785.244 1613312072.4364414
train: epoch 57, iter 3100, loss: 2.847054, top_1: 0.602227, top_k: 0.817578, samples/s: 784.029 1613312105.0883222
train: epoch 57, iter 3200, loss: 2.784105, top_1: 0.594414, top_k: 0.808438, samples/s: 783.058 1613312137.780749
train: epoch 57, iter 3300, loss: 2.881076, top_1: 0.599023, top_k: 0.815391, samples/s: 783.645 1613312170.4484808
train: epoch 57, iter 3400, loss: 2.752655, top_1: 0.595781, top_k: 0.815859, samples/s: 783.685 1613312203.114728
train: epoch 57, iter 3500, loss: 2.659236, top_1: 0.599141, top_k: 0.818242, samples/s: 782.349 1613312235.8367124
train: epoch 57, iter 3600, loss: 2.547416, top_1: 0.599063, top_k: 0.817773, samples/s: 782.737 1613312268.5424616
train: epoch 57, iter 3700, loss: 2.657195, top_1: 0.598008, top_k: 0.820781, samples/s: 784.581 1613312301.1712446
train: epoch 57, iter 3800, loss: 2.698951, top_1: 0.600547, top_k: 0.817383, samples/s: 783.979 1613312333.8253133
train: epoch 57, iter 3900, loss: 2.798840, top_1: 0.595469, top_k: 0.817070, samples/s: 783.365 1613312366.50472
train: epoch 57, iter 4000, loss: 2.652337, top_1: 0.594531, top_k: 0.815078, samples/s: 784.806 1613312399.124244
train: epoch 57, iter 4100, loss: 2.692849, top_1: 0.599492, top_k: 0.815156, samples/s: 784.966 1613312431.737252
train: epoch 57, iter 4200, loss: 2.662896, top_1: 0.596289, top_k: 0.812187, samples/s: 782.439 1613312464.4554276
train: epoch 57, iter 4300, loss: 2.492856, top_1: 0.593711, top_k: 0.814258, samples/s: 784.322 1613312497.0950959
train: epoch 57, iter 4400, loss: 2.577259, top_1: 0.599414, top_k: 0.816211, samples/s: 783.500 1613312529.7689567
train: epoch 57, iter 4500, loss: 2.688289, top_1: 0.601367, top_k: 0.816133, samples/s: 782.602 1613312562.4803255
train: epoch 57, iter 4600, loss: 2.637172, top_1: 0.601484, top_k: 0.814023, samples/s: 783.474 1613312595.155303
train: epoch 57, iter 4700, loss: 2.744647, top_1: 0.602148, top_k: 0.818164, samples/s: 783.953 1613312627.8103342
train: epoch 57, iter 4800, loss: 2.561357, top_1: 0.598516, top_k: 0.815273, samples/s: 783.713 1613312660.4753845
train: epoch 57, iter 4900, loss: 2.750193, top_1: 0.592266, top_k: 0.813828, samples/s: 783.465 1613312693.1507149
train: epoch 57, iter 5000, loss: 2.505631, top_1: 0.601250, top_k: 0.822695, samples/s: 784.093 1613312725.7999206
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_57.
validation: epoch 57, iter 195, top_1: 0.646995, top_k: 0.866386, samples/s: 2345.771 1613312748.0556588
train: epoch 58, iter 100, loss: 2.631944, top_1: 0.617383, top_k: 0.830273, samples/s: 805.218 1613312800.5147717
train: epoch 58, iter 200, loss: 2.435876, top_1: 0.616523, top_k: 0.826875, samples/s: 800.498 1613312832.4948833
train: epoch 58, iter 300, loss: 2.505146, top_1: 0.610469, top_k: 0.825625, samples/s: 786.713 1613312865.035286
train: epoch 58, iter 400, loss: 2.807956, top_1: 0.604648, top_k: 0.818906, samples/s: 778.776 1613312897.907531
train: epoch 58, iter 500, loss: 2.812209, top_1: 0.603711, top_k: 0.823555, samples/s: 782.706 1613312930.6144652
train: epoch 58, iter 600, loss: 2.653369, top_1: 0.608164, top_k: 0.823789, samples/s: 783.623 1613312963.2832696
train: epoch 58, iter 700, loss: 2.581786, top_1: 0.605859, top_k: 0.821016, samples/s: 783.718 1613312995.9480803
train: epoch 58, iter 800, loss: 2.400984, top_1: 0.608242, top_k: 0.824102, samples/s: 783.791 1613313028.6097982
train: epoch 58, iter 900, loss: 2.741256, top_1: 0.605781, top_k: 0.821641, samples/s: 782.516 1613313061.324839
train: epoch 58, iter 1000, loss: 2.621047, top_1: 0.607344, top_k: 0.822578, samples/s: 781.970 1613313094.0627136
train: epoch 58, iter 1100, loss: 2.589777, top_1: 0.609844, top_k: 0.822812, samples/s: 784.564 1613313126.6922047
train: epoch 58, iter 1200, loss: 2.735748, top_1: 0.602812, top_k: 0.818789, samples/s: 780.315 1613313159.4995637
train: epoch 58, iter 1300, loss: 2.634568, top_1: 0.601836, top_k: 0.818789, samples/s: 784.250 1613313192.14224
train: epoch 58, iter 1400, loss: 2.692794, top_1: 0.608516, top_k: 0.821367, samples/s: 782.404 1613313224.8618195
train: epoch 58, iter 1500, loss: 2.688497, top_1: 0.605703, top_k: 0.819961, samples/s: 785.103 1613313257.4690552
train: epoch 58, iter 1600, loss: 2.802685, top_1: 0.600938, top_k: 0.819922, samples/s: 782.146 1613313290.1994529
train: epoch 58, iter 1700, loss: 2.705738, top_1: 0.599531, top_k: 0.820117, samples/s: 784.215 1613313322.8436553
train: epoch 58, iter 1800, loss: 2.714181, top_1: 0.601914, top_k: 0.820625, samples/s: 783.806 1613313355.5047712
train: epoch 58, iter 1900, loss: 2.522646, top_1: 0.600781, top_k: 0.818203, samples/s: 785.748 1613313388.0851617
train: epoch 58, iter 2000, loss: 2.828537, top_1: 0.607031, top_k: 0.820820, samples/s: 781.519 1613313420.8419254
train: epoch 58, iter 2100, loss: 2.728131, top_1: 0.600898, top_k: 0.817813, samples/s: 784.561 1613313453.4716747
train: epoch 58, iter 2200, loss: 2.615989, top_1: 0.606211, top_k: 0.822070, samples/s: 780.188 1613313486.2841594
train: epoch 58, iter 2300, loss: 2.701051, top_1: 0.601094, top_k: 0.817461, samples/s: 783.442 1613313518.9605098
train: epoch 58, iter 2400, loss: 2.645513, top_1: 0.602812, top_k: 0.817344, samples/s: 782.852 1613313551.6614635
train: epoch 58, iter 2500, loss: 2.522511, top_1: 0.601094, top_k: 0.816602, samples/s: 783.117 1613313584.351351
train: epoch 58, iter 2600, loss: 2.760990, top_1: 0.599141, top_k: 0.815820, samples/s: 785.006 1613313616.9626145
train: epoch 58, iter 2700, loss: 2.785228, top_1: 0.603555, top_k: 0.819336, samples/s: 783.790 1613313649.624424
train: epoch 58, iter 2800, loss: 2.667439, top_1: 0.606484, top_k: 0.820391, samples/s: 784.358 1613313682.2625713
train: epoch 58, iter 2900, loss: 2.676655, top_1: 0.607812, top_k: 0.821797, samples/s: 783.702 1613313714.9280553
train: epoch 58, iter 3000, loss: 2.789450, top_1: 0.598555, top_k: 0.818789, samples/s: 780.929 1613313747.7094724
train: epoch 58, iter 3100, loss: 2.692818, top_1: 0.599336, top_k: 0.820898, samples/s: 783.774 1613313780.371997
train: epoch 58, iter 3200, loss: 2.694842, top_1: 0.597266, top_k: 0.816289, samples/s: 782.443 1613313813.0900323
train: epoch 58, iter 3300, loss: 2.974411, top_1: 0.597461, top_k: 0.816914, samples/s: 783.295 1613313845.7724767
train: epoch 58, iter 3400, loss: 2.679363, top_1: 0.599102, top_k: 0.816602, samples/s: 784.170 1613313878.4184089
train: epoch 58, iter 3500, loss: 2.752143, top_1: 0.598320, top_k: 0.816953, samples/s: 784.185 1613313911.0637548
train: epoch 58, iter 3600, loss: 2.564868, top_1: 0.601094, top_k: 0.814727, samples/s: 784.246 1613313943.7065787
train: epoch 58, iter 3700, loss: 2.689327, top_1: 0.604102, top_k: 0.818438, samples/s: 785.078 1613313976.3148236
train: epoch 58, iter 3800, loss: 2.614390, top_1: 0.598086, top_k: 0.814727, samples/s: 785.304 1613314008.913632
train: epoch 58, iter 3900, loss: 2.613611, top_1: 0.600898, top_k: 0.814219, samples/s: 782.111 1613314041.6455734
train: epoch 58, iter 4000, loss: 2.780540, top_1: 0.600430, top_k: 0.820430, samples/s: 785.346 1613314074.2426875
train: epoch 58, iter 4100, loss: 2.649608, top_1: 0.602109, top_k: 0.817578, samples/s: 784.123 1613314106.890576
train: epoch 58, iter 4200, loss: 2.735569, top_1: 0.596680, top_k: 0.817148, samples/s: 783.139 1613314139.5795746
train: epoch 58, iter 4300, loss: 2.655856, top_1: 0.598867, top_k: 0.820117, samples/s: 785.383 1613314172.1750984
train: epoch 58, iter 4400, loss: 2.754524, top_1: 0.598984, top_k: 0.815078, samples/s: 783.776 1613314204.8374841
train: epoch 58, iter 4500, loss: 2.864170, top_1: 0.596602, top_k: 0.813750, samples/s: 785.281 1613314237.4373238
train: epoch 58, iter 4600, loss: 2.736458, top_1: 0.600469, top_k: 0.816289, samples/s: 784.263 1613314270.0793974
train: epoch 58, iter 4700, loss: 2.688406, top_1: 0.599844, top_k: 0.818242, samples/s: 784.679 1613314302.7042084
train: epoch 58, iter 4800, loss: 2.532653, top_1: 0.597734, top_k: 0.816523, samples/s: 784.375 1613314335.3416107
train: epoch 58, iter 4900, loss: 2.757566, top_1: 0.594375, top_k: 0.819883, samples/s: 785.145 1613314367.9471593
train: epoch 58, iter 5000, loss: 2.666283, top_1: 0.602930, top_k: 0.820469, samples/s: 784.321 1613314400.5868192
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_58.
validation: epoch 58, iter 195, top_1: 0.659215, top_k: 0.873818, samples/s: 2359.906 1613314422.7079947
train: epoch 59, iter 100, loss: 2.473195, top_1: 0.614609, top_k: 0.826797, samples/s: 803.785 1613314475.4410484
train: epoch 59, iter 200, loss: 2.378177, top_1: 0.605352, top_k: 0.823047, samples/s: 800.944 1613314507.4034326
train: epoch 59, iter 300, loss: 2.462916, top_1: 0.614102, top_k: 0.828125, samples/s: 787.780 1613314539.8997445
train: epoch 59, iter 400, loss: 2.638546, top_1: 0.615469, top_k: 0.828086, samples/s: 783.942 1613314572.5552392
train: epoch 59, iter 500, loss: 2.604144, top_1: 0.609219, top_k: 0.830391, samples/s: 783.713 1613314605.2201397
train: epoch 59, iter 600, loss: 2.455580, top_1: 0.614219, top_k: 0.826367, samples/s: 784.845 1613314637.8380985
train: epoch 59, iter 700, loss: 2.698916, top_1: 0.606133, top_k: 0.824102, samples/s: 784.697 1613314670.4622204
train: epoch 59, iter 800, loss: 2.686147, top_1: 0.602187, top_k: 0.822930, samples/s: 783.152 1613314703.1505418
train: epoch 59, iter 900, loss: 2.847557, top_1: 0.603086, top_k: 0.823359, samples/s: 782.524 1613314735.865162
train: epoch 59, iter 1000, loss: 2.578949, top_1: 0.605234, top_k: 0.821484, samples/s: 782.587 1613314768.5773747
train: epoch 59, iter 1100, loss: 2.662947, top_1: 0.607187, top_k: 0.821797, samples/s: 785.153 1613314801.1824117
train: epoch 59, iter 1200, loss: 2.647606, top_1: 0.606406, top_k: 0.821406, samples/s: 783.252 1613314833.8666503
train: epoch 59, iter 1300, loss: 2.631021, top_1: 0.609648, top_k: 0.825078, samples/s: 781.822 1613314866.610659
train: epoch 59, iter 1400, loss: 2.587248, top_1: 0.606836, top_k: 0.822891, samples/s: 786.722 1613314899.1507218
train: epoch 59, iter 1500, loss: 2.538790, top_1: 0.606250, top_k: 0.821328, samples/s: 783.119 1613314931.840501
train: epoch 59, iter 1600, loss: 2.694158, top_1: 0.604414, top_k: 0.819180, samples/s: 783.004 1613314964.5351121
train: epoch 59, iter 1700, loss: 2.565419, top_1: 0.609453, top_k: 0.820742, samples/s: 786.419 1613314997.0877488
train: epoch 59, iter 1800, loss: 2.607144, top_1: 0.603242, top_k: 0.819883, samples/s: 784.611 1613315029.7153006
train: epoch 59, iter 1900, loss: 2.581325, top_1: 0.604492, top_k: 0.817344, samples/s: 785.161 1613315062.3201056
train: epoch 59, iter 2000, loss: 2.516038, top_1: 0.602734, top_k: 0.819688, samples/s: 784.182 1613315094.9655194
train: epoch 59, iter 2100, loss: 2.762118, top_1: 0.605039, top_k: 0.820352, samples/s: 785.075 1613315127.5739646
train: epoch 59, iter 2200, loss: 2.547498, top_1: 0.601797, top_k: 0.819609, samples/s: 783.379 1613315160.2528512
train: epoch 59, iter 2300, loss: 2.467788, top_1: 0.603086, top_k: 0.821406, samples/s: 785.835 1613315192.8303535
train: epoch 59, iter 2400, loss: 2.464856, top_1: 0.603437, top_k: 0.819922, samples/s: 785.283 1613315225.429416
train: epoch 59, iter 2500, loss: 2.789411, top_1: 0.596367, top_k: 0.814922, samples/s: 784.009 1613315258.0819936
train: epoch 59, iter 2600, loss: 2.633313, top_1: 0.603672, top_k: 0.821289, samples/s: 785.892 1613315290.6564906
train: epoch 59, iter 2700, loss: 2.547266, top_1: 0.600938, top_k: 0.817187, samples/s: 786.476 1613315323.207068
train: epoch 59, iter 2800, loss: 2.625192, top_1: 0.600586, top_k: 0.817148, samples/s: 785.137 1613315355.8125556
train: epoch 59, iter 2900, loss: 2.623465, top_1: 0.602930, top_k: 0.822812, samples/s: 782.071 1613315388.546155
train: epoch 59, iter 3000, loss: 2.558436, top_1: 0.606406, top_k: 0.821953, samples/s: 787.974 1613315421.0344596
train: epoch 59, iter 3100, loss: 2.606706, top_1: 0.603984, top_k: 0.822148, samples/s: 784.989 1613315453.64639
train: epoch 59, iter 3200, loss: 2.663366, top_1: 0.603320, top_k: 0.819336, samples/s: 785.645 1613315486.2310433
train: epoch 59, iter 3300, loss: 2.436196, top_1: 0.602187, top_k: 0.816602, samples/s: 785.614 1613315518.8170605
train: epoch 59, iter 3400, loss: 2.732648, top_1: 0.602148, top_k: 0.818945, samples/s: 786.656 1613315551.359838
train: epoch 59, iter 3500, loss: 2.573629, top_1: 0.602617, top_k: 0.816562, samples/s: 784.952 1613315583.97333
train: epoch 59, iter 3600, loss: 2.613766, top_1: 0.608359, top_k: 0.818945, samples/s: 785.856 1613315616.5492587
train: epoch 59, iter 3700, loss: 2.703874, top_1: 0.603789, top_k: 0.822812, samples/s: 784.326 1613315649.188742
train: epoch 59, iter 3800, loss: 2.678619, top_1: 0.602305, top_k: 0.820742, samples/s: 787.336 1613315681.7034414
train: epoch 59, iter 3900, loss: 2.623000, top_1: 0.606172, top_k: 0.821328, samples/s: 785.930 1613315714.2763186
train: epoch 59, iter 4000, loss: 2.635037, top_1: 0.601641, top_k: 0.820039, samples/s: 785.118 1613315746.8828335
train: epoch 59, iter 4100, loss: 2.657310, top_1: 0.597266, top_k: 0.815586, samples/s: 783.858 1613315779.5419188
train: epoch 59, iter 4200, loss: 2.787074, top_1: 0.605742, top_k: 0.821875, samples/s: 785.412 1613315812.1361644
train: epoch 59, iter 4300, loss: 2.550252, top_1: 0.601406, top_k: 0.821094, samples/s: 783.070 1613315844.828106
train: epoch 59, iter 4400, loss: 2.773998, top_1: 0.609258, top_k: 0.820391, samples/s: 783.810 1613315877.489038
train: epoch 59, iter 4500, loss: 2.605047, top_1: 0.599961, top_k: 0.813320, samples/s: 785.002 1613315910.1004288
train: epoch 59, iter 4600, loss: 2.496521, top_1: 0.595742, top_k: 0.814453, samples/s: 784.246 1613315942.7433105
train: epoch 59, iter 4700, loss: 2.627097, top_1: 0.603555, top_k: 0.820000, samples/s: 783.672 1613315975.4100697
train: epoch 59, iter 4800, loss: 2.682530, top_1: 0.598477, top_k: 0.815547, samples/s: 784.441 1613316008.0445986
train: epoch 59, iter 4900, loss: 2.497970, top_1: 0.600625, top_k: 0.816680, samples/s: 784.000 1613316040.6977234
train: epoch 59, iter 5000, loss: 2.671317, top_1: 0.602656, top_k: 0.817187, samples/s: 785.992 1613316073.2680817
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_59.
validation: epoch 59, iter 195, top_1: 0.656651, top_k: 0.872796, samples/s: 2349.428 1613316095.4842973
train: epoch 60, iter 100, loss: 2.690861, top_1: 0.607227, top_k: 0.820859, samples/s: 803.482 1613316153.3122823
train: epoch 60, iter 200, loss: 2.811375, top_1: 0.616797, top_k: 0.828516, samples/s: 800.761 1613316185.2819705
train: epoch 60, iter 300, loss: 2.800661, top_1: 0.612930, top_k: 0.827812, samples/s: 789.001 1613316217.7280126
train: epoch 60, iter 400, loss: 2.674760, top_1: 0.611836, top_k: 0.827695, samples/s: 784.258 1613316250.3702636
train: epoch 60, iter 500, loss: 2.492015, top_1: 0.605430, top_k: 0.823945, samples/s: 781.710 1613316283.119031
train: epoch 60, iter 600, loss: 2.629893, top_1: 0.612422, top_k: 0.823125, samples/s: 783.191 1613316315.8057992
train: epoch 60, iter 700, loss: 2.747045, top_1: 0.607891, top_k: 0.827070, samples/s: 784.858 1613316348.423112
train: epoch 60, iter 800, loss: 2.554837, top_1: 0.610234, top_k: 0.820586, samples/s: 783.816 1613316381.0839171
train: epoch 60, iter 900, loss: 2.652920, top_1: 0.614219, top_k: 0.829883, samples/s: 783.303 1613316413.7660189
train: epoch 60, iter 1000, loss: 2.639038, top_1: 0.606641, top_k: 0.823828, samples/s: 784.593 1613316446.3943138
train: epoch 60, iter 1100, loss: 2.576260, top_1: 0.607109, top_k: 0.823711, samples/s: 785.353 1613316478.9912302
train: epoch 60, iter 1200, loss: 2.822649, top_1: 0.605156, top_k: 0.821875, samples/s: 781.947 1613316511.7299385
train: epoch 60, iter 1300, loss: 2.442681, top_1: 0.611016, top_k: 0.824063, samples/s: 787.329 1613316544.2449422
train: epoch 60, iter 1400, loss: 2.573849, top_1: 0.608867, top_k: 0.821523, samples/s: 783.057 1613316576.9373865
train: epoch 60, iter 1500, loss: 2.574565, top_1: 0.610391, top_k: 0.824922, samples/s: 786.125 1613316609.502118
train: epoch 60, iter 1600, loss: 2.559590, top_1: 0.604297, top_k: 0.823359, samples/s: 783.741 1613316642.1659367
train: epoch 60, iter 1700, loss: 2.527170, top_1: 0.606875, top_k: 0.821641, samples/s: 784.566 1613316674.7955787
train: epoch 60, iter 1800, loss: 2.660583, top_1: 0.607539, top_k: 0.821797, samples/s: 784.933 1613316707.4096894
train: epoch 60, iter 1900, loss: 2.558262, top_1: 0.607266, top_k: 0.822109, samples/s: 785.243 1613316740.0111086
train: epoch 60, iter 2000, loss: 2.568017, top_1: 0.609375, top_k: 0.822969, samples/s: 785.352 1613316772.6080012
train: epoch 60, iter 2100, loss: 2.559867, top_1: 0.599727, top_k: 0.817266, samples/s: 787.861 1613316805.1010127
train: epoch 60, iter 2200, loss: 2.505488, top_1: 0.609922, top_k: 0.822461, samples/s: 784.735 1613316837.7234883
train: epoch 60, iter 2300, loss: 2.417548, top_1: 0.606641, top_k: 0.822500, samples/s: 785.803 1613316870.3015745
train: epoch 60, iter 2400, loss: 2.743859, top_1: 0.608594, top_k: 0.821680, samples/s: 786.705 1613316902.8424275
train: epoch 60, iter 2500, loss: 2.473638, top_1: 0.603594, top_k: 0.820469, samples/s: 785.004 1613316935.453651
train: epoch 60, iter 2600, loss: 2.739982, top_1: 0.604531, top_k: 0.818047, samples/s: 785.427 1613316968.047433
train: epoch 60, iter 2700, loss: 2.574117, top_1: 0.605859, top_k: 0.824023, samples/s: 787.500 1613317000.5554023
train: epoch 60, iter 2800, loss: 2.604965, top_1: 0.600938, top_k: 0.820508, samples/s: 786.650 1613317033.0983486
train: epoch 60, iter 2900, loss: 2.688603, top_1: 0.601328, top_k: 0.817734, samples/s: 783.177 1613317065.7858243
train: epoch 60, iter 3000, loss: 2.534030, top_1: 0.599258, top_k: 0.816523, samples/s: 785.402 1613317098.3805897
train: epoch 60, iter 3100, loss: 2.610313, top_1: 0.607187, top_k: 0.818594, samples/s: 780.865 1613317131.1647606
train: epoch 60, iter 3200, loss: 2.609838, top_1: 0.605313, top_k: 0.820195, samples/s: 788.020 1613317163.6512942
train: epoch 60, iter 3300, loss: 2.580770, top_1: 0.606016, top_k: 0.819883, samples/s: 786.248 1613317196.2109663
train: epoch 60, iter 3400, loss: 2.628834, top_1: 0.602109, top_k: 0.819180, samples/s: 786.446 1613317228.7623558
train: epoch 60, iter 3500, loss: 2.676243, top_1: 0.604414, top_k: 0.821914, samples/s: 784.505 1613317261.3943868
train: epoch 60, iter 3600, loss: 2.661195, top_1: 0.610195, top_k: 0.822969, samples/s: 784.218 1613317294.0384984
train: epoch 60, iter 3700, loss: 2.835717, top_1: 0.594766, top_k: 0.815195, samples/s: 786.273 1613317326.5972166
train: epoch 60, iter 3800, loss: 2.710055, top_1: 0.600508, top_k: 0.819492, samples/s: 784.919 1613317359.2119732
train: epoch 60, iter 3900, loss: 2.499641, top_1: 0.602227, top_k: 0.817813, samples/s: 786.459 1613317391.7628818
train: epoch 60, iter 4000, loss: 2.678312, top_1: 0.604141, top_k: 0.819805, samples/s: 784.631 1613317424.389721
train: epoch 60, iter 4100, loss: 2.624792, top_1: 0.603516, top_k: 0.817305, samples/s: 785.111 1613317456.9965742
train: epoch 60, iter 4200, loss: 2.745544, top_1: 0.603555, top_k: 0.822031, samples/s: 784.998 1613317489.6080885
train: epoch 60, iter 4300, loss: 2.628627, top_1: 0.609180, top_k: 0.822656, samples/s: 784.112 1613317522.2565515
train: epoch 60, iter 4400, loss: 2.579076, top_1: 0.603867, top_k: 0.819961, samples/s: 781.872 1613317554.9984393
train: epoch 60, iter 4500, loss: 2.697284, top_1: 0.606836, top_k: 0.818086, samples/s: 782.411 1613317587.7177894
train: epoch 60, iter 4600, loss: 2.622417, top_1: 0.601055, top_k: 0.820703, samples/s: 783.299 1613317620.400107
train: epoch 60, iter 4700, loss: 2.388569, top_1: 0.596328, top_k: 0.816797, samples/s: 784.852 1613317653.0177338
train: epoch 60, iter 4800, loss: 2.793902, top_1: 0.597695, top_k: 0.816953, samples/s: 784.051 1613317685.668632
train: epoch 60, iter 4900, loss: 2.779532, top_1: 0.606836, top_k: 0.821875, samples/s: 786.300 1613317718.226232
train: epoch 60, iter 5000, loss: 2.663066, top_1: 0.607891, top_k: 0.822734, samples/s: 783.588 1613317750.8965213
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_60.
validation: epoch 60, iter 195, top_1: 0.655849, top_k: 0.871895, samples/s: 2365.837 1613317772.9707408
train: epoch 61, iter 100, loss: 2.680730, top_1: 0.611563, top_k: 0.824375, samples/s: 803.445 1613317825.778206
train: epoch 61, iter 200, loss: 2.364426, top_1: 0.616836, top_k: 0.831289, samples/s: 801.930 1613317857.7012336
train: epoch 61, iter 300, loss: 2.671029, top_1: 0.612891, top_k: 0.828359, samples/s: 783.236 1613317890.3862212
train: epoch 61, iter 400, loss: 2.621612, top_1: 0.610508, top_k: 0.824102, samples/s: 784.149 1613317923.0329912
train: epoch 61, iter 500, loss: 2.534561, top_1: 0.613281, top_k: 0.829766, samples/s: 783.588 1613317955.7034395
train: epoch 61, iter 600, loss: 2.645029, top_1: 0.616719, top_k: 0.830625, samples/s: 782.654 1613317988.4124258
train: epoch 61, iter 700, loss: 2.746846, top_1: 0.614648, top_k: 0.831953, samples/s: 783.989 1613318021.0659328
train: epoch 61, iter 800, loss: 2.671105, top_1: 0.609453, top_k: 0.825547, samples/s: 782.239 1613318053.7925835
train: epoch 61, iter 900, loss: 2.516226, top_1: 0.621797, top_k: 0.832500, samples/s: 782.559 1613318086.505794
train: epoch 61, iter 1000, loss: 2.592125, top_1: 0.615938, top_k: 0.827812, samples/s: 784.506 1613318119.1377943
train: epoch 61, iter 1100, loss: 2.621109, top_1: 0.610938, top_k: 0.825742, samples/s: 781.240 1613318151.9060724
train: epoch 61, iter 1200, loss: 2.721239, top_1: 0.611719, top_k: 0.822539, samples/s: 784.428 1613318184.5413566
train: epoch 61, iter 1300, loss: 2.641315, top_1: 0.604336, top_k: 0.824297, samples/s: 781.269 1613318217.3086326
train: epoch 61, iter 1400, loss: 2.463960, top_1: 0.614805, top_k: 0.830508, samples/s: 783.950 1613318249.9637456
train: epoch 61, iter 1500, loss: 2.634266, top_1: 0.611406, top_k: 0.823047, samples/s: 783.241 1613318282.6484327
train: epoch 61, iter 1600, loss: 2.661337, top_1: 0.610820, top_k: 0.825977, samples/s: 780.678 1613318315.4403799
train: epoch 61, iter 1700, loss: 2.849982, top_1: 0.612969, top_k: 0.828672, samples/s: 781.855 1613318348.1830668
train: epoch 61, iter 1800, loss: 2.503156, top_1: 0.610273, top_k: 0.825313, samples/s: 784.313 1613318380.8231082
train: epoch 61, iter 1900, loss: 2.761252, top_1: 0.609922, top_k: 0.824375, samples/s: 782.937 1613318413.5204642
train: epoch 61, iter 2000, loss: 2.601401, top_1: 0.611602, top_k: 0.825000, samples/s: 783.022 1613318446.2143323
train: epoch 61, iter 2100, loss: 2.572718, top_1: 0.602344, top_k: 0.820977, samples/s: 780.204 1613318479.0262651
train: epoch 61, iter 2200, loss: 2.649005, top_1: 0.608594, top_k: 0.819219, samples/s: 782.957 1613318511.7228062
train: epoch 61, iter 2300, loss: 2.586268, top_1: 0.601602, top_k: 0.820547, samples/s: 782.042 1613318544.4577084
train: epoch 61, iter 2400, loss: 2.665585, top_1: 0.607187, top_k: 0.817031, samples/s: 784.810 1613318577.0770392
train: epoch 61, iter 2500, loss: 2.601064, top_1: 0.598633, top_k: 0.818438, samples/s: 782.326 1613318609.7999496
train: epoch 61, iter 2600, loss: 2.541106, top_1: 0.610430, top_k: 0.822031, samples/s: 784.295 1613318642.4406965
train: epoch 61, iter 2700, loss: 2.551649, top_1: 0.599414, top_k: 0.816953, samples/s: 783.368 1613318675.1200783
train: epoch 61, iter 2800, loss: 2.634035, top_1: 0.608125, top_k: 0.825898, samples/s: 783.893 1613318707.7775807
train: epoch 61, iter 2900, loss: 2.558330, top_1: 0.604258, top_k: 0.819531, samples/s: 785.607 1613318740.3638768
train: epoch 61, iter 3000, loss: 2.677615, top_1: 0.609766, top_k: 0.821562, samples/s: 780.583 1613318773.15992
train: epoch 61, iter 3100, loss: 2.620632, top_1: 0.611602, top_k: 0.822617, samples/s: 782.526 1613318805.8744013
train: epoch 61, iter 3200, loss: 2.760021, top_1: 0.601211, top_k: 0.821328, samples/s: 781.813 1613318838.618761
train: epoch 61, iter 3300, loss: 2.475134, top_1: 0.604766, top_k: 0.817891, samples/s: 784.302 1613318871.2593431
train: epoch 61, iter 3400, loss: 2.582734, top_1: 0.611406, top_k: 0.825937, samples/s: 786.355 1613318903.8146071
train: epoch 61, iter 3500, loss: 2.584227, top_1: 0.605234, top_k: 0.822031, samples/s: 782.265 1613318936.5400631
train: epoch 61, iter 3600, loss: 2.499538, top_1: 0.602578, top_k: 0.817734, samples/s: 784.711 1613318969.16358
train: epoch 61, iter 3700, loss: 2.485229, top_1: 0.603047, top_k: 0.818203, samples/s: 781.182 1613319001.9344535
train: epoch 61, iter 3800, loss: 2.645695, top_1: 0.607539, top_k: 0.820430, samples/s: 784.704 1613319034.5581129
train: epoch 61, iter 3900, loss: 2.690922, top_1: 0.602070, top_k: 0.819336, samples/s: 783.561 1613319067.2295187
train: epoch 61, iter 4000, loss: 2.658774, top_1: 0.601289, top_k: 0.819180, samples/s: 784.217 1613319099.8735216
train: epoch 61, iter 4100, loss: 2.782663, top_1: 0.606797, top_k: 0.826328, samples/s: 783.232 1613319132.558693
train: epoch 61, iter 4200, loss: 2.533617, top_1: 0.606875, top_k: 0.823672, samples/s: 783.275 1613319165.2419405
train: epoch 61, iter 4300, loss: 2.580039, top_1: 0.605313, top_k: 0.822969, samples/s: 781.054 1613319198.0182052
train: epoch 61, iter 4400, loss: 2.678872, top_1: 0.602852, top_k: 0.819492, samples/s: 784.684 1613319230.6427236
train: epoch 61, iter 4500, loss: 2.717802, top_1: 0.611211, top_k: 0.824258, samples/s: 781.350 1613319263.406577
train: epoch 61, iter 4600, loss: 2.708682, top_1: 0.606133, top_k: 0.823633, samples/s: 783.687 1613319296.0725758
train: epoch 61, iter 4700, loss: 2.714301, top_1: 0.598008, top_k: 0.814922, samples/s: 783.908 1613319328.729547
train: epoch 61, iter 4800, loss: 2.657739, top_1: 0.605781, top_k: 0.817852, samples/s: 783.162 1613319361.4175403
train: epoch 61, iter 4900, loss: 2.778419, top_1: 0.603008, top_k: 0.819766, samples/s: 781.627 1613319394.1697104
train: epoch 61, iter 5000, loss: 2.580901, top_1: 0.604688, top_k: 0.821875, samples/s: 784.190 1613319426.814893
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_61.
validation: epoch 61, iter 195, top_1: 0.655048, top_k: 0.872917, samples/s: 2353.747 1613319449.004859
train: epoch 62, iter 100, loss: 2.620415, top_1: 0.612148, top_k: 0.826602, samples/s: 803.687 1613319502.2928789
train: epoch 62, iter 200, loss: 2.572678, top_1: 0.625938, top_k: 0.835391, samples/s: 799.578 1613319534.3097281
train: epoch 62, iter 300, loss: 2.539906, top_1: 0.616953, top_k: 0.826484, samples/s: 786.180 1613319566.8722742
train: epoch 62, iter 400, loss: 2.563360, top_1: 0.614492, top_k: 0.828555, samples/s: 782.817 1613319599.5746357
train: epoch 62, iter 500, loss: 2.549336, top_1: 0.612070, top_k: 0.829414, samples/s: 780.903 1613319632.3572154
train: epoch 62, iter 600, loss: 2.713439, top_1: 0.616992, top_k: 0.829727, samples/s: 783.361 1613319665.036947
train: epoch 62, iter 700, loss: 2.507645, top_1: 0.616953, top_k: 0.831016, samples/s: 780.078 1613319697.8542457
train: epoch 62, iter 800, loss: 2.615950, top_1: 0.615508, top_k: 0.827891, samples/s: 780.725 1613319730.6442926
train: epoch 62, iter 900, loss: 2.513773, top_1: 0.606953, top_k: 0.823594, samples/s: 782.539 1613319763.3581831
train: epoch 62, iter 1000, loss: 2.537277, top_1: 0.608867, top_k: 0.823086, samples/s: 780.141 1613319796.172852
train: epoch 62, iter 1100, loss: 2.745191, top_1: 0.609883, top_k: 0.824844, samples/s: 783.829 1613319828.833001
train: epoch 62, iter 1200, loss: 2.473225, top_1: 0.614023, top_k: 0.829023, samples/s: 779.566 1613319861.671763
train: epoch 62, iter 1300, loss: 2.476375, top_1: 0.603828, top_k: 0.823008, samples/s: 780.649 1613319894.4649694
train: epoch 62, iter 1400, loss: 2.594471, top_1: 0.611172, top_k: 0.823594, samples/s: 781.884 1613319927.2064598
train: epoch 62, iter 1500, loss: 2.647728, top_1: 0.618164, top_k: 0.830586, samples/s: 782.485 1613319959.9227378
train: epoch 62, iter 1600, loss: 2.623471, top_1: 0.609336, top_k: 0.826445, samples/s: 779.646 1613319992.7581294
train: epoch 62, iter 1700, loss: 2.675012, top_1: 0.611328, top_k: 0.826211, samples/s: 781.257 1613320025.5257742
train: epoch 62, iter 1800, loss: 2.582841, top_1: 0.611289, top_k: 0.823984, samples/s: 783.461 1613320058.2013068
train: epoch 62, iter 1900, loss: 2.512268, top_1: 0.606523, top_k: 0.822109, samples/s: 783.051 1613320090.893902
train: epoch 62, iter 2000, loss: 2.608573, top_1: 0.610898, top_k: 0.827227, samples/s: 780.139 1613320123.708602
train: epoch 62, iter 2100, loss: 2.723473, top_1: 0.606836, top_k: 0.825352, samples/s: 785.091 1613320156.3162441
train: epoch 62, iter 2200, loss: 2.539939, top_1: 0.606445, top_k: 0.822617, samples/s: 779.381 1613320189.1629214
train: epoch 62, iter 2300, loss: 2.705038, top_1: 0.607617, top_k: 0.822500, samples/s: 783.306 1613320221.8448997
train: epoch 62, iter 2400, loss: 2.788233, top_1: 0.614141, top_k: 0.827930, samples/s: 784.080 1613320254.4946883
train: epoch 62, iter 2500, loss: 2.466622, top_1: 0.613633, top_k: 0.823906, samples/s: 782.933 1613320287.1922154
train: epoch 62, iter 2600, loss: 2.517247, top_1: 0.612539, top_k: 0.823008, samples/s: 781.102 1613320319.9663832
train: epoch 62, iter 2700, loss: 2.569177, top_1: 0.607031, top_k: 0.823242, samples/s: 782.562 1613320352.679484
train: epoch 62, iter 2800, loss: 2.724446, top_1: 0.612383, top_k: 0.826797, samples/s: 784.817 1613320385.2985759
train: epoch 62, iter 2900, loss: 2.525270, top_1: 0.604805, top_k: 0.822344, samples/s: 780.694 1613320418.0898569
train: epoch 62, iter 3000, loss: 2.570015, top_1: 0.603242, top_k: 0.821133, samples/s: 784.005 1613320450.742778
train: epoch 62, iter 3100, loss: 2.617183, top_1: 0.606563, top_k: 0.822070, samples/s: 782.500 1613320483.4583561
train: epoch 62, iter 3200, loss: 2.832525, top_1: 0.604844, top_k: 0.821875, samples/s: 784.219 1613320516.102381
train: epoch 62, iter 3300, loss: 2.666916, top_1: 0.605117, top_k: 0.820156, samples/s: 782.766 1613320548.806822
train: epoch 62, iter 3400, loss: 2.637017, top_1: 0.606563, top_k: 0.819727, samples/s: 784.428 1613320581.442127
train: epoch 62, iter 3500, loss: 2.754683, top_1: 0.603828, top_k: 0.820156, samples/s: 781.289 1613320614.2084992
train: epoch 62, iter 3600, loss: 2.536597, top_1: 0.603906, top_k: 0.820273, samples/s: 783.298 1613320646.890824
train: epoch 62, iter 3700, loss: 2.568743, top_1: 0.608594, top_k: 0.819922, samples/s: 783.034 1613320679.5841186
train: epoch 62, iter 3800, loss: 2.693830, top_1: 0.601914, top_k: 0.818398, samples/s: 782.455 1613320712.3016715
train: epoch 62, iter 3900, loss: 2.678703, top_1: 0.609805, top_k: 0.826289, samples/s: 784.232 1613320744.9451268
train: epoch 62, iter 4000, loss: 2.793125, top_1: 0.604180, top_k: 0.818906, samples/s: 780.222 1613320777.7562299
train: epoch 62, iter 4100, loss: 2.568647, top_1: 0.604453, top_k: 0.821328, samples/s: 784.140 1613320810.4034812
train: epoch 62, iter 4200, loss: 2.704820, top_1: 0.600430, top_k: 0.818047, samples/s: 783.250 1613320843.087793
train: epoch 62, iter 4300, loss: 2.585967, top_1: 0.602969, top_k: 0.818125, samples/s: 781.120 1613320875.8612704
train: epoch 62, iter 4400, loss: 2.672127, top_1: 0.601797, top_k: 0.819805, samples/s: 783.708 1613320908.5265496
train: epoch 62, iter 4500, loss: 2.564388, top_1: 0.601445, top_k: 0.818945, samples/s: 782.742 1613320941.2320986
train: epoch 62, iter 4600, loss: 2.590534, top_1: 0.605586, top_k: 0.823398, samples/s: 780.693 1613320974.0234177
train: epoch 62, iter 4700, loss: 2.849743, top_1: 0.611953, top_k: 0.824844, samples/s: 784.368 1613321006.6612103
train: epoch 62, iter 4800, loss: 2.725924, top_1: 0.609180, top_k: 0.827969, samples/s: 783.861 1613321039.319999
train: epoch 62, iter 4900, loss: 2.710408, top_1: 0.606055, top_k: 0.825586, samples/s: 782.517 1613321072.0349352
train: epoch 62, iter 5000, loss: 2.438974, top_1: 0.605430, top_k: 0.822187, samples/s: 782.612 1613321104.7458682
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_62.
validation: epoch 62, iter 195, top_1: 0.663522, top_k: 0.876142, samples/s: 2325.210 1613321127.1914062
train: epoch 63, iter 100, loss: 2.551642, top_1: 0.617656, top_k: 0.828789, samples/s: 805.443 1613321181.125201
train: epoch 63, iter 200, loss: 2.536582, top_1: 0.619727, top_k: 0.831719, samples/s: 800.281 1613321213.1141002
train: epoch 63, iter 300, loss: 2.553090, top_1: 0.616992, top_k: 0.833125, samples/s: 784.106 1613321245.7626762
train: epoch 63, iter 400, loss: 2.636488, top_1: 0.620742, top_k: 0.833945, samples/s: 781.098 1613321278.537022
train: epoch 63, iter 500, loss: 2.578604, top_1: 0.616211, top_k: 0.826211, samples/s: 779.994 1613321311.3578773
train: epoch 63, iter 600, loss: 2.489254, top_1: 0.613516, top_k: 0.830117, samples/s: 781.029 1613321344.1350226
train: epoch 63, iter 700, loss: 2.450845, top_1: 0.623867, top_k: 0.831523, samples/s: 782.647 1613321376.8445652
train: epoch 63, iter 800, loss: 2.624967, top_1: 0.613398, top_k: 0.830352, samples/s: 779.449 1613321409.6883419
train: epoch 63, iter 900, loss: 2.610455, top_1: 0.618555, top_k: 0.830156, samples/s: 782.086 1613321442.421247
train: epoch 63, iter 1000, loss: 2.565390, top_1: 0.613789, top_k: 0.827852, samples/s: 779.375 1613321475.2681289
train: epoch 63, iter 1100, loss: 2.524380, top_1: 0.617930, top_k: 0.825937, samples/s: 781.224 1613321508.037193
train: epoch 63, iter 1200, loss: 2.721759, top_1: 0.613359, top_k: 0.827187, samples/s: 781.427 1613321540.7977145
train: epoch 63, iter 1300, loss: 2.632756, top_1: 0.604922, top_k: 0.823281, samples/s: 780.702 1613321573.5888093
train: epoch 63, iter 1400, loss: 2.522450, top_1: 0.616328, top_k: 0.828438, samples/s: 781.139 1613321606.3615036
train: epoch 63, iter 1500, loss: 2.564754, top_1: 0.615234, top_k: 0.825898, samples/s: 782.448 1613321639.0792923
train: epoch 63, iter 1600, loss: 2.635777, top_1: 0.611953, top_k: 0.826953, samples/s: 781.852 1613321671.8220248
train: epoch 63, iter 1700, loss: 2.710332, top_1: 0.609961, top_k: 0.824180, samples/s: 782.381 1613321704.5426404
train: epoch 63, iter 1800, loss: 2.313133, top_1: 0.611992, top_k: 0.821797, samples/s: 783.212 1613321737.2285693
train: epoch 63, iter 1900, loss: 2.432756, top_1: 0.609297, top_k: 0.826797, samples/s: 784.111 1613321769.8770616
train: epoch 63, iter 2000, loss: 2.669541, top_1: 0.613906, top_k: 0.826953, samples/s: 781.330 1613321802.6416066
train: epoch 63, iter 2100, loss: 2.379750, top_1: 0.610625, top_k: 0.825352, samples/s: 784.878 1613321835.258147
train: epoch 63, iter 2200, loss: 2.704207, top_1: 0.602891, top_k: 0.822227, samples/s: 782.921 1613321867.956251
train: epoch 63, iter 2300, loss: 2.725676, top_1: 0.606445, top_k: 0.823047, samples/s: 779.225 1613321900.809483
train: epoch 63, iter 2400, loss: 2.501794, top_1: 0.611719, top_k: 0.827734, samples/s: 784.124 1613321933.4573824
train: epoch 63, iter 2500, loss: 2.561571, top_1: 0.612070, top_k: 0.824844, samples/s: 782.715 1613321966.1640143
train: epoch 63, iter 2600, loss: 2.882207, top_1: 0.611328, top_k: 0.827461, samples/s: 781.349 1613321998.9278965
train: epoch 63, iter 2700, loss: 2.546720, top_1: 0.606133, top_k: 0.825859, samples/s: 782.020 1613322031.6635761
train: epoch 63, iter 2800, loss: 2.741983, top_1: 0.613711, top_k: 0.828438, samples/s: 785.505 1613322064.2541177
train: epoch 63, iter 2900, loss: 2.594594, top_1: 0.609258, top_k: 0.822422, samples/s: 781.614 1613322097.0068157
train: epoch 63, iter 3000, loss: 2.705787, top_1: 0.607500, top_k: 0.822500, samples/s: 781.428 1613322129.7673259
train: epoch 63, iter 3100, loss: 2.399673, top_1: 0.615156, top_k: 0.829727, samples/s: 785.001 1613322162.3788009
train: epoch 63, iter 3200, loss: 2.878203, top_1: 0.610195, top_k: 0.825547, samples/s: 782.395 1613322195.0988572
train: epoch 63, iter 3300, loss: 2.568495, top_1: 0.610313, top_k: 0.823594, samples/s: 782.468 1613322227.8158128
train: epoch 63, iter 3400, loss: 2.602963, top_1: 0.604375, top_k: 0.820078, samples/s: 783.603 1613322260.4854069
train: epoch 63, iter 3500, loss: 2.437734, top_1: 0.602422, top_k: 0.822539, samples/s: 781.769 1613322293.2316399
train: epoch 63, iter 3600, loss: 2.651787, top_1: 0.610469, top_k: 0.823711, samples/s: 782.649 1613322325.9411464
train: epoch 63, iter 3700, loss: 2.624599, top_1: 0.611250, top_k: 0.823594, samples/s: 783.331 1613322358.621999
train: epoch 63, iter 3800, loss: 2.554622, top_1: 0.607891, top_k: 0.823555, samples/s: 784.927 1613322391.2365806
train: epoch 63, iter 3900, loss: 2.580559, top_1: 0.607891, top_k: 0.823711, samples/s: 782.402 1613322423.9562309
train: epoch 63, iter 4000, loss: 2.541223, top_1: 0.613555, top_k: 0.829141, samples/s: 782.091 1613322456.6890755
train: epoch 63, iter 4100, loss: 2.670500, top_1: 0.606250, top_k: 0.823555, samples/s: 785.598 1613322489.2756627
train: epoch 63, iter 4200, loss: 2.780231, top_1: 0.607812, top_k: 0.823750, samples/s: 784.724 1613322521.8987093
train: epoch 63, iter 4300, loss: 2.484244, top_1: 0.605859, top_k: 0.822617, samples/s: 781.146 1613322554.6709654
train: epoch 63, iter 4400, loss: 2.580817, top_1: 0.597930, top_k: 0.818281, samples/s: 782.570 1613322587.3837693
train: epoch 63, iter 4500, loss: 2.642368, top_1: 0.608203, top_k: 0.826211, samples/s: 783.605 1613322620.0531592
train: epoch 63, iter 4600, loss: 2.798287, top_1: 0.609062, top_k: 0.827461, samples/s: 781.619 1613322652.8057928
train: epoch 63, iter 4700, loss: 2.654554, top_1: 0.608086, top_k: 0.820039, samples/s: 784.724 1613322685.4286559
train: epoch 63, iter 4800, loss: 2.691257, top_1: 0.602617, top_k: 0.819922, samples/s: 782.609 1613322718.139825
train: epoch 63, iter 4900, loss: 2.623703, top_1: 0.605273, top_k: 0.822930, samples/s: 781.775 1613322750.8857076
train: epoch 63, iter 5000, loss: 2.407040, top_1: 0.605586, top_k: 0.820937, samples/s: 782.616 1613322783.596645
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_63.
validation: epoch 63, iter 195, top_1: 0.664683, top_k: 0.876402, samples/s: 2358.346 1613322805.7529492
train: epoch 64, iter 100, loss: 2.516080, top_1: 0.628047, top_k: 0.840586, samples/s: 804.446 1613322858.3640127
train: epoch 64, iter 200, loss: 2.477208, top_1: 0.620977, top_k: 0.832578, samples/s: 799.157 1613322890.397717
train: epoch 64, iter 300, loss: 2.545338, top_1: 0.615195, top_k: 0.829219, samples/s: 785.420 1613322922.9922726
train: epoch 64, iter 400, loss: 2.612205, top_1: 0.622578, top_k: 0.836094, samples/s: 780.703 1613322955.7827399
train: epoch 64, iter 500, loss: 2.327603, top_1: 0.608477, top_k: 0.825547, samples/s: 780.312 1613322988.5901346
train: epoch 64, iter 600, loss: 2.487026, top_1: 0.619766, top_k: 0.830781, samples/s: 781.638 1613323021.3418217
train: epoch 64, iter 700, loss: 2.611773, top_1: 0.619609, top_k: 0.828203, samples/s: 781.947 1613323054.0805833
train: epoch 64, iter 800, loss: 2.537632, top_1: 0.619727, top_k: 0.830000, samples/s: 781.528 1613323086.8369694
train: epoch 64, iter 900, loss: 2.636012, top_1: 0.619336, top_k: 0.830625, samples/s: 781.455 1613323119.5963802
train: epoch 64, iter 1000, loss: 2.589919, top_1: 0.615820, top_k: 0.831094, samples/s: 782.607 1613323152.307564
train: epoch 64, iter 1100, loss: 2.716123, top_1: 0.614492, top_k: 0.826914, samples/s: 780.689 1613323185.0990627
train: epoch 64, iter 1200, loss: 2.647930, top_1: 0.607578, top_k: 0.823789, samples/s: 779.137 1613323217.956005
train: epoch 64, iter 1300, loss: 2.592986, top_1: 0.613867, top_k: 0.829922, samples/s: 782.086 1613323250.6889727
train: epoch 64, iter 1400, loss: 2.638153, top_1: 0.613320, top_k: 0.825234, samples/s: 781.057 1613323283.465013
train: epoch 64, iter 1500, loss: 2.556863, top_1: 0.613047, top_k: 0.821680, samples/s: 784.458 1613323316.0990336
train: epoch 64, iter 1600, loss: 2.743347, top_1: 0.613945, top_k: 0.824023, samples/s: 782.059 1613323348.8332422
train: epoch 64, iter 1700, loss: 2.496403, top_1: 0.612734, top_k: 0.827656, samples/s: 783.007 1613323381.527702
train: epoch 64, iter 1800, loss: 2.363748, top_1: 0.616016, top_k: 0.827422, samples/s: 783.735 1613323414.1917593
train: epoch 64, iter 1900, loss: 2.393334, top_1: 0.610430, top_k: 0.823320, samples/s: 782.276 1613323446.9167447
train: epoch 64, iter 2000, loss: 2.625379, top_1: 0.617031, top_k: 0.829023, samples/s: 782.951 1613323479.6135886
train: epoch 64, iter 2100, loss: 2.460869, top_1: 0.616563, top_k: 0.825586, samples/s: 782.205 1613323512.3415232
train: epoch 64, iter 2200, loss: 2.492197, top_1: 0.613555, top_k: 0.826055, samples/s: 781.301 1613323545.107414
train: epoch 64, iter 2300, loss: 2.640231, top_1: 0.613320, top_k: 0.826680, samples/s: 782.130 1613323577.8385203
train: epoch 64, iter 2400, loss: 2.623509, top_1: 0.617422, top_k: 0.828750, samples/s: 783.638 1613323610.5067523
train: epoch 64, iter 2500, loss: 2.399059, top_1: 0.613008, top_k: 0.824023, samples/s: 781.687 1613323643.2565103
train: epoch 64, iter 2600, loss: 2.518145, top_1: 0.616836, top_k: 0.827812, samples/s: 783.546 1613323675.9283435
train: epoch 64, iter 2700, loss: 2.386585, top_1: 0.613359, top_k: 0.824258, samples/s: 784.919 1613323708.5432255
train: epoch 64, iter 2800, loss: 2.506278, top_1: 0.610117, top_k: 0.826992, samples/s: 783.800 1613323741.2045915
train: epoch 64, iter 2900, loss: 2.579492, top_1: 0.611055, top_k: 0.824375, samples/s: 782.741 1613323773.9102356
train: epoch 64, iter 3000, loss: 2.570510, top_1: 0.608555, top_k: 0.825898, samples/s: 782.350 1613323806.6321952
train: epoch 64, iter 3100, loss: 2.433781, top_1: 0.609805, top_k: 0.826289, samples/s: 781.242 1613323839.4004805
train: epoch 64, iter 3200, loss: 2.521233, top_1: 0.609844, top_k: 0.824102, samples/s: 783.860 1613323872.0593405
train: epoch 64, iter 3300, loss: 2.613977, top_1: 0.607852, top_k: 0.824023, samples/s: 783.783 1613323904.7214584
train: epoch 64, iter 3400, loss: 2.582335, top_1: 0.606484, top_k: 0.821953, samples/s: 784.650 1613323937.3474703
train: epoch 64, iter 3500, loss: 2.651585, top_1: 0.607109, top_k: 0.824961, samples/s: 783.505 1613323970.0211084
train: epoch 64, iter 3600, loss: 2.709252, top_1: 0.608359, top_k: 0.825156, samples/s: 783.030 1613324002.7147002
train: epoch 64, iter 3700, loss: 2.404634, top_1: 0.606172, top_k: 0.823320, samples/s: 783.122 1613324035.404381
train: epoch 64, iter 3800, loss: 2.586216, top_1: 0.613477, top_k: 0.827969, samples/s: 786.168 1613324067.9673126
train: epoch 64, iter 3900, loss: 2.657640, top_1: 0.608242, top_k: 0.819844, samples/s: 781.890 1613324100.7085626
train: epoch 64, iter 4000, loss: 2.682887, top_1: 0.608398, top_k: 0.823281, samples/s: 783.782 1613324133.3706827
train: epoch 64, iter 4100, loss: 2.576807, top_1: 0.609258, top_k: 0.823125, samples/s: 783.391 1613324166.0490513
train: epoch 64, iter 4200, loss: 2.532491, top_1: 0.613086, top_k: 0.823047, samples/s: 783.155 1613324198.7374864
train: epoch 64, iter 4300, loss: 2.722914, top_1: 0.610234, top_k: 0.823594, samples/s: 782.288 1613324231.461906
train: epoch 64, iter 4400, loss: 2.561545, top_1: 0.613594, top_k: 0.822344, samples/s: 784.736 1613324264.0844152
train: epoch 64, iter 4500, loss: 2.415496, top_1: 0.604336, top_k: 0.822812, samples/s: 785.334 1613324296.6819515
train: epoch 64, iter 4600, loss: 2.524723, top_1: 0.607461, top_k: 0.821680, samples/s: 780.690 1613324329.4734786
train: epoch 64, iter 4700, loss: 2.486399, top_1: 0.605977, top_k: 0.823555, samples/s: 783.988 1613324362.1269495
train: epoch 64, iter 4800, loss: 2.917979, top_1: 0.610078, top_k: 0.823867, samples/s: 783.016 1613324394.8211021
train: epoch 64, iter 4900, loss: 2.600754, top_1: 0.611367, top_k: 0.823711, samples/s: 782.100 1613324427.5535102
train: epoch 64, iter 5000, loss: 2.460034, top_1: 0.615508, top_k: 0.828555, samples/s: 781.686 1613324460.303212
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_64.
validation: epoch 64, iter 195, top_1: 0.662500, top_k: 0.874379, samples/s: 2385.985 1613324482.1733866
train: epoch 65, iter 100, loss: 2.444958, top_1: 0.622031, top_k: 0.830430, samples/s: 805.287 1613324534.967688
train: epoch 65, iter 200, loss: 2.466431, top_1: 0.616953, top_k: 0.830469, samples/s: 801.316 1613324566.9151733
train: epoch 65, iter 300, loss: 2.533304, top_1: 0.626406, top_k: 0.834180, samples/s: 785.345 1613324599.5123515
train: epoch 65, iter 400, loss: 2.562488, top_1: 0.610391, top_k: 0.828359, samples/s: 780.843 1613324632.2973535
train: epoch 65, iter 500, loss: 2.605440, top_1: 0.622188, top_k: 0.830781, samples/s: 781.730 1613324665.0452156
train: epoch 65, iter 600, loss: 2.765813, top_1: 0.618984, top_k: 0.833867, samples/s: 782.267 1613324697.7707317
train: epoch 65, iter 700, loss: 2.552718, top_1: 0.618203, top_k: 0.831367, samples/s: 781.762 1613324730.5172567
train: epoch 65, iter 800, loss: 2.509170, top_1: 0.620664, top_k: 0.830586, samples/s: 782.388 1613324763.2376225
train: epoch 65, iter 900, loss: 2.510563, top_1: 0.608437, top_k: 0.825859, samples/s: 779.939 1613324796.060716
train: epoch 65, iter 1000, loss: 2.783797, top_1: 0.620625, top_k: 0.831328, samples/s: 782.404 1613324828.7803717
train: epoch 65, iter 1100, loss: 2.495151, top_1: 0.621289, top_k: 0.833633, samples/s: 781.342 1613324861.544541
train: epoch 65, iter 1200, loss: 2.594950, top_1: 0.619062, top_k: 0.830313, samples/s: 782.199 1613324894.272844
train: epoch 65, iter 1300, loss: 2.720269, top_1: 0.611563, top_k: 0.823711, samples/s: 784.178 1613324926.9184535
train: epoch 65, iter 1400, loss: 2.500602, top_1: 0.615547, top_k: 0.828047, samples/s: 781.535 1613324959.674468
train: epoch 65, iter 1500, loss: 2.587079, top_1: 0.615273, top_k: 0.829648, samples/s: 780.742 1613324992.4637218
train: epoch 65, iter 1600, loss: 2.662060, top_1: 0.616250, top_k: 0.826016, samples/s: 782.678 1613325025.171951
train: epoch 65, iter 1700, loss: 2.746175, top_1: 0.611133, top_k: 0.822891, samples/s: 783.036 1613325057.8652728
train: epoch 65, iter 1800, loss: 2.623628, top_1: 0.616055, top_k: 0.828203, samples/s: 780.547 1613325090.6627252
train: epoch 65, iter 1900, loss: 2.564314, top_1: 0.620586, top_k: 0.830625, samples/s: 783.134 1613325123.3519013
train: epoch 65, iter 2000, loss: 2.472220, top_1: 0.616992, top_k: 0.831914, samples/s: 780.985 1613325156.131076
train: epoch 65, iter 2100, loss: 2.663064, top_1: 0.615469, top_k: 0.830547, samples/s: 785.504 1613325188.7215698
train: epoch 65, iter 2200, loss: 2.608449, top_1: 0.615469, top_k: 0.828789, samples/s: 780.862 1613325221.5059042
train: epoch 65, iter 2300, loss: 2.528727, top_1: 0.609570, top_k: 0.826484, samples/s: 782.155 1613325254.235964
train: epoch 65, iter 2400, loss: 2.710318, top_1: 0.609531, top_k: 0.824883, samples/s: 783.804 1613325286.8971574
train: epoch 65, iter 2500, loss: 2.666902, top_1: 0.611133, top_k: 0.825234, samples/s: 784.870 1613325319.513945
train: epoch 65, iter 2600, loss: 2.612510, top_1: 0.609570, top_k: 0.825273, samples/s: 781.464 1613325352.2729979
train: epoch 65, iter 2700, loss: 2.446404, top_1: 0.617617, top_k: 0.828047, samples/s: 782.660 1613325384.9819562
train: epoch 65, iter 2800, loss: 2.688268, top_1: 0.612031, top_k: 0.826758, samples/s: 784.570 1613325417.6113927
train: epoch 65, iter 2900, loss: 2.648139, top_1: 0.611172, top_k: 0.827266, samples/s: 783.771 1613325450.274016
train: epoch 65, iter 3000, loss: 2.789897, top_1: 0.613203, top_k: 0.827148, samples/s: 783.281 1613325482.9570696
train: epoch 65, iter 3100, loss: 2.648429, top_1: 0.609297, top_k: 0.823789, samples/s: 782.859 1613325515.6575675
train: epoch 65, iter 3200, loss: 2.469174, top_1: 0.608789, top_k: 0.823516, samples/s: 781.127 1613325548.4307694
train: epoch 65, iter 3300, loss: 2.565663, top_1: 0.611953, top_k: 0.825937, samples/s: 781.982 1613325581.168134
train: epoch 65, iter 3400, loss: 2.637675, top_1: 0.613398, top_k: 0.825625, samples/s: 781.898 1613325613.908993
train: epoch 65, iter 3500, loss: 2.600019, top_1: 0.614883, top_k: 0.828945, samples/s: 782.806 1613325646.6118948
train: epoch 65, iter 3600, loss: 2.721781, top_1: 0.613516, top_k: 0.828789, samples/s: 782.457 1613325679.3293862
train: epoch 65, iter 3700, loss: 2.619678, top_1: 0.613984, top_k: 0.825508, samples/s: 784.683 1613325711.9539907
train: epoch 65, iter 3800, loss: 2.507080, top_1: 0.608086, top_k: 0.823203, samples/s: 781.379 1613325744.7165456
train: epoch 65, iter 3900, loss: 2.635575, top_1: 0.611914, top_k: 0.824961, samples/s: 781.656 1613325777.4675715
train: epoch 65, iter 4000, loss: 2.446188, top_1: 0.608320, top_k: 0.823320, samples/s: 783.454 1613325810.1434011
train: epoch 65, iter 4100, loss: 2.314918, top_1: 0.605703, top_k: 0.820742, samples/s: 784.017 1613325842.7957845
train: epoch 65, iter 4200, loss: 2.515540, top_1: 0.610117, top_k: 0.823320, samples/s: 783.270 1613325875.4791346
train: epoch 65, iter 4300, loss: 2.527387, top_1: 0.606875, top_k: 0.820000, samples/s: 784.966 1613325908.0920455
train: epoch 65, iter 4400, loss: 2.610884, top_1: 0.610391, top_k: 0.823242, samples/s: 781.982 1613325940.829452
train: epoch 65, iter 4500, loss: 2.567782, top_1: 0.607187, top_k: 0.822852, samples/s: 783.216 1613325973.5152025
train: epoch 65, iter 4600, loss: 2.761661, top_1: 0.607070, top_k: 0.822812, samples/s: 783.170 1613326006.202771
train: epoch 65, iter 4700, loss: 2.647350, top_1: 0.614375, top_k: 0.825469, samples/s: 783.293 1613326038.8853424
train: epoch 65, iter 4800, loss: 2.496593, top_1: 0.616797, top_k: 0.827539, samples/s: 783.162 1613326071.5733669
train: epoch 65, iter 4900, loss: 2.507161, top_1: 0.610039, top_k: 0.822930, samples/s: 782.677 1613326104.2815435
train: epoch 65, iter 5000, loss: 2.483598, top_1: 0.611836, top_k: 0.826289, samples/s: 785.311 1613326136.88014
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_65.
validation: epoch 65, iter 195, top_1: 0.663702, top_k: 0.876743, samples/s: 2359.796 1613326158.9936645
train: epoch 66, iter 100, loss: 2.429767, top_1: 0.623398, top_k: 0.833672, samples/s: 806.316 1613326211.3382778
train: epoch 66, iter 200, loss: 2.277568, top_1: 0.625625, top_k: 0.833398, samples/s: 800.071 1613326243.3356442
train: epoch 66, iter 300, loss: 2.632813, top_1: 0.629297, top_k: 0.832852, samples/s: 785.082 1613326275.9435523
train: epoch 66, iter 400, loss: 2.467571, top_1: 0.622812, top_k: 0.836445, samples/s: 782.349 1613326308.6654477
train: epoch 66, iter 500, loss: 2.444444, top_1: 0.617695, top_k: 0.831602, samples/s: 784.351 1613326341.3038402
train: epoch 66, iter 600, loss: 2.448907, top_1: 0.617891, top_k: 0.833047, samples/s: 781.243 1613326374.0722682
train: epoch 66, iter 700, loss: 2.793325, top_1: 0.617734, top_k: 0.830352, samples/s: 781.401 1613326406.8339205
train: epoch 66, iter 800, loss: 2.566493, top_1: 0.623047, top_k: 0.831719, samples/s: 783.182 1613326439.5210764
train: epoch 66, iter 900, loss: 2.428901, top_1: 0.620625, top_k: 0.832187, samples/s: 779.659 1613326472.3559346
train: epoch 66, iter 1000, loss: 2.579148, top_1: 0.618867, top_k: 0.833008, samples/s: 783.854 1613326505.0150871
train: epoch 66, iter 1100, loss: 2.608916, top_1: 0.621914, top_k: 0.830508, samples/s: 784.398 1613326537.6514711
train: epoch 66, iter 1200, loss: 2.460711, top_1: 0.614609, top_k: 0.826953, samples/s: 781.581 1613326570.4056787
train: epoch 66, iter 1300, loss: 2.840889, top_1: 0.621836, top_k: 0.830156, samples/s: 782.069 1613326603.1393101
train: epoch 66, iter 1400, loss: 2.442698, top_1: 0.615039, top_k: 0.830820, samples/s: 784.262 1613326635.7815237
train: epoch 66, iter 1500, loss: 2.419662, top_1: 0.615703, top_k: 0.826094, samples/s: 782.634 1613326668.4915268
train: epoch 66, iter 1600, loss: 2.581972, top_1: 0.616836, top_k: 0.829648, samples/s: 783.080 1613326701.1829677
train: epoch 66, iter 1700, loss: 2.624016, top_1: 0.617734, top_k: 0.830859, samples/s: 783.828 1613326733.8432424
train: epoch 66, iter 1800, loss: 2.580666, top_1: 0.612109, top_k: 0.828516, samples/s: 781.952 1613326766.5817575
train: epoch 66, iter 1900, loss: 2.775009, top_1: 0.615664, top_k: 0.830977, samples/s: 784.714 1613326799.205134
train: epoch 66, iter 2000, loss: 2.589665, top_1: 0.622852, top_k: 0.828945, samples/s: 781.727 1613326831.9531064
train: epoch 66, iter 2100, loss: 2.488683, top_1: 0.612695, top_k: 0.828906, samples/s: 784.571 1613326864.5823407
train: epoch 66, iter 2200, loss: 2.741143, top_1: 0.615000, top_k: 0.831680, samples/s: 782.692 1613326897.290086
train: epoch 66, iter 2300, loss: 2.491252, top_1: 0.617656, top_k: 0.829922, samples/s: 783.776 1613326929.952385
train: epoch 66, iter 2400, loss: 2.665866, top_1: 0.617305, top_k: 0.827969, samples/s: 782.141 1613326962.6830926
train: epoch 66, iter 2500, loss: 2.585562, top_1: 0.617578, top_k: 0.827617, samples/s: 784.058 1613326995.3337119
train: epoch 66, iter 2600, loss: 2.640007, top_1: 0.613437, top_k: 0.828555, samples/s: 780.718 1613327028.1240199
train: epoch 66, iter 2700, loss: 2.614145, top_1: 0.610156, top_k: 0.825469, samples/s: 784.183 1613327060.769539
train: epoch 66, iter 2800, loss: 2.708737, top_1: 0.610859, top_k: 0.828242, samples/s: 782.488 1613327093.4856832
train: epoch 66, iter 2900, loss: 2.583208, top_1: 0.612422, top_k: 0.826758, samples/s: 785.270 1613327126.085998
train: epoch 66, iter 3000, loss: 2.629021, top_1: 0.616797, top_k: 0.828789, samples/s: 783.271 1613327158.7693777
train: epoch 66, iter 3100, loss: 2.424540, top_1: 0.610039, top_k: 0.826055, samples/s: 784.480 1613327191.4024277
train: epoch 66, iter 3200, loss: 2.646795, top_1: 0.615352, top_k: 0.829180, samples/s: 783.038 1613327224.095683
train: epoch 66, iter 3300, loss: 2.567132, top_1: 0.615586, top_k: 0.829258, samples/s: 784.246 1613327256.7384171
train: epoch 66, iter 3400, loss: 2.572717, top_1: 0.611797, top_k: 0.827695, samples/s: 785.104 1613327289.3455522
train: epoch 66, iter 3500, loss: 2.867943, top_1: 0.612734, top_k: 0.829453, samples/s: 785.076 1613327321.9539852
train: epoch 66, iter 3600, loss: 2.579351, top_1: 0.615664, top_k: 0.826523, samples/s: 781.901 1613327354.6946542
train: epoch 66, iter 3700, loss: 2.479345, top_1: 0.610313, top_k: 0.824141, samples/s: 785.722 1613327387.2762265
train: epoch 66, iter 3800, loss: 2.707208, top_1: 0.615273, top_k: 0.826797, samples/s: 782.413 1613327419.9954913
train: epoch 66, iter 3900, loss: 2.633102, top_1: 0.610000, top_k: 0.824961, samples/s: 783.181 1613327452.6826494
train: epoch 66, iter 4000, loss: 2.590925, top_1: 0.609570, top_k: 0.823242, samples/s: 785.364 1613327485.278935
train: epoch 66, iter 4100, loss: 2.652285, top_1: 0.609609, top_k: 0.825703, samples/s: 785.823 1613327517.856241
train: epoch 66, iter 4200, loss: 2.656462, top_1: 0.614570, top_k: 0.826953, samples/s: 785.333 1613327550.4540067
train: epoch 66, iter 4300, loss: 2.657884, top_1: 0.608320, top_k: 0.822812, samples/s: 784.976 1613327583.0664341
train: epoch 66, iter 4400, loss: 2.696123, top_1: 0.605977, top_k: 0.822734, samples/s: 785.222 1613327615.6686945
train: epoch 66, iter 4500, loss: 2.736228, top_1: 0.609609, top_k: 0.826602, samples/s: 784.709 1613327648.2922041
train: epoch 66, iter 4600, loss: 2.673811, top_1: 0.609922, top_k: 0.824375, samples/s: 785.817 1613327680.869816
train: epoch 66, iter 4700, loss: 2.542595, top_1: 0.613398, top_k: 0.830820, samples/s: 782.702 1613327713.5769784
train: epoch 66, iter 4800, loss: 2.653128, top_1: 0.617539, top_k: 0.827305, samples/s: 787.293 1613327746.09349
train: epoch 66, iter 4900, loss: 2.674918, top_1: 0.605664, top_k: 0.823984, samples/s: 785.872 1613327778.6688282
train: epoch 66, iter 5000, loss: 2.471397, top_1: 0.613516, top_k: 0.830117, samples/s: 783.546 1613327811.3406887
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_66.
validation: epoch 66, iter 195, top_1: 0.661238, top_k: 0.876002, samples/s: 2370.854 1613327833.3827891
train: epoch 67, iter 100, loss: 2.600620, top_1: 0.629805, top_k: 0.840391, samples/s: 801.136 1613327886.5391848
train: epoch 67, iter 200, loss: 2.600712, top_1: 0.619844, top_k: 0.833398, samples/s: 803.286 1613327918.408339
train: epoch 67, iter 300, loss: 2.576470, top_1: 0.616914, top_k: 0.829102, samples/s: 787.702 1613327950.90793
train: epoch 67, iter 400, loss: 2.366715, top_1: 0.621250, top_k: 0.837812, samples/s: 782.869 1613327983.6081488
train: epoch 67, iter 500, loss: 2.415563, top_1: 0.627500, top_k: 0.835000, samples/s: 782.608 1613328016.31926
train: epoch 67, iter 600, loss: 2.643327, top_1: 0.622109, top_k: 0.835352, samples/s: 782.782 1613328049.0231586
train: epoch 67, iter 700, loss: 2.491445, top_1: 0.623398, top_k: 0.828203, samples/s: 784.858 1613328081.6406145
train: epoch 67, iter 800, loss: 2.420076, top_1: 0.625078, top_k: 0.833984, samples/s: 785.232 1613328114.242394
train: epoch 67, iter 900, loss: 2.474894, top_1: 0.616992, top_k: 0.832812, samples/s: 781.569 1613328146.9970632
train: epoch 67, iter 1000, loss: 2.544080, top_1: 0.618398, top_k: 0.830820, samples/s: 783.130 1613328179.6862972
train: epoch 67, iter 1100, loss: 2.359770, top_1: 0.617227, top_k: 0.830547, samples/s: 784.016 1613328212.338804
train: epoch 67, iter 1200, loss: 2.589412, top_1: 0.620352, top_k: 0.832773, samples/s: 783.519 1613328245.0118253
train: epoch 67, iter 1300, loss: 2.639956, top_1: 0.623164, top_k: 0.828945, samples/s: 786.999 1613328277.540429
train: epoch 67, iter 1400, loss: 2.468183, top_1: 0.616484, top_k: 0.826914, samples/s: 785.794 1613328310.1190715
train: epoch 67, iter 1500, loss: 2.674239, top_1: 0.622617, top_k: 0.831836, samples/s: 784.218 1613328342.7630446
train: epoch 67, iter 1600, loss: 2.468836, top_1: 0.612578, top_k: 0.826836, samples/s: 785.459 1613328375.3554437
train: epoch 67, iter 1700, loss: 2.593731, top_1: 0.619922, top_k: 0.830937, samples/s: 784.385 1613328407.9924483
train: epoch 67, iter 1800, loss: 2.672713, top_1: 0.615430, top_k: 0.831836, samples/s: 788.081 1613328440.476378
train: epoch 67, iter 1900, loss: 2.539902, top_1: 0.621133, top_k: 0.833242, samples/s: 783.943 1613328473.1318355
train: epoch 67, iter 2000, loss: 2.629897, top_1: 0.618594, top_k: 0.830547, samples/s: 785.084 1613328505.7397366
train: epoch 67, iter 2100, loss: 2.566934, top_1: 0.621094, top_k: 0.829336, samples/s: 785.777 1613328538.3189354
train: epoch 67, iter 2200, loss: 2.436650, top_1: 0.618945, top_k: 0.829375, samples/s: 784.244 1613328570.961806
train: epoch 67, iter 2300, loss: 2.557596, top_1: 0.620352, top_k: 0.831758, samples/s: 783.776 1613328603.624257
train: epoch 67, iter 2400, loss: 2.579225, top_1: 0.617617, top_k: 0.837031, samples/s: 783.588 1613328636.2944117
train: epoch 67, iter 2500, loss: 2.639324, top_1: 0.615039, top_k: 0.830391, samples/s: 786.886 1613328668.8277924
train: epoch 67, iter 2600, loss: 2.440946, top_1: 0.620313, top_k: 0.828320, samples/s: 784.601 1613328701.45578
train: epoch 67, iter 2700, loss: 2.539309, top_1: 0.614219, top_k: 0.827070, samples/s: 784.488 1613328734.088576
train: epoch 67, iter 2800, loss: 2.531761, top_1: 0.614648, top_k: 0.826836, samples/s: 783.939 1613328766.7442605
train: epoch 67, iter 2900, loss: 2.568385, top_1: 0.612109, top_k: 0.823672, samples/s: 786.181 1613328799.3066223
train: epoch 67, iter 3000, loss: 2.512018, top_1: 0.621055, top_k: 0.833125, samples/s: 786.134 1613328831.8710482
train: epoch 67, iter 3100, loss: 2.614186, top_1: 0.616563, top_k: 0.826953, samples/s: 784.469 1613328864.504624
train: epoch 67, iter 3200, loss: 2.491719, top_1: 0.619062, top_k: 0.831484, samples/s: 784.344 1613328897.1434166
train: epoch 67, iter 3300, loss: 2.517895, top_1: 0.620352, top_k: 0.830547, samples/s: 784.205 1613328929.7878535
train: epoch 67, iter 3400, loss: 2.709559, top_1: 0.609922, top_k: 0.824727, samples/s: 784.318 1613328962.4277465
train: epoch 67, iter 3500, loss: 2.768069, top_1: 0.606797, top_k: 0.822109, samples/s: 785.608 1613328995.0139847
train: epoch 67, iter 3600, loss: 2.458355, top_1: 0.621094, top_k: 0.830977, samples/s: 785.340 1613329027.611239
train: epoch 67, iter 3700, loss: 2.544019, top_1: 0.612266, top_k: 0.822461, samples/s: 785.883 1613329060.1861572
train: epoch 67, iter 3800, loss: 2.849930, top_1: 0.613711, top_k: 0.826719, samples/s: 780.876 1613329092.9698353
train: epoch 67, iter 3900, loss: 2.497685, top_1: 0.611406, top_k: 0.825195, samples/s: 789.504 1613329125.3952293
train: epoch 67, iter 4000, loss: 2.588881, top_1: 0.617109, top_k: 0.830352, samples/s: 785.741 1613329157.9759998
train: epoch 67, iter 4100, loss: 2.588603, top_1: 0.608477, top_k: 0.824414, samples/s: 785.956 1613329190.5477784
train: epoch 67, iter 4200, loss: 2.765310, top_1: 0.617539, top_k: 0.830703, samples/s: 786.671 1613329223.089988
train: epoch 67, iter 4300, loss: 2.525459, top_1: 0.612656, top_k: 0.825469, samples/s: 784.755 1613329255.711623
train: epoch 67, iter 4400, loss: 2.438304, top_1: 0.612344, top_k: 0.829336, samples/s: 785.345 1613329288.308705
train: epoch 67, iter 4500, loss: 2.525919, top_1: 0.613945, top_k: 0.828359, samples/s: 784.695 1613329320.9329188
train: epoch 67, iter 4600, loss: 2.699591, top_1: 0.608945, top_k: 0.824883, samples/s: 784.884 1613329353.549154
train: epoch 67, iter 4700, loss: 2.507375, top_1: 0.610664, top_k: 0.828828, samples/s: 788.615 1613329386.0112147
train: epoch 67, iter 4800, loss: 2.629039, top_1: 0.610234, top_k: 0.826719, samples/s: 783.528 1613329418.6839483
train: epoch 67, iter 4900, loss: 2.468371, top_1: 0.610156, top_k: 0.824258, samples/s: 786.455 1613329451.2349932
train: epoch 67, iter 5000, loss: 2.492309, top_1: 0.614766, top_k: 0.829063, samples/s: 785.173 1613329483.8393276
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_67.
validation: epoch 67, iter 195, top_1: 0.669231, top_k: 0.880288, samples/s: 2361.196 1613329506.0201325
train: epoch 68, iter 100, loss: 2.726582, top_1: 0.629727, top_k: 0.839961, samples/s: 805.995 1613329558.4827278
train: epoch 68, iter 200, loss: 2.638762, top_1: 0.620117, top_k: 0.834258, samples/s: 801.272 1613329590.432108
train: epoch 68, iter 300, loss: 2.544270, top_1: 0.630391, top_k: 0.834570, samples/s: 789.876 1613329622.8420196
train: epoch 68, iter 400, loss: 2.527080, top_1: 0.620664, top_k: 0.835078, samples/s: 780.776 1613329655.629891
train: epoch 68, iter 500, loss: 2.651248, top_1: 0.628945, top_k: 0.836602, samples/s: 784.571 1613329688.259213
train: epoch 68, iter 600, loss: 2.489661, top_1: 0.629180, top_k: 0.837461, samples/s: 783.524 1613329720.9320931
train: epoch 68, iter 700, loss: 2.596854, top_1: 0.621445, top_k: 0.832148, samples/s: 784.189 1613329753.577238
train: epoch 68, iter 800, loss: 2.456799, top_1: 0.618984, top_k: 0.832891, samples/s: 783.670 1613329786.244236
train: epoch 68, iter 900, loss: 2.517683, top_1: 0.622773, top_k: 0.836797, samples/s: 783.725 1613329818.9089825
train: epoch 68, iter 1000, loss: 2.436581, top_1: 0.621133, top_k: 0.834688, samples/s: 785.938 1613329851.4812152
train: epoch 68, iter 1100, loss: 2.455149, top_1: 0.621133, top_k: 0.831055, samples/s: 784.239 1613329884.1243517
train: epoch 68, iter 1200, loss: 2.688922, top_1: 0.615742, top_k: 0.832578, samples/s: 782.957 1613329916.8209429
train: epoch 68, iter 1300, loss: 2.680364, top_1: 0.621875, top_k: 0.829727, samples/s: 785.594 1613329949.4079628
train: epoch 68, iter 1400, loss: 2.637664, top_1: 0.614336, top_k: 0.827461, samples/s: 782.990 1613329982.1027753
train: epoch 68, iter 1500, loss: 2.395270, top_1: 0.627578, top_k: 0.837266, samples/s: 784.401 1613330014.7392464
train: epoch 68, iter 1600, loss: 2.517397, top_1: 0.621094, top_k: 0.832578, samples/s: 783.574 1613330047.4099755
train: epoch 68, iter 1700, loss: 2.722534, top_1: 0.622930, top_k: 0.833008, samples/s: 781.438 1613330080.1701882
train: epoch 68, iter 1800, loss: 2.521818, top_1: 0.623359, top_k: 0.833438, samples/s: 784.728 1613330112.7929008
train: epoch 68, iter 1900, loss: 2.490115, top_1: 0.617852, top_k: 0.830430, samples/s: 783.298 1613330145.4756947
train: epoch 68, iter 2000, loss: 2.613442, top_1: 0.612187, top_k: 0.826367, samples/s: 783.754 1613330178.1385012
train: epoch 68, iter 2100, loss: 2.577901, top_1: 0.612461, top_k: 0.829141, samples/s: 783.585 1613330210.8092055
train: epoch 68, iter 2200, loss: 2.570881, top_1: 0.613867, top_k: 0.827695, samples/s: 783.440 1613330243.4852703
train: epoch 68, iter 2300, loss: 2.405946, top_1: 0.619727, top_k: 0.832305, samples/s: 781.175 1613330276.2564914
train: epoch 68, iter 2400, loss: 2.452056, top_1: 0.616328, top_k: 0.828086, samples/s: 784.718 1613330308.8796127
train: epoch 68, iter 2500, loss: 2.506837, top_1: 0.619062, top_k: 0.830234, samples/s: 784.063 1613330341.5301101
train: epoch 68, iter 2600, loss: 2.667066, top_1: 0.615859, top_k: 0.827812, samples/s: 785.606 1613330374.116389
train: epoch 68, iter 2700, loss: 2.442504, top_1: 0.615156, top_k: 0.826680, samples/s: 783.892 1613330406.7740316
train: epoch 68, iter 2800, loss: 2.517327, top_1: 0.622148, top_k: 0.833633, samples/s: 784.164 1613330439.4202092
train: epoch 68, iter 2900, loss: 2.630260, top_1: 0.617969, top_k: 0.831133, samples/s: 784.061 1613330472.0707674
train: epoch 68, iter 3000, loss: 2.616057, top_1: 0.620859, top_k: 0.831328, samples/s: 785.541 1613330504.659709
train: epoch 68, iter 3100, loss: 2.559944, top_1: 0.616602, top_k: 0.828398, samples/s: 785.440 1613330537.25296
train: epoch 68, iter 3200, loss: 2.479040, top_1: 0.620508, top_k: 0.831406, samples/s: 785.319 1613330569.8512096
train: epoch 68, iter 3300, loss: 2.605166, top_1: 0.618281, top_k: 0.826758, samples/s: 783.879 1613330602.5097015
train: epoch 68, iter 3400, loss: 2.380045, top_1: 0.615508, top_k: 0.832187, samples/s: 785.623 1613330635.0948021
train: epoch 68, iter 3500, loss: 2.607614, top_1: 0.612891, top_k: 0.831484, samples/s: 781.902 1613330667.8354766
train: epoch 68, iter 3600, loss: 2.574911, top_1: 0.614766, top_k: 0.823320, samples/s: 785.386 1613330700.4309404
train: epoch 68, iter 3700, loss: 2.412419, top_1: 0.617266, top_k: 0.830352, samples/s: 783.377 1613330733.1100354
train: epoch 68, iter 3800, loss: 2.441345, top_1: 0.620391, top_k: 0.830820, samples/s: 785.285 1613330765.709557
train: epoch 68, iter 3900, loss: 2.651669, top_1: 0.620781, top_k: 0.829531, samples/s: 785.764 1613330798.2897725
train: epoch 68, iter 4000, loss: 2.656810, top_1: 0.614766, top_k: 0.826328, samples/s: 784.693 1613330830.913604
train: epoch 68, iter 4100, loss: 2.660327, top_1: 0.613789, top_k: 0.828164, samples/s: 785.174 1613330863.517775
train: epoch 68, iter 4200, loss: 2.595037, top_1: 0.613516, top_k: 0.824688, samples/s: 782.255 1613330896.2436318
train: epoch 68, iter 4300, loss: 2.640027, top_1: 0.613398, top_k: 0.825742, samples/s: 785.045 1613330928.853226
train: epoch 68, iter 4400, loss: 2.536704, top_1: 0.609961, top_k: 0.824141, samples/s: 783.390 1613330961.5318542
train: epoch 68, iter 4500, loss: 2.441656, top_1: 0.619531, top_k: 0.828242, samples/s: 786.132 1613330994.096223
train: epoch 68, iter 4600, loss: 2.602550, top_1: 0.617539, top_k: 0.825195, samples/s: 786.472 1613331026.6467052
train: epoch 68, iter 4700, loss: 2.604918, top_1: 0.615703, top_k: 0.827500, samples/s: 784.669 1613331059.2718532
train: epoch 68, iter 4800, loss: 2.612562, top_1: 0.617188, top_k: 0.826094, samples/s: 786.508 1613331091.820858
train: epoch 68, iter 4900, loss: 2.502404, top_1: 0.613945, top_k: 0.825156, samples/s: 784.339 1613331124.4597917
train: epoch 68, iter 5000, loss: 2.682189, top_1: 0.624023, top_k: 0.832344, samples/s: 784.668 1613331157.0850003
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_68.
validation: epoch 68, iter 195, top_1: 0.668730, top_k: 0.881070, samples/s: 2362.820 1613331179.1849918
train: epoch 69, iter 100, loss: 2.883533, top_1: 0.636836, top_k: 0.840273, samples/s: 804.121 1613331231.5670452
train: epoch 69, iter 200, loss: 2.458043, top_1: 0.639648, top_k: 0.843594, samples/s: 800.543 1613331263.545651
train: epoch 69, iter 300, loss: 2.412400, top_1: 0.629766, top_k: 0.838633, samples/s: 787.556 1613331296.0510192
train: epoch 69, iter 400, loss: 2.603674, top_1: 0.625195, top_k: 0.836836, samples/s: 784.993 1613331328.662795
train: epoch 69, iter 500, loss: 2.468118, top_1: 0.622383, top_k: 0.832227, samples/s: 783.569 1613331361.3337336
train: epoch 69, iter 600, loss: 2.578798, top_1: 0.631445, top_k: 0.838711, samples/s: 783.687 1613331393.9998636
train: epoch 69, iter 700, loss: 2.560864, top_1: 0.624180, top_k: 0.832891, samples/s: 783.713 1613331426.6648545
train: epoch 69, iter 800, loss: 2.514096, top_1: 0.626211, top_k: 0.833555, samples/s: 783.230 1613331459.3500524
train: epoch 69, iter 900, loss: 2.501559, top_1: 0.623477, top_k: 0.832656, samples/s: 783.029 1613331492.0436168
train: epoch 69, iter 1000, loss: 2.688792, top_1: 0.624219, top_k: 0.834219, samples/s: 784.403 1613331524.6799068
train: epoch 69, iter 1100, loss: 2.637672, top_1: 0.617422, top_k: 0.830859, samples/s: 785.108 1613331557.2868412
train: epoch 69, iter 1200, loss: 2.524896, top_1: 0.623594, top_k: 0.832969, samples/s: 783.138 1613331589.975825
train: epoch 69, iter 1300, loss: 2.804528, top_1: 0.620977, top_k: 0.833711, samples/s: 784.783 1613331622.5963695
train: epoch 69, iter 1400, loss: 2.330054, top_1: 0.620313, top_k: 0.832656, samples/s: 785.032 1613331655.2063928
train: epoch 69, iter 1500, loss: 2.427846, top_1: 0.618242, top_k: 0.835313, samples/s: 785.908 1613331687.7802188
train: epoch 69, iter 1600, loss: 2.523563, top_1: 0.619648, top_k: 0.830469, samples/s: 784.283 1613331720.4215403
train: epoch 69, iter 1700, loss: 2.697752, top_1: 0.626172, top_k: 0.830898, samples/s: 787.011 1613331752.9496324
train: epoch 69, iter 1800, loss: 2.527371, top_1: 0.616406, top_k: 0.829570, samples/s: 782.852 1613331785.6506279
train: epoch 69, iter 1900, loss: 2.630662, top_1: 0.612383, top_k: 0.828945, samples/s: 786.948 1613331818.1813836
train: epoch 69, iter 2000, loss: 2.496762, top_1: 0.622188, top_k: 0.830547, samples/s: 784.516 1613331850.8129241
train: epoch 69, iter 2100, loss: 2.519636, top_1: 0.617891, top_k: 0.829375, samples/s: 784.378 1613331883.4503243
train: epoch 69, iter 2200, loss: 2.547760, top_1: 0.615977, top_k: 0.828203, samples/s: 784.683 1613331916.0749762
train: epoch 69, iter 2300, loss: 2.563378, top_1: 0.615703, top_k: 0.827969, samples/s: 784.979 1613331948.6872559
train: epoch 69, iter 2400, loss: 2.607393, top_1: 0.613789, top_k: 0.828984, samples/s: 784.109 1613331981.3358884
train: epoch 69, iter 2500, loss: 2.514117, top_1: 0.622344, top_k: 0.831836, samples/s: 785.959 1613332013.9074547
train: epoch 69, iter 2600, loss: 2.468373, top_1: 0.623359, top_k: 0.831367, samples/s: 784.348 1613332046.5460796
train: epoch 69, iter 2700, loss: 2.708571, top_1: 0.621289, top_k: 0.832148, samples/s: 784.766 1613332079.167205
train: epoch 69, iter 2800, loss: 2.715404, top_1: 0.616172, top_k: 0.827695, samples/s: 784.797 1613332111.7871046
train: epoch 69, iter 2900, loss: 2.478306, top_1: 0.619219, top_k: 0.831016, samples/s: 787.652 1613332144.288724
train: epoch 69, iter 3000, loss: 2.584242, top_1: 0.613828, top_k: 0.825313, samples/s: 785.877 1613332176.8638449
train: epoch 69, iter 3100, loss: 2.608607, top_1: 0.612695, top_k: 0.828242, samples/s: 783.889 1613332209.5214736
train: epoch 69, iter 3200, loss: 2.628475, top_1: 0.612266, top_k: 0.827773, samples/s: 783.711 1613332242.1867316
train: epoch 69, iter 3300, loss: 2.665962, top_1: 0.614141, top_k: 0.828320, samples/s: 783.984 1613332274.8404846
train: epoch 69, iter 3400, loss: 2.643801, top_1: 0.617227, top_k: 0.828789, samples/s: 783.981 1613332307.4942923
train: epoch 69, iter 3500, loss: 2.433794, top_1: 0.618086, top_k: 0.833867, samples/s: 783.444 1613332340.1704183
train: epoch 69, iter 3600, loss: 2.632298, top_1: 0.616172, top_k: 0.828828, samples/s: 785.799 1613332372.7487457
train: epoch 69, iter 3700, loss: 2.677603, top_1: 0.617578, top_k: 0.829336, samples/s: 785.000 1613332405.3602486
train: epoch 69, iter 3800, loss: 2.488201, top_1: 0.618008, top_k: 0.830391, samples/s: 784.347 1613332437.9988708
train: epoch 69, iter 3900, loss: 2.578483, top_1: 0.617188, top_k: 0.828594, samples/s: 783.829 1613332470.6589713
train: epoch 69, iter 4000, loss: 2.372565, top_1: 0.619805, top_k: 0.831641, samples/s: 786.749 1613332503.1979547
train: epoch 69, iter 4100, loss: 2.588368, top_1: 0.619570, top_k: 0.829141, samples/s: 786.304 1613332535.7553098
train: epoch 69, iter 4200, loss: 2.513851, top_1: 0.614883, top_k: 0.828398, samples/s: 784.180 1613332568.4008965
train: epoch 69, iter 4300, loss: 2.619729, top_1: 0.618828, top_k: 0.828906, samples/s: 786.092 1613332600.9670622
train: epoch 69, iter 4400, loss: 2.580057, top_1: 0.615625, top_k: 0.826055, samples/s: 783.372 1613332633.6464212
train: epoch 69, iter 4500, loss: 2.500906, top_1: 0.616953, top_k: 0.832344, samples/s: 787.993 1613332666.1339302
train: epoch 69, iter 4600, loss: 2.487750, top_1: 0.611992, top_k: 0.826562, samples/s: 782.887 1613332698.8334222
train: epoch 69, iter 4700, loss: 2.490760, top_1: 0.619883, top_k: 0.828516, samples/s: 784.721 1613332731.4565156
train: epoch 69, iter 4800, loss: 2.747794, top_1: 0.610781, top_k: 0.822031, samples/s: 785.075 1613332764.0648508
train: epoch 69, iter 4900, loss: 2.503004, top_1: 0.613437, top_k: 0.829063, samples/s: 784.658 1613332796.690581
train: epoch 69, iter 5000, loss: 2.396959, top_1: 0.619141, top_k: 0.834102, samples/s: 785.296 1613332829.2896583
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_69.
validation: epoch 69, iter 195, top_1: 0.665004, top_k: 0.879467, samples/s: 2368.456 1613332851.3804476
train: epoch 70, iter 100, loss: 2.687088, top_1: 0.631719, top_k: 0.842070, samples/s: 803.891 1613332903.973641
train: epoch 70, iter 200, loss: 2.358652, top_1: 0.629883, top_k: 0.838359, samples/s: 800.601 1613332935.9496424
train: epoch 70, iter 300, loss: 2.520530, top_1: 0.637344, top_k: 0.843086, samples/s: 787.072 1613332968.4751909
train: epoch 70, iter 400, loss: 2.602722, top_1: 0.626016, top_k: 0.838320, samples/s: 783.688 1613333001.141264
train: epoch 70, iter 500, loss: 2.404839, top_1: 0.623125, top_k: 0.833398, samples/s: 782.480 1613333033.8576696
train: epoch 70, iter 600, loss: 2.746153, top_1: 0.626914, top_k: 0.835430, samples/s: 784.480 1613333066.4907303
train: epoch 70, iter 700, loss: 2.501981, top_1: 0.630117, top_k: 0.838359, samples/s: 782.106 1613333099.2229743
train: epoch 70, iter 800, loss: 2.485651, top_1: 0.625469, top_k: 0.837031, samples/s: 784.090 1613333131.87223
train: epoch 70, iter 900, loss: 2.593056, top_1: 0.622344, top_k: 0.834414, samples/s: 782.484 1613333164.588547
train: epoch 70, iter 1000, loss: 2.450662, top_1: 0.624297, top_k: 0.838359, samples/s: 782.748 1613333197.2938778
train: epoch 70, iter 1100, loss: 2.668606, top_1: 0.623281, top_k: 0.835703, samples/s: 783.728 1613333229.9582927
train: epoch 70, iter 1200, loss: 2.376825, top_1: 0.628164, top_k: 0.834102, samples/s: 783.900 1613333262.6154373
train: epoch 70, iter 1300, loss: 2.438235, top_1: 0.626797, top_k: 0.838047, samples/s: 784.134 1613333295.2629242
train: epoch 70, iter 1400, loss: 2.409676, top_1: 0.618867, top_k: 0.830313, samples/s: 783.110 1613333327.9531512
train: epoch 70, iter 1500, loss: 2.593119, top_1: 0.623008, top_k: 0.831641, samples/s: 784.243 1613333360.5960586
train: epoch 70, iter 1600, loss: 2.685457, top_1: 0.622852, top_k: 0.832812, samples/s: 785.248 1613333393.19721
train: epoch 70, iter 1700, loss: 2.683249, top_1: 0.623516, top_k: 0.838047, samples/s: 784.906 1613333425.812572
train: epoch 70, iter 1800, loss: 2.780119, top_1: 0.620273, top_k: 0.831367, samples/s: 784.403 1613333458.4490278
train: epoch 70, iter 1900, loss: 2.420540, top_1: 0.618125, top_k: 0.830078, samples/s: 783.738 1613333491.112938
train: epoch 70, iter 2000, loss: 2.507247, top_1: 0.618242, top_k: 0.829375, samples/s: 784.731 1613333523.7355018
train: epoch 70, iter 2100, loss: 2.581358, top_1: 0.621133, top_k: 0.834844, samples/s: 784.132 1613333556.3831332
train: epoch 70, iter 2200, loss: 2.442452, top_1: 0.621328, top_k: 0.831445, samples/s: 784.057 1613333589.0338638
train: epoch 70, iter 2300, loss: 2.468613, top_1: 0.620430, top_k: 0.831758, samples/s: 785.811 1613333621.61159
train: epoch 70, iter 2400, loss: 2.418067, top_1: 0.623398, top_k: 0.834922, samples/s: 785.297 1613333654.2106826
train: epoch 70, iter 2500, loss: 2.614299, top_1: 0.620117, top_k: 0.832148, samples/s: 784.610 1613333686.8383512
train: epoch 70, iter 2600, loss: 2.625959, top_1: 0.625039, top_k: 0.836016, samples/s: 785.264 1613333719.438922
train: epoch 70, iter 2700, loss: 2.546704, top_1: 0.621641, top_k: 0.830078, samples/s: 786.831 1613333751.9744565
train: epoch 70, iter 2800, loss: 2.657497, top_1: 0.617383, top_k: 0.833398, samples/s: 783.036 1613333784.6677883
train: epoch 70, iter 2900, loss: 2.618089, top_1: 0.614297, top_k: 0.828555, samples/s: 786.824 1613333817.2036626
train: epoch 70, iter 3000, loss: 2.602482, top_1: 0.618633, top_k: 0.828164, samples/s: 783.305 1613333849.8856938
train: epoch 70, iter 3100, loss: 2.502645, top_1: 0.610781, top_k: 0.827422, samples/s: 784.723 1613333882.5086396
train: epoch 70, iter 3200, loss: 2.449672, top_1: 0.617656, top_k: 0.824609, samples/s: 784.618 1613333915.1359632
train: epoch 70, iter 3300, loss: 2.628586, top_1: 0.619219, top_k: 0.830742, samples/s: 785.776 1613333947.7152107
train: epoch 70, iter 3400, loss: 2.561713, top_1: 0.618477, top_k: 0.828047, samples/s: 784.273 1613333980.3568616
train: epoch 70, iter 3500, loss: 2.640946, top_1: 0.618594, top_k: 0.829766, samples/s: 784.118 1613334013.0051541
train: epoch 70, iter 3600, loss: 2.508180, top_1: 0.615078, top_k: 0.830273, samples/s: 785.127 1613334045.6113346
train: epoch 70, iter 3700, loss: 2.510912, top_1: 0.619766, top_k: 0.831016, samples/s: 783.362 1613334078.2909863
train: epoch 70, iter 3800, loss: 2.538067, top_1: 0.616250, top_k: 0.827070, samples/s: 784.317 1613334110.930776
train: epoch 70, iter 3900, loss: 2.640935, top_1: 0.615195, top_k: 0.827070, samples/s: 783.356 1613334143.6107025
train: epoch 70, iter 4000, loss: 2.696807, top_1: 0.619062, top_k: 0.829141, samples/s: 784.171 1613334176.2566352
train: epoch 70, iter 4100, loss: 2.272600, top_1: 0.617305, top_k: 0.830313, samples/s: 784.192 1613334208.9016697
train: epoch 70, iter 4200, loss: 2.601536, top_1: 0.620547, top_k: 0.828203, samples/s: 782.276 1613334241.6267989
train: epoch 70, iter 4300, loss: 2.458553, top_1: 0.617461, top_k: 0.826289, samples/s: 786.735 1613334274.1663437
train: epoch 70, iter 4400, loss: 2.605970, top_1: 0.613203, top_k: 0.828086, samples/s: 783.751 1613334306.829675
train: epoch 70, iter 4500, loss: 2.812301, top_1: 0.613867, top_k: 0.828984, samples/s: 783.209 1613334339.5158153
train: epoch 70, iter 4600, loss: 2.573868, top_1: 0.619102, top_k: 0.832734, samples/s: 785.834 1613334372.0926063
train: epoch 70, iter 4700, loss: 2.386544, top_1: 0.615313, top_k: 0.826719, samples/s: 785.709 1613334404.674637
train: epoch 70, iter 4800, loss: 2.597071, top_1: 0.617031, top_k: 0.830586, samples/s: 784.224 1613334437.3184257
train: epoch 70, iter 4900, loss: 2.535020, top_1: 0.617930, top_k: 0.829922, samples/s: 785.125 1613334469.924656
train: epoch 70, iter 5000, loss: 2.603350, top_1: 0.621680, top_k: 0.832852, samples/s: 785.341 1613334502.5219934
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_70.
validation: epoch 70, iter 195, top_1: 0.667969, top_k: 0.880268, samples/s: 2333.443 1613334524.8803062
train: epoch 71, iter 100, loss: 2.622081, top_1: 0.632539, top_k: 0.840000, samples/s: 804.999 1613334576.930238
train: epoch 71, iter 200, loss: 2.650929, top_1: 0.630234, top_k: 0.837266, samples/s: 801.131 1613334608.885324
train: epoch 71, iter 300, loss: 2.725704, top_1: 0.629687, top_k: 0.838125, samples/s: 787.332 1613334641.400002
train: epoch 71, iter 400, loss: 2.426736, top_1: 0.631289, top_k: 0.839648, samples/s: 785.079 1613334674.008208
train: epoch 71, iter 500, loss: 2.599185, top_1: 0.632930, top_k: 0.839531, samples/s: 783.342 1613334706.6887262
train: epoch 71, iter 600, loss: 2.567936, top_1: 0.632109, top_k: 0.839297, samples/s: 784.594 1613334739.3169549
train: epoch 71, iter 700, loss: 2.505873, top_1: 0.629492, top_k: 0.837734, samples/s: 783.248 1613334772.0014036
train: epoch 71, iter 800, loss: 2.418734, top_1: 0.628594, top_k: 0.834453, samples/s: 783.120 1613334804.691226
train: epoch 71, iter 900, loss: 2.366670, top_1: 0.622383, top_k: 0.832227, samples/s: 782.150 1613334837.421425
train: epoch 71, iter 1000, loss: 2.554638, top_1: 0.623242, top_k: 0.832852, samples/s: 780.350 1613334870.227199
train: epoch 71, iter 1100, loss: 2.578016, top_1: 0.625313, top_k: 0.835664, samples/s: 786.656 1613334902.7701156
train: epoch 71, iter 1200, loss: 2.627037, top_1: 0.628008, top_k: 0.836875, samples/s: 783.678 1613334935.4365637
train: epoch 71, iter 1300, loss: 2.509765, top_1: 0.632812, top_k: 0.836719, samples/s: 783.446 1613334968.1126728
train: epoch 71, iter 1400, loss: 2.605156, top_1: 0.623008, top_k: 0.833438, samples/s: 784.888 1613335000.728853
train: epoch 71, iter 1500, loss: 2.591648, top_1: 0.621133, top_k: 0.833828, samples/s: 783.889 1613335033.3865123
train: epoch 71, iter 1600, loss: 2.441014, top_1: 0.621641, top_k: 0.833984, samples/s: 784.394 1613335066.0232027
train: epoch 71, iter 1700, loss: 2.554953, top_1: 0.623086, top_k: 0.834531, samples/s: 784.333 1613335098.6623814
train: epoch 71, iter 1800, loss: 2.408113, top_1: 0.626836, top_k: 0.834297, samples/s: 783.340 1613335131.3429213
train: epoch 71, iter 1900, loss: 2.559495, top_1: 0.625039, top_k: 0.834961, samples/s: 784.659 1613335163.968594
train: epoch 71, iter 2000, loss: 2.457261, top_1: 0.627617, top_k: 0.835391, samples/s: 785.585 1613335196.555775
train: epoch 71, iter 2100, loss: 2.472019, top_1: 0.623086, top_k: 0.832812, samples/s: 783.387 1613335229.234446
train: epoch 71, iter 2200, loss: 2.807135, top_1: 0.623164, top_k: 0.831953, samples/s: 785.218 1613335261.83671
train: epoch 71, iter 2300, loss: 2.537109, top_1: 0.625273, top_k: 0.834258, samples/s: 784.759 1613335294.4582815
train: epoch 71, iter 2400, loss: 2.492478, top_1: 0.624453, top_k: 0.836328, samples/s: 783.035 1613335327.15155
train: epoch 71, iter 2500, loss: 2.569649, top_1: 0.618711, top_k: 0.829570, samples/s: 784.445 1613335359.7860222
train: epoch 71, iter 2600, loss: 2.538906, top_1: 0.623867, top_k: 0.834219, samples/s: 783.769 1613335392.44876
train: epoch 71, iter 2700, loss: 2.390850, top_1: 0.617773, top_k: 0.827383, samples/s: 785.154 1613335425.0538192
train: epoch 71, iter 2800, loss: 2.643934, top_1: 0.615547, top_k: 0.829609, samples/s: 784.804 1613335457.673355
train: epoch 71, iter 2900, loss: 2.551191, top_1: 0.618828, top_k: 0.834766, samples/s: 786.041 1613335490.2416008
train: epoch 71, iter 3000, loss: 2.435152, top_1: 0.624922, top_k: 0.832344, samples/s: 783.512 1613335522.9150164
train: epoch 71, iter 3100, loss: 2.551634, top_1: 0.616953, top_k: 0.830078, samples/s: 785.083 1613335555.5230114
train: epoch 71, iter 3200, loss: 2.360690, top_1: 0.619609, top_k: 0.829531, samples/s: 782.468 1613335588.2400918
train: epoch 71, iter 3300, loss: 2.479843, top_1: 0.617578, top_k: 0.832539, samples/s: 784.670 1613335620.865199
train: epoch 71, iter 3400, loss: 2.521293, top_1: 0.613125, top_k: 0.825937, samples/s: 784.717 1613335653.488389
train: epoch 71, iter 3500, loss: 2.517347, top_1: 0.615391, top_k: 0.829414, samples/s: 784.402 1613335686.1247554
train: epoch 71, iter 3600, loss: 2.565957, top_1: 0.624570, top_k: 0.835117, samples/s: 784.453 1613335718.7589474
train: epoch 71, iter 3700, loss: 2.464180, top_1: 0.616836, top_k: 0.831719, samples/s: 784.248 1613335751.4016297
train: epoch 71, iter 3800, loss: 2.534194, top_1: 0.617891, top_k: 0.830859, samples/s: 787.402 1613335783.9136162
train: epoch 71, iter 3900, loss: 2.679254, top_1: 0.616250, top_k: 0.828945, samples/s: 780.933 1613335816.6950512
train: epoch 71, iter 4000, loss: 2.690003, top_1: 0.620234, top_k: 0.832852, samples/s: 783.118 1613335849.384801
train: epoch 71, iter 4100, loss: 2.666292, top_1: 0.620352, top_k: 0.837031, samples/s: 784.806 1613335882.0043988
train: epoch 71, iter 4200, loss: 2.461889, top_1: 0.618633, top_k: 0.826758, samples/s: 785.245 1613335914.6056805
train: epoch 71, iter 4300, loss: 2.632308, top_1: 0.623281, top_k: 0.831484, samples/s: 783.803 1613335947.2668452
train: epoch 71, iter 4400, loss: 2.601730, top_1: 0.620117, top_k: 0.831211, samples/s: 784.162 1613335979.9132302
train: epoch 71, iter 4500, loss: 2.519456, top_1: 0.619805, top_k: 0.830391, samples/s: 784.708 1613336012.536786
train: epoch 71, iter 4600, loss: 2.575762, top_1: 0.621563, top_k: 0.830742, samples/s: 781.406 1613336045.2982914
train: epoch 71, iter 4700, loss: 2.625875, top_1: 0.621367, top_k: 0.830742, samples/s: 785.077 1613336077.9065676
train: epoch 71, iter 4800, loss: 2.583536, top_1: 0.617383, top_k: 0.828008, samples/s: 784.205 1613336110.5509996
train: epoch 71, iter 4900, loss: 2.629017, top_1: 0.614609, top_k: 0.828438, samples/s: 784.255 1613336143.1935635
train: epoch 71, iter 5000, loss: 2.337201, top_1: 0.615664, top_k: 0.827422, samples/s: 785.939 1613336175.7660134
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_71.
validation: epoch 71, iter 195, top_1: 0.671074, top_k: 0.881671, samples/s: 2331.770 1613336198.139152
train: epoch 72, iter 100, loss: 2.486900, top_1: 0.627852, top_k: 0.839375, samples/s: 805.032 1613336255.825959
train: epoch 72, iter 200, loss: 2.493315, top_1: 0.632500, top_k: 0.842031, samples/s: 799.726 1613336287.8367865
train: epoch 72, iter 300, loss: 2.274941, top_1: 0.633594, top_k: 0.843789, samples/s: 792.221 1613336320.1509752
train: epoch 72, iter 400, loss: 2.517847, top_1: 0.628750, top_k: 0.840273, samples/s: 781.755 1613336352.8979828
train: epoch 72, iter 500, loss: 2.540143, top_1: 0.628242, top_k: 0.835156, samples/s: 784.599 1613336385.5259924
train: epoch 72, iter 600, loss: 2.747571, top_1: 0.632773, top_k: 0.838477, samples/s: 781.313 1613336418.2913542
train: epoch 72, iter 700, loss: 2.549605, top_1: 0.628047, top_k: 0.839453, samples/s: 785.263 1613336450.891833
train: epoch 72, iter 800, loss: 2.557575, top_1: 0.628008, top_k: 0.837695, samples/s: 782.842 1613336483.5933232
train: epoch 72, iter 900, loss: 2.466821, top_1: 0.628008, top_k: 0.837266, samples/s: 782.548 1613336516.3069627
train: epoch 72, iter 1000, loss: 2.394729, top_1: 0.625703, top_k: 0.839375, samples/s: 782.891 1613336549.0061796
train: epoch 72, iter 1100, loss: 2.400999, top_1: 0.626836, top_k: 0.837617, samples/s: 785.298 1613336581.605267
train: epoch 72, iter 1200, loss: 2.481300, top_1: 0.631250, top_k: 0.837773, samples/s: 782.859 1613336614.3059945
train: epoch 72, iter 1300, loss: 2.403463, top_1: 0.631172, top_k: 0.836445, samples/s: 784.264 1613336646.9480515
train: epoch 72, iter 1400, loss: 2.587738, top_1: 0.630000, top_k: 0.837070, samples/s: 782.348 1613336679.6701176
train: epoch 72, iter 1500, loss: 2.375779, top_1: 0.630703, top_k: 0.838164, samples/s: 784.571 1613336712.2993646
train: epoch 72, iter 1600, loss: 2.554313, top_1: 0.625195, top_k: 0.839844, samples/s: 782.537 1613336745.013543
train: epoch 72, iter 1700, loss: 2.502414, top_1: 0.626016, top_k: 0.835742, samples/s: 783.310 1613336777.6953728
train: epoch 72, iter 1800, loss: 2.705694, top_1: 0.627578, top_k: 0.834727, samples/s: 784.402 1613336810.3316507
train: epoch 72, iter 1900, loss: 2.629359, top_1: 0.622695, top_k: 0.832734, samples/s: 782.664 1613336843.040448
train: epoch 72, iter 2000, loss: 2.762656, top_1: 0.627500, top_k: 0.836914, samples/s: 783.604 1613336875.7100453
train: epoch 72, iter 2100, loss: 2.523394, top_1: 0.623555, top_k: 0.835703, samples/s: 783.402 1613336908.3880634
train: epoch 72, iter 2200, loss: 2.488886, top_1: 0.620195, top_k: 0.831641, samples/s: 784.285 1613336941.0292678
train: epoch 72, iter 2300, loss: 2.540260, top_1: 0.620430, top_k: 0.831172, samples/s: 783.649 1613336973.6968477
train: epoch 72, iter 2400, loss: 2.569615, top_1: 0.625000, top_k: 0.834219, samples/s: 784.277 1613337006.3383741
train: epoch 72, iter 2500, loss: 2.689029, top_1: 0.620000, top_k: 0.835859, samples/s: 783.858 1613337038.997374
train: epoch 72, iter 2600, loss: 2.577787, top_1: 0.618906, top_k: 0.833047, samples/s: 784.177 1613337071.643143
train: epoch 72, iter 2700, loss: 2.341129, top_1: 0.628750, top_k: 0.836445, samples/s: 783.197 1613337104.3300354
train: epoch 72, iter 2800, loss: 2.514287, top_1: 0.625703, top_k: 0.838984, samples/s: 783.980 1613337136.983601
train: epoch 72, iter 2900, loss: 2.470138, top_1: 0.617188, top_k: 0.829219, samples/s: 785.156 1613337169.5889072
train: epoch 72, iter 3000, loss: 2.535861, top_1: 0.624414, top_k: 0.837187, samples/s: 786.999 1613337202.1172967
train: epoch 72, iter 3100, loss: 2.577384, top_1: 0.619570, top_k: 0.829961, samples/s: 780.087 1613337234.9341438
train: epoch 72, iter 3200, loss: 2.597721, top_1: 0.619805, top_k: 0.830195, samples/s: 785.158 1613337267.538908
train: epoch 72, iter 3300, loss: 2.588230, top_1: 0.623203, top_k: 0.836250, samples/s: 783.313 1613337300.2205877
train: epoch 72, iter 3400, loss: 2.607076, top_1: 0.618398, top_k: 0.830156, samples/s: 784.980 1613337332.8329618
train: epoch 72, iter 3500, loss: 2.434583, top_1: 0.616445, top_k: 0.827656, samples/s: 785.105 1613337365.4400585
train: epoch 72, iter 3600, loss: 2.456151, top_1: 0.622656, top_k: 0.834258, samples/s: 785.312 1613337398.0385044
train: epoch 72, iter 3700, loss: 2.727308, top_1: 0.622773, top_k: 0.835156, samples/s: 782.511 1613337430.7537627
train: epoch 72, iter 3800, loss: 2.433870, top_1: 0.621523, top_k: 0.834648, samples/s: 787.477 1613337463.2626362
train: epoch 72, iter 3900, loss: 2.486341, top_1: 0.622383, top_k: 0.832930, samples/s: 782.544 1613337495.9763649
train: epoch 72, iter 4000, loss: 2.580878, top_1: 0.617344, top_k: 0.830547, samples/s: 784.384 1613337528.6135204
train: epoch 72, iter 4100, loss: 2.603755, top_1: 0.619844, top_k: 0.829805, samples/s: 782.523 1613337561.3282256
train: epoch 72, iter 4200, loss: 2.455157, top_1: 0.623281, top_k: 0.836055, samples/s: 787.292 1613337593.8447728
train: epoch 72, iter 4300, loss: 2.725711, top_1: 0.621484, top_k: 0.832305, samples/s: 781.649 1613337626.5959432
train: epoch 72, iter 4400, loss: 2.444305, top_1: 0.623867, top_k: 0.830703, samples/s: 783.032 1613337659.2894466
train: epoch 72, iter 4500, loss: 2.650857, top_1: 0.620195, top_k: 0.828750, samples/s: 786.623 1613337691.833514
train: epoch 72, iter 4600, loss: 2.567562, top_1: 0.624102, top_k: 0.830977, samples/s: 782.761 1613337724.5382545
train: epoch 72, iter 4700, loss: 2.575541, top_1: 0.624336, top_k: 0.833438, samples/s: 785.787 1613337757.1170967
train: epoch 72, iter 4800, loss: 2.483442, top_1: 0.614688, top_k: 0.831562, samples/s: 784.117 1613337789.7652974
train: epoch 72, iter 4900, loss: 2.480341, top_1: 0.619883, top_k: 0.828398, samples/s: 786.093 1613337822.3314228
train: epoch 72, iter 5000, loss: 2.379378, top_1: 0.624336, top_k: 0.834336, samples/s: 785.442 1613337854.9245718
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_72.
validation: epoch 72, iter 195, top_1: 0.665104, top_k: 0.877464, samples/s: 2366.612 1613337876.9831114
train: epoch 73, iter 100, loss: 2.545672, top_1: 0.632812, top_k: 0.838828, samples/s: 804.608 1613337929.2180836
train: epoch 73, iter 200, loss: 2.581749, top_1: 0.624453, top_k: 0.833750, samples/s: 798.893 1613337961.2624412
train: epoch 73, iter 300, loss: 2.417879, top_1: 0.633867, top_k: 0.836992, samples/s: 790.559 1613337993.6445446
train: epoch 73, iter 400, loss: 2.687823, top_1: 0.630352, top_k: 0.841289, samples/s: 781.951 1613338026.3832338
train: epoch 73, iter 500, loss: 2.475689, top_1: 0.628750, top_k: 0.842891, samples/s: 785.685 1613338058.9663086
train: epoch 73, iter 600, loss: 2.569054, top_1: 0.635195, top_k: 0.842578, samples/s: 783.307 1613338091.6481583
train: epoch 73, iter 700, loss: 2.576112, top_1: 0.633242, top_k: 0.841250, samples/s: 783.531 1613338124.3209274
train: epoch 73, iter 800, loss: 2.420304, top_1: 0.630273, top_k: 0.838750, samples/s: 786.469 1613338156.8713202
train: epoch 73, iter 900, loss: 2.544552, top_1: 0.632773, top_k: 0.840000, samples/s: 783.511 1613338189.544755
train: epoch 73, iter 1000, loss: 2.620368, top_1: 0.630859, top_k: 0.839297, samples/s: 780.980 1613338222.3241625
train: epoch 73, iter 1100, loss: 2.646356, top_1: 0.627227, top_k: 0.840625, samples/s: 784.283 1613338254.9653852
train: epoch 73, iter 1200, loss: 2.399353, top_1: 0.623906, top_k: 0.837500, samples/s: 785.969 1613338287.5367098
train: epoch 73, iter 1300, loss: 2.583412, top_1: 0.628867, top_k: 0.839063, samples/s: 783.435 1613338320.213252
train: epoch 73, iter 1400, loss: 2.544689, top_1: 0.629570, top_k: 0.838477, samples/s: 782.656 1613338352.922459
train: epoch 73, iter 1500, loss: 2.419762, top_1: 0.627383, top_k: 0.838359, samples/s: 784.388 1613338385.5592654
train: epoch 73, iter 1600, loss: 2.464441, top_1: 0.628594, top_k: 0.834375, samples/s: 785.349 1613338418.1562665
train: epoch 73, iter 1700, loss: 2.524881, top_1: 0.629453, top_k: 0.839492, samples/s: 784.652 1613338450.782221
train: epoch 73, iter 1800, loss: 2.497135, top_1: 0.624961, top_k: 0.837578, samples/s: 784.536 1613338483.4129553
train: epoch 73, iter 1900, loss: 2.631032, top_1: 0.628477, top_k: 0.834336, samples/s: 785.228 1613338516.0149271
train: epoch 73, iter 2000, loss: 2.574029, top_1: 0.623047, top_k: 0.833984, samples/s: 783.822 1613338548.6754372
train: epoch 73, iter 2100, loss: 2.556382, top_1: 0.622852, top_k: 0.834102, samples/s: 783.328 1613338581.3565238
train: epoch 73, iter 2200, loss: 2.452138, top_1: 0.624062, top_k: 0.834805, samples/s: 785.425 1613338613.9503427
train: epoch 73, iter 2300, loss: 2.589760, top_1: 0.624141, top_k: 0.836992, samples/s: 785.961 1613338646.521873
train: epoch 73, iter 2400, loss: 2.469750, top_1: 0.623359, top_k: 0.832773, samples/s: 786.363 1613338679.0768123
train: epoch 73, iter 2500, loss: 2.549386, top_1: 0.625859, top_k: 0.837227, samples/s: 785.652 1613338711.6611998
train: epoch 73, iter 2600, loss: 2.349085, top_1: 0.624727, top_k: 0.835391, samples/s: 783.385 1613338744.3398938
train: epoch 73, iter 2700, loss: 2.542035, top_1: 0.630938, top_k: 0.837266, samples/s: 785.017 1613338776.9506562
train: epoch 73, iter 2800, loss: 2.564115, top_1: 0.622812, top_k: 0.833320, samples/s: 785.533 1613338809.5399582
train: epoch 73, iter 2900, loss: 2.531232, top_1: 0.622734, top_k: 0.833789, samples/s: 784.336 1613338842.179123
train: epoch 73, iter 3000, loss: 2.503864, top_1: 0.624687, top_k: 0.832344, samples/s: 784.866 1613338874.796122
train: epoch 73, iter 3100, loss: 2.495437, top_1: 0.625352, top_k: 0.834063, samples/s: 786.592 1613338907.3415773
train: epoch 73, iter 3200, loss: 2.546033, top_1: 0.623125, top_k: 0.836484, samples/s: 784.837 1613338939.959781
train: epoch 73, iter 3300, loss: 2.444900, top_1: 0.620039, top_k: 0.830469, samples/s: 783.128 1613338972.6492314
train: epoch 73, iter 3400, loss: 2.531836, top_1: 0.623672, top_k: 0.833320, samples/s: 785.069 1613339005.257828
train: epoch 73, iter 3500, loss: 2.545305, top_1: 0.626172, top_k: 0.831953, samples/s: 785.793 1613339037.836443
train: epoch 73, iter 3600, loss: 2.548495, top_1: 0.621328, top_k: 0.833672, samples/s: 783.690 1613339070.5024045
train: epoch 73, iter 3700, loss: 2.480597, top_1: 0.627891, top_k: 0.837695, samples/s: 785.549 1613339103.090988
train: epoch 73, iter 3800, loss: 2.329496, top_1: 0.626328, top_k: 0.838945, samples/s: 786.421 1613339135.6435585
train: epoch 73, iter 3900, loss: 2.587510, top_1: 0.624922, top_k: 0.834180, samples/s: 784.763 1613339168.264884
train: epoch 73, iter 4000, loss: 2.665577, top_1: 0.618945, top_k: 0.828633, samples/s: 783.670 1613339200.931729
train: epoch 73, iter 4100, loss: 2.604868, top_1: 0.623945, top_k: 0.830977, samples/s: 783.111 1613339233.6219296
train: epoch 73, iter 4200, loss: 2.422953, top_1: 0.622461, top_k: 0.831641, samples/s: 786.879 1613339266.1554546
train: epoch 73, iter 4300, loss: 2.487675, top_1: 0.619844, top_k: 0.831367, samples/s: 783.091 1613339298.846436
train: epoch 73, iter 4400, loss: 2.300504, top_1: 0.623516, top_k: 0.836758, samples/s: 787.826 1613339331.3409464
train: epoch 73, iter 4500, loss: 2.561813, top_1: 0.621445, top_k: 0.833047, samples/s: 784.879 1613339363.9574223
train: epoch 73, iter 4600, loss: 2.397630, top_1: 0.622773, top_k: 0.836602, samples/s: 786.615 1613339396.5019734
train: epoch 73, iter 4700, loss: 2.397599, top_1: 0.625586, top_k: 0.835430, samples/s: 785.441 1613339429.0950563
train: epoch 73, iter 4800, loss: 2.563690, top_1: 0.622852, top_k: 0.832617, samples/s: 785.884 1613339461.669881
train: epoch 73, iter 4900, loss: 2.611164, top_1: 0.617109, top_k: 0.834141, samples/s: 785.157 1613339494.274733
train: epoch 73, iter 5000, loss: 2.620266, top_1: 0.622891, top_k: 0.829688, samples/s: 787.965 1613339526.7635398
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_73.
validation: epoch 73, iter 195, top_1: 0.672075, top_k: 0.879828, samples/s: 2343.702 1613339549.0327458
train: epoch 74, iter 100, loss: 2.489364, top_1: 0.627070, top_k: 0.841367, samples/s: 804.137 1613339601.3849528
train: epoch 74, iter 200, loss: 2.526984, top_1: 0.635742, top_k: 0.843477, samples/s: 800.088 1613339633.3815575
train: epoch 74, iter 300, loss: 2.495771, top_1: 0.638125, top_k: 0.844922, samples/s: 788.225 1613339665.8594146
train: epoch 74, iter 400, loss: 2.620936, top_1: 0.626211, top_k: 0.836289, samples/s: 784.340 1613339698.4983246
train: epoch 74, iter 500, loss: 2.503776, top_1: 0.636094, top_k: 0.843359, samples/s: 784.442 1613339731.1330907
train: epoch 74, iter 600, loss: 2.451737, top_1: 0.640547, top_k: 0.844531, samples/s: 783.891 1613339763.7906218
train: epoch 74, iter 700, loss: 2.647813, top_1: 0.633164, top_k: 0.840195, samples/s: 781.633 1613339796.5425048
train: epoch 74, iter 800, loss: 2.721993, top_1: 0.636914, top_k: 0.840117, samples/s: 783.501 1613339829.2166905
train: epoch 74, iter 900, loss: 2.566879, top_1: 0.629844, top_k: 0.838203, samples/s: 784.373 1613339861.8538718
train: epoch 74, iter 1000, loss: 2.710817, top_1: 0.628086, top_k: 0.837461, samples/s: 781.283 1613339894.6205342
train: epoch 74, iter 1100, loss: 2.645414, top_1: 0.630859, top_k: 0.840469, samples/s: 782.739 1613339927.3261714
train: epoch 74, iter 1200, loss: 2.749294, top_1: 0.625859, top_k: 0.839063, samples/s: 784.532 1613339959.957157
train: epoch 74, iter 1300, loss: 2.560384, top_1: 0.625234, top_k: 0.834531, samples/s: 781.355 1613339992.721162
train: epoch 74, iter 1400, loss: 2.573886, top_1: 0.632227, top_k: 0.839844, samples/s: 783.901 1613340025.3778942
train: epoch 74, iter 1500, loss: 2.405870, top_1: 0.629961, top_k: 0.837969, samples/s: 783.638 1613340058.0460792
train: epoch 74, iter 1600, loss: 2.467027, top_1: 0.632617, top_k: 0.836289, samples/s: 784.366 1613340090.6838303
train: epoch 74, iter 1700, loss: 2.699733, top_1: 0.626484, top_k: 0.839375, samples/s: 784.611 1613340123.3115425
train: epoch 74, iter 1800, loss: 2.625654, top_1: 0.631133, top_k: 0.836055, samples/s: 784.508 1613340155.9433575
train: epoch 74, iter 1900, loss: 2.579641, top_1: 0.625234, top_k: 0.838047, samples/s: 785.516 1613340188.533469
train: epoch 74, iter 2000, loss: 2.600469, top_1: 0.621523, top_k: 0.832695, samples/s: 782.944 1613340221.230608
train: epoch 74, iter 2100, loss: 2.550517, top_1: 0.629297, top_k: 0.835469, samples/s: 785.283 1613340253.830364
train: epoch 74, iter 2200, loss: 2.789973, top_1: 0.628711, top_k: 0.839297, samples/s: 783.228 1613340286.5155506
train: epoch 74, iter 2300, loss: 2.443050, top_1: 0.627812, top_k: 0.841797, samples/s: 784.718 1613340319.1387467
train: epoch 74, iter 2400, loss: 2.585155, top_1: 0.628555, top_k: 0.835977, samples/s: 783.201 1613340351.8249803
train: epoch 74, iter 2500, loss: 2.699667, top_1: 0.624883, top_k: 0.833203, samples/s: 785.907 1613340384.3989172
train: epoch 74, iter 2600, loss: 2.499674, top_1: 0.628555, top_k: 0.835039, samples/s: 783.421 1613340417.0760994
train: epoch 74, iter 2700, loss: 2.553693, top_1: 0.627578, top_k: 0.836523, samples/s: 785.319 1613340449.6743002
train: epoch 74, iter 2800, loss: 2.470268, top_1: 0.631680, top_k: 0.840117, samples/s: 787.437 1613340482.1847997
train: epoch 74, iter 2900, loss: 2.662774, top_1: 0.621797, top_k: 0.833477, samples/s: 782.457 1613340514.9022672
train: epoch 74, iter 3000, loss: 2.522574, top_1: 0.626484, top_k: 0.833438, samples/s: 785.101 1613340547.5096262
train: epoch 74, iter 3100, loss: 2.513978, top_1: 0.626914, top_k: 0.835391, samples/s: 781.573 1613340580.264081
train: epoch 74, iter 3200, loss: 2.629133, top_1: 0.630820, top_k: 0.838359, samples/s: 784.154 1613340612.910657
train: epoch 74, iter 3300, loss: 2.592927, top_1: 0.623086, top_k: 0.836055, samples/s: 783.615 1613340645.579812
train: epoch 74, iter 3400, loss: 2.397609, top_1: 0.623984, top_k: 0.835117, samples/s: 782.416 1613340678.2989514
train: epoch 74, iter 3500, loss: 2.459616, top_1: 0.620977, top_k: 0.832187, samples/s: 784.430 1613340710.934079
train: epoch 74, iter 3600, loss: 2.522892, top_1: 0.625742, top_k: 0.836484, samples/s: 784.216 1613340743.578162
train: epoch 74, iter 3700, loss: 2.748759, top_1: 0.626289, top_k: 0.835391, samples/s: 784.375 1613340776.215674
train: epoch 74, iter 3800, loss: 2.799134, top_1: 0.626445, top_k: 0.835391, samples/s: 783.764 1613340808.8785036
train: epoch 74, iter 3900, loss: 2.596714, top_1: 0.634492, top_k: 0.839570, samples/s: 784.124 1613340841.5264103
train: epoch 74, iter 4000, loss: 2.445179, top_1: 0.621836, top_k: 0.831172, samples/s: 783.610 1613340874.195758
train: epoch 74, iter 4100, loss: 2.762195, top_1: 0.621211, top_k: 0.835156, samples/s: 783.633 1613340906.864138
train: epoch 74, iter 4200, loss: 2.603377, top_1: 0.619883, top_k: 0.835039, samples/s: 784.223 1613340939.5078802
train: epoch 74, iter 4300, loss: 2.543606, top_1: 0.620586, top_k: 0.831758, samples/s: 784.889 1613340972.123925
train: epoch 74, iter 4400, loss: 2.514212, top_1: 0.628516, top_k: 0.835742, samples/s: 785.279 1613341004.7237802
train: epoch 74, iter 4500, loss: 2.320054, top_1: 0.629648, top_k: 0.839063, samples/s: 783.235 1613341037.4087284
train: epoch 74, iter 4600, loss: 2.430697, top_1: 0.623164, top_k: 0.829766, samples/s: 783.566 1613341070.0798728
train: epoch 74, iter 4700, loss: 2.534196, top_1: 0.624570, top_k: 0.833086, samples/s: 781.975 1613341102.817563
train: epoch 74, iter 4800, loss: 2.558466, top_1: 0.622188, top_k: 0.834375, samples/s: 783.838 1613341135.47733
train: epoch 74, iter 4900, loss: 2.634416, top_1: 0.625898, top_k: 0.834258, samples/s: 785.673 1613341168.0608788
train: epoch 74, iter 5000, loss: 2.544166, top_1: 0.630430, top_k: 0.840703, samples/s: 785.301 1613341200.659814
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_74.
validation: epoch 74, iter 195, top_1: 0.672696, top_k: 0.881791, samples/s: 2342.167 1613341222.9419212
train: epoch 75, iter 100, loss: 2.337130, top_1: 0.638633, top_k: 0.842891, samples/s: 804.994 1613341275.1241465
train: epoch 75, iter 200, loss: 2.502985, top_1: 0.636055, top_k: 0.842461, samples/s: 802.158 1613341307.0380917
train: epoch 75, iter 300, loss: 2.618366, top_1: 0.632695, top_k: 0.844805, samples/s: 787.754 1613341339.5357044
train: epoch 75, iter 400, loss: 2.614555, top_1: 0.633555, top_k: 0.841250, samples/s: 784.752 1613341372.157268
train: epoch 75, iter 500, loss: 2.651030, top_1: 0.633867, top_k: 0.840430, samples/s: 783.266 1613341404.8408394
train: epoch 75, iter 600, loss: 2.418134, top_1: 0.627461, top_k: 0.840703, samples/s: 781.124 1613341437.6142254
train: epoch 75, iter 700, loss: 2.518404, top_1: 0.631914, top_k: 0.840273, samples/s: 782.923 1613341470.3121552
train: epoch 75, iter 800, loss: 2.486003, top_1: 0.635078, top_k: 0.842656, samples/s: 782.423 1613341503.0309296
train: epoch 75, iter 900, loss: 2.546623, top_1: 0.635273, top_k: 0.844531, samples/s: 781.869 1613341535.7731047
train: epoch 75, iter 1000, loss: 2.494179, top_1: 0.634180, top_k: 0.840469, samples/s: 783.045 1613341568.4659343
train: epoch 75, iter 1100, loss: 2.640070, top_1: 0.633594, top_k: 0.841445, samples/s: 784.436 1613341601.1007528
train: epoch 75, iter 1200, loss: 2.524267, top_1: 0.626250, top_k: 0.840469, samples/s: 783.813 1613341633.7616267
train: epoch 75, iter 1300, loss: 2.498477, top_1: 0.628516, top_k: 0.834727, samples/s: 781.755 1613341666.5085065
train: epoch 75, iter 1400, loss: 2.555847, top_1: 0.636133, top_k: 0.838594, samples/s: 784.479 1613341699.1417272
train: epoch 75, iter 1500, loss: 2.533214, top_1: 0.633320, top_k: 0.840000, samples/s: 784.843 1613341731.759627
train: epoch 75, iter 1600, loss: 2.563633, top_1: 0.633945, top_k: 0.840586, samples/s: 785.315 1613341764.3582108
train: epoch 75, iter 1700, loss: 2.449033, top_1: 0.631680, top_k: 0.838789, samples/s: 782.002 1613341797.094524
train: epoch 75, iter 1800, loss: 2.676383, top_1: 0.633242, top_k: 0.841562, samples/s: 783.589 1613341829.7647388
train: epoch 75, iter 1900, loss: 2.656079, top_1: 0.628125, top_k: 0.834570, samples/s: 784.787 1613341862.3849819
train: epoch 75, iter 2000, loss: 2.462736, top_1: 0.630195, top_k: 0.838984, samples/s: 782.851 1613341895.0859249
train: epoch 75, iter 2100, loss: 2.576431, top_1: 0.627773, top_k: 0.833672, samples/s: 783.643 1613341927.7539117
train: epoch 75, iter 2200, loss: 2.485463, top_1: 0.626211, top_k: 0.835586, samples/s: 783.825 1613341960.4143791
train: epoch 75, iter 2300, loss: 2.393691, top_1: 0.628555, top_k: 0.837383, samples/s: 783.356 1613341993.0941908
train: epoch 75, iter 2400, loss: 2.347685, top_1: 0.630391, top_k: 0.834102, samples/s: 785.132 1613342025.7001247
train: epoch 75, iter 2500, loss: 2.552268, top_1: 0.633398, top_k: 0.841172, samples/s: 782.954 1613342058.39693
train: epoch 75, iter 2600, loss: 2.581057, top_1: 0.630078, top_k: 0.838047, samples/s: 782.621 1613342091.1074827
train: epoch 75, iter 2700, loss: 2.499694, top_1: 0.629102, top_k: 0.837148, samples/s: 783.756 1613342123.7706814
train: epoch 75, iter 2800, loss: 2.509426, top_1: 0.627812, top_k: 0.837344, samples/s: 784.063 1613342156.421155
train: epoch 75, iter 2900, loss: 2.534861, top_1: 0.624414, top_k: 0.835352, samples/s: 784.887 1613342189.037289
train: epoch 75, iter 3000, loss: 2.638825, top_1: 0.625859, top_k: 0.833438, samples/s: 784.757 1613342221.6588395
train: epoch 75, iter 3100, loss: 2.486087, top_1: 0.630234, top_k: 0.840352, samples/s: 783.211 1613342254.3447776
train: epoch 75, iter 3200, loss: 2.458263, top_1: 0.621758, top_k: 0.835273, samples/s: 784.219 1613342286.9887218
train: epoch 75, iter 3300, loss: 2.563551, top_1: 0.625742, top_k: 0.836641, samples/s: 784.979 1613342319.6010256
train: epoch 75, iter 3400, loss: 2.416347, top_1: 0.629805, top_k: 0.836914, samples/s: 785.726 1613342352.1827295
train: epoch 75, iter 3500, loss: 2.501670, top_1: 0.626836, top_k: 0.838477, samples/s: 784.425 1613342384.817778
train: epoch 75, iter 3600, loss: 2.640157, top_1: 0.630508, top_k: 0.838437, samples/s: 786.572 1613342417.3643095
train: epoch 75, iter 3700, loss: 2.569846, top_1: 0.629648, top_k: 0.834531, samples/s: 783.042 1613342450.0570912
train: epoch 75, iter 3800, loss: 2.696394, top_1: 0.626367, top_k: 0.837266, samples/s: 784.879 1613342482.6735158
train: epoch 75, iter 3900, loss: 2.424032, top_1: 0.630078, top_k: 0.838047, samples/s: 786.491 1613342515.2231503
train: epoch 75, iter 4000, loss: 2.429792, top_1: 0.622344, top_k: 0.834844, samples/s: 785.328 1613342547.820968
train: epoch 75, iter 4100, loss: 2.390878, top_1: 0.625859, top_k: 0.832578, samples/s: 784.752 1613342580.443301
train: epoch 75, iter 4200, loss: 2.668579, top_1: 0.624180, top_k: 0.833711, samples/s: 785.780 1613342613.0219219
train: epoch 75, iter 4300, loss: 2.655245, top_1: 0.621992, top_k: 0.835313, samples/s: 784.361 1613342645.6603231
train: epoch 75, iter 4400, loss: 2.481460, top_1: 0.620195, top_k: 0.832383, samples/s: 785.043 1613342678.2695932
train: epoch 75, iter 4500, loss: 2.440468, top_1: 0.631367, top_k: 0.838828, samples/s: 783.319 1613342710.9510827
train: epoch 75, iter 4600, loss: 2.495613, top_1: 0.629961, top_k: 0.833672, samples/s: 783.821 1613342743.6115835
train: epoch 75, iter 4700, loss: 2.587275, top_1: 0.622578, top_k: 0.837187, samples/s: 785.910 1613342776.1852531
train: epoch 75, iter 4800, loss: 2.667392, top_1: 0.627500, top_k: 0.834219, samples/s: 784.302 1613342808.8257484
train: epoch 75, iter 4900, loss: 2.576083, top_1: 0.623867, top_k: 0.833477, samples/s: 784.635 1613342841.4524672
train: epoch 75, iter 5000, loss: 2.534435, top_1: 0.623750, top_k: 0.833281, samples/s: 783.395 1613342874.1307333
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_75.
validation: epoch 75, iter 195, top_1: 0.671474, top_k: 0.881350, samples/s: 2345.394 1613342896.3783386
train: epoch 76, iter 100, loss: 2.445689, top_1: 0.643203, top_k: 0.842930, samples/s: 804.100 1613342949.3186195
train: epoch 76, iter 200, loss: 2.599771, top_1: 0.635000, top_k: 0.843867, samples/s: 799.504 1613342981.3384087
train: epoch 76, iter 300, loss: 2.464158, top_1: 0.634180, top_k: 0.839688, samples/s: 789.820 1613343013.7509189
train: epoch 76, iter 400, loss: 2.502524, top_1: 0.637500, top_k: 0.844492, samples/s: 782.598 1613343046.462476
train: epoch 76, iter 500, loss: 2.449742, top_1: 0.636992, top_k: 0.843242, samples/s: 787.230 1613343078.9815516
train: epoch 76, iter 600, loss: 2.510179, top_1: 0.637031, top_k: 0.841289, samples/s: 780.513 1613343111.7804718
train: epoch 76, iter 700, loss: 2.508568, top_1: 0.633789, top_k: 0.839883, samples/s: 786.609 1613343144.3252597
train: epoch 76, iter 800, loss: 2.552993, top_1: 0.631133, top_k: 0.839336, samples/s: 782.772 1613343177.0295842
train: epoch 76, iter 900, loss: 2.615976, top_1: 0.632109, top_k: 0.840938, samples/s: 785.461 1613343209.621855
train: epoch 76, iter 1000, loss: 2.484215, top_1: 0.632070, top_k: 0.843516, samples/s: 783.616 1613343242.2909276
train: epoch 76, iter 1100, loss: 2.428299, top_1: 0.633672, top_k: 0.841094, samples/s: 783.842 1613343274.9504752
train: epoch 76, iter 1200, loss: 2.530946, top_1: 0.633906, top_k: 0.843008, samples/s: 784.051 1613343307.6014335
train: epoch 76, iter 1300, loss: 2.461741, top_1: 0.633516, top_k: 0.837930, samples/s: 783.121 1613343340.2911851
train: epoch 76, iter 1400, loss: 2.356253, top_1: 0.630352, top_k: 0.837930, samples/s: 783.624 1613343372.9599438
train: epoch 76, iter 1500, loss: 2.364161, top_1: 0.636758, top_k: 0.838359, samples/s: 783.049 1613343405.6526349
train: epoch 76, iter 1600, loss: 2.598291, top_1: 0.635898, top_k: 0.842148, samples/s: 783.638 1613343438.3207936
train: epoch 76, iter 1700, loss: 2.571615, top_1: 0.635469, top_k: 0.845508, samples/s: 784.286 1613343470.9619446
train: epoch 76, iter 1800, loss: 2.463411, top_1: 0.636523, top_k: 0.842500, samples/s: 783.246 1613343503.6464734
train: epoch 76, iter 1900, loss: 2.561344, top_1: 0.629922, top_k: 0.839023, samples/s: 784.078 1613343536.2962742
train: epoch 76, iter 2000, loss: 2.563392, top_1: 0.627188, top_k: 0.837969, samples/s: 784.504 1613343568.9283993
train: epoch 76, iter 2100, loss: 2.595736, top_1: 0.636250, top_k: 0.842305, samples/s: 785.650 1613343601.5128937
train: epoch 76, iter 2200, loss: 2.428648, top_1: 0.627695, top_k: 0.839180, samples/s: 785.496 1613343634.103773
train: epoch 76, iter 2300, loss: 2.473401, top_1: 0.628281, top_k: 0.837109, samples/s: 784.186 1613343666.749096
train: epoch 76, iter 2400, loss: 2.478614, top_1: 0.628711, top_k: 0.838867, samples/s: 785.037 1613343699.3589768
train: epoch 76, iter 2500, loss: 2.659134, top_1: 0.628047, top_k: 0.836016, samples/s: 784.989 1613343731.9709654
train: epoch 76, iter 2600, loss: 2.349362, top_1: 0.633125, top_k: 0.836406, samples/s: 783.076 1613343764.662559
train: epoch 76, iter 2700, loss: 2.658659, top_1: 0.631055, top_k: 0.839492, samples/s: 783.777 1613343797.3248553
train: epoch 76, iter 2800, loss: 2.497311, top_1: 0.633398, top_k: 0.840117, samples/s: 784.322 1613343829.9645855
train: epoch 76, iter 2900, loss: 2.489990, top_1: 0.632031, top_k: 0.838828, samples/s: 785.777 1613343862.5437238
train: epoch 76, iter 3000, loss: 2.378178, top_1: 0.638281, top_k: 0.841133, samples/s: 785.938 1613343895.1163335
train: epoch 76, iter 3100, loss: 2.511281, top_1: 0.626094, top_k: 0.838086, samples/s: 785.954 1613343927.6881735
train: epoch 76, iter 3200, loss: 2.484742, top_1: 0.620156, top_k: 0.834180, samples/s: 783.736 1613343960.3523057
train: epoch 76, iter 3300, loss: 2.575764, top_1: 0.623594, top_k: 0.834648, samples/s: 783.229 1613343993.037456
train: epoch 76, iter 3400, loss: 2.612226, top_1: 0.630547, top_k: 0.837422, samples/s: 782.794 1613344025.740855
train: epoch 76, iter 3500, loss: 2.609714, top_1: 0.633711, top_k: 0.838789, samples/s: 786.904 1613344058.2734196
train: epoch 76, iter 3600, loss: 2.420430, top_1: 0.633594, top_k: 0.837422, samples/s: 783.844 1613344090.9329665
train: epoch 76, iter 3700, loss: 2.556465, top_1: 0.627656, top_k: 0.837812, samples/s: 785.593 1613344123.5198634
train: epoch 76, iter 3800, loss: 2.431503, top_1: 0.630469, top_k: 0.836875, samples/s: 782.190 1613344156.2484727
train: epoch 76, iter 3900, loss: 2.434369, top_1: 0.633047, top_k: 0.839453, samples/s: 781.081 1613344189.023529
train: epoch 76, iter 4000, loss: 2.732773, top_1: 0.624336, top_k: 0.834297, samples/s: 788.383 1613344221.494992
train: epoch 76, iter 4100, loss: 2.721242, top_1: 0.626523, top_k: 0.837734, samples/s: 785.408 1613344254.089534
train: epoch 76, iter 4200, loss: 2.590213, top_1: 0.630352, top_k: 0.838125, samples/s: 782.778 1613344286.793613
train: epoch 76, iter 4300, loss: 2.674828, top_1: 0.631719, top_k: 0.832344, samples/s: 786.880 1613344319.3270683
train: epoch 76, iter 4400, loss: 2.538941, top_1: 0.628906, top_k: 0.838359, samples/s: 782.752 1613344352.032255
train: epoch 76, iter 4500, loss: 2.360645, top_1: 0.629922, top_k: 0.838750, samples/s: 784.448 1613344384.666626
train: epoch 76, iter 4600, loss: 2.591020, top_1: 0.625742, top_k: 0.838008, samples/s: 785.994 1613344417.2368276
train: epoch 76, iter 4700, loss: 2.692448, top_1: 0.619648, top_k: 0.831797, samples/s: 783.459 1613344449.912399
train: epoch 76, iter 4800, loss: 2.528670, top_1: 0.631719, top_k: 0.836914, samples/s: 785.973 1613344482.483551
train: epoch 76, iter 4900, loss: 2.647751, top_1: 0.622930, top_k: 0.835078, samples/s: 783.019 1613344515.1774716
train: epoch 76, iter 5000, loss: 2.500777, top_1: 0.635625, top_k: 0.839258, samples/s: 785.789 1613344547.75621
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_76.
validation: epoch 76, iter 195, top_1: 0.675240, top_k: 0.885517, samples/s: 2401.815 1613344569.5049248
train: epoch 77, iter 100, loss: 2.530333, top_1: 0.643281, top_k: 0.847852, samples/s: 803.276 1613344622.920196
train: epoch 77, iter 200, loss: 2.511039, top_1: 0.646992, top_k: 0.847305, samples/s: 802.170 1613344654.833697
train: epoch 77, iter 300, loss: 2.475015, top_1: 0.634375, top_k: 0.843555, samples/s: 788.613 1613344687.2957165
train: epoch 77, iter 400, loss: 2.472925, top_1: 0.635234, top_k: 0.841094, samples/s: 781.522 1613344720.0522947
train: epoch 77, iter 500, loss: 2.424736, top_1: 0.638086, top_k: 0.843008, samples/s: 783.580 1613344752.7227707
train: epoch 77, iter 600, loss: 2.455532, top_1: 0.641250, top_k: 0.845352, samples/s: 785.074 1613344785.3312023
train: epoch 77, iter 700, loss: 2.518613, top_1: 0.636016, top_k: 0.841797, samples/s: 783.056 1613344818.0236845
train: epoch 77, iter 800, loss: 2.381742, top_1: 0.638906, top_k: 0.844258, samples/s: 782.988 1613344850.718987
train: epoch 77, iter 900, loss: 2.469009, top_1: 0.634062, top_k: 0.843242, samples/s: 783.795 1613344883.3805084
train: epoch 77, iter 1000, loss: 2.477571, top_1: 0.633203, top_k: 0.843320, samples/s: 783.987 1613344916.034151
train: epoch 77, iter 1100, loss: 2.447765, top_1: 0.639883, top_k: 0.845625, samples/s: 782.333 1613344948.7567353
train: epoch 77, iter 1200, loss: 2.351441, top_1: 0.636250, top_k: 0.843750, samples/s: 783.526 1613344981.4295924
train: epoch 77, iter 1300, loss: 2.345234, top_1: 0.636172, top_k: 0.843867, samples/s: 784.886 1613345014.0457094
train: epoch 77, iter 1400, loss: 2.520526, top_1: 0.635703, top_k: 0.837695, samples/s: 784.715 1613345046.6690648
train: epoch 77, iter 1500, loss: 2.497924, top_1: 0.633750, top_k: 0.839453, samples/s: 782.596 1613345079.3807528
train: epoch 77, iter 1600, loss: 2.496763, top_1: 0.632188, top_k: 0.840000, samples/s: 785.626 1613345111.966231
train: epoch 77, iter 1700, loss: 2.317634, top_1: 0.631758, top_k: 0.844531, samples/s: 784.410 1613345144.602219
train: epoch 77, iter 1800, loss: 2.709054, top_1: 0.635156, top_k: 0.838828, samples/s: 783.107 1613345177.2924342
train: epoch 77, iter 1900, loss: 2.528103, top_1: 0.638281, top_k: 0.837227, samples/s: 784.719 1613345209.915584
train: epoch 77, iter 2000, loss: 2.390283, top_1: 0.632070, top_k: 0.840977, samples/s: 785.513 1613345242.5057943
train: epoch 77, iter 2100, loss: 2.708329, top_1: 0.634883, top_k: 0.842148, samples/s: 782.624 1613345275.2162514
train: epoch 77, iter 2200, loss: 2.488542, top_1: 0.630195, top_k: 0.838750, samples/s: 782.737 1613345307.921955
train: epoch 77, iter 2300, loss: 2.541357, top_1: 0.633828, top_k: 0.841016, samples/s: 783.122 1613345340.6115863
train: epoch 77, iter 2400, loss: 2.641782, top_1: 0.630352, top_k: 0.839141, samples/s: 783.471 1613345373.2866971
train: epoch 77, iter 2500, loss: 2.412290, top_1: 0.629414, top_k: 0.838789, samples/s: 786.887 1613345405.820008
train: epoch 77, iter 2600, loss: 2.280295, top_1: 0.636719, top_k: 0.840859, samples/s: 782.930 1613345438.5176654
train: epoch 77, iter 2700, loss: 2.558278, top_1: 0.629687, top_k: 0.839297, samples/s: 784.317 1613345471.1575835
train: epoch 77, iter 2800, loss: 2.642313, top_1: 0.630117, top_k: 0.837070, samples/s: 784.356 1613345503.7958252
train: epoch 77, iter 2900, loss: 2.580942, top_1: 0.630586, top_k: 0.839688, samples/s: 782.637 1613345536.5058353
train: epoch 77, iter 3000, loss: 2.515886, top_1: 0.635391, top_k: 0.839414, samples/s: 782.760 1613345569.2105067
train: epoch 77, iter 3100, loss: 2.504363, top_1: 0.632852, top_k: 0.839570, samples/s: 785.430 1613345601.8041382
train: epoch 77, iter 3200, loss: 2.576026, top_1: 0.629961, top_k: 0.836836, samples/s: 785.111 1613345634.4109786
train: epoch 77, iter 3300, loss: 2.471276, top_1: 0.630938, top_k: 0.837305, samples/s: 784.655 1613345667.0367374
train: epoch 77, iter 3400, loss: 2.525552, top_1: 0.626953, top_k: 0.837461, samples/s: 784.908 1613345699.6520817
train: epoch 77, iter 3500, loss: 2.436983, top_1: 0.630430, top_k: 0.837930, samples/s: 786.748 1613345732.1910434
train: epoch 77, iter 3600, loss: 2.391577, top_1: 0.631992, top_k: 0.840430, samples/s: 784.041 1613345764.8424249
train: epoch 77, iter 3700, loss: 2.413260, top_1: 0.633047, top_k: 0.840352, samples/s: 785.673 1613345797.4259405
train: epoch 77, iter 3800, loss: 2.552321, top_1: 0.630391, top_k: 0.836523, samples/s: 784.597 1613345830.0541751
train: epoch 77, iter 3900, loss: 2.449011, top_1: 0.632773, top_k: 0.838086, samples/s: 784.940 1613345862.668151
train: epoch 77, iter 4000, loss: 2.529432, top_1: 0.628672, top_k: 0.840391, samples/s: 784.325 1613345895.3077052
train: epoch 77, iter 4100, loss: 2.493840, top_1: 0.632461, top_k: 0.843672, samples/s: 784.272 1613345927.9494913
train: epoch 77, iter 4200, loss: 2.356488, top_1: 0.631211, top_k: 0.844141, samples/s: 784.890 1613345960.5655353
train: epoch 77, iter 4300, loss: 2.633912, top_1: 0.633750, top_k: 0.837773, samples/s: 786.197 1613345993.1272807
train: epoch 77, iter 4400, loss: 2.481686, top_1: 0.633906, top_k: 0.840430, samples/s: 784.751 1613346025.7490652
train: epoch 77, iter 4500, loss: 2.459240, top_1: 0.631211, top_k: 0.841445, samples/s: 784.915 1613346058.3640776
train: epoch 77, iter 4600, loss: 2.371952, top_1: 0.632656, top_k: 0.837891, samples/s: 785.376 1613346090.9600167
train: epoch 77, iter 4700, loss: 2.468513, top_1: 0.631016, top_k: 0.837695, samples/s: 786.612 1613346123.5046165
train: epoch 77, iter 4800, loss: 2.504245, top_1: 0.634883, top_k: 0.842734, samples/s: 784.859 1613346156.1219392
train: epoch 77, iter 4900, loss: 2.471895, top_1: 0.629922, top_k: 0.834844, samples/s: 784.038 1613346188.773478
train: epoch 77, iter 5000, loss: 2.478233, top_1: 0.635742, top_k: 0.838242, samples/s: 781.609 1613346221.5264533
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_77.
validation: epoch 77, iter 195, top_1: 0.679507, top_k: 0.885837, samples/s: 2374.638 1613346243.519384
train: epoch 78, iter 100, loss: 2.542594, top_1: 0.644492, top_k: 0.846289, samples/s: 804.566 1613346296.0358727
train: epoch 78, iter 200, loss: 2.302557, top_1: 0.643828, top_k: 0.848867, samples/s: 801.142 1613346327.9904802
train: epoch 78, iter 300, loss: 2.505702, top_1: 0.645547, top_k: 0.847383, samples/s: 786.270 1613346360.548992
train: epoch 78, iter 400, loss: 2.437091, top_1: 0.643867, top_k: 0.849258, samples/s: 783.318 1613346393.230492
train: epoch 78, iter 500, loss: 2.589339, top_1: 0.637734, top_k: 0.844180, samples/s: 781.064 1613346426.0063014
train: epoch 78, iter 600, loss: 2.526772, top_1: 0.634727, top_k: 0.839883, samples/s: 784.342 1613346458.6450276
train: epoch 78, iter 700, loss: 2.560955, top_1: 0.636563, top_k: 0.842344, samples/s: 783.546 1613346491.31702
train: epoch 78, iter 800, loss: 2.542905, top_1: 0.640430, top_k: 0.844336, samples/s: 782.682 1613346524.025028
train: epoch 78, iter 900, loss: 2.629861, top_1: 0.641719, top_k: 0.845273, samples/s: 784.430 1613346556.6602135
train: epoch 78, iter 1000, loss: 2.611067, top_1: 0.639453, top_k: 0.845547, samples/s: 781.440 1613346589.420215
train: epoch 78, iter 1100, loss: 2.458623, top_1: 0.637227, top_k: 0.843906, samples/s: 782.777 1613346622.1243808
train: epoch 78, iter 1200, loss: 2.596703, top_1: 0.631797, top_k: 0.841094, samples/s: 782.800 1613346654.827523
train: epoch 78, iter 1300, loss: 2.387955, top_1: 0.637500, top_k: 0.846250, samples/s: 784.944 1613346687.4412613
train: epoch 78, iter 1400, loss: 2.419478, top_1: 0.632969, top_k: 0.839258, samples/s: 785.176 1613346720.0455089
train: epoch 78, iter 1500, loss: 2.557508, top_1: 0.632305, top_k: 0.840156, samples/s: 782.719 1613346752.751984
train: epoch 78, iter 1600, loss: 2.459460, top_1: 0.637070, top_k: 0.843945, samples/s: 784.063 1613346785.4023485
train: epoch 78, iter 1700, loss: 2.346912, top_1: 0.640977, top_k: 0.845078, samples/s: 783.710 1613346818.0675921
train: epoch 78, iter 1800, loss: 2.385765, top_1: 0.640586, top_k: 0.841016, samples/s: 784.755 1613346850.689163
train: epoch 78, iter 1900, loss: 2.289214, top_1: 0.635703, top_k: 0.845156, samples/s: 782.925 1613346883.3870115
train: epoch 78, iter 2000, loss: 2.569604, top_1: 0.632812, top_k: 0.842539, samples/s: 783.485 1613346916.061645
train: epoch 78, iter 2100, loss: 2.575861, top_1: 0.629531, top_k: 0.838867, samples/s: 781.838 1613346948.804938
train: epoch 78, iter 2200, loss: 2.387397, top_1: 0.634844, top_k: 0.840742, samples/s: 787.266 1613346981.3225925
train: epoch 78, iter 2300, loss: 2.341394, top_1: 0.628047, top_k: 0.839609, samples/s: 782.076 1613347014.0559092
train: epoch 78, iter 2400, loss: 2.594193, top_1: 0.632656, top_k: 0.839453, samples/s: 785.194 1613347046.6593547
train: epoch 78, iter 2500, loss: 2.387787, top_1: 0.628828, top_k: 0.835508, samples/s: 783.061 1613347079.3515716
train: epoch 78, iter 2600, loss: 2.574426, top_1: 0.626953, top_k: 0.838203, samples/s: 784.877 1613347111.9680903
train: epoch 78, iter 2700, loss: 2.303777, top_1: 0.632031, top_k: 0.841406, samples/s: 783.785 1613347144.6300871
train: epoch 78, iter 2800, loss: 2.648420, top_1: 0.636641, top_k: 0.840703, samples/s: 782.337 1613347177.352614
train: epoch 78, iter 2900, loss: 2.639677, top_1: 0.633047, top_k: 0.839727, samples/s: 786.625 1613347209.8967896
train: epoch 78, iter 3000, loss: 2.668456, top_1: 0.630156, top_k: 0.837500, samples/s: 784.121 1613347242.5447862
train: epoch 78, iter 3100, loss: 2.240325, top_1: 0.638437, top_k: 0.841211, samples/s: 783.407 1613347275.2225873
train: epoch 78, iter 3200, loss: 2.564526, top_1: 0.631133, top_k: 0.840586, samples/s: 783.510 1613347307.8959832
train: epoch 78, iter 3300, loss: 2.514889, top_1: 0.631523, top_k: 0.841484, samples/s: 784.602 1613347340.524026
train: epoch 78, iter 3400, loss: 2.444483, top_1: 0.632969, top_k: 0.839922, samples/s: 784.499 1613347373.1563172
train: epoch 78, iter 3500, loss: 2.386782, top_1: 0.626250, top_k: 0.839297, samples/s: 783.585 1613347405.8267071
train: epoch 78, iter 3600, loss: 2.476653, top_1: 0.628164, top_k: 0.838281, samples/s: 786.628 1613347438.3705754
train: epoch 78, iter 3700, loss: 2.247157, top_1: 0.630508, top_k: 0.841328, samples/s: 784.271 1613347471.0124621
train: epoch 78, iter 3800, loss: 2.382116, top_1: 0.638672, top_k: 0.843242, samples/s: 782.430 1613347503.7309542
train: epoch 78, iter 3900, loss: 2.315054, top_1: 0.632383, top_k: 0.839297, samples/s: 785.810 1613347536.3088076
train: epoch 78, iter 4000, loss: 2.495814, top_1: 0.632422, top_k: 0.837461, samples/s: 784.562 1613347568.9385417
train: epoch 78, iter 4100, loss: 2.586707, top_1: 0.633555, top_k: 0.839688, samples/s: 784.982 1613347601.5506794
train: epoch 78, iter 4200, loss: 2.419844, top_1: 0.631094, top_k: 0.838711, samples/s: 783.884 1613347634.208531
train: epoch 78, iter 4300, loss: 2.570004, top_1: 0.630898, top_k: 0.841836, samples/s: 783.520 1613347666.8816488
train: epoch 78, iter 4400, loss: 2.410693, top_1: 0.634219, top_k: 0.839609, samples/s: 784.812 1613347699.500906
train: epoch 78, iter 4500, loss: 2.508190, top_1: 0.636133, top_k: 0.845078, samples/s: 785.689 1613347732.0838046
train: epoch 78, iter 4600, loss: 2.337551, top_1: 0.632969, top_k: 0.837148, samples/s: 782.045 1613347764.8185663
train: epoch 78, iter 4700, loss: 2.463175, top_1: 0.638437, top_k: 0.840508, samples/s: 784.807 1613347797.4379396
train: epoch 78, iter 4800, loss: 2.491917, top_1: 0.628906, top_k: 0.839727, samples/s: 782.424 1613347830.1569006
train: epoch 78, iter 4900, loss: 2.321687, top_1: 0.625625, top_k: 0.835547, samples/s: 786.981 1613347862.6862571
train: epoch 78, iter 5000, loss: 2.512720, top_1: 0.634141, top_k: 0.842734, samples/s: 781.311 1613347895.4516268
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_78.
validation: epoch 78, iter 195, top_1: 0.682772, top_k: 0.888582, samples/s: 2384.312 1613347917.3868127
train: epoch 79, iter 100, loss: 2.529041, top_1: 0.642969, top_k: 0.847656, samples/s: 804.199 1613347969.655145
train: epoch 79, iter 200, loss: 2.517633, top_1: 0.641836, top_k: 0.846094, samples/s: 800.328 1613348001.641997
train: epoch 79, iter 300, loss: 2.481305, top_1: 0.642188, top_k: 0.849297, samples/s: 784.324 1613348034.2816322
train: epoch 79, iter 400, loss: 2.540280, top_1: 0.647227, top_k: 0.851992, samples/s: 783.880 1613348066.9396632
train: epoch 79, iter 500, loss: 2.524292, top_1: 0.641641, top_k: 0.846953, samples/s: 783.203 1613348099.6260777
train: epoch 79, iter 600, loss: 2.404914, top_1: 0.640625, top_k: 0.845508, samples/s: 781.588 1613348132.3798316
train: epoch 79, iter 700, loss: 2.562094, top_1: 0.648438, top_k: 0.851172, samples/s: 780.379 1613348165.184293
train: epoch 79, iter 800, loss: 2.290370, top_1: 0.639414, top_k: 0.845039, samples/s: 781.607 1613348197.9373753
train: epoch 79, iter 900, loss: 2.251644, top_1: 0.643359, top_k: 0.847383, samples/s: 783.430 1613348230.6147277
train: epoch 79, iter 1000, loss: 2.364930, top_1: 0.641172, top_k: 0.846719, samples/s: 782.958 1613348263.3107007
train: epoch 79, iter 1100, loss: 2.363061, top_1: 0.638008, top_k: 0.844961, samples/s: 780.899 1613348296.0933812
train: epoch 79, iter 1200, loss: 2.396375, top_1: 0.637227, top_k: 0.841211, samples/s: 784.072 1613348328.743777
train: epoch 79, iter 1300, loss: 2.624127, top_1: 0.633867, top_k: 0.844336, samples/s: 783.523 1613348361.4164627
train: epoch 79, iter 1400, loss: 2.608476, top_1: 0.640742, top_k: 0.844102, samples/s: 781.892 1613348394.1574323
train: epoch 79, iter 1500, loss: 2.537894, top_1: 0.632539, top_k: 0.843516, samples/s: 783.545 1613348426.8295252
train: epoch 79, iter 1600, loss: 2.554463, top_1: 0.638555, top_k: 0.843281, samples/s: 786.635 1613348459.3732245
train: epoch 79, iter 1700, loss: 2.710788, top_1: 0.634297, top_k: 0.843555, samples/s: 781.404 1613348492.1347613
train: epoch 79, iter 1800, loss: 2.625395, top_1: 0.634687, top_k: 0.841641, samples/s: 780.843 1613348524.9198656
train: epoch 79, iter 1900, loss: 2.444226, top_1: 0.639297, top_k: 0.843672, samples/s: 783.943 1613348557.5752287
train: epoch 79, iter 2000, loss: 2.568188, top_1: 0.637969, top_k: 0.844648, samples/s: 782.189 1613348590.303875
train: epoch 79, iter 2100, loss: 2.716729, top_1: 0.641055, top_k: 0.846719, samples/s: 785.059 1613348622.912996
train: epoch 79, iter 2200, loss: 2.487186, top_1: 0.639844, top_k: 0.840000, samples/s: 781.203 1613348655.6828716
train: epoch 79, iter 2300, loss: 2.520555, top_1: 0.631953, top_k: 0.840781, samples/s: 786.617 1613348688.2274024
train: epoch 79, iter 2400, loss: 2.624478, top_1: 0.629648, top_k: 0.839375, samples/s: 781.894 1613348720.9684186
train: epoch 79, iter 2500, loss: 2.606878, top_1: 0.634180, top_k: 0.839727, samples/s: 785.127 1613348753.5745423
train: epoch 79, iter 2600, loss: 2.448770, top_1: 0.634609, top_k: 0.841719, samples/s: 782.241 1613348786.3010857
train: epoch 79, iter 2700, loss: 2.478909, top_1: 0.636016, top_k: 0.844258, samples/s: 783.492 1613348818.9752104
train: epoch 79, iter 2800, loss: 2.418793, top_1: 0.632891, top_k: 0.841758, samples/s: 782.645 1613348851.6847954
train: epoch 79, iter 2900, loss: 2.412673, top_1: 0.634922, top_k: 0.840977, samples/s: 782.909 1613348884.3834512
train: epoch 79, iter 3000, loss: 2.553760, top_1: 0.630820, top_k: 0.841172, samples/s: 786.237 1613348916.9435513
train: epoch 79, iter 3100, loss: 2.527740, top_1: 0.635859, top_k: 0.841641, samples/s: 784.925 1613348949.5580933
train: epoch 79, iter 3200, loss: 2.431036, top_1: 0.631797, top_k: 0.836914, samples/s: 784.271 1613348982.1998744
train: epoch 79, iter 3300, loss: 2.273742, top_1: 0.637773, top_k: 0.846328, samples/s: 783.950 1613349014.8549984
train: epoch 79, iter 3400, loss: 2.369518, top_1: 0.636523, top_k: 0.841914, samples/s: 780.806 1613349047.641654
train: epoch 79, iter 3500, loss: 2.696419, top_1: 0.630898, top_k: 0.842422, samples/s: 784.275 1613349080.2833278
train: epoch 79, iter 3600, loss: 2.412900, top_1: 0.635430, top_k: 0.845117, samples/s: 784.477 1613349112.9165056
train: epoch 79, iter 3700, loss: 2.510997, top_1: 0.636289, top_k: 0.840742, samples/s: 784.439 1613349145.55137
train: epoch 79, iter 3800, loss: 2.749150, top_1: 0.637891, top_k: 0.840938, samples/s: 783.258 1613349178.2352607
train: epoch 79, iter 3900, loss: 2.581998, top_1: 0.629844, top_k: 0.837617, samples/s: 786.823 1613349210.7711902
train: epoch 79, iter 4000, loss: 2.372959, top_1: 0.635078, top_k: 0.839570, samples/s: 781.960 1613349243.5094972
train: epoch 79, iter 4100, loss: 2.441219, top_1: 0.631055, top_k: 0.835781, samples/s: 784.973 1613349276.1221032
train: epoch 79, iter 4200, loss: 2.403260, top_1: 0.632148, top_k: 0.840156, samples/s: 784.747 1613349308.7439635
train: epoch 79, iter 4300, loss: 2.570141, top_1: 0.630195, top_k: 0.843047, samples/s: 780.967 1613349341.5239258
train: epoch 79, iter 4400, loss: 2.558620, top_1: 0.636523, top_k: 0.842383, samples/s: 785.090 1613349374.1315365
train: epoch 79, iter 4500, loss: 2.668685, top_1: 0.630742, top_k: 0.840898, samples/s: 784.468 1613349406.765213
train: epoch 79, iter 4600, loss: 2.623041, top_1: 0.629844, top_k: 0.838633, samples/s: 783.270 1613349439.4486654
train: epoch 79, iter 4700, loss: 2.392376, top_1: 0.633789, top_k: 0.838633, samples/s: 784.360 1613349472.0867438
train: epoch 79, iter 4800, loss: 2.418552, top_1: 0.630234, top_k: 0.838203, samples/s: 782.288 1613349504.8113544
train: epoch 79, iter 4900, loss: 2.598992, top_1: 0.632930, top_k: 0.839336, samples/s: 784.334 1613349537.4504838
train: epoch 79, iter 5000, loss: 2.432600, top_1: 0.641289, top_k: 0.844922, samples/s: 783.980 1613349570.104338
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_79.
validation: epoch 79, iter 195, top_1: 0.682813, top_k: 0.889323, samples/s: 2406.445 1613349591.7856677
train: epoch 80, iter 100, loss: 2.414930, top_1: 0.650078, top_k: 0.852461, samples/s: 805.465 1613349644.8840802
train: epoch 80, iter 200, loss: 2.416972, top_1: 0.643164, top_k: 0.846016, samples/s: 799.656 1613349676.8978257
train: epoch 80, iter 300, loss: 2.181439, top_1: 0.645547, top_k: 0.848281, samples/s: 785.434 1613349709.4912107
train: epoch 80, iter 400, loss: 2.707876, top_1: 0.644102, top_k: 0.846211, samples/s: 784.616 1613349742.1186712
train: epoch 80, iter 500, loss: 2.435903, top_1: 0.644648, top_k: 0.851445, samples/s: 781.098 1613349774.8930318
train: epoch 80, iter 600, loss: 2.556104, top_1: 0.645781, top_k: 0.851797, samples/s: 782.069 1613349807.6267726
train: epoch 80, iter 700, loss: 2.326993, top_1: 0.646055, top_k: 0.849727, samples/s: 784.921 1613349840.2414823
train: epoch 80, iter 800, loss: 2.531911, top_1: 0.641836, top_k: 0.844063, samples/s: 782.399 1613349872.961425
train: epoch 80, iter 900, loss: 2.451066, top_1: 0.639805, top_k: 0.843242, samples/s: 783.412 1613349905.6389318
train: epoch 80, iter 1000, loss: 2.318027, top_1: 0.638633, top_k: 0.844180, samples/s: 784.746 1613349938.260961
train: epoch 80, iter 1100, loss: 2.336808, top_1: 0.641406, top_k: 0.842773, samples/s: 784.692 1613349970.885236
train: epoch 80, iter 1200, loss: 2.495507, top_1: 0.637070, top_k: 0.844492, samples/s: 782.833 1613350003.5870438
train: epoch 80, iter 1300, loss: 2.397066, top_1: 0.642734, top_k: 0.845078, samples/s: 783.045 1613350036.2798345
train: epoch 80, iter 1400, loss: 2.528903, top_1: 0.640156, top_k: 0.844766, samples/s: 779.274 1613350069.1311376
train: epoch 80, iter 1500, loss: 2.553942, top_1: 0.637500, top_k: 0.838516, samples/s: 783.682 1613350101.7972207
train: epoch 80, iter 1600, loss: 2.481418, top_1: 0.640195, top_k: 0.847187, samples/s: 782.910 1613350134.495776
train: epoch 80, iter 1700, loss: 2.558679, top_1: 0.632148, top_k: 0.841680, samples/s: 786.884 1613350167.029106
train: epoch 80, iter 1800, loss: 2.713104, top_1: 0.638437, top_k: 0.841367, samples/s: 782.845 1613350199.7304432
train: epoch 80, iter 1900, loss: 2.437926, top_1: 0.639570, top_k: 0.847266, samples/s: 785.100 1613350232.3377285
train: epoch 80, iter 2000, loss: 2.438442, top_1: 0.641992, top_k: 0.848633, samples/s: 779.695 1613350265.1711354
train: epoch 80, iter 2100, loss: 2.413181, top_1: 0.638437, top_k: 0.842734, samples/s: 784.337 1613350297.8101566
train: epoch 80, iter 2200, loss: 2.496284, top_1: 0.638086, top_k: 0.843828, samples/s: 782.454 1613350330.527699
train: epoch 80, iter 2300, loss: 2.572545, top_1: 0.638281, top_k: 0.845039, samples/s: 783.511 1613350363.2010956
train: epoch 80, iter 2400, loss: 2.541259, top_1: 0.633047, top_k: 0.841875, samples/s: 783.453 1613350395.8769753
train: epoch 80, iter 2500, loss: 2.589369, top_1: 0.641133, top_k: 0.844453, samples/s: 781.827 1613350428.620758
train: epoch 80, iter 2600, loss: 2.874558, top_1: 0.641875, top_k: 0.843945, samples/s: 783.802 1613350461.2821143
train: epoch 80, iter 2700, loss: 2.462153, top_1: 0.639531, top_k: 0.841836, samples/s: 784.904 1613350493.8975306
train: epoch 80, iter 2800, loss: 2.373473, top_1: 0.635625, top_k: 0.842656, samples/s: 783.918 1613350526.5539453
train: epoch 80, iter 2900, loss: 2.587055, top_1: 0.637852, top_k: 0.846094, samples/s: 783.658 1613350559.2213392
train: epoch 80, iter 3000, loss: 2.596080, top_1: 0.635508, top_k: 0.841758, samples/s: 783.327 1613350591.9023957
train: epoch 80, iter 3100, loss: 2.472683, top_1: 0.636094, top_k: 0.845313, samples/s: 783.422 1613350624.5795627
train: epoch 80, iter 3200, loss: 2.693836, top_1: 0.639062, top_k: 0.844297, samples/s: 785.083 1613350657.1876051
train: epoch 80, iter 3300, loss: 2.463491, top_1: 0.636719, top_k: 0.844297, samples/s: 779.862 1613350690.0139792
train: epoch 80, iter 3400, loss: 2.491737, top_1: 0.640039, top_k: 0.843633, samples/s: 788.481 1613350722.4814742
train: epoch 80, iter 3500, loss: 2.746388, top_1: 0.628477, top_k: 0.837227, samples/s: 783.543 1613350755.1535385
train: epoch 80, iter 3600, loss: 2.442589, top_1: 0.634609, top_k: 0.842344, samples/s: 784.856 1613350787.771033
train: epoch 80, iter 3700, loss: 2.445191, top_1: 0.632812, top_k: 0.840117, samples/s: 783.051 1613350820.463596
train: epoch 80, iter 3800, loss: 2.627612, top_1: 0.635391, top_k: 0.840156, samples/s: 779.166 1613350853.31921
train: epoch 80, iter 3900, loss: 2.273442, top_1: 0.635117, top_k: 0.841719, samples/s: 786.646 1613350885.862442
train: epoch 80, iter 4000, loss: 2.673653, top_1: 0.635820, top_k: 0.845586, samples/s: 782.428 1613350918.581126
train: epoch 80, iter 4100, loss: 2.405154, top_1: 0.633828, top_k: 0.840977, samples/s: 782.696 1613350951.288586
train: epoch 80, iter 4200, loss: 2.561165, top_1: 0.637305, top_k: 0.842422, samples/s: 783.416 1613350983.9659715
train: epoch 80, iter 4300, loss: 2.434533, top_1: 0.637344, top_k: 0.840703, samples/s: 781.622 1613351016.7184556
train: epoch 80, iter 4400, loss: 2.565965, top_1: 0.635781, top_k: 0.840273, samples/s: 783.451 1613351049.39436
train: epoch 80, iter 4500, loss: 2.633215, top_1: 0.631758, top_k: 0.841094, samples/s: 784.454 1613351082.0285637
train: epoch 80, iter 4600, loss: 2.280655, top_1: 0.635430, top_k: 0.840898, samples/s: 782.543 1613351114.7424107
train: epoch 80, iter 4700, loss: 2.596937, top_1: 0.632070, top_k: 0.840820, samples/s: 783.174 1613351147.4298515
train: epoch 80, iter 4800, loss: 2.570938, top_1: 0.629375, top_k: 0.837070, samples/s: 781.696 1613351180.1792278
train: epoch 80, iter 4900, loss: 2.396651, top_1: 0.630664, top_k: 0.836250, samples/s: 785.242 1613351212.7806077
train: epoch 80, iter 5000, loss: 2.483477, top_1: 0.635938, top_k: 0.841914, samples/s: 783.015 1613351245.4747505
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_80.
validation: epoch 80, iter 195, top_1: 0.682151, top_k: 0.889263, samples/s: 2358.977 1613351267.5993292
train: epoch 81, iter 100, loss: 2.512405, top_1: 0.656406, top_k: 0.855430, samples/s: 802.520 1613351319.9454427
train: epoch 81, iter 200, loss: 2.373581, top_1: 0.641680, top_k: 0.846484, samples/s: 800.441 1613351351.9279332
train: epoch 81, iter 300, loss: 2.502782, top_1: 0.643672, top_k: 0.851523, samples/s: 786.365 1613351384.482744
train: epoch 81, iter 400, loss: 2.429012, top_1: 0.652734, top_k: 0.852617, samples/s: 783.359 1613351417.162465
train: epoch 81, iter 500, loss: 2.495891, top_1: 0.651719, top_k: 0.853516, samples/s: 780.385 1613351449.9668057
train: epoch 81, iter 600, loss: 2.515195, top_1: 0.647617, top_k: 0.850859, samples/s: 783.437 1613351482.6432934
train: epoch 81, iter 700, loss: 2.330251, top_1: 0.646445, top_k: 0.850547, samples/s: 783.846 1613351515.3027036
train: epoch 81, iter 800, loss: 2.560363, top_1: 0.641406, top_k: 0.848867, samples/s: 780.927 1613351548.0842526
train: epoch 81, iter 900, loss: 2.610434, top_1: 0.636055, top_k: 0.845039, samples/s: 783.112 1613351580.7744505
train: epoch 81, iter 1000, loss: 2.258171, top_1: 0.641094, top_k: 0.846836, samples/s: 784.028 1613351613.4263158
train: epoch 81, iter 1100, loss: 2.582818, top_1: 0.638750, top_k: 0.840781, samples/s: 782.801 1613351646.1293347
train: epoch 81, iter 1200, loss: 2.416170, top_1: 0.641055, top_k: 0.849023, samples/s: 782.300 1613351678.853456
train: epoch 81, iter 1300, loss: 2.291568, top_1: 0.648359, top_k: 0.848672, samples/s: 780.995 1613351711.6321778
train: epoch 81, iter 1400, loss: 2.288760, top_1: 0.639141, top_k: 0.848984, samples/s: 783.384 1613351744.310767
train: epoch 81, iter 1500, loss: 2.360022, top_1: 0.643320, top_k: 0.844727, samples/s: 785.945 1613351776.8830838
train: epoch 81, iter 1600, loss: 2.426444, top_1: 0.641953, top_k: 0.844336, samples/s: 783.076 1613351809.574653
train: epoch 81, iter 1700, loss: 2.501864, top_1: 0.642461, top_k: 0.843633, samples/s: 782.940 1613351842.2719214
train: epoch 81, iter 1800, loss: 2.553906, top_1: 0.642578, top_k: 0.847148, samples/s: 784.406 1613351874.9082282
train: epoch 81, iter 1900, loss: 2.366147, top_1: 0.637422, top_k: 0.843281, samples/s: 782.355 1613351907.6298409
train: epoch 81, iter 2000, loss: 2.417188, top_1: 0.637656, top_k: 0.845234, samples/s: 785.241 1613351940.2313027
train: epoch 81, iter 2100, loss: 2.574672, top_1: 0.631992, top_k: 0.840742, samples/s: 783.796 1613351972.8927999
train: epoch 81, iter 2200, loss: 2.427010, top_1: 0.639102, top_k: 0.846250, samples/s: 784.615 1613352005.5203097
train: epoch 81, iter 2300, loss: 2.595179, top_1: 0.638906, top_k: 0.841328, samples/s: 782.464 1613352038.2375321
train: epoch 81, iter 2400, loss: 2.522442, top_1: 0.637852, top_k: 0.844727, samples/s: 782.169 1613352070.9669893
train: epoch 81, iter 2500, loss: 2.696048, top_1: 0.631875, top_k: 0.841328, samples/s: 782.219 1613352103.6943934
train: epoch 81, iter 2600, loss: 2.330220, top_1: 0.643125, top_k: 0.842187, samples/s: 785.185 1613352136.2981067
train: epoch 81, iter 2700, loss: 2.469104, top_1: 0.641172, top_k: 0.843164, samples/s: 782.232 1613352169.0249195
train: epoch 81, iter 2800, loss: 2.416682, top_1: 0.635859, top_k: 0.845273, samples/s: 785.046 1613352201.634538
train: epoch 81, iter 2900, loss: 2.447814, top_1: 0.636914, top_k: 0.846133, samples/s: 782.618 1613352234.3452096
train: epoch 81, iter 3000, loss: 2.337167, top_1: 0.638516, top_k: 0.841289, samples/s: 784.166 1613352266.991339
train: epoch 81, iter 3100, loss: 2.609155, top_1: 0.641250, top_k: 0.843828, samples/s: 784.047 1613352299.642476
train: epoch 81, iter 3200, loss: 2.443948, top_1: 0.636914, top_k: 0.842305, samples/s: 784.560 1613352332.272323
train: epoch 81, iter 3300, loss: 2.487631, top_1: 0.633867, top_k: 0.842500, samples/s: 782.131 1613352365.0032933
train: epoch 81, iter 3400, loss: 2.694515, top_1: 0.636953, top_k: 0.845898, samples/s: 783.912 1613352397.6600394
train: epoch 81, iter 3500, loss: 2.583514, top_1: 0.632812, top_k: 0.843203, samples/s: 783.696 1613352430.3257906
train: epoch 81, iter 3600, loss: 2.499729, top_1: 0.636719, top_k: 0.844258, samples/s: 783.953 1613352462.9808412
train: epoch 81, iter 3700, loss: 2.322558, top_1: 0.639414, top_k: 0.844688, samples/s: 781.650 1613352495.732065
train: epoch 81, iter 3800, loss: 2.430370, top_1: 0.641602, top_k: 0.844375, samples/s: 785.042 1613352528.341726
train: epoch 81, iter 3900, loss: 2.467107, top_1: 0.636797, top_k: 0.841914, samples/s: 782.907 1613352561.0404131
train: epoch 81, iter 4000, loss: 2.440564, top_1: 0.637734, top_k: 0.843281, samples/s: 783.812 1613352593.7012951
train: epoch 81, iter 4100, loss: 2.347080, top_1: 0.641367, top_k: 0.846211, samples/s: 782.645 1613352626.4109216
train: epoch 81, iter 4200, loss: 2.509407, top_1: 0.634766, top_k: 0.841328, samples/s: 783.866 1613352659.0695312
train: epoch 81, iter 4300, loss: 2.458827, top_1: 0.635273, top_k: 0.841094, samples/s: 782.970 1613352691.7655132
train: epoch 81, iter 4400, loss: 2.502572, top_1: 0.636914, top_k: 0.843203, samples/s: 784.224 1613352724.4092145
train: epoch 81, iter 4500, loss: 2.454353, top_1: 0.636289, top_k: 0.840039, samples/s: 781.444 1613352757.169176
train: epoch 81, iter 4600, loss: 2.400103, top_1: 0.634023, top_k: 0.839766, samples/s: 785.611 1613352789.7552116
train: epoch 81, iter 4700, loss: 2.499239, top_1: 0.635508, top_k: 0.841055, samples/s: 783.310 1613352822.437108
train: epoch 81, iter 4800, loss: 2.512575, top_1: 0.636172, top_k: 0.838984, samples/s: 784.182 1613352855.0826032
train: epoch 81, iter 4900, loss: 2.458620, top_1: 0.635312, top_k: 0.841719, samples/s: 782.447 1613352887.8004105
train: epoch 81, iter 5000, loss: 2.382927, top_1: 0.642422, top_k: 0.845078, samples/s: 783.358 1613352920.4803042
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_81.
validation: epoch 81, iter 195, top_1: 0.687620, top_k: 0.890966, samples/s: 2399.529 1613352942.245608
train: epoch 82, iter 100, loss: 2.367038, top_1: 0.645273, top_k: 0.851094, samples/s: 804.370 1613352994.2313972
train: epoch 82, iter 200, loss: 2.412110, top_1: 0.651875, top_k: 0.849141, samples/s: 801.894 1613353026.1557
train: epoch 82, iter 300, loss: 2.410408, top_1: 0.641602, top_k: 0.848398, samples/s: 785.646 1613353058.7403412
train: epoch 82, iter 400, loss: 2.432556, top_1: 0.651758, top_k: 0.851133, samples/s: 784.483 1613353091.373295
train: epoch 82, iter 500, loss: 2.400634, top_1: 0.650352, top_k: 0.849688, samples/s: 782.750 1613353124.0785315
train: epoch 82, iter 600, loss: 2.545501, top_1: 0.647070, top_k: 0.848945, samples/s: 779.781 1613353156.908226
train: epoch 82, iter 700, loss: 2.327107, top_1: 0.640664, top_k: 0.843750, samples/s: 783.271 1613353189.5916934
train: epoch 82, iter 800, loss: 2.459135, top_1: 0.645977, top_k: 0.849805, samples/s: 784.199 1613353222.2365475
train: epoch 82, iter 900, loss: 2.441704, top_1: 0.652422, top_k: 0.853477, samples/s: 779.237 1613353255.0891373
train: epoch 82, iter 1000, loss: 2.472850, top_1: 0.636953, top_k: 0.842266, samples/s: 783.457 1613353287.7648728
train: epoch 82, iter 1100, loss: 2.361213, top_1: 0.643125, top_k: 0.849219, samples/s: 783.712 1613353320.4298892
train: epoch 82, iter 1200, loss: 2.409682, top_1: 0.640781, top_k: 0.845391, samples/s: 782.386 1613353353.1503484
train: epoch 82, iter 1300, loss: 2.470978, top_1: 0.652852, top_k: 0.849727, samples/s: 784.158 1613353385.7968066
train: epoch 82, iter 1400, loss: 2.448602, top_1: 0.647109, top_k: 0.848359, samples/s: 784.159 1613353418.4432395
train: epoch 82, iter 1500, loss: 2.589980, top_1: 0.645273, top_k: 0.851445, samples/s: 783.708 1613353451.1084647
train: epoch 82, iter 1600, loss: 2.318030, top_1: 0.643281, top_k: 0.847187, samples/s: 783.524 1613353483.7814057
train: epoch 82, iter 1700, loss: 2.437797, top_1: 0.638711, top_k: 0.845781, samples/s: 782.354 1613353516.5031478
train: epoch 82, iter 1800, loss: 2.587158, top_1: 0.637578, top_k: 0.843203, samples/s: 786.075 1613353549.07
train: epoch 82, iter 1900, loss: 2.341144, top_1: 0.643398, top_k: 0.847305, samples/s: 782.041 1613353581.8048115
train: epoch 82, iter 2000, loss: 2.419128, top_1: 0.637422, top_k: 0.841680, samples/s: 783.078 1613353614.4964113
train: epoch 82, iter 2100, loss: 2.526599, top_1: 0.644180, top_k: 0.849844, samples/s: 783.088 1613353647.1874826
train: epoch 82, iter 2200, loss: 2.345947, top_1: 0.648086, top_k: 0.846211, samples/s: 783.250 1613353679.8717735
train: epoch 82, iter 2300, loss: 2.410970, top_1: 0.644219, top_k: 0.846641, samples/s: 782.213 1613353712.5994923
train: epoch 82, iter 2400, loss: 2.473077, top_1: 0.638750, top_k: 0.842930, samples/s: 783.488 1613353745.2738056
train: epoch 82, iter 2500, loss: 2.366827, top_1: 0.641641, top_k: 0.843125, samples/s: 782.503 1613353777.989339
train: epoch 82, iter 2600, loss: 2.479890, top_1: 0.640898, top_k: 0.846875, samples/s: 782.376 1613353810.710231
train: epoch 82, iter 2700, loss: 2.534400, top_1: 0.640039, top_k: 0.845117, samples/s: 783.366 1613353843.38976
train: epoch 82, iter 2800, loss: 2.567780, top_1: 0.646055, top_k: 0.847578, samples/s: 782.827 1613353876.091663
train: epoch 82, iter 2900, loss: 2.514933, top_1: 0.632227, top_k: 0.845664, samples/s: 784.768 1613353908.7127903
train: epoch 82, iter 3000, loss: 2.406957, top_1: 0.637461, top_k: 0.845195, samples/s: 782.723 1613353941.419151
train: epoch 82, iter 3100, loss: 2.551088, top_1: 0.640469, top_k: 0.846367, samples/s: 783.182 1613353974.1062706
train: epoch 82, iter 3200, loss: 2.479245, top_1: 0.641719, top_k: 0.845313, samples/s: 782.625 1613354006.816812
train: epoch 82, iter 3300, loss: 2.540458, top_1: 0.642109, top_k: 0.848203, samples/s: 783.456 1613354039.4924176
train: epoch 82, iter 3400, loss: 2.550178, top_1: 0.635859, top_k: 0.843242, samples/s: 783.278 1613354072.1755135
train: epoch 82, iter 3500, loss: 2.512921, top_1: 0.637891, top_k: 0.845547, samples/s: 782.611 1613354104.8865411
train: epoch 82, iter 3600, loss: 2.619494, top_1: 0.640508, top_k: 0.843672, samples/s: 783.277 1613354137.5697753
train: epoch 82, iter 3700, loss: 2.443664, top_1: 0.637109, top_k: 0.840195, samples/s: 784.453 1613354170.2040336
train: epoch 82, iter 3800, loss: 2.588123, top_1: 0.641406, top_k: 0.846445, samples/s: 782.511 1613354202.9192243
train: epoch 82, iter 3900, loss: 2.644178, top_1: 0.641992, top_k: 0.844961, samples/s: 782.801 1613354235.622287
train: epoch 82, iter 4000, loss: 2.440629, top_1: 0.640938, top_k: 0.842617, samples/s: 779.166 1613354268.47789
train: epoch 82, iter 4100, loss: 2.470421, top_1: 0.633945, top_k: 0.839219, samples/s: 785.682 1613354301.0610752
train: epoch 82, iter 4200, loss: 2.507996, top_1: 0.636641, top_k: 0.842305, samples/s: 779.325 1613354333.9099615
train: epoch 82, iter 4300, loss: 2.561822, top_1: 0.637813, top_k: 0.844688, samples/s: 780.453 1613354366.7114615
train: epoch 82, iter 4400, loss: 2.585785, top_1: 0.637344, top_k: 0.842227, samples/s: 785.726 1613354399.2927973
train: epoch 82, iter 4500, loss: 2.388420, top_1: 0.641719, top_k: 0.845625, samples/s: 779.172 1613354432.1481154
train: epoch 82, iter 4600, loss: 2.537207, top_1: 0.638047, top_k: 0.843945, samples/s: 786.349 1613354464.7036881
train: epoch 82, iter 4700, loss: 2.283754, top_1: 0.638086, top_k: 0.845898, samples/s: 782.431 1613354497.4222376
train: epoch 82, iter 4800, loss: 2.344684, top_1: 0.633594, top_k: 0.844336, samples/s: 782.357 1613354530.1439502
train: epoch 82, iter 4900, loss: 2.285703, top_1: 0.635781, top_k: 0.839102, samples/s: 780.385 1613354562.948191
train: epoch 82, iter 5000, loss: 2.493819, top_1: 0.639727, top_k: 0.847500, samples/s: 781.587 1613354595.7021282
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_82.
validation: epoch 82, iter 195, top_1: 0.684836, top_k: 0.889423, samples/s: 2392.410 1613354617.5717397
train: epoch 83, iter 100, loss: 2.330452, top_1: 0.648984, top_k: 0.851289, samples/s: 803.512 1613354669.7652018
train: epoch 83, iter 200, loss: 2.499790, top_1: 0.648008, top_k: 0.852148, samples/s: 799.383 1613354701.7899063
train: epoch 83, iter 300, loss: 2.377847, top_1: 0.647539, top_k: 0.852227, samples/s: 782.635 1613354734.4998899
train: epoch 83, iter 400, loss: 2.534281, top_1: 0.650430, top_k: 0.849648, samples/s: 783.948 1613354767.155157
train: epoch 83, iter 500, loss: 2.256251, top_1: 0.649844, top_k: 0.854531, samples/s: 779.428 1613354799.9996588
train: epoch 83, iter 600, loss: 2.493973, top_1: 0.649297, top_k: 0.851914, samples/s: 780.883 1613354832.7830815
train: epoch 83, iter 700, loss: 2.496318, top_1: 0.655977, top_k: 0.853711, samples/s: 780.686 1613354865.5748131
train: epoch 83, iter 800, loss: 2.530665, top_1: 0.652109, top_k: 0.852656, samples/s: 780.036 1613354898.3938186
train: epoch 83, iter 900, loss: 2.509632, top_1: 0.644414, top_k: 0.849492, samples/s: 782.020 1613354931.1295648
train: epoch 83, iter 1000, loss: 2.596658, top_1: 0.646367, top_k: 0.849141, samples/s: 784.492 1613354963.7620232
train: epoch 83, iter 1100, loss: 2.441906, top_1: 0.648164, top_k: 0.849141, samples/s: 780.394 1613354996.5660229
train: epoch 83, iter 1200, loss: 2.283942, top_1: 0.644297, top_k: 0.849570, samples/s: 781.694 1613355029.3154018
train: epoch 83, iter 1300, loss: 2.338131, top_1: 0.641875, top_k: 0.845469, samples/s: 777.929 1613355062.223357
train: epoch 83, iter 1400, loss: 2.461070, top_1: 0.638320, top_k: 0.842930, samples/s: 783.322 1613355094.9047048
train: epoch 83, iter 1500, loss: 2.653855, top_1: 0.641172, top_k: 0.843555, samples/s: 780.302 1613355127.7124884
train: epoch 83, iter 1600, loss: 2.588134, top_1: 0.640195, top_k: 0.846602, samples/s: 783.441 1613355160.3888397
train: epoch 83, iter 1700, loss: 2.317090, top_1: 0.650078, top_k: 0.848398, samples/s: 781.405 1613355193.1503685
train: epoch 83, iter 1800, loss: 2.387113, top_1: 0.641992, top_k: 0.848398, samples/s: 781.271 1613355225.9174402
train: epoch 83, iter 1900, loss: 2.387591, top_1: 0.643555, top_k: 0.849063, samples/s: 783.340 1613355258.5980535
train: epoch 83, iter 2000, loss: 2.438736, top_1: 0.639570, top_k: 0.848125, samples/s: 781.550 1613355291.3533874
train: epoch 83, iter 2100, loss: 2.445729, top_1: 0.647031, top_k: 0.850938, samples/s: 781.494 1613355324.1111465
train: epoch 83, iter 2200, loss: 2.407497, top_1: 0.638281, top_k: 0.839609, samples/s: 781.378 1613355356.8738594
train: epoch 83, iter 2300, loss: 2.539670, top_1: 0.644180, top_k: 0.849883, samples/s: 782.691 1613355389.5815432
train: epoch 83, iter 2400, loss: 2.457865, top_1: 0.643008, top_k: 0.850078, samples/s: 784.533 1613355422.212454
train: epoch 83, iter 2500, loss: 2.342437, top_1: 0.645820, top_k: 0.849492, samples/s: 780.123 1613355455.0277205
train: epoch 83, iter 2600, loss: 2.554612, top_1: 0.644023, top_k: 0.847383, samples/s: 782.581 1613355487.739948
train: epoch 83, iter 2700, loss: 2.456558, top_1: 0.643594, top_k: 0.848281, samples/s: 780.670 1613355520.5323384
train: epoch 83, iter 2800, loss: 2.559738, top_1: 0.644062, top_k: 0.846328, samples/s: 781.896 1613355553.2733104
train: epoch 83, iter 2900, loss: 2.314718, top_1: 0.639844, top_k: 0.846758, samples/s: 778.182 1613355586.1704426
train: epoch 83, iter 3000, loss: 2.391152, top_1: 0.640508, top_k: 0.847383, samples/s: 785.330 1613355618.7682276
train: epoch 83, iter 3100, loss: 2.486399, top_1: 0.637070, top_k: 0.845156, samples/s: 784.245 1613355651.4111176
train: epoch 83, iter 3200, loss: 2.615417, top_1: 0.638516, top_k: 0.842734, samples/s: 781.308 1613355684.176585
train: epoch 83, iter 3300, loss: 2.630680, top_1: 0.644375, top_k: 0.847578, samples/s: 784.868 1613355716.7935166
train: epoch 83, iter 3400, loss: 2.457122, top_1: 0.646445, top_k: 0.849844, samples/s: 782.044 1613355749.528288
train: epoch 83, iter 3500, loss: 2.346511, top_1: 0.643281, top_k: 0.848906, samples/s: 782.138 1613355782.2591503
train: epoch 83, iter 3600, loss: 2.544847, top_1: 0.638789, top_k: 0.844766, samples/s: 782.804 1613355814.9621248
train: epoch 83, iter 3700, loss: 2.618673, top_1: 0.633320, top_k: 0.842656, samples/s: 781.395 1613355847.7239935
train: epoch 83, iter 3800, loss: 2.417926, top_1: 0.642773, top_k: 0.844219, samples/s: 783.846 1613355880.3835137
train: epoch 83, iter 3900, loss: 2.546911, top_1: 0.641094, top_k: 0.847305, samples/s: 780.414 1613355913.1865165
train: epoch 83, iter 4000, loss: 2.403094, top_1: 0.641992, top_k: 0.844102, samples/s: 781.913 1613355945.9268014
train: epoch 83, iter 4100, loss: 2.461548, top_1: 0.643281, top_k: 0.850586, samples/s: 781.526 1613355978.6832983
train: epoch 83, iter 4200, loss: 2.475721, top_1: 0.638477, top_k: 0.846719, samples/s: 783.206 1613356011.3694339
train: epoch 83, iter 4300, loss: 2.467096, top_1: 0.641484, top_k: 0.847578, samples/s: 782.928 1613356044.067268
train: epoch 83, iter 4400, loss: 2.601143, top_1: 0.639141, top_k: 0.847344, samples/s: 782.995 1613356076.7620864
train: epoch 83, iter 4500, loss: 2.543344, top_1: 0.641211, top_k: 0.845664, samples/s: 780.054 1613356109.5804722
train: epoch 83, iter 4600, loss: 2.605133, top_1: 0.642344, top_k: 0.845430, samples/s: 780.379 1613356142.384922
train: epoch 83, iter 4700, loss: 2.486009, top_1: 0.640078, top_k: 0.845586, samples/s: 784.883 1613356175.0013065
train: epoch 83, iter 4800, loss: 2.281841, top_1: 0.636875, top_k: 0.842461, samples/s: 779.622 1613356207.8376186
train: epoch 83, iter 4900, loss: 2.542248, top_1: 0.639375, top_k: 0.843320, samples/s: 781.000 1613356240.6162267
train: epoch 83, iter 5000, loss: 2.572836, top_1: 0.647344, top_k: 0.847461, samples/s: 782.929 1613356273.3138762
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_83.
validation: epoch 83, iter 195, top_1: 0.687961, top_k: 0.891767, samples/s: 2363.287 1613356295.4069376
train: epoch 84, iter 100, loss: 2.498002, top_1: 0.656797, top_k: 0.856719, samples/s: 803.904 1613356353.5413837
train: epoch 84, iter 200, loss: 2.498946, top_1: 0.652461, top_k: 0.852148, samples/s: 802.632 1613356385.4366503
train: epoch 84, iter 300, loss: 2.359129, top_1: 0.647344, top_k: 0.851758, samples/s: 787.680 1613356417.936816
train: epoch 84, iter 400, loss: 2.347660, top_1: 0.649141, top_k: 0.850273, samples/s: 780.141 1613356450.7514248
train: epoch 84, iter 500, loss: 2.342132, top_1: 0.650703, top_k: 0.851875, samples/s: 779.277 1613356483.602387
train: epoch 84, iter 600, loss: 2.428348, top_1: 0.652930, top_k: 0.850117, samples/s: 779.171 1613356516.4578416
train: epoch 84, iter 700, loss: 2.370840, top_1: 0.654414, top_k: 0.851992, samples/s: 781.983 1613356549.1951466
train: epoch 84, iter 800, loss: 2.548199, top_1: 0.648555, top_k: 0.852969, samples/s: 781.240 1613356581.9635534
train: epoch 84, iter 900, loss: 2.284376, top_1: 0.642148, top_k: 0.848828, samples/s: 781.642 1613356614.7151885
train: epoch 84, iter 1000, loss: 2.380879, top_1: 0.647656, top_k: 0.850508, samples/s: 783.553 1613356647.3868759
train: epoch 84, iter 1100, loss: 2.632935, top_1: 0.651406, top_k: 0.855156, samples/s: 779.844 1613356680.2138517
train: epoch 84, iter 1200, loss: 2.486183, top_1: 0.655195, top_k: 0.855547, samples/s: 784.127 1613356712.8616703
train: epoch 84, iter 1300, loss: 2.584399, top_1: 0.644102, top_k: 0.848359, samples/s: 782.111 1613356745.5936413
train: epoch 84, iter 1400, loss: 2.690756, top_1: 0.649844, top_k: 0.849609, samples/s: 781.052 1613356778.3699
train: epoch 84, iter 1500, loss: 2.532556, top_1: 0.653828, top_k: 0.852734, samples/s: 779.879 1613356811.1955364
train: epoch 84, iter 1600, loss: 2.494021, top_1: 0.644336, top_k: 0.848359, samples/s: 780.978 1613356843.974897
train: epoch 84, iter 1700, loss: 2.504362, top_1: 0.639844, top_k: 0.846484, samples/s: 782.233 1613356876.7016885
train: epoch 84, iter 1800, loss: 2.718336, top_1: 0.640312, top_k: 0.848164, samples/s: 780.828 1613356909.4874463
train: epoch 84, iter 1900, loss: 2.401249, top_1: 0.640742, top_k: 0.850039, samples/s: 780.085 1613356942.3044329
train: epoch 84, iter 2000, loss: 2.467120, top_1: 0.652500, top_k: 0.854023, samples/s: 784.399 1613356974.9408286
train: epoch 84, iter 2100, loss: 2.735754, top_1: 0.645508, top_k: 0.849922, samples/s: 781.179 1613357007.7118914
train: epoch 84, iter 2200, loss: 2.585652, top_1: 0.637383, top_k: 0.846797, samples/s: 779.554 1613357040.551157
train: epoch 84, iter 2300, loss: 2.268547, top_1: 0.651094, top_k: 0.849336, samples/s: 784.111 1613357073.1996627
train: epoch 84, iter 2400, loss: 2.495991, top_1: 0.641016, top_k: 0.845977, samples/s: 781.346 1613357105.963523
train: epoch 84, iter 2500, loss: 2.502553, top_1: 0.642734, top_k: 0.844688, samples/s: 782.044 1613357138.698283
train: epoch 84, iter 2600, loss: 2.390306, top_1: 0.643164, top_k: 0.847070, samples/s: 776.144 1613357171.681871
train: epoch 84, iter 2700, loss: 2.385761, top_1: 0.633711, top_k: 0.843984, samples/s: 785.049 1613357204.2913983
train: epoch 84, iter 2800, loss: 2.451729, top_1: 0.644570, top_k: 0.848555, samples/s: 782.130 1613357237.022447
train: epoch 84, iter 2900, loss: 2.449812, top_1: 0.643594, top_k: 0.848359, samples/s: 782.488 1613357269.7386262
train: epoch 84, iter 3000, loss: 2.360028, top_1: 0.642266, top_k: 0.846172, samples/s: 781.533 1613357302.4947703
train: epoch 84, iter 3100, loss: 2.427779, top_1: 0.640898, top_k: 0.846602, samples/s: 780.208 1613357335.3064907
train: epoch 84, iter 3200, loss: 2.511967, top_1: 0.641563, top_k: 0.844766, samples/s: 783.784 1613357367.9685807
train: epoch 84, iter 3300, loss: 2.304568, top_1: 0.638711, top_k: 0.845234, samples/s: 782.940 1613357400.6658297
train: epoch 84, iter 3400, loss: 2.474781, top_1: 0.643789, top_k: 0.845117, samples/s: 779.789 1613357433.4952
train: epoch 84, iter 3500, loss: 2.590305, top_1: 0.647969, top_k: 0.844922, samples/s: 781.047 1613357466.2716928
train: epoch 84, iter 3600, loss: 2.458388, top_1: 0.645117, top_k: 0.845156, samples/s: 781.662 1613357499.0224943
train: epoch 84, iter 3700, loss: 2.600029, top_1: 0.640312, top_k: 0.846055, samples/s: 781.353 1613357531.7861416
train: epoch 84, iter 3800, loss: 2.532168, top_1: 0.640977, top_k: 0.844766, samples/s: 782.196 1613357564.5145664
train: epoch 84, iter 3900, loss: 2.453547, top_1: 0.642031, top_k: 0.848789, samples/s: 780.527 1613357597.3127992
train: epoch 84, iter 4000, loss: 2.455169, top_1: 0.642969, top_k: 0.847930, samples/s: 778.519 1613357630.1958694
train: epoch 84, iter 4100, loss: 2.588313, top_1: 0.639414, top_k: 0.847070, samples/s: 785.970 1613357662.7670243
train: epoch 84, iter 4200, loss: 2.640531, top_1: 0.644766, top_k: 0.844922, samples/s: 780.513 1613357695.5659506
train: epoch 84, iter 4300, loss: 2.458338, top_1: 0.639258, top_k: 0.844922, samples/s: 782.574 1613357728.2784722
train: epoch 84, iter 4400, loss: 2.430524, top_1: 0.645469, top_k: 0.846914, samples/s: 779.452 1613357761.1221619
train: epoch 84, iter 4500, loss: 2.591452, top_1: 0.643086, top_k: 0.844336, samples/s: 781.774 1613357793.8682084
train: epoch 84, iter 4600, loss: 2.423721, top_1: 0.639727, top_k: 0.840586, samples/s: 779.525 1613357826.7086277
train: epoch 84, iter 4700, loss: 2.448155, top_1: 0.638359, top_k: 0.843828, samples/s: 782.741 1613357859.4143133
train: epoch 84, iter 4800, loss: 2.471754, top_1: 0.640352, top_k: 0.844336, samples/s: 781.860 1613357892.156695
train: epoch 84, iter 4900, loss: 2.616390, top_1: 0.640547, top_k: 0.846680, samples/s: 781.367 1613357924.9197793
train: epoch 84, iter 5000, loss: 2.411844, top_1: 0.651094, top_k: 0.848242, samples/s: 783.196 1613357957.6064284
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_84.
validation: epoch 84, iter 195, top_1: 0.692127, top_k: 0.894651, samples/s: 2391.246 1613357979.461022
train: epoch 85, iter 100, loss: 2.235699, top_1: 0.655508, top_k: 0.854961, samples/s: 803.474 1613358032.5457199
train: epoch 85, iter 200, loss: 2.494081, top_1: 0.649102, top_k: 0.855742, samples/s: 798.716 1613358064.5971434
train: epoch 85, iter 300, loss: 2.388467, top_1: 0.652266, top_k: 0.853516, samples/s: 781.166 1613358097.3686988
train: epoch 85, iter 400, loss: 2.550710, top_1: 0.652578, top_k: 0.854023, samples/s: 778.457 1613358130.2541575
train: epoch 85, iter 500, loss: 2.458829, top_1: 0.650781, top_k: 0.854023, samples/s: 779.948 1613358163.0769439
train: epoch 85, iter 600, loss: 2.322036, top_1: 0.650039, top_k: 0.849219, samples/s: 781.187 1613358195.8475463
train: epoch 85, iter 700, loss: 2.311002, top_1: 0.652383, top_k: 0.856055, samples/s: 779.962 1613358228.6697013
train: epoch 85, iter 800, loss: 2.587749, top_1: 0.651406, top_k: 0.853086, samples/s: 782.734 1613358261.3755312
train: epoch 85, iter 900, loss: 2.337478, top_1: 0.648398, top_k: 0.850625, samples/s: 780.956 1613358294.1558685
train: epoch 85, iter 1000, loss: 2.303671, top_1: 0.655625, top_k: 0.855234, samples/s: 780.311 1613358326.9633164
train: epoch 85, iter 1100, loss: 2.242719, top_1: 0.654414, top_k: 0.857930, samples/s: 782.465 1613358359.6804073
train: epoch 85, iter 1200, loss: 2.192238, top_1: 0.655625, top_k: 0.855625, samples/s: 780.484 1613358392.4805918
train: epoch 85, iter 1300, loss: 2.376107, top_1: 0.650234, top_k: 0.851367, samples/s: 781.032 1613358425.2577686
train: epoch 85, iter 1400, loss: 2.275807, top_1: 0.651406, top_k: 0.852891, samples/s: 780.800 1613358458.0447185
train: epoch 85, iter 1500, loss: 2.605991, top_1: 0.643359, top_k: 0.848789, samples/s: 782.180 1613358490.7736998
train: epoch 85, iter 1600, loss: 2.387526, top_1: 0.644648, top_k: 0.849531, samples/s: 779.927 1613358523.5972307
train: epoch 85, iter 1700, loss: 2.329952, top_1: 0.654844, top_k: 0.857852, samples/s: 781.567 1613358556.3519404
train: epoch 85, iter 1800, loss: 2.577035, top_1: 0.643398, top_k: 0.845625, samples/s: 781.201 1613358589.1219714
train: epoch 85, iter 1900, loss: 2.709964, top_1: 0.647813, top_k: 0.846836, samples/s: 780.927 1613358621.9035919
train: epoch 85, iter 2000, loss: 2.348166, top_1: 0.644805, top_k: 0.848086, samples/s: 782.372 1613358654.6245396
train: epoch 85, iter 2100, loss: 2.391698, top_1: 0.651211, top_k: 0.852617, samples/s: 781.317 1613358687.3897176
train: epoch 85, iter 2200, loss: 2.169014, top_1: 0.649219, top_k: 0.851406, samples/s: 784.838 1613358720.0079181
train: epoch 85, iter 2300, loss: 2.520711, top_1: 0.644180, top_k: 0.847656, samples/s: 782.249 1613358752.7340448
train: epoch 85, iter 2400, loss: 2.554845, top_1: 0.641875, top_k: 0.848359, samples/s: 782.287 1613358785.4587262
train: epoch 85, iter 2500, loss: 2.364418, top_1: 0.648320, top_k: 0.848984, samples/s: 782.253 1613358818.1846464
train: epoch 85, iter 2600, loss: 2.423853, top_1: 0.643242, top_k: 0.848945, samples/s: 781.226 1613358850.953611
train: epoch 85, iter 2700, loss: 2.434316, top_1: 0.647188, top_k: 0.849375, samples/s: 784.383 1613358883.590733
train: epoch 85, iter 2800, loss: 2.457817, top_1: 0.645859, top_k: 0.847383, samples/s: 780.838 1613358916.375992
train: epoch 85, iter 2900, loss: 2.656719, top_1: 0.648242, top_k: 0.848281, samples/s: 782.554 1613358949.0893965
train: epoch 85, iter 3000, loss: 2.555704, top_1: 0.646133, top_k: 0.851250, samples/s: 780.271 1613358981.898593
train: epoch 85, iter 3100, loss: 2.513310, top_1: 0.641992, top_k: 0.848281, samples/s: 780.649 1613359014.691828
train: epoch 85, iter 3200, loss: 2.369136, top_1: 0.644961, top_k: 0.849219, samples/s: 785.635 1613359047.276876
train: epoch 85, iter 3300, loss: 2.556504, top_1: 0.644062, top_k: 0.846367, samples/s: 781.445 1613359080.0366776
train: epoch 85, iter 3400, loss: 2.441200, top_1: 0.643984, top_k: 0.845508, samples/s: 781.391 1613359112.7988098
train: epoch 85, iter 3500, loss: 2.393973, top_1: 0.639687, top_k: 0.846016, samples/s: 782.568 1613359145.511616
train: epoch 85, iter 3600, loss: 2.361260, top_1: 0.641797, top_k: 0.846367, samples/s: 783.553 1613359178.1833138
train: epoch 85, iter 3700, loss: 2.506763, top_1: 0.646797, top_k: 0.852305, samples/s: 781.641 1613359210.9349022
train: epoch 85, iter 3800, loss: 2.411314, top_1: 0.648789, top_k: 0.851562, samples/s: 782.412 1613359243.6542668
train: epoch 85, iter 3900, loss: 2.362873, top_1: 0.639883, top_k: 0.847969, samples/s: 782.229 1613359276.3813
train: epoch 85, iter 4000, loss: 2.428273, top_1: 0.641914, top_k: 0.846133, samples/s: 780.534 1613359309.1792586
train: epoch 85, iter 4100, loss: 2.334011, top_1: 0.644609, top_k: 0.849180, samples/s: 781.677 1613359341.9293776
train: epoch 85, iter 4200, loss: 2.457849, top_1: 0.649375, top_k: 0.847070, samples/s: 782.211 1613359374.657174
train: epoch 85, iter 4300, loss: 2.509799, top_1: 0.641367, top_k: 0.844766, samples/s: 781.548 1613359407.4126022
train: epoch 85, iter 4400, loss: 2.428315, top_1: 0.645156, top_k: 0.846914, samples/s: 780.958 1613359440.1928399
train: epoch 85, iter 4500, loss: 2.608617, top_1: 0.639922, top_k: 0.844141, samples/s: 783.158 1613359472.880981
train: epoch 85, iter 4600, loss: 2.521276, top_1: 0.642617, top_k: 0.845117, samples/s: 782.002 1613359505.6175363
train: epoch 85, iter 4700, loss: 2.305999, top_1: 0.642695, top_k: 0.847187, samples/s: 781.510 1613359538.374593
train: epoch 85, iter 4800, loss: 2.397294, top_1: 0.638125, top_k: 0.847969, samples/s: 783.121 1613359571.0643182
train: epoch 85, iter 4900, loss: 2.557150, top_1: 0.647695, top_k: 0.848008, samples/s: 780.860 1613359603.8486376
train: epoch 85, iter 5000, loss: 2.389713, top_1: 0.645898, top_k: 0.849648, samples/s: 779.882 1613359636.6741273
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_85.
validation: epoch 85, iter 195, top_1: 0.692929, top_k: 0.892087, samples/s: 2327.400 1613359659.0987735
train: epoch 86, iter 100, loss: 2.491333, top_1: 0.645078, top_k: 0.849336, samples/s: 801.971 1613359711.5497775
train: epoch 86, iter 200, loss: 2.453077, top_1: 0.653086, top_k: 0.852227, samples/s: 801.443 1613359743.4923775
train: epoch 86, iter 300, loss: 2.387793, top_1: 0.659375, top_k: 0.857148, samples/s: 781.470 1613359776.2509944
train: epoch 86, iter 400, loss: 2.572134, top_1: 0.659219, top_k: 0.855508, samples/s: 779.029 1613359809.11236
train: epoch 86, iter 500, loss: 2.289368, top_1: 0.657070, top_k: 0.857773, samples/s: 780.717 1613359841.9027827
train: epoch 86, iter 600, loss: 2.371950, top_1: 0.649141, top_k: 0.854727, samples/s: 778.826 1613359874.7727747
train: epoch 86, iter 700, loss: 2.451217, top_1: 0.653711, top_k: 0.854492, samples/s: 781.551 1613359907.5280423
train: epoch 86, iter 800, loss: 2.403538, top_1: 0.652461, top_k: 0.851094, samples/s: 779.098 1613359940.3865988
train: epoch 86, iter 900, loss: 2.505233, top_1: 0.654570, top_k: 0.853906, samples/s: 781.407 1613359973.1481032
train: epoch 86, iter 1000, loss: 2.269728, top_1: 0.652305, top_k: 0.852344, samples/s: 783.003 1613360005.8426204
train: epoch 86, iter 1100, loss: 2.419332, top_1: 0.653086, top_k: 0.852031, samples/s: 780.809 1613360038.6291363
train: epoch 86, iter 1200, loss: 2.566661, top_1: 0.648477, top_k: 0.853398, samples/s: 781.003 1613360071.4074564
train: epoch 86, iter 1300, loss: 2.387444, top_1: 0.653945, top_k: 0.852734, samples/s: 779.892 1613360104.2325418
train: epoch 86, iter 1400, loss: 2.517675, top_1: 0.653633, top_k: 0.848711, samples/s: 780.860 1613360137.0169127
train: epoch 86, iter 1500, loss: 2.504885, top_1: 0.649648, top_k: 0.850195, samples/s: 782.752 1613360169.7219737
train: epoch 86, iter 1600, loss: 2.276183, top_1: 0.655781, top_k: 0.854414, samples/s: 779.734 1613360202.553698
train: epoch 86, iter 1700, loss: 2.577926, top_1: 0.650039, top_k: 0.851367, samples/s: 781.656 1613360235.3046708
train: epoch 86, iter 1800, loss: 2.236256, top_1: 0.652148, top_k: 0.852422, samples/s: 781.337 1613360268.0690007
train: epoch 86, iter 1900, loss: 2.251581, top_1: 0.655781, top_k: 0.854336, samples/s: 780.997 1613360300.8476222
train: epoch 86, iter 2000, loss: 2.460933, top_1: 0.644336, top_k: 0.849570, samples/s: 781.473 1613360333.6063578
train: epoch 86, iter 2100, loss: 2.383921, top_1: 0.650195, top_k: 0.853203, samples/s: 781.817 1613360366.350581
train: epoch 86, iter 2200, loss: 2.609221, top_1: 0.651250, top_k: 0.853984, samples/s: 781.539 1613360399.106515
train: epoch 86, iter 2300, loss: 2.446751, top_1: 0.647266, top_k: 0.847578, samples/s: 780.696 1613360431.8977196
train: epoch 86, iter 2400, loss: 2.474147, top_1: 0.649844, top_k: 0.849961, samples/s: 784.895 1613360464.5135193
train: epoch 86, iter 2500, loss: 2.515488, top_1: 0.645859, top_k: 0.850586, samples/s: 780.732 1613360497.303269
train: epoch 86, iter 2600, loss: 2.492890, top_1: 0.646680, top_k: 0.851211, samples/s: 780.427 1613360530.105762
train: epoch 86, iter 2700, loss: 2.541668, top_1: 0.640742, top_k: 0.847656, samples/s: 782.647 1613360562.8152375
train: epoch 86, iter 2800, loss: 2.329380, top_1: 0.644570, top_k: 0.847070, samples/s: 780.313 1613360595.622619
train: epoch 86, iter 2900, loss: 2.568875, top_1: 0.645703, top_k: 0.846680, samples/s: 780.124 1613360628.4379385
train: epoch 86, iter 3000, loss: 2.410052, top_1: 0.650117, top_k: 0.849727, samples/s: 781.546 1613360661.1935108
train: epoch 86, iter 3100, loss: 2.644800, top_1: 0.645703, top_k: 0.848203, samples/s: 781.835 1613360693.9369872
train: epoch 86, iter 3200, loss: 2.484973, top_1: 0.645312, top_k: 0.850469, samples/s: 780.798 1613360726.7239065
train: epoch 86, iter 3300, loss: 2.445939, top_1: 0.653945, top_k: 0.851758, samples/s: 778.029 1613360759.6276264
train: epoch 86, iter 3400, loss: 2.286150, top_1: 0.646328, top_k: 0.848828, samples/s: 780.265 1613360792.4369519
train: epoch 86, iter 3500, loss: 2.354387, top_1: 0.648906, top_k: 0.852773, samples/s: 779.857 1613360825.2635586
train: epoch 86, iter 3600, loss: 2.525367, top_1: 0.644570, top_k: 0.850938, samples/s: 779.854 1613360858.0902321
train: epoch 86, iter 3700, loss: 2.439828, top_1: 0.649687, top_k: 0.850430, samples/s: 780.727 1613360890.8801317
train: epoch 86, iter 3800, loss: 2.367411, top_1: 0.648711, top_k: 0.847187, samples/s: 780.285 1613360923.6886723
train: epoch 86, iter 3900, loss: 2.310094, top_1: 0.643945, top_k: 0.845625, samples/s: 780.160 1613360956.5025175
train: epoch 86, iter 4000, loss: 2.359968, top_1: 0.643320, top_k: 0.846758, samples/s: 782.489 1613360989.2186427
train: epoch 86, iter 4100, loss: 2.531879, top_1: 0.635039, top_k: 0.846133, samples/s: 779.430 1613361022.0631557
train: epoch 86, iter 4200, loss: 2.384724, top_1: 0.640195, top_k: 0.844141, samples/s: 780.786 1613361054.850615
train: epoch 86, iter 4300, loss: 2.504882, top_1: 0.644258, top_k: 0.846406, samples/s: 778.319 1613361087.742059
train: epoch 86, iter 4400, loss: 2.468506, top_1: 0.642773, top_k: 0.845273, samples/s: 784.114 1613361120.390278
train: epoch 86, iter 4500, loss: 2.394820, top_1: 0.647344, top_k: 0.850508, samples/s: 781.218 1613361153.1597388
train: epoch 86, iter 4600, loss: 2.499788, top_1: 0.646523, top_k: 0.847539, samples/s: 782.247 1613361185.8858929
train: epoch 86, iter 4700, loss: 2.619841, top_1: 0.640938, top_k: 0.845469, samples/s: 780.588 1613361218.68173
train: epoch 86, iter 4800, loss: 2.456535, top_1: 0.642852, top_k: 0.846250, samples/s: 780.831 1613361251.4673023
train: epoch 86, iter 4900, loss: 2.704890, top_1: 0.644961, top_k: 0.849180, samples/s: 781.507 1613361284.2245643
train: epoch 86, iter 5000, loss: 2.359986, top_1: 0.648438, top_k: 0.850313, samples/s: 781.931 1613361316.964009
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_86.
validation: epoch 86, iter 195, top_1: 0.688622, top_k: 0.894171, samples/s: 2368.607 1613361339.0439038
train: epoch 87, iter 100, loss: 2.331725, top_1: 0.669063, top_k: 0.863555, samples/s: 802.299 1613361391.749115
train: epoch 87, iter 200, loss: 2.234846, top_1: 0.658867, top_k: 0.857656, samples/s: 801.143 1613361423.7033854
train: epoch 87, iter 300, loss: 2.585515, top_1: 0.657109, top_k: 0.856367, samples/s: 781.554 1613361456.4586325
train: epoch 87, iter 400, loss: 2.431551, top_1: 0.656680, top_k: 0.856602, samples/s: 781.045 1613361489.2352138
train: epoch 87, iter 500, loss: 2.341043, top_1: 0.663242, top_k: 0.861563, samples/s: 779.091 1613361522.0940962
train: epoch 87, iter 600, loss: 2.341516, top_1: 0.660977, top_k: 0.858867, samples/s: 781.682 1613361554.843947
train: epoch 87, iter 700, loss: 2.433956, top_1: 0.662031, top_k: 0.858633, samples/s: 780.414 1613361587.6470988
train: epoch 87, iter 800, loss: 2.355257, top_1: 0.651055, top_k: 0.855352, samples/s: 778.907 1613361620.5135727
train: epoch 87, iter 900, loss: 2.533508, top_1: 0.651680, top_k: 0.852773, samples/s: 782.924 1613361653.211509
train: epoch 87, iter 1000, loss: 2.555989, top_1: 0.650508, top_k: 0.853516, samples/s: 781.583 1613361685.965613
train: epoch 87, iter 1100, loss: 2.399325, top_1: 0.654414, top_k: 0.854062, samples/s: 780.833 1613361718.7511017
train: epoch 87, iter 1200, loss: 2.379507, top_1: 0.657148, top_k: 0.854492, samples/s: 781.368 1613361751.5141616
train: epoch 87, iter 1300, loss: 2.517312, top_1: 0.651641, top_k: 0.855273, samples/s: 781.045 1613361784.2907546
train: epoch 87, iter 1400, loss: 2.450480, top_1: 0.648906, top_k: 0.848242, samples/s: 779.740 1613361817.1222372
train: epoch 87, iter 1500, loss: 2.140702, top_1: 0.654141, top_k: 0.856133, samples/s: 780.797 1613361849.9092205
train: epoch 87, iter 1600, loss: 2.574800, top_1: 0.658984, top_k: 0.857734, samples/s: 782.168 1613361882.6388035
train: epoch 87, iter 1700, loss: 2.536098, top_1: 0.652617, top_k: 0.851172, samples/s: 780.385 1613361915.443207
train: epoch 87, iter 1800, loss: 2.600250, top_1: 0.650781, top_k: 0.850703, samples/s: 782.114 1613361948.1749623
train: epoch 87, iter 1900, loss: 2.421536, top_1: 0.648594, top_k: 0.847695, samples/s: 782.455 1613361980.892524
train: epoch 87, iter 2000, loss: 2.462129, top_1: 0.656484, top_k: 0.856406, samples/s: 780.653 1613362013.6855626
train: epoch 87, iter 2100, loss: 2.597079, top_1: 0.648359, top_k: 0.851562, samples/s: 784.715 1613362046.3087964
train: epoch 87, iter 2200, loss: 2.374443, top_1: 0.657305, top_k: 0.853672, samples/s: 779.884 1613362079.1342165
train: epoch 87, iter 2300, loss: 2.368247, top_1: 0.647188, top_k: 0.852734, samples/s: 782.142 1613362111.864833
train: epoch 87, iter 2400, loss: 2.444135, top_1: 0.645469, top_k: 0.850938, samples/s: 784.036 1613362144.5164237
train: epoch 87, iter 2500, loss: 2.649095, top_1: 0.648438, top_k: 0.847852, samples/s: 780.231 1613362177.3271885
train: epoch 87, iter 2600, loss: 2.354718, top_1: 0.648672, top_k: 0.851484, samples/s: 784.249 1613362209.9699113
train: epoch 87, iter 2700, loss: 2.350355, top_1: 0.648438, top_k: 0.850195, samples/s: 781.207 1613362242.7397046
train: epoch 87, iter 2800, loss: 2.358218, top_1: 0.647305, top_k: 0.850156, samples/s: 782.053 1613362275.474101
train: epoch 87, iter 2900, loss: 2.481761, top_1: 0.649414, top_k: 0.850195, samples/s: 780.062 1613362308.2919273
train: epoch 87, iter 3000, loss: 2.424646, top_1: 0.646172, top_k: 0.849883, samples/s: 783.495 1613362340.9661467
train: epoch 87, iter 3100, loss: 2.620883, top_1: 0.649531, top_k: 0.852969, samples/s: 783.883 1613362373.624054
train: epoch 87, iter 3200, loss: 2.380798, top_1: 0.649531, top_k: 0.849414, samples/s: 782.425 1613362406.3427894
train: epoch 87, iter 3300, loss: 2.364958, top_1: 0.643164, top_k: 0.849219, samples/s: 781.576 1613362439.0971408
train: epoch 87, iter 3400, loss: 2.552405, top_1: 0.645352, top_k: 0.850391, samples/s: 782.414 1613362471.8164122
train: epoch 87, iter 3500, loss: 2.299088, top_1: 0.646055, top_k: 0.847500, samples/s: 782.004 1613362504.5527637
train: epoch 87, iter 3600, loss: 2.367545, top_1: 0.649922, top_k: 0.850898, samples/s: 783.730 1613362537.217112
train: epoch 87, iter 3700, loss: 2.552991, top_1: 0.646250, top_k: 0.849063, samples/s: 783.274 1613362569.9003475
train: epoch 87, iter 3800, loss: 2.338764, top_1: 0.649180, top_k: 0.850156, samples/s: 781.267 1613362602.667662
train: epoch 87, iter 3900, loss: 2.558633, top_1: 0.647617, top_k: 0.848828, samples/s: 782.862 1613362635.3682325
train: epoch 87, iter 4000, loss: 2.319947, top_1: 0.646328, top_k: 0.846680, samples/s: 780.844 1613362668.1532066
train: epoch 87, iter 4100, loss: 2.513695, top_1: 0.648867, top_k: 0.851602, samples/s: 779.371 1613362701.000202
train: epoch 87, iter 4200, loss: 2.341134, top_1: 0.652969, top_k: 0.852266, samples/s: 784.040 1613362733.6515849
train: epoch 87, iter 4300, loss: 2.379034, top_1: 0.649062, top_k: 0.850703, samples/s: 781.796 1613362766.3968294
train: epoch 87, iter 4400, loss: 2.382246, top_1: 0.646133, top_k: 0.847930, samples/s: 781.878 1613362799.138429
train: epoch 87, iter 4500, loss: 2.475886, top_1: 0.647188, top_k: 0.847461, samples/s: 781.433 1613362831.8988132
train: epoch 87, iter 4600, loss: 2.372241, top_1: 0.655625, top_k: 0.852344, samples/s: 780.559 1613362864.695721
train: epoch 87, iter 4700, loss: 2.395450, top_1: 0.647578, top_k: 0.850430, samples/s: 782.695 1613362897.4032412
train: epoch 87, iter 4800, loss: 2.524470, top_1: 0.644883, top_k: 0.846484, samples/s: 780.931 1613362930.1847157
train: epoch 87, iter 4900, loss: 2.397577, top_1: 0.648867, top_k: 0.852383, samples/s: 780.763 1613362962.973103
train: epoch 87, iter 5000, loss: 2.374186, top_1: 0.651953, top_k: 0.853672, samples/s: 780.892 1613362995.7561154
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_87.
validation: epoch 87, iter 195, top_1: 0.687800, top_k: 0.891567, samples/s: 2346.785 1613363018.0039065
train: epoch 88, iter 100, loss: 2.257994, top_1: 0.662969, top_k: 0.859102, samples/s: 804.401 1613363070.4484603
train: epoch 88, iter 200, loss: 2.436449, top_1: 0.656719, top_k: 0.855000, samples/s: 798.910 1613363102.4921012
train: epoch 88, iter 300, loss: 2.406965, top_1: 0.664648, top_k: 0.858672, samples/s: 783.373 1613363135.1712914
train: epoch 88, iter 400, loss: 2.387937, top_1: 0.654297, top_k: 0.854336, samples/s: 778.158 1613363168.0696564
train: epoch 88, iter 500, loss: 2.370428, top_1: 0.654531, top_k: 0.856758, samples/s: 780.786 1613363200.8570764
train: epoch 88, iter 600, loss: 2.374784, top_1: 0.657500, top_k: 0.857617, samples/s: 776.750 1613363233.8148987
train: epoch 88, iter 700, loss: 2.278891, top_1: 0.660664, top_k: 0.858437, samples/s: 780.576 1613363266.6112463
train: epoch 88, iter 800, loss: 2.428533, top_1: 0.659492, top_k: 0.857773, samples/s: 781.063 1613363299.3869143
train: epoch 88, iter 900, loss: 2.338058, top_1: 0.656602, top_k: 0.854531, samples/s: 776.703 1613363332.3467638
train: epoch 88, iter 1000, loss: 2.263320, top_1: 0.655937, top_k: 0.856055, samples/s: 780.317 1613363365.1539838
train: epoch 88, iter 1100, loss: 2.513559, top_1: 0.655664, top_k: 0.853281, samples/s: 779.903 1613363397.9785867
train: epoch 88, iter 1200, loss: 2.342288, top_1: 0.659922, top_k: 0.859258, samples/s: 781.436 1613363430.7387576
train: epoch 88, iter 1300, loss: 2.369765, top_1: 0.655000, top_k: 0.855977, samples/s: 782.211 1613363463.4664965
train: epoch 88, iter 1400, loss: 2.379350, top_1: 0.656797, top_k: 0.854297, samples/s: 781.178 1613363496.237583
train: epoch 88, iter 1500, loss: 2.503820, top_1: 0.654336, top_k: 0.853125, samples/s: 780.390 1613363529.041566
train: epoch 88, iter 1600, loss: 2.502365, top_1: 0.656367, top_k: 0.851602, samples/s: 781.319 1613363561.8067853
train: epoch 88, iter 1700, loss: 2.403769, top_1: 0.655508, top_k: 0.858281, samples/s: 780.839 1613363594.5919604
train: epoch 88, iter 1800, loss: 2.632205, top_1: 0.648633, top_k: 0.849766, samples/s: 783.975 1613363627.246128
train: epoch 88, iter 1900, loss: 2.359515, top_1: 0.654805, top_k: 0.857891, samples/s: 777.603 1613363660.167827
train: epoch 88, iter 2000, loss: 2.374585, top_1: 0.658867, top_k: 0.854180, samples/s: 783.327 1613363692.848921
train: epoch 88, iter 2100, loss: 2.381924, top_1: 0.651797, top_k: 0.852344, samples/s: 780.386 1613363725.6531057
train: epoch 88, iter 2200, loss: 2.557047, top_1: 0.651367, top_k: 0.850430, samples/s: 785.005 1613363758.2644646
train: epoch 88, iter 2300, loss: 2.284304, top_1: 0.654531, top_k: 0.852227, samples/s: 779.708 1613363791.0971425
train: epoch 88, iter 2400, loss: 2.225255, top_1: 0.650937, top_k: 0.852656, samples/s: 782.975 1613363823.792993
train: epoch 88, iter 2500, loss: 2.567781, top_1: 0.652539, top_k: 0.851250, samples/s: 779.386 1613363856.6393795
train: epoch 88, iter 2600, loss: 2.304992, top_1: 0.650508, top_k: 0.853086, samples/s: 784.249 1613363889.282045
train: epoch 88, iter 2700, loss: 2.300451, top_1: 0.650898, top_k: 0.850352, samples/s: 778.517 1613363922.1651497
train: epoch 88, iter 2800, loss: 2.361745, top_1: 0.653086, top_k: 0.853633, samples/s: 783.050 1613363954.8578265
train: epoch 88, iter 2900, loss: 2.454895, top_1: 0.650781, top_k: 0.851406, samples/s: 779.789 1613363987.6872034
train: epoch 88, iter 3000, loss: 2.509146, top_1: 0.649961, top_k: 0.851133, samples/s: 783.741 1613364020.3510087
train: epoch 88, iter 3100, loss: 2.455932, top_1: 0.649297, top_k: 0.849258, samples/s: 779.504 1613364053.1924763
train: epoch 88, iter 3200, loss: 2.439876, top_1: 0.646367, top_k: 0.851445, samples/s: 782.540 1613364085.9064486
train: epoch 88, iter 3300, loss: 2.503592, top_1: 0.648320, top_k: 0.849844, samples/s: 783.499 1613364118.5803049
train: epoch 88, iter 3400, loss: 2.430561, top_1: 0.650859, top_k: 0.852305, samples/s: 781.048 1613364151.3567948
train: epoch 88, iter 3500, loss: 2.344537, top_1: 0.645430, top_k: 0.849375, samples/s: 783.693 1613364184.0227318
train: epoch 88, iter 3600, loss: 2.619404, top_1: 0.643750, top_k: 0.848945, samples/s: 781.017 1613364216.8004398
train: epoch 88, iter 3700, loss: 2.589965, top_1: 0.650742, top_k: 0.852383, samples/s: 787.570 1613364249.3055182
train: epoch 88, iter 3800, loss: 2.401281, top_1: 0.649531, top_k: 0.853437, samples/s: 778.523 1613364282.1883476
train: epoch 88, iter 3900, loss: 2.356309, top_1: 0.647461, top_k: 0.855000, samples/s: 781.159 1613364314.9600859
train: epoch 88, iter 4000, loss: 2.434362, top_1: 0.650703, top_k: 0.854023, samples/s: 782.510 1613364347.675367
train: epoch 88, iter 4100, loss: 2.362167, top_1: 0.651875, top_k: 0.851172, samples/s: 781.189 1613364380.4458616
train: epoch 88, iter 4200, loss: 2.541500, top_1: 0.652695, top_k: 0.853555, samples/s: 778.489 1613364413.3301477
train: epoch 88, iter 4300, loss: 2.468811, top_1: 0.653789, top_k: 0.853437, samples/s: 779.449 1613364446.1738358
train: epoch 88, iter 4400, loss: 2.659910, top_1: 0.650742, top_k: 0.852930, samples/s: 781.775 1613364478.9197574
train: epoch 88, iter 4500, loss: 2.585714, top_1: 0.648984, top_k: 0.848750, samples/s: 780.887 1613364511.7030733
train: epoch 88, iter 4600, loss: 2.484652, top_1: 0.646445, top_k: 0.847773, samples/s: 780.772 1613364544.4911308
train: epoch 88, iter 4700, loss: 2.406218, top_1: 0.650234, top_k: 0.853164, samples/s: 785.188 1613364577.0947104
train: epoch 88, iter 4800, loss: 2.329947, top_1: 0.648516, top_k: 0.850820, samples/s: 780.445 1613364609.8964474
train: epoch 88, iter 4900, loss: 2.303355, top_1: 0.658086, top_k: 0.855977, samples/s: 782.290 1613364642.6209881
train: epoch 88, iter 5000, loss: 2.337592, top_1: 0.654531, top_k: 0.856406, samples/s: 780.280 1613364675.429695
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_88.
validation: epoch 88, iter 195, top_1: 0.692208, top_k: 0.893049, samples/s: 2366.312 1613364697.494313
train: epoch 89, iter 100, loss: 2.470898, top_1: 0.667305, top_k: 0.861602, samples/s: 802.975 1613364750.1507308
train: epoch 89, iter 200, loss: 2.428263, top_1: 0.656445, top_k: 0.859414, samples/s: 799.109 1613364782.186463
train: epoch 89, iter 300, loss: 2.440521, top_1: 0.659258, top_k: 0.858750, samples/s: 783.757 1613364814.8496244
train: epoch 89, iter 400, loss: 2.406689, top_1: 0.663281, top_k: 0.859648, samples/s: 776.568 1613364847.8150673
train: epoch 89, iter 500, loss: 2.221672, top_1: 0.658945, top_k: 0.857891, samples/s: 778.426 1613364880.7020562
train: epoch 89, iter 600, loss: 2.387030, top_1: 0.661445, top_k: 0.862305, samples/s: 783.326 1613364913.3831103
train: epoch 89, iter 700, loss: 2.399679, top_1: 0.654453, top_k: 0.856211, samples/s: 777.887 1613364946.2928154
train: epoch 89, iter 800, loss: 2.552839, top_1: 0.656836, top_k: 0.851406, samples/s: 778.631 1613364979.1710558
train: epoch 89, iter 900, loss: 2.337387, top_1: 0.661172, top_k: 0.860469, samples/s: 780.805 1613365011.957679
train: epoch 89, iter 1000, loss: 2.234321, top_1: 0.667969, top_k: 0.863477, samples/s: 782.406 1613365044.6773727
train: epoch 89, iter 1100, loss: 2.299377, top_1: 0.651680, top_k: 0.855703, samples/s: 776.805 1613365077.6327608
train: epoch 89, iter 1200, loss: 2.590393, top_1: 0.653828, top_k: 0.853828, samples/s: 780.690 1613365110.4242864
train: epoch 89, iter 1300, loss: 2.211656, top_1: 0.659219, top_k: 0.858281, samples/s: 779.374 1613365143.2711995
train: epoch 89, iter 1400, loss: 2.215509, top_1: 0.654414, top_k: 0.854414, samples/s: 780.879 1613365176.0546815
train: epoch 89, iter 1500, loss: 2.547423, top_1: 0.658984, top_k: 0.859102, samples/s: 777.535 1613365208.9793253
train: epoch 89, iter 1600, loss: 2.546763, top_1: 0.657266, top_k: 0.853516, samples/s: 780.351 1613365241.785092
train: epoch 89, iter 1700, loss: 2.608820, top_1: 0.654297, top_k: 0.855586, samples/s: 780.764 1613365274.573436
train: epoch 89, iter 1800, loss: 2.285735, top_1: 0.657695, top_k: 0.855625, samples/s: 780.915 1613365307.355559
train: epoch 89, iter 1900, loss: 2.481341, top_1: 0.655859, top_k: 0.853359, samples/s: 780.270 1613365340.1646736
train: epoch 89, iter 2000, loss: 2.352382, top_1: 0.658594, top_k: 0.854648, samples/s: 780.264 1613365372.9740224
train: epoch 89, iter 2100, loss: 2.545093, top_1: 0.653359, top_k: 0.855039, samples/s: 780.794 1613365405.7611516
train: epoch 89, iter 2200, loss: 2.318536, top_1: 0.658867, top_k: 0.858750, samples/s: 780.074 1613365438.5785506
train: epoch 89, iter 2300, loss: 2.437310, top_1: 0.657148, top_k: 0.855664, samples/s: 783.143 1613365471.2673242
train: epoch 89, iter 2400, loss: 2.502095, top_1: 0.651133, top_k: 0.854492, samples/s: 779.190 1613365504.1219838
train: epoch 89, iter 2500, loss: 2.257083, top_1: 0.656289, top_k: 0.855508, samples/s: 779.316 1613365536.9713776
train: epoch 89, iter 2600, loss: 2.552442, top_1: 0.654727, top_k: 0.854648, samples/s: 781.798 1613365569.7163796
train: epoch 89, iter 2700, loss: 2.544908, top_1: 0.650352, top_k: 0.852383, samples/s: 780.812 1613365602.5027385
train: epoch 89, iter 2800, loss: 2.488799, top_1: 0.647695, top_k: 0.851641, samples/s: 779.589 1613365635.3405066
train: epoch 89, iter 2900, loss: 2.560059, top_1: 0.648711, top_k: 0.849336, samples/s: 776.744 1613365668.2986643
train: epoch 89, iter 3000, loss: 2.504850, top_1: 0.653281, top_k: 0.853242, samples/s: 780.575 1613365701.094922
train: epoch 89, iter 3100, loss: 2.847447, top_1: 0.646133, top_k: 0.853008, samples/s: 777.494 1613365734.021314
train: epoch 89, iter 3200, loss: 2.254945, top_1: 0.650625, top_k: 0.849414, samples/s: 780.311 1613365766.8286412
train: epoch 89, iter 3300, loss: 2.247405, top_1: 0.649180, top_k: 0.851719, samples/s: 780.875 1613365799.612411
train: epoch 89, iter 3400, loss: 2.399469, top_1: 0.646133, top_k: 0.848711, samples/s: 776.769 1613365832.5694835
train: epoch 89, iter 3500, loss: 2.427422, top_1: 0.654492, top_k: 0.855273, samples/s: 779.552 1613365865.4088786
train: epoch 89, iter 3600, loss: 2.448168, top_1: 0.649687, top_k: 0.846836, samples/s: 779.659 1613365898.243639
train: epoch 89, iter 3700, loss: 2.507155, top_1: 0.655391, top_k: 0.852891, samples/s: 780.616 1613365931.0383239
train: epoch 89, iter 3800, loss: 2.451534, top_1: 0.655469, top_k: 0.854883, samples/s: 780.268 1613365963.847564
train: epoch 89, iter 3900, loss: 2.633399, top_1: 0.649297, top_k: 0.848086, samples/s: 781.714 1613365996.5960312
train: epoch 89, iter 4000, loss: 2.391636, top_1: 0.651172, top_k: 0.853281, samples/s: 780.521 1613366029.3947034
train: epoch 89, iter 4100, loss: 2.327948, top_1: 0.655586, top_k: 0.855820, samples/s: 778.141 1613366062.293582
train: epoch 89, iter 4200, loss: 2.461685, top_1: 0.651836, top_k: 0.849727, samples/s: 780.944 1613366095.074515
train: epoch 89, iter 4300, loss: 2.370018, top_1: 0.651953, top_k: 0.854062, samples/s: 779.929 1613366127.89801
train: epoch 89, iter 4400, loss: 2.328858, top_1: 0.653359, top_k: 0.853164, samples/s: 780.954 1613366160.6785045
train: epoch 89, iter 4500, loss: 2.312099, top_1: 0.652305, top_k: 0.853320, samples/s: 779.779 1613366193.508236
train: epoch 89, iter 4600, loss: 2.583217, top_1: 0.648164, top_k: 0.848281, samples/s: 780.462 1613366226.3093264
train: epoch 89, iter 4700, loss: 2.389336, top_1: 0.652773, top_k: 0.853906, samples/s: 781.710 1613366259.0580266
train: epoch 89, iter 4800, loss: 2.410555, top_1: 0.649414, top_k: 0.849844, samples/s: 779.269 1613366291.9092946
train: epoch 89, iter 4900, loss: 2.408658, top_1: 0.646719, top_k: 0.849805, samples/s: 779.759 1613366324.7399375
train: epoch 89, iter 5000, loss: 2.320869, top_1: 0.659961, top_k: 0.854570, samples/s: 781.368 1613366357.5029464
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_89.
validation: epoch 89, iter 195, top_1: 0.691306, top_k: 0.893790, samples/s: 2364.076 1613366379.5990193
train: epoch 90, iter 100, loss: 2.211011, top_1: 0.666875, top_k: 0.862539, samples/s: 801.693 1613366431.8211899
train: epoch 90, iter 200, loss: 2.320226, top_1: 0.665391, top_k: 0.863789, samples/s: 798.410 1613366463.8850605
train: epoch 90, iter 300, loss: 2.265634, top_1: 0.661406, top_k: 0.858086, samples/s: 777.525 1613366496.809763
train: epoch 90, iter 400, loss: 2.400697, top_1: 0.658711, top_k: 0.858086, samples/s: 777.324 1613366529.7434008
train: epoch 90, iter 500, loss: 2.362647, top_1: 0.668008, top_k: 0.862852, samples/s: 779.826 1613366562.5712519
train: epoch 90, iter 600, loss: 2.537179, top_1: 0.659883, top_k: 0.858633, samples/s: 773.869 1613366595.6517687
train: epoch 90, iter 700, loss: 2.369043, top_1: 0.658477, top_k: 0.857734, samples/s: 781.530 1613366628.4079683
train: epoch 90, iter 800, loss: 2.415946, top_1: 0.660977, top_k: 0.857148, samples/s: 777.536 1613366661.3324847
train: epoch 90, iter 900, loss: 2.199407, top_1: 0.663008, top_k: 0.859688, samples/s: 778.089 1613366694.2336943
train: epoch 90, iter 1000, loss: 2.376002, top_1: 0.662188, top_k: 0.858477, samples/s: 777.523 1613366727.1587296
train: epoch 90, iter 1100, loss: 2.196343, top_1: 0.659766, top_k: 0.857266, samples/s: 778.181 1613366760.0559196
train: epoch 90, iter 1200, loss: 2.285294, top_1: 0.654297, top_k: 0.857227, samples/s: 781.097 1613366792.8304055
train: epoch 90, iter 1300, loss: 2.253670, top_1: 0.659297, top_k: 0.859727, samples/s: 779.331 1613366825.6790593
train: epoch 90, iter 1400, loss: 2.306880, top_1: 0.658906, top_k: 0.858008, samples/s: 778.920 1613366858.5450006
train: epoch 90, iter 1500, loss: 2.439483, top_1: 0.660820, top_k: 0.858047, samples/s: 779.767 1613366891.3753178
train: epoch 90, iter 1600, loss: 2.372229, top_1: 0.659766, top_k: 0.855625, samples/s: 778.243 1613366924.2699668
train: epoch 90, iter 1700, loss: 2.343387, top_1: 0.664141, top_k: 0.861836, samples/s: 779.501 1613366957.1114125
train: epoch 90, iter 1800, loss: 2.701767, top_1: 0.658555, top_k: 0.856992, samples/s: 778.634 1613366989.98962
train: epoch 90, iter 1900, loss: 2.581700, top_1: 0.654531, top_k: 0.856016, samples/s: 779.843 1613367022.8166616
train: epoch 90, iter 2000, loss: 2.315166, top_1: 0.655508, top_k: 0.854688, samples/s: 781.132 1613367055.5896091
train: epoch 90, iter 2100, loss: 2.346257, top_1: 0.653320, top_k: 0.852187, samples/s: 779.342 1613367088.4378443
train: epoch 90, iter 2200, loss: 2.297599, top_1: 0.659414, top_k: 0.855625, samples/s: 779.433 1613367121.2822852
train: epoch 90, iter 2300, loss: 2.432296, top_1: 0.654062, top_k: 0.853555, samples/s: 782.221 1613367154.009541
train: epoch 90, iter 2400, loss: 2.395494, top_1: 0.654766, top_k: 0.855430, samples/s: 779.584 1613367186.8476708
train: epoch 90, iter 2500, loss: 2.457728, top_1: 0.654844, top_k: 0.855781, samples/s: 780.507 1613367219.6468544
train: epoch 90, iter 2600, loss: 2.593814, top_1: 0.652891, top_k: 0.853750, samples/s: 781.076 1613367252.422135
train: epoch 90, iter 2700, loss: 2.307594, top_1: 0.654336, top_k: 0.856523, samples/s: 780.439 1613367285.2241535
train: epoch 90, iter 2800, loss: 2.273932, top_1: 0.653750, top_k: 0.853984, samples/s: 779.569 1613367318.0628307
train: epoch 90, iter 2900, loss: 2.360532, top_1: 0.651563, top_k: 0.852383, samples/s: 782.368 1613367350.7840316
train: epoch 90, iter 3000, loss: 2.365479, top_1: 0.653438, top_k: 0.852930, samples/s: 779.486 1613367383.6261601
train: epoch 90, iter 3100, loss: 2.425577, top_1: 0.650781, top_k: 0.855820, samples/s: 780.873 1613367416.4100115
train: epoch 90, iter 3200, loss: 2.225270, top_1: 0.654219, top_k: 0.852695, samples/s: 784.505 1613367449.0419483
train: epoch 90, iter 3300, loss: 2.491876, top_1: 0.654883, top_k: 0.857305, samples/s: 781.784 1613367481.7876742
train: epoch 90, iter 3400, loss: 2.394534, top_1: 0.652930, top_k: 0.853359, samples/s: 780.207 1613367514.599385
train: epoch 90, iter 3500, loss: 2.582400, top_1: 0.654687, top_k: 0.855117, samples/s: 778.722 1613367547.4737356
train: epoch 90, iter 3600, loss: 2.388982, top_1: 0.660078, top_k: 0.854922, samples/s: 783.777 1613367580.1360364
train: epoch 90, iter 3700, loss: 2.414680, top_1: 0.652891, top_k: 0.852227, samples/s: 779.832 1613367612.963832
train: epoch 90, iter 3800, loss: 2.326235, top_1: 0.653438, top_k: 0.857930, samples/s: 780.445 1613367645.7654355
train: epoch 90, iter 3900, loss: 2.438569, top_1: 0.653203, top_k: 0.855000, samples/s: 781.975 1613367678.503105
train: epoch 90, iter 4000, loss: 2.601209, top_1: 0.649375, top_k: 0.852930, samples/s: 781.502 1613367711.2604606
train: epoch 90, iter 4100, loss: 2.281224, top_1: 0.653477, top_k: 0.852852, samples/s: 781.857 1613367744.0031106
train: epoch 90, iter 4200, loss: 2.352523, top_1: 0.651719, top_k: 0.848828, samples/s: 779.335 1613367776.8515882
train: epoch 90, iter 4300, loss: 2.596605, top_1: 0.651406, top_k: 0.850391, samples/s: 782.460 1613367809.5689664
train: epoch 90, iter 4400, loss: 2.492059, top_1: 0.653438, top_k: 0.855898, samples/s: 781.365 1613367842.3321078
train: epoch 90, iter 4500, loss: 2.293526, top_1: 0.654375, top_k: 0.855039, samples/s: 783.425 1613367875.009106
train: epoch 90, iter 4600, loss: 2.418973, top_1: 0.655664, top_k: 0.855000, samples/s: 780.926 1613367907.7907135
train: epoch 90, iter 4700, loss: 2.449520, top_1: 0.653672, top_k: 0.853477, samples/s: 779.573 1613367940.6292512
train: epoch 90, iter 4800, loss: 2.349276, top_1: 0.658242, top_k: 0.858594, samples/s: 783.550 1613367973.3010447
train: epoch 90, iter 4900, loss: 2.444658, top_1: 0.650625, top_k: 0.852734, samples/s: 780.677 1613368006.0931137
train: epoch 90, iter 5000, loss: 2.255555, top_1: 0.663398, top_k: 0.858906, samples/s: 780.334 1613368038.8995805
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_90.
validation: epoch 90, iter 195, top_1: 0.696014, top_k: 0.895853, samples/s: 2336.689 1613368061.2394216
train: epoch 91, iter 100, loss: 2.550641, top_1: 0.659961, top_k: 0.859062, samples/s: 804.112 1613368113.5172892
train: epoch 91, iter 200, loss: 2.206274, top_1: 0.662344, top_k: 0.861094, samples/s: 798.203 1613368145.589506
train: epoch 91, iter 300, loss: 2.233609, top_1: 0.670352, top_k: 0.867227, samples/s: 784.391 1613368178.2260106
train: epoch 91, iter 400, loss: 2.370723, top_1: 0.665625, top_k: 0.863086, samples/s: 778.181 1613368211.1232204
train: epoch 91, iter 500, loss: 2.223711, top_1: 0.663555, top_k: 0.860898, samples/s: 780.921 1613368243.9050193
train: epoch 91, iter 600, loss: 2.390838, top_1: 0.661445, top_k: 0.859961, samples/s: 777.440 1613368276.8337257
train: epoch 91, iter 700, loss: 2.407516, top_1: 0.662383, top_k: 0.860938, samples/s: 780.552 1613368309.630849
train: epoch 91, iter 800, loss: 2.524699, top_1: 0.664961, top_k: 0.863125, samples/s: 780.779 1613368342.4186273
train: epoch 91, iter 900, loss: 2.335593, top_1: 0.665234, top_k: 0.860039, samples/s: 776.846 1613368375.3724964
train: epoch 91, iter 1000, loss: 2.438298, top_1: 0.654844, top_k: 0.858711, samples/s: 782.073 1613368408.1059253
train: epoch 91, iter 1100, loss: 2.298657, top_1: 0.661094, top_k: 0.861250, samples/s: 778.502 1613368440.9896672
train: epoch 91, iter 1200, loss: 2.370452, top_1: 0.660234, top_k: 0.858516, samples/s: 780.742 1613368473.7788715
train: epoch 91, iter 1300, loss: 2.426818, top_1: 0.658711, top_k: 0.861289, samples/s: 782.431 1613368506.4974215
train: epoch 91, iter 1400, loss: 2.053334, top_1: 0.663203, top_k: 0.859336, samples/s: 779.812 1613368539.3259282
train: epoch 91, iter 1500, loss: 2.451197, top_1: 0.662422, top_k: 0.862695, samples/s: 780.618 1613368572.120419
train: epoch 91, iter 1600, loss: 2.200065, top_1: 0.660977, top_k: 0.859883, samples/s: 777.062 1613368605.0649898
train: epoch 91, iter 1700, loss: 2.316474, top_1: 0.656289, top_k: 0.856172, samples/s: 780.558 1613368637.8620188
train: epoch 91, iter 1800, loss: 2.364850, top_1: 0.660547, top_k: 0.858555, samples/s: 780.418 1613368670.6649342
train: epoch 91, iter 1900, loss: 2.450024, top_1: 0.655937, top_k: 0.855703, samples/s: 779.977 1613368703.4864964
train: epoch 91, iter 2000, loss: 2.486176, top_1: 0.659062, top_k: 0.859844, samples/s: 781.349 1613368736.2503939
train: epoch 91, iter 2100, loss: 2.372054, top_1: 0.662969, top_k: 0.857344, samples/s: 782.849 1613368768.9513218
train: epoch 91, iter 2200, loss: 2.495931, top_1: 0.657969, top_k: 0.856367, samples/s: 780.794 1613368801.7385721
train: epoch 91, iter 2300, loss: 2.383369, top_1: 0.662930, top_k: 0.860820, samples/s: 779.032 1613368834.599897
train: epoch 91, iter 2400, loss: 2.494678, top_1: 0.655625, top_k: 0.854336, samples/s: 781.940 1613368867.338964
train: epoch 91, iter 2500, loss: 2.606973, top_1: 0.655586, top_k: 0.855352, samples/s: 783.449 1613368900.0149508
train: epoch 91, iter 2600, loss: 2.526134, top_1: 0.657969, top_k: 0.857734, samples/s: 780.199 1613368932.8271463
train: epoch 91, iter 2700, loss: 2.428140, top_1: 0.657422, top_k: 0.857852, samples/s: 782.435 1613368965.545429
train: epoch 91, iter 2800, loss: 2.351727, top_1: 0.653750, top_k: 0.856133, samples/s: 780.796 1613368998.332548
train: epoch 91, iter 2900, loss: 2.328771, top_1: 0.661836, top_k: 0.856328, samples/s: 780.915 1613369031.1146567
train: epoch 91, iter 3000, loss: 2.145899, top_1: 0.655352, top_k: 0.854453, samples/s: 780.531 1613369063.9127367
train: epoch 91, iter 3100, loss: 2.464616, top_1: 0.658125, top_k: 0.859414, samples/s: 779.969 1613369096.7345762
train: epoch 91, iter 3200, loss: 2.370825, top_1: 0.654258, top_k: 0.852070, samples/s: 778.118 1613369129.6345108
train: epoch 91, iter 3300, loss: 2.349390, top_1: 0.657500, top_k: 0.857070, samples/s: 782.087 1613369162.3674688
train: epoch 91, iter 3400, loss: 2.455209, top_1: 0.655312, top_k: 0.853906, samples/s: 782.689 1613369195.0751295
train: epoch 91, iter 3500, loss: 2.588138, top_1: 0.650586, top_k: 0.853125, samples/s: 779.318 1613369227.9244525
train: epoch 91, iter 3600, loss: 2.451135, top_1: 0.656641, top_k: 0.854492, samples/s: 780.381 1613369260.7288723
train: epoch 91, iter 3700, loss: 2.323481, top_1: 0.655312, top_k: 0.858555, samples/s: 782.273 1613369293.454084
train: epoch 91, iter 3800, loss: 2.522480, top_1: 0.655820, top_k: 0.855664, samples/s: 779.697 1613369326.287433
train: epoch 91, iter 3900, loss: 2.254198, top_1: 0.652539, top_k: 0.853047, samples/s: 780.175 1613369359.1004872
train: epoch 91, iter 4000, loss: 2.475753, top_1: 0.654453, top_k: 0.855078, samples/s: 779.804 1613369391.9291472
train: epoch 91, iter 4100, loss: 2.464334, top_1: 0.653047, top_k: 0.853359, samples/s: 780.851 1613369424.7139766
train: epoch 91, iter 4200, loss: 2.418274, top_1: 0.658555, top_k: 0.855625, samples/s: 780.035 1613369457.5329478
train: epoch 91, iter 4300, loss: 2.282113, top_1: 0.660273, top_k: 0.855547, samples/s: 781.847 1613369490.2759457
train: epoch 91, iter 4400, loss: 2.689017, top_1: 0.653828, top_k: 0.856328, samples/s: 777.633 1613369523.1963282
train: epoch 91, iter 4500, loss: 2.409500, top_1: 0.655234, top_k: 0.855781, samples/s: 781.583 1613369555.9504406
train: epoch 91, iter 4600, loss: 2.533340, top_1: 0.656016, top_k: 0.854375, samples/s: 783.432 1613369588.627129
train: epoch 91, iter 4700, loss: 2.523773, top_1: 0.652344, top_k: 0.854141, samples/s: 780.267 1613369621.4364216
train: epoch 91, iter 4800, loss: 2.259042, top_1: 0.657148, top_k: 0.858555, samples/s: 781.473 1613369654.1950333
train: epoch 91, iter 4900, loss: 2.330901, top_1: 0.652734, top_k: 0.853906, samples/s: 783.220 1613369686.8806257
train: epoch 91, iter 5000, loss: 2.146640, top_1: 0.664180, top_k: 0.860234, samples/s: 779.996 1613369719.7013502
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_91.
validation: epoch 91, iter 195, top_1: 0.696514, top_k: 0.896875, samples/s: 2400.015 1613369741.478194
train: epoch 92, iter 100, loss: 2.313071, top_1: 0.666016, top_k: 0.863984, samples/s: 804.530 1613369793.7584922
train: epoch 92, iter 200, loss: 2.295607, top_1: 0.668164, top_k: 0.864961, samples/s: 798.360 1613369825.8243773
train: epoch 92, iter 300, loss: 2.296635, top_1: 0.668047, top_k: 0.863516, samples/s: 783.556 1613369858.4957614
train: epoch 92, iter 400, loss: 2.365657, top_1: 0.671250, top_k: 0.863633, samples/s: 777.138 1613369891.437164
train: epoch 92, iter 500, loss: 2.390297, top_1: 0.670859, top_k: 0.867344, samples/s: 777.384 1613369924.3681352
train: epoch 92, iter 600, loss: 2.579475, top_1: 0.669648, top_k: 0.864961, samples/s: 778.992 1613369957.2310793
train: epoch 92, iter 700, loss: 2.352686, top_1: 0.666094, top_k: 0.861406, samples/s: 779.715 1613369990.0636141
train: epoch 92, iter 800, loss: 2.430513, top_1: 0.670469, top_k: 0.866641, samples/s: 781.642 1613370022.8152328
train: epoch 92, iter 900, loss: 2.214537, top_1: 0.658203, top_k: 0.858281, samples/s: 776.290 1613370055.792459
train: epoch 92, iter 1000, loss: 2.165037, top_1: 0.663594, top_k: 0.859453, samples/s: 780.418 1613370088.5954366
train: epoch 92, iter 1100, loss: 2.338913, top_1: 0.663828, top_k: 0.860586, samples/s: 776.837 1613370121.549585
train: epoch 92, iter 1200, loss: 2.465431, top_1: 0.666719, top_k: 0.863867, samples/s: 777.347 1613370154.4822013
train: epoch 92, iter 1300, loss: 2.506473, top_1: 0.658125, top_k: 0.857461, samples/s: 779.737 1613370187.3138041
train: epoch 92, iter 1400, loss: 2.543368, top_1: 0.662266, top_k: 0.861797, samples/s: 778.280 1613370220.20672
train: epoch 92, iter 1500, loss: 2.393315, top_1: 0.660742, top_k: 0.858008, samples/s: 779.474 1613370253.0494115
train: epoch 92, iter 1600, loss: 2.185268, top_1: 0.661758, top_k: 0.860898, samples/s: 779.607 1613370285.8864965
train: epoch 92, iter 1700, loss: 2.589333, top_1: 0.663750, top_k: 0.861211, samples/s: 778.142 1613370318.7855155
train: epoch 92, iter 1800, loss: 2.255223, top_1: 0.658477, top_k: 0.855977, samples/s: 778.407 1613370351.6729949
train: epoch 92, iter 1900, loss: 2.338938, top_1: 0.658242, top_k: 0.857617, samples/s: 777.917 1613370384.5814164
train: epoch 92, iter 2000, loss: 2.300640, top_1: 0.661914, top_k: 0.860000, samples/s: 780.449 1613370417.3830495
train: epoch 92, iter 2100, loss: 2.429104, top_1: 0.656367, top_k: 0.855742, samples/s: 779.034 1613370450.244308
train: epoch 92, iter 2200, loss: 2.436295, top_1: 0.661719, top_k: 0.856211, samples/s: 778.056 1613370483.146777
train: epoch 92, iter 2300, loss: 2.483615, top_1: 0.659922, top_k: 0.855547, samples/s: 778.851 1613370516.0157084
train: epoch 92, iter 2400, loss: 2.562794, top_1: 0.655391, top_k: 0.857695, samples/s: 778.677 1613370548.8920958
train: epoch 92, iter 2500, loss: 2.428073, top_1: 0.663320, top_k: 0.861133, samples/s: 780.325 1613370581.6988184
train: epoch 92, iter 2600, loss: 2.345349, top_1: 0.661758, top_k: 0.857930, samples/s: 779.339 1613370614.5471542
train: epoch 92, iter 2700, loss: 2.407865, top_1: 0.666094, top_k: 0.860117, samples/s: 780.250 1613370647.3571463
train: epoch 92, iter 2800, loss: 2.572472, top_1: 0.655273, top_k: 0.856406, samples/s: 779.560 1613370680.1962042
train: epoch 92, iter 2900, loss: 2.296059, top_1: 0.662539, top_k: 0.858633, samples/s: 783.086 1613370712.8873866
train: epoch 92, iter 3000, loss: 2.300169, top_1: 0.659102, top_k: 0.855273, samples/s: 778.616 1613370745.7662263
train: epoch 92, iter 3100, loss: 2.524035, top_1: 0.654258, top_k: 0.854336, samples/s: 778.963 1613370778.6305242
train: epoch 92, iter 3200, loss: 2.392588, top_1: 0.653945, top_k: 0.852617, samples/s: 780.855 1613370811.4150608
train: epoch 92, iter 3300, loss: 2.425414, top_1: 0.660508, top_k: 0.859414, samples/s: 782.800 1613370844.1181767
train: epoch 92, iter 3400, loss: 2.360282, top_1: 0.659648, top_k: 0.856758, samples/s: 779.101 1613370876.9764845
train: epoch 92, iter 3500, loss: 2.422433, top_1: 0.657227, top_k: 0.858281, samples/s: 781.468 1613370909.7354434
train: epoch 92, iter 3600, loss: 2.450265, top_1: 0.655391, top_k: 0.855664, samples/s: 781.294 1613370942.5015652
train: epoch 92, iter 3700, loss: 2.383219, top_1: 0.661602, top_k: 0.858047, samples/s: 781.086 1613370975.2764103
train: epoch 92, iter 3800, loss: 2.491391, top_1: 0.654922, top_k: 0.856094, samples/s: 779.146 1613371008.1328878
train: epoch 92, iter 3900, loss: 2.369104, top_1: 0.655859, top_k: 0.853125, samples/s: 782.585 1613371040.8450494
train: epoch 92, iter 4000, loss: 2.516964, top_1: 0.658867, top_k: 0.857617, samples/s: 781.944 1613371073.583907
train: epoch 92, iter 4100, loss: 2.339013, top_1: 0.654609, top_k: 0.856875, samples/s: 782.112 1613371106.3157878
train: epoch 92, iter 4200, loss: 2.323835, top_1: 0.655195, top_k: 0.856406, samples/s: 778.893 1613371139.1830256
train: epoch 92, iter 4300, loss: 2.377555, top_1: 0.654687, top_k: 0.859609, samples/s: 781.298 1613371171.9489086
train: epoch 92, iter 4400, loss: 2.359108, top_1: 0.655195, top_k: 0.854570, samples/s: 779.935 1613371204.7723067
train: epoch 92, iter 4500, loss: 2.348059, top_1: 0.658203, top_k: 0.852930, samples/s: 782.425 1613371237.4910247
train: epoch 92, iter 4600, loss: 2.432919, top_1: 0.651367, top_k: 0.851914, samples/s: 780.539 1613371270.288876
train: epoch 92, iter 4700, loss: 2.483247, top_1: 0.656211, top_k: 0.853867, samples/s: 778.643 1613371303.1666431
train: epoch 92, iter 4800, loss: 2.388863, top_1: 0.654375, top_k: 0.855859, samples/s: 782.549 1613371335.880146
train: epoch 92, iter 4900, loss: 2.507444, top_1: 0.663008, top_k: 0.859883, samples/s: 778.657 1613371368.7573776
train: epoch 92, iter 5000, loss: 2.299195, top_1: 0.663828, top_k: 0.857734, samples/s: 780.882 1613371401.5408158
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_92.
validation: epoch 92, iter 195, top_1: 0.701062, top_k: 0.899960, samples/s: 2364.424 1613371423.6237783
train: epoch 93, iter 100, loss: 2.723140, top_1: 0.673242, top_k: 0.866914, samples/s: 802.606 1613371475.8762553
train: epoch 93, iter 200, loss: 2.362730, top_1: 0.675898, top_k: 0.864531, samples/s: 799.769 1613371507.8854723
train: epoch 93, iter 300, loss: 2.405370, top_1: 0.667773, top_k: 0.861133, samples/s: 780.972 1613371540.665314
train: epoch 93, iter 400, loss: 2.277100, top_1: 0.671055, top_k: 0.867305, samples/s: 779.101 1613371573.5234296
train: epoch 93, iter 500, loss: 2.493303, top_1: 0.663242, top_k: 0.858750, samples/s: 778.158 1613371606.4216862
train: epoch 93, iter 600, loss: 2.598119, top_1: 0.667344, top_k: 0.862422, samples/s: 779.010 1613371639.2839622
train: epoch 93, iter 700, loss: 2.284550, top_1: 0.671680, top_k: 0.867109, samples/s: 780.654 1613371672.0769424
train: epoch 93, iter 800, loss: 2.474405, top_1: 0.667617, top_k: 0.861602, samples/s: 779.257 1613371704.9292533
train: epoch 93, iter 900, loss: 2.241225, top_1: 0.664648, top_k: 0.863359, samples/s: 777.530 1613371737.8535278
train: epoch 93, iter 1000, loss: 2.340242, top_1: 0.673945, top_k: 0.863867, samples/s: 783.762 1613371770.5169365
train: epoch 93, iter 1100, loss: 2.332214, top_1: 0.660703, top_k: 0.859141, samples/s: 777.504 1613371803.4423015
train: epoch 93, iter 1200, loss: 2.454860, top_1: 0.660625, top_k: 0.857500, samples/s: 779.815 1613371836.2706373
train: epoch 93, iter 1300, loss: 2.354068, top_1: 0.663164, top_k: 0.857305, samples/s: 780.229 1613371869.0815806
train: epoch 93, iter 1400, loss: 2.244721, top_1: 0.665898, top_k: 0.864258, samples/s: 778.495 1613371901.9654484
train: epoch 93, iter 1500, loss: 2.520825, top_1: 0.663711, top_k: 0.862773, samples/s: 782.825 1613371934.667527
train: epoch 93, iter 1600, loss: 2.458185, top_1: 0.659727, top_k: 0.861641, samples/s: 778.213 1613371967.563474
train: epoch 93, iter 1700, loss: 2.319656, top_1: 0.659648, top_k: 0.855469, samples/s: 782.285 1613372000.28812
train: epoch 93, iter 1800, loss: 2.364885, top_1: 0.661016, top_k: 0.857305, samples/s: 779.464 1613372033.1311138
train: epoch 93, iter 1900, loss: 2.436876, top_1: 0.665352, top_k: 0.860977, samples/s: 780.012 1613372065.951241
train: epoch 93, iter 2000, loss: 2.226288, top_1: 0.665625, top_k: 0.860313, samples/s: 783.549 1613372098.6230118
train: epoch 93, iter 2100, loss: 2.323482, top_1: 0.660234, top_k: 0.857734, samples/s: 778.130 1613372131.5224786
train: epoch 93, iter 2200, loss: 2.280254, top_1: 0.660625, top_k: 0.861953, samples/s: 784.431 1613372164.1577191
train: epoch 93, iter 2300, loss: 2.349072, top_1: 0.660703, top_k: 0.856836, samples/s: 778.263 1613372197.0513484
train: epoch 93, iter 2400, loss: 2.278629, top_1: 0.662461, top_k: 0.858086, samples/s: 781.372 1613372229.8142798
train: epoch 93, iter 2500, loss: 2.503064, top_1: 0.663398, top_k: 0.858711, samples/s: 780.276 1613372262.623219
train: epoch 93, iter 2600, loss: 2.456398, top_1: 0.666719, top_k: 0.859492, samples/s: 781.886 1613372295.364539
train: epoch 93, iter 2700, loss: 2.409507, top_1: 0.662383, top_k: 0.861719, samples/s: 783.193 1613372328.0513191
train: epoch 93, iter 2800, loss: 2.492649, top_1: 0.655195, top_k: 0.856367, samples/s: 782.336 1613372360.7737417
train: epoch 93, iter 2900, loss: 2.402482, top_1: 0.661523, top_k: 0.857891, samples/s: 782.514 1613372393.488807
train: epoch 93, iter 3000, loss: 2.410705, top_1: 0.659375, top_k: 0.857695, samples/s: 783.785 1613372426.1507974
train: epoch 93, iter 3100, loss: 2.409103, top_1: 0.658203, top_k: 0.856172, samples/s: 779.618 1613372458.9874055
train: epoch 93, iter 3200, loss: 2.302074, top_1: 0.660195, top_k: 0.858125, samples/s: 786.822 1613372491.5233061
train: epoch 93, iter 3300, loss: 2.417486, top_1: 0.659141, top_k: 0.857109, samples/s: 784.324 1613372524.1629007
train: epoch 93, iter 3400, loss: 2.297309, top_1: 0.666172, top_k: 0.861953, samples/s: 781.420 1613372556.9237628
train: epoch 93, iter 3500, loss: 2.466689, top_1: 0.663438, top_k: 0.857656, samples/s: 782.326 1613372589.6466656
train: epoch 93, iter 3600, loss: 2.350433, top_1: 0.656523, top_k: 0.858984, samples/s: 784.474 1613372622.2799993
train: epoch 93, iter 3700, loss: 2.361484, top_1: 0.664648, top_k: 0.862070, samples/s: 781.849 1613372655.0229332
train: epoch 93, iter 3800, loss: 2.432600, top_1: 0.660586, top_k: 0.859922, samples/s: 783.284 1613372687.7057953
train: epoch 93, iter 3900, loss: 2.490115, top_1: 0.658711, top_k: 0.857031, samples/s: 782.601 1613372720.4173217
train: epoch 93, iter 4000, loss: 2.502584, top_1: 0.659922, top_k: 0.855000, samples/s: 781.974 1613372753.1549613
train: epoch 93, iter 4100, loss: 2.415162, top_1: 0.657500, top_k: 0.853945, samples/s: 779.210 1613372786.0086455
train: epoch 93, iter 4200, loss: 2.449932, top_1: 0.654570, top_k: 0.855117, samples/s: 783.397 1613372818.6868968
train: epoch 93, iter 4300, loss: 2.277172, top_1: 0.663633, top_k: 0.860781, samples/s: 781.589 1613372851.440634
train: epoch 93, iter 4400, loss: 2.447418, top_1: 0.660859, top_k: 0.854883, samples/s: 782.480 1613372884.157093
train: epoch 93, iter 4500, loss: 2.231508, top_1: 0.656836, top_k: 0.857305, samples/s: 782.197 1613372916.8854728
train: epoch 93, iter 4600, loss: 2.352778, top_1: 0.664727, top_k: 0.860742, samples/s: 781.955 1613372949.6239047
train: epoch 93, iter 4700, loss: 2.341390, top_1: 0.659883, top_k: 0.857578, samples/s: 781.181 1613372982.3947167
train: epoch 93, iter 4800, loss: 2.443380, top_1: 0.656836, top_k: 0.855039, samples/s: 783.063 1613373015.0869775
train: epoch 93, iter 4900, loss: 2.363959, top_1: 0.659375, top_k: 0.856484, samples/s: 781.358 1613373047.8504367
train: epoch 93, iter 5000, loss: 2.511177, top_1: 0.664531, top_k: 0.858125, samples/s: 779.401 1613373080.696187
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_93.
validation: epoch 93, iter 195, top_1: 0.694251, top_k: 0.893490, samples/s: 2338.550 1613373102.99069
train: epoch 94, iter 100, loss: 2.278685, top_1: 0.672461, top_k: 0.862773, samples/s: 803.184 1613373155.0679767
train: epoch 94, iter 200, loss: 2.363363, top_1: 0.670977, top_k: 0.863164, samples/s: 798.257 1613373187.1378982
train: epoch 94, iter 300, loss: 2.581706, top_1: 0.668359, top_k: 0.862187, samples/s: 781.593 1613373219.8914142
train: epoch 94, iter 400, loss: 2.294482, top_1: 0.676602, top_k: 0.866602, samples/s: 781.049 1613373252.6681535
train: epoch 94, iter 500, loss: 2.485908, top_1: 0.676055, top_k: 0.868164, samples/s: 780.831 1613373285.4534035
train: epoch 94, iter 600, loss: 2.422052, top_1: 0.671953, top_k: 0.867070, samples/s: 781.424 1613373318.2141807
train: epoch 94, iter 700, loss: 2.469814, top_1: 0.669883, top_k: 0.866680, samples/s: 781.120 1613373350.9876714
train: epoch 94, iter 800, loss: 2.529514, top_1: 0.663164, top_k: 0.862031, samples/s: 777.650 1613373383.9073367
train: epoch 94, iter 900, loss: 2.480155, top_1: 0.677070, top_k: 0.864062, samples/s: 779.509 1613373416.7484257
train: epoch 94, iter 1000, loss: 2.500367, top_1: 0.677148, top_k: 0.870195, samples/s: 783.070 1613373449.4403517
train: epoch 94, iter 1100, loss: 2.166070, top_1: 0.668828, top_k: 0.864805, samples/s: 782.781 1613373482.1441839
train: epoch 94, iter 1200, loss: 2.462475, top_1: 0.666914, top_k: 0.863047, samples/s: 780.972 1613373514.9239295
train: epoch 94, iter 1300, loss: 2.387960, top_1: 0.659609, top_k: 0.859883, samples/s: 779.473 1613373547.766588
train: epoch 94, iter 1400, loss: 2.424828, top_1: 0.665430, top_k: 0.862891, samples/s: 781.175 1613373580.5377963
train: epoch 94, iter 1500, loss: 2.385292, top_1: 0.667461, top_k: 0.862695, samples/s: 782.412 1613373613.2572033
train: epoch 94, iter 1600, loss: 2.592814, top_1: 0.667734, top_k: 0.861680, samples/s: 780.822 1613373646.0430667
train: epoch 94, iter 1700, loss: 2.355398, top_1: 0.663008, top_k: 0.861523, samples/s: 783.152 1613373678.7314847
train: epoch 94, iter 1800, loss: 2.428958, top_1: 0.666055, top_k: 0.858945, samples/s: 780.554 1613373711.5287075
train: epoch 94, iter 1900, loss: 2.341392, top_1: 0.664258, top_k: 0.860938, samples/s: 780.586 1613373744.324609
train: epoch 94, iter 2000, loss: 2.394022, top_1: 0.663125, top_k: 0.858672, samples/s: 779.244 1613373777.1770062
train: epoch 94, iter 2100, loss: 2.531209, top_1: 0.660820, top_k: 0.858125, samples/s: 781.564 1613373809.9317217
train: epoch 94, iter 2200, loss: 2.356905, top_1: 0.663828, top_k: 0.860938, samples/s: 783.013 1613373842.62608
train: epoch 94, iter 2300, loss: 2.421550, top_1: 0.666211, top_k: 0.860273, samples/s: 781.269 1613373875.3938127
train: epoch 94, iter 2400, loss: 2.360332, top_1: 0.670469, top_k: 0.864883, samples/s: 781.214 1613373908.1626987
train: epoch 94, iter 2500, loss: 2.351102, top_1: 0.663906, top_k: 0.862109, samples/s: 782.861 1613373940.8633604
train: epoch 94, iter 2600, loss: 2.199560, top_1: 0.667031, top_k: 0.864141, samples/s: 781.348 1613373973.6272619
train: epoch 94, iter 2700, loss: 2.541950, top_1: 0.661250, top_k: 0.858672, samples/s: 780.326 1613374006.4339938
train: epoch 94, iter 2800, loss: 2.330286, top_1: 0.665000, top_k: 0.861836, samples/s: 781.035 1613374039.2110515
train: epoch 94, iter 2900, loss: 2.447309, top_1: 0.663945, top_k: 0.859805, samples/s: 781.146 1613374071.98353
train: epoch 94, iter 3000, loss: 2.370081, top_1: 0.664453, top_k: 0.860391, samples/s: 781.412 1613374104.7451935
train: epoch 94, iter 3100, loss: 2.305786, top_1: 0.655391, top_k: 0.856563, samples/s: 783.599 1613374137.4143765
train: epoch 94, iter 3200, loss: 2.455947, top_1: 0.665508, top_k: 0.859102, samples/s: 780.513 1613374170.2133358
train: epoch 94, iter 3300, loss: 2.392872, top_1: 0.663672, top_k: 0.857695, samples/s: 781.794 1613374202.9585288
train: epoch 94, iter 3400, loss: 2.282305, top_1: 0.663477, top_k: 0.859219, samples/s: 782.340 1613374235.6808248
train: epoch 94, iter 3500, loss: 2.140783, top_1: 0.661680, top_k: 0.856328, samples/s: 781.036 1613374268.4578888
train: epoch 94, iter 3600, loss: 2.384731, top_1: 0.655273, top_k: 0.855117, samples/s: 783.572 1613374301.1287596
train: epoch 94, iter 3700, loss: 2.551245, top_1: 0.655508, top_k: 0.856758, samples/s: 779.298 1613374333.97888
train: epoch 94, iter 3800, loss: 2.474287, top_1: 0.657539, top_k: 0.856289, samples/s: 780.877 1613374366.7625492
train: epoch 94, iter 3900, loss: 2.471274, top_1: 0.660391, top_k: 0.860195, samples/s: 785.928 1613374399.335399
train: epoch 94, iter 4000, loss: 2.431880, top_1: 0.664922, top_k: 0.856602, samples/s: 780.025 1613374432.1548705
train: epoch 94, iter 4100, loss: 2.356090, top_1: 0.663203, top_k: 0.855273, samples/s: 781.114 1613374464.9286788
train: epoch 94, iter 4200, loss: 2.585976, top_1: 0.661172, top_k: 0.859414, samples/s: 780.018 1613374497.7484474
train: epoch 94, iter 4300, loss: 2.349962, top_1: 0.663867, top_k: 0.858164, samples/s: 782.190 1613374530.477034
train: epoch 94, iter 4400, loss: 2.206736, top_1: 0.662539, top_k: 0.861328, samples/s: 779.596 1613374563.314527
train: epoch 94, iter 4500, loss: 2.381253, top_1: 0.659805, top_k: 0.858086, samples/s: 780.405 1613374596.1180296
train: epoch 94, iter 4600, loss: 2.332808, top_1: 0.661719, top_k: 0.856563, samples/s: 779.896 1613374628.9429634
train: epoch 94, iter 4700, loss: 2.358192, top_1: 0.660469, top_k: 0.857305, samples/s: 780.350 1613374661.7487023
train: epoch 94, iter 4800, loss: 2.364521, top_1: 0.658203, top_k: 0.857344, samples/s: 780.622 1613374694.543101
train: epoch 94, iter 4900, loss: 2.390182, top_1: 0.656797, top_k: 0.856680, samples/s: 782.924 1613374727.2409616
train: epoch 94, iter 5000, loss: 2.412143, top_1: 0.669609, top_k: 0.864062, samples/s: 782.927 1613374759.9388502
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_94.
validation: epoch 94, iter 195, top_1: 0.703946, top_k: 0.899740, samples/s: 2336.881 1613374782.2866411
train: epoch 95, iter 100, loss: 2.293298, top_1: 0.681992, top_k: 0.871367, samples/s: 804.691 1613374834.2068756
train: epoch 95, iter 200, loss: 2.292238, top_1: 0.672031, top_k: 0.866055, samples/s: 797.640 1613374866.301545
train: epoch 95, iter 300, loss: 2.358907, top_1: 0.676211, top_k: 0.870859, samples/s: 782.135 1613374899.0325089
train: epoch 95, iter 400, loss: 2.230826, top_1: 0.673047, top_k: 0.863594, samples/s: 780.338 1613374931.8389523
train: epoch 95, iter 500, loss: 2.527639, top_1: 0.668477, top_k: 0.861484, samples/s: 779.096 1613374964.6973984
train: epoch 95, iter 600, loss: 2.338259, top_1: 0.672578, top_k: 0.865078, samples/s: 777.756 1613374997.6126223
train: epoch 95, iter 700, loss: 2.319883, top_1: 0.672695, top_k: 0.866641, samples/s: 779.224 1613375030.4658105
train: epoch 95, iter 800, loss: 2.337493, top_1: 0.671445, top_k: 0.862969, samples/s: 778.666 1613375063.3424675
train: epoch 95, iter 900, loss: 2.414600, top_1: 0.667734, top_k: 0.862773, samples/s: 777.897 1613375096.251784
train: epoch 95, iter 1000, loss: 2.345186, top_1: 0.670898, top_k: 0.864844, samples/s: 780.108 1613375129.0677156
train: epoch 95, iter 1100, loss: 2.346358, top_1: 0.672109, top_k: 0.862930, samples/s: 780.940 1613375161.8487265
train: epoch 95, iter 1200, loss: 2.502173, top_1: 0.666133, top_k: 0.862539, samples/s: 777.030 1613375194.7947495
train: epoch 95, iter 1300, loss: 2.479837, top_1: 0.669961, top_k: 0.863398, samples/s: 782.835 1613375227.4967542
train: epoch 95, iter 1400, loss: 2.323086, top_1: 0.671250, top_k: 0.864766, samples/s: 779.497 1613375260.3379948
train: epoch 95, iter 1500, loss: 2.357611, top_1: 0.666836, top_k: 0.862617, samples/s: 779.510 1613375293.179524
train: epoch 95, iter 1600, loss: 2.450745, top_1: 0.667617, top_k: 0.858398, samples/s: 780.739 1613375325.968624
train: epoch 95, iter 1700, loss: 2.182387, top_1: 0.665742, top_k: 0.862461, samples/s: 777.002 1613375358.9157627
train: epoch 95, iter 1800, loss: 2.355453, top_1: 0.674648, top_k: 0.863203, samples/s: 783.350 1613375391.5958812
train: epoch 95, iter 1900, loss: 2.191844, top_1: 0.663203, top_k: 0.860039, samples/s: 778.489 1613375424.480112
train: epoch 95, iter 2000, loss: 2.387669, top_1: 0.659297, top_k: 0.859688, samples/s: 779.946 1613375457.3029044
train: epoch 95, iter 2100, loss: 2.316668, top_1: 0.669609, top_k: 0.863906, samples/s: 782.292 1613375490.027267
train: epoch 95, iter 2200, loss: 2.312314, top_1: 0.673477, top_k: 0.867305, samples/s: 778.547 1613375522.9089236
train: epoch 95, iter 2300, loss: 2.603981, top_1: 0.668086, top_k: 0.859609, samples/s: 779.558 1613375555.748134
train: epoch 95, iter 2400, loss: 2.470780, top_1: 0.664414, top_k: 0.863633, samples/s: 781.899 1613375588.488911
train: epoch 95, iter 2500, loss: 2.459627, top_1: 0.670312, top_k: 0.863711, samples/s: 780.173 1613375621.302138
train: epoch 95, iter 2600, loss: 2.305162, top_1: 0.664805, top_k: 0.861719, samples/s: 778.430 1613375654.1888723
train: epoch 95, iter 2700, loss: 2.435414, top_1: 0.662227, top_k: 0.861367, samples/s: 782.761 1613375686.893674
train: epoch 95, iter 2800, loss: 2.509113, top_1: 0.661602, top_k: 0.857695, samples/s: 778.884 1613375719.7612603
train: epoch 95, iter 2900, loss: 2.233652, top_1: 0.666445, top_k: 0.861055, samples/s: 780.363 1613375752.5664423
train: epoch 95, iter 3000, loss: 2.471684, top_1: 0.665937, top_k: 0.861680, samples/s: 781.950 1613375785.3051054
train: epoch 95, iter 3100, loss: 2.319679, top_1: 0.669531, top_k: 0.859297, samples/s: 780.204 1613375818.1169848
train: epoch 95, iter 3200, loss: 2.637064, top_1: 0.669492, top_k: 0.858242, samples/s: 780.421 1613375850.9198728
train: epoch 95, iter 3300, loss: 2.333399, top_1: 0.665781, top_k: 0.863633, samples/s: 780.643 1613375883.713296
train: epoch 95, iter 3400, loss: 2.325810, top_1: 0.664336, top_k: 0.862187, samples/s: 779.733 1613375916.5450845
train: epoch 95, iter 3500, loss: 2.314015, top_1: 0.665430, top_k: 0.856680, samples/s: 783.603 1613375949.2147212
train: epoch 95, iter 3600, loss: 2.296219, top_1: 0.664531, top_k: 0.860000, samples/s: 781.628 1613375981.9668353
train: epoch 95, iter 3700, loss: 2.405596, top_1: 0.661914, top_k: 0.860469, samples/s: 780.247 1613376014.7769203
train: epoch 95, iter 3800, loss: 2.356133, top_1: 0.665742, top_k: 0.859180, samples/s: 782.000 1613376047.513608
train: epoch 95, iter 3900, loss: 2.373252, top_1: 0.661328, top_k: 0.860156, samples/s: 778.112 1613376080.413659
train: epoch 95, iter 4000, loss: 2.387635, top_1: 0.666289, top_k: 0.860273, samples/s: 782.807 1613376113.1165106
train: epoch 95, iter 4100, loss: 2.619835, top_1: 0.663242, top_k: 0.860703, samples/s: 778.958 1613376145.9809763
train: epoch 95, iter 4200, loss: 2.377862, top_1: 0.664141, top_k: 0.860000, samples/s: 782.486 1613376178.697172
train: epoch 95, iter 4300, loss: 2.383840, top_1: 0.664766, top_k: 0.859609, samples/s: 778.675 1613376211.573535
train: epoch 95, iter 4400, loss: 2.400102, top_1: 0.660078, top_k: 0.860156, samples/s: 780.619 1613376244.3679924
train: epoch 95, iter 4500, loss: 2.478886, top_1: 0.658242, top_k: 0.859648, samples/s: 779.794 1613376277.1972349
train: epoch 95, iter 4600, loss: 2.342521, top_1: 0.663359, top_k: 0.857891, samples/s: 781.435 1613376309.9574525
train: epoch 95, iter 4700, loss: 2.416825, top_1: 0.660937, top_k: 0.857070, samples/s: 780.588 1613376342.7533977
train: epoch 95, iter 4800, loss: 2.407199, top_1: 0.660625, top_k: 0.856836, samples/s: 781.981 1613376375.490608
train: epoch 95, iter 4900, loss: 2.490426, top_1: 0.658242, top_k: 0.859922, samples/s: 778.523 1613376408.3733954
train: epoch 95, iter 5000, loss: 2.359569, top_1: 0.669219, top_k: 0.866055, samples/s: 781.748 1613376441.1205301
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_95.
validation: epoch 95, iter 195, top_1: 0.702204, top_k: 0.901542, samples/s: 2376.063 1613376463.183055
train: epoch 96, iter 100, loss: 2.228086, top_1: 0.682109, top_k: 0.869766, samples/s: 803.289 1613376520.901932
train: epoch 96, iter 200, loss: 2.153588, top_1: 0.681289, top_k: 0.869727, samples/s: 800.309 1613376552.8897176
train: epoch 96, iter 300, loss: 2.396440, top_1: 0.677930, top_k: 0.868477, samples/s: 786.343 1613376585.4453855
train: epoch 96, iter 400, loss: 2.479966, top_1: 0.674922, top_k: 0.869141, samples/s: 780.055 1613376618.2635071
train: epoch 96, iter 500, loss: 2.509972, top_1: 0.673945, top_k: 0.865391, samples/s: 778.682 1613376651.1396222
train: epoch 96, iter 600, loss: 2.389338, top_1: 0.673555, top_k: 0.863867, samples/s: 776.956 1613376684.0886788
train: epoch 96, iter 700, loss: 2.233184, top_1: 0.669414, top_k: 0.862969, samples/s: 778.909 1613376716.9551015
train: epoch 96, iter 800, loss: 2.381349, top_1: 0.670156, top_k: 0.863203, samples/s: 779.607 1613376749.792104
train: epoch 96, iter 900, loss: 2.371628, top_1: 0.673594, top_k: 0.865391, samples/s: 779.931 1613376782.615613
train: epoch 96, iter 1000, loss: 2.265610, top_1: 0.674648, top_k: 0.868984, samples/s: 779.237 1613376815.4682722
train: epoch 96, iter 1100, loss: 2.412268, top_1: 0.665820, top_k: 0.865469, samples/s: 779.105 1613376848.3264155
train: epoch 96, iter 1200, loss: 2.277376, top_1: 0.674375, top_k: 0.864961, samples/s: 778.740 1613376881.2000697
train: epoch 96, iter 1300, loss: 2.328434, top_1: 0.677031, top_k: 0.870547, samples/s: 779.311 1613376914.0496256
train: epoch 96, iter 1400, loss: 2.408652, top_1: 0.671367, top_k: 0.867539, samples/s: 780.441 1613376946.8516357
train: epoch 96, iter 1500, loss: 2.584188, top_1: 0.674453, top_k: 0.868047, samples/s: 779.101 1613376979.7100232
train: epoch 96, iter 1600, loss: 2.441440, top_1: 0.670703, top_k: 0.863320, samples/s: 779.344 1613377012.55811
train: epoch 96, iter 1700, loss: 2.279310, top_1: 0.668438, top_k: 0.861133, samples/s: 780.420 1613377045.3609998
train: epoch 96, iter 1800, loss: 2.313139, top_1: 0.676641, top_k: 0.865039, samples/s: 777.989 1613377078.2663565
train: epoch 96, iter 1900, loss: 2.263445, top_1: 0.670781, top_k: 0.862031, samples/s: 781.515 1613377111.0232031
train: epoch 96, iter 2000, loss: 2.406868, top_1: 0.667070, top_k: 0.862266, samples/s: 777.664 1613377143.9422684
train: epoch 96, iter 2100, loss: 2.361938, top_1: 0.670898, top_k: 0.862930, samples/s: 778.915 1613377176.8085604
train: epoch 96, iter 2200, loss: 2.473548, top_1: 0.666445, top_k: 0.861172, samples/s: 783.885 1613377209.4663298
train: epoch 96, iter 2300, loss: 2.368295, top_1: 0.668516, top_k: 0.865625, samples/s: 781.642 1613377242.2178771
train: epoch 96, iter 2400, loss: 2.470953, top_1: 0.662305, top_k: 0.859453, samples/s: 779.698 1613377275.05118
train: epoch 96, iter 2500, loss: 2.414388, top_1: 0.663789, top_k: 0.856836, samples/s: 780.386 1613377307.855467
train: epoch 96, iter 2600, loss: 2.437878, top_1: 0.670000, top_k: 0.867812, samples/s: 782.158 1613377340.5854795
train: epoch 96, iter 2700, loss: 2.316224, top_1: 0.668555, top_k: 0.861602, samples/s: 778.803 1613377373.4564507
train: epoch 96, iter 2800, loss: 2.313222, top_1: 0.666953, top_k: 0.861602, samples/s: 779.306 1613377406.3060665
train: epoch 96, iter 2900, loss: 2.316195, top_1: 0.665234, top_k: 0.859805, samples/s: 779.155 1613377439.1621895
train: epoch 96, iter 3000, loss: 2.322789, top_1: 0.665664, top_k: 0.861328, samples/s: 779.534 1613377472.0023549
train: epoch 96, iter 3100, loss: 2.337331, top_1: 0.666328, top_k: 0.861367, samples/s: 781.076 1613377504.7776654
train: epoch 96, iter 3200, loss: 2.326222, top_1: 0.670508, top_k: 0.863008, samples/s: 781.116 1613377537.5513442
train: epoch 96, iter 3300, loss: 2.435676, top_1: 0.667656, top_k: 0.861094, samples/s: 781.214 1613377570.3207982
train: epoch 96, iter 3400, loss: 2.301908, top_1: 0.672539, top_k: 0.862891, samples/s: 782.074 1613377603.054307
train: epoch 96, iter 3500, loss: 2.549776, top_1: 0.665312, top_k: 0.858984, samples/s: 778.842 1613377635.923535
train: epoch 96, iter 3600, loss: 2.188625, top_1: 0.661992, top_k: 0.858047, samples/s: 778.815 1613377668.7940774
train: epoch 96, iter 3700, loss: 2.319525, top_1: 0.666484, top_k: 0.862930, samples/s: 782.570 1613377701.5068066
train: epoch 96, iter 3800, loss: 2.265715, top_1: 0.664102, top_k: 0.863203, samples/s: 779.905 1613377734.3312638
train: epoch 96, iter 3900, loss: 2.338734, top_1: 0.663047, top_k: 0.860469, samples/s: 778.718 1613377767.205818
train: epoch 96, iter 4000, loss: 2.362137, top_1: 0.665703, top_k: 0.862031, samples/s: 781.334 1613377799.970331
train: epoch 96, iter 4100, loss: 2.248433, top_1: 0.664531, top_k: 0.859609, samples/s: 780.554 1613377832.7675457
train: epoch 96, iter 4200, loss: 2.352456, top_1: 0.657773, top_k: 0.856289, samples/s: 780.464 1613377865.5685887
train: epoch 96, iter 4300, loss: 2.552626, top_1: 0.663828, top_k: 0.859414, samples/s: 778.798 1613377898.4397304
train: epoch 96, iter 4400, loss: 2.445077, top_1: 0.666211, top_k: 0.861367, samples/s: 783.391 1613377931.1181097
train: epoch 96, iter 4500, loss: 2.371318, top_1: 0.668125, top_k: 0.860039, samples/s: 780.501 1613377963.9175942
train: epoch 96, iter 4600, loss: 2.336492, top_1: 0.661563, top_k: 0.859375, samples/s: 782.473 1613377996.6344135
train: epoch 96, iter 4700, loss: 2.347154, top_1: 0.665898, top_k: 0.860703, samples/s: 779.766 1613378029.4646912
train: epoch 96, iter 4800, loss: 2.402504, top_1: 0.661914, top_k: 0.860195, samples/s: 780.287 1613378062.2731872
train: epoch 96, iter 4900, loss: 2.621770, top_1: 0.667656, top_k: 0.860234, samples/s: 780.216 1613378095.084593
train: epoch 96, iter 5000, loss: 2.188574, top_1: 0.676289, top_k: 0.863945, samples/s: 780.473 1613378127.885257
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_96.
validation: epoch 96, iter 195, top_1: 0.704127, top_k: 0.901683, samples/s: 2361.773 1613378149.9855416
train: epoch 97, iter 100, loss: 2.302231, top_1: 0.678516, top_k: 0.869766, samples/s: 800.011 1613378202.5262332
train: epoch 97, iter 200, loss: 2.407091, top_1: 0.674297, top_k: 0.865625, samples/s: 799.023 1613378234.5653684
train: epoch 97, iter 300, loss: 2.417786, top_1: 0.670898, top_k: 0.866602, samples/s: 778.690 1613378267.4410067
train: epoch 97, iter 400, loss: 2.346369, top_1: 0.679063, top_k: 0.868437, samples/s: 780.152 1613378300.2551363
train: epoch 97, iter 500, loss: 2.406748, top_1: 0.679805, top_k: 0.868320, samples/s: 780.031 1613378333.0743456
train: epoch 97, iter 600, loss: 2.297191, top_1: 0.679102, top_k: 0.870000, samples/s: 778.501 1613378365.9580011
train: epoch 97, iter 700, loss: 2.249121, top_1: 0.678125, top_k: 0.868984, samples/s: 780.216 1613378398.7694342
train: epoch 97, iter 800, loss: 2.421409, top_1: 0.681875, top_k: 0.870977, samples/s: 779.956 1613378431.591841
train: epoch 97, iter 900, loss: 2.246616, top_1: 0.670039, top_k: 0.866719, samples/s: 780.291 1613378464.3999898
train: epoch 97, iter 1000, loss: 2.348150, top_1: 0.667383, top_k: 0.863398, samples/s: 779.921 1613378497.223826
train: epoch 97, iter 1100, loss: 2.469921, top_1: 0.680625, top_k: 0.870039, samples/s: 781.222 1613378529.993125
train: epoch 97, iter 1200, loss: 2.238974, top_1: 0.678906, top_k: 0.867891, samples/s: 779.129 1613378562.8502421
train: epoch 97, iter 1300, loss: 2.322279, top_1: 0.671445, top_k: 0.862578, samples/s: 784.305 1613378595.4906592
train: epoch 97, iter 1400, loss: 2.456413, top_1: 0.671797, top_k: 0.866289, samples/s: 777.989 1613378628.3959816
train: epoch 97, iter 1500, loss: 2.402374, top_1: 0.671562, top_k: 0.864609, samples/s: 780.985 1613378661.1751282
train: epoch 97, iter 1600, loss: 2.349020, top_1: 0.670547, top_k: 0.862930, samples/s: 782.717 1613378693.8816953
train: epoch 97, iter 1700, loss: 2.164240, top_1: 0.676172, top_k: 0.866094, samples/s: 779.573 1613378726.7201207
train: epoch 97, iter 1800, loss: 2.403716, top_1: 0.677773, top_k: 0.867461, samples/s: 781.579 1613378759.4744546
train: epoch 97, iter 1900, loss: 2.324795, top_1: 0.667188, top_k: 0.862383, samples/s: 781.191 1613378792.2449343
train: epoch 97, iter 2000, loss: 2.419762, top_1: 0.674766, top_k: 0.868672, samples/s: 784.913 1613378824.8602107
train: epoch 97, iter 2100, loss: 2.333680, top_1: 0.675508, top_k: 0.863672, samples/s: 781.735 1613378857.6075437
train: epoch 97, iter 2200, loss: 2.263536, top_1: 0.673984, top_k: 0.867852, samples/s: 778.650 1613378890.485384
train: epoch 97, iter 2300, loss: 2.595095, top_1: 0.671523, top_k: 0.865586, samples/s: 780.356 1613378923.2905116
train: epoch 97, iter 2400, loss: 2.599504, top_1: 0.670820, top_k: 0.864688, samples/s: 783.385 1613378955.9692647
train: epoch 97, iter 2500, loss: 2.291829, top_1: 0.667617, top_k: 0.861953, samples/s: 781.982 1613378988.7065418
train: epoch 97, iter 2600, loss: 2.277449, top_1: 0.668711, top_k: 0.861602, samples/s: 782.387 1613379021.4269881
train: epoch 97, iter 2700, loss: 2.417459, top_1: 0.674766, top_k: 0.864961, samples/s: 782.980 1613379054.1225998
train: epoch 97, iter 2800, loss: 2.549921, top_1: 0.667930, top_k: 0.861797, samples/s: 782.045 1613379086.8573399
train: epoch 97, iter 2900, loss: 2.371782, top_1: 0.667656, top_k: 0.862617, samples/s: 780.019 1613379119.6769586
train: epoch 97, iter 3000, loss: 2.406471, top_1: 0.670898, top_k: 0.865586, samples/s: 783.148 1613379152.3655899
train: epoch 97, iter 3100, loss: 2.470960, top_1: 0.668047, top_k: 0.862617, samples/s: 782.950 1613379185.0624185
train: epoch 97, iter 3200, loss: 2.356023, top_1: 0.666758, top_k: 0.860977, samples/s: 780.394 1613379217.866433
train: epoch 97, iter 3300, loss: 2.240144, top_1: 0.670859, top_k: 0.862812, samples/s: 782.549 1613379250.579994
train: epoch 97, iter 3400, loss: 2.516932, top_1: 0.662891, top_k: 0.863477, samples/s: 779.173 1613379283.4353147
train: epoch 97, iter 3500, loss: 2.405510, top_1: 0.666562, top_k: 0.860586, samples/s: 781.702 1613379316.1844242
train: epoch 97, iter 3600, loss: 2.629436, top_1: 0.668633, top_k: 0.861719, samples/s: 781.161 1613379348.95609
train: epoch 97, iter 3700, loss: 2.424395, top_1: 0.665430, top_k: 0.864492, samples/s: 782.801 1613379381.6597428
train: epoch 97, iter 3800, loss: 2.286261, top_1: 0.668477, top_k: 0.863828, samples/s: 783.418 1613379414.3364697
train: epoch 97, iter 3900, loss: 2.365465, top_1: 0.663320, top_k: 0.861523, samples/s: 779.483 1613379447.1790109
train: epoch 97, iter 4000, loss: 2.224890, top_1: 0.668320, top_k: 0.863164, samples/s: 780.929 1613379479.9602473
train: epoch 97, iter 4100, loss: 2.269012, top_1: 0.665039, top_k: 0.861953, samples/s: 781.511 1613379512.7172627
train: epoch 97, iter 4200, loss: 2.600615, top_1: 0.669570, top_k: 0.863281, samples/s: 781.512 1613379545.4742217
train: epoch 97, iter 4300, loss: 2.259495, top_1: 0.668984, top_k: 0.860000, samples/s: 782.102 1613379578.206641
train: epoch 97, iter 4400, loss: 2.364781, top_1: 0.671055, top_k: 0.862070, samples/s: 781.086 1613379610.981456
train: epoch 97, iter 4500, loss: 2.433457, top_1: 0.663867, top_k: 0.862461, samples/s: 781.184 1613379643.752209
train: epoch 97, iter 4600, loss: 2.440664, top_1: 0.666133, top_k: 0.862383, samples/s: 784.251 1613379676.394846
train: epoch 97, iter 4700, loss: 2.211143, top_1: 0.664453, top_k: 0.861484, samples/s: 783.007 1613379709.0893457
train: epoch 97, iter 4800, loss: 2.484980, top_1: 0.675469, top_k: 0.867500, samples/s: 780.213 1613379741.9008694
train: epoch 97, iter 4900, loss: 2.501477, top_1: 0.667266, top_k: 0.860469, samples/s: 785.182 1613379774.5047517
train: epoch 97, iter 5000, loss: 2.141941, top_1: 0.664883, top_k: 0.863555, samples/s: 781.835 1613379807.2482996
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_97.
validation: epoch 97, iter 195, top_1: 0.707031, top_k: 0.901342, samples/s: 2331.827 1613379829.642085
train: epoch 98, iter 100, loss: 2.600465, top_1: 0.682539, top_k: 0.874883, samples/s: 801.291 1613379883.1900532
train: epoch 98, iter 200, loss: 2.427916, top_1: 0.676445, top_k: 0.871094, samples/s: 802.647 1613379915.084401
train: epoch 98, iter 300, loss: 2.370660, top_1: 0.677422, top_k: 0.867227, samples/s: 781.051 1613379947.8607337
train: epoch 98, iter 400, loss: 2.180954, top_1: 0.684883, top_k: 0.871719, samples/s: 783.379 1613379980.5396988
train: epoch 98, iter 500, loss: 2.339920, top_1: 0.672695, top_k: 0.867188, samples/s: 777.045 1613380013.4849958
train: epoch 98, iter 600, loss: 2.467279, top_1: 0.675156, top_k: 0.870664, samples/s: 782.019 1613380046.220886
train: epoch 98, iter 700, loss: 2.156018, top_1: 0.672539, top_k: 0.867109, samples/s: 780.994 1613380078.999565
train: epoch 98, iter 800, loss: 2.294969, top_1: 0.669727, top_k: 0.864727, samples/s: 781.499 1613380111.757175
train: epoch 98, iter 900, loss: 2.533171, top_1: 0.676758, top_k: 0.870156, samples/s: 782.602 1613380144.4685774
train: epoch 98, iter 1000, loss: 2.205769, top_1: 0.673477, top_k: 0.868086, samples/s: 782.863 1613380177.1690135
train: epoch 98, iter 1100, loss: 2.362058, top_1: 0.673984, top_k: 0.865430, samples/s: 781.264 1613380209.9363878
train: epoch 98, iter 1200, loss: 2.286770, top_1: 0.675547, top_k: 0.869805, samples/s: 782.346 1613380242.658523
train: epoch 98, iter 1300, loss: 2.397989, top_1: 0.677969, top_k: 0.870820, samples/s: 781.855 1613380275.4011936
train: epoch 98, iter 1400, loss: 2.287637, top_1: 0.681914, top_k: 0.871953, samples/s: 781.958 1613380308.1395433
train: epoch 98, iter 1500, loss: 2.228160, top_1: 0.678359, top_k: 0.869258, samples/s: 784.384 1613380340.7770014
train: epoch 98, iter 1600, loss: 2.307648, top_1: 0.669063, top_k: 0.866367, samples/s: 781.496 1613380373.534234
train: epoch 98, iter 1700, loss: 2.330276, top_1: 0.672578, top_k: 0.867969, samples/s: 779.674 1613380406.3684323
train: epoch 98, iter 1800, loss: 2.275184, top_1: 0.669883, top_k: 0.865977, samples/s: 781.626 1613380439.1207798
train: epoch 98, iter 1900, loss: 2.276943, top_1: 0.677734, top_k: 0.870859, samples/s: 782.810 1613380471.8237422
train: epoch 98, iter 2000, loss: 2.397162, top_1: 0.671875, top_k: 0.865977, samples/s: 779.556 1613380504.6625862
train: epoch 98, iter 2100, loss: 2.501818, top_1: 0.673398, top_k: 0.869648, samples/s: 779.812 1613380537.4910326
train: epoch 98, iter 2200, loss: 2.245853, top_1: 0.671406, top_k: 0.865547, samples/s: 782.644 1613380570.200754
train: epoch 98, iter 2300, loss: 2.279065, top_1: 0.672422, top_k: 0.865078, samples/s: 780.235 1613380603.0113254
train: epoch 98, iter 2400, loss: 2.272789, top_1: 0.674805, top_k: 0.866758, samples/s: 781.351 1613380635.7751448
train: epoch 98, iter 2500, loss: 2.316844, top_1: 0.673242, top_k: 0.866914, samples/s: 780.980 1613380668.5544446
train: epoch 98, iter 2600, loss: 2.146307, top_1: 0.672617, top_k: 0.863750, samples/s: 781.417 1613380701.3155284
train: epoch 98, iter 2700, loss: 2.326903, top_1: 0.671719, top_k: 0.865156, samples/s: 780.652 1613380734.1085951
train: epoch 98, iter 2800, loss: 2.701811, top_1: 0.677070, top_k: 0.869883, samples/s: 782.677 1613380766.8167543
train: epoch 98, iter 2900, loss: 2.386340, top_1: 0.670664, top_k: 0.860938, samples/s: 780.058 1613380799.6348372
train: epoch 98, iter 3000, loss: 2.314564, top_1: 0.669492, top_k: 0.862734, samples/s: 781.416 1613380832.3959694
train: epoch 98, iter 3100, loss: 2.349596, top_1: 0.671914, top_k: 0.866406, samples/s: 779.334 1613380865.2445097
train: epoch 98, iter 3200, loss: 2.543075, top_1: 0.671562, top_k: 0.863672, samples/s: 782.413 1613380897.9638186
train: epoch 98, iter 3300, loss: 2.255332, top_1: 0.669648, top_k: 0.863125, samples/s: 782.447 1613380930.681621
train: epoch 98, iter 3400, loss: 2.363873, top_1: 0.673125, top_k: 0.867734, samples/s: 781.037 1613380963.4585187
train: epoch 98, iter 3500, loss: 2.252120, top_1: 0.667227, top_k: 0.862734, samples/s: 779.466 1613380996.3015969
train: epoch 98, iter 3600, loss: 2.313777, top_1: 0.671094, top_k: 0.865898, samples/s: 783.474 1613381028.9764948
train: epoch 98, iter 3700, loss: 2.362333, top_1: 0.671172, top_k: 0.866367, samples/s: 779.615 1613381061.8132796
train: epoch 98, iter 3800, loss: 2.173462, top_1: 0.667773, top_k: 0.863750, samples/s: 782.900 1613381094.512241
train: epoch 98, iter 3900, loss: 2.421453, top_1: 0.668672, top_k: 0.864141, samples/s: 782.434 1613381127.2306354
train: epoch 98, iter 4000, loss: 2.188539, top_1: 0.666406, top_k: 0.866367, samples/s: 778.862 1613381160.0991507
train: epoch 98, iter 4100, loss: 2.317645, top_1: 0.676133, top_k: 0.864414, samples/s: 781.383 1613381192.861584
train: epoch 98, iter 4200, loss: 2.368645, top_1: 0.667539, top_k: 0.864414, samples/s: 782.221 1613381225.588843
train: epoch 98, iter 4300, loss: 2.319778, top_1: 0.677656, top_k: 0.865391, samples/s: 782.030 1613381258.3241172
train: epoch 98, iter 4400, loss: 2.448758, top_1: 0.667930, top_k: 0.865664, samples/s: 779.955 1613381291.1465442
train: epoch 98, iter 4500, loss: 2.234677, top_1: 0.670078, top_k: 0.865117, samples/s: 784.223 1613381323.7903662
train: epoch 98, iter 4600, loss: 2.516417, top_1: 0.670078, top_k: 0.867148, samples/s: 779.483 1613381356.6326776
train: epoch 98, iter 4700, loss: 2.355610, top_1: 0.668711, top_k: 0.866211, samples/s: 781.548 1613381389.3882174
train: epoch 98, iter 4800, loss: 2.209832, top_1: 0.664961, top_k: 0.860977, samples/s: 781.716 1613381422.1366212
train: epoch 98, iter 4900, loss: 2.391563, top_1: 0.668125, top_k: 0.864453, samples/s: 781.417 1613381454.897649
train: epoch 98, iter 5000, loss: 2.135555, top_1: 0.677930, top_k: 0.867500, samples/s: 778.954 1613381487.7622652
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_98.
validation: epoch 98, iter 195, top_1: 0.706891, top_k: 0.902003, samples/s: 2358.690 1613381509.890531
train: epoch 99, iter 100, loss: 2.319283, top_1: 0.687852, top_k: 0.875039, samples/s: 804.265 1613381562.4582477
train: epoch 99, iter 200, loss: 2.424352, top_1: 0.684844, top_k: 0.872500, samples/s: 798.041 1613381594.5366886
train: epoch 99, iter 300, loss: 2.252554, top_1: 0.688320, top_k: 0.874648, samples/s: 781.368 1613381627.299701
train: epoch 99, iter 400, loss: 2.336171, top_1: 0.681445, top_k: 0.871367, samples/s: 778.285 1613381660.1927333
train: epoch 99, iter 500, loss: 2.222818, top_1: 0.674687, top_k: 0.866641, samples/s: 777.571 1613381693.1155899
train: epoch 99, iter 600, loss: 2.237558, top_1: 0.679336, top_k: 0.869648, samples/s: 778.995 1613381725.978497
train: epoch 99, iter 700, loss: 2.322804, top_1: 0.681953, top_k: 0.872109, samples/s: 781.972 1613381758.7162352
train: epoch 99, iter 800, loss: 2.321908, top_1: 0.678477, top_k: 0.868750, samples/s: 777.709 1613381791.6334825
train: epoch 99, iter 900, loss: 2.379092, top_1: 0.678477, top_k: 0.872070, samples/s: 782.572 1613381824.3461428
train: epoch 99, iter 1000, loss: 2.286015, top_1: 0.678516, top_k: 0.867734, samples/s: 779.040 1613381857.2069776
train: epoch 99, iter 1100, loss: 2.313670, top_1: 0.683672, top_k: 0.871016, samples/s: 779.152 1613381890.0633082
train: epoch 99, iter 1200, loss: 2.530961, top_1: 0.678047, top_k: 0.867969, samples/s: 779.571 1613381922.901825
train: epoch 99, iter 1300, loss: 2.283647, top_1: 0.681406, top_k: 0.869531, samples/s: 780.036 1613381955.7209227
train: epoch 99, iter 1400, loss: 2.476388, top_1: 0.679258, top_k: 0.869570, samples/s: 780.487 1613381988.5209646
train: epoch 99, iter 1500, loss: 2.192426, top_1: 0.674883, top_k: 0.868281, samples/s: 778.328 1613382021.411965
train: epoch 99, iter 1600, loss: 2.329953, top_1: 0.673633, top_k: 0.866172, samples/s: 781.088 1613382054.1866827
train: epoch 99, iter 1700, loss: 2.261985, top_1: 0.673281, top_k: 0.864648, samples/s: 778.737 1613382087.0604446
train: epoch 99, iter 1800, loss: 2.152265, top_1: 0.672344, top_k: 0.866133, samples/s: 783.644 1613382119.7283735
train: epoch 99, iter 1900, loss: 2.345680, top_1: 0.676445, top_k: 0.868164, samples/s: 781.484 1613382152.4865742
train: epoch 99, iter 2000, loss: 2.331871, top_1: 0.671523, top_k: 0.865234, samples/s: 777.994 1613382185.3916292
train: epoch 99, iter 2100, loss: 2.338751, top_1: 0.679180, top_k: 0.868906, samples/s: 779.979 1613382218.2129917
train: epoch 99, iter 2200, loss: 2.322165, top_1: 0.669883, top_k: 0.865117, samples/s: 781.500 1613382250.970584
train: epoch 99, iter 2300, loss: 2.239061, top_1: 0.678359, top_k: 0.868281, samples/s: 782.255 1613382283.696488
train: epoch 99, iter 2400, loss: 2.389263, top_1: 0.678359, top_k: 0.867305, samples/s: 780.031 1613382316.515631
train: epoch 99, iter 2500, loss: 2.461410, top_1: 0.673711, top_k: 0.867383, samples/s: 781.110 1613382349.289544
train: epoch 99, iter 2600, loss: 2.452456, top_1: 0.672773, top_k: 0.869844, samples/s: 780.090 1613382382.1063154
train: epoch 99, iter 2700, loss: 2.427042, top_1: 0.675195, top_k: 0.867148, samples/s: 784.627 1613382414.733317
train: epoch 99, iter 2800, loss: 2.319705, top_1: 0.674687, top_k: 0.866211, samples/s: 780.501 1613382447.532768
train: epoch 99, iter 2900, loss: 2.308825, top_1: 0.676484, top_k: 0.866641, samples/s: 782.331 1613382480.255543
train: epoch 99, iter 3000, loss: 2.213184, top_1: 0.669336, top_k: 0.866055, samples/s: 782.012 1613382512.9915438
train: epoch 99, iter 3100, loss: 2.362428, top_1: 0.670312, top_k: 0.865039, samples/s: 779.345 1613382545.8395894
train: epoch 99, iter 3200, loss: 2.360945, top_1: 0.671094, top_k: 0.864766, samples/s: 780.155 1613382578.6536238
train: epoch 99, iter 3300, loss: 2.252218, top_1: 0.676523, top_k: 0.866914, samples/s: 783.450 1613382611.3295412
train: epoch 99, iter 3400, loss: 2.075185, top_1: 0.671211, top_k: 0.864414, samples/s: 780.392 1613382644.1335387
train: epoch 99, iter 3500, loss: 2.169900, top_1: 0.665039, top_k: 0.860430, samples/s: 779.787 1613382676.9630594
train: epoch 99, iter 3600, loss: 2.391512, top_1: 0.669570, top_k: 0.863203, samples/s: 782.930 1613382709.6607947
train: epoch 99, iter 3700, loss: 2.246326, top_1: 0.676758, top_k: 0.866875, samples/s: 782.876 1613382742.3608406
train: epoch 99, iter 3800, loss: 2.180463, top_1: 0.674570, top_k: 0.865508, samples/s: 779.565 1613382775.1995392
train: epoch 99, iter 3900, loss: 2.284578, top_1: 0.667070, top_k: 0.863789, samples/s: 781.498 1613382807.9570718
train: epoch 99, iter 4000, loss: 2.418959, top_1: 0.671445, top_k: 0.868516, samples/s: 780.552 1613382840.7544284
train: epoch 99, iter 4100, loss: 2.169766, top_1: 0.672734, top_k: 0.865391, samples/s: 780.063 1613382873.5723271
train: epoch 99, iter 4200, loss: 2.452496, top_1: 0.672500, top_k: 0.864883, samples/s: 780.164 1613382906.38591
train: epoch 99, iter 4300, loss: 2.198850, top_1: 0.668633, top_k: 0.862461, samples/s: 782.123 1613382939.1172283
train: epoch 99, iter 4400, loss: 2.409687, top_1: 0.673477, top_k: 0.865938, samples/s: 782.930 1613382971.815009
train: epoch 99, iter 4500, loss: 2.515301, top_1: 0.669766, top_k: 0.867266, samples/s: 777.865 1613383004.7255406
train: epoch 99, iter 4600, loss: 2.391640, top_1: 0.672813, top_k: 0.862734, samples/s: 781.047 1613383037.5020921
train: epoch 99, iter 4700, loss: 2.322487, top_1: 0.671367, top_k: 0.862734, samples/s: 779.127 1613383070.3594708
train: epoch 99, iter 4800, loss: 2.428704, top_1: 0.675391, top_k: 0.867812, samples/s: 782.063 1613383103.093323
train: epoch 99, iter 4900, loss: 2.304056, top_1: 0.671484, top_k: 0.865117, samples/s: 782.565 1613383135.8062508
train: epoch 99, iter 5000, loss: 2.250156, top_1: 0.678125, top_k: 0.870117, samples/s: 780.922 1613383168.588061
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_99.
validation: epoch 99, iter 195, top_1: 0.708413, top_k: 0.903906, samples/s: 2355.909 1613383190.774772
train: epoch 100, iter 100, loss: 2.261809, top_1: 0.682227, top_k: 0.870078, samples/s: 802.464 1613383243.099221
train: epoch 100, iter 200, loss: 2.319950, top_1: 0.681406, top_k: 0.876563, samples/s: 799.323 1613383275.1263974
train: epoch 100, iter 300, loss: 2.075666, top_1: 0.686914, top_k: 0.875156, samples/s: 781.479 1613383307.8847446
train: epoch 100, iter 400, loss: 2.276678, top_1: 0.680820, top_k: 0.870273, samples/s: 780.011 1613383340.7050376
train: epoch 100, iter 500, loss: 2.199373, top_1: 0.683984, top_k: 0.872734, samples/s: 779.786 1613383373.5342808
train: epoch 100, iter 600, loss: 2.243447, top_1: 0.685156, top_k: 0.872539, samples/s: 780.230 1613383406.3451145
train: epoch 100, iter 700, loss: 2.262938, top_1: 0.686523, top_k: 0.874375, samples/s: 779.679 1613383439.179222
train: epoch 100, iter 800, loss: 2.292304, top_1: 0.688594, top_k: 0.874141, samples/s: 783.167 1613383471.8669603
train: epoch 100, iter 900, loss: 2.285001, top_1: 0.678125, top_k: 0.866680, samples/s: 776.417 1613383504.8390338
train: epoch 100, iter 1000, loss: 2.388569, top_1: 0.683477, top_k: 0.872656, samples/s: 780.892 1613383537.6220434
train: epoch 100, iter 1100, loss: 2.321441, top_1: 0.684883, top_k: 0.872695, samples/s: 778.369 1613383570.5112658
train: epoch 100, iter 1200, loss: 2.419760, top_1: 0.674727, top_k: 0.866602, samples/s: 784.085 1613383603.1608157
train: epoch 100, iter 1300, loss: 2.242239, top_1: 0.679727, top_k: 0.870469, samples/s: 781.689 1613383635.910428
train: epoch 100, iter 1400, loss: 2.359267, top_1: 0.683789, top_k: 0.871563, samples/s: 779.538 1613383668.750393
train: epoch 100, iter 1500, loss: 2.166137, top_1: 0.674219, top_k: 0.868828, samples/s: 781.407 1613383701.511807
train: epoch 100, iter 1600, loss: 2.253297, top_1: 0.685391, top_k: 0.875469, samples/s: 781.180 1613383734.2826385
train: epoch 100, iter 1700, loss: 2.497441, top_1: 0.679102, top_k: 0.868789, samples/s: 779.470 1613383767.1255777
train: epoch 100, iter 1800, loss: 2.310596, top_1: 0.678633, top_k: 0.868828, samples/s: 780.776 1613383799.9133801
train: epoch 100, iter 1900, loss: 2.357228, top_1: 0.682461, top_k: 0.872891, samples/s: 782.599 1613383832.6249104
train: epoch 100, iter 2000, loss: 2.185761, top_1: 0.682852, top_k: 0.868086, samples/s: 780.554 1613383865.4221547
train: epoch 100, iter 2100, loss: 2.337729, top_1: 0.675898, top_k: 0.867344, samples/s: 780.001 1613383898.2426772
train: epoch 100, iter 2200, loss: 2.334294, top_1: 0.675977, top_k: 0.868906, samples/s: 783.232 1613383930.9277298
train: epoch 100, iter 2300, loss: 2.334621, top_1: 0.672813, top_k: 0.867930, samples/s: 781.303 1613383963.6934745
train: epoch 100, iter 2400, loss: 2.361963, top_1: 0.683633, top_k: 0.870703, samples/s: 780.405 1613383996.497002
train: epoch 100, iter 2500, loss: 2.424121, top_1: 0.678672, top_k: 0.871602, samples/s: 781.320 1613384029.2619598
train: epoch 100, iter 2600, loss: 2.334583, top_1: 0.680469, top_k: 0.872031, samples/s: 781.598 1613384062.015403
train: epoch 100, iter 2700, loss: 2.456757, top_1: 0.677344, top_k: 0.867773, samples/s: 782.180 1613384094.7444649
train: epoch 100, iter 2800, loss: 2.399630, top_1: 0.671328, top_k: 0.863359, samples/s: 783.313 1613384127.4261315
train: epoch 100, iter 2900, loss: 2.365431, top_1: 0.673164, top_k: 0.866211, samples/s: 780.851 1613384160.2109883
train: epoch 100, iter 3000, loss: 2.235692, top_1: 0.680547, top_k: 0.868281, samples/s: 781.936 1613384192.9502397
train: epoch 100, iter 3100, loss: 2.274162, top_1: 0.671367, top_k: 0.863906, samples/s: 783.503 1613384225.6239839
train: epoch 100, iter 3200, loss: 2.252471, top_1: 0.676211, top_k: 0.869727, samples/s: 781.591 1613384258.3776047
train: epoch 100, iter 3300, loss: 2.410230, top_1: 0.674023, top_k: 0.865234, samples/s: 782.981 1613384291.073264
train: epoch 100, iter 3400, loss: 2.217518, top_1: 0.674648, top_k: 0.868047, samples/s: 782.369 1613384323.7944033
train: epoch 100, iter 3500, loss: 2.319507, top_1: 0.680430, top_k: 0.870352, samples/s: 782.003 1613384356.5308459
train: epoch 100, iter 3600, loss: 2.424175, top_1: 0.678984, top_k: 0.869141, samples/s: 784.232 1613384389.1742377
train: epoch 100, iter 3700, loss: 2.456402, top_1: 0.676914, top_k: 0.871055, samples/s: 779.276 1613384422.0251987
train: epoch 100, iter 3800, loss: 2.306504, top_1: 0.676641, top_k: 0.864453, samples/s: 781.777 1613384454.771129
train: epoch 100, iter 3900, loss: 2.688967, top_1: 0.673086, top_k: 0.866953, samples/s: 783.191 1613384487.4579413
train: epoch 100, iter 4000, loss: 2.305434, top_1: 0.674687, top_k: 0.870469, samples/s: 780.505 1613384520.2572737
train: epoch 100, iter 4100, loss: 2.409039, top_1: 0.673828, top_k: 0.872266, samples/s: 780.555 1613384553.054372
train: epoch 100, iter 4200, loss: 2.375850, top_1: 0.673594, top_k: 0.868320, samples/s: 782.758 1613384585.759303
train: epoch 100, iter 4300, loss: 2.184034, top_1: 0.677188, top_k: 0.866133, samples/s: 781.260 1613384618.526802
train: epoch 100, iter 4400, loss: 2.321715, top_1: 0.673828, top_k: 0.867383, samples/s: 784.194 1613384651.1718113
train: epoch 100, iter 4500, loss: 2.350875, top_1: 0.671289, top_k: 0.865625, samples/s: 779.986 1613384683.9929183
train: epoch 100, iter 4600, loss: 2.296789, top_1: 0.671406, top_k: 0.864453, samples/s: 781.532 1613384716.7491312
train: epoch 100, iter 4700, loss: 2.296889, top_1: 0.673477, top_k: 0.865859, samples/s: 783.730 1613384749.4134436
train: epoch 100, iter 4800, loss: 2.202083, top_1: 0.669805, top_k: 0.863125, samples/s: 780.474 1613384782.2139971
train: epoch 100, iter 4900, loss: 2.330158, top_1: 0.671055, top_k: 0.862656, samples/s: 781.074 1613384814.9893973
train: epoch 100, iter 5000, loss: 2.358145, top_1: 0.676992, top_k: 0.870938, samples/s: 780.720 1613384847.7795606
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_100.
validation: epoch 100, iter 195, top_1: 0.706931, top_k: 0.901783, samples/s: 2372.615 1613384869.8137462
train: epoch 101, iter 100, loss: 2.274347, top_1: 0.693555, top_k: 0.879023, samples/s: 804.015 1613384922.0218108
train: epoch 101, iter 200, loss: 2.028894, top_1: 0.691719, top_k: 0.877812, samples/s: 800.224 1613384954.0129828
train: epoch 101, iter 300, loss: 2.290434, top_1: 0.684063, top_k: 0.873477, samples/s: 780.345 1613384986.818801
train: epoch 101, iter 400, loss: 2.177512, top_1: 0.682461, top_k: 0.873359, samples/s: 781.481 1613385019.5770977
train: epoch 101, iter 500, loss: 2.180398, top_1: 0.684102, top_k: 0.871445, samples/s: 779.737 1613385052.4086518
train: epoch 101, iter 600, loss: 2.265210, top_1: 0.684336, top_k: 0.874219, samples/s: 781.600 1613385085.162055
train: epoch 101, iter 700, loss: 2.426371, top_1: 0.681406, top_k: 0.870039, samples/s: 779.954 1613385117.9844956
train: epoch 101, iter 800, loss: 2.289730, top_1: 0.682969, top_k: 0.871523, samples/s: 778.870 1613385150.8525758
train: epoch 101, iter 900, loss: 2.352616, top_1: 0.681602, top_k: 0.868750, samples/s: 780.500 1613385183.6520097
train: epoch 101, iter 1000, loss: 2.451648, top_1: 0.679688, top_k: 0.876016, samples/s: 780.939 1613385216.4331117
train: epoch 101, iter 1100, loss: 2.351987, top_1: 0.684531, top_k: 0.871641, samples/s: 779.662 1613385249.267836
train: epoch 101, iter 1200, loss: 2.157005, top_1: 0.680508, top_k: 0.869844, samples/s: 784.959 1613385281.8810515
train: epoch 101, iter 1300, loss: 2.406657, top_1: 0.679141, top_k: 0.872422, samples/s: 782.449 1613385314.5988712
train: epoch 101, iter 1400, loss: 2.540782, top_1: 0.684258, top_k: 0.873516, samples/s: 779.910 1613385347.4230938
train: epoch 101, iter 1500, loss: 2.317500, top_1: 0.681094, top_k: 0.870703, samples/s: 781.823 1613385380.1671507
train: epoch 101, iter 1600, loss: 2.264855, top_1: 0.680156, top_k: 0.871875, samples/s: 782.478 1613385412.8836503
train: epoch 101, iter 1700, loss: 2.330832, top_1: 0.681367, top_k: 0.869766, samples/s: 781.234 1613385445.652387
train: epoch 101, iter 1800, loss: 2.395510, top_1: 0.676445, top_k: 0.870977, samples/s: 781.940 1613385478.3915126
train: epoch 101, iter 1900, loss: 2.203563, top_1: 0.682109, top_k: 0.873828, samples/s: 783.986 1613385511.0450504
train: epoch 101, iter 2000, loss: 2.396397, top_1: 0.680977, top_k: 0.875039, samples/s: 778.007 1613385543.9496717
train: epoch 101, iter 2100, loss: 2.414577, top_1: 0.671016, top_k: 0.864375, samples/s: 778.522 1613385576.8324237
train: epoch 101, iter 2200, loss: 2.363122, top_1: 0.679258, top_k: 0.868594, samples/s: 779.223 1613385609.6857426
train: epoch 101, iter 2300, loss: 2.363749, top_1: 0.683047, top_k: 0.874141, samples/s: 784.651 1613385642.3117182
train: epoch 101, iter 2400, loss: 2.336533, top_1: 0.683047, top_k: 0.869531, samples/s: 779.675 1613385675.1458328
train: epoch 101, iter 2500, loss: 2.324824, top_1: 0.679063, top_k: 0.868008, samples/s: 781.453 1613385707.9054546
train: epoch 101, iter 2600, loss: 2.334229, top_1: 0.678164, top_k: 0.868555, samples/s: 784.215 1613385740.5495331
train: epoch 101, iter 2700, loss: 2.282701, top_1: 0.673945, top_k: 0.865313, samples/s: 779.152 1613385773.4057455
train: epoch 101, iter 2800, loss: 2.503189, top_1: 0.686719, top_k: 0.872461, samples/s: 781.598 1613385806.1590853
train: epoch 101, iter 2900, loss: 2.458344, top_1: 0.677227, top_k: 0.870156, samples/s: 784.349 1613385838.7976284
train: epoch 101, iter 3000, loss: 2.335250, top_1: 0.679648, top_k: 0.868906, samples/s: 780.091 1613385871.6143377
train: epoch 101, iter 3100, loss: 2.265975, top_1: 0.678281, top_k: 0.866523, samples/s: 780.266 1613385904.4236274
train: epoch 101, iter 3200, loss: 2.279820, top_1: 0.678281, top_k: 0.868164, samples/s: 782.857 1613385937.1244793
train: epoch 101, iter 3300, loss: 2.264831, top_1: 0.676055, top_k: 0.867422, samples/s: 781.597 1613385969.8779476
train: epoch 101, iter 3400, loss: 2.179589, top_1: 0.676797, top_k: 0.865781, samples/s: 782.012 1613386002.613932
train: epoch 101, iter 3500, loss: 2.428983, top_1: 0.686602, top_k: 0.873906, samples/s: 781.961 1613386035.3522267
train: epoch 101, iter 3600, loss: 2.234966, top_1: 0.674570, top_k: 0.870625, samples/s: 783.108 1613386068.0424774
train: epoch 101, iter 3700, loss: 2.248734, top_1: 0.681523, top_k: 0.870117, samples/s: 782.214 1613386100.7700293
train: epoch 101, iter 3800, loss: 2.244420, top_1: 0.678047, top_k: 0.870742, samples/s: 781.526 1613386133.526526
train: epoch 101, iter 3900, loss: 2.413789, top_1: 0.675117, top_k: 0.866484, samples/s: 781.845 1613386166.2695982
train: epoch 101, iter 4000, loss: 2.376961, top_1: 0.677656, top_k: 0.868945, samples/s: 782.216 1613386198.9971611
train: epoch 101, iter 4100, loss: 2.258406, top_1: 0.677109, top_k: 0.867539, samples/s: 783.160 1613386231.6852052
train: epoch 101, iter 4200, loss: 2.189660, top_1: 0.678867, top_k: 0.867188, samples/s: 780.770 1613386264.473414
train: epoch 101, iter 4300, loss: 2.284824, top_1: 0.679531, top_k: 0.872695, samples/s: 782.702 1613386297.1805673
train: epoch 101, iter 4400, loss: 2.297704, top_1: 0.676641, top_k: 0.870313, samples/s: 781.742 1613386329.9279613
train: epoch 101, iter 4500, loss: 2.216707, top_1: 0.677422, top_k: 0.870742, samples/s: 782.302 1613386362.6519127
train: epoch 101, iter 4600, loss: 2.329298, top_1: 0.676875, top_k: 0.869766, samples/s: 783.801 1613386395.3132036
train: epoch 101, iter 4700, loss: 2.465529, top_1: 0.675742, top_k: 0.871445, samples/s: 781.182 1613386428.0841367
train: epoch 101, iter 4800, loss: 2.236046, top_1: 0.670781, top_k: 0.865000, samples/s: 784.228 1613386460.7275856
train: epoch 101, iter 4900, loss: 2.388115, top_1: 0.680625, top_k: 0.870742, samples/s: 783.770 1613386493.3902261
train: epoch 101, iter 5000, loss: 2.269869, top_1: 0.682813, top_k: 0.871914, samples/s: 780.954 1613386526.1707385
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_101.
validation: epoch 101, iter 195, top_1: 0.708433, top_k: 0.904868, samples/s: 2341.686 1613386548.452142
train: epoch 102, iter 100, loss: 2.407404, top_1: 0.686875, top_k: 0.875234, samples/s: 802.787 1613386601.2084422
train: epoch 102, iter 200, loss: 2.126452, top_1: 0.690234, top_k: 0.877148, samples/s: 799.964 1613386633.2099085
train: epoch 102, iter 300, loss: 2.269751, top_1: 0.692930, top_k: 0.875117, samples/s: 784.666 1613386665.8352065
train: epoch 102, iter 400, loss: 2.307631, top_1: 0.692734, top_k: 0.877656, samples/s: 778.643 1613386698.7129283
train: epoch 102, iter 500, loss: 2.348831, top_1: 0.683633, top_k: 0.873047, samples/s: 780.218 1613386731.5241938
train: epoch 102, iter 600, loss: 2.181501, top_1: 0.683672, top_k: 0.875977, samples/s: 779.456 1613386764.3676646
train: epoch 102, iter 700, loss: 2.287137, top_1: 0.695977, top_k: 0.878945, samples/s: 782.222 1613386797.0948737
train: epoch 102, iter 800, loss: 2.242645, top_1: 0.687734, top_k: 0.875313, samples/s: 779.655 1613386829.930058
train: epoch 102, iter 900, loss: 2.292002, top_1: 0.690039, top_k: 0.876445, samples/s: 780.315 1613386862.7373178
train: epoch 102, iter 1000, loss: 2.244948, top_1: 0.681094, top_k: 0.871523, samples/s: 781.349 1613386895.501107
train: epoch 102, iter 1100, loss: 2.281258, top_1: 0.684023, top_k: 0.874727, samples/s: 781.526 1613386928.2575843
train: epoch 102, iter 1200, loss: 2.278068, top_1: 0.681406, top_k: 0.873555, samples/s: 781.619 1613386961.0101101
train: epoch 102, iter 1300, loss: 2.232545, top_1: 0.687344, top_k: 0.874023, samples/s: 783.388 1613386993.6885502
train: epoch 102, iter 1400, loss: 2.327932, top_1: 0.686367, top_k: 0.875117, samples/s: 782.254 1613387026.4145668
train: epoch 102, iter 1500, loss: 2.117306, top_1: 0.687695, top_k: 0.873945, samples/s: 783.841 1613387059.0742962
train: epoch 102, iter 1600, loss: 2.216516, top_1: 0.683828, top_k: 0.873516, samples/s: 782.577 1613387091.7866375
train: epoch 102, iter 1700, loss: 2.357544, top_1: 0.679414, top_k: 0.870508, samples/s: 781.921 1613387124.5265865
train: epoch 102, iter 1800, loss: 2.333131, top_1: 0.679453, top_k: 0.870391, samples/s: 783.355 1613387157.2065408
train: epoch 102, iter 1900, loss: 2.221975, top_1: 0.683672, top_k: 0.876055, samples/s: 781.180 1613387189.9774585
train: epoch 102, iter 2000, loss: 2.255323, top_1: 0.682070, top_k: 0.871563, samples/s: 782.843 1613387222.678814
train: epoch 102, iter 2100, loss: 2.417206, top_1: 0.679648, top_k: 0.870586, samples/s: 781.896 1613387255.4197154
train: epoch 102, iter 2200, loss: 2.199357, top_1: 0.683164, top_k: 0.873906, samples/s: 782.256 1613387288.1456354
train: epoch 102, iter 2300, loss: 2.464806, top_1: 0.679219, top_k: 0.870664, samples/s: 782.204 1613387320.873668
train: epoch 102, iter 2400, loss: 2.156012, top_1: 0.683945, top_k: 0.872422, samples/s: 779.486 1613387353.7157538
train: epoch 102, iter 2500, loss: 2.286353, top_1: 0.682344, top_k: 0.869492, samples/s: 782.180 1613387386.4448187
train: epoch 102, iter 2600, loss: 2.236686, top_1: 0.679844, top_k: 0.869102, samples/s: 781.462 1613387419.2039514
train: epoch 102, iter 2700, loss: 2.185367, top_1: 0.688125, top_k: 0.873945, samples/s: 785.515 1613387451.794041
train: epoch 102, iter 2800, loss: 2.411699, top_1: 0.683672, top_k: 0.873828, samples/s: 779.984 1613387484.6152334
train: epoch 102, iter 2900, loss: 2.225178, top_1: 0.684102, top_k: 0.870898, samples/s: 781.099 1613387517.3894935
train: epoch 102, iter 3000, loss: 2.077459, top_1: 0.673086, top_k: 0.867500, samples/s: 782.630 1613387550.0997362
train: epoch 102, iter 3100, loss: 2.286870, top_1: 0.679102, top_k: 0.869570, samples/s: 782.734 1613387582.8055503
train: epoch 102, iter 3200, loss: 2.299933, top_1: 0.684844, top_k: 0.872383, samples/s: 781.942 1613387615.544643
train: epoch 102, iter 3300, loss: 2.441013, top_1: 0.678789, top_k: 0.870898, samples/s: 780.565 1613387648.3414133
train: epoch 102, iter 3400, loss: 2.262403, top_1: 0.683477, top_k: 0.869414, samples/s: 780.406 1613387681.1448293
train: epoch 102, iter 3500, loss: 2.378036, top_1: 0.679609, top_k: 0.872852, samples/s: 783.888 1613387713.802456
train: epoch 102, iter 3600, loss: 2.406431, top_1: 0.680000, top_k: 0.872266, samples/s: 781.312 1613387746.5678394
train: epoch 102, iter 3700, loss: 2.306901, top_1: 0.675039, top_k: 0.867617, samples/s: 782.620 1613387779.2785091
train: epoch 102, iter 3800, loss: 2.436993, top_1: 0.679766, top_k: 0.869180, samples/s: 782.304 1613387812.00244
train: epoch 102, iter 3900, loss: 2.197927, top_1: 0.675586, top_k: 0.866797, samples/s: 782.379 1613387844.7232053
train: epoch 102, iter 4000, loss: 2.369868, top_1: 0.677969, top_k: 0.869219, samples/s: 781.504 1613387877.4804444
train: epoch 102, iter 4100, loss: 2.486820, top_1: 0.680937, top_k: 0.869922, samples/s: 780.439 1613387910.282479
train: epoch 102, iter 4200, loss: 2.276801, top_1: 0.678125, top_k: 0.868125, samples/s: 781.001 1613387943.060911
train: epoch 102, iter 4300, loss: 2.390049, top_1: 0.680664, top_k: 0.870508, samples/s: 780.842 1613387975.8461156
train: epoch 102, iter 4400, loss: 2.318879, top_1: 0.679492, top_k: 0.869375, samples/s: 781.726 1613388008.5941372
train: epoch 102, iter 4500, loss: 2.461191, top_1: 0.678750, top_k: 0.869062, samples/s: 783.133 1613388041.283382
train: epoch 102, iter 4600, loss: 2.492249, top_1: 0.677500, top_k: 0.869805, samples/s: 779.443 1613388074.1272993
train: epoch 102, iter 4700, loss: 2.118878, top_1: 0.674766, top_k: 0.869102, samples/s: 781.816 1613388106.8715148
train: epoch 102, iter 4800, loss: 2.274944, top_1: 0.679453, top_k: 0.872734, samples/s: 780.402 1613388139.675136
train: epoch 102, iter 4900, loss: 2.313295, top_1: 0.675312, top_k: 0.869844, samples/s: 781.142 1613388172.447777
train: epoch 102, iter 5000, loss: 2.088110, top_1: 0.681094, top_k: 0.876367, samples/s: 780.176 1613388205.260896
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_102.
validation: epoch 102, iter 195, top_1: 0.717548, top_k: 0.906711, samples/s: 2346.003 1613388227.512308
train: epoch 103, iter 100, loss: 2.292505, top_1: 0.685742, top_k: 0.875898, samples/s: 804.862 1613388279.6737614
train: epoch 103, iter 200, loss: 2.253487, top_1: 0.688477, top_k: 0.877773, samples/s: 798.221 1613388311.745195
train: epoch 103, iter 300, loss: 2.206017, top_1: 0.688477, top_k: 0.872109, samples/s: 783.392 1613388344.423388
train: epoch 103, iter 400, loss: 2.196615, top_1: 0.702031, top_k: 0.884023, samples/s: 779.334 1613388377.2719555
train: epoch 103, iter 500, loss: 2.319094, top_1: 0.694063, top_k: 0.879180, samples/s: 781.365 1613388410.0351892
train: epoch 103, iter 600, loss: 2.356849, top_1: 0.688398, top_k: 0.874492, samples/s: 779.842 1613388442.8623657
train: epoch 103, iter 700, loss: 2.303042, top_1: 0.688242, top_k: 0.878320, samples/s: 781.288 1613388475.6286535
train: epoch 103, iter 800, loss: 2.227515, top_1: 0.688203, top_k: 0.874727, samples/s: 779.621 1613388508.4652355
train: epoch 103, iter 900, loss: 2.225469, top_1: 0.690586, top_k: 0.875000, samples/s: 780.564 1613388541.2620392
train: epoch 103, iter 1000, loss: 2.459632, top_1: 0.690195, top_k: 0.873711, samples/s: 780.594 1613388574.057625
train: epoch 103, iter 1100, loss: 2.387995, top_1: 0.690469, top_k: 0.880273, samples/s: 781.840 1613388606.8008547
train: epoch 103, iter 1200, loss: 2.211390, top_1: 0.688906, top_k: 0.873477, samples/s: 782.568 1613388639.513607
train: epoch 103, iter 1300, loss: 2.359951, top_1: 0.684609, top_k: 0.871523, samples/s: 779.618 1613388672.350201
train: epoch 103, iter 1400, loss: 2.176831, top_1: 0.687969, top_k: 0.876953, samples/s: 782.021 1613388705.0858686
train: epoch 103, iter 1500, loss: 2.270906, top_1: 0.693086, top_k: 0.879805, samples/s: 781.970 1613388737.823689
train: epoch 103, iter 1600, loss: 2.362515, top_1: 0.683164, top_k: 0.875508, samples/s: 777.915 1613388770.7322621
train: epoch 103, iter 1700, loss: 2.128887, top_1: 0.686641, top_k: 0.877109, samples/s: 782.233 1613388803.4589875
train: epoch 103, iter 1800, loss: 2.336533, top_1: 0.684180, top_k: 0.876602, samples/s: 778.847 1613388836.3280168
train: epoch 103, iter 1900, loss: 2.350036, top_1: 0.685508, top_k: 0.874883, samples/s: 781.362 1613388869.09134
train: epoch 103, iter 2000, loss: 2.389095, top_1: 0.684805, top_k: 0.873008, samples/s: 781.653 1613388901.8424816
train: epoch 103, iter 2100, loss: 2.282152, top_1: 0.684063, top_k: 0.874062, samples/s: 780.523 1613388934.6410465
train: epoch 103, iter 2200, loss: 2.321598, top_1: 0.684648, top_k: 0.872969, samples/s: 782.486 1613388967.357238
train: epoch 103, iter 2300, loss: 2.410395, top_1: 0.687383, top_k: 0.877070, samples/s: 779.457 1613389000.2006943
train: epoch 103, iter 2400, loss: 2.313225, top_1: 0.680859, top_k: 0.872539, samples/s: 779.097 1613389033.0591633
train: epoch 103, iter 2500, loss: 2.414954, top_1: 0.684531, top_k: 0.873672, samples/s: 782.888 1613389065.758643
train: epoch 103, iter 2600, loss: 2.285708, top_1: 0.680234, top_k: 0.870234, samples/s: 781.949 1613389098.4973488
train: epoch 103, iter 2700, loss: 2.155015, top_1: 0.685664, top_k: 0.871680, samples/s: 778.892 1613389131.3645117
train: epoch 103, iter 2800, loss: 2.348054, top_1: 0.685469, top_k: 0.873398, samples/s: 782.353 1613389164.0862699
train: epoch 103, iter 2900, loss: 2.278183, top_1: 0.685820, top_k: 0.873828, samples/s: 781.733 1613389196.8339968
train: epoch 103, iter 3000, loss: 2.135916, top_1: 0.682930, top_k: 0.870430, samples/s: 781.112 1613389229.6078818
train: epoch 103, iter 3100, loss: 2.393511, top_1: 0.682031, top_k: 0.872734, samples/s: 783.756 1613389262.2710464
train: epoch 103, iter 3200, loss: 2.308393, top_1: 0.687656, top_k: 0.876836, samples/s: 779.869 1613389295.097187
train: epoch 103, iter 3300, loss: 2.385513, top_1: 0.683398, top_k: 0.870078, samples/s: 782.952 1613389327.7938526
train: epoch 103, iter 3400, loss: 2.341829, top_1: 0.689609, top_k: 0.873125, samples/s: 780.085 1613389360.610751
train: epoch 103, iter 3500, loss: 2.198515, top_1: 0.680273, top_k: 0.876211, samples/s: 782.253 1613389393.33683
train: epoch 103, iter 3600, loss: 2.263001, top_1: 0.685078, top_k: 0.872891, samples/s: 780.468 1613389426.1376395
train: epoch 103, iter 3700, loss: 2.258093, top_1: 0.676055, top_k: 0.866641, samples/s: 782.650 1613389458.8470562
train: epoch 103, iter 3800, loss: 2.178545, top_1: 0.680195, top_k: 0.870742, samples/s: 785.308 1613389491.4456506
train: epoch 103, iter 3900, loss: 2.202259, top_1: 0.677695, top_k: 0.869883, samples/s: 781.301 1613389524.2114449
train: epoch 103, iter 4000, loss: 2.318120, top_1: 0.675000, top_k: 0.867422, samples/s: 783.102 1613389556.9019501
train: epoch 103, iter 4100, loss: 2.396078, top_1: 0.683906, top_k: 0.871797, samples/s: 782.210 1613389589.6298673
train: epoch 103, iter 4200, loss: 2.290307, top_1: 0.682891, top_k: 0.871797, samples/s: 782.650 1613389622.3391902
train: epoch 103, iter 4300, loss: 2.341232, top_1: 0.680195, top_k: 0.870664, samples/s: 781.180 1613389655.1100233
train: epoch 103, iter 4400, loss: 2.512383, top_1: 0.675742, top_k: 0.870898, samples/s: 782.122 1613389687.8415785
train: epoch 103, iter 4500, loss: 2.296883, top_1: 0.682500, top_k: 0.873672, samples/s: 782.484 1613389720.5578475
train: epoch 103, iter 4600, loss: 2.399032, top_1: 0.683945, top_k: 0.873789, samples/s: 783.216 1613389753.2436798
train: epoch 103, iter 4700, loss: 2.349253, top_1: 0.678359, top_k: 0.870273, samples/s: 779.956 1613389786.0660899
train: epoch 103, iter 4800, loss: 2.440487, top_1: 0.678555, top_k: 0.868203, samples/s: 782.667 1613389818.774666
train: epoch 103, iter 4900, loss: 2.346346, top_1: 0.679688, top_k: 0.870313, samples/s: 783.452 1613389851.4506621
train: epoch 103, iter 5000, loss: 2.097907, top_1: 0.685859, top_k: 0.869141, samples/s: 782.283 1613389884.1753833
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_103.
validation: epoch 103, iter 195, top_1: 0.714563, top_k: 0.905749, samples/s: 2351.512 1613389906.3716264
train: epoch 104, iter 100, loss: 2.280314, top_1: 0.699922, top_k: 0.881953, samples/s: 801.838 1613389959.0467556
train: epoch 104, iter 200, loss: 2.219567, top_1: 0.688750, top_k: 0.874648, samples/s: 800.207 1613389991.038358
train: epoch 104, iter 300, loss: 2.281503, top_1: 0.697344, top_k: 0.881523, samples/s: 784.821 1613390023.6572795
train: epoch 104, iter 400, loss: 2.241282, top_1: 0.693945, top_k: 0.878008, samples/s: 783.346 1613390056.3378692
train: epoch 104, iter 500, loss: 2.168217, top_1: 0.695430, top_k: 0.879648, samples/s: 781.107 1613390089.1116593
train: epoch 104, iter 600, loss: 2.233844, top_1: 0.688242, top_k: 0.875469, samples/s: 781.611 1613390121.864467
train: epoch 104, iter 700, loss: 2.378756, top_1: 0.693945, top_k: 0.877969, samples/s: 782.215 1613390154.592073
train: epoch 104, iter 800, loss: 2.248722, top_1: 0.689883, top_k: 0.878125, samples/s: 781.770 1613390187.3382099
train: epoch 104, iter 900, loss: 2.340822, top_1: 0.690195, top_k: 0.878359, samples/s: 782.060 1613390220.0724664
train: epoch 104, iter 1000, loss: 2.381633, top_1: 0.686797, top_k: 0.876563, samples/s: 780.039 1613390252.891241
train: epoch 104, iter 1100, loss: 2.125634, top_1: 0.697539, top_k: 0.879258, samples/s: 784.535 1613390285.521967
train: epoch 104, iter 1200, loss: 2.220082, top_1: 0.690820, top_k: 0.872891, samples/s: 779.811 1613390318.3504355
train: epoch 104, iter 1300, loss: 2.263412, top_1: 0.687969, top_k: 0.874844, samples/s: 780.916 1613390351.1324906
train: epoch 104, iter 1400, loss: 2.339737, top_1: 0.697109, top_k: 0.878984, samples/s: 783.140 1613390383.8214042
train: epoch 104, iter 1500, loss: 2.490141, top_1: 0.691016, top_k: 0.878164, samples/s: 780.557 1613390416.6184974
train: epoch 104, iter 1600, loss: 2.207726, top_1: 0.690273, top_k: 0.874258, samples/s: 782.972 1613390449.314405
train: epoch 104, iter 1700, loss: 2.337310, top_1: 0.689961, top_k: 0.876172, samples/s: 783.056 1613390482.0068295
train: epoch 104, iter 1800, loss: 2.519306, top_1: 0.685234, top_k: 0.875664, samples/s: 781.215 1613390514.7763922
train: epoch 104, iter 1900, loss: 2.278470, top_1: 0.688242, top_k: 0.873516, samples/s: 782.254 1613390547.502225
train: epoch 104, iter 2000, loss: 2.358693, top_1: 0.681562, top_k: 0.869766, samples/s: 780.555 1613390580.2994208
train: epoch 104, iter 2100, loss: 2.257435, top_1: 0.689375, top_k: 0.875000, samples/s: 784.312 1613390612.9394805
train: epoch 104, iter 2200, loss: 2.348694, top_1: 0.687852, top_k: 0.874883, samples/s: 782.456 1613390645.657015
train: epoch 104, iter 2300, loss: 2.304704, top_1: 0.685508, top_k: 0.874258, samples/s: 781.829 1613390678.4007213
train: epoch 104, iter 2400, loss: 2.322268, top_1: 0.680508, top_k: 0.872578, samples/s: 784.604 1613390711.0287163
train: epoch 104, iter 2500, loss: 2.177427, top_1: 0.685156, top_k: 0.869727, samples/s: 783.108 1613390743.7189643
train: epoch 104, iter 2600, loss: 2.166370, top_1: 0.688242, top_k: 0.875156, samples/s: 783.651 1613390776.3865654
train: epoch 104, iter 2700, loss: 2.254091, top_1: 0.686797, top_k: 0.874336, samples/s: 785.720 1613390808.9680445
train: epoch 104, iter 2800, loss: 2.482965, top_1: 0.680586, top_k: 0.870859, samples/s: 781.719 1613390841.716462
train: epoch 104, iter 2900, loss: 2.347391, top_1: 0.686758, top_k: 0.873281, samples/s: 783.619 1613390874.3853717
train: epoch 104, iter 3000, loss: 2.294819, top_1: 0.687617, top_k: 0.874883, samples/s: 782.890 1613390907.084725
train: epoch 104, iter 3100, loss: 2.307234, top_1: 0.682852, top_k: 0.874375, samples/s: 783.650 1613390939.7523687
train: epoch 104, iter 3200, loss: 2.360432, top_1: 0.685586, top_k: 0.876289, samples/s: 781.776 1613390972.498343
train: epoch 104, iter 3300, loss: 2.089074, top_1: 0.686797, top_k: 0.875313, samples/s: 784.683 1613391005.1229887
train: epoch 104, iter 3400, loss: 2.321469, top_1: 0.685508, top_k: 0.874961, samples/s: 783.891 1613391037.7806578
train: epoch 104, iter 3500, loss: 2.245383, top_1: 0.689844, top_k: 0.874648, samples/s: 785.493 1613391070.3716094
train: epoch 104, iter 3600, loss: 2.364112, top_1: 0.689297, top_k: 0.872461, samples/s: 780.862 1613391103.1560473
train: epoch 104, iter 3700, loss: 2.353973, top_1: 0.677734, top_k: 0.869258, samples/s: 782.469 1613391135.872833
train: epoch 104, iter 3800, loss: 2.291148, top_1: 0.681016, top_k: 0.870469, samples/s: 781.549 1613391168.6283202
train: epoch 104, iter 3900, loss: 2.338444, top_1: 0.684844, top_k: 0.873086, samples/s: 782.176 1613391201.357534
train: epoch 104, iter 4000, loss: 2.175051, top_1: 0.686211, top_k: 0.876289, samples/s: 782.940 1613391234.0547743
train: epoch 104, iter 4100, loss: 2.304974, top_1: 0.682344, top_k: 0.874727, samples/s: 781.935 1613391266.7940276
train: epoch 104, iter 4200, loss: 2.382418, top_1: 0.681484, top_k: 0.869961, samples/s: 780.025 1613391299.613476
train: epoch 104, iter 4300, loss: 2.357823, top_1: 0.680547, top_k: 0.868789, samples/s: 782.607 1613391332.3247874
train: epoch 104, iter 4400, loss: 2.332364, top_1: 0.687109, top_k: 0.875469, samples/s: 782.961 1613391365.0211792
train: epoch 104, iter 4500, loss: 2.238930, top_1: 0.686914, top_k: 0.871797, samples/s: 780.482 1613391397.821423
train: epoch 104, iter 4600, loss: 2.364077, top_1: 0.680898, top_k: 0.867773, samples/s: 783.661 1613391430.4885051
train: epoch 104, iter 4700, loss: 2.246635, top_1: 0.677500, top_k: 0.870625, samples/s: 780.129 1613391463.303657
train: epoch 104, iter 4800, loss: 2.276951, top_1: 0.683789, top_k: 0.871172, samples/s: 782.457 1613391496.0210054
train: epoch 104, iter 4900, loss: 2.257146, top_1: 0.685664, top_k: 0.872578, samples/s: 782.613 1613391528.7320209
train: epoch 104, iter 5000, loss: 2.218460, top_1: 0.685547, top_k: 0.872344, samples/s: 780.466 1613391561.532906
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_104.
validation: epoch 104, iter 195, top_1: 0.718249, top_k: 0.908293, samples/s: 2353.222 1613391583.6599026
train: epoch 105, iter 100, loss: 2.351013, top_1: 0.696953, top_k: 0.878398, samples/s: 804.037 1613391636.651717
train: epoch 105, iter 200, loss: 2.419683, top_1: 0.697539, top_k: 0.881250, samples/s: 800.803 1613391668.6195793
train: epoch 105, iter 300, loss: 2.326147, top_1: 0.700078, top_k: 0.879297, samples/s: 784.147 1613391701.2665026
train: epoch 105, iter 400, loss: 2.188744, top_1: 0.695625, top_k: 0.881289, samples/s: 782.057 1613391734.0006561
train: epoch 105, iter 500, loss: 2.126946, top_1: 0.692500, top_k: 0.878594, samples/s: 781.049 1613391766.7772574
train: epoch 105, iter 600, loss: 2.170666, top_1: 0.701289, top_k: 0.879453, samples/s: 783.657 1613391799.4444852
train: epoch 105, iter 700, loss: 2.235302, top_1: 0.695352, top_k: 0.878359, samples/s: 779.529 1613391832.2849584
train: epoch 105, iter 800, loss: 2.293224, top_1: 0.694258, top_k: 0.878164, samples/s: 780.502 1613391865.0843265
train: epoch 105, iter 900, loss: 2.171496, top_1: 0.693945, top_k: 0.882188, samples/s: 783.621 1613391897.7531183
train: epoch 105, iter 1000, loss: 2.330442, top_1: 0.692305, top_k: 0.877891, samples/s: 783.408 1613391930.4308622
train: epoch 105, iter 1100, loss: 2.147173, top_1: 0.688281, top_k: 0.876875, samples/s: 780.360 1613391963.2362933
train: epoch 105, iter 1200, loss: 2.332953, top_1: 0.692187, top_k: 0.876719, samples/s: 784.206 1613391995.8808084
train: epoch 105, iter 1300, loss: 2.366076, top_1: 0.695547, top_k: 0.881367, samples/s: 783.906 1613392028.5377629
train: epoch 105, iter 1400, loss: 2.123382, top_1: 0.691953, top_k: 0.879492, samples/s: 780.888 1613392061.3209648
train: epoch 105, iter 1500, loss: 2.097210, top_1: 0.690859, top_k: 0.877461, samples/s: 779.652 1613392094.1560388
train: epoch 105, iter 1600, loss: 2.371250, top_1: 0.691797, top_k: 0.878086, samples/s: 783.614 1613392126.8252409
train: epoch 105, iter 1700, loss: 2.455958, top_1: 0.693555, top_k: 0.877773, samples/s: 782.123 1613392159.5567331
train: epoch 105, iter 1800, loss: 2.422514, top_1: 0.687617, top_k: 0.879062, samples/s: 781.662 1613392192.3074384
train: epoch 105, iter 1900, loss: 2.108361, top_1: 0.687891, top_k: 0.875742, samples/s: 782.379 1613392225.0280852
train: epoch 105, iter 2000, loss: 2.379465, top_1: 0.685078, top_k: 0.873672, samples/s: 782.432 1613392257.74663
train: epoch 105, iter 2100, loss: 2.340591, top_1: 0.684297, top_k: 0.872148, samples/s: 782.972 1613392290.44249
train: epoch 105, iter 2200, loss: 2.198785, top_1: 0.683828, top_k: 0.871328, samples/s: 780.749 1613392323.2315176
train: epoch 105, iter 2300, loss: 2.336620, top_1: 0.688047, top_k: 0.875586, samples/s: 782.526 1613392355.9461014
train: epoch 105, iter 2400, loss: 2.161755, top_1: 0.692383, top_k: 0.873711, samples/s: 783.192 1613392388.6328316
train: epoch 105, iter 2500, loss: 2.092077, top_1: 0.688711, top_k: 0.874336, samples/s: 781.505 1613392421.3901637
train: epoch 105, iter 2600, loss: 2.570541, top_1: 0.690430, top_k: 0.872695, samples/s: 783.467 1613392454.0654361
train: epoch 105, iter 2700, loss: 2.287114, top_1: 0.686016, top_k: 0.875078, samples/s: 783.398 1613392486.7435632
train: epoch 105, iter 2800, loss: 2.254196, top_1: 0.689961, top_k: 0.879727, samples/s: 785.076 1613392519.3519764
train: epoch 105, iter 2900, loss: 2.267779, top_1: 0.688672, top_k: 0.875313, samples/s: 784.726 1613392551.974715
train: epoch 105, iter 3000, loss: 2.187042, top_1: 0.688359, top_k: 0.869727, samples/s: 781.604 1613392584.7279193
train: epoch 105, iter 3100, loss: 2.271229, top_1: 0.688008, top_k: 0.875703, samples/s: 781.286 1613392617.4944937
train: epoch 105, iter 3200, loss: 2.405659, top_1: 0.687344, top_k: 0.874883, samples/s: 781.894 1613392650.2354634
train: epoch 105, iter 3300, loss: 2.277692, top_1: 0.683555, top_k: 0.873125, samples/s: 783.494 1613392682.9095657
train: epoch 105, iter 3400, loss: 2.329764, top_1: 0.690781, top_k: 0.874648, samples/s: 781.729 1613392715.6575172
train: epoch 105, iter 3500, loss: 2.489821, top_1: 0.688047, top_k: 0.875469, samples/s: 782.992 1613392748.3525777
train: epoch 105, iter 3600, loss: 2.407185, top_1: 0.688281, top_k: 0.873008, samples/s: 782.552 1613392781.0661333
train: epoch 105, iter 3700, loss: 2.268166, top_1: 0.690898, top_k: 0.875078, samples/s: 783.679 1613392813.732489
train: epoch 105, iter 3800, loss: 2.427673, top_1: 0.685898, top_k: 0.870703, samples/s: 782.699 1613392846.439901
train: epoch 105, iter 3900, loss: 2.527813, top_1: 0.683789, top_k: 0.875547, samples/s: 781.160 1613392879.211582
train: epoch 105, iter 4000, loss: 2.346723, top_1: 0.678398, top_k: 0.872422, samples/s: 784.579 1613392911.840598
train: epoch 105, iter 4100, loss: 2.404567, top_1: 0.690586, top_k: 0.877148, samples/s: 782.648 1613392944.5500455
train: epoch 105, iter 4200, loss: 2.219382, top_1: 0.690508, top_k: 0.877891, samples/s: 784.210 1613392977.194514
train: epoch 105, iter 4300, loss: 2.250806, top_1: 0.688438, top_k: 0.873086, samples/s: 782.040 1613393009.929313
train: epoch 105, iter 4400, loss: 2.151971, top_1: 0.685703, top_k: 0.874570, samples/s: 781.942 1613393042.6683226
train: epoch 105, iter 4500, loss: 2.154086, top_1: 0.679102, top_k: 0.871406, samples/s: 782.644 1613393075.377894
train: epoch 105, iter 4600, loss: 2.276915, top_1: 0.687578, top_k: 0.877773, samples/s: 781.907 1613393108.118369
train: epoch 105, iter 4700, loss: 2.218307, top_1: 0.689414, top_k: 0.874453, samples/s: 781.544 1613393140.8740406
train: epoch 105, iter 4800, loss: 2.294757, top_1: 0.688320, top_k: 0.868711, samples/s: 782.453 1613393173.5916333
train: epoch 105, iter 4900, loss: 2.302954, top_1: 0.685977, top_k: 0.875039, samples/s: 782.328 1613393206.3146033
train: epoch 105, iter 5000, loss: 2.363080, top_1: 0.692305, top_k: 0.879531, samples/s: 784.291 1613393238.9555812
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_105.
validation: epoch 105, iter 195, top_1: 0.719752, top_k: 0.908774, samples/s: 2353.758 1613393261.153703
train: epoch 106, iter 100, loss: 2.232020, top_1: 0.699531, top_k: 0.884219, samples/s: 803.868 1613393313.9155684
train: epoch 106, iter 200, loss: 2.284785, top_1: 0.692109, top_k: 0.877539, samples/s: 800.703 1613393345.8876574
train: epoch 106, iter 300, loss: 2.114867, top_1: 0.701211, top_k: 0.881680, samples/s: 782.071 1613393378.620988
train: epoch 106, iter 400, loss: 2.276443, top_1: 0.695781, top_k: 0.883047, samples/s: 780.702 1613393411.4119575
train: epoch 106, iter 500, loss: 2.251929, top_1: 0.702266, top_k: 0.883594, samples/s: 782.390 1613393444.1322033
train: epoch 106, iter 600, loss: 2.225646, top_1: 0.699336, top_k: 0.879922, samples/s: 783.230 1613393476.81742
train: epoch 106, iter 700, loss: 2.146234, top_1: 0.702148, top_k: 0.883750, samples/s: 780.155 1613393509.6313977
train: epoch 106, iter 800, loss: 2.293677, top_1: 0.692383, top_k: 0.876172, samples/s: 781.059 1613393542.4073865
train: epoch 106, iter 900, loss: 2.115258, top_1: 0.694766, top_k: 0.880469, samples/s: 780.611 1613393575.2022228
train: epoch 106, iter 1000, loss: 2.325808, top_1: 0.696016, top_k: 0.880820, samples/s: 782.009 1613393607.938408
train: epoch 106, iter 1100, loss: 2.153320, top_1: 0.688867, top_k: 0.875781, samples/s: 782.697 1613393640.6457877
train: epoch 106, iter 1200, loss: 2.228843, top_1: 0.700742, top_k: 0.878633, samples/s: 781.737 1613393673.3935232
train: epoch 106, iter 1300, loss: 2.138130, top_1: 0.695859, top_k: 0.879961, samples/s: 781.469 1613393706.1522694
train: epoch 106, iter 1400, loss: 2.256699, top_1: 0.695547, top_k: 0.878672, samples/s: 779.827 1613393738.9801035
train: epoch 106, iter 1500, loss: 2.177638, top_1: 0.695898, top_k: 0.877148, samples/s: 784.555 1613393771.6100836
train: epoch 106, iter 1600, loss: 2.105757, top_1: 0.696758, top_k: 0.879180, samples/s: 781.650 1613393804.3612578
train: epoch 106, iter 1700, loss: 2.372876, top_1: 0.693164, top_k: 0.880781, samples/s: 780.898 1613393837.1439888
train: epoch 106, iter 1800, loss: 2.157829, top_1: 0.693320, top_k: 0.875313, samples/s: 782.465 1613393869.8611958
train: epoch 106, iter 1900, loss: 2.269928, top_1: 0.689688, top_k: 0.877891, samples/s: 782.114 1613393902.5929332
train: epoch 106, iter 2000, loss: 2.478654, top_1: 0.690898, top_k: 0.874687, samples/s: 780.377 1613393935.3975642
train: epoch 106, iter 2100, loss: 2.213301, top_1: 0.683398, top_k: 0.873086, samples/s: 781.956 1613393968.1359715
train: epoch 106, iter 2200, loss: 2.269173, top_1: 0.698398, top_k: 0.879648, samples/s: 781.708 1613394000.884824
train: epoch 106, iter 2300, loss: 2.192759, top_1: 0.684023, top_k: 0.872617, samples/s: 784.036 1613394033.5363235
train: epoch 106, iter 2400, loss: 2.253994, top_1: 0.692031, top_k: 0.876523, samples/s: 782.094 1613394066.2690334
train: epoch 106, iter 2500, loss: 2.208779, top_1: 0.691055, top_k: 0.876328, samples/s: 781.215 1613394099.038467
train: epoch 106, iter 2600, loss: 2.304116, top_1: 0.691680, top_k: 0.876758, samples/s: 781.582 1613394131.792587
train: epoch 106, iter 2700, loss: 2.361253, top_1: 0.690781, top_k: 0.874180, samples/s: 782.691 1613394164.5001602
train: epoch 106, iter 2800, loss: 2.354368, top_1: 0.683594, top_k: 0.872891, samples/s: 781.000 1613394197.2787662
train: epoch 106, iter 2900, loss: 2.307511, top_1: 0.688945, top_k: 0.878594, samples/s: 782.153 1613394230.008877
train: epoch 106, iter 3000, loss: 2.171077, top_1: 0.695273, top_k: 0.877070, samples/s: 781.364 1613394262.772152
train: epoch 106, iter 3100, loss: 2.299721, top_1: 0.692813, top_k: 0.876328, samples/s: 783.893 1613394295.4297543
train: epoch 106, iter 3200, loss: 2.272310, top_1: 0.690547, top_k: 0.879297, samples/s: 784.794 1613394328.04962
train: epoch 106, iter 3300, loss: 2.168801, top_1: 0.684609, top_k: 0.875469, samples/s: 780.846 1613394360.8346748
train: epoch 106, iter 3400, loss: 2.454066, top_1: 0.686250, top_k: 0.873125, samples/s: 781.326 1613394393.5994914
train: epoch 106, iter 3500, loss: 2.289548, top_1: 0.690195, top_k: 0.874375, samples/s: 780.885 1613394426.3827395
train: epoch 106, iter 3600, loss: 2.236215, top_1: 0.691641, top_k: 0.877227, samples/s: 782.110 1613394459.1147768
train: epoch 106, iter 3700, loss: 2.309525, top_1: 0.685156, top_k: 0.875898, samples/s: 780.043 1613394491.93347
train: epoch 106, iter 3800, loss: 2.304852, top_1: 0.690547, top_k: 0.877773, samples/s: 783.342 1613394524.6138968
train: epoch 106, iter 3900, loss: 2.246361, top_1: 0.688047, top_k: 0.876953, samples/s: 781.665 1613394557.364477
train: epoch 106, iter 4000, loss: 2.322659, top_1: 0.694727, top_k: 0.879219, samples/s: 782.858 1613394590.0651624
train: epoch 106, iter 4100, loss: 2.477616, top_1: 0.690391, top_k: 0.877383, samples/s: 780.326 1613394622.8720536
train: epoch 106, iter 4200, loss: 2.368166, top_1: 0.692813, top_k: 0.877578, samples/s: 783.001 1613394655.5667748
train: epoch 106, iter 4300, loss: 2.276348, top_1: 0.683750, top_k: 0.875742, samples/s: 780.944 1613394688.347577
train: epoch 106, iter 4400, loss: 2.207396, top_1: 0.690781, top_k: 0.875273, samples/s: 783.734 1613394721.0116954
train: epoch 106, iter 4500, loss: 2.194993, top_1: 0.689805, top_k: 0.874062, samples/s: 780.687 1613394753.8033905
train: epoch 106, iter 4600, loss: 2.051734, top_1: 0.690937, top_k: 0.877422, samples/s: 781.136 1613394786.576163
train: epoch 106, iter 4700, loss: 2.226256, top_1: 0.696641, top_k: 0.874062, samples/s: 783.525 1613394819.2491024
train: epoch 106, iter 4800, loss: 2.434448, top_1: 0.687148, top_k: 0.875352, samples/s: 779.732 1613394852.080869
train: epoch 106, iter 4900, loss: 2.247091, top_1: 0.689453, top_k: 0.877188, samples/s: 781.065 1613394884.8566158
train: epoch 106, iter 5000, loss: 2.119548, top_1: 0.688438, top_k: 0.875078, samples/s: 783.492 1613394917.5307364
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_106.
validation: epoch 106, iter 195, top_1: 0.723097, top_k: 0.911478, samples/s: 2353.191 1613394939.704534
train: epoch 107, iter 100, loss: 2.070589, top_1: 0.706602, top_k: 0.884336, samples/s: 802.750 1613394992.0576208
train: epoch 107, iter 200, loss: 2.344343, top_1: 0.697266, top_k: 0.879414, samples/s: 798.591 1613395024.1143556
train: epoch 107, iter 300, loss: 2.232109, top_1: 0.705234, top_k: 0.885000, samples/s: 783.793 1613395056.7756836
train: epoch 107, iter 400, loss: 2.222386, top_1: 0.703711, top_k: 0.882148, samples/s: 777.656 1613395089.6951778
train: epoch 107, iter 500, loss: 2.321818, top_1: 0.697031, top_k: 0.884766, samples/s: 781.942 1613395122.4341338
train: epoch 107, iter 600, loss: 2.118574, top_1: 0.701719, top_k: 0.883867, samples/s: 780.977 1613395155.2135465
train: epoch 107, iter 700, loss: 2.201986, top_1: 0.700898, top_k: 0.882500, samples/s: 780.040 1613395188.0324552
train: epoch 107, iter 800, loss: 2.170785, top_1: 0.699414, top_k: 0.883594, samples/s: 783.510 1613395220.7059095
train: epoch 107, iter 900, loss: 2.396367, top_1: 0.695586, top_k: 0.878633, samples/s: 781.126 1613395253.4791267
train: epoch 107, iter 1000, loss: 2.295353, top_1: 0.702266, top_k: 0.885195, samples/s: 781.062 1613395286.2550156
train: epoch 107, iter 1100, loss: 2.209422, top_1: 0.702969, top_k: 0.881953, samples/s: 778.667 1613395319.1317394
train: epoch 107, iter 1200, loss: 2.105557, top_1: 0.700352, top_k: 0.881992, samples/s: 780.978 1613395351.911032
train: epoch 107, iter 1300, loss: 2.255026, top_1: 0.699375, top_k: 0.879258, samples/s: 780.622 1613395384.7054243
train: epoch 107, iter 1400, loss: 2.422489, top_1: 0.693398, top_k: 0.879336, samples/s: 783.552 1613395417.3772118
train: epoch 107, iter 1500, loss: 2.143759, top_1: 0.693359, top_k: 0.874883, samples/s: 779.275 1613395450.2281573
train: epoch 107, iter 1600, loss: 2.153167, top_1: 0.694570, top_k: 0.876211, samples/s: 783.346 1613395482.9084942
train: epoch 107, iter 1700, loss: 2.179808, top_1: 0.692227, top_k: 0.876836, samples/s: 778.929 1613395515.7741287
train: epoch 107, iter 1800, loss: 2.343712, top_1: 0.693242, top_k: 0.881602, samples/s: 782.999 1613395548.4689279
train: epoch 107, iter 1900, loss: 2.136581, top_1: 0.698242, top_k: 0.880820, samples/s: 779.548 1613395581.3085797
train: epoch 107, iter 2000, loss: 2.356972, top_1: 0.701250, top_k: 0.882266, samples/s: 780.775 1613395614.0965006
train: epoch 107, iter 2100, loss: 2.222774, top_1: 0.694336, top_k: 0.879961, samples/s: 781.055 1613395646.872638
train: epoch 107, iter 2200, loss: 2.335022, top_1: 0.691875, top_k: 0.876992, samples/s: 782.189 1613395679.601383
train: epoch 107, iter 2300, loss: 2.176270, top_1: 0.694766, top_k: 0.881016, samples/s: 781.767 1613395712.347703
train: epoch 107, iter 2400, loss: 2.401688, top_1: 0.691484, top_k: 0.879766, samples/s: 780.200 1613395745.159723
train: epoch 107, iter 2500, loss: 2.216976, top_1: 0.691016, top_k: 0.877422, samples/s: 785.699 1613395777.7422447
train: epoch 107, iter 2600, loss: 2.256849, top_1: 0.692539, top_k: 0.877500, samples/s: 778.582 1613395810.6224482
train: epoch 107, iter 2700, loss: 2.426762, top_1: 0.695234, top_k: 0.880430, samples/s: 782.342 1613395843.3446596
train: epoch 107, iter 2800, loss: 2.203725, top_1: 0.695703, top_k: 0.877969, samples/s: 779.929 1613395876.1682303
train: epoch 107, iter 2900, loss: 2.265338, top_1: 0.694531, top_k: 0.880625, samples/s: 782.921 1613395908.8662896
train: epoch 107, iter 3000, loss: 2.173001, top_1: 0.695547, top_k: 0.880391, samples/s: 780.770 1613395941.6543667
train: epoch 107, iter 3100, loss: 2.347533, top_1: 0.696914, top_k: 0.880117, samples/s: 781.545 1613395974.4099524
train: epoch 107, iter 3200, loss: 2.398848, top_1: 0.696328, top_k: 0.881992, samples/s: 782.320 1613396007.1332655
train: epoch 107, iter 3300, loss: 2.256990, top_1: 0.687969, top_k: 0.877266, samples/s: 779.252 1613396039.9852827
train: epoch 107, iter 3400, loss: 2.197252, top_1: 0.693633, top_k: 0.881016, samples/s: 785.263 1613396072.5857458
train: epoch 107, iter 3500, loss: 2.367220, top_1: 0.687930, top_k: 0.873906, samples/s: 780.330 1613396105.3923883
train: epoch 107, iter 3600, loss: 2.341678, top_1: 0.690586, top_k: 0.878125, samples/s: 780.931 1613396138.173857
train: epoch 107, iter 3700, loss: 2.205310, top_1: 0.691289, top_k: 0.876914, samples/s: 781.684 1613396170.9236512
train: epoch 107, iter 3800, loss: 2.039735, top_1: 0.689688, top_k: 0.875742, samples/s: 780.244 1613396203.7337952
train: epoch 107, iter 3900, loss: 2.249994, top_1: 0.695703, top_k: 0.879023, samples/s: 780.635 1613396236.52772
train: epoch 107, iter 4000, loss: 2.197113, top_1: 0.692891, top_k: 0.877461, samples/s: 783.493 1613396269.2018406
train: epoch 107, iter 4100, loss: 2.143373, top_1: 0.692656, top_k: 0.877930, samples/s: 781.454 1613396301.9613445
train: epoch 107, iter 4200, loss: 2.241301, top_1: 0.691914, top_k: 0.878828, samples/s: 782.729 1613396334.6674337
train: epoch 107, iter 4300, loss: 2.094366, top_1: 0.691719, top_k: 0.879023, samples/s: 781.065 1613396367.4432025
train: epoch 107, iter 4400, loss: 2.456419, top_1: 0.688750, top_k: 0.875938, samples/s: 783.198 1613396400.1296396
train: epoch 107, iter 4500, loss: 2.253559, top_1: 0.691367, top_k: 0.878437, samples/s: 780.758 1613396432.9183242
train: epoch 107, iter 4600, loss: 2.180122, top_1: 0.692500, top_k: 0.879766, samples/s: 783.309 1613396465.6001885
train: epoch 107, iter 4700, loss: 2.195730, top_1: 0.690547, top_k: 0.877617, samples/s: 780.090 1613396498.4168622
train: epoch 107, iter 4800, loss: 2.149674, top_1: 0.688281, top_k: 0.877812, samples/s: 784.041 1613396531.0683236
train: epoch 107, iter 4900, loss: 2.178576, top_1: 0.696953, top_k: 0.880039, samples/s: 781.417 1613396563.8292449
train: epoch 107, iter 5000, loss: 2.207689, top_1: 0.695586, top_k: 0.880117, samples/s: 781.401 1613396596.5909584
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_107.
validation: epoch 107, iter 195, top_1: 0.714804, top_k: 0.906751, samples/s: 2371.577 1613396618.6129355
train: epoch 108, iter 100, loss: 2.310118, top_1: 0.705547, top_k: 0.884102, samples/s: 804.414 1613396671.0667381
train: epoch 108, iter 200, loss: 2.420173, top_1: 0.704883, top_k: 0.884883, samples/s: 799.408 1613396703.0903583
train: epoch 108, iter 300, loss: 2.289597, top_1: 0.705352, top_k: 0.885273, samples/s: 782.799 1613396735.7936976
train: epoch 108, iter 400, loss: 2.269119, top_1: 0.701797, top_k: 0.884883, samples/s: 783.126 1613396768.4830346
train: epoch 108, iter 500, loss: 2.263757, top_1: 0.702305, top_k: 0.884687, samples/s: 782.313 1613396801.206497
train: epoch 108, iter 600, loss: 2.330208, top_1: 0.696016, top_k: 0.878984, samples/s: 779.093 1613396834.0652702
train: epoch 108, iter 700, loss: 2.312258, top_1: 0.701250, top_k: 0.882578, samples/s: 780.710 1613396866.855878
train: epoch 108, iter 800, loss: 2.134981, top_1: 0.708984, top_k: 0.884336, samples/s: 783.533 1613396899.5284626
train: epoch 108, iter 900, loss: 2.234006, top_1: 0.699727, top_k: 0.879844, samples/s: 780.545 1613396932.3260498
train: epoch 108, iter 1000, loss: 2.237293, top_1: 0.699609, top_k: 0.882305, samples/s: 780.815 1613396965.1122615
train: epoch 108, iter 1100, loss: 2.163741, top_1: 0.703203, top_k: 0.881836, samples/s: 782.397 1613396997.83222
train: epoch 108, iter 1200, loss: 2.070212, top_1: 0.706367, top_k: 0.886367, samples/s: 779.841 1613397030.659474
train: epoch 108, iter 1300, loss: 2.213286, top_1: 0.702695, top_k: 0.886094, samples/s: 782.721 1613397063.365905
train: epoch 108, iter 1400, loss: 2.075702, top_1: 0.705469, top_k: 0.885352, samples/s: 781.512 1613397096.1229298
train: epoch 108, iter 1500, loss: 2.366054, top_1: 0.697812, top_k: 0.879102, samples/s: 779.981 1613397128.9441316
train: epoch 108, iter 1600, loss: 2.287605, top_1: 0.702695, top_k: 0.882070, samples/s: 784.929 1613397161.5585773
train: epoch 108, iter 1700, loss: 2.336893, top_1: 0.699375, top_k: 0.880859, samples/s: 777.503 1613397194.4844983
train: epoch 108, iter 1800, loss: 2.173422, top_1: 0.692734, top_k: 0.879648, samples/s: 786.212 1613397227.0457673
train: epoch 108, iter 1900, loss: 2.154716, top_1: 0.698398, top_k: 0.878984, samples/s: 782.037 1613397259.7807689
train: epoch 108, iter 2000, loss: 2.276300, top_1: 0.692422, top_k: 0.876133, samples/s: 783.910 1613397292.437518
train: epoch 108, iter 2100, loss: 2.370955, top_1: 0.692773, top_k: 0.876797, samples/s: 781.336 1613397325.2018764
train: epoch 108, iter 2200, loss: 2.294121, top_1: 0.696797, top_k: 0.880000, samples/s: 782.439 1613397357.9200869
train: epoch 108, iter 2300, loss: 2.240822, top_1: 0.699297, top_k: 0.883477, samples/s: 781.723 1613397390.668362
train: epoch 108, iter 2400, loss: 2.102428, top_1: 0.691250, top_k: 0.878867, samples/s: 783.041 1613397423.3613954
train: epoch 108, iter 2500, loss: 2.340631, top_1: 0.695625, top_k: 0.881992, samples/s: 782.853 1613397456.0622418
train: epoch 108, iter 2600, loss: 2.269500, top_1: 0.695156, top_k: 0.878672, samples/s: 782.474 1613397488.7789912
train: epoch 108, iter 2700, loss: 2.271693, top_1: 0.698164, top_k: 0.879062, samples/s: 784.071 1613397521.4291167
train: epoch 108, iter 2800, loss: 2.047520, top_1: 0.694727, top_k: 0.883906, samples/s: 779.874 1613397554.254858
train: epoch 108, iter 2900, loss: 2.361406, top_1: 0.695234, top_k: 0.877344, samples/s: 782.308 1613397586.9786325
train: epoch 108, iter 3000, loss: 2.252494, top_1: 0.694102, top_k: 0.879375, samples/s: 782.987 1613397619.6738672
train: epoch 108, iter 3100, loss: 2.319471, top_1: 0.698867, top_k: 0.878750, samples/s: 782.799 1613397652.3769798
train: epoch 108, iter 3200, loss: 2.293007, top_1: 0.700625, top_k: 0.882500, samples/s: 781.284 1613397685.1436849
train: epoch 108, iter 3300, loss: 2.245775, top_1: 0.696602, top_k: 0.879648, samples/s: 782.958 1613397717.8402126
train: epoch 108, iter 3400, loss: 2.189433, top_1: 0.701289, top_k: 0.883984, samples/s: 780.583 1613397750.636158
train: epoch 108, iter 3500, loss: 2.415118, top_1: 0.689531, top_k: 0.878867, samples/s: 781.214 1613397783.4056747
train: epoch 108, iter 3600, loss: 2.167938, top_1: 0.699805, top_k: 0.879531, samples/s: 781.643 1613397816.1571548
train: epoch 108, iter 3700, loss: 2.338907, top_1: 0.691172, top_k: 0.879336, samples/s: 779.314 1613397849.0065732
train: epoch 108, iter 3800, loss: 2.273355, top_1: 0.693203, top_k: 0.874023, samples/s: 784.598 1613397881.6347787
train: epoch 108, iter 3900, loss: 2.244867, top_1: 0.694375, top_k: 0.878672, samples/s: 782.064 1613397914.368688
train: epoch 108, iter 4000, loss: 2.160703, top_1: 0.698945, top_k: 0.880078, samples/s: 777.982 1613397947.2742887
train: epoch 108, iter 4100, loss: 2.145020, top_1: 0.696094, top_k: 0.878672, samples/s: 784.142 1613397979.9214501
train: epoch 108, iter 4200, loss: 2.186146, top_1: 0.698867, top_k: 0.883203, samples/s: 783.321 1613398012.6027703
train: epoch 108, iter 4300, loss: 2.346137, top_1: 0.690508, top_k: 0.877852, samples/s: 781.239 1613398045.371242
train: epoch 108, iter 4400, loss: 2.129544, top_1: 0.698008, top_k: 0.879687, samples/s: 784.047 1613398078.0223823
train: epoch 108, iter 4500, loss: 2.132954, top_1: 0.697539, top_k: 0.880195, samples/s: 782.060 1613398110.7563622
train: epoch 108, iter 4600, loss: 2.131745, top_1: 0.693789, top_k: 0.879453, samples/s: 778.786 1613398143.6280394
train: epoch 108, iter 4700, loss: 2.166213, top_1: 0.698164, top_k: 0.879922, samples/s: 785.523 1613398176.2178524
train: epoch 108, iter 4800, loss: 2.064214, top_1: 0.693281, top_k: 0.877578, samples/s: 779.594 1613398209.0554755
train: epoch 108, iter 4900, loss: 2.088380, top_1: 0.689219, top_k: 0.877891, samples/s: 781.541 1613398241.8113444
train: epoch 108, iter 5000, loss: 2.129977, top_1: 0.699453, top_k: 0.881172, samples/s: 782.563 1613398274.5242965
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_108.
validation: epoch 108, iter 195, top_1: 0.727384, top_k: 0.913261, samples/s: 2366.434 1613398296.5921984
train: epoch 109, iter 100, loss: 2.158011, top_1: 0.705859, top_k: 0.885625, samples/s: 803.719 1613398354.7486117
train: epoch 109, iter 200, loss: 2.314889, top_1: 0.707031, top_k: 0.882227, samples/s: 802.475 1613398386.649941
train: epoch 109, iter 300, loss: 2.068203, top_1: 0.706641, top_k: 0.886289, samples/s: 787.406 1613398419.1618066
train: epoch 109, iter 400, loss: 2.207953, top_1: 0.709453, top_k: 0.887539, samples/s: 781.304 1613398451.9277625
train: epoch 109, iter 500, loss: 2.380836, top_1: 0.705117, top_k: 0.887930, samples/s: 782.151 1613398484.6578555
train: epoch 109, iter 600, loss: 2.241436, top_1: 0.710625, top_k: 0.888125, samples/s: 778.126 1613398517.5574024
train: epoch 109, iter 700, loss: 2.179446, top_1: 0.703359, top_k: 0.885625, samples/s: 784.056 1613398550.208038
train: epoch 109, iter 800, loss: 2.304249, top_1: 0.706328, top_k: 0.886836, samples/s: 782.266 1613398582.9334712
train: epoch 109, iter 900, loss: 2.138079, top_1: 0.701211, top_k: 0.883984, samples/s: 779.408 1613398615.7789648
train: epoch 109, iter 1000, loss: 2.263986, top_1: 0.699688, top_k: 0.882422, samples/s: 782.612 1613398648.4900193
train: epoch 109, iter 1100, loss: 2.038150, top_1: 0.701602, top_k: 0.882422, samples/s: 781.574 1613398681.244441
train: epoch 109, iter 1200, loss: 2.259145, top_1: 0.703477, top_k: 0.883398, samples/s: 782.917 1613398713.9425907
train: epoch 109, iter 1300, loss: 2.117933, top_1: 0.703906, top_k: 0.883672, samples/s: 779.966 1613398746.7646146
train: epoch 109, iter 1400, loss: 2.332707, top_1: 0.707422, top_k: 0.890195, samples/s: 783.081 1613398779.455948
train: epoch 109, iter 1500, loss: 2.178447, top_1: 0.700352, top_k: 0.886797, samples/s: 782.237 1613398812.1825988
train: epoch 109, iter 1600, loss: 2.302521, top_1: 0.706641, top_k: 0.882695, samples/s: 782.262 1613398844.9081557
train: epoch 109, iter 1700, loss: 2.329464, top_1: 0.696680, top_k: 0.883008, samples/s: 781.476 1613398877.6667953
train: epoch 109, iter 1800, loss: 2.167028, top_1: 0.704766, top_k: 0.883594, samples/s: 783.524 1613398910.3395913
train: epoch 109, iter 1900, loss: 2.218401, top_1: 0.705781, top_k: 0.882812, samples/s: 781.524 1613398943.0961533
train: epoch 109, iter 2000, loss: 2.258720, top_1: 0.697695, top_k: 0.882812, samples/s: 782.196 1613398975.8245108
train: epoch 109, iter 2100, loss: 2.300238, top_1: 0.702031, top_k: 0.881875, samples/s: 783.224 1613399008.5099428
train: epoch 109, iter 2200, loss: 2.206737, top_1: 0.697031, top_k: 0.880859, samples/s: 783.064 1613399041.2020726
train: epoch 109, iter 2300, loss: 2.247365, top_1: 0.698789, top_k: 0.880156, samples/s: 784.128 1613399073.849794
train: epoch 109, iter 2400, loss: 2.248000, top_1: 0.703242, top_k: 0.885312, samples/s: 781.256 1613399106.6175323
train: epoch 109, iter 2500, loss: 2.290076, top_1: 0.694219, top_k: 0.879844, samples/s: 783.223 1613399139.3029513
train: epoch 109, iter 2600, loss: 2.434853, top_1: 0.694844, top_k: 0.882344, samples/s: 784.247 1613399171.9458249
train: epoch 109, iter 2700, loss: 2.411931, top_1: 0.693320, top_k: 0.876953, samples/s: 782.313 1613399204.669291
train: epoch 109, iter 2800, loss: 2.366879, top_1: 0.696719, top_k: 0.880547, samples/s: 781.557 1613399237.424352
train: epoch 109, iter 2900, loss: 2.285874, top_1: 0.703047, top_k: 0.884062, samples/s: 782.848 1613399270.1254363
train: epoch 109, iter 3000, loss: 2.263357, top_1: 0.698320, top_k: 0.881836, samples/s: 782.141 1613399302.8562212
train: epoch 109, iter 3100, loss: 2.304566, top_1: 0.692734, top_k: 0.876016, samples/s: 785.310 1613399335.454733
train: epoch 109, iter 3200, loss: 2.491812, top_1: 0.699375, top_k: 0.882188, samples/s: 781.436 1613399368.2150052
train: epoch 109, iter 3300, loss: 2.271264, top_1: 0.700273, top_k: 0.881406, samples/s: 784.491 1613399400.8476007
train: epoch 109, iter 3400, loss: 2.064329, top_1: 0.698086, top_k: 0.880430, samples/s: 781.149 1613399433.6197746
train: epoch 109, iter 3500, loss: 2.407532, top_1: 0.698867, top_k: 0.880859, samples/s: 782.215 1613399466.3473759
train: epoch 109, iter 3600, loss: 2.187966, top_1: 0.706211, top_k: 0.883281, samples/s: 786.011 1613399498.9169564
train: epoch 109, iter 3700, loss: 2.092955, top_1: 0.698906, top_k: 0.881563, samples/s: 778.511 1613399531.800216
train: epoch 109, iter 3800, loss: 2.218585, top_1: 0.695586, top_k: 0.880430, samples/s: 785.686 1613399564.383273
train: epoch 109, iter 3900, loss: 2.280568, top_1: 0.689609, top_k: 0.876328, samples/s: 785.766 1613399596.962898
train: epoch 109, iter 4000, loss: 2.348151, top_1: 0.700234, top_k: 0.879453, samples/s: 780.432 1613399629.7652676
train: epoch 109, iter 4100, loss: 2.249521, top_1: 0.696328, top_k: 0.879961, samples/s: 781.273 1613399662.5323617
train: epoch 109, iter 4200, loss: 2.134858, top_1: 0.692773, top_k: 0.876992, samples/s: 782.792 1613399695.2357767
train: epoch 109, iter 4300, loss: 2.378235, top_1: 0.696602, top_k: 0.879531, samples/s: 783.419 1613399727.9129536
train: epoch 109, iter 4400, loss: 2.195719, top_1: 0.696719, top_k: 0.879922, samples/s: 782.794 1613399760.6163487
train: epoch 109, iter 4500, loss: 2.188946, top_1: 0.695898, top_k: 0.878516, samples/s: 781.809 1613399793.3609555
train: epoch 109, iter 4600, loss: 2.230928, top_1: 0.696250, top_k: 0.880508, samples/s: 783.105 1613399826.0513692
train: epoch 109, iter 4700, loss: 2.066822, top_1: 0.695000, top_k: 0.880234, samples/s: 783.437 1613399858.7278872
train: epoch 109, iter 4800, loss: 2.233614, top_1: 0.699180, top_k: 0.880625, samples/s: 782.631 1613399891.438009
train: epoch 109, iter 4900, loss: 2.268554, top_1: 0.695352, top_k: 0.881484, samples/s: 782.860 1613399924.1386557
train: epoch 109, iter 5000, loss: 2.273986, top_1: 0.702109, top_k: 0.889258, samples/s: 782.868 1613399956.8388705
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_109.
validation: epoch 109, iter 195, top_1: 0.721795, top_k: 0.912159, samples/s: 2355.327 1613399978.9963424
train: epoch 110, iter 100, loss: 2.143544, top_1: 0.709961, top_k: 0.887305, samples/s: 804.487 1613400031.421178
train: epoch 110, iter 200, loss: 2.286860, top_1: 0.710898, top_k: 0.889414, samples/s: 798.521 1613400063.4805245
train: epoch 110, iter 300, loss: 2.134188, top_1: 0.709961, top_k: 0.890078, samples/s: 785.476 1613400096.0721037
train: epoch 110, iter 400, loss: 2.198192, top_1: 0.712109, top_k: 0.886680, samples/s: 780.099 1613400128.888414
train: epoch 110, iter 500, loss: 2.291021, top_1: 0.701914, top_k: 0.884102, samples/s: 781.714 1613400161.6370106
train: epoch 110, iter 600, loss: 2.399162, top_1: 0.707500, top_k: 0.885312, samples/s: 782.446 1613400194.354843
train: epoch 110, iter 700, loss: 2.197012, top_1: 0.709102, top_k: 0.886953, samples/s: 781.123 1613400227.1281888
train: epoch 110, iter 800, loss: 2.062835, top_1: 0.704141, top_k: 0.885312, samples/s: 780.727 1613400259.9182274
train: epoch 110, iter 900, loss: 2.154649, top_1: 0.703320, top_k: 0.885469, samples/s: 781.798 1613400292.66318
train: epoch 110, iter 1000, loss: 2.119794, top_1: 0.707500, top_k: 0.887148, samples/s: 780.771 1613400325.4513726
train: epoch 110, iter 1100, loss: 2.290303, top_1: 0.710313, top_k: 0.887852, samples/s: 785.536 1613400358.0404892
train: epoch 110, iter 1200, loss: 2.361830, top_1: 0.714883, top_k: 0.888437, samples/s: 780.039 1613400390.8595161
train: epoch 110, iter 1300, loss: 2.147058, top_1: 0.708828, top_k: 0.884375, samples/s: 782.688 1613400423.5672956
train: epoch 110, iter 1400, loss: 2.228916, top_1: 0.703008, top_k: 0.883477, samples/s: 784.219 1613400456.2112203
train: epoch 110, iter 1500, loss: 2.109023, top_1: 0.704414, top_k: 0.884766, samples/s: 779.330 1613400489.0598602
train: epoch 110, iter 1600, loss: 2.174745, top_1: 0.699727, top_k: 0.882617, samples/s: 783.137 1613400521.7489262
train: epoch 110, iter 1700, loss: 2.261347, top_1: 0.706875, top_k: 0.886016, samples/s: 781.714 1613400554.4974425
train: epoch 110, iter 1800, loss: 2.172119, top_1: 0.703750, top_k: 0.885547, samples/s: 780.527 1613400587.2958481
train: epoch 110, iter 1900, loss: 2.131607, top_1: 0.706016, top_k: 0.884336, samples/s: 786.000 1613400619.8657951
train: epoch 110, iter 2000, loss: 2.247510, top_1: 0.703516, top_k: 0.886328, samples/s: 781.313 1613400652.6311567
train: epoch 110, iter 2100, loss: 2.193405, top_1: 0.699922, top_k: 0.881484, samples/s: 783.220 1613400685.3168075
train: epoch 110, iter 2200, loss: 2.146104, top_1: 0.704141, top_k: 0.883711, samples/s: 780.618 1613400718.1117766
train: epoch 110, iter 2300, loss: 2.220136, top_1: 0.705156, top_k: 0.887266, samples/s: 782.209 1613400750.8391473
train: epoch 110, iter 2400, loss: 2.281928, top_1: 0.700898, top_k: 0.880195, samples/s: 781.819 1613400783.5832946
train: epoch 110, iter 2500, loss: 2.134086, top_1: 0.706875, top_k: 0.883047, samples/s: 782.638 1613400816.2931936
train: epoch 110, iter 2600, loss: 2.246908, top_1: 0.701875, top_k: 0.883594, samples/s: 782.572 1613400849.0060327
train: epoch 110, iter 2700, loss: 2.146511, top_1: 0.699258, top_k: 0.881602, samples/s: 782.663 1613400881.7146833
train: epoch 110, iter 2800, loss: 2.103777, top_1: 0.703281, top_k: 0.883828, samples/s: 784.680 1613400914.3394406
train: epoch 110, iter 2900, loss: 2.188167, top_1: 0.696367, top_k: 0.880234, samples/s: 783.906 1613400946.9964557
train: epoch 110, iter 3000, loss: 2.255236, top_1: 0.701445, top_k: 0.880742, samples/s: 782.707 1613400979.7033687
train: epoch 110, iter 3100, loss: 2.206028, top_1: 0.697500, top_k: 0.879297, samples/s: 785.068 1613401012.3120658
train: epoch 110, iter 3200, loss: 2.239030, top_1: 0.704883, top_k: 0.883359, samples/s: 783.759 1613401044.975208
train: epoch 110, iter 3300, loss: 2.144233, top_1: 0.701367, top_k: 0.882305, samples/s: 782.447 1613401077.6930718
train: epoch 110, iter 3400, loss: 2.269232, top_1: 0.702930, top_k: 0.883555, samples/s: 782.733 1613401110.3989797
train: epoch 110, iter 3500, loss: 2.162894, top_1: 0.698633, top_k: 0.880547, samples/s: 781.780 1613401143.144774
train: epoch 110, iter 3600, loss: 2.318456, top_1: 0.692500, top_k: 0.880352, samples/s: 783.625 1613401175.8134246
train: epoch 110, iter 3700, loss: 2.099719, top_1: 0.699336, top_k: 0.881484, samples/s: 781.152 1613401208.5855463
train: epoch 110, iter 3800, loss: 2.355121, top_1: 0.699492, top_k: 0.876250, samples/s: 786.311 1613401241.1426184
train: epoch 110, iter 3900, loss: 2.106250, top_1: 0.702461, top_k: 0.884805, samples/s: 781.581 1613401273.8968287
train: epoch 110, iter 4000, loss: 2.283572, top_1: 0.696836, top_k: 0.878242, samples/s: 782.034 1613401306.631844
train: epoch 110, iter 4100, loss: 2.062770, top_1: 0.697812, top_k: 0.882109, samples/s: 781.391 1613401339.3939567
train: epoch 110, iter 4200, loss: 2.302928, top_1: 0.699180, top_k: 0.881992, samples/s: 782.127 1613401372.125312
train: epoch 110, iter 4300, loss: 2.333200, top_1: 0.698750, top_k: 0.880469, samples/s: 782.336 1613401404.847796
train: epoch 110, iter 4400, loss: 2.268875, top_1: 0.701367, top_k: 0.880313, samples/s: 780.458 1613401437.6490104
train: epoch 110, iter 4500, loss: 2.213070, top_1: 0.696875, top_k: 0.883477, samples/s: 783.622 1613401470.3177884
train: epoch 110, iter 4600, loss: 2.241442, top_1: 0.703828, top_k: 0.884570, samples/s: 785.235 1613401502.9195561
train: epoch 110, iter 4700, loss: 2.304587, top_1: 0.700703, top_k: 0.880039, samples/s: 779.753 1613401535.750461
train: epoch 110, iter 4800, loss: 2.424870, top_1: 0.696875, top_k: 0.877266, samples/s: 783.584 1613401568.4208229
train: epoch 110, iter 4900, loss: 2.231101, top_1: 0.700664, top_k: 0.880000, samples/s: 785.962 1613401600.9923627
train: epoch 110, iter 5000, loss: 2.211510, top_1: 0.707305, top_k: 0.883672, samples/s: 781.789 1613401633.737821
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_110.
validation: epoch 110, iter 195, top_1: 0.728245, top_k: 0.914343, samples/s: 2362.197 1613401655.8488498
train: epoch 111, iter 100, loss: 2.117481, top_1: 0.705039, top_k: 0.885781, samples/s: 804.013 1613401708.2540705
train: epoch 111, iter 200, loss: 2.106461, top_1: 0.720000, top_k: 0.894180, samples/s: 800.550 1613401740.2322898
train: epoch 111, iter 300, loss: 2.252148, top_1: 0.711211, top_k: 0.888359, samples/s: 785.154 1613401772.8371432
train: epoch 111, iter 400, loss: 2.192960, top_1: 0.711562, top_k: 0.892266, samples/s: 780.310 1613401805.64469
train: epoch 111, iter 500, loss: 1.994488, top_1: 0.720898, top_k: 0.896758, samples/s: 781.842 1613401838.3878372
train: epoch 111, iter 600, loss: 2.272298, top_1: 0.704336, top_k: 0.883555, samples/s: 781.181 1613401871.1586974
train: epoch 111, iter 700, loss: 2.212832, top_1: 0.705313, top_k: 0.887422, samples/s: 782.655 1613401903.8679242
train: epoch 111, iter 800, loss: 2.288774, top_1: 0.711445, top_k: 0.887188, samples/s: 780.928 1613401936.6493726
train: epoch 111, iter 900, loss: 2.276007, top_1: 0.707500, top_k: 0.888008, samples/s: 782.261 1613401969.3750186
train: epoch 111, iter 1000, loss: 2.056154, top_1: 0.712500, top_k: 0.887266, samples/s: 783.309 1613402002.056818
train: epoch 111, iter 1100, loss: 2.258224, top_1: 0.705781, top_k: 0.885938, samples/s: 779.680 1613402034.890865
train: epoch 111, iter 1200, loss: 2.172250, top_1: 0.706797, top_k: 0.885898, samples/s: 780.322 1613402067.6978004
train: epoch 111, iter 1300, loss: 2.364041, top_1: 0.707617, top_k: 0.889805, samples/s: 782.861 1613402100.398444
train: epoch 111, iter 1400, loss: 2.340703, top_1: 0.706562, top_k: 0.884883, samples/s: 779.384 1613402133.2448797
train: epoch 111, iter 1500, loss: 2.344910, top_1: 0.710273, top_k: 0.883633, samples/s: 784.753 1613402165.8665612
train: epoch 111, iter 1600, loss: 2.195493, top_1: 0.708281, top_k: 0.883906, samples/s: 782.850 1613402198.5675888
train: epoch 111, iter 1700, loss: 2.257607, top_1: 0.702969, top_k: 0.883555, samples/s: 780.166 1613402231.3812218
train: epoch 111, iter 1800, loss: 2.173436, top_1: 0.706836, top_k: 0.885938, samples/s: 781.686 1613402264.1308575
train: epoch 111, iter 1900, loss: 2.224768, top_1: 0.704531, top_k: 0.884727, samples/s: 782.733 1613402296.8367746
train: epoch 111, iter 2000, loss: 2.289130, top_1: 0.708008, top_k: 0.885703, samples/s: 782.567 1613402329.5496964
train: epoch 111, iter 2100, loss: 2.424112, top_1: 0.703711, top_k: 0.886563, samples/s: 782.639 1613402362.259462
train: epoch 111, iter 2200, loss: 2.271458, top_1: 0.706719, top_k: 0.884883, samples/s: 780.793 1613402395.0467012
train: epoch 111, iter 2300, loss: 2.289563, top_1: 0.699805, top_k: 0.881797, samples/s: 783.464 1613402427.7221558
train: epoch 111, iter 2400, loss: 2.232667, top_1: 0.705195, top_k: 0.885625, samples/s: 781.730 1613402460.4699636
train: epoch 111, iter 2500, loss: 2.111580, top_1: 0.710117, top_k: 0.887695, samples/s: 782.514 1613402493.185082
train: epoch 111, iter 2600, loss: 2.230450, top_1: 0.705586, top_k: 0.882266, samples/s: 783.131 1613402525.8743844
train: epoch 111, iter 2700, loss: 2.254109, top_1: 0.703242, top_k: 0.885586, samples/s: 780.971 1613402558.6540706
train: epoch 111, iter 2800, loss: 2.213474, top_1: 0.704297, top_k: 0.882734, samples/s: 783.064 1613402591.3461967
train: epoch 111, iter 2900, loss: 2.229664, top_1: 0.702969, top_k: 0.882461, samples/s: 781.806 1613402624.090777
train: epoch 111, iter 3000, loss: 2.301164, top_1: 0.705664, top_k: 0.886094, samples/s: 782.248 1613402656.8169608
train: epoch 111, iter 3100, loss: 2.210553, top_1: 0.703984, top_k: 0.881797, samples/s: 784.145 1613402689.4639955
train: epoch 111, iter 3200, loss: 2.391294, top_1: 0.706211, top_k: 0.885195, samples/s: 783.700 1613402722.129497
train: epoch 111, iter 3300, loss: 2.042509, top_1: 0.701602, top_k: 0.886016, samples/s: 780.395 1613402754.9334984
train: epoch 111, iter 3400, loss: 2.214996, top_1: 0.699414, top_k: 0.883398, samples/s: 785.297 1613402787.5325594
train: epoch 111, iter 3500, loss: 2.140642, top_1: 0.702891, top_k: 0.883398, samples/s: 782.060 1613402820.2666125
train: epoch 111, iter 3600, loss: 2.227924, top_1: 0.699609, top_k: 0.884375, samples/s: 780.562 1613402853.0634823
train: epoch 111, iter 3700, loss: 2.031842, top_1: 0.702461, top_k: 0.885586, samples/s: 782.436 1613402885.781785
train: epoch 111, iter 3800, loss: 2.178751, top_1: 0.702266, top_k: 0.884570, samples/s: 784.843 1613402918.3998294
train: epoch 111, iter 3900, loss: 2.075062, top_1: 0.700898, top_k: 0.881602, samples/s: 779.339 1613402951.2482305
train: epoch 111, iter 4000, loss: 2.267151, top_1: 0.696250, top_k: 0.881602, samples/s: 787.675 1613402983.748879
train: epoch 111, iter 4100, loss: 2.232945, top_1: 0.700234, top_k: 0.880430, samples/s: 782.645 1613403016.4584606
train: epoch 111, iter 4200, loss: 2.266795, top_1: 0.703711, top_k: 0.883750, samples/s: 783.692 1613403049.1244478
train: epoch 111, iter 4300, loss: 2.093312, top_1: 0.700234, top_k: 0.881172, samples/s: 783.842 1613403081.7840827
train: epoch 111, iter 4400, loss: 2.193060, top_1: 0.701836, top_k: 0.884961, samples/s: 779.377 1613403114.6308208
train: epoch 111, iter 4500, loss: 2.166576, top_1: 0.700000, top_k: 0.881602, samples/s: 783.672 1613403147.2975595
train: epoch 111, iter 4600, loss: 1.981244, top_1: 0.707109, top_k: 0.885078, samples/s: 784.926 1613403179.912037
train: epoch 111, iter 4700, loss: 2.264839, top_1: 0.699805, top_k: 0.886797, samples/s: 783.798 1613403212.5734828
train: epoch 111, iter 4800, loss: 2.335143, top_1: 0.701172, top_k: 0.882852, samples/s: 782.583 1613403245.285831
train: epoch 111, iter 4900, loss: 2.196519, top_1: 0.701367, top_k: 0.880039, samples/s: 782.252 1613403278.0117831
train: epoch 111, iter 5000, loss: 2.135058, top_1: 0.702422, top_k: 0.885117, samples/s: 783.114 1613403310.7018082
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_111.
validation: epoch 111, iter 195, top_1: 0.728646, top_k: 0.914343, samples/s: 2393.796 1613403332.5179882
train: epoch 112, iter 100, loss: 2.256168, top_1: 0.711836, top_k: 0.891836, samples/s: 802.355 1613403384.98566
train: epoch 112, iter 200, loss: 2.160635, top_1: 0.705859, top_k: 0.884609, samples/s: 800.533 1613403416.9642973
train: epoch 112, iter 300, loss: 2.139818, top_1: 0.710781, top_k: 0.888242, samples/s: 786.219 1613403449.525145
train: epoch 112, iter 400, loss: 2.178118, top_1: 0.712969, top_k: 0.888828, samples/s: 781.716 1613403482.2735999
train: epoch 112, iter 500, loss: 2.240989, top_1: 0.722578, top_k: 0.891797, samples/s: 780.194 1613403515.0860364
train: epoch 112, iter 600, loss: 2.253433, top_1: 0.711836, top_k: 0.887539, samples/s: 781.588 1613403547.8399868
train: epoch 112, iter 700, loss: 2.325547, top_1: 0.713125, top_k: 0.889844, samples/s: 780.579 1613403580.636001
train: epoch 112, iter 800, loss: 2.185309, top_1: 0.716797, top_k: 0.892539, samples/s: 784.057 1613403613.2866259
train: epoch 112, iter 900, loss: 2.076573, top_1: 0.711289, top_k: 0.889961, samples/s: 782.807 1613403645.9894438
train: epoch 112, iter 1000, loss: 2.206563, top_1: 0.716328, top_k: 0.888242, samples/s: 778.433 1613403678.8760526
train: epoch 112, iter 1100, loss: 2.300080, top_1: 0.713398, top_k: 0.889570, samples/s: 785.959 1613403711.4477286
train: epoch 112, iter 1200, loss: 2.065858, top_1: 0.712891, top_k: 0.888281, samples/s: 779.204 1613403744.3017511
train: epoch 112, iter 1300, loss: 2.369797, top_1: 0.711328, top_k: 0.886602, samples/s: 784.051 1613403776.9527063
train: epoch 112, iter 1400, loss: 2.326308, top_1: 0.708555, top_k: 0.887188, samples/s: 780.227 1613403809.763798
train: epoch 112, iter 1500, loss: 2.145002, top_1: 0.708125, top_k: 0.887773, samples/s: 781.272 1613403842.530674
train: epoch 112, iter 1600, loss: 2.122749, top_1: 0.705586, top_k: 0.884453, samples/s: 783.058 1613403875.2230456
train: epoch 112, iter 1700, loss: 2.337353, top_1: 0.709805, top_k: 0.884570, samples/s: 781.372 1613403907.9859014
train: epoch 112, iter 1800, loss: 2.031690, top_1: 0.713516, top_k: 0.888437, samples/s: 781.391 1613403940.7480154
train: epoch 112, iter 1900, loss: 2.253718, top_1: 0.714375, top_k: 0.891914, samples/s: 782.727 1613403973.4542077
train: epoch 112, iter 2000, loss: 2.286361, top_1: 0.711289, top_k: 0.889219, samples/s: 781.311 1613404006.219659
train: epoch 112, iter 2100, loss: 2.297808, top_1: 0.706758, top_k: 0.887383, samples/s: 784.100 1613404038.8685026
train: epoch 112, iter 2200, loss: 2.249540, top_1: 0.702461, top_k: 0.887383, samples/s: 779.427 1613404071.7132428
train: epoch 112, iter 2300, loss: 2.208001, top_1: 0.708086, top_k: 0.884492, samples/s: 783.638 1613404104.381366
train: epoch 112, iter 2400, loss: 2.149718, top_1: 0.703789, top_k: 0.885859, samples/s: 781.752 1613404137.1282282
train: epoch 112, iter 2500, loss: 2.226330, top_1: 0.703125, top_k: 0.885117, samples/s: 783.615 1613404169.7973027
train: epoch 112, iter 2600, loss: 2.344319, top_1: 0.705586, top_k: 0.884453, samples/s: 784.664 1613404202.4227111
train: epoch 112, iter 2700, loss: 2.331270, top_1: 0.707656, top_k: 0.886992, samples/s: 782.877 1613404235.1226757
train: epoch 112, iter 2800, loss: 2.176436, top_1: 0.709180, top_k: 0.886172, samples/s: 784.462 1613404267.7564456
train: epoch 112, iter 2900, loss: 2.171152, top_1: 0.710156, top_k: 0.886953, samples/s: 782.281 1613404300.4812238
train: epoch 112, iter 3000, loss: 2.220811, top_1: 0.704453, top_k: 0.886055, samples/s: 786.009 1613404333.0507996
train: epoch 112, iter 3100, loss: 2.184231, top_1: 0.707305, top_k: 0.887383, samples/s: 781.163 1613404365.8224702
train: epoch 112, iter 3200, loss: 2.240697, top_1: 0.704961, top_k: 0.885938, samples/s: 782.205 1613404398.5504732
train: epoch 112, iter 3300, loss: 2.106951, top_1: 0.705352, top_k: 0.885156, samples/s: 783.116 1613404431.2403915
train: epoch 112, iter 3400, loss: 2.274158, top_1: 0.705781, top_k: 0.887227, samples/s: 783.037 1613404463.933687
train: epoch 112, iter 3500, loss: 2.124482, top_1: 0.704258, top_k: 0.884766, samples/s: 784.645 1613404496.5598495
train: epoch 112, iter 3600, loss: 2.351646, top_1: 0.698984, top_k: 0.883125, samples/s: 780.479 1613404529.3603005
train: epoch 112, iter 3700, loss: 2.184932, top_1: 0.704180, top_k: 0.885977, samples/s: 782.144 1613404562.0908036
train: epoch 112, iter 3800, loss: 2.112401, top_1: 0.705234, top_k: 0.885820, samples/s: 781.488 1613404594.8488674
train: epoch 112, iter 3900, loss: 2.253371, top_1: 0.699961, top_k: 0.880547, samples/s: 782.542 1613404627.562705
train: epoch 112, iter 4000, loss: 2.287276, top_1: 0.707461, top_k: 0.887344, samples/s: 783.582 1613404660.2332006
train: epoch 112, iter 4100, loss: 2.225085, top_1: 0.704492, top_k: 0.883945, samples/s: 779.494 1613404693.0750828
train: epoch 112, iter 4200, loss: 2.115236, top_1: 0.705039, top_k: 0.887539, samples/s: 784.030 1613404725.7268975
train: epoch 112, iter 4300, loss: 2.299078, top_1: 0.698672, top_k: 0.878789, samples/s: 782.035 1613404758.4619231
train: epoch 112, iter 4400, loss: 2.158301, top_1: 0.705977, top_k: 0.886563, samples/s: 782.358 1613404791.1835399
train: epoch 112, iter 4500, loss: 2.384844, top_1: 0.702539, top_k: 0.882969, samples/s: 784.237 1613404823.8268266
train: epoch 112, iter 4600, loss: 2.303048, top_1: 0.699961, top_k: 0.884336, samples/s: 781.856 1613404856.56938
train: epoch 112, iter 4700, loss: 2.235567, top_1: 0.703672, top_k: 0.881602, samples/s: 781.213 1613404889.338908
train: epoch 112, iter 4800, loss: 2.252819, top_1: 0.702852, top_k: 0.883477, samples/s: 783.440 1613404922.0153713
train: epoch 112, iter 4900, loss: 2.098166, top_1: 0.699805, top_k: 0.884023, samples/s: 781.203 1613404954.785235
train: epoch 112, iter 5000, loss: 2.207903, top_1: 0.707812, top_k: 0.886914, samples/s: 783.164 1613404987.4732308
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_112.
validation: epoch 112, iter 195, top_1: 0.730669, top_k: 0.915885, samples/s: 2366.889 1613405009.5448916
train: epoch 113, iter 100, loss: 2.207129, top_1: 0.718945, top_k: 0.890977, samples/s: 803.965 1613405062.2154973
train: epoch 113, iter 200, loss: 2.263624, top_1: 0.719805, top_k: 0.895352, samples/s: 801.260 1613405094.1651282
train: epoch 113, iter 300, loss: 2.201613, top_1: 0.720430, top_k: 0.891953, samples/s: 785.927 1613405126.738137
train: epoch 113, iter 400, loss: 2.092000, top_1: 0.718125, top_k: 0.891016, samples/s: 780.730 1613405159.527911
train: epoch 113, iter 500, loss: 2.179961, top_1: 0.719414, top_k: 0.894531, samples/s: 784.565 1613405192.1575716
train: epoch 113, iter 600, loss: 2.083689, top_1: 0.714922, top_k: 0.891016, samples/s: 781.513 1613405224.9144049
train: epoch 113, iter 700, loss: 2.189911, top_1: 0.710859, top_k: 0.889609, samples/s: 781.653 1613405257.665589
train: epoch 113, iter 800, loss: 2.331785, top_1: 0.715156, top_k: 0.892266, samples/s: 778.881 1613405290.5332608
train: epoch 113, iter 900, loss: 2.082468, top_1: 0.718867, top_k: 0.893555, samples/s: 782.592 1613405323.2450693
train: epoch 113, iter 1000, loss: 2.243801, top_1: 0.711406, top_k: 0.890664, samples/s: 775.350 1613405356.2624202
train: epoch 113, iter 1100, loss: 2.107424, top_1: 0.711836, top_k: 0.891602, samples/s: 790.013 1613405388.666982
train: epoch 113, iter 1200, loss: 2.250624, top_1: 0.711914, top_k: 0.887188, samples/s: 781.072 1613405421.442392
train: epoch 113, iter 1300, loss: 2.165669, top_1: 0.713086, top_k: 0.887188, samples/s: 780.608 1613405454.2373834
train: epoch 113, iter 1400, loss: 2.145205, top_1: 0.711992, top_k: 0.890391, samples/s: 779.147 1613405487.093812
train: epoch 113, iter 1500, loss: 2.243704, top_1: 0.705117, top_k: 0.885469, samples/s: 781.255 1613405519.8615825
train: epoch 113, iter 1600, loss: 1.956446, top_1: 0.712695, top_k: 0.888867, samples/s: 781.383 1613405552.624003
train: epoch 113, iter 1700, loss: 2.164730, top_1: 0.708242, top_k: 0.887227, samples/s: 781.782 1613405585.3697045
train: epoch 113, iter 1800, loss: 2.262958, top_1: 0.707227, top_k: 0.886797, samples/s: 782.211 1613405618.097426
train: epoch 113, iter 1900, loss: 2.081623, top_1: 0.711797, top_k: 0.886680, samples/s: 781.986 1613405650.8345633
train: epoch 113, iter 2000, loss: 2.241229, top_1: 0.707695, top_k: 0.887500, samples/s: 781.347 1613405683.5985572
train: epoch 113, iter 2100, loss: 2.204184, top_1: 0.711211, top_k: 0.889180, samples/s: 784.119 1613405716.2466953
train: epoch 113, iter 2200, loss: 2.022158, top_1: 0.707187, top_k: 0.885352, samples/s: 779.613 1613405749.083489
train: epoch 113, iter 2300, loss: 2.205299, top_1: 0.708086, top_k: 0.888125, samples/s: 783.762 1613405781.7464058
train: epoch 113, iter 2400, loss: 2.066883, top_1: 0.714258, top_k: 0.889258, samples/s: 781.510 1613405814.5034869
train: epoch 113, iter 2500, loss: 2.239727, top_1: 0.709258, top_k: 0.886680, samples/s: 783.212 1613405847.1895003
train: epoch 113, iter 2600, loss: 2.204017, top_1: 0.706133, top_k: 0.889648, samples/s: 782.467 1613405879.9064744
train: epoch 113, iter 2700, loss: 2.165123, top_1: 0.713320, top_k: 0.892695, samples/s: 783.298 1613405912.5888534
train: epoch 113, iter 2800, loss: 2.110481, top_1: 0.710586, top_k: 0.889453, samples/s: 781.969 1613405945.3266387
train: epoch 113, iter 2900, loss: 2.121233, top_1: 0.710430, top_k: 0.890273, samples/s: 785.727 1613405977.9079652
train: epoch 113, iter 3000, loss: 2.068743, top_1: 0.704805, top_k: 0.884375, samples/s: 781.097 1613406010.6823957
train: epoch 113, iter 3100, loss: 2.281201, top_1: 0.708555, top_k: 0.884883, samples/s: 785.678 1613406043.265744
train: epoch 113, iter 3200, loss: 2.278922, top_1: 0.705898, top_k: 0.886055, samples/s: 780.903 1613406076.0482104
train: epoch 113, iter 3300, loss: 2.011228, top_1: 0.708164, top_k: 0.888477, samples/s: 782.937 1613406108.7457063
train: epoch 113, iter 3400, loss: 2.239326, top_1: 0.706016, top_k: 0.883281, samples/s: 784.051 1613406141.3965478
train: epoch 113, iter 3500, loss: 2.396938, top_1: 0.705703, top_k: 0.882891, samples/s: 784.069 1613406174.0468268
train: epoch 113, iter 3600, loss: 2.144782, top_1: 0.708906, top_k: 0.885469, samples/s: 783.712 1613406206.7118843
train: epoch 113, iter 3700, loss: 2.054620, top_1: 0.711836, top_k: 0.887734, samples/s: 781.466 1613406239.4707978
train: epoch 113, iter 3800, loss: 2.308461, top_1: 0.708438, top_k: 0.887227, samples/s: 783.517 1613406272.1440413
train: epoch 113, iter 3900, loss: 2.237911, top_1: 0.707422, top_k: 0.886328, samples/s: 784.557 1613406304.7738967
train: epoch 113, iter 4000, loss: 2.249085, top_1: 0.707344, top_k: 0.887305, samples/s: 782.824 1613406337.4759443
train: epoch 113, iter 4100, loss: 2.159596, top_1: 0.704297, top_k: 0.889023, samples/s: 782.783 1613406370.1797829
train: epoch 113, iter 4200, loss: 2.258460, top_1: 0.706992, top_k: 0.887031, samples/s: 783.713 1613406402.8448436
train: epoch 113, iter 4300, loss: 2.032604, top_1: 0.709219, top_k: 0.886641, samples/s: 783.526 1613406435.5176988
train: epoch 113, iter 4400, loss: 2.225624, top_1: 0.710117, top_k: 0.886406, samples/s: 785.413 1613406468.111963
train: epoch 113, iter 4500, loss: 2.304742, top_1: 0.699414, top_k: 0.885312, samples/s: 781.873 1613406500.8538535
train: epoch 113, iter 4600, loss: 2.250756, top_1: 0.703242, top_k: 0.882500, samples/s: 782.951 1613406533.550643
train: epoch 113, iter 4700, loss: 2.106456, top_1: 0.703633, top_k: 0.883320, samples/s: 781.222 1613406566.3200026
train: epoch 113, iter 4800, loss: 2.237706, top_1: 0.705156, top_k: 0.884844, samples/s: 782.632 1613406599.0300043
train: epoch 113, iter 4900, loss: 2.162366, top_1: 0.708242, top_k: 0.882812, samples/s: 783.514 1613406631.7033968
train: epoch 113, iter 5000, loss: 2.070546, top_1: 0.716758, top_k: 0.888203, samples/s: 784.985 1613406664.3153946
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_113.
validation: epoch 113, iter 195, top_1: 0.731811, top_k: 0.915946, samples/s: 2347.913 1613406686.5585577
train: epoch 114, iter 100, loss: 2.199048, top_1: 0.718672, top_k: 0.891094, samples/s: 803.872 1613406738.9717762
train: epoch 114, iter 200, loss: 2.075879, top_1: 0.721055, top_k: 0.894492, samples/s: 800.585 1613406770.9482698
train: epoch 114, iter 300, loss: 2.243673, top_1: 0.724766, top_k: 0.895039, samples/s: 785.808 1613406803.5263574
train: epoch 114, iter 400, loss: 2.138576, top_1: 0.714609, top_k: 0.889844, samples/s: 780.376 1613406836.330912
train: epoch 114, iter 500, loss: 2.150113, top_1: 0.716367, top_k: 0.891484, samples/s: 781.867 1613406869.0730927
train: epoch 114, iter 600, loss: 2.125287, top_1: 0.712969, top_k: 0.888359, samples/s: 783.536 1613406901.7454019
train: epoch 114, iter 700, loss: 2.237540, top_1: 0.714766, top_k: 0.891406, samples/s: 781.717 1613406934.4938433
train: epoch 114, iter 800, loss: 1.961108, top_1: 0.719219, top_k: 0.890938, samples/s: 781.365 1613406967.257111
train: epoch 114, iter 900, loss: 2.192224, top_1: 0.716406, top_k: 0.890625, samples/s: 781.790 1613407000.002464
train: epoch 114, iter 1000, loss: 2.260053, top_1: 0.716445, top_k: 0.891211, samples/s: 783.297 1613407032.6847405
train: epoch 114, iter 1100, loss: 2.283585, top_1: 0.718555, top_k: 0.891211, samples/s: 782.017 1613407065.4207568
train: epoch 114, iter 1200, loss: 2.135376, top_1: 0.714727, top_k: 0.892930, samples/s: 781.057 1613407098.1966898
train: epoch 114, iter 1300, loss: 2.018063, top_1: 0.714102, top_k: 0.889180, samples/s: 783.376 1613407130.8757846
train: epoch 114, iter 1400, loss: 2.222238, top_1: 0.723359, top_k: 0.891406, samples/s: 780.919 1613407163.6577032
train: epoch 114, iter 1500, loss: 2.413244, top_1: 0.713516, top_k: 0.890039, samples/s: 784.126 1613407196.305484
train: epoch 114, iter 1600, loss: 2.190628, top_1: 0.718828, top_k: 0.892695, samples/s: 784.405 1613407228.9417553
train: epoch 114, iter 1700, loss: 2.155059, top_1: 0.715586, top_k: 0.890938, samples/s: 782.637 1613407261.6516128
train: epoch 114, iter 1800, loss: 2.154588, top_1: 0.705234, top_k: 0.887266, samples/s: 783.978 1613407294.3056707
train: epoch 114, iter 1900, loss: 2.140943, top_1: 0.714883, top_k: 0.888828, samples/s: 781.060 1613407327.0815704
train: epoch 114, iter 2000, loss: 2.104798, top_1: 0.712500, top_k: 0.889180, samples/s: 785.866 1613407359.6571026
train: epoch 114, iter 2100, loss: 2.050498, top_1: 0.711016, top_k: 0.889336, samples/s: 783.558 1613407392.328536
train: epoch 114, iter 2200, loss: 2.114390, top_1: 0.713828, top_k: 0.891680, samples/s: 782.070 1613407425.0622096
train: epoch 114, iter 2300, loss: 2.136934, top_1: 0.709258, top_k: 0.886094, samples/s: 780.227 1613407457.873156
train: epoch 114, iter 2400, loss: 2.141359, top_1: 0.711914, top_k: 0.889570, samples/s: 784.763 1613407490.4945433
train: epoch 114, iter 2500, loss: 2.244708, top_1: 0.714453, top_k: 0.888437, samples/s: 784.196 1613407523.1394892
train: epoch 114, iter 2600, loss: 2.381957, top_1: 0.712266, top_k: 0.887813, samples/s: 782.703 1613407555.8466198
train: epoch 114, iter 2700, loss: 2.325323, top_1: 0.708398, top_k: 0.886406, samples/s: 781.146 1613407588.618966
train: epoch 114, iter 2800, loss: 2.187658, top_1: 0.707734, top_k: 0.890000, samples/s: 785.259 1613407621.219693
train: epoch 114, iter 2900, loss: 2.233191, top_1: 0.707891, top_k: 0.886172, samples/s: 780.651 1613407654.0127704
train: epoch 114, iter 3000, loss: 2.276540, top_1: 0.710781, top_k: 0.888008, samples/s: 784.584 1613407686.6415894
train: epoch 114, iter 3100, loss: 2.188104, top_1: 0.715195, top_k: 0.891406, samples/s: 780.952 1613407719.4221373
train: epoch 114, iter 3200, loss: 2.267224, top_1: 0.712734, top_k: 0.889844, samples/s: 783.550 1613407752.0939713
train: epoch 114, iter 3300, loss: 2.252176, top_1: 0.706250, top_k: 0.883828, samples/s: 782.848 1613407784.795044
train: epoch 114, iter 3400, loss: 2.242907, top_1: 0.709961, top_k: 0.887695, samples/s: 782.456 1613407817.512436
train: epoch 114, iter 3500, loss: 2.245480, top_1: 0.711328, top_k: 0.888437, samples/s: 784.964 1613407850.1254344
train: epoch 114, iter 3600, loss: 2.247468, top_1: 0.709141, top_k: 0.889414, samples/s: 782.643 1613407882.835192
train: epoch 114, iter 3700, loss: 2.204284, top_1: 0.708711, top_k: 0.887930, samples/s: 785.217 1613407915.4375763
train: epoch 114, iter 3800, loss: 2.234895, top_1: 0.712695, top_k: 0.890742, samples/s: 780.729 1613407948.2275054
train: epoch 114, iter 3900, loss: 2.206829, top_1: 0.708984, top_k: 0.891016, samples/s: 783.171 1613407980.9151206
train: epoch 114, iter 4000, loss: 2.137514, top_1: 0.709531, top_k: 0.886680, samples/s: 781.978 1613408013.6526036
train: epoch 114, iter 4100, loss: 2.101842, top_1: 0.708242, top_k: 0.887695, samples/s: 785.480 1613408046.2441597
train: epoch 114, iter 4200, loss: 2.325298, top_1: 0.711367, top_k: 0.887461, samples/s: 782.737 1613408078.9497821
train: epoch 114, iter 4300, loss: 2.096280, top_1: 0.707187, top_k: 0.887266, samples/s: 781.742 1613408111.6972222
train: epoch 114, iter 4400, loss: 2.245319, top_1: 0.710898, top_k: 0.888047, samples/s: 783.627 1613408144.365798
train: epoch 114, iter 4500, loss: 2.220691, top_1: 0.707500, top_k: 0.885977, samples/s: 784.254 1613408177.0082996
train: epoch 114, iter 4600, loss: 2.074385, top_1: 0.713906, top_k: 0.889375, samples/s: 786.189 1613408209.570501
train: epoch 114, iter 4700, loss: 2.135425, top_1: 0.709453, top_k: 0.887188, samples/s: 783.366 1613408242.2498848
train: epoch 114, iter 4800, loss: 2.167552, top_1: 0.714922, top_k: 0.889297, samples/s: 782.650 1613408274.9592795
train: epoch 114, iter 4900, loss: 2.336164, top_1: 0.710625, top_k: 0.887461, samples/s: 785.966 1613408307.5307388
train: epoch 114, iter 5000, loss: 2.219482, top_1: 0.718281, top_k: 0.891406, samples/s: 783.767 1613408340.193433
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_114.
validation: epoch 114, iter 195, top_1: 0.736338, top_k: 0.917448, samples/s: 2384.288 1613408362.104057
train: epoch 115, iter 100, loss: 2.150859, top_1: 0.720430, top_k: 0.895938, samples/s: 804.923 1613408414.3056047
train: epoch 115, iter 200, loss: 2.057750, top_1: 0.722617, top_k: 0.891484, samples/s: 800.548 1613408446.2837408
train: epoch 115, iter 300, loss: 2.101214, top_1: 0.722148, top_k: 0.894180, samples/s: 785.885 1613408478.8584547
train: epoch 115, iter 400, loss: 2.123432, top_1: 0.719922, top_k: 0.893984, samples/s: 781.628 1613408511.6107855
train: epoch 115, iter 500, loss: 2.200267, top_1: 0.724688, top_k: 0.893008, samples/s: 783.285 1613408544.2934177
train: epoch 115, iter 600, loss: 2.264969, top_1: 0.721836, top_k: 0.893672, samples/s: 782.696 1613408577.000948
train: epoch 115, iter 700, loss: 2.278932, top_1: 0.717266, top_k: 0.888555, samples/s: 780.120 1613408609.8164282
train: epoch 115, iter 800, loss: 2.122824, top_1: 0.723477, top_k: 0.893437, samples/s: 787.131 1613408642.339614
train: epoch 115, iter 900, loss: 2.088392, top_1: 0.716680, top_k: 0.892266, samples/s: 779.626 1613408675.175883
train: epoch 115, iter 1000, loss: 1.984619, top_1: 0.718047, top_k: 0.893125, samples/s: 782.797 1613408707.879206
train: epoch 115, iter 1100, loss: 2.177133, top_1: 0.718398, top_k: 0.889922, samples/s: 784.901 1613408740.494603
train: epoch 115, iter 1200, loss: 2.146001, top_1: 0.715742, top_k: 0.891563, samples/s: 782.192 1613408773.2231853
train: epoch 115, iter 1300, loss: 2.193174, top_1: 0.718008, top_k: 0.895625, samples/s: 783.826 1613408805.8835194
train: epoch 115, iter 1400, loss: 2.108367, top_1: 0.722500, top_k: 0.893203, samples/s: 783.127 1613408838.5728889
train: epoch 115, iter 1500, loss: 2.088223, top_1: 0.723828, top_k: 0.894375, samples/s: 781.769 1613408871.319239
train: epoch 115, iter 1600, loss: 2.135800, top_1: 0.713633, top_k: 0.891641, samples/s: 784.532 1613408903.9500997
train: epoch 115, iter 1700, loss: 2.056200, top_1: 0.714297, top_k: 0.889766, samples/s: 783.237 1613408936.6350522
train: epoch 115, iter 1800, loss: 2.208671, top_1: 0.713164, top_k: 0.894180, samples/s: 786.217 1613408969.1959543
train: epoch 115, iter 1900, loss: 2.193114, top_1: 0.721914, top_k: 0.890352, samples/s: 783.005 1613409001.8905344
train: epoch 115, iter 2000, loss: 2.014812, top_1: 0.715000, top_k: 0.891250, samples/s: 784.294 1613409034.5313911
train: epoch 115, iter 2100, loss: 2.274056, top_1: 0.719219, top_k: 0.890352, samples/s: 783.633 1613409067.1997132
train: epoch 115, iter 2200, loss: 2.206304, top_1: 0.712422, top_k: 0.887852, samples/s: 786.783 1613409099.7372894
train: epoch 115, iter 2300, loss: 2.217520, top_1: 0.719063, top_k: 0.893984, samples/s: 782.403 1613409132.456994
train: epoch 115, iter 2400, loss: 2.025715, top_1: 0.715859, top_k: 0.893594, samples/s: 784.846 1613409165.0748172
train: epoch 115, iter 2500, loss: 2.165941, top_1: 0.714766, top_k: 0.890352, samples/s: 783.139 1613409197.7638173
train: epoch 115, iter 2600, loss: 2.290860, top_1: 0.712109, top_k: 0.888281, samples/s: 783.975 1613409230.4179556
train: epoch 115, iter 2700, loss: 2.155030, top_1: 0.717812, top_k: 0.893711, samples/s: 785.695 1613409263.00054
train: epoch 115, iter 2800, loss: 2.144539, top_1: 0.714219, top_k: 0.892227, samples/s: 782.840 1613409295.702005
train: epoch 115, iter 2900, loss: 2.192257, top_1: 0.718398, top_k: 0.890156, samples/s: 784.440 1613409328.336828
train: epoch 115, iter 3000, loss: 2.266077, top_1: 0.712773, top_k: 0.889570, samples/s: 785.497 1613409360.9275973
train: epoch 115, iter 3100, loss: 2.188588, top_1: 0.706680, top_k: 0.888672, samples/s: 783.722 1613409393.5922647
train: epoch 115, iter 3200, loss: 2.116635, top_1: 0.716797, top_k: 0.891016, samples/s: 785.444 1613409426.1853125
train: epoch 115, iter 3300, loss: 2.054118, top_1: 0.715938, top_k: 0.892734, samples/s: 782.985 1613409458.8806791
train: epoch 115, iter 3400, loss: 2.122680, top_1: 0.720234, top_k: 0.892266, samples/s: 784.266 1613409491.5226707
train: epoch 115, iter 3500, loss: 2.247565, top_1: 0.716367, top_k: 0.888555, samples/s: 784.060 1613409524.1732223
train: epoch 115, iter 3600, loss: 2.354975, top_1: 0.716641, top_k: 0.891406, samples/s: 785.474 1613409556.7649677
train: epoch 115, iter 3700, loss: 2.255296, top_1: 0.712695, top_k: 0.891641, samples/s: 782.068 1613409589.498676
train: epoch 115, iter 3800, loss: 2.155235, top_1: 0.711172, top_k: 0.888750, samples/s: 784.285 1613409622.139975
train: epoch 115, iter 3900, loss: 2.182523, top_1: 0.711016, top_k: 0.887852, samples/s: 783.360 1613409654.8196387
train: epoch 115, iter 4000, loss: 2.234517, top_1: 0.713516, top_k: 0.892539, samples/s: 782.424 1613409687.5385647
train: epoch 115, iter 4100, loss: 2.104141, top_1: 0.716875, top_k: 0.892070, samples/s: 783.541 1613409720.210693
train: epoch 115, iter 4200, loss: 2.204346, top_1: 0.712812, top_k: 0.888437, samples/s: 784.110 1613409752.8592436
train: epoch 115, iter 4300, loss: 2.310715, top_1: 0.709219, top_k: 0.886484, samples/s: 784.819 1613409785.478151
train: epoch 115, iter 4400, loss: 2.210716, top_1: 0.709727, top_k: 0.888867, samples/s: 780.550 1613409818.2755318
train: epoch 115, iter 4500, loss: 2.092761, top_1: 0.710156, top_k: 0.886055, samples/s: 783.272 1613409850.959002
train: epoch 115, iter 4600, loss: 2.164020, top_1: 0.710352, top_k: 0.886836, samples/s: 783.449 1613409883.6350088
train: epoch 115, iter 4700, loss: 2.172407, top_1: 0.712344, top_k: 0.888867, samples/s: 784.599 1613409916.263157
train: epoch 115, iter 4800, loss: 2.138953, top_1: 0.717148, top_k: 0.889219, samples/s: 783.654 1613409948.9307566
train: epoch 115, iter 4900, loss: 2.169538, top_1: 0.707344, top_k: 0.886211, samples/s: 785.026 1613409981.54105
train: epoch 115, iter 5000, loss: 2.193935, top_1: 0.719023, top_k: 0.892813, samples/s: 784.423 1613410014.1764688
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_115.
validation: epoch 115, iter 195, top_1: 0.734756, top_k: 0.916947, samples/s: 2348.984 1613410036.390617
train: epoch 116, iter 100, loss: 2.339674, top_1: 0.729844, top_k: 0.897344, samples/s: 803.678 1613410088.8945174
train: epoch 116, iter 200, loss: 2.077820, top_1: 0.727539, top_k: 0.898945, samples/s: 800.895 1613410120.8590367
train: epoch 116, iter 300, loss: 2.096208, top_1: 0.729805, top_k: 0.898555, samples/s: 785.485 1613410153.4500868
train: epoch 116, iter 400, loss: 2.216481, top_1: 0.723633, top_k: 0.894609, samples/s: 783.731 1613410186.1143444
train: epoch 116, iter 500, loss: 2.081962, top_1: 0.725938, top_k: 0.895820, samples/s: 781.887 1613410218.8556328
train: epoch 116, iter 600, loss: 2.124330, top_1: 0.722344, top_k: 0.892969, samples/s: 778.739 1613410251.7293272
train: epoch 116, iter 700, loss: 1.994893, top_1: 0.728320, top_k: 0.896992, samples/s: 784.143 1613410284.3763885
train: epoch 116, iter 800, loss: 2.119520, top_1: 0.721211, top_k: 0.894687, samples/s: 780.086 1613410317.1933577
train: epoch 116, iter 900, loss: 2.077796, top_1: 0.725156, top_k: 0.896055, samples/s: 783.604 1613410349.8630085
train: epoch 116, iter 1000, loss: 2.135777, top_1: 0.725586, top_k: 0.896445, samples/s: 782.195 1613410382.5913403
train: epoch 116, iter 1100, loss: 2.180933, top_1: 0.723828, top_k: 0.897461, samples/s: 780.667 1613410415.3838363
train: epoch 116, iter 1200, loss: 2.057007, top_1: 0.722695, top_k: 0.893477, samples/s: 781.732 1613410448.1316395
train: epoch 116, iter 1300, loss: 2.179111, top_1: 0.723242, top_k: 0.895586, samples/s: 787.905 1613410480.622856
train: epoch 116, iter 1400, loss: 2.237656, top_1: 0.722969, top_k: 0.893672, samples/s: 781.199 1613410513.3929813
train: epoch 116, iter 1500, loss: 2.136037, top_1: 0.714414, top_k: 0.887656, samples/s: 782.579 1613410546.1054196
train: epoch 116, iter 1600, loss: 2.116662, top_1: 0.718867, top_k: 0.892305, samples/s: 784.773 1613410578.7262166
train: epoch 116, iter 1700, loss: 2.247923, top_1: 0.717031, top_k: 0.891836, samples/s: 784.760 1613410611.3477206
train: epoch 116, iter 1800, loss: 2.100264, top_1: 0.718125, top_k: 0.891602, samples/s: 782.355 1613410644.0694392
train: epoch 116, iter 1900, loss: 2.356146, top_1: 0.718555, top_k: 0.892695, samples/s: 783.189 1613410676.7562625
train: epoch 116, iter 2000, loss: 2.283835, top_1: 0.718750, top_k: 0.894414, samples/s: 784.357 1613410709.3943841
train: epoch 116, iter 2100, loss: 2.159178, top_1: 0.720117, top_k: 0.893711, samples/s: 780.281 1613410742.2030728
train: epoch 116, iter 2200, loss: 2.165476, top_1: 0.713281, top_k: 0.886875, samples/s: 787.182 1613410774.7242954
train: epoch 116, iter 2300, loss: 2.221919, top_1: 0.721250, top_k: 0.892539, samples/s: 783.282 1613410807.4072428
train: epoch 116, iter 2400, loss: 2.038247, top_1: 0.717148, top_k: 0.892148, samples/s: 785.788 1613410839.9859128
train: epoch 116, iter 2500, loss: 2.383246, top_1: 0.716523, top_k: 0.889648, samples/s: 782.598 1613410872.69757
train: epoch 116, iter 2600, loss: 2.043080, top_1: 0.717812, top_k: 0.891172, samples/s: 782.013 1613410905.4335382
train: epoch 116, iter 2700, loss: 2.177473, top_1: 0.724375, top_k: 0.897031, samples/s: 783.504 1613410938.1073067
train: epoch 116, iter 2800, loss: 2.089764, top_1: 0.718789, top_k: 0.893750, samples/s: 783.569 1613410970.7783217
train: epoch 116, iter 2900, loss: 1.959750, top_1: 0.720039, top_k: 0.895625, samples/s: 781.770 1613411003.5245864
train: epoch 116, iter 3000, loss: 2.165816, top_1: 0.719648, top_k: 0.889531, samples/s: 784.202 1613411036.1692314
train: epoch 116, iter 3100, loss: 2.060770, top_1: 0.713750, top_k: 0.890117, samples/s: 783.864 1613411068.8278625
train: epoch 116, iter 3200, loss: 2.129585, top_1: 0.720742, top_k: 0.893047, samples/s: 783.957 1613411101.482743
train: epoch 116, iter 3300, loss: 2.160942, top_1: 0.722773, top_k: 0.892305, samples/s: 784.431 1613411134.117809
train: epoch 116, iter 3400, loss: 2.087283, top_1: 0.717930, top_k: 0.893398, samples/s: 782.461 1613411166.8351316
train: epoch 116, iter 3500, loss: 2.098886, top_1: 0.716016, top_k: 0.892266, samples/s: 783.889 1613411199.4928472
train: epoch 116, iter 3600, loss: 1.988593, top_1: 0.717891, top_k: 0.892109, samples/s: 781.876 1613411232.2345998
train: epoch 116, iter 3700, loss: 2.294626, top_1: 0.721680, top_k: 0.892266, samples/s: 782.659 1613411264.9436424
train: epoch 116, iter 3800, loss: 2.202095, top_1: 0.715977, top_k: 0.891406, samples/s: 783.916 1613411297.6001008
train: epoch 116, iter 3900, loss: 2.041145, top_1: 0.714961, top_k: 0.891680, samples/s: 781.067 1613411330.375874
train: epoch 116, iter 4000, loss: 2.144066, top_1: 0.713867, top_k: 0.889336, samples/s: 783.335 1613411363.056675
train: epoch 116, iter 4100, loss: 2.109651, top_1: 0.715703, top_k: 0.890508, samples/s: 782.878 1613411395.7565444
train: epoch 116, iter 4200, loss: 2.123073, top_1: 0.717109, top_k: 0.892070, samples/s: 784.358 1613411428.394578
train: epoch 116, iter 4300, loss: 2.087124, top_1: 0.712656, top_k: 0.890273, samples/s: 782.242 1613411461.1210735
train: epoch 116, iter 4400, loss: 2.109294, top_1: 0.714531, top_k: 0.892617, samples/s: 784.079 1613411493.7707915
train: epoch 116, iter 4500, loss: 2.170535, top_1: 0.714883, top_k: 0.889180, samples/s: 781.663 1613411526.5215027
train: epoch 116, iter 4600, loss: 2.246906, top_1: 0.711914, top_k: 0.891172, samples/s: 785.783 1613411559.100509
train: epoch 116, iter 4700, loss: 2.345248, top_1: 0.720508, top_k: 0.891406, samples/s: 780.792 1613411591.8876557
train: epoch 116, iter 4800, loss: 2.194929, top_1: 0.718555, top_k: 0.889102, samples/s: 784.271 1613411624.5294771
train: epoch 116, iter 4900, loss: 2.246308, top_1: 0.712227, top_k: 0.889180, samples/s: 783.547 1613411657.2014143
train: epoch 116, iter 5000, loss: 2.110528, top_1: 0.729609, top_k: 0.896484, samples/s: 781.699 1613411689.9505363
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_116.
validation: epoch 116, iter 195, top_1: 0.738381, top_k: 0.918790, samples/s: 2361.985 1613411712.072515
train: epoch 117, iter 100, loss: 2.146957, top_1: 0.732109, top_k: 0.900820, samples/s: 805.897 1613411764.914273
train: epoch 117, iter 200, loss: 2.117840, top_1: 0.731016, top_k: 0.896836, samples/s: 801.785 1613411796.8430076
train: epoch 117, iter 300, loss: 2.171073, top_1: 0.733125, top_k: 0.901328, samples/s: 785.974 1613411829.4140415
train: epoch 117, iter 400, loss: 2.145573, top_1: 0.726523, top_k: 0.894492, samples/s: 782.027 1613411862.1495306
train: epoch 117, iter 500, loss: 2.133862, top_1: 0.728086, top_k: 0.896836, samples/s: 781.137 1613411894.9222581
train: epoch 117, iter 600, loss: 2.020518, top_1: 0.724023, top_k: 0.895664, samples/s: 782.891 1613411927.6215513
train: epoch 117, iter 700, loss: 2.107268, top_1: 0.724258, top_k: 0.895781, samples/s: 780.318 1613411960.4287198
train: epoch 117, iter 800, loss: 2.071993, top_1: 0.728750, top_k: 0.896523, samples/s: 782.752 1613411993.133746
train: epoch 117, iter 900, loss: 2.173857, top_1: 0.721406, top_k: 0.893711, samples/s: 781.543 1613412025.8894637
train: epoch 117, iter 1000, loss: 2.281339, top_1: 0.723398, top_k: 0.897891, samples/s: 782.766 1613412058.5940754
train: epoch 117, iter 1100, loss: 2.150900, top_1: 0.722344, top_k: 0.895898, samples/s: 781.536 1613412091.3500898
train: epoch 117, iter 1200, loss: 1.955305, top_1: 0.725273, top_k: 0.895742, samples/s: 784.205 1613412123.9946063
train: epoch 117, iter 1300, loss: 2.249895, top_1: 0.724102, top_k: 0.894844, samples/s: 782.957 1613412156.691091
train: epoch 117, iter 1400, loss: 2.111190, top_1: 0.726719, top_k: 0.896133, samples/s: 783.340 1613412189.3717318
train: epoch 117, iter 1500, loss: 2.181527, top_1: 0.723594, top_k: 0.896523, samples/s: 783.340 1613412222.0522957
train: epoch 117, iter 1600, loss: 2.238635, top_1: 0.726055, top_k: 0.897109, samples/s: 783.495 1613412254.726313
train: epoch 117, iter 1700, loss: 2.170298, top_1: 0.728008, top_k: 0.897344, samples/s: 779.171 1613412287.5817218
train: epoch 117, iter 1800, loss: 2.157782, top_1: 0.720859, top_k: 0.893945, samples/s: 783.538 1613412320.254124
train: epoch 117, iter 1900, loss: 2.255191, top_1: 0.726367, top_k: 0.895195, samples/s: 783.783 1613412352.9162266
train: epoch 117, iter 2000, loss: 2.040701, top_1: 0.720586, top_k: 0.895664, samples/s: 783.540 1613412385.5884137
train: epoch 117, iter 2100, loss: 2.064239, top_1: 0.729141, top_k: 0.897109, samples/s: 784.473 1613412418.2217743
train: epoch 117, iter 2200, loss: 2.219876, top_1: 0.722617, top_k: 0.895234, samples/s: 781.853 1613412450.9649549
train: epoch 117, iter 2300, loss: 2.099774, top_1: 0.720938, top_k: 0.896133, samples/s: 784.807 1613412483.583884
train: epoch 117, iter 2400, loss: 2.303705, top_1: 0.721406, top_k: 0.897617, samples/s: 782.935 1613412516.2817843
train: epoch 117, iter 2500, loss: 2.162628, top_1: 0.723477, top_k: 0.893789, samples/s: 783.425 1613412548.9584079
train: epoch 117, iter 2600, loss: 2.158379, top_1: 0.720430, top_k: 0.893828, samples/s: 784.114 1613412581.6066937
train: epoch 117, iter 2700, loss: 2.086522, top_1: 0.718359, top_k: 0.892461, samples/s: 783.541 1613412614.2789364
train: epoch 117, iter 2800, loss: 2.233476, top_1: 0.721250, top_k: 0.894531, samples/s: 782.940 1613412646.976217
train: epoch 117, iter 2900, loss: 2.044700, top_1: 0.719063, top_k: 0.892344, samples/s: 782.701 1613412679.6834238
train: epoch 117, iter 3000, loss: 2.008296, top_1: 0.720742, top_k: 0.892148, samples/s: 784.121 1613412712.331468
train: epoch 117, iter 3100, loss: 2.117225, top_1: 0.721367, top_k: 0.895312, samples/s: 785.041 1613412744.9411638
train: epoch 117, iter 3200, loss: 2.251565, top_1: 0.718828, top_k: 0.894805, samples/s: 781.086 1613412777.7161443
train: epoch 117, iter 3300, loss: 2.081638, top_1: 0.716250, top_k: 0.892813, samples/s: 785.743 1613412810.2966948
train: epoch 117, iter 3400, loss: 1.945841, top_1: 0.722969, top_k: 0.895820, samples/s: 782.369 1613412843.0178392
train: epoch 117, iter 3500, loss: 2.247540, top_1: 0.718711, top_k: 0.894375, samples/s: 782.293 1613412875.7421024
train: epoch 117, iter 3600, loss: 2.187271, top_1: 0.718828, top_k: 0.888984, samples/s: 783.713 1613412908.407162
train: epoch 117, iter 3700, loss: 2.165059, top_1: 0.718203, top_k: 0.891172, samples/s: 783.505 1613412941.0808027
train: epoch 117, iter 3800, loss: 2.190911, top_1: 0.718789, top_k: 0.892930, samples/s: 782.099 1613412973.8133936
train: epoch 117, iter 3900, loss: 2.063565, top_1: 0.723594, top_k: 0.896406, samples/s: 782.068 1613413006.5469885
train: epoch 117, iter 4000, loss: 2.059839, top_1: 0.720859, top_k: 0.896328, samples/s: 784.566 1613413039.176481
train: epoch 117, iter 4100, loss: 2.089488, top_1: 0.722852, top_k: 0.890820, samples/s: 783.178 1613413071.8638108
train: epoch 117, iter 4200, loss: 2.218157, top_1: 0.719648, top_k: 0.892969, samples/s: 784.123 1613413104.5118117
train: epoch 117, iter 4300, loss: 2.218738, top_1: 0.714805, top_k: 0.890977, samples/s: 781.323 1613413137.2767718
train: epoch 117, iter 4400, loss: 2.216697, top_1: 0.715781, top_k: 0.893711, samples/s: 783.908 1613413169.933694
train: epoch 117, iter 4500, loss: 2.155854, top_1: 0.718164, top_k: 0.891719, samples/s: 783.246 1613413202.61818
train: epoch 117, iter 4600, loss: 1.953702, top_1: 0.714570, top_k: 0.890195, samples/s: 782.292 1613413235.3425615
train: epoch 117, iter 4700, loss: 2.300529, top_1: 0.720000, top_k: 0.894883, samples/s: 781.670 1613413268.0928514
train: epoch 117, iter 4800, loss: 2.166620, top_1: 0.711172, top_k: 0.886523, samples/s: 784.911 1613413300.7080736
train: epoch 117, iter 4900, loss: 2.342058, top_1: 0.719648, top_k: 0.889961, samples/s: 782.833 1613413333.4098024
train: epoch 117, iter 5000, loss: 2.090940, top_1: 0.717461, top_k: 0.895859, samples/s: 781.979 1613413366.1473138
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_117.
validation: epoch 117, iter 195, top_1: 0.739143, top_k: 0.920272, samples/s: 2367.774 1613413388.195987
train: epoch 118, iter 100, loss: 2.289723, top_1: 0.736836, top_k: 0.900352, samples/s: 804.142 1613413440.5360243
train: epoch 118, iter 200, loss: 1.982819, top_1: 0.727734, top_k: 0.898594, samples/s: 800.927 1613413472.4992723
train: epoch 118, iter 300, loss: 1.991265, top_1: 0.732578, top_k: 0.899766, samples/s: 782.765 1613413505.2036004
train: epoch 118, iter 400, loss: 2.087549, top_1: 0.729297, top_k: 0.897109, samples/s: 781.837 1613413537.946964
train: epoch 118, iter 500, loss: 1.960500, top_1: 0.722891, top_k: 0.895664, samples/s: 779.416 1613413570.7920084
train: epoch 118, iter 600, loss: 2.092232, top_1: 0.728594, top_k: 0.900000, samples/s: 783.742 1613413603.4558654
train: epoch 118, iter 700, loss: 2.049482, top_1: 0.727266, top_k: 0.895625, samples/s: 779.743 1613413636.287199
train: epoch 118, iter 800, loss: 2.102683, top_1: 0.726523, top_k: 0.896836, samples/s: 779.919 1613413669.1111486
train: epoch 118, iter 900, loss: 2.136156, top_1: 0.726289, top_k: 0.897969, samples/s: 782.462 1613413701.8283443
train: epoch 118, iter 1000, loss: 2.232821, top_1: 0.726406, top_k: 0.897383, samples/s: 782.040 1613413734.563267
train: epoch 118, iter 1100, loss: 2.261124, top_1: 0.725078, top_k: 0.894180, samples/s: 778.260 1613413767.4572344
train: epoch 118, iter 1200, loss: 2.178108, top_1: 0.723359, top_k: 0.896055, samples/s: 783.558 1613413800.128607
train: epoch 118, iter 1300, loss: 2.046946, top_1: 0.724648, top_k: 0.896094, samples/s: 781.069 1613413832.904254
train: epoch 118, iter 1400, loss: 2.208539, top_1: 0.728828, top_k: 0.895820, samples/s: 781.731 1613413865.6520932
train: epoch 118, iter 1500, loss: 2.152544, top_1: 0.720703, top_k: 0.895781, samples/s: 785.749 1613413898.2325237
train: epoch 118, iter 1600, loss: 2.222666, top_1: 0.725625, top_k: 0.896094, samples/s: 781.150 1613413931.004636
train: epoch 118, iter 1700, loss: 2.211625, top_1: 0.727812, top_k: 0.897422, samples/s: 783.330 1613413963.6856768
train: epoch 118, iter 1800, loss: 1.917641, top_1: 0.726367, top_k: 0.897930, samples/s: 782.287 1613413996.4102302
train: epoch 118, iter 1900, loss: 2.184186, top_1: 0.724570, top_k: 0.896055, samples/s: 781.852 1613414029.1529937
train: epoch 118, iter 2000, loss: 2.208711, top_1: 0.727109, top_k: 0.895312, samples/s: 782.705 1613414061.8599918
train: epoch 118, iter 2100, loss: 2.193738, top_1: 0.722148, top_k: 0.896016, samples/s: 781.753 1613414094.606898
train: epoch 118, iter 2200, loss: 2.008622, top_1: 0.724492, top_k: 0.897891, samples/s: 782.190 1613414127.335597
train: epoch 118, iter 2300, loss: 2.116515, top_1: 0.727070, top_k: 0.892773, samples/s: 783.159 1613414160.023718
train: epoch 118, iter 2400, loss: 2.180073, top_1: 0.724805, top_k: 0.894766, samples/s: 781.472 1613414192.782423
train: epoch 118, iter 2500, loss: 1.987672, top_1: 0.728984, top_k: 0.895938, samples/s: 782.563 1613414225.495408
train: epoch 118, iter 2600, loss: 2.069490, top_1: 0.724961, top_k: 0.898164, samples/s: 781.902 1613414258.2360525
train: epoch 118, iter 2700, loss: 2.077709, top_1: 0.722148, top_k: 0.892930, samples/s: 784.399 1613414290.8726122
train: epoch 118, iter 2800, loss: 2.128665, top_1: 0.725977, top_k: 0.897188, samples/s: 782.780 1613414323.5765374
train: epoch 118, iter 2900, loss: 2.320274, top_1: 0.720781, top_k: 0.893164, samples/s: 782.768 1613414356.280884
train: epoch 118, iter 3000, loss: 2.200744, top_1: 0.723164, top_k: 0.894102, samples/s: 781.127 1613414389.054559
train: epoch 118, iter 3100, loss: 2.068659, top_1: 0.716406, top_k: 0.894375, samples/s: 782.983 1613414421.7495975
train: epoch 118, iter 3200, loss: 2.074761, top_1: 0.718477, top_k: 0.892891, samples/s: 781.222 1613414454.5191376
train: epoch 118, iter 3300, loss: 2.068262, top_1: 0.725547, top_k: 0.895352, samples/s: 783.837 1613414487.178561
train: epoch 118, iter 3400, loss: 2.010046, top_1: 0.724922, top_k: 0.895078, samples/s: 782.727 1613414519.884793
train: epoch 118, iter 3500, loss: 2.201123, top_1: 0.720469, top_k: 0.895078, samples/s: 782.418 1613414552.6037822
train: epoch 118, iter 3600, loss: 2.257962, top_1: 0.721758, top_k: 0.897031, samples/s: 781.388 1613414585.3661053
train: epoch 118, iter 3700, loss: 2.333394, top_1: 0.716875, top_k: 0.894336, samples/s: 780.928 1613414618.1475143
train: epoch 118, iter 3800, loss: 2.294384, top_1: 0.727422, top_k: 0.895625, samples/s: 783.089 1613414650.8385777
train: epoch 118, iter 3900, loss: 2.088284, top_1: 0.720117, top_k: 0.894844, samples/s: 780.459 1613414683.639741
train: epoch 118, iter 4000, loss: 2.224823, top_1: 0.722617, top_k: 0.892383, samples/s: 780.831 1613414716.4254262
train: epoch 118, iter 4100, loss: 2.120368, top_1: 0.718672, top_k: 0.893281, samples/s: 781.501 1613414749.1827886
train: epoch 118, iter 4200, loss: 2.403185, top_1: 0.725977, top_k: 0.893203, samples/s: 783.169 1613414781.8705447
train: epoch 118, iter 4300, loss: 2.148654, top_1: 0.723242, top_k: 0.896016, samples/s: 782.151 1613414814.6008236
train: epoch 118, iter 4400, loss: 2.125093, top_1: 0.719648, top_k: 0.896328, samples/s: 783.515 1613414847.2740352
train: epoch 118, iter 4500, loss: 2.060798, top_1: 0.726562, top_k: 0.896875, samples/s: 782.631 1613414879.984255
train: epoch 118, iter 4600, loss: 2.097114, top_1: 0.720586, top_k: 0.892227, samples/s: 782.479 1613414912.7008257
train: epoch 118, iter 4700, loss: 1.991204, top_1: 0.723672, top_k: 0.895898, samples/s: 782.875 1613414945.4008322
train: epoch 118, iter 4800, loss: 1.983661, top_1: 0.718711, top_k: 0.892891, samples/s: 782.773 1613414978.1050925
train: epoch 118, iter 4900, loss: 2.173406, top_1: 0.724492, top_k: 0.893711, samples/s: 781.296 1613415010.871179
train: epoch 118, iter 5000, loss: 2.206654, top_1: 0.724609, top_k: 0.898672, samples/s: 783.135 1613415043.56024
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_118.
validation: epoch 118, iter 195, top_1: 0.740986, top_k: 0.920893, samples/s: 2332.418 1613415065.9487264
train: epoch 119, iter 100, loss: 2.153480, top_1: 0.736133, top_k: 0.899492, samples/s: 806.392 1613415118.926209
train: epoch 119, iter 200, loss: 2.041461, top_1: 0.735313, top_k: 0.899297, samples/s: 799.915 1613415150.92948
train: epoch 119, iter 300, loss: 2.281757, top_1: 0.729688, top_k: 0.898633, samples/s: 783.401 1613415183.607462
train: epoch 119, iter 400, loss: 2.104125, top_1: 0.737187, top_k: 0.902109, samples/s: 779.168 1613415216.4630413
train: epoch 119, iter 500, loss: 2.118475, top_1: 0.736328, top_k: 0.902383, samples/s: 781.459 1613415249.222334
train: epoch 119, iter 600, loss: 2.133004, top_1: 0.731172, top_k: 0.896992, samples/s: 776.982 1613415282.1702363
train: epoch 119, iter 700, loss: 2.189282, top_1: 0.735586, top_k: 0.903086, samples/s: 781.254 1613415314.9381196
train: epoch 119, iter 800, loss: 2.190888, top_1: 0.728633, top_k: 0.897539, samples/s: 779.650 1613415347.7733316
train: epoch 119, iter 900, loss: 2.064991, top_1: 0.734297, top_k: 0.900664, samples/s: 778.995 1613415380.6361485
train: epoch 119, iter 1000, loss: 2.154743, top_1: 0.729727, top_k: 0.900664, samples/s: 782.195 1613415413.364668
train: epoch 119, iter 1100, loss: 2.040137, top_1: 0.728945, top_k: 0.900352, samples/s: 780.196 1613415446.1768415
train: epoch 119, iter 1200, loss: 2.091351, top_1: 0.733398, top_k: 0.898867, samples/s: 781.736 1613415478.9245138
train: epoch 119, iter 1300, loss: 2.227784, top_1: 0.735625, top_k: 0.901367, samples/s: 780.721 1613415511.7147634
train: epoch 119, iter 1400, loss: 2.190856, top_1: 0.728359, top_k: 0.897266, samples/s: 780.916 1613415544.4967473
train: epoch 119, iter 1500, loss: 2.119851, top_1: 0.728164, top_k: 0.899727, samples/s: 780.665 1613415577.289263
train: epoch 119, iter 1600, loss: 2.053309, top_1: 0.727461, top_k: 0.896484, samples/s: 781.708 1613415610.037982
train: epoch 119, iter 1700, loss: 2.021486, top_1: 0.729102, top_k: 0.900391, samples/s: 781.659 1613415642.7889247
train: epoch 119, iter 1800, loss: 2.116140, top_1: 0.730195, top_k: 0.897305, samples/s: 781.510 1613415675.5459642
train: epoch 119, iter 1900, loss: 2.193961, top_1: 0.731172, top_k: 0.896719, samples/s: 782.586 1613415708.2580483
train: epoch 119, iter 2000, loss: 2.170230, top_1: 0.726172, top_k: 0.900664, samples/s: 781.020 1613415741.0357263
train: epoch 119, iter 2100, loss: 2.076067, top_1: 0.730859, top_k: 0.899453, samples/s: 780.206 1613415773.8475828
train: epoch 119, iter 2200, loss: 2.160262, top_1: 0.724102, top_k: 0.897070, samples/s: 780.329 1613415806.65426
train: epoch 119, iter 2300, loss: 2.217290, top_1: 0.732344, top_k: 0.899531, samples/s: 781.271 1613415839.421361
train: epoch 119, iter 2400, loss: 2.119432, top_1: 0.728750, top_k: 0.898672, samples/s: 785.276 1613415872.021283
train: epoch 119, iter 2500, loss: 2.082218, top_1: 0.725234, top_k: 0.897227, samples/s: 778.932 1613415904.8868654
train: epoch 119, iter 2600, loss: 2.053031, top_1: 0.729062, top_k: 0.899414, samples/s: 782.653 1613415937.596139
train: epoch 119, iter 2700, loss: 2.143353, top_1: 0.729492, top_k: 0.897617, samples/s: 781.381 1613415970.3585851
train: epoch 119, iter 2800, loss: 2.272249, top_1: 0.730039, top_k: 0.896875, samples/s: 779.179 1613416003.2137258
train: epoch 119, iter 2900, loss: 2.150255, top_1: 0.725508, top_k: 0.894102, samples/s: 780.501 1613416036.0131376
train: epoch 119, iter 3000, loss: 2.072758, top_1: 0.726680, top_k: 0.898320, samples/s: 784.005 1613416068.6660516
train: epoch 119, iter 3100, loss: 2.165972, top_1: 0.727656, top_k: 0.899844, samples/s: 782.110 1613416101.3980117
train: epoch 119, iter 3200, loss: 2.125024, top_1: 0.729023, top_k: 0.897422, samples/s: 780.724 1613416134.1880252
train: epoch 119, iter 3300, loss: 2.054402, top_1: 0.726250, top_k: 0.897617, samples/s: 779.303 1613416167.0379584
train: epoch 119, iter 3400, loss: 2.023152, top_1: 0.727695, top_k: 0.898242, samples/s: 780.863 1613416199.8221502
train: epoch 119, iter 3500, loss: 2.230330, top_1: 0.728359, top_k: 0.899766, samples/s: 782.979 1613416232.5177395
train: epoch 119, iter 3600, loss: 2.037451, top_1: 0.725234, top_k: 0.895898, samples/s: 779.859 1613416265.3442764
train: epoch 119, iter 3700, loss: 2.226836, top_1: 0.728906, top_k: 0.897305, samples/s: 780.736 1613416298.1337848
train: epoch 119, iter 3800, loss: 2.239329, top_1: 0.727656, top_k: 0.895938, samples/s: 783.530 1613416330.8064098
train: epoch 119, iter 3900, loss: 2.216643, top_1: 0.724609, top_k: 0.895273, samples/s: 779.331 1613416363.6552186
train: epoch 119, iter 4000, loss: 2.256397, top_1: 0.725234, top_k: 0.893398, samples/s: 781.661 1613416396.405903
train: epoch 119, iter 4100, loss: 2.059048, top_1: 0.729180, top_k: 0.894922, samples/s: 781.812 1613416429.150285
train: epoch 119, iter 4200, loss: 2.106169, top_1: 0.723398, top_k: 0.893203, samples/s: 782.800 1613416461.8534827
train: epoch 119, iter 4300, loss: 2.117955, top_1: 0.721602, top_k: 0.894766, samples/s: 780.925 1613416494.6351178
train: epoch 119, iter 4400, loss: 2.064316, top_1: 0.727461, top_k: 0.895547, samples/s: 779.956 1613416527.45748
train: epoch 119, iter 4500, loss: 2.058266, top_1: 0.729297, top_k: 0.896680, samples/s: 782.017 1613416560.1932864
train: epoch 119, iter 4600, loss: 2.241510, top_1: 0.723594, top_k: 0.893477, samples/s: 780.905 1613416592.9757748
train: epoch 119, iter 4700, loss: 2.116262, top_1: 0.723789, top_k: 0.899141, samples/s: 782.133 1613416625.706761
train: epoch 119, iter 4800, loss: 1.994303, top_1: 0.723711, top_k: 0.895000, samples/s: 780.559 1613416658.503759
train: epoch 119, iter 4900, loss: 2.047583, top_1: 0.722422, top_k: 0.896133, samples/s: 782.184 1613416691.2327216
train: epoch 119, iter 5000, loss: 2.022814, top_1: 0.729414, top_k: 0.898633, samples/s: 779.580 1613416724.0709002
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_119.
validation: epoch 119, iter 195, top_1: 0.742087, top_k: 0.922837, samples/s: 2411.983 1613416745.7253282
train: epoch 120, iter 100, loss: 2.153555, top_1: 0.740352, top_k: 0.905352, samples/s: 804.691 1613416798.7568414
train: epoch 120, iter 200, loss: 2.189328, top_1: 0.743125, top_k: 0.906133, samples/s: 798.786 1613416830.8054352
train: epoch 120, iter 300, loss: 2.057215, top_1: 0.734883, top_k: 0.902227, samples/s: 784.090 1613416863.4548316
train: epoch 120, iter 400, loss: 2.093965, top_1: 0.737109, top_k: 0.901797, samples/s: 779.560 1613416896.2938278
train: epoch 120, iter 500, loss: 2.123772, top_1: 0.734258, top_k: 0.902383, samples/s: 779.185 1613416929.14874
train: epoch 120, iter 600, loss: 2.064722, top_1: 0.735273, top_k: 0.903164, samples/s: 782.490 1613416961.8647175
train: epoch 120, iter 700, loss: 1.975585, top_1: 0.734258, top_k: 0.900195, samples/s: 779.921 1613416994.688684
train: epoch 120, iter 800, loss: 2.149484, top_1: 0.734219, top_k: 0.902461, samples/s: 776.586 1613417027.653399
train: epoch 120, iter 900, loss: 2.095807, top_1: 0.736719, top_k: 0.901445, samples/s: 780.256 1613417060.4631343
train: epoch 120, iter 1000, loss: 2.197739, top_1: 0.731641, top_k: 0.898477, samples/s: 780.843 1613417093.2481937
train: epoch 120, iter 1100, loss: 2.172743, top_1: 0.732187, top_k: 0.899687, samples/s: 782.256 1613417125.9741952
train: epoch 120, iter 1200, loss: 2.183437, top_1: 0.731992, top_k: 0.897773, samples/s: 778.551 1613417158.8557978
train: epoch 120, iter 1300, loss: 2.037711, top_1: 0.732227, top_k: 0.902461, samples/s: 779.129 1613417191.7133567
train: epoch 120, iter 1400, loss: 2.048790, top_1: 0.727891, top_k: 0.902656, samples/s: 779.644 1613417224.548415
train: epoch 120, iter 1500, loss: 1.987472, top_1: 0.735781, top_k: 0.901094, samples/s: 781.499 1613417257.3066258
train: epoch 120, iter 1600, loss: 2.082706, top_1: 0.733906, top_k: 0.901523, samples/s: 782.966 1613417290.0021374
train: epoch 120, iter 1700, loss: 2.170009, top_1: 0.724414, top_k: 0.895820, samples/s: 780.906 1613417322.7846417
train: epoch 120, iter 1800, loss: 2.044914, top_1: 0.730781, top_k: 0.899336, samples/s: 779.934 1613417355.607821
train: epoch 120, iter 1900, loss: 2.115908, top_1: 0.727891, top_k: 0.896250, samples/s: 783.681 1613417388.2742484
train: epoch 120, iter 2000, loss: 2.235808, top_1: 0.733711, top_k: 0.900039, samples/s: 778.349 1613417421.1643856
train: epoch 120, iter 2100, loss: 2.150879, top_1: 0.727852, top_k: 0.898320, samples/s: 779.119 1613417454.0219243
train: epoch 120, iter 2200, loss: 2.162093, top_1: 0.734141, top_k: 0.900039, samples/s: 782.289 1613417486.7464168
train: epoch 120, iter 2300, loss: 2.058731, top_1: 0.733828, top_k: 0.899961, samples/s: 782.750 1613417519.4516592
train: epoch 120, iter 2400, loss: 2.067658, top_1: 0.729570, top_k: 0.894727, samples/s: 781.899 1613417552.1925
train: epoch 120, iter 2500, loss: 2.194242, top_1: 0.731250, top_k: 0.899570, samples/s: 780.582 1613417584.9884942
train: epoch 120, iter 2600, loss: 2.091491, top_1: 0.733086, top_k: 0.900469, samples/s: 780.195 1613417617.8008373
train: epoch 120, iter 2700, loss: 2.231834, top_1: 0.726055, top_k: 0.900352, samples/s: 782.626 1613417650.5111253
train: epoch 120, iter 2800, loss: 2.068796, top_1: 0.733477, top_k: 0.898750, samples/s: 781.219 1613417683.2805665
train: epoch 120, iter 2900, loss: 2.166787, top_1: 0.729336, top_k: 0.897383, samples/s: 779.702 1613417716.1138575
train: epoch 120, iter 3000, loss: 2.392006, top_1: 0.729023, top_k: 0.898750, samples/s: 783.178 1613417748.8009443
train: epoch 120, iter 3100, loss: 2.223710, top_1: 0.730352, top_k: 0.898633, samples/s: 781.627 1613417781.5534527
train: epoch 120, iter 3200, loss: 2.099332, top_1: 0.731094, top_k: 0.898555, samples/s: 778.994 1613417814.4159636
train: epoch 120, iter 3300, loss: 2.189750, top_1: 0.727891, top_k: 0.898711, samples/s: 782.118 1613417847.1476133
train: epoch 120, iter 3400, loss: 1.912787, top_1: 0.728086, top_k: 0.900469, samples/s: 783.895 1613417879.805058
train: epoch 120, iter 3500, loss: 2.175342, top_1: 0.723594, top_k: 0.898984, samples/s: 780.851 1613417912.5898778
train: epoch 120, iter 3600, loss: 2.215699, top_1: 0.728047, top_k: 0.897695, samples/s: 781.019 1613417945.367624
train: epoch 120, iter 3700, loss: 2.107775, top_1: 0.735000, top_k: 0.901445, samples/s: 782.444 1613417978.0855477
train: epoch 120, iter 3800, loss: 2.059938, top_1: 0.731328, top_k: 0.899336, samples/s: 779.779 1613418010.9153016
train: epoch 120, iter 3900, loss: 1.943589, top_1: 0.732930, top_k: 0.898906, samples/s: 782.981 1613418043.610918
train: epoch 120, iter 4000, loss: 2.207154, top_1: 0.732266, top_k: 0.898555, samples/s: 782.941 1613418076.3081515
train: epoch 120, iter 4100, loss: 2.018796, top_1: 0.726875, top_k: 0.897461, samples/s: 779.792 1613418109.137404
train: epoch 120, iter 4200, loss: 2.057767, top_1: 0.729648, top_k: 0.898438, samples/s: 784.566 1613418141.7668278
train: epoch 120, iter 4300, loss: 1.985640, top_1: 0.733437, top_k: 0.900820, samples/s: 780.214 1613418174.5784628
train: epoch 120, iter 4400, loss: 2.205007, top_1: 0.724141, top_k: 0.896094, samples/s: 784.390 1613418207.215311
train: epoch 120, iter 4500, loss: 2.031444, top_1: 0.725352, top_k: 0.892773, samples/s: 778.908 1613418240.0817108
train: epoch 120, iter 4600, loss: 2.424469, top_1: 0.734492, top_k: 0.900273, samples/s: 780.812 1613418272.868075
train: epoch 120, iter 4700, loss: 2.142323, top_1: 0.726836, top_k: 0.897266, samples/s: 781.850 1613418305.6109269
train: epoch 120, iter 4800, loss: 2.216873, top_1: 0.721758, top_k: 0.894922, samples/s: 781.545 1613418338.3665197
train: epoch 120, iter 4900, loss: 2.075564, top_1: 0.729609, top_k: 0.900977, samples/s: 782.261 1613418371.0921426
train: epoch 120, iter 5000, loss: 2.019734, top_1: 0.728047, top_k: 0.898906, samples/s: 780.793 1613418403.879423
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_120.
validation: epoch 120, iter 195, top_1: 0.743249, top_k: 0.921494, samples/s: 2365.213 1613418425.9457524
train: epoch 121, iter 100, loss: 2.006835, top_1: 0.742578, top_k: 0.906406, samples/s: 803.436 1613418484.5282555
train: epoch 121, iter 200, loss: 2.030220, top_1: 0.742031, top_k: 0.904766, samples/s: 802.153 1613418516.4423573
train: epoch 121, iter 300, loss: 2.133657, top_1: 0.738437, top_k: 0.908594, samples/s: 786.499 1613418548.991454
train: epoch 121, iter 400, loss: 2.064819, top_1: 0.739805, top_k: 0.904375, samples/s: 781.414 1613418581.7526312
train: epoch 121, iter 500, loss: 2.209896, top_1: 0.740078, top_k: 0.903945, samples/s: 783.335 1613418614.4333687
train: epoch 121, iter 600, loss: 2.036726, top_1: 0.739414, top_k: 0.902891, samples/s: 778.753 1613418647.306488
train: epoch 121, iter 700, loss: 2.089197, top_1: 0.746055, top_k: 0.906563, samples/s: 780.204 1613418680.118438
train: epoch 121, iter 800, loss: 1.982270, top_1: 0.738047, top_k: 0.902344, samples/s: 778.489 1613418713.002658
train: epoch 121, iter 900, loss: 2.066755, top_1: 0.741211, top_k: 0.903789, samples/s: 780.991 1613418745.7815301
train: epoch 121, iter 1000, loss: 1.968942, top_1: 0.738203, top_k: 0.902773, samples/s: 781.716 1613418778.5299883
train: epoch 121, iter 1100, loss: 1.941999, top_1: 0.736406, top_k: 0.903398, samples/s: 780.320 1613418811.3369787
train: epoch 121, iter 1200, loss: 1.922113, top_1: 0.741445, top_k: 0.903789, samples/s: 784.105 1613418843.9857905
train: epoch 121, iter 1300, loss: 2.294811, top_1: 0.738828, top_k: 0.902656, samples/s: 780.057 1613418876.803884
train: epoch 121, iter 1400, loss: 1.987891, top_1: 0.735195, top_k: 0.901328, samples/s: 780.975 1613418909.5833418
train: epoch 121, iter 1500, loss: 2.056780, top_1: 0.735508, top_k: 0.901992, samples/s: 782.720 1613418942.2898679
train: epoch 121, iter 1600, loss: 2.069436, top_1: 0.734570, top_k: 0.904023, samples/s: 780.709 1613418975.0805542
train: epoch 121, iter 1700, loss: 1.997088, top_1: 0.730469, top_k: 0.900312, samples/s: 780.308 1613419007.888088
train: epoch 121, iter 1800, loss: 2.063546, top_1: 0.735703, top_k: 0.899414, samples/s: 783.530 1613419040.5608032
train: epoch 121, iter 1900, loss: 2.191837, top_1: 0.732930, top_k: 0.901406, samples/s: 780.461 1613419073.3618789
train: epoch 121, iter 2000, loss: 2.062887, top_1: 0.732344, top_k: 0.900430, samples/s: 780.211 1613419106.1734855
train: epoch 121, iter 2100, loss: 2.298992, top_1: 0.734648, top_k: 0.902617, samples/s: 781.624 1613419138.9258187
train: epoch 121, iter 2200, loss: 2.018488, top_1: 0.728672, top_k: 0.899609, samples/s: 780.969 1613419171.7056515
train: epoch 121, iter 2300, loss: 2.069142, top_1: 0.734023, top_k: 0.900352, samples/s: 782.108 1613419204.4376447
train: epoch 121, iter 2400, loss: 2.003434, top_1: 0.737227, top_k: 0.901836, samples/s: 781.973 1613419237.1753979
train: epoch 121, iter 2500, loss: 2.116086, top_1: 0.730508, top_k: 0.898086, samples/s: 780.994 1613419269.954178
train: epoch 121, iter 2600, loss: 2.196208, top_1: 0.732852, top_k: 0.902031, samples/s: 783.226 1613419302.6394506
train: epoch 121, iter 2700, loss: 2.108116, top_1: 0.737109, top_k: 0.900898, samples/s: 780.756 1613419335.4282334
train: epoch 121, iter 2800, loss: 2.084545, top_1: 0.730898, top_k: 0.897695, samples/s: 780.308 1613419368.2357945
train: epoch 121, iter 2900, loss: 2.017057, top_1: 0.724883, top_k: 0.894766, samples/s: 783.730 1613419400.9000883
train: epoch 121, iter 3000, loss: 1.891578, top_1: 0.736055, top_k: 0.899141, samples/s: 782.545 1613419433.6138563
train: epoch 121, iter 3100, loss: 2.158074, top_1: 0.734258, top_k: 0.904961, samples/s: 781.787 1613419466.3592355
train: epoch 121, iter 3200, loss: 2.171354, top_1: 0.733867, top_k: 0.899531, samples/s: 782.851 1613419499.0602975
train: epoch 121, iter 3300, loss: 2.139112, top_1: 0.732070, top_k: 0.900117, samples/s: 783.573 1613419531.7311256
train: epoch 121, iter 3400, loss: 2.258751, top_1: 0.732031, top_k: 0.899414, samples/s: 778.178 1613419564.6284335
train: epoch 121, iter 3500, loss: 2.046895, top_1: 0.725391, top_k: 0.896953, samples/s: 783.932 1613419597.2843504
train: epoch 121, iter 3600, loss: 2.008951, top_1: 0.733437, top_k: 0.899102, samples/s: 781.506 1613419630.041608
train: epoch 121, iter 3700, loss: 2.103310, top_1: 0.726992, top_k: 0.898477, samples/s: 783.776 1613419662.7040257
train: epoch 121, iter 3800, loss: 2.161261, top_1: 0.727422, top_k: 0.900234, samples/s: 780.861 1613419695.4884114
train: epoch 121, iter 3900, loss: 2.058638, top_1: 0.731914, top_k: 0.900820, samples/s: 781.791 1613419728.2337563
train: epoch 121, iter 4000, loss: 2.098183, top_1: 0.733320, top_k: 0.897500, samples/s: 782.854 1613419760.9345243
train: epoch 121, iter 4100, loss: 2.106375, top_1: 0.732930, top_k: 0.900000, samples/s: 783.234 1613419793.6195495
train: epoch 121, iter 4200, loss: 2.041112, top_1: 0.733320, top_k: 0.900859, samples/s: 783.334 1613419826.300293
train: epoch 121, iter 4300, loss: 2.152207, top_1: 0.724961, top_k: 0.895352, samples/s: 782.929 1613419858.998093
train: epoch 121, iter 4400, loss: 2.008674, top_1: 0.732461, top_k: 0.902773, samples/s: 780.957 1613419891.7783957
train: epoch 121, iter 4500, loss: 2.304782, top_1: 0.727031, top_k: 0.898906, samples/s: 784.067 1613419924.4286618
train: epoch 121, iter 4600, loss: 1.952474, top_1: 0.734648, top_k: 0.901016, samples/s: 781.363 1613419957.1919723
train: epoch 121, iter 4700, loss: 1.908530, top_1: 0.733672, top_k: 0.902969, samples/s: 784.283 1613419989.83316
train: epoch 121, iter 4800, loss: 2.071393, top_1: 0.726523, top_k: 0.898828, samples/s: 782.066 1613420022.5670207
train: epoch 121, iter 4900, loss: 2.101513, top_1: 0.732344, top_k: 0.898516, samples/s: 779.004 1613420055.4294677
train: epoch 121, iter 5000, loss: 2.124372, top_1: 0.740313, top_k: 0.902539, samples/s: 785.251 1613420088.0305316
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_121.
validation: epoch 121, iter 195, top_1: 0.748177, top_k: 0.924399, samples/s: 2363.603 1613420110.1166642
train: epoch 122, iter 100, loss: 2.157219, top_1: 0.744336, top_k: 0.907617, samples/s: 804.095 1613420162.5096607
train: epoch 122, iter 200, loss: 2.186967, top_1: 0.746367, top_k: 0.908867, samples/s: 798.248 1613420194.5799417
train: epoch 122, iter 300, loss: 2.251856, top_1: 0.739961, top_k: 0.903008, samples/s: 784.000 1613420227.2329793
train: epoch 122, iter 400, loss: 2.055798, top_1: 0.747266, top_k: 0.908828, samples/s: 778.746 1613420260.1063147
train: epoch 122, iter 500, loss: 2.155340, top_1: 0.745000, top_k: 0.905195, samples/s: 781.565 1613420292.8611486
train: epoch 122, iter 600, loss: 2.211411, top_1: 0.739531, top_k: 0.903008, samples/s: 777.971 1613420325.7672377
train: epoch 122, iter 700, loss: 2.064246, top_1: 0.738945, top_k: 0.901836, samples/s: 780.398 1613420358.5709753
train: epoch 122, iter 800, loss: 2.047464, top_1: 0.742539, top_k: 0.904687, samples/s: 783.191 1613420391.2577424
train: epoch 122, iter 900, loss: 2.110445, top_1: 0.737148, top_k: 0.904492, samples/s: 779.490 1613420424.0997767
train: epoch 122, iter 1000, loss: 2.042445, top_1: 0.736484, top_k: 0.900000, samples/s: 778.992 1613420456.962811
train: epoch 122, iter 1100, loss: 1.944860, top_1: 0.738984, top_k: 0.901328, samples/s: 778.694 1613420489.8382676
train: epoch 122, iter 1200, loss: 1.957856, top_1: 0.740352, top_k: 0.904297, samples/s: 778.374 1613420522.7273645
train: epoch 122, iter 1300, loss: 1.929147, top_1: 0.736367, top_k: 0.904531, samples/s: 782.144 1613420555.4579425
train: epoch 122, iter 1400, loss: 2.130250, top_1: 0.744336, top_k: 0.905859, samples/s: 778.923 1613420588.3238153
train: epoch 122, iter 1500, loss: 1.974757, top_1: 0.739453, top_k: 0.902148, samples/s: 778.267 1613420621.2174475
train: epoch 122, iter 1600, loss: 2.161460, top_1: 0.733867, top_k: 0.901797, samples/s: 782.013 1613420653.9534702
train: epoch 122, iter 1700, loss: 1.983893, top_1: 0.745117, top_k: 0.905820, samples/s: 780.416 1613420686.756447
train: epoch 122, iter 1800, loss: 2.035499, top_1: 0.740273, top_k: 0.906641, samples/s: 778.061 1613420719.6587582
train: epoch 122, iter 1900, loss: 2.012619, top_1: 0.739375, top_k: 0.903008, samples/s: 781.623 1613420752.4111047
train: epoch 122, iter 2000, loss: 2.125952, top_1: 0.738555, top_k: 0.903555, samples/s: 780.653 1613420785.2041886
train: epoch 122, iter 2100, loss: 2.061140, top_1: 0.741641, top_k: 0.907656, samples/s: 777.967 1613420818.1104877
train: epoch 122, iter 2200, loss: 2.090480, top_1: 0.737578, top_k: 0.904648, samples/s: 782.080 1613420850.8437424
train: epoch 122, iter 2300, loss: 2.054794, top_1: 0.738594, top_k: 0.904336, samples/s: 779.254 1613420883.6955955
train: epoch 122, iter 2400, loss: 2.060676, top_1: 0.735586, top_k: 0.903828, samples/s: 780.895 1613420916.4785216
train: epoch 122, iter 2500, loss: 2.101500, top_1: 0.735820, top_k: 0.902930, samples/s: 779.373 1613420949.3253937
train: epoch 122, iter 2600, loss: 2.127148, top_1: 0.734805, top_k: 0.901992, samples/s: 780.469 1613420982.126255
train: epoch 122, iter 2700, loss: 1.967592, top_1: 0.733477, top_k: 0.901016, samples/s: 781.977 1613421014.86374
train: epoch 122, iter 2800, loss: 2.047443, top_1: 0.739805, top_k: 0.902656, samples/s: 779.398 1613421047.7096615
train: epoch 122, iter 2900, loss: 1.998724, top_1: 0.734727, top_k: 0.903008, samples/s: 780.569 1613421080.5061743
train: epoch 122, iter 3000, loss: 2.116317, top_1: 0.739844, top_k: 0.904336, samples/s: 779.938 1613421113.3293629
train: epoch 122, iter 3100, loss: 2.049747, top_1: 0.736641, top_k: 0.902305, samples/s: 783.426 1613421146.0062604
train: epoch 122, iter 3200, loss: 2.165581, top_1: 0.733203, top_k: 0.900430, samples/s: 779.843 1613421178.8334017
train: epoch 122, iter 3300, loss: 2.270051, top_1: 0.731875, top_k: 0.900000, samples/s: 779.872 1613421211.6592877
train: epoch 122, iter 3400, loss: 2.032978, top_1: 0.733398, top_k: 0.900078, samples/s: 782.058 1613421244.3934302
train: epoch 122, iter 3500, loss: 2.186371, top_1: 0.736953, top_k: 0.901836, samples/s: 778.861 1613421277.2619126
train: epoch 122, iter 3600, loss: 2.204802, top_1: 0.737422, top_k: 0.904609, samples/s: 780.188 1613421310.074501
train: epoch 122, iter 3700, loss: 2.047310, top_1: 0.738633, top_k: 0.904414, samples/s: 783.259 1613421342.758404
train: epoch 122, iter 3800, loss: 2.142431, top_1: 0.738437, top_k: 0.902852, samples/s: 779.247 1613421375.6106384
train: epoch 122, iter 3900, loss: 2.159510, top_1: 0.730703, top_k: 0.899062, samples/s: 779.963 1613421408.4328206
train: epoch 122, iter 4000, loss: 1.946300, top_1: 0.738008, top_k: 0.902969, samples/s: 779.721 1613421441.2649655
train: epoch 122, iter 4100, loss: 2.192347, top_1: 0.728164, top_k: 0.897148, samples/s: 780.465 1613421474.0660138
train: epoch 122, iter 4200, loss: 2.347384, top_1: 0.733828, top_k: 0.901055, samples/s: 781.454 1613421506.8255398
train: epoch 122, iter 4300, loss: 1.947414, top_1: 0.731602, top_k: 0.902148, samples/s: 779.287 1613421539.675951
train: epoch 122, iter 4400, loss: 2.251067, top_1: 0.732148, top_k: 0.901680, samples/s: 779.979 1613421572.4973109
train: epoch 122, iter 4500, loss: 2.117255, top_1: 0.732227, top_k: 0.900586, samples/s: 781.441 1613421605.2573905
train: epoch 122, iter 4600, loss: 2.075619, top_1: 0.736641, top_k: 0.901094, samples/s: 779.982 1613421638.0785434
train: epoch 122, iter 4700, loss: 2.045784, top_1: 0.732422, top_k: 0.898711, samples/s: 779.654 1613421670.9137328
train: epoch 122, iter 4800, loss: 1.961854, top_1: 0.735508, top_k: 0.902734, samples/s: 780.051 1613421703.7319796
train: epoch 122, iter 4900, loss: 2.065771, top_1: 0.729961, top_k: 0.902070, samples/s: 780.892 1613421736.5150452
train: epoch 122, iter 5000, loss: 2.060088, top_1: 0.742383, top_k: 0.905820, samples/s: 781.939 1613421769.25414
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_122.
validation: epoch 122, iter 195, top_1: 0.746234, top_k: 0.922576, samples/s: 2343.726 1613421791.5173821
train: epoch 123, iter 100, loss: 1.906404, top_1: 0.741016, top_k: 0.907305, samples/s: 805.445 1613421843.6930826
train: epoch 123, iter 200, loss: 2.023165, top_1: 0.739570, top_k: 0.906719, samples/s: 798.244 1613421875.763626
train: epoch 123, iter 300, loss: 1.913305, top_1: 0.741719, top_k: 0.905977, samples/s: 781.065 1613421908.53926
train: epoch 123, iter 400, loss: 2.142876, top_1: 0.742617, top_k: 0.906719, samples/s: 779.863 1613421941.3656056
train: epoch 123, iter 500, loss: 2.103426, top_1: 0.747070, top_k: 0.909258, samples/s: 778.817 1613421974.2359633
train: epoch 123, iter 600, loss: 1.906333, top_1: 0.746523, top_k: 0.905234, samples/s: 778.166 1613422007.1337328
train: epoch 123, iter 700, loss: 2.051328, top_1: 0.743008, top_k: 0.906289, samples/s: 783.009 1613422039.8281648
train: epoch 123, iter 800, loss: 2.099176, top_1: 0.744766, top_k: 0.908477, samples/s: 777.391 1613422072.7588358
train: epoch 123, iter 900, loss: 2.068403, top_1: 0.745781, top_k: 0.907461, samples/s: 779.306 1613422105.6085863
train: epoch 123, iter 1000, loss: 2.057360, top_1: 0.744453, top_k: 0.904219, samples/s: 778.324 1613422138.4998314
train: epoch 123, iter 1100, loss: 2.040811, top_1: 0.747852, top_k: 0.908750, samples/s: 779.432 1613422171.344259
train: epoch 123, iter 1200, loss: 2.052403, top_1: 0.741914, top_k: 0.906055, samples/s: 781.725 1613422204.0923605
train: epoch 123, iter 1300, loss: 2.047382, top_1: 0.746563, top_k: 0.906445, samples/s: 776.672 1613422237.0534124
train: epoch 123, iter 1400, loss: 2.006635, top_1: 0.740781, top_k: 0.906172, samples/s: 780.985 1613422269.8325675
train: epoch 123, iter 1500, loss: 2.068865, top_1: 0.739062, top_k: 0.902422, samples/s: 778.976 1613422302.6961706
train: epoch 123, iter 1600, loss: 2.167271, top_1: 0.741055, top_k: 0.905664, samples/s: 780.420 1613422335.4990299
train: epoch 123, iter 1700, loss: 2.071409, top_1: 0.745078, top_k: 0.906289, samples/s: 781.506 1613422368.2563055
train: epoch 123, iter 1800, loss: 1.977764, top_1: 0.741836, top_k: 0.904648, samples/s: 778.018 1613422401.1604264
train: epoch 123, iter 1900, loss: 2.127059, top_1: 0.743320, top_k: 0.905000, samples/s: 780.304 1613422433.9681787
train: epoch 123, iter 2000, loss: 2.024427, top_1: 0.740977, top_k: 0.906641, samples/s: 779.963 1613422466.7901978
train: epoch 123, iter 2100, loss: 2.071012, top_1: 0.742422, top_k: 0.907422, samples/s: 779.203 1613422499.644318
train: epoch 123, iter 2200, loss: 2.181354, top_1: 0.741641, top_k: 0.904219, samples/s: 781.624 1613422532.39653
train: epoch 123, iter 2300, loss: 2.208587, top_1: 0.741328, top_k: 0.906289, samples/s: 780.059 1613422565.214668
train: epoch 123, iter 2400, loss: 2.140275, top_1: 0.742109, top_k: 0.905469, samples/s: 779.623 1613422598.0510013
train: epoch 123, iter 2500, loss: 2.136954, top_1: 0.737031, top_k: 0.903945, samples/s: 782.052 1613422630.7853785
train: epoch 123, iter 2600, loss: 2.118700, top_1: 0.736602, top_k: 0.903750, samples/s: 780.871 1613422663.5693474
train: epoch 123, iter 2700, loss: 1.979617, top_1: 0.736758, top_k: 0.904766, samples/s: 779.629 1613422696.405376
train: epoch 123, iter 2800, loss: 2.041916, top_1: 0.737461, top_k: 0.901953, samples/s: 781.505 1613422729.1627324
train: epoch 123, iter 2900, loss: 1.963413, top_1: 0.740430, top_k: 0.903711, samples/s: 778.655 1613422762.0399392
train: epoch 123, iter 3000, loss: 2.098691, top_1: 0.739805, top_k: 0.901328, samples/s: 781.797 1613422794.7850206
train: epoch 123, iter 3100, loss: 2.063865, top_1: 0.733398, top_k: 0.901445, samples/s: 783.696 1613422827.4506783
train: epoch 123, iter 3200, loss: 2.090714, top_1: 0.742227, top_k: 0.904570, samples/s: 779.230 1613422860.3036819
train: epoch 123, iter 3300, loss: 1.942267, top_1: 0.738711, top_k: 0.902188, samples/s: 780.447 1613422893.1054308
train: epoch 123, iter 3400, loss: 2.002011, top_1: 0.738437, top_k: 0.903750, samples/s: 779.046 1613422925.9660869
train: epoch 123, iter 3500, loss: 2.168754, top_1: 0.733320, top_k: 0.903594, samples/s: 781.975 1613422958.7037454
train: epoch 123, iter 3600, loss: 2.119931, top_1: 0.738281, top_k: 0.902969, samples/s: 777.413 1613422991.633399
train: epoch 123, iter 3700, loss: 2.178154, top_1: 0.736250, top_k: 0.903711, samples/s: 782.464 1613423024.3506732
train: epoch 123, iter 3800, loss: 2.204160, top_1: 0.737773, top_k: 0.903867, samples/s: 779.836 1613423057.178016
train: epoch 123, iter 3900, loss: 2.137143, top_1: 0.736328, top_k: 0.904570, samples/s: 780.309 1613423089.9855127
train: epoch 123, iter 4000, loss: 1.995121, top_1: 0.740039, top_k: 0.902578, samples/s: 778.058 1613423122.8880107
train: epoch 123, iter 4100, loss: 2.031652, top_1: 0.731484, top_k: 0.899375, samples/s: 782.931 1613423155.5856402
train: epoch 123, iter 4200, loss: 2.152197, top_1: 0.739492, top_k: 0.903477, samples/s: 783.191 1613423188.2723987
train: epoch 123, iter 4300, loss: 2.000073, top_1: 0.736133, top_k: 0.902969, samples/s: 778.804 1613423221.1432855
train: epoch 123, iter 4400, loss: 2.063953, top_1: 0.744687, top_k: 0.903242, samples/s: 780.278 1613423253.9521196
train: epoch 123, iter 4500, loss: 2.002192, top_1: 0.738047, top_k: 0.905508, samples/s: 782.069 1613423286.6858144
train: epoch 123, iter 4600, loss: 2.147016, top_1: 0.736250, top_k: 0.904609, samples/s: 783.291 1613423319.3685398
train: epoch 123, iter 4700, loss: 2.039445, top_1: 0.731172, top_k: 0.898750, samples/s: 779.310 1613423352.217984
train: epoch 123, iter 4800, loss: 1.909995, top_1: 0.739961, top_k: 0.901289, samples/s: 783.420 1613423384.8951576
train: epoch 123, iter 4900, loss: 2.119801, top_1: 0.735820, top_k: 0.898984, samples/s: 779.047 1613423417.755878
train: epoch 123, iter 5000, loss: 1.974916, top_1: 0.746328, top_k: 0.907539, samples/s: 781.375 1613423450.5185812
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_123.
validation: epoch 123, iter 195, top_1: 0.748417, top_k: 0.925060, samples/s: 2358.541 1613423472.640448
train: epoch 124, iter 100, loss: 2.087494, top_1: 0.753945, top_k: 0.910156, samples/s: 803.689 1613423525.2515473
train: epoch 124, iter 200, loss: 2.119975, top_1: 0.757148, top_k: 0.913242, samples/s: 800.039 1613423557.2501965
train: epoch 124, iter 300, loss: 2.087452, top_1: 0.748477, top_k: 0.908047, samples/s: 782.522 1613423589.96474
train: epoch 124, iter 400, loss: 1.940378, top_1: 0.750586, top_k: 0.907578, samples/s: 776.777 1613423622.9214563
train: epoch 124, iter 500, loss: 2.056159, top_1: 0.749492, top_k: 0.909414, samples/s: 781.132 1613423655.6944234
train: epoch 124, iter 600, loss: 2.138481, top_1: 0.742578, top_k: 0.905430, samples/s: 778.981 1613423688.5577614
train: epoch 124, iter 700, loss: 2.124698, top_1: 0.741758, top_k: 0.903242, samples/s: 778.556 1613423721.4391942
train: epoch 124, iter 800, loss: 2.133664, top_1: 0.745664, top_k: 0.905469, samples/s: 779.479 1613423754.2816477
train: epoch 124, iter 900, loss: 2.131822, top_1: 0.743594, top_k: 0.907305, samples/s: 780.517 1613423787.0804217
train: epoch 124, iter 1000, loss: 2.186855, top_1: 0.748750, top_k: 0.910508, samples/s: 781.751 1613423819.8273692
train: epoch 124, iter 1100, loss: 2.070494, top_1: 0.749687, top_k: 0.906250, samples/s: 779.529 1613423852.6677709
train: epoch 124, iter 1200, loss: 1.889645, top_1: 0.748008, top_k: 0.909023, samples/s: 783.890 1613423885.325409
train: epoch 124, iter 1300, loss: 2.031635, top_1: 0.745898, top_k: 0.905039, samples/s: 778.639 1613423918.2032201
train: epoch 124, iter 1400, loss: 2.103302, top_1: 0.742383, top_k: 0.908398, samples/s: 782.138 1613423950.9340196
train: epoch 124, iter 1500, loss: 2.077908, top_1: 0.744922, top_k: 0.906445, samples/s: 780.662 1613423983.726797
train: epoch 124, iter 1600, loss: 1.982212, top_1: 0.747266, top_k: 0.907656, samples/s: 780.222 1613424016.5379531
train: epoch 124, iter 1700, loss: 1.997766, top_1: 0.746133, top_k: 0.907383, samples/s: 781.831 1613424049.2815628
train: epoch 124, iter 1800, loss: 2.209070, top_1: 0.745273, top_k: 0.906992, samples/s: 781.596 1613424082.0350912
train: epoch 124, iter 1900, loss: 1.979952, top_1: 0.747734, top_k: 0.905195, samples/s: 779.349 1613424114.8829477
train: epoch 124, iter 2000, loss: 1.935622, top_1: 0.743477, top_k: 0.904766, samples/s: 784.493 1613424147.5155425
train: epoch 124, iter 2100, loss: 1.973474, top_1: 0.740508, top_k: 0.905195, samples/s: 781.166 1613424180.2870224
train: epoch 124, iter 2200, loss: 2.079406, top_1: 0.743945, top_k: 0.908164, samples/s: 781.560 1613424213.0420582
train: epoch 124, iter 2300, loss: 1.918495, top_1: 0.740898, top_k: 0.909258, samples/s: 780.967 1613424245.822007
train: epoch 124, iter 2400, loss: 2.081793, top_1: 0.742891, top_k: 0.903867, samples/s: 779.945 1613424278.6448236
train: epoch 124, iter 2500, loss: 2.064730, top_1: 0.743516, top_k: 0.908789, samples/s: 782.308 1613424311.3685687
train: epoch 124, iter 2600, loss: 1.969513, top_1: 0.741602, top_k: 0.903906, samples/s: 782.647 1613424344.0780213
train: epoch 124, iter 2700, loss: 2.221357, top_1: 0.742344, top_k: 0.905508, samples/s: 779.257 1613424376.929811
train: epoch 124, iter 2800, loss: 2.169649, top_1: 0.740273, top_k: 0.903867, samples/s: 783.131 1613424409.6191213
train: epoch 124, iter 2900, loss: 2.029575, top_1: 0.742070, top_k: 0.907383, samples/s: 780.805 1613424442.405724
train: epoch 124, iter 3000, loss: 2.093861, top_1: 0.741758, top_k: 0.906484, samples/s: 780.723 1613424475.1959014
train: epoch 124, iter 3100, loss: 2.210673, top_1: 0.740625, top_k: 0.904766, samples/s: 784.187 1613424507.8412185
train: epoch 124, iter 3200, loss: 2.101968, top_1: 0.743320, top_k: 0.907578, samples/s: 784.858 1613424540.4584928
train: epoch 124, iter 3300, loss: 2.011327, top_1: 0.743789, top_k: 0.906250, samples/s: 782.884 1613424573.1580532
train: epoch 124, iter 3400, loss: 1.965411, top_1: 0.741406, top_k: 0.905312, samples/s: 781.339 1613424605.9224513
train: epoch 124, iter 3500, loss: 2.084852, top_1: 0.744766, top_k: 0.905352, samples/s: 782.693 1613424638.6299858
train: epoch 124, iter 3600, loss: 1.986592, top_1: 0.744609, top_k: 0.908281, samples/s: 782.060 1613424671.3639998
train: epoch 124, iter 3700, loss: 2.029019, top_1: 0.737070, top_k: 0.902734, samples/s: 782.803 1613424704.0669854
train: epoch 124, iter 3800, loss: 2.181173, top_1: 0.745430, top_k: 0.907188, samples/s: 782.810 1613424736.769736
train: epoch 124, iter 3900, loss: 2.262668, top_1: 0.734648, top_k: 0.903125, samples/s: 779.949 1613424769.592396
train: epoch 124, iter 4000, loss: 2.014245, top_1: 0.742148, top_k: 0.905195, samples/s: 783.303 1613424802.2744691
train: epoch 124, iter 4100, loss: 2.104974, top_1: 0.740195, top_k: 0.904062, samples/s: 781.351 1613424835.0383189
train: epoch 124, iter 4200, loss: 2.064016, top_1: 0.740781, top_k: 0.903164, samples/s: 782.038 1613424867.7733145
train: epoch 124, iter 4300, loss: 2.141882, top_1: 0.737969, top_k: 0.904570, samples/s: 782.969 1613424900.4692562
train: epoch 124, iter 4400, loss: 1.990867, top_1: 0.740273, top_k: 0.904414, samples/s: 780.733 1613424933.258979
train: epoch 124, iter 4500, loss: 1.912438, top_1: 0.742148, top_k: 0.907656, samples/s: 781.623 1613424966.0113914
train: epoch 124, iter 4600, loss: 2.030113, top_1: 0.734531, top_k: 0.898672, samples/s: 782.257 1613424998.7372494
train: epoch 124, iter 4700, loss: 2.147168, top_1: 0.739727, top_k: 0.903125, samples/s: 782.275 1613425031.4628675
train: epoch 124, iter 4800, loss: 1.992157, top_1: 0.737539, top_k: 0.900195, samples/s: 781.126 1613425064.2355108
train: epoch 124, iter 4900, loss: 2.135587, top_1: 0.741914, top_k: 0.902383, samples/s: 781.265 1613425097.003356
train: epoch 124, iter 5000, loss: 2.018260, top_1: 0.751289, top_k: 0.908633, samples/s: 781.124 1613425129.7762337
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_124.
validation: epoch 124, iter 195, top_1: 0.752544, top_k: 0.926502, samples/s: 2338.776 1613425152.0766516
train: epoch 125, iter 100, loss: 1.979625, top_1: 0.755313, top_k: 0.911445, samples/s: 803.730 1613425204.920477
train: epoch 125, iter 200, loss: 2.122180, top_1: 0.761289, top_k: 0.915898, samples/s: 800.410 1613425236.9042993
train: epoch 125, iter 300, loss: 1.843304, top_1: 0.752617, top_k: 0.908398, samples/s: 784.672 1613425269.5291998
train: epoch 125, iter 400, loss: 2.006080, top_1: 0.748125, top_k: 0.907734, samples/s: 780.061 1613425302.3470695
train: epoch 125, iter 500, loss: 1.967975, top_1: 0.752031, top_k: 0.909727, samples/s: 779.908 1613425335.1714635
train: epoch 125, iter 600, loss: 1.971107, top_1: 0.749727, top_k: 0.908711, samples/s: 777.248 1613425368.108189
train: epoch 125, iter 700, loss: 1.967305, top_1: 0.752812, top_k: 0.908906, samples/s: 781.831 1613425400.8518922
train: epoch 125, iter 800, loss: 2.134930, top_1: 0.753555, top_k: 0.911953, samples/s: 779.565 1613425433.6906703
train: epoch 125, iter 900, loss: 2.055362, top_1: 0.747227, top_k: 0.905234, samples/s: 778.863 1613425466.5591323
train: epoch 125, iter 1000, loss: 2.140296, top_1: 0.746641, top_k: 0.906406, samples/s: 783.031 1613425499.252499
train: epoch 125, iter 1100, loss: 2.057920, top_1: 0.750234, top_k: 0.906641, samples/s: 779.466 1613425532.0955992
train: epoch 125, iter 1200, loss: 2.060903, top_1: 0.745625, top_k: 0.908047, samples/s: 780.001 1613425564.9160082
train: epoch 125, iter 1300, loss: 2.102673, top_1: 0.746328, top_k: 0.904219, samples/s: 780.758 1613425597.7047353
train: epoch 125, iter 1400, loss: 2.072304, top_1: 0.748086, top_k: 0.907813, samples/s: 780.944 1613425630.4855657
train: epoch 125, iter 1500, loss: 2.020172, top_1: 0.746797, top_k: 0.909375, samples/s: 780.789 1613425663.272876
train: epoch 125, iter 1600, loss: 2.078975, top_1: 0.749219, top_k: 0.909492, samples/s: 782.443 1613425695.990975
train: epoch 125, iter 1700, loss: 2.034899, top_1: 0.746445, top_k: 0.907695, samples/s: 782.866 1613425728.6912827
train: epoch 125, iter 1800, loss: 2.106488, top_1: 0.750273, top_k: 0.907578, samples/s: 784.584 1613425761.320005
train: epoch 125, iter 1900, loss: 2.013878, top_1: 0.751680, top_k: 0.910781, samples/s: 778.315 1613425794.2116108
train: epoch 125, iter 2000, loss: 1.915578, top_1: 0.746992, top_k: 0.907305, samples/s: 781.858 1613425826.9541516
train: epoch 125, iter 2100, loss: 2.112530, top_1: 0.746797, top_k: 0.907578, samples/s: 781.733 1613425859.7018943
train: epoch 125, iter 2200, loss: 2.077083, top_1: 0.749023, top_k: 0.908984, samples/s: 778.672 1613425892.5784774
train: epoch 125, iter 2300, loss: 2.161398, top_1: 0.744062, top_k: 0.907227, samples/s: 783.115 1613425925.2683086
train: epoch 125, iter 2400, loss: 2.025376, top_1: 0.747344, top_k: 0.909531, samples/s: 781.384 1613425958.0307517
train: epoch 125, iter 2500, loss: 2.256355, top_1: 0.741875, top_k: 0.906914, samples/s: 782.145 1613425990.761242
train: epoch 125, iter 2600, loss: 2.203132, top_1: 0.745156, top_k: 0.905703, samples/s: 783.559 1613426023.4326956
train: epoch 125, iter 2700, loss: 2.109699, top_1: 0.747852, top_k: 0.906641, samples/s: 780.078 1613426056.2499292
train: epoch 125, iter 2800, loss: 1.980001, top_1: 0.746484, top_k: 0.906523, samples/s: 782.993 1613426088.9449358
train: epoch 125, iter 2900, loss: 2.074920, top_1: 0.743594, top_k: 0.907070, samples/s: 781.832 1613426121.6885586
train: epoch 125, iter 3000, loss: 2.077522, top_1: 0.738828, top_k: 0.905508, samples/s: 782.463 1613426154.4058132
train: epoch 125, iter 3100, loss: 2.033066, top_1: 0.745703, top_k: 0.910547, samples/s: 781.873 1613426187.1476083
train: epoch 125, iter 3200, loss: 1.987492, top_1: 0.747734, top_k: 0.908242, samples/s: 781.592 1613426219.9013302
train: epoch 125, iter 3300, loss: 2.063300, top_1: 0.742773, top_k: 0.906172, samples/s: 779.121 1613426252.7588694
train: epoch 125, iter 3400, loss: 2.027458, top_1: 0.744922, top_k: 0.907344, samples/s: 784.788 1613426285.3791246
train: epoch 125, iter 3500, loss: 2.033904, top_1: 0.737578, top_k: 0.901523, samples/s: 781.591 1613426318.132971
train: epoch 125, iter 3600, loss: 2.000350, top_1: 0.749453, top_k: 0.907656, samples/s: 783.355 1613426350.8128297
train: epoch 125, iter 3700, loss: 1.984678, top_1: 0.741563, top_k: 0.906602, samples/s: 779.987 1613426383.633871
train: epoch 125, iter 3800, loss: 2.108918, top_1: 0.748945, top_k: 0.908906, samples/s: 785.061 1613426416.2428133
train: epoch 125, iter 3900, loss: 2.086465, top_1: 0.746523, top_k: 0.906914, samples/s: 783.012 1613426448.9371362
train: epoch 125, iter 4000, loss: 2.055073, top_1: 0.744727, top_k: 0.905977, samples/s: 780.582 1613426481.7332044
train: epoch 125, iter 4100, loss: 2.094830, top_1: 0.742617, top_k: 0.905469, samples/s: 783.443 1613426514.4094758
train: epoch 125, iter 4200, loss: 1.970409, top_1: 0.744766, top_k: 0.904883, samples/s: 780.285 1613426547.2178755
train: epoch 125, iter 4300, loss: 2.033689, top_1: 0.746094, top_k: 0.906289, samples/s: 783.635 1613426579.886265
train: epoch 125, iter 4400, loss: 2.147316, top_1: 0.750391, top_k: 0.908203, samples/s: 780.433 1613426612.6884851
train: epoch 125, iter 4500, loss: 1.966403, top_1: 0.747266, top_k: 0.906523, samples/s: 780.958 1613426645.4687314
train: epoch 125, iter 4600, loss: 2.216688, top_1: 0.742070, top_k: 0.905664, samples/s: 782.757 1613426678.1736107
train: epoch 125, iter 4700, loss: 1.994326, top_1: 0.744414, top_k: 0.907656, samples/s: 782.051 1613426710.9081483
train: epoch 125, iter 4800, loss: 2.037813, top_1: 0.743281, top_k: 0.905742, samples/s: 780.454 1613426743.7095098
train: epoch 125, iter 4900, loss: 2.026375, top_1: 0.745742, top_k: 0.906133, samples/s: 782.116 1613426776.4412537
train: epoch 125, iter 5000, loss: 2.041074, top_1: 0.754648, top_k: 0.911289, samples/s: 782.111 1613426809.1731524
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_125.
validation: epoch 125, iter 195, top_1: 0.751803, top_k: 0.927043, samples/s: 2367.129 1613426831.2420955
train: epoch 126, iter 100, loss: 2.034528, top_1: 0.759492, top_k: 0.913320, samples/s: 803.574 1613426883.536532
train: epoch 126, iter 200, loss: 1.948847, top_1: 0.757070, top_k: 0.913008, samples/s: 797.767 1613426915.6260931
train: epoch 126, iter 300, loss: 1.901404, top_1: 0.756914, top_k: 0.913398, samples/s: 783.830 1613426948.2863393
train: epoch 126, iter 400, loss: 1.954342, top_1: 0.753320, top_k: 0.910508, samples/s: 780.602 1613426981.0815082
train: epoch 126, iter 500, loss: 2.020320, top_1: 0.759062, top_k: 0.912617, samples/s: 780.057 1613427013.8995996
train: epoch 126, iter 600, loss: 2.052140, top_1: 0.754414, top_k: 0.910391, samples/s: 778.737 1613427046.7733924
train: epoch 126, iter 700, loss: 2.000987, top_1: 0.750273, top_k: 0.909023, samples/s: 781.067 1613427079.5490706
train: epoch 126, iter 800, loss: 1.996389, top_1: 0.754180, top_k: 0.909961, samples/s: 782.597 1613427112.2606773
train: epoch 126, iter 900, loss: 2.093698, top_1: 0.759492, top_k: 0.913711, samples/s: 782.727 1613427144.9667509
train: epoch 126, iter 1000, loss: 1.894020, top_1: 0.756406, top_k: 0.909570, samples/s: 780.722 1613427177.7569616
train: epoch 126, iter 1100, loss: 2.074240, top_1: 0.753711, top_k: 0.912773, samples/s: 781.391 1613427210.519003
train: epoch 126, iter 1200, loss: 1.876408, top_1: 0.749297, top_k: 0.904883, samples/s: 780.144 1613427243.3335173
train: epoch 126, iter 1300, loss: 1.987184, top_1: 0.748086, top_k: 0.908672, samples/s: 783.017 1613427276.0275538
train: epoch 126, iter 1400, loss: 2.147202, top_1: 0.748516, top_k: 0.908672, samples/s: 779.991 1613427308.8484175
train: epoch 126, iter 1500, loss: 2.013716, top_1: 0.754648, top_k: 0.911563, samples/s: 782.619 1613427341.5590813
train: epoch 126, iter 1600, loss: 1.979046, top_1: 0.756445, top_k: 0.914727, samples/s: 782.710 1613427374.2660377
train: epoch 126, iter 1700, loss: 1.941838, top_1: 0.754414, top_k: 0.911133, samples/s: 782.884 1613427406.9655857
train: epoch 126, iter 1800, loss: 1.943975, top_1: 0.754023, top_k: 0.909922, samples/s: 782.501 1613427439.681203
train: epoch 126, iter 1900, loss: 2.134385, top_1: 0.754727, top_k: 0.913242, samples/s: 780.834 1613427472.4667296
train: epoch 126, iter 2000, loss: 2.186631, top_1: 0.744258, top_k: 0.907734, samples/s: 781.877 1613427505.2083964
train: epoch 126, iter 2100, loss: 2.058465, top_1: 0.751328, top_k: 0.908633, samples/s: 786.081 1613427537.7749553
train: epoch 126, iter 2200, loss: 2.097657, top_1: 0.749023, top_k: 0.909883, samples/s: 779.847 1613427570.6024191
train: epoch 126, iter 2300, loss: 2.022871, top_1: 0.745977, top_k: 0.907031, samples/s: 784.776 1613427603.222691
train: epoch 126, iter 2400, loss: 2.062919, top_1: 0.743906, top_k: 0.908672, samples/s: 777.111 1613427636.1657646
train: epoch 126, iter 2500, loss: 2.030368, top_1: 0.748672, top_k: 0.906094, samples/s: 784.140 1613427668.812465
train: epoch 126, iter 2600, loss: 1.984195, top_1: 0.750273, top_k: 0.910039, samples/s: 785.632 1613427701.3976247
train: epoch 126, iter 2700, loss: 2.005166, top_1: 0.751094, top_k: 0.908086, samples/s: 781.210 1613427734.1673312
train: epoch 126, iter 2800, loss: 1.880772, top_1: 0.752031, top_k: 0.910391, samples/s: 783.282 1613427766.8502858
train: epoch 126, iter 2900, loss: 1.767579, top_1: 0.751953, top_k: 0.910586, samples/s: 782.586 1613427799.5623524
train: epoch 126, iter 3000, loss: 2.075250, top_1: 0.747539, top_k: 0.911211, samples/s: 780.345 1613427832.3684618
train: epoch 126, iter 3100, loss: 1.922570, top_1: 0.745898, top_k: 0.909766, samples/s: 781.959 1613427865.106729
train: epoch 126, iter 3200, loss: 2.101551, top_1: 0.745234, top_k: 0.905312, samples/s: 783.990 1613427897.7600803
train: epoch 126, iter 3300, loss: 1.888650, top_1: 0.752305, top_k: 0.910703, samples/s: 782.070 1613427930.4937851
train: epoch 126, iter 3400, loss: 1.902480, top_1: 0.746250, top_k: 0.908555, samples/s: 783.165 1613427963.181664
train: epoch 126, iter 3500, loss: 2.079546, top_1: 0.748867, top_k: 0.908750, samples/s: 784.511 1613427995.8134832
train: epoch 126, iter 3600, loss: 2.014651, top_1: 0.748750, top_k: 0.910234, samples/s: 782.670 1613428028.521933
train: epoch 126, iter 3700, loss: 2.008532, top_1: 0.747500, top_k: 0.906367, samples/s: 783.364 1613428061.201513
train: epoch 126, iter 3800, loss: 2.078331, top_1: 0.743594, top_k: 0.909375, samples/s: 782.920 1613428093.8997326
train: epoch 126, iter 3900, loss: 1.908373, top_1: 0.753789, top_k: 0.908594, samples/s: 780.582 1613428126.6957653
train: epoch 126, iter 4000, loss: 2.060934, top_1: 0.746719, top_k: 0.909570, samples/s: 781.660 1613428159.4464624
train: epoch 126, iter 4100, loss: 2.108536, top_1: 0.748047, top_k: 0.910898, samples/s: 782.474 1613428192.1632771
train: epoch 126, iter 4200, loss: 1.977865, top_1: 0.754258, top_k: 0.912617, samples/s: 782.124 1613428224.8946123
train: epoch 126, iter 4300, loss: 1.898302, top_1: 0.745742, top_k: 0.906367, samples/s: 779.619 1613428257.7312555
train: epoch 126, iter 4400, loss: 2.006837, top_1: 0.746250, top_k: 0.909727, samples/s: 784.777 1613428290.3524194
train: epoch 126, iter 4500, loss: 2.139150, top_1: 0.751172, top_k: 0.910781, samples/s: 778.541 1613428323.2339842
train: epoch 126, iter 4600, loss: 1.940904, top_1: 0.750430, top_k: 0.910039, samples/s: 781.815 1613428355.9788156
train: epoch 126, iter 4700, loss: 1.980962, top_1: 0.755313, top_k: 0.910625, samples/s: 783.244 1613428388.6628938
train: epoch 126, iter 4800, loss: 1.959369, top_1: 0.749180, top_k: 0.909727, samples/s: 780.960 1613428421.4430175
train: epoch 126, iter 4900, loss: 2.183743, top_1: 0.749258, top_k: 0.906758, samples/s: 782.476 1613428454.159672
train: epoch 126, iter 5000, loss: 2.070529, top_1: 0.756914, top_k: 0.911953, samples/s: 783.349 1613428486.8398554
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_126.
validation: epoch 126, iter 195, top_1: 0.754307, top_k: 0.927504, samples/s: 2300.998 1613428509.502358
train: epoch 127, iter 100, loss: 2.012655, top_1: 0.760039, top_k: 0.911250, samples/s: 803.595 1613428562.6243045
train: epoch 127, iter 200, loss: 2.033912, top_1: 0.755820, top_k: 0.914766, samples/s: 800.989 1613428594.5848567
train: epoch 127, iter 300, loss: 1.997147, top_1: 0.756953, top_k: 0.912930, samples/s: 785.715 1613428627.1665542
train: epoch 127, iter 400, loss: 2.041830, top_1: 0.759219, top_k: 0.911719, samples/s: 781.064 1613428659.942418
train: epoch 127, iter 500, loss: 1.841439, top_1: 0.761016, top_k: 0.913125, samples/s: 778.814 1613428692.8128645
train: epoch 127, iter 600, loss: 2.030051, top_1: 0.758672, top_k: 0.913867, samples/s: 778.686 1613428725.6887312
train: epoch 127, iter 700, loss: 1.959999, top_1: 0.763867, top_k: 0.917109, samples/s: 783.927 1613428758.344904
train: epoch 127, iter 800, loss: 1.949869, top_1: 0.758789, top_k: 0.911875, samples/s: 782.070 1613428791.0784206
train: epoch 127, iter 900, loss: 2.017753, top_1: 0.755938, top_k: 0.913359, samples/s: 777.213 1613428824.0167294
train: epoch 127, iter 1000, loss: 1.982890, top_1: 0.754766, top_k: 0.909883, samples/s: 782.302 1613428856.7406611
train: epoch 127, iter 1100, loss: 2.122899, top_1: 0.758672, top_k: 0.910508, samples/s: 783.191 1613428889.427428
train: epoch 127, iter 1200, loss: 2.025709, top_1: 0.755664, top_k: 0.912188, samples/s: 781.664 1613428922.1780584
train: epoch 127, iter 1300, loss: 1.945756, top_1: 0.753594, top_k: 0.913750, samples/s: 779.542 1613428955.0178401
train: epoch 127, iter 1400, loss: 2.007335, top_1: 0.756211, top_k: 0.909648, samples/s: 781.329 1613428987.7825766
train: epoch 127, iter 1500, loss: 2.133498, top_1: 0.754727, top_k: 0.910742, samples/s: 782.560 1613429020.4957278
train: epoch 127, iter 1600, loss: 2.129048, top_1: 0.755508, top_k: 0.913359, samples/s: 780.114 1613429053.3114054
train: epoch 127, iter 1700, loss: 1.924221, top_1: 0.755000, top_k: 0.910352, samples/s: 783.360 1613429085.9912767
train: epoch 127, iter 1800, loss: 2.079803, top_1: 0.757305, top_k: 0.912539, samples/s: 780.080 1613429118.808421
train: epoch 127, iter 1900, loss: 1.963761, top_1: 0.758008, top_k: 0.912695, samples/s: 781.591 1613429151.5626912
train: epoch 127, iter 2000, loss: 1.973612, top_1: 0.751680, top_k: 0.911445, samples/s: 780.577 1613429184.3584645
train: epoch 127, iter 2100, loss: 2.205644, top_1: 0.752148, top_k: 0.908711, samples/s: 781.011 1613429217.1367905
train: epoch 127, iter 2200, loss: 1.967919, top_1: 0.748320, top_k: 0.908594, samples/s: 782.544 1613429249.8501983
train: epoch 127, iter 2300, loss: 2.033654, top_1: 0.753945, top_k: 0.913555, samples/s: 785.032 1613429282.4603524
train: epoch 127, iter 2400, loss: 2.202370, top_1: 0.759844, top_k: 0.911289, samples/s: 781.637 1613429315.2120564
train: epoch 127, iter 2500, loss: 2.023669, top_1: 0.751602, top_k: 0.910430, samples/s: 782.516 1613429347.9270625
train: epoch 127, iter 2600, loss: 2.161722, top_1: 0.748555, top_k: 0.910273, samples/s: 782.521 1613429380.641789
train: epoch 127, iter 2700, loss: 1.979521, top_1: 0.757422, top_k: 0.911641, samples/s: 784.575 1613429413.2710268
train: epoch 127, iter 2800, loss: 2.048073, top_1: 0.752930, top_k: 0.910742, samples/s: 780.684 1613429446.0627697
train: epoch 127, iter 2900, loss: 2.063963, top_1: 0.752656, top_k: 0.908086, samples/s: 782.327 1613429478.7856133
train: epoch 127, iter 3000, loss: 1.974442, top_1: 0.748750, top_k: 0.910508, samples/s: 781.745 1613429511.5328653
train: epoch 127, iter 3100, loss: 2.019432, top_1: 0.749297, top_k: 0.911250, samples/s: 782.961 1613429544.2293363
train: epoch 127, iter 3200, loss: 1.911545, top_1: 0.755391, top_k: 0.913125, samples/s: 784.063 1613429576.8796694
train: epoch 127, iter 3300, loss: 2.049101, top_1: 0.752773, top_k: 0.911172, samples/s: 777.811 1613429609.792666
train: epoch 127, iter 3400, loss: 1.972661, top_1: 0.757383, top_k: 0.914961, samples/s: 785.761 1613429642.3725433
train: epoch 127, iter 3500, loss: 2.031407, top_1: 0.753008, top_k: 0.910000, samples/s: 781.700 1613429675.121718
train: epoch 127, iter 3600, loss: 2.199610, top_1: 0.747617, top_k: 0.908867, samples/s: 782.862 1613429707.822213
train: epoch 127, iter 3700, loss: 1.932408, top_1: 0.753320, top_k: 0.908203, samples/s: 780.904 1613429740.6047304
train: epoch 127, iter 3800, loss: 2.137783, top_1: 0.754258, top_k: 0.911133, samples/s: 783.184 1613429773.2918208
train: epoch 127, iter 3900, loss: 1.957932, top_1: 0.749844, top_k: 0.908242, samples/s: 781.987 1613429806.0288928
train: epoch 127, iter 4000, loss: 2.029397, top_1: 0.750742, top_k: 0.907969, samples/s: 784.773 1613429838.6497638
train: epoch 127, iter 4100, loss: 2.022977, top_1: 0.748320, top_k: 0.910469, samples/s: 780.706 1613429871.4406028
train: epoch 127, iter 4200, loss: 1.926673, top_1: 0.752109, top_k: 0.912461, samples/s: 783.486 1613429904.1151195
train: epoch 127, iter 4300, loss: 2.055196, top_1: 0.752891, top_k: 0.911289, samples/s: 781.023 1613429936.8926082
train: epoch 127, iter 4400, loss: 2.017533, top_1: 0.747578, top_k: 0.910430, samples/s: 782.457 1613429969.610126
train: epoch 127, iter 4500, loss: 2.137788, top_1: 0.748750, top_k: 0.909648, samples/s: 781.944 1613430002.3489223
train: epoch 127, iter 4600, loss: 2.015631, top_1: 0.754844, top_k: 0.910195, samples/s: 780.279 1613430035.1577656
train: epoch 127, iter 4700, loss: 2.053697, top_1: 0.748125, top_k: 0.908242, samples/s: 784.205 1613430067.8022485
train: epoch 127, iter 4800, loss: 2.128283, top_1: 0.747227, top_k: 0.908047, samples/s: 780.806 1613430100.5889232
train: epoch 127, iter 4900, loss: 2.108504, top_1: 0.753047, top_k: 0.911719, samples/s: 782.292 1613430133.3133476
train: epoch 127, iter 5000, loss: 1.913849, top_1: 0.760430, top_k: 0.912344, samples/s: 783.546 1613430165.9852848
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_127.
validation: epoch 127, iter 195, top_1: 0.757752, top_k: 0.929928, samples/s: 2360.317 1613430188.1055853
train: epoch 128, iter 100, loss: 1.867454, top_1: 0.764219, top_k: 0.916523, samples/s: 804.402 1613430240.5172865
train: epoch 128, iter 200, loss: 2.016160, top_1: 0.759492, top_k: 0.914375, samples/s: 800.597 1613430272.4934325
train: epoch 128, iter 300, loss: 1.924048, top_1: 0.761992, top_k: 0.915156, samples/s: 784.350 1613430305.1320455
train: epoch 128, iter 400, loss: 2.139023, top_1: 0.762070, top_k: 0.914922, samples/s: 781.126 1613430337.905101
train: epoch 128, iter 500, loss: 1.886645, top_1: 0.765469, top_k: 0.917500, samples/s: 780.030 1613430370.7243843
train: epoch 128, iter 600, loss: 1.793089, top_1: 0.767031, top_k: 0.915820, samples/s: 780.005 1613430403.5445755
train: epoch 128, iter 700, loss: 1.880536, top_1: 0.764023, top_k: 0.915430, samples/s: 781.978 1613430436.2820508
train: epoch 128, iter 800, loss: 2.030525, top_1: 0.761602, top_k: 0.914922, samples/s: 780.211 1613430469.0937572
train: epoch 128, iter 900, loss: 1.895479, top_1: 0.756406, top_k: 0.913086, samples/s: 780.782 1613430501.8813186
train: epoch 128, iter 1000, loss: 2.051292, top_1: 0.762734, top_k: 0.915039, samples/s: 783.562 1613430534.552733
train: epoch 128, iter 1100, loss: 2.049427, top_1: 0.758047, top_k: 0.915039, samples/s: 780.123 1613430567.3679717
train: epoch 128, iter 1200, loss: 1.851262, top_1: 0.761563, top_k: 0.915391, samples/s: 782.846 1613430600.0692167
train: epoch 128, iter 1300, loss: 1.987639, top_1: 0.760781, top_k: 0.913750, samples/s: 780.655 1613430632.862213
train: epoch 128, iter 1400, loss: 1.969643, top_1: 0.755547, top_k: 0.912109, samples/s: 782.261 1613430665.5878472
train: epoch 128, iter 1500, loss: 1.952225, top_1: 0.762969, top_k: 0.915547, samples/s: 780.729 1613430698.3777916
train: epoch 128, iter 1600, loss: 1.976146, top_1: 0.758047, top_k: 0.912813, samples/s: 783.135 1613430731.066966
train: epoch 128, iter 1700, loss: 2.051917, top_1: 0.759805, top_k: 0.915859, samples/s: 783.703 1613430763.7322633
train: epoch 128, iter 1800, loss: 2.054547, top_1: 0.757070, top_k: 0.912266, samples/s: 779.911 1613430796.5566206
train: epoch 128, iter 1900, loss: 1.963502, top_1: 0.760469, top_k: 0.912422, samples/s: 781.819 1613430829.300641
train: epoch 128, iter 2000, loss: 2.037003, top_1: 0.754648, top_k: 0.911641, samples/s: 784.003 1613430861.9536426
train: epoch 128, iter 2100, loss: 1.990445, top_1: 0.756289, top_k: 0.912383, samples/s: 780.753 1613430894.7424304
train: epoch 128, iter 2200, loss: 1.920468, top_1: 0.754141, top_k: 0.910352, samples/s: 782.708 1613430927.4494956
train: epoch 128, iter 2300, loss: 1.931301, top_1: 0.758945, top_k: 0.914414, samples/s: 783.114 1613430960.1393826
train: epoch 128, iter 2400, loss: 1.935972, top_1: 0.759023, top_k: 0.913125, samples/s: 780.529 1613430992.9377408
train: epoch 128, iter 2500, loss: 2.015776, top_1: 0.759180, top_k: 0.914609, samples/s: 783.090 1613431025.6286912
train: epoch 128, iter 2600, loss: 1.984285, top_1: 0.755000, top_k: 0.911953, samples/s: 780.951 1613431058.4092531
train: epoch 128, iter 2700, loss: 2.120723, top_1: 0.754648, top_k: 0.913047, samples/s: 781.927 1613431091.1489134
train: epoch 128, iter 2800, loss: 1.963690, top_1: 0.754023, top_k: 0.910625, samples/s: 780.017 1613431123.96871
train: epoch 128, iter 2900, loss: 1.961721, top_1: 0.754297, top_k: 0.910352, samples/s: 784.021 1613431156.6208348
train: epoch 128, iter 3000, loss: 2.122349, top_1: 0.757266, top_k: 0.912344, samples/s: 779.922 1613431189.4446366
train: epoch 128, iter 3100, loss: 2.058672, top_1: 0.755625, top_k: 0.911641, samples/s: 782.830 1613431222.1465745
train: epoch 128, iter 3200, loss: 1.919453, top_1: 0.759766, top_k: 0.912734, samples/s: 778.077 1613431255.0481243
train: epoch 128, iter 3300, loss: 2.084757, top_1: 0.753086, top_k: 0.910781, samples/s: 782.735 1613431287.7539256
train: epoch 128, iter 3400, loss: 2.023069, top_1: 0.752656, top_k: 0.908594, samples/s: 781.691 1613431320.5036259
train: epoch 128, iter 3500, loss: 1.830286, top_1: 0.759687, top_k: 0.914297, samples/s: 779.860 1613431353.3300047
train: epoch 128, iter 3600, loss: 1.965409, top_1: 0.752930, top_k: 0.909297, samples/s: 781.264 1613431386.0973358
train: epoch 128, iter 3700, loss: 2.027791, top_1: 0.756836, top_k: 0.910508, samples/s: 782.441 1613431418.8155563
train: epoch 128, iter 3800, loss: 1.799442, top_1: 0.757070, top_k: 0.914180, samples/s: 781.551 1613431451.570883
train: epoch 128, iter 3900, loss: 1.915202, top_1: 0.755938, top_k: 0.913828, samples/s: 781.808 1613431484.3153954
train: epoch 128, iter 4000, loss: 2.103873, top_1: 0.753359, top_k: 0.911445, samples/s: 781.375 1613431517.0781775
train: epoch 128, iter 4100, loss: 2.054377, top_1: 0.763281, top_k: 0.914023, samples/s: 781.099 1613431549.8526287
train: epoch 128, iter 4200, loss: 2.082244, top_1: 0.755313, top_k: 0.915586, samples/s: 783.242 1613431582.5372722
train: epoch 128, iter 4300, loss: 2.071991, top_1: 0.754883, top_k: 0.911250, samples/s: 780.551 1613431615.3346124
train: epoch 128, iter 4400, loss: 1.832231, top_1: 0.757695, top_k: 0.912422, samples/s: 782.786 1613431648.0382726
train: epoch 128, iter 4500, loss: 1.946498, top_1: 0.759844, top_k: 0.911680, samples/s: 782.663 1613431680.7471478
train: epoch 128, iter 4600, loss: 2.013136, top_1: 0.757461, top_k: 0.914023, samples/s: 783.690 1613431713.4130678
train: epoch 128, iter 4700, loss: 1.995172, top_1: 0.752031, top_k: 0.911836, samples/s: 780.245 1613431746.2233639
train: epoch 128, iter 4800, loss: 1.925739, top_1: 0.755078, top_k: 0.911875, samples/s: 782.964 1613431778.919562
train: epoch 128, iter 4900, loss: 2.214152, top_1: 0.752148, top_k: 0.908633, samples/s: 779.908 1613431811.7439811
train: epoch 128, iter 5000, loss: 1.970207, top_1: 0.761016, top_k: 0.913008, samples/s: 780.716 1613431844.5343423
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_128.
validation: epoch 128, iter 195, top_1: 0.756651, top_k: 0.928686, samples/s: 2372.120 1613431866.5186768
train: epoch 129, iter 100, loss: 2.011764, top_1: 0.762578, top_k: 0.915625, samples/s: 802.909 1613431918.654066
train: epoch 129, iter 200, loss: 2.091228, top_1: 0.763086, top_k: 0.915977, samples/s: 799.819 1613431950.6613228
train: epoch 129, iter 300, loss: 2.101740, top_1: 0.767344, top_k: 0.919805, samples/s: 786.009 1613431983.230893
train: epoch 129, iter 400, loss: 1.941303, top_1: 0.766445, top_k: 0.917148, samples/s: 781.577 1613432015.9854665
train: epoch 129, iter 500, loss: 2.044824, top_1: 0.763594, top_k: 0.915820, samples/s: 779.313 1613432048.8346062
train: epoch 129, iter 600, loss: 1.888621, top_1: 0.767305, top_k: 0.918086, samples/s: 782.736 1613432081.5404716
train: epoch 129, iter 700, loss: 1.917714, top_1: 0.761445, top_k: 0.916094, samples/s: 781.888 1613432114.2816947
train: epoch 129, iter 800, loss: 1.885328, top_1: 0.761602, top_k: 0.916484, samples/s: 781.703 1613432147.0308058
train: epoch 129, iter 900, loss: 2.071434, top_1: 0.767305, top_k: 0.917344, samples/s: 781.874 1613432179.7725654
train: epoch 129, iter 1000, loss: 2.048785, top_1: 0.764375, top_k: 0.916055, samples/s: 780.691 1613432212.564084
train: epoch 129, iter 1100, loss: 1.981201, top_1: 0.763750, top_k: 0.916875, samples/s: 780.778 1613432245.3518634
train: epoch 129, iter 1200, loss: 2.151167, top_1: 0.765312, top_k: 0.915312, samples/s: 781.875 1613432278.0936635
train: epoch 129, iter 1300, loss: 1.989538, top_1: 0.758672, top_k: 0.914492, samples/s: 783.434 1613432310.770427
train: epoch 129, iter 1400, loss: 2.116513, top_1: 0.763242, top_k: 0.914766, samples/s: 782.081 1613432343.5035267
train: epoch 129, iter 1500, loss: 1.942525, top_1: 0.764805, top_k: 0.916328, samples/s: 780.823 1613432376.2894304
train: epoch 129, iter 1600, loss: 2.141914, top_1: 0.762930, top_k: 0.914492, samples/s: 781.012 1613432409.0674245
train: epoch 129, iter 1700, loss: 1.873513, top_1: 0.759141, top_k: 0.913906, samples/s: 781.742 1613432441.8147745
train: epoch 129, iter 1800, loss: 1.940956, top_1: 0.761914, top_k: 0.916094, samples/s: 781.617 1613432474.5674715
train: epoch 129, iter 1900, loss: 2.008600, top_1: 0.762344, top_k: 0.916602, samples/s: 782.048 1613432507.301908
train: epoch 129, iter 2000, loss: 2.112019, top_1: 0.760273, top_k: 0.915937, samples/s: 780.867 1613432540.086038
train: epoch 129, iter 2100, loss: 1.943035, top_1: 0.758906, top_k: 0.914453, samples/s: 784.190 1613432572.7312016
train: epoch 129, iter 2200, loss: 2.061588, top_1: 0.757109, top_k: 0.914258, samples/s: 784.067 1613432605.3815405
train: epoch 129, iter 2300, loss: 2.021473, top_1: 0.761992, top_k: 0.915742, samples/s: 782.721 1613432638.0879264
train: epoch 129, iter 2400, loss: 2.073989, top_1: 0.763086, top_k: 0.915547, samples/s: 780.992 1613432670.8667808
train: epoch 129, iter 2500, loss: 2.201026, top_1: 0.760664, top_k: 0.915898, samples/s: 784.097 1613432703.515816
train: epoch 129, iter 2600, loss: 1.889237, top_1: 0.762930, top_k: 0.915078, samples/s: 782.228 1613432736.2427685
train: epoch 129, iter 2700, loss: 1.917694, top_1: 0.755859, top_k: 0.911953, samples/s: 781.199 1613432769.0128846
train: epoch 129, iter 2800, loss: 2.067443, top_1: 0.762500, top_k: 0.913594, samples/s: 784.971 1613432801.6256146
train: epoch 129, iter 2900, loss: 1.961220, top_1: 0.759648, top_k: 0.914531, samples/s: 781.332 1613432834.3901742
train: epoch 129, iter 3000, loss: 2.037422, top_1: 0.761172, top_k: 0.914258, samples/s: 782.869 1613432867.0904057
train: epoch 129, iter 3100, loss: 1.930109, top_1: 0.759844, top_k: 0.914883, samples/s: 783.224 1613432899.775771
train: epoch 129, iter 3200, loss: 2.079628, top_1: 0.759141, top_k: 0.911406, samples/s: 780.877 1613432932.5595074
train: epoch 129, iter 3300, loss: 1.984460, top_1: 0.757773, top_k: 0.912422, samples/s: 783.529 1613432965.2321827
train: epoch 129, iter 3400, loss: 1.940541, top_1: 0.757852, top_k: 0.916211, samples/s: 782.505 1613432997.9475582
train: epoch 129, iter 3500, loss: 2.127010, top_1: 0.760273, top_k: 0.916992, samples/s: 782.436 1613433030.6659641
train: epoch 129, iter 3600, loss: 2.079405, top_1: 0.754648, top_k: 0.913125, samples/s: 781.975 1613433063.4034445
train: epoch 129, iter 3700, loss: 1.827610, top_1: 0.761719, top_k: 0.913828, samples/s: 782.776 1613433096.1075747
train: epoch 129, iter 3800, loss: 2.062926, top_1: 0.761250, top_k: 0.913438, samples/s: 783.121 1613433128.7972786
train: epoch 129, iter 3900, loss: 1.868622, top_1: 0.759336, top_k: 0.911523, samples/s: 781.050 1613433161.573723
train: epoch 129, iter 4000, loss: 2.031430, top_1: 0.759687, top_k: 0.915391, samples/s: 782.226 1613433194.3007696
train: epoch 129, iter 4100, loss: 1.975344, top_1: 0.757227, top_k: 0.911680, samples/s: 783.350 1613433226.9809694
train: epoch 129, iter 4200, loss: 1.908070, top_1: 0.760078, top_k: 0.913281, samples/s: 778.966 1613433259.8450944
train: epoch 129, iter 4300, loss: 2.144054, top_1: 0.753906, top_k: 0.913555, samples/s: 783.973 1613433292.49922
train: epoch 129, iter 4400, loss: 1.918221, top_1: 0.755938, top_k: 0.914023, samples/s: 784.218 1613433325.14325
train: epoch 129, iter 4500, loss: 1.975063, top_1: 0.753633, top_k: 0.910352, samples/s: 781.980 1613433357.8807156
train: epoch 129, iter 4600, loss: 2.090445, top_1: 0.756172, top_k: 0.913398, samples/s: 782.412 1613433390.5999734
train: epoch 129, iter 4700, loss: 1.952034, top_1: 0.753750, top_k: 0.912148, samples/s: 781.805 1613433423.3447523
train: epoch 129, iter 4800, loss: 2.040169, top_1: 0.758633, top_k: 0.913086, samples/s: 783.096 1613433456.0354269
train: epoch 129, iter 4900, loss: 1.864747, top_1: 0.755352, top_k: 0.913672, samples/s: 781.836 1613433488.778845
train: epoch 129, iter 5000, loss: 1.943937, top_1: 0.764687, top_k: 0.915586, samples/s: 781.338 1613433521.5431273
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_129.
validation: epoch 129, iter 195, top_1: 0.759135, top_k: 0.930529, samples/s: 2368.086 1613433543.6097372
train: epoch 130, iter 100, loss: 1.943736, top_1: 0.769766, top_k: 0.919453, samples/s: 804.119 1613433596.0475843
train: epoch 130, iter 200, loss: 1.890206, top_1: 0.766836, top_k: 0.917188, samples/s: 801.306 1613433627.9953907
train: epoch 130, iter 300, loss: 1.964919, top_1: 0.766328, top_k: 0.918203, samples/s: 783.371 1613433660.6747124
train: epoch 130, iter 400, loss: 2.246000, top_1: 0.768477, top_k: 0.917734, samples/s: 779.624 1613433693.510955
train: epoch 130, iter 500, loss: 2.068174, top_1: 0.766875, top_k: 0.916211, samples/s: 782.222 1613433726.238496
train: epoch 130, iter 600, loss: 1.977448, top_1: 0.767695, top_k: 0.918438, samples/s: 779.821 1613433759.0662534
train: epoch 130, iter 700, loss: 2.009762, top_1: 0.771445, top_k: 0.920352, samples/s: 780.039 1613433791.8851907
train: epoch 130, iter 800, loss: 1.940379, top_1: 0.767930, top_k: 0.918789, samples/s: 782.226 1613433824.612304
train: epoch 130, iter 900, loss: 1.941462, top_1: 0.766563, top_k: 0.918086, samples/s: 781.746 1613433857.3595273
train: epoch 130, iter 1000, loss: 1.897193, top_1: 0.766992, top_k: 0.919336, samples/s: 781.007 1613433890.1376328
train: epoch 130, iter 1100, loss: 1.877114, top_1: 0.769570, top_k: 0.916484, samples/s: 780.668 1613433922.9300656
train: epoch 130, iter 1200, loss: 1.887638, top_1: 0.765156, top_k: 0.917773, samples/s: 781.306 1613433955.6957653
train: epoch 130, iter 1300, loss: 2.002166, top_1: 0.767266, top_k: 0.918398, samples/s: 780.544 1613433988.4934268
train: epoch 130, iter 1400, loss: 1.854337, top_1: 0.761211, top_k: 0.917227, samples/s: 780.659 1613434021.2861466
train: epoch 130, iter 1500, loss: 1.906940, top_1: 0.767734, top_k: 0.917070, samples/s: 780.961 1613434054.0663185
train: epoch 130, iter 1600, loss: 2.041098, top_1: 0.766133, top_k: 0.915820, samples/s: 783.676 1613434086.7328591
train: epoch 130, iter 1700, loss: 2.128094, top_1: 0.763789, top_k: 0.917773, samples/s: 781.763 1613434119.479429
train: epoch 130, iter 1800, loss: 2.007656, top_1: 0.766289, top_k: 0.918164, samples/s: 781.790 1613434152.2247367
train: epoch 130, iter 1900, loss: 1.998186, top_1: 0.771641, top_k: 0.920742, samples/s: 782.374 1613434184.9456518
train: epoch 130, iter 2000, loss: 2.136462, top_1: 0.768281, top_k: 0.916367, samples/s: 783.459 1613434217.6212935
train: epoch 130, iter 2100, loss: 1.868406, top_1: 0.760586, top_k: 0.915977, samples/s: 781.430 1613434250.3817987
train: epoch 130, iter 2200, loss: 1.870890, top_1: 0.761523, top_k: 0.914805, samples/s: 778.738 1613434283.2554893
train: epoch 130, iter 2300, loss: 1.960036, top_1: 0.763633, top_k: 0.915898, samples/s: 783.373 1613434315.9345853
train: epoch 130, iter 2400, loss: 1.915172, top_1: 0.766563, top_k: 0.913320, samples/s: 782.410 1613434348.6541393
train: epoch 130, iter 2500, loss: 2.066702, top_1: 0.769687, top_k: 0.919883, samples/s: 782.238 1613434381.3806016
train: epoch 130, iter 2600, loss: 2.005958, top_1: 0.766523, top_k: 0.917305, samples/s: 780.224 1613434414.1917796
train: epoch 130, iter 2700, loss: 2.035890, top_1: 0.760703, top_k: 0.913906, samples/s: 781.068 1613434446.9673872
train: epoch 130, iter 2800, loss: 1.874732, top_1: 0.766172, top_k: 0.916562, samples/s: 783.273 1613434479.6507232
train: epoch 130, iter 2900, loss: 2.020824, top_1: 0.767734, top_k: 0.916328, samples/s: 780.673 1613434512.4429498
train: epoch 130, iter 3000, loss: 1.804331, top_1: 0.760273, top_k: 0.916484, samples/s: 781.713 1613434545.1916118
train: epoch 130, iter 3100, loss: 2.015700, top_1: 0.762773, top_k: 0.915391, samples/s: 781.765 1613434577.9379373
train: epoch 130, iter 3200, loss: 1.992308, top_1: 0.767852, top_k: 0.915937, samples/s: 781.682 1613434610.6878016
train: epoch 130, iter 3300, loss: 1.963770, top_1: 0.760391, top_k: 0.915586, samples/s: 781.851 1613434643.430725
train: epoch 130, iter 3400, loss: 1.919444, top_1: 0.762891, top_k: 0.917031, samples/s: 779.520 1613434676.2713213
train: epoch 130, iter 3500, loss: 2.053352, top_1: 0.766250, top_k: 0.917852, samples/s: 783.847 1613434708.9307773
train: epoch 130, iter 3600, loss: 1.952939, top_1: 0.758125, top_k: 0.911836, samples/s: 782.435 1613434741.649225
train: epoch 130, iter 3700, loss: 1.816895, top_1: 0.763164, top_k: 0.915391, samples/s: 782.005 1613434774.3855522
train: epoch 130, iter 3800, loss: 1.851701, top_1: 0.765156, top_k: 0.915039, samples/s: 782.590 1613434807.0974302
train: epoch 130, iter 3900, loss: 2.061607, top_1: 0.757031, top_k: 0.914805, samples/s: 779.461 1613434839.9406893
train: epoch 130, iter 4000, loss: 2.029055, top_1: 0.763633, top_k: 0.918008, samples/s: 783.177 1613434872.6280768
train: epoch 130, iter 4100, loss: 2.076091, top_1: 0.761641, top_k: 0.915547, samples/s: 783.062 1613434905.3201754
train: epoch 130, iter 4200, loss: 2.065124, top_1: 0.756484, top_k: 0.915430, samples/s: 782.605 1613434938.0315287
train: epoch 130, iter 4300, loss: 1.995899, top_1: 0.764180, top_k: 0.916406, samples/s: 781.910 1613434970.771851
train: epoch 130, iter 4400, loss: 1.983810, top_1: 0.763359, top_k: 0.917695, samples/s: 783.989 1613435003.4254074
train: epoch 130, iter 4500, loss: 1.976690, top_1: 0.764297, top_k: 0.916055, samples/s: 781.003 1613435036.2037668
train: epoch 130, iter 4600, loss: 1.934815, top_1: 0.762344, top_k: 0.917500, samples/s: 782.822 1613435068.9059503
train: epoch 130, iter 4700, loss: 1.973206, top_1: 0.761523, top_k: 0.915156, samples/s: 783.067 1613435101.5978553
train: epoch 130, iter 4800, loss: 2.064266, top_1: 0.756602, top_k: 0.913555, samples/s: 780.576 1613435134.3941493
train: epoch 130, iter 4900, loss: 1.947868, top_1: 0.764492, top_k: 0.916094, samples/s: 782.471 1613435167.1109686
train: epoch 130, iter 5000, loss: 1.888047, top_1: 0.766602, top_k: 0.920937, samples/s: 785.232 1613435199.712867
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_130.
validation: epoch 130, iter 195, top_1: 0.761599, top_k: 0.931010, samples/s: 2373.831 1613435221.7463996
train: epoch 131, iter 100, loss: 2.055865, top_1: 0.777461, top_k: 0.921680, samples/s: 802.755 1613435274.1433506
train: epoch 131, iter 200, loss: 1.954810, top_1: 0.774727, top_k: 0.923555, samples/s: 799.376 1613435306.1683457
train: epoch 131, iter 300, loss: 1.843273, top_1: 0.776367, top_k: 0.920703, samples/s: 785.577 1613435338.7559314
train: epoch 131, iter 400, loss: 1.960583, top_1: 0.769648, top_k: 0.918359, samples/s: 777.721 1613435371.672814
train: epoch 131, iter 500, loss: 2.017223, top_1: 0.768047, top_k: 0.916211, samples/s: 784.162 1613435404.318826
train: epoch 131, iter 600, loss: 1.841462, top_1: 0.769609, top_k: 0.918828, samples/s: 780.325 1613435437.1257198
train: epoch 131, iter 700, loss: 1.918194, top_1: 0.773008, top_k: 0.921641, samples/s: 780.616 1613435469.9203038
train: epoch 131, iter 800, loss: 2.006608, top_1: 0.771641, top_k: 0.918047, samples/s: 782.306 1613435502.6441417
train: epoch 131, iter 900, loss: 1.937562, top_1: 0.776445, top_k: 0.920156, samples/s: 779.123 1613435535.5016303
train: epoch 131, iter 1000, loss: 1.882910, top_1: 0.769492, top_k: 0.920156, samples/s: 782.257 1613435568.2273922
train: epoch 131, iter 1100, loss: 1.957699, top_1: 0.773711, top_k: 0.919805, samples/s: 784.906 1613435600.8426757
train: epoch 131, iter 1200, loss: 1.860399, top_1: 0.773672, top_k: 0.919922, samples/s: 780.277 1613435633.651542
train: epoch 131, iter 1300, loss: 1.979206, top_1: 0.771680, top_k: 0.915391, samples/s: 782.226 1613435666.3787758
train: epoch 131, iter 1400, loss: 1.880575, top_1: 0.770430, top_k: 0.920820, samples/s: 783.160 1613435699.0667572
train: epoch 131, iter 1500, loss: 2.065690, top_1: 0.766289, top_k: 0.917578, samples/s: 779.068 1613435731.9265518
train: epoch 131, iter 1600, loss: 1.957222, top_1: 0.770977, top_k: 0.919180, samples/s: 781.421 1613435764.6873825
train: epoch 131, iter 1700, loss: 2.120589, top_1: 0.769297, top_k: 0.916758, samples/s: 782.190 1613435797.4160328
train: epoch 131, iter 1800, loss: 1.998483, top_1: 0.768750, top_k: 0.916328, samples/s: 780.061 1613435830.233941
train: epoch 131, iter 1900, loss: 1.903991, top_1: 0.764883, top_k: 0.916797, samples/s: 781.697 1613435862.9832275
train: epoch 131, iter 2000, loss: 1.995998, top_1: 0.766250, top_k: 0.918555, samples/s: 782.202 1613435895.711352
train: epoch 131, iter 2100, loss: 1.886442, top_1: 0.769062, top_k: 0.915742, samples/s: 780.737 1613435928.5009122
train: epoch 131, iter 2200, loss: 1.997027, top_1: 0.768633, top_k: 0.918203, samples/s: 784.349 1613435961.139432
train: epoch 131, iter 2300, loss: 1.918348, top_1: 0.765898, top_k: 0.916992, samples/s: 780.540 1613435993.9371614
train: epoch 131, iter 2400, loss: 1.949909, top_1: 0.766211, top_k: 0.918789, samples/s: 783.103 1613436026.6276734
train: epoch 131, iter 2500, loss: 1.965098, top_1: 0.764492, top_k: 0.914766, samples/s: 781.916 1613436059.3677297
train: epoch 131, iter 2600, loss: 1.903587, top_1: 0.763086, top_k: 0.916289, samples/s: 780.623 1613436092.1622221
train: epoch 131, iter 2700, loss: 1.868567, top_1: 0.771602, top_k: 0.919063, samples/s: 782.283 1613436124.8868728
train: epoch 131, iter 2800, loss: 1.989569, top_1: 0.768516, top_k: 0.918867, samples/s: 785.916 1613436157.4602916
train: epoch 131, iter 2900, loss: 2.004257, top_1: 0.766680, top_k: 0.915820, samples/s: 781.601 1613436190.213646
train: epoch 131, iter 3000, loss: 2.018470, top_1: 0.769180, top_k: 0.918555, samples/s: 781.070 1613436222.989191
train: epoch 131, iter 3100, loss: 1.832929, top_1: 0.767734, top_k: 0.917148, samples/s: 782.106 1613436255.7213302
train: epoch 131, iter 3200, loss: 1.861449, top_1: 0.765195, top_k: 0.915156, samples/s: 783.925 1613436288.3774214
train: epoch 131, iter 3300, loss: 1.934982, top_1: 0.766836, top_k: 0.918125, samples/s: 782.131 1613436321.1085918
train: epoch 131, iter 3400, loss: 2.008316, top_1: 0.766875, top_k: 0.915391, samples/s: 782.464 1613436353.8256702
train: epoch 131, iter 3500, loss: 1.930910, top_1: 0.760547, top_k: 0.914687, samples/s: 781.550 1613436386.5810938
train: epoch 131, iter 3600, loss: 1.978682, top_1: 0.767891, top_k: 0.918672, samples/s: 782.606 1613436419.292296
train: epoch 131, iter 3700, loss: 1.930644, top_1: 0.767734, top_k: 0.918477, samples/s: 785.056 1613436451.9014301
train: epoch 131, iter 3800, loss: 2.132417, top_1: 0.763516, top_k: 0.915547, samples/s: 782.303 1613436484.6253724
train: epoch 131, iter 3900, loss: 2.051913, top_1: 0.770508, top_k: 0.918516, samples/s: 781.632 1613436517.3772962
train: epoch 131, iter 4000, loss: 2.016063, top_1: 0.765703, top_k: 0.919141, samples/s: 779.885 1613436550.2026608
train: epoch 131, iter 4100, loss: 1.919826, top_1: 0.767109, top_k: 0.919023, samples/s: 781.601 1613436582.9560494
train: epoch 131, iter 4200, loss: 2.192450, top_1: 0.761133, top_k: 0.918086, samples/s: 785.968 1613436615.527303
train: epoch 131, iter 4300, loss: 1.977378, top_1: 0.760391, top_k: 0.915234, samples/s: 780.667 1613436648.3198094
train: epoch 131, iter 4400, loss: 1.890260, top_1: 0.763750, top_k: 0.915195, samples/s: 785.508 1613436680.910134
train: epoch 131, iter 4500, loss: 1.892034, top_1: 0.770234, top_k: 0.919844, samples/s: 780.894 1613436713.6930642
train: epoch 131, iter 4600, loss: 2.020517, top_1: 0.765547, top_k: 0.914609, samples/s: 784.519 1613436746.3245997
train: epoch 131, iter 4700, loss: 1.890712, top_1: 0.763398, top_k: 0.917383, samples/s: 781.107 1613436779.0985882
train: epoch 131, iter 4800, loss: 1.994153, top_1: 0.767500, top_k: 0.917188, samples/s: 780.245 1613436811.908885
train: epoch 131, iter 4900, loss: 2.059168, top_1: 0.761602, top_k: 0.916758, samples/s: 784.038 1613436844.5602791
train: epoch 131, iter 5000, loss: 1.823972, top_1: 0.775117, top_k: 0.921094, samples/s: 783.238 1613436877.2450736
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_131.
validation: epoch 131, iter 195, top_1: 0.761558, top_k: 0.931530, samples/s: 2373.859 1613436899.2477932
train: epoch 132, iter 100, loss: 1.914014, top_1: 0.775352, top_k: 0.922969, samples/s: 805.460 1613436951.0476415
train: epoch 132, iter 200, loss: 1.827653, top_1: 0.775547, top_k: 0.924180, samples/s: 798.998 1613436983.087774
train: epoch 132, iter 300, loss: 2.036398, top_1: 0.776328, top_k: 0.919844, samples/s: 786.503 1613437015.6370363
train: epoch 132, iter 400, loss: 1.920718, top_1: 0.772969, top_k: 0.922109, samples/s: 779.526 1613437048.4773571
train: epoch 132, iter 500, loss: 1.919575, top_1: 0.777266, top_k: 0.922773, samples/s: 781.767 1613437081.2236922
train: epoch 132, iter 600, loss: 1.827240, top_1: 0.781680, top_k: 0.925156, samples/s: 781.404 1613437113.985252
train: epoch 132, iter 700, loss: 1.775600, top_1: 0.775156, top_k: 0.922031, samples/s: 781.527 1613437146.7415946
train: epoch 132, iter 800, loss: 1.833421, top_1: 0.770352, top_k: 0.917813, samples/s: 778.704 1613437179.616771
train: epoch 132, iter 900, loss: 1.868390, top_1: 0.768203, top_k: 0.918906, samples/s: 780.538 1613437212.4146411
train: epoch 132, iter 1000, loss: 1.891138, top_1: 0.769727, top_k: 0.917734, samples/s: 781.604 1613437245.1678243
train: epoch 132, iter 1100, loss: 1.930538, top_1: 0.777383, top_k: 0.921094, samples/s: 781.691 1613437277.917322
train: epoch 132, iter 1200, loss: 2.002831, top_1: 0.774648, top_k: 0.920156, samples/s: 782.152 1613437310.6475217
train: epoch 132, iter 1300, loss: 1.931323, top_1: 0.775937, top_k: 0.920703, samples/s: 781.571 1613437343.4020755
train: epoch 132, iter 1400, loss: 1.918959, top_1: 0.771328, top_k: 0.918320, samples/s: 781.660 1613437376.1528566
train: epoch 132, iter 1500, loss: 1.879875, top_1: 0.773438, top_k: 0.919297, samples/s: 781.197 1613437408.9231372
train: epoch 132, iter 1600, loss: 1.950325, top_1: 0.773008, top_k: 0.918555, samples/s: 783.019 1613437441.617108
train: epoch 132, iter 1700, loss: 1.825999, top_1: 0.771367, top_k: 0.918555, samples/s: 783.094 1613437474.307926
train: epoch 132, iter 1800, loss: 1.919569, top_1: 0.775039, top_k: 0.919648, samples/s: 780.129 1613437507.1229873
train: epoch 132, iter 1900, loss: 1.900628, top_1: 0.772813, top_k: 0.920391, samples/s: 784.058 1613437539.7736995
train: epoch 132, iter 2000, loss: 1.992424, top_1: 0.774766, top_k: 0.922422, samples/s: 780.695 1613437572.5649464
train: epoch 132, iter 2100, loss: 2.046856, top_1: 0.772930, top_k: 0.919414, samples/s: 782.222 1613437605.2921593
train: epoch 132, iter 2200, loss: 1.948273, top_1: 0.771367, top_k: 0.920430, samples/s: 784.992 1613437637.9040298
train: epoch 132, iter 2300, loss: 1.937624, top_1: 0.773125, top_k: 0.919336, samples/s: 782.533 1613437670.6182876
train: epoch 132, iter 2400, loss: 1.929206, top_1: 0.774414, top_k: 0.922227, samples/s: 783.839 1613437703.2780328
train: epoch 132, iter 2500, loss: 2.098907, top_1: 0.768398, top_k: 0.916602, samples/s: 781.781 1613437736.023831
train: epoch 132, iter 2600, loss: 1.896427, top_1: 0.775586, top_k: 0.921094, samples/s: 782.825 1613437768.725898
train: epoch 132, iter 2700, loss: 1.976079, top_1: 0.770898, top_k: 0.920703, samples/s: 784.329 1613437801.365245
train: epoch 132, iter 2800, loss: 2.058180, top_1: 0.771875, top_k: 0.918203, samples/s: 782.792 1613437834.0686884
train: epoch 132, iter 2900, loss: 1.962804, top_1: 0.767852, top_k: 0.919023, samples/s: 781.635 1613437866.8205192
train: epoch 132, iter 3000, loss: 1.937835, top_1: 0.765742, top_k: 0.917305, samples/s: 783.263 1613437899.504328
train: epoch 132, iter 3100, loss: 1.975340, top_1: 0.772891, top_k: 0.918633, samples/s: 785.380 1613437932.1000159
train: epoch 132, iter 3200, loss: 1.979405, top_1: 0.770078, top_k: 0.919453, samples/s: 780.995 1613437964.8786294
train: epoch 132, iter 3300, loss: 1.873549, top_1: 0.770078, top_k: 0.916836, samples/s: 783.179 1613437997.5659175
train: epoch 132, iter 3400, loss: 1.813970, top_1: 0.771836, top_k: 0.918555, samples/s: 783.883 1613438030.2239025
train: epoch 132, iter 3500, loss: 1.995423, top_1: 0.766914, top_k: 0.916094, samples/s: 783.194 1613438062.9105818
train: epoch 132, iter 3600, loss: 1.941385, top_1: 0.766953, top_k: 0.919258, samples/s: 784.296 1613438095.5512393
train: epoch 132, iter 3700, loss: 2.035665, top_1: 0.771328, top_k: 0.920430, samples/s: 781.244 1613438128.3195906
train: epoch 132, iter 3800, loss: 1.987700, top_1: 0.768711, top_k: 0.918125, samples/s: 785.615 1613438160.905472
train: epoch 132, iter 3900, loss: 1.780787, top_1: 0.776250, top_k: 0.923672, samples/s: 782.810 1613438193.608253
train: epoch 132, iter 4000, loss: 2.087286, top_1: 0.770391, top_k: 0.920937, samples/s: 786.345 1613438226.163892
train: epoch 132, iter 4100, loss: 2.082444, top_1: 0.770117, top_k: 0.918984, samples/s: 782.683 1613438258.871918
train: epoch 132, iter 4200, loss: 2.065032, top_1: 0.770977, top_k: 0.918672, samples/s: 783.246 1613438291.5563304
train: epoch 132, iter 4300, loss: 1.939674, top_1: 0.765625, top_k: 0.917422, samples/s: 782.005 1613438324.2927325
train: epoch 132, iter 4400, loss: 1.994284, top_1: 0.764023, top_k: 0.916094, samples/s: 785.200 1613438356.8959281
train: epoch 132, iter 4500, loss: 1.922287, top_1: 0.764805, top_k: 0.917148, samples/s: 783.208 1613438389.5819275
train: epoch 132, iter 4600, loss: 1.912358, top_1: 0.770547, top_k: 0.919453, samples/s: 783.727 1613438422.2464325
train: epoch 132, iter 4700, loss: 1.905030, top_1: 0.771172, top_k: 0.920156, samples/s: 782.699 1613438454.9536848
train: epoch 132, iter 4800, loss: 2.017297, top_1: 0.775000, top_k: 0.919063, samples/s: 783.321 1613438487.6350517
train: epoch 132, iter 4900, loss: 1.978410, top_1: 0.769766, top_k: 0.916602, samples/s: 783.832 1613438520.2951064
train: epoch 132, iter 5000, loss: 1.994786, top_1: 0.782656, top_k: 0.925977, samples/s: 782.583 1613438553.007354
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_132.
validation: epoch 132, iter 195, top_1: 0.764083, top_k: 0.933494, samples/s: 2363.239 1613438575.1191952
train: epoch 133, iter 100, loss: 2.034668, top_1: 0.784687, top_k: 0.923555, samples/s: 806.709 1613438632.729219
train: epoch 133, iter 200, loss: 1.945106, top_1: 0.777852, top_k: 0.924531, samples/s: 801.948 1613438664.651759
train: epoch 133, iter 300, loss: 1.937392, top_1: 0.781055, top_k: 0.924922, samples/s: 787.346 1613438697.1657753
train: epoch 133, iter 400, loss: 2.054455, top_1: 0.781719, top_k: 0.921602, samples/s: 780.734 1613438729.9554803
train: epoch 133, iter 500, loss: 1.887434, top_1: 0.774336, top_k: 0.921211, samples/s: 781.357 1613438762.7189026
train: epoch 133, iter 600, loss: 1.915768, top_1: 0.780273, top_k: 0.923750, samples/s: 779.959 1613438795.5411623
train: epoch 133, iter 700, loss: 1.952001, top_1: 0.777891, top_k: 0.922617, samples/s: 784.908 1613438828.1564772
train: epoch 133, iter 800, loss: 2.022139, top_1: 0.780391, top_k: 0.924102, samples/s: 780.656 1613438860.9494662
train: epoch 133, iter 900, loss: 1.901522, top_1: 0.779375, top_k: 0.921914, samples/s: 780.704 1613438893.7403886
train: epoch 133, iter 1000, loss: 2.031451, top_1: 0.773047, top_k: 0.917852, samples/s: 781.426 1613438926.5009162
train: epoch 133, iter 1100, loss: 1.879958, top_1: 0.777578, top_k: 0.922578, samples/s: 782.864 1613438959.2014399
train: epoch 133, iter 1200, loss: 1.850721, top_1: 0.776211, top_k: 0.922578, samples/s: 783.541 1613438991.8735523
train: epoch 133, iter 1300, loss: 1.981907, top_1: 0.777148, top_k: 0.920234, samples/s: 780.904 1613439024.6560163
train: epoch 133, iter 1400, loss: 1.896317, top_1: 0.778320, top_k: 0.922852, samples/s: 785.550 1613439057.2446685
train: epoch 133, iter 1500, loss: 1.870365, top_1: 0.781328, top_k: 0.924570, samples/s: 781.254 1613439090.0125074
train: epoch 133, iter 1600, loss: 1.896285, top_1: 0.777266, top_k: 0.922852, samples/s: 782.909 1613439122.7111063
train: epoch 133, iter 1700, loss: 2.087327, top_1: 0.779687, top_k: 0.922422, samples/s: 784.008 1613439155.3639116
train: epoch 133, iter 1800, loss: 2.038924, top_1: 0.773633, top_k: 0.919609, samples/s: 781.913 1613439188.1041317
train: epoch 133, iter 1900, loss: 1.928838, top_1: 0.770430, top_k: 0.921758, samples/s: 782.901 1613439220.8029118
train: epoch 133, iter 2000, loss: 2.047918, top_1: 0.778359, top_k: 0.921094, samples/s: 784.416 1613439253.4387712
train: epoch 133, iter 2100, loss: 1.811395, top_1: 0.773984, top_k: 0.921562, samples/s: 781.812 1613439286.183237
train: epoch 133, iter 2200, loss: 2.003994, top_1: 0.773125, top_k: 0.920039, samples/s: 783.912 1613439318.8399248
train: epoch 133, iter 2300, loss: 1.827508, top_1: 0.769414, top_k: 0.919570, samples/s: 785.937 1613439351.412484
train: epoch 133, iter 2400, loss: 2.023787, top_1: 0.779336, top_k: 0.919961, samples/s: 780.471 1613439384.213271
train: epoch 133, iter 2500, loss: 1.948872, top_1: 0.770352, top_k: 0.918633, samples/s: 784.483 1613439416.846174
train: epoch 133, iter 2600, loss: 1.869710, top_1: 0.773828, top_k: 0.920234, samples/s: 782.792 1613439449.549664
train: epoch 133, iter 2700, loss: 2.009147, top_1: 0.775937, top_k: 0.923008, samples/s: 782.130 1613439482.2808063
train: epoch 133, iter 2800, loss: 1.966674, top_1: 0.778633, top_k: 0.918711, samples/s: 784.627 1613439514.9076934
train: epoch 133, iter 2900, loss: 1.870391, top_1: 0.777188, top_k: 0.922148, samples/s: 779.784 1613439547.7372715
train: epoch 133, iter 3000, loss: 1.893061, top_1: 0.771875, top_k: 0.920312, samples/s: 782.590 1613439580.4492614
train: epoch 133, iter 3100, loss: 1.971463, top_1: 0.772070, top_k: 0.919687, samples/s: 782.192 1613439613.1777208
train: epoch 133, iter 3200, loss: 1.808843, top_1: 0.777305, top_k: 0.922578, samples/s: 784.262 1613439645.819909
train: epoch 133, iter 3300, loss: 1.844615, top_1: 0.775703, top_k: 0.921367, samples/s: 783.867 1613439678.478512
train: epoch 133, iter 3400, loss: 1.946792, top_1: 0.771484, top_k: 0.920117, samples/s: 780.297 1613439711.286567
train: epoch 133, iter 3500, loss: 1.794305, top_1: 0.775547, top_k: 0.922852, samples/s: 782.926 1613439743.984374
train: epoch 133, iter 3600, loss: 1.863973, top_1: 0.773164, top_k: 0.919336, samples/s: 783.645 1613439776.6522357
train: epoch 133, iter 3700, loss: 1.858698, top_1: 0.778867, top_k: 0.921992, samples/s: 783.235 1613439809.3371267
train: epoch 133, iter 3800, loss: 1.711825, top_1: 0.775039, top_k: 0.921836, samples/s: 782.006 1613439842.0735607
train: epoch 133, iter 3900, loss: 1.964080, top_1: 0.776484, top_k: 0.920781, samples/s: 782.909 1613439874.7721055
train: epoch 133, iter 4000, loss: 1.959736, top_1: 0.774609, top_k: 0.920977, samples/s: 784.467 1613439907.4057062
train: epoch 133, iter 4100, loss: 1.966822, top_1: 0.773594, top_k: 0.922383, samples/s: 780.476 1613439940.2062354
train: epoch 133, iter 4200, loss: 1.963519, top_1: 0.773008, top_k: 0.919609, samples/s: 783.164 1613439972.8941982
train: epoch 133, iter 4300, loss: 1.936345, top_1: 0.776445, top_k: 0.921016, samples/s: 781.743 1613440005.6415296
train: epoch 133, iter 4400, loss: 1.973916, top_1: 0.772109, top_k: 0.916875, samples/s: 780.222 1613440038.4525933
train: epoch 133, iter 4500, loss: 1.885085, top_1: 0.775742, top_k: 0.919961, samples/s: 781.942 1613440071.1917045
train: epoch 133, iter 4600, loss: 1.790636, top_1: 0.778047, top_k: 0.922617, samples/s: 782.655 1613440103.9008985
train: epoch 133, iter 4700, loss: 2.034434, top_1: 0.772656, top_k: 0.919727, samples/s: 778.796 1613440136.7720714
train: epoch 133, iter 4800, loss: 1.799060, top_1: 0.778867, top_k: 0.924141, samples/s: 783.232 1613440169.4571862
train: epoch 133, iter 4900, loss: 1.923454, top_1: 0.775273, top_k: 0.922422, samples/s: 779.710 1613440202.289851
train: epoch 133, iter 5000, loss: 1.956377, top_1: 0.773828, top_k: 0.921523, samples/s: 781.975 1613440235.0275733
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_133.
validation: epoch 133, iter 195, top_1: 0.763602, top_k: 0.933373, samples/s: 2319.765 1613440257.5132072
train: epoch 134, iter 100, loss: 1.866341, top_1: 0.786094, top_k: 0.926094, samples/s: 801.106 1613440310.2442532
train: epoch 134, iter 200, loss: 2.136574, top_1: 0.784219, top_k: 0.923320, samples/s: 800.009 1613440342.243873
train: epoch 134, iter 300, loss: 1.929529, top_1: 0.782148, top_k: 0.922734, samples/s: 784.677 1613440374.8687954
train: epoch 134, iter 400, loss: 1.959177, top_1: 0.778906, top_k: 0.920977, samples/s: 780.692 1613440407.6604235
train: epoch 134, iter 500, loss: 1.891315, top_1: 0.779102, top_k: 0.922891, samples/s: 778.828 1613440440.5301554
train: epoch 134, iter 600, loss: 2.149677, top_1: 0.784570, top_k: 0.924570, samples/s: 782.122 1613440473.2616282
train: epoch 134, iter 700, loss: 2.027510, top_1: 0.780234, top_k: 0.922188, samples/s: 779.506 1613440506.1029437
train: epoch 134, iter 800, loss: 1.943989, top_1: 0.781094, top_k: 0.923164, samples/s: 780.634 1613440538.8968036
train: epoch 134, iter 900, loss: 1.851353, top_1: 0.783125, top_k: 0.925312, samples/s: 780.392 1613440571.700822
train: epoch 134, iter 1000, loss: 1.852542, top_1: 0.781797, top_k: 0.923086, samples/s: 778.209 1613440604.5968158
train: epoch 134, iter 1100, loss: 1.881519, top_1: 0.782422, top_k: 0.923828, samples/s: 781.810 1613440637.3413813
train: epoch 134, iter 1200, loss: 1.950178, top_1: 0.778789, top_k: 0.923164, samples/s: 781.069 1613440670.1170092
train: epoch 134, iter 1300, loss: 1.777750, top_1: 0.782930, top_k: 0.926484, samples/s: 778.645 1613440702.9946368
train: epoch 134, iter 1400, loss: 1.785238, top_1: 0.781836, top_k: 0.924023, samples/s: 782.159 1613440735.7244775
train: epoch 134, iter 1500, loss: 1.981981, top_1: 0.777891, top_k: 0.922852, samples/s: 782.149 1613440768.454801
train: epoch 134, iter 1600, loss: 1.850462, top_1: 0.779023, top_k: 0.921641, samples/s: 781.668 1613440801.205316
train: epoch 134, iter 1700, loss: 1.963027, top_1: 0.778086, top_k: 0.923008, samples/s: 781.286 1613440833.9717681
train: epoch 134, iter 1800, loss: 1.963338, top_1: 0.783711, top_k: 0.922695, samples/s: 784.487 1613440866.604555
train: epoch 134, iter 1900, loss: 1.896344, top_1: 0.779141, top_k: 0.923164, samples/s: 779.475 1613440899.4472468
train: epoch 134, iter 2000, loss: 1.850219, top_1: 0.775391, top_k: 0.924648, samples/s: 782.359 1613440932.168794
train: epoch 134, iter 2100, loss: 1.803603, top_1: 0.781719, top_k: 0.924180, samples/s: 783.095 1613440964.8595624
train: epoch 134, iter 2200, loss: 1.974333, top_1: 0.779961, top_k: 0.923594, samples/s: 783.468 1613440997.5349517
train: epoch 134, iter 2300, loss: 1.793735, top_1: 0.776914, top_k: 0.920703, samples/s: 781.518 1613441030.2915072
train: epoch 134, iter 2400, loss: 1.867435, top_1: 0.781328, top_k: 0.922734, samples/s: 780.660 1613441063.0843272
train: epoch 134, iter 2500, loss: 1.853551, top_1: 0.774062, top_k: 0.919844, samples/s: 782.105 1613441095.8165538
train: epoch 134, iter 2600, loss: 1.867391, top_1: 0.780664, top_k: 0.924375, samples/s: 783.453 1613441128.49232
train: epoch 134, iter 2700, loss: 1.908959, top_1: 0.783359, top_k: 0.924922, samples/s: 783.088 1613441161.1835139
train: epoch 134, iter 2800, loss: 1.841213, top_1: 0.776328, top_k: 0.923164, samples/s: 779.624 1613441194.0198357
train: epoch 134, iter 2900, loss: 1.805859, top_1: 0.778945, top_k: 0.924102, samples/s: 784.222 1613441226.6636784
train: epoch 134, iter 3000, loss: 1.917755, top_1: 0.780742, top_k: 0.922695, samples/s: 781.957 1613441259.4019487
train: epoch 134, iter 3100, loss: 2.037372, top_1: 0.778242, top_k: 0.922617, samples/s: 783.163 1613441292.0899494
train: epoch 134, iter 3200, loss: 1.956260, top_1: 0.779219, top_k: 0.920859, samples/s: 779.513 1613441324.9310367
train: epoch 134, iter 3300, loss: 1.910901, top_1: 0.778008, top_k: 0.922422, samples/s: 781.021 1613441357.708631
train: epoch 134, iter 3400, loss: 1.918298, top_1: 0.775234, top_k: 0.921914, samples/s: 780.950 1613441390.4892476
train: epoch 134, iter 3500, loss: 1.955330, top_1: 0.776719, top_k: 0.924492, samples/s: 783.184 1613441423.1762793
train: epoch 134, iter 3600, loss: 2.077169, top_1: 0.778867, top_k: 0.923984, samples/s: 780.768 1613441455.9645345
train: epoch 134, iter 3700, loss: 1.959193, top_1: 0.780898, top_k: 0.924414, samples/s: 781.317 1613441488.7297196
train: epoch 134, iter 3800, loss: 1.841567, top_1: 0.774531, top_k: 0.918711, samples/s: 782.506 1613441521.4451106
train: epoch 134, iter 3900, loss: 1.832854, top_1: 0.775430, top_k: 0.918750, samples/s: 782.745 1613441554.150553
train: epoch 134, iter 4000, loss: 2.043447, top_1: 0.777617, top_k: 0.923242, samples/s: 779.820 1613441586.9786289
train: epoch 134, iter 4100, loss: 1.944799, top_1: 0.775000, top_k: 0.921406, samples/s: 780.712 1613441619.7691557
train: epoch 134, iter 4200, loss: 1.982514, top_1: 0.771484, top_k: 0.924531, samples/s: 782.034 1613441652.504444
train: epoch 134, iter 4300, loss: 1.887746, top_1: 0.774375, top_k: 0.921172, samples/s: 780.558 1613441685.3014948
train: epoch 134, iter 4400, loss: 1.926000, top_1: 0.772852, top_k: 0.919805, samples/s: 782.690 1613441718.0091233
train: epoch 134, iter 4500, loss: 1.899873, top_1: 0.781523, top_k: 0.924375, samples/s: 780.522 1613441750.8077104
train: epoch 134, iter 4600, loss: 1.878226, top_1: 0.778047, top_k: 0.920859, samples/s: 779.563 1613441783.6466043
train: epoch 134, iter 4700, loss: 1.844177, top_1: 0.773789, top_k: 0.922422, samples/s: 785.002 1613441816.2579877
train: epoch 134, iter 4800, loss: 1.862194, top_1: 0.775078, top_k: 0.924492, samples/s: 780.916 1613441849.039905
train: epoch 134, iter 4900, loss: 1.815439, top_1: 0.778359, top_k: 0.922852, samples/s: 782.762 1613441881.7446666
train: epoch 134, iter 5000, loss: 1.871223, top_1: 0.781953, top_k: 0.925547, samples/s: 781.570 1613441914.4992776
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_134.
validation: epoch 134, iter 195, top_1: 0.766046, top_k: 0.933133, samples/s: 2349.009 1613441936.752795
train: epoch 135, iter 100, loss: 1.875991, top_1: 0.783516, top_k: 0.924727, samples/s: 804.471 1613441989.9468317
train: epoch 135, iter 200, loss: 1.871164, top_1: 0.787188, top_k: 0.926406, samples/s: 800.030 1613442021.9456866
train: epoch 135, iter 300, loss: 1.981720, top_1: 0.787930, top_k: 0.929688, samples/s: 783.258 1613442054.6297038
train: epoch 135, iter 400, loss: 1.929332, top_1: 0.785469, top_k: 0.926641, samples/s: 782.584 1613442087.3418548
train: epoch 135, iter 500, loss: 1.825257, top_1: 0.788789, top_k: 0.925664, samples/s: 779.755 1613442120.1726828
train: epoch 135, iter 600, loss: 1.849103, top_1: 0.785469, top_k: 0.927578, samples/s: 780.156 1613442152.986583
train: epoch 135, iter 700, loss: 1.952784, top_1: 0.786719, top_k: 0.925312, samples/s: 780.405 1613442185.7901285
train: epoch 135, iter 800, loss: 1.889008, top_1: 0.787383, top_k: 0.928516, samples/s: 779.423 1613442218.6349006
train: epoch 135, iter 900, loss: 1.998153, top_1: 0.787656, top_k: 0.926094, samples/s: 779.919 1613442251.4587967
train: epoch 135, iter 1000, loss: 1.855519, top_1: 0.784687, top_k: 0.922852, samples/s: 779.260 1613442284.3104863
train: epoch 135, iter 1100, loss: 1.977849, top_1: 0.787969, top_k: 0.925469, samples/s: 782.172 1613442317.0398338
train: epoch 135, iter 1200, loss: 1.842446, top_1: 0.781992, top_k: 0.923750, samples/s: 779.469 1613442349.882804
train: epoch 135, iter 1300, loss: 1.891550, top_1: 0.782734, top_k: 0.925039, samples/s: 783.468 1613442382.5579898
train: epoch 135, iter 1400, loss: 1.847580, top_1: 0.783242, top_k: 0.923359, samples/s: 780.830 1613442415.3436382
train: epoch 135, iter 1500, loss: 1.833534, top_1: 0.786914, top_k: 0.925117, samples/s: 782.894 1613442448.0427318
train: epoch 135, iter 1600, loss: 1.844116, top_1: 0.780820, top_k: 0.922188, samples/s: 778.832 1613442480.9125288
train: epoch 135, iter 1700, loss: 1.944253, top_1: 0.783945, top_k: 0.924687, samples/s: 779.944 1613442513.7354095
train: epoch 135, iter 1800, loss: 1.899518, top_1: 0.782383, top_k: 0.925703, samples/s: 782.760 1613442546.4401448
train: epoch 135, iter 1900, loss: 2.080811, top_1: 0.783281, top_k: 0.927344, samples/s: 781.160 1613442579.211904
train: epoch 135, iter 2000, loss: 2.127112, top_1: 0.782773, top_k: 0.922148, samples/s: 782.860 1613442611.9124908
train: epoch 135, iter 2100, loss: 1.970685, top_1: 0.784531, top_k: 0.927891, samples/s: 780.176 1613442644.7256196
train: epoch 135, iter 2200, loss: 1.894926, top_1: 0.783086, top_k: 0.924648, samples/s: 784.702 1613442677.3495274
train: epoch 135, iter 2300, loss: 1.859622, top_1: 0.786797, top_k: 0.923672, samples/s: 779.532 1613442710.1897461
train: epoch 135, iter 2400, loss: 1.937853, top_1: 0.783633, top_k: 0.922148, samples/s: 781.797 1613442742.9347556
train: epoch 135, iter 2500, loss: 2.078697, top_1: 0.778008, top_k: 0.922734, samples/s: 782.148 1613442775.6650722
train: epoch 135, iter 2600, loss: 1.975186, top_1: 0.786172, top_k: 0.925781, samples/s: 779.725 1613442808.4972847
train: epoch 135, iter 2700, loss: 1.850307, top_1: 0.780820, top_k: 0.922813, samples/s: 781.276 1613442841.2641838
train: epoch 135, iter 2800, loss: 1.904991, top_1: 0.785820, top_k: 0.927305, samples/s: 780.698 1613442874.055248
train: epoch 135, iter 2900, loss: 1.878325, top_1: 0.786953, top_k: 0.924336, samples/s: 782.208 1613442906.7830987
train: epoch 135, iter 3000, loss: 2.014007, top_1: 0.782891, top_k: 0.925195, samples/s: 781.663 1613442939.533881
train: epoch 135, iter 3100, loss: 1.894891, top_1: 0.785039, top_k: 0.927461, samples/s: 781.172 1613442972.3050885
train: epoch 135, iter 3200, loss: 1.934484, top_1: 0.783750, top_k: 0.926172, samples/s: 781.492 1613443005.0629282
train: epoch 135, iter 3300, loss: 1.843779, top_1: 0.780586, top_k: 0.923672, samples/s: 781.576 1613443037.8172739
train: epoch 135, iter 3400, loss: 1.817391, top_1: 0.787109, top_k: 0.926523, samples/s: 783.627 1613443070.48586
train: epoch 135, iter 3500, loss: 1.793958, top_1: 0.781094, top_k: 0.921562, samples/s: 781.041 1613443103.2626567
train: epoch 135, iter 3600, loss: 1.887193, top_1: 0.777148, top_k: 0.920078, samples/s: 781.348 1613443136.0265412
train: epoch 135, iter 3700, loss: 2.023597, top_1: 0.785664, top_k: 0.923906, samples/s: 781.260 1613443168.7941535
train: epoch 135, iter 3800, loss: 1.940541, top_1: 0.771289, top_k: 0.920508, samples/s: 781.044 1613443201.5707657
train: epoch 135, iter 3900, loss: 1.837118, top_1: 0.782148, top_k: 0.922656, samples/s: 781.684 1613443234.3204935
train: epoch 135, iter 4000, loss: 1.924948, top_1: 0.783555, top_k: 0.924531, samples/s: 782.718 1613443267.0270393
train: epoch 135, iter 4100, loss: 1.836555, top_1: 0.783164, top_k: 0.925156, samples/s: 782.632 1613443299.7372546
train: epoch 135, iter 4200, loss: 1.820134, top_1: 0.779844, top_k: 0.923086, samples/s: 781.018 1613443332.5150237
train: epoch 135, iter 4300, loss: 1.862552, top_1: 0.784062, top_k: 0.923242, samples/s: 783.992 1613443365.168406
train: epoch 135, iter 4400, loss: 1.980938, top_1: 0.781367, top_k: 0.924141, samples/s: 782.892 1613443397.8676195
train: epoch 135, iter 4500, loss: 1.963522, top_1: 0.780898, top_k: 0.924492, samples/s: 782.526 1613443430.5822644
train: epoch 135, iter 4600, loss: 1.853510, top_1: 0.777578, top_k: 0.922930, samples/s: 783.379 1613443463.261148
train: epoch 135, iter 4700, loss: 1.897701, top_1: 0.780820, top_k: 0.923438, samples/s: 780.558 1613443496.0582457
train: epoch 135, iter 4800, loss: 1.859728, top_1: 0.778555, top_k: 0.923008, samples/s: 783.751 1613443528.721636
train: epoch 135, iter 4900, loss: 1.919400, top_1: 0.779336, top_k: 0.922891, samples/s: 782.390 1613443561.441976
train: epoch 135, iter 5000, loss: 1.901538, top_1: 0.792930, top_k: 0.929688, samples/s: 780.142 1613443594.256552
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_135.
validation: epoch 135, iter 195, top_1: 0.760377, top_k: 0.931330, samples/s: 2409.839 1613443615.8774273
train: epoch 136, iter 100, loss: 1.723392, top_1: 0.789531, top_k: 0.927930, samples/s: 802.650 1613443669.2809083
train: epoch 136, iter 200, loss: 1.881891, top_1: 0.792773, top_k: 0.926641, samples/s: 802.884 1613443701.1660628
train: epoch 136, iter 300, loss: 1.787684, top_1: 0.789766, top_k: 0.928125, samples/s: 784.682 1613443733.7906203
train: epoch 136, iter 400, loss: 1.999330, top_1: 0.783828, top_k: 0.922969, samples/s: 779.717 1613443766.623035
train: epoch 136, iter 500, loss: 1.924542, top_1: 0.783594, top_k: 0.927031, samples/s: 780.168 1613443799.4365227
train: epoch 136, iter 600, loss: 1.936284, top_1: 0.785859, top_k: 0.924687, samples/s: 783.377 1613443832.1156118
train: epoch 136, iter 700, loss: 1.731106, top_1: 0.791133, top_k: 0.931875, samples/s: 781.003 1613443864.8939025
train: epoch 136, iter 800, loss: 1.908463, top_1: 0.788594, top_k: 0.928594, samples/s: 782.051 1613443897.628323
train: epoch 136, iter 900, loss: 1.749849, top_1: 0.789766, top_k: 0.927734, samples/s: 780.030 1613443930.4476774
train: epoch 136, iter 1000, loss: 1.879326, top_1: 0.786172, top_k: 0.925625, samples/s: 783.139 1613443963.1365552
train: epoch 136, iter 1100, loss: 1.941507, top_1: 0.784766, top_k: 0.926172, samples/s: 779.596 1613443995.9741132
train: epoch 136, iter 1200, loss: 2.008714, top_1: 0.787930, top_k: 0.925859, samples/s: 781.986 1613444028.7112231
train: epoch 136, iter 1300, loss: 1.826713, top_1: 0.787891, top_k: 0.926016, samples/s: 782.236 1613444061.4379733
train: epoch 136, iter 1400, loss: 1.728676, top_1: 0.790391, top_k: 0.926602, samples/s: 782.724 1613444094.1442773
train: epoch 136, iter 1500, loss: 1.768653, top_1: 0.788047, top_k: 0.926641, samples/s: 778.835 1613444127.01388
train: epoch 136, iter 1600, loss: 2.050972, top_1: 0.784961, top_k: 0.923906, samples/s: 782.563 1613444159.726825
train: epoch 136, iter 1700, loss: 1.958701, top_1: 0.788281, top_k: 0.926133, samples/s: 782.019 1613444192.4625986
train: epoch 136, iter 1800, loss: 1.833623, top_1: 0.788398, top_k: 0.928008, samples/s: 779.983 1613444225.2837882
train: epoch 136, iter 1900, loss: 1.830369, top_1: 0.787383, top_k: 0.925742, samples/s: 783.411 1613444257.961484
train: epoch 136, iter 2000, loss: 2.022043, top_1: 0.783359, top_k: 0.926484, samples/s: 780.974 1613444290.7411063
train: epoch 136, iter 2100, loss: 1.905693, top_1: 0.784336, top_k: 0.925703, samples/s: 782.414 1613444323.460327
train: epoch 136, iter 2200, loss: 1.742121, top_1: 0.792578, top_k: 0.926875, samples/s: 783.056 1613444356.1527658
train: epoch 136, iter 2300, loss: 1.960848, top_1: 0.786953, top_k: 0.926523, samples/s: 780.844 1613444388.9376986
train: epoch 136, iter 2400, loss: 1.950934, top_1: 0.786914, top_k: 0.926758, samples/s: 783.069 1613444421.62961
train: epoch 136, iter 2500, loss: 1.967848, top_1: 0.782227, top_k: 0.925664, samples/s: 781.575 1613444454.3839731
train: epoch 136, iter 2600, loss: 1.957811, top_1: 0.782500, top_k: 0.923945, samples/s: 784.505 1613444487.0160499
train: epoch 136, iter 2700, loss: 1.957288, top_1: 0.784570, top_k: 0.927500, samples/s: 779.417 1613444519.8611107
train: epoch 136, iter 2800, loss: 1.834553, top_1: 0.787891, top_k: 0.926562, samples/s: 783.056 1613444552.5534582
train: epoch 136, iter 2900, loss: 2.121937, top_1: 0.783750, top_k: 0.925664, samples/s: 783.210 1613444585.2395663
train: epoch 136, iter 3000, loss: 2.075536, top_1: 0.778945, top_k: 0.924609, samples/s: 780.820 1613444618.0255497
train: epoch 136, iter 3100, loss: 1.983178, top_1: 0.784648, top_k: 0.923164, samples/s: 781.163 1613444650.7972567
train: epoch 136, iter 3200, loss: 1.930052, top_1: 0.784297, top_k: 0.926719, samples/s: 782.085 1613444683.5302136
train: epoch 136, iter 3300, loss: 2.010262, top_1: 0.785000, top_k: 0.925117, samples/s: 783.273 1613444716.2135391
train: epoch 136, iter 3400, loss: 2.045137, top_1: 0.784883, top_k: 0.925937, samples/s: 779.375 1613444749.060441
train: epoch 136, iter 3500, loss: 2.009611, top_1: 0.782344, top_k: 0.924414, samples/s: 780.629 1613444781.854562
train: epoch 136, iter 3600, loss: 1.949724, top_1: 0.787578, top_k: 0.927148, samples/s: 785.922 1613444814.4276748
train: epoch 136, iter 3700, loss: 1.897694, top_1: 0.792031, top_k: 0.927031, samples/s: 780.008 1613444847.2478924
train: epoch 136, iter 3800, loss: 1.829854, top_1: 0.782266, top_k: 0.924414, samples/s: 781.313 1613444880.0133471
train: epoch 136, iter 3900, loss: 1.826947, top_1: 0.780430, top_k: 0.923242, samples/s: 782.593 1613444912.7250001
train: epoch 136, iter 4000, loss: 1.954312, top_1: 0.783047, top_k: 0.925352, samples/s: 781.008 1613444945.5032341
train: epoch 136, iter 4100, loss: 1.891394, top_1: 0.787188, top_k: 0.928008, samples/s: 781.681 1613444978.2530744
train: epoch 136, iter 4200, loss: 1.771615, top_1: 0.787656, top_k: 0.925586, samples/s: 780.416 1613445011.0561068
train: epoch 136, iter 4300, loss: 1.845237, top_1: 0.786289, top_k: 0.926953, samples/s: 782.944 1613445043.7532413
train: epoch 136, iter 4400, loss: 1.936203, top_1: 0.783203, top_k: 0.924961, samples/s: 781.099 1613445076.5275614
train: epoch 136, iter 4500, loss: 1.880233, top_1: 0.784219, top_k: 0.924414, samples/s: 781.186 1613445109.2982955
train: epoch 136, iter 4600, loss: 1.817821, top_1: 0.785703, top_k: 0.923711, samples/s: 782.339 1613445142.0207367
train: epoch 136, iter 4700, loss: 1.901835, top_1: 0.786445, top_k: 0.924258, samples/s: 780.015 1613445174.8405445
train: epoch 136, iter 4800, loss: 1.830650, top_1: 0.782695, top_k: 0.925586, samples/s: 781.418 1613445207.601535
train: epoch 136, iter 4900, loss: 2.033609, top_1: 0.785547, top_k: 0.925156, samples/s: 783.067 1613445240.293383
train: epoch 136, iter 5000, loss: 1.815558, top_1: 0.789453, top_k: 0.927461, samples/s: 780.588 1613445273.0892746
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_136.
validation: epoch 136, iter 195, top_1: 0.767728, top_k: 0.935056, samples/s: 2334.251 1613445295.4725046
train: epoch 137, iter 100, loss: 1.907875, top_1: 0.798750, top_k: 0.927461, samples/s: 805.369 1613445348.3119807
train: epoch 137, iter 200, loss: 1.804462, top_1: 0.795273, top_k: 0.928711, samples/s: 801.044 1613445380.2704647
train: epoch 137, iter 300, loss: 1.826336, top_1: 0.800117, top_k: 0.931289, samples/s: 781.639 1613445413.0219471
train: epoch 137, iter 400, loss: 1.848384, top_1: 0.789102, top_k: 0.927539, samples/s: 782.329 1613445445.7447817
train: epoch 137, iter 500, loss: 1.790636, top_1: 0.795195, top_k: 0.931875, samples/s: 776.620 1613445478.7080817
train: epoch 137, iter 600, loss: 1.820015, top_1: 0.792734, top_k: 0.929063, samples/s: 780.751 1613445511.4970179
train: epoch 137, iter 700, loss: 1.875414, top_1: 0.789766, top_k: 0.928125, samples/s: 781.161 1613445544.2688375
train: epoch 137, iter 800, loss: 1.715508, top_1: 0.790742, top_k: 0.928555, samples/s: 779.143 1613445577.1254652
train: epoch 137, iter 900, loss: 1.824920, top_1: 0.787969, top_k: 0.925937, samples/s: 781.220 1613445609.8947737
train: epoch 137, iter 1000, loss: 1.950346, top_1: 0.786563, top_k: 0.925977, samples/s: 778.700 1613445642.7699502
train: epoch 137, iter 1100, loss: 1.804687, top_1: 0.792500, top_k: 0.930469, samples/s: 781.281 1613445675.5367403
train: epoch 137, iter 1200, loss: 1.820606, top_1: 0.788242, top_k: 0.931094, samples/s: 780.929 1613445708.3181002
train: epoch 137, iter 1300, loss: 1.994364, top_1: 0.793477, top_k: 0.927188, samples/s: 781.988 1613445741.0552232
train: epoch 137, iter 1400, loss: 1.962391, top_1: 0.791758, top_k: 0.930234, samples/s: 780.402 1613445773.8588235
train: epoch 137, iter 1500, loss: 1.800098, top_1: 0.792773, top_k: 0.929102, samples/s: 781.722 1613445806.6069639
train: epoch 137, iter 1600, loss: 1.888014, top_1: 0.787813, top_k: 0.928477, samples/s: 780.091 1613445839.4236536
train: epoch 137, iter 1700, loss: 1.759899, top_1: 0.793242, top_k: 0.929297, samples/s: 782.139 1613445872.1543648
train: epoch 137, iter 1800, loss: 1.881489, top_1: 0.784375, top_k: 0.924922, samples/s: 780.440 1613445904.956425
train: epoch 137, iter 1900, loss: 1.838790, top_1: 0.789062, top_k: 0.926328, samples/s: 784.821 1613445937.575304
train: epoch 137, iter 2000, loss: 1.837614, top_1: 0.787969, top_k: 0.927617, samples/s: 779.589 1613445970.4131198
train: epoch 137, iter 2100, loss: 1.851653, top_1: 0.792852, top_k: 0.927930, samples/s: 780.978 1613446003.192571
train: epoch 137, iter 2200, loss: 2.047954, top_1: 0.789805, top_k: 0.928945, samples/s: 783.337 1613446035.8732238
train: epoch 137, iter 2300, loss: 1.859214, top_1: 0.785742, top_k: 0.925586, samples/s: 782.464 1613446068.5904193
train: epoch 137, iter 2400, loss: 1.878554, top_1: 0.794258, top_k: 0.931289, samples/s: 781.967 1613446101.328355
train: epoch 137, iter 2500, loss: 1.934034, top_1: 0.786914, top_k: 0.927969, samples/s: 780.614 1613446134.1230645
train: epoch 137, iter 2600, loss: 1.792592, top_1: 0.789141, top_k: 0.927148, samples/s: 781.742 1613446166.8704553
train: epoch 137, iter 2700, loss: 1.875201, top_1: 0.789805, top_k: 0.928047, samples/s: 783.204 1613446199.5566556
train: epoch 137, iter 2800, loss: 1.843896, top_1: 0.783555, top_k: 0.924883, samples/s: 781.139 1613446232.3292634
train: epoch 137, iter 2900, loss: 1.835559, top_1: 0.792109, top_k: 0.929336, samples/s: 781.913 1613446265.0694866
train: epoch 137, iter 3000, loss: 1.870400, top_1: 0.787422, top_k: 0.926641, samples/s: 784.689 1613446297.6939452
train: epoch 137, iter 3100, loss: 1.857628, top_1: 0.792031, top_k: 0.928008, samples/s: 780.687 1613446330.485554
train: epoch 137, iter 3200, loss: 1.783427, top_1: 0.790000, top_k: 0.926016, samples/s: 784.048 1613446363.1365592
train: epoch 137, iter 3300, loss: 1.966654, top_1: 0.788086, top_k: 0.926094, samples/s: 786.304 1613446395.6940303
train: epoch 137, iter 3400, loss: 1.910433, top_1: 0.789141, top_k: 0.927969, samples/s: 780.436 1613446428.4961407
train: epoch 137, iter 3500, loss: 1.964099, top_1: 0.791523, top_k: 0.927500, samples/s: 781.078 1613446461.2713246
train: epoch 137, iter 3600, loss: 1.893291, top_1: 0.792305, top_k: 0.931367, samples/s: 779.968 1613446494.0932336
train: epoch 137, iter 3700, loss: 1.911642, top_1: 0.783789, top_k: 0.927773, samples/s: 783.028 1613446526.7868955
train: epoch 137, iter 3800, loss: 1.808836, top_1: 0.786445, top_k: 0.923555, samples/s: 782.488 1613446559.5030217
train: epoch 137, iter 3900, loss: 1.996097, top_1: 0.790039, top_k: 0.924648, samples/s: 780.676 1613446592.2950168
train: epoch 137, iter 4000, loss: 1.757334, top_1: 0.785820, top_k: 0.927656, samples/s: 786.064 1613446624.862394
train: epoch 137, iter 4100, loss: 1.964583, top_1: 0.786367, top_k: 0.924414, samples/s: 779.787 1613446657.6919286
train: epoch 137, iter 4200, loss: 1.789295, top_1: 0.792305, top_k: 0.928867, samples/s: 782.591 1613446690.4036872
train: epoch 137, iter 4300, loss: 1.888882, top_1: 0.790508, top_k: 0.925859, samples/s: 781.299 1613446723.1696362
train: epoch 137, iter 4400, loss: 1.891196, top_1: 0.785078, top_k: 0.925547, samples/s: 781.744 1613446755.916992
train: epoch 137, iter 4500, loss: 1.821362, top_1: 0.790391, top_k: 0.926836, samples/s: 782.473 1613446788.6338067
train: epoch 137, iter 4600, loss: 1.881375, top_1: 0.786992, top_k: 0.923516, samples/s: 781.339 1613446821.3981197
train: epoch 137, iter 4700, loss: 1.840781, top_1: 0.785937, top_k: 0.925000, samples/s: 783.867 1613446854.0567284
train: epoch 137, iter 4800, loss: 1.792063, top_1: 0.786602, top_k: 0.924531, samples/s: 782.421 1613446886.7756078
train: epoch 137, iter 4900, loss: 1.873897, top_1: 0.792617, top_k: 0.929688, samples/s: 782.160 1613446919.5055318
train: epoch 137, iter 5000, loss: 1.886599, top_1: 0.792969, top_k: 0.929258, samples/s: 778.958 1613446952.3698509
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_137.
validation: epoch 137, iter 195, top_1: 0.767849, top_k: 0.935677, samples/s: 2375.417 1613446974.2090538
train: epoch 138, iter 100, loss: 2.040782, top_1: 0.795156, top_k: 0.928633, samples/s: 804.323 1613447026.399948
train: epoch 138, iter 200, loss: 1.796825, top_1: 0.796719, top_k: 0.929844, samples/s: 799.344 1613447058.4262817
train: epoch 138, iter 300, loss: 1.949830, top_1: 0.795156, top_k: 0.928438, samples/s: 783.258 1613447091.1101925
train: epoch 138, iter 400, loss: 1.847470, top_1: 0.798242, top_k: 0.929688, samples/s: 779.410 1613447123.9556513
train: epoch 138, iter 500, loss: 1.937303, top_1: 0.795547, top_k: 0.931289, samples/s: 780.508 1613447156.7547598
train: epoch 138, iter 600, loss: 1.856236, top_1: 0.792695, top_k: 0.928398, samples/s: 779.013 1613447189.6167893
train: epoch 138, iter 700, loss: 1.973864, top_1: 0.794063, top_k: 0.929453, samples/s: 780.384 1613447222.4212086
train: epoch 138, iter 800, loss: 1.795774, top_1: 0.794805, top_k: 0.930586, samples/s: 781.709 1613447255.1699812
train: epoch 138, iter 900, loss: 1.765082, top_1: 0.792734, top_k: 0.927539, samples/s: 781.341 1613447287.9340565
train: epoch 138, iter 1000, loss: 1.960597, top_1: 0.793672, top_k: 0.930781, samples/s: 780.582 1613447320.7302148
train: epoch 138, iter 1100, loss: 1.756726, top_1: 0.791914, top_k: 0.929102, samples/s: 780.413 1613447353.5332978
train: epoch 138, iter 1200, loss: 1.776521, top_1: 0.793672, top_k: 0.930898, samples/s: 781.433 1613447386.2935705
train: epoch 138, iter 1300, loss: 1.834258, top_1: 0.797188, top_k: 0.930898, samples/s: 781.728 1613447419.041563
train: epoch 138, iter 1400, loss: 1.873543, top_1: 0.791875, top_k: 0.928477, samples/s: 779.088 1613447451.900436
train: epoch 138, iter 1500, loss: 1.843753, top_1: 0.800078, top_k: 0.933008, samples/s: 783.763 1613447484.5634048
train: epoch 138, iter 1600, loss: 1.840818, top_1: 0.794023, top_k: 0.929609, samples/s: 783.372 1613447517.2426188
train: epoch 138, iter 1700, loss: 1.913426, top_1: 0.797695, top_k: 0.929727, samples/s: 782.156 1613447549.972679
train: epoch 138, iter 1800, loss: 1.753393, top_1: 0.797539, top_k: 0.932109, samples/s: 781.348 1613447582.736529
train: epoch 138, iter 1900, loss: 1.913335, top_1: 0.790273, top_k: 0.929609, samples/s: 782.026 1613447615.4720275
train: epoch 138, iter 2000, loss: 1.641257, top_1: 0.797813, top_k: 0.932109, samples/s: 781.574 1613447648.2264423
train: epoch 138, iter 2100, loss: 1.754114, top_1: 0.790703, top_k: 0.926719, samples/s: 781.527 1613447680.982916
train: epoch 138, iter 2200, loss: 1.856984, top_1: 0.794297, top_k: 0.929102, samples/s: 781.504 1613447713.740234
train: epoch 138, iter 2300, loss: 1.869281, top_1: 0.792891, top_k: 0.929023, samples/s: 784.543 1613447746.3707078
train: epoch 138, iter 2400, loss: 1.944680, top_1: 0.794102, top_k: 0.930625, samples/s: 780.626 1613447779.1649816
train: epoch 138, iter 2500, loss: 1.871520, top_1: 0.790273, top_k: 0.928164, samples/s: 781.620 1613447811.917446
train: epoch 138, iter 2600, loss: 1.791728, top_1: 0.793008, top_k: 0.929844, samples/s: 781.630 1613447844.6695025
train: epoch 138, iter 2700, loss: 1.964536, top_1: 0.795937, top_k: 0.931484, samples/s: 782.901 1613447877.3683476
train: epoch 138, iter 2800, loss: 1.878112, top_1: 0.791289, top_k: 0.930000, samples/s: 782.048 1613447910.1029272
train: epoch 138, iter 2900, loss: 1.758865, top_1: 0.794141, top_k: 0.930117, samples/s: 782.196 1613447942.8313675
train: epoch 138, iter 3000, loss: 1.887883, top_1: 0.784219, top_k: 0.923750, samples/s: 780.897 1613447975.614118
train: epoch 138, iter 3100, loss: 1.890766, top_1: 0.791953, top_k: 0.927109, samples/s: 782.019 1613448008.3499193
train: epoch 138, iter 3200, loss: 1.852255, top_1: 0.794141, top_k: 0.928945, samples/s: 782.374 1613448041.070802
train: epoch 138, iter 3300, loss: 1.829763, top_1: 0.793086, top_k: 0.932031, samples/s: 782.117 1613448073.8025045
train: epoch 138, iter 3400, loss: 1.963947, top_1: 0.791211, top_k: 0.928047, samples/s: 780.645 1613448106.595877
train: epoch 138, iter 3500, loss: 1.862353, top_1: 0.794844, top_k: 0.927617, samples/s: 784.074 1613448139.2457688
train: epoch 138, iter 3600, loss: 1.728138, top_1: 0.793281, top_k: 0.930781, samples/s: 778.565 1613448172.1269324
train: epoch 138, iter 3700, loss: 1.858845, top_1: 0.790664, top_k: 0.928516, samples/s: 780.898 1613448204.9095523
train: epoch 138, iter 3800, loss: 1.811493, top_1: 0.794570, top_k: 0.928672, samples/s: 782.547 1613448237.6233668
train: epoch 138, iter 3900, loss: 1.862252, top_1: 0.796172, top_k: 0.928906, samples/s: 782.261 1613448270.3489335
train: epoch 138, iter 4000, loss: 2.021294, top_1: 0.794141, top_k: 0.931797, samples/s: 784.142 1613448302.9961307
train: epoch 138, iter 4100, loss: 1.946556, top_1: 0.791758, top_k: 0.928555, samples/s: 780.967 1613448335.776056
train: epoch 138, iter 4200, loss: 1.836212, top_1: 0.790273, top_k: 0.924883, samples/s: 780.072 1613448368.5934749
train: epoch 138, iter 4300, loss: 1.804888, top_1: 0.798555, top_k: 0.931836, samples/s: 782.992 1613448401.2885442
train: epoch 138, iter 4400, loss: 1.875484, top_1: 0.792383, top_k: 0.930234, samples/s: 783.591 1613448433.9586575
train: epoch 138, iter 4500, loss: 1.923037, top_1: 0.793594, top_k: 0.932227, samples/s: 781.645 1613448466.7101598
train: epoch 138, iter 4600, loss: 1.918092, top_1: 0.792695, top_k: 0.929453, samples/s: 782.091 1613448499.4429717
train: epoch 138, iter 4700, loss: 1.829171, top_1: 0.791562, top_k: 0.927852, samples/s: 780.653 1613448532.236275
train: epoch 138, iter 4800, loss: 1.783268, top_1: 0.790977, top_k: 0.930078, samples/s: 783.113 1613448564.9260263
train: epoch 138, iter 4900, loss: 2.065495, top_1: 0.789414, top_k: 0.929531, samples/s: 780.955 1613448597.7063713
train: epoch 138, iter 5000, loss: 1.937840, top_1: 0.799727, top_k: 0.931641, samples/s: 784.548 1613448630.3366513
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_138.
validation: epoch 138, iter 195, top_1: 0.770172, top_k: 0.936298, samples/s: 2353.926 1613448652.5175428
train: epoch 139, iter 100, loss: 1.846446, top_1: 0.802227, top_k: 0.933594, samples/s: 804.421 1613448705.6830332
train: epoch 139, iter 200, loss: 1.738831, top_1: 0.797422, top_k: 0.932773, samples/s: 799.782 1613448737.6917357
train: epoch 139, iter 300, loss: 1.862557, top_1: 0.793906, top_k: 0.931445, samples/s: 783.637 1613448770.3597586
train: epoch 139, iter 400, loss: 1.774804, top_1: 0.797422, top_k: 0.930508, samples/s: 778.062 1613448803.2620268
train: epoch 139, iter 500, loss: 1.796913, top_1: 0.800000, top_k: 0.932461, samples/s: 778.873 1613448836.129951
train: epoch 139, iter 600, loss: 1.924288, top_1: 0.799805, top_k: 0.933164, samples/s: 780.902 1613448868.9125502
train: epoch 139, iter 700, loss: 2.010515, top_1: 0.798516, top_k: 0.930039, samples/s: 778.908 1613448901.7791212
train: epoch 139, iter 800, loss: 1.811642, top_1: 0.801602, top_k: 0.933398, samples/s: 782.046 1613448934.5137331
train: epoch 139, iter 900, loss: 1.900401, top_1: 0.795742, top_k: 0.931016, samples/s: 780.414 1613448967.3168845
train: epoch 139, iter 1000, loss: 1.832664, top_1: 0.798906, top_k: 0.930977, samples/s: 781.593 1613449000.0704596
train: epoch 139, iter 1100, loss: 1.964269, top_1: 0.793594, top_k: 0.928984, samples/s: 781.200 1613449032.8405964
train: epoch 139, iter 1200, loss: 1.838372, top_1: 0.796250, top_k: 0.932305, samples/s: 780.482 1613449065.6408863
train: epoch 139, iter 1300, loss: 1.843089, top_1: 0.798594, top_k: 0.928125, samples/s: 781.978 1613449098.3782947
train: epoch 139, iter 1400, loss: 1.915378, top_1: 0.794766, top_k: 0.927617, samples/s: 783.453 1613449131.054236
train: epoch 139, iter 1500, loss: 1.968722, top_1: 0.799687, top_k: 0.933008, samples/s: 781.801 1613449163.7991457
train: epoch 139, iter 1600, loss: 1.898313, top_1: 0.798008, top_k: 0.932109, samples/s: 781.957 1613449196.5374026
train: epoch 139, iter 1700, loss: 1.943793, top_1: 0.796367, top_k: 0.930312, samples/s: 783.087 1613449229.2285714
train: epoch 139, iter 1800, loss: 1.786726, top_1: 0.797109, top_k: 0.931523, samples/s: 782.162 1613449261.9583557
train: epoch 139, iter 1900, loss: 1.827238, top_1: 0.798242, top_k: 0.931406, samples/s: 784.003 1613449294.6113307
train: epoch 139, iter 2000, loss: 1.884065, top_1: 0.796836, top_k: 0.932070, samples/s: 782.891 1613449327.3106265
train: epoch 139, iter 2100, loss: 1.866011, top_1: 0.794219, top_k: 0.929453, samples/s: 781.764 1613449360.057148
train: epoch 139, iter 2200, loss: 1.846281, top_1: 0.794609, top_k: 0.929570, samples/s: 781.529 1613449392.81341
train: epoch 139, iter 2300, loss: 1.914029, top_1: 0.796094, top_k: 0.927969, samples/s: 781.276 1613449425.580293
train: epoch 139, iter 2400, loss: 1.847708, top_1: 0.797305, top_k: 0.930430, samples/s: 781.609 1613449458.3332071
train: epoch 139, iter 2500, loss: 1.909116, top_1: 0.796875, top_k: 0.930820, samples/s: 784.799 1613449490.9530776
train: epoch 139, iter 2600, loss: 1.693650, top_1: 0.790547, top_k: 0.928008, samples/s: 780.721 1613449523.7433257
train: epoch 139, iter 2700, loss: 1.781107, top_1: 0.792539, top_k: 0.931172, samples/s: 784.794 1613449556.3633866
train: epoch 139, iter 2800, loss: 1.824875, top_1: 0.793516, top_k: 0.928516, samples/s: 779.727 1613449589.195341
train: epoch 139, iter 2900, loss: 1.788991, top_1: 0.794766, top_k: 0.931016, samples/s: 784.610 1613449621.8228981
train: epoch 139, iter 3000, loss: 1.881163, top_1: 0.793516, top_k: 0.928125, samples/s: 783.393 1613449654.5013936
train: epoch 139, iter 3100, loss: 1.841570, top_1: 0.797969, top_k: 0.931211, samples/s: 784.369 1613449687.139023
train: epoch 139, iter 3200, loss: 2.005746, top_1: 0.800117, top_k: 0.932266, samples/s: 780.659 1613449719.9317904
train: epoch 139, iter 3300, loss: 1.911377, top_1: 0.790781, top_k: 0.928164, samples/s: 782.567 1613449752.6446888
train: epoch 139, iter 3400, loss: 1.816024, top_1: 0.800273, top_k: 0.933086, samples/s: 783.540 1613449785.3170006
train: epoch 139, iter 3500, loss: 1.851205, top_1: 0.793789, top_k: 0.928906, samples/s: 784.003 1613449817.9698203
train: epoch 139, iter 3600, loss: 1.899024, top_1: 0.795625, top_k: 0.931094, samples/s: 781.060 1613449850.7458398
train: epoch 139, iter 3700, loss: 1.920509, top_1: 0.791016, top_k: 0.926836, samples/s: 785.260 1613449883.3464677
train: epoch 139, iter 3800, loss: 1.829588, top_1: 0.795312, top_k: 0.930742, samples/s: 782.346 1613449916.068549
train: epoch 139, iter 3900, loss: 1.824261, top_1: 0.795859, top_k: 0.931211, samples/s: 784.938 1613449948.6826324
train: epoch 139, iter 4000, loss: 1.800297, top_1: 0.800352, top_k: 0.934023, samples/s: 781.347 1613449981.446583
train: epoch 139, iter 4100, loss: 1.811755, top_1: 0.797813, top_k: 0.930664, samples/s: 780.714 1613450014.237067
train: epoch 139, iter 4200, loss: 1.855970, top_1: 0.796797, top_k: 0.931055, samples/s: 782.822 1613450046.9392707
train: epoch 139, iter 4300, loss: 1.826588, top_1: 0.794531, top_k: 0.928125, samples/s: 781.951 1613450079.6779168
train: epoch 139, iter 4400, loss: 1.797781, top_1: 0.794609, top_k: 0.928047, samples/s: 782.891 1613450112.3772225
train: epoch 139, iter 4500, loss: 1.827581, top_1: 0.791562, top_k: 0.927773, samples/s: 781.328 1613450145.1419358
train: epoch 139, iter 4600, loss: 1.779815, top_1: 0.799180, top_k: 0.931562, samples/s: 783.125 1613450177.8314588
train: epoch 139, iter 4700, loss: 1.867341, top_1: 0.798633, top_k: 0.930547, samples/s: 780.778 1613450210.619343
train: epoch 139, iter 4800, loss: 1.843782, top_1: 0.795312, top_k: 0.930625, samples/s: 783.262 1613450243.3030705
train: epoch 139, iter 4900, loss: 1.735264, top_1: 0.801055, top_k: 0.932422, samples/s: 781.310 1613450276.0685446
train: epoch 139, iter 5000, loss: 1.746532, top_1: 0.802227, top_k: 0.932305, samples/s: 783.487 1613450308.7429578
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_139.
validation: epoch 139, iter 195, top_1: 0.772055, top_k: 0.937680, samples/s: 2359.615 1613450330.8587384
train: epoch 140, iter 100, loss: 1.708114, top_1: 0.804141, top_k: 0.933164, samples/s: 803.736 1613450384.1758869
train: epoch 140, iter 200, loss: 1.869184, top_1: 0.807344, top_k: 0.935430, samples/s: 799.729 1613450416.1868277
train: epoch 140, iter 300, loss: 1.842212, top_1: 0.804961, top_k: 0.935078, samples/s: 783.733 1613450448.8508847
train: epoch 140, iter 400, loss: 1.832462, top_1: 0.802617, top_k: 0.932383, samples/s: 778.896 1613450481.7179277
train: epoch 140, iter 500, loss: 1.827187, top_1: 0.803438, top_k: 0.934922, samples/s: 781.520 1613450514.474588
train: epoch 140, iter 600, loss: 1.883649, top_1: 0.797617, top_k: 0.930273, samples/s: 782.923 1613450547.1726189
train: epoch 140, iter 700, loss: 1.839428, top_1: 0.800742, top_k: 0.931797, samples/s: 778.907 1613450580.039108
train: epoch 140, iter 800, loss: 1.865865, top_1: 0.800820, top_k: 0.932539, samples/s: 780.332 1613450612.8456619
train: epoch 140, iter 900, loss: 1.996570, top_1: 0.801406, top_k: 0.931758, samples/s: 779.338 1613450645.6941514
train: epoch 140, iter 1000, loss: 1.887591, top_1: 0.795352, top_k: 0.932734, samples/s: 779.462 1613450678.5372374
train: epoch 140, iter 1100, loss: 1.834789, top_1: 0.802617, top_k: 0.933711, samples/s: 778.775 1613450711.4094195
train: epoch 140, iter 1200, loss: 1.658747, top_1: 0.804258, top_k: 0.935234, samples/s: 779.603 1613450744.2466989
train: epoch 140, iter 1300, loss: 1.871850, top_1: 0.802305, top_k: 0.932266, samples/s: 780.423 1613450777.049452
train: epoch 140, iter 1400, loss: 1.815926, top_1: 0.803828, top_k: 0.932500, samples/s: 781.614 1613450809.8021195
train: epoch 140, iter 1500, loss: 1.942371, top_1: 0.796836, top_k: 0.929922, samples/s: 781.583 1613450842.556112
train: epoch 140, iter 1600, loss: 1.866994, top_1: 0.799844, top_k: 0.930625, samples/s: 781.611 1613450875.3090413
train: epoch 140, iter 1700, loss: 1.817556, top_1: 0.797188, top_k: 0.932578, samples/s: 783.484 1613450907.9836414
train: epoch 140, iter 1800, loss: 1.876002, top_1: 0.801016, top_k: 0.934258, samples/s: 780.466 1613450940.7844894
train: epoch 140, iter 1900, loss: 1.884707, top_1: 0.797031, top_k: 0.930937, samples/s: 782.444 1613450973.5025184
train: epoch 140, iter 2000, loss: 1.709595, top_1: 0.801406, top_k: 0.933594, samples/s: 779.367 1613451006.349699
train: epoch 140, iter 2100, loss: 1.794127, top_1: 0.803789, top_k: 0.933594, samples/s: 783.538 1613451039.0219622
train: epoch 140, iter 2200, loss: 1.862385, top_1: 0.800352, top_k: 0.932695, samples/s: 783.598 1613451071.6918354
train: epoch 140, iter 2300, loss: 1.846336, top_1: 0.801445, top_k: 0.931484, samples/s: 782.575 1613451104.4043438
train: epoch 140, iter 2400, loss: 1.866173, top_1: 0.799141, top_k: 0.931016, samples/s: 782.593 1613451137.1160963
train: epoch 140, iter 2500, loss: 1.903938, top_1: 0.799297, top_k: 0.932969, samples/s: 783.249 1613451169.8005414
train: epoch 140, iter 2600, loss: 1.861403, top_1: 0.802656, top_k: 0.931484, samples/s: 781.568 1613451202.5551455
train: epoch 140, iter 2700, loss: 1.800432, top_1: 0.799414, top_k: 0.932148, samples/s: 783.795 1613451235.2168
train: epoch 140, iter 2800, loss: 1.956859, top_1: 0.799492, top_k: 0.932305, samples/s: 782.267 1613451267.942139
train: epoch 140, iter 2900, loss: 1.900172, top_1: 0.801719, top_k: 0.932305, samples/s: 780.810 1613451300.7285995
train: epoch 140, iter 3000, loss: 1.839800, top_1: 0.796172, top_k: 0.930977, samples/s: 784.203 1613451333.373196
train: epoch 140, iter 3100, loss: 1.781845, top_1: 0.795039, top_k: 0.929688, samples/s: 779.957 1613451366.1954973
train: epoch 140, iter 3200, loss: 2.003018, top_1: 0.799805, top_k: 0.933516, samples/s: 778.138 1613451399.0946083
train: epoch 140, iter 3300, loss: 1.795088, top_1: 0.797539, top_k: 0.930391, samples/s: 783.215 1613451431.7803102
train: epoch 140, iter 3400, loss: 1.927330, top_1: 0.800234, top_k: 0.931875, samples/s: 782.093 1613451464.5130413
train: epoch 140, iter 3500, loss: 1.854273, top_1: 0.796641, top_k: 0.932969, samples/s: 785.184 1613451497.1169078
train: epoch 140, iter 3600, loss: 1.785184, top_1: 0.797656, top_k: 0.932109, samples/s: 781.200 1613451529.8869386
train: epoch 140, iter 3700, loss: 1.836135, top_1: 0.795898, top_k: 0.929023, samples/s: 780.162 1613451562.7006874
train: epoch 140, iter 3800, loss: 1.973274, top_1: 0.800625, top_k: 0.931445, samples/s: 785.217 1613451595.303137
train: epoch 140, iter 3900, loss: 1.876056, top_1: 0.800312, top_k: 0.933594, samples/s: 781.443 1613451628.0630136
train: epoch 140, iter 4000, loss: 1.800756, top_1: 0.798906, top_k: 0.930820, samples/s: 782.458 1613451660.7803745
train: epoch 140, iter 4100, loss: 1.985258, top_1: 0.798867, top_k: 0.931914, samples/s: 781.651 1613451693.5316164
train: epoch 140, iter 4200, loss: 1.866246, top_1: 0.800898, top_k: 0.932344, samples/s: 782.695 1613451726.2391398
train: epoch 140, iter 4300, loss: 2.075217, top_1: 0.794609, top_k: 0.929297, samples/s: 780.989 1613451759.0180814
train: epoch 140, iter 4400, loss: 2.035192, top_1: 0.795664, top_k: 0.929883, samples/s: 782.320 1613451791.741236
train: epoch 140, iter 4500, loss: 1.870899, top_1: 0.799336, top_k: 0.931133, samples/s: 780.825 1613451824.526996
train: epoch 140, iter 4600, loss: 1.931430, top_1: 0.800781, top_k: 0.933125, samples/s: 783.619 1613451857.1960979
train: epoch 140, iter 4700, loss: 1.997687, top_1: 0.796055, top_k: 0.933477, samples/s: 782.156 1613451889.926055
train: epoch 140, iter 4800, loss: 1.827467, top_1: 0.799805, top_k: 0.931758, samples/s: 780.236 1613451922.7366433
train: epoch 140, iter 4900, loss: 2.125071, top_1: 0.801914, top_k: 0.932422, samples/s: 781.222 1613451955.5057862
train: epoch 140, iter 5000, loss: 1.812800, top_1: 0.802734, top_k: 0.933320, samples/s: 782.147 1613451988.2361367
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_140.
validation: epoch 140, iter 195, top_1: 0.774840, top_k: 0.937119, samples/s: 2394.510 1613452010.13471
train: epoch 141, iter 100, loss: 1.860665, top_1: 0.809063, top_k: 0.933906, samples/s: 803.939 1613452062.877583
train: epoch 141, iter 200, loss: 1.869734, top_1: 0.809336, top_k: 0.935977, samples/s: 801.814 1613452094.8053071
train: epoch 141, iter 300, loss: 1.838094, top_1: 0.800937, top_k: 0.932422, samples/s: 783.868 1613452127.4638302
train: epoch 141, iter 400, loss: 1.802383, top_1: 0.803516, top_k: 0.933672, samples/s: 781.799 1613452160.2088118
train: epoch 141, iter 500, loss: 1.850463, top_1: 0.801172, top_k: 0.932969, samples/s: 781.525 1613452192.9653082
train: epoch 141, iter 600, loss: 1.615916, top_1: 0.809297, top_k: 0.936016, samples/s: 779.320 1613452225.81443
train: epoch 141, iter 700, loss: 1.667718, top_1: 0.804648, top_k: 0.934023, samples/s: 784.324 1613452258.454027
train: epoch 141, iter 800, loss: 1.766957, top_1: 0.801406, top_k: 0.932187, samples/s: 778.385 1613452291.3425617
train: epoch 141, iter 900, loss: 1.877916, top_1: 0.799219, top_k: 0.932266, samples/s: 782.128 1613452324.0738008
train: epoch 141, iter 1000, loss: 1.920951, top_1: 0.803906, top_k: 0.935703, samples/s: 782.934 1613452356.7713628
train: epoch 141, iter 1100, loss: 1.745188, top_1: 0.806523, top_k: 0.935039, samples/s: 783.461 1613452389.446784
train: epoch 141, iter 1200, loss: 1.639068, top_1: 0.802969, top_k: 0.932930, samples/s: 781.315 1613452422.2121823
train: epoch 141, iter 1300, loss: 1.830934, top_1: 0.800586, top_k: 0.930781, samples/s: 782.350 1613452454.9341042
train: epoch 141, iter 1400, loss: 1.817502, top_1: 0.804102, top_k: 0.933164, samples/s: 780.710 1613452487.7247353
train: epoch 141, iter 1500, loss: 1.798692, top_1: 0.803711, top_k: 0.933242, samples/s: 782.108 1613452520.4567666
train: epoch 141, iter 1600, loss: 1.924680, top_1: 0.800234, top_k: 0.933320, samples/s: 783.491 1613452553.131045
train: epoch 141, iter 1700, loss: 1.697567, top_1: 0.807500, top_k: 0.935234, samples/s: 780.009 1613452585.95127
train: epoch 141, iter 1800, loss: 1.843277, top_1: 0.803633, top_k: 0.933398, samples/s: 784.436 1613452618.5860827
train: epoch 141, iter 1900, loss: 1.964251, top_1: 0.805977, top_k: 0.935586, samples/s: 784.471 1613452651.2195709
train: epoch 141, iter 2000, loss: 1.826638, top_1: 0.800703, top_k: 0.932383, samples/s: 782.890 1613452683.9189312
train: epoch 141, iter 2100, loss: 1.833672, top_1: 0.801797, top_k: 0.932969, samples/s: 782.774 1613452716.623082
train: epoch 141, iter 2200, loss: 1.774657, top_1: 0.808945, top_k: 0.936133, samples/s: 781.734 1613452749.3708715
train: epoch 141, iter 2300, loss: 1.882895, top_1: 0.805977, top_k: 0.934805, samples/s: 782.183 1613452782.0996885
train: epoch 141, iter 2400, loss: 1.896793, top_1: 0.806719, top_k: 0.934297, samples/s: 783.749 1613452814.7632673
train: epoch 141, iter 2500, loss: 1.861663, top_1: 0.807734, top_k: 0.933906, samples/s: 780.306 1613452847.5708518
train: epoch 141, iter 2600, loss: 1.824512, top_1: 0.803438, top_k: 0.934570, samples/s: 781.512 1613452880.3278942
train: epoch 141, iter 2700, loss: 1.891658, top_1: 0.803750, top_k: 0.934063, samples/s: 784.527 1613452912.9590364
train: epoch 141, iter 2800, loss: 1.785190, top_1: 0.804727, top_k: 0.933086, samples/s: 784.992 1613452945.5707853
train: epoch 141, iter 2900, loss: 1.785769, top_1: 0.796445, top_k: 0.932305, samples/s: 781.162 1613452978.3424783
train: epoch 141, iter 3000, loss: 1.747379, top_1: 0.798750, top_k: 0.932383, samples/s: 783.292 1613453011.0250983
train: epoch 141, iter 3100, loss: 1.867853, top_1: 0.804492, top_k: 0.933750, samples/s: 783.148 1613453043.7136545
train: epoch 141, iter 3200, loss: 1.914199, top_1: 0.802461, top_k: 0.932617, samples/s: 780.312 1613453076.5211341
train: epoch 141, iter 3300, loss: 1.748444, top_1: 0.806133, top_k: 0.934336, samples/s: 781.784 1613453109.2667437
train: epoch 141, iter 3400, loss: 1.834224, top_1: 0.806016, top_k: 0.933281, samples/s: 782.645 1613453141.9763033
train: epoch 141, iter 3500, loss: 1.724526, top_1: 0.800430, top_k: 0.934609, samples/s: 781.875 1613453174.7180326
train: epoch 141, iter 3600, loss: 1.706779, top_1: 0.806758, top_k: 0.934258, samples/s: 782.335 1613453207.4406843
train: epoch 141, iter 3700, loss: 1.848242, top_1: 0.801367, top_k: 0.930898, samples/s: 782.940 1613453240.1378896
train: epoch 141, iter 3800, loss: 1.903653, top_1: 0.798984, top_k: 0.933789, samples/s: 782.348 1613453272.8599312
train: epoch 141, iter 3900, loss: 1.912769, top_1: 0.802773, top_k: 0.933516, samples/s: 782.648 1613453305.569428
train: epoch 141, iter 4000, loss: 1.797411, top_1: 0.796406, top_k: 0.930469, samples/s: 780.664 1613453338.3619502
train: epoch 141, iter 4100, loss: 1.836122, top_1: 0.804727, top_k: 0.934609, samples/s: 784.105 1613453371.0106232
train: epoch 141, iter 4200, loss: 1.841224, top_1: 0.805898, top_k: 0.933477, samples/s: 784.554 1613453403.6406422
train: epoch 141, iter 4300, loss: 1.928159, top_1: 0.808867, top_k: 0.932305, samples/s: 782.434 1613453436.3591106
train: epoch 141, iter 4400, loss: 1.871258, top_1: 0.797969, top_k: 0.931797, samples/s: 783.277 1613453469.0422573
train: epoch 141, iter 4500, loss: 1.958750, top_1: 0.799492, top_k: 0.932227, samples/s: 784.012 1613453501.6948898
train: epoch 141, iter 4600, loss: 1.978536, top_1: 0.799492, top_k: 0.931719, samples/s: 785.198 1613453534.2980616
train: epoch 141, iter 4700, loss: 1.933525, top_1: 0.803164, top_k: 0.933047, samples/s: 781.060 1613453567.0740416
train: epoch 141, iter 4800, loss: 1.822481, top_1: 0.799961, top_k: 0.935508, samples/s: 782.575 1613453599.786515
train: epoch 141, iter 4900, loss: 1.902168, top_1: 0.801758, top_k: 0.931055, samples/s: 783.709 1613453632.451773
train: epoch 141, iter 5000, loss: 1.942837, top_1: 0.805977, top_k: 0.934023, samples/s: 784.273 1613453665.0934203
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_141.
validation: epoch 141, iter 195, top_1: 0.774920, top_k: 0.938882, samples/s: 2375.910 1613453687.0793958
train: epoch 142, iter 100, loss: 1.796531, top_1: 0.807891, top_k: 0.934961, samples/s: 806.110 1613453739.5224786
train: epoch 142, iter 200, loss: 1.736320, top_1: 0.808281, top_k: 0.935937, samples/s: 802.086 1613453771.4393704
train: epoch 142, iter 300, loss: 1.773072, top_1: 0.805469, top_k: 0.934883, samples/s: 786.393 1613453803.9928887
train: epoch 142, iter 400, loss: 1.843904, top_1: 0.809766, top_k: 0.935000, samples/s: 777.693 1613453836.9107642
train: epoch 142, iter 500, loss: 1.869263, top_1: 0.806992, top_k: 0.932852, samples/s: 784.592 1613453869.5391567
train: epoch 142, iter 600, loss: 1.792665, top_1: 0.810898, top_k: 0.937227, samples/s: 778.542 1613453902.4211586
train: epoch 142, iter 700, loss: 1.813853, top_1: 0.806328, top_k: 0.933828, samples/s: 784.191 1613453935.066164
train: epoch 142, iter 800, loss: 1.805158, top_1: 0.806680, top_k: 0.934883, samples/s: 780.715 1613453967.8567026
train: epoch 142, iter 900, loss: 1.697140, top_1: 0.803242, top_k: 0.933047, samples/s: 780.634 1613454000.650562
train: epoch 142, iter 1000, loss: 1.783431, top_1: 0.807422, top_k: 0.935859, samples/s: 783.735 1613454033.3145988
train: epoch 142, iter 1100, loss: 1.748435, top_1: 0.806367, top_k: 0.934766, samples/s: 782.431 1613454066.033177
train: epoch 142, iter 1200, loss: 1.887972, top_1: 0.811289, top_k: 0.935156, samples/s: 781.206 1613454098.8030891
train: epoch 142, iter 1300, loss: 1.717727, top_1: 0.806289, top_k: 0.934063, samples/s: 782.755 1613454131.508018
train: epoch 142, iter 1400, loss: 1.946790, top_1: 0.810156, top_k: 0.937031, samples/s: 784.379 1613454164.1453478
train: epoch 142, iter 1500, loss: 1.811385, top_1: 0.805937, top_k: 0.935391, samples/s: 777.973 1613454197.0513747
train: epoch 142, iter 1600, loss: 1.831511, top_1: 0.806133, top_k: 0.935469, samples/s: 783.435 1613454229.728029
train: epoch 142, iter 1700, loss: 1.918153, top_1: 0.808086, top_k: 0.931445, samples/s: 780.957 1613454262.50826
train: epoch 142, iter 1800, loss: 1.864019, top_1: 0.805195, top_k: 0.935117, samples/s: 783.117 1613454295.1981835
train: epoch 142, iter 1900, loss: 1.756657, top_1: 0.810508, top_k: 0.934063, samples/s: 780.241 1613454328.008575
train: epoch 142, iter 2000, loss: 1.732230, top_1: 0.807930, top_k: 0.934766, samples/s: 783.804 1613454360.669726
train: epoch 142, iter 2100, loss: 1.746573, top_1: 0.809492, top_k: 0.937109, samples/s: 781.414 1613454393.4308846
train: epoch 142, iter 2200, loss: 1.861744, top_1: 0.805781, top_k: 0.932500, samples/s: 782.906 1613454426.1295762
train: epoch 142, iter 2300, loss: 1.798943, top_1: 0.804414, top_k: 0.933867, samples/s: 781.972 1613454458.8672268
train: epoch 142, iter 2400, loss: 1.800331, top_1: 0.813555, top_k: 0.937383, samples/s: 780.924 1613454491.6489596
train: epoch 142, iter 2500, loss: 1.956431, top_1: 0.803438, top_k: 0.934180, samples/s: 784.188 1613454524.2941854
train: epoch 142, iter 2600, loss: 1.855492, top_1: 0.804023, top_k: 0.933398, samples/s: 781.418 1613454557.0552058
train: epoch 142, iter 2700, loss: 1.783871, top_1: 0.807227, top_k: 0.933047, samples/s: 783.887 1613454589.712886
train: epoch 142, iter 2800, loss: 1.976458, top_1: 0.807773, top_k: 0.936719, samples/s: 783.956 1613454622.3678064
train: epoch 142, iter 2900, loss: 1.835778, top_1: 0.807187, top_k: 0.934219, samples/s: 784.074 1613454655.0177164
train: epoch 142, iter 3000, loss: 1.851781, top_1: 0.806406, top_k: 0.936953, samples/s: 783.355 1613454687.6976583
train: epoch 142, iter 3100, loss: 1.768333, top_1: 0.809453, top_k: 0.934453, samples/s: 779.328 1613454720.5465956
train: epoch 142, iter 3200, loss: 1.949498, top_1: 0.807305, top_k: 0.935156, samples/s: 782.425 1613454753.2653456
train: epoch 142, iter 3300, loss: 1.857264, top_1: 0.800391, top_k: 0.931758, samples/s: 781.974 1613454786.0029485
train: epoch 142, iter 3400, loss: 1.878842, top_1: 0.807695, top_k: 0.934414, samples/s: 780.945 1613454818.7837665
train: epoch 142, iter 3500, loss: 1.823885, top_1: 0.804531, top_k: 0.932930, samples/s: 781.665 1613454851.5343897
train: epoch 142, iter 3600, loss: 1.847348, top_1: 0.799844, top_k: 0.935391, samples/s: 782.611 1613454884.2454333
train: epoch 142, iter 3700, loss: 1.770951, top_1: 0.806797, top_k: 0.934766, samples/s: 785.054 1613454916.8546329
train: epoch 142, iter 3800, loss: 1.738706, top_1: 0.806328, top_k: 0.935156, samples/s: 781.947 1613454949.5934067
train: epoch 142, iter 3900, loss: 1.738915, top_1: 0.806445, top_k: 0.936641, samples/s: 783.391 1613454982.2719376
train: epoch 142, iter 4000, loss: 1.655155, top_1: 0.811172, top_k: 0.938164, samples/s: 781.494 1613455015.029632
train: epoch 142, iter 4100, loss: 1.785589, top_1: 0.810039, top_k: 0.937813, samples/s: 782.819 1613455047.7320194
train: epoch 142, iter 4200, loss: 1.775425, top_1: 0.801719, top_k: 0.933320, samples/s: 782.609 1613455080.4430823
train: epoch 142, iter 4300, loss: 1.797240, top_1: 0.801992, top_k: 0.930117, samples/s: 781.094 1613455113.2176685
train: epoch 142, iter 4400, loss: 1.824042, top_1: 0.805117, top_k: 0.934922, samples/s: 784.213 1613455145.8617954
train: epoch 142, iter 4500, loss: 1.931711, top_1: 0.806484, top_k: 0.934570, samples/s: 781.161 1613455178.6336083
train: epoch 142, iter 4600, loss: 1.866338, top_1: 0.804453, top_k: 0.933477, samples/s: 784.576 1613455211.262599
train: epoch 142, iter 4700, loss: 1.775693, top_1: 0.808047, top_k: 0.935625, samples/s: 781.335 1613455244.0271072
train: epoch 142, iter 4800, loss: 1.695378, top_1: 0.806133, top_k: 0.933477, samples/s: 783.117 1613455276.716958
train: epoch 142, iter 4900, loss: 1.942232, top_1: 0.806055, top_k: 0.932930, samples/s: 783.567 1613455309.388001
train: epoch 142, iter 5000, loss: 1.800635, top_1: 0.806641, top_k: 0.935664, samples/s: 779.368 1613455342.2352023
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_142.
validation: epoch 142, iter 195, top_1: 0.773858, top_k: 0.937480, samples/s: 2371.252 1613455364.225342
train: epoch 143, iter 100, loss: 1.722857, top_1: 0.806523, top_k: 0.933359, samples/s: 801.448 1613455416.6312928
train: epoch 143, iter 200, loss: 1.809868, top_1: 0.808594, top_k: 0.935430, samples/s: 801.442 1613455448.5737786
train: epoch 143, iter 300, loss: 1.770180, top_1: 0.807148, top_k: 0.935977, samples/s: 782.100 1613455481.3060482
train: epoch 143, iter 400, loss: 1.803004, top_1: 0.813281, top_k: 0.935586, samples/s: 781.693 1613455514.0554562
train: epoch 143, iter 500, loss: 1.925597, top_1: 0.810781, top_k: 0.937500, samples/s: 780.689 1613455546.8470917
train: epoch 143, iter 600, loss: 1.739135, top_1: 0.811133, top_k: 0.935820, samples/s: 782.340 1613455579.5693848
train: epoch 143, iter 700, loss: 1.889263, top_1: 0.807930, top_k: 0.936367, samples/s: 781.670 1613455612.3197699
train: epoch 143, iter 800, loss: 1.712668, top_1: 0.815586, top_k: 0.937461, samples/s: 780.013 1613455645.1397545
train: epoch 143, iter 900, loss: 1.783576, top_1: 0.809570, top_k: 0.938477, samples/s: 781.334 1613455677.9042795
train: epoch 143, iter 1000, loss: 1.954479, top_1: 0.808945, top_k: 0.939883, samples/s: 781.043 1613455710.680902
train: epoch 143, iter 1100, loss: 1.804349, top_1: 0.809570, top_k: 0.935430, samples/s: 782.155 1613455743.4109945
train: epoch 143, iter 1200, loss: 1.865767, top_1: 0.811133, top_k: 0.936797, samples/s: 782.459 1613455776.1283717
train: epoch 143, iter 1300, loss: 1.832223, top_1: 0.809453, top_k: 0.934844, samples/s: 779.887 1613455808.9536254
train: epoch 143, iter 1400, loss: 1.707553, top_1: 0.807148, top_k: 0.936719, samples/s: 782.639 1613455841.663457
train: epoch 143, iter 1500, loss: 1.790785, top_1: 0.810977, top_k: 0.937031, samples/s: 782.104 1613455874.3956695
train: epoch 143, iter 1600, loss: 1.917290, top_1: 0.806133, top_k: 0.932539, samples/s: 781.289 1613455907.162033
train: epoch 143, iter 1700, loss: 1.850807, top_1: 0.810977, top_k: 0.937187, samples/s: 784.055 1613455939.8129041
train: epoch 143, iter 1800, loss: 1.909041, top_1: 0.807070, top_k: 0.935391, samples/s: 780.022 1613455972.6323776
train: epoch 143, iter 1900, loss: 1.795351, top_1: 0.812656, top_k: 0.936445, samples/s: 783.472 1613456005.3074818
train: epoch 143, iter 2000, loss: 1.709216, top_1: 0.807539, top_k: 0.936250, samples/s: 781.473 1613456038.0661416
train: epoch 143, iter 2100, loss: 1.760157, top_1: 0.810898, top_k: 0.937070, samples/s: 782.045 1613456070.800765
train: epoch 143, iter 2200, loss: 1.875288, top_1: 0.805234, top_k: 0.934023, samples/s: 780.663 1613456103.593506
train: epoch 143, iter 2300, loss: 1.788319, top_1: 0.813281, top_k: 0.937969, samples/s: 782.146 1613456136.323959
train: epoch 143, iter 2400, loss: 1.846761, top_1: 0.810469, top_k: 0.933789, samples/s: 782.752 1613456169.0289984
train: epoch 143, iter 2500, loss: 1.996918, top_1: 0.809414, top_k: 0.934922, samples/s: 782.797 1613456201.7322493
train: epoch 143, iter 2600, loss: 1.671054, top_1: 0.811953, top_k: 0.936172, samples/s: 780.653 1613456234.5253344
train: epoch 143, iter 2700, loss: 1.804324, top_1: 0.809766, top_k: 0.935937, samples/s: 783.773 1613456267.1878536
train: epoch 143, iter 2800, loss: 1.729823, top_1: 0.808086, top_k: 0.933203, samples/s: 781.947 1613456299.9266863
train: epoch 143, iter 2900, loss: 1.902422, top_1: 0.808906, top_k: 0.934453, samples/s: 782.234 1613456332.653492
train: epoch 143, iter 3000, loss: 1.824051, top_1: 0.801562, top_k: 0.934219, samples/s: 784.273 1613456365.2951777
train: epoch 143, iter 3100, loss: 1.672550, top_1: 0.813828, top_k: 0.936836, samples/s: 778.682 1613456398.1711724
train: epoch 143, iter 3200, loss: 1.789971, top_1: 0.808867, top_k: 0.937461, samples/s: 785.195 1613456430.7746418
train: epoch 143, iter 3300, loss: 1.907460, top_1: 0.808242, top_k: 0.935039, samples/s: 780.580 1613456463.5706904
train: epoch 143, iter 3400, loss: 1.748126, top_1: 0.809805, top_k: 0.935820, samples/s: 783.162 1613456496.2587352
train: epoch 143, iter 3500, loss: 1.889227, top_1: 0.810234, top_k: 0.937500, samples/s: 782.808 1613456528.9614897
train: epoch 143, iter 3600, loss: 1.888783, top_1: 0.805859, top_k: 0.934727, samples/s: 781.700 1613456561.7106314
train: epoch 143, iter 3700, loss: 1.744671, top_1: 0.812461, top_k: 0.935898, samples/s: 781.957 1613456594.4490747
train: epoch 143, iter 3800, loss: 1.819822, top_1: 0.807578, top_k: 0.935352, samples/s: 782.254 1613456627.1748497
train: epoch 143, iter 3900, loss: 1.899493, top_1: 0.807070, top_k: 0.935586, samples/s: 784.003 1613456659.8278275
train: epoch 143, iter 4000, loss: 1.830711, top_1: 0.805586, top_k: 0.933867, samples/s: 783.708 1613456692.4931293
train: epoch 143, iter 4100, loss: 1.810437, top_1: 0.807461, top_k: 0.932695, samples/s: 779.760 1613456725.3236272
train: epoch 143, iter 4200, loss: 1.788440, top_1: 0.809336, top_k: 0.933672, samples/s: 782.737 1613456758.0294616
train: epoch 143, iter 4300, loss: 1.801787, top_1: 0.808281, top_k: 0.935078, samples/s: 783.483 1613456790.704032
train: epoch 143, iter 4400, loss: 1.840875, top_1: 0.812227, top_k: 0.936875, samples/s: 785.006 1613456823.3151846
train: epoch 143, iter 4500, loss: 1.718245, top_1: 0.803750, top_k: 0.935078, samples/s: 783.374 1613456855.9944816
train: epoch 143, iter 4600, loss: 1.756915, top_1: 0.807109, top_k: 0.936602, samples/s: 783.576 1613456888.6652334
train: epoch 143, iter 4700, loss: 1.764527, top_1: 0.807773, top_k: 0.936250, samples/s: 782.418 1613456921.3842473
train: epoch 143, iter 4800, loss: 1.919834, top_1: 0.808438, top_k: 0.934336, samples/s: 784.160 1613456954.0305855
train: epoch 143, iter 4900, loss: 1.792414, top_1: 0.813789, top_k: 0.935273, samples/s: 783.251 1613456986.714846
train: epoch 143, iter 5000, loss: 1.820363, top_1: 0.810781, top_k: 0.939492, samples/s: 784.098 1613457019.3638456
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_143.
validation: epoch 143, iter 195, top_1: 0.777504, top_k: 0.938962, samples/s: 2360.032 1613457041.5002341
train: epoch 144, iter 100, loss: 1.755331, top_1: 0.815234, top_k: 0.940547, samples/s: 801.978 1613457093.8816311
train: epoch 144, iter 200, loss: 1.855382, top_1: 0.815586, top_k: 0.940586, samples/s: 800.711 1613457125.8533082
train: epoch 144, iter 300, loss: 1.963592, top_1: 0.811758, top_k: 0.935664, samples/s: 783.533 1613457158.525842
train: epoch 144, iter 400, loss: 1.843235, top_1: 0.814258, top_k: 0.938203, samples/s: 779.994 1613457191.346509
train: epoch 144, iter 500, loss: 1.790003, top_1: 0.813125, top_k: 0.936602, samples/s: 782.028 1613457224.0819108
train: epoch 144, iter 600, loss: 1.884199, top_1: 0.815000, top_k: 0.938125, samples/s: 780.592 1613457256.8775394
train: epoch 144, iter 700, loss: 1.837341, top_1: 0.815781, top_k: 0.937852, samples/s: 781.166 1613457289.64912
train: epoch 144, iter 800, loss: 1.777892, top_1: 0.813477, top_k: 0.937617, samples/s: 781.899 1613457322.389847
train: epoch 144, iter 900, loss: 1.715796, top_1: 0.813906, top_k: 0.940547, samples/s: 780.459 1613457355.1911316
train: epoch 144, iter 1000, loss: 1.929472, top_1: 0.814180, top_k: 0.937891, samples/s: 782.518 1613457387.9060347
train: epoch 144, iter 1100, loss: 1.842245, top_1: 0.813086, top_k: 0.937773, samples/s: 782.413 1613457420.6252315
train: epoch 144, iter 1200, loss: 1.691414, top_1: 0.813359, top_k: 0.936055, samples/s: 779.157 1613457453.4813895
train: epoch 144, iter 1300, loss: 1.757225, top_1: 0.812578, top_k: 0.937422, samples/s: 783.525 1613457486.1541908
train: epoch 144, iter 1400, loss: 1.764874, top_1: 0.810391, top_k: 0.936523, samples/s: 781.205 1613457518.9241033
train: epoch 144, iter 1500, loss: 1.719039, top_1: 0.812891, top_k: 0.938320, samples/s: 780.441 1613457551.7260132
train: epoch 144, iter 1600, loss: 1.746463, top_1: 0.818242, top_k: 0.938633, samples/s: 781.215 1613457584.495469
train: epoch 144, iter 1700, loss: 1.733836, top_1: 0.813086, top_k: 0.936445, samples/s: 783.864 1613457617.1541939
train: epoch 144, iter 1800, loss: 1.865769, top_1: 0.808516, top_k: 0.933164, samples/s: 782.863 1613457649.8546655
train: epoch 144, iter 1900, loss: 1.735392, top_1: 0.812461, top_k: 0.937891, samples/s: 782.884 1613457682.5542903
train: epoch 144, iter 2000, loss: 1.833317, top_1: 0.807578, top_k: 0.938867, samples/s: 782.858 1613457715.2549078
train: epoch 144, iter 2100, loss: 1.792614, top_1: 0.812500, top_k: 0.935156, samples/s: 779.586 1613457748.0929248
train: epoch 144, iter 2200, loss: 1.788151, top_1: 0.813086, top_k: 0.938789, samples/s: 782.556 1613457780.8061833
train: epoch 144, iter 2300, loss: 1.879752, top_1: 0.815195, top_k: 0.937031, samples/s: 782.048 1613457813.540848
train: epoch 144, iter 2400, loss: 1.778729, top_1: 0.810156, top_k: 0.938555, samples/s: 780.466 1613457846.3417077
train: epoch 144, iter 2500, loss: 1.889042, top_1: 0.814258, top_k: 0.936680, samples/s: 782.010 1613457879.0779123
train: epoch 144, iter 2600, loss: 1.708570, top_1: 0.814258, top_k: 0.939023, samples/s: 783.431 1613457911.754661
train: epoch 144, iter 2700, loss: 1.891663, top_1: 0.809180, top_k: 0.936797, samples/s: 782.393 1613457944.4747949
train: epoch 144, iter 2800, loss: 1.695035, top_1: 0.810430, top_k: 0.935898, samples/s: 780.162 1613457977.2884047
train: epoch 144, iter 2900, loss: 1.710192, top_1: 0.814180, top_k: 0.936172, samples/s: 779.619 1613458010.1249511
train: epoch 144, iter 3000, loss: 1.724989, top_1: 0.814766, top_k: 0.938711, samples/s: 785.840 1613458042.7015903
train: epoch 144, iter 3100, loss: 2.042904, top_1: 0.817578, top_k: 0.939531, samples/s: 781.722 1613458075.4498441
train: epoch 144, iter 3200, loss: 1.933629, top_1: 0.812578, top_k: 0.939258, samples/s: 782.023 1613458108.1854887
train: epoch 144, iter 3300, loss: 1.761429, top_1: 0.811953, top_k: 0.938398, samples/s: 782.696 1613458140.892895
train: epoch 144, iter 3400, loss: 1.732803, top_1: 0.814727, top_k: 0.936016, samples/s: 778.749 1613458173.7661593
train: epoch 144, iter 3500, loss: 1.925726, top_1: 0.810625, top_k: 0.936562, samples/s: 784.329 1613458206.4054759
train: epoch 144, iter 3600, loss: 1.818013, top_1: 0.809063, top_k: 0.937070, samples/s: 781.984 1613458239.1427398
train: epoch 144, iter 3700, loss: 1.844680, top_1: 0.813242, top_k: 0.938594, samples/s: 780.427 1613458271.945394
train: epoch 144, iter 3800, loss: 1.825000, top_1: 0.812422, top_k: 0.935234, samples/s: 781.247 1613458304.7134206
train: epoch 144, iter 3900, loss: 1.899328, top_1: 0.811602, top_k: 0.941445, samples/s: 785.251 1613458337.314406
train: epoch 144, iter 4000, loss: 1.765444, top_1: 0.816719, top_k: 0.936836, samples/s: 781.106 1613458370.088479
train: epoch 144, iter 4100, loss: 1.713639, top_1: 0.810977, top_k: 0.936953, samples/s: 779.050 1613458402.9490347
train: epoch 144, iter 4200, loss: 1.669854, top_1: 0.812930, top_k: 0.937656, samples/s: 784.237 1613458435.5921776
train: epoch 144, iter 4300, loss: 1.797905, top_1: 0.812187, top_k: 0.937266, samples/s: 781.108 1613458468.366087
train: epoch 144, iter 4400, loss: 1.849670, top_1: 0.812109, top_k: 0.935742, samples/s: 782.069 1613458501.099783
train: epoch 144, iter 4500, loss: 1.921987, top_1: 0.810469, top_k: 0.937227, samples/s: 784.118 1613458533.7478657
train: epoch 144, iter 4600, loss: 1.838139, top_1: 0.808672, top_k: 0.936133, samples/s: 781.667 1613458566.498446
train: epoch 144, iter 4700, loss: 1.758451, top_1: 0.814805, top_k: 0.937578, samples/s: 781.935 1613458599.237656
train: epoch 144, iter 4800, loss: 1.845943, top_1: 0.811797, top_k: 0.935937, samples/s: 780.300 1613458632.045607
train: epoch 144, iter 4900, loss: 1.826820, top_1: 0.809063, top_k: 0.937344, samples/s: 783.112 1613458664.7357748
train: epoch 144, iter 5000, loss: 1.695133, top_1: 0.813359, top_k: 0.937227, samples/s: 783.390 1613458697.4142323
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_144.
validation: epoch 144, iter 195, top_1: 0.777624, top_k: 0.938321, samples/s: 2346.850 1613458719.6395357
train: epoch 145, iter 100, loss: 1.638501, top_1: 0.817383, top_k: 0.935195, samples/s: 805.864 1613458771.691117
train: epoch 145, iter 200, loss: 1.663468, top_1: 0.818633, top_k: 0.939063, samples/s: 800.508 1613458803.6710415
train: epoch 145, iter 300, loss: 1.786999, top_1: 0.812305, top_k: 0.939688, samples/s: 784.163 1613458836.3171537
train: epoch 145, iter 400, loss: 1.746010, top_1: 0.816523, top_k: 0.937109, samples/s: 782.265 1613458869.042654
train: epoch 145, iter 500, loss: 1.765994, top_1: 0.814688, top_k: 0.939492, samples/s: 780.356 1613458901.848173
train: epoch 145, iter 600, loss: 1.739263, top_1: 0.814180, top_k: 0.937852, samples/s: 780.558 1613458934.6451917
train: epoch 145, iter 700, loss: 1.779829, top_1: 0.817148, top_k: 0.940117, samples/s: 781.598 1613458967.398653
train: epoch 145, iter 800, loss: 1.852660, top_1: 0.816367, top_k: 0.941133, samples/s: 781.134 1613459000.1714485
train: epoch 145, iter 900, loss: 1.686997, top_1: 0.817969, top_k: 0.942305, samples/s: 783.796 1613459032.8334074
train: epoch 145, iter 1000, loss: 1.844795, top_1: 0.813398, top_k: 0.937852, samples/s: 783.372 1613459065.512263
train: epoch 145, iter 1100, loss: 1.724635, top_1: 0.810469, top_k: 0.936172, samples/s: 780.559 1613459098.3097188
train: epoch 145, iter 1200, loss: 1.955180, top_1: 0.816875, top_k: 0.935469, samples/s: 783.642 1613459130.9773798
train: epoch 145, iter 1300, loss: 1.823521, top_1: 0.811523, top_k: 0.938438, samples/s: 784.933 1613459163.5915904
train: epoch 145, iter 1400, loss: 1.876356, top_1: 0.816406, top_k: 0.939023, samples/s: 780.169 1613459196.4049728
train: epoch 145, iter 1500, loss: 1.739455, top_1: 0.818008, top_k: 0.939453, samples/s: 781.232 1613459229.1737218
train: epoch 145, iter 1600, loss: 1.787725, top_1: 0.814688, top_k: 0.938711, samples/s: 781.038 1613459261.9506378
train: epoch 145, iter 1700, loss: 1.804420, top_1: 0.815117, top_k: 0.938398, samples/s: 783.097 1613459294.6414237
train: epoch 145, iter 1800, loss: 1.774851, top_1: 0.816445, top_k: 0.938789, samples/s: 782.332 1613459327.3640716
train: epoch 145, iter 1900, loss: 1.798053, top_1: 0.818008, top_k: 0.939297, samples/s: 782.221 1613459360.0913234
train: epoch 145, iter 2000, loss: 1.992791, top_1: 0.814258, top_k: 0.937266, samples/s: 781.112 1613459392.8652294
train: epoch 145, iter 2100, loss: 1.800181, top_1: 0.817266, top_k: 0.938750, samples/s: 782.601 1613459425.576678
train: epoch 145, iter 2200, loss: 1.878384, top_1: 0.814063, top_k: 0.939453, samples/s: 782.232 1613459458.3034093
train: epoch 145, iter 2300, loss: 1.909392, top_1: 0.812773, top_k: 0.935469, samples/s: 779.426 1613459491.1481755
train: epoch 145, iter 2400, loss: 1.760134, top_1: 0.812578, top_k: 0.937227, samples/s: 784.907 1613459523.7634425
train: epoch 145, iter 2500, loss: 1.887301, top_1: 0.813984, top_k: 0.935977, samples/s: 782.049 1613459556.4980073
train: epoch 145, iter 2600, loss: 1.806130, top_1: 0.814375, top_k: 0.938867, samples/s: 780.552 1613459589.2952785
train: epoch 145, iter 2700, loss: 1.776315, top_1: 0.814219, top_k: 0.937695, samples/s: 782.609 1613459622.0063965
train: epoch 145, iter 2800, loss: 1.809804, top_1: 0.820937, top_k: 0.938359, samples/s: 781.115 1613459654.7801018
train: epoch 145, iter 2900, loss: 1.671960, top_1: 0.817344, top_k: 0.937773, samples/s: 780.343 1613459687.5861528
train: epoch 145, iter 3000, loss: 1.887415, top_1: 0.816133, top_k: 0.935898, samples/s: 781.555 1613459720.3413196
train: epoch 145, iter 3100, loss: 1.860435, top_1: 0.812227, top_k: 0.938789, samples/s: 780.586 1613459753.137211
train: epoch 145, iter 3200, loss: 1.878277, top_1: 0.810469, top_k: 0.938984, samples/s: 781.972 1613459785.8750396
train: epoch 145, iter 3300, loss: 1.861273, top_1: 0.815000, top_k: 0.936094, samples/s: 782.201 1613459818.6032574
train: epoch 145, iter 3400, loss: 1.751382, top_1: 0.811875, top_k: 0.934102, samples/s: 784.026 1613459851.2551458
train: epoch 145, iter 3500, loss: 1.773878, top_1: 0.816562, top_k: 0.938008, samples/s: 783.502 1613459883.9289973
train: epoch 145, iter 3600, loss: 1.736883, top_1: 0.814844, top_k: 0.938008, samples/s: 783.383 1613459916.6077795
train: epoch 145, iter 3700, loss: 1.670123, top_1: 0.819297, top_k: 0.937617, samples/s: 782.558 1613459949.3210342
train: epoch 145, iter 3800, loss: 1.824557, top_1: 0.808984, top_k: 0.935430, samples/s: 781.393 1613459982.082926
train: epoch 145, iter 3900, loss: 1.694860, top_1: 0.814844, top_k: 0.936914, samples/s: 780.445 1613460014.8848133
train: epoch 145, iter 4000, loss: 1.706214, top_1: 0.813359, top_k: 0.935937, samples/s: 782.639 1613460047.594636
train: epoch 145, iter 4100, loss: 1.838049, top_1: 0.811367, top_k: 0.935430, samples/s: 782.564 1613460080.307564
train: epoch 145, iter 4200, loss: 1.816395, top_1: 0.816719, top_k: 0.939727, samples/s: 780.714 1613460113.0980718
train: epoch 145, iter 4300, loss: 1.851070, top_1: 0.815977, top_k: 0.938047, samples/s: 782.777 1613460145.8022141
train: epoch 145, iter 4400, loss: 1.771023, top_1: 0.812734, top_k: 0.937344, samples/s: 783.503 1613460178.475925
train: epoch 145, iter 4500, loss: 1.810411, top_1: 0.811875, top_k: 0.939648, samples/s: 782.319 1613460211.1992302
train: epoch 145, iter 4600, loss: 1.920349, top_1: 0.814844, top_k: 0.937266, samples/s: 779.446 1613460244.0430856
train: epoch 145, iter 4700, loss: 1.810022, top_1: 0.812734, top_k: 0.937461, samples/s: 785.487 1613460276.6343055
train: epoch 145, iter 4800, loss: 1.821976, top_1: 0.811719, top_k: 0.937891, samples/s: 780.576 1613460309.430618
train: epoch 145, iter 4900, loss: 1.710339, top_1: 0.815508, top_k: 0.938789, samples/s: 782.162 1613460342.1603112
train: epoch 145, iter 5000, loss: 1.760436, top_1: 0.813125, top_k: 0.938633, samples/s: 783.166 1613460374.8481452
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_145.
validation: epoch 145, iter 195, top_1: 0.778425, top_k: 0.939964, samples/s: 2357.501 1613460396.9981275
train: epoch 146, iter 100, loss: 1.656429, top_1: 0.818711, top_k: 0.937852, samples/s: 806.135 1613460456.5276427
train: epoch 146, iter 200, loss: 1.741351, top_1: 0.820430, top_k: 0.940117, samples/s: 801.180 1613460488.4809
train: epoch 146, iter 300, loss: 1.856248, top_1: 0.814805, top_k: 0.936172, samples/s: 788.586 1613460520.9437559
train: epoch 146, iter 400, loss: 1.801908, top_1: 0.821133, top_k: 0.941406, samples/s: 778.059 1613460553.8466697
train: epoch 146, iter 500, loss: 1.837873, top_1: 0.816133, top_k: 0.936953, samples/s: 780.592 1613460586.6417272
train: epoch 146, iter 600, loss: 1.862801, top_1: 0.817461, top_k: 0.938516, samples/s: 784.520 1613460619.2730386
train: epoch 146, iter 700, loss: 1.865017, top_1: 0.817539, top_k: 0.937031, samples/s: 779.965 1613460652.0951302
train: epoch 146, iter 800, loss: 1.788133, top_1: 0.817578, top_k: 0.938633, samples/s: 783.643 1613460684.7630124
train: epoch 146, iter 900, loss: 1.755972, top_1: 0.817148, top_k: 0.938398, samples/s: 780.238 1613460717.573577
train: epoch 146, iter 1000, loss: 1.748236, top_1: 0.821406, top_k: 0.941094, samples/s: 781.971 1613460750.3113363
train: epoch 146, iter 1100, loss: 1.731648, top_1: 0.817539, top_k: 0.939609, samples/s: 779.540 1613460783.1511455
train: epoch 146, iter 1200, loss: 1.671180, top_1: 0.816992, top_k: 0.938242, samples/s: 779.526 1613460815.991671
train: epoch 146, iter 1300, loss: 1.748163, top_1: 0.815156, top_k: 0.938047, samples/s: 781.389 1613460848.753772
train: epoch 146, iter 1400, loss: 1.859650, top_1: 0.821211, top_k: 0.939531, samples/s: 781.830 1613460881.4975836
train: epoch 146, iter 1500, loss: 1.847578, top_1: 0.818750, top_k: 0.939219, samples/s: 781.581 1613460914.2515922
train: epoch 146, iter 1600, loss: 1.737266, top_1: 0.817578, top_k: 0.938398, samples/s: 782.791 1613460946.9551268
train: epoch 146, iter 1700, loss: 1.697465, top_1: 0.824336, top_k: 0.942266, samples/s: 778.723 1613460979.829557
train: epoch 146, iter 1800, loss: 1.732022, top_1: 0.813438, top_k: 0.936523, samples/s: 781.703 1613461012.5785165
train: epoch 146, iter 1900, loss: 1.867251, top_1: 0.816641, top_k: 0.940312, samples/s: 781.295 1613461045.3446693
train: epoch 146, iter 2000, loss: 1.763552, top_1: 0.819141, top_k: 0.939219, samples/s: 781.424 1613461078.105328
train: epoch 146, iter 2100, loss: 1.794908, top_1: 0.810352, top_k: 0.936836, samples/s: 780.662 1613461110.8980474
train: epoch 146, iter 2200, loss: 1.913346, top_1: 0.819258, top_k: 0.941602, samples/s: 779.929 1613461143.721551
train: epoch 146, iter 2300, loss: 1.856808, top_1: 0.814375, top_k: 0.940039, samples/s: 780.511 1613461176.5205193
train: epoch 146, iter 2400, loss: 1.736451, top_1: 0.821133, top_k: 0.942187, samples/s: 782.614 1613461209.2315266
train: epoch 146, iter 2500, loss: 1.767299, top_1: 0.814570, top_k: 0.939688, samples/s: 781.565 1613461241.9862478
train: epoch 146, iter 2600, loss: 1.776026, top_1: 0.817500, top_k: 0.940117, samples/s: 783.267 1613461274.6698818
train: epoch 146, iter 2700, loss: 1.742270, top_1: 0.815000, top_k: 0.938125, samples/s: 782.331 1613461307.3925407
train: epoch 146, iter 2800, loss: 1.726880, top_1: 0.814063, top_k: 0.937852, samples/s: 781.793 1613461340.1377757
train: epoch 146, iter 2900, loss: 1.861425, top_1: 0.816953, top_k: 0.938086, samples/s: 782.155 1613461372.8678813
train: epoch 146, iter 3000, loss: 1.728045, top_1: 0.815859, top_k: 0.935234, samples/s: 781.714 1613461405.6164954
train: epoch 146, iter 3100, loss: 1.898196, top_1: 0.816055, top_k: 0.939102, samples/s: 782.417 1613461438.3355858
train: epoch 146, iter 3200, loss: 1.801328, top_1: 0.819180, top_k: 0.936875, samples/s: 780.210 1613461471.1472735
train: epoch 146, iter 3300, loss: 1.724514, top_1: 0.816406, top_k: 0.939453, samples/s: 783.680 1613461503.8136988
train: epoch 146, iter 3400, loss: 1.757537, top_1: 0.814688, top_k: 0.938906, samples/s: 779.556 1613461536.652911
train: epoch 146, iter 3500, loss: 1.941178, top_1: 0.818125, top_k: 0.941172, samples/s: 781.897 1613461569.3936787
train: epoch 146, iter 3600, loss: 1.670376, top_1: 0.814141, top_k: 0.940352, samples/s: 782.775 1613461602.0978868
train: epoch 146, iter 3700, loss: 1.660341, top_1: 0.811250, top_k: 0.938281, samples/s: 780.376 1613461634.9025881
train: epoch 146, iter 3800, loss: 1.912411, top_1: 0.814414, top_k: 0.937969, samples/s: 782.750 1613461667.60777
train: epoch 146, iter 3900, loss: 1.870883, top_1: 0.818477, top_k: 0.937695, samples/s: 784.607 1613461700.2356272
train: epoch 146, iter 4000, loss: 1.782181, top_1: 0.814609, top_k: 0.936953, samples/s: 780.949 1613461733.0162232
train: epoch 146, iter 4100, loss: 1.726777, top_1: 0.816719, top_k: 0.939492, samples/s: 783.562 1613461765.687604
train: epoch 146, iter 4200, loss: 1.737128, top_1: 0.813516, top_k: 0.938086, samples/s: 778.482 1613461798.572093
train: epoch 146, iter 4300, loss: 1.747430, top_1: 0.821602, top_k: 0.941172, samples/s: 786.536 1613461831.1198132
train: epoch 146, iter 4400, loss: 1.811320, top_1: 0.812852, top_k: 0.938711, samples/s: 779.435 1613461863.9642234
train: epoch 146, iter 4500, loss: 1.775876, top_1: 0.817930, top_k: 0.937813, samples/s: 784.040 1613461896.6155455
train: epoch 146, iter 4600, loss: 1.866700, top_1: 0.817148, top_k: 0.939102, samples/s: 780.684 1613461929.407239
train: epoch 146, iter 4700, loss: 1.747385, top_1: 0.816289, top_k: 0.936367, samples/s: 783.346 1613461962.087608
train: epoch 146, iter 4800, loss: 1.785740, top_1: 0.818672, top_k: 0.940937, samples/s: 783.202 1613461994.773837
train: epoch 146, iter 4900, loss: 1.852628, top_1: 0.814766, top_k: 0.937266, samples/s: 781.412 1613462027.5351222
train: epoch 146, iter 5000, loss: 1.770457, top_1: 0.818516, top_k: 0.937852, samples/s: 783.590 1613462060.2052276
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_146.
validation: epoch 146, iter 195, top_1: 0.780308, top_k: 0.940004, samples/s: 2354.519 1613462082.390352
train: epoch 147, iter 100, loss: 1.696518, top_1: 0.822852, top_k: 0.941211, samples/s: 804.864 1613462134.825482
train: epoch 147, iter 200, loss: 1.816670, top_1: 0.818945, top_k: 0.940273, samples/s: 799.688 1613462166.838037
train: epoch 147, iter 300, loss: 1.878834, top_1: 0.821250, top_k: 0.941055, samples/s: 783.261 1613462199.5218477
train: epoch 147, iter 400, loss: 1.819540, top_1: 0.818750, top_k: 0.939219, samples/s: 782.947 1613462232.2187953
train: epoch 147, iter 500, loss: 1.755625, top_1: 0.823828, top_k: 0.940352, samples/s: 781.249 1613462264.9867861
train: epoch 147, iter 600, loss: 1.727115, top_1: 0.820781, top_k: 0.938164, samples/s: 781.123 1613462297.7601945
train: epoch 147, iter 700, loss: 1.844697, top_1: 0.821055, top_k: 0.939063, samples/s: 781.077 1613462330.5353513
train: epoch 147, iter 800, loss: 1.706146, top_1: 0.823281, top_k: 0.942891, samples/s: 781.051 1613462363.3116796
train: epoch 147, iter 900, loss: 1.829268, top_1: 0.817539, top_k: 0.939570, samples/s: 781.285 1613462396.0781925
train: epoch 147, iter 1000, loss: 1.795494, top_1: 0.815078, top_k: 0.937852, samples/s: 784.697 1613462428.702281
train: epoch 147, iter 1100, loss: 1.621280, top_1: 0.818281, top_k: 0.937148, samples/s: 782.183 1613462461.431188
train: epoch 147, iter 1200, loss: 1.865743, top_1: 0.815820, top_k: 0.939648, samples/s: 783.419 1613462494.1085052
train: epoch 147, iter 1300, loss: 1.747396, top_1: 0.820117, top_k: 0.940625, samples/s: 782.416 1613462526.827759
train: epoch 147, iter 1400, loss: 1.911395, top_1: 0.821211, top_k: 0.940156, samples/s: 779.134 1613462559.684636
train: epoch 147, iter 1500, loss: 1.749202, top_1: 0.821055, top_k: 0.939961, samples/s: 783.953 1613462592.3397276
train: epoch 147, iter 1600, loss: 1.806888, top_1: 0.815117, top_k: 0.936523, samples/s: 781.293 1613462625.1058428
train: epoch 147, iter 1700, loss: 1.695577, top_1: 0.819922, top_k: 0.941289, samples/s: 781.863 1613462657.8482208
train: epoch 147, iter 1800, loss: 1.740853, top_1: 0.818320, top_k: 0.940352, samples/s: 783.604 1613462690.5177214
train: epoch 147, iter 1900, loss: 1.705238, top_1: 0.822305, top_k: 0.939688, samples/s: 780.096 1613462723.3343043
train: epoch 147, iter 2000, loss: 1.768283, top_1: 0.817852, top_k: 0.939492, samples/s: 782.347 1613462756.0563235
train: epoch 147, iter 2100, loss: 1.828454, top_1: 0.820742, top_k: 0.938438, samples/s: 781.064 1613462788.8320453
train: epoch 147, iter 2200, loss: 1.857977, top_1: 0.816523, top_k: 0.937813, samples/s: 781.404 1613462821.5937176
train: epoch 147, iter 2300, loss: 1.890826, top_1: 0.820742, top_k: 0.939883, samples/s: 784.222 1613462854.2375152
train: epoch 147, iter 2400, loss: 1.778032, top_1: 0.823164, top_k: 0.940703, samples/s: 781.578 1613462886.991725
train: epoch 147, iter 2500, loss: 1.895669, top_1: 0.814648, top_k: 0.939609, samples/s: 783.089 1613462919.682682
train: epoch 147, iter 2600, loss: 1.656597, top_1: 0.818711, top_k: 0.940664, samples/s: 781.314 1613462952.448078
train: epoch 147, iter 2700, loss: 1.805464, top_1: 0.817422, top_k: 0.937734, samples/s: 781.522 1613462985.2046332
train: epoch 147, iter 2800, loss: 1.687211, top_1: 0.819570, top_k: 0.941133, samples/s: 783.155 1613463017.8929818
train: epoch 147, iter 2900, loss: 1.852691, top_1: 0.816602, top_k: 0.936992, samples/s: 784.408 1613463050.529027
train: epoch 147, iter 3000, loss: 1.762295, top_1: 0.818086, top_k: 0.939688, samples/s: 786.154 1613463083.0926445
train: epoch 147, iter 3100, loss: 1.703762, top_1: 0.817969, top_k: 0.941172, samples/s: 780.014 1613463115.9125288
train: epoch 147, iter 3200, loss: 1.854005, top_1: 0.816992, top_k: 0.939766, samples/s: 783.884 1613463148.5704186
train: epoch 147, iter 3300, loss: 1.979920, top_1: 0.813555, top_k: 0.937539, samples/s: 782.609 1613463181.281481
train: epoch 147, iter 3400, loss: 1.724568, top_1: 0.818477, top_k: 0.939219, samples/s: 780.726 1613463214.0714242
train: epoch 147, iter 3500, loss: 1.801150, top_1: 0.816523, top_k: 0.937422, samples/s: 784.104 1613463246.7202575
train: epoch 147, iter 3600, loss: 1.766433, top_1: 0.813594, top_k: 0.935781, samples/s: 783.581 1613463279.390721
train: epoch 147, iter 3700, loss: 1.792388, top_1: 0.821211, top_k: 0.942383, samples/s: 781.764 1613463312.1371856
train: epoch 147, iter 3800, loss: 1.678547, top_1: 0.817070, top_k: 0.940586, samples/s: 784.460 1613463344.77109
train: epoch 147, iter 3900, loss: 1.803922, top_1: 0.816367, top_k: 0.939219, samples/s: 783.006 1613463377.4656734
train: epoch 147, iter 4000, loss: 1.726603, top_1: 0.817852, top_k: 0.940391, samples/s: 782.376 1613463410.1865113
train: epoch 147, iter 4100, loss: 1.711092, top_1: 0.820117, top_k: 0.938828, samples/s: 782.505 1613463442.9019508
train: epoch 147, iter 4200, loss: 1.844125, top_1: 0.819180, top_k: 0.940312, samples/s: 780.790 1613463475.6891415
train: epoch 147, iter 4300, loss: 1.715277, top_1: 0.813125, top_k: 0.937305, samples/s: 783.424 1613463508.3662384
train: epoch 147, iter 4400, loss: 1.886735, top_1: 0.818711, top_k: 0.937461, samples/s: 781.564 1613463541.1211507
train: epoch 147, iter 4500, loss: 1.800709, top_1: 0.820117, top_k: 0.941094, samples/s: 783.199 1613463573.8076286
train: epoch 147, iter 4600, loss: 1.751643, top_1: 0.818320, top_k: 0.939258, samples/s: 782.707 1613463606.5145938
train: epoch 147, iter 4700, loss: 1.671777, top_1: 0.815273, top_k: 0.938867, samples/s: 781.887 1613463639.2559133
train: epoch 147, iter 4800, loss: 1.754635, top_1: 0.815234, top_k: 0.937969, samples/s: 782.232 1613463671.9826536
train: epoch 147, iter 4900, loss: 1.817100, top_1: 0.816562, top_k: 0.938203, samples/s: 780.448 1613463704.784441
train: epoch 147, iter 5000, loss: 1.669485, top_1: 0.823047, top_k: 0.938633, samples/s: 784.665 1613463737.4097931
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_147.
validation: epoch 147, iter 195, top_1: 0.780148, top_k: 0.939924, samples/s: 2350.639 1613463759.6360273
train: epoch 148, iter 100, loss: 1.859490, top_1: 0.822383, top_k: 0.939609, samples/s: 804.971 1613463811.7356074
train: epoch 148, iter 200, loss: 1.727480, top_1: 0.822969, top_k: 0.940117, samples/s: 798.793 1613463843.783912
train: epoch 148, iter 300, loss: 1.841052, top_1: 0.820156, top_k: 0.938633, samples/s: 784.197 1613463876.4286733
train: epoch 148, iter 400, loss: 1.769759, top_1: 0.826797, top_k: 0.944766, samples/s: 782.758 1613463909.1335447
train: epoch 148, iter 500, loss: 1.749374, top_1: 0.823984, top_k: 0.938555, samples/s: 777.952 1613463942.0403676
train: epoch 148, iter 600, loss: 1.803372, top_1: 0.821914, top_k: 0.941211, samples/s: 779.672 1613463974.874752
train: epoch 148, iter 700, loss: 1.719463, top_1: 0.824297, top_k: 0.942656, samples/s: 783.569 1613464007.5457923
train: epoch 148, iter 800, loss: 1.758395, top_1: 0.820273, top_k: 0.939961, samples/s: 780.582 1613464040.3417456
train: epoch 148, iter 900, loss: 1.734596, top_1: 0.821367, top_k: 0.940391, samples/s: 781.126 1613464073.11501
train: epoch 148, iter 1000, loss: 1.705015, top_1: 0.823828, top_k: 0.943125, samples/s: 782.015 1613464105.8509495
train: epoch 148, iter 1100, loss: 1.818196, top_1: 0.821602, top_k: 0.938203, samples/s: 783.773 1613464138.5134811
train: epoch 148, iter 1200, loss: 1.891931, top_1: 0.821328, top_k: 0.939883, samples/s: 780.512 1613464171.3123791
train: epoch 148, iter 1300, loss: 2.013032, top_1: 0.818320, top_k: 0.937969, samples/s: 784.769 1613464203.9334583
train: epoch 148, iter 1400, loss: 1.902912, top_1: 0.822617, top_k: 0.939922, samples/s: 779.895 1613464236.7583683
train: epoch 148, iter 1500, loss: 1.746826, top_1: 0.818242, top_k: 0.939180, samples/s: 782.077 1613464269.4917285
train: epoch 148, iter 1600, loss: 1.914895, top_1: 0.813633, top_k: 0.940508, samples/s: 779.406 1613464302.3373334
train: epoch 148, iter 1700, loss: 1.746808, top_1: 0.819023, top_k: 0.940469, samples/s: 783.960 1613464334.9920628
train: epoch 148, iter 1800, loss: 1.692940, top_1: 0.820547, top_k: 0.940898, samples/s: 782.839 1613464367.693575
train: epoch 148, iter 1900, loss: 1.711735, top_1: 0.819883, top_k: 0.939453, samples/s: 781.496 1613464400.4512134
train: epoch 148, iter 2000, loss: 1.798889, top_1: 0.822969, top_k: 0.943672, samples/s: 781.355 1613464433.214755
train: epoch 148, iter 2100, loss: 1.807468, top_1: 0.819805, top_k: 0.939180, samples/s: 781.500 1613464465.972365
train: epoch 148, iter 2200, loss: 1.759271, top_1: 0.826367, top_k: 0.941641, samples/s: 784.557 1613464498.6021638
train: epoch 148, iter 2300, loss: 1.754932, top_1: 0.825000, top_k: 0.941055, samples/s: 783.192 1613464531.2890036
train: epoch 148, iter 2400, loss: 1.862502, top_1: 0.820391, top_k: 0.941797, samples/s: 781.408 1613464564.0503213
train: epoch 148, iter 2500, loss: 1.701935, top_1: 0.821289, top_k: 0.939688, samples/s: 783.206 1613464596.7364645
train: epoch 148, iter 2600, loss: 1.867854, top_1: 0.820859, top_k: 0.940078, samples/s: 783.162 1613464629.4244862
train: epoch 148, iter 2700, loss: 1.834127, top_1: 0.818438, top_k: 0.938516, samples/s: 781.282 1613464662.1911814
train: epoch 148, iter 2800, loss: 1.816793, top_1: 0.821133, top_k: 0.942656, samples/s: 783.824 1613464694.8515303
train: epoch 148, iter 2900, loss: 1.873271, top_1: 0.817969, top_k: 0.936914, samples/s: 780.395 1613464727.655454
train: epoch 148, iter 3000, loss: 1.693320, top_1: 0.823828, top_k: 0.938711, samples/s: 781.366 1613464760.4185998
train: epoch 148, iter 3100, loss: 1.816926, top_1: 0.821211, top_k: 0.938398, samples/s: 783.426 1613464793.0955417
train: epoch 148, iter 3200, loss: 1.727200, top_1: 0.822891, top_k: 0.938438, samples/s: 781.887 1613464825.8368962
train: epoch 148, iter 3300, loss: 1.670749, top_1: 0.818281, top_k: 0.940195, samples/s: 784.089 1613464858.4862354
train: epoch 148, iter 3400, loss: 1.838112, top_1: 0.819219, top_k: 0.937969, samples/s: 781.100 1613464891.2606118
train: epoch 148, iter 3500, loss: 1.666547, top_1: 0.817617, top_k: 0.937852, samples/s: 783.654 1613464923.9280262
train: epoch 148, iter 3600, loss: 1.898393, top_1: 0.824063, top_k: 0.944453, samples/s: 780.691 1613464956.7194948
train: epoch 148, iter 3700, loss: 1.723707, top_1: 0.826797, top_k: 0.942852, samples/s: 783.707 1613464989.38476
train: epoch 148, iter 3800, loss: 1.889924, top_1: 0.823672, top_k: 0.941367, samples/s: 783.471 1613465022.0597968
train: epoch 148, iter 3900, loss: 1.722576, top_1: 0.820781, top_k: 0.939844, samples/s: 781.124 1613465054.8331053
train: epoch 148, iter 4000, loss: 1.759656, top_1: 0.824063, top_k: 0.943633, samples/s: 783.634 1613465087.5014691
train: epoch 148, iter 4100, loss: 1.844037, top_1: 0.819805, top_k: 0.940039, samples/s: 781.479 1613465120.259979
train: epoch 148, iter 4200, loss: 1.749804, top_1: 0.816211, top_k: 0.938516, samples/s: 782.997 1613465152.9547246
train: epoch 148, iter 4300, loss: 1.708095, top_1: 0.820234, top_k: 0.939063, samples/s: 782.452 1613465185.672343
train: epoch 148, iter 4400, loss: 1.919208, top_1: 0.817969, top_k: 0.938672, samples/s: 781.613 1613465218.425127
train: epoch 148, iter 4500, loss: 1.912682, top_1: 0.820820, top_k: 0.939063, samples/s: 779.681 1613465251.2591321
train: epoch 148, iter 4600, loss: 1.839435, top_1: 0.821523, top_k: 0.941211, samples/s: 784.577 1613465283.8881917
train: epoch 148, iter 4700, loss: 1.802977, top_1: 0.818398, top_k: 0.941719, samples/s: 783.347 1613465316.568512
train: epoch 148, iter 4800, loss: 1.721036, top_1: 0.823203, top_k: 0.938555, samples/s: 779.552 1613465349.4078274
train: epoch 148, iter 4900, loss: 1.600044, top_1: 0.823438, top_k: 0.943047, samples/s: 782.200 1613465382.1360629
train: epoch 148, iter 5000, loss: 1.793230, top_1: 0.822227, top_k: 0.942266, samples/s: 783.149 1613465414.8245745
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_148.
validation: epoch 148, iter 195, top_1: 0.781130, top_k: 0.939724, samples/s: 2356.132 1613465436.9907792
train: epoch 149, iter 100, loss: 1.725972, top_1: 0.824063, top_k: 0.940898, samples/s: 802.775 1613465489.4613693
train: epoch 149, iter 200, loss: 1.838328, top_1: 0.823438, top_k: 0.942773, samples/s: 800.488 1613465521.4419146
train: epoch 149, iter 300, loss: 1.612546, top_1: 0.821211, top_k: 0.940000, samples/s: 784.925 1613465554.0563395
train: epoch 149, iter 400, loss: 1.675857, top_1: 0.821797, top_k: 0.941016, samples/s: 779.193 1613465586.910842
train: epoch 149, iter 500, loss: 1.673645, top_1: 0.821328, top_k: 0.940742, samples/s: 781.065 1613465619.6867268
train: epoch 149, iter 600, loss: 1.780061, top_1: 0.823203, top_k: 0.941797, samples/s: 782.658 1613465652.3956642
train: epoch 149, iter 700, loss: 1.742608, top_1: 0.817695, top_k: 0.938867, samples/s: 782.356 1613465685.1173933
train: epoch 149, iter 800, loss: 1.690649, top_1: 0.820820, top_k: 0.938867, samples/s: 783.458 1613465717.7929442
train: epoch 149, iter 900, loss: 1.791531, top_1: 0.819063, top_k: 0.939609, samples/s: 778.347 1613465750.6833174
train: epoch 149, iter 1000, loss: 1.722340, top_1: 0.823906, top_k: 0.940078, samples/s: 783.008 1613465783.3776238
train: epoch 149, iter 1100, loss: 1.807982, top_1: 0.821172, top_k: 0.939023, samples/s: 782.694 1613465816.0852647
train: epoch 149, iter 1200, loss: 1.819589, top_1: 0.818984, top_k: 0.940898, samples/s: 780.798 1613465848.8720953
train: epoch 149, iter 1300, loss: 1.784689, top_1: 0.822187, top_k: 0.939023, samples/s: 783.127 1613465881.561601
train: epoch 149, iter 1400, loss: 1.792928, top_1: 0.820352, top_k: 0.938359, samples/s: 781.478 1613465914.3200362
train: epoch 149, iter 1500, loss: 1.729904, top_1: 0.825625, top_k: 0.941328, samples/s: 783.254 1613465947.0043147
train: epoch 149, iter 1600, loss: 1.716147, top_1: 0.822656, top_k: 0.942148, samples/s: 784.028 1613465979.6560676
train: epoch 149, iter 1700, loss: 1.815278, top_1: 0.822852, top_k: 0.941055, samples/s: 782.453 1613466012.3737814
train: epoch 149, iter 1800, loss: 1.761433, top_1: 0.823672, top_k: 0.941094, samples/s: 782.633 1613466045.0839033
train: epoch 149, iter 1900, loss: 1.729005, top_1: 0.822617, top_k: 0.940508, samples/s: 782.676 1613466077.792162
train: epoch 149, iter 2000, loss: 1.744648, top_1: 0.822266, top_k: 0.939922, samples/s: 782.787 1613466110.4958107
train: epoch 149, iter 2100, loss: 1.721712, top_1: 0.819375, top_k: 0.937969, samples/s: 783.495 1613466143.1698194
train: epoch 149, iter 2200, loss: 1.735045, top_1: 0.821953, top_k: 0.938828, samples/s: 783.969 1613466175.8242786
train: epoch 149, iter 2300, loss: 1.739609, top_1: 0.826250, top_k: 0.942656, samples/s: 782.963 1613466208.5205762
train: epoch 149, iter 2400, loss: 1.786302, top_1: 0.818906, top_k: 0.941055, samples/s: 784.687 1613466241.1450498
train: epoch 149, iter 2500, loss: 1.766603, top_1: 0.824766, top_k: 0.940742, samples/s: 783.097 1613466273.8357298
train: epoch 149, iter 2600, loss: 1.738251, top_1: 0.823672, top_k: 0.941289, samples/s: 785.070 1613466306.4442542
train: epoch 149, iter 2700, loss: 1.861860, top_1: 0.820391, top_k: 0.940859, samples/s: 781.217 1613466339.2136467
train: epoch 149, iter 2800, loss: 1.711365, top_1: 0.827461, top_k: 0.941250, samples/s: 781.671 1613466371.964251
train: epoch 149, iter 2900, loss: 1.742133, top_1: 0.821836, top_k: 0.939063, samples/s: 785.305 1613466404.562787
train: epoch 149, iter 3000, loss: 1.838543, top_1: 0.823125, top_k: 0.939023, samples/s: 784.247 1613466437.2056122
train: epoch 149, iter 3100, loss: 1.804842, top_1: 0.823047, top_k: 0.940742, samples/s: 782.778 1613466469.9101036
train: epoch 149, iter 3200, loss: 1.774061, top_1: 0.824922, top_k: 0.939961, samples/s: 783.277 1613466502.592786
train: epoch 149, iter 3300, loss: 1.829950, top_1: 0.825859, top_k: 0.940273, samples/s: 783.260 1613466535.2766519
train: epoch 149, iter 3400, loss: 1.602511, top_1: 0.823164, top_k: 0.942891, samples/s: 783.041 1613466567.9697697
train: epoch 149, iter 3500, loss: 1.712713, top_1: 0.820586, top_k: 0.942578, samples/s: 783.441 1613466600.6460867
train: epoch 149, iter 3600, loss: 1.739701, top_1: 0.822148, top_k: 0.941094, samples/s: 782.160 1613466633.375992
train: epoch 149, iter 3700, loss: 1.753766, top_1: 0.822734, top_k: 0.939023, samples/s: 781.664 1613466666.1266434
train: epoch 149, iter 3800, loss: 1.700193, top_1: 0.822852, top_k: 0.941445, samples/s: 784.868 1613466698.743516
train: epoch 149, iter 3900, loss: 1.826372, top_1: 0.824492, top_k: 0.943008, samples/s: 782.860 1613466731.444155
train: epoch 149, iter 4000, loss: 1.845025, top_1: 0.819883, top_k: 0.939688, samples/s: 785.570 1613466764.0320237
train: epoch 149, iter 4100, loss: 1.824477, top_1: 0.823516, top_k: 0.942539, samples/s: 780.178 1613466796.845007
train: epoch 149, iter 4200, loss: 1.735080, top_1: 0.822344, top_k: 0.940156, samples/s: 785.388 1613466829.440387
train: epoch 149, iter 4300, loss: 1.878382, top_1: 0.825352, top_k: 0.943164, samples/s: 782.970 1613466862.136322
train: epoch 149, iter 4400, loss: 1.867229, top_1: 0.825742, top_k: 0.944336, samples/s: 782.948 1613466894.8333125
train: epoch 149, iter 4500, loss: 1.857930, top_1: 0.825703, top_k: 0.941562, samples/s: 781.785 1613466927.5788367
train: epoch 149, iter 4600, loss: 1.820879, top_1: 0.822031, top_k: 0.938320, samples/s: 785.022 1613466960.1893544
train: epoch 149, iter 4700, loss: 1.748617, top_1: 0.822656, top_k: 0.939688, samples/s: 784.230 1613466992.8329465
train: epoch 149, iter 4800, loss: 1.757896, top_1: 0.821836, top_k: 0.941875, samples/s: 783.999 1613467025.485997
train: epoch 149, iter 4900, loss: 1.790020, top_1: 0.823906, top_k: 0.942813, samples/s: 785.210 1613467058.0887077
train: epoch 149, iter 5000, loss: 1.883077, top_1: 0.825625, top_k: 0.942266, samples/s: 783.095 1613467090.7796144
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_149.
validation: epoch 149, iter 195, top_1: 0.779087, top_k: 0.940044, samples/s: 2314.357 1613467113.3169937
train: epoch 150, iter 100, loss: 1.836535, top_1: 0.823594, top_k: 0.939375, samples/s: 804.781 1613467165.9678578
train: epoch 150, iter 200, loss: 1.814763, top_1: 0.823555, top_k: 0.941602, samples/s: 800.171 1613467197.96123
train: epoch 150, iter 300, loss: 1.873434, top_1: 0.822930, top_k: 0.941211, samples/s: 784.435 1613467230.5959868
train: epoch 150, iter 400, loss: 1.761141, top_1: 0.821367, top_k: 0.940156, samples/s: 782.204 1613467263.3242934
train: epoch 150, iter 500, loss: 1.834190, top_1: 0.822305, top_k: 0.940312, samples/s: 778.421 1613467296.2110574
train: epoch 150, iter 600, loss: 1.858047, top_1: 0.817578, top_k: 0.938867, samples/s: 783.582 1613467328.881868
train: epoch 150, iter 700, loss: 1.647105, top_1: 0.820977, top_k: 0.942422, samples/s: 779.072 1613467361.741186
train: epoch 150, iter 800, loss: 1.793992, top_1: 0.822891, top_k: 0.938438, samples/s: 782.023 1613467394.476764
train: epoch 150, iter 900, loss: 1.651347, top_1: 0.823789, top_k: 0.942227, samples/s: 781.625 1613467427.229022
train: epoch 150, iter 1000, loss: 1.676661, top_1: 0.827422, top_k: 0.943008, samples/s: 784.533 1613467459.8599162
train: epoch 150, iter 1100, loss: 1.830242, top_1: 0.821953, top_k: 0.939414, samples/s: 782.609 1613467492.5709887
train: epoch 150, iter 1200, loss: 1.856255, top_1: 0.824961, top_k: 0.941953, samples/s: 782.844 1613467525.2722178
train: epoch 150, iter 1300, loss: 1.787315, top_1: 0.821250, top_k: 0.940156, samples/s: 781.910 1613467558.0125945
train: epoch 150, iter 1400, loss: 1.843235, top_1: 0.821523, top_k: 0.940352, samples/s: 786.166 1613467590.575707
train: epoch 150, iter 1500, loss: 1.678249, top_1: 0.823945, top_k: 0.940469, samples/s: 781.950 1613467623.3143535
train: epoch 150, iter 1600, loss: 1.668751, top_1: 0.822031, top_k: 0.942461, samples/s: 784.774 1613467655.9352016
train: epoch 150, iter 1700, loss: 1.664605, top_1: 0.825508, top_k: 0.943203, samples/s: 778.270 1613467688.8287299
train: epoch 150, iter 1800, loss: 1.619186, top_1: 0.822734, top_k: 0.941094, samples/s: 785.655 1613467721.4129944
train: epoch 150, iter 1900, loss: 1.836661, top_1: 0.820898, top_k: 0.939844, samples/s: 781.324 1613467754.1778464
train: epoch 150, iter 2000, loss: 1.734406, top_1: 0.821445, top_k: 0.938477, samples/s: 784.341 1613467786.8167815
train: epoch 150, iter 2100, loss: 1.843747, top_1: 0.824258, top_k: 0.939844, samples/s: 780.352 1613467819.6224587
train: epoch 150, iter 2200, loss: 1.727961, top_1: 0.824141, top_k: 0.940586, samples/s: 784.589 1613467852.25099
train: epoch 150, iter 2300, loss: 1.820436, top_1: 0.827305, top_k: 0.944375, samples/s: 785.146 1613467884.8563929
train: epoch 150, iter 2400, loss: 1.721623, top_1: 0.820625, top_k: 0.940156, samples/s: 782.717 1613467917.5629187
train: epoch 150, iter 2500, loss: 1.681437, top_1: 0.822227, top_k: 0.940000, samples/s: 784.267 1613467950.204876
train: epoch 150, iter 2600, loss: 1.837600, top_1: 0.825625, top_k: 0.941523, samples/s: 784.251 1613467982.8474767
train: epoch 150, iter 2700, loss: 1.906764, top_1: 0.823242, top_k: 0.941602, samples/s: 781.644 1613468015.598967
train: epoch 150, iter 2800, loss: 1.685108, top_1: 0.824922, top_k: 0.940156, samples/s: 779.372 1613468048.445938
train: epoch 150, iter 2900, loss: 1.819443, top_1: 0.823906, top_k: 0.940508, samples/s: 785.951 1613468081.0178435
train: epoch 150, iter 3000, loss: 1.767509, top_1: 0.823438, top_k: 0.942930, samples/s: 781.687 1613468113.7675455
train: epoch 150, iter 3100, loss: 1.854800, top_1: 0.827187, top_k: 0.941680, samples/s: 785.861 1613468146.3433936
train: epoch 150, iter 3200, loss: 1.796705, top_1: 0.824609, top_k: 0.940273, samples/s: 784.192 1613468178.9883852
train: epoch 150, iter 3300, loss: 1.633905, top_1: 0.826992, top_k: 0.942227, samples/s: 781.514 1613468211.7452943
train: epoch 150, iter 3400, loss: 1.681074, top_1: 0.824023, top_k: 0.940781, samples/s: 785.236 1613468244.3469503
train: epoch 150, iter 3500, loss: 1.657806, top_1: 0.824609, top_k: 0.943359, samples/s: 782.774 1613468277.0511642
train: epoch 150, iter 3600, loss: 1.649162, top_1: 0.819922, top_k: 0.937773, samples/s: 783.566 1613468309.722386
train: epoch 150, iter 3700, loss: 1.806757, top_1: 0.821875, top_k: 0.940781, samples/s: 780.269 1613468342.531522
train: epoch 150, iter 3800, loss: 1.708977, top_1: 0.824492, top_k: 0.939258, samples/s: 783.913 1613468375.1882539
train: epoch 150, iter 3900, loss: 1.912507, top_1: 0.821953, top_k: 0.941523, samples/s: 780.483 1613468407.988409
train: epoch 150, iter 4000, loss: 1.774356, top_1: 0.815352, top_k: 0.939219, samples/s: 786.520 1613468440.5369034
train: epoch 150, iter 4100, loss: 1.741772, top_1: 0.826523, top_k: 0.943672, samples/s: 782.585 1613468473.249015
train: epoch 150, iter 4200, loss: 1.698473, top_1: 0.822539, top_k: 0.942813, samples/s: 782.435 1613468505.9673653
train: epoch 150, iter 4300, loss: 1.728081, top_1: 0.825000, top_k: 0.940156, samples/s: 783.817 1613468538.6280167
train: epoch 150, iter 4400, loss: 1.895069, top_1: 0.823828, top_k: 0.939883, samples/s: 784.350 1613468571.2665014
train: epoch 150, iter 4500, loss: 1.722090, top_1: 0.823477, top_k: 0.937695, samples/s: 782.946 1613468603.9634905
train: epoch 150, iter 4600, loss: 1.714739, top_1: 0.822578, top_k: 0.942070, samples/s: 782.648 1613468636.6730018
train: epoch 150, iter 4700, loss: 1.827528, top_1: 0.826406, top_k: 0.939805, samples/s: 785.667 1613468669.2568204
train: epoch 150, iter 4800, loss: 1.762456, top_1: 0.823086, top_k: 0.940781, samples/s: 783.031 1613468701.9502237
train: epoch 150, iter 4900, loss: 1.726878, top_1: 0.823633, top_k: 0.940078, samples/s: 782.772 1613468734.6545656
train: epoch 150, iter 5000, loss: 1.685096, top_1: 0.826289, top_k: 0.944648, samples/s: 783.618 1613468767.32354
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_150.
validation: epoch 150, iter 195, top_1: 0.781550, top_k: 0.939984, samples/s: 2380.408 1613468789.2364683
train: epoch 151, iter 100, loss: 1.756724, top_1: 0.819258, top_k: 0.940352, samples/s: 804.270 1613468841.4174283
train: epoch 151, iter 200, loss: 1.765483, top_1: 0.827930, top_k: 0.945195, samples/s: 799.254 1613468873.4472122
train: epoch 151, iter 300, loss: 1.825807, top_1: 0.824375, top_k: 0.940625, samples/s: 785.813 1613468906.0248947
train: epoch 151, iter 400, loss: 1.754007, top_1: 0.826680, top_k: 0.939961, samples/s: 780.851 1613468938.80969
train: epoch 151, iter 500, loss: 1.833374, top_1: 0.824336, top_k: 0.941602, samples/s: 779.514 1613468971.650571
train: epoch 151, iter 600, loss: 1.655645, top_1: 0.822539, top_k: 0.940820, samples/s: 782.517 1613469004.3656008
train: epoch 151, iter 700, loss: 1.779986, top_1: 0.823555, top_k: 0.940234, samples/s: 782.940 1613469037.0628004
train: epoch 151, iter 800, loss: 1.713472, top_1: 0.826367, top_k: 0.940586, samples/s: 780.446 1613469069.864626
train: epoch 151, iter 900, loss: 1.714874, top_1: 0.826523, top_k: 0.940586, samples/s: 782.603 1613469102.5759134
train: epoch 151, iter 1000, loss: 1.834872, top_1: 0.826055, top_k: 0.942578, samples/s: 781.810 1613469135.320471
train: epoch 151, iter 1100, loss: 1.819549, top_1: 0.823945, top_k: 0.940508, samples/s: 780.898 1613469168.1032817
train: epoch 151, iter 1200, loss: 1.757697, top_1: 0.827539, top_k: 0.945352, samples/s: 784.269 1613469200.745021
train: epoch 151, iter 1300, loss: 1.872749, top_1: 0.823281, top_k: 0.940352, samples/s: 780.265 1613469233.5544734
train: epoch 151, iter 1400, loss: 1.752865, top_1: 0.823906, top_k: 0.941484, samples/s: 783.063 1613469266.2465868
train: epoch 151, iter 1500, loss: 1.911266, top_1: 0.823477, top_k: 0.941523, samples/s: 784.929 1613469298.8608992
train: epoch 151, iter 1600, loss: 1.814943, top_1: 0.819961, top_k: 0.939531, samples/s: 780.580 1613469331.6570563
train: epoch 151, iter 1700, loss: 1.774849, top_1: 0.821602, top_k: 0.942031, samples/s: 780.358 1613469364.4625463
train: epoch 151, iter 1800, loss: 1.735316, top_1: 0.824883, top_k: 0.941133, samples/s: 782.586 1613469397.174621
train: epoch 151, iter 1900, loss: 1.814197, top_1: 0.826133, top_k: 0.941719, samples/s: 783.375 1613469429.8537178
train: epoch 151, iter 2000, loss: 1.856068, top_1: 0.819766, top_k: 0.940391, samples/s: 783.442 1613469462.5300488
train: epoch 151, iter 2100, loss: 1.837951, top_1: 0.826172, top_k: 0.942344, samples/s: 781.762 1613469495.2765844
train: epoch 151, iter 2200, loss: 1.686646, top_1: 0.821289, top_k: 0.938438, samples/s: 782.136 1613469528.0074623
train: epoch 151, iter 2300, loss: 1.801414, top_1: 0.825508, top_k: 0.943008, samples/s: 780.344 1613469560.8135002
train: epoch 151, iter 2400, loss: 1.674709, top_1: 0.825117, top_k: 0.940547, samples/s: 784.392 1613469593.4501526
train: epoch 151, iter 2500, loss: 1.655721, top_1: 0.826172, top_k: 0.941914, samples/s: 780.801 1613469626.2370532
train: epoch 151, iter 2600, loss: 1.825991, top_1: 0.825664, top_k: 0.939453, samples/s: 784.614 1613469658.8645196
train: epoch 151, iter 2700, loss: 1.765174, top_1: 0.824063, top_k: 0.941562, samples/s: 783.233 1613469691.5495238
train: epoch 151, iter 2800, loss: 1.681077, top_1: 0.820977, top_k: 0.940078, samples/s: 783.747 1613469724.2131982
train: epoch 151, iter 2900, loss: 1.918894, top_1: 0.823242, top_k: 0.939453, samples/s: 784.062 1613469756.8635762
train: epoch 151, iter 3000, loss: 1.811610, top_1: 0.821602, top_k: 0.941992, samples/s: 783.730 1613469789.5279162
train: epoch 151, iter 3100, loss: 1.880021, top_1: 0.827344, top_k: 0.943477, samples/s: 782.210 1613469822.2558143
train: epoch 151, iter 3200, loss: 1.709642, top_1: 0.824141, top_k: 0.943008, samples/s: 783.302 1613469854.937931
train: epoch 151, iter 3300, loss: 1.684655, top_1: 0.826562, top_k: 0.944297, samples/s: 781.661 1613469887.6887143
train: epoch 151, iter 3400, loss: 1.638404, top_1: 0.824688, top_k: 0.940547, samples/s: 783.294 1613469920.3712368
train: epoch 151, iter 3500, loss: 1.723813, top_1: 0.825937, top_k: 0.943125, samples/s: 785.065 1613469952.9798992
train: epoch 151, iter 3600, loss: 1.834529, top_1: 0.823281, top_k: 0.941836, samples/s: 782.170 1613469985.709398
train: epoch 151, iter 3700, loss: 1.764096, top_1: 0.823867, top_k: 0.940547, samples/s: 782.820 1613470018.4116666
train: epoch 151, iter 3800, loss: 1.771279, top_1: 0.821016, top_k: 0.939844, samples/s: 783.862 1613470051.070542
train: epoch 151, iter 3900, loss: 1.807551, top_1: 0.825195, top_k: 0.941641, samples/s: 782.516 1613470083.7854803
train: epoch 151, iter 4000, loss: 1.656052, top_1: 0.824258, top_k: 0.941406, samples/s: 782.338 1613470116.5079424
train: epoch 151, iter 4100, loss: 1.826186, top_1: 0.823555, top_k: 0.942070, samples/s: 784.603 1613470149.135805
train: epoch 151, iter 4200, loss: 1.760023, top_1: 0.823398, top_k: 0.942695, samples/s: 783.945 1613470181.7912228
train: epoch 151, iter 4300, loss: 1.809529, top_1: 0.827070, top_k: 0.941406, samples/s: 781.734 1613470214.5389516
train: epoch 151, iter 4400, loss: 1.628221, top_1: 0.825195, top_k: 0.940391, samples/s: 783.731 1613470247.2032537
train: epoch 151, iter 4500, loss: 1.824785, top_1: 0.826055, top_k: 0.942148, samples/s: 783.444 1613470279.8794932
train: epoch 151, iter 4600, loss: 1.790744, top_1: 0.819570, top_k: 0.942773, samples/s: 781.886 1613470312.6207924
train: epoch 151, iter 4700, loss: 1.815258, top_1: 0.824883, top_k: 0.941953, samples/s: 785.160 1613470345.2256124
train: epoch 151, iter 4800, loss: 1.711393, top_1: 0.822930, top_k: 0.939648, samples/s: 781.239 1613470377.994133
train: epoch 151, iter 4900, loss: 1.817852, top_1: 0.825078, top_k: 0.940039, samples/s: 783.833 1613470410.654211
train: epoch 151, iter 5000, loss: 1.830565, top_1: 0.825781, top_k: 0.942539, samples/s: 784.130 1613470443.3017848
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_151.
validation: epoch 151, iter 195, top_1: 0.781090, top_k: 0.940665, samples/s: 2364.558 1613470465.3847263
train: epoch 152, iter 100, loss: 1.694954, top_1: 0.823516, top_k: 0.941523, samples/s: 805.536 1613470517.4840822
train: epoch 152, iter 200, loss: 1.625119, top_1: 0.827930, top_k: 0.941836, samples/s: 800.229 1613470549.474818
train: epoch 152, iter 300, loss: 1.787053, top_1: 0.821016, top_k: 0.940508, samples/s: 779.997 1613470582.295578
train: epoch 152, iter 400, loss: 1.684086, top_1: 0.822187, top_k: 0.941016, samples/s: 782.980 1613470614.9910386
train: epoch 152, iter 500, loss: 1.880302, top_1: 0.824023, top_k: 0.942109, samples/s: 778.246 1613470647.8855183
train: epoch 152, iter 600, loss: 1.746223, top_1: 0.824609, top_k: 0.942266, samples/s: 781.350 1613470680.649315
train: epoch 152, iter 700, loss: 1.716054, top_1: 0.821055, top_k: 0.943633, samples/s: 784.679 1613470713.274136
train: epoch 152, iter 800, loss: 1.862958, top_1: 0.823125, top_k: 0.938398, samples/s: 778.586 1613470746.154284
train: epoch 152, iter 900, loss: 1.776013, top_1: 0.826680, top_k: 0.942891, samples/s: 781.504 1613470778.9117374
train: epoch 152, iter 1000, loss: 1.660186, top_1: 0.826641, top_k: 0.943242, samples/s: 782.111 1613470811.643648
train: epoch 152, iter 1100, loss: 1.688747, top_1: 0.832344, top_k: 0.943633, samples/s: 784.276 1613470844.2851386
train: epoch 152, iter 1200, loss: 1.707495, top_1: 0.824766, top_k: 0.942070, samples/s: 779.630 1613470877.1212294
train: epoch 152, iter 1300, loss: 1.827923, top_1: 0.824023, top_k: 0.943086, samples/s: 781.888 1613470909.8625193
train: epoch 152, iter 1400, loss: 1.728224, top_1: 0.827500, top_k: 0.943750, samples/s: 782.812 1613470942.5651605
train: epoch 152, iter 1500, loss: 1.730077, top_1: 0.829492, top_k: 0.943789, samples/s: 782.628 1613470975.2754574
train: epoch 152, iter 1600, loss: 1.845080, top_1: 0.826055, top_k: 0.942305, samples/s: 781.101 1613471008.0496578
train: epoch 152, iter 1700, loss: 1.741140, top_1: 0.826602, top_k: 0.940781, samples/s: 779.745 1613471040.8808694
train: epoch 152, iter 1800, loss: 1.759224, top_1: 0.822539, top_k: 0.941172, samples/s: 783.240 1613471073.5657172
train: epoch 152, iter 1900, loss: 1.860968, top_1: 0.825078, top_k: 0.941719, samples/s: 779.438 1613471106.4098196
train: epoch 152, iter 2000, loss: 1.793855, top_1: 0.825937, top_k: 0.942539, samples/s: 781.242 1613471139.1782355
train: epoch 152, iter 2100, loss: 1.704243, top_1: 0.826211, top_k: 0.940898, samples/s: 781.778 1613471171.924038
train: epoch 152, iter 2200, loss: 1.653360, top_1: 0.825820, top_k: 0.943008, samples/s: 783.817 1613471204.584773
train: epoch 152, iter 2300, loss: 1.818740, top_1: 0.824766, top_k: 0.943203, samples/s: 782.793 1613471237.2881095
train: epoch 152, iter 2400, loss: 1.675643, top_1: 0.825156, top_k: 0.940508, samples/s: 782.781 1613471269.992074
train: epoch 152, iter 2500, loss: 1.694599, top_1: 0.823164, top_k: 0.941523, samples/s: 780.861 1613471302.7763891
train: epoch 152, iter 2600, loss: 1.825580, top_1: 0.823086, top_k: 0.941602, samples/s: 782.035 1613471335.511506
train: epoch 152, iter 2700, loss: 1.668544, top_1: 0.821680, top_k: 0.941211, samples/s: 782.491 1613471368.2275622
train: epoch 152, iter 2800, loss: 1.782444, top_1: 0.827266, top_k: 0.943008, samples/s: 780.695 1613471401.018852
train: epoch 152, iter 2900, loss: 1.777333, top_1: 0.827227, top_k: 0.939570, samples/s: 781.682 1613471433.7687724
train: epoch 152, iter 3000, loss: 1.874439, top_1: 0.822695, top_k: 0.940664, samples/s: 779.318 1613471466.6179008
train: epoch 152, iter 3100, loss: 1.793053, top_1: 0.830273, top_k: 0.942461, samples/s: 782.107 1613471499.350081
train: epoch 152, iter 3200, loss: 1.848072, top_1: 0.822695, top_k: 0.941211, samples/s: 779.986 1613471532.1710927
train: epoch 152, iter 3300, loss: 1.720713, top_1: 0.824336, top_k: 0.941328, samples/s: 784.704 1613471564.7949853
train: epoch 152, iter 3400, loss: 1.699096, top_1: 0.826094, top_k: 0.941562, samples/s: 782.206 1613471597.5229275
train: epoch 152, iter 3500, loss: 1.721233, top_1: 0.828086, top_k: 0.942969, samples/s: 783.201 1613471630.2092602
train: epoch 152, iter 3600, loss: 1.774957, top_1: 0.824492, top_k: 0.943281, samples/s: 782.577 1613471662.9216902
train: epoch 152, iter 3700, loss: 1.729723, top_1: 0.822656, top_k: 0.938008, samples/s: 779.874 1613471695.7475069
train: epoch 152, iter 3800, loss: 1.649533, top_1: 0.826875, top_k: 0.942734, samples/s: 782.199 1613471728.4757173
train: epoch 152, iter 3900, loss: 1.734963, top_1: 0.822891, top_k: 0.940039, samples/s: 779.891 1613471761.3008301
train: epoch 152, iter 4000, loss: 1.804461, top_1: 0.824922, top_k: 0.942148, samples/s: 782.856 1613471794.001636
train: epoch 152, iter 4100, loss: 1.758235, top_1: 0.830625, top_k: 0.942578, samples/s: 783.045 1613471826.6945708
train: epoch 152, iter 4200, loss: 1.891284, top_1: 0.826445, top_k: 0.941797, samples/s: 780.774 1613471859.4824367
train: epoch 152, iter 4300, loss: 1.814178, top_1: 0.824766, top_k: 0.942070, samples/s: 784.029 1613471892.13432
train: epoch 152, iter 4400, loss: 1.636473, top_1: 0.825273, top_k: 0.941641, samples/s: 779.692 1613471924.9678354
train: epoch 152, iter 4500, loss: 1.640111, top_1: 0.824727, top_k: 0.941914, samples/s: 783.009 1613471957.6622145
train: epoch 152, iter 4600, loss: 1.723776, top_1: 0.822930, top_k: 0.941562, samples/s: 782.173 1613471990.3915591
train: epoch 152, iter 4700, loss: 1.662780, top_1: 0.826367, top_k: 0.941719, samples/s: 781.413 1613472023.1526637
train: epoch 152, iter 4800, loss: 1.821570, top_1: 0.825352, top_k: 0.942383, samples/s: 783.221 1613472055.8382847
train: epoch 152, iter 4900, loss: 1.569070, top_1: 0.827461, top_k: 0.944102, samples/s: 782.620 1613472088.5489244
train: epoch 152, iter 5000, loss: 1.787455, top_1: 0.825859, top_k: 0.940117, samples/s: 783.038 1613472121.2420738
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_152.
validation: epoch 152, iter 195, top_1: 0.776402, top_k: 0.938041, samples/s: 2351.913 1613472143.4449866
train: epoch 153, iter 100, loss: 1.702958, top_1: 0.825391, top_k: 0.942187, samples/s: 803.892 1613472195.8169134
train: epoch 153, iter 200, loss: 1.799326, top_1: 0.825117, top_k: 0.940898, samples/s: 801.005 1613472227.7767155
train: epoch 153, iter 300, loss: 1.679951, top_1: 0.824570, top_k: 0.940430, samples/s: 782.233 1613472260.503548
train: epoch 153, iter 400, loss: 1.685928, top_1: 0.827852, top_k: 0.945117, samples/s: 782.759 1613472293.2086122
train: epoch 153, iter 500, loss: 1.649855, top_1: 0.824258, top_k: 0.943242, samples/s: 778.461 1613472326.0937963
train: epoch 153, iter 600, loss: 1.791358, top_1: 0.828086, top_k: 0.941992, samples/s: 782.733 1613472358.7996292
train: epoch 153, iter 700, loss: 1.693067, top_1: 0.826680, top_k: 0.940977, samples/s: 781.916 1613472391.5397332
train: epoch 153, iter 800, loss: 1.791226, top_1: 0.824805, top_k: 0.939766, samples/s: 781.650 1613472424.2909718
train: epoch 153, iter 900, loss: 1.794088, top_1: 0.824336, top_k: 0.940781, samples/s: 781.960 1613472457.0293086
train: epoch 153, iter 1000, loss: 1.722724, top_1: 0.825352, top_k: 0.942617, samples/s: 782.118 1613472489.7608414
train: epoch 153, iter 1100, loss: 1.708403, top_1: 0.830781, top_k: 0.942031, samples/s: 781.919 1613472522.500826
train: epoch 153, iter 1200, loss: 1.700686, top_1: 0.825430, top_k: 0.941680, samples/s: 782.585 1613472555.2128956
train: epoch 153, iter 1300, loss: 1.811261, top_1: 0.826484, top_k: 0.943438, samples/s: 783.033 1613472587.9063919
train: epoch 153, iter 1400, loss: 1.795274, top_1: 0.827031, top_k: 0.940547, samples/s: 783.477 1613472620.5812447
train: epoch 153, iter 1500, loss: 1.937044, top_1: 0.825352, top_k: 0.942383, samples/s: 779.861 1613472653.407577
train: epoch 153, iter 1600, loss: 1.794869, top_1: 0.821797, top_k: 0.937813, samples/s: 784.093 1613472686.0566728
train: epoch 153, iter 1700, loss: 1.668204, top_1: 0.826953, top_k: 0.942852, samples/s: 782.279 1613472718.7817006
train: epoch 153, iter 1800, loss: 1.861585, top_1: 0.823359, top_k: 0.942813, samples/s: 782.473 1613472751.4985342
train: epoch 153, iter 1900, loss: 1.766432, top_1: 0.826172, top_k: 0.943086, samples/s: 780.829 1613472784.2840545
train: epoch 153, iter 2000, loss: 1.752933, top_1: 0.825547, top_k: 0.941289, samples/s: 781.559 1613472817.0391836
train: epoch 153, iter 2100, loss: 1.754012, top_1: 0.825898, top_k: 0.940625, samples/s: 780.268 1613472849.8483677
train: epoch 153, iter 2200, loss: 1.671708, top_1: 0.825430, top_k: 0.942734, samples/s: 785.283 1613472882.4481459
train: epoch 153, iter 2300, loss: 1.787570, top_1: 0.825430, top_k: 0.941328, samples/s: 782.009 1613472915.184287
train: epoch 153, iter 2400, loss: 1.899797, top_1: 0.821602, top_k: 0.940156, samples/s: 780.727 1613472947.9743013
train: epoch 153, iter 2500, loss: 1.805933, top_1: 0.825703, top_k: 0.942109, samples/s: 783.563 1613472980.645527
train: epoch 153, iter 2600, loss: 1.617872, top_1: 0.828125, top_k: 0.943320, samples/s: 780.432 1613473013.4478629
train: epoch 153, iter 2700, loss: 1.681026, top_1: 0.820234, top_k: 0.938750, samples/s: 783.334 1613473046.128675
train: epoch 153, iter 2800, loss: 1.643095, top_1: 0.824336, top_k: 0.942461, samples/s: 782.257 1613473078.8545034
train: epoch 153, iter 2900, loss: 1.827517, top_1: 0.824609, top_k: 0.941836, samples/s: 783.348 1613473111.534788
train: epoch 153, iter 3000, loss: 1.766975, top_1: 0.823867, top_k: 0.937734, samples/s: 782.550 1613473144.2484288
train: epoch 153, iter 3100, loss: 1.785942, top_1: 0.829688, top_k: 0.943672, samples/s: 782.799 1613473176.9515042
train: epoch 153, iter 3200, loss: 1.680375, top_1: 0.830195, top_k: 0.943594, samples/s: 783.637 1613473209.6196718
train: epoch 153, iter 3300, loss: 1.931332, top_1: 0.828789, top_k: 0.942734, samples/s: 782.994 1613473242.3148215
train: epoch 153, iter 3400, loss: 1.695152, top_1: 0.828125, top_k: 0.941992, samples/s: 783.932 1613473274.9705794
train: epoch 153, iter 3500, loss: 1.742452, top_1: 0.825313, top_k: 0.941719, samples/s: 783.501 1613473307.644555
train: epoch 153, iter 3600, loss: 1.701077, top_1: 0.828203, top_k: 0.943320, samples/s: 782.295 1613473340.36875
train: epoch 153, iter 3700, loss: 1.792836, top_1: 0.823047, top_k: 0.941406, samples/s: 783.043 1613473373.0616767
train: epoch 153, iter 3800, loss: 1.753565, top_1: 0.827891, top_k: 0.941484, samples/s: 784.054 1613473405.7124686
train: epoch 153, iter 3900, loss: 1.831531, top_1: 0.821875, top_k: 0.940156, samples/s: 783.359 1613473438.3923438
train: epoch 153, iter 4000, loss: 1.741822, top_1: 0.821914, top_k: 0.938750, samples/s: 782.945 1613473471.0893488
train: epoch 153, iter 4100, loss: 1.733185, top_1: 0.820703, top_k: 0.940078, samples/s: 783.914 1613473503.7459059
train: epoch 153, iter 4200, loss: 1.808257, top_1: 0.826133, top_k: 0.942969, samples/s: 783.233 1613473536.430918
train: epoch 153, iter 4300, loss: 1.678449, top_1: 0.830508, top_k: 0.940977, samples/s: 783.018 1613473569.124969
train: epoch 153, iter 4400, loss: 1.792563, top_1: 0.825352, top_k: 0.940273, samples/s: 784.753 1613473601.7466817
train: epoch 153, iter 4500, loss: 1.862055, top_1: 0.826406, top_k: 0.941875, samples/s: 783.556 1613473634.4183583
train: epoch 153, iter 4600, loss: 1.645965, top_1: 0.825000, top_k: 0.943398, samples/s: 782.749 1613473667.1235905
train: epoch 153, iter 4700, loss: 1.797268, top_1: 0.827109, top_k: 0.943164, samples/s: 785.552 1613473699.7120755
train: epoch 153, iter 4800, loss: 1.776556, top_1: 0.826016, top_k: 0.943203, samples/s: 781.753 1613473732.4589734
train: epoch 153, iter 4900, loss: 1.726119, top_1: 0.824414, top_k: 0.941719, samples/s: 784.262 1613473765.1011512
train: epoch 153, iter 5000, loss: 1.784807, top_1: 0.827344, top_k: 0.941680, samples/s: 781.391 1613473797.8633142
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_153.
validation: epoch 153, iter 195, top_1: 0.779067, top_k: 0.939744, samples/s: 2367.337 1613473819.9281116
train: epoch 154, iter 100, loss: 1.821650, top_1: 0.826367, top_k: 0.942031, samples/s: 805.952 1613473872.4888868
train: epoch 154, iter 200, loss: 1.689498, top_1: 0.828594, top_k: 0.943984, samples/s: 799.963 1613473904.490376
train: epoch 154, iter 300, loss: 1.785195, top_1: 0.826523, top_k: 0.943008, samples/s: 783.160 1613473937.1784558
train: epoch 154, iter 400, loss: 1.821651, top_1: 0.827656, top_k: 0.943789, samples/s: 779.302 1613473970.0283456
train: epoch 154, iter 500, loss: 1.793201, top_1: 0.823984, top_k: 0.943242, samples/s: 779.274 1613474002.8793232
train: epoch 154, iter 600, loss: 1.746583, top_1: 0.827578, top_k: 0.942266, samples/s: 782.505 1613474035.5948422
train: epoch 154, iter 700, loss: 1.699401, top_1: 0.827578, top_k: 0.944258, samples/s: 783.876 1613474068.2530763
train: epoch 154, iter 800, loss: 1.891470, top_1: 0.827148, top_k: 0.944023, samples/s: 779.245 1613474101.1053019
train: epoch 154, iter 900, loss: 1.791926, top_1: 0.826211, top_k: 0.943672, samples/s: 778.780 1613474133.9772327
train: epoch 154, iter 1000, loss: 1.814152, top_1: 0.826484, top_k: 0.941719, samples/s: 781.070 1613474166.7532003
train: epoch 154, iter 1100, loss: 1.731446, top_1: 0.825391, top_k: 0.943242, samples/s: 782.220 1613474199.4801884
train: epoch 154, iter 1200, loss: 1.709170, top_1: 0.827266, top_k: 0.941953, samples/s: 778.969 1613474232.3445365
train: epoch 154, iter 1300, loss: 1.826880, top_1: 0.829102, top_k: 0.942383, samples/s: 783.016 1613474265.0383048
train: epoch 154, iter 1400, loss: 1.769175, top_1: 0.827148, top_k: 0.941992, samples/s: 783.596 1613474297.7081833
train: epoch 154, iter 1500, loss: 1.742992, top_1: 0.822812, top_k: 0.940625, samples/s: 780.059 1613474330.5261643
train: epoch 154, iter 1600, loss: 1.805880, top_1: 0.825508, top_k: 0.942930, samples/s: 782.620 1613474363.236791
train: epoch 154, iter 1700, loss: 1.700717, top_1: 0.830977, top_k: 0.942813, samples/s: 780.611 1613474396.031617
train: epoch 154, iter 1800, loss: 1.673996, top_1: 0.828633, top_k: 0.942227, samples/s: 785.517 1613474428.6215787
train: epoch 154, iter 1900, loss: 1.815528, top_1: 0.828242, top_k: 0.941758, samples/s: 779.894 1613474461.4466455
train: epoch 154, iter 2000, loss: 1.647141, top_1: 0.824805, top_k: 0.939961, samples/s: 780.898 1613474494.2293932
train: epoch 154, iter 2100, loss: 1.632838, top_1: 0.830977, top_k: 0.943281, samples/s: 782.807 1613474526.9321923
train: epoch 154, iter 2200, loss: 1.887770, top_1: 0.826836, top_k: 0.943750, samples/s: 781.189 1613474559.7027338
train: epoch 154, iter 2300, loss: 1.778203, top_1: 0.825234, top_k: 0.943047, samples/s: 783.870 1613474592.3612974
train: epoch 154, iter 2400, loss: 1.729998, top_1: 0.829023, top_k: 0.940547, samples/s: 779.192 1613474625.215772
train: epoch 154, iter 2500, loss: 1.734741, top_1: 0.824141, top_k: 0.942031, samples/s: 781.736 1613474657.9634576
train: epoch 154, iter 2600, loss: 1.710288, top_1: 0.828203, top_k: 0.941641, samples/s: 780.627 1613474690.7575972
train: epoch 154, iter 2700, loss: 1.684870, top_1: 0.832070, top_k: 0.943281, samples/s: 783.428 1613474723.4343958
train: epoch 154, iter 2800, loss: 1.782217, top_1: 0.824883, top_k: 0.941328, samples/s: 780.306 1613474756.2420313
train: epoch 154, iter 2900, loss: 1.743988, top_1: 0.832656, top_k: 0.941367, samples/s: 780.937 1613474789.023268
train: epoch 154, iter 3000, loss: 1.766692, top_1: 0.826367, top_k: 0.943789, samples/s: 783.788 1613474821.6851745
train: epoch 154, iter 3100, loss: 1.765255, top_1: 0.828711, top_k: 0.941836, samples/s: 783.021 1613474854.3790598
train: epoch 154, iter 3200, loss: 1.859595, top_1: 0.826367, top_k: 0.943477, samples/s: 784.468 1613474887.0125535
train: epoch 154, iter 3300, loss: 1.648063, top_1: 0.827031, top_k: 0.943047, samples/s: 781.996 1613474919.7492855
train: epoch 154, iter 3400, loss: 1.707562, top_1: 0.828672, top_k: 0.942617, samples/s: 782.618 1613474952.4600568
train: epoch 154, iter 3500, loss: 1.647692, top_1: 0.825742, top_k: 0.942773, samples/s: 784.225 1613474985.10378
train: epoch 154, iter 3600, loss: 1.610824, top_1: 0.821484, top_k: 0.941680, samples/s: 783.852 1613475017.762959
train: epoch 154, iter 3700, loss: 1.701606, top_1: 0.824023, top_k: 0.942500, samples/s: 779.939 1613475050.586018
train: epoch 154, iter 3800, loss: 1.852894, top_1: 0.826211, top_k: 0.943516, samples/s: 781.252 1613475083.3540447
train: epoch 154, iter 3900, loss: 1.905765, top_1: 0.824844, top_k: 0.941562, samples/s: 784.223 1613475115.9978015
train: epoch 154, iter 4000, loss: 1.836382, top_1: 0.828125, top_k: 0.942383, samples/s: 781.626 1613475148.7499886
train: epoch 154, iter 4100, loss: 1.747955, top_1: 0.830664, top_k: 0.941562, samples/s: 780.546 1613475181.547565
train: epoch 154, iter 4200, loss: 1.792953, top_1: 0.825391, top_k: 0.941602, samples/s: 785.155 1613475214.1525226
train: epoch 154, iter 4300, loss: 1.643484, top_1: 0.826367, top_k: 0.943750, samples/s: 779.897 1613475246.9774542
train: epoch 154, iter 4400, loss: 1.695447, top_1: 0.830586, top_k: 0.944531, samples/s: 781.702 1613475279.7264862
train: epoch 154, iter 4500, loss: 1.810411, top_1: 0.828086, top_k: 0.942656, samples/s: 783.561 1613475312.3978152
train: epoch 154, iter 4600, loss: 1.929299, top_1: 0.826758, top_k: 0.942187, samples/s: 782.945 1613475345.0949142
train: epoch 154, iter 4700, loss: 1.681468, top_1: 0.828086, top_k: 0.943828, samples/s: 780.008 1613475377.9150484
train: epoch 154, iter 4800, loss: 1.688019, top_1: 0.826953, top_k: 0.943438, samples/s: 783.789 1613475410.5769365
train: epoch 154, iter 4900, loss: 1.758560, top_1: 0.824414, top_k: 0.941836, samples/s: 783.220 1613475443.2625241
train: epoch 154, iter 5000, loss: 1.585213, top_1: 0.824063, top_k: 0.940859, samples/s: 782.405 1613475475.9821262
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_154.
validation: epoch 154, iter 195, top_1: 0.782512, top_k: 0.940725, samples/s: 2376.555 1613475497.9930987
train: epoch 155, iter 100, loss: 1.729641, top_1: 0.826797, top_k: 0.941484, samples/s: 806.018 1613475550.7613702
train: epoch 155, iter 200, loss: 1.805675, top_1: 0.828750, top_k: 0.941289, samples/s: 800.823 1613475582.7284093
train: epoch 155, iter 300, loss: 1.882291, top_1: 0.825195, top_k: 0.941914, samples/s: 784.590 1613475615.35696
train: epoch 155, iter 400, loss: 1.704178, top_1: 0.826016, top_k: 0.941484, samples/s: 783.107 1613475648.0472872
train: epoch 155, iter 500, loss: 1.635210, top_1: 0.822422, top_k: 0.940742, samples/s: 780.028 1613475680.8666174
train: epoch 155, iter 600, loss: 1.752297, top_1: 0.827812, top_k: 0.943320, samples/s: 783.406 1613475713.5443325
train: epoch 155, iter 700, loss: 1.598162, top_1: 0.832461, top_k: 0.944336, samples/s: 780.345 1613475746.3504276
train: epoch 155, iter 800, loss: 1.742963, top_1: 0.827070, top_k: 0.940820, samples/s: 784.180 1613475778.995931
train: epoch 155, iter 900, loss: 1.687338, top_1: 0.823203, top_k: 0.941680, samples/s: 783.234 1613475811.6809838
train: epoch 155, iter 1000, loss: 1.831300, top_1: 0.825156, top_k: 0.941445, samples/s: 782.735 1613475844.3867307
train: epoch 155, iter 1100, loss: 1.844117, top_1: 0.825898, top_k: 0.943750, samples/s: 783.896 1613475877.0441794
train: epoch 155, iter 1200, loss: 1.774893, top_1: 0.828320, top_k: 0.943438, samples/s: 783.086 1613475909.735326
train: epoch 155, iter 1300, loss: 1.665716, top_1: 0.826406, top_k: 0.941992, samples/s: 783.069 1613475942.427338
train: epoch 155, iter 1400, loss: 1.772414, top_1: 0.831289, top_k: 0.943945, samples/s: 783.199 1613475975.113718
train: epoch 155, iter 1500, loss: 1.809239, top_1: 0.821406, top_k: 0.940742, samples/s: 782.497 1613476007.8294249
train: epoch 155, iter 1600, loss: 1.659041, top_1: 0.826680, top_k: 0.941367, samples/s: 784.096 1613476040.4785514
train: epoch 155, iter 1700, loss: 1.690896, top_1: 0.827930, top_k: 0.944258, samples/s: 785.201 1613476073.081633
train: epoch 155, iter 1800, loss: 1.851010, top_1: 0.828750, top_k: 0.941797, samples/s: 781.554 1613476105.836918
train: epoch 155, iter 1900, loss: 1.647594, top_1: 0.823359, top_k: 0.939375, samples/s: 783.852 1613476138.4962087
train: epoch 155, iter 2000, loss: 1.759241, top_1: 0.829102, top_k: 0.943867, samples/s: 781.747 1613476171.2433143
train: epoch 155, iter 2100, loss: 1.810829, top_1: 0.825391, top_k: 0.940508, samples/s: 784.554 1613476203.8732674
train: epoch 155, iter 2200, loss: 1.816936, top_1: 0.828750, top_k: 0.944102, samples/s: 781.108 1613476236.647241
train: epoch 155, iter 2300, loss: 1.768977, top_1: 0.825000, top_k: 0.942617, samples/s: 783.667 1613476269.314265
train: epoch 155, iter 2400, loss: 1.715320, top_1: 0.825469, top_k: 0.942539, samples/s: 780.499 1613476302.1137567
train: epoch 155, iter 2500, loss: 1.763979, top_1: 0.832031, top_k: 0.942930, samples/s: 784.279 1613476334.7551847
train: epoch 155, iter 2600, loss: 1.742908, top_1: 0.826914, top_k: 0.943320, samples/s: 783.315 1613476367.4367888
train: epoch 155, iter 2700, loss: 1.707052, top_1: 0.824414, top_k: 0.941758, samples/s: 783.877 1613476400.0950685
train: epoch 155, iter 2800, loss: 1.716397, top_1: 0.821562, top_k: 0.938945, samples/s: 781.478 1613476432.8534513
train: epoch 155, iter 2900, loss: 1.892011, top_1: 0.825273, top_k: 0.942734, samples/s: 783.718 1613476465.518262
train: epoch 155, iter 3000, loss: 1.592217, top_1: 0.825977, top_k: 0.941641, samples/s: 780.878 1613476498.3018782
train: epoch 155, iter 3100, loss: 1.732286, top_1: 0.822656, top_k: 0.942070, samples/s: 784.032 1613476530.9535697
train: epoch 155, iter 3200, loss: 1.750182, top_1: 0.828672, top_k: 0.943086, samples/s: 783.702 1613476563.6190379
train: epoch 155, iter 3300, loss: 1.752372, top_1: 0.831484, top_k: 0.944258, samples/s: 784.871 1613476596.235956
train: epoch 155, iter 3400, loss: 1.697922, top_1: 0.825703, top_k: 0.941758, samples/s: 782.166 1613476628.965614
train: epoch 155, iter 3500, loss: 1.759051, top_1: 0.828828, top_k: 0.943125, samples/s: 782.281 1613476661.6903052
train: epoch 155, iter 3600, loss: 1.842770, top_1: 0.822422, top_k: 0.939805, samples/s: 782.430 1613476694.4088998
train: epoch 155, iter 3700, loss: 1.775599, top_1: 0.827422, top_k: 0.943164, samples/s: 781.864 1613476727.1512377
train: epoch 155, iter 3800, loss: 1.722656, top_1: 0.828125, top_k: 0.943867, samples/s: 786.075 1613476759.7181323
train: epoch 155, iter 3900, loss: 1.850672, top_1: 0.825273, top_k: 0.940430, samples/s: 781.794 1613476792.463275
train: epoch 155, iter 4000, loss: 1.699671, top_1: 0.822031, top_k: 0.940352, samples/s: 784.131 1613476825.110893
train: epoch 155, iter 4100, loss: 1.688385, top_1: 0.828086, top_k: 0.943477, samples/s: 783.254 1613476857.7950718
train: epoch 155, iter 4200, loss: 1.691965, top_1: 0.826875, top_k: 0.942578, samples/s: 784.115 1613476890.4432821
train: epoch 155, iter 4300, loss: 1.787607, top_1: 0.824180, top_k: 0.941484, samples/s: 783.041 1613476923.136363
train: epoch 155, iter 4400, loss: 1.630134, top_1: 0.825039, top_k: 0.940039, samples/s: 781.655 1613476955.8873794
train: epoch 155, iter 4500, loss: 1.741974, top_1: 0.828008, top_k: 0.943203, samples/s: 785.486 1613476988.4787548
train: epoch 155, iter 4600, loss: 1.793439, top_1: 0.826992, top_k: 0.941523, samples/s: 782.292 1613477021.203014
train: epoch 155, iter 4700, loss: 1.802580, top_1: 0.826289, top_k: 0.943164, samples/s: 783.154 1613477053.8914022
train: epoch 155, iter 4800, loss: 1.863161, top_1: 0.824414, top_k: 0.939883, samples/s: 784.702 1613477086.5152788
train: epoch 155, iter 4900, loss: 1.762196, top_1: 0.827969, top_k: 0.942461, samples/s: 785.052 1613477119.1244712
train: epoch 155, iter 5000, loss: 1.807302, top_1: 0.824180, top_k: 0.940078, samples/s: 784.119 1613477151.7726445
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_155.
validation: epoch 155, iter 195, top_1: 0.782672, top_k: 0.941546, samples/s: 2360.495 1613477173.858194
train: epoch 156, iter 100, loss: 1.713939, top_1: 0.827109, top_k: 0.943477, samples/s: 804.709 1613477226.876044
train: epoch 156, iter 200, loss: 1.831028, top_1: 0.829805, top_k: 0.941172, samples/s: 801.141 1613477258.830359
train: epoch 156, iter 300, loss: 1.753435, top_1: 0.826641, top_k: 0.942227, samples/s: 786.523 1613477291.3790276
train: epoch 156, iter 400, loss: 1.690710, top_1: 0.823047, top_k: 0.942031, samples/s: 782.001 1613477324.1152399
train: epoch 156, iter 500, loss: 1.708451, top_1: 0.831562, top_k: 0.944531, samples/s: 781.289 1613477356.8820407
train: epoch 156, iter 600, loss: 1.844534, top_1: 0.827383, top_k: 0.941172, samples/s: 782.950 1613477389.5784261
train: epoch 156, iter 700, loss: 1.725109, top_1: 0.825898, top_k: 0.942695, samples/s: 781.469 1613477422.337293
train: epoch 156, iter 800, loss: 1.731840, top_1: 0.827773, top_k: 0.944258, samples/s: 782.763 1613477455.0420003
train: epoch 156, iter 900, loss: 1.804400, top_1: 0.828477, top_k: 0.942461, samples/s: 783.696 1613477487.7077553
train: epoch 156, iter 1000, loss: 1.671928, top_1: 0.822617, top_k: 0.941133, samples/s: 783.748 1613477520.3713548
train: epoch 156, iter 1100, loss: 1.836947, top_1: 0.826445, top_k: 0.942813, samples/s: 782.977 1613477553.067
train: epoch 156, iter 1200, loss: 1.606827, top_1: 0.824766, top_k: 0.943320, samples/s: 783.084 1613477585.758288
train: epoch 156, iter 1300, loss: 1.794463, top_1: 0.828320, top_k: 0.941641, samples/s: 783.989 1613477618.4121308
train: epoch 156, iter 1400, loss: 1.727446, top_1: 0.831484, top_k: 0.946211, samples/s: 786.288 1613477650.9698956
train: epoch 156, iter 1500, loss: 1.810194, top_1: 0.824609, top_k: 0.944023, samples/s: 781.960 1613477683.7080812
train: epoch 156, iter 1600, loss: 1.696927, top_1: 0.828047, top_k: 0.945742, samples/s: 785.086 1613477716.3159604
train: epoch 156, iter 1700, loss: 1.755961, top_1: 0.828086, top_k: 0.943047, samples/s: 781.654 1613477749.0671186
train: epoch 156, iter 1800, loss: 1.759310, top_1: 0.827500, top_k: 0.944258, samples/s: 784.309 1613477781.707347
train: epoch 156, iter 1900, loss: 1.850069, top_1: 0.828555, top_k: 0.942813, samples/s: 784.310 1613477814.3478935
train: epoch 156, iter 2000, loss: 1.591607, top_1: 0.826523, top_k: 0.942227, samples/s: 783.981 1613477847.0013726
train: epoch 156, iter 2100, loss: 1.759467, top_1: 0.824531, top_k: 0.940508, samples/s: 783.566 1613477879.6724224
train: epoch 156, iter 2200, loss: 1.778756, top_1: 0.824648, top_k: 0.940391, samples/s: 783.607 1613477912.3418424
train: epoch 156, iter 2300, loss: 1.850486, top_1: 0.825703, top_k: 0.942930, samples/s: 781.926 1613477945.081545
train: epoch 156, iter 2400, loss: 1.748528, top_1: 0.824922, top_k: 0.940391, samples/s: 784.117 1613477977.7297928
train: epoch 156, iter 2500, loss: 1.818533, top_1: 0.824414, top_k: 0.942656, samples/s: 783.879 1613478010.3878078
train: epoch 156, iter 2600, loss: 1.774056, top_1: 0.823867, top_k: 0.941016, samples/s: 783.356 1613478043.0677288
train: epoch 156, iter 2700, loss: 1.832738, top_1: 0.825156, top_k: 0.941133, samples/s: 782.823 1613478075.7698658
train: epoch 156, iter 2800, loss: 1.828507, top_1: 0.828594, top_k: 0.941680, samples/s: 785.211 1613478108.3726206
train: epoch 156, iter 2900, loss: 1.685996, top_1: 0.824727, top_k: 0.940898, samples/s: 783.520 1613478141.0456705
train: epoch 156, iter 3000, loss: 1.668437, top_1: 0.824922, top_k: 0.943281, samples/s: 778.979 1613478173.90928
train: epoch 156, iter 3100, loss: 1.750294, top_1: 0.823477, top_k: 0.941953, samples/s: 786.423 1613478206.4616997
train: epoch 156, iter 3200, loss: 1.810224, top_1: 0.828281, top_k: 0.942813, samples/s: 783.244 1613478239.1463277
train: epoch 156, iter 3300, loss: 1.772890, top_1: 0.826602, top_k: 0.941406, samples/s: 782.748 1613478271.8515327
train: epoch 156, iter 3400, loss: 1.772998, top_1: 0.830547, top_k: 0.944727, samples/s: 783.873 1613478304.5098786
train: epoch 156, iter 3500, loss: 1.816919, top_1: 0.829297, top_k: 0.940820, samples/s: 783.784 1613478337.1719735
train: epoch 156, iter 3600, loss: 1.845788, top_1: 0.825859, top_k: 0.941953, samples/s: 783.767 1613478369.8347027
train: epoch 156, iter 3700, loss: 1.723928, top_1: 0.829063, top_k: 0.943906, samples/s: 783.413 1613478402.5122893
train: epoch 156, iter 3800, loss: 1.678035, top_1: 0.824883, top_k: 0.942109, samples/s: 781.513 1613478435.2692025
train: epoch 156, iter 3900, loss: 1.691615, top_1: 0.828086, top_k: 0.943008, samples/s: 783.260 1613478467.9530985
train: epoch 156, iter 4000, loss: 1.746870, top_1: 0.825195, top_k: 0.942305, samples/s: 782.962 1613478500.6494813
train: epoch 156, iter 4100, loss: 1.766714, top_1: 0.822891, top_k: 0.941680, samples/s: 783.819 1613478533.3100832
train: epoch 156, iter 4200, loss: 1.698693, top_1: 0.826328, top_k: 0.940820, samples/s: 784.181 1613478565.9556148
train: epoch 156, iter 4300, loss: 1.791749, top_1: 0.827656, top_k: 0.942969, samples/s: 782.388 1613478598.6758945
train: epoch 156, iter 4400, loss: 1.648904, top_1: 0.826602, top_k: 0.942578, samples/s: 782.146 1613478631.4063962
train: epoch 156, iter 4500, loss: 1.715235, top_1: 0.825664, top_k: 0.941289, samples/s: 782.883 1613478664.105989
train: epoch 156, iter 4600, loss: 1.746031, top_1: 0.825781, top_k: 0.940742, samples/s: 784.393 1613478696.7427244
train: epoch 156, iter 4700, loss: 1.760206, top_1: 0.828906, top_k: 0.943594, samples/s: 782.738 1613478729.4484675
train: epoch 156, iter 4800, loss: 1.808827, top_1: 0.828008, top_k: 0.940039, samples/s: 784.273 1613478762.0901384
train: epoch 156, iter 4900, loss: 1.842106, top_1: 0.823281, top_k: 0.941016, samples/s: 784.072 1613478794.7401972
train: epoch 156, iter 5000, loss: 1.727304, top_1: 0.822852, top_k: 0.942227, samples/s: 784.072 1613478827.3902612
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_156.
validation: epoch 156, iter 195, top_1: 0.781671, top_k: 0.940925, samples/s: 2363.873 1613478849.494039
train: epoch 157, iter 100, loss: 1.848510, top_1: 0.826016, top_k: 0.941797, samples/s: 805.234 1613478901.9896696
train: epoch 157, iter 200, loss: 1.720645, top_1: 0.826992, top_k: 0.943789, samples/s: 801.672 1613478933.9230618
train: epoch 157, iter 300, loss: 1.733227, top_1: 0.828828, top_k: 0.943477, samples/s: 784.782 1613478966.543406
train: epoch 157, iter 400, loss: 1.770380, top_1: 0.833594, top_k: 0.946992, samples/s: 783.618 1613478999.2124395
train: epoch 157, iter 500, loss: 1.821724, top_1: 0.824375, top_k: 0.940312, samples/s: 783.053 1613479031.9049366
train: epoch 157, iter 600, loss: 1.774095, top_1: 0.824883, top_k: 0.940703, samples/s: 782.254 1613479064.6309288
train: epoch 157, iter 700, loss: 1.705954, top_1: 0.825586, top_k: 0.941445, samples/s: 784.143 1613479097.27792
train: epoch 157, iter 800, loss: 1.794053, top_1: 0.824531, top_k: 0.943125, samples/s: 781.763 1613479130.0244703
train: epoch 157, iter 900, loss: 1.810122, top_1: 0.825469, top_k: 0.942539, samples/s: 780.753 1613479162.8134131
train: epoch 157, iter 1000, loss: 1.693739, top_1: 0.828516, top_k: 0.940234, samples/s: 782.817 1613479195.5158074
train: epoch 157, iter 1100, loss: 1.600247, top_1: 0.824219, top_k: 0.943086, samples/s: 785.595 1613479228.1025534
train: epoch 157, iter 1200, loss: 1.665915, top_1: 0.825859, top_k: 0.943086, samples/s: 782.261 1613479260.8281922
train: epoch 157, iter 1300, loss: 1.843672, top_1: 0.827187, top_k: 0.940781, samples/s: 782.955 1613479293.5247438
train: epoch 157, iter 1400, loss: 1.768894, top_1: 0.821953, top_k: 0.939414, samples/s: 783.061 1613479326.2169836
train: epoch 157, iter 1500, loss: 1.783645, top_1: 0.826016, top_k: 0.942578, samples/s: 784.904 1613479358.8324268
train: epoch 157, iter 1600, loss: 1.833413, top_1: 0.829805, top_k: 0.941797, samples/s: 779.246 1613479391.6847625
train: epoch 157, iter 1700, loss: 1.797903, top_1: 0.822891, top_k: 0.943633, samples/s: 785.625 1613479424.2701516
train: epoch 157, iter 1800, loss: 1.763182, top_1: 0.825703, top_k: 0.942031, samples/s: 783.579 1613479456.9407997
train: epoch 157, iter 1900, loss: 1.656046, top_1: 0.826875, top_k: 0.940508, samples/s: 785.499 1613479489.5315466
train: epoch 157, iter 2000, loss: 1.660622, top_1: 0.822422, top_k: 0.942344, samples/s: 786.486 1613479522.0813978
train: epoch 157, iter 2100, loss: 1.817410, top_1: 0.824883, top_k: 0.939648, samples/s: 782.346 1613479554.8034766
train: epoch 157, iter 2200, loss: 1.830530, top_1: 0.827461, top_k: 0.944297, samples/s: 782.650 1613479587.512834
train: epoch 157, iter 2300, loss: 1.694725, top_1: 0.829570, top_k: 0.941289, samples/s: 783.350 1613479620.19302
train: epoch 157, iter 2400, loss: 1.784208, top_1: 0.822734, top_k: 0.942070, samples/s: 782.413 1613479652.9122665
train: epoch 157, iter 2500, loss: 1.711263, top_1: 0.821641, top_k: 0.941758, samples/s: 781.887 1613479685.653633
train: epoch 157, iter 2600, loss: 1.726890, top_1: 0.830117, top_k: 0.944609, samples/s: 784.475 1613479718.2868404
train: epoch 157, iter 2700, loss: 1.831120, top_1: 0.826406, top_k: 0.941602, samples/s: 782.518 1613479751.0017211
train: epoch 157, iter 2800, loss: 1.742775, top_1: 0.827148, top_k: 0.946094, samples/s: 783.549 1613479783.6736224
train: epoch 157, iter 2900, loss: 1.793342, top_1: 0.821680, top_k: 0.942266, samples/s: 784.203 1613479816.3182983
train: epoch 157, iter 3000, loss: 1.748725, top_1: 0.829570, top_k: 0.943086, samples/s: 784.165 1613479848.9644938
train: epoch 157, iter 3100, loss: 1.821148, top_1: 0.829297, top_k: 0.943906, samples/s: 782.717 1613479881.6711469
train: epoch 157, iter 3200, loss: 1.840464, top_1: 0.823633, top_k: 0.939805, samples/s: 783.112 1613479914.3611405
train: epoch 157, iter 3300, loss: 1.829162, top_1: 0.827734, top_k: 0.943281, samples/s: 784.462 1613479946.9950118
train: epoch 157, iter 3400, loss: 1.574054, top_1: 0.828984, top_k: 0.941094, samples/s: 781.441 1613479979.7549682
train: epoch 157, iter 3500, loss: 1.760523, top_1: 0.827109, top_k: 0.944141, samples/s: 783.522 1613480012.4279637
train: epoch 157, iter 3600, loss: 1.657725, top_1: 0.827500, top_k: 0.941562, samples/s: 786.002 1613480044.9978225
train: epoch 157, iter 3700, loss: 1.783289, top_1: 0.825703, top_k: 0.941445, samples/s: 785.007 1613480077.6090016
train: epoch 157, iter 3800, loss: 1.697487, top_1: 0.825273, top_k: 0.943672, samples/s: 781.084 1613480110.3839695
train: epoch 157, iter 3900, loss: 1.810116, top_1: 0.826641, top_k: 0.943047, samples/s: 781.587 1613480143.1378458
train: epoch 157, iter 4000, loss: 1.861213, top_1: 0.826289, top_k: 0.941602, samples/s: 783.259 1613480175.8217072
train: epoch 157, iter 4100, loss: 1.803909, top_1: 0.830078, top_k: 0.943281, samples/s: 785.470 1613480208.4137793
train: epoch 157, iter 4200, loss: 1.668449, top_1: 0.825273, top_k: 0.942539, samples/s: 784.670 1613480241.038875
train: epoch 157, iter 4300, loss: 1.827656, top_1: 0.827969, top_k: 0.942461, samples/s: 783.663 1613480273.706023
train: epoch 157, iter 4400, loss: 1.709860, top_1: 0.828359, top_k: 0.941445, samples/s: 784.986 1613480306.318032
train: epoch 157, iter 4500, loss: 1.734572, top_1: 0.826992, top_k: 0.941797, samples/s: 782.702 1613480339.0253055
train: epoch 157, iter 4600, loss: 1.716654, top_1: 0.825742, top_k: 0.939961, samples/s: 785.088 1613480371.6330328
train: epoch 157, iter 4700, loss: 1.799368, top_1: 0.823320, top_k: 0.940625, samples/s: 781.885 1613480404.3743956
train: epoch 157, iter 4800, loss: 1.704693, top_1: 0.830937, top_k: 0.945117, samples/s: 784.699 1613480436.998369
train: epoch 157, iter 4900, loss: 1.821949, top_1: 0.830625, top_k: 0.942813, samples/s: 782.421 1613480469.717362
train: epoch 157, iter 5000, loss: 1.751347, top_1: 0.828789, top_k: 0.940664, samples/s: 784.221 1613480502.361192
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_157.
validation: epoch 157, iter 195, top_1: 0.782552, top_k: 0.941587, samples/s: 2365.940 1613480524.462515
train: epoch 158, iter 100, loss: 1.723499, top_1: 0.830586, top_k: 0.942539, samples/s: 804.186 1613480582.0853417
train: epoch 158, iter 200, loss: 1.678472, top_1: 0.826445, top_k: 0.943008, samples/s: 802.414 1613480613.989357
train: epoch 158, iter 300, loss: 1.738410, top_1: 0.826484, top_k: 0.942383, samples/s: 788.581 1613480646.45243
train: epoch 158, iter 400, loss: 1.664731, top_1: 0.828008, top_k: 0.944180, samples/s: 782.611 1613480679.163416
train: epoch 158, iter 500, loss: 1.774836, top_1: 0.828242, top_k: 0.942422, samples/s: 783.568 1613480711.8345163
train: epoch 158, iter 600, loss: 1.792267, top_1: 0.826680, top_k: 0.944648, samples/s: 783.457 1613480744.5103016
train: epoch 158, iter 700, loss: 1.758698, top_1: 0.824688, top_k: 0.943750, samples/s: 780.271 1613480777.3193235
train: epoch 158, iter 800, loss: 1.698241, top_1: 0.825000, top_k: 0.942344, samples/s: 781.639 1613480810.0710928
train: epoch 158, iter 900, loss: 1.728663, top_1: 0.829063, top_k: 0.942500, samples/s: 784.670 1613480842.696169
train: epoch 158, iter 1000, loss: 1.801378, top_1: 0.822031, top_k: 0.940195, samples/s: 781.188 1613480875.466877
train: epoch 158, iter 1100, loss: 1.796396, top_1: 0.825937, top_k: 0.942227, samples/s: 782.780 1613480908.1707973
train: epoch 158, iter 1200, loss: 1.766480, top_1: 0.832656, top_k: 0.946250, samples/s: 783.041 1613480940.863844
train: epoch 158, iter 1300, loss: 1.653736, top_1: 0.830391, top_k: 0.942969, samples/s: 781.987 1613480973.6009963
train: epoch 158, iter 1400, loss: 1.881531, top_1: 0.825547, top_k: 0.942773, samples/s: 782.466 1613481006.3180423
train: epoch 158, iter 1500, loss: 1.642872, top_1: 0.828750, top_k: 0.943594, samples/s: 783.350 1613481038.998176
train: epoch 158, iter 1600, loss: 1.698688, top_1: 0.826562, top_k: 0.942305, samples/s: 783.885 1613481071.6559558
train: epoch 158, iter 1700, loss: 1.666739, top_1: 0.824023, top_k: 0.940898, samples/s: 784.138 1613481104.303282
train: epoch 158, iter 1800, loss: 1.764676, top_1: 0.825664, top_k: 0.943477, samples/s: 783.281 1613481136.986468
train: epoch 158, iter 1900, loss: 1.749260, top_1: 0.829219, top_k: 0.941289, samples/s: 782.752 1613481169.6914954
train: epoch 158, iter 2000, loss: 1.847378, top_1: 0.827891, top_k: 0.941289, samples/s: 782.298 1613481202.4155414
train: epoch 158, iter 2100, loss: 1.644466, top_1: 0.827695, top_k: 0.942227, samples/s: 784.498 1613481235.047896
train: epoch 158, iter 2200, loss: 1.591913, top_1: 0.827422, top_k: 0.944258, samples/s: 782.032 1613481267.783144
train: epoch 158, iter 2300, loss: 1.702962, top_1: 0.828867, top_k: 0.943164, samples/s: 783.411 1613481300.460691
train: epoch 158, iter 2400, loss: 1.807101, top_1: 0.824297, top_k: 0.942227, samples/s: 784.237 1613481333.1038587
train: epoch 158, iter 2500, loss: 1.816664, top_1: 0.827109, top_k: 0.941094, samples/s: 784.671 1613481365.7291076
train: epoch 158, iter 2600, loss: 1.747691, top_1: 0.826758, top_k: 0.942344, samples/s: 779.713 1613481398.5616434
train: epoch 158, iter 2700, loss: 1.722470, top_1: 0.824570, top_k: 0.941680, samples/s: 784.257 1613481431.204043
train: epoch 158, iter 2800, loss: 1.712431, top_1: 0.827344, top_k: 0.942539, samples/s: 783.925 1613481463.8601906
train: epoch 158, iter 2900, loss: 1.790727, top_1: 0.826523, top_k: 0.942109, samples/s: 780.310 1613481496.6676764
train: epoch 158, iter 3000, loss: 1.708119, top_1: 0.829805, top_k: 0.944141, samples/s: 784.239 1613481529.3107755
train: epoch 158, iter 3100, loss: 1.658250, top_1: 0.822305, top_k: 0.941953, samples/s: 782.927 1613481562.0086455
train: epoch 158, iter 3200, loss: 1.879909, top_1: 0.827148, top_k: 0.942187, samples/s: 782.977 1613481594.7043076
train: epoch 158, iter 3300, loss: 1.713294, top_1: 0.824805, top_k: 0.942539, samples/s: 782.131 1613481627.4354196
train: epoch 158, iter 3400, loss: 1.734079, top_1: 0.826719, top_k: 0.944258, samples/s: 783.311 1613481660.1171155
train: epoch 158, iter 3500, loss: 1.711983, top_1: 0.826406, top_k: 0.943672, samples/s: 782.315 1613481692.8405752
train: epoch 158, iter 3600, loss: 1.681862, top_1: 0.830195, top_k: 0.942383, samples/s: 786.387 1613481725.394477
train: epoch 158, iter 3700, loss: 1.839320, top_1: 0.825977, top_k: 0.942344, samples/s: 783.210 1613481758.0804887
train: epoch 158, iter 3800, loss: 1.660843, top_1: 0.825117, top_k: 0.940781, samples/s: 784.841 1613481790.6987276
train: epoch 158, iter 3900, loss: 1.688522, top_1: 0.822227, top_k: 0.939727, samples/s: 782.166 1613481823.4281814
train: epoch 158, iter 4000, loss: 1.828276, top_1: 0.823047, top_k: 0.940703, samples/s: 785.405 1613481856.0228446
train: epoch 158, iter 4100, loss: 1.743445, top_1: 0.828398, top_k: 0.942227, samples/s: 782.560 1613481888.7361078
train: epoch 158, iter 4200, loss: 1.762762, top_1: 0.825898, top_k: 0.944336, samples/s: 784.438 1613481921.3709452
train: epoch 158, iter 4300, loss: 1.799277, top_1: 0.827070, top_k: 0.940312, samples/s: 783.303 1613481954.0530353
train: epoch 158, iter 4400, loss: 1.698769, top_1: 0.829023, top_k: 0.941523, samples/s: 784.962 1613481986.6660836
train: epoch 158, iter 4500, loss: 1.741940, top_1: 0.828555, top_k: 0.943633, samples/s: 783.232 1613482019.3511243
train: epoch 158, iter 4600, loss: 1.875407, top_1: 0.824063, top_k: 0.940742, samples/s: 784.571 1613482051.9804175
train: epoch 158, iter 4700, loss: 1.799611, top_1: 0.831836, top_k: 0.943438, samples/s: 782.708 1613482084.6873813
train: epoch 158, iter 4800, loss: 1.751312, top_1: 0.827187, top_k: 0.942617, samples/s: 782.190 1613482117.4159381
train: epoch 158, iter 4900, loss: 1.854796, top_1: 0.825195, top_k: 0.940859, samples/s: 783.066 1613482150.108022
train: epoch 158, iter 5000, loss: 1.770781, top_1: 0.826641, top_k: 0.941484, samples/s: 786.053 1613482182.6758308
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_158.
validation: epoch 158, iter 195, top_1: 0.782672, top_k: 0.941326, samples/s: 2373.117 1613482204.695441
train: epoch 159, iter 100, loss: 1.817964, top_1: 0.827500, top_k: 0.944531, samples/s: 804.168 1613482256.827232
train: epoch 159, iter 200, loss: 1.906230, top_1: 0.824961, top_k: 0.939688, samples/s: 797.699 1613482288.9195912
train: epoch 159, iter 300, loss: 1.788745, top_1: 0.827852, top_k: 0.941758, samples/s: 786.002 1613482321.489336
train: epoch 159, iter 400, loss: 1.655329, top_1: 0.826172, top_k: 0.942422, samples/s: 785.000 1613482354.1007977
train: epoch 159, iter 500, loss: 1.792895, top_1: 0.828867, top_k: 0.943594, samples/s: 779.655 1613482386.93593
train: epoch 159, iter 600, loss: 1.743516, top_1: 0.823867, top_k: 0.938945, samples/s: 782.931 1613482419.633523
train: epoch 159, iter 700, loss: 1.915336, top_1: 0.824102, top_k: 0.943047, samples/s: 782.611 1613482452.344537
train: epoch 159, iter 800, loss: 1.747180, top_1: 0.830781, top_k: 0.944297, samples/s: 783.876 1613482485.002716
train: epoch 159, iter 900, loss: 1.881047, top_1: 0.830313, top_k: 0.942461, samples/s: 783.630 1613482517.6712549
train: epoch 159, iter 1000, loss: 1.756964, top_1: 0.827227, top_k: 0.942227, samples/s: 782.340 1613482550.3935902
train: epoch 159, iter 1100, loss: 1.728409, top_1: 0.824805, top_k: 0.942109, samples/s: 784.282 1613482583.0350287
train: epoch 159, iter 1200, loss: 1.677710, top_1: 0.830508, top_k: 0.944258, samples/s: 782.974 1613482615.7307212
train: epoch 159, iter 1300, loss: 1.814805, top_1: 0.827227, top_k: 0.944023, samples/s: 782.844 1613482648.4319606
train: epoch 159, iter 1400, loss: 1.690934, top_1: 0.827070, top_k: 0.943086, samples/s: 782.832 1613482681.1338265
train: epoch 159, iter 1500, loss: 1.766421, top_1: 0.824883, top_k: 0.940586, samples/s: 781.737 1613482713.881398
train: epoch 159, iter 1600, loss: 1.790990, top_1: 0.827930, top_k: 0.940859, samples/s: 783.140 1613482746.5703673
train: epoch 159, iter 1700, loss: 1.724567, top_1: 0.827148, top_k: 0.938945, samples/s: 783.841 1613482779.230036
train: epoch 159, iter 1800, loss: 1.874773, top_1: 0.826797, top_k: 0.940977, samples/s: 781.915 1613482811.970126
train: epoch 159, iter 1900, loss: 1.673923, top_1: 0.823984, top_k: 0.941641, samples/s: 784.140 1613482844.6173136
train: epoch 159, iter 2000, loss: 1.748644, top_1: 0.827109, top_k: 0.944688, samples/s: 781.482 1613482877.375665
train: epoch 159, iter 2100, loss: 1.757551, top_1: 0.828164, top_k: 0.943398, samples/s: 783.338 1613482910.0563648
train: epoch 159, iter 2200, loss: 1.742914, top_1: 0.829570, top_k: 0.943594, samples/s: 782.967 1613482942.7523818
train: epoch 159, iter 2300, loss: 1.812690, top_1: 0.827812, top_k: 0.944883, samples/s: 783.024 1613482975.4461117
train: epoch 159, iter 2400, loss: 1.752521, top_1: 0.828711, top_k: 0.942734, samples/s: 783.505 1613483008.1199038
train: epoch 159, iter 2500, loss: 1.686300, top_1: 0.824492, top_k: 0.940430, samples/s: 783.387 1613483040.7985034
train: epoch 159, iter 2600, loss: 1.902882, top_1: 0.823516, top_k: 0.941836, samples/s: 784.119 1613483073.446627
train: epoch 159, iter 2700, loss: 1.806394, top_1: 0.823320, top_k: 0.942891, samples/s: 784.546 1613483106.07692
train: epoch 159, iter 2800, loss: 1.770483, top_1: 0.826328, top_k: 0.941992, samples/s: 782.430 1613483138.7955618
train: epoch 159, iter 2900, loss: 1.615705, top_1: 0.831094, top_k: 0.945039, samples/s: 782.465 1613483171.5126817
train: epoch 159, iter 3000, loss: 1.686828, top_1: 0.828555, top_k: 0.940781, samples/s: 783.979 1613483204.1665483
train: epoch 159, iter 3100, loss: 1.800920, top_1: 0.829844, top_k: 0.944883, samples/s: 782.479 1613483236.883119
train: epoch 159, iter 3200, loss: 1.804399, top_1: 0.828594, top_k: 0.942656, samples/s: 780.913 1613483269.6652029
train: epoch 159, iter 3300, loss: 1.738752, top_1: 0.827891, top_k: 0.942344, samples/s: 782.921 1613483302.3632956
train: epoch 159, iter 3400, loss: 1.639685, top_1: 0.829727, top_k: 0.944141, samples/s: 783.250 1613483335.0476043
train: epoch 159, iter 3500, loss: 1.667377, top_1: 0.828750, top_k: 0.944141, samples/s: 783.425 1613483367.7246416
train: epoch 159, iter 3600, loss: 1.722484, top_1: 0.827187, top_k: 0.941094, samples/s: 781.860 1613483400.4670033
train: epoch 159, iter 3700, loss: 1.730344, top_1: 0.828438, top_k: 0.945234, samples/s: 782.637 1613483433.1769364
train: epoch 159, iter 3800, loss: 1.767702, top_1: 0.828047, top_k: 0.941211, samples/s: 780.703 1613483465.9681346
train: epoch 159, iter 3900, loss: 1.928703, top_1: 0.827383, top_k: 0.941484, samples/s: 784.047 1613483498.619017
train: epoch 159, iter 4000, loss: 1.767084, top_1: 0.827539, top_k: 0.943203, samples/s: 784.662 1613483531.2445834
train: epoch 159, iter 4100, loss: 1.887298, top_1: 0.827969, top_k: 0.943047, samples/s: 782.496 1613483563.9603457
train: epoch 159, iter 4200, loss: 1.909706, top_1: 0.822344, top_k: 0.940820, samples/s: 782.092 1613483596.6931446
train: epoch 159, iter 4300, loss: 1.755203, top_1: 0.824102, top_k: 0.941836, samples/s: 784.055 1613483629.3438804
train: epoch 159, iter 4400, loss: 1.671653, top_1: 0.823906, top_k: 0.942500, samples/s: 783.882 1613483662.001868
train: epoch 159, iter 4500, loss: 1.895644, top_1: 0.826602, top_k: 0.942148, samples/s: 783.884 1613483694.6598458
train: epoch 159, iter 4600, loss: 1.744986, top_1: 0.822930, top_k: 0.942813, samples/s: 781.567 1613483727.4145222
train: epoch 159, iter 4700, loss: 1.730868, top_1: 0.826719, top_k: 0.942695, samples/s: 783.103 1613483760.104955
train: epoch 159, iter 4800, loss: 1.801536, top_1: 0.827539, top_k: 0.940859, samples/s: 783.826 1613483792.76526
train: epoch 159, iter 4900, loss: 1.791954, top_1: 0.825430, top_k: 0.940234, samples/s: 782.721 1613483825.4716845
train: epoch 159, iter 5000, loss: 1.799065, top_1: 0.825117, top_k: 0.939961, samples/s: 783.143 1613483858.16051
Saving model to ./repvggB1g2/snapshots/model_save/snapshot_epoch_159.
validation: epoch 159, iter 195, top_1: 0.782452, top_k: 0.941346, samples/s: 2347.240 1613483880.3984568
