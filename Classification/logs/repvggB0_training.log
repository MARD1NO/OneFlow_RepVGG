==================================================================
Running repvggB0: num_gpu_per_node = 4, num_nodes = 1.
==================================================================
dtype = float32
gpu_num_per_node = 4
num_nodes = 1
node_ips = ['192.168.1.13', '192.168.1.14']
ctrl_port = 50051
model = repvggB0
mixup = False
use_fp16 = None
use_xla = None
channel_last = False
pad_output = None
num_epochs = 160
model_load_dir = None
batch_size_per_device = 64
val_batch_size_per_device = 64
nccl_fusion_threshold_mb = 16
nccl_fusion_max_ops = 24
fuse_bn_relu = True
fuse_bn_add_relu = True
gpu_image_decoder = True
image_path = test_img/tiger.jpg
num_classes = 1000
num_examples = 1281167
num_val_examples = 50000
rgb_mean = [123.68, 116.779, 103.939]
rgb_std = [58.393, 57.12, 57.375]
image_shape = [3, 224, 224]
label_smoothing = 0.1
model_save_dir = ./repvggB0/snapshots/model_save/
log_dir = ./output
loss_print_every_n_iter = 100
image_size = 224
resize_shorter = 256
train_data_dir = /DATA/disk1/ImageNet/ofrecord/train
train_data_part_num = 256
val_data_dir = /DATA/disk1/ImageNet/ofrecord/validation
val_data_part_num = 256
optimizer = sgd
learning_rate = 0.1
wd = 3.0517578125e-05
momentum = 0.9
lr_decay = cosine
lr_decay_rate = 0.94
lr_decay_epochs = 2
warmup_epochs = 5
decay_rate = 0.9
epsilon = 1.0
gradient_clipping = 0.0
------------------------------------------------------------------
Time stamp: 2021-02-09-09:45:15
!!!!!===!!!! ./repvggB0/snapshots/model_save/
[1mWARNING: 'flow.train.CheckPoint' is deprecated. Please use the new API:[0m
flow.train.CheckPoint().save(path) => [1m[92mflow.checkpoint.save(path)[0m
flow.train.CheckPoint().load(path) => [1m[92mflow.load_variables(flow.checkpoint.get(path))[0m
flow.train.CheckPoint().init() is not needed any more.

Loading data from /DATA/disk1/ImageNet/ofrecord/train
No MixUp
loss.shape (1,)
predictions:  (256, 1000)
Optimizer:  SGD
Loading data from /DATA/disk1/ImageNet/ofrecord/validation
Saving model to ./repvggB0/snapshots/model_save/snapshot_initial_model.
Init model on demand.
train: epoch 0, iter 100, loss: 6.853383, top_1: 0.002344, top_k: 0.008750, samples/s: 1720.183 1612835283.6710827
train: epoch 0, iter 200, loss: 6.800279, top_1: 0.004102, top_k: 0.017227, samples/s: 1737.251 1612835298.4072282
train: epoch 0, iter 300, loss: 6.692850, top_1: 0.006172, top_k: 0.023047, samples/s: 1762.459 1612835312.93206
train: epoch 0, iter 400, loss: 6.614110, top_1: 0.007930, top_k: 0.032891, samples/s: 1749.043 1612835327.5686064
train: epoch 0, iter 500, loss: 6.521072, top_1: 0.010430, top_k: 0.038711, samples/s: 1754.100 1612835342.1630774
train: epoch 0, iter 600, loss: 6.473244, top_1: 0.012969, top_k: 0.049727, samples/s: 1751.378 1612835356.780387
train: epoch 0, iter 700, loss: 6.349934, top_1: 0.015508, top_k: 0.054375, samples/s: 1750.695 1612835371.40286
train: epoch 0, iter 800, loss: 6.315725, top_1: 0.018672, top_k: 0.065625, samples/s: 1753.423 1612835386.0028322
train: epoch 0, iter 900, loss: 6.345139, top_1: 0.022109, top_k: 0.073477, samples/s: 1740.638 1612835400.7101452
train: epoch 0, iter 1000, loss: 6.152515, top_1: 0.022695, top_k: 0.083359, samples/s: 1761.363 1612835415.244291
train: epoch 0, iter 1100, loss: 6.183953, top_1: 0.029805, top_k: 0.090156, samples/s: 1753.867 1612835429.8406186
train: epoch 0, iter 1200, loss: 6.023862, top_1: 0.030195, top_k: 0.100352, samples/s: 1751.352 1612835444.4578633
train: epoch 0, iter 1300, loss: 5.844461, top_1: 0.032305, top_k: 0.107813, samples/s: 1753.670 1612835459.0558336
train: epoch 0, iter 1400, loss: 5.991779, top_1: 0.035859, top_k: 0.116484, samples/s: 1757.018 1612835473.6260264
train: epoch 0, iter 1500, loss: 5.906652, top_1: 0.036953, top_k: 0.123867, samples/s: 1751.921 1612835488.2384913
train: epoch 0, iter 1600, loss: 5.811521, top_1: 0.043359, top_k: 0.133477, samples/s: 1754.520 1612835502.829387
train: epoch 0, iter 1700, loss: 5.747728, top_1: 0.045898, top_k: 0.143164, samples/s: 1757.529 1612835517.3952863
train: epoch 0, iter 1800, loss: 5.752016, top_1: 0.047227, top_k: 0.148906, samples/s: 1753.798 1612835531.9921894
train: epoch 0, iter 1900, loss: 5.765119, top_1: 0.049805, top_k: 0.156602, samples/s: 1751.312 1612835546.6098273
train: epoch 0, iter 2000, loss: 5.593657, top_1: 0.055508, top_k: 0.168789, samples/s: 1759.734 1612835561.1574671
train: epoch 0, iter 2100, loss: 5.528019, top_1: 0.060742, top_k: 0.175898, samples/s: 1753.270 1612835575.7587268
train: epoch 0, iter 2200, loss: 5.605139, top_1: 0.061758, top_k: 0.181016, samples/s: 1731.040 1612835590.5476327
train: epoch 0, iter 2300, loss: 5.641042, top_1: 0.066875, top_k: 0.193516, samples/s: 1756.313 1612835605.1235328
train: epoch 0, iter 2400, loss: 5.505242, top_1: 0.070469, top_k: 0.197109, samples/s: 1745.589 1612835619.7890353
train: epoch 0, iter 2500, loss: 5.619199, top_1: 0.074336, top_k: 0.206758, samples/s: 1746.454 1612835634.4473772
train: epoch 0, iter 2600, loss: 5.574465, top_1: 0.074102, top_k: 0.205313, samples/s: 1746.415 1612835649.1059544
train: epoch 0, iter 2700, loss: 5.299956, top_1: 0.076953, top_k: 0.214414, samples/s: 1737.120 1612835663.8437703
train: epoch 0, iter 2800, loss: 5.503370, top_1: 0.082461, top_k: 0.220547, samples/s: 1740.575 1612835678.5508258
train: epoch 0, iter 2900, loss: 5.516881, top_1: 0.087188, top_k: 0.232695, samples/s: 1739.806 1612835693.265117
train: epoch 0, iter 3000, loss: 5.300394, top_1: 0.091133, top_k: 0.242305, samples/s: 1750.438 1612835707.8899782
train: epoch 0, iter 3100, loss: 5.432683, top_1: 0.092891, top_k: 0.242500, samples/s: 1731.096 1612835722.6783638
train: epoch 0, iter 3200, loss: 5.501250, top_1: 0.095937, top_k: 0.249219, samples/s: 1747.366 1612835737.3288767
train: epoch 0, iter 3300, loss: 5.415349, top_1: 0.099687, top_k: 0.258945, samples/s: 1745.271 1612835751.9971871
train: epoch 0, iter 3400, loss: 5.222220, top_1: 0.102656, top_k: 0.261250, samples/s: 1739.805 1612835766.7114272
train: epoch 0, iter 3500, loss: 5.255350, top_1: 0.104414, top_k: 0.268789, samples/s: 1740.033 1612835781.423785
train: epoch 0, iter 3600, loss: 5.213450, top_1: 0.109023, top_k: 0.269492, samples/s: 1741.603 1612835796.122841
train: epoch 0, iter 3700, loss: 5.037556, top_1: 0.111992, top_k: 0.282852, samples/s: 1725.321 1612835810.9607074
train: epoch 0, iter 3800, loss: 5.142065, top_1: 0.118281, top_k: 0.289570, samples/s: 1735.209 1612835825.7139006
train: epoch 0, iter 3900, loss: 4.961091, top_1: 0.115391, top_k: 0.292187, samples/s: 1743.753 1612835840.394939
train: epoch 0, iter 4000, loss: 5.316017, top_1: 0.125430, top_k: 0.299141, samples/s: 1744.274 1612835855.071479
train: epoch 0, iter 4100, loss: 4.958073, top_1: 0.127578, top_k: 0.306289, samples/s: 1744.469 1612835869.7464964
train: epoch 0, iter 4200, loss: 5.123753, top_1: 0.130000, top_k: 0.311836, samples/s: 1739.493 1612835884.4633667
train: epoch 0, iter 4300, loss: 5.005185, top_1: 0.133867, top_k: 0.314453, samples/s: 1741.466 1612835899.1637032
train: epoch 0, iter 4400, loss: 5.157137, top_1: 0.135078, top_k: 0.321562, samples/s: 1735.376 1612835913.9154649
train: epoch 0, iter 4500, loss: 4.966675, top_1: 0.137695, top_k: 0.326562, samples/s: 1734.438 1612835928.6753657
train: epoch 0, iter 4600, loss: 5.032268, top_1: 0.145234, top_k: 0.334219, samples/s: 1740.570 1612835943.383192
train: epoch 0, iter 4700, loss: 5.090381, top_1: 0.145820, top_k: 0.336836, samples/s: 1735.130 1612835958.1371279
train: epoch 0, iter 4800, loss: 4.953204, top_1: 0.147539, top_k: 0.337539, samples/s: 1734.867 1612835972.8933058
train: epoch 0, iter 4900, loss: 4.914216, top_1: 0.148633, top_k: 0.335352, samples/s: 1720.466 1612835987.77301
train: epoch 0, iter 5000, loss: 4.924631, top_1: 0.152891, top_k: 0.346992, samples/s: 1728.880 1612836002.580315
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_0.
validation: epoch 0, iter 195, top_1: 0.164183, top_k: 0.371434, samples/s: 2898.428 1612836020.1963828
train: epoch 1, iter 100, loss: 5.042485, top_1: 0.155625, top_k: 0.351719, samples/s: 1741.840 1612836055.5126586
train: epoch 1, iter 200, loss: 4.840420, top_1: 0.161523, top_k: 0.367148, samples/s: 1755.885 1612836070.0921419
train: epoch 1, iter 300, loss: 4.864166, top_1: 0.164258, top_k: 0.363828, samples/s: 1758.858 1612836084.6469684
train: epoch 1, iter 400, loss: 4.730528, top_1: 0.167500, top_k: 0.370000, samples/s: 1753.322 1612836099.2479124
train: epoch 1, iter 500, loss: 4.808221, top_1: 0.170703, top_k: 0.372617, samples/s: 1759.783 1612836113.7952864
train: epoch 1, iter 600, loss: 4.919610, top_1: 0.168594, top_k: 0.376094, samples/s: 1753.925 1612836128.390956
train: epoch 1, iter 700, loss: 4.793603, top_1: 0.178164, top_k: 0.381875, samples/s: 1743.098 1612836143.0774887
train: epoch 1, iter 800, loss: 4.489809, top_1: 0.172031, top_k: 0.384141, samples/s: 1748.114 1612836157.7218614
train: epoch 1, iter 900, loss: 4.763155, top_1: 0.178164, top_k: 0.381992, samples/s: 1726.842 1612836172.546613
train: epoch 1, iter 1000, loss: 4.839386, top_1: 0.181719, top_k: 0.391797, samples/s: 1744.239 1612836187.2234006
train: epoch 1, iter 1100, loss: 4.719354, top_1: 0.185859, top_k: 0.393633, samples/s: 1743.687 1612836201.9049702
train: epoch 1, iter 1200, loss: 4.621760, top_1: 0.183867, top_k: 0.396016, samples/s: 1739.596 1612836216.6210113
train: epoch 1, iter 1300, loss: 4.696120, top_1: 0.190469, top_k: 0.404336, samples/s: 1735.708 1612836231.3700626
train: epoch 1, iter 1400, loss: 4.665932, top_1: 0.192852, top_k: 0.410742, samples/s: 1723.683 1612836246.221959
train: epoch 1, iter 1500, loss: 4.707706, top_1: 0.192422, top_k: 0.407656, samples/s: 1739.666 1612836260.9373965
train: epoch 1, iter 1600, loss: 4.594276, top_1: 0.196445, top_k: 0.414219, samples/s: 1705.689 1612836275.9460857
train: epoch 1, iter 1700, loss: 4.363398, top_1: 0.206016, top_k: 0.422461, samples/s: 1742.192 1612836290.6402326
train: epoch 1, iter 1800, loss: 4.660360, top_1: 0.201133, top_k: 0.417891, samples/s: 1729.284 1612836305.4439437
train: epoch 1, iter 1900, loss: 4.548224, top_1: 0.198203, top_k: 0.416797, samples/s: 1728.084 1612836320.2580738
train: epoch 1, iter 2000, loss: 4.647082, top_1: 0.205625, top_k: 0.427852, samples/s: 1736.636 1612836334.9992409
train: epoch 1, iter 2100, loss: 4.478198, top_1: 0.209609, top_k: 0.425117, samples/s: 1738.012 1612836349.7287326
train: epoch 1, iter 2200, loss: 4.506357, top_1: 0.210508, top_k: 0.434414, samples/s: 1743.897 1612836364.408408
train: epoch 1, iter 2300, loss: 4.522627, top_1: 0.212930, top_k: 0.436094, samples/s: 1729.064 1612836379.214151
train: epoch 1, iter 2400, loss: 4.385012, top_1: 0.216914, top_k: 0.444141, samples/s: 1737.581 1612836393.9472694
train: epoch 1, iter 2500, loss: 4.495168, top_1: 0.216172, top_k: 0.443047, samples/s: 1737.646 1612836408.679824
train: epoch 1, iter 2600, loss: 4.442113, top_1: 0.220312, top_k: 0.448086, samples/s: 1728.060 1612836423.4941206
train: epoch 1, iter 2700, loss: 4.372051, top_1: 0.223047, top_k: 0.446133, samples/s: 1746.107 1612836438.1553335
train: epoch 1, iter 2800, loss: 4.550159, top_1: 0.223945, top_k: 0.450977, samples/s: 1736.847 1612836452.8946903
train: epoch 1, iter 2900, loss: 4.442740, top_1: 0.224414, top_k: 0.455352, samples/s: 1734.171 1612836467.6567385
train: epoch 1, iter 3000, loss: 4.381757, top_1: 0.229531, top_k: 0.456914, samples/s: 1721.977 1612836482.523424
train: epoch 1, iter 3100, loss: 4.468516, top_1: 0.229023, top_k: 0.456797, samples/s: 1725.817 1612836497.356923
train: epoch 1, iter 3200, loss: 4.448962, top_1: 0.229609, top_k: 0.461992, samples/s: 1744.616 1612836512.030676
train: epoch 1, iter 3300, loss: 4.453536, top_1: 0.231367, top_k: 0.460313, samples/s: 1706.958 1612836527.0280786
train: epoch 1, iter 3400, loss: 4.222920, top_1: 0.238516, top_k: 0.465273, samples/s: 1745.480 1612836541.694629
train: epoch 1, iter 3500, loss: 4.299686, top_1: 0.237227, top_k: 0.472578, samples/s: 1708.890 1612836556.6751325
train: epoch 1, iter 3600, loss: 4.463746, top_1: 0.236992, top_k: 0.470508, samples/s: 1759.558 1612836571.2241416
train: epoch 1, iter 3700, loss: 4.446532, top_1: 0.239414, top_k: 0.473281, samples/s: 1734.511 1612836585.983398
train: epoch 1, iter 3800, loss: 4.449999, top_1: 0.240117, top_k: 0.474141, samples/s: 1732.584 1612836600.7589664
train: epoch 1, iter 3900, loss: 4.328288, top_1: 0.241523, top_k: 0.475703, samples/s: 1736.576 1612836615.5006652
train: epoch 1, iter 4000, loss: 4.373228, top_1: 0.247930, top_k: 0.477500, samples/s: 1725.437 1612836630.3374941
train: epoch 1, iter 4100, loss: 4.294297, top_1: 0.246719, top_k: 0.480312, samples/s: 1727.763 1612836645.1542897
train: epoch 1, iter 4200, loss: 4.145096, top_1: 0.247188, top_k: 0.482539, samples/s: 1734.900 1612836659.9101944
train: epoch 1, iter 4300, loss: 4.181039, top_1: 0.251016, top_k: 0.488594, samples/s: 1735.381 1612836674.6619878
train: epoch 1, iter 4400, loss: 4.443697, top_1: 0.252031, top_k: 0.488164, samples/s: 1730.311 1612836689.4569898
train: epoch 1, iter 4500, loss: 4.291330, top_1: 0.251836, top_k: 0.493477, samples/s: 1721.683 1612836704.3261752
train: epoch 1, iter 4600, loss: 4.359800, top_1: 0.255937, top_k: 0.491289, samples/s: 1728.176 1612836719.1394904
train: epoch 1, iter 4700, loss: 4.137901, top_1: 0.253242, top_k: 0.490469, samples/s: 1740.793 1612836733.8454874
train: epoch 1, iter 4800, loss: 4.315930, top_1: 0.256797, top_k: 0.497070, samples/s: 1726.074 1612836748.676815
train: epoch 1, iter 4900, loss: 4.178236, top_1: 0.258906, top_k: 0.496719, samples/s: 1741.240 1612836763.3789277
train: epoch 1, iter 5000, loss: 4.349142, top_1: 0.265195, top_k: 0.500977, samples/s: 1732.345 1612836778.156584
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_1.
validation: epoch 1, iter 195, top_1: 0.272837, top_k: 0.525140, samples/s: 2819.731 1612836796.3246813
train: epoch 2, iter 100, loss: 4.168240, top_1: 0.273438, top_k: 0.510703, samples/s: 1742.188 1612836831.4234276
train: epoch 2, iter 200, loss: 3.948145, top_1: 0.272539, top_k: 0.512539, samples/s: 1760.514 1612836845.9645889
train: epoch 2, iter 300, loss: 4.165706, top_1: 0.274297, top_k: 0.509414, samples/s: 1761.286 1612836860.4994383
train: epoch 2, iter 400, loss: 4.243589, top_1: 0.269336, top_k: 0.515859, samples/s: 1750.617 1612836875.1228583
train: epoch 2, iter 500, loss: 4.114588, top_1: 0.271836, top_k: 0.514102, samples/s: 1751.548 1612836889.738742
train: epoch 2, iter 600, loss: 4.221477, top_1: 0.267188, top_k: 0.507578, samples/s: 1753.184 1612836904.3405523
train: epoch 2, iter 700, loss: 4.196861, top_1: 0.268594, top_k: 0.512383, samples/s: 1742.323 1612836919.0338197
train: epoch 2, iter 800, loss: 4.096137, top_1: 0.275547, top_k: 0.518750, samples/s: 1740.176 1612836933.744765
train: epoch 2, iter 900, loss: 4.428544, top_1: 0.273320, top_k: 0.512461, samples/s: 1731.950 1612836948.525683
train: epoch 2, iter 1000, loss: 3.976927, top_1: 0.277500, top_k: 0.521445, samples/s: 1735.316 1612836963.2781208
train: epoch 2, iter 1100, loss: 4.231570, top_1: 0.276602, top_k: 0.519062, samples/s: 1734.929 1612836978.0336902
train: epoch 2, iter 1200, loss: 4.138690, top_1: 0.287148, top_k: 0.528750, samples/s: 1732.943 1612836992.8063147
train: epoch 2, iter 1300, loss: 4.166052, top_1: 0.287344, top_k: 0.528906, samples/s: 1733.206 1612837007.5770137
train: epoch 2, iter 1400, loss: 4.091207, top_1: 0.286367, top_k: 0.530000, samples/s: 1731.805 1612837022.3588414
train: epoch 2, iter 1500, loss: 3.849583, top_1: 0.286992, top_k: 0.534453, samples/s: 1746.144 1612837037.0197606
train: epoch 2, iter 1600, loss: 4.279907, top_1: 0.283281, top_k: 0.528477, samples/s: 1732.692 1612837051.7944028
train: epoch 2, iter 1700, loss: 4.210112, top_1: 0.287461, top_k: 0.527031, samples/s: 1727.910 1612837066.610007
train: epoch 2, iter 1800, loss: 4.040239, top_1: 0.289492, top_k: 0.532891, samples/s: 1725.362 1612837081.4474716
train: epoch 2, iter 1900, loss: 4.224461, top_1: 0.289883, top_k: 0.531250, samples/s: 1740.443 1612837096.156429
train: epoch 2, iter 2000, loss: 4.156527, top_1: 0.292656, top_k: 0.535508, samples/s: 1736.433 1612837110.8996966
train: epoch 2, iter 2100, loss: 4.122835, top_1: 0.289727, top_k: 0.534961, samples/s: 1730.638 1612837125.6914706
train: epoch 2, iter 2200, loss: 4.105931, top_1: 0.288906, top_k: 0.534570, samples/s: 1725.096 1612837140.5312338
train: epoch 2, iter 2300, loss: 4.292622, top_1: 0.297539, top_k: 0.545039, samples/s: 1734.132 1612837155.2936766
train: epoch 2, iter 2400, loss: 4.204027, top_1: 0.295508, top_k: 0.537578, samples/s: 1729.956 1612837170.0917203
train: epoch 2, iter 2500, loss: 4.062606, top_1: 0.300117, top_k: 0.538984, samples/s: 1736.695 1612837184.8324072
train: epoch 2, iter 2600, loss: 4.272293, top_1: 0.295273, top_k: 0.534141, samples/s: 1729.218 1612837199.63673
train: epoch 2, iter 2700, loss: 4.267064, top_1: 0.296602, top_k: 0.545195, samples/s: 1718.513 1612837214.5333316
train: epoch 2, iter 2800, loss: 3.994640, top_1: 0.304414, top_k: 0.551602, samples/s: 1732.670 1612837229.3083441
train: epoch 2, iter 2900, loss: 4.096816, top_1: 0.298516, top_k: 0.546250, samples/s: 1733.621 1612837244.0750349
train: epoch 2, iter 3000, loss: 4.185822, top_1: 0.299961, top_k: 0.541094, samples/s: 1728.534 1612837258.885297
train: epoch 2, iter 3100, loss: 3.986625, top_1: 0.302695, top_k: 0.551875, samples/s: 1730.145 1612837273.6817465
train: epoch 2, iter 3200, loss: 4.064508, top_1: 0.307695, top_k: 0.557305, samples/s: 1727.630 1612837288.4996576
train: epoch 2, iter 3300, loss: 3.939060, top_1: 0.308242, top_k: 0.554531, samples/s: 1740.769 1612837303.2058158
train: epoch 2, iter 3400, loss: 4.014090, top_1: 0.309141, top_k: 0.557852, samples/s: 1735.769 1612837317.9543388
train: epoch 2, iter 3500, loss: 3.869751, top_1: 0.307070, top_k: 0.551680, samples/s: 1725.960 1612837332.786636
train: epoch 2, iter 3600, loss: 4.057336, top_1: 0.310742, top_k: 0.553789, samples/s: 1735.753 1612837347.5353234
train: epoch 2, iter 3700, loss: 4.079700, top_1: 0.306641, top_k: 0.557578, samples/s: 1738.370 1612837362.261774
train: epoch 2, iter 3800, loss: 3.897038, top_1: 0.314414, top_k: 0.561328, samples/s: 1737.384 1612837376.9965687
train: epoch 2, iter 3900, loss: 4.046135, top_1: 0.311484, top_k: 0.554883, samples/s: 1727.033 1612837391.819658
train: epoch 2, iter 4000, loss: 3.865642, top_1: 0.311406, top_k: 0.557187, samples/s: 1734.784 1612837406.5765398
train: epoch 2, iter 4100, loss: 4.070792, top_1: 0.313008, top_k: 0.566953, samples/s: 1736.426 1612837421.319615
train: epoch 2, iter 4200, loss: 3.940452, top_1: 0.313555, top_k: 0.555000, samples/s: 1740.777 1612837436.025505
train: epoch 2, iter 4300, loss: 4.132030, top_1: 0.312773, top_k: 0.567852, samples/s: 1746.319 1612837450.6849315
train: epoch 2, iter 4400, loss: 4.073452, top_1: 0.317852, top_k: 0.562305, samples/s: 1736.801 1612837465.4247098
train: epoch 2, iter 4500, loss: 3.991319, top_1: 0.319023, top_k: 0.562109, samples/s: 1737.877 1612837480.1554008
train: epoch 2, iter 4600, loss: 3.801638, top_1: 0.322734, top_k: 0.572500, samples/s: 1757.223 1612837494.7237458
train: epoch 2, iter 4700, loss: 3.943166, top_1: 0.320312, top_k: 0.567695, samples/s: 1742.549 1612837509.4148908
train: epoch 2, iter 4800, loss: 4.046217, top_1: 0.317891, top_k: 0.567852, samples/s: 1754.423 1612837524.0065238
train: epoch 2, iter 4900, loss: 4.086784, top_1: 0.316289, top_k: 0.564727, samples/s: 1748.380 1612837538.6486554
train: epoch 2, iter 5000, loss: 3.604068, top_1: 0.326836, top_k: 0.570820, samples/s: 1738.916 1612837553.3704653
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_2.
validation: epoch 2, iter 195, top_1: 0.359976, top_k: 0.623317, samples/s: 2935.598 1612837570.8119717
train: epoch 3, iter 100, loss: 4.046943, top_1: 0.333789, top_k: 0.582969, samples/s: 1755.523 1612837606.771554
train: epoch 3, iter 200, loss: 3.930157, top_1: 0.329297, top_k: 0.580156, samples/s: 1756.177 1612837621.3486373
train: epoch 3, iter 300, loss: 3.884345, top_1: 0.331172, top_k: 0.584141, samples/s: 1754.626 1612837635.9386566
train: epoch 3, iter 400, loss: 3.914565, top_1: 0.335469, top_k: 0.587187, samples/s: 1749.652 1612837650.5701215
train: epoch 3, iter 500, loss: 3.830481, top_1: 0.332695, top_k: 0.583242, samples/s: 1752.335 1612837665.1792374
train: epoch 3, iter 600, loss: 3.726587, top_1: 0.327969, top_k: 0.575547, samples/s: 1758.854 1612837679.7341547
train: epoch 3, iter 700, loss: 3.892666, top_1: 0.326016, top_k: 0.580195, samples/s: 1751.391 1612837694.3511117
train: epoch 3, iter 800, loss: 3.881681, top_1: 0.335977, top_k: 0.581992, samples/s: 1730.092 1612837709.1479604
train: epoch 3, iter 900, loss: 3.797436, top_1: 0.332031, top_k: 0.579727, samples/s: 1734.612 1612837723.906313
train: epoch 3, iter 1000, loss: 3.898338, top_1: 0.332891, top_k: 0.582344, samples/s: 1727.134 1612837738.7285557
train: epoch 3, iter 1100, loss: 3.983081, top_1: 0.333203, top_k: 0.584219, samples/s: 1734.687 1612837753.4862604
train: epoch 3, iter 1200, loss: 3.589043, top_1: 0.330625, top_k: 0.580156, samples/s: 1722.805 1612837768.3457658
train: epoch 3, iter 1300, loss: 3.922767, top_1: 0.332031, top_k: 0.584375, samples/s: 1740.981 1612837783.0501244
train: epoch 3, iter 1400, loss: 3.833786, top_1: 0.339648, top_k: 0.580117, samples/s: 1735.222 1612837797.8032682
train: epoch 3, iter 1500, loss: 3.956445, top_1: 0.331641, top_k: 0.584258, samples/s: 1734.670 1612837812.5611236
train: epoch 3, iter 1600, loss: 3.930328, top_1: 0.341172, top_k: 0.587773, samples/s: 1740.744 1612837827.2675102
train: epoch 3, iter 1700, loss: 3.929805, top_1: 0.330781, top_k: 0.582969, samples/s: 1740.330 1612837841.9773645
train: epoch 3, iter 1800, loss: 4.108269, top_1: 0.337266, top_k: 0.588750, samples/s: 1736.056 1612837856.723376
train: epoch 3, iter 1900, loss: 3.833569, top_1: 0.339375, top_k: 0.590313, samples/s: 1730.901 1612837871.513427
train: epoch 3, iter 2000, loss: 3.690098, top_1: 0.339492, top_k: 0.591953, samples/s: 1724.754 1612837886.3560984
train: epoch 3, iter 2100, loss: 3.795718, top_1: 0.339531, top_k: 0.587852, samples/s: 1745.566 1612837901.0218432
train: epoch 3, iter 2200, loss: 3.952759, top_1: 0.337930, top_k: 0.592617, samples/s: 1729.673 1612837915.8223898
train: epoch 3, iter 2300, loss: 3.949596, top_1: 0.343398, top_k: 0.593086, samples/s: 1744.939 1612837930.4932578
train: epoch 3, iter 2400, loss: 3.438365, top_1: 0.346523, top_k: 0.587852, samples/s: 1719.147 1612837945.3844178
train: epoch 3, iter 2500, loss: 3.921478, top_1: 0.343555, top_k: 0.590313, samples/s: 1724.970 1612837960.2252212
train: epoch 3, iter 2600, loss: 3.999122, top_1: 0.342891, top_k: 0.594258, samples/s: 1737.422 1612837974.9597507
train: epoch 3, iter 2700, loss: 3.765423, top_1: 0.347578, top_k: 0.592852, samples/s: 1730.673 1612837989.7517023
train: epoch 3, iter 2800, loss: 3.536399, top_1: 0.350742, top_k: 0.596797, samples/s: 1747.175 1612838004.4038954
train: epoch 3, iter 2900, loss: 3.781741, top_1: 0.344727, top_k: 0.594258, samples/s: 1724.638 1612838019.2475407
train: epoch 3, iter 3000, loss: 3.861826, top_1: 0.343555, top_k: 0.594688, samples/s: 1728.332 1612838034.059562
train: epoch 3, iter 3100, loss: 3.811278, top_1: 0.345430, top_k: 0.591719, samples/s: 1742.826 1612838048.7483585
train: epoch 3, iter 3200, loss: 3.692844, top_1: 0.345039, top_k: 0.593633, samples/s: 1733.927 1612838063.5126512
train: epoch 3, iter 3300, loss: 4.045551, top_1: 0.347969, top_k: 0.591367, samples/s: 1739.059 1612838078.2330787
train: epoch 3, iter 3400, loss: 3.668408, top_1: 0.341133, top_k: 0.590430, samples/s: 1731.022 1612838093.022087
train: epoch 3, iter 3500, loss: 3.681272, top_1: 0.343516, top_k: 0.593555, samples/s: 1740.508 1612838107.730729
train: epoch 3, iter 3600, loss: 3.865762, top_1: 0.346016, top_k: 0.599648, samples/s: 1736.195 1612838122.4753182
train: epoch 3, iter 3700, loss: 3.858821, top_1: 0.341992, top_k: 0.593906, samples/s: 1724.849 1612838137.3171353
train: epoch 3, iter 3800, loss: 3.718938, top_1: 0.349453, top_k: 0.596016, samples/s: 1743.478 1612838152.000451
train: epoch 3, iter 3900, loss: 3.757803, top_1: 0.353047, top_k: 0.600313, samples/s: 1733.483 1612838166.769396
train: epoch 3, iter 4000, loss: 3.878139, top_1: 0.346992, top_k: 0.596406, samples/s: 1734.933 1612838181.524124
train: epoch 3, iter 4100, loss: 3.676938, top_1: 0.346289, top_k: 0.598633, samples/s: 1735.366 1612838196.2759507
train: epoch 3, iter 4200, loss: 4.032241, top_1: 0.351523, top_k: 0.599492, samples/s: 1736.101 1612838211.0217474
train: epoch 3, iter 4300, loss: 3.918365, top_1: 0.347109, top_k: 0.600039, samples/s: 1722.828 1612838225.8809671
train: epoch 3, iter 4400, loss: 3.833310, top_1: 0.356406, top_k: 0.605273, samples/s: 1727.727 1612838240.6981566
train: epoch 3, iter 4500, loss: 3.819500, top_1: 0.352617, top_k: 0.604297, samples/s: 1738.147 1612838255.4264424
train: epoch 3, iter 4600, loss: 3.745728, top_1: 0.353516, top_k: 0.603398, samples/s: 1734.645 1612838270.184454
train: epoch 3, iter 4700, loss: 3.619370, top_1: 0.359492, top_k: 0.609961, samples/s: 1721.677 1612838285.0537465
train: epoch 3, iter 4800, loss: 3.591898, top_1: 0.353320, top_k: 0.602812, samples/s: 1743.966 1612838299.7329433
train: epoch 3, iter 4900, loss: 3.786335, top_1: 0.353477, top_k: 0.602852, samples/s: 1735.425 1612838314.4843497
train: epoch 3, iter 5000, loss: 3.686236, top_1: 0.357031, top_k: 0.606250, samples/s: 1737.260 1612838329.220206
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_3.
validation: epoch 3, iter 195, top_1: 0.397636, top_k: 0.664143, samples/s: 2817.556 1612838347.3995755
train: epoch 4, iter 100, loss: 3.761801, top_1: 0.362461, top_k: 0.613359, samples/s: 1743.061 1612838382.4040947
train: epoch 4, iter 200, loss: 3.791661, top_1: 0.361367, top_k: 0.611094, samples/s: 1757.227 1612838396.972597
train: epoch 4, iter 300, loss: 3.632285, top_1: 0.362578, top_k: 0.613477, samples/s: 1756.600 1612838411.5460892
train: epoch 4, iter 400, loss: 3.788066, top_1: 0.363594, top_k: 0.613008, samples/s: 1751.130 1612838426.1652164
train: epoch 4, iter 500, loss: 3.687921, top_1: 0.361406, top_k: 0.614492, samples/s: 1747.518 1612838440.8146894
train: epoch 4, iter 600, loss: 3.801113, top_1: 0.369492, top_k: 0.615938, samples/s: 1757.142 1612838455.3836884
train: epoch 4, iter 700, loss: 3.860980, top_1: 0.357734, top_k: 0.615977, samples/s: 1745.721 1612838470.0481102
train: epoch 4, iter 800, loss: 3.973006, top_1: 0.357930, top_k: 0.608711, samples/s: 1741.645 1612838484.7468262
train: epoch 4, iter 900, loss: 3.708448, top_1: 0.363047, top_k: 0.611484, samples/s: 1719.755 1612838499.6327016
train: epoch 4, iter 1000, loss: 3.863460, top_1: 0.357891, top_k: 0.612969, samples/s: 1711.815 1612838514.587574
train: epoch 4, iter 1100, loss: 3.809793, top_1: 0.361680, top_k: 0.609883, samples/s: 1728.365 1612838529.3995495
train: epoch 4, iter 1200, loss: 3.881947, top_1: 0.366914, top_k: 0.619727, samples/s: 1722.729 1612838544.2593722
train: epoch 4, iter 1300, loss: 3.699335, top_1: 0.363633, top_k: 0.610898, samples/s: 1739.808 1612838558.9736586
train: epoch 4, iter 1400, loss: 3.706356, top_1: 0.367695, top_k: 0.617031, samples/s: 1721.750 1612838573.8426163
train: epoch 4, iter 1500, loss: 3.695239, top_1: 0.363438, top_k: 0.617969, samples/s: 1723.949 1612838588.6918468
train: epoch 4, iter 1600, loss: 3.881724, top_1: 0.361953, top_k: 0.612969, samples/s: 1736.366 1612838603.4353912
train: epoch 4, iter 1700, loss: 3.690570, top_1: 0.365000, top_k: 0.621680, samples/s: 1733.082 1612838618.206657
train: epoch 4, iter 1800, loss: 3.744305, top_1: 0.364922, top_k: 0.615117, samples/s: 1728.228 1612838633.0196013
train: epoch 4, iter 1900, loss: 3.757343, top_1: 0.361563, top_k: 0.614609, samples/s: 1728.524 1612838647.8298528
train: epoch 4, iter 2000, loss: 3.667362, top_1: 0.367969, top_k: 0.620547, samples/s: 1730.754 1612838662.621074
train: epoch 4, iter 2100, loss: 3.589860, top_1: 0.368047, top_k: 0.617656, samples/s: 1724.472 1612838677.4662585
train: epoch 4, iter 2200, loss: 3.578784, top_1: 0.363828, top_k: 0.615352, samples/s: 1725.227 1612838692.3048677
train: epoch 4, iter 2300, loss: 3.792389, top_1: 0.369727, top_k: 0.622031, samples/s: 1739.438 1612838707.0222867
train: epoch 4, iter 2400, loss: 3.700736, top_1: 0.361602, top_k: 0.616250, samples/s: 1743.244 1612838721.7074971
train: epoch 4, iter 2500, loss: 3.613355, top_1: 0.365508, top_k: 0.616758, samples/s: 1717.570 1612838736.6122937
train: epoch 4, iter 2600, loss: 3.594436, top_1: 0.367773, top_k: 0.618437, samples/s: 1726.363 1612838751.4411533
train: epoch 4, iter 2700, loss: 3.680723, top_1: 0.359219, top_k: 0.611602, samples/s: 1719.577 1612838766.3285255
train: epoch 4, iter 2800, loss: 3.734321, top_1: 0.372188, top_k: 0.620820, samples/s: 1736.386 1612838781.0718532
train: epoch 4, iter 2900, loss: 3.608154, top_1: 0.367422, top_k: 0.615781, samples/s: 1738.940 1612838795.7934377
train: epoch 4, iter 3000, loss: 3.793083, top_1: 0.364844, top_k: 0.621797, samples/s: 1708.666 1612838810.7759385
train: epoch 4, iter 3100, loss: 3.559198, top_1: 0.369766, top_k: 0.622070, samples/s: 1738.873 1612838825.498071
train: epoch 4, iter 3200, loss: 3.742663, top_1: 0.369453, top_k: 0.620156, samples/s: 1736.999 1612838840.2363813
train: epoch 4, iter 3300, loss: 3.683104, top_1: 0.370000, top_k: 0.621133, samples/s: 1743.431 1612838854.919802
train: epoch 4, iter 3400, loss: 3.747406, top_1: 0.373789, top_k: 0.624062, samples/s: 1733.187 1612838869.6902797
train: epoch 4, iter 3500, loss: 3.589667, top_1: 0.373594, top_k: 0.627227, samples/s: 1717.962 1612838884.5916915
train: epoch 4, iter 3600, loss: 3.490055, top_1: 0.376289, top_k: 0.621602, samples/s: 1731.490 1612838899.3766544
train: epoch 4, iter 3700, loss: 3.904645, top_1: 0.370586, top_k: 0.623437, samples/s: 1716.885 1612838914.2874043
train: epoch 4, iter 3800, loss: 3.530823, top_1: 0.369453, top_k: 0.620703, samples/s: 1750.185 1612838928.9144104
train: epoch 4, iter 3900, loss: 3.656785, top_1: 0.372617, top_k: 0.622852, samples/s: 1726.644 1612838943.7410996
train: epoch 4, iter 4000, loss: 3.654169, top_1: 0.372266, top_k: 0.618984, samples/s: 1741.500 1612838958.4408123
train: epoch 4, iter 4100, loss: 3.644142, top_1: 0.371406, top_k: 0.621992, samples/s: 1732.749 1612838973.2149596
train: epoch 4, iter 4200, loss: 3.707423, top_1: 0.373906, top_k: 0.624687, samples/s: 1739.666 1612838987.9304955
train: epoch 4, iter 4300, loss: 3.736838, top_1: 0.373281, top_k: 0.623945, samples/s: 1725.841 1612839002.7637794
train: epoch 4, iter 4400, loss: 3.617243, top_1: 0.376328, top_k: 0.621328, samples/s: 1722.390 1612839017.6268477
train: epoch 4, iter 4500, loss: 3.591925, top_1: 0.371875, top_k: 0.625703, samples/s: 1734.915 1612839032.382672
train: epoch 4, iter 4600, loss: 3.947536, top_1: 0.368789, top_k: 0.620664, samples/s: 1725.683 1612839047.217361
train: epoch 4, iter 4700, loss: 3.676912, top_1: 0.368906, top_k: 0.629219, samples/s: 1729.505 1612839062.0193594
train: epoch 4, iter 4800, loss: 3.697399, top_1: 0.375391, top_k: 0.626563, samples/s: 1729.725 1612839076.8193154
train: epoch 4, iter 4900, loss: 3.753341, top_1: 0.376367, top_k: 0.628359, samples/s: 1726.415 1612839091.6478174
train: epoch 4, iter 5000, loss: 3.607816, top_1: 0.375898, top_k: 0.622305, samples/s: 1732.825 1612839106.4212716
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_4.
validation: epoch 4, iter 195, top_1: 0.405449, top_k: 0.669331, samples/s: 2890.158 1612839124.096669
train: epoch 5, iter 100, loss: 3.668614, top_1: 0.382305, top_k: 0.635273, samples/s: 1752.592 1612839158.900377
train: epoch 5, iter 200, loss: 3.667422, top_1: 0.377695, top_k: 0.631680, samples/s: 1754.269 1612839173.4935167
train: epoch 5, iter 300, loss: 3.557747, top_1: 0.380195, top_k: 0.634375, samples/s: 1751.757 1612839188.1071637
train: epoch 5, iter 400, loss: 3.629349, top_1: 0.382969, top_k: 0.634492, samples/s: 1764.352 1612839202.616729
train: epoch 5, iter 500, loss: 3.619938, top_1: 0.384336, top_k: 0.636914, samples/s: 1752.245 1612839217.2267
train: epoch 5, iter 600, loss: 3.616142, top_1: 0.384648, top_k: 0.633047, samples/s: 1744.872 1612839231.8981204
train: epoch 5, iter 700, loss: 3.795834, top_1: 0.385977, top_k: 0.635391, samples/s: 1743.717 1612839246.579399
train: epoch 5, iter 800, loss: 3.633048, top_1: 0.382461, top_k: 0.627891, samples/s: 1728.911 1612839261.3864603
train: epoch 5, iter 900, loss: 3.494451, top_1: 0.385391, top_k: 0.637344, samples/s: 1736.875 1612839276.1255748
train: epoch 5, iter 1000, loss: 3.700686, top_1: 0.386992, top_k: 0.634219, samples/s: 1729.399 1612839290.9284027
train: epoch 5, iter 1100, loss: 3.694344, top_1: 0.382500, top_k: 0.635898, samples/s: 1735.259 1612839305.6812477
train: epoch 5, iter 1200, loss: 3.560221, top_1: 0.384453, top_k: 0.637031, samples/s: 1724.881 1612839320.5229065
train: epoch 5, iter 1300, loss: 3.670101, top_1: 0.387734, top_k: 0.636172, samples/s: 1726.611 1612839335.3495238
train: epoch 5, iter 1400, loss: 3.667629, top_1: 0.389062, top_k: 0.640586, samples/s: 1732.550 1612839350.1254873
train: epoch 5, iter 1500, loss: 3.564554, top_1: 0.385586, top_k: 0.639375, samples/s: 1729.306 1612839364.9291768
train: epoch 5, iter 1600, loss: 3.667747, top_1: 0.381094, top_k: 0.632773, samples/s: 1733.248 1612839379.6990483
train: epoch 5, iter 1700, loss: 3.589654, top_1: 0.381953, top_k: 0.634258, samples/s: 1734.638 1612839394.457207
train: epoch 5, iter 1800, loss: 3.555145, top_1: 0.392227, top_k: 0.644297, samples/s: 1727.417 1612839409.277083
train: epoch 5, iter 1900, loss: 3.546389, top_1: 0.388828, top_k: 0.640234, samples/s: 1721.940 1612839424.1439626
train: epoch 5, iter 2000, loss: 3.700344, top_1: 0.388789, top_k: 0.638047, samples/s: 1736.958 1612839438.8824587
train: epoch 5, iter 2100, loss: 3.378906, top_1: 0.387656, top_k: 0.640352, samples/s: 1734.504 1612839453.6416821
train: epoch 5, iter 2200, loss: 3.643750, top_1: 0.389844, top_k: 0.640156, samples/s: 1725.453 1612839468.4782803
train: epoch 5, iter 2300, loss: 3.641333, top_1: 0.389414, top_k: 0.641016, samples/s: 1716.896 1612839483.3889031
train: epoch 5, iter 2400, loss: 3.632234, top_1: 0.386250, top_k: 0.639492, samples/s: 1732.037 1612839498.1692271
train: epoch 5, iter 2500, loss: 3.565723, top_1: 0.395078, top_k: 0.646875, samples/s: 1733.809 1612839512.9343636
train: epoch 5, iter 2600, loss: 3.624593, top_1: 0.394531, top_k: 0.644180, samples/s: 1742.848 1612839527.6230233
train: epoch 5, iter 2700, loss: 3.891376, top_1: 0.390352, top_k: 0.637305, samples/s: 1724.200 1612839542.4704251
train: epoch 5, iter 2800, loss: 3.757705, top_1: 0.390977, top_k: 0.641367, samples/s: 1728.353 1612839557.2822104
train: epoch 5, iter 2900, loss: 3.558229, top_1: 0.392305, top_k: 0.642109, samples/s: 1731.250 1612839572.0692606
train: epoch 5, iter 3000, loss: 3.570482, top_1: 0.394180, top_k: 0.641602, samples/s: 1742.351 1612839586.761994
train: epoch 5, iter 3100, loss: 3.763938, top_1: 0.389023, top_k: 0.638633, samples/s: 1728.686 1612839601.571041
train: epoch 5, iter 3200, loss: 3.574423, top_1: 0.392891, top_k: 0.642266, samples/s: 1737.360 1612839616.3059669
train: epoch 5, iter 3300, loss: 3.722408, top_1: 0.388125, top_k: 0.641680, samples/s: 1724.900 1612839631.1473827
train: epoch 5, iter 3400, loss: 3.556504, top_1: 0.390430, top_k: 0.643867, samples/s: 1739.005 1612839645.868505
train: epoch 5, iter 3500, loss: 3.536077, top_1: 0.394570, top_k: 0.643984, samples/s: 1726.848 1612839660.6932154
train: epoch 5, iter 3600, loss: 3.578431, top_1: 0.393867, top_k: 0.644844, samples/s: 1735.310 1612839675.4455514
train: epoch 5, iter 3700, loss: 3.572760, top_1: 0.394453, top_k: 0.643711, samples/s: 1728.586 1612839690.2553952
train: epoch 5, iter 3800, loss: 3.539623, top_1: 0.398008, top_k: 0.648242, samples/s: 1737.564 1612839704.9886217
train: epoch 5, iter 3900, loss: 3.633920, top_1: 0.394609, top_k: 0.641445, samples/s: 1725.402 1612839719.8257396
train: epoch 5, iter 4000, loss: 3.470183, top_1: 0.391836, top_k: 0.643359, samples/s: 1721.761 1612839734.694263
train: epoch 5, iter 4100, loss: 3.544508, top_1: 0.395625, top_k: 0.644570, samples/s: 1727.028 1612839749.5174165
train: epoch 5, iter 4200, loss: 3.570740, top_1: 0.394961, top_k: 0.646211, samples/s: 1731.475 1612839764.30252
train: epoch 5, iter 4300, loss: 3.542905, top_1: 0.394453, top_k: 0.646250, samples/s: 1726.218 1612839779.132583
train: epoch 5, iter 4400, loss: 3.475978, top_1: 0.393359, top_k: 0.644141, samples/s: 1725.628 1612839793.967822
train: epoch 5, iter 4500, loss: 3.620641, top_1: 0.395273, top_k: 0.646875, samples/s: 1732.385 1612839808.7451417
train: epoch 5, iter 4600, loss: 3.600945, top_1: 0.399102, top_k: 0.653516, samples/s: 1733.437 1612839823.5134788
train: epoch 5, iter 4700, loss: 3.648945, top_1: 0.401445, top_k: 0.652813, samples/s: 1729.377 1612839838.3164728
train: epoch 5, iter 4800, loss: 3.507953, top_1: 0.399766, top_k: 0.651602, samples/s: 1716.736 1612839853.2284975
train: epoch 5, iter 4900, loss: 3.565279, top_1: 0.394805, top_k: 0.646016, samples/s: 1727.577 1612839868.0468974
train: epoch 5, iter 5000, loss: 3.518883, top_1: 0.401094, top_k: 0.652578, samples/s: 1739.470 1612839882.7640617
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_5.
validation: epoch 5, iter 195, top_1: 0.430308, top_k: 0.699980, samples/s: 2876.351 1612839900.5150807
train: epoch 6, iter 100, loss: 3.599499, top_1: 0.405742, top_k: 0.655664, samples/s: 1759.204 1612839935.3877776
train: epoch 6, iter 200, loss: 3.519357, top_1: 0.407422, top_k: 0.656289, samples/s: 1763.684 1612839949.9028695
train: epoch 6, iter 300, loss: 3.766019, top_1: 0.404570, top_k: 0.653008, samples/s: 1741.897 1612839964.5995128
train: epoch 6, iter 400, loss: 3.571636, top_1: 0.405039, top_k: 0.655078, samples/s: 1764.563 1612839979.1073482
train: epoch 6, iter 500, loss: 3.515404, top_1: 0.400273, top_k: 0.648203, samples/s: 1758.510 1612839993.6652067
train: epoch 6, iter 600, loss: 3.520248, top_1: 0.405195, top_k: 0.654297, samples/s: 1746.431 1612840008.3235605
train: epoch 6, iter 700, loss: 3.998290, top_1: 0.352031, top_k: 0.597461, samples/s: 1715.702 1612840023.2445548
train: epoch 6, iter 800, loss: 3.664222, top_1: 0.368086, top_k: 0.618477, samples/s: 1738.146 1612840037.9729323
train: epoch 6, iter 900, loss: 3.493632, top_1: 0.384727, top_k: 0.636953, samples/s: 1732.143 1612840052.7523527
train: epoch 6, iter 1000, loss: 3.573652, top_1: 0.394453, top_k: 0.642578, samples/s: 1737.177 1612840067.4888124
train: epoch 6, iter 1100, loss: 3.608173, top_1: 0.390391, top_k: 0.640664, samples/s: 1729.092 1612840082.2942698
train: epoch 6, iter 1200, loss: 3.713226, top_1: 0.394414, top_k: 0.645078, samples/s: 1743.024 1612840096.9813774
train: epoch 6, iter 1300, loss: 3.453914, top_1: 0.398984, top_k: 0.646563, samples/s: 1733.879 1612840111.746048
train: epoch 6, iter 1400, loss: 3.470836, top_1: 0.402852, top_k: 0.655273, samples/s: 1737.509 1612840126.4797177
train: epoch 6, iter 1500, loss: 3.468327, top_1: 0.399375, top_k: 0.646211, samples/s: 1739.950 1612840141.1928117
train: epoch 6, iter 1600, loss: 3.756485, top_1: 0.399805, top_k: 0.649844, samples/s: 1735.918 1612840155.9400065
train: epoch 6, iter 1700, loss: 3.601808, top_1: 0.396797, top_k: 0.646797, samples/s: 1736.528 1612840170.6820686
train: epoch 6, iter 1800, loss: 3.497584, top_1: 0.403359, top_k: 0.649531, samples/s: 1727.754 1612840185.498985
train: epoch 6, iter 1900, loss: 3.481787, top_1: 0.405273, top_k: 0.652070, samples/s: 1740.956 1612840200.2035913
train: epoch 6, iter 2000, loss: 3.517737, top_1: 0.405977, top_k: 0.654609, samples/s: 1727.762 1612840215.0205226
train: epoch 6, iter 2100, loss: 3.709075, top_1: 0.404766, top_k: 0.653125, samples/s: 1733.289 1612840229.7900155
train: epoch 6, iter 2200, loss: 3.448904, top_1: 0.402969, top_k: 0.653672, samples/s: 1738.787 1612840244.5130303
train: epoch 6, iter 2300, loss: 3.696244, top_1: 0.401914, top_k: 0.653477, samples/s: 1733.566 1612840259.2802603
train: epoch 6, iter 2400, loss: 3.751715, top_1: 0.405547, top_k: 0.658516, samples/s: 1736.542 1612840274.0222065
train: epoch 6, iter 2500, loss: 3.515599, top_1: 0.406328, top_k: 0.656953, samples/s: 1732.086 1612840288.802013
train: epoch 6, iter 2600, loss: 3.495626, top_1: 0.403672, top_k: 0.653984, samples/s: 1724.780 1612840303.6444664
train: epoch 6, iter 2700, loss: 3.534669, top_1: 0.406367, top_k: 0.658086, samples/s: 1729.213 1612840318.4489594
train: epoch 6, iter 2800, loss: 3.492878, top_1: 0.408750, top_k: 0.660391, samples/s: 1738.469 1612840333.174526
train: epoch 6, iter 2900, loss: 3.672162, top_1: 0.409062, top_k: 0.660312, samples/s: 1726.117 1612840348.005477
train: epoch 6, iter 3000, loss: 3.536662, top_1: 0.410859, top_k: 0.656641, samples/s: 1739.041 1612840362.7263253
train: epoch 6, iter 3100, loss: 3.618275, top_1: 0.409648, top_k: 0.656211, samples/s: 1734.909 1612840377.4820516
train: epoch 6, iter 3200, loss: 3.510134, top_1: 0.410117, top_k: 0.657695, samples/s: 1731.367 1612840392.268092
train: epoch 6, iter 3300, loss: 3.416340, top_1: 0.406250, top_k: 0.656875, samples/s: 1732.250 1612840407.0465772
train: epoch 6, iter 3400, loss: 3.520274, top_1: 0.410234, top_k: 0.661875, samples/s: 1748.829 1612840421.6848722
train: epoch 6, iter 3500, loss: 3.577801, top_1: 0.412187, top_k: 0.658398, samples/s: 1732.788 1612840436.4587646
train: epoch 6, iter 3600, loss: 3.654007, top_1: 0.415195, top_k: 0.661797, samples/s: 1715.498 1612840451.3815234
train: epoch 6, iter 3700, loss: 3.494637, top_1: 0.408672, top_k: 0.661992, samples/s: 1741.129 1612840466.0846329
train: epoch 6, iter 3800, loss: 3.453072, top_1: 0.413047, top_k: 0.660937, samples/s: 1727.566 1612840480.9032934
train: epoch 6, iter 3900, loss: 3.537088, top_1: 0.414023, top_k: 0.658828, samples/s: 1738.216 1612840495.6309135
train: epoch 6, iter 4000, loss: 3.590237, top_1: 0.412656, top_k: 0.657305, samples/s: 1731.748 1612840510.413686
train: epoch 6, iter 4100, loss: 3.422713, top_1: 0.415273, top_k: 0.666367, samples/s: 1738.793 1612840525.1365173
train: epoch 6, iter 4200, loss: 3.423296, top_1: 0.405664, top_k: 0.659492, samples/s: 1739.130 1612840539.8565488
train: epoch 6, iter 4300, loss: 3.525260, top_1: 0.420039, top_k: 0.664883, samples/s: 1719.492 1612840554.7446668
train: epoch 6, iter 4400, loss: 3.471859, top_1: 0.413125, top_k: 0.661680, samples/s: 1738.203 1612840569.4725907
train: epoch 6, iter 4500, loss: 3.656153, top_1: 0.411758, top_k: 0.666445, samples/s: 1728.347 1612840584.2844374
train: epoch 6, iter 4600, loss: 3.669723, top_1: 0.409961, top_k: 0.660781, samples/s: 1741.559 1612840598.9838235
train: epoch 6, iter 4700, loss: 3.486500, top_1: 0.413320, top_k: 0.669063, samples/s: 1733.259 1612840613.7537005
train: epoch 6, iter 4800, loss: 3.598842, top_1: 0.409297, top_k: 0.658945, samples/s: 1733.245 1612840628.5237348
train: epoch 6, iter 4900, loss: 3.753312, top_1: 0.416914, top_k: 0.669961, samples/s: 1737.580 1612840643.2568715
train: epoch 6, iter 5000, loss: 3.390889, top_1: 0.405977, top_k: 0.666797, samples/s: 1728.340 1612840658.0687313
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_6.
validation: epoch 6, iter 195, top_1: 0.440805, top_k: 0.708634, samples/s: 2832.209 1612840676.1205986
train: epoch 7, iter 100, loss: 3.283700, top_1: 0.418398, top_k: 0.671016, samples/s: 1758.053 1612840711.4937956
train: epoch 7, iter 200, loss: 3.392720, top_1: 0.418906, top_k: 0.667813, samples/s: 1749.760 1612840726.1245875
train: epoch 7, iter 300, loss: 3.481457, top_1: 0.415625, top_k: 0.663203, samples/s: 1761.582 1612840740.6566713
train: epoch 7, iter 400, loss: 3.489793, top_1: 0.423242, top_k: 0.667109, samples/s: 1752.859 1612840755.2614455
train: epoch 7, iter 500, loss: 3.489700, top_1: 0.419336, top_k: 0.667695, samples/s: 1758.100 1612840769.8225722
train: epoch 7, iter 600, loss: 3.529412, top_1: 0.424883, top_k: 0.669102, samples/s: 1749.590 1612840784.4546301
train: epoch 7, iter 700, loss: 3.671044, top_1: 0.411680, top_k: 0.662344, samples/s: 1756.759 1612840799.026815
train: epoch 7, iter 800, loss: 3.300290, top_1: 0.414414, top_k: 0.666641, samples/s: 1726.892 1612840813.8511345
train: epoch 7, iter 900, loss: 3.533933, top_1: 0.421172, top_k: 0.670859, samples/s: 1740.173 1612840828.562318
train: epoch 7, iter 1000, loss: 3.628164, top_1: 0.422187, top_k: 0.669727, samples/s: 1740.114 1612840843.2741055
train: epoch 7, iter 1100, loss: 3.361350, top_1: 0.416523, top_k: 0.667461, samples/s: 1735.980 1612840858.020777
train: epoch 7, iter 1200, loss: 3.703586, top_1: 0.418281, top_k: 0.669766, samples/s: 1738.410 1612840872.746865
train: epoch 7, iter 1300, loss: 3.315303, top_1: 0.424531, top_k: 0.672422, samples/s: 1726.782 1612840887.572112
train: epoch 7, iter 1400, loss: 3.607530, top_1: 0.419727, top_k: 0.672344, samples/s: 1729.085 1612840902.3776708
train: epoch 7, iter 1500, loss: 3.515897, top_1: 0.415742, top_k: 0.664805, samples/s: 1748.279 1612840917.0206156
train: epoch 7, iter 1600, loss: 3.332811, top_1: 0.420469, top_k: 0.674648, samples/s: 1741.238 1612840931.7227755
train: epoch 7, iter 1700, loss: 3.429908, top_1: 0.421055, top_k: 0.672109, samples/s: 1742.533 1612840946.4140215
train: epoch 7, iter 1800, loss: 3.234388, top_1: 0.420312, top_k: 0.670547, samples/s: 1746.311 1612840961.0735548
train: epoch 7, iter 1900, loss: 3.784362, top_1: 0.418320, top_k: 0.670234, samples/s: 1739.054 1612840975.7941332
train: epoch 7, iter 2000, loss: 3.412559, top_1: 0.420312, top_k: 0.673984, samples/s: 1726.080 1612840990.6254387
train: epoch 7, iter 2100, loss: 3.361864, top_1: 0.420664, top_k: 0.671250, samples/s: 1750.305 1612841005.2515042
train: epoch 7, iter 2200, loss: 3.255335, top_1: 0.425742, top_k: 0.670977, samples/s: 1732.017 1612841020.0320156
train: epoch 7, iter 2300, loss: 3.377651, top_1: 0.423945, top_k: 0.668242, samples/s: 1744.920 1612841034.7030597
train: epoch 7, iter 2400, loss: 3.368491, top_1: 0.421094, top_k: 0.669102, samples/s: 1738.568 1612841049.427862
train: epoch 7, iter 2500, loss: 3.576797, top_1: 0.418359, top_k: 0.665977, samples/s: 1715.846 1612841064.347692
train: epoch 7, iter 2600, loss: 3.547302, top_1: 0.427227, top_k: 0.675039, samples/s: 1750.872 1612841078.9688742
train: epoch 7, iter 2700, loss: 3.433468, top_1: 0.425195, top_k: 0.672734, samples/s: 1743.847 1612841093.6490579
train: epoch 7, iter 2800, loss: 3.295043, top_1: 0.424063, top_k: 0.669492, samples/s: 1736.218 1612841108.3937528
train: epoch 7, iter 2900, loss: 3.451277, top_1: 0.420820, top_k: 0.670977, samples/s: 1730.549 1612841123.1868205
train: epoch 7, iter 3000, loss: 3.640721, top_1: 0.423984, top_k: 0.673281, samples/s: 1747.316 1612841137.8378336
train: epoch 7, iter 3100, loss: 3.592399, top_1: 0.422383, top_k: 0.674492, samples/s: 1740.020 1612841152.5502882
train: epoch 7, iter 3200, loss: 3.529763, top_1: 0.424531, top_k: 0.674492, samples/s: 1730.845 1612841167.3407168
train: epoch 7, iter 3300, loss: 3.376346, top_1: 0.423281, top_k: 0.673438, samples/s: 1748.354 1612841181.9830713
train: epoch 7, iter 3400, loss: 3.546787, top_1: 0.422187, top_k: 0.674570, samples/s: 1741.862 1612841196.6799812
train: epoch 7, iter 3500, loss: 3.543380, top_1: 0.424727, top_k: 0.673945, samples/s: 1730.988 1612841211.469221
train: epoch 7, iter 3600, loss: 3.644165, top_1: 0.421523, top_k: 0.672734, samples/s: 1754.599 1612841226.0594466
train: epoch 7, iter 3700, loss: 3.561628, top_1: 0.422891, top_k: 0.673516, samples/s: 1731.845 1612841240.8413675
train: epoch 7, iter 3800, loss: 3.453351, top_1: 0.423398, top_k: 0.670625, samples/s: 1744.406 1612841255.5168583
train: epoch 7, iter 3900, loss: 3.380420, top_1: 0.422656, top_k: 0.672539, samples/s: 1736.546 1612841270.2588313
train: epoch 7, iter 4000, loss: 3.585854, top_1: 0.429258, top_k: 0.676797, samples/s: 1737.736 1612841284.990644
train: epoch 7, iter 4100, loss: 3.191020, top_1: 0.427773, top_k: 0.673594, samples/s: 1743.021 1612841299.6777651
train: epoch 7, iter 4200, loss: 3.253678, top_1: 0.424648, top_k: 0.667266, samples/s: 1743.663 1612841314.3594701
train: epoch 7, iter 4300, loss: 3.460583, top_1: 0.425547, top_k: 0.678594, samples/s: 1747.403 1612841329.0098364
train: epoch 7, iter 4400, loss: 3.229561, top_1: 0.427461, top_k: 0.676328, samples/s: 1734.851 1612841343.7661421
train: epoch 7, iter 4500, loss: 3.365956, top_1: 0.420078, top_k: 0.669570, samples/s: 1740.843 1612841358.4716353
train: epoch 7, iter 4600, loss: 3.660536, top_1: 0.426289, top_k: 0.672148, samples/s: 1737.987 1612841373.2012892
train: epoch 7, iter 4700, loss: 3.527839, top_1: 0.428516, top_k: 0.676406, samples/s: 1722.544 1612841388.063114
train: epoch 7, iter 4800, loss: 3.440839, top_1: 0.426836, top_k: 0.677188, samples/s: 1764.125 1612841402.5745103
train: epoch 7, iter 4900, loss: 3.453465, top_1: 0.429336, top_k: 0.681680, samples/s: 1738.522 1612841417.2996335
train: epoch 7, iter 5000, loss: 3.328176, top_1: 0.424531, top_k: 0.671953, samples/s: 1739.718 1612841432.014671
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_7.
validation: epoch 7, iter 195, top_1: 0.460477, top_k: 0.721474, samples/s: 2741.573 1612841450.6600144
train: epoch 8, iter 100, loss: 3.564341, top_1: 0.437500, top_k: 0.684414, samples/s: 1750.884 1612841485.3330908
train: epoch 8, iter 200, loss: 3.351145, top_1: 0.436367, top_k: 0.688672, samples/s: 1752.728 1612841499.9390821
train: epoch 8, iter 300, loss: 3.533471, top_1: 0.428438, top_k: 0.676953, samples/s: 1759.503 1612841514.4886198
train: epoch 8, iter 400, loss: 3.389900, top_1: 0.432852, top_k: 0.677188, samples/s: 1757.723 1612841529.052739
train: epoch 8, iter 500, loss: 3.436994, top_1: 0.429063, top_k: 0.680391, samples/s: 1744.391 1612841543.728435
train: epoch 8, iter 600, loss: 3.493007, top_1: 0.428359, top_k: 0.681602, samples/s: 1766.301 1612841558.2219284
train: epoch 8, iter 700, loss: 3.508740, top_1: 0.431367, top_k: 0.681328, samples/s: 1750.867 1612841572.843299
train: epoch 8, iter 800, loss: 3.475667, top_1: 0.435625, top_k: 0.683359, samples/s: 1754.127 1612841587.4374583
train: epoch 8, iter 900, loss: 3.450080, top_1: 0.429727, top_k: 0.681602, samples/s: 1748.056 1612841602.082231
train: epoch 8, iter 1000, loss: 3.250949, top_1: 0.429492, top_k: 0.683359, samples/s: 1730.475 1612841616.8758848
train: epoch 8, iter 1100, loss: 3.463782, top_1: 0.429805, top_k: 0.679141, samples/s: 1732.993 1612841631.6479971
train: epoch 8, iter 1200, loss: 3.439669, top_1: 0.429883, top_k: 0.681953, samples/s: 1748.051 1612841646.2929552
train: epoch 8, iter 1300, loss: 3.494121, top_1: 0.433477, top_k: 0.677109, samples/s: 1745.086 1612841660.9626875
train: epoch 8, iter 1400, loss: 3.534874, top_1: 0.434258, top_k: 0.680508, samples/s: 1744.925 1612841675.633784
train: epoch 8, iter 1500, loss: 3.389555, top_1: 0.430117, top_k: 0.680469, samples/s: 1749.875 1612841690.2634084
train: epoch 8, iter 1600, loss: 3.566735, top_1: 0.426914, top_k: 0.677578, samples/s: 1739.419 1612841704.9809504
train: epoch 8, iter 1700, loss: 3.386867, top_1: 0.434453, top_k: 0.685820, samples/s: 1745.004 1612841719.6514082
train: epoch 8, iter 1800, loss: 3.432225, top_1: 0.429297, top_k: 0.679063, samples/s: 1724.040 1612841734.500806
train: epoch 8, iter 1900, loss: 3.532664, top_1: 0.431016, top_k: 0.679922, samples/s: 1750.951 1612841749.1208549
train: epoch 8, iter 2000, loss: 3.269389, top_1: 0.437383, top_k: 0.683477, samples/s: 1746.865 1612841763.7756808
train: epoch 8, iter 2100, loss: 3.333016, top_1: 0.431328, top_k: 0.681445, samples/s: 1738.523 1612841778.5012524
train: epoch 8, iter 2200, loss: 3.435410, top_1: 0.435859, top_k: 0.679883, samples/s: 1743.588 1612841793.1832504
train: epoch 8, iter 2300, loss: 3.065285, top_1: 0.429414, top_k: 0.679414, samples/s: 1743.465 1612841807.866658
train: epoch 8, iter 2400, loss: 3.333467, top_1: 0.436367, top_k: 0.686172, samples/s: 1736.874 1612841822.6057758
train: epoch 8, iter 2500, loss: 3.325195, top_1: 0.432500, top_k: 0.679297, samples/s: 1745.429 1612841837.2726204
train: epoch 8, iter 2600, loss: 3.532711, top_1: 0.434883, top_k: 0.681250, samples/s: 1731.675 1612841852.0560243
train: epoch 8, iter 2700, loss: 3.442567, top_1: 0.440703, top_k: 0.684102, samples/s: 1749.416 1612841866.6894324
train: epoch 8, iter 2800, loss: 3.410414, top_1: 0.436172, top_k: 0.684688, samples/s: 1732.792 1612841881.4633784
train: epoch 8, iter 2900, loss: 3.253010, top_1: 0.436016, top_k: 0.686523, samples/s: 1742.820 1612841896.1521368
train: epoch 8, iter 3000, loss: 3.535085, top_1: 0.430977, top_k: 0.681133, samples/s: 1741.124 1612841910.8552964
train: epoch 8, iter 3100, loss: 3.376559, top_1: 0.430469, top_k: 0.680430, samples/s: 1739.985 1612841925.5680518
train: epoch 8, iter 3200, loss: 3.328331, top_1: 0.435977, top_k: 0.686562, samples/s: 1735.304 1612841940.3205616
train: epoch 8, iter 3300, loss: 3.346860, top_1: 0.437383, top_k: 0.684180, samples/s: 1743.953 1612841954.9998424
train: epoch 8, iter 3400, loss: 3.468309, top_1: 0.433242, top_k: 0.682578, samples/s: 1734.864 1612841969.7559934
train: epoch 8, iter 3500, loss: 3.350196, top_1: 0.434219, top_k: 0.682461, samples/s: 1742.107 1612841984.450876
train: epoch 8, iter 3600, loss: 3.370292, top_1: 0.431172, top_k: 0.683359, samples/s: 1745.676 1612841999.1157043
train: epoch 8, iter 3700, loss: 3.448639, top_1: 0.432617, top_k: 0.682461, samples/s: 1745.914 1612842013.7785077
train: epoch 8, iter 3800, loss: 3.251133, top_1: 0.436641, top_k: 0.684922, samples/s: 1733.724 1612842028.5445597
train: epoch 8, iter 3900, loss: 3.500137, top_1: 0.433711, top_k: 0.683008, samples/s: 1755.010 1612842043.1311798
train: epoch 8, iter 4000, loss: 3.334952, top_1: 0.437695, top_k: 0.681367, samples/s: 1745.651 1612842057.7962272
train: epoch 8, iter 4100, loss: 3.427233, top_1: 0.438711, top_k: 0.684453, samples/s: 1747.703 1612842072.443972
train: epoch 8, iter 4200, loss: 3.311902, top_1: 0.433359, top_k: 0.683359, samples/s: 1727.319 1612842087.2646248
train: epoch 8, iter 4300, loss: 3.311703, top_1: 0.431445, top_k: 0.683867, samples/s: 1744.173 1612842101.9421153
train: epoch 8, iter 4400, loss: 3.214407, top_1: 0.434336, top_k: 0.679336, samples/s: 1742.145 1612842116.6366265
train: epoch 8, iter 4500, loss: 3.323030, top_1: 0.437539, top_k: 0.686016, samples/s: 1731.254 1612842131.4235919
train: epoch 8, iter 4600, loss: 3.219629, top_1: 0.434727, top_k: 0.682461, samples/s: 1758.923 1612842145.9779985
train: epoch 8, iter 4700, loss: 3.397865, top_1: 0.440781, top_k: 0.689648, samples/s: 1745.117 1612842160.647526
train: epoch 8, iter 4800, loss: 3.494070, top_1: 0.436484, top_k: 0.686367, samples/s: 1738.302 1612842175.3744504
train: epoch 8, iter 4900, loss: 3.316918, top_1: 0.440820, top_k: 0.683828, samples/s: 1740.738 1612842190.080845
train: epoch 8, iter 5000, loss: 3.353011, top_1: 0.438633, top_k: 0.683672, samples/s: 1755.174 1612842204.666412
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_8.
validation: epoch 8, iter 195, top_1: 0.468990, top_k: 0.725621, samples/s: 2800.247 1612842222.9224508
train: epoch 9, iter 100, loss: 3.273304, top_1: 0.450781, top_k: 0.695039, samples/s: 1728.850 1612842258.6820316
train: epoch 9, iter 200, loss: 3.340853, top_1: 0.446523, top_k: 0.691133, samples/s: 1760.425 1612842273.2238958
train: epoch 9, iter 300, loss: 3.283046, top_1: 0.448711, top_k: 0.694648, samples/s: 1754.108 1612842287.8182876
train: epoch 9, iter 400, loss: 3.514160, top_1: 0.442227, top_k: 0.690273, samples/s: 1755.291 1612842302.402783
train: epoch 9, iter 500, loss: 3.304629, top_1: 0.444063, top_k: 0.691289, samples/s: 1760.729 1612842316.9422483
train: epoch 9, iter 600, loss: 3.305920, top_1: 0.442773, top_k: 0.686953, samples/s: 1761.539 1612842331.474943
train: epoch 9, iter 700, loss: 3.186405, top_1: 0.440430, top_k: 0.688438, samples/s: 1750.481 1612842346.0994802
train: epoch 9, iter 800, loss: 3.368753, top_1: 0.444844, top_k: 0.692187, samples/s: 1745.844 1612842360.7628455
train: epoch 9, iter 900, loss: 3.396432, top_1: 0.440430, top_k: 0.686211, samples/s: 1762.441 1612842375.2882025
train: epoch 9, iter 1000, loss: 3.299801, top_1: 0.446992, top_k: 0.689141, samples/s: 1735.801 1612842390.0364068
train: epoch 9, iter 1100, loss: 3.386106, top_1: 0.441484, top_k: 0.688516, samples/s: 1737.528 1612842404.7699413
train: epoch 9, iter 1200, loss: 3.319382, top_1: 0.441680, top_k: 0.689883, samples/s: 1743.726 1612842419.4511833
train: epoch 9, iter 1300, loss: 3.240330, top_1: 0.434453, top_k: 0.683008, samples/s: 1736.274 1612842434.1954668
train: epoch 9, iter 1400, loss: 3.323934, top_1: 0.444922, top_k: 0.691992, samples/s: 1747.324 1612842448.8463676
train: epoch 9, iter 1500, loss: 3.223668, top_1: 0.446289, top_k: 0.693047, samples/s: 1739.171 1612842463.566122
train: epoch 9, iter 1600, loss: 3.267186, top_1: 0.438867, top_k: 0.688555, samples/s: 1747.367 1612842478.2166092
train: epoch 9, iter 1700, loss: 3.372778, top_1: 0.441523, top_k: 0.689219, samples/s: 1745.869 1612842492.879798
train: epoch 9, iter 1800, loss: 3.223272, top_1: 0.440781, top_k: 0.688203, samples/s: 1732.709 1612842507.6544032
train: epoch 9, iter 1900, loss: 3.470333, top_1: 0.442188, top_k: 0.689766, samples/s: 1740.519 1612842522.362625
train: epoch 9, iter 2000, loss: 3.464277, top_1: 0.438633, top_k: 0.684258, samples/s: 1737.788 1612842537.0940447
train: epoch 9, iter 2100, loss: 3.440488, top_1: 0.448398, top_k: 0.691953, samples/s: 1728.594 1612842551.9037564
train: epoch 9, iter 2200, loss: 3.438310, top_1: 0.438984, top_k: 0.685977, samples/s: 1753.609 1612842566.5021596
train: epoch 9, iter 2300, loss: 3.308467, top_1: 0.441992, top_k: 0.692109, samples/s: 1745.406 1612842581.169305
train: epoch 9, iter 2400, loss: 3.395582, top_1: 0.441719, top_k: 0.688008, samples/s: 1731.346 1612842595.9554882
train: epoch 9, iter 2500, loss: 3.271782, top_1: 0.445391, top_k: 0.688789, samples/s: 1742.253 1612842610.6491327
train: epoch 9, iter 2600, loss: 3.220602, top_1: 0.442227, top_k: 0.692227, samples/s: 1746.690 1612842625.305367
train: epoch 9, iter 2700, loss: 3.382992, top_1: 0.441563, top_k: 0.689648, samples/s: 1737.704 1612842640.03748
train: epoch 9, iter 2800, loss: 3.314070, top_1: 0.434492, top_k: 0.687187, samples/s: 1744.326 1612842654.7135587
train: epoch 9, iter 2900, loss: 3.374274, top_1: 0.437344, top_k: 0.689258, samples/s: 1743.178 1612842669.3994687
train: epoch 9, iter 3000, loss: 3.359661, top_1: 0.440234, top_k: 0.688594, samples/s: 1744.441 1612842684.0746446
train: epoch 9, iter 3100, loss: 3.523487, top_1: 0.439492, top_k: 0.688828, samples/s: 1733.010 1612842698.8466244
train: epoch 9, iter 3200, loss: 3.326488, top_1: 0.445859, top_k: 0.690937, samples/s: 1735.482 1612842713.5975313
train: epoch 9, iter 3300, loss: 3.297319, top_1: 0.445000, top_k: 0.688086, samples/s: 1731.428 1612842728.3830235
train: epoch 9, iter 3400, loss: 3.371478, top_1: 0.441563, top_k: 0.691172, samples/s: 1762.148 1612842742.9107957
train: epoch 9, iter 3500, loss: 3.291065, top_1: 0.443164, top_k: 0.690352, samples/s: 1733.037 1612842757.6825213
train: epoch 9, iter 3600, loss: 3.517365, top_1: 0.446719, top_k: 0.695312, samples/s: 1736.368 1612842772.425977
train: epoch 9, iter 3700, loss: 3.300069, top_1: 0.445703, top_k: 0.694922, samples/s: 1738.218 1612842787.1536252
train: epoch 9, iter 3800, loss: 3.420256, top_1: 0.441719, top_k: 0.693086, samples/s: 1747.168 1612842801.8059437
train: epoch 9, iter 3900, loss: 3.287991, top_1: 0.447695, top_k: 0.692930, samples/s: 1729.249 1612842816.6100225
train: epoch 9, iter 4000, loss: 3.084612, top_1: 0.443789, top_k: 0.688711, samples/s: 1753.805 1612842831.2068827
train: epoch 9, iter 4100, loss: 3.272426, top_1: 0.445234, top_k: 0.688984, samples/s: 1732.097 1612842845.986627
train: epoch 9, iter 4200, loss: 3.266969, top_1: 0.446914, top_k: 0.692891, samples/s: 1736.684 1612842860.7274103
train: epoch 9, iter 4300, loss: 3.233934, top_1: 0.439648, top_k: 0.686797, samples/s: 1739.643 1612842875.443082
train: epoch 9, iter 4400, loss: 3.709918, top_1: 0.449570, top_k: 0.693203, samples/s: 1743.972 1612842890.1221836
train: epoch 9, iter 4500, loss: 3.320282, top_1: 0.442734, top_k: 0.691797, samples/s: 1748.847 1612842904.7604513
train: epoch 9, iter 4600, loss: 3.231531, top_1: 0.443320, top_k: 0.690352, samples/s: 1722.341 1612842919.6238673
train: epoch 9, iter 4700, loss: 3.240503, top_1: 0.443867, top_k: 0.690469, samples/s: 1744.570 1612842934.2980707
train: epoch 9, iter 4800, loss: 3.514438, top_1: 0.449258, top_k: 0.694609, samples/s: 1738.761 1612842949.021092
train: epoch 9, iter 4900, loss: 3.368673, top_1: 0.441758, top_k: 0.688750, samples/s: 1746.967 1612842963.6750636
train: epoch 9, iter 5000, loss: 3.335644, top_1: 0.446289, top_k: 0.696641, samples/s: 1736.319 1612842978.4189236
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_9.
validation: epoch 9, iter 195, top_1: 0.484075, top_k: 0.739583, samples/s: 2843.504 1612842996.4306178
train: epoch 10, iter 100, loss: 3.489684, top_1: 0.455078, top_k: 0.702656, samples/s: 1754.927 1612843036.9899545
train: epoch 10, iter 200, loss: 3.409976, top_1: 0.451250, top_k: 0.698164, samples/s: 1747.883 1612843051.6362085
train: epoch 10, iter 300, loss: 3.245552, top_1: 0.449922, top_k: 0.693477, samples/s: 1771.259 1612843066.0894046
train: epoch 10, iter 400, loss: 3.355167, top_1: 0.448437, top_k: 0.698672, samples/s: 1757.845 1612843080.6524827
train: epoch 10, iter 500, loss: 3.431387, top_1: 0.448945, top_k: 0.696211, samples/s: 1743.396 1612843095.3364398
train: epoch 10, iter 600, loss: 3.463978, top_1: 0.452930, top_k: 0.700000, samples/s: 1767.974 1612843109.8163373
train: epoch 10, iter 700, loss: 3.333225, top_1: 0.451445, top_k: 0.696875, samples/s: 1741.336 1612843124.5176718
train: epoch 10, iter 800, loss: 3.316651, top_1: 0.457070, top_k: 0.700391, samples/s: 1757.029 1612843139.0876696
train: epoch 10, iter 900, loss: 3.152232, top_1: 0.455430, top_k: 0.699297, samples/s: 1747.236 1612843153.7395024
train: epoch 10, iter 1000, loss: 3.390542, top_1: 0.449609, top_k: 0.697109, samples/s: 1740.346 1612843168.449122
train: epoch 10, iter 1100, loss: 3.375411, top_1: 0.446016, top_k: 0.695664, samples/s: 1742.419 1612843183.1414413
train: epoch 10, iter 1200, loss: 3.369951, top_1: 0.450117, top_k: 0.698438, samples/s: 1742.147 1612843197.8358383
train: epoch 10, iter 1300, loss: 3.427575, top_1: 0.452578, top_k: 0.697422, samples/s: 1742.225 1612843212.5296772
train: epoch 10, iter 1400, loss: 3.416052, top_1: 0.452891, top_k: 0.695781, samples/s: 1750.602 1612843227.153249
train: epoch 10, iter 1500, loss: 3.339107, top_1: 0.450039, top_k: 0.697109, samples/s: 1738.356 1612843241.8797977
train: epoch 10, iter 1600, loss: 3.223220, top_1: 0.454961, top_k: 0.701055, samples/s: 1741.802 1612843256.577262
train: epoch 10, iter 1700, loss: 3.068406, top_1: 0.452188, top_k: 0.697891, samples/s: 1736.549 1612843271.3191853
train: epoch 10, iter 1800, loss: 3.234631, top_1: 0.449609, top_k: 0.699023, samples/s: 1740.897 1612843286.024139
train: epoch 10, iter 1900, loss: 3.439387, top_1: 0.446172, top_k: 0.697266, samples/s: 1742.446 1612843300.7161722
train: epoch 10, iter 2000, loss: 3.302182, top_1: 0.454102, top_k: 0.689297, samples/s: 1744.805 1612843315.388306
train: epoch 10, iter 2100, loss: 3.436529, top_1: 0.452695, top_k: 0.695508, samples/s: 1741.364 1612843330.0894465
train: epoch 10, iter 2200, loss: 3.091533, top_1: 0.450859, top_k: 0.695586, samples/s: 1732.431 1612843344.866368
train: epoch 10, iter 2300, loss: 3.114787, top_1: 0.450430, top_k: 0.696211, samples/s: 1743.048 1612843359.5533032
train: epoch 10, iter 2400, loss: 3.318491, top_1: 0.452734, top_k: 0.699023, samples/s: 1742.670 1612843374.2433686
train: epoch 10, iter 2500, loss: 3.230368, top_1: 0.445078, top_k: 0.693125, samples/s: 1741.894 1612843388.9400213
train: epoch 10, iter 2600, loss: 3.505898, top_1: 0.453242, top_k: 0.695742, samples/s: 1728.491 1612843403.7506325
train: epoch 10, iter 2700, loss: 3.459573, top_1: 0.449727, top_k: 0.697227, samples/s: 1738.720 1612843418.474049
train: epoch 10, iter 2800, loss: 3.303751, top_1: 0.447891, top_k: 0.696328, samples/s: 1745.669 1612843433.138921
train: epoch 10, iter 2900, loss: 3.176462, top_1: 0.454141, top_k: 0.696797, samples/s: 1746.033 1612843447.8007536
train: epoch 10, iter 3000, loss: 3.203767, top_1: 0.456250, top_k: 0.702656, samples/s: 1748.554 1612843462.4414482
train: epoch 10, iter 3100, loss: 3.274662, top_1: 0.452578, top_k: 0.697656, samples/s: 1743.689 1612843477.1229088
train: epoch 10, iter 3200, loss: 3.521197, top_1: 0.448828, top_k: 0.699648, samples/s: 1736.361 1612843491.8665664
train: epoch 10, iter 3300, loss: 3.269730, top_1: 0.448672, top_k: 0.694961, samples/s: 1736.089 1612843506.6122413
train: epoch 10, iter 3400, loss: 3.251268, top_1: 0.446367, top_k: 0.696289, samples/s: 1738.975 1612843521.3335085
train: epoch 10, iter 3500, loss: 3.318058, top_1: 0.452148, top_k: 0.695430, samples/s: 1735.694 1612843536.0827026
train: epoch 10, iter 3600, loss: 3.395801, top_1: 0.451250, top_k: 0.698828, samples/s: 1745.880 1612843550.7457154
train: epoch 10, iter 3700, loss: 3.332886, top_1: 0.452109, top_k: 0.697617, samples/s: 1740.743 1612843565.4521997
train: epoch 10, iter 3800, loss: 3.190398, top_1: 0.448828, top_k: 0.696836, samples/s: 1730.722 1612843580.243687
train: epoch 10, iter 3900, loss: 3.278715, top_1: 0.448594, top_k: 0.699727, samples/s: 1747.474 1612843594.8934455
train: epoch 10, iter 4000, loss: 3.053933, top_1: 0.449844, top_k: 0.698438, samples/s: 1745.056 1612843609.5633833
train: epoch 10, iter 4100, loss: 3.287889, top_1: 0.450117, top_k: 0.699688, samples/s: 1741.078 1612843624.266988
train: epoch 10, iter 4200, loss: 3.393838, top_1: 0.451523, top_k: 0.699219, samples/s: 1739.724 1612843638.9818795
train: epoch 10, iter 4300, loss: 3.314678, top_1: 0.449727, top_k: 0.695508, samples/s: 1737.645 1612843653.7145276
train: epoch 10, iter 4400, loss: 3.365829, top_1: 0.454180, top_k: 0.698594, samples/s: 1754.061 1612843668.3091238
train: epoch 10, iter 4500, loss: 3.284108, top_1: 0.453750, top_k: 0.701172, samples/s: 1735.870 1612843683.0569327
train: epoch 10, iter 4600, loss: 3.379773, top_1: 0.450703, top_k: 0.695703, samples/s: 1741.227 1612843697.7590508
train: epoch 10, iter 4700, loss: 3.177563, top_1: 0.450586, top_k: 0.693320, samples/s: 1745.452 1612843712.4257574
train: epoch 10, iter 4800, loss: 3.217957, top_1: 0.449180, top_k: 0.700781, samples/s: 1748.156 1612843727.0698285
train: epoch 10, iter 4900, loss: 3.295906, top_1: 0.451953, top_k: 0.702539, samples/s: 1734.471 1612843741.8294134
train: epoch 10, iter 5000, loss: 3.293176, top_1: 0.455586, top_k: 0.699531, samples/s: 1748.465 1612843756.4708223
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_10.
validation: epoch 10, iter 195, top_1: 0.490365, top_k: 0.747216, samples/s: 2802.570 1612843774.7090762
train: epoch 11, iter 100, loss: 3.351613, top_1: 0.458477, top_k: 0.703906, samples/s: 1757.669 1612843810.445884
train: epoch 11, iter 200, loss: 3.468266, top_1: 0.457461, top_k: 0.703711, samples/s: 1749.565 1612843825.0780158
train: epoch 11, iter 300, loss: 3.138521, top_1: 0.461016, top_k: 0.705586, samples/s: 1758.761 1612843839.6338105
train: epoch 11, iter 400, loss: 3.315696, top_1: 0.460000, top_k: 0.704141, samples/s: 1763.307 1612843854.15196
train: epoch 11, iter 500, loss: 3.420224, top_1: 0.463047, top_k: 0.707461, samples/s: 1762.433 1612843868.6773033
train: epoch 11, iter 600, loss: 3.491593, top_1: 0.460234, top_k: 0.706250, samples/s: 1760.373 1612843883.2196705
train: epoch 11, iter 700, loss: 3.388810, top_1: 0.456328, top_k: 0.704922, samples/s: 1754.166 1612843897.813474
train: epoch 11, iter 800, loss: 3.324584, top_1: 0.459688, top_k: 0.700547, samples/s: 1750.678 1612843912.4364867
train: epoch 11, iter 900, loss: 3.322837, top_1: 0.454570, top_k: 0.702383, samples/s: 1740.335 1612843927.1462507
train: epoch 11, iter 1000, loss: 3.060453, top_1: 0.454219, top_k: 0.700625, samples/s: 1743.009 1612843941.833496
train: epoch 11, iter 1100, loss: 3.122660, top_1: 0.453867, top_k: 0.699805, samples/s: 1744.034 1612843956.5120223
train: epoch 11, iter 1200, loss: 3.184699, top_1: 0.458828, top_k: 0.704570, samples/s: 1746.947 1612843971.1663063
train: epoch 11, iter 1300, loss: 3.374147, top_1: 0.456328, top_k: 0.701836, samples/s: 1739.965 1612843985.8791575
train: epoch 11, iter 1400, loss: 3.595312, top_1: 0.457773, top_k: 0.705781, samples/s: 1735.226 1612844000.6322608
train: epoch 11, iter 1500, loss: 3.121416, top_1: 0.460742, top_k: 0.702070, samples/s: 1700.498 1612844015.6867425
train: epoch 11, iter 1600, loss: 3.472815, top_1: 0.457969, top_k: 0.705977, samples/s: 1769.075 1612844030.1575067
train: epoch 11, iter 1700, loss: 3.396041, top_1: 0.458125, top_k: 0.705508, samples/s: 1734.911 1612844044.913341
train: epoch 11, iter 1800, loss: 3.298467, top_1: 0.465977, top_k: 0.709258, samples/s: 1736.808 1612844059.6530223
train: epoch 11, iter 1900, loss: 3.422415, top_1: 0.456055, top_k: 0.702070, samples/s: 1741.786 1612844074.3505833
train: epoch 11, iter 2000, loss: 3.273727, top_1: 0.458906, top_k: 0.704141, samples/s: 1740.559 1612844089.0584917
train: epoch 11, iter 2100, loss: 3.359256, top_1: 0.456680, top_k: 0.707031, samples/s: 1740.243 1612844103.769106
train: epoch 11, iter 2200, loss: 3.282961, top_1: 0.459492, top_k: 0.701680, samples/s: 1736.895 1612844118.5080066
train: epoch 11, iter 2300, loss: 3.159305, top_1: 0.458984, top_k: 0.702617, samples/s: 1744.343 1612844133.1839952
train: epoch 11, iter 2400, loss: 3.393024, top_1: 0.460781, top_k: 0.707422, samples/s: 1744.252 1612844147.8607545
train: epoch 11, iter 2500, loss: 3.558931, top_1: 0.458242, top_k: 0.703203, samples/s: 1732.265 1612844162.639096
train: epoch 11, iter 2600, loss: 3.372891, top_1: 0.456211, top_k: 0.705078, samples/s: 1742.281 1612844177.3324718
train: epoch 11, iter 2700, loss: 3.235011, top_1: 0.461367, top_k: 0.703711, samples/s: 1741.453 1612844192.0329623
train: epoch 11, iter 2800, loss: 3.183526, top_1: 0.464297, top_k: 0.705039, samples/s: 1738.471 1612844206.7584622
train: epoch 11, iter 2900, loss: 3.247601, top_1: 0.459609, top_k: 0.706562, samples/s: 1738.016 1612844221.4879057
train: epoch 11, iter 3000, loss: 3.127915, top_1: 0.458516, top_k: 0.703789, samples/s: 1740.080 1612844236.1998405
train: epoch 11, iter 3100, loss: 3.083883, top_1: 0.455898, top_k: 0.699922, samples/s: 1729.943 1612844250.998114
train: epoch 11, iter 3200, loss: 3.246576, top_1: 0.454141, top_k: 0.699609, samples/s: 1745.764 1612844265.662116
train: epoch 11, iter 3300, loss: 3.260746, top_1: 0.465156, top_k: 0.702969, samples/s: 1743.400 1612844280.3460839
train: epoch 11, iter 3400, loss: 3.101594, top_1: 0.458633, top_k: 0.702617, samples/s: 1734.250 1612844295.1075063
train: epoch 11, iter 3500, loss: 3.274171, top_1: 0.457070, top_k: 0.705234, samples/s: 1747.805 1612844309.7549677
train: epoch 11, iter 3600, loss: 3.381983, top_1: 0.458437, top_k: 0.706133, samples/s: 1747.274 1612844324.4058526
train: epoch 11, iter 3700, loss: 3.177108, top_1: 0.457813, top_k: 0.702852, samples/s: 1748.330 1612844339.0486937
train: epoch 11, iter 3800, loss: 3.338330, top_1: 0.458164, top_k: 0.702734, samples/s: 1739.109 1612844353.768551
train: epoch 11, iter 3900, loss: 3.407570, top_1: 0.458906, top_k: 0.704336, samples/s: 1737.753 1612844368.5003026
train: epoch 11, iter 4000, loss: 3.259918, top_1: 0.459414, top_k: 0.704336, samples/s: 1741.823 1612844383.1974435
train: epoch 11, iter 4100, loss: 3.261561, top_1: 0.456836, top_k: 0.703203, samples/s: 1746.244 1612844397.857476
train: epoch 11, iter 4200, loss: 3.410227, top_1: 0.458711, top_k: 0.702930, samples/s: 1748.693 1612844412.496971
train: epoch 11, iter 4300, loss: 3.213662, top_1: 0.459336, top_k: 0.706953, samples/s: 1726.279 1612844427.3266768
train: epoch 11, iter 4400, loss: 3.176339, top_1: 0.457891, top_k: 0.701641, samples/s: 1751.912 1612844441.9391613
train: epoch 11, iter 4500, loss: 3.252454, top_1: 0.464844, top_k: 0.709336, samples/s: 1736.800 1612844456.6789746
train: epoch 11, iter 4600, loss: 3.307716, top_1: 0.456758, top_k: 0.705469, samples/s: 1746.453 1612844471.3372502
train: epoch 11, iter 4700, loss: 3.239527, top_1: 0.458008, top_k: 0.707695, samples/s: 1736.961 1612844486.0756388
train: epoch 11, iter 4800, loss: 3.500260, top_1: 0.461641, top_k: 0.704102, samples/s: 1734.207 1612844500.8374195
train: epoch 11, iter 4900, loss: 3.071759, top_1: 0.454961, top_k: 0.705391, samples/s: 1748.143 1612844515.4815202
train: epoch 11, iter 5000, loss: 3.403489, top_1: 0.457891, top_k: 0.704141, samples/s: 1740.956 1612844530.1860852
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_11.
validation: epoch 11, iter 195, top_1: 0.508614, top_k: 0.759956, samples/s: 2750.636 1612844548.7815068
train: epoch 12, iter 100, loss: 3.157213, top_1: 0.463828, top_k: 0.710898, samples/s: 1750.565 1612844584.090473
train: epoch 12, iter 200, loss: 3.265103, top_1: 0.470469, top_k: 0.713672, samples/s: 1760.867 1612844598.6286664
train: epoch 12, iter 300, loss: 3.164522, top_1: 0.465078, top_k: 0.708203, samples/s: 1757.669 1612844613.1934156
train: epoch 12, iter 400, loss: 3.392684, top_1: 0.466133, top_k: 0.708047, samples/s: 1754.765 1612844627.7825196
train: epoch 12, iter 500, loss: 3.080151, top_1: 0.465195, top_k: 0.707344, samples/s: 1764.412 1612844642.2913299
train: epoch 12, iter 600, loss: 3.447227, top_1: 0.466367, top_k: 0.707773, samples/s: 1757.397 1612844656.8582973
train: epoch 12, iter 700, loss: 3.289191, top_1: 0.469336, top_k: 0.711484, samples/s: 1746.514 1612844671.5160596
train: epoch 12, iter 800, loss: 3.255800, top_1: 0.468086, top_k: 0.709883, samples/s: 1743.614 1612844686.1982236
train: epoch 12, iter 900, loss: 3.215815, top_1: 0.465430, top_k: 0.710508, samples/s: 1743.333 1612844700.882721
train: epoch 12, iter 1000, loss: 3.101080, top_1: 0.465664, top_k: 0.706680, samples/s: 1742.579 1612844715.5737004
train: epoch 12, iter 1100, loss: 3.133222, top_1: 0.463047, top_k: 0.704727, samples/s: 1748.793 1612844730.2123559
train: epoch 12, iter 1200, loss: 3.301591, top_1: 0.464375, top_k: 0.709375, samples/s: 1739.568 1612844744.9285994
train: epoch 12, iter 1300, loss: 3.250505, top_1: 0.461562, top_k: 0.707617, samples/s: 1740.901 1612844759.6336355
train: epoch 12, iter 1400, loss: 3.215216, top_1: 0.464102, top_k: 0.711250, samples/s: 1726.179 1612844774.4641573
train: epoch 12, iter 1500, loss: 3.252561, top_1: 0.468906, top_k: 0.712031, samples/s: 1749.309 1612844789.098449
train: epoch 12, iter 1600, loss: 3.257967, top_1: 0.468125, top_k: 0.706680, samples/s: 1748.337 1612844803.7408762
train: epoch 12, iter 1700, loss: 3.339080, top_1: 0.469180, top_k: 0.708477, samples/s: 1742.503 1612844818.4323735
train: epoch 12, iter 1800, loss: 3.198423, top_1: 0.460938, top_k: 0.704531, samples/s: 1743.169 1612844833.1183033
train: epoch 12, iter 1900, loss: 3.273411, top_1: 0.456953, top_k: 0.703047, samples/s: 1734.807 1612844847.8749871
train: epoch 12, iter 2000, loss: 3.395368, top_1: 0.465039, top_k: 0.710234, samples/s: 1742.678 1612844862.565041
train: epoch 12, iter 2100, loss: 3.428636, top_1: 0.461914, top_k: 0.707695, samples/s: 1738.636 1612844877.289192
train: epoch 12, iter 2200, loss: 3.318787, top_1: 0.464922, top_k: 0.710352, samples/s: 1741.755 1612844891.9870174
train: epoch 12, iter 2300, loss: 3.216819, top_1: 0.459102, top_k: 0.707422, samples/s: 1744.618 1612844906.660756
train: epoch 12, iter 2400, loss: 3.205179, top_1: 0.457148, top_k: 0.704258, samples/s: 1743.737 1612844921.3418262
train: epoch 12, iter 2500, loss: 3.218114, top_1: 0.459180, top_k: 0.705664, samples/s: 1749.504 1612844935.9745364
train: epoch 12, iter 2600, loss: 3.248293, top_1: 0.464414, top_k: 0.709648, samples/s: 1736.602 1612844950.7160065
train: epoch 12, iter 2700, loss: 3.169533, top_1: 0.463555, top_k: 0.709727, samples/s: 1737.693 1612844965.4482284
train: epoch 12, iter 2800, loss: 3.167197, top_1: 0.464414, top_k: 0.707969, samples/s: 1739.525 1612844980.1648595
train: epoch 12, iter 2900, loss: 3.275557, top_1: 0.464492, top_k: 0.709297, samples/s: 1747.439 1612844994.8148952
train: epoch 12, iter 3000, loss: 3.285337, top_1: 0.462383, top_k: 0.706680, samples/s: 1746.537 1612845009.4724352
train: epoch 12, iter 3100, loss: 3.233016, top_1: 0.461914, top_k: 0.709766, samples/s: 1736.539 1612845024.2143753
train: epoch 12, iter 3200, loss: 3.235776, top_1: 0.464102, top_k: 0.712031, samples/s: 1743.460 1612845038.8978941
train: epoch 12, iter 3300, loss: 3.223143, top_1: 0.465703, top_k: 0.711836, samples/s: 1732.163 1612845053.6770148
train: epoch 12, iter 3400, loss: 3.397611, top_1: 0.462109, top_k: 0.706094, samples/s: 1749.248 1612845068.3124857
train: epoch 12, iter 3500, loss: 3.342863, top_1: 0.462344, top_k: 0.706914, samples/s: 1749.125 1612845082.9478054
train: epoch 12, iter 3600, loss: 3.294827, top_1: 0.464297, top_k: 0.711680, samples/s: 1748.603 1612845097.5880806
train: epoch 12, iter 3700, loss: 3.281255, top_1: 0.460273, top_k: 0.707070, samples/s: 1745.698 1612845112.2526739
train: epoch 12, iter 3800, loss: 3.339218, top_1: 0.458867, top_k: 0.706797, samples/s: 1732.855 1612845127.0262709
train: epoch 12, iter 3900, loss: 3.328742, top_1: 0.467930, top_k: 0.710000, samples/s: 1744.549 1612845141.7002952
train: epoch 12, iter 4000, loss: 3.310676, top_1: 0.463711, top_k: 0.708242, samples/s: 1739.284 1612845156.4189208
train: epoch 12, iter 4100, loss: 3.200920, top_1: 0.466953, top_k: 0.712891, samples/s: 1744.256 1612845171.0956664
train: epoch 12, iter 4200, loss: 3.124237, top_1: 0.459375, top_k: 0.703633, samples/s: 1724.871 1612845185.9374588
train: epoch 12, iter 4300, loss: 3.293490, top_1: 0.465430, top_k: 0.708203, samples/s: 1745.202 1612845200.6062183
train: epoch 12, iter 4400, loss: 3.421739, top_1: 0.459688, top_k: 0.708242, samples/s: 1748.845 1612845215.2444346
train: epoch 12, iter 4500, loss: 3.380779, top_1: 0.463438, top_k: 0.707852, samples/s: 1733.248 1612845230.0143867
train: epoch 12, iter 4600, loss: 3.257143, top_1: 0.469258, top_k: 0.712422, samples/s: 1743.405 1612845244.6983268
train: epoch 12, iter 4700, loss: 3.266603, top_1: 0.464375, top_k: 0.702383, samples/s: 1741.905 1612845259.394867
train: epoch 12, iter 4800, loss: 3.293843, top_1: 0.455508, top_k: 0.705195, samples/s: 1744.895 1612845274.0662339
train: epoch 12, iter 4900, loss: 3.092252, top_1: 0.468242, top_k: 0.711328, samples/s: 1729.089 1612845288.8717268
train: epoch 12, iter 5000, loss: 3.073411, top_1: 0.460195, top_k: 0.705508, samples/s: 1741.512 1612845303.5715544
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_12.
validation: epoch 12, iter 195, top_1: 0.511098, top_k: 0.764343, samples/s: 2813.337 1612845321.7287245
train: epoch 13, iter 100, loss: 3.089543, top_1: 0.473008, top_k: 0.716289, samples/s: 1752.650 1612845356.5873687
train: epoch 13, iter 200, loss: 3.409811, top_1: 0.474102, top_k: 0.714336, samples/s: 1756.894 1612845371.1586962
train: epoch 13, iter 300, loss: 3.073369, top_1: 0.471562, top_k: 0.714375, samples/s: 1757.923 1612845385.7210455
train: epoch 13, iter 400, loss: 3.075254, top_1: 0.466680, top_k: 0.713984, samples/s: 1760.923 1612845400.2590175
train: epoch 13, iter 500, loss: 3.249355, top_1: 0.474961, top_k: 0.716211, samples/s: 1756.841 1612845414.830504
train: epoch 13, iter 600, loss: 3.286312, top_1: 0.474883, top_k: 0.716289, samples/s: 1764.430 1612845429.3395052
train: epoch 13, iter 700, loss: 3.333965, top_1: 0.467852, top_k: 0.715352, samples/s: 1752.380 1612845443.948114
train: epoch 13, iter 800, loss: 3.289845, top_1: 0.466367, top_k: 0.712656, samples/s: 1747.611 1612845458.5967355
train: epoch 13, iter 900, loss: 3.460730, top_1: 0.474883, top_k: 0.715586, samples/s: 1745.698 1612845473.2613356
train: epoch 13, iter 1000, loss: 3.176214, top_1: 0.470078, top_k: 0.712383, samples/s: 1743.372 1612845487.9454942
train: epoch 13, iter 1100, loss: 3.075544, top_1: 0.464453, top_k: 0.708438, samples/s: 1730.486 1612845502.739035
train: epoch 13, iter 1200, loss: 3.120151, top_1: 0.472187, top_k: 0.715586, samples/s: 1748.655 1612845517.3788562
train: epoch 13, iter 1300, loss: 3.388727, top_1: 0.474844, top_k: 0.719102, samples/s: 1747.775 1612845532.0261528
train: epoch 13, iter 1400, loss: 2.938116, top_1: 0.470742, top_k: 0.712500, samples/s: 1745.440 1612845546.6928866
train: epoch 13, iter 1500, loss: 3.165919, top_1: 0.468242, top_k: 0.713633, samples/s: 1742.808 1612845561.381784
train: epoch 13, iter 1600, loss: 3.325523, top_1: 0.469570, top_k: 0.712812, samples/s: 1734.440 1612845576.1416552
train: epoch 13, iter 1700, loss: 3.108281, top_1: 0.471758, top_k: 0.718516, samples/s: 1739.406 1612845590.8593223
train: epoch 13, iter 1800, loss: 3.324619, top_1: 0.466875, top_k: 0.711133, samples/s: 1736.260 1612845605.6036022
train: epoch 13, iter 1900, loss: 3.163831, top_1: 0.468242, top_k: 0.711133, samples/s: 1749.869 1612845620.2333152
train: epoch 13, iter 2000, loss: 3.193899, top_1: 0.466758, top_k: 0.711523, samples/s: 1743.291 1612845634.9181445
train: epoch 13, iter 2100, loss: 3.254323, top_1: 0.474297, top_k: 0.714844, samples/s: 1733.400 1612845649.6867855
train: epoch 13, iter 2200, loss: 3.099289, top_1: 0.474727, top_k: 0.716445, samples/s: 1736.267 1612845664.4311128
train: epoch 13, iter 2300, loss: 3.272087, top_1: 0.469727, top_k: 0.712539, samples/s: 1741.859 1612845679.1280756
train: epoch 13, iter 2400, loss: 3.209960, top_1: 0.470508, top_k: 0.714805, samples/s: 1747.636 1612845693.776441
train: epoch 13, iter 2500, loss: 3.269223, top_1: 0.471875, top_k: 0.717305, samples/s: 1740.019 1612845708.488855
train: epoch 13, iter 2600, loss: 3.134433, top_1: 0.465781, top_k: 0.716484, samples/s: 1731.995 1612845723.2695472
train: epoch 13, iter 2700, loss: 3.121486, top_1: 0.471758, top_k: 0.710391, samples/s: 1736.621 1612845738.0107672
train: epoch 13, iter 2800, loss: 3.337025, top_1: 0.470039, top_k: 0.714844, samples/s: 1748.792 1612845752.6494858
train: epoch 13, iter 2900, loss: 3.268885, top_1: 0.468633, top_k: 0.712930, samples/s: 1736.154 1612845767.3946617
train: epoch 13, iter 3000, loss: 3.193250, top_1: 0.459570, top_k: 0.709063, samples/s: 1741.212 1612845782.0970654
train: epoch 13, iter 3100, loss: 3.135309, top_1: 0.469141, top_k: 0.713906, samples/s: 1743.152 1612845796.7831764
train: epoch 13, iter 3200, loss: 3.024417, top_1: 0.466367, top_k: 0.714063, samples/s: 1723.824 1612845811.633861
train: epoch 13, iter 3300, loss: 3.314715, top_1: 0.470273, top_k: 0.714336, samples/s: 1741.160 1612845826.3367167
train: epoch 13, iter 3400, loss: 3.210907, top_1: 0.468906, top_k: 0.716133, samples/s: 1735.374 1612845841.0886009
train: epoch 13, iter 3500, loss: 3.146346, top_1: 0.463438, top_k: 0.713203, samples/s: 1750.103 1612845855.7163668
train: epoch 13, iter 3600, loss: 3.249465, top_1: 0.468906, top_k: 0.714102, samples/s: 1747.682 1612845870.3642566
train: epoch 13, iter 3700, loss: 3.387669, top_1: 0.469062, top_k: 0.711758, samples/s: 1738.696 1612845885.0879552
train: epoch 13, iter 3800, loss: 3.278905, top_1: 0.467344, top_k: 0.710820, samples/s: 1738.324 1612845899.8147428
train: epoch 13, iter 3900, loss: 3.133645, top_1: 0.471016, top_k: 0.713594, samples/s: 1736.937 1612845914.5533519
train: epoch 13, iter 4000, loss: 3.099757, top_1: 0.470898, top_k: 0.713281, samples/s: 1747.891 1612845929.199516
train: epoch 13, iter 4100, loss: 3.099164, top_1: 0.470352, top_k: 0.712812, samples/s: 1735.838 1612845943.9475043
train: epoch 13, iter 4200, loss: 3.368575, top_1: 0.472187, top_k: 0.716758, samples/s: 1740.590 1612845958.6550987
train: epoch 13, iter 4300, loss: 3.388172, top_1: 0.466914, top_k: 0.711484, samples/s: 1734.421 1612845973.4150977
train: epoch 13, iter 4400, loss: 3.288898, top_1: 0.470469, top_k: 0.714609, samples/s: 1744.912 1612845988.0863607
train: epoch 13, iter 4500, loss: 3.163609, top_1: 0.474727, top_k: 0.715586, samples/s: 1745.214 1612846002.7549715
train: epoch 13, iter 4600, loss: 3.314153, top_1: 0.466250, top_k: 0.710117, samples/s: 1738.766 1612846017.478198
train: epoch 13, iter 4700, loss: 3.377404, top_1: 0.471406, top_k: 0.710781, samples/s: 1750.228 1612846032.1048036
train: epoch 13, iter 4800, loss: 3.223153, top_1: 0.468125, top_k: 0.712422, samples/s: 1730.937 1612846046.894535
train: epoch 13, iter 4900, loss: 3.345828, top_1: 0.470000, top_k: 0.713359, samples/s: 1741.285 1612846061.5962584
train: epoch 13, iter 5000, loss: 3.206840, top_1: 0.470313, top_k: 0.712930, samples/s: 1745.127 1612846076.2656386
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_13.
validation: epoch 13, iter 195, top_1: 0.504067, top_k: 0.759816, samples/s: 2919.707 1612846093.8217964
train: epoch 14, iter 100, loss: 3.201228, top_1: 0.485977, top_k: 0.724336, samples/s: 1749.739 1612846128.6606534
train: epoch 14, iter 200, loss: 3.340627, top_1: 0.474570, top_k: 0.719805, samples/s: 1755.488 1612846143.2435684
train: epoch 14, iter 300, loss: 3.280229, top_1: 0.472969, top_k: 0.717812, samples/s: 1764.753 1612846157.7499022
train: epoch 14, iter 400, loss: 3.032874, top_1: 0.479570, top_k: 0.723047, samples/s: 1758.460 1612846172.3080232
train: epoch 14, iter 500, loss: 3.412611, top_1: 0.477148, top_k: 0.716445, samples/s: 1757.670 1612846186.8727458
train: epoch 14, iter 600, loss: 3.305901, top_1: 0.477305, top_k: 0.717734, samples/s: 1758.142 1612846201.433527
train: epoch 14, iter 700, loss: 3.213779, top_1: 0.475195, top_k: 0.721914, samples/s: 1747.470 1612846216.0832388
train: epoch 14, iter 800, loss: 2.979872, top_1: 0.477422, top_k: 0.720195, samples/s: 1751.506 1612846230.6992369
train: epoch 14, iter 900, loss: 3.232842, top_1: 0.472266, top_k: 0.716367, samples/s: 1756.582 1612846245.27301
train: epoch 14, iter 1000, loss: 3.314842, top_1: 0.473516, top_k: 0.717109, samples/s: 1745.842 1612846259.9364436
train: epoch 14, iter 1100, loss: 3.159140, top_1: 0.471914, top_k: 0.717187, samples/s: 1744.102 1612846274.6145875
train: epoch 14, iter 1200, loss: 3.355086, top_1: 0.472305, top_k: 0.719531, samples/s: 1736.582 1612846289.3560555
train: epoch 14, iter 1300, loss: 3.095545, top_1: 0.471875, top_k: 0.721328, samples/s: 1733.115 1612846304.12723
train: epoch 14, iter 1400, loss: 3.074646, top_1: 0.472266, top_k: 0.718203, samples/s: 1733.651 1612846318.893729
train: epoch 14, iter 1500, loss: 3.185724, top_1: 0.471484, top_k: 0.713672, samples/s: 1731.777 1612846333.6761742
train: epoch 14, iter 1600, loss: 3.169095, top_1: 0.474805, top_k: 0.716641, samples/s: 1735.854 1612846348.4239628
train: epoch 14, iter 1700, loss: 3.235835, top_1: 0.480742, top_k: 0.719688, samples/s: 1746.290 1612846363.0837238
train: epoch 14, iter 1800, loss: 3.279144, top_1: 0.477031, top_k: 0.716797, samples/s: 1730.301 1612846377.878767
train: epoch 14, iter 1900, loss: 3.385836, top_1: 0.468555, top_k: 0.711953, samples/s: 1746.167 1612846392.539449
train: epoch 14, iter 2000, loss: 3.279642, top_1: 0.476641, top_k: 0.721133, samples/s: 1736.229 1612846407.283999
train: epoch 14, iter 2100, loss: 3.436277, top_1: 0.474219, top_k: 0.716133, samples/s: 1734.925 1612846422.0397987
train: epoch 14, iter 2200, loss: 3.053553, top_1: 0.478945, top_k: 0.722266, samples/s: 1741.000 1612846436.743868
train: epoch 14, iter 2300, loss: 3.009242, top_1: 0.474180, top_k: 0.717617, samples/s: 1745.828 1612846451.40739
train: epoch 14, iter 2400, loss: 3.256577, top_1: 0.475664, top_k: 0.716250, samples/s: 1731.812 1612846466.1896183
train: epoch 14, iter 2500, loss: 3.225165, top_1: 0.472109, top_k: 0.714922, samples/s: 1741.869 1612846480.8864686
train: epoch 14, iter 2600, loss: 3.152744, top_1: 0.469180, top_k: 0.715273, samples/s: 1742.137 1612846495.581104
train: epoch 14, iter 2700, loss: 3.351246, top_1: 0.473750, top_k: 0.719414, samples/s: 1735.324 1612846510.3333364
train: epoch 14, iter 2800, loss: 3.336866, top_1: 0.474531, top_k: 0.717734, samples/s: 1747.045 1612846524.9866436
train: epoch 14, iter 2900, loss: 3.282037, top_1: 0.470586, top_k: 0.715195, samples/s: 1751.222 1612846539.6050122
train: epoch 14, iter 3000, loss: 3.294109, top_1: 0.466602, top_k: 0.711289, samples/s: 1726.901 1612846554.4293787
train: epoch 14, iter 3100, loss: 3.182626, top_1: 0.471328, top_k: 0.711328, samples/s: 1741.181 1612846569.131919
train: epoch 14, iter 3200, loss: 3.307152, top_1: 0.473906, top_k: 0.716211, samples/s: 1750.171 1612846583.7590842
train: epoch 14, iter 3300, loss: 3.273862, top_1: 0.468242, top_k: 0.713437, samples/s: 1741.376 1612846598.4601421
train: epoch 14, iter 3400, loss: 3.218660, top_1: 0.476602, top_k: 0.716484, samples/s: 1724.978 1612846613.300858
train: epoch 14, iter 3500, loss: 3.430096, top_1: 0.477461, top_k: 0.716562, samples/s: 1739.796 1612846628.0153453
train: epoch 14, iter 3600, loss: 3.129256, top_1: 0.476758, top_k: 0.715273, samples/s: 1745.259 1612846642.683592
train: epoch 14, iter 3700, loss: 3.202867, top_1: 0.470117, top_k: 0.713242, samples/s: 1728.432 1612846657.4946368
train: epoch 14, iter 3800, loss: 3.242317, top_1: 0.477227, top_k: 0.717070, samples/s: 1744.295 1612846672.1711156
train: epoch 14, iter 3900, loss: 3.130574, top_1: 0.469766, top_k: 0.711602, samples/s: 1725.339 1612846687.0087655
train: epoch 14, iter 4000, loss: 3.151004, top_1: 0.472461, top_k: 0.716719, samples/s: 1731.701 1612846701.7919626
train: epoch 14, iter 4100, loss: 3.171023, top_1: 0.472461, top_k: 0.714609, samples/s: 1738.206 1612846716.5197666
train: epoch 14, iter 4200, loss: 3.087816, top_1: 0.470781, top_k: 0.713320, samples/s: 1740.529 1612846731.2279572
train: epoch 14, iter 4300, loss: 3.310223, top_1: 0.473711, top_k: 0.718516, samples/s: 1736.949 1612846745.9664538
train: epoch 14, iter 4400, loss: 3.246121, top_1: 0.471992, top_k: 0.715547, samples/s: 1738.140 1612846760.6947863
train: epoch 14, iter 4500, loss: 3.269807, top_1: 0.475195, top_k: 0.718398, samples/s: 1736.273 1612846775.4390469
train: epoch 14, iter 4600, loss: 3.050823, top_1: 0.474844, top_k: 0.718672, samples/s: 1717.889 1612846790.3412697
train: epoch 14, iter 4700, loss: 3.160794, top_1: 0.475117, top_k: 0.713711, samples/s: 1730.822 1612846805.131642
train: epoch 14, iter 4800, loss: 3.286691, top_1: 0.473516, top_k: 0.720039, samples/s: 1728.640 1612846819.940992
train: epoch 14, iter 4900, loss: 3.135731, top_1: 0.469062, top_k: 0.718125, samples/s: 1727.563 1612846834.7596037
train: epoch 14, iter 5000, loss: 3.204266, top_1: 0.480352, top_k: 0.720469, samples/s: 1724.201 1612846849.6070018
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_14.
validation: epoch 14, iter 195, top_1: 0.519671, top_k: 0.773257, samples/s: 2786.671 1612846868.033181
train: epoch 15, iter 100, loss: 3.300931, top_1: 0.481602, top_k: 0.728086, samples/s: 1755.775 1612846902.8293743
train: epoch 15, iter 200, loss: 3.198778, top_1: 0.481289, top_k: 0.722891, samples/s: 1763.102 1612846917.3493752
train: epoch 15, iter 300, loss: 3.162701, top_1: 0.478125, top_k: 0.719922, samples/s: 1760.324 1612846931.8919744
train: epoch 15, iter 400, loss: 3.149839, top_1: 0.483672, top_k: 0.723672, samples/s: 1757.664 1612846946.4568415
train: epoch 15, iter 500, loss: 3.219860, top_1: 0.487656, top_k: 0.725820, samples/s: 1750.740 1612846961.0792732
train: epoch 15, iter 600, loss: 3.036672, top_1: 0.477852, top_k: 0.720195, samples/s: 1757.336 1612846975.6466753
train: epoch 15, iter 700, loss: 3.372095, top_1: 0.476016, top_k: 0.719453, samples/s: 1748.821 1612846990.2851617
train: epoch 15, iter 800, loss: 3.134693, top_1: 0.475625, top_k: 0.723789, samples/s: 1722.872 1612847005.1440485
train: epoch 15, iter 900, loss: 3.048380, top_1: 0.481719, top_k: 0.724648, samples/s: 1742.109 1612847019.8388171
train: epoch 15, iter 1000, loss: 3.087860, top_1: 0.478906, top_k: 0.723867, samples/s: 1738.220 1612847034.5665872
train: epoch 15, iter 1100, loss: 3.381843, top_1: 0.477734, top_k: 0.721523, samples/s: 1732.298 1612847049.3445764
train: epoch 15, iter 1200, loss: 3.037961, top_1: 0.475508, top_k: 0.720117, samples/s: 1722.074 1612847064.2103791
train: epoch 15, iter 1300, loss: 3.391834, top_1: 0.478828, top_k: 0.720117, samples/s: 1718.856 1612847079.1040974
train: epoch 15, iter 1400, loss: 3.271325, top_1: 0.478398, top_k: 0.719844, samples/s: 1741.938 1612847093.8003006
train: epoch 15, iter 1500, loss: 3.007679, top_1: 0.485195, top_k: 0.725547, samples/s: 1737.085 1612847108.537692
train: epoch 15, iter 1600, loss: 3.226088, top_1: 0.477422, top_k: 0.718867, samples/s: 1724.091 1612847123.3861892
train: epoch 15, iter 1700, loss: 3.193765, top_1: 0.476875, top_k: 0.722539, samples/s: 1731.564 1612847138.1703475
train: epoch 15, iter 1800, loss: 3.326816, top_1: 0.476719, top_k: 0.717852, samples/s: 1733.821 1612847152.9354517
train: epoch 15, iter 1900, loss: 3.192949, top_1: 0.474844, top_k: 0.717852, samples/s: 1727.950 1612847167.7507174
train: epoch 15, iter 2000, loss: 3.333443, top_1: 0.473555, top_k: 0.717266, samples/s: 1729.145 1612847182.555748
train: epoch 15, iter 2100, loss: 3.369268, top_1: 0.481133, top_k: 0.725195, samples/s: 1738.408 1612847197.2818558
train: epoch 15, iter 2200, loss: 3.210872, top_1: 0.474922, top_k: 0.718555, samples/s: 1736.055 1612847212.0279186
train: epoch 15, iter 2300, loss: 3.205005, top_1: 0.477070, top_k: 0.720781, samples/s: 1720.066 1612847226.9111264
train: epoch 15, iter 2400, loss: 3.297931, top_1: 0.479414, top_k: 0.720859, samples/s: 1738.673 1612847241.6348796
train: epoch 15, iter 2500, loss: 3.175544, top_1: 0.478633, top_k: 0.722344, samples/s: 1732.325 1612847256.4127026
train: epoch 15, iter 2600, loss: 3.377683, top_1: 0.477930, top_k: 0.726641, samples/s: 1731.581 1612847271.1969373
train: epoch 15, iter 2700, loss: 2.990609, top_1: 0.479336, top_k: 0.721719, samples/s: 1730.729 1612847285.9883542
train: epoch 15, iter 2800, loss: 3.280229, top_1: 0.478945, top_k: 0.724609, samples/s: 1734.092 1612847300.7511785
train: epoch 15, iter 2900, loss: 3.171411, top_1: 0.476211, top_k: 0.718008, samples/s: 1741.531 1612847315.4508128
train: epoch 15, iter 3000, loss: 3.029058, top_1: 0.480273, top_k: 0.721172, samples/s: 1725.316 1612847330.2887058
train: epoch 15, iter 3100, loss: 3.214231, top_1: 0.476875, top_k: 0.720742, samples/s: 1735.917 1612847345.036037
train: epoch 15, iter 3200, loss: 3.216895, top_1: 0.482266, top_k: 0.726680, samples/s: 1745.215 1612847359.7046874
train: epoch 15, iter 3300, loss: 3.533295, top_1: 0.478633, top_k: 0.724258, samples/s: 1734.672 1612847374.462493
train: epoch 15, iter 3400, loss: 3.180174, top_1: 0.480508, top_k: 0.723359, samples/s: 1735.918 1612847389.209751
train: epoch 15, iter 3500, loss: 3.216876, top_1: 0.476289, top_k: 0.720508, samples/s: 1731.108 1612847403.9979458
train: epoch 15, iter 3600, loss: 3.048081, top_1: 0.474180, top_k: 0.719492, samples/s: 1735.563 1612847418.748229
train: epoch 15, iter 3700, loss: 3.160316, top_1: 0.476914, top_k: 0.722617, samples/s: 1734.676 1612847433.5060198
train: epoch 15, iter 3800, loss: 3.308633, top_1: 0.471914, top_k: 0.715703, samples/s: 1732.321 1612847448.2838209
train: epoch 15, iter 3900, loss: 3.126959, top_1: 0.475898, top_k: 0.720391, samples/s: 1722.747 1612847463.1438541
train: epoch 15, iter 4000, loss: 3.045240, top_1: 0.479375, top_k: 0.720508, samples/s: 1712.956 1612847478.088791
train: epoch 15, iter 4100, loss: 3.120752, top_1: 0.477734, top_k: 0.722422, samples/s: 1748.030 1612847492.7339084
train: epoch 15, iter 4200, loss: 3.071121, top_1: 0.477305, top_k: 0.717422, samples/s: 1729.380 1612847507.5368197
train: epoch 15, iter 4300, loss: 3.221948, top_1: 0.478047, top_k: 0.718711, samples/s: 1728.595 1612847522.346508
train: epoch 15, iter 4400, loss: 3.197759, top_1: 0.482109, top_k: 0.721836, samples/s: 1730.735 1612847537.1379528
train: epoch 15, iter 4500, loss: 3.263595, top_1: 0.473516, top_k: 0.716562, samples/s: 1738.355 1612847551.864465
train: epoch 15, iter 4600, loss: 3.311440, top_1: 0.478047, top_k: 0.720117, samples/s: 1734.216 1612847566.6262627
train: epoch 15, iter 4700, loss: 3.186750, top_1: 0.475898, top_k: 0.722969, samples/s: 1748.737 1612847581.2653773
train: epoch 15, iter 4800, loss: 3.436948, top_1: 0.475039, top_k: 0.719336, samples/s: 1748.280 1612847595.908284
train: epoch 15, iter 4900, loss: 3.326655, top_1: 0.471758, top_k: 0.715469, samples/s: 1734.952 1612847610.6638417
train: epoch 15, iter 5000, loss: 3.187646, top_1: 0.474023, top_k: 0.720469, samples/s: 1752.459 1612847625.2718313
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_15.
validation: epoch 15, iter 195, top_1: 0.527183, top_k: 0.782592, samples/s: 2842.143 1612847643.2724206
train: epoch 16, iter 100, loss: 3.162476, top_1: 0.494102, top_k: 0.735352, samples/s: 1745.050 1612847678.2475278
train: epoch 16, iter 200, loss: 2.931883, top_1: 0.491016, top_k: 0.731953, samples/s: 1761.535 1612847692.78034
train: epoch 16, iter 300, loss: 3.496988, top_1: 0.482383, top_k: 0.727500, samples/s: 1757.982 1612847707.342704
train: epoch 16, iter 400, loss: 3.300079, top_1: 0.488711, top_k: 0.726758, samples/s: 1752.738 1612847721.9482052
train: epoch 16, iter 500, loss: 3.289863, top_1: 0.480195, top_k: 0.723164, samples/s: 1753.244 1612847736.549714
train: epoch 16, iter 600, loss: 3.337025, top_1: 0.477773, top_k: 0.725625, samples/s: 1752.184 1612847751.1600091
train: epoch 16, iter 700, loss: 3.304494, top_1: 0.479453, top_k: 0.720938, samples/s: 1724.798 1612847766.0027676
train: epoch 16, iter 800, loss: 3.270731, top_1: 0.480781, top_k: 0.725859, samples/s: 1745.218 1612847780.670984
train: epoch 16, iter 900, loss: 3.168190, top_1: 0.490977, top_k: 0.730977, samples/s: 1730.464 1612847795.4652946
train: epoch 16, iter 1000, loss: 3.190819, top_1: 0.485820, top_k: 0.722461, samples/s: 1737.371 1612847810.199649
train: epoch 16, iter 1100, loss: 3.122254, top_1: 0.487539, top_k: 0.726484, samples/s: 1735.043 1612847824.9544213
train: epoch 16, iter 1200, loss: 3.156972, top_1: 0.487695, top_k: 0.729961, samples/s: 1719.036 1612847839.8464575
train: epoch 16, iter 1300, loss: 3.234063, top_1: 0.486680, top_k: 0.722695, samples/s: 1738.301 1612847854.5733786
train: epoch 16, iter 1400, loss: 3.245288, top_1: 0.486211, top_k: 0.724922, samples/s: 1724.864 1612847869.415135
train: epoch 16, iter 1500, loss: 3.362511, top_1: 0.485586, top_k: 0.725391, samples/s: 1741.185 1612847884.1178188
train: epoch 16, iter 1600, loss: 3.345267, top_1: 0.479805, top_k: 0.723555, samples/s: 1737.505 1612847898.8515778
train: epoch 16, iter 1700, loss: 3.316117, top_1: 0.481211, top_k: 0.723711, samples/s: 1728.018 1612847913.6663673
train: epoch 16, iter 1800, loss: 3.163517, top_1: 0.472187, top_k: 0.720781, samples/s: 1732.742 1612847928.4404755
train: epoch 16, iter 1900, loss: 3.347227, top_1: 0.478281, top_k: 0.720938, samples/s: 1760.703 1612847942.9801376
train: epoch 16, iter 2000, loss: 3.062465, top_1: 0.479609, top_k: 0.724648, samples/s: 1746.878 1612847957.6348953
train: epoch 16, iter 2100, loss: 3.397113, top_1: 0.483945, top_k: 0.723555, samples/s: 1738.246 1612847972.362387
train: epoch 16, iter 2200, loss: 3.333337, top_1: 0.475781, top_k: 0.723555, samples/s: 1738.437 1612847987.0881984
train: epoch 16, iter 2300, loss: 3.050083, top_1: 0.481836, top_k: 0.723398, samples/s: 1741.578 1612848001.7875144
train: epoch 16, iter 2400, loss: 3.147797, top_1: 0.478828, top_k: 0.722031, samples/s: 1747.842 1612848016.434279
train: epoch 16, iter 2500, loss: 3.090719, top_1: 0.483398, top_k: 0.724141, samples/s: 1737.424 1612848031.1686199
train: epoch 16, iter 2600, loss: 3.200020, top_1: 0.479453, top_k: 0.720117, samples/s: 1747.040 1612848045.822003
train: epoch 16, iter 2700, loss: 3.168849, top_1: 0.485586, top_k: 0.723477, samples/s: 1745.911 1612848060.484812
train: epoch 16, iter 2800, loss: 3.068230, top_1: 0.477773, top_k: 0.722227, samples/s: 1739.896 1612848075.198347
train: epoch 16, iter 2900, loss: 3.128640, top_1: 0.476719, top_k: 0.724141, samples/s: 1743.343 1612848089.8827395
train: epoch 16, iter 3000, loss: 3.201265, top_1: 0.483125, top_k: 0.721797, samples/s: 1746.282 1612848104.542453
train: epoch 16, iter 3100, loss: 3.390666, top_1: 0.482734, top_k: 0.719688, samples/s: 1750.208 1612848119.1693208
train: epoch 16, iter 3200, loss: 3.254885, top_1: 0.483242, top_k: 0.720664, samples/s: 1742.543 1612848133.8604589
train: epoch 16, iter 3300, loss: 3.332269, top_1: 0.483047, top_k: 0.724414, samples/s: 1740.120 1612848148.572101
train: epoch 16, iter 3400, loss: 3.321918, top_1: 0.486328, top_k: 0.726016, samples/s: 1733.557 1612848163.3395
train: epoch 16, iter 3500, loss: 3.133022, top_1: 0.489141, top_k: 0.723555, samples/s: 1738.296 1612848178.0665736
train: epoch 16, iter 3600, loss: 3.201441, top_1: 0.480586, top_k: 0.727852, samples/s: 1751.331 1612848192.683923
train: epoch 16, iter 3700, loss: 3.193214, top_1: 0.480820, top_k: 0.719805, samples/s: 1740.432 1612848207.3930428
train: epoch 16, iter 3800, loss: 3.188764, top_1: 0.484180, top_k: 0.725508, samples/s: 1746.379 1612848222.051869
train: epoch 16, iter 3900, loss: 3.119825, top_1: 0.482734, top_k: 0.726641, samples/s: 1742.055 1612848236.747101
train: epoch 16, iter 4000, loss: 3.284719, top_1: 0.483867, top_k: 0.724141, samples/s: 1744.737 1612848251.419837
train: epoch 16, iter 4100, loss: 3.107225, top_1: 0.483281, top_k: 0.725703, samples/s: 1750.516 1612848266.04413
train: epoch 16, iter 4200, loss: 3.235821, top_1: 0.475508, top_k: 0.720156, samples/s: 1744.289 1612848280.7205925
train: epoch 16, iter 4300, loss: 3.264153, top_1: 0.478320, top_k: 0.720977, samples/s: 1747.100 1612848295.3734355
train: epoch 16, iter 4400, loss: 3.307238, top_1: 0.479453, top_k: 0.722227, samples/s: 1737.902 1612848310.103824
train: epoch 16, iter 4500, loss: 3.061337, top_1: 0.484922, top_k: 0.724648, samples/s: 1733.555 1612848324.8711782
train: epoch 16, iter 4600, loss: 3.257482, top_1: 0.479922, top_k: 0.721055, samples/s: 1740.796 1612848339.5770454
train: epoch 16, iter 4700, loss: 3.136501, top_1: 0.479219, top_k: 0.724531, samples/s: 1751.636 1612848354.1919856
train: epoch 16, iter 4800, loss: 2.938986, top_1: 0.478633, top_k: 0.722812, samples/s: 1752.632 1612848368.7985437
train: epoch 16, iter 4900, loss: 3.201338, top_1: 0.476680, top_k: 0.717461, samples/s: 1748.042 1612848383.443503
train: epoch 16, iter 5000, loss: 3.280430, top_1: 0.477187, top_k: 0.725000, samples/s: 1750.093 1612848398.0712981
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_16.
validation: epoch 16, iter 195, top_1: 0.505288, top_k: 0.763101, samples/s: 2850.114 1612848416.041535
train: epoch 17, iter 100, loss: 2.939397, top_1: 0.486758, top_k: 0.726719, samples/s: 1745.126 1612848450.8654044
train: epoch 17, iter 200, loss: 3.317086, top_1: 0.481992, top_k: 0.727187, samples/s: 1746.406 1612848465.5241857
train: epoch 17, iter 300, loss: 3.177044, top_1: 0.491523, top_k: 0.733711, samples/s: 1760.272 1612848480.0675304
train: epoch 17, iter 400, loss: 3.067359, top_1: 0.487422, top_k: 0.726992, samples/s: 1747.022 1612848494.72082
train: epoch 17, iter 500, loss: 3.205758, top_1: 0.485625, top_k: 0.730898, samples/s: 1759.138 1612848509.2733526
train: epoch 17, iter 600, loss: 3.082629, top_1: 0.490234, top_k: 0.729023, samples/s: 1757.970 1612848523.8356192
train: epoch 17, iter 700, loss: 3.346919, top_1: 0.478828, top_k: 0.725391, samples/s: 1721.324 1612848538.707926
train: epoch 17, iter 800, loss: 3.311313, top_1: 0.485039, top_k: 0.725938, samples/s: 1737.573 1612848553.4411242
train: epoch 17, iter 900, loss: 3.229968, top_1: 0.490195, top_k: 0.729141, samples/s: 1735.161 1612848568.1948106
train: epoch 17, iter 1000, loss: 3.145640, top_1: 0.482070, top_k: 0.727617, samples/s: 1729.528 1612848582.996554
train: epoch 17, iter 1100, loss: 3.108912, top_1: 0.491992, top_k: 0.731211, samples/s: 1725.517 1612848597.8326037
train: epoch 17, iter 1200, loss: 3.304735, top_1: 0.489180, top_k: 0.727734, samples/s: 1719.558 1612848612.7202365
train: epoch 17, iter 1300, loss: 3.286802, top_1: 0.486992, top_k: 0.731406, samples/s: 1726.872 1612848627.544722
train: epoch 17, iter 1400, loss: 3.201980, top_1: 0.480078, top_k: 0.726133, samples/s: 1734.354 1612848642.3052542
train: epoch 17, iter 1500, loss: 3.305602, top_1: 0.486094, top_k: 0.729453, samples/s: 1728.061 1612848657.1195269
train: epoch 17, iter 1600, loss: 3.031032, top_1: 0.486563, top_k: 0.727109, samples/s: 1725.329 1612848671.9572868
train: epoch 17, iter 1700, loss: 3.049785, top_1: 0.484414, top_k: 0.721367, samples/s: 1727.993 1612848686.7721198
train: epoch 17, iter 1800, loss: 3.256107, top_1: 0.486250, top_k: 0.725977, samples/s: 1731.128 1612848701.5601616
train: epoch 17, iter 1900, loss: 2.994009, top_1: 0.485391, top_k: 0.727031, samples/s: 1727.513 1612848716.3791394
train: epoch 17, iter 2000, loss: 3.023129, top_1: 0.483281, top_k: 0.729727, samples/s: 1722.470 1612848731.2415292
train: epoch 17, iter 2100, loss: 3.283022, top_1: 0.484141, top_k: 0.724883, samples/s: 1724.212 1612848746.0889118
train: epoch 17, iter 2200, loss: 3.275960, top_1: 0.484102, top_k: 0.724609, samples/s: 1714.311 1612848761.0219984
train: epoch 17, iter 2300, loss: 3.107806, top_1: 0.486836, top_k: 0.726641, samples/s: 1728.808 1612848775.8299367
train: epoch 17, iter 2400, loss: 3.402033, top_1: 0.490234, top_k: 0.731992, samples/s: 1721.500 1612848790.700639
train: epoch 17, iter 2500, loss: 3.242039, top_1: 0.484219, top_k: 0.725625, samples/s: 1733.545 1612848805.4680455
train: epoch 17, iter 2600, loss: 3.151839, top_1: 0.484375, top_k: 0.725000, samples/s: 1733.724 1612848820.2339563
train: epoch 17, iter 2700, loss: 3.500473, top_1: 0.481797, top_k: 0.725859, samples/s: 1741.114 1612848834.9372022
train: epoch 17, iter 2800, loss: 3.131945, top_1: 0.486953, top_k: 0.730391, samples/s: 1739.926 1612848849.6505044
train: epoch 17, iter 2900, loss: 3.008161, top_1: 0.479180, top_k: 0.724102, samples/s: 1742.802 1612848864.339457
train: epoch 17, iter 3000, loss: 3.166547, top_1: 0.488555, top_k: 0.726914, samples/s: 1738.802 1612848879.062295
train: epoch 17, iter 3100, loss: 3.303869, top_1: 0.488125, top_k: 0.727031, samples/s: 1745.385 1612848893.729567
train: epoch 17, iter 3200, loss: 3.055369, top_1: 0.485234, top_k: 0.728164, samples/s: 1748.267 1612848908.3726258
train: epoch 17, iter 3300, loss: 3.169265, top_1: 0.483750, top_k: 0.728828, samples/s: 1746.624 1612848923.0294702
train: epoch 17, iter 3400, loss: 3.215754, top_1: 0.486211, top_k: 0.726797, samples/s: 1734.854 1612848937.7857287
train: epoch 17, iter 3500, loss: 3.370551, top_1: 0.481992, top_k: 0.726602, samples/s: 1734.927 1612848952.5414517
train: epoch 17, iter 3600, loss: 3.205282, top_1: 0.483438, top_k: 0.729375, samples/s: 1742.712 1612848967.231123
train: epoch 17, iter 3700, loss: 3.304281, top_1: 0.484414, top_k: 0.728555, samples/s: 1752.696 1612848981.837177
train: epoch 17, iter 3800, loss: 2.961779, top_1: 0.485195, top_k: 0.725664, samples/s: 1737.307 1612848996.5726933
train: epoch 17, iter 3900, loss: 3.163333, top_1: 0.480352, top_k: 0.726211, samples/s: 1743.811 1612849011.2531638
train: epoch 17, iter 4000, loss: 3.298641, top_1: 0.479492, top_k: 0.721562, samples/s: 1745.175 1612849025.922128
train: epoch 17, iter 4100, loss: 3.200374, top_1: 0.487539, top_k: 0.724883, samples/s: 1742.072 1612849040.6173344
train: epoch 17, iter 4200, loss: 3.130687, top_1: 0.481875, top_k: 0.721133, samples/s: 1743.258 1612849055.302432
train: epoch 17, iter 4300, loss: 3.152811, top_1: 0.487461, top_k: 0.731367, samples/s: 1740.758 1612849070.0087113
train: epoch 17, iter 4400, loss: 3.225629, top_1: 0.482734, top_k: 0.725977, samples/s: 1737.349 1612849084.7437723
train: epoch 17, iter 4500, loss: 3.053457, top_1: 0.489805, top_k: 0.731445, samples/s: 1743.685 1612849099.4253688
train: epoch 17, iter 4600, loss: 3.163178, top_1: 0.481680, top_k: 0.727539, samples/s: 1747.624 1612849114.073829
train: epoch 17, iter 4700, loss: 3.210425, top_1: 0.484180, top_k: 0.728633, samples/s: 1737.951 1612849128.8038485
train: epoch 17, iter 4800, loss: 3.256575, top_1: 0.482930, top_k: 0.724531, samples/s: 1742.942 1612849143.4915686
train: epoch 17, iter 4900, loss: 3.062710, top_1: 0.485625, top_k: 0.727500, samples/s: 1734.020 1612849158.255095
train: epoch 17, iter 5000, loss: 3.138628, top_1: 0.486133, top_k: 0.730547, samples/s: 1745.922 1612849172.9177132
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_17.
validation: epoch 17, iter 195, top_1: 0.534756, top_k: 0.785937, samples/s: 2886.673 1612849190.6969056
train: epoch 18, iter 100, loss: 3.293478, top_1: 0.494922, top_k: 0.732891, samples/s: 1751.779 1612849225.3331592
train: epoch 18, iter 200, loss: 3.030895, top_1: 0.492422, top_k: 0.732305, samples/s: 1754.763 1612849239.922191
train: epoch 18, iter 300, loss: 3.122317, top_1: 0.485156, top_k: 0.727422, samples/s: 1757.765 1612849254.4859567
train: epoch 18, iter 400, loss: 3.161216, top_1: 0.486094, top_k: 0.732695, samples/s: 1759.519 1612849269.0354035
train: epoch 18, iter 500, loss: 3.220993, top_1: 0.493125, top_k: 0.733945, samples/s: 1757.938 1612849283.5979934
train: epoch 18, iter 600, loss: 3.018895, top_1: 0.488984, top_k: 0.733398, samples/s: 1755.960 1612849298.1768131
train: epoch 18, iter 700, loss: 3.094737, top_1: 0.484805, top_k: 0.734180, samples/s: 1747.011 1612849312.830421
train: epoch 18, iter 800, loss: 3.078489, top_1: 0.488633, top_k: 0.727031, samples/s: 1717.107 1612849327.7392952
train: epoch 18, iter 900, loss: 3.096363, top_1: 0.487617, top_k: 0.733477, samples/s: 1728.401 1612849342.5507348
train: epoch 18, iter 1000, loss: 3.013578, top_1: 0.491055, top_k: 0.732734, samples/s: 1724.976 1612849357.3913076
train: epoch 18, iter 1100, loss: 3.218610, top_1: 0.493398, top_k: 0.733672, samples/s: 1726.669 1612849372.2175791
train: epoch 18, iter 1200, loss: 3.265578, top_1: 0.492812, top_k: 0.729922, samples/s: 1725.028 1612849387.0578861
train: epoch 18, iter 1300, loss: 3.005510, top_1: 0.488242, top_k: 0.726602, samples/s: 1742.841 1612849401.7466059
train: epoch 18, iter 1400, loss: 3.162877, top_1: 0.485391, top_k: 0.726797, samples/s: 1727.850 1612849416.562737
train: epoch 18, iter 1500, loss: 3.084128, top_1: 0.487227, top_k: 0.728437, samples/s: 1747.468 1612849431.212488
train: epoch 18, iter 1600, loss: 3.261344, top_1: 0.493750, top_k: 0.734492, samples/s: 1736.976 1612849445.9506888
train: epoch 18, iter 1700, loss: 3.011014, top_1: 0.487344, top_k: 0.728047, samples/s: 1745.674 1612849460.615586
train: epoch 18, iter 1800, loss: 3.113351, top_1: 0.481836, top_k: 0.726719, samples/s: 1747.190 1612849475.2676063
train: epoch 18, iter 1900, loss: 2.974319, top_1: 0.488203, top_k: 0.733086, samples/s: 1743.246 1612849489.9529111
train: epoch 18, iter 2000, loss: 3.376413, top_1: 0.492539, top_k: 0.731250, samples/s: 1740.861 1612849504.6582747
train: epoch 18, iter 2100, loss: 3.147622, top_1: 0.483203, top_k: 0.725352, samples/s: 1740.634 1612849519.3655298
train: epoch 18, iter 2200, loss: 3.237018, top_1: 0.491602, top_k: 0.729961, samples/s: 1735.254 1612849534.1184301
train: epoch 18, iter 2300, loss: 3.247949, top_1: 0.485117, top_k: 0.725195, samples/s: 1753.497 1612849548.7178445
train: epoch 18, iter 2400, loss: 3.242975, top_1: 0.478711, top_k: 0.724766, samples/s: 1736.448 1612849563.4605806
train: epoch 18, iter 2500, loss: 3.078650, top_1: 0.489375, top_k: 0.734727, samples/s: 1741.709 1612849578.158765
train: epoch 18, iter 2600, loss: 3.032405, top_1: 0.487109, top_k: 0.730195, samples/s: 1739.622 1612849592.8745663
train: epoch 18, iter 2700, loss: 2.908388, top_1: 0.492188, top_k: 0.732812, samples/s: 1746.722 1612849607.53062
train: epoch 18, iter 2800, loss: 3.192846, top_1: 0.481055, top_k: 0.730273, samples/s: 1726.758 1612849622.3560967
train: epoch 18, iter 2900, loss: 3.126117, top_1: 0.485156, top_k: 0.724609, samples/s: 1756.031 1612849636.9343987
train: epoch 18, iter 3000, loss: 3.143265, top_1: 0.485938, top_k: 0.724375, samples/s: 1731.143 1612849651.7223146
train: epoch 18, iter 3100, loss: 3.028256, top_1: 0.492305, top_k: 0.729648, samples/s: 1751.239 1612849666.340571
train: epoch 18, iter 3200, loss: 3.036571, top_1: 0.491758, top_k: 0.729609, samples/s: 1740.441 1612849681.0494642
train: epoch 18, iter 3300, loss: 3.150088, top_1: 0.488203, top_k: 0.730859, samples/s: 1735.162 1612849695.8031762
train: epoch 18, iter 3400, loss: 2.997774, top_1: 0.487070, top_k: 0.724609, samples/s: 1747.740 1612849710.4507415
train: epoch 18, iter 3500, loss: 3.102316, top_1: 0.483867, top_k: 0.727539, samples/s: 1741.681 1612849725.149193
train: epoch 18, iter 3600, loss: 3.064335, top_1: 0.494102, top_k: 0.736328, samples/s: 1750.680 1612849739.7719445
train: epoch 18, iter 3700, loss: 2.992994, top_1: 0.484922, top_k: 0.731953, samples/s: 1725.119 1612849754.6115906
train: epoch 18, iter 3800, loss: 3.115553, top_1: 0.491289, top_k: 0.732891, samples/s: 1755.069 1612849769.1978228
train: epoch 18, iter 3900, loss: 2.991696, top_1: 0.487969, top_k: 0.728516, samples/s: 1746.644 1612849783.8545053
train: epoch 18, iter 4000, loss: 3.156883, top_1: 0.491367, top_k: 0.729453, samples/s: 1731.701 1612849798.6377046
train: epoch 18, iter 4100, loss: 3.294430, top_1: 0.488594, top_k: 0.729648, samples/s: 1744.687 1612849813.3108804
train: epoch 18, iter 4200, loss: 3.123683, top_1: 0.489766, top_k: 0.729336, samples/s: 1753.692 1612849827.9086375
train: epoch 18, iter 4300, loss: 3.111118, top_1: 0.482305, top_k: 0.724570, samples/s: 1738.809 1612849842.6314065
train: epoch 18, iter 4400, loss: 3.256126, top_1: 0.485781, top_k: 0.727969, samples/s: 1745.058 1612849857.301353
train: epoch 18, iter 4500, loss: 3.121747, top_1: 0.484961, top_k: 0.729648, samples/s: 1748.553 1612849871.9420357
train: epoch 18, iter 4600, loss: 3.092033, top_1: 0.487422, top_k: 0.727031, samples/s: 1739.615 1612849886.6578915
train: epoch 18, iter 4700, loss: 3.146979, top_1: 0.485039, top_k: 0.730859, samples/s: 1738.906 1612849901.3798177
train: epoch 18, iter 4800, loss: 3.267773, top_1: 0.483984, top_k: 0.729492, samples/s: 1748.982 1612849916.0168653
train: epoch 18, iter 4900, loss: 3.186354, top_1: 0.489531, top_k: 0.727500, samples/s: 1745.943 1612849930.6794095
train: epoch 18, iter 5000, loss: 3.063426, top_1: 0.491992, top_k: 0.730586, samples/s: 1742.150 1612849945.3739114
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_18.
validation: epoch 18, iter 195, top_1: 0.537740, top_k: 0.783353, samples/s: 2897.069 1612849963.0457776
train: epoch 19, iter 100, loss: 3.001865, top_1: 0.500977, top_k: 0.737031, samples/s: 1746.317 1612849998.5238345
train: epoch 19, iter 200, loss: 3.270253, top_1: 0.497812, top_k: 0.737969, samples/s: 1761.794 1612850013.0544538
train: epoch 19, iter 300, loss: 3.105752, top_1: 0.491953, top_k: 0.734297, samples/s: 1755.446 1612850027.6376317
train: epoch 19, iter 400, loss: 2.991163, top_1: 0.494102, top_k: 0.734102, samples/s: 1751.695 1612850042.2520745
train: epoch 19, iter 500, loss: 3.028411, top_1: 0.493984, top_k: 0.732383, samples/s: 1764.729 1612850056.7584863
train: epoch 19, iter 600, loss: 3.186072, top_1: 0.500781, top_k: 0.737930, samples/s: 1748.849 1612850071.396686
train: epoch 19, iter 700, loss: 3.191847, top_1: 0.489492, top_k: 0.729727, samples/s: 1720.509 1612850086.2759652
train: epoch 19, iter 800, loss: 3.000339, top_1: 0.498633, top_k: 0.736602, samples/s: 1733.214 1612850101.0466068
train: epoch 19, iter 900, loss: 3.140268, top_1: 0.489570, top_k: 0.729648, samples/s: 1723.458 1612850115.9001071
train: epoch 19, iter 1000, loss: 3.064795, top_1: 0.493320, top_k: 0.733867, samples/s: 1732.106 1612850130.6797888
train: epoch 19, iter 1100, loss: 3.046379, top_1: 0.490859, top_k: 0.730859, samples/s: 1726.019 1612850145.51212
train: epoch 19, iter 1200, loss: 3.227154, top_1: 0.496914, top_k: 0.733867, samples/s: 1725.536 1612850160.3476014
train: epoch 19, iter 1300, loss: 3.142297, top_1: 0.489336, top_k: 0.732344, samples/s: 1728.661 1612850175.1567838
train: epoch 19, iter 1400, loss: 3.055400, top_1: 0.490781, top_k: 0.733945, samples/s: 1714.681 1612850190.0866995
train: epoch 19, iter 1500, loss: 3.319837, top_1: 0.487969, top_k: 0.729492, samples/s: 1725.636 1612850204.9217024
train: epoch 19, iter 1600, loss: 2.918038, top_1: 0.488633, top_k: 0.729531, samples/s: 1726.777 1612850219.74703
train: epoch 19, iter 1700, loss: 3.212103, top_1: 0.491563, top_k: 0.729453, samples/s: 1731.479 1612850234.5320523
train: epoch 19, iter 1800, loss: 3.293429, top_1: 0.487734, top_k: 0.727070, samples/s: 1723.455 1612850249.3859653
train: epoch 19, iter 1900, loss: 2.961798, top_1: 0.491406, top_k: 0.732461, samples/s: 1712.321 1612850264.3364105
train: epoch 19, iter 2000, loss: 3.283604, top_1: 0.493047, top_k: 0.734570, samples/s: 1728.324 1612850279.1488433
train: epoch 19, iter 2100, loss: 3.214128, top_1: 0.488633, top_k: 0.733516, samples/s: 1727.261 1612850293.969676
train: epoch 19, iter 2200, loss: 3.210881, top_1: 0.492930, top_k: 0.731953, samples/s: 1712.602 1612850308.9176736
train: epoch 19, iter 2300, loss: 3.157649, top_1: 0.496523, top_k: 0.736602, samples/s: 1718.162 1612850323.8173473
train: epoch 19, iter 2400, loss: 3.384243, top_1: 0.494180, top_k: 0.733242, samples/s: 1729.486 1612850338.6194153
train: epoch 19, iter 2500, loss: 2.909208, top_1: 0.493789, top_k: 0.736016, samples/s: 1714.884 1612850353.5478265
train: epoch 19, iter 2600, loss: 3.242944, top_1: 0.488906, top_k: 0.731484, samples/s: 1739.460 1612850368.2646947
train: epoch 19, iter 2700, loss: 3.179283, top_1: 0.498437, top_k: 0.736094, samples/s: 1724.530 1612850383.1093545
train: epoch 19, iter 2800, loss: 3.022840, top_1: 0.486367, top_k: 0.729766, samples/s: 1720.525 1612850397.9886088
train: epoch 19, iter 2900, loss: 3.073751, top_1: 0.490234, top_k: 0.728867, samples/s: 1726.973 1612850412.812181
train: epoch 19, iter 3000, loss: 3.142740, top_1: 0.492383, top_k: 0.735391, samples/s: 1725.423 1612850427.649075
train: epoch 19, iter 3100, loss: 3.263764, top_1: 0.486758, top_k: 0.729609, samples/s: 1715.198 1612850442.5744667
train: epoch 19, iter 3200, loss: 2.981616, top_1: 0.480938, top_k: 0.724805, samples/s: 1726.372 1612850457.4036582
train: epoch 19, iter 3300, loss: 2.876576, top_1: 0.486016, top_k: 0.727461, samples/s: 1724.030 1612850472.2522628
train: epoch 19, iter 3400, loss: 3.353257, top_1: 0.489453, top_k: 0.732500, samples/s: 1728.506 1612850487.0627167
train: epoch 19, iter 3500, loss: 2.939663, top_1: 0.489844, top_k: 0.729766, samples/s: 1726.569 1612850501.8897736
train: epoch 19, iter 3600, loss: 3.090052, top_1: 0.486914, top_k: 0.727539, samples/s: 1720.173 1612850516.7719696
train: epoch 19, iter 3700, loss: 3.189957, top_1: 0.491172, top_k: 0.731680, samples/s: 1720.777 1612850531.6489682
train: epoch 19, iter 3800, loss: 3.183446, top_1: 0.489844, top_k: 0.730742, samples/s: 1714.634 1612850546.5792768
train: epoch 19, iter 3900, loss: 3.062139, top_1: 0.491211, top_k: 0.727227, samples/s: 1721.440 1612850561.450537
train: epoch 19, iter 4000, loss: 3.231112, top_1: 0.493516, top_k: 0.729609, samples/s: 1717.682 1612850576.354642
train: epoch 19, iter 4100, loss: 2.985677, top_1: 0.488516, top_k: 0.725117, samples/s: 1727.280 1612850591.1754174
train: epoch 19, iter 4200, loss: 2.924806, top_1: 0.485078, top_k: 0.727773, samples/s: 1722.776 1612850606.0351517
train: epoch 19, iter 4300, loss: 3.055007, top_1: 0.493437, top_k: 0.731445, samples/s: 1721.686 1612850620.9042122
train: epoch 19, iter 4400, loss: 3.110446, top_1: 0.487969, top_k: 0.728398, samples/s: 1717.328 1612850635.81108
train: epoch 19, iter 4500, loss: 2.969671, top_1: 0.492305, top_k: 0.731797, samples/s: 1720.254 1612850650.6926587
train: epoch 19, iter 4600, loss: 3.381516, top_1: 0.489180, top_k: 0.735352, samples/s: 1713.191 1612850665.635503
train: epoch 19, iter 4700, loss: 3.241415, top_1: 0.492656, top_k: 0.733828, samples/s: 1724.546 1612850680.47996
train: epoch 19, iter 4800, loss: 3.170691, top_1: 0.494063, top_k: 0.734609, samples/s: 1733.964 1612850695.2438824
train: epoch 19, iter 4900, loss: 3.137259, top_1: 0.488125, top_k: 0.729961, samples/s: 1727.678 1612850710.0613961
train: epoch 19, iter 5000, loss: 3.235881, top_1: 0.491250, top_k: 0.731953, samples/s: 1716.800 1612850724.9729066
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_19.
validation: epoch 19, iter 195, top_1: 0.536999, top_k: 0.786438, samples/s: 2861.685 1612850742.8201387
train: epoch 20, iter 100, loss: 3.157615, top_1: 0.493633, top_k: 0.736133, samples/s: 1757.591 1612850777.6356275
train: epoch 20, iter 200, loss: 3.075816, top_1: 0.498164, top_k: 0.741484, samples/s: 1755.005 1612850792.2224786
train: epoch 20, iter 300, loss: 3.054039, top_1: 0.499258, top_k: 0.736172, samples/s: 1754.278 1612850806.8154383
train: epoch 20, iter 400, loss: 2.976803, top_1: 0.491094, top_k: 0.733828, samples/s: 1762.298 1612850821.341857
train: epoch 20, iter 500, loss: 2.954205, top_1: 0.503242, top_k: 0.743164, samples/s: 1737.104 1612850836.079446
train: epoch 20, iter 600, loss: 3.295154, top_1: 0.502656, top_k: 0.741523, samples/s: 1737.004 1612850850.8170676
train: epoch 20, iter 700, loss: 3.070845, top_1: 0.494180, top_k: 0.736172, samples/s: 1724.149 1612850865.6649237
train: epoch 20, iter 800, loss: 3.311418, top_1: 0.498164, top_k: 0.738281, samples/s: 1718.282 1612850880.5635133
train: epoch 20, iter 900, loss: 3.119377, top_1: 0.498086, top_k: 0.739727, samples/s: 1711.334 1612850895.522598
train: epoch 20, iter 1000, loss: 3.066637, top_1: 0.499336, top_k: 0.740469, samples/s: 1725.807 1612850910.3562837
train: epoch 20, iter 1100, loss: 2.996380, top_1: 0.494883, top_k: 0.737031, samples/s: 1726.375 1612850925.1850493
train: epoch 20, iter 1200, loss: 3.359970, top_1: 0.501250, top_k: 0.739727, samples/s: 1722.288 1612850940.0489497
train: epoch 20, iter 1300, loss: 3.180665, top_1: 0.494297, top_k: 0.733437, samples/s: 1714.233 1612850954.9827502
train: epoch 20, iter 1400, loss: 3.200111, top_1: 0.488633, top_k: 0.729375, samples/s: 1715.744 1612850969.9033837
train: epoch 20, iter 1500, loss: 3.113370, top_1: 0.493672, top_k: 0.737773, samples/s: 1712.193 1612850984.8550007
train: epoch 20, iter 1600, loss: 2.949610, top_1: 0.496563, top_k: 0.734258, samples/s: 1724.464 1612850999.7001576
train: epoch 20, iter 1700, loss: 3.120414, top_1: 0.498828, top_k: 0.737969, samples/s: 1737.645 1612851014.4332159
train: epoch 20, iter 1800, loss: 3.175770, top_1: 0.493008, top_k: 0.732969, samples/s: 1717.033 1612851029.3425257
train: epoch 20, iter 1900, loss: 3.041762, top_1: 0.496641, top_k: 0.735547, samples/s: 1730.799 1612851044.133079
train: epoch 20, iter 2000, loss: 3.189491, top_1: 0.490859, top_k: 0.736250, samples/s: 1701.567 1612851059.1780016
train: epoch 20, iter 2100, loss: 2.988732, top_1: 0.495664, top_k: 0.733906, samples/s: 1729.685 1612851073.978418
train: epoch 20, iter 2200, loss: 3.291996, top_1: 0.491523, top_k: 0.735273, samples/s: 1727.172 1612851088.800343
train: epoch 20, iter 2300, loss: 3.109411, top_1: 0.492461, top_k: 0.736016, samples/s: 1720.276 1612851103.681643
train: epoch 20, iter 2400, loss: 3.088843, top_1: 0.497188, top_k: 0.735547, samples/s: 1711.853 1612851118.6365354
train: epoch 20, iter 2500, loss: 3.091769, top_1: 0.492852, top_k: 0.735078, samples/s: 1715.761 1612851133.5567422
train: epoch 20, iter 2600, loss: 3.239287, top_1: 0.496094, top_k: 0.734805, samples/s: 1719.034 1612851148.4491973
train: epoch 20, iter 2700, loss: 2.809177, top_1: 0.495781, top_k: 0.734531, samples/s: 1729.052 1612851163.254568
train: epoch 20, iter 2800, loss: 3.185407, top_1: 0.496797, top_k: 0.735352, samples/s: 1732.800 1612851178.028692
train: epoch 20, iter 2900, loss: 3.057922, top_1: 0.495156, top_k: 0.734258, samples/s: 1736.944 1612851192.7669735
train: epoch 20, iter 3000, loss: 3.068002, top_1: 0.497422, top_k: 0.738398, samples/s: 1734.873 1612851207.5234866
train: epoch 20, iter 3100, loss: 3.212597, top_1: 0.490078, top_k: 0.729805, samples/s: 1730.389 1612851222.317473
train: epoch 20, iter 3200, loss: 3.102319, top_1: 0.497734, top_k: 0.735547, samples/s: 1723.324 1612851237.1723614
train: epoch 20, iter 3300, loss: 2.929704, top_1: 0.495820, top_k: 0.735586, samples/s: 1724.608 1612851252.016381
train: epoch 20, iter 3400, loss: 3.421494, top_1: 0.497383, top_k: 0.735820, samples/s: 1741.323 1612851266.717802
train: epoch 20, iter 3500, loss: 3.224300, top_1: 0.499961, top_k: 0.737734, samples/s: 1726.532 1612851281.5452485
train: epoch 20, iter 3600, loss: 3.254205, top_1: 0.497773, top_k: 0.737031, samples/s: 1719.077 1612851296.4370394
train: epoch 20, iter 3700, loss: 3.066703, top_1: 0.489805, top_k: 0.727969, samples/s: 1726.296 1612851311.2663908
train: epoch 20, iter 3800, loss: 3.071446, top_1: 0.493242, top_k: 0.729180, samples/s: 1719.552 1612851326.1540482
train: epoch 20, iter 3900, loss: 3.168196, top_1: 0.493086, top_k: 0.735000, samples/s: 1725.489 1612851340.9903376
train: epoch 20, iter 4000, loss: 3.104981, top_1: 0.493633, top_k: 0.732773, samples/s: 1731.245 1612851355.7773728
train: epoch 20, iter 4100, loss: 3.155631, top_1: 0.487148, top_k: 0.726836, samples/s: 1732.251 1612851370.5558796
train: epoch 20, iter 4200, loss: 3.270586, top_1: 0.494102, top_k: 0.733711, samples/s: 1744.383 1612851385.2315006
train: epoch 20, iter 4300, loss: 3.079388, top_1: 0.496836, top_k: 0.737773, samples/s: 1724.042 1612851400.0803351
train: epoch 20, iter 4400, loss: 3.131852, top_1: 0.490938, top_k: 0.731992, samples/s: 1723.269 1612851414.9358327
train: epoch 20, iter 4500, loss: 3.046785, top_1: 0.492383, top_k: 0.733789, samples/s: 1727.557 1612851429.754413
train: epoch 20, iter 4600, loss: 3.069704, top_1: 0.492109, top_k: 0.734258, samples/s: 1718.333 1612851444.652607
train: epoch 20, iter 4700, loss: 2.899510, top_1: 0.492852, top_k: 0.732656, samples/s: 1744.257 1612851459.3296359
train: epoch 20, iter 4800, loss: 3.080102, top_1: 0.489961, top_k: 0.731445, samples/s: 1737.868 1612851474.0600777
train: epoch 20, iter 4900, loss: 3.230550, top_1: 0.484922, top_k: 0.725586, samples/s: 1715.321 1612851488.984819
train: epoch 20, iter 5000, loss: 2.865707, top_1: 0.493359, top_k: 0.735352, samples/s: 1725.376 1612851503.8216655
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_20.
validation: epoch 20, iter 195, top_1: 0.539022, top_k: 0.784455, samples/s: 2800.227 1612851522.0332603
train: epoch 21, iter 100, loss: 2.995331, top_1: 0.506250, top_k: 0.749414, samples/s: 1751.857 1612851556.7528555
train: epoch 21, iter 200, loss: 2.986547, top_1: 0.510742, top_k: 0.744961, samples/s: 1762.089 1612851571.2812448
train: epoch 21, iter 300, loss: 3.126634, top_1: 0.500703, top_k: 0.740820, samples/s: 1746.700 1612851585.9371989
train: epoch 21, iter 400, loss: 3.165491, top_1: 0.497422, top_k: 0.744336, samples/s: 1771.710 1612851600.3865037
train: epoch 21, iter 500, loss: 3.168419, top_1: 0.503477, top_k: 0.743828, samples/s: 1755.029 1612851614.9731698
train: epoch 21, iter 600, loss: 3.151655, top_1: 0.501367, top_k: 0.738281, samples/s: 1753.297 1612851629.5746331
train: epoch 21, iter 700, loss: 3.090561, top_1: 0.493320, top_k: 0.735938, samples/s: 1754.130 1612851644.1684566
train: epoch 21, iter 800, loss: 3.227705, top_1: 0.497695, top_k: 0.737383, samples/s: 1732.960 1612851658.9411445
train: epoch 21, iter 900, loss: 3.136911, top_1: 0.500625, top_k: 0.739805, samples/s: 1733.517 1612851673.708449
train: epoch 21, iter 1000, loss: 3.170472, top_1: 0.492305, top_k: 0.733867, samples/s: 1730.281 1612851688.5038068
train: epoch 21, iter 1100, loss: 3.157903, top_1: 0.497812, top_k: 0.738164, samples/s: 1752.452 1612851703.1118624
train: epoch 21, iter 1200, loss: 3.070471, top_1: 0.501758, top_k: 0.738672, samples/s: 1722.613 1612851717.972973
train: epoch 21, iter 1300, loss: 3.116864, top_1: 0.499219, top_k: 0.737773, samples/s: 1717.624 1612851732.8773508
train: epoch 21, iter 1400, loss: 3.014735, top_1: 0.500977, top_k: 0.735898, samples/s: 1734.034 1612851747.6405544
train: epoch 21, iter 1500, loss: 2.895026, top_1: 0.496484, top_k: 0.736563, samples/s: 1737.030 1612851762.3783247
train: epoch 21, iter 1600, loss: 3.154631, top_1: 0.496914, top_k: 0.735195, samples/s: 1733.364 1612851777.147299
train: epoch 21, iter 1700, loss: 3.039003, top_1: 0.500391, top_k: 0.739023, samples/s: 1725.434 1612851791.9842288
train: epoch 21, iter 1800, loss: 3.358035, top_1: 0.492969, top_k: 0.734492, samples/s: 1710.217 1612851806.953122
train: epoch 21, iter 1900, loss: 3.131567, top_1: 0.499922, top_k: 0.740898, samples/s: 1746.705 1612851821.6092782
train: epoch 21, iter 2000, loss: 3.076845, top_1: 0.492383, top_k: 0.736641, samples/s: 1746.085 1612851836.2706082
train: epoch 21, iter 2100, loss: 3.027927, top_1: 0.492500, top_k: 0.731797, samples/s: 1737.295 1612851851.0060987
train: epoch 21, iter 2200, loss: 3.210299, top_1: 0.494180, top_k: 0.736914, samples/s: 1735.495 1612851865.7569804
train: epoch 21, iter 2300, loss: 3.220772, top_1: 0.493516, top_k: 0.734375, samples/s: 1730.041 1612851880.5542996
train: epoch 21, iter 2400, loss: 3.107415, top_1: 0.499570, top_k: 0.737422, samples/s: 1721.251 1612851895.4273076
train: epoch 21, iter 2500, loss: 3.329875, top_1: 0.497266, top_k: 0.736055, samples/s: 1734.865 1612851910.1834526
train: epoch 21, iter 2600, loss: 2.951978, top_1: 0.494336, top_k: 0.735547, samples/s: 1732.973 1612851924.9556918
train: epoch 21, iter 2700, loss: 3.131589, top_1: 0.504453, top_k: 0.743672, samples/s: 1733.007 1612851939.7277615
train: epoch 21, iter 2800, loss: 2.946172, top_1: 0.494336, top_k: 0.737969, samples/s: 1734.894 1612851954.4836698
train: epoch 21, iter 2900, loss: 3.181248, top_1: 0.500234, top_k: 0.733984, samples/s: 1733.862 1612851969.2484293
train: epoch 21, iter 3000, loss: 3.048210, top_1: 0.495664, top_k: 0.734844, samples/s: 1722.307 1612851984.1122284
train: epoch 21, iter 3100, loss: 3.039200, top_1: 0.489453, top_k: 0.731602, samples/s: 1735.395 1612851998.8639185
train: epoch 21, iter 3200, loss: 3.096518, top_1: 0.493086, top_k: 0.735430, samples/s: 1727.526 1612852013.6827655
train: epoch 21, iter 3300, loss: 3.154089, top_1: 0.493789, top_k: 0.735859, samples/s: 1740.765 1612852028.3889587
train: epoch 21, iter 3400, loss: 2.999192, top_1: 0.501367, top_k: 0.738906, samples/s: 1731.052 1612852043.1776447
train: epoch 21, iter 3500, loss: 3.081371, top_1: 0.497070, top_k: 0.732578, samples/s: 1733.521 1612852057.945224
train: epoch 21, iter 3600, loss: 3.015044, top_1: 0.489883, top_k: 0.732422, samples/s: 1734.754 1612852072.702423
train: epoch 21, iter 3700, loss: 3.068336, top_1: 0.493477, top_k: 0.737891, samples/s: 1722.832 1612852087.561669
train: epoch 21, iter 3800, loss: 3.258045, top_1: 0.500781, top_k: 0.738008, samples/s: 1731.336 1612852102.347951
train: epoch 21, iter 3900, loss: 3.226788, top_1: 0.491758, top_k: 0.734102, samples/s: 1733.776 1612852117.1133366
train: epoch 21, iter 4000, loss: 3.063831, top_1: 0.494727, top_k: 0.733633, samples/s: 1726.385 1612852131.9420078
train: epoch 21, iter 4100, loss: 2.978560, top_1: 0.495508, top_k: 0.737461, samples/s: 1737.195 1612852146.6784573
train: epoch 21, iter 4200, loss: 3.238500, top_1: 0.489492, top_k: 0.733359, samples/s: 1724.370 1612852161.524477
train: epoch 21, iter 4300, loss: 3.150999, top_1: 0.497500, top_k: 0.734414, samples/s: 1738.966 1612852176.2459157
train: epoch 21, iter 4400, loss: 3.072427, top_1: 0.490391, top_k: 0.732734, samples/s: 1707.211 1612852191.2410784
train: epoch 21, iter 4500, loss: 3.025424, top_1: 0.492188, top_k: 0.730977, samples/s: 1757.108 1612852205.8104885
train: epoch 21, iter 4600, loss: 3.206767, top_1: 0.496172, top_k: 0.731953, samples/s: 1729.579 1612852220.6118517
train: epoch 21, iter 4700, loss: 3.018911, top_1: 0.489570, top_k: 0.729844, samples/s: 1747.373 1612852235.2623436
train: epoch 21, iter 4800, loss: 3.160587, top_1: 0.489219, top_k: 0.730742, samples/s: 1741.053 1612852249.9660492
train: epoch 21, iter 4900, loss: 2.983765, top_1: 0.491094, top_k: 0.730547, samples/s: 1750.282 1612852264.5922937
train: epoch 21, iter 5000, loss: 2.805047, top_1: 0.493633, top_k: 0.734180, samples/s: 1747.925 1612852279.238261
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_21.
validation: epoch 21, iter 195, top_1: 0.542087, top_k: 0.794131, samples/s: 2855.942 1612852297.1553466
train: epoch 22, iter 100, loss: 3.123698, top_1: 0.514766, top_k: 0.751133, samples/s: 1738.854 1612852332.2808836
train: epoch 22, iter 200, loss: 3.183517, top_1: 0.491211, top_k: 0.734492, samples/s: 1753.984 1612852346.876258
train: epoch 22, iter 300, loss: 2.887333, top_1: 0.499961, top_k: 0.746172, samples/s: 1751.050 1612852361.496069
train: epoch 22, iter 400, loss: 3.159650, top_1: 0.503320, top_k: 0.741133, samples/s: 1753.987 1612852376.0913615
train: epoch 22, iter 500, loss: 2.849127, top_1: 0.501406, top_k: 0.739844, samples/s: 1748.528 1612852390.732238
train: epoch 22, iter 600, loss: 3.153443, top_1: 0.503555, top_k: 0.744336, samples/s: 1753.599 1612852405.3307831
train: epoch 22, iter 700, loss: 3.048467, top_1: 0.500625, top_k: 0.739062, samples/s: 1748.706 1612852419.9701757
train: epoch 22, iter 800, loss: 3.109656, top_1: 0.502734, top_k: 0.741602, samples/s: 1744.608 1612852434.6439066
train: epoch 22, iter 900, loss: 2.887254, top_1: 0.502969, top_k: 0.739805, samples/s: 1729.237 1612852449.4482565
train: epoch 22, iter 1000, loss: 3.033185, top_1: 0.501484, top_k: 0.740156, samples/s: 1730.705 1612852464.2398348
train: epoch 22, iter 1100, loss: 3.002513, top_1: 0.495937, top_k: 0.738828, samples/s: 1741.757 1612852478.9375806
train: epoch 22, iter 1200, loss: 2.993192, top_1: 0.495430, top_k: 0.735859, samples/s: 1729.308 1612852493.7411966
train: epoch 22, iter 1300, loss: 3.132355, top_1: 0.502227, top_k: 0.740586, samples/s: 1722.482 1612852508.603512
train: epoch 22, iter 1400, loss: 3.021450, top_1: 0.504922, top_k: 0.742070, samples/s: 1747.878 1612852523.249849
train: epoch 22, iter 1500, loss: 2.894495, top_1: 0.497070, top_k: 0.739609, samples/s: 1727.127 1612852538.072225
train: epoch 22, iter 1600, loss: 3.144588, top_1: 0.501641, top_k: 0.740391, samples/s: 1733.958 1612852552.8360538
train: epoch 22, iter 1700, loss: 3.073207, top_1: 0.489922, top_k: 0.737539, samples/s: 1717.560 1612852567.740978
train: epoch 22, iter 1800, loss: 3.126647, top_1: 0.499336, top_k: 0.739258, samples/s: 1722.585 1612852582.602318
train: epoch 22, iter 1900, loss: 3.080763, top_1: 0.502422, top_k: 0.743281, samples/s: 1744.375 1612852597.2780578
train: epoch 22, iter 2000, loss: 3.189154, top_1: 0.498555, top_k: 0.734844, samples/s: 1727.604 1612852612.0963154
train: epoch 22, iter 2100, loss: 3.163132, top_1: 0.499141, top_k: 0.741328, samples/s: 1730.004 1612852626.8938904
train: epoch 22, iter 2200, loss: 3.185481, top_1: 0.495352, top_k: 0.736484, samples/s: 1731.388 1612852641.6796947
train: epoch 22, iter 2300, loss: 3.204478, top_1: 0.494258, top_k: 0.738828, samples/s: 1730.439 1612852656.473634
train: epoch 22, iter 2400, loss: 3.131001, top_1: 0.501094, top_k: 0.740000, samples/s: 1724.195 1612852671.3211427
train: epoch 22, iter 2500, loss: 3.073845, top_1: 0.497695, top_k: 0.737266, samples/s: 1733.030 1612852686.093004
train: epoch 22, iter 2600, loss: 3.070292, top_1: 0.500313, top_k: 0.738672, samples/s: 1725.252 1612852700.9313667
train: epoch 22, iter 2700, loss: 3.201693, top_1: 0.497500, top_k: 0.738203, samples/s: 1735.470 1612852715.682417
train: epoch 22, iter 2800, loss: 3.199721, top_1: 0.496250, top_k: 0.735469, samples/s: 1734.018 1612852730.4459083
train: epoch 22, iter 2900, loss: 3.114331, top_1: 0.498828, top_k: 0.737383, samples/s: 1742.854 1612852745.1344185
train: epoch 22, iter 3000, loss: 3.041221, top_1: 0.496641, top_k: 0.736914, samples/s: 1722.023 1612852760.0006492
train: epoch 22, iter 3100, loss: 3.258543, top_1: 0.497656, top_k: 0.738633, samples/s: 1720.488 1612852774.8801308
train: epoch 22, iter 3200, loss: 3.242612, top_1: 0.499766, top_k: 0.737422, samples/s: 1704.907 1612852789.8956416
train: epoch 22, iter 3300, loss: 3.343782, top_1: 0.490625, top_k: 0.732539, samples/s: 1750.136 1612852804.5230706
train: epoch 22, iter 3400, loss: 3.204388, top_1: 0.495742, top_k: 0.734375, samples/s: 1732.535 1612852819.299163
train: epoch 22, iter 3500, loss: 3.250007, top_1: 0.495742, top_k: 0.738867, samples/s: 1737.986 1612852834.028801
train: epoch 22, iter 3600, loss: 3.430296, top_1: 0.491445, top_k: 0.738242, samples/s: 1722.907 1612852848.887345
train: epoch 22, iter 3700, loss: 3.142759, top_1: 0.499023, top_k: 0.736094, samples/s: 1735.595 1612852863.6373487
train: epoch 22, iter 3800, loss: 3.133577, top_1: 0.498008, top_k: 0.738867, samples/s: 1740.843 1612852878.3428597
train: epoch 22, iter 3900, loss: 2.941412, top_1: 0.499492, top_k: 0.740273, samples/s: 1730.899 1612852893.1329474
train: epoch 22, iter 4000, loss: 3.081788, top_1: 0.500273, top_k: 0.736367, samples/s: 1729.014 1612852907.9390483
train: epoch 22, iter 4100, loss: 3.047076, top_1: 0.500742, top_k: 0.740781, samples/s: 1720.880 1612852922.8151522
train: epoch 22, iter 4200, loss: 3.228046, top_1: 0.498984, top_k: 0.734219, samples/s: 1694.558 1612852937.9222884
train: epoch 22, iter 4300, loss: 2.982393, top_1: 0.497227, top_k: 0.737031, samples/s: 1755.653 1612852952.503845
train: epoch 22, iter 4400, loss: 3.080343, top_1: 0.496797, top_k: 0.736836, samples/s: 1749.122 1612852967.1397586
train: epoch 22, iter 4500, loss: 3.134270, top_1: 0.497344, top_k: 0.736172, samples/s: 1726.418 1612852981.968059
train: epoch 22, iter 4600, loss: 2.967783, top_1: 0.496484, top_k: 0.734180, samples/s: 1730.283 1612852996.7634277
train: epoch 22, iter 4700, loss: 2.987022, top_1: 0.493398, top_k: 0.737930, samples/s: 1717.392 1612853011.669659
train: epoch 22, iter 4800, loss: 3.091057, top_1: 0.493281, top_k: 0.736133, samples/s: 1740.498 1612853026.3780813
train: epoch 22, iter 4900, loss: 3.191548, top_1: 0.497852, top_k: 0.737461, samples/s: 1735.324 1612853041.1304185
train: epoch 22, iter 5000, loss: 3.227903, top_1: 0.499414, top_k: 0.741914, samples/s: 1738.662 1612853055.8543348
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_22.
validation: epoch 22, iter 195, top_1: 0.539944, top_k: 0.788862, samples/s: 2893.650 1612853073.552536
train: epoch 23, iter 100, loss: 2.948920, top_1: 0.506992, top_k: 0.746367, samples/s: 1744.378 1612853114.3908777
train: epoch 23, iter 200, loss: 3.027400, top_1: 0.513477, top_k: 0.749766, samples/s: 1764.119 1612853128.9022253
train: epoch 23, iter 300, loss: 2.996080, top_1: 0.499727, top_k: 0.739531, samples/s: 1763.679 1612853143.4173317
train: epoch 23, iter 400, loss: 3.110870, top_1: 0.508164, top_k: 0.747930, samples/s: 1755.246 1612853158.0021737
train: epoch 23, iter 500, loss: 3.263696, top_1: 0.495625, top_k: 0.736602, samples/s: 1745.603 1612853172.6676388
train: epoch 23, iter 600, loss: 3.017863, top_1: 0.503477, top_k: 0.745078, samples/s: 1757.083 1612853187.2375853
train: epoch 23, iter 700, loss: 3.280194, top_1: 0.503633, top_k: 0.742305, samples/s: 1760.284 1612853201.780315
train: epoch 23, iter 800, loss: 3.125865, top_1: 0.502070, top_k: 0.738047, samples/s: 1718.611 1612853216.6760747
train: epoch 23, iter 900, loss: 2.946332, top_1: 0.509062, top_k: 0.745273, samples/s: 1731.740 1612853231.4589622
train: epoch 23, iter 1000, loss: 3.249372, top_1: 0.504375, top_k: 0.741641, samples/s: 1734.290 1612853246.2199912
train: epoch 23, iter 1100, loss: 3.150812, top_1: 0.496328, top_k: 0.736953, samples/s: 1717.939 1612853261.121542
train: epoch 23, iter 1200, loss: 3.178762, top_1: 0.501758, top_k: 0.743203, samples/s: 1746.071 1612853275.7830522
train: epoch 23, iter 1300, loss: 3.176126, top_1: 0.502734, top_k: 0.743477, samples/s: 1731.205 1612853290.5709174
train: epoch 23, iter 1400, loss: 3.130971, top_1: 0.496758, top_k: 0.737695, samples/s: 1734.305 1612853305.331455
train: epoch 23, iter 1500, loss: 2.849554, top_1: 0.507461, top_k: 0.744023, samples/s: 1731.210 1612853320.1187372
train: epoch 23, iter 1600, loss: 3.142184, top_1: 0.503555, top_k: 0.744414, samples/s: 1732.318 1612853334.8966515
train: epoch 23, iter 1700, loss: 3.306623, top_1: 0.504844, top_k: 0.738125, samples/s: 1736.343 1612853349.640268
train: epoch 23, iter 1800, loss: 3.083304, top_1: 0.499258, top_k: 0.738555, samples/s: 1735.435 1612853364.3916411
train: epoch 23, iter 1900, loss: 2.969096, top_1: 0.496992, top_k: 0.736602, samples/s: 1725.716 1612853379.2260756
train: epoch 23, iter 2000, loss: 3.177285, top_1: 0.495820, top_k: 0.736914, samples/s: 1730.199 1612853394.0220659
train: epoch 23, iter 2100, loss: 3.284237, top_1: 0.499688, top_k: 0.736719, samples/s: 1732.533 1612853408.7981384
train: epoch 23, iter 2200, loss: 3.184258, top_1: 0.499961, top_k: 0.738437, samples/s: 1748.725 1612853423.437332
train: epoch 23, iter 2300, loss: 3.196187, top_1: 0.495234, top_k: 0.740039, samples/s: 1732.921 1612853438.2100384
train: epoch 23, iter 2400, loss: 2.928892, top_1: 0.495586, top_k: 0.737500, samples/s: 1744.830 1612853452.8819895
train: epoch 23, iter 2500, loss: 2.907378, top_1: 0.505195, top_k: 0.744414, samples/s: 1747.767 1612853467.5292017
train: epoch 23, iter 2600, loss: 3.059251, top_1: 0.502148, top_k: 0.740313, samples/s: 1743.527 1612853482.2122052
train: epoch 23, iter 2700, loss: 3.047072, top_1: 0.504258, top_k: 0.743008, samples/s: 1738.916 1612853496.9338987
train: epoch 23, iter 2800, loss: 2.947748, top_1: 0.501211, top_k: 0.741250, samples/s: 1743.303 1612853511.6187665
train: epoch 23, iter 2900, loss: 3.062086, top_1: 0.503750, top_k: 0.740547, samples/s: 1752.474 1612853526.2266252
train: epoch 23, iter 3000, loss: 3.089257, top_1: 0.504414, top_k: 0.740820, samples/s: 1735.621 1612853540.9763703
train: epoch 23, iter 3100, loss: 3.382381, top_1: 0.497773, top_k: 0.737109, samples/s: 1745.052 1612853555.6464572
train: epoch 23, iter 3200, loss: 3.163557, top_1: 0.501172, top_k: 0.737812, samples/s: 1737.713 1612853570.378467
train: epoch 23, iter 3300, loss: 3.363704, top_1: 0.497070, top_k: 0.738516, samples/s: 1747.034 1612853585.0318775
train: epoch 23, iter 3400, loss: 2.931762, top_1: 0.494883, top_k: 0.736406, samples/s: 1754.243 1612853599.6250718
train: epoch 23, iter 3500, loss: 2.996456, top_1: 0.500391, top_k: 0.742031, samples/s: 1737.973 1612853614.3548167
train: epoch 23, iter 3600, loss: 3.303504, top_1: 0.499883, top_k: 0.736094, samples/s: 1746.045 1612853629.0165312
train: epoch 23, iter 3700, loss: 3.153385, top_1: 0.501094, top_k: 0.736719, samples/s: 1747.873 1612853643.662954
train: epoch 23, iter 3800, loss: 3.159361, top_1: 0.498672, top_k: 0.740898, samples/s: 1740.155 1612853658.3742414
train: epoch 23, iter 3900, loss: 3.021043, top_1: 0.498281, top_k: 0.738672, samples/s: 1752.158 1612853672.9848297
train: epoch 23, iter 4000, loss: 2.921523, top_1: 0.501055, top_k: 0.734844, samples/s: 1748.421 1612853687.6265972
train: epoch 23, iter 4100, loss: 3.105798, top_1: 0.497852, top_k: 0.740391, samples/s: 1741.153 1612853702.3298192
train: epoch 23, iter 4200, loss: 3.253984, top_1: 0.500195, top_k: 0.736406, samples/s: 1763.841 1612853716.8432667
train: epoch 23, iter 4300, loss: 3.056076, top_1: 0.496758, top_k: 0.740313, samples/s: 1741.377 1612853731.544547
train: epoch 23, iter 4400, loss: 2.890387, top_1: 0.496367, top_k: 0.740156, samples/s: 1753.803 1612853746.1410997
train: epoch 23, iter 4500, loss: 2.971459, top_1: 0.502422, top_k: 0.740977, samples/s: 1743.192 1612853760.8268533
train: epoch 23, iter 4600, loss: 3.175096, top_1: 0.498750, top_k: 0.737500, samples/s: 1744.100 1612853775.5050411
train: epoch 23, iter 4700, loss: 3.065611, top_1: 0.494609, top_k: 0.734570, samples/s: 1754.420 1612853790.0965867
train: epoch 23, iter 4800, loss: 3.185542, top_1: 0.504805, top_k: 0.737305, samples/s: 1741.758 1612853804.79443
train: epoch 23, iter 4900, loss: 3.187361, top_1: 0.500625, top_k: 0.743984, samples/s: 1760.211 1612853819.338461
train: epoch 23, iter 5000, loss: 3.162676, top_1: 0.499570, top_k: 0.737891, samples/s: 1749.168 1612853833.9736345
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_23.
validation: epoch 23, iter 195, top_1: 0.545813, top_k: 0.792368, samples/s: 2888.766 1612853851.6983063
train: epoch 24, iter 100, loss: 3.108002, top_1: 0.511055, top_k: 0.746680, samples/s: 1752.909 1612853886.529069
train: epoch 24, iter 200, loss: 3.159313, top_1: 0.510352, top_k: 0.744570, samples/s: 1759.705 1612853901.0768967
train: epoch 24, iter 300, loss: 2.999807, top_1: 0.508828, top_k: 0.743750, samples/s: 1763.496 1612853915.5935006
train: epoch 24, iter 400, loss: 3.026154, top_1: 0.503672, top_k: 0.744297, samples/s: 1755.597 1612853930.1754408
train: epoch 24, iter 500, loss: 3.249674, top_1: 0.508984, top_k: 0.746992, samples/s: 1760.742 1612853944.7148278
train: epoch 24, iter 600, loss: 3.010885, top_1: 0.507891, top_k: 0.743828, samples/s: 1752.381 1612853959.323479
train: epoch 24, iter 700, loss: 3.168193, top_1: 0.496914, top_k: 0.737773, samples/s: 1743.027 1612853974.010628
train: epoch 24, iter 800, loss: 3.125746, top_1: 0.504687, top_k: 0.743984, samples/s: 1730.414 1612853988.804687
train: epoch 24, iter 900, loss: 3.006883, top_1: 0.499023, top_k: 0.739258, samples/s: 1733.308 1612854003.574565
train: epoch 24, iter 1000, loss: 3.133347, top_1: 0.505391, top_k: 0.746211, samples/s: 1739.444 1612854018.2915435
train: epoch 24, iter 1100, loss: 3.187291, top_1: 0.500703, top_k: 0.741328, samples/s: 1716.937 1612854033.2018564
train: epoch 24, iter 1200, loss: 3.121743, top_1: 0.500859, top_k: 0.743008, samples/s: 1735.520 1612854047.9524314
train: epoch 24, iter 1300, loss: 3.178381, top_1: 0.502617, top_k: 0.742422, samples/s: 1737.446 1612854062.6870322
train: epoch 24, iter 1400, loss: 2.972164, top_1: 0.509570, top_k: 0.747930, samples/s: 1735.508 1612854077.4373794
train: epoch 24, iter 1500, loss: 3.083735, top_1: 0.502930, top_k: 0.742188, samples/s: 1727.568 1612854092.2564428
train: epoch 24, iter 1600, loss: 2.946723, top_1: 0.502656, top_k: 0.746484, samples/s: 1714.139 1612854107.1905105
train: epoch 24, iter 1700, loss: 3.139677, top_1: 0.501602, top_k: 0.741016, samples/s: 1741.635 1612854121.8893442
train: epoch 24, iter 1800, loss: 3.413431, top_1: 0.510547, top_k: 0.746289, samples/s: 1718.159 1612854136.7890108
train: epoch 24, iter 1900, loss: 2.925316, top_1: 0.504297, top_k: 0.742461, samples/s: 1736.935 1612854151.5277047
train: epoch 24, iter 2000, loss: 2.947572, top_1: 0.504531, top_k: 0.742422, samples/s: 1740.436 1612854166.236607
train: epoch 24, iter 2100, loss: 3.011935, top_1: 0.508086, top_k: 0.745273, samples/s: 1725.095 1612854181.0762994
train: epoch 24, iter 2200, loss: 3.256752, top_1: 0.506250, top_k: 0.741836, samples/s: 1728.057 1612854195.8907473
train: epoch 24, iter 2300, loss: 3.084730, top_1: 0.502578, top_k: 0.740938, samples/s: 1735.483 1612854210.6416574
train: epoch 24, iter 2400, loss: 3.052047, top_1: 0.502852, top_k: 0.740078, samples/s: 1720.467 1612854225.5213747
train: epoch 24, iter 2500, loss: 3.155416, top_1: 0.504727, top_k: 0.744727, samples/s: 1732.034 1612854240.30172
train: epoch 24, iter 2600, loss: 3.066587, top_1: 0.500234, top_k: 0.740078, samples/s: 1741.569 1612854255.0010612
train: epoch 24, iter 2700, loss: 3.082803, top_1: 0.502383, top_k: 0.737266, samples/s: 1737.720 1612854269.7332356
train: epoch 24, iter 2800, loss: 3.036733, top_1: 0.504062, top_k: 0.740625, samples/s: 1710.593 1612854284.6985924
train: epoch 24, iter 2900, loss: 3.130512, top_1: 0.509180, top_k: 0.745469, samples/s: 1727.884 1612854299.5146904
train: epoch 24, iter 3000, loss: 3.052412, top_1: 0.502344, top_k: 0.739023, samples/s: 1733.420 1612854314.282772
train: epoch 24, iter 3100, loss: 3.133754, top_1: 0.496484, top_k: 0.733203, samples/s: 1741.657 1612854328.9814925
train: epoch 24, iter 3200, loss: 3.213533, top_1: 0.509023, top_k: 0.745938, samples/s: 1721.754 1612854343.8500035
train: epoch 24, iter 3300, loss: 3.234850, top_1: 0.495859, top_k: 0.735664, samples/s: 1733.882 1612854358.6146462
train: epoch 24, iter 3400, loss: 3.225776, top_1: 0.505664, top_k: 0.740898, samples/s: 1740.977 1612854373.3189366
train: epoch 24, iter 3500, loss: 2.964448, top_1: 0.496250, top_k: 0.741406, samples/s: 1745.906 1612854387.981797
train: epoch 24, iter 3600, loss: 3.259147, top_1: 0.502969, top_k: 0.737109, samples/s: 1740.003 1612854402.6944556
train: epoch 24, iter 3700, loss: 3.004961, top_1: 0.496367, top_k: 0.741875, samples/s: 1738.641 1612854417.4186308
train: epoch 24, iter 3800, loss: 3.333845, top_1: 0.502148, top_k: 0.740898, samples/s: 1746.394 1612854432.0773363
train: epoch 24, iter 3900, loss: 3.249765, top_1: 0.503984, top_k: 0.739922, samples/s: 1751.968 1612854446.689476
train: epoch 24, iter 4000, loss: 3.129483, top_1: 0.501484, top_k: 0.742109, samples/s: 1739.649 1612854461.4051938
train: epoch 24, iter 4100, loss: 3.228012, top_1: 0.502188, top_k: 0.734570, samples/s: 1753.340 1612854476.0058599
train: epoch 24, iter 4200, loss: 3.049937, top_1: 0.501680, top_k: 0.743906, samples/s: 1742.128 1612854490.7004817
train: epoch 24, iter 4300, loss: 3.107778, top_1: 0.498203, top_k: 0.735938, samples/s: 1741.192 1612854505.4030447
train: epoch 24, iter 4400, loss: 3.121316, top_1: 0.501797, top_k: 0.741836, samples/s: 1756.646 1612854519.9762414
train: epoch 24, iter 4500, loss: 3.001344, top_1: 0.495273, top_k: 0.735742, samples/s: 1728.166 1612854534.789716
train: epoch 24, iter 4600, loss: 2.922728, top_1: 0.507500, top_k: 0.746016, samples/s: 1740.686 1612854549.4964924
train: epoch 24, iter 4700, loss: 3.029203, top_1: 0.503008, top_k: 0.743672, samples/s: 1750.131 1612854564.1240432
train: epoch 24, iter 4800, loss: 3.140591, top_1: 0.494805, top_k: 0.739453, samples/s: 1750.313 1612854578.7501361
train: epoch 24, iter 4900, loss: 3.151995, top_1: 0.501992, top_k: 0.743164, samples/s: 1745.108 1612854593.4195466
train: epoch 24, iter 5000, loss: 2.838893, top_1: 0.499883, top_k: 0.746094, samples/s: 1751.856 1612854608.0326474
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_24.
validation: epoch 24, iter 195, top_1: 0.558113, top_k: 0.800321, samples/s: 2891.154 1612854625.7302094
train: epoch 25, iter 100, loss: 3.227525, top_1: 0.518672, top_k: 0.752227, samples/s: 1756.508 1612854660.62774
train: epoch 25, iter 200, loss: 3.068228, top_1: 0.511797, top_k: 0.752539, samples/s: 1757.784 1612854675.1917233
train: epoch 25, iter 300, loss: 3.022610, top_1: 0.507734, top_k: 0.749844, samples/s: 1757.879 1612854689.7545328
train: epoch 25, iter 400, loss: 2.989415, top_1: 0.507695, top_k: 0.747227, samples/s: 1756.530 1612854704.3288033
train: epoch 25, iter 500, loss: 3.081752, top_1: 0.503437, top_k: 0.741328, samples/s: 1752.510 1612854718.9363894
train: epoch 25, iter 600, loss: 3.101691, top_1: 0.506055, top_k: 0.746094, samples/s: 1752.146 1612854733.5469875
train: epoch 25, iter 700, loss: 3.116838, top_1: 0.507227, top_k: 0.743008, samples/s: 1742.686 1612854748.2369442
train: epoch 25, iter 800, loss: 3.155901, top_1: 0.510859, top_k: 0.752578, samples/s: 1719.060 1612854763.1288805
train: epoch 25, iter 900, loss: 3.196276, top_1: 0.503672, top_k: 0.743906, samples/s: 1731.967 1612854777.90975
train: epoch 25, iter 1000, loss: 3.225692, top_1: 0.501875, top_k: 0.743125, samples/s: 1735.573 1612854792.6599195
train: epoch 25, iter 1100, loss: 2.991857, top_1: 0.505547, top_k: 0.740234, samples/s: 1738.239 1612854807.387426
train: epoch 25, iter 1200, loss: 2.975019, top_1: 0.512852, top_k: 0.750156, samples/s: 1728.696 1612854822.1965952
train: epoch 25, iter 1300, loss: 3.113671, top_1: 0.511406, top_k: 0.746484, samples/s: 1730.143 1612854836.9927619
train: epoch 25, iter 1400, loss: 3.063120, top_1: 0.501953, top_k: 0.743555, samples/s: 1725.889 1612854851.8260844
train: epoch 25, iter 1500, loss: 3.013373, top_1: 0.511406, top_k: 0.750625, samples/s: 1721.268 1612854866.6985168
train: epoch 25, iter 1600, loss: 3.033705, top_1: 0.506641, top_k: 0.748008, samples/s: 1730.140 1612854881.494986
train: epoch 25, iter 1700, loss: 3.192698, top_1: 0.512031, top_k: 0.749687, samples/s: 1718.490 1612854896.3917673
train: epoch 25, iter 1800, loss: 3.082372, top_1: 0.506602, top_k: 0.746250, samples/s: 1728.938 1612854911.1985626
train: epoch 25, iter 1900, loss: 3.087142, top_1: 0.503633, top_k: 0.746563, samples/s: 1745.859 1612854925.8621247
train: epoch 25, iter 2000, loss: 3.106919, top_1: 0.501953, top_k: 0.741406, samples/s: 1727.776 1612854940.6785066
train: epoch 25, iter 2100, loss: 3.113937, top_1: 0.500742, top_k: 0.740000, samples/s: 1732.159 1612854955.457769
train: epoch 25, iter 2200, loss: 3.106458, top_1: 0.501875, top_k: 0.737461, samples/s: 1727.899 1612854970.2734745
train: epoch 25, iter 2300, loss: 3.127844, top_1: 0.508047, top_k: 0.747617, samples/s: 1734.307 1612854985.0343792
train: epoch 25, iter 2400, loss: 2.960900, top_1: 0.501445, top_k: 0.744336, samples/s: 1738.821 1612854999.7570384
train: epoch 25, iter 2500, loss: 3.227231, top_1: 0.501016, top_k: 0.739766, samples/s: 1726.247 1612855014.5872376
train: epoch 25, iter 2600, loss: 2.933884, top_1: 0.501914, top_k: 0.742539, samples/s: 1729.364 1612855029.390008
train: epoch 25, iter 2700, loss: 3.200020, top_1: 0.508672, top_k: 0.744336, samples/s: 1732.573 1612855044.1657183
train: epoch 25, iter 2800, loss: 3.044607, top_1: 0.501016, top_k: 0.740820, samples/s: 1732.225 1612855058.944397
train: epoch 25, iter 2900, loss: 3.106255, top_1: 0.506016, top_k: 0.741836, samples/s: 1739.367 1612855073.6623611
train: epoch 25, iter 3000, loss: 3.180219, top_1: 0.500391, top_k: 0.742031, samples/s: 1734.433 1612855088.4222596
train: epoch 25, iter 3100, loss: 3.071318, top_1: 0.509609, top_k: 0.745352, samples/s: 1724.878 1612855103.2638714
train: epoch 25, iter 3200, loss: 3.102096, top_1: 0.502109, top_k: 0.741875, samples/s: 1711.186 1612855118.2243466
train: epoch 25, iter 3300, loss: 3.261569, top_1: 0.501211, top_k: 0.742070, samples/s: 1731.660 1612855133.0077603
train: epoch 25, iter 3400, loss: 3.279246, top_1: 0.511289, top_k: 0.745977, samples/s: 1733.609 1612855147.7746668
train: epoch 25, iter 3500, loss: 3.332603, top_1: 0.506133, top_k: 0.741055, samples/s: 1730.880 1612855162.5647814
train: epoch 25, iter 3600, loss: 3.130825, top_1: 0.497031, top_k: 0.737344, samples/s: 1732.835 1612855177.3382823
train: epoch 25, iter 3700, loss: 3.288128, top_1: 0.502500, top_k: 0.741172, samples/s: 1731.287 1612855192.1249719
train: epoch 25, iter 3800, loss: 3.201877, top_1: 0.507031, top_k: 0.744961, samples/s: 1729.983 1612855206.922886
train: epoch 25, iter 3900, loss: 3.077016, top_1: 0.504219, top_k: 0.741641, samples/s: 1734.626 1612855221.6811125
train: epoch 25, iter 4000, loss: 3.048184, top_1: 0.501953, top_k: 0.743008, samples/s: 1740.398 1612855236.390285
train: epoch 25, iter 4100, loss: 3.156936, top_1: 0.504141, top_k: 0.739688, samples/s: 1732.730 1612855251.164712
train: epoch 25, iter 4200, loss: 3.045036, top_1: 0.505117, top_k: 0.743906, samples/s: 1713.632 1612855266.1036727
train: epoch 25, iter 4300, loss: 3.185298, top_1: 0.503867, top_k: 0.741328, samples/s: 1738.459 1612855280.82944
train: epoch 25, iter 4400, loss: 3.178735, top_1: 0.507070, top_k: 0.744297, samples/s: 1736.875 1612855295.5685492
train: epoch 25, iter 4500, loss: 3.328519, top_1: 0.503242, top_k: 0.744570, samples/s: 1748.920 1612855310.2061508
train: epoch 25, iter 4600, loss: 2.999273, top_1: 0.504648, top_k: 0.738047, samples/s: 1739.640 1612855324.9218836
train: epoch 25, iter 4700, loss: 3.316804, top_1: 0.493477, top_k: 0.734258, samples/s: 1742.880 1612855339.6102264
train: epoch 25, iter 4800, loss: 2.994251, top_1: 0.505625, top_k: 0.741758, samples/s: 1751.897 1612855354.2228436
train: epoch 25, iter 4900, loss: 2.914266, top_1: 0.501055, top_k: 0.742969, samples/s: 1734.110 1612855368.985566
train: epoch 25, iter 5000, loss: 3.178385, top_1: 0.503203, top_k: 0.745000, samples/s: 1748.106 1612855383.6299841
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_25.
validation: epoch 25, iter 195, top_1: 0.541386, top_k: 0.790585, samples/s: 2819.937 1612855401.6948547
train: epoch 26, iter 100, loss: 3.004981, top_1: 0.511719, top_k: 0.752422, samples/s: 1753.506 1612855436.3780873
train: epoch 26, iter 200, loss: 3.213681, top_1: 0.514570, top_k: 0.752773, samples/s: 1757.161 1612855450.946991
train: epoch 26, iter 300, loss: 3.346391, top_1: 0.511484, top_k: 0.744258, samples/s: 1756.028 1612855465.5253
train: epoch 26, iter 400, loss: 3.132263, top_1: 0.512383, top_k: 0.751016, samples/s: 1751.264 1612855480.143606
train: epoch 26, iter 500, loss: 2.962403, top_1: 0.512227, top_k: 0.753164, samples/s: 1760.976 1612855494.680676
train: epoch 26, iter 600, loss: 3.145945, top_1: 0.510898, top_k: 0.750938, samples/s: 1755.922 1612855509.259994
train: epoch 26, iter 700, loss: 3.012670, top_1: 0.512266, top_k: 0.750469, samples/s: 1731.175 1612855524.047565
train: epoch 26, iter 800, loss: 2.965906, top_1: 0.508281, top_k: 0.746367, samples/s: 1737.559 1612855538.780868
train: epoch 26, iter 900, loss: 3.065438, top_1: 0.512773, top_k: 0.750273, samples/s: 1737.589 1612855553.5140018
train: epoch 26, iter 1000, loss: 3.136233, top_1: 0.514102, top_k: 0.749297, samples/s: 1735.356 1612855568.266017
train: epoch 26, iter 1100, loss: 3.082934, top_1: 0.507109, top_k: 0.749375, samples/s: 1738.801 1612855582.9887815
train: epoch 26, iter 1200, loss: 3.141365, top_1: 0.504414, top_k: 0.744062, samples/s: 1734.131 1612855597.7512076
train: epoch 26, iter 1300, loss: 3.163804, top_1: 0.507852, top_k: 0.743984, samples/s: 1728.292 1612855612.5638237
train: epoch 26, iter 1400, loss: 3.051573, top_1: 0.506758, top_k: 0.743203, samples/s: 1726.767 1612855627.3889258
train: epoch 26, iter 1500, loss: 3.005311, top_1: 0.505234, top_k: 0.743242, samples/s: 1726.917 1612855642.2130291
train: epoch 26, iter 1600, loss: 3.057445, top_1: 0.502422, top_k: 0.742852, samples/s: 1724.255 1612855657.0600736
train: epoch 26, iter 1700, loss: 3.167838, top_1: 0.506914, top_k: 0.743789, samples/s: 1738.123 1612855671.7886345
train: epoch 26, iter 1800, loss: 3.185418, top_1: 0.501289, top_k: 0.741406, samples/s: 1741.168 1612855686.4913166
train: epoch 26, iter 1900, loss: 3.059608, top_1: 0.510898, top_k: 0.746563, samples/s: 1733.574 1612855701.258494
train: epoch 26, iter 2000, loss: 3.206738, top_1: 0.504727, top_k: 0.744141, samples/s: 1734.937 1612855716.0140793
train: epoch 26, iter 2100, loss: 2.971015, top_1: 0.502109, top_k: 0.744531, samples/s: 1733.243 1612855730.7845478
train: epoch 26, iter 2200, loss: 3.146284, top_1: 0.506133, top_k: 0.744023, samples/s: 1732.136 1612855745.5635223
train: epoch 26, iter 2300, loss: 3.024049, top_1: 0.502617, top_k: 0.745078, samples/s: 1739.390 1612855760.28142
train: epoch 26, iter 2400, loss: 3.093404, top_1: 0.509141, top_k: 0.744844, samples/s: 1735.053 1612855775.0359766
train: epoch 26, iter 2500, loss: 3.220428, top_1: 0.512227, top_k: 0.756172, samples/s: 1737.630 1612855789.7685921
train: epoch 26, iter 2600, loss: 3.085284, top_1: 0.507852, top_k: 0.749297, samples/s: 1737.419 1612855804.5031896
train: epoch 26, iter 2700, loss: 3.061932, top_1: 0.509844, top_k: 0.744570, samples/s: 1716.542 1612855819.4168692
train: epoch 26, iter 2800, loss: 3.274647, top_1: 0.503203, top_k: 0.743594, samples/s: 1729.413 1612855834.2196627
train: epoch 26, iter 2900, loss: 3.150347, top_1: 0.507930, top_k: 0.746445, samples/s: 1718.452 1612855849.116778
train: epoch 26, iter 3000, loss: 3.109330, top_1: 0.506406, top_k: 0.743633, samples/s: 1751.776 1612855863.730465
train: epoch 26, iter 3100, loss: 3.296977, top_1: 0.509531, top_k: 0.745898, samples/s: 1733.715 1612855878.4964173
train: epoch 26, iter 3200, loss: 3.060035, top_1: 0.506367, top_k: 0.743867, samples/s: 1726.730 1612855893.322116
train: epoch 26, iter 3300, loss: 2.833949, top_1: 0.501094, top_k: 0.742461, samples/s: 1744.014 1612855908.0008748
train: epoch 26, iter 3400, loss: 3.193334, top_1: 0.504219, top_k: 0.737148, samples/s: 1726.944 1612855922.8247526
train: epoch 26, iter 3500, loss: 3.132553, top_1: 0.505156, top_k: 0.743945, samples/s: 1733.626 1612855937.5914927
train: epoch 26, iter 3600, loss: 3.046971, top_1: 0.503359, top_k: 0.740547, samples/s: 1725.455 1612855952.4283123
train: epoch 26, iter 3700, loss: 2.956591, top_1: 0.507461, top_k: 0.743750, samples/s: 1722.404 1612855967.2911422
train: epoch 26, iter 3800, loss: 3.224023, top_1: 0.509023, top_k: 0.742891, samples/s: 1733.835 1612855982.0561965
train: epoch 26, iter 3900, loss: 3.010867, top_1: 0.511797, top_k: 0.749297, samples/s: 1731.570 1612855996.840372
train: epoch 26, iter 4000, loss: 2.996089, top_1: 0.506719, top_k: 0.742383, samples/s: 1735.809 1612856011.5885062
train: epoch 26, iter 4100, loss: 3.083274, top_1: 0.504844, top_k: 0.742539, samples/s: 1743.313 1612856026.2732563
train: epoch 26, iter 4200, loss: 3.199434, top_1: 0.498047, top_k: 0.736563, samples/s: 1733.112 1612856041.0443563
train: epoch 26, iter 4300, loss: 3.102944, top_1: 0.503828, top_k: 0.741406, samples/s: 1717.752 1612856055.9475472
train: epoch 26, iter 4400, loss: 3.101865, top_1: 0.502266, top_k: 0.740781, samples/s: 1734.729 1612856070.7049215
train: epoch 26, iter 4500, loss: 3.038363, top_1: 0.508437, top_k: 0.742656, samples/s: 1742.294 1612856085.3981936
train: epoch 26, iter 4600, loss: 3.094764, top_1: 0.504531, top_k: 0.740859, samples/s: 1746.251 1612856100.058138
train: epoch 26, iter 4700, loss: 3.173936, top_1: 0.500742, top_k: 0.737930, samples/s: 1734.765 1612856114.8152678
train: epoch 26, iter 4800, loss: 3.127791, top_1: 0.503008, top_k: 0.743672, samples/s: 1722.247 1612856129.6794355
train: epoch 26, iter 4900, loss: 2.902937, top_1: 0.511719, top_k: 0.745820, samples/s: 1730.971 1612856144.4688728
train: epoch 26, iter 5000, loss: 2.908350, top_1: 0.506563, top_k: 0.744570, samples/s: 1738.644 1612856159.1930225
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_26.
validation: epoch 26, iter 195, top_1: 0.548498, top_k: 0.797135, samples/s: 2883.390 1612856176.9552484
train: epoch 27, iter 100, loss: 3.161523, top_1: 0.513125, top_k: 0.753008, samples/s: 1760.082 1612856212.1700337
train: epoch 27, iter 200, loss: 3.184498, top_1: 0.514219, top_k: 0.751367, samples/s: 1759.600 1612856226.7188215
train: epoch 27, iter 300, loss: 2.840381, top_1: 0.514492, top_k: 0.753789, samples/s: 1753.435 1612856241.318683
train: epoch 27, iter 400, loss: 2.980109, top_1: 0.509062, top_k: 0.746797, samples/s: 1746.919 1612856255.9730673
train: epoch 27, iter 500, loss: 3.150296, top_1: 0.513164, top_k: 0.749805, samples/s: 1765.247 1612856270.4754605
train: epoch 27, iter 600, loss: 3.115507, top_1: 0.513711, top_k: 0.749961, samples/s: 1736.103 1612856285.2210062
train: epoch 27, iter 700, loss: 3.206094, top_1: 0.512031, top_k: 0.749102, samples/s: 1749.012 1612856299.857862
train: epoch 27, iter 800, loss: 3.033610, top_1: 0.509141, top_k: 0.746328, samples/s: 1733.466 1612856314.6259604
train: epoch 27, iter 900, loss: 2.996266, top_1: 0.515117, top_k: 0.751875, samples/s: 1734.880 1612856329.3820245
train: epoch 27, iter 1000, loss: 3.241474, top_1: 0.514648, top_k: 0.751406, samples/s: 1721.901 1612856344.2492442
train: epoch 27, iter 1100, loss: 3.034513, top_1: 0.512734, top_k: 0.746289, samples/s: 1728.806 1612856359.0571468
train: epoch 27, iter 1200, loss: 2.810805, top_1: 0.507031, top_k: 0.746211, samples/s: 1744.164 1612856373.7346456
train: epoch 27, iter 1300, loss: 3.205369, top_1: 0.509453, top_k: 0.746641, samples/s: 1737.995 1612856388.464351
train: epoch 27, iter 1400, loss: 3.300587, top_1: 0.507852, top_k: 0.744570, samples/s: 1727.386 1612856403.2844143
train: epoch 27, iter 1500, loss: 2.952713, top_1: 0.510234, top_k: 0.747578, samples/s: 1726.631 1612856418.1109645
train: epoch 27, iter 1600, loss: 3.359106, top_1: 0.503906, top_k: 0.743125, samples/s: 1731.809 1612856432.8931925
train: epoch 27, iter 1700, loss: 3.143720, top_1: 0.502734, top_k: 0.742383, samples/s: 1728.346 1612856447.7050009
train: epoch 27, iter 1800, loss: 3.060615, top_1: 0.507070, top_k: 0.745039, samples/s: 1726.942 1612856462.5289016
train: epoch 27, iter 1900, loss: 3.214037, top_1: 0.506367, top_k: 0.748242, samples/s: 1725.976 1612856477.3610568
train: epoch 27, iter 2000, loss: 3.237277, top_1: 0.511875, top_k: 0.749883, samples/s: 1731.132 1612856492.1490388
train: epoch 27, iter 2100, loss: 3.070998, top_1: 0.505234, top_k: 0.742500, samples/s: 1732.853 1612856506.922396
train: epoch 27, iter 2200, loss: 3.090255, top_1: 0.510977, top_k: 0.746875, samples/s: 1731.509 1612856521.7072728
train: epoch 27, iter 2300, loss: 3.275285, top_1: 0.506719, top_k: 0.746289, samples/s: 1734.448 1612856536.467017
train: epoch 27, iter 2400, loss: 3.032212, top_1: 0.509570, top_k: 0.747891, samples/s: 1737.215 1612856551.2032342
train: epoch 27, iter 2500, loss: 3.100721, top_1: 0.510312, top_k: 0.752305, samples/s: 1726.244 1612856566.0330632
train: epoch 27, iter 2600, loss: 3.110341, top_1: 0.512266, top_k: 0.742188, samples/s: 1741.140 1612856580.7361534
train: epoch 27, iter 2700, loss: 2.966314, top_1: 0.506523, top_k: 0.744141, samples/s: 1750.803 1612856595.357962
train: epoch 27, iter 2800, loss: 3.248629, top_1: 0.508984, top_k: 0.743789, samples/s: 1743.927 1612856610.0374658
train: epoch 27, iter 2900, loss: 3.144581, top_1: 0.507656, top_k: 0.748945, samples/s: 1743.751 1612856624.718398
train: epoch 27, iter 3000, loss: 3.082415, top_1: 0.507969, top_k: 0.747539, samples/s: 1751.217 1612856639.3368945
train: epoch 27, iter 3100, loss: 3.028815, top_1: 0.505000, top_k: 0.745586, samples/s: 1745.384 1612856654.004151
train: epoch 27, iter 3200, loss: 3.140919, top_1: 0.507461, top_k: 0.745938, samples/s: 1742.126 1612856668.6988032
train: epoch 27, iter 3300, loss: 3.025654, top_1: 0.512773, top_k: 0.749844, samples/s: 1740.304 1612856683.4088657
train: epoch 27, iter 3400, loss: 3.066117, top_1: 0.514531, top_k: 0.749141, samples/s: 1748.172 1612856698.052754
train: epoch 27, iter 3500, loss: 3.151541, top_1: 0.506484, top_k: 0.743125, samples/s: 1744.276 1612856712.7293172
train: epoch 27, iter 3600, loss: 3.211641, top_1: 0.513516, top_k: 0.744922, samples/s: 1751.246 1612856727.347517
train: epoch 27, iter 3700, loss: 3.011024, top_1: 0.509805, top_k: 0.742734, samples/s: 1758.439 1612856741.9058275
train: epoch 27, iter 3800, loss: 3.068418, top_1: 0.503750, top_k: 0.740391, samples/s: 1745.231 1612856756.5744646
train: epoch 27, iter 3900, loss: 3.060460, top_1: 0.516641, top_k: 0.748984, samples/s: 1743.447 1612856771.2580185
train: epoch 27, iter 4000, loss: 3.097843, top_1: 0.509727, top_k: 0.746523, samples/s: 1756.580 1612856785.8317118
train: epoch 27, iter 4100, loss: 3.323736, top_1: 0.502578, top_k: 0.737930, samples/s: 1746.523 1612856800.4894748
train: epoch 27, iter 4200, loss: 3.130748, top_1: 0.504609, top_k: 0.743516, samples/s: 1754.611 1612856815.0795777
train: epoch 27, iter 4300, loss: 2.962343, top_1: 0.506445, top_k: 0.741797, samples/s: 1749.451 1612856829.7127192
train: epoch 27, iter 4400, loss: 2.822903, top_1: 0.509922, top_k: 0.746602, samples/s: 1743.195 1612856844.398454
train: epoch 27, iter 4500, loss: 3.137118, top_1: 0.504258, top_k: 0.747227, samples/s: 1746.393 1612856859.0572102
train: epoch 27, iter 4600, loss: 2.972652, top_1: 0.512461, top_k: 0.748672, samples/s: 1755.393 1612856873.6408484
train: epoch 27, iter 4700, loss: 3.282709, top_1: 0.508711, top_k: 0.742383, samples/s: 1751.223 1612856888.2592232
train: epoch 27, iter 4800, loss: 3.095299, top_1: 0.508359, top_k: 0.745352, samples/s: 1749.740 1612856902.8899376
train: epoch 27, iter 4900, loss: 3.043700, top_1: 0.504844, top_k: 0.742969, samples/s: 1755.943 1612856917.468943
train: epoch 27, iter 5000, loss: 3.028307, top_1: 0.511953, top_k: 0.743789, samples/s: 1746.587 1612856932.1260977
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_27.
validation: epoch 27, iter 195, top_1: 0.552444, top_k: 0.797636, samples/s: 2863.360 1612856950.0431397
train: epoch 28, iter 100, loss: 2.978493, top_1: 0.518945, top_k: 0.756602, samples/s: 1754.693 1612856985.0455642
train: epoch 28, iter 200, loss: 2.972753, top_1: 0.517695, top_k: 0.755234, samples/s: 1760.673 1612856999.585424
train: epoch 28, iter 300, loss: 3.008730, top_1: 0.516094, top_k: 0.753984, samples/s: 1755.356 1612857014.169478
train: epoch 28, iter 400, loss: 2.939996, top_1: 0.516758, top_k: 0.756680, samples/s: 1755.178 1612857028.754894
train: epoch 28, iter 500, loss: 3.163516, top_1: 0.508594, top_k: 0.748008, samples/s: 1758.266 1612857043.314683
train: epoch 28, iter 600, loss: 3.134957, top_1: 0.509414, top_k: 0.747109, samples/s: 1748.180 1612857057.9583738
train: epoch 28, iter 700, loss: 3.048348, top_1: 0.513711, top_k: 0.752734, samples/s: 1743.688 1612857072.6399207
train: epoch 28, iter 800, loss: 2.831501, top_1: 0.514180, top_k: 0.752969, samples/s: 1748.724 1612857087.2792344
train: epoch 28, iter 900, loss: 3.006309, top_1: 0.507891, top_k: 0.743633, samples/s: 1726.355 1612857102.1080923
train: epoch 28, iter 1000, loss: 3.043604, top_1: 0.511602, top_k: 0.748594, samples/s: 1736.411 1612857116.8512144
train: epoch 28, iter 1100, loss: 3.141304, top_1: 0.513320, top_k: 0.749180, samples/s: 1740.914 1612857131.556158
train: epoch 28, iter 1200, loss: 2.950819, top_1: 0.510078, top_k: 0.751602, samples/s: 1709.411 1612857146.5320754
train: epoch 28, iter 1300, loss: 3.186042, top_1: 0.501914, top_k: 0.744961, samples/s: 1760.123 1612857161.076491
train: epoch 28, iter 1400, loss: 3.141802, top_1: 0.509375, top_k: 0.748320, samples/s: 1736.456 1612857175.8191319
train: epoch 28, iter 1500, loss: 2.860957, top_1: 0.512891, top_k: 0.748359, samples/s: 1734.355 1612857190.5796626
train: epoch 28, iter 1600, loss: 3.133359, top_1: 0.508086, top_k: 0.742266, samples/s: 1710.627 1612857205.5449286
train: epoch 28, iter 1700, loss: 2.946852, top_1: 0.506680, top_k: 0.745156, samples/s: 1738.599 1612857220.2693744
train: epoch 28, iter 1800, loss: 3.006929, top_1: 0.507930, top_k: 0.743945, samples/s: 1733.583 1612857235.036484
train: epoch 28, iter 1900, loss: 3.173302, top_1: 0.512227, top_k: 0.747812, samples/s: 1731.677 1612857249.8198924
train: epoch 28, iter 2000, loss: 3.240606, top_1: 0.511758, top_k: 0.748906, samples/s: 1724.531 1612857264.6644475
train: epoch 28, iter 2100, loss: 2.970376, top_1: 0.510000, top_k: 0.746484, samples/s: 1723.838 1612857279.515048
train: epoch 28, iter 2200, loss: 3.023050, top_1: 0.511328, top_k: 0.752031, samples/s: 1735.523 1612857294.2656307
train: epoch 28, iter 2300, loss: 3.200652, top_1: 0.505469, top_k: 0.747539, samples/s: 1733.323 1612857309.0350006
train: epoch 28, iter 2400, loss: 3.061103, top_1: 0.512500, top_k: 0.747734, samples/s: 1736.659 1612857323.7759538
train: epoch 28, iter 2500, loss: 2.893544, top_1: 0.505547, top_k: 0.744219, samples/s: 1737.826 1612857338.5069547
train: epoch 28, iter 2600, loss: 3.124175, top_1: 0.508164, top_k: 0.746211, samples/s: 1723.203 1612857353.363008
train: epoch 28, iter 2700, loss: 3.284797, top_1: 0.508516, top_k: 0.746094, samples/s: 1727.297 1612857368.1838768
train: epoch 28, iter 2800, loss: 2.994753, top_1: 0.509062, top_k: 0.747930, samples/s: 1730.224 1612857382.979694
train: epoch 28, iter 2900, loss: 3.151338, top_1: 0.506914, top_k: 0.745664, samples/s: 1740.072 1612857397.6916842
train: epoch 28, iter 3000, loss: 2.945652, top_1: 0.509375, top_k: 0.747812, samples/s: 1725.547 1612857412.5275881
train: epoch 28, iter 3100, loss: 3.328656, top_1: 0.507734, top_k: 0.748477, samples/s: 1720.402 1612857427.4078918
train: epoch 28, iter 3200, loss: 2.979868, top_1: 0.511602, top_k: 0.751602, samples/s: 1739.093 1612857442.1281643
train: epoch 28, iter 3300, loss: 3.098637, top_1: 0.508984, top_k: 0.747773, samples/s: 1721.398 1612857456.9997964
train: epoch 28, iter 3400, loss: 2.888788, top_1: 0.509414, top_k: 0.748008, samples/s: 1740.289 1612857471.7099984
train: epoch 28, iter 3500, loss: 2.929664, top_1: 0.514687, top_k: 0.750039, samples/s: 1719.901 1612857486.5945957
train: epoch 28, iter 3600, loss: 3.183248, top_1: 0.510234, top_k: 0.747070, samples/s: 1734.120 1612857501.3570526
train: epoch 28, iter 3700, loss: 3.035276, top_1: 0.516797, top_k: 0.754609, samples/s: 1732.027 1612857516.13742
train: epoch 28, iter 3800, loss: 3.105484, top_1: 0.505039, top_k: 0.743906, samples/s: 1737.737 1612857530.8693469
train: epoch 28, iter 3900, loss: 3.228300, top_1: 0.507188, top_k: 0.743789, samples/s: 1738.383 1612857545.5956671
train: epoch 28, iter 4000, loss: 2.992610, top_1: 0.511563, top_k: 0.749102, samples/s: 1735.983 1612857560.3423002
train: epoch 28, iter 4100, loss: 3.028056, top_1: 0.506523, top_k: 0.744570, samples/s: 1737.068 1612857575.079813
train: epoch 28, iter 4200, loss: 3.051154, top_1: 0.506797, top_k: 0.741875, samples/s: 1753.290 1612857589.6809037
train: epoch 28, iter 4300, loss: 3.013625, top_1: 0.506914, top_k: 0.744453, samples/s: 1745.242 1612857604.34932
train: epoch 28, iter 4400, loss: 3.017923, top_1: 0.510352, top_k: 0.745508, samples/s: 1750.232 1612857618.975971
train: epoch 28, iter 4500, loss: 3.045473, top_1: 0.509570, top_k: 0.745039, samples/s: 1758.385 1612857633.5348027
train: epoch 28, iter 4600, loss: 3.106880, top_1: 0.508984, top_k: 0.748242, samples/s: 1750.334 1612857648.1605768
train: epoch 28, iter 4700, loss: 3.008856, top_1: 0.511719, top_k: 0.742656, samples/s: 1741.664 1612857662.8592005
train: epoch 28, iter 4800, loss: 3.030063, top_1: 0.510977, top_k: 0.750625, samples/s: 1745.658 1612857677.5241168
train: epoch 28, iter 4900, loss: 3.013972, top_1: 0.502227, top_k: 0.746055, samples/s: 1748.135 1612857692.168287
train: epoch 28, iter 5000, loss: 2.957198, top_1: 0.514336, top_k: 0.747500, samples/s: 1741.667 1612857706.8668065
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_28.
validation: epoch 28, iter 195, top_1: 0.554267, top_k: 0.800942, samples/s: 2935.372 1612857724.3479602
train: epoch 29, iter 100, loss: 3.034214, top_1: 0.512188, top_k: 0.750508, samples/s: 1748.888 1612857759.788535
train: epoch 29, iter 200, loss: 2.974984, top_1: 0.517773, top_k: 0.759023, samples/s: 1757.998 1612857774.3504548
train: epoch 29, iter 300, loss: 2.821278, top_1: 0.515586, top_k: 0.753359, samples/s: 1754.340 1612857788.9428737
train: epoch 29, iter 400, loss: 3.223595, top_1: 0.516953, top_k: 0.754102, samples/s: 1756.704 1612857803.515642
train: epoch 29, iter 500, loss: 3.057660, top_1: 0.506719, top_k: 0.748398, samples/s: 1757.500 1612857818.0817826
train: epoch 29, iter 600, loss: 2.788334, top_1: 0.517148, top_k: 0.754141, samples/s: 1754.987 1612857832.6687799
train: epoch 29, iter 700, loss: 2.916410, top_1: 0.509453, top_k: 0.749492, samples/s: 1737.856 1612857847.399594
train: epoch 29, iter 800, loss: 3.138324, top_1: 0.510977, top_k: 0.753594, samples/s: 1731.092 1612857862.1878767
train: epoch 29, iter 900, loss: 3.129804, top_1: 0.514023, top_k: 0.748047, samples/s: 1739.819 1612857876.9021018
train: epoch 29, iter 1000, loss: 2.951313, top_1: 0.516523, top_k: 0.754687, samples/s: 1716.913 1612857891.8126996
train: epoch 29, iter 1100, loss: 2.914681, top_1: 0.513477, top_k: 0.749531, samples/s: 1731.701 1612857906.5956793
train: epoch 29, iter 1200, loss: 3.101323, top_1: 0.513828, top_k: 0.753672, samples/s: 1727.084 1612857921.4183993
train: epoch 29, iter 1300, loss: 2.903056, top_1: 0.513242, top_k: 0.751016, samples/s: 1739.890 1612857936.1320157
train: epoch 29, iter 1400, loss: 3.016187, top_1: 0.513672, top_k: 0.749219, samples/s: 1748.139 1612857950.7760813
train: epoch 29, iter 1500, loss: 3.034545, top_1: 0.510469, top_k: 0.749883, samples/s: 1730.830 1612857965.5667267
train: epoch 29, iter 1600, loss: 3.257124, top_1: 0.511758, top_k: 0.750039, samples/s: 1736.490 1612857980.3090925
train: epoch 29, iter 1700, loss: 2.994314, top_1: 0.514258, top_k: 0.750469, samples/s: 1728.125 1612857995.1228266
train: epoch 29, iter 1800, loss: 3.067163, top_1: 0.507500, top_k: 0.746563, samples/s: 1734.748 1612858009.8800364
train: epoch 29, iter 1900, loss: 3.015112, top_1: 0.514219, top_k: 0.747617, samples/s: 1735.175 1612858024.6335568
train: epoch 29, iter 2000, loss: 3.110649, top_1: 0.518828, top_k: 0.756367, samples/s: 1729.016 1612858039.4396987
train: epoch 29, iter 2100, loss: 3.165684, top_1: 0.514297, top_k: 0.751445, samples/s: 1728.583 1612858054.2495668
train: epoch 29, iter 2200, loss: 2.999081, top_1: 0.515000, top_k: 0.752070, samples/s: 1728.153 1612858069.0630116
train: epoch 29, iter 2300, loss: 3.067386, top_1: 0.513867, top_k: 0.750508, samples/s: 1725.314 1612858083.900897
train: epoch 29, iter 2400, loss: 2.844479, top_1: 0.512305, top_k: 0.752812, samples/s: 1735.295 1612858098.6534128
train: epoch 29, iter 2500, loss: 3.073332, top_1: 0.515898, top_k: 0.751563, samples/s: 1733.549 1612858113.4207568
train: epoch 29, iter 2600, loss: 2.903102, top_1: 0.512656, top_k: 0.751836, samples/s: 1733.900 1612858128.1852336
train: epoch 29, iter 2700, loss: 3.075010, top_1: 0.508906, top_k: 0.742148, samples/s: 1733.643 1612858142.9518707
train: epoch 29, iter 2800, loss: 2.983879, top_1: 0.512383, top_k: 0.748711, samples/s: 1731.831 1612858157.7338321
train: epoch 29, iter 2900, loss: 2.826367, top_1: 0.506641, top_k: 0.746836, samples/s: 1729.805 1612858172.5331526
train: epoch 29, iter 3000, loss: 3.019103, top_1: 0.508359, top_k: 0.750742, samples/s: 1724.665 1612858187.3768053
train: epoch 29, iter 3100, loss: 2.854767, top_1: 0.512773, top_k: 0.746953, samples/s: 1738.836 1612858202.099187
train: epoch 29, iter 3200, loss: 3.200291, top_1: 0.509336, top_k: 0.747578, samples/s: 1741.387 1612858216.8000572
train: epoch 29, iter 3300, loss: 3.088342, top_1: 0.512305, top_k: 0.748008, samples/s: 1721.659 1612858231.6694906
train: epoch 29, iter 3400, loss: 2.992997, top_1: 0.511836, top_k: 0.752344, samples/s: 1717.723 1612858246.5729153
train: epoch 29, iter 3500, loss: 2.867378, top_1: 0.505742, top_k: 0.741484, samples/s: 1725.970 1612858261.4051085
train: epoch 29, iter 3600, loss: 3.003657, top_1: 0.514883, top_k: 0.748477, samples/s: 1742.705 1612858276.0949137
train: epoch 29, iter 3700, loss: 3.165583, top_1: 0.503867, top_k: 0.747344, samples/s: 1731.801 1612858290.8772507
train: epoch 29, iter 3800, loss: 3.193615, top_1: 0.506250, top_k: 0.743633, samples/s: 1731.289 1612858305.6639256
train: epoch 29, iter 3900, loss: 3.006353, top_1: 0.514883, top_k: 0.751758, samples/s: 1719.656 1612858320.5506887
train: epoch 29, iter 4000, loss: 3.032060, top_1: 0.512773, top_k: 0.748086, samples/s: 1734.392 1612858335.310846
train: epoch 29, iter 4100, loss: 3.153173, top_1: 0.508125, top_k: 0.746602, samples/s: 1731.212 1612858350.098412
train: epoch 29, iter 4200, loss: 2.998251, top_1: 0.509062, top_k: 0.750664, samples/s: 1729.442 1612858364.9006395
train: epoch 29, iter 4300, loss: 3.076593, top_1: 0.509453, top_k: 0.744453, samples/s: 1737.731 1612858379.632505
train: epoch 29, iter 4400, loss: 3.110681, top_1: 0.513477, top_k: 0.746172, samples/s: 1740.325 1612858394.3426716
train: epoch 29, iter 4500, loss: 3.081408, top_1: 0.510430, top_k: 0.749687, samples/s: 1739.245 1612858409.0613654
train: epoch 29, iter 4600, loss: 2.922380, top_1: 0.510898, top_k: 0.747266, samples/s: 1738.795 1612858423.7842913
train: epoch 29, iter 4700, loss: 2.967770, top_1: 0.508203, top_k: 0.746211, samples/s: 1735.543 1612858438.534696
train: epoch 29, iter 4800, loss: 3.192280, top_1: 0.510078, top_k: 0.748047, samples/s: 1734.604 1612858453.2931404
train: epoch 29, iter 4900, loss: 2.997089, top_1: 0.502891, top_k: 0.744766, samples/s: 1751.848 1612858467.9062507
train: epoch 29, iter 5000, loss: 3.045197, top_1: 0.510312, top_k: 0.749297, samples/s: 1736.871 1612858482.645392
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_29.
validation: epoch 29, iter 195, top_1: 0.543189, top_k: 0.793730, samples/s: 2760.889 1612858501.106222
train: epoch 30, iter 100, loss: 3.105117, top_1: 0.514961, top_k: 0.753672, samples/s: 1754.155 1612858536.0624514
train: epoch 30, iter 200, loss: 2.829220, top_1: 0.516875, top_k: 0.755742, samples/s: 1760.999 1612858550.5996752
train: epoch 30, iter 300, loss: 3.004708, top_1: 0.524766, top_k: 0.761367, samples/s: 1762.167 1612858565.1273615
train: epoch 30, iter 400, loss: 3.071382, top_1: 0.519961, top_k: 0.758633, samples/s: 1760.250 1612858579.6706254
train: epoch 30, iter 500, loss: 3.138401, top_1: 0.514453, top_k: 0.754102, samples/s: 1740.487 1612858594.379216
train: epoch 30, iter 600, loss: 2.980424, top_1: 0.516914, top_k: 0.752539, samples/s: 1770.555 1612858608.8378623
train: epoch 30, iter 700, loss: 2.991497, top_1: 0.514609, top_k: 0.752734, samples/s: 1747.432 1612858623.4882617
train: epoch 30, iter 800, loss: 2.992196, top_1: 0.513945, top_k: 0.748672, samples/s: 1739.544 1612858638.2044327
train: epoch 30, iter 900, loss: 3.193572, top_1: 0.511719, top_k: 0.754141, samples/s: 1736.519 1612858652.9470992
train: epoch 30, iter 1000, loss: 3.102720, top_1: 0.512930, top_k: 0.749687, samples/s: 1731.265 1612858667.7334561
train: epoch 30, iter 1100, loss: 3.049505, top_1: 0.517734, top_k: 0.756680, samples/s: 1725.878 1612858682.5666513
train: epoch 30, iter 1200, loss: 3.159513, top_1: 0.513945, top_k: 0.751758, samples/s: 1742.511 1612858697.2579815
train: epoch 30, iter 1300, loss: 2.940623, top_1: 0.513945, top_k: 0.752930, samples/s: 1735.497 1612858712.0087368
train: epoch 30, iter 1400, loss: 3.017891, top_1: 0.513437, top_k: 0.753203, samples/s: 1715.774 1612858726.929117
train: epoch 30, iter 1500, loss: 3.057970, top_1: 0.513711, top_k: 0.751680, samples/s: 1733.362 1612858741.6980956
train: epoch 30, iter 1600, loss: 3.105170, top_1: 0.515508, top_k: 0.747031, samples/s: 1738.112 1612858756.4267726
train: epoch 30, iter 1700, loss: 2.788620, top_1: 0.517734, top_k: 0.757773, samples/s: 1727.150 1612858771.2488506
train: epoch 30, iter 1800, loss: 2.778413, top_1: 0.512031, top_k: 0.748516, samples/s: 1730.626 1612858786.0415213
train: epoch 30, iter 1900, loss: 2.905096, top_1: 0.521406, top_k: 0.751758, samples/s: 1722.117 1612858800.9066474
train: epoch 30, iter 2000, loss: 3.075664, top_1: 0.514648, top_k: 0.750273, samples/s: 1743.371 1612858815.5907927
train: epoch 30, iter 2100, loss: 3.093500, top_1: 0.520195, top_k: 0.754492, samples/s: 1724.193 1612858830.4384074
train: epoch 30, iter 2200, loss: 3.057766, top_1: 0.520156, top_k: 0.751289, samples/s: 1731.724 1612858845.221621
train: epoch 30, iter 2300, loss: 3.074882, top_1: 0.518320, top_k: 0.752852, samples/s: 1726.462 1612858860.0492857
train: epoch 30, iter 2400, loss: 2.871084, top_1: 0.509609, top_k: 0.750625, samples/s: 1718.583 1612858874.945378
train: epoch 30, iter 2500, loss: 2.974437, top_1: 0.512891, top_k: 0.749180, samples/s: 1730.790 1612858889.7362053
train: epoch 30, iter 2600, loss: 3.141021, top_1: 0.510234, top_k: 0.745586, samples/s: 1725.579 1612858904.5719013
train: epoch 30, iter 2700, loss: 3.179924, top_1: 0.507227, top_k: 0.745703, samples/s: 1728.163 1612858919.3852842
train: epoch 30, iter 2800, loss: 3.050195, top_1: 0.512109, top_k: 0.749180, samples/s: 1731.760 1612858934.1679418
train: epoch 30, iter 2900, loss: 3.044816, top_1: 0.509180, top_k: 0.750586, samples/s: 1728.487 1612858948.978506
train: epoch 30, iter 3000, loss: 3.042941, top_1: 0.514023, top_k: 0.748398, samples/s: 1728.339 1612858963.7905188
train: epoch 30, iter 3100, loss: 2.949637, top_1: 0.514766, top_k: 0.748555, samples/s: 1726.096 1612858978.6215987
train: epoch 30, iter 3200, loss: 3.000821, top_1: 0.512578, top_k: 0.752109, samples/s: 1734.320 1612858993.3824408
train: epoch 30, iter 3300, loss: 3.140769, top_1: 0.510117, top_k: 0.743437, samples/s: 1730.239 1612859008.1780427
train: epoch 30, iter 3400, loss: 2.975374, top_1: 0.512109, top_k: 0.749102, samples/s: 1736.344 1612859022.921658
train: epoch 30, iter 3500, loss: 3.156467, top_1: 0.513398, top_k: 0.752070, samples/s: 1731.775 1612859037.7042444
train: epoch 30, iter 3600, loss: 3.063405, top_1: 0.511758, top_k: 0.752695, samples/s: 1724.662 1612859052.5476959
train: epoch 30, iter 3700, loss: 3.343816, top_1: 0.517734, top_k: 0.755664, samples/s: 1726.937 1612859067.3720844
train: epoch 30, iter 3800, loss: 3.033190, top_1: 0.512188, top_k: 0.749648, samples/s: 1715.109 1612859082.2978563
train: epoch 30, iter 3900, loss: 3.121918, top_1: 0.513398, top_k: 0.753555, samples/s: 1738.775 1612859097.020901
train: epoch 30, iter 4000, loss: 2.966221, top_1: 0.512148, top_k: 0.749141, samples/s: 1736.242 1612859111.7652833
train: epoch 30, iter 4100, loss: 3.141387, top_1: 0.511133, top_k: 0.751719, samples/s: 1736.780 1612859126.50522
train: epoch 30, iter 4200, loss: 2.934729, top_1: 0.508086, top_k: 0.746563, samples/s: 1734.806 1612859141.261894
train: epoch 30, iter 4300, loss: 3.154927, top_1: 0.506602, top_k: 0.745820, samples/s: 1721.239 1612859156.1348999
train: epoch 30, iter 4400, loss: 3.150403, top_1: 0.515625, top_k: 0.747500, samples/s: 1726.081 1612859170.966204
train: epoch 30, iter 4500, loss: 3.029467, top_1: 0.514727, top_k: 0.751445, samples/s: 1727.633 1612859185.7841468
train: epoch 30, iter 4600, loss: 2.891866, top_1: 0.509609, top_k: 0.747539, samples/s: 1730.727 1612859200.5756295
train: epoch 30, iter 4700, loss: 2.866758, top_1: 0.513867, top_k: 0.747891, samples/s: 1748.646 1612859215.2159834
train: epoch 30, iter 4800, loss: 2.888131, top_1: 0.511211, top_k: 0.751641, samples/s: 1739.001 1612859229.9366527
train: epoch 30, iter 4900, loss: 3.067545, top_1: 0.513281, top_k: 0.751523, samples/s: 1725.278 1612859244.7748125
train: epoch 30, iter 5000, loss: 3.271337, top_1: 0.514219, top_k: 0.747227, samples/s: 1726.829 1612859259.5996728
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_30.
validation: epoch 30, iter 195, top_1: 0.564623, top_k: 0.803606, samples/s: 2859.859 1612859277.465124
train: epoch 31, iter 100, loss: 3.227642, top_1: 0.518594, top_k: 0.756484, samples/s: 1743.112 1612859312.2258222
train: epoch 31, iter 200, loss: 2.960831, top_1: 0.519141, top_k: 0.758633, samples/s: 1770.350 1612859326.686316
train: epoch 31, iter 300, loss: 2.860647, top_1: 0.516992, top_k: 0.759844, samples/s: 1758.363 1612859341.245317
train: epoch 31, iter 400, loss: 2.767488, top_1: 0.513398, top_k: 0.751211, samples/s: 1750.684 1612859355.8683238
train: epoch 31, iter 500, loss: 3.141456, top_1: 0.523281, top_k: 0.760938, samples/s: 1764.622 1612859370.3754807
train: epoch 31, iter 600, loss: 3.093033, top_1: 0.514453, top_k: 0.751953, samples/s: 1739.157 1612859385.0953107
train: epoch 31, iter 700, loss: 2.945261, top_1: 0.522383, top_k: 0.757734, samples/s: 1737.289 1612859399.8308215
train: epoch 31, iter 800, loss: 2.814361, top_1: 0.521094, top_k: 0.755586, samples/s: 1737.484 1612859414.5648358
train: epoch 31, iter 900, loss: 2.889184, top_1: 0.514687, top_k: 0.753398, samples/s: 1735.787 1612859429.3132088
train: epoch 31, iter 1000, loss: 3.026215, top_1: 0.517813, top_k: 0.755664, samples/s: 1729.117 1612859444.1184182
train: epoch 31, iter 1100, loss: 3.001241, top_1: 0.514961, top_k: 0.751563, samples/s: 1734.552 1612859458.8772593
train: epoch 31, iter 1200, loss: 3.005126, top_1: 0.517539, top_k: 0.755117, samples/s: 1729.014 1612859473.6833498
train: epoch 31, iter 1300, loss: 3.065888, top_1: 0.513789, top_k: 0.750625, samples/s: 1727.934 1612859488.498808
train: epoch 31, iter 1400, loss: 2.731120, top_1: 0.517617, top_k: 0.753945, samples/s: 1727.229 1612859503.3202672
train: epoch 31, iter 1500, loss: 3.183186, top_1: 0.515781, top_k: 0.750352, samples/s: 1737.794 1612859518.0515323
train: epoch 31, iter 1600, loss: 3.109799, top_1: 0.519141, top_k: 0.750625, samples/s: 1732.681 1612859532.8263361
train: epoch 31, iter 1700, loss: 3.028584, top_1: 0.516250, top_k: 0.755664, samples/s: 1713.124 1612859547.7697766
train: epoch 31, iter 1800, loss: 3.043079, top_1: 0.518047, top_k: 0.753203, samples/s: 1738.035 1612859562.499038
train: epoch 31, iter 1900, loss: 3.015839, top_1: 0.515195, top_k: 0.753242, samples/s: 1719.299 1612859577.388808
train: epoch 31, iter 2000, loss: 2.927325, top_1: 0.517656, top_k: 0.752539, samples/s: 1729.933 1612859592.1871798
train: epoch 31, iter 2100, loss: 2.997191, top_1: 0.511016, top_k: 0.747344, samples/s: 1735.414 1612859606.938629
train: epoch 31, iter 2200, loss: 2.931155, top_1: 0.514922, top_k: 0.751719, samples/s: 1731.879 1612859621.7202775
train: epoch 31, iter 2300, loss: 2.852134, top_1: 0.511055, top_k: 0.755703, samples/s: 1726.071 1612859636.5515954
train: epoch 31, iter 2400, loss: 3.220090, top_1: 0.515703, top_k: 0.750586, samples/s: 1733.233 1612859651.3217514
train: epoch 31, iter 2500, loss: 2.967660, top_1: 0.516797, top_k: 0.753437, samples/s: 1739.541 1612859666.0382295
train: epoch 31, iter 2600, loss: 3.087746, top_1: 0.516094, top_k: 0.755078, samples/s: 1739.006 1612859680.759382
train: epoch 31, iter 2700, loss: 3.006091, top_1: 0.514297, top_k: 0.752461, samples/s: 1743.080 1612859695.4459934
train: epoch 31, iter 2800, loss: 3.042073, top_1: 0.515820, top_k: 0.753594, samples/s: 1749.383 1612859710.079635
train: epoch 31, iter 2900, loss: 3.084884, top_1: 0.513125, top_k: 0.750195, samples/s: 1735.541 1612859724.8301327
train: epoch 31, iter 3000, loss: 2.908145, top_1: 0.510859, top_k: 0.747461, samples/s: 1739.610 1612859739.545998
train: epoch 31, iter 3100, loss: 3.069016, top_1: 0.515898, top_k: 0.749102, samples/s: 1749.998 1612859754.1745894
train: epoch 31, iter 3200, loss: 2.943990, top_1: 0.518242, top_k: 0.750820, samples/s: 1748.092 1612859768.8191304
train: epoch 31, iter 3300, loss: 3.075756, top_1: 0.504766, top_k: 0.743711, samples/s: 1740.438 1612859783.5281854
train: epoch 31, iter 3400, loss: 3.067491, top_1: 0.515586, top_k: 0.750391, samples/s: 1750.744 1612859798.1504235
train: epoch 31, iter 3500, loss: 3.152300, top_1: 0.511719, top_k: 0.748633, samples/s: 1745.622 1612859812.8157814
train: epoch 31, iter 3600, loss: 2.994628, top_1: 0.521172, top_k: 0.754961, samples/s: 1754.053 1612859827.4105065
train: epoch 31, iter 3700, loss: 3.034254, top_1: 0.516914, top_k: 0.750195, samples/s: 1743.112 1612859842.0968926
train: epoch 31, iter 3800, loss: 2.998308, top_1: 0.514141, top_k: 0.751016, samples/s: 1746.327 1612859856.7561705
train: epoch 31, iter 3900, loss: 2.957915, top_1: 0.513516, top_k: 0.752617, samples/s: 1737.596 1612859871.4892876
train: epoch 31, iter 4000, loss: 2.949530, top_1: 0.518711, top_k: 0.751680, samples/s: 1751.828 1612859886.102484
train: epoch 31, iter 4100, loss: 3.176137, top_1: 0.515547, top_k: 0.753047, samples/s: 1753.822 1612859900.6992328
train: epoch 31, iter 4200, loss: 3.130639, top_1: 0.513906, top_k: 0.748750, samples/s: 1742.356 1612859915.3920195
train: epoch 31, iter 4300, loss: 3.095192, top_1: 0.512695, top_k: 0.747773, samples/s: 1760.382 1612859929.9342854
train: epoch 31, iter 4400, loss: 3.059817, top_1: 0.511563, top_k: 0.749922, samples/s: 1739.146 1612859944.6541502
train: epoch 31, iter 4500, loss: 3.060183, top_1: 0.512031, top_k: 0.748477, samples/s: 1748.862 1612859959.2921774
train: epoch 31, iter 4600, loss: 3.030220, top_1: 0.515469, top_k: 0.750547, samples/s: 1755.181 1612859973.8776
train: epoch 31, iter 4700, loss: 3.072633, top_1: 0.510742, top_k: 0.745000, samples/s: 1733.835 1612859988.6426463
train: epoch 31, iter 4800, loss: 3.087548, top_1: 0.519805, top_k: 0.754414, samples/s: 1754.065 1612860003.2372997
train: epoch 31, iter 4900, loss: 2.882055, top_1: 0.514375, top_k: 0.747852, samples/s: 1745.161 1612860017.906373
train: epoch 31, iter 5000, loss: 2.995375, top_1: 0.519375, top_k: 0.750352, samples/s: 1754.499 1612860032.4974365
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_31.
validation: epoch 31, iter 195, top_1: 0.563602, top_k: 0.804868, samples/s: 2892.663 1612860050.238544
train: epoch 32, iter 100, loss: 3.123415, top_1: 0.519531, top_k: 0.758086, samples/s: 1757.788 1612860085.129425
train: epoch 32, iter 200, loss: 2.859045, top_1: 0.523398, top_k: 0.763320, samples/s: 1755.519 1612860099.7121363
train: epoch 32, iter 300, loss: 3.103852, top_1: 0.520312, top_k: 0.759531, samples/s: 1757.121 1612860114.2813284
train: epoch 32, iter 400, loss: 2.997580, top_1: 0.523906, top_k: 0.758008, samples/s: 1755.509 1612860128.8639452
train: epoch 32, iter 500, loss: 3.140479, top_1: 0.521016, top_k: 0.753828, samples/s: 1756.623 1612860143.4374428
train: epoch 32, iter 600, loss: 3.016304, top_1: 0.519844, top_k: 0.760000, samples/s: 1749.259 1612860158.072189
train: epoch 32, iter 700, loss: 3.286558, top_1: 0.522656, top_k: 0.757773, samples/s: 1744.064 1612860172.750574
train: epoch 32, iter 800, loss: 3.067199, top_1: 0.518086, top_k: 0.758789, samples/s: 1738.417 1612860187.4765284
train: epoch 32, iter 900, loss: 2.913200, top_1: 0.516953, top_k: 0.752148, samples/s: 1716.078 1612860202.3942955
train: epoch 32, iter 1000, loss: 2.974661, top_1: 0.518906, top_k: 0.752695, samples/s: 1742.165 1612860217.0886846
train: epoch 32, iter 1100, loss: 3.125568, top_1: 0.516055, top_k: 0.752969, samples/s: 1733.497 1612860231.8564613
train: epoch 32, iter 1200, loss: 3.025293, top_1: 0.521836, top_k: 0.756172, samples/s: 1734.048 1612860246.6196578
train: epoch 32, iter 1300, loss: 2.906627, top_1: 0.523945, top_k: 0.759258, samples/s: 1732.904 1612860261.392599
train: epoch 32, iter 1400, loss: 3.168316, top_1: 0.511563, top_k: 0.751445, samples/s: 1732.262 1612860276.17089
train: epoch 32, iter 1500, loss: 2.937056, top_1: 0.519141, top_k: 0.756133, samples/s: 1727.972 1612860290.9859054
train: epoch 32, iter 1600, loss: 2.841022, top_1: 0.518086, top_k: 0.755000, samples/s: 1730.391 1612860305.7803316
train: epoch 32, iter 1700, loss: 3.126826, top_1: 0.519219, top_k: 0.755195, samples/s: 1734.511 1612860320.5395749
train: epoch 32, iter 1800, loss: 2.950785, top_1: 0.518359, top_k: 0.750078, samples/s: 1732.461 1612860335.3161926
train: epoch 32, iter 1900, loss: 3.169011, top_1: 0.518203, top_k: 0.750977, samples/s: 1733.664 1612860350.0826163
train: epoch 32, iter 2000, loss: 2.996193, top_1: 0.513789, top_k: 0.752305, samples/s: 1720.425 1612860364.9626315
train: epoch 32, iter 2100, loss: 2.943861, top_1: 0.513281, top_k: 0.751523, samples/s: 1735.818 1612860379.7107232
train: epoch 32, iter 2200, loss: 3.080306, top_1: 0.522578, top_k: 0.754102, samples/s: 1722.618 1612860394.5717845
train: epoch 32, iter 2300, loss: 2.830279, top_1: 0.509727, top_k: 0.751406, samples/s: 1725.644 1612860409.4068618
train: epoch 32, iter 2400, loss: 3.162946, top_1: 0.516953, top_k: 0.749766, samples/s: 1730.084 1612860424.2038302
train: epoch 32, iter 2500, loss: 2.886956, top_1: 0.515391, top_k: 0.755703, samples/s: 1737.810 1612860438.9349637
train: epoch 32, iter 2600, loss: 3.032409, top_1: 0.518516, top_k: 0.752109, samples/s: 1727.855 1612860453.7510676
train: epoch 32, iter 2700, loss: 3.097644, top_1: 0.515469, top_k: 0.751680, samples/s: 1732.295 1612860468.5291796
train: epoch 32, iter 2800, loss: 3.130354, top_1: 0.515117, top_k: 0.749922, samples/s: 1725.780 1612860483.3630404
train: epoch 32, iter 2900, loss: 3.159739, top_1: 0.511523, top_k: 0.748555, samples/s: 1728.569 1612860498.1729064
train: epoch 32, iter 3000, loss: 3.035973, top_1: 0.514531, top_k: 0.753477, samples/s: 1737.775 1612860512.904452
train: epoch 32, iter 3100, loss: 2.984562, top_1: 0.511094, top_k: 0.752891, samples/s: 1727.895 1612860527.7201204
train: epoch 32, iter 3200, loss: 2.892226, top_1: 0.514766, top_k: 0.755781, samples/s: 1735.703 1612860542.4692369
train: epoch 32, iter 3300, loss: 2.841896, top_1: 0.514687, top_k: 0.746602, samples/s: 1729.877 1612860557.2679753
train: epoch 32, iter 3400, loss: 3.054988, top_1: 0.511445, top_k: 0.750117, samples/s: 1741.310 1612860571.9695275
train: epoch 32, iter 3500, loss: 3.080004, top_1: 0.519687, top_k: 0.751602, samples/s: 1728.873 1612860586.7768383
train: epoch 32, iter 3600, loss: 3.024574, top_1: 0.514570, top_k: 0.752852, samples/s: 1742.452 1612860601.4688318
train: epoch 32, iter 3700, loss: 3.080533, top_1: 0.512656, top_k: 0.750234, samples/s: 1744.143 1612860616.1465862
train: epoch 32, iter 3800, loss: 3.109531, top_1: 0.520820, top_k: 0.755117, samples/s: 1745.121 1612860630.8159385
train: epoch 32, iter 3900, loss: 2.877510, top_1: 0.513008, top_k: 0.753203, samples/s: 1744.859 1612860645.4876304
train: epoch 32, iter 4000, loss: 3.099912, top_1: 0.520664, top_k: 0.756914, samples/s: 1746.033 1612860660.1494796
train: epoch 32, iter 4100, loss: 3.095433, top_1: 0.515625, top_k: 0.753672, samples/s: 1719.544 1612860675.037109
train: epoch 32, iter 4200, loss: 2.838548, top_1: 0.518906, top_k: 0.756211, samples/s: 1760.567 1612860689.5779614
train: epoch 32, iter 4300, loss: 3.054841, top_1: 0.519414, top_k: 0.753633, samples/s: 1746.789 1612860704.2333152
train: epoch 32, iter 4400, loss: 3.002110, top_1: 0.514219, top_k: 0.749922, samples/s: 1750.326 1612860718.8591797
train: epoch 32, iter 4500, loss: 2.874690, top_1: 0.516406, top_k: 0.754922, samples/s: 1751.977 1612860733.4712877
train: epoch 32, iter 4600, loss: 3.058812, top_1: 0.520547, top_k: 0.753711, samples/s: 1750.334 1612860748.0970309
train: epoch 32, iter 4700, loss: 3.022842, top_1: 0.511484, top_k: 0.748555, samples/s: 1748.780 1612860762.7358608
train: epoch 32, iter 4800, loss: 2.900985, top_1: 0.518828, top_k: 0.754102, samples/s: 1729.069 1612860777.5415475
train: epoch 32, iter 4900, loss: 2.929306, top_1: 0.511836, top_k: 0.750469, samples/s: 1742.395 1612860792.2338998
train: epoch 32, iter 5000, loss: 2.918313, top_1: 0.515859, top_k: 0.753008, samples/s: 1740.690 1612860806.940725
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_32.
validation: epoch 32, iter 195, top_1: 0.564844, top_k: 0.808934, samples/s: 2825.146 1612860825.0538223
train: epoch 33, iter 100, loss: 3.039576, top_1: 0.523516, top_k: 0.763867, samples/s: 1750.411 1612860859.8070157
train: epoch 33, iter 200, loss: 2.862511, top_1: 0.524375, top_k: 0.757344, samples/s: 1758.107 1612860874.3682775
train: epoch 33, iter 300, loss: 2.917448, top_1: 0.524844, top_k: 0.755938, samples/s: 1742.548 1612860889.0592415
train: epoch 33, iter 400, loss: 2.888446, top_1: 0.522969, top_k: 0.760469, samples/s: 1752.172 1612860903.6696465
train: epoch 33, iter 500, loss: 3.043155, top_1: 0.522930, top_k: 0.755000, samples/s: 1762.407 1612860918.195325
train: epoch 33, iter 600, loss: 2.934077, top_1: 0.523906, top_k: 0.754414, samples/s: 1739.113 1612860932.915477
train: epoch 33, iter 700, loss: 2.998035, top_1: 0.514141, top_k: 0.754219, samples/s: 1750.943 1612860947.5360746
train: epoch 33, iter 800, loss: 3.140139, top_1: 0.518594, top_k: 0.758437, samples/s: 1737.805 1612860962.2673624
train: epoch 33, iter 900, loss: 2.919622, top_1: 0.520039, top_k: 0.754141, samples/s: 1734.694 1612860977.0249944
train: epoch 33, iter 1000, loss: 2.851893, top_1: 0.524258, top_k: 0.762969, samples/s: 1720.847 1612860991.9014685
train: epoch 33, iter 1100, loss: 2.981446, top_1: 0.520664, top_k: 0.756211, samples/s: 1729.923 1612861006.6997006
train: epoch 33, iter 1200, loss: 2.938886, top_1: 0.520039, top_k: 0.752227, samples/s: 1726.541 1612861021.5270936
train: epoch 33, iter 1300, loss: 2.952264, top_1: 0.516055, top_k: 0.750898, samples/s: 1720.244 1612861036.4086976
train: epoch 33, iter 1400, loss: 3.113863, top_1: 0.515781, top_k: 0.752461, samples/s: 1719.888 1612861051.2934713
train: epoch 33, iter 1500, loss: 2.945489, top_1: 0.520938, top_k: 0.754453, samples/s: 1729.755 1612861066.0931158
train: epoch 33, iter 1600, loss: 3.107597, top_1: 0.516523, top_k: 0.755938, samples/s: 1725.080 1612861080.9330394
train: epoch 33, iter 1700, loss: 3.028331, top_1: 0.518828, top_k: 0.757422, samples/s: 1719.708 1612861095.8193607
train: epoch 33, iter 1800, loss: 2.982189, top_1: 0.517500, top_k: 0.757070, samples/s: 1737.547 1612861110.5526643
train: epoch 33, iter 1900, loss: 2.864038, top_1: 0.518477, top_k: 0.756719, samples/s: 1728.070 1612861125.3669283
train: epoch 33, iter 2000, loss: 2.958687, top_1: 0.515273, top_k: 0.753633, samples/s: 1738.948 1612861140.0884194
train: epoch 33, iter 2100, loss: 3.114889, top_1: 0.518477, top_k: 0.756836, samples/s: 1744.922 1612861154.7596622
train: epoch 33, iter 2200, loss: 2.944378, top_1: 0.519922, top_k: 0.756758, samples/s: 1740.601 1612861169.467149
train: epoch 33, iter 2300, loss: 2.835271, top_1: 0.516758, top_k: 0.756250, samples/s: 1742.842 1612861184.1558037
train: epoch 33, iter 2400, loss: 3.228756, top_1: 0.513555, top_k: 0.748867, samples/s: 1745.427 1612861198.8227108
train: epoch 33, iter 2500, loss: 3.010417, top_1: 0.515039, top_k: 0.755742, samples/s: 1734.065 1612861213.585803
train: epoch 33, iter 2600, loss: 3.116937, top_1: 0.517578, top_k: 0.751211, samples/s: 1732.737 1612861228.3601093
train: epoch 33, iter 2700, loss: 2.909161, top_1: 0.523008, top_k: 0.762422, samples/s: 1740.925 1612861243.064886
train: epoch 33, iter 2800, loss: 3.027411, top_1: 0.516641, top_k: 0.751797, samples/s: 1752.528 1612861257.6723626
train: epoch 33, iter 2900, loss: 3.077026, top_1: 0.511836, top_k: 0.748164, samples/s: 1726.674 1612861272.4985573
train: epoch 33, iter 3000, loss: 3.028041, top_1: 0.518984, top_k: 0.750586, samples/s: 1756.425 1612861287.0735881
train: epoch 33, iter 3100, loss: 2.885276, top_1: 0.515352, top_k: 0.751836, samples/s: 1735.163 1612861301.8272758
train: epoch 33, iter 3200, loss: 2.860032, top_1: 0.522109, top_k: 0.755391, samples/s: 1750.672 1612861316.4502006
train: epoch 33, iter 3300, loss: 2.825618, top_1: 0.518867, top_k: 0.759102, samples/s: 1745.796 1612861331.1140304
train: epoch 33, iter 3400, loss: 3.035249, top_1: 0.518320, top_k: 0.752188, samples/s: 1747.568 1612861345.7629502
train: epoch 33, iter 3500, loss: 2.870065, top_1: 0.519922, top_k: 0.757109, samples/s: 1746.926 1612861360.4172254
train: epoch 33, iter 3600, loss: 3.045685, top_1: 0.516055, top_k: 0.754531, samples/s: 1748.086 1612861375.0617983
train: epoch 33, iter 3700, loss: 2.805060, top_1: 0.513828, top_k: 0.753242, samples/s: 1750.534 1612861389.685911
train: epoch 33, iter 3800, loss: 2.887515, top_1: 0.516758, top_k: 0.756133, samples/s: 1735.058 1612861404.440459
train: epoch 33, iter 3900, loss: 3.043517, top_1: 0.521641, top_k: 0.756836, samples/s: 1748.711 1612861419.079832
train: epoch 33, iter 4000, loss: 3.102011, top_1: 0.522266, top_k: 0.759023, samples/s: 1740.630 1612861433.7872634
train: epoch 33, iter 4100, loss: 3.121321, top_1: 0.516055, top_k: 0.752500, samples/s: 1746.715 1612861448.4433758
train: epoch 33, iter 4200, loss: 3.007271, top_1: 0.520703, top_k: 0.752578, samples/s: 1746.584 1612861463.1004207
train: epoch 33, iter 4300, loss: 3.093593, top_1: 0.510078, top_k: 0.748359, samples/s: 1745.906 1612861477.7633462
train: epoch 33, iter 4400, loss: 3.066826, top_1: 0.520039, top_k: 0.750625, samples/s: 1750.972 1612861492.3837435
train: epoch 33, iter 4500, loss: 3.174620, top_1: 0.519297, top_k: 0.754297, samples/s: 1744.660 1612861507.0570996
train: epoch 33, iter 4600, loss: 2.980485, top_1: 0.517031, top_k: 0.753437, samples/s: 1745.036 1612861521.7273715
train: epoch 33, iter 4700, loss: 3.298063, top_1: 0.515000, top_k: 0.751289, samples/s: 1750.587 1612861536.3510673
train: epoch 33, iter 4800, loss: 2.809725, top_1: 0.515586, top_k: 0.752109, samples/s: 1743.037 1612861551.0379932
train: epoch 33, iter 4900, loss: 2.779513, top_1: 0.514375, top_k: 0.753359, samples/s: 1762.053 1612861565.5665183
train: epoch 33, iter 5000, loss: 3.032427, top_1: 0.518437, top_k: 0.751406, samples/s: 1752.417 1612861580.1748586
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_33.
validation: epoch 33, iter 195, top_1: 0.552043, top_k: 0.801943, samples/s: 2838.600 1612861598.2838867
train: epoch 34, iter 100, loss: 3.131543, top_1: 0.526914, top_k: 0.762695, samples/s: 1730.623 1612861633.1088889
train: epoch 34, iter 200, loss: 2.823898, top_1: 0.525469, top_k: 0.761641, samples/s: 1770.366 1612861647.5692205
train: epoch 34, iter 300, loss: 3.001943, top_1: 0.525898, top_k: 0.761211, samples/s: 1759.659 1612861662.1173863
train: epoch 34, iter 400, loss: 2.965181, top_1: 0.526953, top_k: 0.759766, samples/s: 1755.268 1612861676.702056
train: epoch 34, iter 500, loss: 3.079912, top_1: 0.515781, top_k: 0.753359, samples/s: 1755.674 1612861691.2833524
train: epoch 34, iter 600, loss: 3.080328, top_1: 0.520742, top_k: 0.757422, samples/s: 1759.674 1612861705.8317564
train: epoch 34, iter 700, loss: 2.980153, top_1: 0.529062, top_k: 0.761758, samples/s: 1738.608 1612861720.5560093
train: epoch 34, iter 800, loss: 3.119226, top_1: 0.530859, top_k: 0.765078, samples/s: 1747.888 1612861735.2022007
train: epoch 34, iter 900, loss: 3.062318, top_1: 0.526641, top_k: 0.762266, samples/s: 1735.398 1612861749.9544663
train: epoch 34, iter 1000, loss: 3.040417, top_1: 0.521328, top_k: 0.756953, samples/s: 1737.205 1612861764.690145
train: epoch 34, iter 1100, loss: 2.858849, top_1: 0.525898, top_k: 0.759961, samples/s: 1719.670 1612861779.576734
train: epoch 34, iter 1200, loss: 2.707504, top_1: 0.523242, top_k: 0.756953, samples/s: 1728.015 1612861794.3913972
train: epoch 34, iter 1300, loss: 2.861265, top_1: 0.525742, top_k: 0.755195, samples/s: 1743.839 1612861809.0716717
train: epoch 34, iter 1400, loss: 2.987481, top_1: 0.520938, top_k: 0.759570, samples/s: 1732.846 1612861823.8451033
train: epoch 34, iter 1500, loss: 2.999345, top_1: 0.524336, top_k: 0.756914, samples/s: 1719.894 1612861838.729702
train: epoch 34, iter 1600, loss: 3.123664, top_1: 0.521094, top_k: 0.756641, samples/s: 1725.035 1612861853.5699623
train: epoch 34, iter 1700, loss: 3.058884, top_1: 0.517539, top_k: 0.752148, samples/s: 1722.428 1612861868.4326906
train: epoch 34, iter 1800, loss: 3.242388, top_1: 0.522891, top_k: 0.758555, samples/s: 1747.539 1612861883.0819206
train: epoch 34, iter 1900, loss: 2.996660, top_1: 0.520469, top_k: 0.755742, samples/s: 1729.160 1612861897.8868475
train: epoch 34, iter 2000, loss: 2.979532, top_1: 0.520117, top_k: 0.757969, samples/s: 1729.084 1612861912.6923676
train: epoch 34, iter 2100, loss: 3.189896, top_1: 0.515625, top_k: 0.753359, samples/s: 1736.291 1612861927.436378
train: epoch 34, iter 2200, loss: 3.105829, top_1: 0.519180, top_k: 0.756016, samples/s: 1735.447 1612861942.1876419
train: epoch 34, iter 2300, loss: 2.955502, top_1: 0.523984, top_k: 0.755352, samples/s: 1724.336 1612861957.0340512
train: epoch 34, iter 2400, loss: 2.841560, top_1: 0.520781, top_k: 0.756602, samples/s: 1730.541 1612861971.8269553
train: epoch 34, iter 2500, loss: 3.095677, top_1: 0.520898, top_k: 0.756484, samples/s: 1725.275 1612861986.6652455
train: epoch 34, iter 2600, loss: 3.034699, top_1: 0.525430, top_k: 0.759492, samples/s: 1736.983 1612862001.4034011
train: epoch 34, iter 2700, loss: 2.836326, top_1: 0.519766, top_k: 0.752344, samples/s: 1734.557 1612862016.1622167
train: epoch 34, iter 2800, loss: 2.975376, top_1: 0.518281, top_k: 0.756055, samples/s: 1733.587 1612862030.9295733
train: epoch 34, iter 2900, loss: 3.010139, top_1: 0.512227, top_k: 0.752930, samples/s: 1733.021 1612862045.701202
train: epoch 34, iter 3000, loss: 2.971723, top_1: 0.510898, top_k: 0.754609, samples/s: 1735.245 1612862060.4543915
train: epoch 34, iter 3100, loss: 2.872160, top_1: 0.515312, top_k: 0.752930, samples/s: 1731.985 1612862075.234867
train: epoch 34, iter 3200, loss: 2.910634, top_1: 0.516953, top_k: 0.756680, samples/s: 1725.452 1612862090.0715358
train: epoch 34, iter 3300, loss: 3.020869, top_1: 0.519844, top_k: 0.753672, samples/s: 1709.552 1612862105.0462403
train: epoch 34, iter 3400, loss: 2.890921, top_1: 0.518984, top_k: 0.754102, samples/s: 1743.385 1612862119.73061
train: epoch 34, iter 3500, loss: 2.877353, top_1: 0.519219, top_k: 0.750273, samples/s: 1728.364 1612862134.5420158
train: epoch 34, iter 3600, loss: 3.111268, top_1: 0.514961, top_k: 0.754453, samples/s: 1737.981 1612862149.2717464
train: epoch 34, iter 3700, loss: 3.017594, top_1: 0.520742, top_k: 0.759297, samples/s: 1718.151 1612862164.1714847
train: epoch 34, iter 3800, loss: 3.148534, top_1: 0.518359, top_k: 0.754414, samples/s: 1726.564 1612862178.9987288
train: epoch 34, iter 3900, loss: 3.142565, top_1: 0.521016, top_k: 0.757422, samples/s: 1723.527 1612862193.8519797
train: epoch 34, iter 4000, loss: 3.088120, top_1: 0.519883, top_k: 0.753711, samples/s: 1732.556 1612862208.627847
train: epoch 34, iter 4100, loss: 3.014006, top_1: 0.522500, top_k: 0.758906, samples/s: 1741.093 1612862223.33111
train: epoch 34, iter 4200, loss: 3.134861, top_1: 0.519453, top_k: 0.751719, samples/s: 1736.842 1612862238.0705028
train: epoch 34, iter 4300, loss: 2.864770, top_1: 0.515859, top_k: 0.755820, samples/s: 1736.536 1612862252.8125455
train: epoch 34, iter 4400, loss: 2.949529, top_1: 0.513477, top_k: 0.748125, samples/s: 1724.764 1612862267.6551015
train: epoch 34, iter 4500, loss: 2.875999, top_1: 0.517578, top_k: 0.755586, samples/s: 1740.678 1612862282.3620863
train: epoch 34, iter 4600, loss: 2.952051, top_1: 0.515039, top_k: 0.753125, samples/s: 1721.762 1612862297.230862
train: epoch 34, iter 4700, loss: 3.186699, top_1: 0.520469, top_k: 0.754297, samples/s: 1733.595 1612862311.9975278
train: epoch 34, iter 4800, loss: 3.027578, top_1: 0.515273, top_k: 0.754805, samples/s: 1731.477 1612862326.7825963
train: epoch 34, iter 4900, loss: 3.139005, top_1: 0.521484, top_k: 0.755859, samples/s: 1730.002 1612862341.580245
train: epoch 34, iter 5000, loss: 2.887652, top_1: 0.524297, top_k: 0.754805, samples/s: 1740.923 1612862356.285458
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_34.
validation: epoch 34, iter 195, top_1: 0.561498, top_k: 0.809455, samples/s: 2833.781 1612862374.3087275
train: epoch 35, iter 100, loss: 3.008422, top_1: 0.536250, top_k: 0.767539, samples/s: 1751.852 1612862414.651158
train: epoch 35, iter 200, loss: 3.074722, top_1: 0.527813, top_k: 0.758164, samples/s: 1758.714 1612862429.2072096
train: epoch 35, iter 300, loss: 2.929927, top_1: 0.527109, top_k: 0.761172, samples/s: 1766.687 1612862443.6976986
train: epoch 35, iter 400, loss: 2.893735, top_1: 0.526602, top_k: 0.761094, samples/s: 1757.997 1612862458.259884
train: epoch 35, iter 500, loss: 2.900565, top_1: 0.525586, top_k: 0.765625, samples/s: 1753.671 1612862472.8575988
train: epoch 35, iter 600, loss: 3.089781, top_1: 0.520820, top_k: 0.755664, samples/s: 1745.714 1612862487.5220668
train: epoch 35, iter 700, loss: 2.938406, top_1: 0.523242, top_k: 0.758281, samples/s: 1735.578 1612862502.2726016
train: epoch 35, iter 800, loss: 2.987633, top_1: 0.527461, top_k: 0.759844, samples/s: 1747.612 1612862516.9207914
train: epoch 35, iter 900, loss: 3.018815, top_1: 0.520352, top_k: 0.755938, samples/s: 1741.360 1612862531.6219194
train: epoch 35, iter 1000, loss: 2.881433, top_1: 0.525273, top_k: 0.760273, samples/s: 1722.016 1612862546.4882658
train: epoch 35, iter 1100, loss: 3.054560, top_1: 0.526602, top_k: 0.762461, samples/s: 1733.246 1612862561.2582195
train: epoch 35, iter 1200, loss: 3.050480, top_1: 0.530469, top_k: 0.763203, samples/s: 1724.201 1612862576.105657
train: epoch 35, iter 1300, loss: 3.084922, top_1: 0.521797, top_k: 0.754844, samples/s: 1742.906 1612862590.7938557
train: epoch 35, iter 1400, loss: 2.878707, top_1: 0.518672, top_k: 0.758906, samples/s: 1722.478 1612862605.656354
train: epoch 35, iter 1500, loss: 3.031515, top_1: 0.529453, top_k: 0.763047, samples/s: 1741.258 1612862620.358185
train: epoch 35, iter 1600, loss: 2.924164, top_1: 0.521250, top_k: 0.754648, samples/s: 1731.019 1612862635.1470816
train: epoch 35, iter 1700, loss: 3.209555, top_1: 0.521914, top_k: 0.759102, samples/s: 1722.956 1612862650.0053296
train: epoch 35, iter 1800, loss: 2.969894, top_1: 0.521211, top_k: 0.760391, samples/s: 1747.943 1612862664.6510246
train: epoch 35, iter 1900, loss: 2.971289, top_1: 0.515156, top_k: 0.753086, samples/s: 1746.784 1612862679.3068588
train: epoch 35, iter 2000, loss: 3.094872, top_1: 0.519844, top_k: 0.754727, samples/s: 1728.637 1612862694.1160479
train: epoch 35, iter 2100, loss: 3.179728, top_1: 0.522852, top_k: 0.756523, samples/s: 1728.667 1612862708.9250495
train: epoch 35, iter 2200, loss: 2.783416, top_1: 0.519414, top_k: 0.754492, samples/s: 1726.622 1612862723.7516627
train: epoch 35, iter 2300, loss: 2.963136, top_1: 0.522852, top_k: 0.757812, samples/s: 1731.725 1612862738.5345721
train: epoch 35, iter 2400, loss: 2.983070, top_1: 0.516055, top_k: 0.750117, samples/s: 1737.117 1612862753.2716234
train: epoch 35, iter 2500, loss: 2.989383, top_1: 0.525664, top_k: 0.760625, samples/s: 1720.508 1612862768.1509979
train: epoch 35, iter 2600, loss: 3.076047, top_1: 0.520000, top_k: 0.755313, samples/s: 1728.148 1612862782.964562
train: epoch 35, iter 2700, loss: 3.176400, top_1: 0.524375, top_k: 0.758086, samples/s: 1736.147 1612862797.709887
train: epoch 35, iter 2800, loss: 2.957859, top_1: 0.513672, top_k: 0.752891, samples/s: 1748.737 1612862812.3493812
train: epoch 35, iter 2900, loss: 2.903420, top_1: 0.524375, top_k: 0.759609, samples/s: 1743.136 1612862827.035129
train: epoch 35, iter 3000, loss: 2.933910, top_1: 0.518867, top_k: 0.755508, samples/s: 1746.235 1612862841.6952653
train: epoch 35, iter 3100, loss: 3.136323, top_1: 0.521758, top_k: 0.753477, samples/s: 1743.331 1612862856.3798032
train: epoch 35, iter 3200, loss: 2.859267, top_1: 0.522539, top_k: 0.758516, samples/s: 1748.790 1612862871.0185075
train: epoch 35, iter 3300, loss: 3.098222, top_1: 0.520000, top_k: 0.755195, samples/s: 1745.071 1612862885.6885457
train: epoch 35, iter 3400, loss: 3.012620, top_1: 0.517773, top_k: 0.752695, samples/s: 1749.067 1612862900.324691
train: epoch 35, iter 3500, loss: 2.953973, top_1: 0.518086, top_k: 0.753437, samples/s: 1748.500 1612862914.9658194
train: epoch 35, iter 3600, loss: 3.017068, top_1: 0.519102, top_k: 0.756602, samples/s: 1750.227 1612862929.5925317
train: epoch 35, iter 3700, loss: 2.965561, top_1: 0.517539, top_k: 0.754922, samples/s: 1746.379 1612862944.251464
train: epoch 35, iter 3800, loss: 2.978633, top_1: 0.523711, top_k: 0.754531, samples/s: 1748.130 1612862958.895669
train: epoch 35, iter 3900, loss: 3.041659, top_1: 0.521719, top_k: 0.758437, samples/s: 1743.162 1612862973.5816202
train: epoch 35, iter 4000, loss: 3.169927, top_1: 0.517734, top_k: 0.756758, samples/s: 1754.444 1612862988.1731179
train: epoch 35, iter 4100, loss: 2.967227, top_1: 0.515859, top_k: 0.753203, samples/s: 1748.325 1612863002.8156867
train: epoch 35, iter 4200, loss: 2.916865, top_1: 0.522461, top_k: 0.754102, samples/s: 1755.444 1612863017.3989422
train: epoch 35, iter 4300, loss: 3.004005, top_1: 0.517813, top_k: 0.754492, samples/s: 1746.176 1612863032.0595815
train: epoch 35, iter 4400, loss: 3.115129, top_1: 0.519297, top_k: 0.756992, samples/s: 1742.507 1612863046.7509882
train: epoch 35, iter 4500, loss: 2.779045, top_1: 0.519844, top_k: 0.756484, samples/s: 1745.354 1612863061.418768
train: epoch 35, iter 4600, loss: 3.144071, top_1: 0.519648, top_k: 0.756914, samples/s: 1753.674 1612863076.0164235
train: epoch 35, iter 4700, loss: 3.137127, top_1: 0.521445, top_k: 0.754648, samples/s: 1746.035 1612863090.6782277
train: epoch 35, iter 4800, loss: 3.292336, top_1: 0.516953, top_k: 0.752422, samples/s: 1757.087 1612863105.2481065
train: epoch 35, iter 4900, loss: 2.889587, top_1: 0.525234, top_k: 0.758047, samples/s: 1745.359 1612863119.915384
train: epoch 35, iter 5000, loss: 2.967605, top_1: 0.523594, top_k: 0.755977, samples/s: 1727.172 1612863134.7371752
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_35.
validation: epoch 35, iter 195, top_1: 0.558514, top_k: 0.804026, samples/s: 2924.160 1612863152.1021965
train: epoch 36, iter 100, loss: 2.866328, top_1: 0.532461, top_k: 0.770391, samples/s: 1750.991 1612863187.4828176
train: epoch 36, iter 200, loss: 2.894332, top_1: 0.527617, top_k: 0.767969, samples/s: 1762.193 1612863202.0101607
train: epoch 36, iter 300, loss: 3.178720, top_1: 0.533867, top_k: 0.770781, samples/s: 1757.397 1612863216.577164
train: epoch 36, iter 400, loss: 3.002133, top_1: 0.530742, top_k: 0.758633, samples/s: 1762.092 1612863231.1053622
train: epoch 36, iter 500, loss: 3.015065, top_1: 0.527891, top_k: 0.758203, samples/s: 1755.576 1612863245.6874616
train: epoch 36, iter 600, loss: 2.751810, top_1: 0.522734, top_k: 0.760938, samples/s: 1751.815 1612863260.3008666
train: epoch 36, iter 700, loss: 2.853650, top_1: 0.527305, top_k: 0.761563, samples/s: 1745.870 1612863274.9640553
train: epoch 36, iter 800, loss: 2.830802, top_1: 0.528125, top_k: 0.761836, samples/s: 1720.833 1612863289.8405724
train: epoch 36, iter 900, loss: 3.036026, top_1: 0.518945, top_k: 0.754922, samples/s: 1747.622 1612863304.4890535
train: epoch 36, iter 1000, loss: 3.059106, top_1: 0.526602, top_k: 0.761250, samples/s: 1723.115 1612863319.3458276
train: epoch 36, iter 1100, loss: 3.104454, top_1: 0.522617, top_k: 0.760156, samples/s: 1747.582 1612863333.9946191
train: epoch 36, iter 1200, loss: 2.960628, top_1: 0.521094, top_k: 0.756328, samples/s: 1737.961 1612863348.724592
train: epoch 36, iter 1300, loss: 2.982699, top_1: 0.528711, top_k: 0.762422, samples/s: 1734.353 1612863363.4850988
train: epoch 36, iter 1400, loss: 3.062329, top_1: 0.527031, top_k: 0.760625, samples/s: 1734.751 1612863378.242676
train: epoch 36, iter 1500, loss: 2.824945, top_1: 0.525430, top_k: 0.759141, samples/s: 1718.437 1612863393.1394901
train: epoch 36, iter 1600, loss: 2.991743, top_1: 0.525977, top_k: 0.758516, samples/s: 1740.913 1612863407.8444679
train: epoch 36, iter 1700, loss: 3.078542, top_1: 0.522109, top_k: 0.756016, samples/s: 1736.170 1612863422.5895145
train: epoch 36, iter 1800, loss: 2.765872, top_1: 0.526172, top_k: 0.759492, samples/s: 1737.353 1612863437.3246627
train: epoch 36, iter 1900, loss: 2.886792, top_1: 0.521797, top_k: 0.760039, samples/s: 1737.800 1612863452.056172
train: epoch 36, iter 2000, loss: 2.969153, top_1: 0.521797, top_k: 0.761992, samples/s: 1724.711 1612863466.8989599
train: epoch 36, iter 2100, loss: 2.940619, top_1: 0.516875, top_k: 0.758203, samples/s: 1746.508 1612863481.5568087
train: epoch 36, iter 2200, loss: 3.051968, top_1: 0.520469, top_k: 0.755625, samples/s: 1721.745 1612863496.425437
train: epoch 36, iter 2300, loss: 3.066769, top_1: 0.527852, top_k: 0.764180, samples/s: 1735.475 1612863511.1763852
train: epoch 36, iter 2400, loss: 2.957550, top_1: 0.519023, top_k: 0.757227, samples/s: 1736.267 1612863525.9206896
train: epoch 36, iter 2500, loss: 2.911052, top_1: 0.520312, top_k: 0.756563, samples/s: 1735.598 1612863540.6706681
train: epoch 36, iter 2600, loss: 2.897103, top_1: 0.514414, top_k: 0.757695, samples/s: 1726.311 1612863555.4999216
train: epoch 36, iter 2700, loss: 3.097166, top_1: 0.523750, top_k: 0.757500, samples/s: 1729.779 1612863570.2995272
train: epoch 36, iter 2800, loss: 3.105004, top_1: 0.517852, top_k: 0.751484, samples/s: 1736.191 1612863585.044475
train: epoch 36, iter 2900, loss: 2.936638, top_1: 0.522109, top_k: 0.757461, samples/s: 1719.828 1612863599.9297323
train: epoch 36, iter 3000, loss: 2.999320, top_1: 0.519414, top_k: 0.755117, samples/s: 1740.746 1612863614.6359806
train: epoch 36, iter 3100, loss: 3.013314, top_1: 0.519609, top_k: 0.755195, samples/s: 1740.490 1612863629.3445778
train: epoch 36, iter 3200, loss: 3.157879, top_1: 0.515664, top_k: 0.753125, samples/s: 1719.731 1612863644.2305763
train: epoch 36, iter 3300, loss: 3.108544, top_1: 0.519414, top_k: 0.755273, samples/s: 1734.246 1612863658.99199
train: epoch 36, iter 3400, loss: 3.100998, top_1: 0.524180, top_k: 0.757188, samples/s: 1745.310 1612863673.6598706
train: epoch 36, iter 3500, loss: 2.838879, top_1: 0.523398, top_k: 0.757500, samples/s: 1731.273 1612863688.4467323
train: epoch 36, iter 3600, loss: 2.952149, top_1: 0.521680, top_k: 0.756563, samples/s: 1732.934 1612863703.2193518
train: epoch 36, iter 3700, loss: 3.066177, top_1: 0.521484, top_k: 0.755938, samples/s: 1726.081 1612863718.050589
train: epoch 36, iter 3800, loss: 2.906539, top_1: 0.525625, top_k: 0.757461, samples/s: 1744.596 1612863732.7244818
train: epoch 36, iter 3900, loss: 3.073704, top_1: 0.517539, top_k: 0.755625, samples/s: 1741.544 1612863747.424063
train: epoch 36, iter 4000, loss: 3.063626, top_1: 0.523047, top_k: 0.756953, samples/s: 1718.963 1612863762.316761
train: epoch 36, iter 4100, loss: 3.058229, top_1: 0.520117, top_k: 0.754062, samples/s: 1735.257 1612863777.069781
train: epoch 36, iter 4200, loss: 3.160486, top_1: 0.522813, top_k: 0.756211, samples/s: 1746.497 1612863791.727555
train: epoch 36, iter 4300, loss: 3.129652, top_1: 0.517930, top_k: 0.749336, samples/s: 1743.312 1612863806.41227
train: epoch 36, iter 4400, loss: 2.927658, top_1: 0.519766, top_k: 0.754180, samples/s: 1723.812 1612863821.2631245
train: epoch 36, iter 4500, loss: 3.108958, top_1: 0.519844, top_k: 0.756953, samples/s: 1735.378 1612863836.0148544
train: epoch 36, iter 4600, loss: 2.943292, top_1: 0.518594, top_k: 0.751484, samples/s: 1741.621 1612863850.713806
train: epoch 36, iter 4700, loss: 2.942391, top_1: 0.520273, top_k: 0.757930, samples/s: 1726.463 1612863865.5418189
train: epoch 36, iter 4800, loss: 3.028951, top_1: 0.521836, top_k: 0.760742, samples/s: 1720.812 1612863880.4185998
train: epoch 36, iter 4900, loss: 2.994076, top_1: 0.525234, top_k: 0.759805, samples/s: 1726.363 1612863895.2473683
train: epoch 36, iter 5000, loss: 2.911986, top_1: 0.522188, top_k: 0.758945, samples/s: 1741.951 1612863909.9435961
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_36.
validation: epoch 36, iter 195, top_1: 0.569511, top_k: 0.812159, samples/s: 2871.605 1612863927.7525194
train: epoch 37, iter 100, loss: 3.076979, top_1: 0.531328, top_k: 0.763047, samples/s: 1749.763 1612863962.9586253
train: epoch 37, iter 200, loss: 3.118207, top_1: 0.527461, top_k: 0.764805, samples/s: 1752.162 1612863977.5692358
train: epoch 37, iter 300, loss: 3.073045, top_1: 0.530234, top_k: 0.761641, samples/s: 1761.246 1612863992.1043403
train: epoch 37, iter 400, loss: 3.041786, top_1: 0.529102, top_k: 0.762500, samples/s: 1754.877 1612864006.6923172
train: epoch 37, iter 500, loss: 3.049826, top_1: 0.530703, top_k: 0.765273, samples/s: 1746.219 1612864021.352504
train: epoch 37, iter 600, loss: 2.809489, top_1: 0.528555, top_k: 0.764023, samples/s: 1749.287 1612864035.9870443
train: epoch 37, iter 700, loss: 2.904205, top_1: 0.524062, top_k: 0.761836, samples/s: 1736.624 1612864050.7283044
train: epoch 37, iter 800, loss: 3.061140, top_1: 0.529687, top_k: 0.760195, samples/s: 1746.408 1612864065.386928
train: epoch 37, iter 900, loss: 2.889811, top_1: 0.530039, top_k: 0.760195, samples/s: 1742.382 1612864080.0794563
train: epoch 37, iter 1000, loss: 3.225062, top_1: 0.525859, top_k: 0.761992, samples/s: 1725.090 1612864094.9192092
train: epoch 37, iter 1100, loss: 2.894967, top_1: 0.523945, top_k: 0.758984, samples/s: 1728.017 1612864109.7339118
train: epoch 37, iter 1200, loss: 2.735911, top_1: 0.522031, top_k: 0.758672, samples/s: 1738.740 1612864124.4572554
train: epoch 37, iter 1300, loss: 3.002385, top_1: 0.530898, top_k: 0.766055, samples/s: 1731.470 1612864139.2423224
train: epoch 37, iter 1400, loss: 3.149916, top_1: 0.518984, top_k: 0.756094, samples/s: 1738.527 1612864153.9674098
train: epoch 37, iter 1500, loss: 3.300333, top_1: 0.526250, top_k: 0.758242, samples/s: 1715.669 1612864168.8887782
train: epoch 37, iter 1600, loss: 2.757183, top_1: 0.527617, top_k: 0.759648, samples/s: 1724.963 1612864183.729672
train: epoch 37, iter 1700, loss: 3.117775, top_1: 0.529062, top_k: 0.756523, samples/s: 1719.938 1612864198.6138983
train: epoch 37, iter 1800, loss: 2.954339, top_1: 0.522148, top_k: 0.758633, samples/s: 1738.622 1612864213.338246
train: epoch 37, iter 1900, loss: 3.110063, top_1: 0.525078, top_k: 0.759922, samples/s: 1737.411 1612864228.0727618
train: epoch 37, iter 2000, loss: 3.045470, top_1: 0.529727, top_k: 0.761055, samples/s: 1718.823 1612864242.9667125
train: epoch 37, iter 2100, loss: 2.970008, top_1: 0.524180, top_k: 0.760352, samples/s: 1730.858 1612864257.7570002
train: epoch 37, iter 2200, loss: 2.962510, top_1: 0.523008, top_k: 0.757461, samples/s: 1723.660 1612864272.6092093
train: epoch 37, iter 2300, loss: 3.177944, top_1: 0.521602, top_k: 0.756719, samples/s: 1741.123 1612864287.3123116
train: epoch 37, iter 2400, loss: 2.972378, top_1: 0.526211, top_k: 0.757500, samples/s: 1736.687 1612864302.0529783
train: epoch 37, iter 2500, loss: 3.240315, top_1: 0.521289, top_k: 0.756172, samples/s: 1728.430 1612864316.8641095
train: epoch 37, iter 2600, loss: 2.919942, top_1: 0.519687, top_k: 0.756289, samples/s: 1765.206 1612864331.3667336
train: epoch 37, iter 2700, loss: 2.933415, top_1: 0.523828, top_k: 0.759531, samples/s: 1745.328 1612864346.0343854
train: epoch 37, iter 2800, loss: 3.054053, top_1: 0.526055, top_k: 0.761406, samples/s: 1742.342 1612864360.7272763
train: epoch 37, iter 2900, loss: 2.913447, top_1: 0.519492, top_k: 0.757383, samples/s: 1727.802 1612864375.5438693
train: epoch 37, iter 3000, loss: 2.840604, top_1: 0.522148, top_k: 0.755664, samples/s: 1759.694 1612864390.0917642
train: epoch 37, iter 3100, loss: 3.026565, top_1: 0.523867, top_k: 0.755703, samples/s: 1750.047 1612864404.7199578
train: epoch 37, iter 3200, loss: 3.126749, top_1: 0.525156, top_k: 0.759648, samples/s: 1742.636 1612864419.4107149
train: epoch 37, iter 3300, loss: 2.997910, top_1: 0.520898, top_k: 0.759219, samples/s: 1748.655 1612864434.050251
train: epoch 37, iter 3400, loss: 3.013566, top_1: 0.518398, top_k: 0.760352, samples/s: 1751.048 1612864448.6700242
train: epoch 37, iter 3500, loss: 2.966641, top_1: 0.522930, top_k: 0.759961, samples/s: 1745.620 1612864463.3352482
train: epoch 37, iter 3600, loss: 2.985051, top_1: 0.518828, top_k: 0.753047, samples/s: 1752.191 1612864477.9455254
train: epoch 37, iter 3700, loss: 3.110361, top_1: 0.523789, top_k: 0.758906, samples/s: 1746.896 1612864492.600088
train: epoch 37, iter 3800, loss: 2.886132, top_1: 0.522500, top_k: 0.756875, samples/s: 1749.893 1612864507.229559
train: epoch 37, iter 3900, loss: 3.044175, top_1: 0.521016, top_k: 0.759336, samples/s: 1747.576 1612864521.878411
train: epoch 37, iter 4000, loss: 3.316141, top_1: 0.526602, top_k: 0.759414, samples/s: 1749.216 1612864536.513595
train: epoch 37, iter 4100, loss: 3.116075, top_1: 0.527031, top_k: 0.759922, samples/s: 1755.254 1612864551.0983906
train: epoch 37, iter 4200, loss: 2.867139, top_1: 0.518281, top_k: 0.756367, samples/s: 1748.283 1612864565.7412813
train: epoch 37, iter 4300, loss: 3.019644, top_1: 0.522969, top_k: 0.758281, samples/s: 1741.694 1612864580.439587
train: epoch 37, iter 4400, loss: 3.183106, top_1: 0.519766, top_k: 0.759453, samples/s: 1757.023 1612864595.0097392
train: epoch 37, iter 4500, loss: 2.984970, top_1: 0.519180, top_k: 0.756758, samples/s: 1753.202 1612864609.6116087
train: epoch 37, iter 4600, loss: 2.962667, top_1: 0.518047, top_k: 0.758594, samples/s: 1744.410 1612864624.287068
train: epoch 37, iter 4700, loss: 3.161977, top_1: 0.525508, top_k: 0.760039, samples/s: 1734.105 1612864639.0501394
train: epoch 37, iter 4800, loss: 3.100089, top_1: 0.522852, top_k: 0.762109, samples/s: 1746.661 1612864653.7062275
train: epoch 37, iter 4900, loss: 2.871911, top_1: 0.524336, top_k: 0.761797, samples/s: 1753.437 1612864668.306123
train: epoch 37, iter 5000, loss: 3.018062, top_1: 0.524805, top_k: 0.758164, samples/s: 1734.551 1612864683.0649967
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_37.
validation: epoch 37, iter 195, top_1: 0.563522, top_k: 0.809655, samples/s: 2852.241 1612864701.0191607
train: epoch 38, iter 100, loss: 2.839566, top_1: 0.532109, top_k: 0.769531, samples/s: 1756.052 1612864736.2900383
train: epoch 38, iter 200, loss: 2.879767, top_1: 0.531289, top_k: 0.767617, samples/s: 1748.189 1612864750.9338818
train: epoch 38, iter 300, loss: 3.090791, top_1: 0.530391, top_k: 0.763203, samples/s: 1764.682 1612864765.4405243
train: epoch 38, iter 400, loss: 3.069433, top_1: 0.531563, top_k: 0.764805, samples/s: 1762.484 1612864779.965444
train: epoch 38, iter 500, loss: 3.024116, top_1: 0.524609, top_k: 0.764336, samples/s: 1756.972 1612864794.5360293
train: epoch 38, iter 600, loss: 3.081629, top_1: 0.521914, top_k: 0.757383, samples/s: 1754.191 1612864809.1295862
train: epoch 38, iter 700, loss: 2.967285, top_1: 0.527813, top_k: 0.759648, samples/s: 1738.148 1612864823.8579562
train: epoch 38, iter 800, loss: 3.050375, top_1: 0.528789, top_k: 0.762070, samples/s: 1721.848 1612864838.7257817
train: epoch 38, iter 900, loss: 2.885581, top_1: 0.528555, top_k: 0.763125, samples/s: 1744.042 1612864853.4042242
train: epoch 38, iter 1000, loss: 3.173789, top_1: 0.524336, top_k: 0.759180, samples/s: 1738.744 1612864868.1275446
train: epoch 38, iter 1100, loss: 2.759167, top_1: 0.522500, top_k: 0.759687, samples/s: 1733.389 1612864882.8962898
train: epoch 38, iter 1200, loss: 3.001156, top_1: 0.526445, top_k: 0.764102, samples/s: 1738.517 1612864897.6214561
train: epoch 38, iter 1300, loss: 3.165189, top_1: 0.519414, top_k: 0.759961, samples/s: 1734.359 1612864912.3819773
train: epoch 38, iter 1400, loss: 2.952948, top_1: 0.526445, top_k: 0.758984, samples/s: 1735.626 1612864927.131721
train: epoch 38, iter 1500, loss: 2.769340, top_1: 0.531211, top_k: 0.764648, samples/s: 1727.748 1612864941.9487114
train: epoch 38, iter 1600, loss: 2.886611, top_1: 0.528555, top_k: 0.764609, samples/s: 1746.338 1612864956.6078737
train: epoch 38, iter 1700, loss: 2.926812, top_1: 0.524883, top_k: 0.763086, samples/s: 1735.631 1612864971.3575985
train: epoch 38, iter 1800, loss: 3.065804, top_1: 0.524922, top_k: 0.759102, samples/s: 1730.393 1612864986.1518722
train: epoch 38, iter 1900, loss: 2.938785, top_1: 0.526836, top_k: 0.760625, samples/s: 1733.364 1612865000.9209204
train: epoch 38, iter 2000, loss: 2.966485, top_1: 0.525469, top_k: 0.762656, samples/s: 1729.143 1612865015.725926
train: epoch 38, iter 2100, loss: 2.939428, top_1: 0.526406, top_k: 0.756367, samples/s: 1728.992 1612865030.5323277
train: epoch 38, iter 2200, loss: 3.226203, top_1: 0.526836, top_k: 0.759492, samples/s: 1739.759 1612865045.246994
train: epoch 38, iter 2300, loss: 3.003214, top_1: 0.523281, top_k: 0.766641, samples/s: 1735.363 1612865059.9988341
train: epoch 38, iter 2400, loss: 2.862365, top_1: 0.520039, top_k: 0.756719, samples/s: 1737.116 1612865074.7359467
train: epoch 38, iter 2500, loss: 3.066174, top_1: 0.523438, top_k: 0.753867, samples/s: 1720.783 1612865089.6129115
train: epoch 38, iter 2600, loss: 2.873266, top_1: 0.519102, top_k: 0.756133, samples/s: 1739.961 1612865104.325887
train: epoch 38, iter 2700, loss: 2.935663, top_1: 0.523945, top_k: 0.755586, samples/s: 1727.679 1612865119.143442
train: epoch 38, iter 2800, loss: 2.990797, top_1: 0.524922, top_k: 0.760273, samples/s: 1732.409 1612865133.9205558
train: epoch 38, iter 2900, loss: 2.841969, top_1: 0.521836, top_k: 0.760898, samples/s: 1726.574 1612865148.7475438
train: epoch 38, iter 3000, loss: 2.958488, top_1: 0.521055, top_k: 0.757070, samples/s: 1732.205 1612865163.5263953
train: epoch 38, iter 3100, loss: 2.895846, top_1: 0.524727, top_k: 0.759961, samples/s: 1736.560 1612865178.2682455
train: epoch 38, iter 3200, loss: 2.958872, top_1: 0.521289, top_k: 0.758437, samples/s: 1723.509 1612865193.1216686
train: epoch 38, iter 3300, loss: 3.022244, top_1: 0.522773, top_k: 0.759297, samples/s: 1734.323 1612865207.8824954
train: epoch 38, iter 3400, loss: 3.058413, top_1: 0.526172, top_k: 0.763164, samples/s: 1736.517 1612865222.6245654
train: epoch 38, iter 3500, loss: 3.093950, top_1: 0.526328, top_k: 0.756250, samples/s: 1732.666 1612865237.3994732
train: epoch 38, iter 3600, loss: 3.060473, top_1: 0.520938, top_k: 0.756953, samples/s: 1732.855 1612865252.1728172
train: epoch 38, iter 3700, loss: 2.899311, top_1: 0.522969, top_k: 0.760859, samples/s: 1733.179 1612865266.943331
train: epoch 38, iter 3800, loss: 2.894418, top_1: 0.525508, top_k: 0.758203, samples/s: 1712.596 1612865281.8915238
train: epoch 38, iter 3900, loss: 2.818480, top_1: 0.518437, top_k: 0.756016, samples/s: 1732.908 1612865296.6643329
train: epoch 38, iter 4000, loss: 3.140094, top_1: 0.529531, top_k: 0.763359, samples/s: 1737.644 1612865311.3968527
train: epoch 38, iter 4100, loss: 3.208292, top_1: 0.526016, top_k: 0.759805, samples/s: 1734.406 1612865326.1569755
train: epoch 38, iter 4200, loss: 3.064488, top_1: 0.523672, top_k: 0.751367, samples/s: 1727.787 1612865340.9736521
train: epoch 38, iter 4300, loss: 3.008598, top_1: 0.526172, top_k: 0.760469, samples/s: 1733.342 1612865355.7427454
train: epoch 38, iter 4400, loss: 3.039633, top_1: 0.523750, top_k: 0.760703, samples/s: 1724.491 1612865370.5877206
train: epoch 38, iter 4500, loss: 2.926350, top_1: 0.519258, top_k: 0.756523, samples/s: 1732.114 1612865385.3673801
train: epoch 38, iter 4600, loss: 2.984812, top_1: 0.518828, top_k: 0.750820, samples/s: 1738.496 1612865400.0927682
train: epoch 38, iter 4700, loss: 2.980594, top_1: 0.524609, top_k: 0.753945, samples/s: 1730.238 1612865414.888364
train: epoch 38, iter 4800, loss: 3.005614, top_1: 0.526055, top_k: 0.757969, samples/s: 1737.489 1612865429.622265
train: epoch 38, iter 4900, loss: 3.035989, top_1: 0.522148, top_k: 0.756680, samples/s: 1721.831 1612865444.4902914
train: epoch 38, iter 5000, loss: 2.915534, top_1: 0.529961, top_k: 0.761250, samples/s: 1750.081 1612865459.1181188
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_38.
validation: epoch 38, iter 195, top_1: 0.573898, top_k: 0.816426, samples/s: 2914.050 1612865476.6826985
train: epoch 39, iter 100, loss: 3.134345, top_1: 0.537695, top_k: 0.769922, samples/s: 1755.655 1612865511.5745993
train: epoch 39, iter 200, loss: 3.105535, top_1: 0.538828, top_k: 0.768242, samples/s: 1755.670 1612865526.1559763
train: epoch 39, iter 300, loss: 3.010419, top_1: 0.527734, top_k: 0.761836, samples/s: 1765.155 1612865540.6587076
train: epoch 39, iter 400, loss: 2.827870, top_1: 0.541250, top_k: 0.766172, samples/s: 1749.433 1612865555.2921124
train: epoch 39, iter 500, loss: 2.915071, top_1: 0.535625, top_k: 0.770273, samples/s: 1767.720 1612865569.774033
train: epoch 39, iter 600, loss: 2.984357, top_1: 0.530156, top_k: 0.766211, samples/s: 1752.748 1612865584.379583
train: epoch 39, iter 700, loss: 2.995223, top_1: 0.530625, top_k: 0.771055, samples/s: 1730.962 1612865599.169145
train: epoch 39, iter 800, loss: 2.903604, top_1: 0.530430, top_k: 0.762422, samples/s: 1731.641 1612865613.9527268
train: epoch 39, iter 900, loss: 2.904870, top_1: 0.524258, top_k: 0.759219, samples/s: 1726.684 1612865628.7788322
train: epoch 39, iter 1000, loss: 2.983328, top_1: 0.529219, top_k: 0.766172, samples/s: 1740.885 1612865643.484039
train: epoch 39, iter 1100, loss: 3.088397, top_1: 0.531055, top_k: 0.764883, samples/s: 1721.284 1612865658.3567243
train: epoch 39, iter 1200, loss: 2.977119, top_1: 0.524766, top_k: 0.758555, samples/s: 1741.331 1612865673.0580006
train: epoch 39, iter 1300, loss: 3.139380, top_1: 0.528125, top_k: 0.760898, samples/s: 1730.484 1612865687.8515654
train: epoch 39, iter 1400, loss: 2.948615, top_1: 0.531523, top_k: 0.757461, samples/s: 1734.992 1612865702.6066763
train: epoch 39, iter 1500, loss: 3.171564, top_1: 0.529844, top_k: 0.761406, samples/s: 1729.433 1612865717.4092422
train: epoch 39, iter 1600, loss: 3.145926, top_1: 0.529141, top_k: 0.761758, samples/s: 1729.761 1612865732.209009
train: epoch 39, iter 1700, loss: 3.060493, top_1: 0.523828, top_k: 0.758203, samples/s: 1719.166 1612865747.0999045
train: epoch 39, iter 1800, loss: 3.052979, top_1: 0.526328, top_k: 0.763281, samples/s: 1731.801 1612865761.882202
train: epoch 39, iter 1900, loss: 3.020545, top_1: 0.527227, top_k: 0.759570, samples/s: 1736.175 1612865776.6273174
train: epoch 39, iter 2000, loss: 2.988719, top_1: 0.524648, top_k: 0.758516, samples/s: 1717.936 1612865791.5289643
train: epoch 39, iter 2100, loss: 3.242024, top_1: 0.521797, top_k: 0.756953, samples/s: 1738.078 1612865806.2577882
train: epoch 39, iter 2200, loss: 2.946485, top_1: 0.524531, top_k: 0.759805, samples/s: 1721.894 1612865821.1252367
train: epoch 39, iter 2300, loss: 3.024888, top_1: 0.520430, top_k: 0.754609, samples/s: 1729.042 1612865835.931059
train: epoch 39, iter 2400, loss: 2.783214, top_1: 0.524648, top_k: 0.757109, samples/s: 1726.051 1612865850.7626057
train: epoch 39, iter 2500, loss: 3.087157, top_1: 0.529102, top_k: 0.760625, samples/s: 1737.002 1612865865.5006418
train: epoch 39, iter 2600, loss: 2.994710, top_1: 0.526797, top_k: 0.763086, samples/s: 1741.923 1612865880.1970494
train: epoch 39, iter 2700, loss: 2.983613, top_1: 0.525508, top_k: 0.762031, samples/s: 1731.748 1612865894.9797897
train: epoch 39, iter 2800, loss: 2.910080, top_1: 0.525352, top_k: 0.762031, samples/s: 1733.619 1612865909.7466197
train: epoch 39, iter 2900, loss: 2.964975, top_1: 0.522500, top_k: 0.759883, samples/s: 1742.184 1612865924.4407952
train: epoch 39, iter 3000, loss: 2.999623, top_1: 0.523555, top_k: 0.762305, samples/s: 1725.819 1612865939.2743404
train: epoch 39, iter 3100, loss: 2.979356, top_1: 0.530352, top_k: 0.763984, samples/s: 1723.630 1612865954.1266537
train: epoch 39, iter 3200, loss: 3.197032, top_1: 0.520938, top_k: 0.756523, samples/s: 1732.144 1612865968.9063063
train: epoch 39, iter 3300, loss: 2.946739, top_1: 0.524844, top_k: 0.760664, samples/s: 1745.605 1612865983.5714958
train: epoch 39, iter 3400, loss: 2.895226, top_1: 0.523203, top_k: 0.761211, samples/s: 1734.515 1612865998.331046
train: epoch 39, iter 3500, loss: 3.082655, top_1: 0.529375, top_k: 0.761328, samples/s: 1732.678 1612866013.105478
train: epoch 39, iter 3600, loss: 3.067689, top_1: 0.527031, top_k: 0.763984, samples/s: 1724.576 1612866027.949748
train: epoch 39, iter 3700, loss: 2.808886, top_1: 0.527422, top_k: 0.761797, samples/s: 1736.594 1612866042.6911404
train: epoch 39, iter 3800, loss: 2.947931, top_1: 0.530391, top_k: 0.763047, samples/s: 1734.931 1612866057.4467726
train: epoch 39, iter 3900, loss: 2.880248, top_1: 0.524961, top_k: 0.760977, samples/s: 1730.162 1612866072.2433574
train: epoch 39, iter 4000, loss: 3.210750, top_1: 0.521484, top_k: 0.756523, samples/s: 1745.023 1612866086.9133856
train: epoch 39, iter 4100, loss: 2.987701, top_1: 0.522578, top_k: 0.760312, samples/s: 1724.307 1612866101.7599607
train: epoch 39, iter 4200, loss: 2.906717, top_1: 0.520703, top_k: 0.759648, samples/s: 1735.668 1612866116.5092862
train: epoch 39, iter 4300, loss: 2.981507, top_1: 0.526836, top_k: 0.759023, samples/s: 1736.892 1612866131.2482417
train: epoch 39, iter 4400, loss: 3.139802, top_1: 0.519414, top_k: 0.755000, samples/s: 1729.526 1612866146.04999
train: epoch 39, iter 4500, loss: 3.112521, top_1: 0.521133, top_k: 0.759922, samples/s: 1728.855 1612866160.8574824
train: epoch 39, iter 4600, loss: 2.926127, top_1: 0.524687, top_k: 0.759062, samples/s: 1735.100 1612866175.6117039
train: epoch 39, iter 4700, loss: 3.199450, top_1: 0.525977, top_k: 0.759297, samples/s: 1739.614 1612866190.3276925
train: epoch 39, iter 4800, loss: 3.022024, top_1: 0.528789, top_k: 0.765547, samples/s: 1727.001 1612866205.1510272
train: epoch 39, iter 4900, loss: 2.960340, top_1: 0.530586, top_k: 0.760781, samples/s: 1741.946 1612866219.8472223
train: epoch 39, iter 5000, loss: 2.965627, top_1: 0.525547, top_k: 0.760039, samples/s: 1735.344 1612866234.5993774
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_39.
validation: epoch 39, iter 195, top_1: 0.572175, top_k: 0.812420, samples/s: 2931.819 1612866252.0987728
train: epoch 40, iter 100, loss: 2.896096, top_1: 0.531797, top_k: 0.767969, samples/s: 1748.139 1612866287.1149905
train: epoch 40, iter 200, loss: 2.812145, top_1: 0.532266, top_k: 0.759609, samples/s: 1757.877 1612866301.6782255
train: epoch 40, iter 300, loss: 2.844181, top_1: 0.534297, top_k: 0.767422, samples/s: 1743.513 1612866316.3609254
train: epoch 40, iter 400, loss: 2.941267, top_1: 0.532969, top_k: 0.768477, samples/s: 1768.645 1612866330.8352745
train: epoch 40, iter 500, loss: 3.024026, top_1: 0.529258, top_k: 0.763711, samples/s: 1757.358 1612866345.402689
train: epoch 40, iter 600, loss: 2.836182, top_1: 0.532773, top_k: 0.763125, samples/s: 1745.308 1612866360.0705023
train: epoch 40, iter 700, loss: 2.945539, top_1: 0.531445, top_k: 0.766016, samples/s: 1745.991 1612866374.7327085
train: epoch 40, iter 800, loss: 2.908171, top_1: 0.531445, top_k: 0.761641, samples/s: 1734.295 1612866389.493749
train: epoch 40, iter 900, loss: 2.793113, top_1: 0.532930, top_k: 0.762734, samples/s: 1719.129 1612866404.384946
train: epoch 40, iter 1000, loss: 2.915513, top_1: 0.530273, top_k: 0.763437, samples/s: 1720.545 1612866419.2640114
train: epoch 40, iter 1100, loss: 2.977042, top_1: 0.532969, top_k: 0.760625, samples/s: 1721.223 1612866434.1372063
train: epoch 40, iter 1200, loss: 3.010651, top_1: 0.526484, top_k: 0.764648, samples/s: 1754.458 1612866448.728855
train: epoch 40, iter 1300, loss: 2.851564, top_1: 0.528516, top_k: 0.762500, samples/s: 1725.833 1612866463.561923
train: epoch 40, iter 1400, loss: 3.001176, top_1: 0.530664, top_k: 0.761563, samples/s: 1748.799 1612866478.2005363
train: epoch 40, iter 1500, loss: 2.952003, top_1: 0.527852, top_k: 0.761133, samples/s: 1740.582 1612866492.9083111
train: epoch 40, iter 1600, loss: 2.824275, top_1: 0.526680, top_k: 0.762383, samples/s: 1732.743 1612866507.6826138
train: epoch 40, iter 1700, loss: 2.877452, top_1: 0.530820, top_k: 0.764297, samples/s: 1752.573 1612866522.290183
train: epoch 40, iter 1800, loss: 3.198676, top_1: 0.534180, top_k: 0.763867, samples/s: 1746.625 1612866536.9464912
train: epoch 40, iter 1900, loss: 2.831223, top_1: 0.533008, top_k: 0.763789, samples/s: 1746.629 1612866551.603263
train: epoch 40, iter 2000, loss: 3.056348, top_1: 0.532031, top_k: 0.763750, samples/s: 1750.001 1612866566.2318988
train: epoch 40, iter 2100, loss: 3.308787, top_1: 0.524687, top_k: 0.759102, samples/s: 1750.139 1612866580.8592763
train: epoch 40, iter 2200, loss: 2.970084, top_1: 0.521758, top_k: 0.757617, samples/s: 1742.395 1612866595.5517392
train: epoch 40, iter 2300, loss: 2.795450, top_1: 0.525898, top_k: 0.761563, samples/s: 1746.059 1612866610.2134175
train: epoch 40, iter 2400, loss: 2.933545, top_1: 0.531211, top_k: 0.765547, samples/s: 1753.657 1612866624.8113327
train: epoch 40, iter 2500, loss: 2.919855, top_1: 0.532695, top_k: 0.763320, samples/s: 1736.038 1612866639.5575662
train: epoch 40, iter 2600, loss: 3.147264, top_1: 0.529961, top_k: 0.762578, samples/s: 1764.795 1612866654.0635605
train: epoch 40, iter 2700, loss: 3.044974, top_1: 0.530000, top_k: 0.764883, samples/s: 1742.983 1612866668.7509418
train: epoch 40, iter 2800, loss: 2.897118, top_1: 0.526953, top_k: 0.761445, samples/s: 1753.516 1612866683.3501718
train: epoch 40, iter 2900, loss: 2.807304, top_1: 0.529375, top_k: 0.767070, samples/s: 1744.413 1612866698.0256972
train: epoch 40, iter 3000, loss: 2.852672, top_1: 0.523398, top_k: 0.756055, samples/s: 1748.675 1612866712.6652546
train: epoch 40, iter 3100, loss: 2.998134, top_1: 0.529336, top_k: 0.763594, samples/s: 1746.097 1612866727.326571
train: epoch 40, iter 3200, loss: 2.913574, top_1: 0.529727, top_k: 0.762891, samples/s: 1749.466 1612866741.9596643
train: epoch 40, iter 3300, loss: 2.881361, top_1: 0.531680, top_k: 0.762852, samples/s: 1733.967 1612866756.7233858
train: epoch 40, iter 3400, loss: 2.800631, top_1: 0.534258, top_k: 0.768164, samples/s: 1743.803 1612866771.4039807
train: epoch 40, iter 3500, loss: 2.909316, top_1: 0.525820, top_k: 0.757422, samples/s: 1745.719 1612866786.0684104
train: epoch 40, iter 3600, loss: 3.057985, top_1: 0.523945, top_k: 0.757930, samples/s: 1747.612 1612866800.7170064
train: epoch 40, iter 3700, loss: 2.872171, top_1: 0.524922, top_k: 0.763164, samples/s: 1744.979 1612866815.387715
train: epoch 40, iter 3800, loss: 3.083570, top_1: 0.526406, top_k: 0.760352, samples/s: 1743.966 1612866830.066781
train: epoch 40, iter 3900, loss: 3.087021, top_1: 0.525781, top_k: 0.759102, samples/s: 1753.887 1612866844.662966
train: epoch 40, iter 4000, loss: 2.799016, top_1: 0.524102, top_k: 0.755313, samples/s: 1747.822 1612866859.3098502
train: epoch 40, iter 4100, loss: 3.091220, top_1: 0.529570, top_k: 0.760469, samples/s: 1756.141 1612866873.8872235
train: epoch 40, iter 4200, loss: 3.081390, top_1: 0.522813, top_k: 0.760078, samples/s: 1747.942 1612866888.5329907
train: epoch 40, iter 4300, loss: 2.985909, top_1: 0.523711, top_k: 0.757188, samples/s: 1737.985 1612866903.2627618
train: epoch 40, iter 4400, loss: 3.005903, top_1: 0.519023, top_k: 0.761563, samples/s: 1753.547 1612866917.8616486
train: epoch 40, iter 4500, loss: 2.881734, top_1: 0.531172, top_k: 0.766133, samples/s: 1756.338 1612866932.4374726
train: epoch 40, iter 4600, loss: 3.041811, top_1: 0.529687, top_k: 0.761328, samples/s: 1756.141 1612866947.0148823
train: epoch 40, iter 4700, loss: 2.860633, top_1: 0.531016, top_k: 0.761484, samples/s: 1740.924 1612866961.7196653
train: epoch 40, iter 4800, loss: 2.980500, top_1: 0.526289, top_k: 0.764414, samples/s: 1750.820 1612866976.3415039
train: epoch 40, iter 4900, loss: 3.050750, top_1: 0.530742, top_k: 0.764648, samples/s: 1746.800 1612866990.9967782
train: epoch 40, iter 5000, loss: 2.804974, top_1: 0.531602, top_k: 0.762656, samples/s: 1755.723 1612867005.5777173
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_40.
validation: epoch 40, iter 195, top_1: 0.577163, top_k: 0.814824, samples/s: 2795.939 1612867023.9284952
train: epoch 41, iter 100, loss: 2.907455, top_1: 0.532891, top_k: 0.767383, samples/s: 1752.707 1612867058.8280597
train: epoch 41, iter 200, loss: 2.741385, top_1: 0.534648, top_k: 0.767148, samples/s: 1755.473 1612867073.4110415
train: epoch 41, iter 300, loss: 2.951552, top_1: 0.536055, top_k: 0.767930, samples/s: 1763.532 1612867087.9275692
train: epoch 41, iter 400, loss: 3.014472, top_1: 0.533125, top_k: 0.765391, samples/s: 1759.329 1612867102.4782774
train: epoch 41, iter 500, loss: 3.041825, top_1: 0.533164, top_k: 0.763711, samples/s: 1763.863 1612867116.991928
train: epoch 41, iter 600, loss: 3.054920, top_1: 0.533086, top_k: 0.766055, samples/s: 1757.454 1612867131.5584316
train: epoch 41, iter 700, loss: 2.974965, top_1: 0.525781, top_k: 0.767656, samples/s: 1745.872 1612867146.2216063
train: epoch 41, iter 800, loss: 2.972227, top_1: 0.530195, top_k: 0.764961, samples/s: 1733.678 1612867160.9879565
train: epoch 41, iter 900, loss: 2.688508, top_1: 0.534453, top_k: 0.766719, samples/s: 1742.688 1612867175.677883
train: epoch 41, iter 1000, loss: 2.912347, top_1: 0.531172, top_k: 0.764375, samples/s: 1753.317 1612867190.2787216
train: epoch 41, iter 1100, loss: 2.818002, top_1: 0.533516, top_k: 0.766602, samples/s: 1722.278 1612867205.1427543
train: epoch 41, iter 1200, loss: 2.952499, top_1: 0.536211, top_k: 0.772305, samples/s: 1749.749 1612867219.7735088
train: epoch 41, iter 1300, loss: 2.849881, top_1: 0.526211, top_k: 0.760273, samples/s: 1726.984 1612867234.5969787
train: epoch 41, iter 1400, loss: 2.970961, top_1: 0.529922, top_k: 0.763242, samples/s: 1725.937 1612867249.429491
train: epoch 41, iter 1500, loss: 3.050272, top_1: 0.533711, top_k: 0.761602, samples/s: 1736.112 1612867264.1750817
train: epoch 41, iter 1600, loss: 2.835823, top_1: 0.526563, top_k: 0.757930, samples/s: 1727.821 1612867278.9915442
train: epoch 41, iter 1700, loss: 2.758419, top_1: 0.527578, top_k: 0.760742, samples/s: 1741.705 1612867293.6896932
train: epoch 41, iter 1800, loss: 2.873546, top_1: 0.536445, top_k: 0.766680, samples/s: 1732.192 1612867308.4686816
train: epoch 41, iter 1900, loss: 2.947145, top_1: 0.530391, top_k: 0.763047, samples/s: 1740.887 1612867323.173755
train: epoch 41, iter 2000, loss: 2.984778, top_1: 0.529844, top_k: 0.763516, samples/s: 1742.242 1612867337.8675258
train: epoch 41, iter 2100, loss: 2.981445, top_1: 0.525898, top_k: 0.758555, samples/s: 1729.959 1612867352.6654904
train: epoch 41, iter 2200, loss: 3.022750, top_1: 0.522422, top_k: 0.757539, samples/s: 1729.201 1612867367.4700165
train: epoch 41, iter 2300, loss: 2.773500, top_1: 0.534453, top_k: 0.763984, samples/s: 1744.284 1612867382.1465318
train: epoch 41, iter 2400, loss: 2.826434, top_1: 0.525547, top_k: 0.760703, samples/s: 1718.792 1612867397.04073
train: epoch 41, iter 2500, loss: 3.012113, top_1: 0.526914, top_k: 0.763750, samples/s: 1739.830 1612867411.75478
train: epoch 41, iter 2600, loss: 2.966952, top_1: 0.529297, top_k: 0.759531, samples/s: 1719.566 1612867426.6423643
train: epoch 41, iter 2700, loss: 3.137584, top_1: 0.525781, top_k: 0.760273, samples/s: 1723.642 1612867441.494532
train: epoch 41, iter 2800, loss: 2.799405, top_1: 0.529102, top_k: 0.760781, samples/s: 1737.144 1612867456.231423
train: epoch 41, iter 2900, loss: 2.948708, top_1: 0.528789, top_k: 0.765039, samples/s: 1739.248 1612867470.950427
train: epoch 41, iter 3000, loss: 3.131607, top_1: 0.532031, top_k: 0.763555, samples/s: 1735.116 1612867485.7044353
train: epoch 41, iter 3100, loss: 2.967975, top_1: 0.528398, top_k: 0.762578, samples/s: 1731.996 1612867500.485078
train: epoch 41, iter 3200, loss: 2.898879, top_1: 0.522148, top_k: 0.756563, samples/s: 1728.708 1612867515.2938125
train: epoch 41, iter 3300, loss: 2.951152, top_1: 0.531289, top_k: 0.765820, samples/s: 1734.730 1612867530.0511403
train: epoch 41, iter 3400, loss: 3.011688, top_1: 0.526367, top_k: 0.760977, samples/s: 1730.344 1612867544.845925
train: epoch 41, iter 3500, loss: 3.016083, top_1: 0.528672, top_k: 0.763867, samples/s: 1744.754 1612867559.5184557
train: epoch 41, iter 3600, loss: 3.058382, top_1: 0.526680, top_k: 0.762773, samples/s: 1735.683 1612867574.2677026
train: epoch 41, iter 3700, loss: 2.960000, top_1: 0.521602, top_k: 0.761094, samples/s: 1731.689 1612867589.0510569
train: epoch 41, iter 3800, loss: 2.793054, top_1: 0.526797, top_k: 0.762930, samples/s: 1736.301 1612867603.7949908
train: epoch 41, iter 3900, loss: 3.064964, top_1: 0.526094, top_k: 0.760742, samples/s: 1734.574 1612867618.5536416
train: epoch 41, iter 4000, loss: 2.921379, top_1: 0.525625, top_k: 0.760039, samples/s: 1732.088 1612867633.333494
train: epoch 41, iter 4100, loss: 2.964347, top_1: 0.523789, top_k: 0.761602, samples/s: 1728.786 1612867648.1415577
train: epoch 41, iter 4200, loss: 2.857586, top_1: 0.527344, top_k: 0.765820, samples/s: 1722.101 1612867663.0073028
train: epoch 41, iter 4300, loss: 2.936182, top_1: 0.533984, top_k: 0.767813, samples/s: 1727.475 1612867677.826473
train: epoch 41, iter 4400, loss: 2.878960, top_1: 0.531992, top_k: 0.766992, samples/s: 1736.598 1612867692.5679471
train: epoch 41, iter 4500, loss: 3.046594, top_1: 0.530586, top_k: 0.763672, samples/s: 1721.264 1612867707.4407427
train: epoch 41, iter 4600, loss: 2.880714, top_1: 0.527031, top_k: 0.763203, samples/s: 1731.542 1612867722.225233
train: epoch 41, iter 4700, loss: 3.035989, top_1: 0.522930, top_k: 0.758750, samples/s: 1741.967 1612867736.9212568
train: epoch 41, iter 4800, loss: 3.135404, top_1: 0.526328, top_k: 0.759648, samples/s: 1726.572 1612867751.7482865
train: epoch 41, iter 4900, loss: 2.991632, top_1: 0.528125, top_k: 0.760117, samples/s: 1729.507 1612867766.550188
train: epoch 41, iter 5000, loss: 3.097008, top_1: 0.528164, top_k: 0.759297, samples/s: 1725.447 1612867781.3869827
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_41.
validation: epoch 41, iter 195, top_1: 0.575641, top_k: 0.815525, samples/s: 2794.387 1612867799.6551907
train: epoch 42, iter 100, loss: 2.969474, top_1: 0.535781, top_k: 0.766914, samples/s: 1757.165 1612867834.5377333
train: epoch 42, iter 200, loss: 2.897510, top_1: 0.539141, top_k: 0.772422, samples/s: 1761.953 1612867849.0666947
train: epoch 42, iter 300, loss: 2.992192, top_1: 0.533047, top_k: 0.769883, samples/s: 1757.530 1612867863.6326218
train: epoch 42, iter 400, loss: 2.779459, top_1: 0.535508, top_k: 0.766719, samples/s: 1759.779 1612867878.1799092
train: epoch 42, iter 500, loss: 3.111280, top_1: 0.528516, top_k: 0.764570, samples/s: 1749.217 1612867892.8150237
train: epoch 42, iter 600, loss: 2.990953, top_1: 0.537031, top_k: 0.767031, samples/s: 1759.609 1612867907.3636887
train: epoch 42, iter 700, loss: 2.711919, top_1: 0.537695, top_k: 0.770234, samples/s: 1745.724 1612867922.0281248
train: epoch 42, iter 800, loss: 3.139733, top_1: 0.532344, top_k: 0.768398, samples/s: 1741.894 1612867936.72501
train: epoch 42, iter 900, loss: 2.836498, top_1: 0.533633, top_k: 0.764258, samples/s: 1729.719 1612867951.524881
train: epoch 42, iter 1000, loss: 2.933403, top_1: 0.534023, top_k: 0.765742, samples/s: 1733.191 1612867966.2954044
train: epoch 42, iter 1100, loss: 3.051166, top_1: 0.531133, top_k: 0.769141, samples/s: 1742.998 1612867980.9826505
train: epoch 42, iter 1200, loss: 3.076365, top_1: 0.537070, top_k: 0.762266, samples/s: 1736.241 1612867995.7271872
train: epoch 42, iter 1300, loss: 2.776371, top_1: 0.530859, top_k: 0.761680, samples/s: 1731.994 1612868010.5077987
train: epoch 42, iter 1400, loss: 2.828460, top_1: 0.528633, top_k: 0.763477, samples/s: 1743.696 1612868025.1892257
train: epoch 42, iter 1500, loss: 2.784183, top_1: 0.530078, top_k: 0.765117, samples/s: 1726.525 1612868040.0167031
train: epoch 42, iter 1600, loss: 2.742678, top_1: 0.529102, top_k: 0.764336, samples/s: 1733.931 1612868054.7808926
train: epoch 42, iter 1700, loss: 2.881094, top_1: 0.527695, top_k: 0.768164, samples/s: 1727.474 1612868069.6002223
train: epoch 42, iter 1800, loss: 2.854357, top_1: 0.530117, top_k: 0.762813, samples/s: 1745.661 1612868084.2650657
train: epoch 42, iter 1900, loss: 2.915196, top_1: 0.529336, top_k: 0.759023, samples/s: 1741.139 1612868098.9681036
train: epoch 42, iter 2000, loss: 3.051289, top_1: 0.529336, top_k: 0.765156, samples/s: 1732.844 1612868113.7415533
train: epoch 42, iter 2100, loss: 2.972867, top_1: 0.528711, top_k: 0.763594, samples/s: 1721.656 1612868128.6110115
train: epoch 42, iter 2200, loss: 3.122481, top_1: 0.528008, top_k: 0.761016, samples/s: 1735.745 1612868143.3597264
train: epoch 42, iter 2300, loss: 2.857197, top_1: 0.529492, top_k: 0.763594, samples/s: 1738.267 1612868158.0869396
train: epoch 42, iter 2400, loss: 2.821992, top_1: 0.529102, top_k: 0.760703, samples/s: 1725.001 1612868172.9276168
train: epoch 42, iter 2500, loss: 3.167944, top_1: 0.525703, top_k: 0.762109, samples/s: 1744.913 1612868187.5987046
train: epoch 42, iter 2600, loss: 2.810451, top_1: 0.534805, top_k: 0.765781, samples/s: 1741.923 1612868202.2951603
train: epoch 42, iter 2700, loss: 2.914683, top_1: 0.527773, top_k: 0.760195, samples/s: 1729.141 1612868217.1001623
train: epoch 42, iter 2800, loss: 2.776778, top_1: 0.535469, top_k: 0.768398, samples/s: 1733.875 1612868231.86479
train: epoch 42, iter 2900, loss: 3.108003, top_1: 0.534766, top_k: 0.769062, samples/s: 1745.410 1612868246.5318818
train: epoch 42, iter 3000, loss: 2.904343, top_1: 0.528789, top_k: 0.764453, samples/s: 1722.870 1612868261.3908117
train: epoch 42, iter 3100, loss: 2.881663, top_1: 0.527813, top_k: 0.762695, samples/s: 1720.012 1612868276.2744539
train: epoch 42, iter 3200, loss: 2.847918, top_1: 0.530937, top_k: 0.764297, samples/s: 1750.774 1612868290.8965113
train: epoch 42, iter 3300, loss: 2.915229, top_1: 0.528438, top_k: 0.765977, samples/s: 1735.871 1612868305.6442142
train: epoch 42, iter 3400, loss: 2.877041, top_1: 0.531953, top_k: 0.763828, samples/s: 1726.594 1612868320.4710424
train: epoch 42, iter 3500, loss: 3.202229, top_1: 0.524883, top_k: 0.760508, samples/s: 1734.595 1612868335.2295392
train: epoch 42, iter 3600, loss: 2.815298, top_1: 0.530391, top_k: 0.761211, samples/s: 1736.918 1612868349.9683006
train: epoch 42, iter 3700, loss: 2.996100, top_1: 0.524258, top_k: 0.761563, samples/s: 1731.277 1612868364.7550898
train: epoch 42, iter 3800, loss: 3.008053, top_1: 0.526328, top_k: 0.760273, samples/s: 1732.407 1612868379.532187
train: epoch 42, iter 3900, loss: 2.963834, top_1: 0.532656, top_k: 0.767578, samples/s: 1738.046 1612868394.2613378
train: epoch 42, iter 4000, loss: 2.902364, top_1: 0.524883, top_k: 0.762734, samples/s: 1737.182 1612868408.9978435
train: epoch 42, iter 4100, loss: 2.753991, top_1: 0.529961, top_k: 0.763633, samples/s: 1733.311 1612868423.7673297
train: epoch 42, iter 4200, loss: 3.015331, top_1: 0.531641, top_k: 0.762813, samples/s: 1711.708 1612868438.723188
train: epoch 42, iter 4300, loss: 2.773674, top_1: 0.534648, top_k: 0.765273, samples/s: 1743.180 1612868453.40895
train: epoch 42, iter 4400, loss: 2.985406, top_1: 0.528828, top_k: 0.760000, samples/s: 1741.058 1612868468.112577
train: epoch 42, iter 4500, loss: 3.201368, top_1: 0.529727, top_k: 0.763203, samples/s: 1745.416 1612868482.7796767
train: epoch 42, iter 4600, loss: 2.860825, top_1: 0.528945, top_k: 0.755742, samples/s: 1752.589 1612868497.3865464
train: epoch 42, iter 4700, loss: 2.883230, top_1: 0.529961, top_k: 0.765234, samples/s: 1750.089 1612868512.0143733
train: epoch 42, iter 4800, loss: 2.956362, top_1: 0.530469, top_k: 0.759961, samples/s: 1723.334 1612868526.8693264
train: epoch 42, iter 4900, loss: 2.841143, top_1: 0.534258, top_k: 0.767969, samples/s: 1746.576 1612868541.5265517
train: epoch 42, iter 5000, loss: 2.771718, top_1: 0.536211, top_k: 0.764609, samples/s: 1744.974 1612868556.1972594
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_42.
validation: epoch 42, iter 195, top_1: 0.579647, top_k: 0.818890, samples/s: 2865.189 1612868574.127827
train: epoch 43, iter 100, loss: 2.880304, top_1: 0.536289, top_k: 0.767227, samples/s: 1755.294 1612868608.6388173
train: epoch 43, iter 200, loss: 2.993340, top_1: 0.540859, top_k: 0.773828, samples/s: 1760.047 1612868623.1836338
train: epoch 43, iter 300, loss: 2.909384, top_1: 0.543906, top_k: 0.774375, samples/s: 1762.299 1612868637.7108228
train: epoch 43, iter 400, loss: 2.999664, top_1: 0.533203, top_k: 0.769648, samples/s: 1761.835 1612868652.240404
train: epoch 43, iter 500, loss: 3.016241, top_1: 0.534258, top_k: 0.767852, samples/s: 1759.868 1612868666.7869484
train: epoch 43, iter 600, loss: 2.822655, top_1: 0.538711, top_k: 0.770664, samples/s: 1752.885 1612868681.3914914
train: epoch 43, iter 700, loss: 2.757029, top_1: 0.534297, top_k: 0.767578, samples/s: 1738.996 1612868696.1126225
train: epoch 43, iter 800, loss: 2.942769, top_1: 0.535391, top_k: 0.770273, samples/s: 1747.391 1612868710.7629335
train: epoch 43, iter 900, loss: 2.957406, top_1: 0.533164, top_k: 0.768320, samples/s: 1738.971 1612868725.484382
train: epoch 43, iter 1000, loss: 2.951012, top_1: 0.533125, top_k: 0.770312, samples/s: 1744.791 1612868740.156536
train: epoch 43, iter 1100, loss: 2.953384, top_1: 0.532031, top_k: 0.768047, samples/s: 1734.697 1612868754.9141757
train: epoch 43, iter 1200, loss: 2.983018, top_1: 0.525352, top_k: 0.761875, samples/s: 1738.916 1612868769.6360066
train: epoch 43, iter 1300, loss: 2.970933, top_1: 0.531211, top_k: 0.763047, samples/s: 1739.238 1612868784.3550763
train: epoch 43, iter 1400, loss: 3.073428, top_1: 0.531328, top_k: 0.762695, samples/s: 1724.146 1612868799.2030492
train: epoch 43, iter 1500, loss: 2.887058, top_1: 0.524453, top_k: 0.761250, samples/s: 1743.028 1612868813.8900986
train: epoch 43, iter 1600, loss: 2.970833, top_1: 0.532539, top_k: 0.766289, samples/s: 1741.907 1612868828.586681
train: epoch 43, iter 1700, loss: 2.962947, top_1: 0.536719, top_k: 0.770703, samples/s: 1716.388 1612868843.5017188
train: epoch 43, iter 1800, loss: 3.139851, top_1: 0.526445, top_k: 0.763125, samples/s: 1741.329 1612868858.203072
train: epoch 43, iter 1900, loss: 2.906009, top_1: 0.533789, top_k: 0.769687, samples/s: 1734.185 1612868872.9650683
train: epoch 43, iter 2000, loss: 2.804928, top_1: 0.531758, top_k: 0.766328, samples/s: 1738.704 1612868887.6886942
train: epoch 43, iter 2100, loss: 2.763982, top_1: 0.533906, top_k: 0.766484, samples/s: 1736.654 1612868902.4296517
train: epoch 43, iter 2200, loss: 2.811749, top_1: 0.532109, top_k: 0.766563, samples/s: 1740.893 1612868917.134802
train: epoch 43, iter 2300, loss: 2.772083, top_1: 0.526875, top_k: 0.766758, samples/s: 1737.160 1612868931.8714752
train: epoch 43, iter 2400, loss: 2.943449, top_1: 0.527578, top_k: 0.761602, samples/s: 1733.473 1612868946.639543
train: epoch 43, iter 2500, loss: 2.894369, top_1: 0.533398, top_k: 0.769570, samples/s: 1727.717 1612868961.4567766
train: epoch 43, iter 2600, loss: 3.274899, top_1: 0.533320, top_k: 0.768672, samples/s: 1718.732 1612868976.3514779
train: epoch 43, iter 2700, loss: 2.973275, top_1: 0.531875, top_k: 0.770938, samples/s: 1733.468 1612868991.119525
train: epoch 43, iter 2800, loss: 2.784112, top_1: 0.532461, top_k: 0.766484, samples/s: 1735.578 1612869005.8697083
train: epoch 43, iter 2900, loss: 3.110118, top_1: 0.529883, top_k: 0.761406, samples/s: 1743.925 1612869020.5492554
train: epoch 43, iter 3000, loss: 2.956989, top_1: 0.531055, top_k: 0.767891, samples/s: 1723.785 1612869035.4003258
train: epoch 43, iter 3100, loss: 2.917847, top_1: 0.526328, top_k: 0.762852, samples/s: 1741.490 1612869050.1003528
train: epoch 43, iter 3200, loss: 3.037057, top_1: 0.529219, top_k: 0.762188, samples/s: 1731.759 1612869064.8830287
train: epoch 43, iter 3300, loss: 2.770318, top_1: 0.532031, top_k: 0.761484, samples/s: 1724.020 1612869079.7320442
train: epoch 43, iter 3400, loss: 2.965209, top_1: 0.532188, top_k: 0.764102, samples/s: 1751.611 1612869094.3471375
train: epoch 43, iter 3500, loss: 3.008546, top_1: 0.523477, top_k: 0.761719, samples/s: 1726.275 1612869109.1767023
train: epoch 43, iter 3600, loss: 2.915749, top_1: 0.525820, top_k: 0.761797, samples/s: 1735.494 1612869123.9275696
train: epoch 43, iter 3700, loss: 2.944531, top_1: 0.521406, top_k: 0.760508, samples/s: 1745.431 1612869138.5944593
train: epoch 43, iter 3800, loss: 2.990910, top_1: 0.530742, top_k: 0.766445, samples/s: 1734.439 1612869153.3542838
train: epoch 43, iter 3900, loss: 2.904899, top_1: 0.530117, top_k: 0.763906, samples/s: 1733.966 1612869168.1180515
train: epoch 43, iter 4000, loss: 3.171232, top_1: 0.528242, top_k: 0.762227, samples/s: 1733.718 1612869182.8840215
train: epoch 43, iter 4100, loss: 2.887314, top_1: 0.535469, top_k: 0.769648, samples/s: 1734.610 1612869197.642633
train: epoch 43, iter 4200, loss: 3.065197, top_1: 0.532813, top_k: 0.765000, samples/s: 1745.485 1612869212.308817
train: epoch 43, iter 4300, loss: 3.116100, top_1: 0.526836, top_k: 0.761328, samples/s: 1742.481 1612869227.0005443
train: epoch 43, iter 4400, loss: 2.976330, top_1: 0.531875, top_k: 0.765352, samples/s: 1749.818 1612869241.6305835
train: epoch 43, iter 4500, loss: 2.966631, top_1: 0.525742, top_k: 0.759570, samples/s: 1748.379 1612869256.2727945
train: epoch 43, iter 4600, loss: 2.765419, top_1: 0.532266, top_k: 0.762109, samples/s: 1751.443 1612869270.88924
train: epoch 43, iter 4700, loss: 2.903811, top_1: 0.535430, top_k: 0.765391, samples/s: 1746.625 1612869285.5460699
train: epoch 43, iter 4800, loss: 2.844837, top_1: 0.529727, top_k: 0.765859, samples/s: 1747.850 1612869300.1930807
train: epoch 43, iter 4900, loss: 2.866132, top_1: 0.530859, top_k: 0.759844, samples/s: 1751.658 1612869314.8074079
train: epoch 43, iter 5000, loss: 3.133679, top_1: 0.528945, top_k: 0.761367, samples/s: 1745.934 1612869329.4700322
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_43.
validation: epoch 43, iter 195, top_1: 0.582652, top_k: 0.819832, samples/s: 2784.157 1612869347.8207388
train: epoch 44, iter 100, loss: 2.974746, top_1: 0.536016, top_k: 0.766211, samples/s: 1761.680 1612869382.4894707
train: epoch 44, iter 200, loss: 3.056687, top_1: 0.538008, top_k: 0.769453, samples/s: 1760.666 1612869397.0293858
train: epoch 44, iter 300, loss: 2.972720, top_1: 0.539922, top_k: 0.771211, samples/s: 1755.388 1612869411.6133807
train: epoch 44, iter 400, loss: 3.030123, top_1: 0.541094, top_k: 0.771523, samples/s: 1766.990 1612869426.1009746
train: epoch 44, iter 500, loss: 2.797439, top_1: 0.537969, top_k: 0.770195, samples/s: 1756.075 1612869440.6789343
train: epoch 44, iter 600, loss: 2.911198, top_1: 0.529297, top_k: 0.763984, samples/s: 1749.897 1612869455.3084216
train: epoch 44, iter 700, loss: 2.806574, top_1: 0.534883, top_k: 0.771992, samples/s: 1747.373 1612869469.9589975
train: epoch 44, iter 800, loss: 3.194004, top_1: 0.538125, top_k: 0.769609, samples/s: 1736.952 1612869484.6974258
train: epoch 44, iter 900, loss: 2.961614, top_1: 0.540664, top_k: 0.775430, samples/s: 1735.391 1612869499.4491048
train: epoch 44, iter 1000, loss: 3.097114, top_1: 0.536328, top_k: 0.767617, samples/s: 1726.895 1612869514.2733955
train: epoch 44, iter 1100, loss: 2.754532, top_1: 0.535820, top_k: 0.773164, samples/s: 1737.602 1612869529.0063953
train: epoch 44, iter 1200, loss: 2.711790, top_1: 0.533477, top_k: 0.764805, samples/s: 1729.327 1612869543.8098576
train: epoch 44, iter 1300, loss: 3.005963, top_1: 0.535039, top_k: 0.770312, samples/s: 1739.514 1612869558.5266342
train: epoch 44, iter 1400, loss: 2.924667, top_1: 0.532773, top_k: 0.765547, samples/s: 1723.583 1612869573.3793154
train: epoch 44, iter 1500, loss: 2.897171, top_1: 0.535039, top_k: 0.768516, samples/s: 1747.936 1612869588.0251818
train: epoch 44, iter 1600, loss: 2.859028, top_1: 0.536992, top_k: 0.769766, samples/s: 1730.843 1612869602.8156595
train: epoch 44, iter 1700, loss: 2.921246, top_1: 0.535937, top_k: 0.768945, samples/s: 1729.462 1612869617.6179376
train: epoch 44, iter 1800, loss: 3.041626, top_1: 0.534570, top_k: 0.766953, samples/s: 1731.275 1612869632.404822
train: epoch 44, iter 1900, loss: 3.029098, top_1: 0.529492, top_k: 0.762305, samples/s: 1740.447 1612869647.113707
train: epoch 44, iter 2000, loss: 2.974826, top_1: 0.536953, top_k: 0.772539, samples/s: 1742.577 1612869661.8044784
train: epoch 44, iter 2100, loss: 2.812157, top_1: 0.538789, top_k: 0.770117, samples/s: 1729.963 1612869676.6025507
train: epoch 44, iter 2200, loss: 2.891791, top_1: 0.527461, top_k: 0.763555, samples/s: 1716.663 1612869691.5151746
train: epoch 44, iter 2300, loss: 2.882162, top_1: 0.529883, top_k: 0.761680, samples/s: 1727.736 1612869706.3322778
train: epoch 44, iter 2400, loss: 2.983149, top_1: 0.525234, top_k: 0.763750, samples/s: 1740.227 1612869721.0429616
train: epoch 44, iter 2500, loss: 2.971972, top_1: 0.534961, top_k: 0.769023, samples/s: 1734.583 1612869735.801581
train: epoch 44, iter 2600, loss: 2.832311, top_1: 0.532070, top_k: 0.765156, samples/s: 1726.990 1612869750.6251185
train: epoch 44, iter 2700, loss: 2.856841, top_1: 0.539687, top_k: 0.772188, samples/s: 1745.706 1612869765.289629
train: epoch 44, iter 2800, loss: 3.102713, top_1: 0.535977, top_k: 0.771211, samples/s: 1734.828 1612869780.0460958
train: epoch 44, iter 2900, loss: 2.933400, top_1: 0.530781, top_k: 0.762617, samples/s: 1729.595 1612869794.8472364
train: epoch 44, iter 3000, loss: 2.797895, top_1: 0.532344, top_k: 0.767813, samples/s: 1744.524 1612869809.5217762
train: epoch 44, iter 3100, loss: 3.002528, top_1: 0.533945, top_k: 0.769609, samples/s: 1744.747 1612869824.1943846
train: epoch 44, iter 3200, loss: 2.931452, top_1: 0.534570, top_k: 0.765117, samples/s: 1723.333 1612869839.049276
train: epoch 44, iter 3300, loss: 2.878110, top_1: 0.541562, top_k: 0.767969, samples/s: 1720.784 1612869853.926329
train: epoch 44, iter 3400, loss: 2.882319, top_1: 0.530820, top_k: 0.762539, samples/s: 1742.082 1612869868.6213286
train: epoch 44, iter 3500, loss: 2.867532, top_1: 0.531641, top_k: 0.763320, samples/s: 1731.096 1612869883.4095829
train: epoch 44, iter 3600, loss: 2.837563, top_1: 0.532148, top_k: 0.766172, samples/s: 1729.334 1612869898.213026
train: epoch 44, iter 3700, loss: 2.971339, top_1: 0.530859, top_k: 0.762305, samples/s: 1727.648 1612869913.0308514
train: epoch 44, iter 3800, loss: 3.097025, top_1: 0.532109, top_k: 0.763086, samples/s: 1750.962 1612869927.6513815
train: epoch 44, iter 3900, loss: 2.874375, top_1: 0.532148, top_k: 0.762070, samples/s: 1731.836 1612869942.4334407
train: epoch 44, iter 4000, loss: 2.801380, top_1: 0.534062, top_k: 0.765312, samples/s: 1742.392 1612869957.125769
train: epoch 44, iter 4100, loss: 3.065261, top_1: 0.531602, top_k: 0.763633, samples/s: 1735.446 1612869971.8770597
train: epoch 44, iter 4200, loss: 3.045895, top_1: 0.534414, top_k: 0.761992, samples/s: 1735.638 1612869986.6267471
train: epoch 44, iter 4300, loss: 3.063898, top_1: 0.538594, top_k: 0.769023, samples/s: 1744.730 1612870001.2993965
train: epoch 44, iter 4400, loss: 3.030300, top_1: 0.532266, top_k: 0.764180, samples/s: 1732.384 1612870016.0767918
train: epoch 44, iter 4500, loss: 2.977917, top_1: 0.534062, top_k: 0.767578, samples/s: 1737.439 1612870030.8111088
train: epoch 44, iter 4600, loss: 3.093523, top_1: 0.524570, top_k: 0.762891, samples/s: 1735.347 1612870045.5632026
train: epoch 44, iter 4700, loss: 2.913838, top_1: 0.532305, top_k: 0.765391, samples/s: 1716.211 1612870060.4797766
train: epoch 44, iter 4800, loss: 2.930009, top_1: 0.531992, top_k: 0.766992, samples/s: 1732.481 1612870075.2562387
train: epoch 44, iter 4900, loss: 2.999510, top_1: 0.530117, top_k: 0.770547, samples/s: 1727.782 1612870090.0729551
train: epoch 44, iter 5000, loss: 3.014594, top_1: 0.528164, top_k: 0.763242, samples/s: 1737.859 1612870104.8041475
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_44.
validation: epoch 44, iter 195, top_1: 0.560897, top_k: 0.807232, samples/s: 2825.911 1612870122.8833265
train: epoch 45, iter 100, loss: 2.991184, top_1: 0.538984, top_k: 0.773984, samples/s: 1751.785 1612870158.0301228
train: epoch 45, iter 200, loss: 2.707557, top_1: 0.541562, top_k: 0.769844, samples/s: 1758.342 1612870172.5892863
train: epoch 45, iter 300, loss: 2.927490, top_1: 0.543516, top_k: 0.771641, samples/s: 1755.244 1612870187.1741078
train: epoch 45, iter 400, loss: 2.882031, top_1: 0.544063, top_k: 0.771016, samples/s: 1753.959 1612870201.769995
train: epoch 45, iter 500, loss: 2.825425, top_1: 0.541133, top_k: 0.774648, samples/s: 1755.921 1612870216.348911
train: epoch 45, iter 600, loss: 2.890743, top_1: 0.536250, top_k: 0.768359, samples/s: 1748.610 1612870230.9894006
train: epoch 45, iter 700, loss: 2.752808, top_1: 0.540742, top_k: 0.770977, samples/s: 1746.196 1612870245.6495478
train: epoch 45, iter 800, loss: 2.979392, top_1: 0.536602, top_k: 0.771367, samples/s: 1736.768 1612870260.3900225
train: epoch 45, iter 900, loss: 3.012417, top_1: 0.538281, top_k: 0.771445, samples/s: 1724.621 1612870275.233478
train: epoch 45, iter 1000, loss: 3.016503, top_1: 0.537305, top_k: 0.769492, samples/s: 1745.913 1612870289.8962576
train: epoch 45, iter 1100, loss: 2.813601, top_1: 0.536719, top_k: 0.769258, samples/s: 1745.852 1612870304.559663
train: epoch 45, iter 1200, loss: 3.321503, top_1: 0.530820, top_k: 0.765977, samples/s: 1717.427 1612870319.4656866
train: epoch 45, iter 1300, loss: 2.931665, top_1: 0.533594, top_k: 0.763945, samples/s: 1743.808 1612870334.1461346
train: epoch 45, iter 1400, loss: 3.157318, top_1: 0.536055, top_k: 0.768477, samples/s: 1734.382 1612870348.9063952
train: epoch 45, iter 1500, loss: 2.873450, top_1: 0.540937, top_k: 0.772422, samples/s: 1733.898 1612870363.6709702
train: epoch 45, iter 1600, loss: 2.926659, top_1: 0.539023, top_k: 0.772383, samples/s: 1725.358 1612870378.5084124
train: epoch 45, iter 1700, loss: 3.017248, top_1: 0.534922, top_k: 0.764766, samples/s: 1738.419 1612870393.2343986
train: epoch 45, iter 1800, loss: 2.929982, top_1: 0.531523, top_k: 0.768672, samples/s: 1723.551 1612870408.0875773
train: epoch 45, iter 1900, loss: 2.904477, top_1: 0.533203, top_k: 0.765703, samples/s: 1739.543 1612870422.8038754
train: epoch 45, iter 2000, loss: 2.918507, top_1: 0.529961, top_k: 0.771133, samples/s: 1748.265 1612870437.4470313
train: epoch 45, iter 2100, loss: 3.073926, top_1: 0.527461, top_k: 0.764805, samples/s: 1736.426 1612870452.1899211
train: epoch 45, iter 2200, loss: 2.995941, top_1: 0.533867, top_k: 0.768320, samples/s: 1734.948 1612870466.945417
train: epoch 45, iter 2300, loss: 3.004343, top_1: 0.535508, top_k: 0.767891, samples/s: 1747.025 1612870481.5988865
train: epoch 45, iter 2400, loss: 3.049287, top_1: 0.532617, top_k: 0.768516, samples/s: 1724.282 1612870496.445713
train: epoch 45, iter 2500, loss: 2.968053, top_1: 0.533359, top_k: 0.768320, samples/s: 1727.021 1612870511.2689426
train: epoch 45, iter 2600, loss: 2.810950, top_1: 0.534023, top_k: 0.765820, samples/s: 1737.044 1612870526.0066175
train: epoch 45, iter 2700, loss: 2.942243, top_1: 0.529180, top_k: 0.765508, samples/s: 1735.309 1612870540.7589824
train: epoch 45, iter 2800, loss: 3.107690, top_1: 0.536445, top_k: 0.769766, samples/s: 1732.923 1612870555.5317998
train: epoch 45, iter 2900, loss: 3.076221, top_1: 0.537305, top_k: 0.766367, samples/s: 1736.708 1612870570.2724214
train: epoch 45, iter 3000, loss: 2.884418, top_1: 0.536406, top_k: 0.766758, samples/s: 1736.713 1612870585.0127316
train: epoch 45, iter 3100, loss: 2.766232, top_1: 0.530859, top_k: 0.765117, samples/s: 1737.983 1612870599.7424955
train: epoch 45, iter 3200, loss: 2.962579, top_1: 0.536016, top_k: 0.768047, samples/s: 1732.568 1612870614.518209
train: epoch 45, iter 3300, loss: 2.774538, top_1: 0.530117, top_k: 0.764375, samples/s: 1727.786 1612870629.3349133
train: epoch 45, iter 3400, loss: 3.214926, top_1: 0.530430, top_k: 0.764727, samples/s: 1738.879 1612870644.0573697
train: epoch 45, iter 3500, loss: 2.875510, top_1: 0.536563, top_k: 0.771484, samples/s: 1732.047 1612870658.8372486
train: epoch 45, iter 3600, loss: 2.799028, top_1: 0.530469, top_k: 0.765820, samples/s: 1742.545 1612870673.5283294
train: epoch 45, iter 3700, loss: 2.647906, top_1: 0.531484, top_k: 0.764258, samples/s: 1735.664 1612870688.2778327
train: epoch 45, iter 3800, loss: 2.989043, top_1: 0.531328, top_k: 0.766211, samples/s: 1730.202 1612870703.0740485
train: epoch 45, iter 3900, loss: 2.853214, top_1: 0.540508, top_k: 0.770977, samples/s: 1737.907 1612870717.8040707
train: epoch 45, iter 4000, loss: 3.097292, top_1: 0.538242, top_k: 0.767500, samples/s: 1738.263 1612870732.5314536
train: epoch 45, iter 4100, loss: 2.934062, top_1: 0.534531, top_k: 0.768242, samples/s: 1739.247 1612870747.2504127
train: epoch 45, iter 4200, loss: 2.947461, top_1: 0.526836, top_k: 0.764570, samples/s: 1734.138 1612870762.0128367
train: epoch 45, iter 4300, loss: 2.878487, top_1: 0.530820, top_k: 0.764258, samples/s: 1737.060 1612870776.7504041
train: epoch 45, iter 4400, loss: 2.994319, top_1: 0.528867, top_k: 0.762695, samples/s: 1729.002 1612870791.5565982
train: epoch 45, iter 4500, loss: 2.824879, top_1: 0.531133, top_k: 0.766953, samples/s: 1719.856 1612870806.4415486
train: epoch 45, iter 4600, loss: 2.949227, top_1: 0.529375, top_k: 0.765234, samples/s: 1765.973 1612870820.9378636
train: epoch 45, iter 4700, loss: 3.056942, top_1: 0.529844, top_k: 0.762422, samples/s: 1751.065 1612870835.5575318
train: epoch 45, iter 4800, loss: 2.971659, top_1: 0.538359, top_k: 0.768125, samples/s: 1742.597 1612870850.248258
train: epoch 45, iter 4900, loss: 2.912475, top_1: 0.532148, top_k: 0.764023, samples/s: 1738.214 1612870864.9759562
train: epoch 45, iter 5000, loss: 2.620108, top_1: 0.539062, top_k: 0.770664, samples/s: 1757.461 1612870879.5428054
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_45.
validation: epoch 45, iter 195, top_1: 0.581811, top_k: 0.821575, samples/s: 2843.260 1612870897.5153606
train: epoch 46, iter 100, loss: 2.987578, top_1: 0.548750, top_k: 0.779297, samples/s: 1746.998 1612870932.5555158
train: epoch 46, iter 200, loss: 2.963506, top_1: 0.539766, top_k: 0.771445, samples/s: 1758.498 1612870947.1133325
train: epoch 46, iter 300, loss: 2.890548, top_1: 0.546875, top_k: 0.776133, samples/s: 1758.470 1612870961.6714764
train: epoch 46, iter 400, loss: 2.993061, top_1: 0.542852, top_k: 0.776992, samples/s: 1761.570 1612870976.2039142
train: epoch 46, iter 500, loss: 2.897482, top_1: 0.547578, top_k: 0.776758, samples/s: 1752.402 1612870990.8128836
train: epoch 46, iter 600, loss: 2.971538, top_1: 0.538867, top_k: 0.770898, samples/s: 1757.537 1612871005.3782823
train: epoch 46, iter 700, loss: 2.946908, top_1: 0.539531, top_k: 0.774141, samples/s: 1746.437 1612871020.0370536
train: epoch 46, iter 800, loss: 2.760118, top_1: 0.543008, top_k: 0.769805, samples/s: 1746.246 1612871034.6969151
train: epoch 46, iter 900, loss: 2.954971, top_1: 0.540742, top_k: 0.772500, samples/s: 1737.259 1612871049.4330306
train: epoch 46, iter 1000, loss: 3.031244, top_1: 0.534961, top_k: 0.765625, samples/s: 1745.432 1612871064.0995185
train: epoch 46, iter 1100, loss: 3.022452, top_1: 0.531094, top_k: 0.768789, samples/s: 1737.177 1612871078.8359914
train: epoch 46, iter 1200, loss: 2.967339, top_1: 0.534102, top_k: 0.768789, samples/s: 1736.205 1612871093.580763
train: epoch 46, iter 1300, loss: 2.904228, top_1: 0.539922, top_k: 0.771758, samples/s: 1744.020 1612871108.2594903
train: epoch 46, iter 1400, loss: 3.084356, top_1: 0.541992, top_k: 0.774766, samples/s: 1738.195 1612871122.9874074
train: epoch 46, iter 1500, loss: 2.572826, top_1: 0.536875, top_k: 0.770430, samples/s: 1735.900 1612871137.7348666
train: epoch 46, iter 1600, loss: 2.937248, top_1: 0.536289, top_k: 0.769766, samples/s: 1738.983 1612871152.4560583
train: epoch 46, iter 1700, loss: 2.953854, top_1: 0.537031, top_k: 0.769844, samples/s: 1728.565 1612871167.2661126
train: epoch 46, iter 1800, loss: 2.648837, top_1: 0.539375, top_k: 0.767852, samples/s: 1744.723 1612871181.9388316
train: epoch 46, iter 1900, loss: 3.155481, top_1: 0.538086, top_k: 0.769648, samples/s: 1735.886 1612871196.686425
train: epoch 46, iter 2000, loss: 2.836314, top_1: 0.541328, top_k: 0.769609, samples/s: 1737.638 1612871211.4189887
train: epoch 46, iter 2100, loss: 2.894464, top_1: 0.533438, top_k: 0.766875, samples/s: 1727.013 1612871226.242312
train: epoch 46, iter 2200, loss: 3.007094, top_1: 0.535859, top_k: 0.769336, samples/s: 1737.748 1612871240.9740176
train: epoch 46, iter 2300, loss: 2.822717, top_1: 0.525898, top_k: 0.756680, samples/s: 1738.658 1612871255.6979766
train: epoch 46, iter 2400, loss: 2.733248, top_1: 0.539727, top_k: 0.771289, samples/s: 1733.806 1612871270.4632006
train: epoch 46, iter 2500, loss: 2.908998, top_1: 0.541992, top_k: 0.773438, samples/s: 1727.736 1612871285.2803342
train: epoch 46, iter 2600, loss: 2.899012, top_1: 0.533438, top_k: 0.767383, samples/s: 1739.157 1612871300.0000532
train: epoch 46, iter 2700, loss: 2.839778, top_1: 0.539648, top_k: 0.771016, samples/s: 1720.236 1612871314.8817897
train: epoch 46, iter 2800, loss: 2.877532, top_1: 0.532031, top_k: 0.770820, samples/s: 1753.686 1612871329.479602
train: epoch 46, iter 2900, loss: 3.198454, top_1: 0.535352, top_k: 0.764961, samples/s: 1718.670 1612871344.3748617
train: epoch 46, iter 3000, loss: 2.910638, top_1: 0.538398, top_k: 0.766055, samples/s: 1743.842 1612871359.0551224
train: epoch 46, iter 3100, loss: 3.005415, top_1: 0.531133, top_k: 0.763008, samples/s: 1728.542 1612871373.8652487
train: epoch 46, iter 3200, loss: 2.892768, top_1: 0.532344, top_k: 0.764727, samples/s: 1724.497 1612871388.7101214
train: epoch 46, iter 3300, loss: 2.877782, top_1: 0.534141, top_k: 0.769805, samples/s: 1740.739 1612871403.4164908
train: epoch 46, iter 3400, loss: 2.871020, top_1: 0.537500, top_k: 0.766875, samples/s: 1750.138 1612871418.0439377
train: epoch 46, iter 3500, loss: 3.062223, top_1: 0.531758, top_k: 0.763398, samples/s: 1732.294 1612871432.8219945
train: epoch 46, iter 3600, loss: 3.029891, top_1: 0.536992, top_k: 0.770898, samples/s: 1736.638 1612871447.5632136
train: epoch 46, iter 3700, loss: 2.901130, top_1: 0.531523, top_k: 0.763594, samples/s: 1736.202 1612871462.3079422
train: epoch 46, iter 3800, loss: 3.045422, top_1: 0.530937, top_k: 0.767734, samples/s: 1733.778 1612871477.073385
train: epoch 46, iter 3900, loss: 2.921202, top_1: 0.532148, top_k: 0.766016, samples/s: 1732.821 1612871491.8469908
train: epoch 46, iter 4000, loss: 3.041776, top_1: 0.528867, top_k: 0.765898, samples/s: 1735.143 1612871506.6008656
train: epoch 46, iter 4100, loss: 2.918162, top_1: 0.531563, top_k: 0.761758, samples/s: 1739.276 1612871521.319635
train: epoch 46, iter 4200, loss: 3.027770, top_1: 0.533867, top_k: 0.766016, samples/s: 1736.441 1612871536.062456
train: epoch 46, iter 4300, loss: 2.959193, top_1: 0.536484, top_k: 0.769219, samples/s: 1737.460 1612871550.7966151
train: epoch 46, iter 4400, loss: 2.941647, top_1: 0.530820, top_k: 0.764922, samples/s: 1739.001 1612871565.517644
train: epoch 46, iter 4500, loss: 2.956942, top_1: 0.531719, top_k: 0.761133, samples/s: 1734.153 1612871580.2799032
train: epoch 46, iter 4600, loss: 2.852558, top_1: 0.528984, top_k: 0.763359, samples/s: 1732.887 1612871595.0529666
train: epoch 46, iter 4700, loss: 2.999968, top_1: 0.530039, top_k: 0.765586, samples/s: 1734.255 1612871609.8143091
train: epoch 46, iter 4800, loss: 3.030618, top_1: 0.529336, top_k: 0.767578, samples/s: 1738.512 1612871624.539541
train: epoch 46, iter 4900, loss: 2.922844, top_1: 0.530234, top_k: 0.764180, samples/s: 1718.954 1612871639.4323251
train: epoch 46, iter 5000, loss: 2.906476, top_1: 0.533594, top_k: 0.766289, samples/s: 1730.813 1612871654.2231758
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_46.
validation: epoch 46, iter 195, top_1: 0.574900, top_k: 0.815665, samples/s: 2821.039 1612871672.3477008
train: epoch 47, iter 100, loss: 2.890588, top_1: 0.545625, top_k: 0.775742, samples/s: 1750.299 1612871711.9560328
train: epoch 47, iter 200, loss: 3.041215, top_1: 0.537617, top_k: 0.777656, samples/s: 1753.698 1612871726.553702
train: epoch 47, iter 300, loss: 2.860142, top_1: 0.547031, top_k: 0.780781, samples/s: 1757.456 1612871741.1202765
train: epoch 47, iter 400, loss: 2.800628, top_1: 0.542031, top_k: 0.773750, samples/s: 1756.695 1612871755.6931221
train: epoch 47, iter 500, loss: 3.011569, top_1: 0.543789, top_k: 0.771758, samples/s: 1759.032 1612871770.246556
train: epoch 47, iter 600, loss: 3.166625, top_1: 0.540352, top_k: 0.768203, samples/s: 1731.612 1612871785.030433
train: epoch 47, iter 700, loss: 2.972924, top_1: 0.542461, top_k: 0.776445, samples/s: 1749.448 1612871799.66364
train: epoch 47, iter 800, loss: 3.108940, top_1: 0.543594, top_k: 0.774141, samples/s: 1742.862 1612871814.3520675
train: epoch 47, iter 900, loss: 2.975689, top_1: 0.540508, top_k: 0.773398, samples/s: 1741.064 1612871829.0558028
train: epoch 47, iter 1000, loss: 2.998485, top_1: 0.541211, top_k: 0.774531, samples/s: 1726.547 1612871843.883113
train: epoch 47, iter 1100, loss: 3.041965, top_1: 0.545937, top_k: 0.771953, samples/s: 1740.739 1612871858.5894167
train: epoch 47, iter 1200, loss: 2.990797, top_1: 0.534727, top_k: 0.769375, samples/s: 1720.416 1612871873.4696262
train: epoch 47, iter 1300, loss: 2.798240, top_1: 0.543047, top_k: 0.776367, samples/s: 1739.588 1612871888.1857011
train: epoch 47, iter 1400, loss: 2.838480, top_1: 0.538594, top_k: 0.770820, samples/s: 1735.945 1612871902.932663
train: epoch 47, iter 1500, loss: 2.925521, top_1: 0.539805, top_k: 0.773359, samples/s: 1755.184 1612871917.5180595
train: epoch 47, iter 1600, loss: 2.820979, top_1: 0.541367, top_k: 0.773359, samples/s: 1722.754 1612871932.3779583
train: epoch 47, iter 1700, loss: 3.147623, top_1: 0.537617, top_k: 0.770312, samples/s: 1722.353 1612871947.241431
train: epoch 47, iter 1800, loss: 2.906733, top_1: 0.537500, top_k: 0.768594, samples/s: 1733.424 1612871962.009887
train: epoch 47, iter 1900, loss: 2.984359, top_1: 0.533281, top_k: 0.769414, samples/s: 1742.246 1612871976.7035306
train: epoch 47, iter 2000, loss: 2.969088, top_1: 0.540078, top_k: 0.770625, samples/s: 1738.688 1612871991.4273138
train: epoch 47, iter 2100, loss: 2.922848, top_1: 0.537188, top_k: 0.768711, samples/s: 1741.101 1612872006.130639
train: epoch 47, iter 2200, loss: 2.825691, top_1: 0.535000, top_k: 0.767422, samples/s: 1736.102 1612872020.8762987
train: epoch 47, iter 2300, loss: 3.066188, top_1: 0.534727, top_k: 0.771641, samples/s: 1734.955 1612872035.631688
train: epoch 47, iter 2400, loss: 2.906355, top_1: 0.536914, top_k: 0.765938, samples/s: 1737.036 1612872050.3694785
train: epoch 47, iter 2500, loss: 3.036661, top_1: 0.535781, top_k: 0.764805, samples/s: 1730.973 1612872065.1587963
train: epoch 47, iter 2600, loss: 3.034215, top_1: 0.536016, top_k: 0.768203, samples/s: 1747.351 1612872079.8096247
train: epoch 47, iter 2700, loss: 2.865119, top_1: 0.540391, top_k: 0.769727, samples/s: 1739.325 1612872094.5279644
train: epoch 47, iter 2800, loss: 2.799430, top_1: 0.537852, top_k: 0.770430, samples/s: 1719.456 1612872109.416439
train: epoch 47, iter 2900, loss: 2.981785, top_1: 0.533555, top_k: 0.767656, samples/s: 1738.424 1612872124.1423166
train: epoch 47, iter 3000, loss: 2.765929, top_1: 0.535898, top_k: 0.767266, samples/s: 1730.302 1612872138.9374063
train: epoch 47, iter 3100, loss: 2.950744, top_1: 0.537383, top_k: 0.766406, samples/s: 1746.590 1612872153.5945532
train: epoch 47, iter 3200, loss: 2.874317, top_1: 0.532656, top_k: 0.765742, samples/s: 1734.867 1612872168.3507757
train: epoch 47, iter 3300, loss: 3.111046, top_1: 0.535273, top_k: 0.766289, samples/s: 1729.891 1612872183.1493979
train: epoch 47, iter 3400, loss: 2.894973, top_1: 0.535625, top_k: 0.771953, samples/s: 1739.189 1612872197.8688369
train: epoch 47, iter 3500, loss: 2.862029, top_1: 0.529570, top_k: 0.765352, samples/s: 1744.503 1612872212.5435681
train: epoch 47, iter 3600, loss: 2.990863, top_1: 0.536602, top_k: 0.769336, samples/s: 1731.818 1612872227.3256853
train: epoch 47, iter 3700, loss: 3.064587, top_1: 0.538555, top_k: 0.767578, samples/s: 1732.615 1612872242.1010237
train: epoch 47, iter 3800, loss: 3.023087, top_1: 0.531563, top_k: 0.761641, samples/s: 1723.382 1612872256.9556208
train: epoch 47, iter 3900, loss: 2.924058, top_1: 0.536250, top_k: 0.769844, samples/s: 1741.601 1612872271.6546626
train: epoch 47, iter 4000, loss: 2.793200, top_1: 0.534883, top_k: 0.762617, samples/s: 1734.005 1612872286.4182389
train: epoch 47, iter 4100, loss: 3.048254, top_1: 0.534687, top_k: 0.767148, samples/s: 1738.746 1612872301.1415622
train: epoch 47, iter 4200, loss: 2.885837, top_1: 0.534219, top_k: 0.769922, samples/s: 1743.368 1612872315.825696
train: epoch 47, iter 4300, loss: 3.103065, top_1: 0.536211, top_k: 0.766953, samples/s: 1735.378 1612872330.5775435
train: epoch 47, iter 4400, loss: 2.790972, top_1: 0.536875, top_k: 0.768516, samples/s: 1729.112 1612872345.3828034
train: epoch 47, iter 4500, loss: 2.875205, top_1: 0.538398, top_k: 0.766914, samples/s: 1733.266 1612872360.1525855
train: epoch 47, iter 4600, loss: 2.935272, top_1: 0.536406, top_k: 0.768633, samples/s: 1729.137 1612872374.9577756
train: epoch 47, iter 4700, loss: 2.962942, top_1: 0.533086, top_k: 0.769180, samples/s: 1732.417 1612872389.7347474
train: epoch 47, iter 4800, loss: 2.987612, top_1: 0.528555, top_k: 0.762617, samples/s: 1739.383 1612872404.4525466
train: epoch 47, iter 4900, loss: 2.834095, top_1: 0.535234, top_k: 0.769258, samples/s: 1720.494 1612872419.3320646
train: epoch 47, iter 5000, loss: 2.768614, top_1: 0.533672, top_k: 0.771289, samples/s: 1738.137 1612872434.0604532
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_47.
validation: epoch 47, iter 195, top_1: 0.590685, top_k: 0.826623, samples/s: 2861.732 1612872451.9663475
train: epoch 48, iter 100, loss: 2.906240, top_1: 0.549375, top_k: 0.781523, samples/s: 1751.847 1612872486.7424397
train: epoch 48, iter 200, loss: 3.052837, top_1: 0.540195, top_k: 0.775039, samples/s: 1761.979 1612872501.2714489
train: epoch 48, iter 300, loss: 3.087693, top_1: 0.548633, top_k: 0.774609, samples/s: 1743.257 1612872515.9567826
train: epoch 48, iter 400, loss: 2.966622, top_1: 0.538242, top_k: 0.777031, samples/s: 1767.253 1612872530.4424253
train: epoch 48, iter 500, loss: 2.951255, top_1: 0.541602, top_k: 0.771133, samples/s: 1757.609 1612872545.00764
train: epoch 48, iter 600, loss: 2.934989, top_1: 0.537930, top_k: 0.770938, samples/s: 1741.153 1612872559.7105129
train: epoch 48, iter 700, loss: 2.992949, top_1: 0.540078, top_k: 0.772461, samples/s: 1738.014 1612872574.4399872
train: epoch 48, iter 800, loss: 2.875265, top_1: 0.541875, top_k: 0.771094, samples/s: 1733.363 1612872589.2092319
train: epoch 48, iter 900, loss: 2.988757, top_1: 0.540703, top_k: 0.773125, samples/s: 1729.086 1612872604.0144773
train: epoch 48, iter 1000, loss: 2.897645, top_1: 0.540352, top_k: 0.770195, samples/s: 1756.858 1612872618.5859764
train: epoch 48, iter 1100, loss: 2.899213, top_1: 0.538242, top_k: 0.769102, samples/s: 1736.209 1612872633.3307202
train: epoch 48, iter 1200, loss: 2.980940, top_1: 0.544453, top_k: 0.776211, samples/s: 1740.886 1612872648.0361865
train: epoch 48, iter 1300, loss: 2.948756, top_1: 0.533906, top_k: 0.769648, samples/s: 1741.377 1612872662.7369187
train: epoch 48, iter 1400, loss: 3.050033, top_1: 0.543047, top_k: 0.773711, samples/s: 1733.747 1612872677.503001
train: epoch 48, iter 1500, loss: 2.782231, top_1: 0.542031, top_k: 0.770781, samples/s: 1732.813 1612872692.2762601
train: epoch 48, iter 1600, loss: 2.989404, top_1: 0.530937, top_k: 0.765625, samples/s: 1730.316 1612872707.0712254
train: epoch 48, iter 1700, loss: 2.996197, top_1: 0.542969, top_k: 0.775156, samples/s: 1740.633 1612872721.7785673
train: epoch 48, iter 1800, loss: 2.831851, top_1: 0.536719, top_k: 0.769805, samples/s: 1737.242 1612872736.5145214
train: epoch 48, iter 1900, loss: 2.788829, top_1: 0.536953, top_k: 0.774727, samples/s: 1735.254 1612872751.2674346
train: epoch 48, iter 2000, loss: 2.944394, top_1: 0.538672, top_k: 0.771758, samples/s: 1736.733 1612872766.0078044
train: epoch 48, iter 2100, loss: 3.095243, top_1: 0.543672, top_k: 0.771367, samples/s: 1732.386 1612872780.7850065
train: epoch 48, iter 2200, loss: 2.970965, top_1: 0.537461, top_k: 0.771406, samples/s: 1732.493 1612872795.5614548
train: epoch 48, iter 2300, loss: 3.037816, top_1: 0.538438, top_k: 0.772695, samples/s: 1741.239 1612872810.2636652
train: epoch 48, iter 2400, loss: 2.931608, top_1: 0.537461, top_k: 0.770664, samples/s: 1730.714 1612872825.055267
train: epoch 48, iter 2500, loss: 2.974780, top_1: 0.535547, top_k: 0.767539, samples/s: 1733.841 1612872839.8201857
train: epoch 48, iter 2600, loss: 2.968198, top_1: 0.535977, top_k: 0.770312, samples/s: 1744.268 1612872854.4968352
train: epoch 48, iter 2700, loss: 3.061666, top_1: 0.533203, top_k: 0.769258, samples/s: 1738.652 1612872869.2209077
train: epoch 48, iter 2800, loss: 3.091685, top_1: 0.536445, top_k: 0.767891, samples/s: 1743.358 1612872883.905164
train: epoch 48, iter 2900, loss: 3.039948, top_1: 0.539102, top_k: 0.767852, samples/s: 1724.207 1612872898.752533
train: epoch 48, iter 3000, loss: 2.737161, top_1: 0.540195, top_k: 0.769023, samples/s: 1733.090 1612872913.523864
train: epoch 48, iter 3100, loss: 3.002694, top_1: 0.532695, top_k: 0.767969, samples/s: 1737.683 1612872928.2561224
train: epoch 48, iter 3200, loss: 3.001810, top_1: 0.542305, top_k: 0.770859, samples/s: 1729.673 1612872943.0565796
train: epoch 48, iter 3300, loss: 2.981664, top_1: 0.538789, top_k: 0.768477, samples/s: 1737.396 1612872957.7913294
train: epoch 48, iter 3400, loss: 2.762852, top_1: 0.537813, top_k: 0.771680, samples/s: 1727.756 1612872972.6082456
train: epoch 48, iter 3500, loss: 2.761509, top_1: 0.538711, top_k: 0.768828, samples/s: 1747.437 1612872987.2582457
train: epoch 48, iter 3600, loss: 2.758235, top_1: 0.534648, top_k: 0.767227, samples/s: 1730.363 1612873002.0527713
train: epoch 48, iter 3700, loss: 2.821203, top_1: 0.541172, top_k: 0.772031, samples/s: 1742.943 1612873016.7406192
train: epoch 48, iter 3800, loss: 2.921830, top_1: 0.540742, top_k: 0.769336, samples/s: 1739.204 1612873031.4599624
train: epoch 48, iter 3900, loss: 2.878592, top_1: 0.544844, top_k: 0.769023, samples/s: 1734.824 1612873046.2164712
train: epoch 48, iter 4000, loss: 3.145204, top_1: 0.535391, top_k: 0.771602, samples/s: 1733.161 1612873060.9872282
train: epoch 48, iter 4100, loss: 3.024382, top_1: 0.536484, top_k: 0.765391, samples/s: 1733.662 1612873075.7536407
train: epoch 48, iter 4200, loss: 2.910899, top_1: 0.534492, top_k: 0.768789, samples/s: 1734.596 1612873090.512116
train: epoch 48, iter 4300, loss: 2.852742, top_1: 0.542734, top_k: 0.775469, samples/s: 1736.028 1612873105.258461
train: epoch 48, iter 4400, loss: 2.931908, top_1: 0.540547, top_k: 0.770742, samples/s: 1743.356 1612873119.942768
train: epoch 48, iter 4500, loss: 2.794668, top_1: 0.538008, top_k: 0.769531, samples/s: 1734.912 1612873134.6985059
train: epoch 48, iter 4600, loss: 2.885040, top_1: 0.536133, top_k: 0.770430, samples/s: 1744.482 1612873149.3734264
train: epoch 48, iter 4700, loss: 2.884594, top_1: 0.535117, top_k: 0.768398, samples/s: 1728.696 1612873164.1822374
train: epoch 48, iter 4800, loss: 2.795785, top_1: 0.535195, top_k: 0.767422, samples/s: 1726.160 1612873179.0128024
train: epoch 48, iter 4900, loss: 3.002748, top_1: 0.533867, top_k: 0.769180, samples/s: 1737.997 1612873193.7424855
train: epoch 48, iter 5000, loss: 3.144576, top_1: 0.541602, top_k: 0.774258, samples/s: 1732.425 1612873208.5194466
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_48.
validation: epoch 48, iter 195, top_1: 0.577003, top_k: 0.817268, samples/s: 2849.221 1612873226.4510841
train: epoch 49, iter 100, loss: 2.835071, top_1: 0.553008, top_k: 0.781953, samples/s: 1742.835 1612873261.0720809
train: epoch 49, iter 200, loss: 2.923798, top_1: 0.545586, top_k: 0.774414, samples/s: 1768.860 1612873275.5447972
train: epoch 49, iter 300, loss: 2.875415, top_1: 0.542148, top_k: 0.772617, samples/s: 1758.737 1612873290.100622
train: epoch 49, iter 400, loss: 2.891550, top_1: 0.549805, top_k: 0.782070, samples/s: 1745.223 1612873304.7692454
train: epoch 49, iter 500, loss: 2.822203, top_1: 0.551836, top_k: 0.780312, samples/s: 1760.868 1612873319.3075392
train: epoch 49, iter 600, loss: 2.727919, top_1: 0.545781, top_k: 0.775508, samples/s: 1753.256 1612873333.908902
train: epoch 49, iter 700, loss: 2.937266, top_1: 0.536914, top_k: 0.770742, samples/s: 1741.112 1612873348.6121233
train: epoch 49, iter 800, loss: 3.054350, top_1: 0.543555, top_k: 0.775156, samples/s: 1734.623 1612873363.3704216
train: epoch 49, iter 900, loss: 2.947851, top_1: 0.539609, top_k: 0.773516, samples/s: 1726.363 1612873378.1994095
train: epoch 49, iter 1000, loss: 2.810855, top_1: 0.545312, top_k: 0.774805, samples/s: 1743.916 1612873392.8788583
train: epoch 49, iter 1100, loss: 2.839982, top_1: 0.540039, top_k: 0.767969, samples/s: 1741.351 1612873407.5800693
train: epoch 49, iter 1200, loss: 3.053022, top_1: 0.542383, top_k: 0.775312, samples/s: 1737.365 1612873422.3150344
train: epoch 49, iter 1300, loss: 2.972491, top_1: 0.540234, top_k: 0.773164, samples/s: 1737.187 1612873437.051472
train: epoch 49, iter 1400, loss: 2.866621, top_1: 0.540000, top_k: 0.770195, samples/s: 1737.720 1612873451.7834249
train: epoch 49, iter 1500, loss: 3.013586, top_1: 0.544219, top_k: 0.773164, samples/s: 1742.327 1612873466.4764578
train: epoch 49, iter 1600, loss: 3.050964, top_1: 0.540273, top_k: 0.770781, samples/s: 1740.227 1612873481.187196
train: epoch 49, iter 1700, loss: 2.782141, top_1: 0.539609, top_k: 0.771055, samples/s: 1731.855 1612873495.968986
train: epoch 49, iter 1800, loss: 3.032777, top_1: 0.540742, top_k: 0.770586, samples/s: 1744.253 1612873510.6458044
train: epoch 49, iter 1900, loss: 2.889004, top_1: 0.538594, top_k: 0.770469, samples/s: 1734.225 1612873525.4074104
train: epoch 49, iter 2000, loss: 2.672181, top_1: 0.539219, top_k: 0.775586, samples/s: 1740.919 1612873540.1123092
train: epoch 49, iter 2100, loss: 2.782966, top_1: 0.546289, top_k: 0.775273, samples/s: 1730.448 1612873554.9062827
train: epoch 49, iter 2200, loss: 3.017637, top_1: 0.540937, top_k: 0.773008, samples/s: 1752.951 1612873569.5100892
train: epoch 49, iter 2300, loss: 2.856906, top_1: 0.545039, top_k: 0.773008, samples/s: 1735.323 1612873584.2623725
train: epoch 49, iter 2400, loss: 2.789060, top_1: 0.534727, top_k: 0.772070, samples/s: 1730.807 1612873599.0531428
train: epoch 49, iter 2500, loss: 2.892258, top_1: 0.546133, top_k: 0.773633, samples/s: 1728.700 1612873613.8620133
train: epoch 49, iter 2600, loss: 3.068417, top_1: 0.533516, top_k: 0.768437, samples/s: 1741.151 1612873628.5649664
train: epoch 49, iter 2700, loss: 3.062335, top_1: 0.536016, top_k: 0.768516, samples/s: 1729.129 1612873643.370134
train: epoch 49, iter 2800, loss: 2.937313, top_1: 0.533750, top_k: 0.766289, samples/s: 1739.800 1612873658.0844045
train: epoch 49, iter 2900, loss: 2.949800, top_1: 0.538672, top_k: 0.771016, samples/s: 1736.025 1612873672.8307111
train: epoch 49, iter 3000, loss: 2.963977, top_1: 0.532617, top_k: 0.763633, samples/s: 1728.661 1612873687.6398556
train: epoch 49, iter 3100, loss: 2.768566, top_1: 0.539023, top_k: 0.768867, samples/s: 1746.725 1612873702.2958775
train: epoch 49, iter 3200, loss: 2.686457, top_1: 0.530234, top_k: 0.764687, samples/s: 1741.481 1612873716.9960408
train: epoch 49, iter 3300, loss: 2.820635, top_1: 0.537969, top_k: 0.770898, samples/s: 1735.549 1612873731.7463953
train: epoch 49, iter 3400, loss: 2.996069, top_1: 0.535781, top_k: 0.766875, samples/s: 1729.431 1612873746.5489283
train: epoch 49, iter 3500, loss: 2.941420, top_1: 0.535430, top_k: 0.763789, samples/s: 1733.438 1612873761.3173378
train: epoch 49, iter 3600, loss: 2.826505, top_1: 0.536836, top_k: 0.766523, samples/s: 1713.506 1612873776.2574267
train: epoch 49, iter 3700, loss: 2.805149, top_1: 0.538438, top_k: 0.772891, samples/s: 1748.755 1612873790.896371
train: epoch 49, iter 3800, loss: 2.844924, top_1: 0.544141, top_k: 0.769219, samples/s: 1741.865 1612873805.5933447
train: epoch 49, iter 3900, loss: 3.062829, top_1: 0.537109, top_k: 0.765664, samples/s: 1742.374 1612873820.2859488
train: epoch 49, iter 4000, loss: 2.898690, top_1: 0.539297, top_k: 0.773008, samples/s: 1734.756 1612873835.0430396
train: epoch 49, iter 4100, loss: 3.104823, top_1: 0.533203, top_k: 0.766992, samples/s: 1730.179 1612873849.8392015
train: epoch 49, iter 4200, loss: 2.816051, top_1: 0.540156, top_k: 0.772891, samples/s: 1741.512 1612873864.5390294
train: epoch 49, iter 4300, loss: 2.838869, top_1: 0.537930, top_k: 0.769570, samples/s: 1740.153 1612873879.2504113
train: epoch 49, iter 4400, loss: 2.857144, top_1: 0.541602, top_k: 0.774727, samples/s: 1742.648 1612873893.9406343
train: epoch 49, iter 4500, loss: 3.033473, top_1: 0.541328, top_k: 0.771016, samples/s: 1728.149 1612873908.754295
train: epoch 49, iter 4600, loss: 2.950369, top_1: 0.536563, top_k: 0.768242, samples/s: 1748.267 1612873923.3972552
train: epoch 49, iter 4700, loss: 3.091890, top_1: 0.538867, top_k: 0.767422, samples/s: 1736.802 1612873938.1370258
train: epoch 49, iter 4800, loss: 2.801043, top_1: 0.536875, top_k: 0.772461, samples/s: 1739.372 1612873952.8549888
train: epoch 49, iter 4900, loss: 3.054579, top_1: 0.532227, top_k: 0.765820, samples/s: 1745.597 1612873967.5204074
train: epoch 49, iter 5000, loss: 2.914227, top_1: 0.538555, top_k: 0.767852, samples/s: 1728.711 1612873982.3291488
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_49.
validation: epoch 49, iter 195, top_1: 0.581671, top_k: 0.819211, samples/s: 2926.103 1612873999.8204095
train: epoch 50, iter 100, loss: 3.017214, top_1: 0.554766, top_k: 0.781328, samples/s: 1747.150 1612874034.5967705
train: epoch 50, iter 200, loss: 3.013902, top_1: 0.546992, top_k: 0.777305, samples/s: 1749.132 1612874049.232775
train: epoch 50, iter 300, loss: 2.874749, top_1: 0.556172, top_k: 0.781719, samples/s: 1764.896 1612874063.7376986
train: epoch 50, iter 400, loss: 2.942934, top_1: 0.548203, top_k: 0.776953, samples/s: 1743.616 1612874078.4199347
train: epoch 50, iter 500, loss: 2.985169, top_1: 0.549297, top_k: 0.776055, samples/s: 1762.819 1612874092.9421074
train: epoch 50, iter 600, loss: 2.907614, top_1: 0.537930, top_k: 0.771328, samples/s: 1735.477 1612874107.6930594
train: epoch 50, iter 700, loss: 3.178757, top_1: 0.542148, top_k: 0.774922, samples/s: 1758.797 1612874122.2484722
train: epoch 50, iter 800, loss: 3.044471, top_1: 0.542891, top_k: 0.774961, samples/s: 1730.522 1612874137.0417259
train: epoch 50, iter 900, loss: 3.027478, top_1: 0.541562, top_k: 0.772500, samples/s: 1745.405 1612874151.7087817
train: epoch 50, iter 1000, loss: 3.054138, top_1: 0.544180, top_k: 0.774453, samples/s: 1744.195 1612874166.386011
train: epoch 50, iter 1100, loss: 2.915909, top_1: 0.540898, top_k: 0.774453, samples/s: 1741.012 1612874181.0900505
train: epoch 50, iter 1200, loss: 2.894509, top_1: 0.542266, top_k: 0.774062, samples/s: 1727.142 1612874195.9123528
train: epoch 50, iter 1300, loss: 2.800685, top_1: 0.545977, top_k: 0.775781, samples/s: 1747.308 1612874210.563395
train: epoch 50, iter 1400, loss: 2.902932, top_1: 0.542500, top_k: 0.773906, samples/s: 1734.126 1612874225.3258245
train: epoch 50, iter 1500, loss: 2.992407, top_1: 0.540469, top_k: 0.771836, samples/s: 1726.900 1612874240.150184
train: epoch 50, iter 1600, loss: 2.849233, top_1: 0.540078, top_k: 0.771602, samples/s: 1726.752 1612874254.9756021
train: epoch 50, iter 1700, loss: 2.822592, top_1: 0.538281, top_k: 0.772773, samples/s: 1731.994 1612874269.756282
train: epoch 50, iter 1800, loss: 2.937576, top_1: 0.548164, top_k: 0.773555, samples/s: 1743.769 1612874284.4371924
train: epoch 50, iter 1900, loss: 2.920002, top_1: 0.541133, top_k: 0.775000, samples/s: 1722.749 1612874299.2971008
train: epoch 50, iter 2000, loss: 3.013466, top_1: 0.540625, top_k: 0.773164, samples/s: 1738.192 1612874314.0250688
train: epoch 50, iter 2100, loss: 2.657600, top_1: 0.539531, top_k: 0.771680, samples/s: 1726.284 1612874328.8545547
train: epoch 50, iter 2200, loss: 3.081995, top_1: 0.541797, top_k: 0.771055, samples/s: 1748.267 1612874343.4976351
train: epoch 50, iter 2300, loss: 2.825324, top_1: 0.538906, top_k: 0.768125, samples/s: 1726.615 1612874358.3243248
train: epoch 50, iter 2400, loss: 2.882705, top_1: 0.545742, top_k: 0.771289, samples/s: 1726.596 1612874373.151307
train: epoch 50, iter 2500, loss: 2.946960, top_1: 0.541836, top_k: 0.773164, samples/s: 1753.870 1612874387.7474754
train: epoch 50, iter 2600, loss: 3.030131, top_1: 0.540937, top_k: 0.771992, samples/s: 1743.154 1612874402.433503
train: epoch 50, iter 2700, loss: 2.842258, top_1: 0.535039, top_k: 0.770938, samples/s: 1721.017 1612874417.3084686
train: epoch 50, iter 2800, loss: 2.871902, top_1: 0.535820, top_k: 0.767070, samples/s: 1740.089 1612874432.0203693
train: epoch 50, iter 2900, loss: 2.903287, top_1: 0.537813, top_k: 0.770195, samples/s: 1731.846 1612874446.8022547
train: epoch 50, iter 3000, loss: 2.904337, top_1: 0.543047, top_k: 0.772500, samples/s: 1739.566 1612874461.5187626
train: epoch 50, iter 3100, loss: 2.977193, top_1: 0.540156, top_k: 0.771719, samples/s: 1714.726 1612874476.4480789
train: epoch 50, iter 3200, loss: 2.839959, top_1: 0.545977, top_k: 0.777891, samples/s: 1741.259 1612874491.1501231
train: epoch 50, iter 3300, loss: 2.814249, top_1: 0.540781, top_k: 0.774727, samples/s: 1732.414 1612874505.9272084
train: epoch 50, iter 3400, loss: 2.717113, top_1: 0.538984, top_k: 0.769727, samples/s: 1738.536 1612874520.6522365
train: epoch 50, iter 3500, loss: 2.895146, top_1: 0.539180, top_k: 0.768867, samples/s: 1726.689 1612874535.4791713
train: epoch 50, iter 3600, loss: 2.883363, top_1: 0.536484, top_k: 0.772695, samples/s: 1738.613 1612874550.202716
train: epoch 50, iter 3700, loss: 2.831234, top_1: 0.537383, top_k: 0.772031, samples/s: 1726.489 1612874565.0307739
train: epoch 50, iter 3800, loss: 2.912975, top_1: 0.535273, top_k: 0.770742, samples/s: 1726.018 1612874579.862293
train: epoch 50, iter 3900, loss: 2.938798, top_1: 0.541992, top_k: 0.773906, samples/s: 1744.490 1612874594.5370665
train: epoch 50, iter 4000, loss: 2.860779, top_1: 0.535820, top_k: 0.771172, samples/s: 1746.532 1612874609.1946325
train: epoch 50, iter 4100, loss: 2.898706, top_1: 0.537422, top_k: 0.774414, samples/s: 1730.328 1612874623.989652
train: epoch 50, iter 4200, loss: 2.943819, top_1: 0.536289, top_k: 0.767188, samples/s: 1729.416 1612874638.7922206
train: epoch 50, iter 4300, loss: 2.999445, top_1: 0.540391, top_k: 0.766250, samples/s: 1742.446 1612874653.4841838
train: epoch 50, iter 4400, loss: 2.830111, top_1: 0.543594, top_k: 0.774961, samples/s: 1732.217 1612874668.263036
train: epoch 50, iter 4500, loss: 2.849564, top_1: 0.541250, top_k: 0.770547, samples/s: 1742.437 1612874682.9549947
train: epoch 50, iter 4600, loss: 2.786006, top_1: 0.538125, top_k: 0.769766, samples/s: 1732.122 1612874697.7346215
train: epoch 50, iter 4700, loss: 2.645228, top_1: 0.537852, top_k: 0.767422, samples/s: 1734.710 1612874712.4920628
train: epoch 50, iter 4800, loss: 3.015229, top_1: 0.541250, top_k: 0.771992, samples/s: 1738.403 1612874727.218352
train: epoch 50, iter 4900, loss: 2.970419, top_1: 0.536563, top_k: 0.767969, samples/s: 1731.412 1612874742.0039573
train: epoch 50, iter 5000, loss: 2.795573, top_1: 0.545664, top_k: 0.773750, samples/s: 1734.698 1612874756.7614565
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_50.
validation: epoch 50, iter 195, top_1: 0.582612, top_k: 0.818269, samples/s: 2843.503 1612874774.767251
train: epoch 51, iter 100, loss: 2.604064, top_1: 0.545977, top_k: 0.775820, samples/s: 1752.000 1612874809.3470857
train: epoch 51, iter 200, loss: 2.886295, top_1: 0.550234, top_k: 0.781719, samples/s: 1757.577 1612874823.9125397
train: epoch 51, iter 300, loss: 3.156868, top_1: 0.538281, top_k: 0.767383, samples/s: 1758.646 1612874838.4692378
train: epoch 51, iter 400, loss: 2.815381, top_1: 0.544492, top_k: 0.777539, samples/s: 1758.594 1612874853.0262387
train: epoch 51, iter 500, loss: 2.816685, top_1: 0.551016, top_k: 0.781172, samples/s: 1756.703 1612874867.5990195
train: epoch 51, iter 600, loss: 2.873376, top_1: 0.544297, top_k: 0.774883, samples/s: 1759.937 1612874882.1449904
train: epoch 51, iter 700, loss: 2.856324, top_1: 0.545508, top_k: 0.778828, samples/s: 1738.500 1612874896.8702884
train: epoch 51, iter 800, loss: 2.922238, top_1: 0.551094, top_k: 0.781289, samples/s: 1754.038 1612874911.4652154
train: epoch 51, iter 900, loss: 2.832992, top_1: 0.547383, top_k: 0.778242, samples/s: 1730.456 1612874926.258963
train: epoch 51, iter 1000, loss: 3.063488, top_1: 0.549805, top_k: 0.777891, samples/s: 1730.538 1612874941.0520449
train: epoch 51, iter 1100, loss: 2.780886, top_1: 0.544258, top_k: 0.773164, samples/s: 1742.425 1612874955.7442975
train: epoch 51, iter 1200, loss: 2.757149, top_1: 0.547227, top_k: 0.775547, samples/s: 1737.892 1612874970.4747086
train: epoch 51, iter 1300, loss: 2.865384, top_1: 0.540156, top_k: 0.773438, samples/s: 1729.564 1612874985.2761862
train: epoch 51, iter 1400, loss: 2.884187, top_1: 0.543867, top_k: 0.775625, samples/s: 1720.023 1612875000.1596522
train: epoch 51, iter 1500, loss: 3.168585, top_1: 0.548672, top_k: 0.775898, samples/s: 1750.568 1612875014.7836
train: epoch 51, iter 1600, loss: 2.857981, top_1: 0.540117, top_k: 0.769141, samples/s: 1735.762 1612875029.5320947
train: epoch 51, iter 1700, loss: 2.785484, top_1: 0.546328, top_k: 0.771563, samples/s: 1731.514 1612875044.3167908
train: epoch 51, iter 1800, loss: 2.842682, top_1: 0.544180, top_k: 0.776289, samples/s: 1732.497 1612875059.0931466
train: epoch 51, iter 1900, loss: 2.970304, top_1: 0.544336, top_k: 0.774961, samples/s: 1732.914 1612875073.8660216
train: epoch 51, iter 2000, loss: 2.814646, top_1: 0.545352, top_k: 0.775117, samples/s: 1730.823 1612875088.6566513
train: epoch 51, iter 2100, loss: 3.019989, top_1: 0.543594, top_k: 0.771875, samples/s: 1742.675 1612875103.3466716
train: epoch 51, iter 2200, loss: 2.743680, top_1: 0.545586, top_k: 0.775859, samples/s: 1728.763 1612875118.155066
train: epoch 51, iter 2300, loss: 2.860419, top_1: 0.549883, top_k: 0.775117, samples/s: 1752.094 1612875132.7660973
train: epoch 51, iter 2400, loss: 2.905890, top_1: 0.543672, top_k: 0.775547, samples/s: 1728.976 1612875147.5724857
train: epoch 51, iter 2500, loss: 2.872286, top_1: 0.541328, top_k: 0.770859, samples/s: 1740.162 1612875162.2837725
train: epoch 51, iter 2600, loss: 3.088444, top_1: 0.546328, top_k: 0.779414, samples/s: 1722.019 1612875177.1500733
train: epoch 51, iter 2700, loss: 2.864058, top_1: 0.541992, top_k: 0.770664, samples/s: 1742.206 1612875191.8441446
train: epoch 51, iter 2800, loss: 2.803366, top_1: 0.532578, top_k: 0.768164, samples/s: 1729.124 1612875206.6492653
train: epoch 51, iter 2900, loss: 2.890562, top_1: 0.541133, top_k: 0.773711, samples/s: 1740.515 1612875221.357569
train: epoch 51, iter 3000, loss: 2.843265, top_1: 0.538477, top_k: 0.769570, samples/s: 1741.090 1612875236.0609617
train: epoch 51, iter 3100, loss: 2.760827, top_1: 0.538633, top_k: 0.773359, samples/s: 1716.299 1612875250.976774
train: epoch 51, iter 3200, loss: 2.859274, top_1: 0.543320, top_k: 0.774883, samples/s: 1736.476 1612875265.7192855
train: epoch 51, iter 3300, loss: 2.878179, top_1: 0.541172, top_k: 0.772266, samples/s: 1731.218 1612875280.5066025
train: epoch 51, iter 3400, loss: 2.919553, top_1: 0.540156, top_k: 0.771484, samples/s: 1725.823 1612875295.3400767
train: epoch 51, iter 3500, loss: 2.908943, top_1: 0.545859, top_k: 0.771641, samples/s: 1741.491 1612875310.0401146
train: epoch 51, iter 3600, loss: 2.827637, top_1: 0.545586, top_k: 0.774180, samples/s: 1730.632 1612875324.8324802
train: epoch 51, iter 3700, loss: 2.923961, top_1: 0.543281, top_k: 0.771211, samples/s: 1722.619 1612875339.6935828
train: epoch 51, iter 3800, loss: 2.639240, top_1: 0.537578, top_k: 0.767539, samples/s: 1726.744 1612875354.5192802
train: epoch 51, iter 3900, loss: 2.896365, top_1: 0.542734, top_k: 0.775547, samples/s: 1734.066 1612875369.2821624
train: epoch 51, iter 4000, loss: 3.025805, top_1: 0.549414, top_k: 0.774766, samples/s: 1755.033 1612875383.8686824
train: epoch 51, iter 4100, loss: 2.893635, top_1: 0.539570, top_k: 0.770820, samples/s: 1727.966 1612875398.683799
train: epoch 51, iter 4200, loss: 2.904721, top_1: 0.544102, top_k: 0.775430, samples/s: 1728.206 1612875413.4969685
train: epoch 51, iter 4300, loss: 2.886193, top_1: 0.534219, top_k: 0.767773, samples/s: 1734.623 1612875428.2551043
train: epoch 51, iter 4400, loss: 3.350521, top_1: 0.505273, top_k: 0.744961, samples/s: 1728.508 1612875443.0656567
train: epoch 51, iter 4500, loss: 3.221158, top_1: 0.501836, top_k: 0.737539, samples/s: 1735.950 1612875457.8125203
train: epoch 51, iter 4600, loss: 2.833629, top_1: 0.526328, top_k: 0.757383, samples/s: 1735.165 1612875472.566297
train: epoch 51, iter 4700, loss: 3.183516, top_1: 0.528906, top_k: 0.759922, samples/s: 1740.806 1612875487.2720346
train: epoch 51, iter 4800, loss: 3.182814, top_1: 0.528164, top_k: 0.759727, samples/s: 1741.423 1612875501.9726086
train: epoch 51, iter 4900, loss: 2.848240, top_1: 0.529336, top_k: 0.761602, samples/s: 1739.447 1612875516.6899595
train: epoch 51, iter 5000, loss: 3.072380, top_1: 0.536133, top_k: 0.766563, samples/s: 1736.898 1612875531.4288445
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_51.
validation: epoch 51, iter 195, top_1: 0.564563, top_k: 0.804006, samples/s: 2877.917 1612875549.2409084
train: epoch 52, iter 100, loss: 2.918272, top_1: 0.542266, top_k: 0.773828, samples/s: 1753.948 1612875584.7561738
train: epoch 52, iter 200, loss: 2.830649, top_1: 0.539844, top_k: 0.773477, samples/s: 1760.394 1612875599.2983668
train: epoch 52, iter 300, loss: 3.109962, top_1: 0.552031, top_k: 0.775078, samples/s: 1752.589 1612875613.9052854
train: epoch 52, iter 400, loss: 3.149990, top_1: 0.542617, top_k: 0.773086, samples/s: 1755.249 1612875628.4900916
train: epoch 52, iter 500, loss: 2.733002, top_1: 0.543828, top_k: 0.775859, samples/s: 1755.439 1612875643.0733566
train: epoch 52, iter 600, loss: 3.084739, top_1: 0.542930, top_k: 0.776563, samples/s: 1766.747 1612875657.563303
train: epoch 52, iter 700, loss: 2.809714, top_1: 0.548594, top_k: 0.777734, samples/s: 1734.652 1612875672.3212316
train: epoch 52, iter 800, loss: 3.046891, top_1: 0.550625, top_k: 0.780078, samples/s: 1740.127 1612875687.0328526
train: epoch 52, iter 900, loss: 2.942110, top_1: 0.537344, top_k: 0.770508, samples/s: 1739.988 1612875701.745548
train: epoch 52, iter 1000, loss: 3.203063, top_1: 0.538203, top_k: 0.771992, samples/s: 1735.673 1612875716.4949336
train: epoch 52, iter 1100, loss: 2.967391, top_1: 0.542578, top_k: 0.775039, samples/s: 1727.067 1612875731.3177333
train: epoch 52, iter 1200, loss: 2.755940, top_1: 0.549258, top_k: 0.776211, samples/s: 1735.882 1612875746.0652518
train: epoch 52, iter 1300, loss: 2.789357, top_1: 0.546875, top_k: 0.778477, samples/s: 1727.812 1612875760.8816776
train: epoch 52, iter 1400, loss: 2.855112, top_1: 0.541953, top_k: 0.775547, samples/s: 1742.799 1612875775.5706854
train: epoch 52, iter 1500, loss: 2.756277, top_1: 0.533789, top_k: 0.768828, samples/s: 1728.332 1612875790.3827066
train: epoch 52, iter 1600, loss: 2.901185, top_1: 0.539883, top_k: 0.774102, samples/s: 1742.806 1612875805.0716083
train: epoch 52, iter 1700, loss: 3.023836, top_1: 0.545820, top_k: 0.777578, samples/s: 1730.609 1612875819.8641083
train: epoch 52, iter 1800, loss: 2.920578, top_1: 0.547148, top_k: 0.774883, samples/s: 1737.301 1612875834.5996468
train: epoch 52, iter 1900, loss: 2.862948, top_1: 0.544023, top_k: 0.773516, samples/s: 1733.205 1612875849.369968
train: epoch 52, iter 2000, loss: 2.977175, top_1: 0.538945, top_k: 0.768867, samples/s: 1749.159 1612875864.005557
train: epoch 52, iter 2100, loss: 3.135803, top_1: 0.541680, top_k: 0.775977, samples/s: 1733.317 1612875878.7749636
train: epoch 52, iter 2200, loss: 2.915548, top_1: 0.539023, top_k: 0.774414, samples/s: 1725.356 1612875893.612479
train: epoch 52, iter 2300, loss: 2.728123, top_1: 0.546094, top_k: 0.776211, samples/s: 1731.864 1612875908.394256
train: epoch 52, iter 2400, loss: 2.987679, top_1: 0.540625, top_k: 0.771211, samples/s: 1742.747 1612875923.083615
train: epoch 52, iter 2500, loss: 2.862414, top_1: 0.541016, top_k: 0.772930, samples/s: 1731.405 1612875937.8693025
train: epoch 52, iter 2600, loss: 3.020956, top_1: 0.545000, top_k: 0.775781, samples/s: 1738.832 1612875952.5918255
train: epoch 52, iter 2700, loss: 2.829712, top_1: 0.543359, top_k: 0.772344, samples/s: 1737.929 1612875967.322058
train: epoch 52, iter 2800, loss: 2.852328, top_1: 0.536445, top_k: 0.767461, samples/s: 1743.118 1612875982.0083601
train: epoch 52, iter 2900, loss: 2.782641, top_1: 0.544336, top_k: 0.777539, samples/s: 1739.570 1612875996.7246864
train: epoch 52, iter 3000, loss: 2.921727, top_1: 0.539922, top_k: 0.771953, samples/s: 1739.363 1612876011.442731
train: epoch 52, iter 3100, loss: 3.032083, top_1: 0.542734, top_k: 0.772617, samples/s: 1735.440 1612876026.1939385
train: epoch 52, iter 3200, loss: 2.848953, top_1: 0.540820, top_k: 0.768984, samples/s: 1738.626 1612876040.918239
train: epoch 52, iter 3300, loss: 2.865453, top_1: 0.542734, top_k: 0.770156, samples/s: 1742.671 1612876055.6083517
train: epoch 52, iter 3400, loss: 3.219991, top_1: 0.543828, top_k: 0.769297, samples/s: 1726.707 1612876070.4342282
train: epoch 52, iter 3500, loss: 2.932393, top_1: 0.545820, top_k: 0.773125, samples/s: 1736.020 1612876085.1805887
train: epoch 52, iter 3600, loss: 3.055137, top_1: 0.544180, top_k: 0.774414, samples/s: 1735.420 1612876099.932055
train: epoch 52, iter 3700, loss: 3.076487, top_1: 0.540391, top_k: 0.770117, samples/s: 1731.150 1612876114.719995
train: epoch 52, iter 3800, loss: 2.894616, top_1: 0.541523, top_k: 0.774609, samples/s: 1736.471 1612876129.4625285
train: epoch 52, iter 3900, loss: 2.984209, top_1: 0.542578, top_k: 0.773242, samples/s: 1729.196 1612876144.2671366
train: epoch 52, iter 4000, loss: 2.818649, top_1: 0.543164, top_k: 0.777695, samples/s: 1754.410 1612876158.8588748
train: epoch 52, iter 4100, loss: 3.061502, top_1: 0.544375, top_k: 0.773906, samples/s: 1735.815 1612876173.6069355
train: epoch 52, iter 4200, loss: 2.982374, top_1: 0.537383, top_k: 0.772188, samples/s: 1742.167 1612876188.3013837
train: epoch 52, iter 4300, loss: 2.842933, top_1: 0.539922, top_k: 0.768242, samples/s: 1741.655 1612876202.999984
train: epoch 52, iter 4400, loss: 3.056862, top_1: 0.546680, top_k: 0.773984, samples/s: 1720.455 1612876217.879697
train: epoch 52, iter 4500, loss: 2.707863, top_1: 0.536484, top_k: 0.768320, samples/s: 1753.989 1612876232.4750295
train: epoch 52, iter 4600, loss: 3.036024, top_1: 0.536094, top_k: 0.772227, samples/s: 1735.399 1612876247.2267869
train: epoch 52, iter 4700, loss: 2.928295, top_1: 0.539805, top_k: 0.774219, samples/s: 1730.310 1612876262.0217173
train: epoch 52, iter 4800, loss: 2.825396, top_1: 0.538438, top_k: 0.771914, samples/s: 1741.741 1612876276.7197516
train: epoch 52, iter 4900, loss: 2.951331, top_1: 0.541133, top_k: 0.770508, samples/s: 1735.578 1612876291.4698296
train: epoch 52, iter 5000, loss: 2.934761, top_1: 0.546992, top_k: 0.777031, samples/s: 1725.388 1612876306.307152
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_52.
validation: epoch 52, iter 195, top_1: 0.584936, top_k: 0.824139, samples/s: 2840.450 1612876324.244431
train: epoch 53, iter 100, loss: 2.818450, top_1: 0.548281, top_k: 0.782031, samples/s: 1745.654 1612876359.9990475
train: epoch 53, iter 200, loss: 2.927599, top_1: 0.550586, top_k: 0.779844, samples/s: 1756.780 1612876374.5711186
train: epoch 53, iter 300, loss: 2.740976, top_1: 0.547344, top_k: 0.779336, samples/s: 1754.323 1612876389.163649
train: epoch 53, iter 400, loss: 2.918431, top_1: 0.544922, top_k: 0.778203, samples/s: 1748.421 1612876403.8054223
train: epoch 53, iter 500, loss: 2.795729, top_1: 0.547930, top_k: 0.779258, samples/s: 1763.913 1612876418.3185997
train: epoch 53, iter 600, loss: 2.875816, top_1: 0.546172, top_k: 0.777383, samples/s: 1754.183 1612876432.9123232
train: epoch 53, iter 700, loss: 2.789651, top_1: 0.553398, top_k: 0.779375, samples/s: 1752.883 1612876447.5168467
train: epoch 53, iter 800, loss: 2.790717, top_1: 0.552070, top_k: 0.777969, samples/s: 1742.466 1612876462.2085752
train: epoch 53, iter 900, loss: 2.972825, top_1: 0.549258, top_k: 0.781797, samples/s: 1732.416 1612876476.9857407
train: epoch 53, iter 1000, loss: 2.850240, top_1: 0.552266, top_k: 0.778477, samples/s: 1733.053 1612876491.7573583
train: epoch 53, iter 1100, loss: 2.794340, top_1: 0.549023, top_k: 0.777773, samples/s: 1745.516 1612876506.4234324
train: epoch 53, iter 1200, loss: 2.760756, top_1: 0.550625, top_k: 0.781445, samples/s: 1730.966 1612876521.212827
train: epoch 53, iter 1300, loss: 2.723000, top_1: 0.551445, top_k: 0.779219, samples/s: 1744.036 1612876535.891416
train: epoch 53, iter 1400, loss: 3.057653, top_1: 0.541953, top_k: 0.773828, samples/s: 1738.258 1612876550.618795
train: epoch 53, iter 1500, loss: 2.767313, top_1: 0.544805, top_k: 0.775508, samples/s: 1744.241 1612876565.2956805
train: epoch 53, iter 1600, loss: 3.063062, top_1: 0.547969, top_k: 0.776602, samples/s: 1740.009 1612876580.0082436
train: epoch 53, iter 1700, loss: 2.867392, top_1: 0.549414, top_k: 0.780703, samples/s: 1740.780 1612876594.7142906
train: epoch 53, iter 1800, loss: 2.876336, top_1: 0.547031, top_k: 0.774023, samples/s: 1737.504 1612876609.4481864
train: epoch 53, iter 1900, loss: 2.724574, top_1: 0.546328, top_k: 0.774492, samples/s: 1727.492 1612876624.2672708
train: epoch 53, iter 2000, loss: 2.854425, top_1: 0.541953, top_k: 0.776680, samples/s: 1731.213 1612876639.054575
train: epoch 53, iter 2100, loss: 2.987425, top_1: 0.545117, top_k: 0.774336, samples/s: 1740.134 1612876653.7661145
train: epoch 53, iter 2200, loss: 3.020440, top_1: 0.545508, top_k: 0.777773, samples/s: 1738.604 1612876668.4906075
train: epoch 53, iter 2300, loss: 2.868061, top_1: 0.544570, top_k: 0.778984, samples/s: 1722.696 1612876683.35103
train: epoch 53, iter 2400, loss: 2.879784, top_1: 0.544219, top_k: 0.776133, samples/s: 1747.084 1612876698.0039537
train: epoch 53, iter 2500, loss: 2.974734, top_1: 0.547305, top_k: 0.777813, samples/s: 1731.725 1612876712.7869606
train: epoch 53, iter 2600, loss: 2.811119, top_1: 0.541836, top_k: 0.771406, samples/s: 1727.785 1612876727.603559
train: epoch 53, iter 2700, loss: 2.977273, top_1: 0.539648, top_k: 0.772500, samples/s: 1736.806 1612876742.343308
train: epoch 53, iter 2800, loss: 2.577708, top_1: 0.542188, top_k: 0.771602, samples/s: 1729.635 1612876757.1440818
train: epoch 53, iter 2900, loss: 3.012280, top_1: 0.543008, top_k: 0.772773, samples/s: 1731.130 1612876771.9321065
train: epoch 53, iter 3000, loss: 2.984552, top_1: 0.541758, top_k: 0.772891, samples/s: 1732.504 1612876786.7084355
train: epoch 53, iter 3100, loss: 3.027649, top_1: 0.543086, top_k: 0.775820, samples/s: 1740.125 1612876801.419991
train: epoch 53, iter 3200, loss: 3.084835, top_1: 0.543594, top_k: 0.773750, samples/s: 1734.392 1612876816.1802058
train: epoch 53, iter 3300, loss: 2.792569, top_1: 0.550977, top_k: 0.774180, samples/s: 1757.809 1612876830.743785
train: epoch 53, iter 3400, loss: 2.692685, top_1: 0.543477, top_k: 0.777305, samples/s: 1748.242 1612876845.3870842
train: epoch 53, iter 3500, loss: 2.680501, top_1: 0.542539, top_k: 0.774336, samples/s: 1752.008 1612876859.998907
train: epoch 53, iter 3600, loss: 2.857133, top_1: 0.541562, top_k: 0.773086, samples/s: 1748.296 1612876874.6416988
train: epoch 53, iter 3700, loss: 2.780668, top_1: 0.540430, top_k: 0.770859, samples/s: 1746.282 1612876889.3014457
train: epoch 53, iter 3800, loss: 3.087704, top_1: 0.542734, top_k: 0.772813, samples/s: 1753.186 1612876903.9034038
train: epoch 53, iter 3900, loss: 3.079086, top_1: 0.540586, top_k: 0.775273, samples/s: 1751.562 1612876918.5189848
train: epoch 53, iter 4000, loss: 2.996958, top_1: 0.540898, top_k: 0.771328, samples/s: 1744.293 1612876933.1953733
train: epoch 53, iter 4100, loss: 2.902449, top_1: 0.541719, top_k: 0.772266, samples/s: 1753.245 1612876947.796877
train: epoch 53, iter 4200, loss: 2.909634, top_1: 0.543203, top_k: 0.774180, samples/s: 1741.613 1612876962.4958794
train: epoch 53, iter 4300, loss: 2.874330, top_1: 0.545977, top_k: 0.777578, samples/s: 1742.323 1612876977.1890066
train: epoch 53, iter 4400, loss: 2.931665, top_1: 0.542773, top_k: 0.772891, samples/s: 1740.861 1612876991.894277
train: epoch 53, iter 4500, loss: 2.865422, top_1: 0.546523, top_k: 0.777617, samples/s: 1739.237 1612877006.613362
train: epoch 53, iter 4600, loss: 2.828499, top_1: 0.539883, top_k: 0.771914, samples/s: 1737.143 1612877021.35022
train: epoch 53, iter 4700, loss: 2.846518, top_1: 0.537969, top_k: 0.770078, samples/s: 1743.455 1612877036.0337014
train: epoch 53, iter 4800, loss: 2.870934, top_1: 0.542813, top_k: 0.778203, samples/s: 1749.200 1612877050.6689637
train: epoch 53, iter 4900, loss: 3.001230, top_1: 0.543164, top_k: 0.775039, samples/s: 1745.426 1612877065.3358834
train: epoch 53, iter 5000, loss: 3.077675, top_1: 0.540273, top_k: 0.773125, samples/s: 1744.675 1612877080.0091572
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_53.
validation: epoch 53, iter 195, top_1: 0.590805, top_k: 0.822135, samples/s: 2858.787 1612877097.8540823
train: epoch 54, iter 100, loss: 2.837921, top_1: 0.557109, top_k: 0.787422, samples/s: 1750.899 1612877133.4071069
train: epoch 54, iter 200, loss: 2.852635, top_1: 0.553203, top_k: 0.782383, samples/s: 1754.208 1612877148.0007963
train: epoch 54, iter 300, loss: 2.842667, top_1: 0.545234, top_k: 0.780391, samples/s: 1757.915 1612877162.5633473
train: epoch 54, iter 400, loss: 2.962339, top_1: 0.550234, top_k: 0.775703, samples/s: 1755.089 1612877177.1494918
train: epoch 54, iter 500, loss: 2.707207, top_1: 0.551133, top_k: 0.779727, samples/s: 1757.651 1612877191.7143645
train: epoch 54, iter 600, loss: 2.811997, top_1: 0.554297, top_k: 0.783672, samples/s: 1751.278 1612877206.33225
train: epoch 54, iter 700, loss: 2.860127, top_1: 0.553867, top_k: 0.782422, samples/s: 1760.994 1612877220.869521
train: epoch 54, iter 800, loss: 2.916998, top_1: 0.544687, top_k: 0.775000, samples/s: 1752.243 1612877235.479305
train: epoch 54, iter 900, loss: 2.781738, top_1: 0.549766, top_k: 0.776992, samples/s: 1728.371 1612877250.290952
train: epoch 54, iter 1000, loss: 2.958076, top_1: 0.544648, top_k: 0.776094, samples/s: 1744.335 1612877264.9675543
train: epoch 54, iter 1100, loss: 2.912920, top_1: 0.542813, top_k: 0.769766, samples/s: 1745.842 1612877279.6304379
train: epoch 54, iter 1200, loss: 2.724533, top_1: 0.550312, top_k: 0.779883, samples/s: 1733.783 1612877294.3961842
train: epoch 54, iter 1300, loss: 2.785991, top_1: 0.549258, top_k: 0.773281, samples/s: 1739.809 1612877309.1100998
train: epoch 54, iter 1400, loss: 2.934813, top_1: 0.549258, top_k: 0.779609, samples/s: 1741.698 1612877323.808444
train: epoch 54, iter 1500, loss: 2.834200, top_1: 0.546719, top_k: 0.776641, samples/s: 1741.425 1612877338.5089962
train: epoch 54, iter 1600, loss: 2.901379, top_1: 0.547578, top_k: 0.776289, samples/s: 1739.991 1612877353.2217114
train: epoch 54, iter 1700, loss: 2.697692, top_1: 0.543047, top_k: 0.778125, samples/s: 1743.325 1612877367.906333
train: epoch 54, iter 1800, loss: 2.855321, top_1: 0.549102, top_k: 0.778750, samples/s: 1740.116 1612877382.6183972
train: epoch 54, iter 1900, loss: 2.864797, top_1: 0.550195, top_k: 0.776719, samples/s: 1744.534 1612877397.29237
train: epoch 54, iter 2000, loss: 2.962047, top_1: 0.553125, top_k: 0.782383, samples/s: 1743.235 1612877411.977715
train: epoch 54, iter 2100, loss: 2.807105, top_1: 0.552617, top_k: 0.779727, samples/s: 1733.190 1612877426.748244
train: epoch 54, iter 2200, loss: 2.842609, top_1: 0.543750, top_k: 0.778203, samples/s: 1718.916 1612877441.641671
train: epoch 54, iter 2300, loss: 2.855007, top_1: 0.544648, top_k: 0.772930, samples/s: 1735.685 1612877456.3905332
train: epoch 54, iter 2400, loss: 2.905760, top_1: 0.545508, top_k: 0.778750, samples/s: 1736.887 1612877471.1295106
train: epoch 54, iter 2500, loss: 2.619137, top_1: 0.551523, top_k: 0.777656, samples/s: 1737.200 1612877485.8658955
train: epoch 54, iter 2600, loss: 2.868365, top_1: 0.542656, top_k: 0.774336, samples/s: 1732.961 1612877500.63828
train: epoch 54, iter 2700, loss: 3.030326, top_1: 0.545586, top_k: 0.777891, samples/s: 1742.618 1612877515.3288128
train: epoch 54, iter 2800, loss: 2.966584, top_1: 0.548008, top_k: 0.773125, samples/s: 1729.269 1612877530.1327865
train: epoch 54, iter 2900, loss: 2.830180, top_1: 0.541758, top_k: 0.772070, samples/s: 1742.579 1612877544.8236141
train: epoch 54, iter 3000, loss: 2.891141, top_1: 0.544609, top_k: 0.775781, samples/s: 1737.095 1612877559.5609152
train: epoch 54, iter 3100, loss: 2.586184, top_1: 0.542813, top_k: 0.775898, samples/s: 1742.698 1612877574.2507193
train: epoch 54, iter 3200, loss: 2.964475, top_1: 0.543789, top_k: 0.770469, samples/s: 1726.678 1612877589.076959
train: epoch 54, iter 3300, loss: 2.956797, top_1: 0.548945, top_k: 0.780156, samples/s: 1748.993 1612877603.7138813
train: epoch 54, iter 3400, loss: 2.961469, top_1: 0.544922, top_k: 0.775391, samples/s: 1736.854 1612877618.453162
train: epoch 54, iter 3500, loss: 2.892996, top_1: 0.546016, top_k: 0.777539, samples/s: 1724.649 1612877633.2967813
train: epoch 54, iter 3600, loss: 2.901760, top_1: 0.544414, top_k: 0.775430, samples/s: 1740.828 1612877648.0028806
train: epoch 54, iter 3700, loss: 2.804894, top_1: 0.540391, top_k: 0.774805, samples/s: 1734.826 1612877662.758967
train: epoch 54, iter 3800, loss: 2.755089, top_1: 0.547148, top_k: 0.780508, samples/s: 1735.095 1612877677.513264
train: epoch 54, iter 3900, loss: 2.965331, top_1: 0.544844, top_k: 0.776523, samples/s: 1744.800 1612877692.1854012
train: epoch 54, iter 4000, loss: 2.927863, top_1: 0.543203, top_k: 0.775391, samples/s: 1732.707 1612877706.959993
train: epoch 54, iter 4100, loss: 2.855972, top_1: 0.539297, top_k: 0.775039, samples/s: 1734.074 1612877721.7231357
train: epoch 54, iter 4200, loss: 2.890448, top_1: 0.536328, top_k: 0.767109, samples/s: 1737.100 1612877736.4600778
train: epoch 54, iter 4300, loss: 2.867655, top_1: 0.547422, top_k: 0.778242, samples/s: 1729.568 1612877751.2614305
train: epoch 54, iter 4400, loss: 2.907074, top_1: 0.545039, top_k: 0.775937, samples/s: 1714.355 1612877766.1942616
train: epoch 54, iter 4500, loss: 2.993850, top_1: 0.540352, top_k: 0.775195, samples/s: 1753.691 1612877780.7919612
train: epoch 54, iter 4600, loss: 2.632383, top_1: 0.547109, top_k: 0.777578, samples/s: 1735.592 1612877795.5419333
train: epoch 54, iter 4700, loss: 2.969706, top_1: 0.536602, top_k: 0.773086, samples/s: 1737.562 1612877810.2752638
train: epoch 54, iter 4800, loss: 2.891229, top_1: 0.542383, top_k: 0.770000, samples/s: 1738.671 1612877824.9992423
train: epoch 54, iter 4900, loss: 3.022083, top_1: 0.544219, top_k: 0.770430, samples/s: 1738.326 1612877839.7264016
train: epoch 54, iter 5000, loss: 3.029921, top_1: 0.547188, top_k: 0.773984, samples/s: 1721.941 1612877854.592888
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_54.
validation: epoch 54, iter 195, top_1: 0.595573, top_k: 0.827845, samples/s: 2856.972 1612877872.460262
train: epoch 55, iter 100, loss: 2.704042, top_1: 0.558320, top_k: 0.785078, samples/s: 1756.341 1612877907.1405263
train: epoch 55, iter 200, loss: 2.900017, top_1: 0.549531, top_k: 0.780508, samples/s: 1758.097 1612877921.7019768
train: epoch 55, iter 300, loss: 2.790957, top_1: 0.550547, top_k: 0.776680, samples/s: 1757.832 1612877936.265036
train: epoch 55, iter 400, loss: 2.918052, top_1: 0.550898, top_k: 0.781758, samples/s: 1749.784 1612877950.8954334
train: epoch 55, iter 500, loss: 2.844663, top_1: 0.554766, top_k: 0.779766, samples/s: 1755.359 1612877965.4794142
train: epoch 55, iter 600, loss: 2.822381, top_1: 0.559453, top_k: 0.785078, samples/s: 1755.321 1612877980.0639286
train: epoch 55, iter 700, loss: 3.064741, top_1: 0.553359, top_k: 0.782617, samples/s: 1733.244 1612877994.8335474
train: epoch 55, iter 800, loss: 2.969200, top_1: 0.545937, top_k: 0.774023, samples/s: 1739.597 1612878009.5500782
train: epoch 55, iter 900, loss: 2.833560, top_1: 0.546484, top_k: 0.777852, samples/s: 1733.672 1612878024.3159497
train: epoch 55, iter 1000, loss: 2.994088, top_1: 0.552969, top_k: 0.781484, samples/s: 1727.662 1612878039.133743
train: epoch 55, iter 1100, loss: 2.895693, top_1: 0.545469, top_k: 0.776992, samples/s: 1745.792 1612878053.797464
train: epoch 55, iter 1200, loss: 2.712886, top_1: 0.546055, top_k: 0.778281, samples/s: 1743.280 1612878068.4825134
train: epoch 55, iter 1300, loss: 2.826962, top_1: 0.549297, top_k: 0.781758, samples/s: 1735.573 1612878083.23262
train: epoch 55, iter 1400, loss: 2.939896, top_1: 0.546094, top_k: 0.774883, samples/s: 1719.412 1612878098.1214118
train: epoch 55, iter 1500, loss: 3.008765, top_1: 0.549961, top_k: 0.779102, samples/s: 1734.118 1612878112.8840785
train: epoch 55, iter 1600, loss: 3.042550, top_1: 0.544063, top_k: 0.774922, samples/s: 1723.326 1612878127.7393372
train: epoch 55, iter 1700, loss: 2.949267, top_1: 0.548789, top_k: 0.779609, samples/s: 1733.758 1612878142.5046122
train: epoch 55, iter 1800, loss: 2.922009, top_1: 0.546836, top_k: 0.774492, samples/s: 1733.354 1612878157.2740204
train: epoch 55, iter 1900, loss: 2.975827, top_1: 0.544023, top_k: 0.775117, samples/s: 1740.004 1612878171.9862728
train: epoch 55, iter 2000, loss: 3.064348, top_1: 0.547227, top_k: 0.778711, samples/s: 1744.003 1612878186.6651564
train: epoch 55, iter 2100, loss: 2.992320, top_1: 0.550430, top_k: 0.774844, samples/s: 1729.684 1612878201.4656134
train: epoch 55, iter 2200, loss: 2.727338, top_1: 0.548320, top_k: 0.781328, samples/s: 1738.040 1612878216.1947525
train: epoch 55, iter 2300, loss: 2.721719, top_1: 0.546523, top_k: 0.778555, samples/s: 1738.436 1612878230.9206126
train: epoch 55, iter 2400, loss: 2.937660, top_1: 0.551875, top_k: 0.780156, samples/s: 1734.457 1612878245.6802714
train: epoch 55, iter 2500, loss: 2.860143, top_1: 0.550391, top_k: 0.780859, samples/s: 1745.747 1612878260.344501
train: epoch 55, iter 2600, loss: 3.070865, top_1: 0.549531, top_k: 0.778398, samples/s: 1735.880 1612878275.092096
train: epoch 55, iter 2700, loss: 2.912906, top_1: 0.546250, top_k: 0.775508, samples/s: 1736.991 1612878289.8302422
train: epoch 55, iter 2800, loss: 2.746525, top_1: 0.547148, top_k: 0.772148, samples/s: 1736.058 1612878304.5762568
train: epoch 55, iter 2900, loss: 2.925677, top_1: 0.543203, top_k: 0.774492, samples/s: 1741.292 1612878319.2780151
train: epoch 55, iter 3000, loss: 2.759730, top_1: 0.550156, top_k: 0.778711, samples/s: 1743.627 1612878333.960016
train: epoch 55, iter 3100, loss: 2.822879, top_1: 0.546328, top_k: 0.774922, samples/s: 1735.829 1612878348.7080417
train: epoch 55, iter 3200, loss: 2.659817, top_1: 0.547656, top_k: 0.775664, samples/s: 1739.714 1612878363.4230583
train: epoch 55, iter 3300, loss: 3.036842, top_1: 0.543008, top_k: 0.773633, samples/s: 1742.598 1612878378.1139257
train: epoch 55, iter 3400, loss: 2.952017, top_1: 0.542773, top_k: 0.772969, samples/s: 1735.314 1612878392.8662713
train: epoch 55, iter 3500, loss: 2.883510, top_1: 0.548164, top_k: 0.772734, samples/s: 1742.539 1612878407.5573478
train: epoch 55, iter 3600, loss: 2.732704, top_1: 0.544297, top_k: 0.775312, samples/s: 1738.931 1612878422.2791042
train: epoch 55, iter 3700, loss: 3.003990, top_1: 0.546836, top_k: 0.777422, samples/s: 1737.647 1612878437.0116897
train: epoch 55, iter 3800, loss: 2.951545, top_1: 0.546484, top_k: 0.773789, samples/s: 1739.247 1612878451.7306614
train: epoch 55, iter 3900, loss: 2.796568, top_1: 0.544258, top_k: 0.773438, samples/s: 1741.254 1612878466.4327176
train: epoch 55, iter 4000, loss: 2.820399, top_1: 0.548281, top_k: 0.777813, samples/s: 1732.216 1612878481.2114136
train: epoch 55, iter 4100, loss: 2.681106, top_1: 0.544258, top_k: 0.775000, samples/s: 1740.204 1612878495.9223952
train: epoch 55, iter 4200, loss: 2.955191, top_1: 0.545781, top_k: 0.773750, samples/s: 1742.226 1612878510.6162608
train: epoch 55, iter 4300, loss: 2.766654, top_1: 0.541836, top_k: 0.775352, samples/s: 1736.061 1612878525.362257
train: epoch 55, iter 4400, loss: 2.959837, top_1: 0.541211, top_k: 0.772500, samples/s: 1741.231 1612878540.064447
train: epoch 55, iter 4500, loss: 3.007530, top_1: 0.543164, top_k: 0.775820, samples/s: 1723.430 1612878554.9186149
train: epoch 55, iter 4600, loss: 3.018384, top_1: 0.546211, top_k: 0.771719, samples/s: 1744.862 1612878569.5902505
train: epoch 55, iter 4700, loss: 2.823300, top_1: 0.538438, top_k: 0.776719, samples/s: 1729.992 1612878584.3880787
train: epoch 55, iter 4800, loss: 2.980162, top_1: 0.545469, top_k: 0.772813, samples/s: 1741.711 1612878599.086223
train: epoch 55, iter 4900, loss: 2.758842, top_1: 0.543750, top_k: 0.778281, samples/s: 1727.333 1612878613.9067402
train: epoch 55, iter 5000, loss: 3.037952, top_1: 0.549609, top_k: 0.774492, samples/s: 1752.809 1612878628.511845
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_55.
validation: epoch 55, iter 195, top_1: 0.592788, top_k: 0.827063, samples/s: 2886.533 1612878646.2197726
train: epoch 56, iter 100, loss: 2.861562, top_1: 0.558828, top_k: 0.786367, samples/s: 1737.246 1612878680.9938834
train: epoch 56, iter 200, loss: 2.641864, top_1: 0.560391, top_k: 0.786602, samples/s: 1761.515 1612878695.5266907
train: epoch 56, iter 300, loss: 2.784130, top_1: 0.555781, top_k: 0.782227, samples/s: 1764.618 1612878710.0341167
train: epoch 56, iter 400, loss: 3.042171, top_1: 0.554688, top_k: 0.784766, samples/s: 1762.408 1612878724.5598266
train: epoch 56, iter 500, loss: 2.842560, top_1: 0.558242, top_k: 0.784453, samples/s: 1762.623 1612878739.0836024
train: epoch 56, iter 600, loss: 2.921494, top_1: 0.560547, top_k: 0.785352, samples/s: 1736.417 1612878753.8265638
train: epoch 56, iter 700, loss: 2.767388, top_1: 0.559375, top_k: 0.789766, samples/s: 1755.243 1612878768.4113476
train: epoch 56, iter 800, loss: 3.003310, top_1: 0.552578, top_k: 0.783828, samples/s: 1752.776 1612878783.0168502
train: epoch 56, iter 900, loss: 2.706130, top_1: 0.552773, top_k: 0.779883, samples/s: 1730.354 1612878797.8114786
train: epoch 56, iter 1000, loss: 2.796429, top_1: 0.551562, top_k: 0.781250, samples/s: 1739.536 1612878812.5280292
train: epoch 56, iter 1100, loss: 2.933846, top_1: 0.557734, top_k: 0.786836, samples/s: 1741.130 1612878827.231127
train: epoch 56, iter 1200, loss: 2.920109, top_1: 0.552305, top_k: 0.779805, samples/s: 1738.872 1612878841.9532566
train: epoch 56, iter 1300, loss: 2.967472, top_1: 0.552305, top_k: 0.783164, samples/s: 1743.731 1612878856.6344912
train: epoch 56, iter 1400, loss: 2.796817, top_1: 0.549961, top_k: 0.781133, samples/s: 1738.475 1612878871.3599784
train: epoch 56, iter 1500, loss: 2.692351, top_1: 0.546055, top_k: 0.777070, samples/s: 1745.518 1612878886.026085
train: epoch 56, iter 1600, loss: 2.727767, top_1: 0.552461, top_k: 0.782109, samples/s: 1730.262 1612878900.8215325
train: epoch 56, iter 1700, loss: 2.955364, top_1: 0.549102, top_k: 0.775273, samples/s: 1749.565 1612878915.4538193
train: epoch 56, iter 1800, loss: 2.896473, top_1: 0.542227, top_k: 0.773164, samples/s: 1738.132 1612878930.1822755
train: epoch 56, iter 1900, loss: 2.958414, top_1: 0.543828, top_k: 0.776211, samples/s: 1736.050 1612878944.9283774
train: epoch 56, iter 2000, loss: 2.933663, top_1: 0.545625, top_k: 0.775352, samples/s: 1738.177 1612878959.6565077
train: epoch 56, iter 2100, loss: 2.770113, top_1: 0.543867, top_k: 0.773516, samples/s: 1747.501 1612878974.305931
train: epoch 56, iter 2200, loss: 2.899963, top_1: 0.544102, top_k: 0.774883, samples/s: 1732.213 1612878989.084766
train: epoch 56, iter 2300, loss: 2.841780, top_1: 0.547070, top_k: 0.774453, samples/s: 1752.714 1612879003.6907017
train: epoch 56, iter 2400, loss: 2.859888, top_1: 0.549258, top_k: 0.780078, samples/s: 1739.257 1612879018.4095027
train: epoch 56, iter 2500, loss: 2.761798, top_1: 0.551484, top_k: 0.778203, samples/s: 1731.549 1612879033.1940634
train: epoch 56, iter 2600, loss: 2.995496, top_1: 0.544375, top_k: 0.774531, samples/s: 1735.807 1612879047.9421875
train: epoch 56, iter 2700, loss: 2.864098, top_1: 0.545234, top_k: 0.776563, samples/s: 1755.519 1612879062.524821
train: epoch 56, iter 2800, loss: 2.868391, top_1: 0.544687, top_k: 0.777773, samples/s: 1733.444 1612879077.2931023
train: epoch 56, iter 2900, loss: 2.826114, top_1: 0.541641, top_k: 0.774336, samples/s: 1730.558 1612879092.0859735
train: epoch 56, iter 3000, loss: 2.891552, top_1: 0.540703, top_k: 0.772656, samples/s: 1734.227 1612879106.8475678
train: epoch 56, iter 3100, loss: 3.074042, top_1: 0.545391, top_k: 0.777109, samples/s: 1733.130 1612879121.6186619
train: epoch 56, iter 3200, loss: 2.763524, top_1: 0.543242, top_k: 0.774727, samples/s: 1731.159 1612879136.406602
train: epoch 56, iter 3300, loss: 2.925950, top_1: 0.547070, top_k: 0.778398, samples/s: 1750.156 1612879151.0336237
train: epoch 56, iter 3400, loss: 2.822072, top_1: 0.544102, top_k: 0.774531, samples/s: 1744.372 1612879165.709338
train: epoch 56, iter 3500, loss: 2.810497, top_1: 0.551250, top_k: 0.779922, samples/s: 1729.939 1612879180.5076525
train: epoch 56, iter 3600, loss: 2.741121, top_1: 0.544766, top_k: 0.773125, samples/s: 1740.570 1612879195.2153773
train: epoch 56, iter 3700, loss: 2.767926, top_1: 0.548359, top_k: 0.776289, samples/s: 1739.962 1612879209.9284296
train: epoch 56, iter 3800, loss: 2.835984, top_1: 0.545469, top_k: 0.777539, samples/s: 1738.143 1612879224.6567595
train: epoch 56, iter 3900, loss: 2.913033, top_1: 0.550352, top_k: 0.781523, samples/s: 1734.951 1612879239.4122887
train: epoch 56, iter 4000, loss: 2.940054, top_1: 0.540703, top_k: 0.773438, samples/s: 1745.224 1612879254.0808203
train: epoch 56, iter 4100, loss: 2.911809, top_1: 0.549219, top_k: 0.775625, samples/s: 1740.425 1612879268.7898238
train: epoch 56, iter 4200, loss: 2.714100, top_1: 0.548008, top_k: 0.784453, samples/s: 1733.821 1612879283.5549343
train: epoch 56, iter 4300, loss: 2.841103, top_1: 0.548516, top_k: 0.776680, samples/s: 1731.716 1612879298.338076
train: epoch 56, iter 4400, loss: 2.815010, top_1: 0.543281, top_k: 0.774219, samples/s: 1733.791 1612879313.103298
train: epoch 56, iter 4500, loss: 2.814717, top_1: 0.546172, top_k: 0.781094, samples/s: 1741.608 1612879327.8023033
train: epoch 56, iter 4600, loss: 2.894842, top_1: 0.548672, top_k: 0.775391, samples/s: 1746.382 1612879342.461255
train: epoch 56, iter 4700, loss: 3.076537, top_1: 0.550312, top_k: 0.777852, samples/s: 1736.474 1612879357.203719
train: epoch 56, iter 4800, loss: 2.881350, top_1: 0.541914, top_k: 0.772930, samples/s: 1740.464 1612879371.9126282
train: epoch 56, iter 4900, loss: 2.892867, top_1: 0.548516, top_k: 0.777773, samples/s: 1719.285 1612879386.8024442
train: epoch 56, iter 5000, loss: 2.952369, top_1: 0.548711, top_k: 0.775977, samples/s: 1765.049 1612879401.306247
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_56.
validation: epoch 56, iter 195, top_1: 0.579828, top_k: 0.817468, samples/s: 2837.280 1612879419.3522232
train: epoch 57, iter 100, loss: 2.720124, top_1: 0.552578, top_k: 0.785234, samples/s: 1730.555 1612879453.950001
train: epoch 57, iter 200, loss: 2.873732, top_1: 0.558281, top_k: 0.784883, samples/s: 1768.980 1612879468.421745
train: epoch 57, iter 300, loss: 2.974929, top_1: 0.550703, top_k: 0.782305, samples/s: 1761.707 1612879482.953031
train: epoch 57, iter 400, loss: 2.889511, top_1: 0.561523, top_k: 0.786563, samples/s: 1762.569 1612879497.4771423
train: epoch 57, iter 500, loss: 2.740888, top_1: 0.554922, top_k: 0.783008, samples/s: 1743.635 1612879512.1593559
train: epoch 57, iter 600, loss: 2.730720, top_1: 0.552305, top_k: 0.783867, samples/s: 1767.486 1612879526.6430106
train: epoch 57, iter 700, loss: 2.937975, top_1: 0.558242, top_k: 0.788008, samples/s: 1742.514 1612879541.3344872
train: epoch 57, iter 800, loss: 2.840244, top_1: 0.557227, top_k: 0.786992, samples/s: 1748.414 1612879555.976301
train: epoch 57, iter 900, loss: 2.935331, top_1: 0.549609, top_k: 0.778867, samples/s: 1743.990 1612879570.655289
train: epoch 57, iter 1000, loss: 2.903589, top_1: 0.557109, top_k: 0.786797, samples/s: 1740.587 1612879585.3629298
train: epoch 57, iter 1100, loss: 2.753588, top_1: 0.546523, top_k: 0.775937, samples/s: 1730.442 1612879600.1569247
train: epoch 57, iter 1200, loss: 2.746873, top_1: 0.545508, top_k: 0.777500, samples/s: 1737.544 1612879614.890354
train: epoch 57, iter 1300, loss: 2.871013, top_1: 0.550742, top_k: 0.777539, samples/s: 1742.965 1612879629.5779114
train: epoch 57, iter 1400, loss: 2.714226, top_1: 0.557383, top_k: 0.784297, samples/s: 1739.209 1612879644.2971845
train: epoch 57, iter 1500, loss: 2.908661, top_1: 0.547227, top_k: 0.778672, samples/s: 1744.505 1612879658.9719129
train: epoch 57, iter 1600, loss: 3.083935, top_1: 0.557695, top_k: 0.781641, samples/s: 1735.916 1612879673.7191112
train: epoch 57, iter 1700, loss: 2.806372, top_1: 0.549531, top_k: 0.776758, samples/s: 1735.970 1612879688.4659631
train: epoch 57, iter 1800, loss: 2.825411, top_1: 0.553594, top_k: 0.781758, samples/s: 1731.021 1612879703.2549512
train: epoch 57, iter 1900, loss: 2.917726, top_1: 0.550391, top_k: 0.782031, samples/s: 1740.770 1612879717.9610178
train: epoch 57, iter 2000, loss: 2.936488, top_1: 0.543672, top_k: 0.774453, samples/s: 1739.403 1612879732.6786926
train: epoch 57, iter 2100, loss: 2.851234, top_1: 0.548945, top_k: 0.777930, samples/s: 1738.880 1612879747.4008758
train: epoch 57, iter 2200, loss: 2.659010, top_1: 0.551367, top_k: 0.782578, samples/s: 1739.812 1612879762.1150615
train: epoch 57, iter 2300, loss: 2.978660, top_1: 0.545547, top_k: 0.776367, samples/s: 1737.346 1612879776.8501866
train: epoch 57, iter 2400, loss: 2.938597, top_1: 0.552852, top_k: 0.781602, samples/s: 1739.650 1612879791.5658672
train: epoch 57, iter 2500, loss: 2.880681, top_1: 0.549102, top_k: 0.777969, samples/s: 1728.009 1612879806.3805685
train: epoch 57, iter 2600, loss: 2.795345, top_1: 0.549023, top_k: 0.778086, samples/s: 1737.363 1612879821.1155472
train: epoch 57, iter 2700, loss: 2.793232, top_1: 0.550937, top_k: 0.781836, samples/s: 1740.445 1612879835.8244565
train: epoch 57, iter 2800, loss: 2.793994, top_1: 0.546445, top_k: 0.780156, samples/s: 1736.730 1612879850.5646963
train: epoch 57, iter 2900, loss: 2.884191, top_1: 0.549023, top_k: 0.777500, samples/s: 1734.084 1612879865.3276646
train: epoch 57, iter 3000, loss: 2.826355, top_1: 0.546211, top_k: 0.775742, samples/s: 1754.249 1612879879.920737
train: epoch 57, iter 3100, loss: 2.913575, top_1: 0.547461, top_k: 0.779336, samples/s: 1733.042 1612879894.6925135
train: epoch 57, iter 3200, loss: 2.654967, top_1: 0.543945, top_k: 0.774922, samples/s: 1737.175 1612879909.4290137
train: epoch 57, iter 3300, loss: 2.891055, top_1: 0.549063, top_k: 0.775234, samples/s: 1740.047 1612879924.1412783
train: epoch 57, iter 3400, loss: 2.930516, top_1: 0.548750, top_k: 0.778125, samples/s: 1744.819 1612879938.8132858
train: epoch 57, iter 3500, loss: 3.051315, top_1: 0.546875, top_k: 0.780195, samples/s: 1741.233 1612879953.5154617
train: epoch 57, iter 3600, loss: 2.854531, top_1: 0.547188, top_k: 0.777031, samples/s: 1738.912 1612879968.2373586
train: epoch 57, iter 3700, loss: 3.067481, top_1: 0.543711, top_k: 0.775469, samples/s: 1744.375 1612879982.9130898
train: epoch 57, iter 3800, loss: 2.812478, top_1: 0.549727, top_k: 0.776680, samples/s: 1731.926 1612879997.6942782
train: epoch 57, iter 3900, loss: 3.024559, top_1: 0.549648, top_k: 0.777773, samples/s: 1743.655 1612880012.3761313
train: epoch 57, iter 4000, loss: 2.988815, top_1: 0.546289, top_k: 0.777383, samples/s: 1741.575 1612880027.0754578
train: epoch 57, iter 4100, loss: 2.704899, top_1: 0.547539, top_k: 0.779453, samples/s: 1741.047 1612880041.7793007
train: epoch 57, iter 4200, loss: 2.711140, top_1: 0.549297, top_k: 0.780078, samples/s: 1744.590 1612880056.4532206
train: epoch 57, iter 4300, loss: 2.979701, top_1: 0.542695, top_k: 0.776563, samples/s: 1744.515 1612880071.1277776
train: epoch 57, iter 4400, loss: 2.846094, top_1: 0.551055, top_k: 0.778438, samples/s: 1744.314 1612880085.8040245
train: epoch 57, iter 4500, loss: 2.926762, top_1: 0.547070, top_k: 0.777461, samples/s: 1715.309 1612880100.728436
train: epoch 57, iter 4600, loss: 2.821562, top_1: 0.550430, top_k: 0.778945, samples/s: 1754.171 1612880115.3221805
train: epoch 57, iter 4700, loss: 2.767615, top_1: 0.543984, top_k: 0.775820, samples/s: 1747.108 1612880129.975028
train: epoch 57, iter 4800, loss: 2.845489, top_1: 0.551328, top_k: 0.778594, samples/s: 1735.163 1612880144.7286243
train: epoch 57, iter 4900, loss: 3.181386, top_1: 0.547148, top_k: 0.773008, samples/s: 1727.658 1612880159.54644
train: epoch 57, iter 5000, loss: 2.703904, top_1: 0.554375, top_k: 0.783672, samples/s: 1744.082 1612880174.224676
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_57.
validation: epoch 57, iter 195, top_1: 0.597196, top_k: 0.831050, samples/s: 2802.876 1612880192.5149817
train: epoch 58, iter 100, loss: 2.938895, top_1: 0.568711, top_k: 0.790625, samples/s: 1756.719 1612880227.2622938
train: epoch 58, iter 200, loss: 2.846129, top_1: 0.557383, top_k: 0.788164, samples/s: 1754.883 1612880241.8501396
train: epoch 58, iter 300, loss: 2.794195, top_1: 0.558047, top_k: 0.782383, samples/s: 1753.412 1612880256.4505165
train: epoch 58, iter 400, loss: 2.876195, top_1: 0.556289, top_k: 0.781992, samples/s: 1769.531 1612880270.9173834
train: epoch 58, iter 500, loss: 3.106363, top_1: 0.554648, top_k: 0.785156, samples/s: 1753.249 1612880285.5188942
train: epoch 58, iter 600, loss: 2.650692, top_1: 0.554883, top_k: 0.784258, samples/s: 1753.414 1612880300.118876
train: epoch 58, iter 700, loss: 2.859950, top_1: 0.553320, top_k: 0.785508, samples/s: 1738.709 1612880314.8425062
train: epoch 58, iter 800, loss: 2.761978, top_1: 0.559258, top_k: 0.787500, samples/s: 1757.626 1612880329.407536
train: epoch 58, iter 900, loss: 2.748014, top_1: 0.553477, top_k: 0.782266, samples/s: 1727.486 1612880344.2268503
train: epoch 58, iter 1000, loss: 2.735474, top_1: 0.556875, top_k: 0.784102, samples/s: 1750.340 1612880358.852566
train: epoch 58, iter 1100, loss: 2.956864, top_1: 0.554453, top_k: 0.783281, samples/s: 1737.474 1612880373.586571
train: epoch 58, iter 1200, loss: 2.887568, top_1: 0.554961, top_k: 0.781367, samples/s: 1750.294 1612880388.2127342
train: epoch 58, iter 1300, loss: 2.940867, top_1: 0.549258, top_k: 0.781367, samples/s: 1723.784 1612880403.063755
train: epoch 58, iter 1400, loss: 2.958410, top_1: 0.553125, top_k: 0.781680, samples/s: 1733.545 1612880417.8312585
train: epoch 58, iter 1500, loss: 2.887230, top_1: 0.556328, top_k: 0.782070, samples/s: 1743.724 1612880432.5123978
train: epoch 58, iter 1600, loss: 2.853776, top_1: 0.550586, top_k: 0.780781, samples/s: 1750.564 1612880447.136248
train: epoch 58, iter 1700, loss: 2.684665, top_1: 0.550195, top_k: 0.782695, samples/s: 1717.752 1612880462.0395045
train: epoch 58, iter 1800, loss: 2.868583, top_1: 0.550781, top_k: 0.780742, samples/s: 1762.648 1612880476.5630014
train: epoch 58, iter 1900, loss: 2.816412, top_1: 0.548555, top_k: 0.782578, samples/s: 1740.845 1612880491.26851
train: epoch 58, iter 2000, loss: 2.951010, top_1: 0.550195, top_k: 0.778555, samples/s: 1746.000 1612880505.9306176
train: epoch 58, iter 2100, loss: 2.748945, top_1: 0.549648, top_k: 0.778789, samples/s: 1732.263 1612880520.709017
train: epoch 58, iter 2200, loss: 2.731529, top_1: 0.553125, top_k: 0.781875, samples/s: 1733.444 1612880535.477259
train: epoch 58, iter 2300, loss: 2.843641, top_1: 0.543906, top_k: 0.775352, samples/s: 1743.829 1612880550.1575665
train: epoch 58, iter 2400, loss: 2.904477, top_1: 0.552773, top_k: 0.779727, samples/s: 1740.374 1612880564.8670907
train: epoch 58, iter 2500, loss: 2.791426, top_1: 0.542148, top_k: 0.774531, samples/s: 1741.636 1612880579.5659842
train: epoch 58, iter 2600, loss: 2.711002, top_1: 0.545859, top_k: 0.778906, samples/s: 1740.503 1612880594.2743309
train: epoch 58, iter 2700, loss: 2.731642, top_1: 0.551602, top_k: 0.782539, samples/s: 1753.791 1612880608.8712559
train: epoch 58, iter 2800, loss: 2.961082, top_1: 0.549844, top_k: 0.779492, samples/s: 1741.284 1612880623.5730364
train: epoch 58, iter 2900, loss: 2.903170, top_1: 0.555039, top_k: 0.784375, samples/s: 1721.095 1612880638.4472692
train: epoch 58, iter 3000, loss: 2.855091, top_1: 0.547930, top_k: 0.780859, samples/s: 1735.115 1612880653.2014012
train: epoch 58, iter 3100, loss: 3.060233, top_1: 0.549453, top_k: 0.778086, samples/s: 1746.679 1612880667.857813
train: epoch 58, iter 3200, loss: 2.688740, top_1: 0.545664, top_k: 0.775586, samples/s: 1747.594 1612880682.5064864
train: epoch 58, iter 3300, loss: 2.942267, top_1: 0.546328, top_k: 0.776719, samples/s: 1740.250 1612880697.2170532
train: epoch 58, iter 3400, loss: 2.657026, top_1: 0.544883, top_k: 0.771680, samples/s: 1738.214 1612880711.9448307
train: epoch 58, iter 3500, loss: 3.011591, top_1: 0.551250, top_k: 0.781211, samples/s: 1744.066 1612880726.6232169
train: epoch 58, iter 3600, loss: 2.755656, top_1: 0.555664, top_k: 0.779375, samples/s: 1714.006 1612880741.5588639
train: epoch 58, iter 3700, loss: 2.790889, top_1: 0.549687, top_k: 0.782422, samples/s: 1747.847 1612880756.2054772
train: epoch 58, iter 3800, loss: 2.785503, top_1: 0.550000, top_k: 0.778008, samples/s: 1733.638 1612880770.9721358
train: epoch 58, iter 3900, loss: 2.872753, top_1: 0.546289, top_k: 0.776719, samples/s: 1746.934 1612880785.6263876
train: epoch 58, iter 4000, loss: 2.845225, top_1: 0.549648, top_k: 0.780625, samples/s: 1742.702 1612880800.3162262
train: epoch 58, iter 4100, loss: 2.724537, top_1: 0.553477, top_k: 0.779648, samples/s: 1742.622 1612880815.006656
train: epoch 58, iter 4200, loss: 2.887097, top_1: 0.546797, top_k: 0.778398, samples/s: 1739.981 1612880829.719528
train: epoch 58, iter 4300, loss: 2.878554, top_1: 0.548828, top_k: 0.774687, samples/s: 1739.257 1612880844.4384153
train: epoch 58, iter 4400, loss: 2.848732, top_1: 0.549844, top_k: 0.776367, samples/s: 1724.157 1612880859.2862628
train: epoch 58, iter 4500, loss: 3.115721, top_1: 0.545937, top_k: 0.772266, samples/s: 1735.830 1612880874.0342584
train: epoch 58, iter 4600, loss: 2.700854, top_1: 0.546250, top_k: 0.778281, samples/s: 1742.010 1612880888.729882
train: epoch 58, iter 4700, loss: 2.895930, top_1: 0.546484, top_k: 0.777305, samples/s: 1736.497 1612880903.4722447
train: epoch 58, iter 4800, loss: 2.817163, top_1: 0.549063, top_k: 0.778203, samples/s: 1738.623 1612880918.1965964
train: epoch 58, iter 4900, loss: 2.705604, top_1: 0.547344, top_k: 0.777188, samples/s: 1751.164 1612880932.8153355
train: epoch 58, iter 5000, loss: 2.767280, top_1: 0.551445, top_k: 0.780078, samples/s: 1731.125 1612880947.6035316
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_58.
validation: epoch 58, iter 195, top_1: 0.595974, top_k: 0.829006, samples/s: 2873.541 1612880965.429267
train: epoch 59, iter 100, loss: 2.734825, top_1: 0.565000, top_k: 0.788359, samples/s: 1745.736 1612881001.0240877
train: epoch 59, iter 200, loss: 2.765995, top_1: 0.555664, top_k: 0.783555, samples/s: 1763.519 1612881015.5404806
train: epoch 59, iter 300, loss: 2.866017, top_1: 0.557578, top_k: 0.789492, samples/s: 1756.890 1612881030.1116848
train: epoch 59, iter 400, loss: 2.736028, top_1: 0.560469, top_k: 0.789141, samples/s: 1760.178 1612881044.6556294
train: epoch 59, iter 500, loss: 2.775022, top_1: 0.559063, top_k: 0.783789, samples/s: 1753.840 1612881059.252186
train: epoch 59, iter 600, loss: 2.894153, top_1: 0.560391, top_k: 0.786914, samples/s: 1761.281 1612881073.787004
train: epoch 59, iter 700, loss: 2.851134, top_1: 0.558750, top_k: 0.786602, samples/s: 1751.145 1612881088.406011
train: epoch 59, iter 800, loss: 2.967439, top_1: 0.554336, top_k: 0.784297, samples/s: 1749.258 1612881103.0408008
train: epoch 59, iter 900, loss: 2.992069, top_1: 0.548594, top_k: 0.782539, samples/s: 1735.130 1612881117.794709
train: epoch 59, iter 1000, loss: 2.666095, top_1: 0.551172, top_k: 0.782031, samples/s: 1735.300 1612881132.5472882
train: epoch 59, iter 1100, loss: 2.738344, top_1: 0.554180, top_k: 0.779844, samples/s: 1739.524 1612881147.2638748
train: epoch 59, iter 1200, loss: 3.226972, top_1: 0.555312, top_k: 0.781094, samples/s: 1735.065 1612881162.018399
train: epoch 59, iter 1300, loss: 2.758561, top_1: 0.557617, top_k: 0.789609, samples/s: 1744.111 1612881176.6963363
train: epoch 59, iter 1400, loss: 2.683390, top_1: 0.553828, top_k: 0.784375, samples/s: 1716.175 1612881191.6132839
train: epoch 59, iter 1500, loss: 2.926931, top_1: 0.559492, top_k: 0.782773, samples/s: 1730.101 1612881206.410114
train: epoch 59, iter 1600, loss: 2.742447, top_1: 0.555156, top_k: 0.785859, samples/s: 1737.979 1612881221.139828
train: epoch 59, iter 1700, loss: 2.840678, top_1: 0.563398, top_k: 0.787031, samples/s: 1747.368 1612881235.790522
train: epoch 59, iter 1800, loss: 2.657450, top_1: 0.552734, top_k: 0.782891, samples/s: 1741.515 1612881250.4903393
train: epoch 59, iter 1900, loss: 2.790948, top_1: 0.550625, top_k: 0.782695, samples/s: 1735.986 1612881265.236994
train: epoch 59, iter 2000, loss: 2.926301, top_1: 0.557500, top_k: 0.783594, samples/s: 1739.123 1612881279.9569838
train: epoch 59, iter 2100, loss: 2.816036, top_1: 0.552148, top_k: 0.781094, samples/s: 1744.890 1612881294.6283958
train: epoch 59, iter 2200, loss: 2.911274, top_1: 0.554453, top_k: 0.782578, samples/s: 1743.930 1612881309.3079412
train: epoch 59, iter 2300, loss: 2.739941, top_1: 0.556602, top_k: 0.785078, samples/s: 1737.678 1612881324.0402064
train: epoch 59, iter 2400, loss: 2.937207, top_1: 0.552305, top_k: 0.786484, samples/s: 1743.005 1612881338.727524
train: epoch 59, iter 2500, loss: 2.975558, top_1: 0.548359, top_k: 0.775977, samples/s: 1739.783 1612881353.4419644
train: epoch 59, iter 2600, loss: 3.030410, top_1: 0.548828, top_k: 0.777773, samples/s: 1742.583 1612881368.132804
train: epoch 59, iter 2700, loss: 2.898333, top_1: 0.552266, top_k: 0.777305, samples/s: 1742.066 1612881382.8279724
train: epoch 59, iter 2800, loss: 2.850672, top_1: 0.546680, top_k: 0.780430, samples/s: 1733.721 1612881397.5940003
train: epoch 59, iter 2900, loss: 2.706038, top_1: 0.558711, top_k: 0.788125, samples/s: 1753.135 1612881412.1963267
train: epoch 59, iter 3000, loss: 2.882527, top_1: 0.549141, top_k: 0.780000, samples/s: 1724.139 1612881427.0444088
train: epoch 59, iter 3100, loss: 2.716897, top_1: 0.553086, top_k: 0.780703, samples/s: 1748.254 1612881441.6875894
train: epoch 59, iter 3200, loss: 2.759004, top_1: 0.550430, top_k: 0.779375, samples/s: 1743.357 1612881456.371906
train: epoch 59, iter 3300, loss: 2.986180, top_1: 0.547266, top_k: 0.775469, samples/s: 1742.701 1612881471.0616431
train: epoch 59, iter 3400, loss: 2.806493, top_1: 0.548828, top_k: 0.778555, samples/s: 1736.812 1612881485.8014116
train: epoch 59, iter 3500, loss: 2.700798, top_1: 0.551602, top_k: 0.782617, samples/s: 1738.141 1612881500.5297015
train: epoch 59, iter 3600, loss: 2.690003, top_1: 0.559844, top_k: 0.785977, samples/s: 1740.390 1612881515.2390795
train: epoch 59, iter 3700, loss: 2.831721, top_1: 0.554531, top_k: 0.781641, samples/s: 1739.769 1612881529.9536233
train: epoch 59, iter 3800, loss: 3.134887, top_1: 0.551445, top_k: 0.781563, samples/s: 1748.190 1612881544.5973976
train: epoch 59, iter 3900, loss: 2.722660, top_1: 0.555312, top_k: 0.779844, samples/s: 1743.159 1612881559.2833369
train: epoch 59, iter 4000, loss: 2.827746, top_1: 0.556133, top_k: 0.784883, samples/s: 1743.780 1612881573.9641006
train: epoch 59, iter 4100, loss: 2.854906, top_1: 0.544687, top_k: 0.772734, samples/s: 1736.964 1612881588.7024283
train: epoch 59, iter 4200, loss: 2.938959, top_1: 0.554766, top_k: 0.780977, samples/s: 1738.506 1612881603.4277909
train: epoch 59, iter 4300, loss: 2.877361, top_1: 0.549883, top_k: 0.778164, samples/s: 1754.803 1612881618.0162516
train: epoch 59, iter 4400, loss: 2.959433, top_1: 0.553516, top_k: 0.784570, samples/s: 1722.119 1612881632.8816261
train: epoch 59, iter 4500, loss: 2.910027, top_1: 0.551484, top_k: 0.779687, samples/s: 1748.494 1612881647.5228121
train: epoch 59, iter 4600, loss: 3.028242, top_1: 0.548633, top_k: 0.779883, samples/s: 1733.416 1612881662.291373
train: epoch 59, iter 4700, loss: 2.864843, top_1: 0.551523, top_k: 0.780156, samples/s: 1746.386 1612881676.950218
train: epoch 59, iter 4800, loss: 2.922604, top_1: 0.546680, top_k: 0.781523, samples/s: 1750.636 1612881691.573505
train: epoch 59, iter 4900, loss: 2.703684, top_1: 0.553555, top_k: 0.783594, samples/s: 1740.244 1612881706.2841165
train: epoch 59, iter 5000, loss: 2.854105, top_1: 0.553008, top_k: 0.778086, samples/s: 1740.262 1612881720.994485
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_59.
validation: epoch 59, iter 195, top_1: 0.598498, top_k: 0.832332, samples/s: 2878.723 1612881738.7180421
train: epoch 60, iter 100, loss: 2.850427, top_1: 0.557969, top_k: 0.785937, samples/s: 1757.884 1612881778.9891922
train: epoch 60, iter 200, loss: 2.816023, top_1: 0.561133, top_k: 0.787813, samples/s: 1758.590 1612881793.5462728
train: epoch 60, iter 300, loss: 2.757874, top_1: 0.562617, top_k: 0.790781, samples/s: 1755.832 1612881808.1264465
train: epoch 60, iter 400, loss: 2.940061, top_1: 0.554922, top_k: 0.784609, samples/s: 1754.526 1612881822.7171128
train: epoch 60, iter 500, loss: 2.702410, top_1: 0.558633, top_k: 0.786641, samples/s: 1757.323 1612881837.2846644
train: epoch 60, iter 600, loss: 3.028908, top_1: 0.559961, top_k: 0.788398, samples/s: 1753.845 1612881851.8811274
train: epoch 60, iter 700, loss: 2.976492, top_1: 0.556836, top_k: 0.783281, samples/s: 1751.675 1612881866.4957478
train: epoch 60, iter 800, loss: 2.951309, top_1: 0.558789, top_k: 0.783398, samples/s: 1751.836 1612881881.109053
train: epoch 60, iter 900, loss: 2.907362, top_1: 0.556875, top_k: 0.785156, samples/s: 1754.010 1612881895.7041254
train: epoch 60, iter 1000, loss: 2.985913, top_1: 0.555820, top_k: 0.784023, samples/s: 1740.514 1612881910.412474
train: epoch 60, iter 1100, loss: 2.958266, top_1: 0.552188, top_k: 0.783203, samples/s: 1741.696 1612881925.11069
train: epoch 60, iter 1200, loss: 2.644507, top_1: 0.561797, top_k: 0.789258, samples/s: 1743.265 1612881939.795823
train: epoch 60, iter 1300, loss: 2.850554, top_1: 0.554922, top_k: 0.783242, samples/s: 1731.672 1612881954.5793235
train: epoch 60, iter 1400, loss: 2.741129, top_1: 0.561328, top_k: 0.786016, samples/s: 1748.302 1612881969.2220185
train: epoch 60, iter 1500, loss: 2.851595, top_1: 0.559414, top_k: 0.786953, samples/s: 1747.669 1612881983.8700593
train: epoch 60, iter 1600, loss: 2.912218, top_1: 0.553711, top_k: 0.781719, samples/s: 1743.587 1612881998.552423
train: epoch 60, iter 1700, loss: 2.832132, top_1: 0.552148, top_k: 0.785742, samples/s: 1732.122 1612882013.332044
train: epoch 60, iter 1800, loss: 2.945213, top_1: 0.551836, top_k: 0.779922, samples/s: 1728.688 1612882028.141022
train: epoch 60, iter 1900, loss: 2.726981, top_1: 0.555703, top_k: 0.781641, samples/s: 1739.230 1612882042.860056
train: epoch 60, iter 2000, loss: 2.938864, top_1: 0.550586, top_k: 0.781836, samples/s: 1741.101 1612882057.5634775
train: epoch 60, iter 2100, loss: 3.000701, top_1: 0.553594, top_k: 0.782930, samples/s: 1745.836 1612882072.2269297
train: epoch 60, iter 2200, loss: 2.877087, top_1: 0.555273, top_k: 0.779180, samples/s: 1748.697 1612882086.866392
train: epoch 60, iter 2300, loss: 2.936516, top_1: 0.550117, top_k: 0.779453, samples/s: 1734.567 1612882101.6250994
train: epoch 60, iter 2400, loss: 2.693342, top_1: 0.555430, top_k: 0.781016, samples/s: 1742.449 1612882116.3170419
train: epoch 60, iter 2500, loss: 3.031713, top_1: 0.550117, top_k: 0.780859, samples/s: 1748.869 1612882130.9550614
train: epoch 60, iter 2600, loss: 2.976287, top_1: 0.553086, top_k: 0.779609, samples/s: 1738.841 1612882145.6775835
train: epoch 60, iter 2700, loss: 2.959251, top_1: 0.551523, top_k: 0.778477, samples/s: 1736.357 1612882160.421056
train: epoch 60, iter 2800, loss: 3.054848, top_1: 0.549492, top_k: 0.780312, samples/s: 1737.401 1612882175.15572
train: epoch 60, iter 2900, loss: 2.980406, top_1: 0.551289, top_k: 0.777617, samples/s: 1741.306 1612882189.8573432
train: epoch 60, iter 3000, loss: 2.833470, top_1: 0.554648, top_k: 0.784727, samples/s: 1741.958 1612882204.553417
train: epoch 60, iter 3100, loss: 2.690138, top_1: 0.550859, top_k: 0.778008, samples/s: 1751.665 1612882219.168068
train: epoch 60, iter 3200, loss: 2.798021, top_1: 0.556406, top_k: 0.784414, samples/s: 1709.163 1612882234.1462846
train: epoch 60, iter 3300, loss: 3.082477, top_1: 0.548672, top_k: 0.779844, samples/s: 1761.359 1612882248.6804247
train: epoch 60, iter 3400, loss: 2.836600, top_1: 0.552188, top_k: 0.781289, samples/s: 1740.429 1612882263.389511
train: epoch 60, iter 3500, loss: 2.894359, top_1: 0.555195, top_k: 0.781758, samples/s: 1740.864 1612882278.0948496
train: epoch 60, iter 3600, loss: 2.650751, top_1: 0.550195, top_k: 0.781523, samples/s: 1744.313 1612882292.771046
train: epoch 60, iter 3700, loss: 2.956450, top_1: 0.551914, top_k: 0.782891, samples/s: 1736.129 1612882307.5165107
train: epoch 60, iter 3800, loss: 2.870367, top_1: 0.552500, top_k: 0.780742, samples/s: 1729.175 1612882322.3211946
train: epoch 60, iter 3900, loss: 2.940731, top_1: 0.549727, top_k: 0.778477, samples/s: 1749.222 1612882336.956322
train: epoch 60, iter 4000, loss: 2.920811, top_1: 0.553438, top_k: 0.782148, samples/s: 1751.447 1612882351.5727527
train: epoch 60, iter 4100, loss: 2.910409, top_1: 0.554258, top_k: 0.782031, samples/s: 1737.954 1612882366.3027368
train: epoch 60, iter 4200, loss: 2.939716, top_1: 0.552539, top_k: 0.782773, samples/s: 1734.719 1612882381.0602071
train: epoch 60, iter 4300, loss: 2.840726, top_1: 0.557969, top_k: 0.785117, samples/s: 1752.724 1612882395.6660664
train: epoch 60, iter 4400, loss: 2.966373, top_1: 0.552422, top_k: 0.775977, samples/s: 1739.927 1612882410.379306
train: epoch 60, iter 4500, loss: 2.883511, top_1: 0.553555, top_k: 0.780508, samples/s: 1740.608 1612882425.0867922
train: epoch 60, iter 4600, loss: 3.155815, top_1: 0.554961, top_k: 0.783477, samples/s: 1741.037 1612882439.790735
train: epoch 60, iter 4700, loss: 2.978194, top_1: 0.552852, top_k: 0.779062, samples/s: 1748.398 1612882454.4326622
train: epoch 60, iter 4800, loss: 2.861999, top_1: 0.550039, top_k: 0.779336, samples/s: 1743.180 1612882469.1184168
train: epoch 60, iter 4900, loss: 2.959771, top_1: 0.546211, top_k: 0.782930, samples/s: 1728.510 1612882483.9289434
train: epoch 60, iter 5000, loss: 2.915618, top_1: 0.558047, top_k: 0.785820, samples/s: 1754.667 1612882498.5185654
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_60.
validation: epoch 60, iter 195, top_1: 0.598958, top_k: 0.834936, samples/s: 2878.962 1612882516.318307
train: epoch 61, iter 100, loss: 2.894495, top_1: 0.559336, top_k: 0.784922, samples/s: 1752.866 1612882551.2825327
train: epoch 61, iter 200, loss: 2.797523, top_1: 0.562383, top_k: 0.789922, samples/s: 1754.682 1612882565.872011
train: epoch 61, iter 300, loss: 2.854454, top_1: 0.557813, top_k: 0.787227, samples/s: 1753.305 1612882580.4730756
train: epoch 61, iter 400, loss: 2.560033, top_1: 0.562969, top_k: 0.788672, samples/s: 1746.567 1612882595.1303108
train: epoch 61, iter 500, loss: 2.669561, top_1: 0.563398, top_k: 0.789258, samples/s: 1764.540 1612882609.6383867
train: epoch 61, iter 600, loss: 2.809363, top_1: 0.567734, top_k: 0.795273, samples/s: 1752.613 1612882624.2451015
train: epoch 61, iter 700, loss: 2.942561, top_1: 0.559648, top_k: 0.788281, samples/s: 1747.670 1612882638.8931727
train: epoch 61, iter 800, loss: 2.730449, top_1: 0.558320, top_k: 0.786523, samples/s: 1752.085 1612882653.504441
train: epoch 61, iter 900, loss: 2.856954, top_1: 0.563281, top_k: 0.791016, samples/s: 1746.007 1612882668.1666746
train: epoch 61, iter 1000, loss: 2.702615, top_1: 0.565078, top_k: 0.786875, samples/s: 1730.177 1612882682.9625363
train: epoch 61, iter 1100, loss: 2.736989, top_1: 0.558398, top_k: 0.787109, samples/s: 1743.988 1612882697.6419375
train: epoch 61, iter 1200, loss: 2.842923, top_1: 0.556328, top_k: 0.783125, samples/s: 1745.837 1612882712.305056
train: epoch 61, iter 1300, loss: 3.000766, top_1: 0.560000, top_k: 0.786016, samples/s: 1745.646 1612882726.9702044
train: epoch 61, iter 1400, loss: 2.696546, top_1: 0.559648, top_k: 0.782891, samples/s: 1741.232 1612882741.6723554
train: epoch 61, iter 1500, loss: 2.865470, top_1: 0.556016, top_k: 0.783008, samples/s: 1734.767 1612882756.4293644
train: epoch 61, iter 1600, loss: 3.085066, top_1: 0.558867, top_k: 0.784727, samples/s: 1739.482 1612882771.146407
train: epoch 61, iter 1700, loss: 2.735930, top_1: 0.562383, top_k: 0.784648, samples/s: 1738.287 1612882785.873476
train: epoch 61, iter 1800, loss: 2.806423, top_1: 0.551992, top_k: 0.782891, samples/s: 1740.279 1612882800.5838268
train: epoch 61, iter 1900, loss: 2.700619, top_1: 0.559453, top_k: 0.786914, samples/s: 1742.805 1612882815.2727556
train: epoch 61, iter 2000, loss: 3.026881, top_1: 0.556523, top_k: 0.783984, samples/s: 1739.878 1612882829.986403
train: epoch 61, iter 2100, loss: 2.860599, top_1: 0.530078, top_k: 0.765625, samples/s: 1742.156 1612882844.6808598
train: epoch 61, iter 2200, loss: 3.100229, top_1: 0.543281, top_k: 0.769570, samples/s: 1750.904 1612882859.3019133
train: epoch 61, iter 2300, loss: 2.889838, top_1: 0.543164, top_k: 0.773438, samples/s: 1736.595 1612882874.04339
train: epoch 61, iter 2400, loss: 2.843993, top_1: 0.547266, top_k: 0.772383, samples/s: 1744.616 1612882888.7171423
train: epoch 61, iter 2500, loss: 3.081847, top_1: 0.542188, top_k: 0.773203, samples/s: 1742.487 1612882903.4087665
train: epoch 61, iter 2600, loss: 2.913928, top_1: 0.549141, top_k: 0.778633, samples/s: 1731.103 1612882918.1969848
train: epoch 61, iter 2700, loss: 2.792880, top_1: 0.548008, top_k: 0.774414, samples/s: 1743.185 1612882932.882818
train: epoch 61, iter 2800, loss: 3.030804, top_1: 0.552070, top_k: 0.778906, samples/s: 1745.344 1612882947.5504217
train: epoch 61, iter 2900, loss: 2.884283, top_1: 0.550742, top_k: 0.781328, samples/s: 1738.878 1612882962.2724848
train: epoch 61, iter 3000, loss: 3.027782, top_1: 0.551250, top_k: 0.779766, samples/s: 1744.263 1612882976.9492157
train: epoch 61, iter 3100, loss: 2.984539, top_1: 0.557500, top_k: 0.782266, samples/s: 1742.207 1612882991.6431863
train: epoch 61, iter 3200, loss: 3.047944, top_1: 0.552070, top_k: 0.778242, samples/s: 1720.554 1612883006.522186
train: epoch 61, iter 3300, loss: 2.763644, top_1: 0.552617, top_k: 0.777852, samples/s: 1749.019 1612883021.158977
train: epoch 61, iter 3400, loss: 2.923177, top_1: 0.555312, top_k: 0.786563, samples/s: 1744.740 1612883035.8315346
train: epoch 61, iter 3500, loss: 2.780974, top_1: 0.552969, top_k: 0.777305, samples/s: 1750.076 1612883050.459484
train: epoch 61, iter 3600, loss: 3.000898, top_1: 0.550977, top_k: 0.779570, samples/s: 1729.950 1612883065.2576084
train: epoch 61, iter 3700, loss: 2.922676, top_1: 0.550508, top_k: 0.775273, samples/s: 1742.818 1612883079.946519
train: epoch 61, iter 3800, loss: 2.819110, top_1: 0.550703, top_k: 0.782891, samples/s: 1745.963 1612883094.6089008
train: epoch 61, iter 3900, loss: 3.032358, top_1: 0.549414, top_k: 0.777852, samples/s: 1744.155 1612883109.2864428
train: epoch 61, iter 4000, loss: 2.986892, top_1: 0.548242, top_k: 0.779102, samples/s: 1750.838 1612883123.908009
train: epoch 61, iter 4100, loss: 2.753361, top_1: 0.554180, top_k: 0.785469, samples/s: 1740.724 1612883138.6145966
train: epoch 61, iter 4200, loss: 2.847391, top_1: 0.559492, top_k: 0.786992, samples/s: 1739.657 1612883153.3300729
train: epoch 61, iter 4300, loss: 2.870672, top_1: 0.549453, top_k: 0.781602, samples/s: 1751.464 1612883167.9464881
train: epoch 61, iter 4400, loss: 2.780293, top_1: 0.555937, top_k: 0.779531, samples/s: 1741.425 1612883182.6470828
train: epoch 61, iter 4500, loss: 2.796087, top_1: 0.556953, top_k: 0.780312, samples/s: 1733.840 1612883197.4121573
train: epoch 61, iter 4600, loss: 3.119530, top_1: 0.555742, top_k: 0.782031, samples/s: 1743.946 1612883212.0913157
train: epoch 61, iter 4700, loss: 2.820792, top_1: 0.551328, top_k: 0.781328, samples/s: 1743.196 1612883226.7770774
train: epoch 61, iter 4800, loss: 2.963040, top_1: 0.556250, top_k: 0.780586, samples/s: 1739.669 1612883241.492468
train: epoch 61, iter 4900, loss: 2.735094, top_1: 0.547539, top_k: 0.778945, samples/s: 1742.889 1612883256.1806836
train: epoch 61, iter 5000, loss: 2.851569, top_1: 0.558320, top_k: 0.782109, samples/s: 1743.757 1612883270.8616092
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_61.
validation: epoch 61, iter 195, top_1: 0.605068, top_k: 0.836558, samples/s: 2760.793 1612883289.3739195
train: epoch 62, iter 100, loss: 2.779109, top_1: 0.559375, top_k: 0.785430, samples/s: 1758.314 1612883324.291501
train: epoch 62, iter 200, loss: 2.646120, top_1: 0.574453, top_k: 0.797461, samples/s: 1757.715 1612883338.855736
train: epoch 62, iter 300, loss: 2.901300, top_1: 0.561836, top_k: 0.785391, samples/s: 1744.118 1612883353.533588
train: epoch 62, iter 400, loss: 2.921832, top_1: 0.560352, top_k: 0.784766, samples/s: 1767.258 1612883368.0193498
train: epoch 62, iter 500, loss: 2.963651, top_1: 0.560781, top_k: 0.789336, samples/s: 1746.587 1612883382.676488
train: epoch 62, iter 600, loss: 2.872792, top_1: 0.563789, top_k: 0.791055, samples/s: 1758.208 1612883397.236799
train: epoch 62, iter 700, loss: 2.705698, top_1: 0.565156, top_k: 0.790273, samples/s: 1729.312 1612883412.0403953
train: epoch 62, iter 800, loss: 2.735733, top_1: 0.559141, top_k: 0.786680, samples/s: 1768.168 1612883426.5188508
train: epoch 62, iter 900, loss: 2.918838, top_1: 0.553828, top_k: 0.785664, samples/s: 1747.048 1612883441.1718984
train: epoch 62, iter 1000, loss: 2.930418, top_1: 0.559492, top_k: 0.788008, samples/s: 1743.840 1612883455.8521507
train: epoch 62, iter 1100, loss: 2.799249, top_1: 0.555820, top_k: 0.783516, samples/s: 1737.709 1612883470.5841649
train: epoch 62, iter 1200, loss: 2.843327, top_1: 0.557461, top_k: 0.786758, samples/s: 1746.700 1612883485.2404141
train: epoch 62, iter 1300, loss: 2.834523, top_1: 0.556211, top_k: 0.787227, samples/s: 1743.808 1612883499.920924
train: epoch 62, iter 1400, loss: 2.703445, top_1: 0.557422, top_k: 0.782305, samples/s: 1735.908 1612883514.6682694
train: epoch 62, iter 1500, loss: 2.933910, top_1: 0.560156, top_k: 0.785781, samples/s: 1746.332 1612883529.3276172
train: epoch 62, iter 1600, loss: 2.931801, top_1: 0.558906, top_k: 0.788320, samples/s: 1747.415 1612883543.9777682
train: epoch 62, iter 1700, loss: 2.599646, top_1: 0.560195, top_k: 0.787852, samples/s: 1739.896 1612883558.6913083
train: epoch 62, iter 1800, loss: 2.640834, top_1: 0.557227, top_k: 0.784297, samples/s: 1741.800 1612883573.3887248
train: epoch 62, iter 1900, loss: 2.870834, top_1: 0.558945, top_k: 0.783867, samples/s: 1736.942 1612883588.1273267
train: epoch 62, iter 2000, loss: 2.747120, top_1: 0.557734, top_k: 0.782109, samples/s: 1739.340 1612883602.8454363
train: epoch 62, iter 2100, loss: 2.612839, top_1: 0.554492, top_k: 0.782813, samples/s: 1739.203 1612883617.5648258
train: epoch 62, iter 2200, loss: 2.936320, top_1: 0.556016, top_k: 0.783867, samples/s: 1742.935 1612883632.2527413
train: epoch 62, iter 2300, loss: 2.630028, top_1: 0.558320, top_k: 0.784375, samples/s: 1742.518 1612883646.944136
train: epoch 62, iter 2400, loss: 2.706193, top_1: 0.559102, top_k: 0.786875, samples/s: 1742.457 1612883661.6360312
train: epoch 62, iter 2500, loss: 2.809365, top_1: 0.554375, top_k: 0.783867, samples/s: 1744.542 1612883676.3103335
train: epoch 62, iter 2600, loss: 2.937599, top_1: 0.555625, top_k: 0.783242, samples/s: 1746.773 1612883690.9659622
train: epoch 62, iter 2700, loss: 3.006026, top_1: 0.551250, top_k: 0.781328, samples/s: 1741.113 1612883705.6692045
train: epoch 62, iter 2800, loss: 2.685103, top_1: 0.564180, top_k: 0.791016, samples/s: 1742.244 1612883720.3628724
train: epoch 62, iter 2900, loss: 2.829646, top_1: 0.553516, top_k: 0.780234, samples/s: 1742.735 1612883735.0524049
train: epoch 62, iter 3000, loss: 2.885341, top_1: 0.556836, top_k: 0.783359, samples/s: 1733.421 1612883749.8209217
train: epoch 62, iter 3100, loss: 2.744248, top_1: 0.555547, top_k: 0.786914, samples/s: 1751.895 1612883764.4336185
train: epoch 62, iter 3200, loss: 2.859142, top_1: 0.552852, top_k: 0.783359, samples/s: 1743.890 1612883779.1134975
train: epoch 62, iter 3300, loss: 2.794461, top_1: 0.553164, top_k: 0.782773, samples/s: 1745.567 1612883793.779235
train: epoch 62, iter 3400, loss: 2.892864, top_1: 0.555234, top_k: 0.784102, samples/s: 1741.966 1612883808.4752305
train: epoch 62, iter 3500, loss: 2.794967, top_1: 0.555117, top_k: 0.783984, samples/s: 1749.149 1612883823.1109555
train: epoch 62, iter 3600, loss: 2.968516, top_1: 0.552656, top_k: 0.779180, samples/s: 1741.712 1612883837.809094
train: epoch 62, iter 3700, loss: 2.879442, top_1: 0.551992, top_k: 0.780547, samples/s: 1738.497 1612883852.534493
train: epoch 62, iter 3800, loss: 2.897528, top_1: 0.552734, top_k: 0.780000, samples/s: 1741.584 1612883867.2337444
train: epoch 62, iter 3900, loss: 2.946849, top_1: 0.553906, top_k: 0.781172, samples/s: 1754.158 1612883881.827606
train: epoch 62, iter 4000, loss: 2.686678, top_1: 0.557305, top_k: 0.782500, samples/s: 1751.847 1612883896.440764
train: epoch 62, iter 4100, loss: 3.077077, top_1: 0.554609, top_k: 0.783750, samples/s: 1746.083 1612883911.1021245
train: epoch 62, iter 4200, loss: 2.934756, top_1: 0.555156, top_k: 0.781172, samples/s: 1743.416 1612883925.786004
train: epoch 62, iter 4300, loss: 2.712983, top_1: 0.554453, top_k: 0.782148, samples/s: 1736.298 1612883940.5299623
train: epoch 62, iter 4400, loss: 2.865524, top_1: 0.554453, top_k: 0.780547, samples/s: 1748.955 1612883955.1673114
train: epoch 62, iter 4500, loss: 2.973063, top_1: 0.550859, top_k: 0.782969, samples/s: 1746.037 1612883969.8291147
train: epoch 62, iter 4600, loss: 2.822428, top_1: 0.554688, top_k: 0.783047, samples/s: 1746.135 1612883984.490031
train: epoch 62, iter 4700, loss: 2.912689, top_1: 0.561328, top_k: 0.787813, samples/s: 1748.041 1612883999.13503
train: epoch 62, iter 4800, loss: 2.974343, top_1: 0.558672, top_k: 0.787695, samples/s: 1742.243 1612884013.828703
train: epoch 62, iter 4900, loss: 2.916382, top_1: 0.555508, top_k: 0.781094, samples/s: 1743.507 1612884028.5117977
train: epoch 62, iter 5000, loss: 2.680700, top_1: 0.552695, top_k: 0.781094, samples/s: 1748.909 1612884043.1494524
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_62.
validation: epoch 62, iter 195, top_1: 0.593389, top_k: 0.828806, samples/s: 2885.083 1612884060.8882787
train: epoch 63, iter 100, loss: 2.979271, top_1: 0.565273, top_k: 0.792461, samples/s: 1745.881 1612884095.6443856
train: epoch 63, iter 200, loss: 2.883560, top_1: 0.572266, top_k: 0.793633, samples/s: 1760.267 1612884110.1875682
train: epoch 63, iter 300, loss: 2.738639, top_1: 0.563594, top_k: 0.789141, samples/s: 1758.588 1612884124.744757
train: epoch 63, iter 400, loss: 2.654834, top_1: 0.567109, top_k: 0.791914, samples/s: 1758.975 1612884139.2987971
train: epoch 63, iter 500, loss: 3.158669, top_1: 0.561328, top_k: 0.790352, samples/s: 1756.134 1612884153.8761537
train: epoch 63, iter 600, loss: 2.788775, top_1: 0.561719, top_k: 0.785742, samples/s: 1761.725 1612884168.4073713
train: epoch 63, iter 700, loss: 2.938024, top_1: 0.560078, top_k: 0.787891, samples/s: 1758.755 1612884182.9630597
train: epoch 63, iter 800, loss: 2.748524, top_1: 0.560469, top_k: 0.788164, samples/s: 1738.864 1612884197.6853118
train: epoch 63, iter 900, loss: 2.981235, top_1: 0.559375, top_k: 0.791289, samples/s: 1735.106 1612884212.439508
train: epoch 63, iter 1000, loss: 3.081625, top_1: 0.561172, top_k: 0.787188, samples/s: 1751.274 1612884227.0573828
train: epoch 63, iter 1100, loss: 2.866794, top_1: 0.565469, top_k: 0.790039, samples/s: 1732.897 1612884241.8303623
train: epoch 63, iter 1200, loss: 2.830714, top_1: 0.559805, top_k: 0.786563, samples/s: 1757.514 1612884256.3964078
train: epoch 63, iter 1300, loss: 3.002723, top_1: 0.555078, top_k: 0.780430, samples/s: 1742.849 1612884271.0850005
train: epoch 63, iter 1400, loss: 2.696773, top_1: 0.560625, top_k: 0.787227, samples/s: 1747.640 1612884285.7332802
train: epoch 63, iter 1500, loss: 3.071056, top_1: 0.555820, top_k: 0.786680, samples/s: 1732.701 1612884300.507948
train: epoch 63, iter 1600, loss: 2.883607, top_1: 0.561406, top_k: 0.789727, samples/s: 1742.045 1612884315.2033167
train: epoch 63, iter 1700, loss: 2.831853, top_1: 0.555664, top_k: 0.783984, samples/s: 1745.009 1612884329.8737252
train: epoch 63, iter 1800, loss: 2.794643, top_1: 0.557383, top_k: 0.784180, samples/s: 1738.435 1612884344.5996852
train: epoch 63, iter 1900, loss: 2.994663, top_1: 0.556797, top_k: 0.783867, samples/s: 1749.957 1612884359.2285025
train: epoch 63, iter 2000, loss: 2.859766, top_1: 0.558750, top_k: 0.787578, samples/s: 1751.775 1612884373.8423152
train: epoch 63, iter 2100, loss: 2.782590, top_1: 0.556133, top_k: 0.782734, samples/s: 1729.364 1612884388.645438
train: epoch 63, iter 2200, loss: 3.041588, top_1: 0.555039, top_k: 0.782266, samples/s: 1745.585 1612884403.311035
train: epoch 63, iter 2300, loss: 3.015825, top_1: 0.557734, top_k: 0.785039, samples/s: 1752.482 1612884417.918829
train: epoch 63, iter 2400, loss: 2.710005, top_1: 0.554609, top_k: 0.782461, samples/s: 1737.199 1612884432.6551595
train: epoch 63, iter 2500, loss: 2.862627, top_1: 0.558086, top_k: 0.786094, samples/s: 1747.586 1612884447.30393
train: epoch 63, iter 2600, loss: 2.969190, top_1: 0.555586, top_k: 0.787578, samples/s: 1744.687 1612884461.9770992
train: epoch 63, iter 2700, loss: 2.798648, top_1: 0.558203, top_k: 0.789336, samples/s: 1740.358 1612884476.6867852
train: epoch 63, iter 2800, loss: 2.933649, top_1: 0.556992, top_k: 0.786758, samples/s: 1745.607 1612884491.3522074
train: epoch 63, iter 2900, loss: 2.690288, top_1: 0.554180, top_k: 0.785586, samples/s: 1743.160 1612884506.0380678
train: epoch 63, iter 3000, loss: 2.633268, top_1: 0.553711, top_k: 0.785859, samples/s: 1744.946 1612884520.7090151
train: epoch 63, iter 3100, loss: 2.788278, top_1: 0.558281, top_k: 0.787891, samples/s: 1743.381 1612884535.3931284
train: epoch 63, iter 3200, loss: 2.762566, top_1: 0.558438, top_k: 0.783086, samples/s: 1751.604 1612884550.0083172
train: epoch 63, iter 3300, loss: 2.788052, top_1: 0.560469, top_k: 0.788438, samples/s: 1735.380 1612884564.7600946
train: epoch 63, iter 3400, loss: 2.865208, top_1: 0.554297, top_k: 0.783867, samples/s: 1743.856 1612884579.440281
train: epoch 63, iter 3500, loss: 3.043201, top_1: 0.556797, top_k: 0.780781, samples/s: 1749.700 1612884594.0713506
train: epoch 63, iter 3600, loss: 2.831820, top_1: 0.558477, top_k: 0.785273, samples/s: 1735.437 1612884608.8226848
train: epoch 63, iter 3700, loss: 2.706209, top_1: 0.558750, top_k: 0.783789, samples/s: 1741.304 1612884623.524305
train: epoch 63, iter 3800, loss: 2.933038, top_1: 0.559766, top_k: 0.785742, samples/s: 1736.567 1612884638.2659876
train: epoch 63, iter 3900, loss: 2.784362, top_1: 0.556016, top_k: 0.785703, samples/s: 1743.407 1612884652.9499042
train: epoch 63, iter 4000, loss: 2.668449, top_1: 0.557187, top_k: 0.784258, samples/s: 1743.520 1612884667.6328847
train: epoch 63, iter 4100, loss: 2.678395, top_1: 0.555625, top_k: 0.784961, samples/s: 1744.367 1612884682.3086357
train: epoch 63, iter 4200, loss: 2.862643, top_1: 0.557930, top_k: 0.784219, samples/s: 1730.763 1612884697.0997374
train: epoch 63, iter 4300, loss: 2.886316, top_1: 0.553242, top_k: 0.781328, samples/s: 1752.185 1612884711.7101407
train: epoch 63, iter 4400, loss: 2.858395, top_1: 0.558438, top_k: 0.785859, samples/s: 1753.024 1612884726.313438
train: epoch 63, iter 4500, loss: 2.784574, top_1: 0.553398, top_k: 0.781328, samples/s: 1742.000 1612884741.009217
train: epoch 63, iter 4600, loss: 2.895592, top_1: 0.553789, top_k: 0.784570, samples/s: 1738.759 1612884755.7323313
train: epoch 63, iter 4700, loss: 2.828576, top_1: 0.556758, top_k: 0.783320, samples/s: 1744.832 1612884770.4043033
train: epoch 63, iter 4800, loss: 2.926074, top_1: 0.551875, top_k: 0.785156, samples/s: 1739.256 1612884785.123206
train: epoch 63, iter 4900, loss: 2.860080, top_1: 0.552969, top_k: 0.781445, samples/s: 1753.350 1612884799.7237842
train: epoch 63, iter 5000, loss: 2.741047, top_1: 0.553477, top_k: 0.784844, samples/s: 1741.169 1612884814.4265895
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_63.
validation: epoch 63, iter 195, top_1: 0.606671, top_k: 0.838321, samples/s: 2793.425 1612884832.7686841
train: epoch 64, iter 100, loss: 2.746695, top_1: 0.571211, top_k: 0.792148, samples/s: 1754.336 1612884867.388701
train: epoch 64, iter 200, loss: 2.759566, top_1: 0.567383, top_k: 0.792070, samples/s: 1755.012 1612884881.97576
train: epoch 64, iter 300, loss: 2.864223, top_1: 0.571602, top_k: 0.792422, samples/s: 1762.510 1612884896.5002484
train: epoch 64, iter 400, loss: 2.748629, top_1: 0.566562, top_k: 0.792344, samples/s: 1759.726 1612884911.0478635
train: epoch 64, iter 500, loss: 2.792279, top_1: 0.565312, top_k: 0.788477, samples/s: 1750.342 1612884925.673686
train: epoch 64, iter 600, loss: 2.786044, top_1: 0.561758, top_k: 0.788125, samples/s: 1760.649 1612884940.2136564
train: epoch 64, iter 700, loss: 2.835425, top_1: 0.561406, top_k: 0.788750, samples/s: 1755.517 1612884954.7962768
train: epoch 64, iter 800, loss: 2.944093, top_1: 0.564180, top_k: 0.787227, samples/s: 1749.645 1612884969.427836
train: epoch 64, iter 900, loss: 2.784913, top_1: 0.564805, top_k: 0.794883, samples/s: 1732.996 1612884984.1999826
train: epoch 64, iter 1000, loss: 3.096643, top_1: 0.568516, top_k: 0.789297, samples/s: 1736.633 1612884998.941197
train: epoch 64, iter 1100, loss: 2.654960, top_1: 0.561406, top_k: 0.792773, samples/s: 1751.856 1612885013.554154
train: epoch 64, iter 1200, loss: 2.922487, top_1: 0.556484, top_k: 0.788359, samples/s: 1740.584 1612885028.2618885
train: epoch 64, iter 1300, loss: 2.838420, top_1: 0.570234, top_k: 0.788125, samples/s: 1733.439 1612885043.0301886
train: epoch 64, iter 1400, loss: 2.879200, top_1: 0.556367, top_k: 0.787383, samples/s: 1730.111 1612885057.8269453
train: epoch 64, iter 1500, loss: 3.095361, top_1: 0.561641, top_k: 0.787656, samples/s: 1756.736 1612885072.3994355
train: epoch 64, iter 1600, loss: 2.985003, top_1: 0.560977, top_k: 0.787500, samples/s: 1734.905 1612885087.1553137
train: epoch 64, iter 1700, loss: 2.754564, top_1: 0.561484, top_k: 0.784258, samples/s: 1764.145 1612885101.6665847
train: epoch 64, iter 1800, loss: 2.613438, top_1: 0.554805, top_k: 0.782461, samples/s: 1730.284 1612885116.461801
train: epoch 64, iter 1900, loss: 2.949954, top_1: 0.560430, top_k: 0.788594, samples/s: 1728.296 1612885131.27405
train: epoch 64, iter 2000, loss: 3.026287, top_1: 0.565508, top_k: 0.786328, samples/s: 1745.771 1612885145.938058
train: epoch 64, iter 2100, loss: 2.885429, top_1: 0.562344, top_k: 0.791133, samples/s: 1754.235 1612885160.531371
train: epoch 64, iter 2200, loss: 2.810037, top_1: 0.564375, top_k: 0.789922, samples/s: 1735.594 1612885175.2813632
train: epoch 64, iter 2300, loss: 2.589878, top_1: 0.566133, top_k: 0.791367, samples/s: 1742.651 1612885189.971629
train: epoch 64, iter 2400, loss: 2.768257, top_1: 0.560625, top_k: 0.790937, samples/s: 1743.719 1612885204.6529028
train: epoch 64, iter 2500, loss: 2.717059, top_1: 0.555469, top_k: 0.785859, samples/s: 1740.030 1612885219.3653305
train: epoch 64, iter 2600, loss: 2.672830, top_1: 0.559492, top_k: 0.787500, samples/s: 1748.938 1612885234.0027738
train: epoch 64, iter 2700, loss: 2.962775, top_1: 0.562461, top_k: 0.790625, samples/s: 1749.948 1612885248.6317377
train: epoch 64, iter 2800, loss: 3.068424, top_1: 0.560859, top_k: 0.787852, samples/s: 1736.119 1612885263.3773189
train: epoch 64, iter 2900, loss: 2.878584, top_1: 0.557461, top_k: 0.785039, samples/s: 1744.576 1612885278.0512652
train: epoch 64, iter 3000, loss: 2.851329, top_1: 0.556523, top_k: 0.784961, samples/s: 1730.814 1612885292.8420446
train: epoch 64, iter 3100, loss: 3.086596, top_1: 0.556562, top_k: 0.782656, samples/s: 1749.192 1612885307.477395
train: epoch 64, iter 3200, loss: 2.808337, top_1: 0.562773, top_k: 0.788945, samples/s: 1748.357 1612885322.119701
train: epoch 64, iter 3300, loss: 2.855468, top_1: 0.557305, top_k: 0.784531, samples/s: 1743.988 1612885336.7986364
train: epoch 64, iter 3400, loss: 2.904829, top_1: 0.554258, top_k: 0.780625, samples/s: 1736.650 1612885351.5397353
train: epoch 64, iter 3500, loss: 2.813877, top_1: 0.555234, top_k: 0.785664, samples/s: 1750.263 1612885366.1660984
train: epoch 64, iter 3600, loss: 2.963187, top_1: 0.557227, top_k: 0.783633, samples/s: 1745.554 1612885380.8319783
train: epoch 64, iter 3700, loss: 2.702365, top_1: 0.559063, top_k: 0.785117, samples/s: 1724.123 1612885395.6800542
train: epoch 64, iter 3800, loss: 2.664155, top_1: 0.558398, top_k: 0.787617, samples/s: 1749.127 1612885410.3159852
train: epoch 64, iter 3900, loss: 2.898888, top_1: 0.555352, top_k: 0.783164, samples/s: 1738.772 1612885425.039005
train: epoch 64, iter 4000, loss: 2.841054, top_1: 0.562734, top_k: 0.787461, samples/s: 1747.884 1612885439.6852071
train: epoch 64, iter 4100, loss: 2.793215, top_1: 0.558281, top_k: 0.785273, samples/s: 1754.550 1612885454.2758787
train: epoch 64, iter 4200, loss: 2.815937, top_1: 0.556484, top_k: 0.781094, samples/s: 1739.888 1612885468.9894772
train: epoch 64, iter 4300, loss: 2.833281, top_1: 0.557813, top_k: 0.787930, samples/s: 1744.598 1612885483.663311
train: epoch 64, iter 4400, loss: 2.571501, top_1: 0.557695, top_k: 0.782188, samples/s: 1746.700 1612885498.3195305
train: epoch 64, iter 4500, loss: 2.737471, top_1: 0.556641, top_k: 0.788477, samples/s: 1749.406 1612885512.9530838
train: epoch 64, iter 4600, loss: 2.762138, top_1: 0.553906, top_k: 0.779336, samples/s: 1749.639 1612885527.5846782
train: epoch 64, iter 4700, loss: 2.714480, top_1: 0.557930, top_k: 0.776602, samples/s: 1731.856 1612885542.366519
train: epoch 64, iter 4800, loss: 2.785815, top_1: 0.557773, top_k: 0.783438, samples/s: 1748.005 1612885557.011781
train: epoch 64, iter 4900, loss: 2.925882, top_1: 0.555625, top_k: 0.783867, samples/s: 1752.668 1612885571.6181183
train: epoch 64, iter 5000, loss: 2.938579, top_1: 0.557930, top_k: 0.783086, samples/s: 1727.675 1612885586.435673
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_64.
validation: epoch 64, iter 195, top_1: 0.590345, top_k: 0.824038, samples/s: 2841.406 1612885604.3911772
train: epoch 65, iter 100, loss: 2.808637, top_1: 0.574141, top_k: 0.795977, samples/s: 1756.233 1612885640.1663477
train: epoch 65, iter 200, loss: 2.893572, top_1: 0.572734, top_k: 0.793242, samples/s: 1757.658 1612885654.7311256
train: epoch 65, iter 300, loss: 2.978962, top_1: 0.572305, top_k: 0.798750, samples/s: 1759.723 1612885669.2788165
train: epoch 65, iter 400, loss: 2.927470, top_1: 0.560664, top_k: 0.788633, samples/s: 1758.951 1612885683.8330142
train: epoch 65, iter 500, loss: 2.882082, top_1: 0.567187, top_k: 0.795508, samples/s: 1752.415 1612885698.441448
train: epoch 65, iter 600, loss: 2.850671, top_1: 0.566641, top_k: 0.793711, samples/s: 1746.388 1612885713.1002533
train: epoch 65, iter 700, loss: 2.713027, top_1: 0.560273, top_k: 0.789844, samples/s: 1754.610 1612885727.6903856
train: epoch 65, iter 800, loss: 2.754503, top_1: 0.566055, top_k: 0.792031, samples/s: 1754.289 1612885742.2831733
train: epoch 65, iter 900, loss: 2.830785, top_1: 0.556914, top_k: 0.786797, samples/s: 1746.883 1612885756.937856
train: epoch 65, iter 1000, loss: 2.747270, top_1: 0.565586, top_k: 0.791211, samples/s: 1753.973 1612885771.5333107
train: epoch 65, iter 1100, loss: 2.769645, top_1: 0.566328, top_k: 0.791094, samples/s: 1731.338 1612885786.319548
train: epoch 65, iter 1200, loss: 2.721694, top_1: 0.565000, top_k: 0.795430, samples/s: 1743.202 1612885801.0051208
train: epoch 65, iter 1300, loss: 2.590007, top_1: 0.556367, top_k: 0.788320, samples/s: 1746.475 1612885815.6632583
train: epoch 65, iter 1400, loss: 2.746485, top_1: 0.564297, top_k: 0.787500, samples/s: 1745.632 1612885830.3283925
train: epoch 65, iter 1500, loss: 2.776351, top_1: 0.558828, top_k: 0.787656, samples/s: 1738.873 1612885845.0506268
train: epoch 65, iter 1600, loss: 2.760016, top_1: 0.560820, top_k: 0.788047, samples/s: 1745.300 1612885859.718582
train: epoch 65, iter 1700, loss: 2.901434, top_1: 0.559141, top_k: 0.786406, samples/s: 1723.896 1612885874.56862
train: epoch 65, iter 1800, loss: 2.881258, top_1: 0.559219, top_k: 0.789375, samples/s: 1736.993 1612885889.306823
train: epoch 65, iter 1900, loss: 2.964828, top_1: 0.562187, top_k: 0.793945, samples/s: 1763.166 1612885903.8260658
train: epoch 65, iter 2000, loss: 2.713362, top_1: 0.562266, top_k: 0.787969, samples/s: 1734.998 1612885918.581191
train: epoch 65, iter 2100, loss: 2.751517, top_1: 0.563516, top_k: 0.788711, samples/s: 1729.241 1612885933.3853464
train: epoch 65, iter 2200, loss: 3.132622, top_1: 0.559023, top_k: 0.784570, samples/s: 1750.965 1612885948.0058873
train: epoch 65, iter 2300, loss: 2.831405, top_1: 0.558750, top_k: 0.786875, samples/s: 1736.340 1612885962.749527
train: epoch 65, iter 2400, loss: 2.798417, top_1: 0.560937, top_k: 0.786172, samples/s: 1735.755 1612885977.4980874
train: epoch 65, iter 2500, loss: 2.853826, top_1: 0.561953, top_k: 0.786367, samples/s: 1753.065 1612885992.1011732
train: epoch 65, iter 2600, loss: 2.906246, top_1: 0.558242, top_k: 0.783359, samples/s: 1729.018 1612886006.9072511
train: epoch 65, iter 2700, loss: 2.903935, top_1: 0.562266, top_k: 0.788555, samples/s: 1741.346 1612886021.6085289
train: epoch 65, iter 2800, loss: 2.565184, top_1: 0.562969, top_k: 0.790078, samples/s: 1752.164 1612886036.2189958
train: epoch 65, iter 2900, loss: 2.938539, top_1: 0.556016, top_k: 0.787617, samples/s: 1732.059 1612886050.999102
train: epoch 65, iter 3000, loss: 2.942829, top_1: 0.556836, top_k: 0.789805, samples/s: 1753.398 1612886065.599694
train: epoch 65, iter 3100, loss: 2.987216, top_1: 0.556055, top_k: 0.783789, samples/s: 1743.284 1612886080.2842166
train: epoch 65, iter 3200, loss: 2.883443, top_1: 0.561602, top_k: 0.784687, samples/s: 1742.507 1612886094.9757652
train: epoch 65, iter 3300, loss: 2.635116, top_1: 0.563906, top_k: 0.787539, samples/s: 1743.373 1612886109.659932
train: epoch 65, iter 3400, loss: 2.855758, top_1: 0.554766, top_k: 0.782070, samples/s: 1743.781 1612886124.341043
train: epoch 65, iter 3500, loss: 2.790375, top_1: 0.563477, top_k: 0.783945, samples/s: 1741.226 1612886139.0428932
train: epoch 65, iter 3600, loss: 2.757794, top_1: 0.560273, top_k: 0.789102, samples/s: 1739.491 1612886153.7599285
train: epoch 65, iter 3700, loss: 2.801916, top_1: 0.558750, top_k: 0.783008, samples/s: 1757.570 1612886168.3254328
train: epoch 65, iter 3800, loss: 2.885906, top_1: 0.559961, top_k: 0.784648, samples/s: 1741.033 1612886183.0293062
train: epoch 65, iter 3900, loss: 2.781141, top_1: 0.558164, top_k: 0.782578, samples/s: 1747.456 1612886197.6792297
train: epoch 65, iter 4000, loss: 2.933561, top_1: 0.560977, top_k: 0.786211, samples/s: 1743.082 1612886212.3658733
train: epoch 65, iter 4100, loss: 3.023505, top_1: 0.553008, top_k: 0.784258, samples/s: 1738.312 1612886227.0928361
train: epoch 65, iter 4200, loss: 2.685153, top_1: 0.560742, top_k: 0.785703, samples/s: 1748.453 1612886241.7342517
train: epoch 65, iter 4300, loss: 2.811114, top_1: 0.555820, top_k: 0.780937, samples/s: 1744.802 1612886256.4064586
train: epoch 65, iter 4400, loss: 2.813266, top_1: 0.561953, top_k: 0.789531, samples/s: 1748.496 1612886271.047671
train: epoch 65, iter 4500, loss: 2.766093, top_1: 0.555312, top_k: 0.780469, samples/s: 1732.776 1612886285.8216372
train: epoch 65, iter 4600, loss: 2.678076, top_1: 0.561289, top_k: 0.786875, samples/s: 1741.837 1612886300.5186973
train: epoch 65, iter 4700, loss: 2.774199, top_1: 0.557578, top_k: 0.783750, samples/s: 1735.000 1612886315.2738023
train: epoch 65, iter 4800, loss: 2.732938, top_1: 0.565117, top_k: 0.789414, samples/s: 1754.322 1612886329.8662453
train: epoch 65, iter 4900, loss: 2.915215, top_1: 0.559648, top_k: 0.784648, samples/s: 1747.730 1612886344.513838
train: epoch 65, iter 5000, loss: 2.651639, top_1: 0.558242, top_k: 0.789062, samples/s: 1728.412 1612886359.3251107
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_65.
validation: epoch 65, iter 195, top_1: 0.606070, top_k: 0.837620, samples/s: 2807.096 1612886377.582608
train: epoch 66, iter 100, loss: 2.793157, top_1: 0.567852, top_k: 0.792695, samples/s: 1744.804 1612886412.4675198
train: epoch 66, iter 200, loss: 2.872045, top_1: 0.570312, top_k: 0.795703, samples/s: 1760.322 1612886427.0105288
train: epoch 66, iter 300, loss: 2.914361, top_1: 0.567969, top_k: 0.790586, samples/s: 1757.907 1612886441.5730906
train: epoch 66, iter 400, loss: 2.805237, top_1: 0.565000, top_k: 0.792422, samples/s: 1758.611 1612886456.129962
train: epoch 66, iter 500, loss: 2.926684, top_1: 0.569922, top_k: 0.792031, samples/s: 1756.058 1612886470.7081516
train: epoch 66, iter 600, loss: 2.765440, top_1: 0.570195, top_k: 0.795547, samples/s: 1755.626 1612886485.289908
train: epoch 66, iter 700, loss: 2.865197, top_1: 0.565508, top_k: 0.792305, samples/s: 1744.783 1612886499.9621346
train: epoch 66, iter 800, loss: 2.878932, top_1: 0.566211, top_k: 0.791328, samples/s: 1747.074 1612886514.6152792
train: epoch 66, iter 900, loss: 2.838221, top_1: 0.565273, top_k: 0.792734, samples/s: 1753.426 1612886529.2152283
train: epoch 66, iter 1000, loss: 2.802631, top_1: 0.562500, top_k: 0.786523, samples/s: 1736.096 1612886543.9609122
train: epoch 66, iter 1100, loss: 2.895700, top_1: 0.570117, top_k: 0.791016, samples/s: 1738.045 1612886558.6900895
train: epoch 66, iter 1200, loss: 2.878633, top_1: 0.568672, top_k: 0.789648, samples/s: 1745.069 1612886573.3603554
train: epoch 66, iter 1300, loss: 2.592783, top_1: 0.569453, top_k: 0.793516, samples/s: 1740.946 1612886588.0646784
train: epoch 66, iter 1400, loss: 2.768873, top_1: 0.568789, top_k: 0.791211, samples/s: 1740.053 1612886602.777203
train: epoch 66, iter 1500, loss: 2.763766, top_1: 0.564961, top_k: 0.791758, samples/s: 1749.958 1612886617.405833
train: epoch 66, iter 1600, loss: 2.966518, top_1: 0.559297, top_k: 0.785391, samples/s: 1748.265 1612886632.048882
train: epoch 66, iter 1700, loss: 2.677731, top_1: 0.567148, top_k: 0.793086, samples/s: 1754.021 1612886646.6439004
train: epoch 66, iter 1800, loss: 2.858507, top_1: 0.560977, top_k: 0.790820, samples/s: 1746.176 1612886661.3045359
train: epoch 66, iter 1900, loss: 2.705539, top_1: 0.565078, top_k: 0.789648, samples/s: 1733.928 1612886676.0686626
train: epoch 66, iter 2000, loss: 2.680224, top_1: 0.563945, top_k: 0.785625, samples/s: 1737.053 1612886690.806314
train: epoch 66, iter 2100, loss: 2.667205, top_1: 0.563008, top_k: 0.789102, samples/s: 1746.833 1612886705.4613929
train: epoch 66, iter 2200, loss: 2.943903, top_1: 0.560156, top_k: 0.787422, samples/s: 1750.420 1612886720.0864599
train: epoch 66, iter 2300, loss: 2.839073, top_1: 0.558672, top_k: 0.784414, samples/s: 1739.685 1612886734.8017228
train: epoch 66, iter 2400, loss: 3.011826, top_1: 0.561680, top_k: 0.785937, samples/s: 1722.972 1612886749.6597767
train: epoch 66, iter 2500, loss: 2.793976, top_1: 0.566367, top_k: 0.789219, samples/s: 1735.502 1612886764.4105508
train: epoch 66, iter 2600, loss: 2.674217, top_1: 0.568125, top_k: 0.788047, samples/s: 1747.944 1612886779.0563104
train: epoch 66, iter 2700, loss: 2.870305, top_1: 0.558281, top_k: 0.788047, samples/s: 1746.468 1612886793.714532
train: epoch 66, iter 2800, loss: 2.981836, top_1: 0.564023, top_k: 0.792656, samples/s: 1731.849 1612886808.4964015
train: epoch 66, iter 2900, loss: 2.843574, top_1: 0.559883, top_k: 0.788242, samples/s: 1746.325 1612886823.155778
train: epoch 66, iter 3000, loss: 2.938397, top_1: 0.564844, top_k: 0.790391, samples/s: 1742.974 1612886837.8433638
train: epoch 66, iter 3100, loss: 2.879734, top_1: 0.558047, top_k: 0.788359, samples/s: 1749.708 1612886852.4743254
train: epoch 66, iter 3200, loss: 2.792647, top_1: 0.561133, top_k: 0.786758, samples/s: 1743.128 1612886867.1605067
train: epoch 66, iter 3300, loss: 2.849987, top_1: 0.567227, top_k: 0.788555, samples/s: 1740.410 1612886881.8697183
train: epoch 66, iter 3400, loss: 2.933622, top_1: 0.560703, top_k: 0.784102, samples/s: 1736.948 1612886896.6081874
train: epoch 66, iter 3500, loss: 2.710864, top_1: 0.566523, top_k: 0.792852, samples/s: 1741.366 1612886911.3092961
train: epoch 66, iter 3600, loss: 2.735645, top_1: 0.561875, top_k: 0.784180, samples/s: 1743.061 1612886925.9961534
train: epoch 66, iter 3700, loss: 2.797918, top_1: 0.556094, top_k: 0.782070, samples/s: 1735.203 1612886940.7494252
train: epoch 66, iter 3800, loss: 2.707794, top_1: 0.559336, top_k: 0.785977, samples/s: 1747.936 1612886955.3952596
train: epoch 66, iter 3900, loss: 2.656880, top_1: 0.562187, top_k: 0.785781, samples/s: 1727.211 1612886970.2169225
train: epoch 66, iter 4000, loss: 2.859938, top_1: 0.557266, top_k: 0.782070, samples/s: 1739.492 1612886984.933845
train: epoch 66, iter 4100, loss: 2.784547, top_1: 0.559492, top_k: 0.786523, samples/s: 1745.098 1612886999.6035423
train: epoch 66, iter 4200, loss: 2.917683, top_1: 0.561602, top_k: 0.792344, samples/s: 1745.699 1612887014.2681057
train: epoch 66, iter 4300, loss: 2.827092, top_1: 0.556602, top_k: 0.784844, samples/s: 1739.573 1612887028.9843314
train: epoch 66, iter 4400, loss: 2.843456, top_1: 0.559648, top_k: 0.784297, samples/s: 1733.211 1612887043.7545753
train: epoch 66, iter 4500, loss: 2.833996, top_1: 0.555273, top_k: 0.782734, samples/s: 1749.857 1612887058.3843694
train: epoch 66, iter 4600, loss: 2.742293, top_1: 0.560625, top_k: 0.784844, samples/s: 1750.817 1612887073.0061128
train: epoch 66, iter 4700, loss: 2.628185, top_1: 0.560625, top_k: 0.788594, samples/s: 1746.615 1612887087.6630898
train: epoch 66, iter 4800, loss: 2.726618, top_1: 0.559258, top_k: 0.788125, samples/s: 1737.737 1612887102.394821
train: epoch 66, iter 4900, loss: 2.956253, top_1: 0.560781, top_k: 0.786719, samples/s: 1736.216 1612887117.1395698
train: epoch 66, iter 5000, loss: 2.830971, top_1: 0.567539, top_k: 0.792070, samples/s: 1723.943 1612887131.989261
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_66.
validation: epoch 66, iter 195, top_1: 0.610357, top_k: 0.839603, samples/s: 2867.728 1612887149.6778488
train: epoch 67, iter 100, loss: 2.928900, top_1: 0.571914, top_k: 0.796719, samples/s: 1754.346 1612887184.391553
train: epoch 67, iter 200, loss: 2.706239, top_1: 0.572305, top_k: 0.796992, samples/s: 1759.197 1612887198.9436502
train: epoch 67, iter 300, loss: 2.673807, top_1: 0.565781, top_k: 0.792969, samples/s: 1759.197 1612887213.4957616
train: epoch 67, iter 400, loss: 2.848837, top_1: 0.569258, top_k: 0.794766, samples/s: 1751.501 1612887228.111748
train: epoch 67, iter 500, loss: 2.642800, top_1: 0.569570, top_k: 0.793516, samples/s: 1758.825 1612887242.6670208
train: epoch 67, iter 600, loss: 2.819231, top_1: 0.570000, top_k: 0.798164, samples/s: 1758.565 1612887257.2242987
train: epoch 67, iter 700, loss: 2.672422, top_1: 0.567422, top_k: 0.792891, samples/s: 1741.874 1612887271.9210384
train: epoch 67, iter 800, loss: 2.732210, top_1: 0.570117, top_k: 0.797578, samples/s: 1748.413 1612887286.5629294
train: epoch 67, iter 900, loss: 2.984228, top_1: 0.562773, top_k: 0.788906, samples/s: 1747.348 1612887301.2136548
train: epoch 67, iter 1000, loss: 2.758707, top_1: 0.568008, top_k: 0.794180, samples/s: 1732.601 1612887315.9892027
train: epoch 67, iter 1100, loss: 2.911769, top_1: 0.566914, top_k: 0.793320, samples/s: 1739.102 1612887330.7093787
train: epoch 67, iter 1200, loss: 2.797070, top_1: 0.566094, top_k: 0.793086, samples/s: 1744.980 1612887345.3800333
train: epoch 67, iter 1300, loss: 2.984653, top_1: 0.568242, top_k: 0.791719, samples/s: 1740.461 1612887360.0887845
train: epoch 67, iter 1400, loss: 2.753165, top_1: 0.564219, top_k: 0.786406, samples/s: 1751.870 1612887374.7017353
train: epoch 67, iter 1500, loss: 2.904055, top_1: 0.565391, top_k: 0.786406, samples/s: 1733.115 1612887389.472882
train: epoch 67, iter 1600, loss: 2.748835, top_1: 0.566758, top_k: 0.794102, samples/s: 1736.424 1612887404.2157757
train: epoch 67, iter 1700, loss: 2.752990, top_1: 0.560664, top_k: 0.789687, samples/s: 1734.765 1612887418.9728491
train: epoch 67, iter 1800, loss: 2.892678, top_1: 0.559219, top_k: 0.791211, samples/s: 1751.730 1612887433.5869477
train: epoch 67, iter 1900, loss: 2.713651, top_1: 0.567578, top_k: 0.791016, samples/s: 1752.457 1612887448.1950202
train: epoch 67, iter 2000, loss: 2.687599, top_1: 0.568945, top_k: 0.792734, samples/s: 1743.424 1612887462.8787875
train: epoch 67, iter 2100, loss: 2.952024, top_1: 0.561914, top_k: 0.788359, samples/s: 1731.128 1612887477.6668441
train: epoch 67, iter 2200, loss: 2.776252, top_1: 0.559023, top_k: 0.787305, samples/s: 1729.221 1612887492.471238
train: epoch 67, iter 2300, loss: 2.672813, top_1: 0.568281, top_k: 0.793359, samples/s: 1750.997 1612887507.091419
train: epoch 67, iter 2400, loss: 2.831056, top_1: 0.561133, top_k: 0.793047, samples/s: 1737.028 1612887521.8292806
train: epoch 67, iter 2500, loss: 2.879631, top_1: 0.560820, top_k: 0.789062, samples/s: 1740.334 1612887536.539079
train: epoch 67, iter 2600, loss: 2.994406, top_1: 0.563164, top_k: 0.788594, samples/s: 1740.338 1612887551.2488804
train: epoch 67, iter 2700, loss: 2.756053, top_1: 0.566641, top_k: 0.791680, samples/s: 1747.371 1612887565.8994496
train: epoch 67, iter 2800, loss: 2.598219, top_1: 0.562187, top_k: 0.791016, samples/s: 1733.901 1612887580.663899
train: epoch 67, iter 2900, loss: 2.836511, top_1: 0.564102, top_k: 0.789336, samples/s: 1742.881 1612887595.3521874
train: epoch 67, iter 3000, loss: 2.915311, top_1: 0.571719, top_k: 0.795547, samples/s: 1738.009 1612887610.0816321
train: epoch 67, iter 3100, loss: 2.946752, top_1: 0.572266, top_k: 0.793711, samples/s: 1740.523 1612887624.789833
train: epoch 67, iter 3200, loss: 2.918031, top_1: 0.561406, top_k: 0.790312, samples/s: 1739.366 1612887639.5078518
train: epoch 67, iter 3300, loss: 3.054812, top_1: 0.569414, top_k: 0.792500, samples/s: 1747.921 1612887654.1538255
train: epoch 67, iter 3400, loss: 2.726619, top_1: 0.561719, top_k: 0.787188, samples/s: 1741.750 1612887668.8517182
train: epoch 67, iter 3500, loss: 2.805924, top_1: 0.556562, top_k: 0.787773, samples/s: 1731.087 1612887683.640136
train: epoch 67, iter 3600, loss: 2.711979, top_1: 0.568203, top_k: 0.790273, samples/s: 1742.968 1612887698.3276815
train: epoch 67, iter 3700, loss: 2.708493, top_1: 0.566250, top_k: 0.788281, samples/s: 1749.927 1612887712.9568453
train: epoch 67, iter 3800, loss: 2.872766, top_1: 0.564023, top_k: 0.786680, samples/s: 1748.263 1612887727.5999846
train: epoch 67, iter 3900, loss: 2.673046, top_1: 0.565430, top_k: 0.788828, samples/s: 1738.487 1612887742.3254263
train: epoch 67, iter 4000, loss: 2.845628, top_1: 0.556914, top_k: 0.785742, samples/s: 1742.109 1612887757.020212
train: epoch 67, iter 4100, loss: 3.029161, top_1: 0.553086, top_k: 0.782188, samples/s: 1737.935 1612887771.7504504
train: epoch 67, iter 4200, loss: 2.812233, top_1: 0.566641, top_k: 0.790508, samples/s: 1747.985 1612887786.3958552
train: epoch 67, iter 4300, loss: 2.820393, top_1: 0.559414, top_k: 0.785117, samples/s: 1737.689 1612887801.128051
train: epoch 67, iter 4400, loss: 2.780468, top_1: 0.568438, top_k: 0.792305, samples/s: 1743.617 1612887815.810292
train: epoch 67, iter 4500, loss: 3.008282, top_1: 0.568633, top_k: 0.793008, samples/s: 1733.260 1612887830.579994
train: epoch 67, iter 4600, loss: 2.954662, top_1: 0.565234, top_k: 0.786680, samples/s: 1749.028 1612887845.2166743
train: epoch 67, iter 4700, loss: 2.927226, top_1: 0.558594, top_k: 0.787109, samples/s: 1744.880 1612887859.8882394
train: epoch 67, iter 4800, loss: 2.962636, top_1: 0.564297, top_k: 0.792461, samples/s: 1750.475 1612887874.5127766
train: epoch 67, iter 4900, loss: 2.707479, top_1: 0.560898, top_k: 0.785430, samples/s: 1733.243 1612887889.282895
train: epoch 67, iter 5000, loss: 2.794313, top_1: 0.565078, top_k: 0.793086, samples/s: 1740.150 1612887903.9941602
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_67.
validation: epoch 67, iter 195, top_1: 0.614884, top_k: 0.840986, samples/s: 2834.656 1612887922.050317
train: epoch 68, iter 100, loss: 2.950423, top_1: 0.574492, top_k: 0.797813, samples/s: 1752.303 1612887957.681254
train: epoch 68, iter 200, loss: 3.095716, top_1: 0.568203, top_k: 0.792500, samples/s: 1758.457 1612887972.2394753
train: epoch 68, iter 300, loss: 3.062029, top_1: 0.567969, top_k: 0.792695, samples/s: 1751.492 1612887986.8556058
train: epoch 68, iter 400, loss: 2.833172, top_1: 0.569688, top_k: 0.795000, samples/s: 1757.743 1612888001.4196858
train: epoch 68, iter 500, loss: 2.622731, top_1: 0.574609, top_k: 0.794102, samples/s: 1757.377 1612888015.9869537
train: epoch 68, iter 600, loss: 2.930259, top_1: 0.573398, top_k: 0.794805, samples/s: 1757.602 1612888030.5521936
train: epoch 68, iter 700, loss: 2.707538, top_1: 0.572500, top_k: 0.796328, samples/s: 1751.461 1612888045.1685076
train: epoch 68, iter 800, loss: 2.796165, top_1: 0.569180, top_k: 0.799375, samples/s: 1744.183 1612888059.8458817
train: epoch 68, iter 900, loss: 2.821751, top_1: 0.572773, top_k: 0.798555, samples/s: 1740.512 1612888074.554231
train: epoch 68, iter 1000, loss: 2.827290, top_1: 0.564180, top_k: 0.789844, samples/s: 1743.219 1612888089.2396388
train: epoch 68, iter 1100, loss: 2.699800, top_1: 0.570898, top_k: 0.793516, samples/s: 1722.297 1612888104.1035724
train: epoch 68, iter 1200, loss: 2.667019, top_1: 0.564258, top_k: 0.790469, samples/s: 1760.673 1612888118.6434772
train: epoch 68, iter 1300, loss: 2.685644, top_1: 0.565078, top_k: 0.793086, samples/s: 1738.934 1612888133.3650863
train: epoch 68, iter 1400, loss: 2.940991, top_1: 0.561914, top_k: 0.790625, samples/s: 1729.100 1612888148.1705298
train: epoch 68, iter 1500, loss: 2.804767, top_1: 0.570234, top_k: 0.792891, samples/s: 1763.857 1612888162.6841924
train: epoch 68, iter 1600, loss: 2.808693, top_1: 0.571953, top_k: 0.790977, samples/s: 1739.574 1612888177.4003208
train: epoch 68, iter 1700, loss: 2.783276, top_1: 0.567070, top_k: 0.793125, samples/s: 1737.945 1612888192.130392
train: epoch 68, iter 1800, loss: 2.946240, top_1: 0.566719, top_k: 0.793125, samples/s: 1741.941 1612888206.8267403
train: epoch 68, iter 1900, loss: 2.812123, top_1: 0.564336, top_k: 0.790156, samples/s: 1744.946 1612888221.4976258
train: epoch 68, iter 2000, loss: 2.721003, top_1: 0.565273, top_k: 0.787539, samples/s: 1747.308 1612888236.1487262
train: epoch 68, iter 2100, loss: 2.763032, top_1: 0.562969, top_k: 0.788477, samples/s: 1742.104 1612888250.8435996
train: epoch 68, iter 2200, loss: 2.950100, top_1: 0.564805, top_k: 0.791914, samples/s: 1742.658 1612888265.5338123
train: epoch 68, iter 2300, loss: 2.789940, top_1: 0.565547, top_k: 0.790312, samples/s: 1733.368 1612888280.3027625
train: epoch 68, iter 2400, loss: 2.630707, top_1: 0.560742, top_k: 0.789844, samples/s: 1743.545 1612888294.985426
train: epoch 68, iter 2500, loss: 2.954865, top_1: 0.560312, top_k: 0.788281, samples/s: 1736.064 1612888309.731451
train: epoch 68, iter 2600, loss: 3.012189, top_1: 0.564961, top_k: 0.789297, samples/s: 1724.992 1612888324.5721326
train: epoch 68, iter 2700, loss: 2.883670, top_1: 0.566367, top_k: 0.790703, samples/s: 1728.557 1612888339.3822308
train: epoch 68, iter 2800, loss: 2.680748, top_1: 0.567344, top_k: 0.794102, samples/s: 1753.414 1612888353.982458
train: epoch 68, iter 2900, loss: 2.839345, top_1: 0.564336, top_k: 0.791055, samples/s: 1743.157 1612888368.668277
train: epoch 68, iter 3000, loss: 2.797091, top_1: 0.561797, top_k: 0.788906, samples/s: 1741.340 1612888383.3695488
train: epoch 68, iter 3100, loss: 2.828442, top_1: 0.561133, top_k: 0.790586, samples/s: 1747.674 1612888398.017621
train: epoch 68, iter 3200, loss: 2.923071, top_1: 0.566172, top_k: 0.789453, samples/s: 1748.224 1612888412.6610851
train: epoch 68, iter 3300, loss: 2.889439, top_1: 0.568008, top_k: 0.794922, samples/s: 1739.181 1612888427.3807054
train: epoch 68, iter 3400, loss: 2.927939, top_1: 0.565742, top_k: 0.789180, samples/s: 1740.708 1612888442.0872333
train: epoch 68, iter 3500, loss: 2.575978, top_1: 0.568320, top_k: 0.792070, samples/s: 1726.730 1612888456.9129725
train: epoch 68, iter 3600, loss: 2.723393, top_1: 0.561250, top_k: 0.789766, samples/s: 1750.877 1612888471.5342069
train: epoch 68, iter 3700, loss: 2.841908, top_1: 0.565039, top_k: 0.791484, samples/s: 1732.268 1612888486.312635
train: epoch 68, iter 3800, loss: 2.741817, top_1: 0.569336, top_k: 0.794766, samples/s: 1740.877 1612888501.01775
train: epoch 68, iter 3900, loss: 2.762917, top_1: 0.565547, top_k: 0.788945, samples/s: 1737.351 1612888515.7528312
train: epoch 68, iter 4000, loss: 2.608162, top_1: 0.563984, top_k: 0.789414, samples/s: 1746.118 1612888530.4139438
train: epoch 68, iter 4100, loss: 2.865641, top_1: 0.562461, top_k: 0.788711, samples/s: 1739.186 1612888545.133451
train: epoch 68, iter 4200, loss: 2.750761, top_1: 0.560352, top_k: 0.785859, samples/s: 1741.802 1612888559.83092
train: epoch 68, iter 4300, loss: 2.813298, top_1: 0.565391, top_k: 0.794141, samples/s: 1747.498 1612888574.480438
train: epoch 68, iter 4400, loss: 2.942227, top_1: 0.559609, top_k: 0.788555, samples/s: 1736.648 1612888589.2214754
train: epoch 68, iter 4500, loss: 2.759622, top_1: 0.564141, top_k: 0.793203, samples/s: 1719.919 1612888604.1059554
train: epoch 68, iter 4600, loss: 2.733512, top_1: 0.564492, top_k: 0.790742, samples/s: 1745.210 1612888618.7746408
train: epoch 68, iter 4700, loss: 2.990502, top_1: 0.560742, top_k: 0.786289, samples/s: 1733.048 1612888633.5463066
train: epoch 68, iter 4800, loss: 2.870006, top_1: 0.557305, top_k: 0.788438, samples/s: 1733.329 1612888648.3156204
train: epoch 68, iter 4900, loss: 2.572958, top_1: 0.564102, top_k: 0.787891, samples/s: 1729.785 1612888663.1151214
train: epoch 68, iter 5000, loss: 2.731373, top_1: 0.569141, top_k: 0.791328, samples/s: 1749.307 1612888677.7495346
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_68.
validation: epoch 68, iter 195, top_1: 0.609696, top_k: 0.839764, samples/s: 2821.428 1612888695.8231192
train: epoch 69, iter 100, loss: 2.684154, top_1: 0.589297, top_k: 0.809219, samples/s: 1747.264 1612888731.233539
train: epoch 69, iter 200, loss: 2.672590, top_1: 0.576250, top_k: 0.801250, samples/s: 1754.741 1612888745.8225608
train: epoch 69, iter 300, loss: 2.686590, top_1: 0.569023, top_k: 0.795391, samples/s: 1759.411 1612888760.3730097
train: epoch 69, iter 400, loss: 2.920633, top_1: 0.568945, top_k: 0.792109, samples/s: 1758.133 1612888774.9337697
train: epoch 69, iter 500, loss: 2.800965, top_1: 0.571484, top_k: 0.797539, samples/s: 1761.293 1612888789.4685407
train: epoch 69, iter 600, loss: 2.733549, top_1: 0.573008, top_k: 0.797969, samples/s: 1755.704 1612888804.0496075
train: epoch 69, iter 700, loss: 2.804242, top_1: 0.569883, top_k: 0.796602, samples/s: 1747.527 1612888818.6989214
train: epoch 69, iter 800, loss: 2.847503, top_1: 0.569648, top_k: 0.794453, samples/s: 1751.864 1612888833.3118966
train: epoch 69, iter 900, loss: 2.888082, top_1: 0.568594, top_k: 0.795547, samples/s: 1743.363 1612888847.996127
train: epoch 69, iter 1000, loss: 2.771522, top_1: 0.571992, top_k: 0.793125, samples/s: 1742.787 1612888862.6852233
train: epoch 69, iter 1100, loss: 2.831461, top_1: 0.561172, top_k: 0.785508, samples/s: 1740.650 1612888877.3923652
train: epoch 69, iter 1200, loss: 2.922891, top_1: 0.561680, top_k: 0.791836, samples/s: 1732.265 1612888892.1707604
train: epoch 69, iter 1300, loss: 2.747256, top_1: 0.568633, top_k: 0.795117, samples/s: 1743.067 1612888906.8575294
train: epoch 69, iter 1400, loss: 2.585650, top_1: 0.562031, top_k: 0.793711, samples/s: 1734.668 1612888921.6153636
train: epoch 69, iter 1500, loss: 2.879183, top_1: 0.569883, top_k: 0.793711, samples/s: 1740.105 1612888936.3270867
train: epoch 69, iter 1600, loss: 2.896850, top_1: 0.566719, top_k: 0.794961, samples/s: 1745.992 1612888950.989291
train: epoch 69, iter 1700, loss: 2.902816, top_1: 0.568242, top_k: 0.792148, samples/s: 1738.403 1612888965.715443
train: epoch 69, iter 1800, loss: 2.928289, top_1: 0.565234, top_k: 0.790039, samples/s: 1732.420 1612888980.4924426
train: epoch 69, iter 1900, loss: 2.796934, top_1: 0.560312, top_k: 0.788555, samples/s: 1746.978 1612888995.1462917
train: epoch 69, iter 2000, loss: 2.665147, top_1: 0.569531, top_k: 0.791211, samples/s: 1741.783 1612889009.8438778
train: epoch 69, iter 2100, loss: 2.931320, top_1: 0.562852, top_k: 0.792070, samples/s: 1737.460 1612889024.5780573
train: epoch 69, iter 2200, loss: 2.882035, top_1: 0.562500, top_k: 0.786172, samples/s: 1735.551 1612889039.3284283
train: epoch 69, iter 2300, loss: 2.757459, top_1: 0.566836, top_k: 0.790430, samples/s: 1743.918 1612889054.008068
train: epoch 69, iter 2400, loss: 2.832666, top_1: 0.564375, top_k: 0.789609, samples/s: 1744.532 1612889068.6824236
train: epoch 69, iter 2500, loss: 3.113915, top_1: 0.564883, top_k: 0.789805, samples/s: 1751.127 1612889083.301954
train: epoch 69, iter 2600, loss: 2.587273, top_1: 0.571602, top_k: 0.796289, samples/s: 1735.603 1612889098.0514863
train: epoch 69, iter 2700, loss: 2.730400, top_1: 0.568359, top_k: 0.793516, samples/s: 1740.386 1612889112.7611597
train: epoch 69, iter 2800, loss: 2.788718, top_1: 0.567539, top_k: 0.790586, samples/s: 1742.404 1612889127.4532037
train: epoch 69, iter 2900, loss: 2.859491, top_1: 0.567266, top_k: 0.793516, samples/s: 1733.748 1612889142.218965
train: epoch 69, iter 3000, loss: 2.721127, top_1: 0.558906, top_k: 0.785898, samples/s: 1742.151 1612889156.9133775
train: epoch 69, iter 3100, loss: 2.809560, top_1: 0.565781, top_k: 0.790586, samples/s: 1735.547 1612889171.66377
train: epoch 69, iter 3200, loss: 2.774288, top_1: 0.560859, top_k: 0.789375, samples/s: 1746.579 1612889186.3210347
train: epoch 69, iter 3300, loss: 2.668276, top_1: 0.560859, top_k: 0.788633, samples/s: 1731.136 1612889201.1091
train: epoch 69, iter 3400, loss: 2.767927, top_1: 0.561641, top_k: 0.791133, samples/s: 1740.939 1612889215.8137836
train: epoch 69, iter 3500, loss: 3.021866, top_1: 0.561953, top_k: 0.791172, samples/s: 1736.075 1612889230.5595999
train: epoch 69, iter 3600, loss: 2.890278, top_1: 0.566641, top_k: 0.794219, samples/s: 1735.778 1612889245.3080752
train: epoch 69, iter 3700, loss: 2.882020, top_1: 0.560820, top_k: 0.787773, samples/s: 1739.147 1612889260.0279202
train: epoch 69, iter 3800, loss: 2.754492, top_1: 0.567734, top_k: 0.792031, samples/s: 1752.845 1612889274.6327238
train: epoch 69, iter 3900, loss: 2.663213, top_1: 0.563906, top_k: 0.792383, samples/s: 1745.480 1612889289.299189
train: epoch 69, iter 4000, loss: 2.632206, top_1: 0.566094, top_k: 0.792695, samples/s: 1731.447 1612889304.084488
train: epoch 69, iter 4100, loss: 2.886248, top_1: 0.569766, top_k: 0.793477, samples/s: 1751.786 1612889318.6982121
train: epoch 69, iter 4200, loss: 2.873420, top_1: 0.564805, top_k: 0.793516, samples/s: 1745.018 1612889333.3685112
train: epoch 69, iter 4300, loss: 2.809218, top_1: 0.562773, top_k: 0.788555, samples/s: 1740.339 1612889348.0783732
train: epoch 69, iter 4400, loss: 2.841627, top_1: 0.568945, top_k: 0.790508, samples/s: 1742.677 1612889362.7684026
train: epoch 69, iter 4500, loss: 2.608148, top_1: 0.569141, top_k: 0.794961, samples/s: 1746.945 1612889377.422514
train: epoch 69, iter 4600, loss: 2.872902, top_1: 0.562773, top_k: 0.788633, samples/s: 1744.803 1612889392.0946655
train: epoch 69, iter 4700, loss: 2.894028, top_1: 0.566953, top_k: 0.789766, samples/s: 1736.700 1612889406.8352072
train: epoch 69, iter 4800, loss: 2.908638, top_1: 0.564453, top_k: 0.787617, samples/s: 1744.337 1612889421.5112731
train: epoch 69, iter 4900, loss: 2.843996, top_1: 0.561133, top_k: 0.786445, samples/s: 1734.408 1612889436.2714007
train: epoch 69, iter 5000, loss: 3.014897, top_1: 0.564414, top_k: 0.790977, samples/s: 1737.940 1612889451.0014527
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_69.
validation: epoch 69, iter 195, top_1: 0.607412, top_k: 0.837380, samples/s: 2829.229 1612889469.0811098
train: epoch 70, iter 100, loss: 2.719963, top_1: 0.577969, top_k: 0.802969, samples/s: 1750.270 1612889503.8914835
train: epoch 70, iter 200, loss: 2.761550, top_1: 0.575078, top_k: 0.795937, samples/s: 1748.207 1612889518.534934
train: epoch 70, iter 300, loss: 2.720486, top_1: 0.581992, top_k: 0.798398, samples/s: 1767.976 1612889533.0147657
train: epoch 70, iter 400, loss: 2.593576, top_1: 0.575391, top_k: 0.798750, samples/s: 1755.314 1612889547.59929
train: epoch 70, iter 500, loss: 2.812844, top_1: 0.571484, top_k: 0.794766, samples/s: 1755.837 1612889562.1790373
train: epoch 70, iter 600, loss: 2.844249, top_1: 0.574375, top_k: 0.800039, samples/s: 1767.642 1612889576.6615865
train: epoch 70, iter 700, loss: 2.787290, top_1: 0.574766, top_k: 0.799883, samples/s: 1747.520 1612889591.31087
train: epoch 70, iter 800, loss: 2.962453, top_1: 0.571289, top_k: 0.792617, samples/s: 1742.082 1612889606.0059237
train: epoch 70, iter 900, loss: 2.912002, top_1: 0.576406, top_k: 0.797969, samples/s: 1739.187 1612889620.7254448
train: epoch 70, iter 1000, loss: 2.812386, top_1: 0.568594, top_k: 0.792344, samples/s: 1733.137 1612889635.4963996
train: epoch 70, iter 1100, loss: 2.920885, top_1: 0.571719, top_k: 0.796250, samples/s: 1750.644 1612889650.1195302
train: epoch 70, iter 1200, loss: 2.972845, top_1: 0.567773, top_k: 0.792695, samples/s: 1743.834 1612889664.799837
train: epoch 70, iter 1300, loss: 2.701814, top_1: 0.567773, top_k: 0.796836, samples/s: 1742.313 1612889679.4929392
train: epoch 70, iter 1400, loss: 2.743172, top_1: 0.569688, top_k: 0.795742, samples/s: 1730.830 1612889694.283534
train: epoch 70, iter 1500, loss: 2.937787, top_1: 0.571211, top_k: 0.794219, samples/s: 1743.009 1612889708.970845
train: epoch 70, iter 1600, loss: 2.833901, top_1: 0.566953, top_k: 0.791641, samples/s: 1739.956 1612889723.6838746
train: epoch 70, iter 1700, loss: 2.603835, top_1: 0.575859, top_k: 0.794258, samples/s: 1740.365 1612889738.3934042
train: epoch 70, iter 1800, loss: 2.776516, top_1: 0.571914, top_k: 0.793984, samples/s: 1737.054 1612889753.130986
train: epoch 70, iter 1900, loss: 2.805122, top_1: 0.564336, top_k: 0.791133, samples/s: 1732.798 1612889767.9048383
train: epoch 70, iter 2000, loss: 2.967790, top_1: 0.561289, top_k: 0.789258, samples/s: 1734.633 1612889782.6628988
train: epoch 70, iter 2100, loss: 2.661195, top_1: 0.568398, top_k: 0.790859, samples/s: 1741.430 1612889797.3635144
train: epoch 70, iter 2200, loss: 2.942279, top_1: 0.569727, top_k: 0.794648, samples/s: 1730.787 1612889812.1544244
train: epoch 70, iter 2300, loss: 2.751837, top_1: 0.568438, top_k: 0.794297, samples/s: 1740.225 1612889826.8652604
train: epoch 70, iter 2400, loss: 2.902284, top_1: 0.567148, top_k: 0.792773, samples/s: 1749.588 1612889841.4971871
train: epoch 70, iter 2500, loss: 3.006170, top_1: 0.571602, top_k: 0.791211, samples/s: 1736.355 1612889856.240767
train: epoch 70, iter 2600, loss: 2.623074, top_1: 0.573086, top_k: 0.798672, samples/s: 1738.000 1612889870.9704013
train: epoch 70, iter 2700, loss: 2.832672, top_1: 0.572773, top_k: 0.799492, samples/s: 1735.842 1612889885.7181647
train: epoch 70, iter 2800, loss: 2.724667, top_1: 0.568047, top_k: 0.791289, samples/s: 1739.601 1612889900.4343069
train: epoch 70, iter 2900, loss: 2.840410, top_1: 0.557617, top_k: 0.787852, samples/s: 1750.675 1612889915.0571904
train: epoch 70, iter 3000, loss: 2.973491, top_1: 0.566602, top_k: 0.792500, samples/s: 1733.831 1612889929.8221195
train: epoch 70, iter 3100, loss: 2.885946, top_1: 0.561367, top_k: 0.789844, samples/s: 1758.452 1612889944.380431
train: epoch 70, iter 3200, loss: 3.043100, top_1: 0.564219, top_k: 0.788086, samples/s: 1743.649 1612889959.0622342
train: epoch 70, iter 3300, loss: 2.905756, top_1: 0.565508, top_k: 0.793008, samples/s: 1739.803 1612889973.7765465
train: epoch 70, iter 3400, loss: 2.724006, top_1: 0.565195, top_k: 0.787422, samples/s: 1731.608 1612889988.5606039
train: epoch 70, iter 3500, loss: 2.777491, top_1: 0.567227, top_k: 0.794336, samples/s: 1752.487 1612890003.16832
train: epoch 70, iter 3600, loss: 2.855151, top_1: 0.571172, top_k: 0.793867, samples/s: 1738.009 1612890017.8981407
train: epoch 70, iter 3700, loss: 2.685564, top_1: 0.563320, top_k: 0.791328, samples/s: 1750.387 1612890032.5231373
train: epoch 70, iter 3800, loss: 2.801564, top_1: 0.563750, top_k: 0.790430, samples/s: 1738.051 1612890047.2523634
train: epoch 70, iter 3900, loss: 2.867581, top_1: 0.564102, top_k: 0.788750, samples/s: 1742.728 1612890061.9419515
train: epoch 70, iter 4000, loss: 2.808737, top_1: 0.566914, top_k: 0.793477, samples/s: 1740.102 1612890076.6537254
train: epoch 70, iter 4100, loss: 2.707981, top_1: 0.570352, top_k: 0.794180, samples/s: 1740.519 1612890091.3625286
train: epoch 70, iter 4200, loss: 2.715654, top_1: 0.568633, top_k: 0.793008, samples/s: 1738.982 1612890106.0832562
train: epoch 70, iter 4300, loss: 2.981191, top_1: 0.564492, top_k: 0.791289, samples/s: 1744.811 1612890120.7553158
train: epoch 70, iter 4400, loss: 2.862591, top_1: 0.563555, top_k: 0.790859, samples/s: 1742.446 1612890135.447256
train: epoch 70, iter 4500, loss: 2.863049, top_1: 0.558750, top_k: 0.790352, samples/s: 1731.250 1612890150.2342691
train: epoch 70, iter 4600, loss: 2.847741, top_1: 0.565664, top_k: 0.795195, samples/s: 1750.088 1612890164.8621202
train: epoch 70, iter 4700, loss: 2.864835, top_1: 0.559414, top_k: 0.789141, samples/s: 1741.064 1612890179.5657618
train: epoch 70, iter 4800, loss: 2.985741, top_1: 0.573555, top_k: 0.793594, samples/s: 1742.305 1612890194.2589927
train: epoch 70, iter 4900, loss: 2.902628, top_1: 0.563789, top_k: 0.787930, samples/s: 1743.019 1612890208.9461632
train: epoch 70, iter 5000, loss: 2.765753, top_1: 0.569102, top_k: 0.791719, samples/s: 1736.137 1612890223.6915638
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_70.
validation: epoch 70, iter 195, top_1: 0.600541, top_k: 0.830429, samples/s: 2789.884 1612890242.0090215
train: epoch 71, iter 100, loss: 2.779899, top_1: 0.575508, top_k: 0.800273, samples/s: 1747.063 1612890276.7807353
train: epoch 71, iter 200, loss: 2.768486, top_1: 0.576289, top_k: 0.796016, samples/s: 1765.039 1612890291.2847912
train: epoch 71, iter 300, loss: 2.771224, top_1: 0.576250, top_k: 0.799766, samples/s: 1755.756 1612890305.8652682
train: epoch 71, iter 400, loss: 2.820067, top_1: 0.576211, top_k: 0.800508, samples/s: 1747.801 1612890320.512261
train: epoch 71, iter 500, loss: 2.800113, top_1: 0.581367, top_k: 0.801016, samples/s: 1763.985 1612890335.0248077
train: epoch 71, iter 600, loss: 2.516323, top_1: 0.579180, top_k: 0.801406, samples/s: 1762.513 1612890349.5495908
train: epoch 71, iter 700, loss: 2.867166, top_1: 0.571445, top_k: 0.800664, samples/s: 1751.193 1612890364.1681316
train: epoch 71, iter 800, loss: 2.804442, top_1: 0.574063, top_k: 0.798125, samples/s: 1723.626 1612890379.0205438
train: epoch 71, iter 900, loss: 2.819004, top_1: 0.567422, top_k: 0.793320, samples/s: 1770.394 1612890393.480626
train: epoch 71, iter 1000, loss: 2.763948, top_1: 0.569180, top_k: 0.792422, samples/s: 1745.935 1612890408.1432333
train: epoch 71, iter 1100, loss: 2.696179, top_1: 0.570703, top_k: 0.797109, samples/s: 1735.133 1612890422.897206
train: epoch 71, iter 1200, loss: 2.701817, top_1: 0.579844, top_k: 0.798711, samples/s: 1739.966 1612890437.6100786
train: epoch 71, iter 1300, loss: 2.858412, top_1: 0.572148, top_k: 0.799102, samples/s: 1752.134 1612890452.2208552
train: epoch 71, iter 1400, loss: 2.721587, top_1: 0.571797, top_k: 0.797734, samples/s: 1734.125 1612890466.9834015
train: epoch 71, iter 1500, loss: 2.808876, top_1: 0.572500, top_k: 0.791523, samples/s: 1735.590 1612890481.7333694
train: epoch 71, iter 1600, loss: 2.763110, top_1: 0.567227, top_k: 0.792773, samples/s: 1741.661 1612890496.431964
train: epoch 71, iter 1700, loss: 2.824145, top_1: 0.573750, top_k: 0.795820, samples/s: 1740.958 1612890511.1365736
train: epoch 71, iter 1800, loss: 2.994766, top_1: 0.573125, top_k: 0.797695, samples/s: 1744.260 1612890525.8132386
train: epoch 71, iter 1900, loss: 2.876292, top_1: 0.570625, top_k: 0.791953, samples/s: 1742.521 1612890540.504611
train: epoch 71, iter 2000, loss: 2.846755, top_1: 0.569609, top_k: 0.795781, samples/s: 1731.261 1612890555.2915854
train: epoch 71, iter 2100, loss: 2.766966, top_1: 0.572852, top_k: 0.792266, samples/s: 1747.006 1612890569.945188
train: epoch 71, iter 2200, loss: 2.766523, top_1: 0.572734, top_k: 0.791641, samples/s: 1719.458 1612890584.8335836
train: epoch 71, iter 2300, loss: 2.901810, top_1: 0.568125, top_k: 0.793047, samples/s: 1760.901 1612890599.3716247
train: epoch 71, iter 2400, loss: 2.571874, top_1: 0.565000, top_k: 0.787695, samples/s: 1740.655 1612890614.0787313
train: epoch 71, iter 2500, loss: 2.985323, top_1: 0.568789, top_k: 0.791445, samples/s: 1745.078 1612890628.7484927
train: epoch 71, iter 2600, loss: 2.752186, top_1: 0.566992, top_k: 0.791016, samples/s: 1742.350 1612890643.4413059
train: epoch 71, iter 2700, loss: 2.812589, top_1: 0.570000, top_k: 0.796445, samples/s: 1737.983 1612890658.1710556
train: epoch 71, iter 2800, loss: 2.839531, top_1: 0.567109, top_k: 0.790898, samples/s: 1734.479 1612890672.9304848
train: epoch 71, iter 2900, loss: 2.738007, top_1: 0.571016, top_k: 0.793203, samples/s: 1734.365 1612890687.6910233
train: epoch 71, iter 3000, loss: 2.726304, top_1: 0.572422, top_k: 0.796094, samples/s: 1761.706 1612890702.2223728
train: epoch 71, iter 3100, loss: 2.790592, top_1: 0.564961, top_k: 0.790820, samples/s: 1731.316 1612890717.0087872
train: epoch 71, iter 3200, loss: 2.927824, top_1: 0.565078, top_k: 0.789336, samples/s: 1738.053 1612890731.7380714
train: epoch 71, iter 3300, loss: 2.850779, top_1: 0.566406, top_k: 0.793984, samples/s: 1737.984 1612890746.4676476
train: epoch 71, iter 3400, loss: 2.751005, top_1: 0.563516, top_k: 0.792695, samples/s: 1733.911 1612890761.2319438
train: epoch 71, iter 3500, loss: 2.845179, top_1: 0.561445, top_k: 0.790352, samples/s: 1749.389 1612890775.865601
train: epoch 71, iter 3600, loss: 2.869122, top_1: 0.569531, top_k: 0.792969, samples/s: 1732.659 1612890790.6406229
train: epoch 71, iter 3700, loss: 2.953681, top_1: 0.561406, top_k: 0.790742, samples/s: 1742.771 1612890805.3298748
train: epoch 71, iter 3800, loss: 2.850601, top_1: 0.566016, top_k: 0.794219, samples/s: 1738.013 1612890820.059378
train: epoch 71, iter 3900, loss: 2.754564, top_1: 0.570469, top_k: 0.793281, samples/s: 1738.192 1612890834.787255
train: epoch 71, iter 4000, loss: 2.930071, top_1: 0.567852, top_k: 0.797148, samples/s: 1742.059 1612890849.4825716
train: epoch 71, iter 4100, loss: 2.883338, top_1: 0.571836, top_k: 0.798164, samples/s: 1744.722 1612890864.1553466
train: epoch 71, iter 4200, loss: 2.817866, top_1: 0.571641, top_k: 0.791836, samples/s: 1736.686 1612890878.8960648
train: epoch 71, iter 4300, loss: 2.914396, top_1: 0.572109, top_k: 0.792461, samples/s: 1753.558 1612890893.4949572
train: epoch 71, iter 4400, loss: 2.855789, top_1: 0.571094, top_k: 0.794883, samples/s: 1747.754 1612890908.1423433
train: epoch 71, iter 4500, loss: 2.806633, top_1: 0.558906, top_k: 0.788789, samples/s: 1736.640 1612890922.8834908
train: epoch 71, iter 4600, loss: 2.979613, top_1: 0.568398, top_k: 0.789961, samples/s: 1736.117 1612890937.6290343
train: epoch 71, iter 4700, loss: 2.736180, top_1: 0.568125, top_k: 0.794961, samples/s: 1745.545 1612890952.294831
train: epoch 71, iter 4800, loss: 2.587972, top_1: 0.568867, top_k: 0.793555, samples/s: 1758.769 1612890966.850531
train: epoch 71, iter 4900, loss: 2.818455, top_1: 0.574102, top_k: 0.795234, samples/s: 1738.312 1612890981.5774364
train: epoch 71, iter 5000, loss: 2.611789, top_1: 0.562617, top_k: 0.789258, samples/s: 1733.502 1612890996.3451993
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_71.
validation: epoch 71, iter 195, top_1: 0.611498, top_k: 0.840885, samples/s: 2897.514 1612891014.0148604
train: epoch 72, iter 100, loss: 2.887433, top_1: 0.573906, top_k: 0.800156, samples/s: 1760.022 1612891054.0922775
train: epoch 72, iter 200, loss: 2.720481, top_1: 0.581953, top_k: 0.804453, samples/s: 1745.486 1612891068.7587516
train: epoch 72, iter 300, loss: 2.847964, top_1: 0.575781, top_k: 0.795234, samples/s: 1770.955 1612891083.2141895
train: epoch 72, iter 400, loss: 2.794548, top_1: 0.581211, top_k: 0.799609, samples/s: 1746.752 1612891097.8699465
train: epoch 72, iter 500, loss: 2.691029, top_1: 0.569531, top_k: 0.796562, samples/s: 1766.469 1612891112.362121
train: epoch 72, iter 600, loss: 2.864052, top_1: 0.577187, top_k: 0.798672, samples/s: 1755.342 1612891126.946135
train: epoch 72, iter 700, loss: 2.768947, top_1: 0.578828, top_k: 0.798125, samples/s: 1752.110 1612891141.557107
train: epoch 72, iter 800, loss: 2.721381, top_1: 0.571641, top_k: 0.793672, samples/s: 1746.346 1612891156.2162662
train: epoch 72, iter 900, loss: 2.740347, top_1: 0.573516, top_k: 0.793281, samples/s: 1750.072 1612891170.8442607
train: epoch 72, iter 1000, loss: 2.772360, top_1: 0.575430, top_k: 0.798672, samples/s: 1742.328 1612891185.5372677
train: epoch 72, iter 1100, loss: 2.760883, top_1: 0.574961, top_k: 0.800312, samples/s: 1747.226 1612891200.1890857
train: epoch 72, iter 1200, loss: 2.702452, top_1: 0.576367, top_k: 0.797500, samples/s: 1729.145 1612891214.9940279
train: epoch 72, iter 1300, loss: 2.702775, top_1: 0.572695, top_k: 0.795977, samples/s: 1738.746 1612891229.7173784
train: epoch 72, iter 1400, loss: 2.791733, top_1: 0.577617, top_k: 0.798984, samples/s: 1754.013 1612891244.3123777
train: epoch 72, iter 1500, loss: 2.665430, top_1: 0.571172, top_k: 0.796250, samples/s: 1738.745 1612891259.0356493
train: epoch 72, iter 1600, loss: 2.865762, top_1: 0.574063, top_k: 0.798867, samples/s: 1739.279 1612891273.7544112
train: epoch 72, iter 1700, loss: 2.738055, top_1: 0.571133, top_k: 0.797266, samples/s: 1744.276 1612891288.4310052
train: epoch 72, iter 1800, loss: 2.639193, top_1: 0.570703, top_k: 0.795352, samples/s: 1729.878 1612891303.2297528
train: epoch 72, iter 1900, loss: 2.643337, top_1: 0.571250, top_k: 0.794492, samples/s: 1732.656 1612891318.0047293
train: epoch 72, iter 2000, loss: 2.747081, top_1: 0.576289, top_k: 0.800937, samples/s: 1746.793 1612891332.660126
train: epoch 72, iter 2100, loss: 2.955293, top_1: 0.575430, top_k: 0.800820, samples/s: 1750.224 1612891347.2868361
train: epoch 72, iter 2200, loss: 2.870030, top_1: 0.574844, top_k: 0.794922, samples/s: 1724.856 1612891362.1287653
train: epoch 72, iter 2300, loss: 2.905180, top_1: 0.569375, top_k: 0.793242, samples/s: 1742.674 1612891376.8187652
train: epoch 72, iter 2400, loss: 2.619699, top_1: 0.569102, top_k: 0.794141, samples/s: 1744.932 1612891391.489905
train: epoch 72, iter 2500, loss: 2.925825, top_1: 0.575977, top_k: 0.795156, samples/s: 1735.831 1612891406.237739
train: epoch 72, iter 2600, loss: 2.743598, top_1: 0.570508, top_k: 0.792969, samples/s: 1728.195 1612891421.0509915
train: epoch 72, iter 2700, loss: 2.687920, top_1: 0.570664, top_k: 0.795273, samples/s: 1752.591 1612891435.6578634
train: epoch 72, iter 2800, loss: 2.807382, top_1: 0.570664, top_k: 0.793203, samples/s: 1726.461 1612891450.4858754
train: epoch 72, iter 2900, loss: 2.787722, top_1: 0.569219, top_k: 0.793047, samples/s: 1745.005 1612891465.1563625
train: epoch 72, iter 3000, loss: 2.710555, top_1: 0.572812, top_k: 0.794336, samples/s: 1747.502 1612891479.8058443
train: epoch 72, iter 3100, loss: 2.900549, top_1: 0.568945, top_k: 0.795195, samples/s: 1740.823 1612891494.5114925
train: epoch 72, iter 3200, loss: 2.899346, top_1: 0.566914, top_k: 0.793516, samples/s: 1746.489 1612891509.169443
train: epoch 72, iter 3300, loss: 2.778546, top_1: 0.569844, top_k: 0.795781, samples/s: 1737.163 1612891523.9061735
train: epoch 72, iter 3400, loss: 2.851819, top_1: 0.570586, top_k: 0.792266, samples/s: 1745.406 1612891538.573204
train: epoch 72, iter 3500, loss: 2.793291, top_1: 0.568828, top_k: 0.788750, samples/s: 1748.936 1612891553.210757
train: epoch 72, iter 3600, loss: 2.684934, top_1: 0.567617, top_k: 0.795273, samples/s: 1740.913 1612891567.9155853
train: epoch 72, iter 3700, loss: 2.795663, top_1: 0.568242, top_k: 0.795469, samples/s: 1737.445 1612891582.6498735
train: epoch 72, iter 3800, loss: 2.800872, top_1: 0.571875, top_k: 0.792734, samples/s: 1742.902 1612891597.3381002
train: epoch 72, iter 3900, loss: 2.851953, top_1: 0.570977, top_k: 0.794141, samples/s: 1748.755 1612891611.9770653
train: epoch 72, iter 4000, loss: 2.801110, top_1: 0.570039, top_k: 0.795742, samples/s: 1742.733 1612891626.6666877
train: epoch 72, iter 4100, loss: 2.791291, top_1: 0.567930, top_k: 0.794805, samples/s: 1732.135 1612891641.4461343
train: epoch 72, iter 4200, loss: 3.071028, top_1: 0.569609, top_k: 0.791992, samples/s: 1748.041 1612891656.091044
train: epoch 72, iter 4300, loss: 2.896001, top_1: 0.568516, top_k: 0.793594, samples/s: 1734.690 1612891670.8486733
train: epoch 72, iter 4400, loss: 2.747522, top_1: 0.571562, top_k: 0.798945, samples/s: 1748.127 1612891685.4929283
train: epoch 72, iter 4500, loss: 2.813447, top_1: 0.565898, top_k: 0.790703, samples/s: 1746.263 1612891700.1531262
train: epoch 72, iter 4600, loss: 2.845520, top_1: 0.568906, top_k: 0.792773, samples/s: 1755.965 1612891714.7316716
train: epoch 72, iter 4700, loss: 2.878160, top_1: 0.570156, top_k: 0.790273, samples/s: 1723.965 1612891729.5812464
train: epoch 72, iter 4800, loss: 2.724483, top_1: 0.566758, top_k: 0.792070, samples/s: 1755.889 1612891744.1606622
train: epoch 72, iter 4900, loss: 2.802982, top_1: 0.564961, top_k: 0.790977, samples/s: 1742.501 1612891758.8521907
train: epoch 72, iter 5000, loss: 2.848006, top_1: 0.571445, top_k: 0.796328, samples/s: 1731.492 1612891773.6371338
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_72.
validation: epoch 72, iter 195, top_1: 0.617087, top_k: 0.843610, samples/s: 2822.447 1612891791.79825
train: epoch 73, iter 100, loss: 2.568861, top_1: 0.576602, top_k: 0.802070, samples/s: 1751.087 1612891827.0907395
train: epoch 73, iter 200, loss: 2.969237, top_1: 0.575508, top_k: 0.796758, samples/s: 1762.455 1612891841.6158946
train: epoch 73, iter 300, loss: 2.638802, top_1: 0.579492, top_k: 0.802461, samples/s: 1756.791 1612891856.1879597
train: epoch 73, iter 400, loss: 2.753523, top_1: 0.572812, top_k: 0.795312, samples/s: 1762.893 1612891870.7094991
train: epoch 73, iter 500, loss: 2.644543, top_1: 0.580391, top_k: 0.802969, samples/s: 1749.946 1612891885.3389246
train: epoch 73, iter 600, loss: 2.649852, top_1: 0.579688, top_k: 0.803281, samples/s: 1761.945 1612891899.867978
train: epoch 73, iter 700, loss: 2.774153, top_1: 0.577969, top_k: 0.803750, samples/s: 1746.356 1612891914.5270622
train: epoch 73, iter 800, loss: 2.913382, top_1: 0.578867, top_k: 0.803164, samples/s: 1746.527 1612891929.1847734
train: epoch 73, iter 900, loss: 2.673395, top_1: 0.576445, top_k: 0.804023, samples/s: 1738.067 1612891943.9137247
train: epoch 73, iter 1000, loss: 2.616875, top_1: 0.575586, top_k: 0.799531, samples/s: 1756.635 1612891958.4870498
train: epoch 73, iter 1100, loss: 2.868034, top_1: 0.574453, top_k: 0.800664, samples/s: 1733.856 1612891973.251984
train: epoch 73, iter 1200, loss: 2.760789, top_1: 0.573086, top_k: 0.798086, samples/s: 1746.878 1612891987.9064841
train: epoch 73, iter 1300, loss: 2.789281, top_1: 0.577227, top_k: 0.802695, samples/s: 1751.447 1612892002.5230227
train: epoch 73, iter 1400, loss: 2.661725, top_1: 0.574883, top_k: 0.796523, samples/s: 1743.395 1612892017.2069619
train: epoch 73, iter 1500, loss: 2.627884, top_1: 0.576016, top_k: 0.797227, samples/s: 1742.360 1612892031.8996766
train: epoch 73, iter 1600, loss: 2.842334, top_1: 0.569688, top_k: 0.794297, samples/s: 1735.065 1612892046.654305
train: epoch 73, iter 1700, loss: 2.771204, top_1: 0.576484, top_k: 0.796289, samples/s: 1749.430 1612892061.2875075
train: epoch 73, iter 1800, loss: 2.680123, top_1: 0.569219, top_k: 0.795000, samples/s: 1704.105 1612892076.3100576
train: epoch 73, iter 1900, loss: 2.801358, top_1: 0.566484, top_k: 0.793672, samples/s: 1748.667 1612892090.9498253
train: epoch 73, iter 2000, loss: 2.574680, top_1: 0.573828, top_k: 0.797891, samples/s: 1750.014 1612892105.5783103
train: epoch 73, iter 2100, loss: 2.696711, top_1: 0.576406, top_k: 0.799609, samples/s: 1747.318 1612892120.2293022
train: epoch 73, iter 2200, loss: 2.706016, top_1: 0.569180, top_k: 0.793047, samples/s: 1738.053 1612892134.9585037
train: epoch 73, iter 2300, loss: 2.751654, top_1: 0.572227, top_k: 0.794336, samples/s: 1754.438 1612892149.5500531
train: epoch 73, iter 2400, loss: 2.771082, top_1: 0.568086, top_k: 0.795586, samples/s: 1740.446 1612892164.2588925
train: epoch 73, iter 2500, loss: 2.507287, top_1: 0.573789, top_k: 0.794336, samples/s: 1735.570 1612892179.009081
train: epoch 73, iter 2600, loss: 2.664934, top_1: 0.574414, top_k: 0.797930, samples/s: 1741.062 1612892193.712724
train: epoch 73, iter 2700, loss: 2.919191, top_1: 0.570273, top_k: 0.795898, samples/s: 1748.541 1612892208.3535511
train: epoch 73, iter 2800, loss: 2.691278, top_1: 0.571602, top_k: 0.798359, samples/s: 1743.628 1612892223.0355773
train: epoch 73, iter 2900, loss: 2.933292, top_1: 0.567813, top_k: 0.793008, samples/s: 1734.088 1612892237.7983398
train: epoch 73, iter 3000, loss: 2.685193, top_1: 0.569336, top_k: 0.795352, samples/s: 1744.730 1612892252.4711013
train: epoch 73, iter 3100, loss: 2.935054, top_1: 0.569180, top_k: 0.792891, samples/s: 1728.533 1612892267.281418
train: epoch 73, iter 3200, loss: 2.825951, top_1: 0.568828, top_k: 0.795195, samples/s: 1743.286 1612892281.9662914
train: epoch 73, iter 3300, loss: 2.811249, top_1: 0.568008, top_k: 0.792344, samples/s: 1748.723 1612892296.6055534
train: epoch 73, iter 3400, loss: 2.789519, top_1: 0.568555, top_k: 0.798711, samples/s: 1733.749 1612892311.3711913
train: epoch 73, iter 3500, loss: 2.750168, top_1: 0.571953, top_k: 0.797148, samples/s: 1737.812 1612892326.1023395
train: epoch 73, iter 3600, loss: 2.697434, top_1: 0.575547, top_k: 0.795352, samples/s: 1743.776 1612892340.7832031
train: epoch 73, iter 3700, loss: 2.689592, top_1: 0.572148, top_k: 0.797773, samples/s: 1750.163 1612892355.410379
train: epoch 73, iter 3800, loss: 2.922500, top_1: 0.573945, top_k: 0.799687, samples/s: 1735.064 1612892370.1648235
train: epoch 73, iter 3900, loss: 2.767510, top_1: 0.566992, top_k: 0.794336, samples/s: 1742.577 1612892384.8558357
train: epoch 73, iter 4000, loss: 2.873938, top_1: 0.570117, top_k: 0.795977, samples/s: 1739.856 1612892399.569952
train: epoch 73, iter 4100, loss: 2.773247, top_1: 0.572422, top_k: 0.797188, samples/s: 1745.348 1612892414.2371466
train: epoch 73, iter 4200, loss: 2.773443, top_1: 0.569609, top_k: 0.793203, samples/s: 1745.560 1612892428.9029324
train: epoch 73, iter 4300, loss: 2.932078, top_1: 0.569102, top_k: 0.791211, samples/s: 1745.343 1612892443.5706043
train: epoch 73, iter 4400, loss: 2.770732, top_1: 0.565781, top_k: 0.796250, samples/s: 1744.810 1612892458.2426152
train: epoch 73, iter 4500, loss: 2.718008, top_1: 0.578477, top_k: 0.796562, samples/s: 1739.516 1612892472.959409
train: epoch 73, iter 4600, loss: 2.842221, top_1: 0.571055, top_k: 0.793789, samples/s: 1739.552 1612892487.6758554
train: epoch 73, iter 4700, loss: 2.826931, top_1: 0.569805, top_k: 0.796992, samples/s: 1747.868 1612892502.3225985
train: epoch 73, iter 4800, loss: 2.762435, top_1: 0.567266, top_k: 0.789805, samples/s: 1738.084 1612892517.0510747
train: epoch 73, iter 4900, loss: 2.825596, top_1: 0.572148, top_k: 0.795664, samples/s: 1756.436 1612892531.626093
train: epoch 73, iter 5000, loss: 2.938116, top_1: 0.571875, top_k: 0.798594, samples/s: 1724.957 1612892546.467009
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_73.
validation: epoch 73, iter 195, top_1: 0.619111, top_k: 0.846995, samples/s: 2857.560 1612892564.23891
train: epoch 74, iter 100, loss: 2.823234, top_1: 0.573047, top_k: 0.797461, samples/s: 1751.936 1612892599.5846062
train: epoch 74, iter 200, loss: 2.652050, top_1: 0.582422, top_k: 0.801836, samples/s: 1760.103 1612892614.1292446
train: epoch 74, iter 300, loss: 2.606521, top_1: 0.583633, top_k: 0.804063, samples/s: 1757.603 1612892628.6947463
train: epoch 74, iter 400, loss: 2.823590, top_1: 0.577578, top_k: 0.796992, samples/s: 1758.850 1612892643.2493918
train: epoch 74, iter 500, loss: 2.687196, top_1: 0.582148, top_k: 0.806523, samples/s: 1756.223 1612892657.8261256
train: epoch 74, iter 600, loss: 2.964731, top_1: 0.585625, top_k: 0.805703, samples/s: 1756.957 1612892672.396822
train: epoch 74, iter 700, loss: 2.823454, top_1: 0.580742, top_k: 0.802930, samples/s: 1750.358 1612892687.0223389
train: epoch 74, iter 800, loss: 2.772914, top_1: 0.577852, top_k: 0.799648, samples/s: 1748.429 1612892701.6641228
train: epoch 74, iter 900, loss: 2.743550, top_1: 0.573750, top_k: 0.796484, samples/s: 1743.006 1612892716.3513749
train: epoch 74, iter 1000, loss: 2.886021, top_1: 0.581875, top_k: 0.804297, samples/s: 1733.398 1612892731.1204214
train: epoch 74, iter 1100, loss: 2.744231, top_1: 0.574961, top_k: 0.796016, samples/s: 1732.454 1612892745.8967304
train: epoch 74, iter 1200, loss: 2.890913, top_1: 0.573047, top_k: 0.799922, samples/s: 1748.413 1612892760.5386071
train: epoch 74, iter 1300, loss: 2.603847, top_1: 0.574492, top_k: 0.795508, samples/s: 1726.031 1612892775.3703196
train: epoch 74, iter 1400, loss: 2.838341, top_1: 0.575508, top_k: 0.800508, samples/s: 1747.094 1612892790.023224
train: epoch 74, iter 1500, loss: 2.799369, top_1: 0.570469, top_k: 0.796719, samples/s: 1743.559 1612892804.7058642
train: epoch 74, iter 1600, loss: 2.953689, top_1: 0.579727, top_k: 0.796914, samples/s: 1745.969 1612892819.3682237
train: epoch 74, iter 1700, loss: 2.870933, top_1: 0.571914, top_k: 0.798086, samples/s: 1741.028 1612892834.0721388
train: epoch 74, iter 1800, loss: 2.650491, top_1: 0.577187, top_k: 0.796289, samples/s: 1737.452 1612892848.806349
train: epoch 74, iter 1900, loss: 2.666123, top_1: 0.573594, top_k: 0.798281, samples/s: 1745.409 1612892863.473437
train: epoch 74, iter 2000, loss: 2.913169, top_1: 0.576055, top_k: 0.795234, samples/s: 1751.361 1612892878.0906692
train: epoch 74, iter 2100, loss: 2.564103, top_1: 0.576406, top_k: 0.795664, samples/s: 1745.481 1612892892.7570302
train: epoch 74, iter 2200, loss: 2.613155, top_1: 0.576406, top_k: 0.801562, samples/s: 1736.120 1612892907.5026183
train: epoch 74, iter 2300, loss: 2.678161, top_1: 0.577539, top_k: 0.796992, samples/s: 1738.034 1612892922.2319024
train: epoch 74, iter 2400, loss: 2.857011, top_1: 0.578516, top_k: 0.796562, samples/s: 1718.158 1612892937.1315365
train: epoch 74, iter 2500, loss: 2.803006, top_1: 0.568594, top_k: 0.795937, samples/s: 1746.001 1612892951.79364
train: epoch 74, iter 2600, loss: 2.858902, top_1: 0.573047, top_k: 0.798828, samples/s: 1743.142 1612892966.4797668
train: epoch 74, iter 2700, loss: 2.926121, top_1: 0.581406, top_k: 0.802695, samples/s: 1751.519 1612892981.0956948
train: epoch 74, iter 2800, loss: 2.459535, top_1: 0.577812, top_k: 0.799648, samples/s: 1736.632 1612892995.8368645
train: epoch 74, iter 2900, loss: 2.898707, top_1: 0.569961, top_k: 0.793008, samples/s: 1741.007 1612893010.5409074
train: epoch 74, iter 3000, loss: 2.722125, top_1: 0.573008, top_k: 0.797227, samples/s: 1747.355 1612893025.1916192
train: epoch 74, iter 3100, loss: 2.727643, top_1: 0.571680, top_k: 0.793477, samples/s: 1734.534 1612893039.9507232
train: epoch 74, iter 3200, loss: 2.777506, top_1: 0.574531, top_k: 0.796836, samples/s: 1735.931 1612893054.6977656
train: epoch 74, iter 3300, loss: 2.720567, top_1: 0.572969, top_k: 0.794805, samples/s: 1742.479 1612893069.3894868
train: epoch 74, iter 3400, loss: 2.972160, top_1: 0.571094, top_k: 0.798086, samples/s: 1740.249 1612893084.1000113
train: epoch 74, iter 3500, loss: 2.520374, top_1: 0.571094, top_k: 0.794414, samples/s: 1741.434 1612893098.8006027
train: epoch 74, iter 3600, loss: 2.776085, top_1: 0.576445, top_k: 0.797266, samples/s: 1746.308 1612893113.460151
train: epoch 74, iter 3700, loss: 2.842745, top_1: 0.570703, top_k: 0.798086, samples/s: 1746.548 1612893128.1175845
train: epoch 74, iter 3800, loss: 2.744005, top_1: 0.575313, top_k: 0.796914, samples/s: 1732.509 1612893142.8938947
train: epoch 74, iter 3900, loss: 3.160020, top_1: 0.577109, top_k: 0.799453, samples/s: 1743.500 1612893157.5769062
train: epoch 74, iter 4000, loss: 2.625307, top_1: 0.573750, top_k: 0.794570, samples/s: 1743.855 1612893172.2570217
train: epoch 74, iter 4100, loss: 2.803672, top_1: 0.569961, top_k: 0.794453, samples/s: 1743.094 1612893186.9435966
train: epoch 74, iter 4200, loss: 2.695625, top_1: 0.576250, top_k: 0.799258, samples/s: 1742.820 1612893201.6324244
train: epoch 74, iter 4300, loss: 2.622284, top_1: 0.570664, top_k: 0.797617, samples/s: 1728.968 1612893216.4389558
train: epoch 74, iter 4400, loss: 2.823318, top_1: 0.572539, top_k: 0.796055, samples/s: 1752.087 1612893231.0501628
train: epoch 74, iter 4500, loss: 2.753867, top_1: 0.575469, top_k: 0.795937, samples/s: 1745.811 1612893245.7137244
train: epoch 74, iter 4600, loss: 2.833930, top_1: 0.574023, top_k: 0.796602, samples/s: 1729.672 1612893260.514342
train: epoch 74, iter 4700, loss: 2.874488, top_1: 0.572461, top_k: 0.799102, samples/s: 1753.996 1612893275.1095514
train: epoch 74, iter 4800, loss: 2.918196, top_1: 0.572109, top_k: 0.793438, samples/s: 1748.429 1612893289.751183
train: epoch 74, iter 4900, loss: 2.833626, top_1: 0.575234, top_k: 0.802773, samples/s: 1740.208 1612893304.4620268
train: epoch 74, iter 5000, loss: 2.739870, top_1: 0.576992, top_k: 0.800000, samples/s: 1751.831 1612893319.0753665
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_74.
validation: epoch 74, iter 195, top_1: 0.615304, top_k: 0.846494, samples/s: 2831.101 1612893337.1744292
train: epoch 75, iter 100, loss: 2.862861, top_1: 0.583086, top_k: 0.801016, samples/s: 1750.893 1612893372.5583236
train: epoch 75, iter 200, loss: 2.759740, top_1: 0.581680, top_k: 0.802969, samples/s: 1758.607 1612893387.1152046
train: epoch 75, iter 300, loss: 2.864245, top_1: 0.578945, top_k: 0.802500, samples/s: 1755.435 1612893401.698485
train: epoch 75, iter 400, loss: 2.738324, top_1: 0.582227, top_k: 0.804297, samples/s: 1759.688 1612893416.246505
train: epoch 75, iter 500, loss: 2.836622, top_1: 0.579688, top_k: 0.800391, samples/s: 1761.877 1612893430.7764926
train: epoch 75, iter 600, loss: 2.761482, top_1: 0.578203, top_k: 0.804180, samples/s: 1758.701 1612893445.3326643
train: epoch 75, iter 700, loss: 2.746349, top_1: 0.577500, top_k: 0.802344, samples/s: 1754.954 1612893459.9200566
train: epoch 75, iter 800, loss: 2.941013, top_1: 0.581641, top_k: 0.802227, samples/s: 1758.985 1612893474.4738007
train: epoch 75, iter 900, loss: 2.717773, top_1: 0.579102, top_k: 0.806797, samples/s: 1737.177 1612893489.210411
train: epoch 75, iter 1000, loss: 2.683078, top_1: 0.583828, top_k: 0.803789, samples/s: 1741.133 1612893503.9134064
train: epoch 75, iter 1100, loss: 2.749724, top_1: 0.578281, top_k: 0.802422, samples/s: 1744.766 1612893518.5859246
train: epoch 75, iter 1200, loss: 2.881315, top_1: 0.573203, top_k: 0.802539, samples/s: 1742.743 1612893533.2753792
train: epoch 75, iter 1300, loss: 2.685621, top_1: 0.575391, top_k: 0.800703, samples/s: 1742.342 1612893547.968279
train: epoch 75, iter 1400, loss: 2.871436, top_1: 0.577539, top_k: 0.802656, samples/s: 1741.946 1612893562.6644306
train: epoch 75, iter 1500, loss: 2.780671, top_1: 0.573633, top_k: 0.800312, samples/s: 1734.007 1612893577.42797
train: epoch 75, iter 1600, loss: 2.604281, top_1: 0.580195, top_k: 0.801719, samples/s: 1747.194 1612893592.079999
train: epoch 75, iter 1700, loss: 2.846260, top_1: 0.579727, top_k: 0.798594, samples/s: 1744.167 1612893606.7575295
train: epoch 75, iter 1800, loss: 2.773038, top_1: 0.580586, top_k: 0.802305, samples/s: 1737.142 1612893621.4943204
train: epoch 75, iter 1900, loss: 2.823754, top_1: 0.574922, top_k: 0.795508, samples/s: 1733.050 1612893636.2659912
train: epoch 75, iter 2000, loss: 2.884570, top_1: 0.570977, top_k: 0.796328, samples/s: 1750.742 1612893650.888407
train: epoch 75, iter 2100, loss: 2.900672, top_1: 0.573281, top_k: 0.796055, samples/s: 1738.499 1612893665.6137254
train: epoch 75, iter 2200, loss: 2.523950, top_1: 0.572227, top_k: 0.797031, samples/s: 1741.179 1612893680.3163943
train: epoch 75, iter 2300, loss: 2.865024, top_1: 0.573594, top_k: 0.797461, samples/s: 1750.942 1612893694.9371226
train: epoch 75, iter 2400, loss: 2.714859, top_1: 0.576094, top_k: 0.794727, samples/s: 1730.359 1612893709.7317
train: epoch 75, iter 2500, loss: 2.859782, top_1: 0.577656, top_k: 0.800078, samples/s: 1755.593 1612893724.3137202
train: epoch 75, iter 2600, loss: 2.681102, top_1: 0.580391, top_k: 0.802695, samples/s: 1742.476 1612893739.0055592
train: epoch 75, iter 2700, loss: 2.726880, top_1: 0.574688, top_k: 0.801133, samples/s: 1752.092 1612893753.6165347
train: epoch 75, iter 2800, loss: 2.518707, top_1: 0.572891, top_k: 0.799023, samples/s: 1738.175 1612893768.3446093
train: epoch 75, iter 2900, loss: 2.740794, top_1: 0.569102, top_k: 0.792773, samples/s: 1732.083 1612893783.1244795
train: epoch 75, iter 3000, loss: 2.748191, top_1: 0.573672, top_k: 0.798125, samples/s: 1750.119 1612893797.752125
train: epoch 75, iter 3100, loss: 2.857817, top_1: 0.573555, top_k: 0.798047, samples/s: 1736.199 1612893812.497013
train: epoch 75, iter 3200, loss: 2.903193, top_1: 0.573945, top_k: 0.800000, samples/s: 1746.398 1612893827.155712
train: epoch 75, iter 3300, loss: 2.717719, top_1: 0.577227, top_k: 0.800039, samples/s: 1749.704 1612893841.7867756
train: epoch 75, iter 3400, loss: 2.812729, top_1: 0.574609, top_k: 0.800078, samples/s: 1739.086 1612893856.5071354
train: epoch 75, iter 3500, loss: 2.638596, top_1: 0.569766, top_k: 0.797109, samples/s: 1739.018 1612893871.2280695
train: epoch 75, iter 3600, loss: 2.714654, top_1: 0.576758, top_k: 0.796211, samples/s: 1733.995 1612893885.9916403
train: epoch 75, iter 3700, loss: 2.782344, top_1: 0.576484, top_k: 0.799453, samples/s: 1741.081 1612893900.6952617
train: epoch 75, iter 3800, loss: 2.685378, top_1: 0.575234, top_k: 0.799844, samples/s: 1759.937 1612893915.241207
train: epoch 75, iter 3900, loss: 2.780952, top_1: 0.577109, top_k: 0.798867, samples/s: 1748.603 1612893929.881419
train: epoch 75, iter 4000, loss: 2.800034, top_1: 0.572109, top_k: 0.795664, samples/s: 1743.316 1612893944.56604
train: epoch 75, iter 4100, loss: 2.798423, top_1: 0.567070, top_k: 0.794063, samples/s: 1742.257 1612893959.2596838
train: epoch 75, iter 4200, loss: 2.695316, top_1: 0.571836, top_k: 0.797188, samples/s: 1748.829 1612893973.8979685
train: epoch 75, iter 4300, loss: 2.788326, top_1: 0.566484, top_k: 0.791562, samples/s: 1735.878 1612893988.645728
train: epoch 75, iter 4400, loss: 2.730464, top_1: 0.575195, top_k: 0.797344, samples/s: 1736.875 1612894003.3847613
train: epoch 75, iter 4500, loss: 2.806383, top_1: 0.575703, top_k: 0.798047, samples/s: 1740.329 1612894018.094575
train: epoch 75, iter 4600, loss: 2.840723, top_1: 0.569063, top_k: 0.793203, samples/s: 1748.592 1612894032.734952
train: epoch 75, iter 4700, loss: 2.670190, top_1: 0.574141, top_k: 0.799023, samples/s: 1729.476 1612894047.5371814
train: epoch 75, iter 4800, loss: 2.859412, top_1: 0.572773, top_k: 0.796602, samples/s: 1739.071 1612894062.2576358
train: epoch 75, iter 4900, loss: 2.883596, top_1: 0.566719, top_k: 0.791992, samples/s: 1739.165 1612894076.9772668
train: epoch 75, iter 5000, loss: 2.692506, top_1: 0.573281, top_k: 0.794141, samples/s: 1759.458 1612894091.5272017
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_75.
validation: epoch 75, iter 195, top_1: 0.612079, top_k: 0.842268, samples/s: 2813.608 1612894109.7207494
train: epoch 76, iter 100, loss: 2.859212, top_1: 0.580742, top_k: 0.802930, samples/s: 1748.253 1612894144.5091515
train: epoch 76, iter 200, loss: 2.752028, top_1: 0.579336, top_k: 0.801992, samples/s: 1759.111 1612894159.0618923
train: epoch 76, iter 300, loss: 2.812732, top_1: 0.581367, top_k: 0.801992, samples/s: 1758.789 1612894173.6173494
train: epoch 76, iter 400, loss: 2.674692, top_1: 0.581875, top_k: 0.804102, samples/s: 1753.647 1612894188.2157927
train: epoch 76, iter 500, loss: 2.870205, top_1: 0.582148, top_k: 0.806445, samples/s: 1765.340 1612894202.716998
train: epoch 76, iter 600, loss: 2.756620, top_1: 0.585234, top_k: 0.806641, samples/s: 1767.547 1612894217.2002509
train: epoch 76, iter 700, loss: 2.860034, top_1: 0.580547, top_k: 0.803438, samples/s: 1748.801 1612894231.8389297
train: epoch 76, iter 800, loss: 2.704240, top_1: 0.585234, top_k: 0.802227, samples/s: 1744.638 1612894246.512439
train: epoch 76, iter 900, loss: 2.886506, top_1: 0.578281, top_k: 0.801602, samples/s: 1727.660 1612894261.3302166
train: epoch 76, iter 1000, loss: 2.823982, top_1: 0.577969, top_k: 0.805469, samples/s: 1758.472 1612894275.8882437
train: epoch 76, iter 1100, loss: 2.790518, top_1: 0.584688, top_k: 0.803984, samples/s: 1745.808 1612894290.5519729
train: epoch 76, iter 1200, loss: 2.791577, top_1: 0.580781, top_k: 0.799844, samples/s: 1737.102 1612894305.2890987
train: epoch 76, iter 1300, loss: 2.963756, top_1: 0.580703, top_k: 0.803594, samples/s: 1753.336 1612894319.8898962
train: epoch 76, iter 1400, loss: 2.818528, top_1: 0.573320, top_k: 0.797070, samples/s: 1737.838 1612894334.6208324
train: epoch 76, iter 1500, loss: 2.531518, top_1: 0.579180, top_k: 0.803359, samples/s: 1743.570 1612894349.3033645
train: epoch 76, iter 1600, loss: 2.743073, top_1: 0.578164, top_k: 0.802031, samples/s: 1738.337 1612894364.0300972
train: epoch 76, iter 1700, loss: 2.715027, top_1: 0.583789, top_k: 0.805820, samples/s: 1749.160 1612894378.6656523
train: epoch 76, iter 1800, loss: 2.746268, top_1: 0.576914, top_k: 0.797500, samples/s: 1744.241 1612894393.3425653
train: epoch 76, iter 1900, loss: 2.697191, top_1: 0.577266, top_k: 0.800078, samples/s: 1751.970 1612894407.9546466
train: epoch 76, iter 2000, loss: 2.572969, top_1: 0.581250, top_k: 0.803633, samples/s: 1741.260 1612894422.65673
train: epoch 76, iter 2100, loss: 2.568608, top_1: 0.577266, top_k: 0.801914, samples/s: 1751.722 1612894437.2708519
train: epoch 76, iter 2200, loss: 2.844391, top_1: 0.577070, top_k: 0.799063, samples/s: 1737.383 1612894452.0056386
train: epoch 76, iter 2300, loss: 2.800607, top_1: 0.573398, top_k: 0.795391, samples/s: 1745.615 1612894466.6709847
train: epoch 76, iter 2400, loss: 2.820485, top_1: 0.580664, top_k: 0.799180, samples/s: 1750.940 1612894481.2917008
train: epoch 76, iter 2500, loss: 2.831499, top_1: 0.576992, top_k: 0.798477, samples/s: 1728.234 1612894496.1045434
train: epoch 76, iter 2600, loss: 2.890835, top_1: 0.578633, top_k: 0.799805, samples/s: 1757.046 1612894510.6743803
train: epoch 76, iter 2700, loss: 2.724898, top_1: 0.578008, top_k: 0.802734, samples/s: 1749.615 1612894525.306219
train: epoch 76, iter 2800, loss: 2.693992, top_1: 0.579063, top_k: 0.802031, samples/s: 1745.877 1612894539.969274
train: epoch 76, iter 2900, loss: 2.579542, top_1: 0.584727, top_k: 0.803945, samples/s: 1731.227 1612894554.7565074
train: epoch 76, iter 3000, loss: 2.810982, top_1: 0.578594, top_k: 0.796211, samples/s: 1739.160 1612894569.4762924
train: epoch 76, iter 3100, loss: 2.870386, top_1: 0.582891, top_k: 0.802227, samples/s: 1743.456 1612894584.1598146
train: epoch 76, iter 3200, loss: 2.723419, top_1: 0.573594, top_k: 0.796953, samples/s: 1751.426 1612894598.7763865
train: epoch 76, iter 3300, loss: 2.730511, top_1: 0.571211, top_k: 0.793867, samples/s: 1745.669 1612894613.441268
train: epoch 76, iter 3400, loss: 2.668790, top_1: 0.573555, top_k: 0.798008, samples/s: 1751.741 1612894628.055261
train: epoch 76, iter 3500, loss: 2.712232, top_1: 0.584492, top_k: 0.803164, samples/s: 1730.358 1612894642.8499477
train: epoch 76, iter 3600, loss: 2.728402, top_1: 0.574219, top_k: 0.799375, samples/s: 1740.837 1612894657.5554922
train: epoch 76, iter 3700, loss: 2.703605, top_1: 0.576914, top_k: 0.795781, samples/s: 1750.725 1612894672.1779723
train: epoch 76, iter 3800, loss: 2.857595, top_1: 0.578086, top_k: 0.794375, samples/s: 1746.236 1612894686.8381279
train: epoch 76, iter 3900, loss: 2.831455, top_1: 0.576016, top_k: 0.799375, samples/s: 1746.840 1612894701.4931602
train: epoch 76, iter 4000, loss: 2.850461, top_1: 0.573750, top_k: 0.796875, samples/s: 1737.091 1612894716.2303927
train: epoch 76, iter 4100, loss: 2.829827, top_1: 0.573125, top_k: 0.795664, samples/s: 1742.427 1612894730.922604
train: epoch 76, iter 4200, loss: 2.995780, top_1: 0.577891, top_k: 0.799180, samples/s: 1747.302 1612894745.5737212
train: epoch 76, iter 4300, loss: 2.559347, top_1: 0.578320, top_k: 0.798633, samples/s: 1747.342 1612894760.2246628
train: epoch 76, iter 4400, loss: 2.667914, top_1: 0.574766, top_k: 0.799297, samples/s: 1747.945 1612894774.8704264
train: epoch 76, iter 4500, loss: 2.714371, top_1: 0.576758, top_k: 0.800898, samples/s: 1726.354 1612894789.6994162
train: epoch 76, iter 4600, loss: 2.814088, top_1: 0.572070, top_k: 0.795937, samples/s: 1748.789 1612894804.3379583
train: epoch 76, iter 4700, loss: 2.846530, top_1: 0.572617, top_k: 0.796445, samples/s: 1745.093 1612894819.0077257
train: epoch 76, iter 4800, loss: 2.865129, top_1: 0.577656, top_k: 0.797461, samples/s: 1743.972 1612894833.6868944
train: epoch 76, iter 4900, loss: 2.559027, top_1: 0.572422, top_k: 0.796602, samples/s: 1757.883 1612894848.2498324
train: epoch 76, iter 5000, loss: 2.791378, top_1: 0.570117, top_k: 0.794844, samples/s: 1744.691 1612894862.922929
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_76.
validation: epoch 76, iter 195, top_1: 0.611819, top_k: 0.841086, samples/s: 2841.424 1612894880.8881469
train: epoch 77, iter 100, loss: 2.862260, top_1: 0.576914, top_k: 0.803555, samples/s: 1744.786 1612894915.6988382
train: epoch 77, iter 200, loss: 2.754870, top_1: 0.588867, top_k: 0.804766, samples/s: 1753.149 1612894930.301186
train: epoch 77, iter 300, loss: 2.830323, top_1: 0.575234, top_k: 0.799844, samples/s: 1744.916 1612894944.9722383
train: epoch 77, iter 400, loss: 2.767757, top_1: 0.584063, top_k: 0.804961, samples/s: 1750.978 1612894959.5926821
train: epoch 77, iter 500, loss: 2.790574, top_1: 0.578164, top_k: 0.801133, samples/s: 1765.857 1612894974.0898948
train: epoch 77, iter 600, loss: 2.609942, top_1: 0.584492, top_k: 0.805234, samples/s: 1758.604 1612894988.646888
train: epoch 77, iter 700, loss: 2.817734, top_1: 0.584766, top_k: 0.806328, samples/s: 1753.784 1612895003.2438374
train: epoch 77, iter 800, loss: 2.530277, top_1: 0.582148, top_k: 0.806680, samples/s: 1739.505 1612895017.9608116
train: epoch 77, iter 900, loss: 2.596329, top_1: 0.581562, top_k: 0.801602, samples/s: 1761.581 1612895032.4931388
train: epoch 77, iter 1000, loss: 2.553071, top_1: 0.578086, top_k: 0.802422, samples/s: 1745.687 1612895047.1578279
train: epoch 77, iter 1100, loss: 2.486238, top_1: 0.584453, top_k: 0.805820, samples/s: 1740.463 1612895061.8665009
train: epoch 77, iter 1200, loss: 2.874402, top_1: 0.582266, top_k: 0.801758, samples/s: 1743.902 1612895076.54635
train: epoch 77, iter 1300, loss: 2.817287, top_1: 0.579570, top_k: 0.802188, samples/s: 1747.581 1612895091.1950707
train: epoch 77, iter 1400, loss: 2.656974, top_1: 0.578828, top_k: 0.800859, samples/s: 1739.904 1612895105.908519
train: epoch 77, iter 1500, loss: 2.914611, top_1: 0.584609, top_k: 0.800000, samples/s: 1758.611 1612895120.4655297
train: epoch 77, iter 1600, loss: 2.816844, top_1: 0.581680, top_k: 0.803359, samples/s: 1743.918 1612895135.1450512
train: epoch 77, iter 1700, loss: 2.621075, top_1: 0.576484, top_k: 0.801172, samples/s: 1752.458 1612895149.7530925
train: epoch 77, iter 1800, loss: 2.647121, top_1: 0.581562, top_k: 0.803047, samples/s: 1746.087 1612895164.4145067
train: epoch 77, iter 1900, loss: 2.590535, top_1: 0.581914, top_k: 0.803008, samples/s: 1745.027 1612895179.0847492
train: epoch 77, iter 2000, loss: 2.655348, top_1: 0.574883, top_k: 0.802188, samples/s: 1749.465 1612895193.7178211
train: epoch 77, iter 2100, loss: 2.566162, top_1: 0.576719, top_k: 0.802148, samples/s: 1745.405 1612895208.3849542
train: epoch 77, iter 2200, loss: 2.726354, top_1: 0.574727, top_k: 0.797188, samples/s: 1744.493 1612895223.0597072
train: epoch 77, iter 2300, loss: 2.595099, top_1: 0.582500, top_k: 0.798555, samples/s: 1755.274 1612895237.6442707
train: epoch 77, iter 2400, loss: 2.739006, top_1: 0.578242, top_k: 0.799844, samples/s: 1745.077 1612895252.31403
train: epoch 77, iter 2500, loss: 2.662891, top_1: 0.576250, top_k: 0.795664, samples/s: 1754.234 1612895266.9073322
train: epoch 77, iter 2600, loss: 2.853032, top_1: 0.579570, top_k: 0.799844, samples/s: 1744.798 1612895281.579574
train: epoch 77, iter 2700, loss: 2.972928, top_1: 0.575234, top_k: 0.796328, samples/s: 1740.772 1612895296.2857523
train: epoch 77, iter 2800, loss: 2.746138, top_1: 0.576758, top_k: 0.796836, samples/s: 1758.142 1612895310.8464499
train: epoch 77, iter 2900, loss: 2.791506, top_1: 0.578945, top_k: 0.800742, samples/s: 1742.430 1612895325.5385962
train: epoch 77, iter 3000, loss: 2.773445, top_1: 0.581133, top_k: 0.807187, samples/s: 1740.035 1612895340.250923
train: epoch 77, iter 3100, loss: 2.744019, top_1: 0.580937, top_k: 0.800703, samples/s: 1745.746 1612895354.9152462
train: epoch 77, iter 3200, loss: 2.745932, top_1: 0.577617, top_k: 0.797539, samples/s: 1741.835 1612895369.6123161
train: epoch 77, iter 3300, loss: 2.750223, top_1: 0.577031, top_k: 0.801953, samples/s: 1748.854 1612895384.2507837
train: epoch 77, iter 3400, loss: 2.727240, top_1: 0.575430, top_k: 0.798555, samples/s: 1748.919 1612895398.888049
train: epoch 77, iter 3500, loss: 2.401108, top_1: 0.579063, top_k: 0.800273, samples/s: 1738.434 1612895413.6139448
train: epoch 77, iter 3600, loss: 2.783327, top_1: 0.581133, top_k: 0.801211, samples/s: 1758.521 1612895428.1717024
train: epoch 77, iter 3700, loss: 2.887569, top_1: 0.582305, top_k: 0.801875, samples/s: 1737.515 1612895442.9053628
train: epoch 77, iter 3800, loss: 2.690784, top_1: 0.574336, top_k: 0.796484, samples/s: 1736.114 1612895457.651448
train: epoch 77, iter 3900, loss: 2.808895, top_1: 0.577227, top_k: 0.800742, samples/s: 1752.486 1612895472.258704
train: epoch 77, iter 4000, loss: 2.603792, top_1: 0.581836, top_k: 0.802617, samples/s: 1731.848 1612895487.0406568
train: epoch 77, iter 4100, loss: 2.764966, top_1: 0.575117, top_k: 0.797773, samples/s: 1746.518 1612895501.6983936
train: epoch 77, iter 4200, loss: 2.871337, top_1: 0.579766, top_k: 0.800703, samples/s: 1741.942 1612895516.3946311
train: epoch 77, iter 4300, loss: 2.593617, top_1: 0.575898, top_k: 0.800820, samples/s: 1748.286 1612895531.0375152
train: epoch 77, iter 4400, loss: 3.008190, top_1: 0.579297, top_k: 0.798633, samples/s: 1746.262 1612895545.6974273
train: epoch 77, iter 4500, loss: 2.624924, top_1: 0.580156, top_k: 0.800625, samples/s: 1732.028 1612895560.477797
train: epoch 77, iter 4600, loss: 2.741045, top_1: 0.576250, top_k: 0.796406, samples/s: 1754.539 1612895575.0685022
train: epoch 77, iter 4700, loss: 2.687833, top_1: 0.574336, top_k: 0.800977, samples/s: 1742.018 1612895589.7641408
train: epoch 77, iter 4800, loss: 2.741157, top_1: 0.583984, top_k: 0.803164, samples/s: 1756.674 1612895604.3371127
train: epoch 77, iter 4900, loss: 2.824402, top_1: 0.576914, top_k: 0.800547, samples/s: 1723.433 1612895619.1911967
train: epoch 77, iter 5000, loss: 2.718300, top_1: 0.582461, top_k: 0.800391, samples/s: 1752.401 1612895633.7997704
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_77.
validation: epoch 77, iter 195, top_1: 0.624339, top_k: 0.851522, samples/s: 2909.740 1612895651.3438575
train: epoch 78, iter 100, loss: 2.788111, top_1: 0.590273, top_k: 0.809883, samples/s: 1746.961 1612895687.8766003
train: epoch 78, iter 200, loss: 2.783250, top_1: 0.591133, top_k: 0.811367, samples/s: 1755.610 1612895702.4584503
train: epoch 78, iter 300, loss: 2.691587, top_1: 0.587695, top_k: 0.806914, samples/s: 1759.748 1612895717.0060158
train: epoch 78, iter 400, loss: 2.787790, top_1: 0.586406, top_k: 0.806680, samples/s: 1761.527 1612895731.5387883
train: epoch 78, iter 500, loss: 2.572996, top_1: 0.587734, top_k: 0.809180, samples/s: 1757.564 1612895746.104443
train: epoch 78, iter 600, loss: 2.704085, top_1: 0.583867, top_k: 0.804375, samples/s: 1742.952 1612895760.7922041
train: epoch 78, iter 700, loss: 2.860027, top_1: 0.581523, top_k: 0.799961, samples/s: 1773.307 1612895775.2285073
train: epoch 78, iter 800, loss: 2.667747, top_1: 0.586211, top_k: 0.808438, samples/s: 1749.882 1612895789.858049
train: epoch 78, iter 900, loss: 2.616970, top_1: 0.589219, top_k: 0.808203, samples/s: 1751.578 1612895804.4734437
train: epoch 78, iter 1000, loss: 2.604039, top_1: 0.587695, top_k: 0.807148, samples/s: 1744.668 1612895819.1466954
train: epoch 78, iter 1100, loss: 2.810427, top_1: 0.581562, top_k: 0.804102, samples/s: 1725.302 1612895833.9846604
train: epoch 78, iter 1200, loss: 2.906647, top_1: 0.581758, top_k: 0.800586, samples/s: 1752.017 1612895848.5964339
train: epoch 78, iter 1300, loss: 2.897050, top_1: 0.578164, top_k: 0.799336, samples/s: 1747.822 1612895863.2432284
train: epoch 78, iter 1400, loss: 2.783967, top_1: 0.582734, top_k: 0.802539, samples/s: 1754.652 1612895877.8330266
train: epoch 78, iter 1500, loss: 2.726992, top_1: 0.579180, top_k: 0.802695, samples/s: 1735.259 1612895892.5858653
train: epoch 78, iter 1600, loss: 2.690133, top_1: 0.584180, top_k: 0.802773, samples/s: 1742.093 1612895907.280836
train: epoch 78, iter 1700, loss: 2.657650, top_1: 0.584805, top_k: 0.805508, samples/s: 1750.206 1612895921.9076574
train: epoch 78, iter 1800, loss: 2.642866, top_1: 0.579648, top_k: 0.800156, samples/s: 1748.156 1612895936.5516632
train: epoch 78, iter 1900, loss: 2.700544, top_1: 0.580625, top_k: 0.806445, samples/s: 1727.762 1612895951.3685002
train: epoch 78, iter 2000, loss: 2.759714, top_1: 0.576133, top_k: 0.796914, samples/s: 1756.150 1612895965.9458156
train: epoch 78, iter 2100, loss: 2.820828, top_1: 0.582617, top_k: 0.802070, samples/s: 1752.000 1612895980.5577178
train: epoch 78, iter 2200, loss: 2.862803, top_1: 0.575117, top_k: 0.800625, samples/s: 1740.920 1612895995.2626169
train: epoch 78, iter 2300, loss: 2.762579, top_1: 0.582930, top_k: 0.803633, samples/s: 1742.753 1612896009.951985
train: epoch 78, iter 2400, loss: 2.686246, top_1: 0.580820, top_k: 0.799570, samples/s: 1747.423 1612896024.6022623
train: epoch 78, iter 2500, loss: 2.607523, top_1: 0.570937, top_k: 0.793438, samples/s: 1744.898 1612896039.2734554
train: epoch 78, iter 2600, loss: 2.730344, top_1: 0.575313, top_k: 0.800039, samples/s: 1750.878 1612896053.894743
train: epoch 78, iter 2700, loss: 2.848131, top_1: 0.581953, top_k: 0.800234, samples/s: 1737.939 1612896068.6248808
train: epoch 78, iter 2800, loss: 2.698984, top_1: 0.586992, top_k: 0.809727, samples/s: 1754.612 1612896083.2148912
train: epoch 78, iter 2900, loss: 2.859102, top_1: 0.580391, top_k: 0.798789, samples/s: 1741.316 1612896097.916472
train: epoch 78, iter 3000, loss: 2.745866, top_1: 0.572891, top_k: 0.795664, samples/s: 1736.700 1612896112.6571374
train: epoch 78, iter 3100, loss: 2.803218, top_1: 0.583984, top_k: 0.804727, samples/s: 1758.758 1612896127.2128012
train: epoch 78, iter 3200, loss: 2.723039, top_1: 0.580117, top_k: 0.799687, samples/s: 1741.479 1612896141.9129906
train: epoch 78, iter 3300, loss: 2.816595, top_1: 0.583047, top_k: 0.805234, samples/s: 1755.449 1612896156.4961104
train: epoch 78, iter 3400, loss: 2.575691, top_1: 0.585000, top_k: 0.802344, samples/s: 1737.845 1612896171.226958
train: epoch 78, iter 3500, loss: 2.670009, top_1: 0.580391, top_k: 0.802188, samples/s: 1746.930 1612896185.8816009
train: epoch 78, iter 3600, loss: 2.704623, top_1: 0.575781, top_k: 0.797031, samples/s: 1741.871 1612896200.5781393
train: epoch 78, iter 3700, loss: 2.616264, top_1: 0.583398, top_k: 0.805156, samples/s: 1747.886 1612896215.2246532
train: epoch 78, iter 3800, loss: 2.875291, top_1: 0.578281, top_k: 0.799531, samples/s: 1750.875 1612896229.8456867
train: epoch 78, iter 3900, loss: 2.675712, top_1: 0.582383, top_k: 0.805703, samples/s: 1741.903 1612896244.5422583
train: epoch 78, iter 4000, loss: 2.703773, top_1: 0.578984, top_k: 0.796562, samples/s: 1747.215 1612896259.1941106
train: epoch 78, iter 4100, loss: 2.769024, top_1: 0.579688, top_k: 0.803945, samples/s: 1751.627 1612896273.8091722
train: epoch 78, iter 4200, loss: 2.630627, top_1: 0.579648, top_k: 0.801367, samples/s: 1752.656 1612896288.416299
train: epoch 78, iter 4300, loss: 2.921121, top_1: 0.582031, top_k: 0.800977, samples/s: 1740.745 1612896303.1217868
train: epoch 78, iter 4400, loss: 2.653616, top_1: 0.578672, top_k: 0.801328, samples/s: 1749.067 1612896317.7582266
train: epoch 78, iter 4500, loss: 2.735892, top_1: 0.585781, top_k: 0.805391, samples/s: 1741.375 1612896332.4591918
train: epoch 78, iter 4600, loss: 2.766776, top_1: 0.580977, top_k: 0.801250, samples/s: 1747.064 1612896347.1124122
train: epoch 78, iter 4700, loss: 2.533949, top_1: 0.582070, top_k: 0.806367, samples/s: 1745.796 1612896361.7761636
train: epoch 78, iter 4800, loss: 2.684515, top_1: 0.578789, top_k: 0.801953, samples/s: 1756.894 1612896376.3473196
train: epoch 78, iter 4900, loss: 2.700962, top_1: 0.574883, top_k: 0.797734, samples/s: 1729.055 1612896391.153547
train: epoch 78, iter 5000, loss: 2.761567, top_1: 0.580508, top_k: 0.802031, samples/s: 1755.161 1612896405.7387428
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_78.
validation: epoch 78, iter 195, top_1: 0.618249, top_k: 0.846294, samples/s: 2798.107 1612896424.0129116
train: epoch 79, iter 100, loss: 2.769863, top_1: 0.590820, top_k: 0.809648, samples/s: 1751.647 1612896459.329306
train: epoch 79, iter 200, loss: 2.653697, top_1: 0.584531, top_k: 0.805977, samples/s: 1753.388 1612896473.929615
train: epoch 79, iter 300, loss: 2.459516, top_1: 0.588672, top_k: 0.808203, samples/s: 1751.477 1612896488.545866
train: epoch 79, iter 400, loss: 2.562364, top_1: 0.591133, top_k: 0.812617, samples/s: 1759.850 1612896503.0924933
train: epoch 79, iter 500, loss: 2.617329, top_1: 0.587930, top_k: 0.809297, samples/s: 1751.626 1612896517.7077222
train: epoch 79, iter 600, loss: 2.602040, top_1: 0.582852, top_k: 0.804961, samples/s: 1759.438 1612896532.2576587
train: epoch 79, iter 700, loss: 2.673408, top_1: 0.593711, top_k: 0.811953, samples/s: 1756.467 1612896546.8323233
train: epoch 79, iter 800, loss: 2.670334, top_1: 0.581758, top_k: 0.802969, samples/s: 1748.151 1612896561.4763784
train: epoch 79, iter 900, loss: 2.657351, top_1: 0.588477, top_k: 0.809180, samples/s: 1752.227 1612896576.0864046
train: epoch 79, iter 1000, loss: 2.726162, top_1: 0.590430, top_k: 0.808047, samples/s: 1748.260 1612896590.729484
train: epoch 79, iter 1100, loss: 2.673373, top_1: 0.587422, top_k: 0.807422, samples/s: 1748.588 1612896605.3698432
train: epoch 79, iter 1200, loss: 2.782812, top_1: 0.584219, top_k: 0.804766, samples/s: 1740.764 1612896620.076041
train: epoch 79, iter 1300, loss: 2.729942, top_1: 0.579922, top_k: 0.805078, samples/s: 1745.738 1612896634.740381
train: epoch 79, iter 1400, loss: 2.702384, top_1: 0.587187, top_k: 0.804766, samples/s: 1754.968 1612896649.3275533
train: epoch 79, iter 1500, loss: 2.876293, top_1: 0.575703, top_k: 0.798906, samples/s: 1743.820 1612896664.007975
train: epoch 79, iter 1600, loss: 2.850425, top_1: 0.586484, top_k: 0.807930, samples/s: 1729.942 1612896678.8062115
train: epoch 79, iter 1700, loss: 2.847406, top_1: 0.582461, top_k: 0.804531, samples/s: 1756.858 1612896693.3776126
train: epoch 79, iter 1800, loss: 2.775378, top_1: 0.581055, top_k: 0.807031, samples/s: 1734.072 1612896708.1405666
train: epoch 79, iter 1900, loss: 2.807000, top_1: 0.583320, top_k: 0.803555, samples/s: 1748.527 1612896722.7814016
train: epoch 79, iter 2000, loss: 2.748893, top_1: 0.585820, top_k: 0.803242, samples/s: 1749.003 1612896737.4184213
train: epoch 79, iter 2100, loss: 2.682051, top_1: 0.582148, top_k: 0.804844, samples/s: 1748.266 1612896752.06145
train: epoch 79, iter 2200, loss: 2.653640, top_1: 0.579453, top_k: 0.800820, samples/s: 1737.774 1612896766.7929554
train: epoch 79, iter 2300, loss: 2.777767, top_1: 0.583125, top_k: 0.806094, samples/s: 1747.003 1612896781.4466069
train: epoch 79, iter 2400, loss: 2.741501, top_1: 0.584375, top_k: 0.800937, samples/s: 1733.406 1612896796.2151625
train: epoch 79, iter 2500, loss: 2.738473, top_1: 0.581016, top_k: 0.803477, samples/s: 1747.338 1612896810.866051
train: epoch 79, iter 2600, loss: 2.721663, top_1: 0.580898, top_k: 0.801523, samples/s: 1754.205 1612896825.4595795
train: epoch 79, iter 2700, loss: 2.964666, top_1: 0.582891, top_k: 0.808984, samples/s: 1740.717 1612896840.1661322
train: epoch 79, iter 2800, loss: 2.581138, top_1: 0.581367, top_k: 0.804023, samples/s: 1736.439 1612896854.9089928
train: epoch 79, iter 2900, loss: 2.640346, top_1: 0.582852, top_k: 0.804648, samples/s: 1756.416 1612896869.4840882
train: epoch 79, iter 3000, loss: 2.690205, top_1: 0.582305, top_k: 0.804102, samples/s: 1733.727 1612896884.249938
train: epoch 79, iter 3100, loss: 2.957222, top_1: 0.574063, top_k: 0.802813, samples/s: 1746.738 1612896898.9058568
train: epoch 79, iter 3200, loss: 2.770277, top_1: 0.572656, top_k: 0.797930, samples/s: 1748.238 1612896913.5491893
train: epoch 79, iter 3300, loss: 2.763207, top_1: 0.584375, top_k: 0.804609, samples/s: 1729.696 1612896928.3495069
train: epoch 79, iter 3400, loss: 2.818748, top_1: 0.585781, top_k: 0.804141, samples/s: 1757.987 1612896942.9115305
train: epoch 79, iter 3500, loss: 2.726037, top_1: 0.575391, top_k: 0.802148, samples/s: 1755.359 1612896957.4954844
train: epoch 79, iter 3600, loss: 2.889182, top_1: 0.577812, top_k: 0.796367, samples/s: 1736.775 1612896972.2355835
train: epoch 79, iter 3700, loss: 2.819098, top_1: 0.567344, top_k: 0.794023, samples/s: 1743.537 1612896986.9182007
train: epoch 79, iter 3800, loss: 2.710281, top_1: 0.578945, top_k: 0.800781, samples/s: 1752.988 1612897001.5218885
train: epoch 79, iter 3900, loss: 2.655256, top_1: 0.577344, top_k: 0.796562, samples/s: 1744.459 1612897016.1969364
train: epoch 79, iter 4000, loss: 2.698025, top_1: 0.575039, top_k: 0.796992, samples/s: 1744.863 1612897030.868553
train: epoch 79, iter 4100, loss: 2.704454, top_1: 0.578633, top_k: 0.797578, samples/s: 1750.216 1612897045.495274
train: epoch 79, iter 4200, loss: 2.596410, top_1: 0.573711, top_k: 0.799375, samples/s: 1745.004 1612897060.165713
train: epoch 79, iter 4300, loss: 2.548775, top_1: 0.579492, top_k: 0.801992, samples/s: 1748.072 1612897074.81054
train: epoch 79, iter 4400, loss: 2.699851, top_1: 0.580703, top_k: 0.804297, samples/s: 1760.417 1612897089.3524613
train: epoch 79, iter 4500, loss: 2.775447, top_1: 0.573984, top_k: 0.797930, samples/s: 1743.958 1612897104.0317721
train: epoch 79, iter 4600, loss: 2.826632, top_1: 0.580078, top_k: 0.801875, samples/s: 1755.599 1612897118.6136
train: epoch 79, iter 4700, loss: 2.733415, top_1: 0.581641, top_k: 0.800703, samples/s: 1738.831 1612897133.3361359
train: epoch 79, iter 4800, loss: 2.612201, top_1: 0.581523, top_k: 0.801406, samples/s: 1737.046 1612897148.07389
train: epoch 79, iter 4900, loss: 2.807290, top_1: 0.586094, top_k: 0.804531, samples/s: 1754.216 1612897162.6672244
train: epoch 79, iter 5000, loss: 2.588580, top_1: 0.584922, top_k: 0.809102, samples/s: 1749.834 1612897177.2971737
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_79.
validation: epoch 79, iter 195, top_1: 0.631831, top_k: 0.853746, samples/s: 2829.712 1612897195.387189
train: epoch 80, iter 100, loss: 2.750586, top_1: 0.591055, top_k: 0.809219, samples/s: 1754.716 1612897230.0572193
train: epoch 80, iter 200, loss: 2.666387, top_1: 0.587305, top_k: 0.809922, samples/s: 1760.207 1612897244.601128
train: epoch 80, iter 300, loss: 2.678926, top_1: 0.584531, top_k: 0.804531, samples/s: 1760.378 1612897259.1432505
train: epoch 80, iter 400, loss: 2.635398, top_1: 0.588555, top_k: 0.807891, samples/s: 1754.952 1612897273.73057
train: epoch 80, iter 500, loss: 2.802322, top_1: 0.591680, top_k: 0.809492, samples/s: 1760.258 1612897288.2738025
train: epoch 80, iter 600, loss: 2.618263, top_1: 0.592070, top_k: 0.810898, samples/s: 1752.719 1612897302.8796709
train: epoch 80, iter 700, loss: 2.878387, top_1: 0.589219, top_k: 0.808086, samples/s: 1760.889 1612897317.4178648
train: epoch 80, iter 800, loss: 2.523297, top_1: 0.594922, top_k: 0.810898, samples/s: 1762.590 1612897331.9419296
train: epoch 80, iter 900, loss: 2.585330, top_1: 0.588594, top_k: 0.807578, samples/s: 1740.642 1612897346.6491158
train: epoch 80, iter 1000, loss: 2.965860, top_1: 0.587344, top_k: 0.808203, samples/s: 1743.053 1612897361.3359988
train: epoch 80, iter 1100, loss: 2.650174, top_1: 0.586719, top_k: 0.808438, samples/s: 1737.886 1612897376.0665684
train: epoch 80, iter 1200, loss: 2.504477, top_1: 0.589531, top_k: 0.806328, samples/s: 1746.665 1612897390.7230566
train: epoch 80, iter 1300, loss: 2.789312, top_1: 0.584648, top_k: 0.808164, samples/s: 1728.293 1612897405.535288
train: epoch 80, iter 1400, loss: 2.564177, top_1: 0.588320, top_k: 0.805977, samples/s: 1755.813 1612897420.1155448
train: epoch 80, iter 1500, loss: 2.654505, top_1: 0.582617, top_k: 0.801680, samples/s: 1759.877 1612897434.6619725
train: epoch 80, iter 1600, loss: 2.697102, top_1: 0.588164, top_k: 0.808164, samples/s: 1735.677 1612897449.4112136
train: epoch 80, iter 1700, loss: 2.654486, top_1: 0.578398, top_k: 0.801836, samples/s: 1744.046 1612897464.089754
train: epoch 80, iter 1800, loss: 2.829788, top_1: 0.581328, top_k: 0.805039, samples/s: 1730.831 1612897478.8802774
train: epoch 80, iter 1900, loss: 2.672761, top_1: 0.581172, top_k: 0.802578, samples/s: 1758.813 1612897493.4355898
train: epoch 80, iter 2000, loss: 2.815187, top_1: 0.592539, top_k: 0.812383, samples/s: 1741.644 1612897508.134356
train: epoch 80, iter 2100, loss: 3.034335, top_1: 0.586680, top_k: 0.808008, samples/s: 1737.684 1612897522.8666115
train: epoch 80, iter 2200, loss: 2.693715, top_1: 0.586250, top_k: 0.803594, samples/s: 1753.734 1612897537.4640272
train: epoch 80, iter 2300, loss: 2.909201, top_1: 0.585039, top_k: 0.805430, samples/s: 1749.704 1612897552.0950124
train: epoch 80, iter 2400, loss: 2.678354, top_1: 0.585781, top_k: 0.806758, samples/s: 1747.199 1612897566.7470603
train: epoch 80, iter 2500, loss: 2.766290, top_1: 0.583750, top_k: 0.805469, samples/s: 1728.322 1612897581.5591373
train: epoch 80, iter 2600, loss: 2.726446, top_1: 0.584883, top_k: 0.807891, samples/s: 1748.195 1612897596.202826
train: epoch 80, iter 2700, loss: 2.874671, top_1: 0.584844, top_k: 0.801836, samples/s: 1726.865 1612897611.0274394
train: epoch 80, iter 2800, loss: 2.838803, top_1: 0.579023, top_k: 0.802617, samples/s: 1758.643 1612897625.5840366
train: epoch 80, iter 2900, loss: 2.714899, top_1: 0.584922, top_k: 0.805625, samples/s: 1748.736 1612897640.2231383
train: epoch 80, iter 3000, loss: 2.804166, top_1: 0.586055, top_k: 0.804688, samples/s: 1732.834 1612897654.9966912
train: epoch 80, iter 3100, loss: 2.598641, top_1: 0.583477, top_k: 0.805117, samples/s: 1747.522 1612897669.6459475
train: epoch 80, iter 3200, loss: 2.713187, top_1: 0.578203, top_k: 0.796328, samples/s: 1747.307 1612897684.2971478
train: epoch 80, iter 3300, loss: 2.788141, top_1: 0.580078, top_k: 0.803359, samples/s: 1734.022 1612897699.0604203
train: epoch 80, iter 3400, loss: 2.682451, top_1: 0.586445, top_k: 0.805625, samples/s: 1741.709 1612897713.7586646
train: epoch 80, iter 3500, loss: 2.959655, top_1: 0.583555, top_k: 0.802539, samples/s: 1748.143 1612897728.4027538
train: epoch 80, iter 3600, loss: 2.665542, top_1: 0.578047, top_k: 0.804141, samples/s: 1739.841 1612897743.116746
train: epoch 80, iter 3700, loss: 2.718310, top_1: 0.582656, top_k: 0.803711, samples/s: 1742.794 1612897757.8058603
train: epoch 80, iter 3800, loss: 2.758768, top_1: 0.576641, top_k: 0.799375, samples/s: 1740.470 1612897772.5144756
train: epoch 80, iter 3900, loss: 2.889177, top_1: 0.577695, top_k: 0.800547, samples/s: 1745.091 1612897787.1842015
train: epoch 80, iter 4000, loss: 2.784679, top_1: 0.584688, top_k: 0.802578, samples/s: 1745.578 1612897801.8499272
train: epoch 80, iter 4100, loss: 2.680605, top_1: 0.580820, top_k: 0.800312, samples/s: 1749.947 1612897816.4788952
train: epoch 80, iter 4200, loss: 2.815369, top_1: 0.579414, top_k: 0.803008, samples/s: 1741.615 1612897831.1778908
train: epoch 80, iter 4300, loss: 2.605403, top_1: 0.578242, top_k: 0.800273, samples/s: 1738.970 1612897845.899328
train: epoch 80, iter 4400, loss: 2.759901, top_1: 0.581406, top_k: 0.805039, samples/s: 1752.047 1612897860.5106864
train: epoch 80, iter 4500, loss: 2.493397, top_1: 0.577461, top_k: 0.803477, samples/s: 1749.953 1612897875.1396415
train: epoch 80, iter 4600, loss: 2.766216, top_1: 0.584688, top_k: 0.803242, samples/s: 1744.358 1612897889.8155677
train: epoch 80, iter 4700, loss: 2.805722, top_1: 0.586992, top_k: 0.806914, samples/s: 1756.758 1612897904.3878362
train: epoch 80, iter 4800, loss: 2.743565, top_1: 0.581836, top_k: 0.801562, samples/s: 1742.671 1612897919.0779552
train: epoch 80, iter 4900, loss: 2.630767, top_1: 0.581523, top_k: 0.804648, samples/s: 1740.861 1612897933.7833076
train: epoch 80, iter 5000, loss: 2.652964, top_1: 0.591055, top_k: 0.806484, samples/s: 1753.406 1612897948.3834572
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_80.
validation: epoch 80, iter 195, top_1: 0.630549, top_k: 0.852484, samples/s: 2729.117 1612897967.1180766
train: epoch 81, iter 100, loss: 2.536445, top_1: 0.593516, top_k: 0.814180, samples/s: 1738.996 1612898001.8380582
train: epoch 81, iter 200, loss: 2.639311, top_1: 0.594023, top_k: 0.812734, samples/s: 1762.173 1612898016.3656268
train: epoch 81, iter 300, loss: 2.674937, top_1: 0.587500, top_k: 0.808320, samples/s: 1758.822 1612898030.920998
train: epoch 81, iter 400, loss: 2.902673, top_1: 0.591719, top_k: 0.810664, samples/s: 1754.862 1612898045.5088024
train: epoch 81, iter 500, loss: 2.697342, top_1: 0.597695, top_k: 0.814023, samples/s: 1766.579 1612898060.0000873
train: epoch 81, iter 600, loss: 2.631762, top_1: 0.592031, top_k: 0.812461, samples/s: 1759.946 1612898074.546051
train: epoch 81, iter 700, loss: 2.608830, top_1: 0.591562, top_k: 0.807305, samples/s: 1745.390 1612898089.2132385
train: epoch 81, iter 800, loss: 2.567420, top_1: 0.583516, top_k: 0.809375, samples/s: 1746.711 1612898103.8694346
train: epoch 81, iter 900, loss: 2.630242, top_1: 0.590781, top_k: 0.808008, samples/s: 1751.510 1612898118.4852805
train: epoch 81, iter 1000, loss: 2.807858, top_1: 0.591562, top_k: 0.810859, samples/s: 1746.511 1612898133.143077
train: epoch 81, iter 1100, loss: 2.675070, top_1: 0.584961, top_k: 0.805664, samples/s: 1750.039 1612898147.7714276
train: epoch 81, iter 1200, loss: 2.710295, top_1: 0.590039, top_k: 0.811055, samples/s: 1745.711 1612898162.4358833
train: epoch 81, iter 1300, loss: 2.746258, top_1: 0.588750, top_k: 0.807852, samples/s: 1737.653 1612898177.1683824
train: epoch 81, iter 1400, loss: 2.739974, top_1: 0.586797, top_k: 0.807070, samples/s: 1742.157 1612898191.8627741
train: epoch 81, iter 1500, loss: 2.855044, top_1: 0.588867, top_k: 0.806133, samples/s: 1756.209 1612898206.439627
train: epoch 81, iter 1600, loss: 2.807517, top_1: 0.586289, top_k: 0.807109, samples/s: 1748.159 1612898221.0836253
train: epoch 81, iter 1700, loss: 2.824289, top_1: 0.591367, top_k: 0.810898, samples/s: 1748.572 1612898235.7241414
train: epoch 81, iter 1800, loss: 2.822026, top_1: 0.583359, top_k: 0.804961, samples/s: 1741.052 1612898250.4279656
train: epoch 81, iter 1900, loss: 2.630717, top_1: 0.586133, top_k: 0.805078, samples/s: 1733.916 1612898265.1922576
train: epoch 81, iter 2000, loss: 2.708256, top_1: 0.586602, top_k: 0.806680, samples/s: 1752.452 1612898279.8003087
train: epoch 81, iter 2100, loss: 2.616237, top_1: 0.584297, top_k: 0.805547, samples/s: 1757.677 1612898294.3649364
train: epoch 81, iter 2200, loss: 2.859759, top_1: 0.580508, top_k: 0.807109, samples/s: 1751.270 1612898308.9828794
train: epoch 81, iter 2300, loss: 2.684114, top_1: 0.585391, top_k: 0.804531, samples/s: 1740.207 1612898323.6938527
train: epoch 81, iter 2400, loss: 2.772814, top_1: 0.583164, top_k: 0.805977, samples/s: 1742.347 1612898338.3866649
train: epoch 81, iter 2500, loss: 2.787494, top_1: 0.580039, top_k: 0.804922, samples/s: 1739.678 1612898353.1019833
train: epoch 81, iter 2600, loss: 2.610995, top_1: 0.588281, top_k: 0.806641, samples/s: 1748.612 1612898367.7421937
train: epoch 81, iter 2700, loss: 2.575261, top_1: 0.590820, top_k: 0.804688, samples/s: 1733.862 1612898382.506965
train: epoch 81, iter 2800, loss: 2.473601, top_1: 0.593398, top_k: 0.809102, samples/s: 1758.439 1612898397.0652714
train: epoch 81, iter 2900, loss: 2.889224, top_1: 0.586328, top_k: 0.808281, samples/s: 1745.750 1612898411.7295053
train: epoch 81, iter 3000, loss: 2.726775, top_1: 0.586055, top_k: 0.804570, samples/s: 1737.973 1612898426.4592085
train: epoch 81, iter 3100, loss: 2.824407, top_1: 0.584883, top_k: 0.800820, samples/s: 1744.075 1612898441.1375146
train: epoch 81, iter 3200, loss: 2.695067, top_1: 0.587852, top_k: 0.806367, samples/s: 1749.802 1612898455.767744
train: epoch 81, iter 3300, loss: 2.884462, top_1: 0.579688, top_k: 0.804844, samples/s: 1747.008 1612898470.421424
train: epoch 81, iter 3400, loss: 2.658583, top_1: 0.585703, top_k: 0.804922, samples/s: 1742.696 1612898485.1113997
train: epoch 81, iter 3500, loss: 2.809552, top_1: 0.584023, top_k: 0.804766, samples/s: 1731.570 1612898499.8955657
train: epoch 81, iter 3600, loss: 2.807931, top_1: 0.581680, top_k: 0.805898, samples/s: 1739.321 1612898514.614005
train: epoch 81, iter 3700, loss: 2.585338, top_1: 0.588711, top_k: 0.808398, samples/s: 1763.363 1612898529.1316693
train: epoch 81, iter 3800, loss: 2.835726, top_1: 0.581914, top_k: 0.802227, samples/s: 1735.424 1612898543.8830824
train: epoch 81, iter 3900, loss: 2.827716, top_1: 0.584414, top_k: 0.803438, samples/s: 1758.353 1612898558.4421475
train: epoch 81, iter 4000, loss: 2.968784, top_1: 0.583672, top_k: 0.805156, samples/s: 1742.946 1612898573.129883
train: epoch 81, iter 4100, loss: 2.643345, top_1: 0.586953, top_k: 0.803555, samples/s: 1745.450 1612898587.79663
train: epoch 81, iter 4200, loss: 2.705496, top_1: 0.581406, top_k: 0.803203, samples/s: 1744.942 1612898602.4676425
train: epoch 81, iter 4300, loss: 2.703563, top_1: 0.590938, top_k: 0.808477, samples/s: 1742.001 1612898617.163416
train: epoch 81, iter 4400, loss: 2.638626, top_1: 0.585039, top_k: 0.805703, samples/s: 1746.088 1612898631.824723
train: epoch 81, iter 4500, loss: 2.763993, top_1: 0.580547, top_k: 0.799687, samples/s: 1744.379 1612898646.5003726
train: epoch 81, iter 4600, loss: 2.618901, top_1: 0.586602, top_k: 0.803672, samples/s: 1748.278 1612898661.1434216
train: epoch 81, iter 4700, loss: 2.882657, top_1: 0.583164, top_k: 0.804766, samples/s: 1738.009 1612898675.87286
train: epoch 81, iter 4800, loss: 2.935577, top_1: 0.578555, top_k: 0.804414, samples/s: 1740.511 1612898690.5811903
train: epoch 81, iter 4900, loss: 2.854498, top_1: 0.582656, top_k: 0.801133, samples/s: 1739.476 1612898705.2982657
train: epoch 81, iter 5000, loss: 2.662025, top_1: 0.589375, top_k: 0.809258, samples/s: 1747.498 1612898719.9477959
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_81.
validation: epoch 81, iter 195, top_1: 0.620413, top_k: 0.846815, samples/s: 2880.298 1612898737.7037015
train: epoch 82, iter 100, loss: 2.768584, top_1: 0.590195, top_k: 0.811484, samples/s: 1754.663 1612898772.5791736
train: epoch 82, iter 200, loss: 2.796252, top_1: 0.592344, top_k: 0.813320, samples/s: 1751.579 1612898787.1945014
train: epoch 82, iter 300, loss: 2.641708, top_1: 0.590742, top_k: 0.810586, samples/s: 1761.359 1612898801.7287483
train: epoch 82, iter 400, loss: 2.736389, top_1: 0.595430, top_k: 0.815195, samples/s: 1758.331 1612898816.288147
train: epoch 82, iter 500, loss: 2.659736, top_1: 0.595781, top_k: 0.809375, samples/s: 1758.914 1612898830.842418
train: epoch 82, iter 600, loss: 2.841659, top_1: 0.585156, top_k: 0.808438, samples/s: 1751.668 1612898845.4571588
train: epoch 82, iter 700, loss: 2.797209, top_1: 0.591172, top_k: 0.805586, samples/s: 1752.416 1612898860.0654407
train: epoch 82, iter 800, loss: 2.854008, top_1: 0.590391, top_k: 0.809844, samples/s: 1753.738 1612898874.6628509
train: epoch 82, iter 900, loss: 2.839248, top_1: 0.596680, top_k: 0.814414, samples/s: 1753.300 1612898889.263849
train: epoch 82, iter 1000, loss: 2.590578, top_1: 0.583594, top_k: 0.805117, samples/s: 1733.974 1612898904.0277274
train: epoch 82, iter 1100, loss: 2.607888, top_1: 0.585625, top_k: 0.806094, samples/s: 1748.851 1612898918.6658072
train: epoch 82, iter 1200, loss: 2.577859, top_1: 0.587578, top_k: 0.808047, samples/s: 1742.018 1612898933.3614242
train: epoch 82, iter 1300, loss: 2.588257, top_1: 0.591797, top_k: 0.808477, samples/s: 1756.132 1612898947.939289
train: epoch 82, iter 1400, loss: 2.645757, top_1: 0.593398, top_k: 0.809570, samples/s: 1746.105 1612898962.600194
train: epoch 82, iter 1500, loss: 2.860193, top_1: 0.590391, top_k: 0.807578, samples/s: 1734.385 1612898977.3603878
train: epoch 82, iter 1600, loss: 2.662868, top_1: 0.585586, top_k: 0.806836, samples/s: 1739.023 1612898992.0812945
train: epoch 82, iter 1700, loss: 2.588709, top_1: 0.585117, top_k: 0.806133, samples/s: 1746.386 1612899006.740157
train: epoch 82, iter 1800, loss: 2.756110, top_1: 0.582266, top_k: 0.806484, samples/s: 1729.083 1612899021.5456622
train: epoch 82, iter 1900, loss: 2.956592, top_1: 0.583945, top_k: 0.807773, samples/s: 1740.249 1612899036.2562253
train: epoch 82, iter 2000, loss: 2.740072, top_1: 0.586992, top_k: 0.804570, samples/s: 1740.043 1612899050.9685247
train: epoch 82, iter 2100, loss: 2.632366, top_1: 0.589883, top_k: 0.811172, samples/s: 1747.300 1612899065.6197062
train: epoch 82, iter 2200, loss: 2.687847, top_1: 0.586641, top_k: 0.806680, samples/s: 1740.010 1612899080.3327196
train: epoch 82, iter 2300, loss: 2.751789, top_1: 0.594766, top_k: 0.811523, samples/s: 1737.399 1612899095.066942
train: epoch 82, iter 2400, loss: 2.599102, top_1: 0.587422, top_k: 0.805625, samples/s: 1740.072 1612899109.7793021
train: epoch 82, iter 2500, loss: 2.658102, top_1: 0.588750, top_k: 0.805781, samples/s: 1730.263 1612899124.5743673
train: epoch 82, iter 2600, loss: 2.659928, top_1: 0.581797, top_k: 0.804688, samples/s: 1745.646 1612899139.2395015
train: epoch 82, iter 2700, loss: 2.758013, top_1: 0.591094, top_k: 0.806172, samples/s: 1741.105 1612899153.943202
train: epoch 82, iter 2800, loss: 2.682678, top_1: 0.591719, top_k: 0.808555, samples/s: 1745.135 1612899168.6121366
train: epoch 82, iter 2900, loss: 2.823978, top_1: 0.584336, top_k: 0.808594, samples/s: 1736.125 1612899183.3575895
train: epoch 82, iter 3000, loss: 2.674938, top_1: 0.585039, top_k: 0.807578, samples/s: 1736.490 1612899198.0999858
train: epoch 82, iter 3100, loss: 2.481677, top_1: 0.587187, top_k: 0.805273, samples/s: 1753.647 1612899212.6981506
train: epoch 82, iter 3200, loss: 2.748024, top_1: 0.592461, top_k: 0.810352, samples/s: 1731.883 1612899227.4798539
train: epoch 82, iter 3300, loss: 2.685889, top_1: 0.588398, top_k: 0.809375, samples/s: 1748.744 1612899242.1188116
train: epoch 82, iter 3400, loss: 2.775398, top_1: 0.587305, top_k: 0.806523, samples/s: 1746.105 1612899256.7799685
train: epoch 82, iter 3500, loss: 2.682252, top_1: 0.586211, top_k: 0.806953, samples/s: 1738.504 1612899271.5053356
train: epoch 82, iter 3600, loss: 2.833885, top_1: 0.586641, top_k: 0.808555, samples/s: 1747.708 1612899286.1530318
train: epoch 82, iter 3700, loss: 2.911366, top_1: 0.583086, top_k: 0.803242, samples/s: 1742.745 1612899300.842598
train: epoch 82, iter 3800, loss: 2.867399, top_1: 0.589297, top_k: 0.807383, samples/s: 1740.498 1612899315.5509684
train: epoch 82, iter 3900, loss: 2.750218, top_1: 0.587227, top_k: 0.804141, samples/s: 1755.988 1612899330.1296573
train: epoch 82, iter 4000, loss: 2.595668, top_1: 0.592070, top_k: 0.809297, samples/s: 1740.737 1612899344.836048
train: epoch 82, iter 4100, loss: 2.492456, top_1: 0.583242, top_k: 0.800352, samples/s: 1749.011 1612899359.4729357
train: epoch 82, iter 4200, loss: 2.898801, top_1: 0.592773, top_k: 0.811680, samples/s: 1750.046 1612899374.1011186
train: epoch 82, iter 4300, loss: 2.709630, top_1: 0.584805, top_k: 0.806250, samples/s: 1748.123 1612899388.745334
train: epoch 82, iter 4400, loss: 2.726364, top_1: 0.583359, top_k: 0.802383, samples/s: 1730.543 1612899403.5383928
train: epoch 82, iter 4500, loss: 2.682956, top_1: 0.585938, top_k: 0.803750, samples/s: 1741.972 1612899418.2344413
train: epoch 82, iter 4600, loss: 2.634182, top_1: 0.586602, top_k: 0.804844, samples/s: 1736.962 1612899432.9728584
train: epoch 82, iter 4700, loss: 2.728653, top_1: 0.581445, top_k: 0.800508, samples/s: 1739.725 1612899447.6877694
train: epoch 82, iter 4800, loss: 2.682810, top_1: 0.579063, top_k: 0.803125, samples/s: 1736.758 1612899462.4278722
train: epoch 82, iter 4900, loss: 2.792920, top_1: 0.586328, top_k: 0.804531, samples/s: 1747.934 1612899477.0737684
train: epoch 82, iter 5000, loss: 2.784806, top_1: 0.587617, top_k: 0.807344, samples/s: 1740.390 1612899491.7830763
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_82.
validation: epoch 82, iter 195, top_1: 0.631410, top_k: 0.854467, samples/s: 2894.277 1612899509.5352917
train: epoch 83, iter 100, loss: 2.576466, top_1: 0.596055, top_k: 0.815703, samples/s: 1748.768 1612899544.0094924
train: epoch 83, iter 200, loss: 2.612204, top_1: 0.591641, top_k: 0.810937, samples/s: 1750.770 1612899558.6316373
train: epoch 83, iter 300, loss: 2.764709, top_1: 0.593945, top_k: 0.812539, samples/s: 1762.372 1612899573.157668
train: epoch 83, iter 400, loss: 2.753182, top_1: 0.594258, top_k: 0.810937, samples/s: 1752.704 1612899587.7634594
train: epoch 83, iter 500, loss: 2.915466, top_1: 0.573164, top_k: 0.796914, samples/s: 1755.049 1612899602.3499413
train: epoch 83, iter 600, loss: 2.751961, top_1: 0.581133, top_k: 0.804492, samples/s: 1763.711 1612899616.8648934
train: epoch 83, iter 700, loss: 2.513916, top_1: 0.591211, top_k: 0.813828, samples/s: 1743.141 1612899631.5509386
train: epoch 83, iter 800, loss: 2.765849, top_1: 0.590820, top_k: 0.811328, samples/s: 1750.465 1612899646.1757028
train: epoch 83, iter 900, loss: 2.714346, top_1: 0.587500, top_k: 0.803398, samples/s: 1763.154 1612899660.6950955
train: epoch 83, iter 1000, loss: 2.680820, top_1: 0.589023, top_k: 0.808789, samples/s: 1733.113 1612899675.4661567
train: epoch 83, iter 1100, loss: 2.831330, top_1: 0.591719, top_k: 0.812617, samples/s: 1743.015 1612899690.1533768
train: epoch 83, iter 1200, loss: 2.984405, top_1: 0.586445, top_k: 0.804922, samples/s: 1744.182 1612899704.8307114
train: epoch 83, iter 1300, loss: 2.797131, top_1: 0.587734, top_k: 0.806758, samples/s: 1751.872 1612899719.443624
train: epoch 83, iter 1400, loss: 2.739990, top_1: 0.580273, top_k: 0.804258, samples/s: 1745.452 1612899734.1103828
train: epoch 83, iter 1500, loss: 2.818305, top_1: 0.586445, top_k: 0.810586, samples/s: 1745.096 1612899748.780035
train: epoch 83, iter 1600, loss: 2.662610, top_1: 0.590547, top_k: 0.809727, samples/s: 1744.285 1612899763.456495
train: epoch 83, iter 1700, loss: 2.574282, top_1: 0.589883, top_k: 0.806680, samples/s: 1735.976 1612899778.2032435
train: epoch 83, iter 1800, loss: 2.741080, top_1: 0.590859, top_k: 0.807305, samples/s: 1744.816 1612899792.875305
train: epoch 83, iter 1900, loss: 2.717215, top_1: 0.585703, top_k: 0.807461, samples/s: 1734.727 1612899807.6326942
train: epoch 83, iter 2000, loss: 2.766572, top_1: 0.589727, top_k: 0.808633, samples/s: 1735.567 1612899822.3829172
train: epoch 83, iter 2100, loss: 2.783398, top_1: 0.592891, top_k: 0.812773, samples/s: 1732.632 1612899837.1581037
train: epoch 83, iter 2200, loss: 2.788784, top_1: 0.582539, top_k: 0.802539, samples/s: 1754.666 1612899851.7477484
train: epoch 83, iter 2300, loss: 2.701480, top_1: 0.587187, top_k: 0.811562, samples/s: 1753.593 1612899866.346342
train: epoch 83, iter 2400, loss: 2.616711, top_1: 0.588320, top_k: 0.807891, samples/s: 1744.392 1612899881.02196
train: epoch 83, iter 2500, loss: 2.551433, top_1: 0.594219, top_k: 0.811680, samples/s: 1736.061 1612899895.7679682
train: epoch 83, iter 2600, loss: 2.723711, top_1: 0.588984, top_k: 0.807539, samples/s: 1749.462 1612899910.4010909
train: epoch 83, iter 2700, loss: 2.700022, top_1: 0.595273, top_k: 0.810508, samples/s: 1744.062 1612899925.0794797
train: epoch 83, iter 2800, loss: 2.730885, top_1: 0.589258, top_k: 0.807734, samples/s: 1741.141 1612899939.7824965
train: epoch 83, iter 2900, loss: 2.731083, top_1: 0.584883, top_k: 0.807383, samples/s: 1732.459 1612899954.559115
train: epoch 83, iter 3000, loss: 2.811575, top_1: 0.586367, top_k: 0.805039, samples/s: 1740.625 1612899969.266472
train: epoch 83, iter 3100, loss: 2.738708, top_1: 0.581875, top_k: 0.809023, samples/s: 1741.728 1612899983.964541
train: epoch 83, iter 3200, loss: 2.661367, top_1: 0.585117, top_k: 0.802500, samples/s: 1740.307 1612899998.6746209
train: epoch 83, iter 3300, loss: 2.628295, top_1: 0.592461, top_k: 0.810742, samples/s: 1746.584 1612900013.331812
train: epoch 83, iter 3400, loss: 2.804821, top_1: 0.588828, top_k: 0.807344, samples/s: 1738.473 1612900028.0574358
train: epoch 83, iter 3500, loss: 2.688037, top_1: 0.591172, top_k: 0.806289, samples/s: 1744.208 1612900042.7345476
train: epoch 83, iter 3600, loss: 2.995811, top_1: 0.583516, top_k: 0.802266, samples/s: 1754.571 1612900057.3249416
train: epoch 83, iter 3700, loss: 2.660041, top_1: 0.585156, top_k: 0.805312, samples/s: 1741.390 1612900072.0258646
train: epoch 83, iter 3800, loss: 2.574244, top_1: 0.584570, top_k: 0.805508, samples/s: 1746.197 1612900086.6863284
train: epoch 83, iter 3900, loss: 2.563872, top_1: 0.583320, top_k: 0.801172, samples/s: 1735.516 1612900101.4369485
train: epoch 83, iter 4000, loss: 2.634341, top_1: 0.590000, top_k: 0.808320, samples/s: 1749.233 1612900116.071921
train: epoch 83, iter 4100, loss: 2.708365, top_1: 0.583398, top_k: 0.806953, samples/s: 1738.412 1612900130.7980304
train: epoch 83, iter 4200, loss: 2.821120, top_1: 0.589961, top_k: 0.807539, samples/s: 1739.235 1612900145.5171018
train: epoch 83, iter 4300, loss: 2.611231, top_1: 0.591016, top_k: 0.809219, samples/s: 1739.234 1612900160.236338
train: epoch 83, iter 4400, loss: 2.822361, top_1: 0.587695, top_k: 0.807070, samples/s: 1750.574 1612900174.8600261
train: epoch 83, iter 4500, loss: 2.593395, top_1: 0.586094, top_k: 0.810586, samples/s: 1748.277 1612900189.5030417
train: epoch 83, iter 4600, loss: 2.793387, top_1: 0.591875, top_k: 0.808477, samples/s: 1743.107 1612900204.1894019
train: epoch 83, iter 4700, loss: 2.521554, top_1: 0.588750, top_k: 0.811406, samples/s: 1737.184 1612900218.92599
train: epoch 83, iter 4800, loss: 2.911444, top_1: 0.586797, top_k: 0.800117, samples/s: 1753.951 1612900233.5215352
train: epoch 83, iter 4900, loss: 2.807207, top_1: 0.584102, top_k: 0.802891, samples/s: 1740.935 1612900248.2263165
train: epoch 83, iter 5000, loss: 2.730597, top_1: 0.591289, top_k: 0.810469, samples/s: 1743.979 1612900262.9054484
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_83.
validation: epoch 83, iter 195, top_1: 0.631871, top_k: 0.854046, samples/s: 2867.599 1612900280.7638533
train: epoch 84, iter 100, loss: 2.656022, top_1: 0.601562, top_k: 0.815430, samples/s: 1747.822 1612900320.2912776
train: epoch 84, iter 200, loss: 2.903437, top_1: 0.600430, top_k: 0.814570, samples/s: 1761.247 1612900334.826322
train: epoch 84, iter 300, loss: 2.749861, top_1: 0.596680, top_k: 0.812930, samples/s: 1754.777 1612900349.415085
train: epoch 84, iter 400, loss: 2.822426, top_1: 0.597344, top_k: 0.813906, samples/s: 1760.087 1612900363.959793
train: epoch 84, iter 500, loss: 2.593370, top_1: 0.595508, top_k: 0.810391, samples/s: 1763.592 1612900378.4758463
train: epoch 84, iter 600, loss: 2.554123, top_1: 0.601172, top_k: 0.813164, samples/s: 1751.105 1612900393.095022
train: epoch 84, iter 700, loss: 2.738673, top_1: 0.596836, top_k: 0.814883, samples/s: 1758.104 1612900407.6561587
train: epoch 84, iter 800, loss: 2.542704, top_1: 0.595508, top_k: 0.812109, samples/s: 1749.058 1612900422.2926285
train: epoch 84, iter 900, loss: 2.595484, top_1: 0.589375, top_k: 0.809961, samples/s: 1759.415 1612900436.84285
train: epoch 84, iter 1000, loss: 2.789519, top_1: 0.588711, top_k: 0.809180, samples/s: 1734.117 1612900451.6055064
train: epoch 84, iter 1100, loss: 2.769495, top_1: 0.602383, top_k: 0.818828, samples/s: 1749.423 1612900466.238815
train: epoch 84, iter 1200, loss: 2.552324, top_1: 0.596211, top_k: 0.812734, samples/s: 1728.075 1612900481.053031
train: epoch 84, iter 1300, loss: 2.732798, top_1: 0.592500, top_k: 0.811367, samples/s: 1753.984 1612900495.6484127
train: epoch 84, iter 1400, loss: 2.716217, top_1: 0.592266, top_k: 0.813320, samples/s: 1736.449 1612900510.391042
train: epoch 84, iter 1500, loss: 2.727587, top_1: 0.602344, top_k: 0.816758, samples/s: 1751.604 1612900525.0063622
train: epoch 84, iter 1600, loss: 2.691882, top_1: 0.590664, top_k: 0.810703, samples/s: 1740.484 1612900539.714815
train: epoch 84, iter 1700, loss: 2.712003, top_1: 0.590117, top_k: 0.806484, samples/s: 1734.070 1612900554.4777179
train: epoch 84, iter 1800, loss: 2.606175, top_1: 0.591484, top_k: 0.810234, samples/s: 1753.467 1612900569.077413
train: epoch 84, iter 1900, loss: 2.587987, top_1: 0.590430, top_k: 0.808750, samples/s: 1735.745 1612900583.826129
train: epoch 84, iter 2000, loss: 2.843812, top_1: 0.598203, top_k: 0.814102, samples/s: 1755.012 1612900598.4128752
train: epoch 84, iter 2100, loss: 2.627697, top_1: 0.590313, top_k: 0.812617, samples/s: 1743.583 1612900613.0953577
train: epoch 84, iter 2200, loss: 2.618795, top_1: 0.585156, top_k: 0.806953, samples/s: 1742.402 1612900627.78765
train: epoch 84, iter 2300, loss: 2.595506, top_1: 0.597344, top_k: 0.813164, samples/s: 1745.912 1612900642.4504638
train: epoch 84, iter 2400, loss: 2.773947, top_1: 0.591602, top_k: 0.808516, samples/s: 1730.347 1612900657.245241
train: epoch 84, iter 2500, loss: 2.745282, top_1: 0.595742, top_k: 0.811367, samples/s: 1749.477 1612900671.8781214
train: epoch 84, iter 2600, loss: 2.714127, top_1: 0.589258, top_k: 0.807539, samples/s: 1745.608 1612900686.5435379
train: epoch 84, iter 2700, loss: 2.646644, top_1: 0.583867, top_k: 0.802891, samples/s: 1745.589 1612900701.209154
train: epoch 84, iter 2800, loss: 2.788709, top_1: 0.589531, top_k: 0.811680, samples/s: 1737.033 1612900715.9468274
train: epoch 84, iter 2900, loss: 2.844700, top_1: 0.585742, top_k: 0.809531, samples/s: 1752.531 1612900730.554335
train: epoch 84, iter 3000, loss: 2.799678, top_1: 0.587383, top_k: 0.807734, samples/s: 1739.472 1612900745.2713692
train: epoch 84, iter 3100, loss: 2.758703, top_1: 0.583711, top_k: 0.807773, samples/s: 1743.020 1612900759.958522
train: epoch 84, iter 3200, loss: 2.481549, top_1: 0.582227, top_k: 0.805586, samples/s: 1743.949 1612900774.6379251
train: epoch 84, iter 3300, loss: 2.726735, top_1: 0.583789, top_k: 0.805195, samples/s: 1747.256 1612900789.289408
train: epoch 84, iter 3400, loss: 2.650426, top_1: 0.585898, top_k: 0.808750, samples/s: 1744.434 1612900803.9646595
train: epoch 84, iter 3500, loss: 2.530333, top_1: 0.587617, top_k: 0.805703, samples/s: 1733.073 1612900818.7362015
train: epoch 84, iter 3600, loss: 2.770968, top_1: 0.592187, top_k: 0.806758, samples/s: 1737.959 1612900833.466093
train: epoch 84, iter 3700, loss: 2.567390, top_1: 0.588242, top_k: 0.808320, samples/s: 1742.915 1612900848.154078
train: epoch 84, iter 3800, loss: 2.632830, top_1: 0.585273, top_k: 0.807539, samples/s: 1736.793 1612900862.8938727
train: epoch 84, iter 3900, loss: 2.697185, top_1: 0.587109, top_k: 0.805898, samples/s: 1754.744 1612900877.4828892
train: epoch 84, iter 4000, loss: 2.769395, top_1: 0.593984, top_k: 0.810820, samples/s: 1743.479 1612900892.1662304
train: epoch 84, iter 4100, loss: 2.519416, top_1: 0.589258, top_k: 0.809336, samples/s: 1747.965 1612900906.811779
train: epoch 84, iter 4200, loss: 2.826025, top_1: 0.591680, top_k: 0.809492, samples/s: 1734.783 1612900921.5687177
train: epoch 84, iter 4300, loss: 2.969561, top_1: 0.586992, top_k: 0.809961, samples/s: 1725.144 1612900936.408003
train: epoch 84, iter 4400, loss: 2.865136, top_1: 0.590117, top_k: 0.810352, samples/s: 1741.676 1612900951.1065102
train: epoch 84, iter 4500, loss: 2.754722, top_1: 0.586953, top_k: 0.808945, samples/s: 1747.489 1612900965.756139
train: epoch 84, iter 4600, loss: 2.859216, top_1: 0.587930, top_k: 0.807930, samples/s: 1739.955 1612900980.4691086
train: epoch 84, iter 4700, loss: 2.621393, top_1: 0.589336, top_k: 0.805430, samples/s: 1733.834 1612900995.2343752
train: epoch 84, iter 4800, loss: 2.546399, top_1: 0.590859, top_k: 0.808008, samples/s: 1749.004 1612901009.8710158
train: epoch 84, iter 4900, loss: 2.661434, top_1: 0.586719, top_k: 0.808008, samples/s: 1739.469 1612901024.5882096
train: epoch 84, iter 5000, loss: 2.631418, top_1: 0.596914, top_k: 0.812031, samples/s: 1739.853 1612901039.3025305
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_84.
validation: epoch 84, iter 195, top_1: 0.636338, top_k: 0.858594, samples/s: 2876.145 1612901057.0376887
train: epoch 85, iter 100, loss: 2.548525, top_1: 0.600742, top_k: 0.818242, samples/s: 1729.144 1612901091.946967
train: epoch 85, iter 200, loss: 2.629362, top_1: 0.600273, top_k: 0.814453, samples/s: 1780.365 1612901106.3262472
train: epoch 85, iter 300, loss: 2.724190, top_1: 0.598125, top_k: 0.814961, samples/s: 1757.261 1612901120.8941545
train: epoch 85, iter 400, loss: 2.789990, top_1: 0.599219, top_k: 0.812813, samples/s: 1761.930 1612901135.4237428
train: epoch 85, iter 500, loss: 2.602296, top_1: 0.593906, top_k: 0.812227, samples/s: 1752.155 1612901150.0343206
train: epoch 85, iter 600, loss: 2.596008, top_1: 0.594453, top_k: 0.809727, samples/s: 1761.387 1612901164.5682852
train: epoch 85, iter 700, loss: 2.641526, top_1: 0.595430, top_k: 0.815195, samples/s: 1754.013 1612901179.16344
train: epoch 85, iter 800, loss: 2.719709, top_1: 0.595820, top_k: 0.810937, samples/s: 1746.107 1612901193.8245637
train: epoch 85, iter 900, loss: 2.653135, top_1: 0.595195, top_k: 0.810703, samples/s: 1752.440 1612901208.4327865
train: epoch 85, iter 1000, loss: 2.596085, top_1: 0.602930, top_k: 0.816406, samples/s: 1737.095 1612901223.170046
train: epoch 85, iter 1100, loss: 2.654089, top_1: 0.599141, top_k: 0.814492, samples/s: 1740.161 1612901237.8813512
train: epoch 85, iter 1200, loss: 2.729318, top_1: 0.595039, top_k: 0.810352, samples/s: 1738.779 1612901252.6043766
train: epoch 85, iter 1300, loss: 2.596256, top_1: 0.593984, top_k: 0.814766, samples/s: 1742.485 1612901267.295949
train: epoch 85, iter 1400, loss: 2.617877, top_1: 0.595430, top_k: 0.814805, samples/s: 1751.930 1612901281.908431
train: epoch 85, iter 1500, loss: 2.693364, top_1: 0.591797, top_k: 0.810234, samples/s: 1754.118 1612901296.5025904
train: epoch 85, iter 1600, loss: 2.611063, top_1: 0.596992, top_k: 0.812969, samples/s: 1736.683 1612901311.2433438
train: epoch 85, iter 1700, loss: 2.490315, top_1: 0.593555, top_k: 0.813906, samples/s: 1744.885 1612901325.9148598
train: epoch 85, iter 1800, loss: 2.904715, top_1: 0.590586, top_k: 0.808828, samples/s: 1743.499 1612901340.5979753
train: epoch 85, iter 1900, loss: 2.688462, top_1: 0.591172, top_k: 0.808203, samples/s: 1739.426 1612901355.3154047
train: epoch 85, iter 2000, loss: 2.853746, top_1: 0.586250, top_k: 0.809844, samples/s: 1739.757 1612901370.0301337
train: epoch 85, iter 2100, loss: 2.641188, top_1: 0.594844, top_k: 0.809297, samples/s: 1752.853 1612901384.634867
train: epoch 85, iter 2200, loss: 2.780283, top_1: 0.592266, top_k: 0.809766, samples/s: 1740.195 1612901399.3459275
train: epoch 85, iter 2300, loss: 2.727330, top_1: 0.593398, top_k: 0.813008, samples/s: 1742.955 1612901414.0335937
train: epoch 85, iter 2400, loss: 2.671883, top_1: 0.587695, top_k: 0.807148, samples/s: 1737.800 1612901428.7648833
train: epoch 85, iter 2500, loss: 2.779945, top_1: 0.593320, top_k: 0.807266, samples/s: 1743.070 1612901443.4516225
train: epoch 85, iter 2600, loss: 2.493753, top_1: 0.587656, top_k: 0.809492, samples/s: 1750.378 1612901458.0769784
train: epoch 85, iter 2700, loss: 2.598135, top_1: 0.590664, top_k: 0.812852, samples/s: 1738.297 1612901472.804044
train: epoch 85, iter 2800, loss: 2.619907, top_1: 0.593477, top_k: 0.810625, samples/s: 1738.092 1612901487.5331213
train: epoch 85, iter 2900, loss: 2.778444, top_1: 0.593125, top_k: 0.809688, samples/s: 1745.896 1612901502.19585
train: epoch 85, iter 3000, loss: 2.779319, top_1: 0.594102, top_k: 0.813555, samples/s: 1735.670 1612901516.9452136
train: epoch 85, iter 3100, loss: 2.632635, top_1: 0.591875, top_k: 0.811602, samples/s: 1749.708 1612901531.5761533
train: epoch 85, iter 3200, loss: 2.556523, top_1: 0.590195, top_k: 0.811211, samples/s: 1736.695 1612901546.3172648
train: epoch 85, iter 3300, loss: 2.638500, top_1: 0.589219, top_k: 0.809102, samples/s: 1739.639 1612901561.0325656
train: epoch 85, iter 3400, loss: 2.806614, top_1: 0.592461, top_k: 0.807852, samples/s: 1751.614 1612901575.6476605
train: epoch 85, iter 3500, loss: 2.654923, top_1: 0.587852, top_k: 0.809375, samples/s: 1742.877 1612901590.3359966
train: epoch 85, iter 3600, loss: 2.679409, top_1: 0.588125, top_k: 0.808008, samples/s: 1741.134 1612901605.0390608
train: epoch 85, iter 3700, loss: 2.599298, top_1: 0.583438, top_k: 0.807969, samples/s: 1745.251 1612901619.707508
train: epoch 85, iter 3800, loss: 2.808175, top_1: 0.594219, top_k: 0.812813, samples/s: 1749.089 1612901634.3435805
train: epoch 85, iter 3900, loss: 2.874569, top_1: 0.594414, top_k: 0.813555, samples/s: 1737.090 1612901649.080934
train: epoch 85, iter 4000, loss: 2.550229, top_1: 0.592422, top_k: 0.809570, samples/s: 1748.434 1612901663.7229853
train: epoch 85, iter 4100, loss: 2.531080, top_1: 0.589102, top_k: 0.809453, samples/s: 1721.221 1612901678.5957947
train: epoch 85, iter 4200, loss: 2.634369, top_1: 0.592969, top_k: 0.808281, samples/s: 1759.085 1612901693.148774
train: epoch 85, iter 4300, loss: 2.786542, top_1: 0.588828, top_k: 0.808320, samples/s: 1745.976 1612901707.8110032
train: epoch 85, iter 4400, loss: 2.640453, top_1: 0.590391, top_k: 0.807930, samples/s: 1741.295 1612901722.5128279
train: epoch 85, iter 4500, loss: 2.693559, top_1: 0.589805, top_k: 0.802070, samples/s: 1750.071 1612901737.140686
train: epoch 85, iter 4600, loss: 2.720281, top_1: 0.585859, top_k: 0.806328, samples/s: 1744.225 1612901751.8177612
train: epoch 85, iter 4700, loss: 2.776611, top_1: 0.591133, top_k: 0.808867, samples/s: 1725.075 1612901766.6580787
train: epoch 85, iter 4800, loss: 2.629204, top_1: 0.587734, top_k: 0.805586, samples/s: 1756.474 1612901781.23229
train: epoch 85, iter 4900, loss: 2.648838, top_1: 0.593398, top_k: 0.810664, samples/s: 1726.247 1612901796.0621858
train: epoch 85, iter 5000, loss: 2.512862, top_1: 0.597422, top_k: 0.815937, samples/s: 1754.986 1612901810.6491928
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_85.
validation: epoch 85, iter 195, top_1: 0.637019, top_k: 0.855909, samples/s: 2832.476 1612901828.6875515
train: epoch 86, iter 100, loss: 2.570851, top_1: 0.597031, top_k: 0.814609, samples/s: 1754.568 1612901863.2931774
train: epoch 86, iter 200, loss: 2.520606, top_1: 0.598828, top_k: 0.819180, samples/s: 1760.788 1612901877.8320775
train: epoch 86, iter 300, loss: 2.593379, top_1: 0.603281, top_k: 0.822344, samples/s: 1758.939 1612901892.38627
train: epoch 86, iter 400, loss: 2.835340, top_1: 0.604805, top_k: 0.818789, samples/s: 1752.405 1612901906.9947896
train: epoch 86, iter 500, loss: 2.600720, top_1: 0.603672, top_k: 0.819922, samples/s: 1751.241 1612901921.613098
train: epoch 86, iter 600, loss: 2.618585, top_1: 0.597305, top_k: 0.815586, samples/s: 1753.887 1612901936.2093382
train: epoch 86, iter 700, loss: 2.707959, top_1: 0.594883, top_k: 0.815664, samples/s: 1740.486 1612901950.9181414
train: epoch 86, iter 800, loss: 2.506529, top_1: 0.595508, top_k: 0.814492, samples/s: 1757.809 1612901965.4812915
train: epoch 86, iter 900, loss: 2.605193, top_1: 0.601602, top_k: 0.815391, samples/s: 1754.021 1612901980.0762572
train: epoch 86, iter 1000, loss: 2.463691, top_1: 0.597734, top_k: 0.812266, samples/s: 1737.776 1612901994.807739
train: epoch 86, iter 1100, loss: 2.756585, top_1: 0.600859, top_k: 0.816562, samples/s: 1746.583 1612902009.4649777
train: epoch 86, iter 1200, loss: 2.645325, top_1: 0.600117, top_k: 0.818281, samples/s: 1736.310 1612902024.2088344
train: epoch 86, iter 1300, loss: 2.833301, top_1: 0.595742, top_k: 0.811328, samples/s: 1752.744 1612902038.814548
train: epoch 86, iter 1400, loss: 2.709455, top_1: 0.599297, top_k: 0.812773, samples/s: 1738.681 1612902053.5383608
train: epoch 86, iter 1500, loss: 2.485608, top_1: 0.596914, top_k: 0.815703, samples/s: 1741.381 1612902068.2394023
train: epoch 86, iter 1600, loss: 2.799966, top_1: 0.601289, top_k: 0.815508, samples/s: 1742.470 1612902082.9310734
train: epoch 86, iter 1700, loss: 2.627605, top_1: 0.593359, top_k: 0.812930, samples/s: 1733.410 1612902097.699656
train: epoch 86, iter 1800, loss: 2.688093, top_1: 0.592773, top_k: 0.810391, samples/s: 1741.751 1612902112.397535
train: epoch 86, iter 1900, loss: 2.582096, top_1: 0.602812, top_k: 0.817734, samples/s: 1749.237 1612902127.032495
train: epoch 86, iter 2000, loss: 2.791254, top_1: 0.589141, top_k: 0.805469, samples/s: 1738.240 1612902141.760021
train: epoch 86, iter 2100, loss: 2.591021, top_1: 0.604141, top_k: 0.813906, samples/s: 1742.316 1612902156.4530945
train: epoch 86, iter 2200, loss: 2.753550, top_1: 0.599883, top_k: 0.814336, samples/s: 1742.647 1612902171.143474
train: epoch 86, iter 2300, loss: 2.582252, top_1: 0.595625, top_k: 0.812656, samples/s: 1744.193 1612902185.8207033
train: epoch 86, iter 2400, loss: 2.818112, top_1: 0.596836, top_k: 0.812383, samples/s: 1741.467 1612902200.5209067
train: epoch 86, iter 2500, loss: 2.754153, top_1: 0.593555, top_k: 0.814180, samples/s: 1731.574 1612902215.3051953
train: epoch 86, iter 2600, loss: 2.723316, top_1: 0.594609, top_k: 0.812187, samples/s: 1745.438 1612902229.9720592
train: epoch 86, iter 2700, loss: 2.836335, top_1: 0.592695, top_k: 0.808281, samples/s: 1750.900 1612902244.5930831
train: epoch 86, iter 2800, loss: 2.763393, top_1: 0.595273, top_k: 0.811289, samples/s: 1735.953 1612902259.339978
train: epoch 86, iter 2900, loss: 2.755808, top_1: 0.597305, top_k: 0.812422, samples/s: 1724.787 1612902274.1823716
train: epoch 86, iter 3000, loss: 2.790818, top_1: 0.593437, top_k: 0.811289, samples/s: 1761.777 1612902288.7132404
train: epoch 86, iter 3100, loss: 2.695677, top_1: 0.593164, top_k: 0.809961, samples/s: 1733.214 1612902303.483482
train: epoch 86, iter 3200, loss: 2.744602, top_1: 0.590859, top_k: 0.810469, samples/s: 1749.039 1612902318.1200194
train: epoch 86, iter 3300, loss: 2.723640, top_1: 0.595781, top_k: 0.813711, samples/s: 1751.426 1612902332.7370367
train: epoch 86, iter 3400, loss: 2.889607, top_1: 0.591211, top_k: 0.810625, samples/s: 1743.407 1612902347.420592
train: epoch 86, iter 3500, loss: 2.686376, top_1: 0.596094, top_k: 0.814219, samples/s: 1747.205 1612902362.0729432
train: epoch 86, iter 3600, loss: 2.725850, top_1: 0.596836, top_k: 0.812773, samples/s: 1744.665 1612902376.745902
train: epoch 86, iter 3700, loss: 2.871151, top_1: 0.593398, top_k: 0.813438, samples/s: 1743.250 1612902391.43124
train: epoch 86, iter 3800, loss: 2.729987, top_1: 0.596328, top_k: 0.812187, samples/s: 1738.374 1612902406.1575098
train: epoch 86, iter 3900, loss: 2.540331, top_1: 0.597070, top_k: 0.815117, samples/s: 1746.009 1612902420.8195035
train: epoch 86, iter 4000, loss: 2.749719, top_1: 0.593437, top_k: 0.809609, samples/s: 1744.176 1612902435.4970233
train: epoch 86, iter 4100, loss: 2.694878, top_1: 0.586875, top_k: 0.805781, samples/s: 1751.084 1612902450.1164215
train: epoch 86, iter 4200, loss: 2.936778, top_1: 0.589609, top_k: 0.808828, samples/s: 1742.821 1612902464.805372
train: epoch 86, iter 4300, loss: 2.648108, top_1: 0.587461, top_k: 0.806250, samples/s: 1752.705 1612902479.4112394
train: epoch 86, iter 4400, loss: 2.874259, top_1: 0.595586, top_k: 0.811992, samples/s: 1747.973 1612902494.056828
train: epoch 86, iter 4500, loss: 2.789573, top_1: 0.594375, top_k: 0.806719, samples/s: 1742.396 1612902508.749258
train: epoch 86, iter 4600, loss: 2.824840, top_1: 0.593047, top_k: 0.812813, samples/s: 1738.081 1612902523.4780905
train: epoch 86, iter 4700, loss: 2.745537, top_1: 0.593750, top_k: 0.813789, samples/s: 1740.915 1612902538.1830072
train: epoch 86, iter 4800, loss: 2.803068, top_1: 0.590664, top_k: 0.806133, samples/s: 1746.550 1612902552.8404365
train: epoch 86, iter 4900, loss: 2.763590, top_1: 0.590625, top_k: 0.812148, samples/s: 1725.135 1612902567.679876
train: epoch 86, iter 5000, loss: 2.564959, top_1: 0.596406, top_k: 0.812305, samples/s: 1768.263 1612902582.1573327
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_86.
validation: epoch 86, iter 195, top_1: 0.635056, top_k: 0.857612, samples/s: 2840.782 1612902600.2162628
train: epoch 87, iter 100, loss: 2.525957, top_1: 0.607187, top_k: 0.822383, samples/s: 1748.565 1612902634.6989791
train: epoch 87, iter 200, loss: 2.605033, top_1: 0.604102, top_k: 0.819688, samples/s: 1756.318 1612902649.2748802
train: epoch 87, iter 300, loss: 2.688669, top_1: 0.602656, top_k: 0.815430, samples/s: 1752.293 1612902663.884307
train: epoch 87, iter 400, loss: 2.661825, top_1: 0.600664, top_k: 0.821484, samples/s: 1761.116 1612902678.4205303
train: epoch 87, iter 500, loss: 2.482395, top_1: 0.607812, top_k: 0.817617, samples/s: 1765.590 1612902692.9201136
train: epoch 87, iter 600, loss: 2.492277, top_1: 0.600898, top_k: 0.817656, samples/s: 1753.829 1612902707.5165617
train: epoch 87, iter 700, loss: 2.784175, top_1: 0.601523, top_k: 0.817617, samples/s: 1750.420 1612902722.1416793
train: epoch 87, iter 800, loss: 2.780657, top_1: 0.594688, top_k: 0.815391, samples/s: 1747.666 1612902736.7897258
train: epoch 87, iter 900, loss: 2.826733, top_1: 0.603164, top_k: 0.819258, samples/s: 1743.220 1612902751.4752488
train: epoch 87, iter 1000, loss: 2.699208, top_1: 0.592578, top_k: 0.811680, samples/s: 1742.865 1612902766.163704
train: epoch 87, iter 1100, loss: 2.485315, top_1: 0.594531, top_k: 0.814023, samples/s: 1747.549 1612902780.8127928
train: epoch 87, iter 1200, loss: 2.517355, top_1: 0.600898, top_k: 0.812187, samples/s: 1750.157 1612902795.4400382
train: epoch 87, iter 1300, loss: 2.869072, top_1: 0.600469, top_k: 0.816055, samples/s: 1734.729 1612902810.197439
train: epoch 87, iter 1400, loss: 2.852120, top_1: 0.599883, top_k: 0.815547, samples/s: 1747.794 1612902824.8444245
train: epoch 87, iter 1500, loss: 2.609412, top_1: 0.598672, top_k: 0.815430, samples/s: 1754.368 1612902839.4365997
train: epoch 87, iter 1600, loss: 2.726751, top_1: 0.604180, top_k: 0.820430, samples/s: 1737.067 1612902854.174077
train: epoch 87, iter 1700, loss: 2.905016, top_1: 0.598672, top_k: 0.811797, samples/s: 1735.286 1612902868.9266467
train: epoch 87, iter 1800, loss: 2.585423, top_1: 0.600547, top_k: 0.815703, samples/s: 1738.223 1612902883.6543884
train: epoch 87, iter 1900, loss: 2.618427, top_1: 0.599141, top_k: 0.814688, samples/s: 1737.611 1612902898.3871946
train: epoch 87, iter 2000, loss: 2.790718, top_1: 0.593867, top_k: 0.813438, samples/s: 1755.581 1612902912.9692926
train: epoch 87, iter 2100, loss: 2.594182, top_1: 0.595195, top_k: 0.812813, samples/s: 1731.082 1612902927.7577453
train: epoch 87, iter 2200, loss: 2.692210, top_1: 0.599961, top_k: 0.817187, samples/s: 1751.462 1612902942.3740647
train: epoch 87, iter 2300, loss: 2.584502, top_1: 0.587852, top_k: 0.806562, samples/s: 1749.783 1612902957.0045576
train: epoch 87, iter 2400, loss: 2.556751, top_1: 0.596992, top_k: 0.815391, samples/s: 1728.934 1612902971.8112764
train: epoch 87, iter 2500, loss: 2.498867, top_1: 0.593789, top_k: 0.814180, samples/s: 1738.982 1612902986.5325024
train: epoch 87, iter 2600, loss: 2.540366, top_1: 0.592891, top_k: 0.809141, samples/s: 1741.507 1612903001.2324684
train: epoch 87, iter 2700, loss: 2.533029, top_1: 0.597891, top_k: 0.817070, samples/s: 1743.436 1612903015.916071
train: epoch 87, iter 2800, loss: 2.812864, top_1: 0.596055, top_k: 0.813086, samples/s: 1745.463 1612903030.5827694
train: epoch 87, iter 2900, loss: 2.717617, top_1: 0.599570, top_k: 0.816992, samples/s: 1742.076 1612903045.2778566
train: epoch 87, iter 3000, loss: 2.691229, top_1: 0.601172, top_k: 0.817031, samples/s: 1743.491 1612903059.9609818
train: epoch 87, iter 3100, loss: 2.756939, top_1: 0.593867, top_k: 0.816797, samples/s: 1741.899 1612903074.657554
train: epoch 87, iter 3200, loss: 2.799005, top_1: 0.594141, top_k: 0.810039, samples/s: 1739.309 1612903089.3760421
train: epoch 87, iter 3300, loss: 2.640430, top_1: 0.593320, top_k: 0.809688, samples/s: 1744.990 1612903104.0466762
train: epoch 87, iter 3400, loss: 2.662053, top_1: 0.593867, top_k: 0.813359, samples/s: 1738.696 1612903118.7703028
train: epoch 87, iter 3500, loss: 2.677663, top_1: 0.588281, top_k: 0.807773, samples/s: 1754.542 1612903133.3610296
train: epoch 87, iter 3600, loss: 2.848038, top_1: 0.592695, top_k: 0.812461, samples/s: 1737.201 1612903148.097449
train: epoch 87, iter 3700, loss: 2.731274, top_1: 0.590469, top_k: 0.809648, samples/s: 1741.300 1612903162.799174
train: epoch 87, iter 3800, loss: 2.605695, top_1: 0.593945, top_k: 0.812109, samples/s: 1751.102 1612903177.4184513
train: epoch 87, iter 3900, loss: 2.709087, top_1: 0.593242, top_k: 0.810312, samples/s: 1741.047 1612903192.1221828
train: epoch 87, iter 4000, loss: 2.821630, top_1: 0.589883, top_k: 0.807852, samples/s: 1715.150 1612903207.0480962
train: epoch 87, iter 4100, loss: 2.532414, top_1: 0.597930, top_k: 0.810508, samples/s: 1757.455 1612903221.6146178
train: epoch 87, iter 4200, loss: 2.886399, top_1: 0.603867, top_k: 0.816484, samples/s: 1755.442 1612903236.197774
train: epoch 87, iter 4300, loss: 2.608682, top_1: 0.593789, top_k: 0.807891, samples/s: 1719.552 1612903251.085447
train: epoch 87, iter 4400, loss: 2.607157, top_1: 0.596094, top_k: 0.810508, samples/s: 1753.757 1612903265.6826725
train: epoch 87, iter 4500, loss: 2.772558, top_1: 0.594297, top_k: 0.815859, samples/s: 1752.229 1612903280.2925184
train: epoch 87, iter 4600, loss: 2.582963, top_1: 0.599023, top_k: 0.814883, samples/s: 1737.194 1612903295.0290384
train: epoch 87, iter 4700, loss: 2.687224, top_1: 0.597109, top_k: 0.812695, samples/s: 1735.499 1612903309.7797232
train: epoch 87, iter 4800, loss: 2.878177, top_1: 0.593867, top_k: 0.810078, samples/s: 1748.862 1612903324.4178658
train: epoch 87, iter 4900, loss: 2.602082, top_1: 0.594844, top_k: 0.811016, samples/s: 1747.249 1612903339.0694919
train: epoch 87, iter 5000, loss: 2.555850, top_1: 0.595898, top_k: 0.815742, samples/s: 1741.724 1612903353.7675774
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_87.
validation: epoch 87, iter 195, top_1: 0.642568, top_k: 0.864643, samples/s: 2923.740 1612903371.286387
train: epoch 88, iter 100, loss: 2.571765, top_1: 0.609180, top_k: 0.823945, samples/s: 1743.344 1612903406.1389678
train: epoch 88, iter 200, loss: 2.665404, top_1: 0.602461, top_k: 0.816602, samples/s: 1766.935 1612903420.6274338
train: epoch 88, iter 300, loss: 2.571233, top_1: 0.606563, top_k: 0.820469, samples/s: 1758.334 1612903435.1865516
train: epoch 88, iter 400, loss: 2.670826, top_1: 0.600313, top_k: 0.814258, samples/s: 1759.604 1612903449.7352893
train: epoch 88, iter 500, loss: 2.634874, top_1: 0.600391, top_k: 0.813828, samples/s: 1762.092 1612903464.263485
train: epoch 88, iter 600, loss: 2.798997, top_1: 0.601250, top_k: 0.815977, samples/s: 1751.614 1612903478.8785968
train: epoch 88, iter 700, loss: 2.489139, top_1: 0.606094, top_k: 0.824922, samples/s: 1755.749 1612903493.4592483
train: epoch 88, iter 800, loss: 2.554973, top_1: 0.600078, top_k: 0.815625, samples/s: 1750.320 1612903508.0850694
train: epoch 88, iter 900, loss: 2.600550, top_1: 0.601055, top_k: 0.816211, samples/s: 1742.666 1612903522.7752433
train: epoch 88, iter 1000, loss: 2.595655, top_1: 0.603477, top_k: 0.821094, samples/s: 1736.258 1612903537.5195992
train: epoch 88, iter 1100, loss: 2.896698, top_1: 0.598711, top_k: 0.815000, samples/s: 1744.835 1612903552.1914897
train: epoch 88, iter 1200, loss: 2.590007, top_1: 0.605430, top_k: 0.819023, samples/s: 1742.395 1612903566.8839335
train: epoch 88, iter 1300, loss: 2.678100, top_1: 0.600586, top_k: 0.816758, samples/s: 1749.266 1612903581.5186043
train: epoch 88, iter 1400, loss: 2.634631, top_1: 0.601719, top_k: 0.816094, samples/s: 1745.698 1612903596.1832528
train: epoch 88, iter 1500, loss: 2.767054, top_1: 0.596602, top_k: 0.815352, samples/s: 1740.933 1612903610.887996
train: epoch 88, iter 1600, loss: 2.708836, top_1: 0.606445, top_k: 0.818555, samples/s: 1743.592 1612903625.570293
train: epoch 88, iter 1700, loss: 2.653824, top_1: 0.605078, top_k: 0.819258, samples/s: 1746.411 1612903640.2289538
train: epoch 88, iter 1800, loss: 2.760449, top_1: 0.596562, top_k: 0.813516, samples/s: 1737.304 1612903654.964529
train: epoch 88, iter 1900, loss: 2.692109, top_1: 0.600859, top_k: 0.819922, samples/s: 1735.695 1612903669.7135227
train: epoch 88, iter 2000, loss: 2.694477, top_1: 0.604727, top_k: 0.818750, samples/s: 1744.671 1612903684.3870935
train: epoch 88, iter 2100, loss: 2.563061, top_1: 0.598828, top_k: 0.814961, samples/s: 1731.154 1612903699.1746628
train: epoch 88, iter 2200, loss: 2.592147, top_1: 0.593945, top_k: 0.814023, samples/s: 1744.808 1612903713.846745
train: epoch 88, iter 2300, loss: 2.621130, top_1: 0.596758, top_k: 0.813320, samples/s: 1745.795 1612903728.5105116
train: epoch 88, iter 2400, loss: 2.589594, top_1: 0.598242, top_k: 0.811328, samples/s: 1740.800 1612903743.2165613
train: epoch 88, iter 2500, loss: 2.781282, top_1: 0.603398, top_k: 0.817070, samples/s: 1745.975 1612903757.8787975
train: epoch 88, iter 2600, loss: 2.660735, top_1: 0.590859, top_k: 0.811641, samples/s: 1747.996 1612903772.5240352
train: epoch 88, iter 2700, loss: 2.545096, top_1: 0.596406, top_k: 0.811133, samples/s: 1745.628 1612903787.1893058
train: epoch 88, iter 2800, loss: 2.631880, top_1: 0.601992, top_k: 0.812539, samples/s: 1741.636 1612903801.8885272
train: epoch 88, iter 2900, loss: 2.829318, top_1: 0.595469, top_k: 0.810312, samples/s: 1740.907 1612903816.5931635
train: epoch 88, iter 3000, loss: 2.907195, top_1: 0.592578, top_k: 0.814063, samples/s: 1745.219 1612903831.2617214
train: epoch 88, iter 3100, loss: 2.810995, top_1: 0.597695, top_k: 0.818125, samples/s: 1749.248 1612903845.8965907
train: epoch 88, iter 3200, loss: 2.684065, top_1: 0.597656, top_k: 0.816211, samples/s: 1740.097 1612903860.6084194
train: epoch 88, iter 3300, loss: 2.694982, top_1: 0.593086, top_k: 0.811602, samples/s: 1744.348 1612903875.2844179
train: epoch 88, iter 3400, loss: 2.762733, top_1: 0.594531, top_k: 0.810898, samples/s: 1740.635 1612903889.991725
train: epoch 88, iter 3500, loss: 2.591770, top_1: 0.595664, top_k: 0.815117, samples/s: 1750.953 1612903904.6122782
train: epoch 88, iter 3600, loss: 2.566393, top_1: 0.592148, top_k: 0.810820, samples/s: 1746.052 1612903919.273922
train: epoch 88, iter 3700, loss: 2.722114, top_1: 0.597891, top_k: 0.816055, samples/s: 1737.357 1612903934.0089467
train: epoch 88, iter 3800, loss: 2.491415, top_1: 0.596875, top_k: 0.811719, samples/s: 1755.957 1612903948.5878372
train: epoch 88, iter 3900, loss: 2.671594, top_1: 0.591992, top_k: 0.812852, samples/s: 1728.903 1612903963.3949113
train: epoch 88, iter 4000, loss: 2.611060, top_1: 0.595820, top_k: 0.810664, samples/s: 1754.873 1612903977.9829605
train: epoch 88, iter 4100, loss: 2.816417, top_1: 0.598672, top_k: 0.814141, samples/s: 1743.857 1612903992.6630197
train: epoch 88, iter 4200, loss: 2.622421, top_1: 0.602539, top_k: 0.812578, samples/s: 1745.571 1612904007.3286498
train: epoch 88, iter 4300, loss: 2.625832, top_1: 0.601328, top_k: 0.818281, samples/s: 1738.318 1612904022.0556617
train: epoch 88, iter 4400, loss: 2.717125, top_1: 0.594727, top_k: 0.813398, samples/s: 1735.736 1612904036.8043625
train: epoch 88, iter 4500, loss: 2.650507, top_1: 0.594766, top_k: 0.811484, samples/s: 1732.393 1612904051.581656
train: epoch 88, iter 4600, loss: 2.600266, top_1: 0.596406, top_k: 0.813555, samples/s: 1749.560 1612904066.2138555
train: epoch 88, iter 4700, loss: 2.626307, top_1: 0.594414, top_k: 0.809063, samples/s: 1750.793 1612904080.8358212
train: epoch 88, iter 4800, loss: 2.626991, top_1: 0.592031, top_k: 0.812109, samples/s: 1748.374 1612904095.4779372
train: epoch 88, iter 4900, loss: 2.739938, top_1: 0.593672, top_k: 0.811992, samples/s: 1738.882 1612904110.200067
train: epoch 88, iter 5000, loss: 2.652495, top_1: 0.595430, top_k: 0.814805, samples/s: 1741.768 1612904124.8977685
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_88.
validation: epoch 88, iter 195, top_1: 0.644551, top_k: 0.861318, samples/s: 2800.805 1612904143.1558483
train: epoch 89, iter 100, loss: 2.713954, top_1: 0.608125, top_k: 0.823789, samples/s: 1753.601 1612904177.5294433
train: epoch 89, iter 200, loss: 2.813107, top_1: 0.602617, top_k: 0.819727, samples/s: 1750.828 1612904192.151068
train: epoch 89, iter 300, loss: 2.600322, top_1: 0.601875, top_k: 0.816914, samples/s: 1763.110 1612904206.671181
train: epoch 89, iter 400, loss: 2.796634, top_1: 0.603281, top_k: 0.821250, samples/s: 1760.524 1612904221.212075
train: epoch 89, iter 500, loss: 2.801118, top_1: 0.607031, top_k: 0.818047, samples/s: 1752.837 1612904235.8169804
train: epoch 89, iter 600, loss: 2.636689, top_1: 0.604297, top_k: 0.821367, samples/s: 1757.880 1612904250.3799427
train: epoch 89, iter 700, loss: 2.691323, top_1: 0.598594, top_k: 0.814297, samples/s: 1744.667 1612904265.0532432
train: epoch 89, iter 800, loss: 2.654660, top_1: 0.601719, top_k: 0.818516, samples/s: 1743.862 1612904279.7333193
train: epoch 89, iter 900, loss: 2.654524, top_1: 0.604961, top_k: 0.817422, samples/s: 1750.438 1612904294.3581827
train: epoch 89, iter 1000, loss: 2.652218, top_1: 0.610469, top_k: 0.821289, samples/s: 1742.751 1612904309.0475678
train: epoch 89, iter 1100, loss: 2.869388, top_1: 0.599297, top_k: 0.817656, samples/s: 1732.424 1612904323.824581
train: epoch 89, iter 1200, loss: 2.683241, top_1: 0.593594, top_k: 0.817305, samples/s: 1743.495 1612904338.507774
train: epoch 89, iter 1300, loss: 2.612236, top_1: 0.603477, top_k: 0.822695, samples/s: 1729.967 1612904353.3057387
train: epoch 89, iter 1400, loss: 2.468360, top_1: 0.604414, top_k: 0.818516, samples/s: 1746.751 1612904367.961526
train: epoch 89, iter 1500, loss: 2.689095, top_1: 0.596641, top_k: 0.816484, samples/s: 1740.618 1612904382.6689186
train: epoch 89, iter 1600, loss: 2.545994, top_1: 0.602930, top_k: 0.817773, samples/s: 1730.460 1612904397.4626892
train: epoch 89, iter 1700, loss: 2.607286, top_1: 0.599297, top_k: 0.818281, samples/s: 1730.866 1612904412.2530186
train: epoch 89, iter 1800, loss: 2.717506, top_1: 0.601250, top_k: 0.816523, samples/s: 1757.566 1612904426.8185422
train: epoch 89, iter 1900, loss: 2.535283, top_1: 0.609727, top_k: 0.818594, samples/s: 1746.485 1612904441.4765787
train: epoch 89, iter 2000, loss: 2.531201, top_1: 0.607109, top_k: 0.818945, samples/s: 1718.509 1612904456.3732235
train: epoch 89, iter 2100, loss: 2.609102, top_1: 0.598437, top_k: 0.814414, samples/s: 1754.508 1612904470.9641626
train: epoch 89, iter 2200, loss: 2.635882, top_1: 0.603125, top_k: 0.817773, samples/s: 1746.524 1612904485.6219194
train: epoch 89, iter 2300, loss: 2.719984, top_1: 0.598672, top_k: 0.819336, samples/s: 1733.195 1612904500.392325
train: epoch 89, iter 2400, loss: 2.471456, top_1: 0.598008, top_k: 0.817773, samples/s: 1743.641 1612904515.074209
train: epoch 89, iter 2500, loss: 2.624954, top_1: 0.597539, top_k: 0.811445, samples/s: 1714.040 1612904530.009627
train: epoch 89, iter 2600, loss: 2.703782, top_1: 0.595391, top_k: 0.811055, samples/s: 1737.745 1612904544.7413938
train: epoch 89, iter 2700, loss: 2.681527, top_1: 0.602266, top_k: 0.814609, samples/s: 1746.186 1612904559.4018867
train: epoch 89, iter 2800, loss: 2.633811, top_1: 0.594648, top_k: 0.812930, samples/s: 1728.913 1612904574.2089303
train: epoch 89, iter 2900, loss: 2.687706, top_1: 0.599102, top_k: 0.815742, samples/s: 1745.370 1612904588.8763206
train: epoch 89, iter 3000, loss: 2.645894, top_1: 0.601094, top_k: 0.817031, samples/s: 1731.964 1612904603.6571853
train: epoch 89, iter 3100, loss: 2.754757, top_1: 0.592578, top_k: 0.810391, samples/s: 1744.155 1612904618.3348165
train: epoch 89, iter 3200, loss: 2.684911, top_1: 0.599609, top_k: 0.814883, samples/s: 1744.857 1612904633.0065606
train: epoch 89, iter 3300, loss: 2.513322, top_1: 0.599063, top_k: 0.811484, samples/s: 1736.765 1612904647.7465568
train: epoch 89, iter 3400, loss: 2.667605, top_1: 0.601875, top_k: 0.813438, samples/s: 1730.413 1612904662.5407193
train: epoch 89, iter 3500, loss: 2.713621, top_1: 0.604219, top_k: 0.818203, samples/s: 1743.494 1612904677.2240036
train: epoch 89, iter 3600, loss: 2.614265, top_1: 0.599727, top_k: 0.809648, samples/s: 1750.048 1612904691.851989
train: epoch 89, iter 3700, loss: 2.518954, top_1: 0.597617, top_k: 0.813398, samples/s: 1735.410 1612904706.6036112
train: epoch 89, iter 3800, loss: 2.602571, top_1: 0.597852, top_k: 0.815391, samples/s: 1746.654 1612904721.2602155
train: epoch 89, iter 3900, loss: 2.713293, top_1: 0.595859, top_k: 0.812422, samples/s: 1744.453 1612904735.9353073
train: epoch 89, iter 4000, loss: 2.548453, top_1: 0.593984, top_k: 0.814609, samples/s: 1741.799 1612904750.632742
train: epoch 89, iter 4100, loss: 2.603575, top_1: 0.598828, top_k: 0.815586, samples/s: 1745.134 1612904765.3020442
train: epoch 89, iter 4200, loss: 2.650557, top_1: 0.601758, top_k: 0.813359, samples/s: 1747.028 1612904779.9556096
train: epoch 89, iter 4300, loss: 2.682177, top_1: 0.600664, top_k: 0.814297, samples/s: 1742.415 1612904794.6477501
train: epoch 89, iter 4400, loss: 2.788242, top_1: 0.594336, top_k: 0.811250, samples/s: 1737.359 1612904809.3828723
train: epoch 89, iter 4500, loss: 2.767460, top_1: 0.595156, top_k: 0.816094, samples/s: 1749.030 1612904824.0194283
train: epoch 89, iter 4600, loss: 2.563715, top_1: 0.592734, top_k: 0.808828, samples/s: 1747.546 1612904838.6685889
train: epoch 89, iter 4700, loss: 2.629855, top_1: 0.601211, top_k: 0.812266, samples/s: 1739.228 1612904853.3877282
train: epoch 89, iter 4800, loss: 2.788997, top_1: 0.599453, top_k: 0.814141, samples/s: 1742.344 1612904868.0806282
train: epoch 89, iter 4900, loss: 2.454661, top_1: 0.599961, top_k: 0.814258, samples/s: 1734.701 1612904882.838211
train: epoch 89, iter 5000, loss: 2.439224, top_1: 0.605391, top_k: 0.819844, samples/s: 1755.196 1612904897.42354
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_89.
validation: epoch 89, iter 195, top_1: 0.644311, top_k: 0.863522, samples/s: 2829.701 1612904915.4991076
train: epoch 90, iter 100, loss: 2.514925, top_1: 0.609414, top_k: 0.821992, samples/s: 1758.097 1612904950.9007986
train: epoch 90, iter 200, loss: 2.610247, top_1: 0.613477, top_k: 0.825000, samples/s: 1753.379 1612904965.501194
train: epoch 90, iter 300, loss: 2.699693, top_1: 0.602422, top_k: 0.818789, samples/s: 1759.897 1612904980.047413
train: epoch 90, iter 400, loss: 2.374098, top_1: 0.604023, top_k: 0.818555, samples/s: 1762.226 1612904994.5744755
train: epoch 90, iter 500, loss: 2.540879, top_1: 0.614727, top_k: 0.826289, samples/s: 1743.847 1612905009.2547603
train: epoch 90, iter 600, loss: 2.584519, top_1: 0.598711, top_k: 0.815703, samples/s: 1768.441 1612905023.7307441
train: epoch 90, iter 700, loss: 2.468383, top_1: 0.605781, top_k: 0.819180, samples/s: 1754.672 1612905038.3203678
train: epoch 90, iter 800, loss: 2.747184, top_1: 0.609375, top_k: 0.826133, samples/s: 1744.601 1612905052.9942582
train: epoch 90, iter 900, loss: 2.243873, top_1: 0.607109, top_k: 0.820117, samples/s: 1756.093 1612905067.5719926
train: epoch 90, iter 1000, loss: 2.665023, top_1: 0.600781, top_k: 0.817813, samples/s: 1735.342 1612905082.3241575
train: epoch 90, iter 1100, loss: 2.510972, top_1: 0.604766, top_k: 0.821797, samples/s: 1724.333 1612905097.1705182
train: epoch 90, iter 1200, loss: 2.677775, top_1: 0.600352, top_k: 0.814648, samples/s: 1761.399 1612905111.7044082
train: epoch 90, iter 1300, loss: 2.613291, top_1: 0.604062, top_k: 0.822695, samples/s: 1741.692 1612905126.4026706
train: epoch 90, iter 1400, loss: 2.570293, top_1: 0.597539, top_k: 0.816602, samples/s: 1738.493 1612905141.1280663
train: epoch 90, iter 1500, loss: 2.582231, top_1: 0.601758, top_k: 0.820234, samples/s: 1754.293 1612905155.720839
train: epoch 90, iter 1600, loss: 2.633762, top_1: 0.606367, top_k: 0.819805, samples/s: 1743.064 1612905170.4076514
train: epoch 90, iter 1700, loss: 2.614485, top_1: 0.606211, top_k: 0.820078, samples/s: 1742.003 1612905185.1033523
train: epoch 90, iter 1800, loss: 2.760405, top_1: 0.602383, top_k: 0.816680, samples/s: 1730.763 1612905199.894566
train: epoch 90, iter 1900, loss: 2.610164, top_1: 0.600078, top_k: 0.817656, samples/s: 1732.859 1612905214.6677992
train: epoch 90, iter 2000, loss: 2.720776, top_1: 0.602812, top_k: 0.817500, samples/s: 1747.991 1612905229.3131769
train: epoch 90, iter 2100, loss: 2.749599, top_1: 0.586914, top_k: 0.807031, samples/s: 1738.635 1612905244.0374193
train: epoch 90, iter 2200, loss: 2.647472, top_1: 0.602187, top_k: 0.816484, samples/s: 1729.552 1612905258.8389778
train: epoch 90, iter 2300, loss: 2.428785, top_1: 0.597578, top_k: 0.812227, samples/s: 1748.102 1612905273.4834397
train: epoch 90, iter 2400, loss: 2.650674, top_1: 0.599570, top_k: 0.815586, samples/s: 1748.553 1612905288.124074
train: epoch 90, iter 2500, loss: 2.671588, top_1: 0.601836, top_k: 0.816250, samples/s: 1745.669 1612905302.7888877
train: epoch 90, iter 2600, loss: 2.672930, top_1: 0.601953, top_k: 0.818477, samples/s: 1734.919 1612905317.544614
train: epoch 90, iter 2700, loss: 2.613614, top_1: 0.601172, top_k: 0.815312, samples/s: 1744.732 1612905332.2174091
train: epoch 90, iter 2800, loss: 2.616264, top_1: 0.603867, top_k: 0.820234, samples/s: 1742.079 1612905346.9124331
train: epoch 90, iter 2900, loss: 2.681099, top_1: 0.599219, top_k: 0.812891, samples/s: 1746.142 1612905361.5733857
train: epoch 90, iter 3000, loss: 2.540170, top_1: 0.600313, top_k: 0.817930, samples/s: 1738.640 1612905376.2976089
train: epoch 90, iter 3100, loss: 2.491963, top_1: 0.598828, top_k: 0.816484, samples/s: 1742.002 1612905390.993337
train: epoch 90, iter 3200, loss: 2.413939, top_1: 0.599531, top_k: 0.815039, samples/s: 1749.760 1612905405.6238363
train: epoch 90, iter 3300, loss: 2.902074, top_1: 0.604922, top_k: 0.819180, samples/s: 1741.731 1612905420.3219173
train: epoch 90, iter 3400, loss: 2.698687, top_1: 0.601836, top_k: 0.817422, samples/s: 1747.771 1612905434.969057
train: epoch 90, iter 3500, loss: 2.664254, top_1: 0.598125, top_k: 0.814453, samples/s: 1735.953 1612905449.7160435
train: epoch 90, iter 3600, loss: 2.580260, top_1: 0.605469, top_k: 0.818750, samples/s: 1749.741 1612905464.3467228
train: epoch 90, iter 3700, loss: 2.781367, top_1: 0.598984, top_k: 0.817656, samples/s: 1739.728 1612905479.0617554
train: epoch 90, iter 3800, loss: 2.474376, top_1: 0.603398, top_k: 0.820312, samples/s: 1747.022 1612905493.7152655
train: epoch 90, iter 3900, loss: 2.512546, top_1: 0.598750, top_k: 0.817227, samples/s: 1728.383 1612905508.5266964
train: epoch 90, iter 4000, loss: 2.774235, top_1: 0.598203, top_k: 0.814531, samples/s: 1750.345 1612905523.1523976
train: epoch 90, iter 4100, loss: 2.717134, top_1: 0.599102, top_k: 0.815859, samples/s: 1736.100 1612905537.8981738
train: epoch 90, iter 4200, loss: 2.724124, top_1: 0.600391, top_k: 0.813672, samples/s: 1744.209 1612905552.5753095
train: epoch 90, iter 4300, loss: 2.799889, top_1: 0.597539, top_k: 0.816875, samples/s: 1735.867 1612905567.3229454
train: epoch 90, iter 4400, loss: 2.769540, top_1: 0.590898, top_k: 0.811953, samples/s: 1749.121 1612905581.9589348
train: epoch 90, iter 4500, loss: 2.704622, top_1: 0.596992, top_k: 0.812813, samples/s: 1746.994 1612905596.6126506
train: epoch 90, iter 4600, loss: 2.428937, top_1: 0.601211, top_k: 0.814375, samples/s: 1753.325 1612905611.2133849
train: epoch 90, iter 4700, loss: 2.482876, top_1: 0.599844, top_k: 0.815547, samples/s: 1742.670 1612905625.9035208
train: epoch 90, iter 4800, loss: 2.696574, top_1: 0.605039, top_k: 0.817383, samples/s: 1744.819 1612905640.5755403
train: epoch 90, iter 4900, loss: 2.717489, top_1: 0.595039, top_k: 0.813750, samples/s: 1738.383 1612905655.301958
train: epoch 90, iter 5000, loss: 2.545116, top_1: 0.605469, top_k: 0.816641, samples/s: 1740.061 1612905670.0139441
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_90.
validation: epoch 90, iter 195, top_1: 0.642488, top_k: 0.862841, samples/s: 2812.586 1612905688.2055495
train: epoch 91, iter 100, loss: 2.676269, top_1: 0.606641, top_k: 0.821523, samples/s: 1751.362 1612905723.1330755
train: epoch 91, iter 200, loss: 2.593306, top_1: 0.604922, top_k: 0.814375, samples/s: 1763.262 1612905737.6516013
train: epoch 91, iter 300, loss: 2.575148, top_1: 0.611445, top_k: 0.826680, samples/s: 1740.614 1612905752.3591518
train: epoch 91, iter 400, loss: 2.744392, top_1: 0.611875, top_k: 0.824141, samples/s: 1756.453 1612905766.9340363
train: epoch 91, iter 500, loss: 2.697295, top_1: 0.604062, top_k: 0.818984, samples/s: 1770.584 1612905781.392417
train: epoch 91, iter 600, loss: 2.466833, top_1: 0.610898, top_k: 0.818750, samples/s: 1760.283 1612905795.9354854
train: epoch 91, iter 700, loss: 2.511358, top_1: 0.606133, top_k: 0.820430, samples/s: 1748.295 1612905810.5783458
train: epoch 91, iter 800, loss: 2.549926, top_1: 0.612852, top_k: 0.825273, samples/s: 1744.899 1612905825.2496624
train: epoch 91, iter 900, loss: 2.641051, top_1: 0.607461, top_k: 0.821797, samples/s: 1744.268 1612905839.9263875
train: epoch 91, iter 1000, loss: 2.628579, top_1: 0.599336, top_k: 0.814180, samples/s: 1737.458 1612905854.660495
train: epoch 91, iter 1100, loss: 2.603983, top_1: 0.601914, top_k: 0.820508, samples/s: 1738.060 1612905869.3895948
train: epoch 91, iter 1200, loss: 2.810948, top_1: 0.601328, top_k: 0.819336, samples/s: 1744.527 1612905884.0640228
train: epoch 91, iter 1300, loss: 2.660583, top_1: 0.603437, top_k: 0.820469, samples/s: 1742.906 1612905898.7521827
train: epoch 91, iter 1400, loss: 2.818236, top_1: 0.606953, top_k: 0.820430, samples/s: 1730.324 1612905913.547042
train: epoch 91, iter 1500, loss: 2.752838, top_1: 0.602578, top_k: 0.822109, samples/s: 1747.855 1612905928.193613
train: epoch 91, iter 1600, loss: 2.732763, top_1: 0.608789, top_k: 0.822383, samples/s: 1741.340 1612905942.8949344
train: epoch 91, iter 1700, loss: 2.683116, top_1: 0.595664, top_k: 0.815156, samples/s: 1739.472 1612905957.6120172
train: epoch 91, iter 1800, loss: 2.488849, top_1: 0.604336, top_k: 0.816836, samples/s: 1757.103 1612905972.1814702
train: epoch 91, iter 1900, loss: 2.549012, top_1: 0.601523, top_k: 0.813828, samples/s: 1734.026 1612905986.9447904
train: epoch 91, iter 2000, loss: 2.790720, top_1: 0.605234, top_k: 0.817617, samples/s: 1740.337 1612906001.6545577
train: epoch 91, iter 2100, loss: 2.559178, top_1: 0.613437, top_k: 0.823984, samples/s: 1747.112 1612906016.3074033
train: epoch 91, iter 2200, loss: 2.717132, top_1: 0.607344, top_k: 0.821289, samples/s: 1737.828 1612906031.0384018
train: epoch 91, iter 2300, loss: 2.454457, top_1: 0.606914, top_k: 0.820703, samples/s: 1733.418 1612906045.806855
train: epoch 91, iter 2400, loss: 2.687402, top_1: 0.605234, top_k: 0.819336, samples/s: 1749.828 1612906060.436886
train: epoch 91, iter 2500, loss: 2.558520, top_1: 0.603281, top_k: 0.815781, samples/s: 1752.106 1612906075.0478773
train: epoch 91, iter 2600, loss: 2.712311, top_1: 0.607695, top_k: 0.822148, samples/s: 1750.494 1612906089.6723557
train: epoch 91, iter 2700, loss: 2.578849, top_1: 0.604492, top_k: 0.820195, samples/s: 1741.835 1612906104.3694608
train: epoch 91, iter 2800, loss: 2.688916, top_1: 0.602031, top_k: 0.818203, samples/s: 1736.490 1612906119.1119435
train: epoch 91, iter 2900, loss: 2.817446, top_1: 0.600469, top_k: 0.819492, samples/s: 1748.315 1612906133.7544997
train: epoch 91, iter 3000, loss: 2.703494, top_1: 0.606484, top_k: 0.818945, samples/s: 1745.245 1612906148.422925
train: epoch 91, iter 3100, loss: 2.706368, top_1: 0.603398, top_k: 0.817461, samples/s: 1744.198 1612906163.1002138
train: epoch 91, iter 3200, loss: 2.701982, top_1: 0.600313, top_k: 0.816484, samples/s: 1738.130 1612906177.8286595
train: epoch 91, iter 3300, loss: 2.571518, top_1: 0.608281, top_k: 0.820156, samples/s: 1740.625 1612906192.5362082
train: epoch 91, iter 3400, loss: 2.788989, top_1: 0.599961, top_k: 0.816758, samples/s: 1760.660 1612906207.0760791
train: epoch 91, iter 3500, loss: 2.596826, top_1: 0.598242, top_k: 0.814453, samples/s: 1745.363 1612906221.7435691
train: epoch 91, iter 3600, loss: 2.712142, top_1: 0.601484, top_k: 0.816953, samples/s: 1729.674 1612906236.5439749
train: epoch 91, iter 3700, loss: 2.584786, top_1: 0.604023, top_k: 0.820352, samples/s: 1741.505 1612906251.243925
train: epoch 91, iter 3800, loss: 2.757973, top_1: 0.606758, top_k: 0.817578, samples/s: 1739.888 1612906265.957571
train: epoch 91, iter 3900, loss: 2.682105, top_1: 0.602852, top_k: 0.819102, samples/s: 1751.600 1612906280.572682
train: epoch 91, iter 4000, loss: 2.786329, top_1: 0.596016, top_k: 0.812383, samples/s: 1747.678 1612906295.2206576
train: epoch 91, iter 4100, loss: 2.715712, top_1: 0.604805, top_k: 0.819844, samples/s: 1745.171 1612906309.8897681
train: epoch 91, iter 4200, loss: 2.568691, top_1: 0.604648, top_k: 0.819258, samples/s: 1745.532 1612906324.5558317
train: epoch 91, iter 4300, loss: 2.652222, top_1: 0.597070, top_k: 0.815039, samples/s: 1738.422 1612906339.2817209
train: epoch 91, iter 4400, loss: 2.511795, top_1: 0.604062, top_k: 0.817578, samples/s: 1745.600 1612906353.947164
train: epoch 91, iter 4500, loss: 2.724478, top_1: 0.603945, top_k: 0.819648, samples/s: 1736.906 1612906368.6861045
train: epoch 91, iter 4600, loss: 2.643105, top_1: 0.610039, top_k: 0.817852, samples/s: 1748.169 1612906383.3300188
train: epoch 91, iter 4700, loss: 2.730117, top_1: 0.600234, top_k: 0.817930, samples/s: 1739.328 1612906398.048261
train: epoch 91, iter 4800, loss: 2.729059, top_1: 0.601641, top_k: 0.817852, samples/s: 1749.316 1612906412.6825209
train: epoch 91, iter 4900, loss: 2.584467, top_1: 0.600508, top_k: 0.815352, samples/s: 1748.667 1612906427.3222632
train: epoch 91, iter 5000, loss: 2.609327, top_1: 0.608359, top_k: 0.819688, samples/s: 1748.023 1612906441.9673777
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_91.
validation: epoch 91, iter 195, top_1: 0.634756, top_k: 0.859095, samples/s: 2801.980 1612906460.1994705
train: epoch 92, iter 100, loss: 2.554579, top_1: 0.610391, top_k: 0.825039, samples/s: 1739.999 1612906495.5453298
train: epoch 92, iter 200, loss: 2.574841, top_1: 0.608047, top_k: 0.822227, samples/s: 1760.481 1612906510.0866833
train: epoch 92, iter 300, loss: 2.528999, top_1: 0.618437, top_k: 0.830273, samples/s: 1751.175 1612906524.7056806
train: epoch 92, iter 400, loss: 2.556174, top_1: 0.616953, top_k: 0.826484, samples/s: 1753.265 1612906539.3068447
train: epoch 92, iter 500, loss: 2.754211, top_1: 0.614375, top_k: 0.822734, samples/s: 1770.272 1612906553.7679017
train: epoch 92, iter 600, loss: 2.552785, top_1: 0.614375, top_k: 0.825781, samples/s: 1757.079 1612906568.3375075
train: epoch 92, iter 700, loss: 2.624868, top_1: 0.610625, top_k: 0.824375, samples/s: 1757.711 1612906582.9019098
train: epoch 92, iter 800, loss: 2.612530, top_1: 0.614258, top_k: 0.824531, samples/s: 1736.610 1612906597.6432896
train: epoch 92, iter 900, loss: 2.643783, top_1: 0.601523, top_k: 0.818672, samples/s: 1749.342 1612906612.2773666
train: epoch 92, iter 1000, loss: 2.654225, top_1: 0.610625, top_k: 0.822031, samples/s: 1748.373 1612906626.919509
train: epoch 92, iter 1100, loss: 2.639716, top_1: 0.602617, top_k: 0.817109, samples/s: 1747.861 1612906641.566005
train: epoch 92, iter 1200, loss: 2.779008, top_1: 0.613867, top_k: 0.825234, samples/s: 1730.882 1612906656.3560948
train: epoch 92, iter 1300, loss: 2.532576, top_1: 0.609961, top_k: 0.822734, samples/s: 1748.189 1612906670.9998252
train: epoch 92, iter 1400, loss: 2.780679, top_1: 0.605625, top_k: 0.820039, samples/s: 1752.398 1612906685.608439
train: epoch 92, iter 1500, loss: 2.590354, top_1: 0.606445, top_k: 0.819766, samples/s: 1747.814 1612906700.2552795
train: epoch 92, iter 1600, loss: 2.506056, top_1: 0.602891, top_k: 0.821797, samples/s: 1728.389 1612906715.066716
train: epoch 92, iter 1700, loss: 2.830573, top_1: 0.606289, top_k: 0.821055, samples/s: 1737.754 1612906729.7985096
train: epoch 92, iter 1800, loss: 2.813283, top_1: 0.604844, top_k: 0.819570, samples/s: 1754.948 1612906744.385706
train: epoch 92, iter 1900, loss: 2.631718, top_1: 0.607812, top_k: 0.821836, samples/s: 1749.007 1612906759.0226488
train: epoch 92, iter 2000, loss: 2.575306, top_1: 0.608516, top_k: 0.820117, samples/s: 1739.219 1612906773.741876
train: epoch 92, iter 2100, loss: 2.682698, top_1: 0.609805, top_k: 0.822500, samples/s: 1737.233 1612906788.4779623
train: epoch 92, iter 2200, loss: 2.454841, top_1: 0.605898, top_k: 0.822773, samples/s: 1743.307 1612906803.16271
train: epoch 92, iter 2300, loss: 2.569668, top_1: 0.597617, top_k: 0.813047, samples/s: 1733.563 1612906817.9299028
train: epoch 92, iter 2400, loss: 2.819243, top_1: 0.605391, top_k: 0.817305, samples/s: 1738.543 1612906832.6549401
train: epoch 92, iter 2500, loss: 2.618386, top_1: 0.608125, top_k: 0.820078, samples/s: 1754.670 1612906847.244517
train: epoch 92, iter 2600, loss: 2.541450, top_1: 0.602969, top_k: 0.818086, samples/s: 1747.916 1612906861.890532
train: epoch 92, iter 2700, loss: 2.745354, top_1: 0.606641, top_k: 0.821719, samples/s: 1727.826 1612906876.7068412
train: epoch 92, iter 2800, loss: 2.598027, top_1: 0.605273, top_k: 0.816797, samples/s: 1746.500 1612906891.3647833
train: epoch 92, iter 2900, loss: 2.635457, top_1: 0.605469, top_k: 0.821758, samples/s: 1752.322 1612906905.9739058
train: epoch 92, iter 3000, loss: 2.633322, top_1: 0.611289, top_k: 0.824258, samples/s: 1729.385 1612906920.776979
train: epoch 92, iter 3100, loss: 2.570158, top_1: 0.602695, top_k: 0.819688, samples/s: 1742.119 1612906935.471606
train: epoch 92, iter 3200, loss: 2.755693, top_1: 0.604336, top_k: 0.817813, samples/s: 1749.071 1612906950.108005
train: epoch 92, iter 3300, loss: 2.452536, top_1: 0.601914, top_k: 0.821133, samples/s: 1737.391 1612906964.8427446
train: epoch 92, iter 3400, loss: 2.657994, top_1: 0.603750, top_k: 0.818203, samples/s: 1731.213 1612906979.6300697
train: epoch 92, iter 3500, loss: 2.848054, top_1: 0.606836, top_k: 0.820977, samples/s: 1760.437 1612906994.1719182
train: epoch 92, iter 3600, loss: 2.556161, top_1: 0.605703, top_k: 0.815273, samples/s: 1747.973 1612907008.8174345
train: epoch 92, iter 3700, loss: 2.716633, top_1: 0.604531, top_k: 0.814219, samples/s: 1734.381 1612907023.5776823
train: epoch 92, iter 3800, loss: 2.687415, top_1: 0.605234, top_k: 0.816641, samples/s: 1728.760 1612907038.3860168
train: epoch 92, iter 3900, loss: 2.671059, top_1: 0.600430, top_k: 0.816445, samples/s: 1759.526 1612907052.935425
train: epoch 92, iter 4000, loss: 2.732398, top_1: 0.605820, top_k: 0.814492, samples/s: 1742.859 1612907067.62389
train: epoch 92, iter 4100, loss: 2.771062, top_1: 0.595977, top_k: 0.814453, samples/s: 1749.372 1612907082.2576988
train: epoch 92, iter 4200, loss: 2.568130, top_1: 0.594766, top_k: 0.811836, samples/s: 1748.445 1612907096.8993578
train: epoch 92, iter 4300, loss: 2.635575, top_1: 0.602578, top_k: 0.818281, samples/s: 1736.498 1612907111.641638
train: epoch 92, iter 4400, loss: 2.761011, top_1: 0.600859, top_k: 0.814648, samples/s: 1732.185 1612907126.4206164
train: epoch 92, iter 4500, loss: 2.620159, top_1: 0.599258, top_k: 0.814883, samples/s: 1749.235 1612907141.0556247
train: epoch 92, iter 4600, loss: 2.461343, top_1: 0.603398, top_k: 0.815859, samples/s: 1732.084 1612907155.8355775
train: epoch 92, iter 4700, loss: 2.562114, top_1: 0.602344, top_k: 0.812031, samples/s: 1748.831 1612907170.4738736
train: epoch 92, iter 4800, loss: 2.447569, top_1: 0.601484, top_k: 0.814688, samples/s: 1739.423 1612907185.191333
train: epoch 92, iter 4900, loss: 2.649979, top_1: 0.607500, top_k: 0.819180, samples/s: 1745.941 1612907199.8539655
train: epoch 92, iter 5000, loss: 2.673479, top_1: 0.611484, top_k: 0.819492, samples/s: 1742.529 1612907214.5452852
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_92.
validation: epoch 92, iter 195, top_1: 0.648498, top_k: 0.867087, samples/s: 2863.688 1612907232.3346827
train: epoch 93, iter 100, loss: 2.470642, top_1: 0.615469, top_k: 0.828555, samples/s: 1751.649 1612907267.7870052
train: epoch 93, iter 200, loss: 2.606480, top_1: 0.618398, top_k: 0.827109, samples/s: 1763.803 1612907282.3011448
train: epoch 93, iter 300, loss: 2.725571, top_1: 0.609375, top_k: 0.822187, samples/s: 1759.304 1612907296.8522995
train: epoch 93, iter 400, loss: 2.551064, top_1: 0.611406, top_k: 0.822539, samples/s: 1751.912 1612907311.4649243
train: epoch 93, iter 500, loss: 2.671477, top_1: 0.607187, top_k: 0.820586, samples/s: 1762.456 1612907325.9900787
train: epoch 93, iter 600, loss: 2.648494, top_1: 0.612539, top_k: 0.827305, samples/s: 1753.126 1612907340.5925767
train: epoch 93, iter 700, loss: 2.552904, top_1: 0.614414, top_k: 0.826328, samples/s: 1746.033 1612907355.2544632
train: epoch 93, iter 800, loss: 2.643934, top_1: 0.605625, top_k: 0.821289, samples/s: 1744.601 1612907369.9282818
train: epoch 93, iter 900, loss: 2.680026, top_1: 0.612461, top_k: 0.828398, samples/s: 1745.495 1612907384.5945525
train: epoch 93, iter 1000, loss: 2.646296, top_1: 0.617656, top_k: 0.826445, samples/s: 1735.596 1612907399.344558
train: epoch 93, iter 1100, loss: 2.513364, top_1: 0.613984, top_k: 0.825898, samples/s: 1750.354 1612907413.9701872
train: epoch 93, iter 1200, loss: 2.609666, top_1: 0.610078, top_k: 0.823945, samples/s: 1728.092 1612907428.7842684
train: epoch 93, iter 1300, loss: 2.560019, top_1: 0.606055, top_k: 0.822305, samples/s: 1751.052 1612907443.4039853
train: epoch 93, iter 1400, loss: 2.556918, top_1: 0.613672, top_k: 0.823516, samples/s: 1746.845 1612907458.0589814
train: epoch 93, iter 1500, loss: 2.702611, top_1: 0.606914, top_k: 0.823008, samples/s: 1741.325 1612907472.7604382
train: epoch 93, iter 1600, loss: 2.689187, top_1: 0.606289, top_k: 0.820352, samples/s: 1732.330 1612907487.5381696
train: epoch 93, iter 1700, loss: 2.814167, top_1: 0.603633, top_k: 0.818789, samples/s: 1748.136 1612907502.182355
train: epoch 93, iter 1800, loss: 2.733905, top_1: 0.606367, top_k: 0.822578, samples/s: 1744.123 1612907516.860263
train: epoch 93, iter 1900, loss: 2.560536, top_1: 0.606797, top_k: 0.820117, samples/s: 1741.682 1612907531.55871
train: epoch 93, iter 2000, loss: 2.653628, top_1: 0.609414, top_k: 0.821328, samples/s: 1748.859 1612907546.1968858
train: epoch 93, iter 2100, loss: 2.600242, top_1: 0.606250, top_k: 0.819453, samples/s: 1745.725 1612907560.8612168
train: epoch 93, iter 2200, loss: 2.576829, top_1: 0.613555, top_k: 0.822930, samples/s: 1729.796 1612907575.6606922
train: epoch 93, iter 2300, loss: 2.448303, top_1: 0.607461, top_k: 0.819609, samples/s: 1738.058 1612907590.3896725
train: epoch 93, iter 2400, loss: 2.653462, top_1: 0.609336, top_k: 0.821484, samples/s: 1749.873 1612907605.0193405
train: epoch 93, iter 2500, loss: 2.615515, top_1: 0.611484, top_k: 0.825430, samples/s: 1741.574 1612907619.7186944
train: epoch 93, iter 2600, loss: 2.754516, top_1: 0.607383, top_k: 0.818320, samples/s: 1752.596 1612907634.3255992
train: epoch 93, iter 2700, loss: 2.537830, top_1: 0.612031, top_k: 0.821680, samples/s: 1746.896 1612907648.9802377
train: epoch 93, iter 2800, loss: 2.595342, top_1: 0.602266, top_k: 0.821094, samples/s: 1741.018 1612907663.684175
train: epoch 93, iter 2900, loss: 2.813068, top_1: 0.608516, top_k: 0.820508, samples/s: 1730.463 1612907678.4778893
train: epoch 93, iter 3000, loss: 2.748650, top_1: 0.605313, top_k: 0.818203, samples/s: 1747.746 1612907693.125313
train: epoch 93, iter 3100, loss: 2.573112, top_1: 0.609375, top_k: 0.821641, samples/s: 1743.906 1612907707.8049977
train: epoch 93, iter 3200, loss: 2.678326, top_1: 0.610547, top_k: 0.823672, samples/s: 1748.816 1612907722.443518
train: epoch 93, iter 3300, loss: 2.774476, top_1: 0.611172, top_k: 0.819609, samples/s: 1724.776 1612907737.2859838
train: epoch 93, iter 3400, loss: 2.615430, top_1: 0.607383, top_k: 0.822695, samples/s: 1739.565 1612907752.002407
train: epoch 93, iter 3500, loss: 2.638230, top_1: 0.603320, top_k: 0.818516, samples/s: 1719.532 1612907766.8901277
train: epoch 93, iter 3600, loss: 2.582674, top_1: 0.606328, top_k: 0.820156, samples/s: 1737.626 1612907781.62283
train: epoch 93, iter 3700, loss: 2.466476, top_1: 0.611250, top_k: 0.822109, samples/s: 1752.980 1612907796.2265806
train: epoch 93, iter 3800, loss: 2.643513, top_1: 0.608203, top_k: 0.820469, samples/s: 1745.851 1612907810.8899844
train: epoch 93, iter 3900, loss: 2.698957, top_1: 0.605078, top_k: 0.820156, samples/s: 1740.534 1612907825.598044
train: epoch 93, iter 4000, loss: 2.487919, top_1: 0.605156, top_k: 0.820117, samples/s: 1750.494 1612907840.2224858
train: epoch 93, iter 4100, loss: 2.544716, top_1: 0.607812, top_k: 0.819492, samples/s: 1732.042 1612907855.002684
train: epoch 93, iter 4200, loss: 2.557626, top_1: 0.606680, top_k: 0.820586, samples/s: 1735.008 1612907869.7576807
train: epoch 93, iter 4300, loss: 2.458352, top_1: 0.606641, top_k: 0.820586, samples/s: 1755.516 1612907884.3403242
train: epoch 93, iter 4400, loss: 2.503985, top_1: 0.602187, top_k: 0.819453, samples/s: 1740.682 1612907899.0471919
train: epoch 93, iter 4500, loss: 2.565897, top_1: 0.603164, top_k: 0.818672, samples/s: 1742.987 1612907913.734596
train: epoch 93, iter 4600, loss: 2.727519, top_1: 0.608281, top_k: 0.825703, samples/s: 1743.244 1612907928.4198878
train: epoch 93, iter 4700, loss: 2.619216, top_1: 0.603867, top_k: 0.822812, samples/s: 1744.065 1612907943.0981636
train: epoch 93, iter 4800, loss: 2.687587, top_1: 0.609258, top_k: 0.820039, samples/s: 1743.191 1612907957.783934
train: epoch 93, iter 4900, loss: 2.606275, top_1: 0.606953, top_k: 0.821133, samples/s: 1747.078 1612907972.4370139
train: epoch 93, iter 5000, loss: 2.637154, top_1: 0.607930, top_k: 0.822500, samples/s: 1736.086 1612907987.1828012
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_93.
validation: epoch 93, iter 195, top_1: 0.642728, top_k: 0.863161, samples/s: 2835.326 1612908005.270513
train: epoch 94, iter 100, loss: 2.752488, top_1: 0.612187, top_k: 0.826445, samples/s: 1757.518 1612908040.019893
train: epoch 94, iter 200, loss: 2.613522, top_1: 0.614492, top_k: 0.825000, samples/s: 1742.905 1612908054.7080693
train: epoch 94, iter 300, loss: 2.756392, top_1: 0.611016, top_k: 0.824570, samples/s: 1765.667 1612908069.2067502
train: epoch 94, iter 400, loss: 2.471593, top_1: 0.617578, top_k: 0.825781, samples/s: 1760.825 1612908083.7454565
train: epoch 94, iter 500, loss: 2.498334, top_1: 0.614961, top_k: 0.827695, samples/s: 1750.726 1612908098.3679912
train: epoch 94, iter 600, loss: 2.785871, top_1: 0.617930, top_k: 0.829336, samples/s: 1759.110 1612908112.920904
train: epoch 94, iter 700, loss: 2.613468, top_1: 0.610352, top_k: 0.826289, samples/s: 1753.987 1612908127.516045
train: epoch 94, iter 800, loss: 2.648813, top_1: 0.614258, top_k: 0.823672, samples/s: 1756.477 1612908142.0907435
train: epoch 94, iter 900, loss: 2.490665, top_1: 0.620039, top_k: 0.827656, samples/s: 1735.352 1612908156.8427038
train: epoch 94, iter 1000, loss: 2.540492, top_1: 0.619023, top_k: 0.828359, samples/s: 1747.679 1612908171.4906948
train: epoch 94, iter 1100, loss: 2.574941, top_1: 0.609180, top_k: 0.824141, samples/s: 1733.723 1612908186.2566495
train: epoch 94, iter 1200, loss: 2.666016, top_1: 0.609727, top_k: 0.823203, samples/s: 1748.256 1612908200.8998115
train: epoch 94, iter 1300, loss: 2.708824, top_1: 0.608281, top_k: 0.821055, samples/s: 1742.751 1612908215.5892124
train: epoch 94, iter 1400, loss: 2.569446, top_1: 0.613086, top_k: 0.825703, samples/s: 1739.855 1612908230.303187
train: epoch 94, iter 1500, loss: 2.524624, top_1: 0.616406, top_k: 0.826250, samples/s: 1738.917 1612908245.024951
train: epoch 94, iter 1600, loss: 2.758071, top_1: 0.612187, top_k: 0.826328, samples/s: 1741.800 1612908259.7223942
train: epoch 94, iter 1700, loss: 2.469335, top_1: 0.606094, top_k: 0.818203, samples/s: 1738.397 1612908274.4485686
train: epoch 94, iter 1800, loss: 2.809486, top_1: 0.612734, top_k: 0.823320, samples/s: 1740.516 1612908289.1568322
train: epoch 94, iter 1900, loss: 2.462959, top_1: 0.608164, top_k: 0.821875, samples/s: 1754.363 1612908303.7491038
train: epoch 94, iter 2000, loss: 2.659526, top_1: 0.612969, top_k: 0.822969, samples/s: 1742.227 1612908318.4428365
train: epoch 94, iter 2100, loss: 2.579151, top_1: 0.607109, top_k: 0.820391, samples/s: 1740.377 1612908333.152413
train: epoch 94, iter 2200, loss: 2.608887, top_1: 0.610664, top_k: 0.824336, samples/s: 1756.753 1612908347.7246237
train: epoch 94, iter 2300, loss: 2.487770, top_1: 0.611367, top_k: 0.824688, samples/s: 1739.456 1612908362.4420044
train: epoch 94, iter 2400, loss: 2.850056, top_1: 0.611250, top_k: 0.827773, samples/s: 1748.834 1612908377.0802162
train: epoch 94, iter 2500, loss: 2.733377, top_1: 0.611719, top_k: 0.823789, samples/s: 1735.238 1612908391.8332262
train: epoch 94, iter 2600, loss: 2.848671, top_1: 0.609258, top_k: 0.822266, samples/s: 1749.791 1612908406.4635692
train: epoch 94, iter 2700, loss: 2.581470, top_1: 0.607031, top_k: 0.823320, samples/s: 1740.378 1612908421.1730902
train: epoch 94, iter 2800, loss: 2.481089, top_1: 0.611836, top_k: 0.818398, samples/s: 1718.596 1612908436.0689104
train: epoch 94, iter 2900, loss: 2.596948, top_1: 0.608750, top_k: 0.820781, samples/s: 1771.578 1612908450.5193465
train: epoch 94, iter 3000, loss: 2.484169, top_1: 0.608437, top_k: 0.821758, samples/s: 1733.913 1612908465.2835665
train: epoch 94, iter 3100, loss: 2.669992, top_1: 0.606172, top_k: 0.819648, samples/s: 1741.700 1612908479.9819095
train: epoch 94, iter 3200, loss: 2.566462, top_1: 0.608164, top_k: 0.820156, samples/s: 1745.342 1612908494.6495075
train: epoch 94, iter 3300, loss: 2.691145, top_1: 0.611289, top_k: 0.821406, samples/s: 1734.139 1612908509.4119577
train: epoch 94, iter 3400, loss: 2.581459, top_1: 0.606094, top_k: 0.822109, samples/s: 1743.999 1612908524.0908093
train: epoch 94, iter 3500, loss: 2.615989, top_1: 0.609531, top_k: 0.822266, samples/s: 1750.232 1612908538.7175255
train: epoch 94, iter 3600, loss: 2.667245, top_1: 0.608008, top_k: 0.819688, samples/s: 1724.016 1612908553.5664446
train: epoch 94, iter 3700, loss: 2.638402, top_1: 0.605469, top_k: 0.822773, samples/s: 1741.943 1612908568.2626429
train: epoch 94, iter 3800, loss: 2.706608, top_1: 0.607773, top_k: 0.819609, samples/s: 1746.321 1612908582.9220986
train: epoch 94, iter 3900, loss: 2.466096, top_1: 0.605547, top_k: 0.818867, samples/s: 1747.142 1612908597.5746148
train: epoch 94, iter 4000, loss: 2.644873, top_1: 0.606094, top_k: 0.819492, samples/s: 1757.720 1612908612.1388688
train: epoch 94, iter 4100, loss: 2.575701, top_1: 0.617070, top_k: 0.827266, samples/s: 1729.400 1612908626.94177
train: epoch 94, iter 4200, loss: 2.383683, top_1: 0.611563, top_k: 0.826484, samples/s: 1742.565 1612908641.632687
train: epoch 94, iter 4300, loss: 2.622967, top_1: 0.610156, top_k: 0.821133, samples/s: 1749.254 1612908656.267549
train: epoch 94, iter 4400, loss: 2.626235, top_1: 0.606641, top_k: 0.820469, samples/s: 1739.915 1612908670.9809508
train: epoch 94, iter 4500, loss: 2.721853, top_1: 0.608711, top_k: 0.819531, samples/s: 1742.847 1612908685.6694744
train: epoch 94, iter 4600, loss: 2.841190, top_1: 0.602617, top_k: 0.821328, samples/s: 1744.686 1612908700.3426101
train: epoch 94, iter 4700, loss: 2.521654, top_1: 0.601641, top_k: 0.818281, samples/s: 1740.332 1612908715.052561
train: epoch 94, iter 4800, loss: 2.646844, top_1: 0.605234, top_k: 0.817500, samples/s: 1752.485 1612908729.66025
train: epoch 94, iter 4900, loss: 2.658158, top_1: 0.609102, top_k: 0.824922, samples/s: 1743.732 1612908744.341459
train: epoch 94, iter 5000, loss: 2.390223, top_1: 0.615469, top_k: 0.828438, samples/s: 1747.759 1612908758.9887853
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_94.
validation: epoch 94, iter 195, top_1: 0.652724, top_k: 0.868650, samples/s: 2835.937 1612908777.0544674
train: epoch 95, iter 100, loss: 2.568267, top_1: 0.623047, top_k: 0.833711, samples/s: 1748.131 1612908811.505426
train: epoch 95, iter 200, loss: 2.557954, top_1: 0.620469, top_k: 0.827734, samples/s: 1756.171 1612908826.0825493
train: epoch 95, iter 300, loss: 2.609250, top_1: 0.620820, top_k: 0.831094, samples/s: 1762.776 1612908840.6050808
train: epoch 95, iter 400, loss: 2.522673, top_1: 0.618906, top_k: 0.832422, samples/s: 1756.379 1612908855.180657
train: epoch 95, iter 500, loss: 2.695793, top_1: 0.612812, top_k: 0.824570, samples/s: 1763.114 1612908869.7002566
train: epoch 95, iter 600, loss: 2.621072, top_1: 0.613516, top_k: 0.822695, samples/s: 1761.471 1612908884.233606
train: epoch 95, iter 700, loss: 2.560743, top_1: 0.615586, top_k: 0.828672, samples/s: 1742.334 1612908898.926613
train: epoch 95, iter 800, loss: 2.532475, top_1: 0.606172, top_k: 0.823906, samples/s: 1754.596 1612908913.5167258
train: epoch 95, iter 900, loss: 2.631184, top_1: 0.612539, top_k: 0.825703, samples/s: 1748.471 1612908928.158148
train: epoch 95, iter 1000, loss: 2.516547, top_1: 0.612734, top_k: 0.824336, samples/s: 1726.150 1612908942.9888077
train: epoch 95, iter 1100, loss: 2.549353, top_1: 0.613789, top_k: 0.823047, samples/s: 1747.051 1612908957.6420646
train: epoch 95, iter 1200, loss: 2.725093, top_1: 0.613125, top_k: 0.826680, samples/s: 1748.168 1612908972.2860146
train: epoch 95, iter 1300, loss: 2.542976, top_1: 0.611445, top_k: 0.823477, samples/s: 1730.090 1612908987.082926
train: epoch 95, iter 1400, loss: 2.666596, top_1: 0.615781, top_k: 0.823203, samples/s: 1745.389 1612909001.7501166
train: epoch 95, iter 1500, loss: 2.755806, top_1: 0.610273, top_k: 0.824805, samples/s: 1743.417 1612909016.4339442
train: epoch 95, iter 1600, loss: 2.628196, top_1: 0.609062, top_k: 0.822852, samples/s: 1742.944 1612909031.1217308
train: epoch 95, iter 1700, loss: 2.503898, top_1: 0.612695, top_k: 0.823047, samples/s: 1740.265 1612909045.8320904
train: epoch 95, iter 1800, loss: 2.436210, top_1: 0.618750, top_k: 0.826250, samples/s: 1743.163 1612909060.5180426
train: epoch 95, iter 1900, loss: 2.637926, top_1: 0.615234, top_k: 0.826523, samples/s: 1729.044 1612909075.3240194
train: epoch 95, iter 2000, loss: 2.722974, top_1: 0.611250, top_k: 0.825156, samples/s: 1741.396 1612909090.0247939
train: epoch 95, iter 2100, loss: 2.586322, top_1: 0.613789, top_k: 0.825313, samples/s: 1743.587 1612909104.707158
train: epoch 95, iter 2200, loss: 2.630399, top_1: 0.613320, top_k: 0.825039, samples/s: 1747.114 1612909119.3602054
train: epoch 95, iter 2300, loss: 2.735028, top_1: 0.610352, top_k: 0.818984, samples/s: 1733.886 1612909134.1245208
train: epoch 95, iter 2400, loss: 2.641536, top_1: 0.609844, top_k: 0.823398, samples/s: 1747.990 1612909148.7698078
train: epoch 95, iter 2500, loss: 2.555040, top_1: 0.606172, top_k: 0.821562, samples/s: 1747.840 1612909163.4165077
train: epoch 95, iter 2600, loss: 2.629981, top_1: 0.608867, top_k: 0.822852, samples/s: 1748.626 1612909178.0569932
train: epoch 95, iter 2700, loss: 2.806631, top_1: 0.608516, top_k: 0.824727, samples/s: 1746.410 1612909192.715154
train: epoch 95, iter 2800, loss: 2.641097, top_1: 0.611680, top_k: 0.822930, samples/s: 1734.309 1612909207.4763806
train: epoch 95, iter 2900, loss: 2.416919, top_1: 0.609180, top_k: 0.818945, samples/s: 1756.260 1612909222.0525005
train: epoch 95, iter 3000, loss: 2.411838, top_1: 0.609297, top_k: 0.823828, samples/s: 1730.966 1612909236.8425236
train: epoch 95, iter 3100, loss: 2.749425, top_1: 0.612695, top_k: 0.823164, samples/s: 1735.106 1612909251.5960965
train: epoch 95, iter 3200, loss: 2.661522, top_1: 0.609727, top_k: 0.824336, samples/s: 1741.067 1612909266.2997777
train: epoch 95, iter 3300, loss: 2.658523, top_1: 0.613203, top_k: 0.825195, samples/s: 1755.930 1612909280.878906
train: epoch 95, iter 3400, loss: 2.669110, top_1: 0.609883, top_k: 0.823906, samples/s: 1728.107 1612909295.6928625
train: epoch 95, iter 3500, loss: 2.513764, top_1: 0.611758, top_k: 0.822148, samples/s: 1745.731 1612909310.3571796
train: epoch 95, iter 3600, loss: 2.639471, top_1: 0.610508, top_k: 0.823359, samples/s: 1756.604 1612909324.9307244
train: epoch 95, iter 3700, loss: 2.444668, top_1: 0.609062, top_k: 0.821133, samples/s: 1738.684 1612909339.6544783
train: epoch 95, iter 3800, loss: 2.431679, top_1: 0.610547, top_k: 0.824102, samples/s: 1731.987 1612909354.4352672
train: epoch 95, iter 3900, loss: 2.618377, top_1: 0.604570, top_k: 0.820820, samples/s: 1747.530 1612909369.0844743
train: epoch 95, iter 4000, loss: 2.466789, top_1: 0.608516, top_k: 0.821641, samples/s: 1735.538 1612909383.8349469
train: epoch 95, iter 4100, loss: 2.525996, top_1: 0.611641, top_k: 0.824883, samples/s: 1746.795 1612909398.4906023
train: epoch 95, iter 4200, loss: 2.603141, top_1: 0.608789, top_k: 0.823281, samples/s: 1745.743 1612909413.1546133
train: epoch 95, iter 4300, loss: 2.767918, top_1: 0.608437, top_k: 0.821758, samples/s: 1743.924 1612909427.8341436
train: epoch 95, iter 4400, loss: 2.559154, top_1: 0.608281, top_k: 0.821484, samples/s: 1748.488 1612909442.4752965
train: epoch 95, iter 4500, loss: 2.670434, top_1: 0.605781, top_k: 0.818242, samples/s: 1748.670 1612909457.1149902
train: epoch 95, iter 4600, loss: 2.565154, top_1: 0.614922, top_k: 0.826055, samples/s: 1735.146 1612909471.8692586
train: epoch 95, iter 4700, loss: 2.479789, top_1: 0.609023, top_k: 0.822187, samples/s: 1734.783 1612909486.6256897
train: epoch 95, iter 4800, loss: 2.531153, top_1: 0.608203, top_k: 0.822578, samples/s: 1741.361 1612909501.3268335
train: epoch 95, iter 4900, loss: 2.906025, top_1: 0.606250, top_k: 0.818555, samples/s: 1744.495 1612909516.001612
train: epoch 95, iter 5000, loss: 2.636418, top_1: 0.612266, top_k: 0.828477, samples/s: 1741.824 1612909530.698906
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_95.
validation: epoch 95, iter 195, top_1: 0.648858, top_k: 0.866667, samples/s: 2884.824 1612909548.3800366
train: epoch 96, iter 100, loss: 2.614702, top_1: 0.619883, top_k: 0.831836, samples/s: 1750.208 1612909583.1008542
train: epoch 96, iter 200, loss: 2.519417, top_1: 0.624727, top_k: 0.835156, samples/s: 1756.684 1612909597.6738331
train: epoch 96, iter 300, loss: 2.495447, top_1: 0.619805, top_k: 0.831211, samples/s: 1767.859 1612909612.1545212
train: epoch 96, iter 400, loss: 2.523141, top_1: 0.619141, top_k: 0.828594, samples/s: 1751.011 1612909626.7746472
train: epoch 96, iter 500, loss: 2.598328, top_1: 0.618047, top_k: 0.828047, samples/s: 1758.337 1612909641.3340616
train: epoch 96, iter 600, loss: 2.709141, top_1: 0.618437, top_k: 0.827227, samples/s: 1765.312 1612909655.8355896
train: epoch 96, iter 700, loss: 2.614741, top_1: 0.618359, top_k: 0.833047, samples/s: 1747.949 1612909670.4812953
train: epoch 96, iter 800, loss: 2.599944, top_1: 0.610898, top_k: 0.827930, samples/s: 1746.551 1612909685.138723
train: epoch 96, iter 900, loss: 2.651492, top_1: 0.614531, top_k: 0.825664, samples/s: 1766.260 1612909699.6326373
train: epoch 96, iter 1000, loss: 2.611381, top_1: 0.618086, top_k: 0.825977, samples/s: 1736.765 1612909714.372684
train: epoch 96, iter 1100, loss: 2.509004, top_1: 0.616445, top_k: 0.828438, samples/s: 1731.618 1612909729.1565733
train: epoch 96, iter 1200, loss: 2.461208, top_1: 0.622734, top_k: 0.830469, samples/s: 1752.348 1612909743.7655177
train: epoch 96, iter 1300, loss: 2.437751, top_1: 0.617148, top_k: 0.830547, samples/s: 1744.032 1612909758.4441922
train: epoch 96, iter 1400, loss: 2.717498, top_1: 0.616797, top_k: 0.827305, samples/s: 1734.780 1612909773.2011116
train: epoch 96, iter 1500, loss: 2.575308, top_1: 0.615547, top_k: 0.826328, samples/s: 1743.203 1612909787.8866818
train: epoch 96, iter 1600, loss: 2.602306, top_1: 0.619922, top_k: 0.829336, samples/s: 1745.742 1612909802.5509667
train: epoch 96, iter 1700, loss: 2.776513, top_1: 0.615586, top_k: 0.824727, samples/s: 1729.731 1612909817.3508854
train: epoch 96, iter 1800, loss: 2.633277, top_1: 0.615234, top_k: 0.822617, samples/s: 1751.198 1612909831.9694927
train: epoch 96, iter 1900, loss: 2.868268, top_1: 0.614336, top_k: 0.823203, samples/s: 1745.628 1612909846.6346784
train: epoch 96, iter 2000, loss: 2.555926, top_1: 0.613047, top_k: 0.827305, samples/s: 1739.621 1612909861.3505762
train: epoch 96, iter 2100, loss: 2.641138, top_1: 0.611797, top_k: 0.829102, samples/s: 1738.441 1612909876.0763888
train: epoch 96, iter 2200, loss: 2.632554, top_1: 0.616094, top_k: 0.827891, samples/s: 1749.521 1612909890.709002
train: epoch 96, iter 2300, loss: 2.717874, top_1: 0.612070, top_k: 0.827773, samples/s: 1739.216 1612909905.4282238
train: epoch 96, iter 2400, loss: 2.567467, top_1: 0.612031, top_k: 0.823203, samples/s: 1750.982 1612909920.0488522
train: epoch 96, iter 2500, loss: 2.553967, top_1: 0.609883, top_k: 0.823594, samples/s: 1733.876 1612909934.8132718
train: epoch 96, iter 2600, loss: 2.368393, top_1: 0.616055, top_k: 0.824375, samples/s: 1747.253 1612909949.4647567
train: epoch 96, iter 2700, loss: 2.474480, top_1: 0.615742, top_k: 0.824844, samples/s: 1745.739 1612909964.1294897
train: epoch 96, iter 2800, loss: 2.642650, top_1: 0.611055, top_k: 0.825898, samples/s: 1745.336 1612909978.7967033
train: epoch 96, iter 2900, loss: 2.681372, top_1: 0.611875, top_k: 0.824102, samples/s: 1740.419 1612909993.505798
train: epoch 96, iter 3000, loss: 2.664529, top_1: 0.613359, top_k: 0.823086, samples/s: 1743.332 1612910008.1904147
train: epoch 96, iter 3100, loss: 2.606350, top_1: 0.611484, top_k: 0.824609, samples/s: 1745.827 1612910022.85391
train: epoch 96, iter 3200, loss: 2.524873, top_1: 0.613437, top_k: 0.827969, samples/s: 1737.984 1612910037.5836415
train: epoch 96, iter 3300, loss: 2.669605, top_1: 0.610469, top_k: 0.828008, samples/s: 1730.647 1612910052.3757062
train: epoch 96, iter 3400, loss: 2.638558, top_1: 0.616094, top_k: 0.823047, samples/s: 1742.620 1612910067.0663273
train: epoch 96, iter 3500, loss: 2.631627, top_1: 0.610352, top_k: 0.826992, samples/s: 1751.794 1612910081.679876
train: epoch 96, iter 3600, loss: 2.638708, top_1: 0.604219, top_k: 0.818750, samples/s: 1743.743 1612910096.3609424
train: epoch 96, iter 3700, loss: 2.780976, top_1: 0.614258, top_k: 0.825820, samples/s: 1721.422 1612910111.232412
train: epoch 96, iter 3800, loss: 2.627575, top_1: 0.614102, top_k: 0.827812, samples/s: 1751.300 1612910125.8500419
train: epoch 96, iter 3900, loss: 2.576349, top_1: 0.614297, top_k: 0.823789, samples/s: 1744.153 1612910140.527654
train: epoch 96, iter 4000, loss: 2.619791, top_1: 0.610625, top_k: 0.824414, samples/s: 1746.403 1612910155.1863322
train: epoch 96, iter 4100, loss: 2.790104, top_1: 0.613320, top_k: 0.823984, samples/s: 1741.676 1612910169.884876
train: epoch 96, iter 4200, loss: 2.614889, top_1: 0.605586, top_k: 0.821016, samples/s: 1733.049 1612910184.6565688
train: epoch 96, iter 4300, loss: 2.588632, top_1: 0.609297, top_k: 0.820742, samples/s: 1758.083 1612910199.2178407
train: epoch 96, iter 4400, loss: 2.554539, top_1: 0.614844, top_k: 0.826836, samples/s: 1746.237 1612910213.8778698
train: epoch 96, iter 4500, loss: 2.640290, top_1: 0.608164, top_k: 0.822656, samples/s: 1748.772 1612910228.5167384
train: epoch 96, iter 4600, loss: 2.815876, top_1: 0.609297, top_k: 0.821484, samples/s: 1732.819 1612910243.290339
train: epoch 96, iter 4700, loss: 2.592808, top_1: 0.612461, top_k: 0.823359, samples/s: 1748.810 1612910257.9288886
train: epoch 96, iter 4800, loss: 2.671377, top_1: 0.610430, top_k: 0.821836, samples/s: 1745.339 1612910272.5965004
train: epoch 96, iter 4900, loss: 2.617762, top_1: 0.612031, top_k: 0.824063, samples/s: 1743.070 1612910287.283324
train: epoch 96, iter 5000, loss: 2.562446, top_1: 0.619844, top_k: 0.828125, samples/s: 1752.821 1612910301.8882575
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_96.
validation: epoch 96, iter 195, top_1: 0.652384, top_k: 0.867448, samples/s: 2903.183 1612910319.5147192
train: epoch 97, iter 100, loss: 2.657586, top_1: 0.621758, top_k: 0.832187, samples/s: 1759.241 1612910359.55234
train: epoch 97, iter 200, loss: 2.662008, top_1: 0.618086, top_k: 0.827891, samples/s: 1751.647 1612910374.167099
train: epoch 97, iter 300, loss: 2.553511, top_1: 0.614336, top_k: 0.829258, samples/s: 1753.787 1612910388.7640586
train: epoch 97, iter 400, loss: 2.582049, top_1: 0.616523, top_k: 0.827500, samples/s: 1758.042 1612910403.3258798
train: epoch 97, iter 500, loss: 2.536206, top_1: 0.621133, top_k: 0.834883, samples/s: 1760.092 1612910417.870376
train: epoch 97, iter 600, loss: 2.536707, top_1: 0.625234, top_k: 0.836172, samples/s: 1760.063 1612910432.4153593
train: epoch 97, iter 700, loss: 2.641248, top_1: 0.623828, top_k: 0.831289, samples/s: 1743.216 1612910447.100826
train: epoch 97, iter 800, loss: 2.505334, top_1: 0.618711, top_k: 0.830820, samples/s: 1755.660 1612910461.682227
train: epoch 97, iter 900, loss: 2.448014, top_1: 0.613633, top_k: 0.828398, samples/s: 1752.178 1612910476.2926617
train: epoch 97, iter 1000, loss: 2.526111, top_1: 0.617461, top_k: 0.829180, samples/s: 1736.308 1612910491.0365467
train: epoch 97, iter 1100, loss: 2.392781, top_1: 0.619023, top_k: 0.827812, samples/s: 1737.129 1612910505.773571
train: epoch 97, iter 1200, loss: 2.609926, top_1: 0.619687, top_k: 0.828086, samples/s: 1744.702 1612910520.4465044
train: epoch 97, iter 1300, loss: 2.552038, top_1: 0.619258, top_k: 0.828359, samples/s: 1740.724 1612910535.153132
train: epoch 97, iter 1400, loss: 2.654588, top_1: 0.620234, top_k: 0.826875, samples/s: 1751.571 1612910549.7685456
train: epoch 97, iter 1500, loss: 2.788216, top_1: 0.618594, top_k: 0.827734, samples/s: 1750.211 1612910564.3953428
train: epoch 97, iter 1600, loss: 2.739878, top_1: 0.612109, top_k: 0.825078, samples/s: 1739.510 1612910579.1120834
train: epoch 97, iter 1700, loss: 2.461412, top_1: 0.623906, top_k: 0.831367, samples/s: 1739.929 1612910593.8253164
train: epoch 97, iter 1800, loss: 2.639219, top_1: 0.613828, top_k: 0.827383, samples/s: 1745.198 1612910608.4942539
train: epoch 97, iter 1900, loss: 2.581674, top_1: 0.621172, top_k: 0.831289, samples/s: 1746.003 1612910623.156282
train: epoch 97, iter 2000, loss: 2.717761, top_1: 0.617500, top_k: 0.830977, samples/s: 1746.666 1612910637.8127806
train: epoch 97, iter 2100, loss: 2.594252, top_1: 0.616602, top_k: 0.825234, samples/s: 1745.058 1612910652.4827662
train: epoch 97, iter 2200, loss: 2.790507, top_1: 0.615469, top_k: 0.831094, samples/s: 1740.062 1612910667.1948826
train: epoch 97, iter 2300, loss: 2.495923, top_1: 0.611250, top_k: 0.824727, samples/s: 1733.378 1612910681.9637642
train: epoch 97, iter 2400, loss: 2.643663, top_1: 0.617656, top_k: 0.828125, samples/s: 1747.747 1612910696.6111083
train: epoch 97, iter 2500, loss: 2.724911, top_1: 0.615703, top_k: 0.828008, samples/s: 1737.654 1612910711.3436818
train: epoch 97, iter 2600, loss: 2.321367, top_1: 0.618867, top_k: 0.827578, samples/s: 1748.131 1612910725.9878075
train: epoch 97, iter 2700, loss: 2.681971, top_1: 0.616523, top_k: 0.829492, samples/s: 1746.211 1612910740.6481304
train: epoch 97, iter 2800, loss: 2.533273, top_1: 0.614727, top_k: 0.824336, samples/s: 1733.484 1612910755.416144
train: epoch 97, iter 2900, loss: 2.619251, top_1: 0.613125, top_k: 0.826055, samples/s: 1744.512 1612910770.090692
train: epoch 97, iter 3000, loss: 2.629663, top_1: 0.616523, top_k: 0.828711, samples/s: 1740.950 1612910784.7952948
train: epoch 97, iter 3100, loss: 2.757938, top_1: 0.619609, top_k: 0.827148, samples/s: 1747.474 1612910799.4450517
train: epoch 97, iter 3200, loss: 2.667827, top_1: 0.612773, top_k: 0.827187, samples/s: 1735.313 1612910814.197471
train: epoch 97, iter 3300, loss: 2.716686, top_1: 0.609414, top_k: 0.824922, samples/s: 1760.070 1612910828.7424128
train: epoch 97, iter 3400, loss: 2.577132, top_1: 0.613750, top_k: 0.823750, samples/s: 1733.769 1612910843.5077896
train: epoch 97, iter 3500, loss: 2.792424, top_1: 0.616211, top_k: 0.826523, samples/s: 1742.301 1612910858.201054
train: epoch 97, iter 3600, loss: 2.640345, top_1: 0.616172, top_k: 0.827969, samples/s: 1739.304 1612910872.91958
train: epoch 97, iter 3700, loss: 2.794718, top_1: 0.616836, top_k: 0.824297, samples/s: 1735.995 1612910887.6661777
train: epoch 97, iter 3800, loss: 2.720119, top_1: 0.611016, top_k: 0.822891, samples/s: 1751.935 1612910902.278579
train: epoch 97, iter 3900, loss: 2.550939, top_1: 0.611680, top_k: 0.824609, samples/s: 1756.347 1612910916.8543046
train: epoch 97, iter 4000, loss: 2.571637, top_1: 0.614062, top_k: 0.823984, samples/s: 1750.821 1612910931.475967
train: epoch 97, iter 4100, loss: 2.549503, top_1: 0.611836, top_k: 0.825273, samples/s: 1740.445 1612910946.1848269
train: epoch 97, iter 4200, loss: 2.555396, top_1: 0.614219, top_k: 0.826250, samples/s: 1752.775 1612910960.7903228
train: epoch 97, iter 4300, loss: 2.717335, top_1: 0.611602, top_k: 0.827109, samples/s: 1748.565 1612910975.4308908
train: epoch 97, iter 4400, loss: 2.708697, top_1: 0.612617, top_k: 0.825625, samples/s: 1738.704 1612910990.154505
train: epoch 97, iter 4500, loss: 2.563899, top_1: 0.607383, top_k: 0.823633, samples/s: 1742.054 1612911004.8497307
train: epoch 97, iter 4600, loss: 2.667367, top_1: 0.616133, top_k: 0.825586, samples/s: 1743.212 1612911019.5352657
train: epoch 97, iter 4700, loss: 2.636333, top_1: 0.612578, top_k: 0.826016, samples/s: 1743.083 1612911034.2219257
train: epoch 97, iter 4800, loss: 2.570830, top_1: 0.613320, top_k: 0.826797, samples/s: 1743.342 1612911048.906387
train: epoch 97, iter 4900, loss: 2.779118, top_1: 0.613203, top_k: 0.820703, samples/s: 1741.388 1612911063.6073072
train: epoch 97, iter 5000, loss: 2.471879, top_1: 0.613594, top_k: 0.827734, samples/s: 1743.819 1612911078.2877269
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_97.
validation: epoch 97, iter 195, top_1: 0.658293, top_k: 0.871534, samples/s: 2817.630 1612911096.4373724
train: epoch 98, iter 100, loss: 2.427896, top_1: 0.626758, top_k: 0.836172, samples/s: 1759.128 1612911130.9236717
train: epoch 98, iter 200, loss: 2.865892, top_1: 0.622578, top_k: 0.831719, samples/s: 1756.963 1612911145.4944348
train: epoch 98, iter 300, loss: 2.433495, top_1: 0.616211, top_k: 0.825547, samples/s: 1757.506 1612911160.0602643
train: epoch 98, iter 400, loss: 2.512945, top_1: 0.624687, top_k: 0.835156, samples/s: 1755.842 1612911174.6401694
train: epoch 98, iter 500, loss: 2.486469, top_1: 0.613359, top_k: 0.830039, samples/s: 1755.393 1612911189.2238905
train: epoch 98, iter 600, loss: 2.589878, top_1: 0.624375, top_k: 0.832227, samples/s: 1762.044 1612911203.752446
train: epoch 98, iter 700, loss: 2.422394, top_1: 0.621563, top_k: 0.829766, samples/s: 1754.361 1612911218.3445904
train: epoch 98, iter 800, loss: 2.593999, top_1: 0.621680, top_k: 0.830078, samples/s: 1750.830 1612911232.966412
train: epoch 98, iter 900, loss: 2.726493, top_1: 0.619687, top_k: 0.834766, samples/s: 1740.767 1612911247.6724784
train: epoch 98, iter 1000, loss: 2.445132, top_1: 0.618633, top_k: 0.831172, samples/s: 1739.750 1612911262.387136
train: epoch 98, iter 1100, loss: 2.458050, top_1: 0.617031, top_k: 0.826523, samples/s: 1744.724 1612911277.0599468
train: epoch 98, iter 1200, loss: 2.439761, top_1: 0.622109, top_k: 0.832187, samples/s: 1747.439 1612911291.7100723
train: epoch 98, iter 1300, loss: 2.488305, top_1: 0.626133, top_k: 0.831562, samples/s: 1743.752 1612911306.3910096
train: epoch 98, iter 1400, loss: 2.534713, top_1: 0.627188, top_k: 0.833906, samples/s: 1733.992 1612911321.1545997
train: epoch 98, iter 1500, loss: 2.450381, top_1: 0.622070, top_k: 0.830547, samples/s: 1750.668 1612911335.7775693
train: epoch 98, iter 1600, loss: 2.633830, top_1: 0.619922, top_k: 0.828555, samples/s: 1734.375 1612911350.53794
train: epoch 98, iter 1700, loss: 2.636661, top_1: 0.613945, top_k: 0.828359, samples/s: 1744.865 1612911365.2095864
train: epoch 98, iter 1800, loss: 2.621363, top_1: 0.619375, top_k: 0.828789, samples/s: 1740.864 1612911379.9148636
train: epoch 98, iter 1900, loss: 2.618511, top_1: 0.623164, top_k: 0.830195, samples/s: 1736.531 1612911394.6569333
train: epoch 98, iter 2000, loss: 2.616626, top_1: 0.616484, top_k: 0.826914, samples/s: 1758.717 1612911409.2130349
train: epoch 98, iter 2100, loss: 2.475995, top_1: 0.616719, top_k: 0.828750, samples/s: 1743.391 1612911423.8970723
train: epoch 98, iter 2200, loss: 2.807105, top_1: 0.619180, top_k: 0.827578, samples/s: 1737.728 1612911438.6289368
train: epoch 98, iter 2300, loss: 2.665130, top_1: 0.620156, top_k: 0.824414, samples/s: 1739.292 1612911453.3475742
train: epoch 98, iter 2400, loss: 2.491816, top_1: 0.622344, top_k: 0.830078, samples/s: 1751.268 1612911467.965494
train: epoch 98, iter 2500, loss: 2.551194, top_1: 0.618477, top_k: 0.827930, samples/s: 1746.852 1612911482.620485
train: epoch 98, iter 2600, loss: 2.475288, top_1: 0.616289, top_k: 0.829492, samples/s: 1743.992 1612911497.2994208
train: epoch 98, iter 2700, loss: 2.445310, top_1: 0.617500, top_k: 0.827148, samples/s: 1739.859 1612911512.0133123
train: epoch 98, iter 2800, loss: 2.695069, top_1: 0.620156, top_k: 0.833164, samples/s: 1748.145 1612911526.657384
train: epoch 98, iter 2900, loss: 2.406677, top_1: 0.612187, top_k: 0.826836, samples/s: 1742.547 1612911541.348528
train: epoch 98, iter 3000, loss: 2.694371, top_1: 0.615078, top_k: 0.827383, samples/s: 1740.698 1612911556.0552394
train: epoch 98, iter 3100, loss: 2.683070, top_1: 0.617852, top_k: 0.827891, samples/s: 1733.022 1612911570.8271194
train: epoch 98, iter 3200, loss: 2.490447, top_1: 0.619180, top_k: 0.829609, samples/s: 1749.501 1612911585.4598775
train: epoch 98, iter 3300, loss: 2.494933, top_1: 0.613359, top_k: 0.829063, samples/s: 1751.900 1612911600.072553
train: epoch 98, iter 3400, loss: 2.652209, top_1: 0.622773, top_k: 0.831289, samples/s: 1735.193 1612911614.8259938
train: epoch 98, iter 3500, loss: 2.585021, top_1: 0.614844, top_k: 0.826602, samples/s: 1751.790 1612911629.4396305
train: epoch 98, iter 3600, loss: 2.579494, top_1: 0.616914, top_k: 0.827773, samples/s: 1730.037 1612911644.2370446
train: epoch 98, iter 3700, loss: 2.736221, top_1: 0.616953, top_k: 0.832695, samples/s: 1750.096 1612911658.8647857
train: epoch 98, iter 3800, loss: 2.546356, top_1: 0.613906, top_k: 0.824648, samples/s: 1749.433 1612911673.4980302
train: epoch 98, iter 3900, loss: 2.822106, top_1: 0.611992, top_k: 0.828203, samples/s: 1748.239 1612911688.1413734
train: epoch 98, iter 4000, loss: 2.632479, top_1: 0.614492, top_k: 0.829766, samples/s: 1741.180 1612911702.8440711
train: epoch 98, iter 4100, loss: 2.596856, top_1: 0.613594, top_k: 0.827148, samples/s: 1743.273 1612911717.5290513
train: epoch 98, iter 4200, loss: 2.435335, top_1: 0.615977, top_k: 0.827031, samples/s: 1750.097 1612911732.1568055
train: epoch 98, iter 4300, loss: 2.548153, top_1: 0.616563, top_k: 0.827930, samples/s: 1749.439 1612911746.7901196
train: epoch 98, iter 4400, loss: 2.753912, top_1: 0.617891, top_k: 0.827812, samples/s: 1738.539 1612911761.5151296
train: epoch 98, iter 4500, loss: 2.686983, top_1: 0.612187, top_k: 0.823594, samples/s: 1757.392 1612911776.0821085
train: epoch 98, iter 4600, loss: 2.512941, top_1: 0.612617, top_k: 0.825859, samples/s: 1745.151 1612911790.7513697
train: epoch 98, iter 4700, loss: 2.625680, top_1: 0.611211, top_k: 0.825078, samples/s: 1737.351 1612911805.4864507
train: epoch 98, iter 4800, loss: 2.456911, top_1: 0.616094, top_k: 0.823047, samples/s: 1748.621 1612911820.1265159
train: epoch 98, iter 4900, loss: 2.577926, top_1: 0.618984, top_k: 0.827344, samples/s: 1740.026 1612911834.8390727
train: epoch 98, iter 5000, loss: 2.552148, top_1: 0.622070, top_k: 0.831953, samples/s: 1731.384 1612911849.6248865
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_98.
validation: epoch 98, iter 195, top_1: 0.660697, top_k: 0.873638, samples/s: 2900.880 1612911867.1495278
train: epoch 99, iter 100, loss: 2.478872, top_1: 0.630313, top_k: 0.839609, samples/s: 1751.842 1612911901.624334
train: epoch 99, iter 200, loss: 2.308292, top_1: 0.631719, top_k: 0.836250, samples/s: 1760.919 1612911916.162134
train: epoch 99, iter 300, loss: 2.567257, top_1: 0.629687, top_k: 0.839023, samples/s: 1749.543 1612911930.7945244
train: epoch 99, iter 400, loss: 2.589237, top_1: 0.627109, top_k: 0.831836, samples/s: 1753.896 1612911945.390593
train: epoch 99, iter 500, loss: 2.464329, top_1: 0.619531, top_k: 0.829258, samples/s: 1746.292 1612911960.050278
train: epoch 99, iter 600, loss: 2.574868, top_1: 0.622969, top_k: 0.829844, samples/s: 1767.260 1612911974.5358746
train: epoch 99, iter 700, loss: 2.731833, top_1: 0.624453, top_k: 0.832344, samples/s: 1744.889 1612911989.2073307
train: epoch 99, iter 800, loss: 2.424660, top_1: 0.620430, top_k: 0.831836, samples/s: 1760.891 1612912003.7456422
train: epoch 99, iter 900, loss: 2.536892, top_1: 0.627461, top_k: 0.833711, samples/s: 1738.664 1612912018.4693723
train: epoch 99, iter 1000, loss: 2.511255, top_1: 0.615859, top_k: 0.831562, samples/s: 1743.508 1612912033.15238
train: epoch 99, iter 1100, loss: 2.522034, top_1: 0.625977, top_k: 0.835547, samples/s: 1751.290 1612912047.7701583
train: epoch 99, iter 1200, loss: 2.516639, top_1: 0.619336, top_k: 0.830820, samples/s: 1717.231 1612912062.6778927
train: epoch 99, iter 1300, loss: 2.477869, top_1: 0.624336, top_k: 0.832812, samples/s: 1753.358 1612912077.278447
train: epoch 99, iter 1400, loss: 2.381572, top_1: 0.621523, top_k: 0.831875, samples/s: 1752.007 1612912091.8902493
train: epoch 99, iter 1500, loss: 2.484394, top_1: 0.622344, top_k: 0.834102, samples/s: 1747.474 1612912106.5400488
train: epoch 99, iter 1600, loss: 2.760472, top_1: 0.615586, top_k: 0.823984, samples/s: 1752.399 1612912121.1484978
train: epoch 99, iter 1700, loss: 2.600638, top_1: 0.618867, top_k: 0.827187, samples/s: 1744.641 1612912135.8219993
train: epoch 99, iter 1800, loss: 2.540928, top_1: 0.620469, top_k: 0.829336, samples/s: 1747.076 1612912150.4750662
train: epoch 99, iter 1900, loss: 2.499827, top_1: 0.616484, top_k: 0.827344, samples/s: 1736.543 1612912165.2170382
train: epoch 99, iter 2000, loss: 2.611311, top_1: 0.621172, top_k: 0.834297, samples/s: 1745.222 1612912179.8858752
train: epoch 99, iter 2100, loss: 2.445329, top_1: 0.620625, top_k: 0.830117, samples/s: 1734.962 1612912194.6410677
train: epoch 99, iter 2200, loss: 2.627615, top_1: 0.619766, top_k: 0.831094, samples/s: 1739.898 1612912209.355087
train: epoch 99, iter 2300, loss: 2.525627, top_1: 0.623320, top_k: 0.831641, samples/s: 1744.719 1612912224.0273402
train: epoch 99, iter 2400, loss: 2.445466, top_1: 0.620156, top_k: 0.832969, samples/s: 1738.771 1612912238.7503886
train: epoch 99, iter 2500, loss: 2.643779, top_1: 0.623086, top_k: 0.832344, samples/s: 1744.853 1612912253.4221282
train: epoch 99, iter 2600, loss: 2.449526, top_1: 0.622773, top_k: 0.834727, samples/s: 1744.816 1612912268.0941758
train: epoch 99, iter 2700, loss: 2.484461, top_1: 0.622422, top_k: 0.829023, samples/s: 1744.314 1612912282.7704682
train: epoch 99, iter 2800, loss: 2.651953, top_1: 0.613945, top_k: 0.822930, samples/s: 1744.860 1612912297.4421275
train: epoch 99, iter 2900, loss: 2.413639, top_1: 0.619141, top_k: 0.832031, samples/s: 1738.114 1612912312.170671
train: epoch 99, iter 3000, loss: 2.714786, top_1: 0.615508, top_k: 0.826016, samples/s: 1750.430 1612912326.7957416
train: epoch 99, iter 3100, loss: 2.865570, top_1: 0.615781, top_k: 0.827578, samples/s: 1752.537 1612912341.403111
train: epoch 99, iter 3200, loss: 2.721570, top_1: 0.616914, top_k: 0.826289, samples/s: 1748.761 1612912356.0420032
train: epoch 99, iter 3300, loss: 2.498299, top_1: 0.616953, top_k: 0.827070, samples/s: 1731.972 1612912370.8228884
train: epoch 99, iter 3400, loss: 2.637299, top_1: 0.614805, top_k: 0.825586, samples/s: 1751.439 1612912385.4394858
train: epoch 99, iter 3500, loss: 2.543502, top_1: 0.616367, top_k: 0.828398, samples/s: 1743.839 1612912400.1196294
train: epoch 99, iter 3600, loss: 2.582628, top_1: 0.615859, top_k: 0.825898, samples/s: 1736.919 1612912414.858616
train: epoch 99, iter 3700, loss: 2.477760, top_1: 0.619961, top_k: 0.829063, samples/s: 1757.331 1612912429.425947
train: epoch 99, iter 3800, loss: 2.621203, top_1: 0.619414, top_k: 0.827617, samples/s: 1745.747 1612912444.090531
train: epoch 99, iter 3900, loss: 2.738090, top_1: 0.610703, top_k: 0.824531, samples/s: 1745.792 1612912458.7539878
train: epoch 99, iter 4000, loss: 2.713667, top_1: 0.615039, top_k: 0.827109, samples/s: 1751.954 1612912473.3662188
train: epoch 99, iter 4100, loss: 2.603909, top_1: 0.617305, top_k: 0.830547, samples/s: 1742.410 1612912488.0589895
train: epoch 99, iter 4200, loss: 2.594240, top_1: 0.618164, top_k: 0.825977, samples/s: 1743.628 1612912502.7405663
train: epoch 99, iter 4300, loss: 2.529544, top_1: 0.616719, top_k: 0.828281, samples/s: 1742.234 1612912517.434297
train: epoch 99, iter 4400, loss: 2.687764, top_1: 0.619727, top_k: 0.828555, samples/s: 1757.301 1612912532.0021448
train: epoch 99, iter 4500, loss: 2.505558, top_1: 0.615352, top_k: 0.829961, samples/s: 1753.210 1612912546.6043205
train: epoch 99, iter 4600, loss: 2.511356, top_1: 0.619531, top_k: 0.829766, samples/s: 1731.906 1612912561.3853118
train: epoch 99, iter 4700, loss: 2.665917, top_1: 0.615234, top_k: 0.827812, samples/s: 1741.526 1612912576.0853598
train: epoch 99, iter 4800, loss: 2.598750, top_1: 0.618594, top_k: 0.829375, samples/s: 1744.223 1612912590.7620547
train: epoch 99, iter 4900, loss: 2.788009, top_1: 0.617070, top_k: 0.829258, samples/s: 1751.094 1612912605.381779
train: epoch 99, iter 5000, loss: 2.580091, top_1: 0.626602, top_k: 0.833203, samples/s: 1747.773 1612912620.0287027
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_99.
validation: epoch 99, iter 195, top_1: 0.661579, top_k: 0.876222, samples/s: 2838.157 1612912638.0344956
train: epoch 100, iter 100, loss: 2.376064, top_1: 0.626055, top_k: 0.834805, samples/s: 1741.051 1612912673.311854
train: epoch 100, iter 200, loss: 2.491871, top_1: 0.628828, top_k: 0.837187, samples/s: 1750.491 1612912687.9363253
train: epoch 100, iter 300, loss: 2.630895, top_1: 0.628086, top_k: 0.835508, samples/s: 1751.925 1612912702.5487876
train: epoch 100, iter 400, loss: 2.466928, top_1: 0.629492, top_k: 0.838203, samples/s: 1769.900 1612912717.0129411
train: epoch 100, iter 500, loss: 2.596603, top_1: 0.622227, top_k: 0.832070, samples/s: 1763.391 1612912731.5307589
train: epoch 100, iter 600, loss: 2.643013, top_1: 0.630898, top_k: 0.834922, samples/s: 1756.753 1612912746.1027145
train: epoch 100, iter 700, loss: 2.559894, top_1: 0.628789, top_k: 0.835742, samples/s: 1755.752 1612912760.6833522
train: epoch 100, iter 800, loss: 2.481889, top_1: 0.628594, top_k: 0.838672, samples/s: 1750.460 1612912775.3091817
train: epoch 100, iter 900, loss: 2.909331, top_1: 0.620977, top_k: 0.827422, samples/s: 1745.638 1612912789.9732816
train: epoch 100, iter 1000, loss: 2.449497, top_1: 0.627266, top_k: 0.837695, samples/s: 1748.561 1612912804.6138122
train: epoch 100, iter 1100, loss: 2.662671, top_1: 0.622461, top_k: 0.828984, samples/s: 1742.143 1612912819.3084013
train: epoch 100, iter 1200, loss: 2.465153, top_1: 0.621445, top_k: 0.831289, samples/s: 1748.506 1612912833.9494295
train: epoch 100, iter 1300, loss: 2.634038, top_1: 0.623984, top_k: 0.832969, samples/s: 1747.108 1612912848.6022801
train: epoch 100, iter 1400, loss: 2.509794, top_1: 0.622930, top_k: 0.834297, samples/s: 1729.912 1612912863.4006736
train: epoch 100, iter 1500, loss: 2.495650, top_1: 0.619727, top_k: 0.830078, samples/s: 1742.239 1612912878.094509
train: epoch 100, iter 1600, loss: 2.390001, top_1: 0.628320, top_k: 0.837383, samples/s: 1738.380 1612912892.821084
train: epoch 100, iter 1700, loss: 2.660188, top_1: 0.622500, top_k: 0.832070, samples/s: 1759.060 1612912907.3740528
train: epoch 100, iter 1800, loss: 2.625760, top_1: 0.622852, top_k: 0.832422, samples/s: 1731.749 1612912922.1570852
train: epoch 100, iter 1900, loss: 2.633397, top_1: 0.621992, top_k: 0.829023, samples/s: 1753.099 1612912936.7594984
train: epoch 100, iter 2000, loss: 2.525044, top_1: 0.625000, top_k: 0.832422, samples/s: 1739.804 1612912951.4737911
train: epoch 100, iter 2100, loss: 2.604811, top_1: 0.621719, top_k: 0.830156, samples/s: 1749.439 1612912966.1070607
train: epoch 100, iter 2200, loss: 2.472392, top_1: 0.620664, top_k: 0.829727, samples/s: 1750.807 1612912980.7288463
train: epoch 100, iter 2300, loss: 2.542472, top_1: 0.616172, top_k: 0.830195, samples/s: 1741.914 1612912995.425325
train: epoch 100, iter 2400, loss: 2.464460, top_1: 0.631484, top_k: 0.836797, samples/s: 1741.033 1612913010.1292903
train: epoch 100, iter 2500, loss: 2.381278, top_1: 0.624141, top_k: 0.829063, samples/s: 1749.027 1612913024.76596
train: epoch 100, iter 2600, loss: 2.504413, top_1: 0.622070, top_k: 0.829961, samples/s: 1739.736 1612913039.4808552
train: epoch 100, iter 2700, loss: 2.608650, top_1: 0.620938, top_k: 0.829414, samples/s: 1736.110 1612913054.2264805
train: epoch 100, iter 2800, loss: 2.721710, top_1: 0.617891, top_k: 0.827266, samples/s: 1749.181 1612913068.8618617
train: epoch 100, iter 2900, loss: 2.494597, top_1: 0.621016, top_k: 0.831641, samples/s: 1751.649 1612913083.4766984
train: epoch 100, iter 3000, loss: 2.568372, top_1: 0.625977, top_k: 0.834531, samples/s: 1732.829 1612913098.2502813
train: epoch 100, iter 3100, loss: 2.516192, top_1: 0.617617, top_k: 0.829609, samples/s: 1757.130 1612913112.8193936
train: epoch 100, iter 3200, loss: 2.463395, top_1: 0.620469, top_k: 0.828633, samples/s: 1729.592 1612913127.62095
train: epoch 100, iter 3300, loss: 2.546845, top_1: 0.618281, top_k: 0.824688, samples/s: 1744.198 1612913142.2979054
train: epoch 100, iter 3400, loss: 2.576611, top_1: 0.620117, top_k: 0.831328, samples/s: 1747.166 1612913156.9500842
train: epoch 100, iter 3500, loss: 2.558485, top_1: 0.619258, top_k: 0.828047, samples/s: 1744.897 1612913171.6217139
train: epoch 100, iter 3600, loss: 2.602211, top_1: 0.618906, top_k: 0.828438, samples/s: 1743.805 1612913186.301976
train: epoch 100, iter 3700, loss: 2.589203, top_1: 0.624687, top_k: 0.834688, samples/s: 1747.994 1612913200.9473612
train: epoch 100, iter 3800, loss: 2.559089, top_1: 0.622383, top_k: 0.833203, samples/s: 1734.625 1612913215.7055821
train: epoch 100, iter 3900, loss: 2.537291, top_1: 0.622422, top_k: 0.832578, samples/s: 1748.329 1612913230.348111
train: epoch 100, iter 4000, loss: 2.696198, top_1: 0.620508, top_k: 0.830820, samples/s: 1743.893 1612913245.0279953
train: epoch 100, iter 4100, loss: 2.766009, top_1: 0.619102, top_k: 0.830195, samples/s: 1750.170 1612913259.6551442
train: epoch 100, iter 4200, loss: 2.600657, top_1: 0.613516, top_k: 0.824609, samples/s: 1742.023 1612913274.3506615
train: epoch 100, iter 4300, loss: 2.437305, top_1: 0.620469, top_k: 0.826328, samples/s: 1750.848 1612913288.9721313
train: epoch 100, iter 4400, loss: 2.420438, top_1: 0.619805, top_k: 0.829141, samples/s: 1737.019 1612913303.7099926
train: epoch 100, iter 4500, loss: 2.317924, top_1: 0.617695, top_k: 0.827617, samples/s: 1741.525 1612913318.4098577
train: epoch 100, iter 4600, loss: 2.512562, top_1: 0.617539, top_k: 0.827656, samples/s: 1751.762 1612913333.0236754
train: epoch 100, iter 4700, loss: 2.530849, top_1: 0.618477, top_k: 0.832578, samples/s: 1747.772 1612913347.670886
train: epoch 100, iter 4800, loss: 2.755564, top_1: 0.621758, top_k: 0.828750, samples/s: 1751.883 1612913362.283727
train: epoch 100, iter 4900, loss: 2.619031, top_1: 0.619414, top_k: 0.828359, samples/s: 1745.179 1612913376.9527497
train: epoch 100, iter 5000, loss: 2.638118, top_1: 0.624453, top_k: 0.833477, samples/s: 1741.402 1612913391.6535213
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_100.
validation: epoch 100, iter 195, top_1: 0.663602, top_k: 0.874800, samples/s: 2858.124 1612913409.5315719
train: epoch 101, iter 100, loss: 2.585377, top_1: 0.633867, top_k: 0.838789, samples/s: 1740.368 1612913444.7340271
train: epoch 101, iter 200, loss: 2.489396, top_1: 0.633320, top_k: 0.835078, samples/s: 1770.634 1612913459.192098
train: epoch 101, iter 300, loss: 2.489002, top_1: 0.630664, top_k: 0.835117, samples/s: 1757.766 1612913473.7561622
train: epoch 101, iter 400, loss: 2.571689, top_1: 0.626641, top_k: 0.832773, samples/s: 1755.338 1612913488.3400612
train: epoch 101, iter 500, loss: 2.491431, top_1: 0.626797, top_k: 0.830156, samples/s: 1764.889 1612913502.8452857
train: epoch 101, iter 600, loss: 2.538121, top_1: 0.630195, top_k: 0.836523, samples/s: 1756.172 1612913517.4223824
train: epoch 101, iter 700, loss: 2.474266, top_1: 0.624297, top_k: 0.832148, samples/s: 1747.234 1612913532.0741827
train: epoch 101, iter 800, loss: 2.774619, top_1: 0.626289, top_k: 0.833281, samples/s: 1750.987 1612913546.6945016
train: epoch 101, iter 900, loss: 2.434744, top_1: 0.627461, top_k: 0.835547, samples/s: 1744.553 1612913561.3688629
train: epoch 101, iter 1000, loss: 2.569908, top_1: 0.621523, top_k: 0.827734, samples/s: 1734.048 1612913576.1319246
train: epoch 101, iter 1100, loss: 2.572286, top_1: 0.626484, top_k: 0.832578, samples/s: 1750.392 1612913590.7572124
train: epoch 101, iter 1200, loss: 2.582611, top_1: 0.622695, top_k: 0.829180, samples/s: 1741.864 1612913605.4540508
train: epoch 101, iter 1300, loss: 2.643698, top_1: 0.626992, top_k: 0.838281, samples/s: 1754.569 1612913620.0445297
train: epoch 101, iter 1400, loss: 2.666231, top_1: 0.625508, top_k: 0.833281, samples/s: 1741.591 1612913634.7437534
train: epoch 101, iter 1500, loss: 2.553915, top_1: 0.620195, top_k: 0.831758, samples/s: 1758.659 1612913649.3003445
train: epoch 101, iter 1600, loss: 2.623136, top_1: 0.624492, top_k: 0.831562, samples/s: 1748.172 1612913663.9441195
train: epoch 101, iter 1700, loss: 2.632780, top_1: 0.624375, top_k: 0.831641, samples/s: 1750.151 1612913678.5714905
train: epoch 101, iter 1800, loss: 2.486597, top_1: 0.622656, top_k: 0.833711, samples/s: 1738.611 1612913693.2958922
train: epoch 101, iter 1900, loss: 2.629957, top_1: 0.626563, top_k: 0.832656, samples/s: 1724.267 1612913708.1428087
train: epoch 101, iter 2000, loss: 2.583025, top_1: 0.626484, top_k: 0.835273, samples/s: 1769.078 1612913722.6136146
train: epoch 101, iter 2100, loss: 2.590512, top_1: 0.614844, top_k: 0.833008, samples/s: 1734.443 1612913737.3733044
train: epoch 101, iter 2200, loss: 2.641978, top_1: 0.621758, top_k: 0.831641, samples/s: 1747.892 1612913752.0195332
train: epoch 101, iter 2300, loss: 2.505575, top_1: 0.626250, top_k: 0.835156, samples/s: 1740.702 1612913766.726301
train: epoch 101, iter 2400, loss: 2.391265, top_1: 0.623359, top_k: 0.830195, samples/s: 1739.675 1612913781.4416819
train: epoch 101, iter 2500, loss: 2.603914, top_1: 0.622617, top_k: 0.830000, samples/s: 1746.774 1612913796.0972679
train: epoch 101, iter 2600, loss: 2.624798, top_1: 0.619258, top_k: 0.832266, samples/s: 1745.120 1612913810.76682
train: epoch 101, iter 2700, loss: 2.582319, top_1: 0.622070, top_k: 0.833242, samples/s: 1754.613 1612913825.3568532
train: epoch 101, iter 2800, loss: 2.485803, top_1: 0.624922, top_k: 0.835977, samples/s: 1742.656 1612913840.0470421
train: epoch 101, iter 2900, loss: 2.493469, top_1: 0.623281, top_k: 0.830820, samples/s: 1740.925 1612913854.7519462
train: epoch 101, iter 3000, loss: 2.837111, top_1: 0.617578, top_k: 0.828711, samples/s: 1748.115 1612913869.3961895
train: epoch 101, iter 3100, loss: 2.620331, top_1: 0.624609, top_k: 0.832656, samples/s: 1745.365 1612913884.0636384
train: epoch 101, iter 3200, loss: 2.652107, top_1: 0.620469, top_k: 0.830352, samples/s: 1736.109 1612913898.8093052
train: epoch 101, iter 3300, loss: 2.449715, top_1: 0.617695, top_k: 0.828125, samples/s: 1740.692 1612913913.5160766
train: epoch 101, iter 3400, loss: 2.562706, top_1: 0.622578, top_k: 0.831094, samples/s: 1755.189 1612913928.1014056
train: epoch 101, iter 3500, loss: 2.659696, top_1: 0.623984, top_k: 0.833711, samples/s: 1731.060 1612913942.8901536
train: epoch 101, iter 3600, loss: 2.532894, top_1: 0.617812, top_k: 0.827187, samples/s: 1760.560 1612913957.4308548
train: epoch 101, iter 3700, loss: 2.506283, top_1: 0.621445, top_k: 0.832031, samples/s: 1742.870 1612913972.1193502
train: epoch 101, iter 3800, loss: 2.670330, top_1: 0.622109, top_k: 0.831055, samples/s: 1744.224 1612913986.796294
train: epoch 101, iter 3900, loss: 2.451237, top_1: 0.626172, top_k: 0.833398, samples/s: 1745.279 1612914001.4644384
train: epoch 101, iter 4000, loss: 2.763342, top_1: 0.622812, top_k: 0.829883, samples/s: 1745.200 1612914016.1332536
train: epoch 101, iter 4100, loss: 2.461936, top_1: 0.622383, top_k: 0.831367, samples/s: 1747.191 1612914030.7853053
train: epoch 101, iter 4200, loss: 2.496152, top_1: 0.619297, top_k: 0.827187, samples/s: 1749.045 1612914045.4218607
train: epoch 101, iter 4300, loss: 2.655191, top_1: 0.624375, top_k: 0.832656, samples/s: 1744.794 1612914060.0941007
train: epoch 101, iter 4400, loss: 2.446172, top_1: 0.618555, top_k: 0.830039, samples/s: 1743.370 1612914074.7783046
train: epoch 101, iter 4500, loss: 2.860605, top_1: 0.623359, top_k: 0.830547, samples/s: 1738.736 1612914089.5016518
train: epoch 101, iter 4600, loss: 2.622262, top_1: 0.621563, top_k: 0.831289, samples/s: 1751.283 1612914104.1195297
train: epoch 101, iter 4700, loss: 2.665818, top_1: 0.627891, top_k: 0.837227, samples/s: 1746.152 1612914118.7802615
train: epoch 101, iter 4800, loss: 2.382437, top_1: 0.618398, top_k: 0.826367, samples/s: 1745.081 1612914133.4501407
train: epoch 101, iter 4900, loss: 2.647355, top_1: 0.626875, top_k: 0.833984, samples/s: 1741.479 1612914148.150229
train: epoch 101, iter 5000, loss: 2.607438, top_1: 0.623086, top_k: 0.839844, samples/s: 1744.980 1612914162.8208556
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_101.
validation: epoch 101, iter 195, top_1: 0.661318, top_k: 0.873698, samples/s: 2796.902 1612914181.096991
train: epoch 102, iter 100, loss: 2.521143, top_1: 0.631250, top_k: 0.842305, samples/s: 1756.517 1612914215.9338503
train: epoch 102, iter 200, loss: 2.583489, top_1: 0.630781, top_k: 0.834688, samples/s: 1749.842 1612914230.563768
train: epoch 102, iter 300, loss: 2.343401, top_1: 0.633281, top_k: 0.839844, samples/s: 1761.805 1612914245.0941575
train: epoch 102, iter 400, loss: 2.542853, top_1: 0.628477, top_k: 0.837656, samples/s: 1760.236 1612914259.6376517
train: epoch 102, iter 500, loss: 2.674870, top_1: 0.626563, top_k: 0.834844, samples/s: 1757.746 1612914274.2017062
train: epoch 102, iter 600, loss: 2.500156, top_1: 0.628437, top_k: 0.836055, samples/s: 1758.874 1612914288.7564833
train: epoch 102, iter 700, loss: 2.570999, top_1: 0.637695, top_k: 0.842734, samples/s: 1739.834 1612914303.4706247
train: epoch 102, iter 800, loss: 2.699158, top_1: 0.631406, top_k: 0.836172, samples/s: 1756.931 1612914318.0414064
train: epoch 102, iter 900, loss: 2.599479, top_1: 0.626563, top_k: 0.836875, samples/s: 1743.872 1612914332.7214599
train: epoch 102, iter 1000, loss: 2.415654, top_1: 0.621094, top_k: 0.831758, samples/s: 1743.763 1612914347.4023223
train: epoch 102, iter 1100, loss: 2.643831, top_1: 0.626641, top_k: 0.832695, samples/s: 1745.511 1612914362.0684586
train: epoch 102, iter 1200, loss: 2.589149, top_1: 0.626055, top_k: 0.833945, samples/s: 1733.680 1612914376.8347576
train: epoch 102, iter 1300, loss: 2.615687, top_1: 0.626797, top_k: 0.835117, samples/s: 1727.032 1612914391.6578338
train: epoch 102, iter 1400, loss: 2.554915, top_1: 0.629180, top_k: 0.835000, samples/s: 1734.968 1612914406.4131577
train: epoch 102, iter 1500, loss: 2.305642, top_1: 0.622617, top_k: 0.829570, samples/s: 1749.608 1612914421.0450048
train: epoch 102, iter 1600, loss: 2.409541, top_1: 0.624141, top_k: 0.832148, samples/s: 1734.834 1612914435.801502
train: epoch 102, iter 1700, loss: 2.466591, top_1: 0.626563, top_k: 0.833789, samples/s: 1736.428 1612914450.5444193
train: epoch 102, iter 1800, loss: 2.475120, top_1: 0.626133, top_k: 0.831562, samples/s: 1741.353 1612914465.245576
train: epoch 102, iter 1900, loss: 2.726368, top_1: 0.630273, top_k: 0.838672, samples/s: 1725.621 1612914480.080837
train: epoch 102, iter 2000, loss: 2.577166, top_1: 0.624570, top_k: 0.831602, samples/s: 1759.311 1612914494.632024
train: epoch 102, iter 2100, loss: 2.527555, top_1: 0.625156, top_k: 0.832891, samples/s: 1731.080 1612914509.4204082
train: epoch 102, iter 2200, loss: 2.538585, top_1: 0.628867, top_k: 0.832539, samples/s: 1742.786 1612914524.1095414
train: epoch 102, iter 2300, loss: 2.479812, top_1: 0.620977, top_k: 0.832109, samples/s: 1739.582 1612914538.8257494
train: epoch 102, iter 2400, loss: 2.464635, top_1: 0.622383, top_k: 0.832227, samples/s: 1744.269 1612914553.5023756
train: epoch 102, iter 2500, loss: 2.520701, top_1: 0.628789, top_k: 0.835117, samples/s: 1745.209 1612914568.1711452
train: epoch 102, iter 2600, loss: 2.472899, top_1: 0.621875, top_k: 0.830625, samples/s: 1739.123 1612914582.8911371
train: epoch 102, iter 2700, loss: 2.491329, top_1: 0.625000, top_k: 0.834570, samples/s: 1739.688 1612914597.6064296
train: epoch 102, iter 2800, loss: 2.489473, top_1: 0.626875, top_k: 0.836719, samples/s: 1743.217 1612914612.292033
train: epoch 102, iter 2900, loss: 2.429076, top_1: 0.626289, top_k: 0.832734, samples/s: 1746.456 1612914626.9502892
train: epoch 102, iter 3000, loss: 2.654805, top_1: 0.624023, top_k: 0.831719, samples/s: 1738.945 1612914641.6718242
train: epoch 102, iter 3100, loss: 2.412311, top_1: 0.623555, top_k: 0.831602, samples/s: 1747.486 1612914656.3213892
train: epoch 102, iter 3200, loss: 2.343458, top_1: 0.626797, top_k: 0.831523, samples/s: 1744.723 1612914670.9941995
train: epoch 102, iter 3300, loss: 2.728460, top_1: 0.626367, top_k: 0.835313, samples/s: 1745.544 1612914685.6601193
train: epoch 102, iter 3400, loss: 2.429370, top_1: 0.625547, top_k: 0.828320, samples/s: 1748.085 1612914700.3050725
train: epoch 102, iter 3500, loss: 2.522909, top_1: 0.628984, top_k: 0.834688, samples/s: 1737.272 1612914715.0405614
train: epoch 102, iter 3600, loss: 2.698511, top_1: 0.625781, top_k: 0.833242, samples/s: 1755.955 1612914729.6198244
train: epoch 102, iter 3700, loss: 2.616311, top_1: 0.618359, top_k: 0.830508, samples/s: 1740.874 1612914744.3246799
train: epoch 102, iter 3800, loss: 2.503653, top_1: 0.628047, top_k: 0.836055, samples/s: 1751.065 1612914758.944398
train: epoch 102, iter 3900, loss: 2.473171, top_1: 0.627734, top_k: 0.833164, samples/s: 1725.474 1612914773.7809014
train: epoch 102, iter 4000, loss: 2.514590, top_1: 0.618867, top_k: 0.827031, samples/s: 1753.242 1612914788.3825107
train: epoch 102, iter 4100, loss: 2.486190, top_1: 0.620586, top_k: 0.830664, samples/s: 1741.344 1612914803.0836754
train: epoch 102, iter 4200, loss: 2.517081, top_1: 0.622266, top_k: 0.830469, samples/s: 1744.433 1612914817.75897
train: epoch 102, iter 4300, loss: 2.605879, top_1: 0.623984, top_k: 0.830586, samples/s: 1739.814 1612914832.4732027
train: epoch 102, iter 4400, loss: 2.513682, top_1: 0.625352, top_k: 0.833789, samples/s: 1748.450 1612914847.1146672
train: epoch 102, iter 4500, loss: 2.546251, top_1: 0.622656, top_k: 0.831445, samples/s: 1739.695 1612914861.8299897
train: epoch 102, iter 4600, loss: 2.634663, top_1: 0.627461, top_k: 0.835938, samples/s: 1752.308 1612914876.4392703
train: epoch 102, iter 4700, loss: 2.429372, top_1: 0.623555, top_k: 0.830703, samples/s: 1747.443 1612914891.0891902
train: epoch 102, iter 4800, loss: 2.651980, top_1: 0.621406, top_k: 0.832578, samples/s: 1740.890 1612914905.7943506
train: epoch 102, iter 4900, loss: 2.357614, top_1: 0.622383, top_k: 0.832734, samples/s: 1750.931 1612914920.415085
train: epoch 102, iter 5000, loss: 2.539375, top_1: 0.628984, top_k: 0.840117, samples/s: 1744.988 1612914935.085672
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_102.
validation: epoch 102, iter 195, top_1: 0.671554, top_k: 0.877183, samples/s: 2816.668 1612914953.2460403
train: epoch 103, iter 100, loss: 2.714483, top_1: 0.626328, top_k: 0.834375, samples/s: 1752.099 1612914987.772361
train: epoch 103, iter 200, loss: 2.570009, top_1: 0.634844, top_k: 0.841562, samples/s: 1765.551 1612915002.2721744
train: epoch 103, iter 300, loss: 2.535377, top_1: 0.639414, top_k: 0.842305, samples/s: 1752.397 1612915016.8805895
train: epoch 103, iter 400, loss: 2.604867, top_1: 0.634609, top_k: 0.840898, samples/s: 1748.217 1612915031.5240486
train: epoch 103, iter 500, loss: 2.435824, top_1: 0.635547, top_k: 0.841250, samples/s: 1765.218 1612915046.0265527
train: epoch 103, iter 600, loss: 2.525137, top_1: 0.627461, top_k: 0.838477, samples/s: 1756.817 1612915060.5984144
train: epoch 103, iter 700, loss: 2.606485, top_1: 0.633750, top_k: 0.835508, samples/s: 1753.750 1612915075.195697
train: epoch 103, iter 800, loss: 2.576787, top_1: 0.630117, top_k: 0.836992, samples/s: 1765.285 1612915089.6975846
train: epoch 103, iter 900, loss: 2.610879, top_1: 0.630430, top_k: 0.838867, samples/s: 1727.911 1612915104.5130992
train: epoch 103, iter 1000, loss: 2.481357, top_1: 0.634727, top_k: 0.841523, samples/s: 1741.822 1612915119.210381
train: epoch 103, iter 1100, loss: 2.620382, top_1: 0.634805, top_k: 0.837109, samples/s: 1742.386 1612915133.9029162
train: epoch 103, iter 1200, loss: 2.619043, top_1: 0.634609, top_k: 0.837305, samples/s: 1748.601 1612915148.54318
train: epoch 103, iter 1300, loss: 2.323918, top_1: 0.627344, top_k: 0.835703, samples/s: 1744.028 1612915163.221834
train: epoch 103, iter 1400, loss: 2.395871, top_1: 0.630938, top_k: 0.834453, samples/s: 1742.818 1612915177.9107478
train: epoch 103, iter 1500, loss: 2.372389, top_1: 0.633516, top_k: 0.840039, samples/s: 1745.906 1612915192.573536
train: epoch 103, iter 1600, loss: 2.438318, top_1: 0.630664, top_k: 0.842773, samples/s: 1742.814 1612915207.2624242
train: epoch 103, iter 1700, loss: 2.568136, top_1: 0.628164, top_k: 0.838906, samples/s: 1747.241 1612915221.9140706
train: epoch 103, iter 1800, loss: 2.593208, top_1: 0.626016, top_k: 0.832227, samples/s: 1740.296 1612915236.6242077
train: epoch 103, iter 1900, loss: 2.518388, top_1: 0.626953, top_k: 0.833125, samples/s: 1736.949 1612915251.3627467
train: epoch 103, iter 2000, loss: 2.588615, top_1: 0.629414, top_k: 0.834180, samples/s: 1744.373 1612915266.0384657
train: epoch 103, iter 2100, loss: 2.494862, top_1: 0.627031, top_k: 0.835391, samples/s: 1745.224 1612915280.7071176
train: epoch 103, iter 2200, loss: 2.400378, top_1: 0.631719, top_k: 0.833398, samples/s: 1746.273 1612915295.3669813
train: epoch 103, iter 2300, loss: 2.523821, top_1: 0.626992, top_k: 0.835508, samples/s: 1726.421 1612915310.1958961
train: epoch 103, iter 2400, loss: 2.572952, top_1: 0.629766, top_k: 0.834023, samples/s: 1745.982 1612915324.857515
train: epoch 103, iter 2500, loss: 2.765186, top_1: 0.626914, top_k: 0.838281, samples/s: 1748.341 1612915339.4999413
train: epoch 103, iter 2600, loss: 2.417256, top_1: 0.629492, top_k: 0.834453, samples/s: 1745.579 1612915354.1655335
train: epoch 103, iter 2700, loss: 2.441843, top_1: 0.627695, top_k: 0.834453, samples/s: 1742.035 1612915368.860989
train: epoch 103, iter 2800, loss: 2.453038, top_1: 0.625195, top_k: 0.833008, samples/s: 1740.760 1612915383.5676181
train: epoch 103, iter 2900, loss: 2.599872, top_1: 0.629805, top_k: 0.836953, samples/s: 1751.880 1612915398.1801405
train: epoch 103, iter 3000, loss: 2.558460, top_1: 0.624805, top_k: 0.835781, samples/s: 1743.291 1612915412.8649392
train: epoch 103, iter 3100, loss: 2.444370, top_1: 0.626719, top_k: 0.832891, samples/s: 1744.581 1612915427.5389636
train: epoch 103, iter 3200, loss: 2.440364, top_1: 0.628516, top_k: 0.836836, samples/s: 1748.258 1612915442.18214
train: epoch 103, iter 3300, loss: 2.585186, top_1: 0.631484, top_k: 0.838320, samples/s: 1744.794 1612915456.854323
train: epoch 103, iter 3400, loss: 2.487426, top_1: 0.634062, top_k: 0.840938, samples/s: 1745.826 1612915471.5178776
train: epoch 103, iter 3500, loss: 2.632243, top_1: 0.619922, top_k: 0.833438, samples/s: 1732.195 1612915486.2969203
train: epoch 103, iter 3600, loss: 2.693638, top_1: 0.628633, top_k: 0.838711, samples/s: 1754.013 1612915500.8920202
train: epoch 103, iter 3700, loss: 2.474062, top_1: 0.624687, top_k: 0.831758, samples/s: 1736.338 1612915515.6356614
train: epoch 103, iter 3800, loss: 2.409216, top_1: 0.627227, top_k: 0.830820, samples/s: 1744.684 1612915530.3087423
train: epoch 103, iter 3900, loss: 2.392529, top_1: 0.622188, top_k: 0.835195, samples/s: 1757.855 1612915544.8719785
train: epoch 103, iter 4000, loss: 2.646336, top_1: 0.626953, top_k: 0.832891, samples/s: 1745.267 1612915559.5402145
train: epoch 103, iter 4100, loss: 2.497640, top_1: 0.628164, top_k: 0.836523, samples/s: 1748.848 1612915574.1784427
train: epoch 103, iter 4200, loss: 2.544653, top_1: 0.628477, top_k: 0.835508, samples/s: 1741.032 1612915588.8823109
train: epoch 103, iter 4300, loss: 2.658734, top_1: 0.626484, top_k: 0.833125, samples/s: 1744.424 1612915603.5576508
train: epoch 103, iter 4400, loss: 2.568741, top_1: 0.623242, top_k: 0.833594, samples/s: 1748.272 1612915618.2007334
train: epoch 103, iter 4500, loss: 2.468472, top_1: 0.629961, top_k: 0.835234, samples/s: 1736.775 1612915632.9406426
train: epoch 103, iter 4600, loss: 2.596559, top_1: 0.624492, top_k: 0.831172, samples/s: 1745.834 1612915647.604177
train: epoch 103, iter 4700, loss: 2.633994, top_1: 0.623320, top_k: 0.830352, samples/s: 1748.034 1612915662.2491279
train: epoch 103, iter 4800, loss: 2.596605, top_1: 0.629531, top_k: 0.835625, samples/s: 1727.898 1612915677.0648804
train: epoch 103, iter 4900, loss: 2.616890, top_1: 0.622031, top_k: 0.832148, samples/s: 1772.072 1612915691.5111854
train: epoch 103, iter 5000, loss: 2.388749, top_1: 0.627773, top_k: 0.832656, samples/s: 1738.074 1612915706.2402225
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_103.
validation: epoch 103, iter 195, top_1: 0.674339, top_k: 0.881250, samples/s: 2889.869 1612915723.9865725
train: epoch 104, iter 100, loss: 2.543647, top_1: 0.644336, top_k: 0.846914, samples/s: 1752.519 1612915758.5191834
train: epoch 104, iter 200, loss: 2.448608, top_1: 0.635156, top_k: 0.840078, samples/s: 1766.931 1612915773.0075443
train: epoch 104, iter 300, loss: 2.547582, top_1: 0.637148, top_k: 0.842070, samples/s: 1757.470 1612915787.5739527
train: epoch 104, iter 400, loss: 2.476449, top_1: 0.635703, top_k: 0.838281, samples/s: 1764.135 1612915802.085177
train: epoch 104, iter 500, loss: 2.581626, top_1: 0.630078, top_k: 0.838437, samples/s: 1754.201 1612915816.6787567
train: epoch 104, iter 600, loss: 2.680525, top_1: 0.627344, top_k: 0.836602, samples/s: 1761.999 1612915831.207667
train: epoch 104, iter 700, loss: 2.497242, top_1: 0.636133, top_k: 0.840781, samples/s: 1752.131 1612915845.8184967
train: epoch 104, iter 800, loss: 2.453506, top_1: 0.633477, top_k: 0.838477, samples/s: 1736.547 1612915860.5603614
train: epoch 104, iter 900, loss: 2.659331, top_1: 0.630352, top_k: 0.841133, samples/s: 1751.162 1612915875.1792572
train: epoch 104, iter 1000, loss: 2.570014, top_1: 0.631328, top_k: 0.839258, samples/s: 1749.543 1612915889.811691
train: epoch 104, iter 1100, loss: 2.627227, top_1: 0.636602, top_k: 0.840273, samples/s: 1740.004 1612915904.5242474
train: epoch 104, iter 1200, loss: 2.528075, top_1: 0.632578, top_k: 0.839609, samples/s: 1738.453 1612915919.249984
train: epoch 104, iter 1300, loss: 2.584604, top_1: 0.627070, top_k: 0.836289, samples/s: 1743.773 1612915933.9308026
train: epoch 104, iter 1400, loss: 2.695726, top_1: 0.633594, top_k: 0.840156, samples/s: 1740.247 1612915948.6414447
train: epoch 104, iter 1500, loss: 2.574384, top_1: 0.638281, top_k: 0.841094, samples/s: 1748.544 1612915963.282133
train: epoch 104, iter 1600, loss: 2.469190, top_1: 0.634609, top_k: 0.839414, samples/s: 1733.704 1612915978.0481482
train: epoch 104, iter 1700, loss: 2.456717, top_1: 0.635391, top_k: 0.843711, samples/s: 1747.894 1612915992.694368
train: epoch 104, iter 1800, loss: 2.657229, top_1: 0.634102, top_k: 0.838672, samples/s: 1741.891 1612916007.3914251
train: epoch 104, iter 1900, loss: 2.428473, top_1: 0.630469, top_k: 0.837617, samples/s: 1738.315 1612916022.117927
train: epoch 104, iter 2000, loss: 2.476217, top_1: 0.627891, top_k: 0.835820, samples/s: 1744.666 1612916036.7916386
train: epoch 104, iter 2100, loss: 2.619368, top_1: 0.629687, top_k: 0.834805, samples/s: 1732.788 1612916051.565109
train: epoch 104, iter 2200, loss: 2.422640, top_1: 0.628242, top_k: 0.837852, samples/s: 1751.376 1612916066.1822526
train: epoch 104, iter 2300, loss: 2.625573, top_1: 0.629180, top_k: 0.840352, samples/s: 1725.503 1612916081.0185213
train: epoch 104, iter 2400, loss: 2.442632, top_1: 0.630039, top_k: 0.836406, samples/s: 1767.298 1612916095.5041766
train: epoch 104, iter 2500, loss: 2.616946, top_1: 0.629922, top_k: 0.834023, samples/s: 1743.174 1612916110.18967
train: epoch 104, iter 2600, loss: 2.490782, top_1: 0.633359, top_k: 0.837969, samples/s: 1740.431 1612916124.8987691
train: epoch 104, iter 2700, loss: 2.614906, top_1: 0.630898, top_k: 0.837422, samples/s: 1753.163 1612916139.500833
train: epoch 104, iter 2800, loss: 2.595144, top_1: 0.626914, top_k: 0.831562, samples/s: 1740.558 1612916154.2087815
train: epoch 104, iter 2900, loss: 2.470763, top_1: 0.624844, top_k: 0.832227, samples/s: 1749.679 1612916168.8400147
train: epoch 104, iter 3000, loss: 2.436513, top_1: 0.627852, top_k: 0.835703, samples/s: 1736.180 1612916183.5851464
train: epoch 104, iter 3100, loss: 2.427720, top_1: 0.630000, top_k: 0.838633, samples/s: 1732.184 1612916198.3640795
train: epoch 104, iter 3200, loss: 2.426131, top_1: 0.628008, top_k: 0.839844, samples/s: 1762.457 1612916212.8893137
train: epoch 104, iter 3300, loss: 2.655876, top_1: 0.632031, top_k: 0.837656, samples/s: 1747.564 1612916227.5382743
train: epoch 104, iter 3400, loss: 2.559177, top_1: 0.627188, top_k: 0.835195, samples/s: 1732.695 1612916242.3129196
train: epoch 104, iter 3500, loss: 2.514819, top_1: 0.637031, top_k: 0.839609, samples/s: 1746.544 1612916256.9708323
train: epoch 104, iter 3600, loss: 2.654964, top_1: 0.629648, top_k: 0.835508, samples/s: 1731.992 1612916271.7510772
train: epoch 104, iter 3700, loss: 2.490734, top_1: 0.630508, top_k: 0.837031, samples/s: 1754.175 1612916286.3448603
train: epoch 104, iter 3800, loss: 2.543693, top_1: 0.628828, top_k: 0.836719, samples/s: 1738.473 1612916301.0705106
train: epoch 104, iter 3900, loss: 2.556556, top_1: 0.626563, top_k: 0.836211, samples/s: 1741.176 1612916315.773188
train: epoch 104, iter 4000, loss: 2.581221, top_1: 0.625078, top_k: 0.835898, samples/s: 1745.221 1612916330.4418101
train: epoch 104, iter 4100, loss: 2.424025, top_1: 0.627578, top_k: 0.834648, samples/s: 1742.722 1612916345.1313932
train: epoch 104, iter 4200, loss: 2.479213, top_1: 0.623672, top_k: 0.832734, samples/s: 1745.308 1612916359.7993155
train: epoch 104, iter 4300, loss: 2.587815, top_1: 0.631016, top_k: 0.833711, samples/s: 1748.559 1612916374.4399173
train: epoch 104, iter 4400, loss: 2.632573, top_1: 0.622461, top_k: 0.831016, samples/s: 1732.446 1612916389.216778
train: epoch 104, iter 4500, loss: 2.589641, top_1: 0.638203, top_k: 0.841094, samples/s: 1735.282 1612916403.9694157
train: epoch 104, iter 4600, loss: 2.614395, top_1: 0.625625, top_k: 0.836211, samples/s: 1751.577 1612916418.5848286
train: epoch 104, iter 4700, loss: 2.531235, top_1: 0.626758, top_k: 0.836016, samples/s: 1751.614 1612916433.1998558
train: epoch 104, iter 4800, loss: 2.599582, top_1: 0.630234, top_k: 0.834297, samples/s: 1750.251 1612916447.8264778
train: epoch 104, iter 4900, loss: 2.557756, top_1: 0.628164, top_k: 0.836289, samples/s: 1736.556 1612916462.5682142
train: epoch 104, iter 5000, loss: 2.551857, top_1: 0.634336, top_k: 0.836875, samples/s: 1733.458 1612916477.3364
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_104.
validation: epoch 104, iter 195, top_1: 0.669712, top_k: 0.877324, samples/s: 2906.240 1612916494.890553
train: epoch 105, iter 100, loss: 2.472627, top_1: 0.637695, top_k: 0.844375, samples/s: 1755.273 1612916529.37899
train: epoch 105, iter 200, loss: 2.550426, top_1: 0.637305, top_k: 0.846758, samples/s: 1744.754 1612916544.0514638
train: epoch 105, iter 300, loss: 2.468632, top_1: 0.638711, top_k: 0.842148, samples/s: 1771.638 1612916558.501558
train: epoch 105, iter 400, loss: 2.473181, top_1: 0.635898, top_k: 0.846289, samples/s: 1761.708 1612916573.0327997
train: epoch 105, iter 500, loss: 2.549720, top_1: 0.640820, top_k: 0.843672, samples/s: 1763.342 1612916587.5506005
train: epoch 105, iter 600, loss: 2.469921, top_1: 0.642305, top_k: 0.841445, samples/s: 1743.808 1612916602.231243
train: epoch 105, iter 700, loss: 2.477972, top_1: 0.636719, top_k: 0.842500, samples/s: 1763.146 1612916616.7506745
train: epoch 105, iter 800, loss: 2.653847, top_1: 0.638164, top_k: 0.840781, samples/s: 1744.929 1612916631.4218695
train: epoch 105, iter 900, loss: 2.645109, top_1: 0.631914, top_k: 0.839453, samples/s: 1747.682 1612916646.0697706
train: epoch 105, iter 1000, loss: 2.597767, top_1: 0.635859, top_k: 0.839883, samples/s: 1748.119 1612916660.7140625
train: epoch 105, iter 1100, loss: 2.536071, top_1: 0.631289, top_k: 0.840000, samples/s: 1751.153 1612916675.3329954
train: epoch 105, iter 1200, loss: 2.764772, top_1: 0.635664, top_k: 0.838281, samples/s: 1747.189 1612916689.9850342
train: epoch 105, iter 1300, loss: 2.435245, top_1: 0.641523, top_k: 0.842070, samples/s: 1742.925 1612916704.6731079
train: epoch 105, iter 1400, loss: 2.433607, top_1: 0.638203, top_k: 0.840977, samples/s: 1744.501 1612916719.34772
train: epoch 105, iter 1500, loss: 2.258462, top_1: 0.635156, top_k: 0.840977, samples/s: 1750.801 1612916733.9696176
train: epoch 105, iter 1600, loss: 2.575995, top_1: 0.633828, top_k: 0.841484, samples/s: 1732.850 1612916748.7429852
train: epoch 105, iter 1700, loss: 2.653805, top_1: 0.640625, top_k: 0.842578, samples/s: 1754.786 1612916763.3316329
train: epoch 105, iter 1800, loss: 2.477310, top_1: 0.634609, top_k: 0.838398, samples/s: 1736.848 1612916778.071015
train: epoch 105, iter 1900, loss: 2.595210, top_1: 0.632344, top_k: 0.841211, samples/s: 1734.592 1612916792.8295248
train: epoch 105, iter 2000, loss: 2.497805, top_1: 0.629297, top_k: 0.833711, samples/s: 1754.553 1612916807.4200969
train: epoch 105, iter 2100, loss: 2.693641, top_1: 0.637188, top_k: 0.840742, samples/s: 1743.777 1612916822.1008651
train: epoch 105, iter 2200, loss: 2.383632, top_1: 0.627852, top_k: 0.835547, samples/s: 1743.468 1612916836.784223
train: epoch 105, iter 2300, loss: 2.632538, top_1: 0.632461, top_k: 0.839063, samples/s: 1733.223 1612916851.5543907
train: epoch 105, iter 2400, loss: 2.342801, top_1: 0.634492, top_k: 0.838477, samples/s: 1742.506 1612916866.2459025
train: epoch 105, iter 2500, loss: 2.633146, top_1: 0.628477, top_k: 0.830195, samples/s: 1739.117 1612916880.9660387
train: epoch 105, iter 2600, loss: 2.634273, top_1: 0.631367, top_k: 0.837227, samples/s: 1743.654 1612916895.6478
train: epoch 105, iter 2700, loss: 2.626078, top_1: 0.631719, top_k: 0.840625, samples/s: 1736.314 1612916910.3916848
train: epoch 105, iter 2800, loss: 2.735903, top_1: 0.632734, top_k: 0.838672, samples/s: 1742.136 1612916925.0863585
train: epoch 105, iter 2900, loss: 2.554851, top_1: 0.630000, top_k: 0.837773, samples/s: 1733.248 1612916939.856325
train: epoch 105, iter 3000, loss: 2.736425, top_1: 0.629570, top_k: 0.831719, samples/s: 1735.077 1612916954.6106505
train: epoch 105, iter 3100, loss: 2.598981, top_1: 0.632070, top_k: 0.838789, samples/s: 1755.594 1612916969.1926465
train: epoch 105, iter 3200, loss: 2.449702, top_1: 0.630195, top_k: 0.840977, samples/s: 1743.558 1612916983.875232
train: epoch 105, iter 3300, loss: 2.574237, top_1: 0.632227, top_k: 0.837969, samples/s: 1739.014 1612916998.596255
train: epoch 105, iter 3400, loss: 2.585699, top_1: 0.632812, top_k: 0.834141, samples/s: 1727.625 1612917013.4143314
train: epoch 105, iter 3500, loss: 2.447426, top_1: 0.633242, top_k: 0.834609, samples/s: 1745.109 1612917028.0838318
train: epoch 105, iter 3600, loss: 2.620845, top_1: 0.633359, top_k: 0.838242, samples/s: 1745.631 1612917042.7490845
train: epoch 105, iter 3700, loss: 2.627950, top_1: 0.628125, top_k: 0.834609, samples/s: 1735.158 1612917057.5027833
train: epoch 105, iter 3800, loss: 2.587272, top_1: 0.628203, top_k: 0.835313, samples/s: 1743.060 1612917072.1896033
train: epoch 105, iter 3900, loss: 2.615843, top_1: 0.626133, top_k: 0.836250, samples/s: 1738.189 1612917086.9175377
train: epoch 105, iter 4000, loss: 2.769846, top_1: 0.626641, top_k: 0.833789, samples/s: 1727.438 1612917101.7371922
train: epoch 105, iter 4100, loss: 2.619731, top_1: 0.630977, top_k: 0.837695, samples/s: 1729.648 1612917116.5379221
train: epoch 105, iter 4200, loss: 2.469266, top_1: 0.632578, top_k: 0.837617, samples/s: 1761.437 1612917131.0714483
train: epoch 105, iter 4300, loss: 2.559315, top_1: 0.625977, top_k: 0.834336, samples/s: 1736.858 1612917145.810682
train: epoch 105, iter 4400, loss: 2.714676, top_1: 0.633828, top_k: 0.837500, samples/s: 1749.539 1612917160.4430902
train: epoch 105, iter 4500, loss: 2.582090, top_1: 0.631641, top_k: 0.831797, samples/s: 1736.356 1612917175.1866555
train: epoch 105, iter 4600, loss: 2.542994, top_1: 0.632188, top_k: 0.841094, samples/s: 1742.345 1612917189.8795176
train: epoch 105, iter 4700, loss: 2.454750, top_1: 0.632578, top_k: 0.835898, samples/s: 1752.476 1612917204.4874158
train: epoch 105, iter 4800, loss: 2.493968, top_1: 0.629023, top_k: 0.831758, samples/s: 1737.223 1612917219.2235465
train: epoch 105, iter 4900, loss: 2.546226, top_1: 0.632812, top_k: 0.838633, samples/s: 1736.112 1612917233.969122
train: epoch 105, iter 5000, loss: 2.462699, top_1: 0.632695, top_k: 0.838086, samples/s: 1737.442 1612917248.7035055
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_105.
validation: epoch 105, iter 195, top_1: 0.665665, top_k: 0.877724, samples/s: 2868.950 1612917266.5550637
train: epoch 106, iter 100, loss: 2.380948, top_1: 0.638047, top_k: 0.842109, samples/s: 1731.482 1612917300.7931798
train: epoch 106, iter 200, loss: 2.335758, top_1: 0.634141, top_k: 0.840391, samples/s: 1768.547 1612917315.268336
train: epoch 106, iter 300, loss: 2.617729, top_1: 0.638555, top_k: 0.840313, samples/s: 1756.462 1612917329.8430195
train: epoch 106, iter 400, loss: 2.413262, top_1: 0.638828, top_k: 0.843516, samples/s: 1760.925 1612917344.3810678
train: epoch 106, iter 500, loss: 2.666850, top_1: 0.637617, top_k: 0.843203, samples/s: 1757.814 1612917358.9443989
train: epoch 106, iter 600, loss: 2.458075, top_1: 0.639102, top_k: 0.840742, samples/s: 1752.751 1612917373.5500262
train: epoch 106, iter 700, loss: 2.585800, top_1: 0.636406, top_k: 0.838945, samples/s: 1753.043 1612917388.1531928
train: epoch 106, iter 800, loss: 2.468184, top_1: 0.637266, top_k: 0.841133, samples/s: 1747.568 1612917402.802193
train: epoch 106, iter 900, loss: 2.563782, top_1: 0.633711, top_k: 0.841875, samples/s: 1747.126 1612917417.4547238
train: epoch 106, iter 1000, loss: 2.580940, top_1: 0.640391, top_k: 0.843477, samples/s: 1734.067 1612917432.2177572
train: epoch 106, iter 1100, loss: 2.472853, top_1: 0.634805, top_k: 0.840234, samples/s: 1721.776 1612917447.0866559
train: epoch 106, iter 1200, loss: 2.407415, top_1: 0.633867, top_k: 0.840469, samples/s: 1758.535 1612917461.6436765
train: epoch 106, iter 1300, loss: 2.534974, top_1: 0.640430, top_k: 0.843320, samples/s: 1736.827 1612917476.3831754
train: epoch 106, iter 1400, loss: 2.420235, top_1: 0.639453, top_k: 0.843516, samples/s: 1749.308 1612917491.0175161
train: epoch 106, iter 1500, loss: 2.629415, top_1: 0.637305, top_k: 0.838359, samples/s: 1734.973 1612917505.7728138
train: epoch 106, iter 1600, loss: 2.579303, top_1: 0.634219, top_k: 0.843125, samples/s: 1731.233 1612917520.5599976
train: epoch 106, iter 1700, loss: 2.543459, top_1: 0.630352, top_k: 0.840820, samples/s: 1741.848 1612917535.2569838
train: epoch 106, iter 1800, loss: 2.340388, top_1: 0.634570, top_k: 0.838945, samples/s: 1734.616 1612917550.015383
train: epoch 106, iter 1900, loss: 2.462501, top_1: 0.631445, top_k: 0.839141, samples/s: 1749.242 1612917564.6502914
train: epoch 106, iter 2000, loss: 2.523525, top_1: 0.630195, top_k: 0.835586, samples/s: 1739.085 1612917579.3705733
train: epoch 106, iter 2100, loss: 2.700484, top_1: 0.630859, top_k: 0.838125, samples/s: 1736.843 1612917594.109967
train: epoch 106, iter 2200, loss: 2.410826, top_1: 0.638320, top_k: 0.841562, samples/s: 1744.493 1612917608.7848163
train: epoch 106, iter 2300, loss: 2.468889, top_1: 0.633867, top_k: 0.839063, samples/s: 1743.020 1612917623.4718783
train: epoch 106, iter 2400, loss: 2.661203, top_1: 0.629336, top_k: 0.837695, samples/s: 1743.877 1612917638.1518848
train: epoch 106, iter 2500, loss: 2.638050, top_1: 0.635625, top_k: 0.840469, samples/s: 1741.529 1612917652.8515472
train: epoch 106, iter 2600, loss: 2.530113, top_1: 0.631523, top_k: 0.839258, samples/s: 1742.317 1612917667.544636
train: epoch 106, iter 2700, loss: 2.546626, top_1: 0.636641, top_k: 0.843555, samples/s: 1741.274 1612917682.2465658
train: epoch 106, iter 2800, loss: 2.514161, top_1: 0.631211, top_k: 0.837617, samples/s: 1740.431 1612917696.9555433
train: epoch 106, iter 2900, loss: 2.496694, top_1: 0.632109, top_k: 0.834258, samples/s: 1745.264 1612917711.6237535
train: epoch 106, iter 3000, loss: 2.537695, top_1: 0.638125, top_k: 0.838477, samples/s: 1737.530 1612917726.3574142
train: epoch 106, iter 3100, loss: 2.623851, top_1: 0.633750, top_k: 0.838828, samples/s: 1759.983 1612917740.902913
train: epoch 106, iter 3200, loss: 2.282228, top_1: 0.638242, top_k: 0.837969, samples/s: 1743.924 1612917755.5825424
train: epoch 106, iter 3300, loss: 2.608164, top_1: 0.629492, top_k: 0.834922, samples/s: 1749.773 1612917770.2129538
train: epoch 106, iter 3400, loss: 2.478858, top_1: 0.637461, top_k: 0.837070, samples/s: 1743.549 1612917784.8956792
train: epoch 106, iter 3500, loss: 2.452035, top_1: 0.638555, top_k: 0.838203, samples/s: 1737.656 1612917799.628157
train: epoch 106, iter 3600, loss: 2.345892, top_1: 0.634180, top_k: 0.840547, samples/s: 1747.275 1612917814.2795246
train: epoch 106, iter 3700, loss: 2.296575, top_1: 0.633750, top_k: 0.839297, samples/s: 1740.827 1612917828.9852264
train: epoch 106, iter 3800, loss: 2.474436, top_1: 0.633281, top_k: 0.840313, samples/s: 1740.294 1612917843.695299
train: epoch 106, iter 3900, loss: 2.570172, top_1: 0.631094, top_k: 0.841719, samples/s: 1738.055 1612917858.42451
train: epoch 106, iter 4000, loss: 2.613650, top_1: 0.631992, top_k: 0.839336, samples/s: 1751.684 1612917873.0389576
train: epoch 106, iter 4100, loss: 2.615024, top_1: 0.637500, top_k: 0.840586, samples/s: 1743.644 1612917887.7209167
train: epoch 106, iter 4200, loss: 2.583826, top_1: 0.632852, top_k: 0.839883, samples/s: 1746.976 1612917902.3747027
train: epoch 106, iter 4300, loss: 2.512167, top_1: 0.634453, top_k: 0.840234, samples/s: 1742.320 1612917917.0678277
train: epoch 106, iter 4400, loss: 2.668045, top_1: 0.635195, top_k: 0.838203, samples/s: 1737.644 1612917931.8004074
train: epoch 106, iter 4500, loss: 2.524981, top_1: 0.630508, top_k: 0.837891, samples/s: 1732.662 1612917946.5753329
train: epoch 106, iter 4600, loss: 2.545707, top_1: 0.631992, top_k: 0.840117, samples/s: 1734.048 1612917961.33856
train: epoch 106, iter 4700, loss: 2.337576, top_1: 0.638516, top_k: 0.838086, samples/s: 1740.609 1612917976.0460026
train: epoch 106, iter 4800, loss: 2.625805, top_1: 0.630195, top_k: 0.837891, samples/s: 1752.025 1612917990.6576114
train: epoch 106, iter 4900, loss: 2.537970, top_1: 0.637852, top_k: 0.836836, samples/s: 1750.165 1612918005.2849193
train: epoch 106, iter 5000, loss: 2.466990, top_1: 0.632266, top_k: 0.839414, samples/s: 1738.827 1612918020.007398
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_106.
validation: epoch 106, iter 195, top_1: 0.672095, top_k: 0.880569, samples/s: 2888.999 1612918037.7301342
train: epoch 107, iter 100, loss: 2.376750, top_1: 0.646523, top_k: 0.845039, samples/s: 1744.008 1612918072.3544092
train: epoch 107, iter 200, loss: 2.488023, top_1: 0.646055, top_k: 0.846719, samples/s: 1753.803 1612918086.9512625
train: epoch 107, iter 300, loss: 2.435006, top_1: 0.638945, top_k: 0.844414, samples/s: 1759.864 1612918101.4977393
train: epoch 107, iter 400, loss: 2.575980, top_1: 0.643398, top_k: 0.845234, samples/s: 1753.422 1612918116.0977535
train: epoch 107, iter 500, loss: 2.469268, top_1: 0.638672, top_k: 0.841641, samples/s: 1764.461 1612918130.6064427
train: epoch 107, iter 600, loss: 2.556859, top_1: 0.641133, top_k: 0.841094, samples/s: 1752.322 1612918145.2156086
train: epoch 107, iter 700, loss: 2.247271, top_1: 0.636484, top_k: 0.841719, samples/s: 1750.014 1612918159.8440926
train: epoch 107, iter 800, loss: 2.486223, top_1: 0.643242, top_k: 0.844102, samples/s: 1743.479 1612918174.5273077
train: epoch 107, iter 900, loss: 2.514531, top_1: 0.638437, top_k: 0.844727, samples/s: 1726.712 1612918189.353282
train: epoch 107, iter 1000, loss: 2.360025, top_1: 0.641445, top_k: 0.845430, samples/s: 1752.969 1612918203.957014
train: epoch 107, iter 1100, loss: 2.394167, top_1: 0.641641, top_k: 0.844688, samples/s: 1731.785 1612918218.7394052
train: epoch 107, iter 1200, loss: 2.393966, top_1: 0.645156, top_k: 0.846641, samples/s: 1743.249 1612918233.4246297
train: epoch 107, iter 1300, loss: 2.625659, top_1: 0.640898, top_k: 0.842344, samples/s: 1735.184 1612918248.1781604
train: epoch 107, iter 1400, loss: 2.479984, top_1: 0.641875, top_k: 0.840234, samples/s: 1747.385 1612918262.828603
train: epoch 107, iter 1500, loss: 2.375197, top_1: 0.636211, top_k: 0.841211, samples/s: 1739.321 1612918277.5469773
train: epoch 107, iter 1600, loss: 2.436030, top_1: 0.635508, top_k: 0.839531, samples/s: 1735.664 1612918292.296395
train: epoch 107, iter 1700, loss: 2.484040, top_1: 0.638828, top_k: 0.842031, samples/s: 1742.267 1612918306.9898546
train: epoch 107, iter 1800, loss: 2.531004, top_1: 0.640977, top_k: 0.843203, samples/s: 1743.560 1612918321.67248
train: epoch 107, iter 1900, loss: 2.440039, top_1: 0.638008, top_k: 0.842422, samples/s: 1746.709 1612918336.3286018
train: epoch 107, iter 2000, loss: 2.686470, top_1: 0.640703, top_k: 0.845664, samples/s: 1744.378 1612918351.0043192
train: epoch 107, iter 2100, loss: 2.464236, top_1: 0.637461, top_k: 0.842461, samples/s: 1728.327 1612918365.816402
train: epoch 107, iter 2200, loss: 2.593240, top_1: 0.637109, top_k: 0.843711, samples/s: 1730.272 1612918380.6117685
train: epoch 107, iter 2300, loss: 2.478117, top_1: 0.631953, top_k: 0.841836, samples/s: 1742.186 1612918395.305957
train: epoch 107, iter 2400, loss: 2.569477, top_1: 0.638711, top_k: 0.841758, samples/s: 1746.036 1612918409.967705
train: epoch 107, iter 2500, loss: 2.479134, top_1: 0.637383, top_k: 0.840820, samples/s: 1743.497 1612918424.6508293
train: epoch 107, iter 2600, loss: 2.558556, top_1: 0.640703, top_k: 0.841953, samples/s: 1724.950 1612918439.491902
train: epoch 107, iter 2700, loss: 2.456026, top_1: 0.641172, top_k: 0.843594, samples/s: 1743.031 1612918454.1788557
train: epoch 107, iter 2800, loss: 2.474458, top_1: 0.633125, top_k: 0.839727, samples/s: 1740.061 1612918468.891006
train: epoch 107, iter 2900, loss: 2.585639, top_1: 0.638203, top_k: 0.842305, samples/s: 1742.503 1612918483.5824938
train: epoch 107, iter 3000, loss: 2.514857, top_1: 0.635000, top_k: 0.842656, samples/s: 1732.995 1612918498.354603
train: epoch 107, iter 3100, loss: 2.551479, top_1: 0.640820, top_k: 0.842031, samples/s: 1732.340 1612918513.132413
train: epoch 107, iter 3200, loss: 2.640546, top_1: 0.641367, top_k: 0.842969, samples/s: 1746.018 1612918527.7947102
train: epoch 107, iter 3300, loss: 2.648461, top_1: 0.634180, top_k: 0.840625, samples/s: 1743.212 1612918542.4797814
train: epoch 107, iter 3400, loss: 2.571560, top_1: 0.634727, top_k: 0.838477, samples/s: 1735.563 1612918557.2300358
train: epoch 107, iter 3500, loss: 2.560829, top_1: 0.629336, top_k: 0.840117, samples/s: 1745.214 1612918571.8987257
train: epoch 107, iter 3600, loss: 2.462280, top_1: 0.635000, top_k: 0.839727, samples/s: 1748.912 1612918586.5364385
train: epoch 107, iter 3700, loss: 2.631433, top_1: 0.628008, top_k: 0.837500, samples/s: 1738.714 1612918601.259917
train: epoch 107, iter 3800, loss: 2.497663, top_1: 0.625977, top_k: 0.834883, samples/s: 1735.105 1612918616.0144203
train: epoch 107, iter 3900, loss: 2.468512, top_1: 0.638789, top_k: 0.837969, samples/s: 1740.670 1612918630.7210736
train: epoch 107, iter 4000, loss: 2.496239, top_1: 0.638789, top_k: 0.843281, samples/s: 1742.411 1612918645.4133449
train: epoch 107, iter 4100, loss: 2.704868, top_1: 0.636836, top_k: 0.838125, samples/s: 1734.931 1612918660.169076
train: epoch 107, iter 4200, loss: 2.485895, top_1: 0.635000, top_k: 0.840625, samples/s: 1742.433 1612918674.861087
train: epoch 107, iter 4300, loss: 2.533209, top_1: 0.639219, top_k: 0.841328, samples/s: 1729.870 1612918689.6599762
train: epoch 107, iter 4400, loss: 2.659981, top_1: 0.636719, top_k: 0.842227, samples/s: 1747.725 1612918704.3075218
train: epoch 107, iter 4500, loss: 2.506144, top_1: 0.632656, top_k: 0.838555, samples/s: 1736.215 1612918719.0522764
train: epoch 107, iter 4600, loss: 2.443132, top_1: 0.632852, top_k: 0.839805, samples/s: 1739.905 1612918733.7657018
train: epoch 107, iter 4700, loss: 2.524328, top_1: 0.635859, top_k: 0.839375, samples/s: 1745.478 1612918748.4321377
train: epoch 107, iter 4800, loss: 2.461299, top_1: 0.634141, top_k: 0.838828, samples/s: 1740.249 1612918763.1427188
train: epoch 107, iter 4900, loss: 2.573579, top_1: 0.636328, top_k: 0.841758, samples/s: 1732.786 1612918777.9165666
train: epoch 107, iter 5000, loss: 2.323682, top_1: 0.643125, top_k: 0.845547, samples/s: 1738.754 1612918792.6397831
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_107.
validation: epoch 107, iter 195, top_1: 0.674639, top_k: 0.881851, samples/s: 2948.717 1612918809.9928555
train: epoch 108, iter 100, loss: 2.435643, top_1: 0.645352, top_k: 0.845781, samples/s: 1755.435 1612918844.6349096
train: epoch 108, iter 200, loss: 2.451929, top_1: 0.640586, top_k: 0.847734, samples/s: 1749.080 1612918859.2710865
train: epoch 108, iter 300, loss: 2.671808, top_1: 0.647383, top_k: 0.846445, samples/s: 1756.147 1612918873.8484764
train: epoch 108, iter 400, loss: 2.482928, top_1: 0.640195, top_k: 0.844961, samples/s: 1759.388 1612918888.3991356
train: epoch 108, iter 500, loss: 2.579318, top_1: 0.641484, top_k: 0.843164, samples/s: 1761.526 1612918902.931822
train: epoch 108, iter 600, loss: 2.505355, top_1: 0.642070, top_k: 0.844844, samples/s: 1758.270 1612918917.4916608
train: epoch 108, iter 700, loss: 2.440746, top_1: 0.642188, top_k: 0.843594, samples/s: 1745.515 1612918932.157753
train: epoch 108, iter 800, loss: 2.289067, top_1: 0.643516, top_k: 0.846562, samples/s: 1736.508 1612918946.8999825
train: epoch 108, iter 900, loss: 2.569128, top_1: 0.644453, top_k: 0.845820, samples/s: 1757.266 1612918961.4681144
train: epoch 108, iter 1000, loss: 2.294175, top_1: 0.641289, top_k: 0.845664, samples/s: 1733.482 1612918976.236025
train: epoch 108, iter 1100, loss: 2.493009, top_1: 0.642539, top_k: 0.843359, samples/s: 1751.169 1612918990.8548715
train: epoch 108, iter 1200, loss: 2.619762, top_1: 0.641406, top_k: 0.845703, samples/s: 1728.391 1612919005.6664019
train: epoch 108, iter 1300, loss: 2.569707, top_1: 0.639336, top_k: 0.841836, samples/s: 1738.050 1612919020.3954468
train: epoch 108, iter 1400, loss: 2.339243, top_1: 0.641016, top_k: 0.844258, samples/s: 1744.294 1612919035.0719976
train: epoch 108, iter 1500, loss: 2.344425, top_1: 0.638633, top_k: 0.840938, samples/s: 1739.658 1612919049.7874105
train: epoch 108, iter 1600, loss: 2.471939, top_1: 0.644531, top_k: 0.843398, samples/s: 1726.099 1612919064.6185272
train: epoch 108, iter 1700, loss: 2.481518, top_1: 0.641367, top_k: 0.844609, samples/s: 1739.781 1612919079.3330905
train: epoch 108, iter 1800, loss: 2.525234, top_1: 0.638633, top_k: 0.844102, samples/s: 1724.186 1612919094.180627
train: epoch 108, iter 1900, loss: 2.412766, top_1: 0.646641, top_k: 0.846680, samples/s: 1751.444 1612919108.797244
train: epoch 108, iter 2000, loss: 2.423532, top_1: 0.631250, top_k: 0.840820, samples/s: 1756.061 1612919123.3752306
train: epoch 108, iter 2100, loss: 2.610713, top_1: 0.640820, top_k: 0.843047, samples/s: 1746.538 1612919138.0328388
train: epoch 108, iter 2200, loss: 2.416152, top_1: 0.639492, top_k: 0.841484, samples/s: 1735.286 1612919152.7854383
train: epoch 108, iter 2300, loss: 2.470901, top_1: 0.639570, top_k: 0.844492, samples/s: 1737.497 1612919167.5193584
train: epoch 108, iter 2400, loss: 2.456417, top_1: 0.637539, top_k: 0.841992, samples/s: 1731.302 1612919182.3059301
train: epoch 108, iter 2500, loss: 2.598944, top_1: 0.640430, top_k: 0.843711, samples/s: 1748.611 1612919196.9460602
train: epoch 108, iter 2600, loss: 2.414719, top_1: 0.637305, top_k: 0.840391, samples/s: 1739.414 1612919211.6635878
train: epoch 108, iter 2700, loss: 2.401855, top_1: 0.633789, top_k: 0.839531, samples/s: 1743.095 1612919226.35019
train: epoch 108, iter 2800, loss: 2.485719, top_1: 0.635195, top_k: 0.839727, samples/s: 1731.107 1612919241.1383832
train: epoch 108, iter 2900, loss: 2.599872, top_1: 0.636602, top_k: 0.837695, samples/s: 1740.803 1612919255.8442938
train: epoch 108, iter 3000, loss: 2.475565, top_1: 0.640039, top_k: 0.842891, samples/s: 1742.830 1612919270.5329673
train: epoch 108, iter 3100, loss: 2.299195, top_1: 0.637656, top_k: 0.840117, samples/s: 1744.536 1612919285.207316
train: epoch 108, iter 3200, loss: 2.693423, top_1: 0.636602, top_k: 0.842734, samples/s: 1745.355 1612919299.87487
train: epoch 108, iter 3300, loss: 2.537584, top_1: 0.641719, top_k: 0.844102, samples/s: 1744.689 1612919314.5479586
train: epoch 108, iter 3400, loss: 2.396943, top_1: 0.640039, top_k: 0.843242, samples/s: 1743.044 1612919329.2349432
train: epoch 108, iter 3500, loss: 2.485116, top_1: 0.631758, top_k: 0.841914, samples/s: 1735.224 1612919343.9880354
train: epoch 108, iter 3600, loss: 2.417171, top_1: 0.637461, top_k: 0.841836, samples/s: 1729.797 1612919358.7874491
train: epoch 108, iter 3700, loss: 2.419939, top_1: 0.634531, top_k: 0.840664, samples/s: 1747.330 1612919373.4383862
train: epoch 108, iter 3800, loss: 2.349413, top_1: 0.632695, top_k: 0.837617, samples/s: 1739.092 1612919388.1587873
train: epoch 108, iter 3900, loss: 2.590915, top_1: 0.635312, top_k: 0.840391, samples/s: 1745.915 1612919402.821522
train: epoch 108, iter 4000, loss: 2.553724, top_1: 0.641797, top_k: 0.845938, samples/s: 1742.588 1612919417.5122762
train: epoch 108, iter 4100, loss: 2.482338, top_1: 0.637656, top_k: 0.840859, samples/s: 1738.605 1612919432.2368333
train: epoch 108, iter 4200, loss: 2.599840, top_1: 0.642461, top_k: 0.843477, samples/s: 1737.007 1612919446.9747462
train: epoch 108, iter 4300, loss: 2.541761, top_1: 0.640352, top_k: 0.842266, samples/s: 1746.221 1612919461.6349638
train: epoch 108, iter 4400, loss: 2.534697, top_1: 0.639453, top_k: 0.839375, samples/s: 1734.797 1612919476.3917172
train: epoch 108, iter 4500, loss: 2.553529, top_1: 0.640781, top_k: 0.844063, samples/s: 1749.125 1612919491.0276296
train: epoch 108, iter 4600, loss: 2.375224, top_1: 0.638281, top_k: 0.840313, samples/s: 1742.003 1612919505.7234316
train: epoch 108, iter 4700, loss: 2.467297, top_1: 0.644766, top_k: 0.842070, samples/s: 1732.999 1612919520.4954212
train: epoch 108, iter 4800, loss: 2.531775, top_1: 0.635508, top_k: 0.841484, samples/s: 1729.851 1612919535.294387
train: epoch 108, iter 4900, loss: 2.346384, top_1: 0.631250, top_k: 0.840820, samples/s: 1753.103 1612919549.897118
train: epoch 108, iter 5000, loss: 2.425138, top_1: 0.641367, top_k: 0.844492, samples/s: 1742.425 1612919564.5892878
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_108.
validation: epoch 108, iter 195, top_1: 0.679107, top_k: 0.884075, samples/s: 2830.426 1612919582.6461442
train: epoch 109, iter 100, loss: 2.379429, top_1: 0.648906, top_k: 0.848516, samples/s: 1743.276 1612919622.8104072
train: epoch 109, iter 200, loss: 2.494648, top_1: 0.645664, top_k: 0.848359, samples/s: 1759.918 1612919637.3564782
train: epoch 109, iter 300, loss: 2.508585, top_1: 0.646289, top_k: 0.849219, samples/s: 1756.668 1612919651.929607
train: epoch 109, iter 400, loss: 2.547757, top_1: 0.653281, top_k: 0.853594, samples/s: 1755.461 1612919666.512779
train: epoch 109, iter 500, loss: 2.387572, top_1: 0.640586, top_k: 0.846211, samples/s: 1769.003 1612919680.9840527
train: epoch 109, iter 600, loss: 2.531633, top_1: 0.648125, top_k: 0.849844, samples/s: 1755.053 1612919695.5705307
train: epoch 109, iter 700, loss: 2.501206, top_1: 0.638984, top_k: 0.843672, samples/s: 1752.422 1612919710.1788182
train: epoch 109, iter 800, loss: 2.418184, top_1: 0.642656, top_k: 0.847500, samples/s: 1760.956 1612919724.7164478
train: epoch 109, iter 900, loss: 2.320230, top_1: 0.644023, top_k: 0.849883, samples/s: 1751.405 1612919739.3332512
train: epoch 109, iter 1000, loss: 2.530589, top_1: 0.637578, top_k: 0.845000, samples/s: 1741.098 1612919754.0366316
train: epoch 109, iter 1100, loss: 2.549191, top_1: 0.644023, top_k: 0.846992, samples/s: 1730.481 1612919768.8301275
train: epoch 109, iter 1200, loss: 2.657768, top_1: 0.643203, top_k: 0.844805, samples/s: 1720.535 1612919783.7092295
train: epoch 109, iter 1300, loss: 2.359034, top_1: 0.647188, top_k: 0.847109, samples/s: 1753.514 1612919798.308497
train: epoch 109, iter 1400, loss: 2.354680, top_1: 0.648594, top_k: 0.846406, samples/s: 1735.170 1612919813.0620947
train: epoch 109, iter 1500, loss: 2.519266, top_1: 0.641367, top_k: 0.848281, samples/s: 1742.899 1612919827.7502577
train: epoch 109, iter 1600, loss: 2.491193, top_1: 0.641641, top_k: 0.845703, samples/s: 1750.931 1612919842.3710551
train: epoch 109, iter 1700, loss: 2.327778, top_1: 0.643984, top_k: 0.842969, samples/s: 1748.070 1612919857.0157924
train: epoch 109, iter 1800, loss: 2.427744, top_1: 0.643477, top_k: 0.844727, samples/s: 1734.346 1612919871.776423
train: epoch 109, iter 1900, loss: 2.330662, top_1: 0.648750, top_k: 0.850898, samples/s: 1743.808 1612919886.456924
train: epoch 109, iter 2000, loss: 2.439688, top_1: 0.639258, top_k: 0.842930, samples/s: 1743.125 1612919901.143147
train: epoch 109, iter 2100, loss: 2.552712, top_1: 0.639219, top_k: 0.845391, samples/s: 1744.457 1612919915.8182914
train: epoch 109, iter 2200, loss: 2.369397, top_1: 0.643008, top_k: 0.846914, samples/s: 1741.110 1612919930.521536
train: epoch 109, iter 2300, loss: 2.442217, top_1: 0.634297, top_k: 0.841133, samples/s: 1737.276 1612919945.2571542
train: epoch 109, iter 2400, loss: 2.499529, top_1: 0.640938, top_k: 0.845352, samples/s: 1746.787 1612919959.912674
train: epoch 109, iter 2500, loss: 2.328194, top_1: 0.640820, top_k: 0.844688, samples/s: 1744.380 1612919974.5883694
train: epoch 109, iter 2600, loss: 2.625835, top_1: 0.642305, top_k: 0.844961, samples/s: 1735.607 1612919989.338271
train: epoch 109, iter 2700, loss: 2.495671, top_1: 0.637734, top_k: 0.841562, samples/s: 1737.436 1612920004.072615
train: epoch 109, iter 2800, loss: 2.620036, top_1: 0.641055, top_k: 0.844531, samples/s: 1752.462 1612920018.6806557
train: epoch 109, iter 2900, loss: 2.738047, top_1: 0.640195, top_k: 0.841836, samples/s: 1745.083 1612920033.3504512
train: epoch 109, iter 3000, loss: 2.660376, top_1: 0.636563, top_k: 0.842656, samples/s: 1740.717 1612920048.0570977
train: epoch 109, iter 3100, loss: 2.343204, top_1: 0.644570, top_k: 0.842578, samples/s: 1741.334 1612920062.758345
train: epoch 109, iter 3200, loss: 2.467354, top_1: 0.642969, top_k: 0.846680, samples/s: 1744.562 1612920077.4325242
train: epoch 109, iter 3300, loss: 2.778093, top_1: 0.644336, top_k: 0.843359, samples/s: 1742.535 1612920092.1237674
train: epoch 109, iter 3400, loss: 2.423166, top_1: 0.638672, top_k: 0.844414, samples/s: 1745.386 1612920106.791062
train: epoch 109, iter 3500, loss: 2.472302, top_1: 0.637383, top_k: 0.842852, samples/s: 1736.400 1612920121.5342255
train: epoch 109, iter 3600, loss: 2.454101, top_1: 0.643789, top_k: 0.845742, samples/s: 1714.796 1612920136.4632356
train: epoch 109, iter 3700, loss: 2.500964, top_1: 0.644297, top_k: 0.844609, samples/s: 1753.437 1612920151.0629447
train: epoch 109, iter 3800, loss: 2.679618, top_1: 0.637109, top_k: 0.842109, samples/s: 1748.464 1612920165.7046545
train: epoch 109, iter 3900, loss: 2.440309, top_1: 0.636641, top_k: 0.843984, samples/s: 1740.918 1612920180.4093187
train: epoch 109, iter 4000, loss: 2.435293, top_1: 0.640469, top_k: 0.841836, samples/s: 1745.534 1612920195.0752418
train: epoch 109, iter 4100, loss: 2.672943, top_1: 0.636133, top_k: 0.845664, samples/s: 1734.886 1612920209.8312619
train: epoch 109, iter 4200, loss: 2.497886, top_1: 0.640664, top_k: 0.843281, samples/s: 1760.868 1612920224.3695712
train: epoch 109, iter 4300, loss: 2.688172, top_1: 0.634102, top_k: 0.838750, samples/s: 1743.952 1612920239.0491555
train: epoch 109, iter 4400, loss: 2.662475, top_1: 0.637500, top_k: 0.843594, samples/s: 1748.850 1612920253.6870599
train: epoch 109, iter 4500, loss: 2.543554, top_1: 0.638984, top_k: 0.843242, samples/s: 1727.326 1612920268.507658
train: epoch 109, iter 4600, loss: 2.726535, top_1: 0.639922, top_k: 0.846719, samples/s: 1739.360 1612920283.2262552
train: epoch 109, iter 4700, loss: 2.663406, top_1: 0.644648, top_k: 0.846367, samples/s: 1753.424 1612920297.8257282
train: epoch 109, iter 4800, loss: 2.763070, top_1: 0.636484, top_k: 0.837969, samples/s: 1747.045 1612920312.4790065
train: epoch 109, iter 4900, loss: 2.557135, top_1: 0.639258, top_k: 0.842617, samples/s: 1743.552 1612920327.161821
train: epoch 109, iter 5000, loss: 2.384479, top_1: 0.648203, top_k: 0.848398, samples/s: 1725.199 1612920342.0009363
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_109.
validation: epoch 109, iter 195, top_1: 0.678425, top_k: 0.883994, samples/s: 2834.938 1612920359.9679885
train: epoch 110, iter 100, loss: 2.501073, top_1: 0.650039, top_k: 0.847500, samples/s: 1759.939 1612920394.4212615
train: epoch 110, iter 200, loss: 2.464511, top_1: 0.656055, top_k: 0.854023, samples/s: 1757.278 1612920408.9894416
train: epoch 110, iter 300, loss: 2.513321, top_1: 0.652930, top_k: 0.849531, samples/s: 1746.333 1612920423.6485164
train: epoch 110, iter 400, loss: 2.552807, top_1: 0.649414, top_k: 0.851914, samples/s: 1741.210 1612920438.3509607
train: epoch 110, iter 500, loss: 2.581423, top_1: 0.642852, top_k: 0.846406, samples/s: 1776.134 1612920452.7646947
train: epoch 110, iter 600, loss: 2.426536, top_1: 0.643867, top_k: 0.849180, samples/s: 1758.438 1612920467.322614
train: epoch 110, iter 700, loss: 2.336107, top_1: 0.658477, top_k: 0.850273, samples/s: 1749.454 1612920481.9565804
train: epoch 110, iter 800, loss: 2.733756, top_1: 0.647461, top_k: 0.848437, samples/s: 1745.779 1612920496.6197064
train: epoch 110, iter 900, loss: 2.566985, top_1: 0.652383, top_k: 0.850820, samples/s: 1743.973 1612920511.298884
train: epoch 110, iter 1000, loss: 2.439153, top_1: 0.644141, top_k: 0.846680, samples/s: 1742.579 1612920525.9897418
train: epoch 110, iter 1100, loss: 2.483179, top_1: 0.646914, top_k: 0.848008, samples/s: 1739.263 1612920540.7086372
train: epoch 110, iter 1200, loss: 2.381442, top_1: 0.654453, top_k: 0.850977, samples/s: 1727.022 1612920555.531771
train: epoch 110, iter 1300, loss: 2.288594, top_1: 0.647344, top_k: 0.847500, samples/s: 1748.484 1612920570.1730902
train: epoch 110, iter 1400, loss: 2.484227, top_1: 0.647188, top_k: 0.843789, samples/s: 1731.317 1612920584.9595213
train: epoch 110, iter 1500, loss: 2.392070, top_1: 0.647813, top_k: 0.847852, samples/s: 1746.596 1612920599.616585
train: epoch 110, iter 1600, loss: 2.595164, top_1: 0.643828, top_k: 0.845859, samples/s: 1737.601 1612920614.3495073
train: epoch 110, iter 1700, loss: 2.388600, top_1: 0.644687, top_k: 0.846133, samples/s: 1730.505 1612920629.142974
train: epoch 110, iter 1800, loss: 2.253647, top_1: 0.646211, top_k: 0.847266, samples/s: 1751.249 1612920643.7609975
train: epoch 110, iter 1900, loss: 2.357754, top_1: 0.643516, top_k: 0.845469, samples/s: 1742.524 1612920658.4523497
train: epoch 110, iter 2000, loss: 2.375996, top_1: 0.639609, top_k: 0.848281, samples/s: 1743.686 1612920673.1338902
train: epoch 110, iter 2100, loss: 2.572156, top_1: 0.647656, top_k: 0.844219, samples/s: 1727.421 1612920687.9536705
train: epoch 110, iter 2200, loss: 2.454585, top_1: 0.640000, top_k: 0.845742, samples/s: 1756.003 1612920702.5322433
train: epoch 110, iter 2300, loss: 2.506681, top_1: 0.643789, top_k: 0.850469, samples/s: 1739.928 1612920717.2454762
train: epoch 110, iter 2400, loss: 2.357385, top_1: 0.638633, top_k: 0.838906, samples/s: 1733.932 1612920732.0096107
train: epoch 110, iter 2500, loss: 2.634244, top_1: 0.645156, top_k: 0.844844, samples/s: 1751.635 1612920746.6245215
train: epoch 110, iter 2600, loss: 2.417043, top_1: 0.644453, top_k: 0.845234, samples/s: 1745.314 1612920761.2923968
train: epoch 110, iter 2700, loss: 2.350176, top_1: 0.642070, top_k: 0.841836, samples/s: 1737.909 1612920776.0227423
train: epoch 110, iter 2800, loss: 2.408447, top_1: 0.643359, top_k: 0.847109, samples/s: 1745.909 1612920790.6856437
train: epoch 110, iter 2900, loss: 2.510211, top_1: 0.641289, top_k: 0.846680, samples/s: 1738.856 1612920805.407885
train: epoch 110, iter 3000, loss: 2.392836, top_1: 0.642500, top_k: 0.845742, samples/s: 1749.460 1612920820.041005
train: epoch 110, iter 3100, loss: 2.439883, top_1: 0.641719, top_k: 0.843555, samples/s: 1746.164 1612920834.7016597
train: epoch 110, iter 3200, loss: 2.373227, top_1: 0.641367, top_k: 0.843750, samples/s: 1739.738 1612920849.4165332
train: epoch 110, iter 3300, loss: 2.256461, top_1: 0.644062, top_k: 0.849648, samples/s: 1741.040 1612920864.1204045
train: epoch 110, iter 3400, loss: 2.373423, top_1: 0.642109, top_k: 0.844180, samples/s: 1742.884 1612920878.8087466
train: epoch 110, iter 3500, loss: 2.557486, top_1: 0.643242, top_k: 0.843477, samples/s: 1741.666 1612920893.5073717
train: epoch 110, iter 3600, loss: 2.319682, top_1: 0.636328, top_k: 0.843398, samples/s: 1741.840 1612920908.2044296
train: epoch 110, iter 3700, loss: 2.505174, top_1: 0.639219, top_k: 0.838477, samples/s: 1732.911 1612920922.977253
train: epoch 110, iter 3800, loss: 2.294147, top_1: 0.641016, top_k: 0.843789, samples/s: 1741.001 1612920937.6813655
train: epoch 110, iter 3900, loss: 2.450222, top_1: 0.639531, top_k: 0.841680, samples/s: 1744.578 1612920952.355398
train: epoch 110, iter 4000, loss: 2.419312, top_1: 0.641719, top_k: 0.841914, samples/s: 1747.960 1612920967.001045
train: epoch 110, iter 4100, loss: 2.529930, top_1: 0.641094, top_k: 0.845117, samples/s: 1735.475 1612920981.7520819
train: epoch 110, iter 4200, loss: 2.631685, top_1: 0.645977, top_k: 0.847969, samples/s: 1746.088 1612920996.4133978
train: epoch 110, iter 4300, loss: 2.426726, top_1: 0.639180, top_k: 0.844414, samples/s: 1731.246 1612921011.2004287
train: epoch 110, iter 4400, loss: 2.357459, top_1: 0.644375, top_k: 0.846211, samples/s: 1748.771 1612921025.8393593
train: epoch 110, iter 4500, loss: 2.466144, top_1: 0.642617, top_k: 0.844961, samples/s: 1736.141 1612921040.5847406
train: epoch 110, iter 4600, loss: 2.552225, top_1: 0.636289, top_k: 0.842539, samples/s: 1754.148 1612921055.1786306
train: epoch 110, iter 4700, loss: 2.480463, top_1: 0.640508, top_k: 0.844609, samples/s: 1737.250 1612921069.9148004
train: epoch 110, iter 4800, loss: 2.502155, top_1: 0.635938, top_k: 0.840430, samples/s: 1738.937 1612921084.6362824
train: epoch 110, iter 4900, loss: 2.445543, top_1: 0.644102, top_k: 0.844727, samples/s: 1740.068 1612921099.3482974
train: epoch 110, iter 5000, loss: 2.404471, top_1: 0.650273, top_k: 0.843984, samples/s: 1749.267 1612921113.9829547
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_110.
validation: epoch 110, iter 195, top_1: 0.680649, top_k: 0.884655, samples/s: 2867.019 1612921131.8321836
train: epoch 111, iter 100, loss: 2.451193, top_1: 0.646289, top_k: 0.846953, samples/s: 1748.629 1612921166.1218092
train: epoch 111, iter 200, loss: 2.354032, top_1: 0.648750, top_k: 0.849297, samples/s: 1754.183 1612921180.7155154
train: epoch 111, iter 300, loss: 2.416088, top_1: 0.649062, top_k: 0.850156, samples/s: 1750.904 1612921195.3364894
train: epoch 111, iter 400, loss: 2.388479, top_1: 0.650469, top_k: 0.851250, samples/s: 1757.420 1612921209.9034257
train: epoch 111, iter 500, loss: 2.471960, top_1: 0.660898, top_k: 0.857578, samples/s: 1764.468 1612921224.4119112
train: epoch 111, iter 600, loss: 2.409934, top_1: 0.647188, top_k: 0.844883, samples/s: 1758.191 1612921238.9723494
train: epoch 111, iter 700, loss: 2.406115, top_1: 0.645703, top_k: 0.846094, samples/s: 1739.772 1612921253.6869624
train: epoch 111, iter 800, loss: 2.338364, top_1: 0.647891, top_k: 0.846758, samples/s: 1747.076 1612921268.3399937
train: epoch 111, iter 900, loss: 2.422265, top_1: 0.651016, top_k: 0.850664, samples/s: 1750.560 1612921282.9639544
train: epoch 111, iter 1000, loss: 2.520914, top_1: 0.649727, top_k: 0.848516, samples/s: 1735.520 1612921297.7144942
train: epoch 111, iter 1100, loss: 2.571669, top_1: 0.650234, top_k: 0.847812, samples/s: 1739.117 1612921312.434694
train: epoch 111, iter 1200, loss: 2.341496, top_1: 0.649922, top_k: 0.850391, samples/s: 1742.333 1612921327.1275964
train: epoch 111, iter 1300, loss: 2.412855, top_1: 0.651641, top_k: 0.849219, samples/s: 1733.097 1612921341.8988209
train: epoch 111, iter 1400, loss: 2.423285, top_1: 0.644258, top_k: 0.846367, samples/s: 1747.870 1612921356.545173
train: epoch 111, iter 1500, loss: 2.639755, top_1: 0.651602, top_k: 0.850313, samples/s: 1739.547 1612921371.261692
train: epoch 111, iter 1600, loss: 2.407300, top_1: 0.648594, top_k: 0.848242, samples/s: 1732.396 1612921386.0389109
train: epoch 111, iter 1700, loss: 2.449389, top_1: 0.646602, top_k: 0.846016, samples/s: 1739.715 1612921400.7539315
train: epoch 111, iter 1800, loss: 2.402613, top_1: 0.648477, top_k: 0.848086, samples/s: 1747.418 1612921415.4041085
train: epoch 111, iter 1900, loss: 2.335833, top_1: 0.652070, top_k: 0.849414, samples/s: 1737.474 1612921430.1381834
train: epoch 111, iter 2000, loss: 2.352335, top_1: 0.648203, top_k: 0.847500, samples/s: 1735.816 1612921444.8863225
train: epoch 111, iter 2100, loss: 2.586784, top_1: 0.644883, top_k: 0.846758, samples/s: 1738.299 1612921459.6133504
train: epoch 111, iter 2200, loss: 2.462950, top_1: 0.645469, top_k: 0.849688, samples/s: 1740.233 1612921474.3240237
train: epoch 111, iter 2300, loss: 2.501898, top_1: 0.643984, top_k: 0.847031, samples/s: 1741.769 1612921489.0217195
train: epoch 111, iter 2400, loss: 2.521533, top_1: 0.652891, top_k: 0.849727, samples/s: 1742.763 1612921503.710985
train: epoch 111, iter 2500, loss: 2.370508, top_1: 0.644531, top_k: 0.843750, samples/s: 1736.374 1612921518.454394
train: epoch 111, iter 2600, loss: 2.539609, top_1: 0.645547, top_k: 0.847070, samples/s: 1742.722 1612921533.1440942
train: epoch 111, iter 2700, loss: 2.349564, top_1: 0.647813, top_k: 0.847852, samples/s: 1744.775 1612921547.8164535
train: epoch 111, iter 2800, loss: 2.548881, top_1: 0.647422, top_k: 0.847891, samples/s: 1736.701 1612921562.5570276
train: epoch 111, iter 2900, loss: 2.364401, top_1: 0.640938, top_k: 0.844961, samples/s: 1741.478 1612921577.257149
train: epoch 111, iter 3000, loss: 2.466352, top_1: 0.649531, top_k: 0.853320, samples/s: 1728.072 1612921592.0714126
train: epoch 111, iter 3100, loss: 2.410318, top_1: 0.647148, top_k: 0.847109, samples/s: 1746.467 1612921606.7294984
train: epoch 111, iter 3200, loss: 2.614995, top_1: 0.649102, top_k: 0.848516, samples/s: 1745.064 1612921621.3994608
train: epoch 111, iter 3300, loss: 2.540060, top_1: 0.642227, top_k: 0.846484, samples/s: 1743.799 1612921636.0800314
train: epoch 111, iter 3400, loss: 2.481602, top_1: 0.641758, top_k: 0.845664, samples/s: 1712.648 1612921651.0277529
train: epoch 111, iter 3500, loss: 2.474612, top_1: 0.644922, top_k: 0.848242, samples/s: 1747.426 1612921665.677874
train: epoch 111, iter 3600, loss: 2.630301, top_1: 0.640000, top_k: 0.844063, samples/s: 1739.731 1612921680.3928084
train: epoch 111, iter 3700, loss: 2.362561, top_1: 0.644258, top_k: 0.848672, samples/s: 1733.531 1612921695.1602898
train: epoch 111, iter 3800, loss: 2.562038, top_1: 0.644336, top_k: 0.843437, samples/s: 1733.032 1612921709.932021
train: epoch 111, iter 3900, loss: 2.337182, top_1: 0.643164, top_k: 0.844844, samples/s: 1738.474 1612921724.657676
train: epoch 111, iter 4000, loss: 2.565832, top_1: 0.649102, top_k: 0.846094, samples/s: 1740.414 1612921739.3667915
train: epoch 111, iter 4100, loss: 2.450286, top_1: 0.639687, top_k: 0.840859, samples/s: 1746.903 1612921754.0213685
train: epoch 111, iter 4200, loss: 2.467279, top_1: 0.644336, top_k: 0.846523, samples/s: 1738.907 1612921768.743215
train: epoch 111, iter 4300, loss: 2.260727, top_1: 0.645352, top_k: 0.847070, samples/s: 1739.710 1612921783.4582477
train: epoch 111, iter 4400, loss: 2.502746, top_1: 0.643203, top_k: 0.848359, samples/s: 1745.363 1612921798.125705
train: epoch 111, iter 4500, loss: 2.611151, top_1: 0.641328, top_k: 0.844258, samples/s: 1736.219 1612921812.8704536
train: epoch 111, iter 4600, loss: 2.441820, top_1: 0.646250, top_k: 0.846328, samples/s: 1748.546 1612921827.5111864
train: epoch 111, iter 4700, loss: 2.528252, top_1: 0.643711, top_k: 0.845742, samples/s: 1741.247 1612921842.2132041
train: epoch 111, iter 4800, loss: 2.491990, top_1: 0.643711, top_k: 0.843672, samples/s: 1745.566 1612921856.8789856
train: epoch 111, iter 4900, loss: 2.543504, top_1: 0.648750, top_k: 0.845742, samples/s: 1737.835 1612921871.6099422
train: epoch 111, iter 5000, loss: 2.494034, top_1: 0.646641, top_k: 0.846406, samples/s: 1747.886 1612921886.256154
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_111.
validation: epoch 111, iter 195, top_1: 0.681851, top_k: 0.883554, samples/s: 2897.103 1612921903.9471445
train: epoch 112, iter 100, loss: 2.253685, top_1: 0.651445, top_k: 0.850391, samples/s: 1733.729 1612921938.7019954
train: epoch 112, iter 200, loss: 2.201599, top_1: 0.648672, top_k: 0.848008, samples/s: 1757.997 1612921953.2639816
train: epoch 112, iter 300, loss: 2.432415, top_1: 0.649062, top_k: 0.851953, samples/s: 1761.138 1612921967.8000627
train: epoch 112, iter 400, loss: 2.499084, top_1: 0.652617, top_k: 0.852812, samples/s: 1752.685 1612921982.4062512
train: epoch 112, iter 500, loss: 2.542666, top_1: 0.660664, top_k: 0.857695, samples/s: 1756.168 1612921996.9837701
train: epoch 112, iter 600, loss: 2.475538, top_1: 0.652383, top_k: 0.849336, samples/s: 1750.372 1612922011.6089635
train: epoch 112, iter 700, loss: 2.553156, top_1: 0.653633, top_k: 0.851914, samples/s: 1754.388 1612922026.2008567
train: epoch 112, iter 800, loss: 2.465518, top_1: 0.651211, top_k: 0.854102, samples/s: 1743.992 1612922040.8798223
train: epoch 112, iter 900, loss: 2.579082, top_1: 0.648477, top_k: 0.851289, samples/s: 1738.286 1612922055.607025
train: epoch 112, iter 1000, loss: 2.279739, top_1: 0.651016, top_k: 0.848711, samples/s: 1744.245 1612922070.2838163
train: epoch 112, iter 1100, loss: 2.379432, top_1: 0.653086, top_k: 0.851875, samples/s: 1734.962 1612922085.0391572
train: epoch 112, iter 1200, loss: 2.380983, top_1: 0.648047, top_k: 0.849922, samples/s: 1756.209 1612922099.6159809
train: epoch 112, iter 1300, loss: 2.725282, top_1: 0.652734, top_k: 0.849141, samples/s: 1741.371 1612922114.317052
train: epoch 112, iter 1400, loss: 2.523343, top_1: 0.645312, top_k: 0.848516, samples/s: 1744.710 1612922128.9900477
train: epoch 112, iter 1500, loss: 2.385401, top_1: 0.649258, top_k: 0.849727, samples/s: 1713.229 1612922143.9325383
train: epoch 112, iter 1600, loss: 2.565177, top_1: 0.655469, top_k: 0.853047, samples/s: 1747.675 1612922158.5805528
train: epoch 112, iter 1700, loss: 2.380930, top_1: 0.652031, top_k: 0.852187, samples/s: 1725.513 1612922173.4167633
train: epoch 112, iter 1800, loss: 2.447552, top_1: 0.652148, top_k: 0.852227, samples/s: 1736.380 1612922188.1600802
train: epoch 112, iter 1900, loss: 2.475554, top_1: 0.651719, top_k: 0.852187, samples/s: 1741.688 1612922202.8584251
train: epoch 112, iter 2000, loss: 2.321097, top_1: 0.653320, top_k: 0.852461, samples/s: 1738.440 1612922217.584335
train: epoch 112, iter 2100, loss: 2.184694, top_1: 0.649687, top_k: 0.847734, samples/s: 1740.025 1612922232.2967098
train: epoch 112, iter 2200, loss: 2.590029, top_1: 0.646133, top_k: 0.846914, samples/s: 1746.024 1612922246.958742
train: epoch 112, iter 2300, loss: 2.600770, top_1: 0.650117, top_k: 0.847773, samples/s: 1746.824 1612922261.613759
train: epoch 112, iter 2400, loss: 2.329265, top_1: 0.650469, top_k: 0.853164, samples/s: 1732.763 1612922276.3879085
train: epoch 112, iter 2500, loss: 2.472338, top_1: 0.648359, top_k: 0.848008, samples/s: 1744.844 1612922291.0596716
train: epoch 112, iter 2600, loss: 2.610405, top_1: 0.645547, top_k: 0.847461, samples/s: 1744.670 1612922305.7330103
train: epoch 112, iter 2700, loss: 2.508567, top_1: 0.647188, top_k: 0.851406, samples/s: 1725.351 1612922320.570598
train: epoch 112, iter 2800, loss: 2.395731, top_1: 0.646016, top_k: 0.847734, samples/s: 1741.693 1612922335.2688317
train: epoch 112, iter 2900, loss: 2.357475, top_1: 0.649727, top_k: 0.849141, samples/s: 1734.992 1612922350.0240078
train: epoch 112, iter 3000, loss: 2.396026, top_1: 0.651875, top_k: 0.849336, samples/s: 1747.562 1612922364.6729794
train: epoch 112, iter 3100, loss: 2.511254, top_1: 0.652461, top_k: 0.850313, samples/s: 1728.173 1612922379.486399
train: epoch 112, iter 3200, loss: 2.605487, top_1: 0.644883, top_k: 0.845313, samples/s: 1726.715 1612922394.3121867
train: epoch 112, iter 3300, loss: 2.379734, top_1: 0.643945, top_k: 0.846719, samples/s: 1763.367 1612922408.8298132
train: epoch 112, iter 3400, loss: 2.594210, top_1: 0.646797, top_k: 0.846484, samples/s: 1727.719 1612922423.6470826
train: epoch 112, iter 3500, loss: 2.594759, top_1: 0.650742, top_k: 0.847187, samples/s: 1740.977 1612922438.3513846
train: epoch 112, iter 3600, loss: 2.464534, top_1: 0.647852, top_k: 0.848203, samples/s: 1740.677 1612922453.0583885
train: epoch 112, iter 3700, loss: 2.455257, top_1: 0.648789, top_k: 0.848672, samples/s: 1736.539 1612922467.800322
train: epoch 112, iter 3800, loss: 2.511843, top_1: 0.644609, top_k: 0.845156, samples/s: 1744.894 1612922482.4716835
train: epoch 112, iter 3900, loss: 2.364319, top_1: 0.644062, top_k: 0.848047, samples/s: 1739.267 1612922497.1904738
train: epoch 112, iter 4000, loss: 2.433267, top_1: 0.652617, top_k: 0.850664, samples/s: 1733.103 1612922511.961682
train: epoch 112, iter 4100, loss: 2.418551, top_1: 0.651641, top_k: 0.849922, samples/s: 1736.287 1612922526.7058215
train: epoch 112, iter 4200, loss: 2.561611, top_1: 0.642148, top_k: 0.843008, samples/s: 1731.914 1612922541.4872046
train: epoch 112, iter 4300, loss: 2.676518, top_1: 0.648633, top_k: 0.850039, samples/s: 1733.318 1612922556.2565043
train: epoch 112, iter 4400, loss: 2.473112, top_1: 0.644648, top_k: 0.846914, samples/s: 1739.781 1612922570.9710088
train: epoch 112, iter 4500, loss: 2.544003, top_1: 0.645391, top_k: 0.848672, samples/s: 1745.437 1612922585.6379056
train: epoch 112, iter 4600, loss: 2.383538, top_1: 0.648750, top_k: 0.847891, samples/s: 1743.227 1612922600.323274
train: epoch 112, iter 4700, loss: 2.661149, top_1: 0.645625, top_k: 0.848398, samples/s: 1743.651 1612922615.005033
train: epoch 112, iter 4800, loss: 2.536095, top_1: 0.646172, top_k: 0.846875, samples/s: 1735.279 1612922629.7578304
train: epoch 112, iter 4900, loss: 2.356828, top_1: 0.645117, top_k: 0.845156, samples/s: 1739.855 1612922644.4716353
train: epoch 112, iter 5000, loss: 2.196447, top_1: 0.651563, top_k: 0.849922, samples/s: 1736.821 1612922659.2111535
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_112.
validation: epoch 112, iter 195, top_1: 0.689704, top_k: 0.891887, samples/s: 2884.635 1612922676.9922256
train: epoch 113, iter 100, loss: 2.335515, top_1: 0.655234, top_k: 0.852852, samples/s: 1754.909 1612922711.6408772
train: epoch 113, iter 200, loss: 2.320599, top_1: 0.663359, top_k: 0.857578, samples/s: 1749.344 1612922726.2750056
train: epoch 113, iter 300, loss: 2.236944, top_1: 0.663594, top_k: 0.858008, samples/s: 1770.347 1612922740.7355332
train: epoch 113, iter 400, loss: 2.726676, top_1: 0.655195, top_k: 0.854688, samples/s: 1757.744 1612922755.299399
train: epoch 113, iter 500, loss: 2.261093, top_1: 0.663477, top_k: 0.854648, samples/s: 1760.550 1612922769.8403811
train: epoch 113, iter 600, loss: 2.452723, top_1: 0.653594, top_k: 0.854062, samples/s: 1751.306 1612922784.4580307
train: epoch 113, iter 700, loss: 2.369129, top_1: 0.660508, top_k: 0.855820, samples/s: 1752.899 1612922799.062405
train: epoch 113, iter 800, loss: 2.360676, top_1: 0.658164, top_k: 0.850859, samples/s: 1729.767 1612922813.86202
train: epoch 113, iter 900, loss: 2.455098, top_1: 0.657305, top_k: 0.852187, samples/s: 1755.943 1612922828.4410887
train: epoch 113, iter 1000, loss: 2.564305, top_1: 0.655430, top_k: 0.850586, samples/s: 1743.862 1612922843.1211476
train: epoch 113, iter 1100, loss: 2.381706, top_1: 0.654609, top_k: 0.855117, samples/s: 1742.687 1612922857.811128
train: epoch 113, iter 1200, loss: 2.453619, top_1: 0.654609, top_k: 0.850586, samples/s: 1744.818 1612922872.4831312
train: epoch 113, iter 1300, loss: 2.538990, top_1: 0.655937, top_k: 0.854102, samples/s: 1742.519 1612922887.1745749
train: epoch 113, iter 1400, loss: 2.576982, top_1: 0.659570, top_k: 0.854414, samples/s: 1742.861 1612922901.8630555
train: epoch 113, iter 1500, loss: 2.341015, top_1: 0.646563, top_k: 0.851484, samples/s: 1738.586 1612922916.5876708
train: epoch 113, iter 1600, loss: 2.464543, top_1: 0.651250, top_k: 0.851914, samples/s: 1720.856 1612922931.463929
train: epoch 113, iter 1700, loss: 2.606252, top_1: 0.646484, top_k: 0.848516, samples/s: 1747.538 1612922946.113132
train: epoch 113, iter 1800, loss: 2.448232, top_1: 0.657813, top_k: 0.850391, samples/s: 1742.946 1612922960.8009353
train: epoch 113, iter 1900, loss: 2.602829, top_1: 0.648555, top_k: 0.847930, samples/s: 1747.048 1612922975.4542067
train: epoch 113, iter 2000, loss: 2.391931, top_1: 0.656875, top_k: 0.852539, samples/s: 1734.429 1612922990.2141073
train: epoch 113, iter 2100, loss: 2.375411, top_1: 0.650664, top_k: 0.849531, samples/s: 1735.860 1612923004.961866
train: epoch 113, iter 2200, loss: 2.506166, top_1: 0.647344, top_k: 0.849531, samples/s: 1739.247 1612923019.6808248
train: epoch 113, iter 2300, loss: 2.469497, top_1: 0.652305, top_k: 0.852266, samples/s: 1747.815 1612923034.3277164
train: epoch 113, iter 2400, loss: 2.496152, top_1: 0.651836, top_k: 0.851172, samples/s: 1730.489 1612923049.1212313
train: epoch 113, iter 2500, loss: 2.599426, top_1: 0.646484, top_k: 0.849102, samples/s: 1740.794 1612923063.827165
train: epoch 113, iter 2600, loss: 2.583673, top_1: 0.654023, top_k: 0.849883, samples/s: 1738.160 1612923078.5553539
train: epoch 113, iter 2700, loss: 2.443039, top_1: 0.648320, top_k: 0.850469, samples/s: 1732.126 1612923093.3348985
train: epoch 113, iter 2800, loss: 2.537312, top_1: 0.648828, top_k: 0.848594, samples/s: 1730.270 1612923108.1303022
train: epoch 113, iter 2900, loss: 2.347987, top_1: 0.653203, top_k: 0.853828, samples/s: 1746.483 1612923122.788268
train: epoch 113, iter 3000, loss: 2.442755, top_1: 0.649297, top_k: 0.846992, samples/s: 1745.159 1612923137.4574442
train: epoch 113, iter 3100, loss: 2.437677, top_1: 0.650234, top_k: 0.849297, samples/s: 1728.325 1612923152.269475
train: epoch 113, iter 3200, loss: 2.439837, top_1: 0.647031, top_k: 0.847461, samples/s: 1737.593 1612923167.0025113
train: epoch 113, iter 3300, loss: 2.548956, top_1: 0.649180, top_k: 0.848320, samples/s: 1732.270 1612923181.780814
train: epoch 113, iter 3400, loss: 2.346842, top_1: 0.647813, top_k: 0.849492, samples/s: 1747.071 1612923196.4338682
train: epoch 113, iter 3500, loss: 2.594270, top_1: 0.653281, top_k: 0.854570, samples/s: 1750.714 1612923211.0565393
train: epoch 113, iter 3600, loss: 2.409485, top_1: 0.652344, top_k: 0.850508, samples/s: 1742.636 1612923225.7469223
train: epoch 113, iter 3700, loss: 2.508562, top_1: 0.657109, top_k: 0.851367, samples/s: 1740.320 1612923240.45681
train: epoch 113, iter 3800, loss: 2.303596, top_1: 0.652109, top_k: 0.851836, samples/s: 1731.634 1612923255.2406266
train: epoch 113, iter 3900, loss: 2.493687, top_1: 0.648711, top_k: 0.848672, samples/s: 1755.807 1612923269.8207748
train: epoch 113, iter 4000, loss: 2.535759, top_1: 0.646094, top_k: 0.848086, samples/s: 1732.475 1612923284.5972712
train: epoch 113, iter 4100, loss: 2.378052, top_1: 0.642734, top_k: 0.846133, samples/s: 1746.981 1612923299.2512171
train: epoch 113, iter 4200, loss: 2.467842, top_1: 0.647578, top_k: 0.847539, samples/s: 1750.112 1612923313.8787882
train: epoch 113, iter 4300, loss: 2.411023, top_1: 0.649062, top_k: 0.849414, samples/s: 1737.129 1612923328.6157777
train: epoch 113, iter 4400, loss: 2.513885, top_1: 0.654727, top_k: 0.851758, samples/s: 1749.606 1612923343.2476177
train: epoch 113, iter 4500, loss: 2.394361, top_1: 0.647148, top_k: 0.848633, samples/s: 1729.113 1612923358.0528526
train: epoch 113, iter 4600, loss: 2.370972, top_1: 0.648867, top_k: 0.846875, samples/s: 1733.009 1612923372.8249288
train: epoch 113, iter 4700, loss: 2.343652, top_1: 0.646055, top_k: 0.849141, samples/s: 1745.466 1612923387.4914863
train: epoch 113, iter 4800, loss: 2.423859, top_1: 0.650391, top_k: 0.849102, samples/s: 1741.005 1612923402.1956856
train: epoch 113, iter 4900, loss: 2.282499, top_1: 0.651484, top_k: 0.852734, samples/s: 1746.373 1612923416.8546402
train: epoch 113, iter 5000, loss: 2.394184, top_1: 0.657656, top_k: 0.853008, samples/s: 1738.880 1612923431.5767183
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_113.
validation: epoch 113, iter 195, top_1: 0.687119, top_k: 0.889363, samples/s: 2790.625 1612923449.9007196
train: epoch 114, iter 100, loss: 2.356686, top_1: 0.658125, top_k: 0.854297, samples/s: 1755.457 1612923485.1708264
train: epoch 114, iter 200, loss: 2.212155, top_1: 0.662148, top_k: 0.862539, samples/s: 1751.357 1612923499.7880647
train: epoch 114, iter 300, loss: 2.421136, top_1: 0.663398, top_k: 0.858984, samples/s: 1762.975 1612923514.3089418
train: epoch 114, iter 400, loss: 2.530645, top_1: 0.651016, top_k: 0.851914, samples/s: 1757.792 1612923528.8726568
train: epoch 114, iter 500, loss: 2.442187, top_1: 0.658906, top_k: 0.855313, samples/s: 1750.494 1612923543.497152
train: epoch 114, iter 600, loss: 2.511402, top_1: 0.660312, top_k: 0.851680, samples/s: 1756.835 1612923558.0686967
train: epoch 114, iter 700, loss: 2.294417, top_1: 0.654180, top_k: 0.852812, samples/s: 1752.742 1612923572.6743817
train: epoch 114, iter 800, loss: 2.221142, top_1: 0.654453, top_k: 0.855391, samples/s: 1720.785 1612923587.5513458
train: epoch 114, iter 900, loss: 2.395827, top_1: 0.657227, top_k: 0.853125, samples/s: 1752.450 1612923602.1594722
train: epoch 114, iter 1000, loss: 2.439867, top_1: 0.659531, top_k: 0.853906, samples/s: 1741.737 1612923616.8574557
train: epoch 114, iter 1100, loss: 2.539936, top_1: 0.660547, top_k: 0.854688, samples/s: 1734.193 1612923631.61932
train: epoch 114, iter 1200, loss: 2.319975, top_1: 0.657773, top_k: 0.855820, samples/s: 1735.057 1612923646.3739138
train: epoch 114, iter 1300, loss: 2.454065, top_1: 0.654336, top_k: 0.853828, samples/s: 1728.923 1612923661.1808748
train: epoch 114, iter 1400, loss: 2.572078, top_1: 0.658047, top_k: 0.853242, samples/s: 1746.490 1612923675.838807
train: epoch 114, iter 1500, loss: 2.460999, top_1: 0.654102, top_k: 0.850195, samples/s: 1750.936 1612923690.4595838
train: epoch 114, iter 1600, loss: 2.558811, top_1: 0.655742, top_k: 0.856992, samples/s: 1729.023 1612923705.2656333
train: epoch 114, iter 1700, loss: 2.451691, top_1: 0.654102, top_k: 0.855039, samples/s: 1742.556 1612923719.9566948
train: epoch 114, iter 1800, loss: 2.495598, top_1: 0.652695, top_k: 0.854570, samples/s: 1733.200 1612923734.727056
train: epoch 114, iter 1900, loss: 2.482884, top_1: 0.650547, top_k: 0.854531, samples/s: 1744.581 1612923749.4010072
train: epoch 114, iter 2000, loss: 2.332723, top_1: 0.656016, top_k: 0.853086, samples/s: 1730.506 1612923764.1945038
train: epoch 114, iter 2100, loss: 2.452676, top_1: 0.649336, top_k: 0.851719, samples/s: 1749.813 1612923778.8245287
train: epoch 114, iter 2200, loss: 2.303119, top_1: 0.660508, top_k: 0.856758, samples/s: 1742.662 1612923793.514726
train: epoch 114, iter 2300, loss: 2.359043, top_1: 0.651016, top_k: 0.852227, samples/s: 1736.417 1612923808.2576904
train: epoch 114, iter 2400, loss: 2.198124, top_1: 0.656328, top_k: 0.852305, samples/s: 1735.938 1612923823.0048482
train: epoch 114, iter 2500, loss: 2.478367, top_1: 0.661289, top_k: 0.856133, samples/s: 1738.710 1612923837.728301
train: epoch 114, iter 2600, loss: 2.484086, top_1: 0.651953, top_k: 0.852187, samples/s: 1735.816 1612923852.4767435
train: epoch 114, iter 2700, loss: 2.537977, top_1: 0.653203, top_k: 0.850078, samples/s: 1741.221 1612923867.1788445
train: epoch 114, iter 2800, loss: 2.449096, top_1: 0.654805, top_k: 0.852461, samples/s: 1740.730 1612923881.8852165
train: epoch 114, iter 2900, loss: 2.430531, top_1: 0.653750, top_k: 0.852109, samples/s: 1745.204 1612923896.5540385
train: epoch 114, iter 3000, loss: 2.330641, top_1: 0.652344, top_k: 0.849648, samples/s: 1737.381 1612923911.2888002
train: epoch 114, iter 3100, loss: 2.466638, top_1: 0.653125, top_k: 0.852617, samples/s: 1736.127 1612923926.034467
train: epoch 114, iter 3200, loss: 2.518047, top_1: 0.655977, top_k: 0.854102, samples/s: 1748.068 1612923940.6794245
train: epoch 114, iter 3300, loss: 2.318564, top_1: 0.645820, top_k: 0.846133, samples/s: 1741.678 1612923955.3774805
train: epoch 114, iter 3400, loss: 2.407708, top_1: 0.656055, top_k: 0.849297, samples/s: 1745.420 1612923970.0444908
train: epoch 114, iter 3500, loss: 2.538249, top_1: 0.653633, top_k: 0.852852, samples/s: 1738.903 1612923984.7663994
train: epoch 114, iter 3600, loss: 2.303703, top_1: 0.656406, top_k: 0.854531, samples/s: 1743.769 1612923999.4472833
train: epoch 114, iter 3700, loss: 2.530428, top_1: 0.651367, top_k: 0.852852, samples/s: 1736.089 1612924014.1930306
train: epoch 114, iter 3800, loss: 2.490713, top_1: 0.654141, top_k: 0.850977, samples/s: 1752.288 1612924028.8025177
train: epoch 114, iter 3900, loss: 2.424875, top_1: 0.651094, top_k: 0.851094, samples/s: 1742.278 1612924043.4959273
train: epoch 114, iter 4000, loss: 2.495857, top_1: 0.651602, top_k: 0.850586, samples/s: 1738.506 1612924058.2211614
train: epoch 114, iter 4100, loss: 2.468489, top_1: 0.648242, top_k: 0.849453, samples/s: 1748.734 1612924072.8603163
train: epoch 114, iter 4200, loss: 2.434223, top_1: 0.655898, top_k: 0.852539, samples/s: 1737.834 1612924087.5913837
train: epoch 114, iter 4300, loss: 2.497842, top_1: 0.648867, top_k: 0.850117, samples/s: 1740.484 1612924102.2999163
train: epoch 114, iter 4400, loss: 2.562194, top_1: 0.648516, top_k: 0.846914, samples/s: 1732.529 1612924117.0760355
train: epoch 114, iter 4500, loss: 2.610043, top_1: 0.659102, top_k: 0.856484, samples/s: 1734.259 1612924131.837335
train: epoch 114, iter 4600, loss: 2.382225, top_1: 0.655625, top_k: 0.852422, samples/s: 1735.458 1612924146.5884378
train: epoch 114, iter 4700, loss: 2.463181, top_1: 0.654375, top_k: 0.851289, samples/s: 1747.104 1612924161.2413263
train: epoch 114, iter 4800, loss: 2.441681, top_1: 0.655000, top_k: 0.852969, samples/s: 1738.740 1612924175.96456
train: epoch 114, iter 4900, loss: 2.450835, top_1: 0.655352, top_k: 0.855234, samples/s: 1737.868 1612924190.695335
train: epoch 114, iter 5000, loss: 2.311510, top_1: 0.655898, top_k: 0.853398, samples/s: 1739.876 1612924205.4090436
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_114.
validation: epoch 114, iter 195, top_1: 0.692448, top_k: 0.892127, samples/s: 2851.407 1612924223.3379254
train: epoch 115, iter 100, loss: 2.318112, top_1: 0.657773, top_k: 0.857500, samples/s: 1752.756 1612924258.2317092
train: epoch 115, iter 200, loss: 2.464605, top_1: 0.663555, top_k: 0.858867, samples/s: 1758.086 1612924272.7929916
train: epoch 115, iter 300, loss: 2.710884, top_1: 0.660742, top_k: 0.855273, samples/s: 1763.284 1612924287.311348
train: epoch 115, iter 400, loss: 2.428663, top_1: 0.662891, top_k: 0.857383, samples/s: 1758.770 1612924301.8669524
train: epoch 115, iter 500, loss: 2.412521, top_1: 0.661367, top_k: 0.855469, samples/s: 1754.631 1612924316.4569955
train: epoch 115, iter 600, loss: 2.453852, top_1: 0.655586, top_k: 0.852812, samples/s: 1753.378 1612924331.0573194
train: epoch 115, iter 700, loss: 2.513714, top_1: 0.661719, top_k: 0.852109, samples/s: 1754.379 1612924345.6493564
train: epoch 115, iter 800, loss: 2.438186, top_1: 0.660937, top_k: 0.856836, samples/s: 1756.217 1612924360.226132
train: epoch 115, iter 900, loss: 2.420937, top_1: 0.652734, top_k: 0.852969, samples/s: 1730.847 1612924375.01658
train: epoch 115, iter 1000, loss: 2.357889, top_1: 0.660898, top_k: 0.858164, samples/s: 1743.489 1612924389.6998591
train: epoch 115, iter 1100, loss: 2.481389, top_1: 0.660469, top_k: 0.853008, samples/s: 1732.620 1612924404.4750493
train: epoch 115, iter 1200, loss: 2.367125, top_1: 0.652109, top_k: 0.852617, samples/s: 1742.780 1612924419.1642652
train: epoch 115, iter 1300, loss: 2.535274, top_1: 0.652422, top_k: 0.852539, samples/s: 1747.478 1612924433.8139708
train: epoch 115, iter 1400, loss: 2.491652, top_1: 0.656289, top_k: 0.853633, samples/s: 1726.645 1612924448.6404076
train: epoch 115, iter 1500, loss: 2.364735, top_1: 0.653008, top_k: 0.854688, samples/s: 1736.933 1612924463.3790045
train: epoch 115, iter 1600, loss: 2.472266, top_1: 0.654375, top_k: 0.851328, samples/s: 1734.272 1612924478.1402795
train: epoch 115, iter 1700, loss: 2.572859, top_1: 0.653008, top_k: 0.853164, samples/s: 1731.638 1612924492.9240007
train: epoch 115, iter 1800, loss: 2.541574, top_1: 0.653008, top_k: 0.854922, samples/s: 1740.166 1612924507.6351464
train: epoch 115, iter 1900, loss: 2.427969, top_1: 0.657617, top_k: 0.852383, samples/s: 1741.956 1612924522.3312602
train: epoch 115, iter 2000, loss: 2.301125, top_1: 0.658867, top_k: 0.853242, samples/s: 1727.157 1612924537.153356
train: epoch 115, iter 2100, loss: 2.465917, top_1: 0.658867, top_k: 0.853984, samples/s: 1743.362 1612924551.8376176
train: epoch 115, iter 2200, loss: 2.505905, top_1: 0.652969, top_k: 0.851484, samples/s: 1732.035 1612924566.6178718
train: epoch 115, iter 2300, loss: 2.339021, top_1: 0.653281, top_k: 0.854375, samples/s: 1735.833 1612924581.3658786
train: epoch 115, iter 2400, loss: 2.431070, top_1: 0.655977, top_k: 0.854414, samples/s: 1731.220 1612924596.1531227
train: epoch 115, iter 2500, loss: 2.373514, top_1: 0.657617, top_k: 0.856211, samples/s: 1748.876 1612924610.7910948
train: epoch 115, iter 2600, loss: 2.391312, top_1: 0.653203, top_k: 0.853008, samples/s: 1741.689 1612924625.489459
train: epoch 115, iter 2700, loss: 2.419433, top_1: 0.655039, top_k: 0.853516, samples/s: 1721.660 1612924640.358914
train: epoch 115, iter 2800, loss: 2.349900, top_1: 0.657539, top_k: 0.852344, samples/s: 1736.332 1612924655.1025968
train: epoch 115, iter 2900, loss: 2.363167, top_1: 0.663516, top_k: 0.856953, samples/s: 1746.980 1612924669.7564683
train: epoch 115, iter 3000, loss: 2.209555, top_1: 0.655469, top_k: 0.856094, samples/s: 1729.512 1612924684.5582976
train: epoch 115, iter 3100, loss: 2.385153, top_1: 0.654492, top_k: 0.852031, samples/s: 1736.087 1612924699.304082
train: epoch 115, iter 3200, loss: 2.417836, top_1: 0.659453, top_k: 0.854766, samples/s: 1734.963 1612924714.059451
train: epoch 115, iter 3300, loss: 2.617511, top_1: 0.656328, top_k: 0.854375, samples/s: 1736.451 1612924728.8021557
train: epoch 115, iter 3400, loss: 2.716707, top_1: 0.652578, top_k: 0.852656, samples/s: 1724.717 1612924743.6452043
train: epoch 115, iter 3500, loss: 2.366583, top_1: 0.660664, top_k: 0.855703, samples/s: 1747.823 1612924758.291948
train: epoch 115, iter 3600, loss: 2.473561, top_1: 0.655273, top_k: 0.851602, samples/s: 1741.882 1612924772.9887185
train: epoch 115, iter 3700, loss: 2.443084, top_1: 0.655234, top_k: 0.853008, samples/s: 1733.037 1612924787.7605653
train: epoch 115, iter 3800, loss: 2.365545, top_1: 0.655742, top_k: 0.854961, samples/s: 1733.406 1612924802.5290735
train: epoch 115, iter 3900, loss: 2.468858, top_1: 0.653750, top_k: 0.853047, samples/s: 1728.660 1612924817.338235
train: epoch 115, iter 4000, loss: 2.391482, top_1: 0.650977, top_k: 0.851836, samples/s: 1747.620 1612924831.9867222
train: epoch 115, iter 4100, loss: 2.427510, top_1: 0.655586, top_k: 0.852031, samples/s: 1736.941 1612924846.7252934
train: epoch 115, iter 4200, loss: 2.565290, top_1: 0.655078, top_k: 0.850586, samples/s: 1749.873 1612924861.3549786
train: epoch 115, iter 4300, loss: 2.411550, top_1: 0.644844, top_k: 0.847461, samples/s: 1740.897 1612924876.0600185
train: epoch 115, iter 4400, loss: 2.534724, top_1: 0.651484, top_k: 0.851992, samples/s: 1738.097 1612924890.7887297
train: epoch 115, iter 4500, loss: 2.489027, top_1: 0.654609, top_k: 0.853750, samples/s: 1732.694 1612924905.5634072
train: epoch 115, iter 4600, loss: 2.423110, top_1: 0.651094, top_k: 0.847734, samples/s: 1738.670 1612924920.287447
train: epoch 115, iter 4700, loss: 2.388585, top_1: 0.653828, top_k: 0.850547, samples/s: 1749.125 1612924934.9232807
train: epoch 115, iter 4800, loss: 2.367635, top_1: 0.656211, top_k: 0.848437, samples/s: 1718.563 1612924949.8194013
train: epoch 115, iter 4900, loss: 2.345911, top_1: 0.650430, top_k: 0.851719, samples/s: 1738.890 1612924964.5415144
train: epoch 115, iter 5000, loss: 2.398935, top_1: 0.660391, top_k: 0.860742, samples/s: 1744.839 1612924979.2132587
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_115.
validation: epoch 115, iter 195, top_1: 0.686238, top_k: 0.888462, samples/s: 2900.315 1612924996.8685818
train: epoch 116, iter 100, loss: 2.456119, top_1: 0.668477, top_k: 0.859727, samples/s: 1747.488 1612925032.334702
train: epoch 116, iter 200, loss: 2.357189, top_1: 0.669922, top_k: 0.859688, samples/s: 1764.497 1612925046.8431153
train: epoch 116, iter 300, loss: 2.252582, top_1: 0.664180, top_k: 0.860820, samples/s: 1749.988 1612925061.4717612
train: epoch 116, iter 400, loss: 2.357496, top_1: 0.664805, top_k: 0.857539, samples/s: 1763.296 1612925075.990039
train: epoch 116, iter 500, loss: 2.365938, top_1: 0.662461, top_k: 0.856367, samples/s: 1755.501 1612925090.5727282
train: epoch 116, iter 600, loss: 2.515003, top_1: 0.667930, top_k: 0.858984, samples/s: 1751.687 1612925105.1871982
train: epoch 116, iter 700, loss: 2.346533, top_1: 0.665117, top_k: 0.856992, samples/s: 1747.859 1612925119.833684
train: epoch 116, iter 800, loss: 2.510104, top_1: 0.658945, top_k: 0.853906, samples/s: 1735.423 1612925134.585123
train: epoch 116, iter 900, loss: 2.389038, top_1: 0.661523, top_k: 0.854766, samples/s: 1738.385 1612925149.3114197
train: epoch 116, iter 1000, loss: 2.324765, top_1: 0.660547, top_k: 0.860781, samples/s: 1743.920 1612925163.9909887
train: epoch 116, iter 1100, loss: 2.328295, top_1: 0.658398, top_k: 0.858047, samples/s: 1735.347 1612925178.7431037
train: epoch 116, iter 1200, loss: 2.404234, top_1: 0.661523, top_k: 0.856172, samples/s: 1742.500 1612925193.4346304
train: epoch 116, iter 1300, loss: 2.325151, top_1: 0.659414, top_k: 0.854141, samples/s: 1729.703 1612925208.2349074
train: epoch 116, iter 1400, loss: 2.284293, top_1: 0.660820, top_k: 0.857539, samples/s: 1743.982 1612925222.913989
train: epoch 116, iter 1500, loss: 2.479256, top_1: 0.661836, top_k: 0.853398, samples/s: 1735.942 1612925237.6609566
train: epoch 116, iter 1600, loss: 2.321864, top_1: 0.660195, top_k: 0.856250, samples/s: 1729.484 1612925252.463077
train: epoch 116, iter 1700, loss: 2.393939, top_1: 0.662305, top_k: 0.857070, samples/s: 1743.100 1612925267.149523
train: epoch 116, iter 1800, loss: 2.257515, top_1: 0.655742, top_k: 0.854961, samples/s: 1737.121 1612925281.886548
train: epoch 116, iter 1900, loss: 2.411654, top_1: 0.658203, top_k: 0.852148, samples/s: 1736.429 1612925296.6294987
train: epoch 116, iter 2000, loss: 2.393109, top_1: 0.659219, top_k: 0.856016, samples/s: 1741.287 1612925311.3312228
train: epoch 116, iter 2100, loss: 2.268100, top_1: 0.659141, top_k: 0.856211, samples/s: 1718.898 1612925326.224512
train: epoch 116, iter 2200, loss: 2.419696, top_1: 0.658242, top_k: 0.855352, samples/s: 1756.075 1612925340.802464
train: epoch 116, iter 2300, loss: 2.504213, top_1: 0.662930, top_k: 0.856914, samples/s: 1734.158 1612925355.5647047
train: epoch 116, iter 2400, loss: 2.252543, top_1: 0.658203, top_k: 0.856328, samples/s: 1729.981 1612925370.362497
train: epoch 116, iter 2500, loss: 2.427387, top_1: 0.659102, top_k: 0.856367, samples/s: 1738.361 1612925385.0890143
train: epoch 116, iter 2600, loss: 2.383170, top_1: 0.656328, top_k: 0.854570, samples/s: 1731.997 1612925399.8697083
train: epoch 116, iter 2700, loss: 2.455878, top_1: 0.665859, top_k: 0.857773, samples/s: 1731.111 1612925414.6578956
train: epoch 116, iter 2800, loss: 2.252085, top_1: 0.658594, top_k: 0.856758, samples/s: 1745.573 1612925429.323541
train: epoch 116, iter 2900, loss: 2.364451, top_1: 0.658242, top_k: 0.856211, samples/s: 1736.242 1612925444.0679998
train: epoch 116, iter 3000, loss: 2.441432, top_1: 0.659102, top_k: 0.854180, samples/s: 1722.629 1612925458.9290094
train: epoch 116, iter 3100, loss: 2.411762, top_1: 0.656602, top_k: 0.855391, samples/s: 1751.304 1612925473.546702
train: epoch 116, iter 3200, loss: 2.387765, top_1: 0.661680, top_k: 0.855430, samples/s: 1724.555 1612925488.3911324
train: epoch 116, iter 3300, loss: 2.378513, top_1: 0.661992, top_k: 0.859141, samples/s: 1751.439 1612925503.0076623
train: epoch 116, iter 3400, loss: 2.450731, top_1: 0.655508, top_k: 0.851172, samples/s: 1741.040 1612925517.7115028
train: epoch 116, iter 3500, loss: 2.410374, top_1: 0.654336, top_k: 0.854492, samples/s: 1739.707 1612925532.426689
train: epoch 116, iter 3600, loss: 2.382834, top_1: 0.660430, top_k: 0.856016, samples/s: 1730.290 1612925547.221931
train: epoch 116, iter 3700, loss: 2.424253, top_1: 0.653828, top_k: 0.852539, samples/s: 1750.711 1612925561.844568
train: epoch 116, iter 3800, loss: 2.513890, top_1: 0.656133, top_k: 0.854648, samples/s: 1727.823 1612925576.6608934
train: epoch 116, iter 3900, loss: 2.275317, top_1: 0.656719, top_k: 0.853945, samples/s: 1747.368 1612925591.311428
train: epoch 116, iter 4000, loss: 2.388613, top_1: 0.659570, top_k: 0.856016, samples/s: 1744.414 1612925605.9868217
train: epoch 116, iter 4100, loss: 2.348338, top_1: 0.657656, top_k: 0.853945, samples/s: 1741.554 1612925620.6863375
train: epoch 116, iter 4200, loss: 2.513252, top_1: 0.660586, top_k: 0.856523, samples/s: 1739.011 1612925635.4074516
train: epoch 116, iter 4300, loss: 2.338525, top_1: 0.656328, top_k: 0.853633, samples/s: 1744.001 1612925650.086289
train: epoch 116, iter 4400, loss: 2.445876, top_1: 0.655820, top_k: 0.854883, samples/s: 1728.298 1612925664.89857
train: epoch 116, iter 4500, loss: 2.527443, top_1: 0.653984, top_k: 0.852187, samples/s: 1745.939 1612925679.5611427
train: epoch 116, iter 4600, loss: 2.442039, top_1: 0.650625, top_k: 0.853320, samples/s: 1743.925 1612925694.24066
train: epoch 116, iter 4700, loss: 2.442308, top_1: 0.660547, top_k: 0.857617, samples/s: 1734.535 1612925708.9996798
train: epoch 116, iter 4800, loss: 2.487390, top_1: 0.662070, top_k: 0.858516, samples/s: 1747.770 1612925723.6469042
train: epoch 116, iter 4900, loss: 2.508637, top_1: 0.660273, top_k: 0.857109, samples/s: 1735.382 1612925738.3986728
train: epoch 116, iter 5000, loss: 2.440848, top_1: 0.665625, top_k: 0.859453, samples/s: 1732.671 1612925753.1735315
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_116.
validation: epoch 116, iter 195, top_1: 0.694852, top_k: 0.894091, samples/s: 2877.405 1612925770.9070587
train: epoch 117, iter 100, loss: 2.364171, top_1: 0.668398, top_k: 0.862227, samples/s: 1755.194 1612925806.0603526
train: epoch 117, iter 200, loss: 2.250328, top_1: 0.667266, top_k: 0.859219, samples/s: 1750.252 1612925820.6868143
train: epoch 117, iter 300, loss: 2.540597, top_1: 0.672656, top_k: 0.861914, samples/s: 1758.857 1612925835.241693
train: epoch 117, iter 400, loss: 2.317954, top_1: 0.661133, top_k: 0.859688, samples/s: 1753.570 1612925849.8404992
train: epoch 117, iter 500, loss: 2.309232, top_1: 0.665156, top_k: 0.862852, samples/s: 1767.477 1612925864.3244004
train: epoch 117, iter 600, loss: 2.415626, top_1: 0.663164, top_k: 0.857500, samples/s: 1760.265 1612925878.8676848
train: epoch 117, iter 700, loss: 2.222943, top_1: 0.663086, top_k: 0.857461, samples/s: 1740.949 1612925893.5723903
train: epoch 117, iter 800, loss: 2.457719, top_1: 0.666719, top_k: 0.859258, samples/s: 1749.509 1612925908.2049685
train: epoch 117, iter 900, loss: 2.391572, top_1: 0.661914, top_k: 0.854844, samples/s: 1753.414 1612925922.8050537
train: epoch 117, iter 1000, loss: 2.470660, top_1: 0.660977, top_k: 0.856953, samples/s: 1733.422 1612925937.5736523
train: epoch 117, iter 1100, loss: 2.288768, top_1: 0.665977, top_k: 0.860898, samples/s: 1742.535 1612925952.2648125
train: epoch 117, iter 1200, loss: 2.206996, top_1: 0.660195, top_k: 0.857695, samples/s: 1734.804 1612925967.0214846
train: epoch 117, iter 1300, loss: 2.463721, top_1: 0.666211, top_k: 0.859180, samples/s: 1732.158 1612925981.8008323
train: epoch 117, iter 1400, loss: 2.354227, top_1: 0.663906, top_k: 0.856289, samples/s: 1742.888 1612925996.4890175
train: epoch 117, iter 1500, loss: 2.639567, top_1: 0.665273, top_k: 0.860742, samples/s: 1737.551 1612926011.2224402
train: epoch 117, iter 1600, loss: 2.518239, top_1: 0.666250, top_k: 0.858945, samples/s: 1749.307 1612926025.85685
train: epoch 117, iter 1700, loss: 2.344037, top_1: 0.662227, top_k: 0.855703, samples/s: 1739.303 1612926040.5753794
train: epoch 117, iter 1800, loss: 2.379686, top_1: 0.659648, top_k: 0.855117, samples/s: 1728.669 1612926055.3845296
train: epoch 117, iter 1900, loss: 2.483553, top_1: 0.667383, top_k: 0.860820, samples/s: 1744.854 1612926070.0561502
train: epoch 117, iter 2000, loss: 2.386617, top_1: 0.662109, top_k: 0.856328, samples/s: 1734.070 1612926084.8190663
train: epoch 117, iter 2100, loss: 2.480482, top_1: 0.660898, top_k: 0.857305, samples/s: 1743.726 1612926099.500318
train: epoch 117, iter 2200, loss: 2.476197, top_1: 0.666367, top_k: 0.860781, samples/s: 1736.869 1612926114.2394288
train: epoch 117, iter 2300, loss: 2.521066, top_1: 0.660430, top_k: 0.855898, samples/s: 1730.829 1612926129.030048
train: epoch 117, iter 2400, loss: 2.404982, top_1: 0.656641, top_k: 0.853633, samples/s: 1731.032 1612926143.8189263
train: epoch 117, iter 2500, loss: 2.419490, top_1: 0.665664, top_k: 0.857891, samples/s: 1736.041 1612926158.565091
train: epoch 117, iter 2600, loss: 2.404403, top_1: 0.662695, top_k: 0.858281, samples/s: 1747.778 1612926173.2122715
train: epoch 117, iter 2700, loss: 2.312171, top_1: 0.662969, top_k: 0.852969, samples/s: 1742.958 1612926187.8999968
train: epoch 117, iter 2800, loss: 2.352807, top_1: 0.658945, top_k: 0.855586, samples/s: 1734.125 1612926202.6624858
train: epoch 117, iter 2900, loss: 2.431828, top_1: 0.657109, top_k: 0.855938, samples/s: 1728.571 1612926217.472458
train: epoch 117, iter 3000, loss: 2.554494, top_1: 0.658203, top_k: 0.856563, samples/s: 1758.171 1612926232.0329323
train: epoch 117, iter 3100, loss: 2.322314, top_1: 0.664531, top_k: 0.858711, samples/s: 1723.060 1612926246.890309
train: epoch 117, iter 3200, loss: 2.423060, top_1: 0.664062, top_k: 0.862500, samples/s: 1742.928 1612926261.5781424
train: epoch 117, iter 3300, loss: 2.508774, top_1: 0.660508, top_k: 0.852148, samples/s: 1733.396 1612926276.346856
train: epoch 117, iter 3400, loss: 2.395764, top_1: 0.661641, top_k: 0.852891, samples/s: 1744.887 1612926291.0182931
train: epoch 117, iter 3500, loss: 2.317407, top_1: 0.658125, top_k: 0.857617, samples/s: 1729.219 1612926305.8226626
train: epoch 117, iter 3600, loss: 2.553099, top_1: 0.658945, top_k: 0.857617, samples/s: 1734.711 1612926320.5801487
train: epoch 117, iter 3700, loss: 2.464961, top_1: 0.656680, top_k: 0.851719, samples/s: 1737.010 1612926335.318124
train: epoch 117, iter 3800, loss: 2.557851, top_1: 0.662031, top_k: 0.856602, samples/s: 1742.969 1612926350.0057
train: epoch 117, iter 3900, loss: 2.350601, top_1: 0.662578, top_k: 0.856875, samples/s: 1743.776 1612926364.6865306
train: epoch 117, iter 4000, loss: 2.317892, top_1: 0.664453, top_k: 0.858281, samples/s: 1738.949 1612926379.4080167
train: epoch 117, iter 4100, loss: 2.359961, top_1: 0.664883, top_k: 0.856953, samples/s: 1723.097 1612926394.2650092
train: epoch 117, iter 4200, loss: 2.623702, top_1: 0.658867, top_k: 0.855117, samples/s: 1725.378 1612926409.1023147
train: epoch 117, iter 4300, loss: 2.304211, top_1: 0.656758, top_k: 0.854141, samples/s: 1737.631 1612926423.8350456
train: epoch 117, iter 4400, loss: 2.278679, top_1: 0.655703, top_k: 0.856484, samples/s: 1737.550 1612926438.5684793
train: epoch 117, iter 4500, loss: 2.509988, top_1: 0.657852, top_k: 0.856406, samples/s: 1746.866 1612926453.2232628
train: epoch 117, iter 4600, loss: 2.607211, top_1: 0.652656, top_k: 0.851875, samples/s: 1742.982 1612926467.910701
train: epoch 117, iter 4700, loss: 2.463089, top_1: 0.666719, top_k: 0.858398, samples/s: 1734.583 1612926482.6693456
train: epoch 117, iter 4800, loss: 2.399584, top_1: 0.658438, top_k: 0.853672, samples/s: 1746.604 1612926497.3263063
train: epoch 117, iter 4900, loss: 2.372402, top_1: 0.659727, top_k: 0.855195, samples/s: 1748.276 1612926511.9693525
train: epoch 117, iter 5000, loss: 2.381975, top_1: 0.664453, top_k: 0.857187, samples/s: 1744.452 1612926526.6444337
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_117.
validation: epoch 117, iter 195, top_1: 0.698377, top_k: 0.894291, samples/s: 2888.350 1612926544.3446608
train: epoch 118, iter 100, loss: 2.378931, top_1: 0.666719, top_k: 0.862539, samples/s: 1742.204 1612926579.7941496
train: epoch 118, iter 200, loss: 2.406555, top_1: 0.670859, top_k: 0.864844, samples/s: 1765.365 1612926594.2952738
train: epoch 118, iter 300, loss: 2.414902, top_1: 0.670508, top_k: 0.861406, samples/s: 1759.945 1612926608.841287
train: epoch 118, iter 400, loss: 2.533015, top_1: 0.673008, top_k: 0.865273, samples/s: 1754.414 1612926623.4330313
train: epoch 118, iter 500, loss: 2.402963, top_1: 0.662617, top_k: 0.857891, samples/s: 1762.820 1612926637.9551494
train: epoch 118, iter 600, loss: 2.358953, top_1: 0.666562, top_k: 0.862070, samples/s: 1758.176 1612926652.5157456
train: epoch 118, iter 700, loss: 2.383639, top_1: 0.669961, top_k: 0.861445, samples/s: 1748.613 1612926667.1558523
train: epoch 118, iter 800, loss: 2.234785, top_1: 0.668789, top_k: 0.861016, samples/s: 1745.597 1612926681.8213174
train: epoch 118, iter 900, loss: 2.597870, top_1: 0.669805, top_k: 0.863320, samples/s: 1734.770 1612926696.5783954
train: epoch 118, iter 1000, loss: 2.507498, top_1: 0.672500, top_k: 0.863672, samples/s: 1734.319 1612926711.3392668
train: epoch 118, iter 1100, loss: 2.265410, top_1: 0.665625, top_k: 0.860938, samples/s: 1742.834 1612926726.0278826
train: epoch 118, iter 1200, loss: 2.169655, top_1: 0.665391, top_k: 0.859141, samples/s: 1733.329 1612926740.797148
train: epoch 118, iter 1300, loss: 2.270220, top_1: 0.665430, top_k: 0.857500, samples/s: 1749.505 1612926755.429818
train: epoch 118, iter 1400, loss: 2.278314, top_1: 0.665156, top_k: 0.859727, samples/s: 1740.096 1612926770.1416724
train: epoch 118, iter 1500, loss: 2.322360, top_1: 0.662148, top_k: 0.859258, samples/s: 1739.281 1612926784.8604772
train: epoch 118, iter 1600, loss: 2.431118, top_1: 0.671289, top_k: 0.859609, samples/s: 1747.553 1612926799.509505
train: epoch 118, iter 1700, loss: 2.392699, top_1: 0.660469, top_k: 0.858516, samples/s: 1736.075 1612926814.2554095
train: epoch 118, iter 1800, loss: 2.371293, top_1: 0.667422, top_k: 0.860469, samples/s: 1740.618 1612926828.9628026
train: epoch 118, iter 1900, loss: 2.319174, top_1: 0.664297, top_k: 0.859531, samples/s: 1731.582 1612926843.7470036
train: epoch 118, iter 2000, loss: 2.269660, top_1: 0.664141, top_k: 0.859766, samples/s: 1739.057 1612926858.4676495
train: epoch 118, iter 2100, loss: 2.231659, top_1: 0.663047, top_k: 0.858203, samples/s: 1731.097 1612926873.2558794
train: epoch 118, iter 2200, loss: 2.207741, top_1: 0.663516, top_k: 0.858320, samples/s: 1739.984 1612926887.9686992
train: epoch 118, iter 2300, loss: 2.519156, top_1: 0.660781, top_k: 0.859727, samples/s: 1747.537 1612926902.6178362
train: epoch 118, iter 2400, loss: 2.347781, top_1: 0.669102, top_k: 0.857773, samples/s: 1744.722 1612926917.2907674
train: epoch 118, iter 2500, loss: 2.453102, top_1: 0.665664, top_k: 0.857734, samples/s: 1725.257 1612926932.129045
train: epoch 118, iter 2600, loss: 2.496740, top_1: 0.660664, top_k: 0.855625, samples/s: 1738.133 1612926946.8575072
train: epoch 118, iter 2700, loss: 2.345505, top_1: 0.664375, top_k: 0.859727, samples/s: 1724.281 1612926961.70433
train: epoch 118, iter 2800, loss: 2.433473, top_1: 0.665078, top_k: 0.859805, samples/s: 1744.071 1612926976.3826094
train: epoch 118, iter 2900, loss: 2.313579, top_1: 0.662383, top_k: 0.857109, samples/s: 1738.576 1612926991.1072514
train: epoch 118, iter 3000, loss: 2.586025, top_1: 0.665508, top_k: 0.861445, samples/s: 1743.035 1612927005.794278
train: epoch 118, iter 3100, loss: 2.280325, top_1: 0.658789, top_k: 0.856484, samples/s: 1741.962 1612927020.4903615
train: epoch 118, iter 3200, loss: 2.522372, top_1: 0.656289, top_k: 0.854961, samples/s: 1725.948 1612927035.3232343
train: epoch 118, iter 3300, loss: 2.325224, top_1: 0.664375, top_k: 0.858398, samples/s: 1746.250 1612927049.9827666
train: epoch 118, iter 3400, loss: 2.368344, top_1: 0.666523, top_k: 0.854492, samples/s: 1730.123 1612927064.779441
train: epoch 118, iter 3500, loss: 2.417755, top_1: 0.664414, top_k: 0.859062, samples/s: 1736.022 1612927079.5257964
train: epoch 118, iter 3600, loss: 2.332102, top_1: 0.664258, top_k: 0.859336, samples/s: 1742.050 1612927094.221211
train: epoch 118, iter 3700, loss: 2.516554, top_1: 0.662266, top_k: 0.855469, samples/s: 1744.101 1612927108.8994772
train: epoch 118, iter 3800, loss: 2.439736, top_1: 0.668789, top_k: 0.861523, samples/s: 1746.315 1612927123.5586376
train: epoch 118, iter 3900, loss: 2.277071, top_1: 0.659414, top_k: 0.857500, samples/s: 1727.569 1612927138.3774667
train: epoch 118, iter 4000, loss: 2.542770, top_1: 0.666094, top_k: 0.859375, samples/s: 1734.557 1612927153.1359613
train: epoch 118, iter 4100, loss: 2.366902, top_1: 0.660117, top_k: 0.855430, samples/s: 1730.153 1612927167.9322908
train: epoch 118, iter 4200, loss: 2.316679, top_1: 0.666250, top_k: 0.859805, samples/s: 1751.000 1612927182.552497
train: epoch 118, iter 4300, loss: 2.489957, top_1: 0.663828, top_k: 0.857539, samples/s: 1740.088 1612927197.2647233
train: epoch 118, iter 4400, loss: 2.443292, top_1: 0.661133, top_k: 0.858477, samples/s: 1735.376 1612927212.0162492
train: epoch 118, iter 4500, loss: 2.399893, top_1: 0.664727, top_k: 0.858203, samples/s: 1728.308 1612927226.828401
train: epoch 118, iter 4600, loss: 2.204827, top_1: 0.659453, top_k: 0.856758, samples/s: 1750.683 1612927241.4512687
train: epoch 118, iter 4700, loss: 2.521662, top_1: 0.662227, top_k: 0.858672, samples/s: 1743.664 1612927256.1329932
train: epoch 118, iter 4800, loss: 2.419774, top_1: 0.664648, top_k: 0.858945, samples/s: 1736.142 1612927270.8783514
train: epoch 118, iter 4900, loss: 2.429007, top_1: 0.659766, top_k: 0.856914, samples/s: 1746.336 1612927285.5376117
train: epoch 118, iter 5000, loss: 2.411966, top_1: 0.668359, top_k: 0.861289, samples/s: 1726.270 1612927300.3675635
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_118.
validation: epoch 118, iter 195, top_1: 0.694631, top_k: 0.892428, samples/s: 2861.455 1612927318.3068562
train: epoch 119, iter 100, loss: 2.451215, top_1: 0.670742, top_k: 0.861719, samples/s: 1754.813 1612927353.1665783
train: epoch 119, iter 200, loss: 2.465038, top_1: 0.675664, top_k: 0.860313, samples/s: 1756.051 1612927367.7451358
train: epoch 119, iter 300, loss: 2.300874, top_1: 0.667461, top_k: 0.861250, samples/s: 1759.352 1612927382.295509
train: epoch 119, iter 400, loss: 2.492868, top_1: 0.667578, top_k: 0.862852, samples/s: 1757.343 1612927396.8629854
train: epoch 119, iter 500, loss: 2.332918, top_1: 0.673320, top_k: 0.863008, samples/s: 1758.630 1612927411.419737
train: epoch 119, iter 600, loss: 2.438344, top_1: 0.670078, top_k: 0.861641, samples/s: 1744.903 1612927426.0910468
train: epoch 119, iter 700, loss: 2.434848, top_1: 0.670117, top_k: 0.864375, samples/s: 1768.095 1612927440.5699067
train: epoch 119, iter 800, loss: 2.421390, top_1: 0.666797, top_k: 0.860000, samples/s: 1746.428 1612927455.2284076
train: epoch 119, iter 900, loss: 2.292176, top_1: 0.671172, top_k: 0.865625, samples/s: 1740.739 1612927469.934787
train: epoch 119, iter 1000, loss: 2.505857, top_1: 0.669570, top_k: 0.863828, samples/s: 1734.889 1612927484.6908226
train: epoch 119, iter 1100, loss: 2.365008, top_1: 0.663984, top_k: 0.859219, samples/s: 1741.762 1612927499.3885803
train: epoch 119, iter 1200, loss: 2.331622, top_1: 0.675977, top_k: 0.864336, samples/s: 1729.936 1612927514.1867921
train: epoch 119, iter 1300, loss: 2.400061, top_1: 0.672734, top_k: 0.862266, samples/s: 1748.647 1612927528.8266566
train: epoch 119, iter 1400, loss: 2.412292, top_1: 0.666523, top_k: 0.858437, samples/s: 1736.888 1612927543.5656583
train: epoch 119, iter 1500, loss: 2.363481, top_1: 0.669453, top_k: 0.861211, samples/s: 1736.647 1612927558.3067129
train: epoch 119, iter 1600, loss: 2.389618, top_1: 0.668047, top_k: 0.864453, samples/s: 1743.512 1612927572.9897206
train: epoch 119, iter 1700, loss: 2.434263, top_1: 0.669219, top_k: 0.862070, samples/s: 1744.201 1612927587.6669228
train: epoch 119, iter 1800, loss: 2.466712, top_1: 0.669258, top_k: 0.865625, samples/s: 1733.195 1612927602.4373834
train: epoch 119, iter 1900, loss: 2.607904, top_1: 0.673672, top_k: 0.861055, samples/s: 1733.980 1612927617.2010798
train: epoch 119, iter 2000, loss: 2.360279, top_1: 0.660937, top_k: 0.857109, samples/s: 1730.274 1612927631.9965055
train: epoch 119, iter 2100, loss: 2.542243, top_1: 0.668633, top_k: 0.859336, samples/s: 1733.625 1612927646.763195
train: epoch 119, iter 2200, loss: 2.473508, top_1: 0.667773, top_k: 0.861719, samples/s: 1744.967 1612927661.4339132
train: epoch 119, iter 2300, loss: 2.210341, top_1: 0.672930, top_k: 0.860781, samples/s: 1734.344 1612927676.1945343
train: epoch 119, iter 2400, loss: 2.445124, top_1: 0.665273, top_k: 0.858594, samples/s: 1756.078 1612927690.772474
train: epoch 119, iter 2500, loss: 2.243185, top_1: 0.667852, top_k: 0.860430, samples/s: 1721.013 1612927705.6474838
train: epoch 119, iter 2600, loss: 2.533629, top_1: 0.666523, top_k: 0.859219, samples/s: 1733.346 1612927720.4165912
train: epoch 119, iter 2700, loss: 2.268939, top_1: 0.670664, top_k: 0.861211, samples/s: 1740.485 1612927735.1251333
train: epoch 119, iter 2800, loss: 2.369880, top_1: 0.666172, top_k: 0.860039, samples/s: 1723.069 1612927749.9823394
train: epoch 119, iter 2900, loss: 2.297715, top_1: 0.668125, top_k: 0.859180, samples/s: 1748.333 1612927764.6248307
train: epoch 119, iter 3000, loss: 2.270743, top_1: 0.665000, top_k: 0.859062, samples/s: 1725.420 1612927779.4617941
train: epoch 119, iter 3100, loss: 2.386706, top_1: 0.662383, top_k: 0.858477, samples/s: 1738.161 1612927794.1900332
train: epoch 119, iter 3200, loss: 2.332552, top_1: 0.668203, top_k: 0.860820, samples/s: 1734.614 1612927808.9483583
train: epoch 119, iter 3300, loss: 2.318274, top_1: 0.666094, top_k: 0.859531, samples/s: 1740.475 1612927823.6569705
train: epoch 119, iter 3400, loss: 2.361932, top_1: 0.662383, top_k: 0.857070, samples/s: 1746.074 1612927838.3184268
train: epoch 119, iter 3500, loss: 2.190474, top_1: 0.666445, top_k: 0.860469, samples/s: 1740.864 1612927853.0237684
train: epoch 119, iter 3600, loss: 2.424007, top_1: 0.664180, top_k: 0.859492, samples/s: 1744.184 1612927867.7011797
train: epoch 119, iter 3700, loss: 2.440179, top_1: 0.666250, top_k: 0.860742, samples/s: 1740.027 1612927882.4136515
train: epoch 119, iter 3800, loss: 2.529620, top_1: 0.668633, top_k: 0.861406, samples/s: 1741.104 1612927897.1169438
train: epoch 119, iter 3900, loss: 2.324752, top_1: 0.666523, top_k: 0.858320, samples/s: 1731.977 1612927911.8976798
train: epoch 119, iter 4000, loss: 2.194993, top_1: 0.663281, top_k: 0.859375, samples/s: 1738.145 1612927926.6259978
train: epoch 119, iter 4100, loss: 2.287968, top_1: 0.672930, top_k: 0.865234, samples/s: 1744.230 1612927941.3029504
train: epoch 119, iter 4200, loss: 2.318693, top_1: 0.668242, top_k: 0.858750, samples/s: 1743.146 1612927955.9891117
train: epoch 119, iter 4300, loss: 2.491452, top_1: 0.661758, top_k: 0.857734, samples/s: 1737.196 1612927970.725445
train: epoch 119, iter 4400, loss: 2.183981, top_1: 0.666211, top_k: 0.858984, samples/s: 1737.441 1612927985.45977
train: epoch 119, iter 4500, loss: 2.378032, top_1: 0.668789, top_k: 0.861602, samples/s: 1738.121 1612928000.1883154
train: epoch 119, iter 4600, loss: 2.291329, top_1: 0.666523, top_k: 0.858164, samples/s: 1735.295 1612928014.9408672
train: epoch 119, iter 4700, loss: 2.342233, top_1: 0.663281, top_k: 0.856563, samples/s: 1739.817 1612928029.6551015
train: epoch 119, iter 4800, loss: 2.454678, top_1: 0.666172, top_k: 0.857383, samples/s: 1727.805 1612928044.4715357
train: epoch 119, iter 4900, loss: 2.368864, top_1: 0.663281, top_k: 0.855938, samples/s: 1741.003 1612928059.175733
train: epoch 119, iter 5000, loss: 2.284657, top_1: 0.668086, top_k: 0.860586, samples/s: 1745.375 1612928073.8430626
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_119.
validation: epoch 119, iter 195, top_1: 0.698758, top_k: 0.895172, samples/s: 2922.445 1612928091.3909187
train: epoch 120, iter 100, loss: 2.283770, top_1: 0.674492, top_k: 0.867500, samples/s: 1746.984 1612928126.1602285
train: epoch 120, iter 200, loss: 2.449104, top_1: 0.676836, top_k: 0.869023, samples/s: 1759.865 1612928140.7069576
train: epoch 120, iter 300, loss: 2.185342, top_1: 0.674922, top_k: 0.863437, samples/s: 1751.872 1612928155.319672
train: epoch 120, iter 400, loss: 2.287620, top_1: 0.672734, top_k: 0.866484, samples/s: 1752.110 1612928169.9306357
train: epoch 120, iter 500, loss: 2.304957, top_1: 0.672813, top_k: 0.863203, samples/s: 1758.144 1612928184.4914224
train: epoch 120, iter 600, loss: 2.430301, top_1: 0.676055, top_k: 0.864844, samples/s: 1740.170 1612928199.2026227
train: epoch 120, iter 700, loss: 2.161084, top_1: 0.673633, top_k: 0.863828, samples/s: 1750.869 1612928213.8239303
train: epoch 120, iter 800, loss: 2.285456, top_1: 0.678047, top_k: 0.862070, samples/s: 1735.317 1612928228.5763588
train: epoch 120, iter 900, loss: 2.263983, top_1: 0.673867, top_k: 0.866367, samples/s: 1756.879 1612928243.147622
train: epoch 120, iter 1000, loss: 2.334390, top_1: 0.670586, top_k: 0.862969, samples/s: 1735.406 1612928257.8991647
train: epoch 120, iter 1100, loss: 2.293568, top_1: 0.673594, top_k: 0.863516, samples/s: 1731.827 1612928272.6812878
train: epoch 120, iter 1200, loss: 2.261958, top_1: 0.671484, top_k: 0.864805, samples/s: 1742.356 1612928287.3740244
train: epoch 120, iter 1300, loss: 2.148028, top_1: 0.667891, top_k: 0.863359, samples/s: 1735.978 1612928302.120754
train: epoch 120, iter 1400, loss: 2.490856, top_1: 0.670937, top_k: 0.867617, samples/s: 1740.548 1612928316.8287747
train: epoch 120, iter 1500, loss: 2.418971, top_1: 0.671875, top_k: 0.863750, samples/s: 1736.748 1612928331.5689294
train: epoch 120, iter 1600, loss: 2.315460, top_1: 0.672539, top_k: 0.868359, samples/s: 1741.197 1612928346.2715325
train: epoch 120, iter 1700, loss: 2.282338, top_1: 0.674297, top_k: 0.861172, samples/s: 1736.281 1612928361.0156052
train: epoch 120, iter 1800, loss: 2.245442, top_1: 0.664922, top_k: 0.860469, samples/s: 1711.450 1612928375.9737504
train: epoch 120, iter 1900, loss: 2.291101, top_1: 0.668438, top_k: 0.863359, samples/s: 1752.290 1612928390.5834215
train: epoch 120, iter 2000, loss: 2.398244, top_1: 0.672188, top_k: 0.864141, samples/s: 1744.479 1612928405.2580163
train: epoch 120, iter 2100, loss: 2.367059, top_1: 0.673789, top_k: 0.862812, samples/s: 1742.470 1612928419.9498644
train: epoch 120, iter 2200, loss: 2.297834, top_1: 0.672734, top_k: 0.863867, samples/s: 1749.980 1612928434.5785728
train: epoch 120, iter 2300, loss: 2.391144, top_1: 0.667383, top_k: 0.864570, samples/s: 1743.014 1612928449.266076
train: epoch 120, iter 2400, loss: 2.590346, top_1: 0.671328, top_k: 0.859727, samples/s: 1733.987 1612928464.0294564
train: epoch 120, iter 2500, loss: 2.377074, top_1: 0.670703, top_k: 0.862852, samples/s: 1738.238 1612928478.7570481
train: epoch 120, iter 2600, loss: 2.194986, top_1: 0.668945, top_k: 0.863828, samples/s: 1748.793 1612928493.3957133
train: epoch 120, iter 2700, loss: 2.301153, top_1: 0.668359, top_k: 0.863242, samples/s: 1732.151 1612928508.1749663
train: epoch 120, iter 2800, loss: 2.206604, top_1: 0.670742, top_k: 0.863906, samples/s: 1735.391 1612928522.9267256
train: epoch 120, iter 2900, loss: 2.384066, top_1: 0.667539, top_k: 0.859453, samples/s: 1732.379 1612928537.7040863
train: epoch 120, iter 3000, loss: 2.313478, top_1: 0.665430, top_k: 0.859023, samples/s: 1740.309 1612928552.4140725
train: epoch 120, iter 3100, loss: 2.278530, top_1: 0.669023, top_k: 0.858555, samples/s: 1738.447 1612928567.1398396
train: epoch 120, iter 3200, loss: 2.381715, top_1: 0.669883, top_k: 0.859219, samples/s: 1746.137 1612928581.8008492
train: epoch 120, iter 3300, loss: 2.458225, top_1: 0.670391, top_k: 0.862695, samples/s: 1744.630 1612928596.4743962
train: epoch 120, iter 3400, loss: 2.330693, top_1: 0.671680, top_k: 0.862539, samples/s: 1726.387 1612928611.3030524
train: epoch 120, iter 3500, loss: 2.479722, top_1: 0.665898, top_k: 0.860859, samples/s: 1747.735 1612928625.9506042
train: epoch 120, iter 3600, loss: 2.564559, top_1: 0.664687, top_k: 0.857930, samples/s: 1745.682 1612928640.6153798
train: epoch 120, iter 3700, loss: 2.374990, top_1: 0.666992, top_k: 0.859961, samples/s: 1734.157 1612928655.3775973
train: epoch 120, iter 3800, loss: 2.226194, top_1: 0.672266, top_k: 0.862969, samples/s: 1743.981 1612928670.05669
train: epoch 120, iter 3900, loss: 2.418607, top_1: 0.667148, top_k: 0.861484, samples/s: 1743.116 1612928684.7429776
train: epoch 120, iter 4000, loss: 2.385175, top_1: 0.669180, top_k: 0.860820, samples/s: 1748.266 1612928699.3860462
train: epoch 120, iter 4100, loss: 2.384594, top_1: 0.668203, top_k: 0.862891, samples/s: 1743.510 1612928714.0690596
train: epoch 120, iter 4200, loss: 2.270674, top_1: 0.666875, top_k: 0.863359, samples/s: 1736.485 1612928728.8114579
train: epoch 120, iter 4300, loss: 2.345704, top_1: 0.671094, top_k: 0.864180, samples/s: 1746.789 1612928743.4669375
train: epoch 120, iter 4400, loss: 2.254493, top_1: 0.669687, top_k: 0.863047, samples/s: 1735.302 1612928758.2193904
train: epoch 120, iter 4500, loss: 2.456748, top_1: 0.665117, top_k: 0.859961, samples/s: 1734.904 1612928772.975323
train: epoch 120, iter 4600, loss: 2.507533, top_1: 0.670547, top_k: 0.863867, samples/s: 1743.065 1612928787.6620634
train: epoch 120, iter 4700, loss: 2.372623, top_1: 0.669844, top_k: 0.860430, samples/s: 1733.075 1612928802.4334598
train: epoch 120, iter 4800, loss: 2.239250, top_1: 0.664883, top_k: 0.862422, samples/s: 1735.628 1612928817.1831725
train: epoch 120, iter 4900, loss: 2.381214, top_1: 0.669805, top_k: 0.866328, samples/s: 1738.507 1612928831.908545
train: epoch 120, iter 5000, loss: 2.469779, top_1: 0.669023, top_k: 0.861016, samples/s: 1745.105 1612928846.5780423
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_120.
validation: epoch 120, iter 195, top_1: 0.700501, top_k: 0.896114, samples/s: 2846.273 1612928864.5945349
train: epoch 121, iter 100, loss: 2.275948, top_1: 0.681992, top_k: 0.870859, samples/s: 1747.290 1612928904.6368911
train: epoch 121, iter 200, loss: 2.374187, top_1: 0.680000, top_k: 0.869531, samples/s: 1765.203 1612928919.1394093
train: epoch 121, iter 300, loss: 2.365648, top_1: 0.682461, top_k: 0.867656, samples/s: 1758.954 1612928933.6935127
train: epoch 121, iter 400, loss: 2.287015, top_1: 0.678633, top_k: 0.869258, samples/s: 1761.747 1612928948.2245772
train: epoch 121, iter 500, loss: 2.589082, top_1: 0.678047, top_k: 0.868125, samples/s: 1752.777 1612928962.8299644
train: epoch 121, iter 600, loss: 2.190068, top_1: 0.679102, top_k: 0.865508, samples/s: 1759.759 1612928977.3773637
train: epoch 121, iter 700, loss: 2.371281, top_1: 0.677188, top_k: 0.863437, samples/s: 1744.882 1612928992.0489037
train: epoch 121, iter 800, loss: 2.286863, top_1: 0.679453, top_k: 0.865469, samples/s: 1747.357 1612929006.6995356
train: epoch 121, iter 900, loss: 2.512894, top_1: 0.675078, top_k: 0.864961, samples/s: 1742.928 1612929021.3875253
train: epoch 121, iter 1000, loss: 2.363653, top_1: 0.678008, top_k: 0.867695, samples/s: 1732.001 1612929036.168054
train: epoch 121, iter 1100, loss: 2.612489, top_1: 0.667852, top_k: 0.861523, samples/s: 1743.264 1612929050.8531537
train: epoch 121, iter 1200, loss: 2.309716, top_1: 0.678477, top_k: 0.866445, samples/s: 1727.605 1612929065.6713605
train: epoch 121, iter 1300, loss: 2.372443, top_1: 0.679180, top_k: 0.867227, samples/s: 1745.573 1612929080.3372786
train: epoch 121, iter 1400, loss: 2.297472, top_1: 0.674805, top_k: 0.866445, samples/s: 1738.281 1612929095.0642254
train: epoch 121, iter 1500, loss: 2.438401, top_1: 0.675508, top_k: 0.869141, samples/s: 1720.962 1612929109.9396534
train: epoch 121, iter 1600, loss: 2.369060, top_1: 0.672383, top_k: 0.864883, samples/s: 1738.150 1612929124.6679442
train: epoch 121, iter 1700, loss: 2.422017, top_1: 0.668203, top_k: 0.860938, samples/s: 1742.052 1612929139.3633268
train: epoch 121, iter 1800, loss: 2.397418, top_1: 0.675430, top_k: 0.861602, samples/s: 1738.521 1612929154.0884604
train: epoch 121, iter 1900, loss: 2.453246, top_1: 0.673203, top_k: 0.863984, samples/s: 1735.629 1612929168.8381603
train: epoch 121, iter 2000, loss: 2.204746, top_1: 0.673008, top_k: 0.865430, samples/s: 1741.184 1612929183.5407975
train: epoch 121, iter 2100, loss: 2.241061, top_1: 0.673086, top_k: 0.866055, samples/s: 1741.001 1612929198.2449346
train: epoch 121, iter 2200, loss: 2.172212, top_1: 0.672227, top_k: 0.865625, samples/s: 1734.347 1612929213.0055254
train: epoch 121, iter 2300, loss: 2.445292, top_1: 0.672734, top_k: 0.864375, samples/s: 1748.750 1612929227.644531
train: epoch 121, iter 2400, loss: 2.442637, top_1: 0.673789, top_k: 0.865820, samples/s: 1719.128 1612929242.5358858
train: epoch 121, iter 2500, loss: 2.349857, top_1: 0.674141, top_k: 0.864375, samples/s: 1753.335 1612929257.136628
train: epoch 121, iter 2600, loss: 2.135481, top_1: 0.676133, top_k: 0.865391, samples/s: 1738.253 1612929271.8640192
train: epoch 121, iter 2700, loss: 2.478109, top_1: 0.668047, top_k: 0.861133, samples/s: 1728.808 1612929286.6719406
train: epoch 121, iter 2800, loss: 2.323457, top_1: 0.672695, top_k: 0.860625, samples/s: 1742.282 1612929301.3653092
train: epoch 121, iter 2900, loss: 2.450817, top_1: 0.668555, top_k: 0.861055, samples/s: 1743.547 1612929316.0479622
train: epoch 121, iter 3000, loss: 2.358309, top_1: 0.674063, top_k: 0.865000, samples/s: 1732.547 1612929330.8240154
train: epoch 121, iter 3100, loss: 2.390713, top_1: 0.667266, top_k: 0.862344, samples/s: 1743.215 1612929345.5094428
train: epoch 121, iter 3200, loss: 2.432468, top_1: 0.677266, top_k: 0.868203, samples/s: 1745.343 1612929360.1770694
train: epoch 121, iter 3300, loss: 2.383919, top_1: 0.670469, top_k: 0.857578, samples/s: 1719.098 1612929375.068656
train: epoch 121, iter 3400, loss: 2.499177, top_1: 0.667773, top_k: 0.859922, samples/s: 1751.257 1612929389.6866727
train: epoch 121, iter 3500, loss: 2.307401, top_1: 0.666172, top_k: 0.862773, samples/s: 1739.029 1612929404.40751
train: epoch 121, iter 3600, loss: 2.267904, top_1: 0.672070, top_k: 0.862109, samples/s: 1725.737 1612929419.2417521
train: epoch 121, iter 3700, loss: 2.305953, top_1: 0.671992, top_k: 0.863047, samples/s: 1748.564 1612929433.882378
train: epoch 121, iter 3800, loss: 2.333549, top_1: 0.672188, top_k: 0.862148, samples/s: 1728.117 1612929448.6961188
train: epoch 121, iter 3900, loss: 2.345946, top_1: 0.671211, top_k: 0.861836, samples/s: 1750.028 1612929463.3244786
train: epoch 121, iter 4000, loss: 2.379552, top_1: 0.671172, top_k: 0.862734, samples/s: 1744.289 1612929478.0009403
train: epoch 121, iter 4100, loss: 2.184133, top_1: 0.664687, top_k: 0.856953, samples/s: 1739.753 1612929492.7156992
train: epoch 121, iter 4200, loss: 2.463451, top_1: 0.675703, top_k: 0.865352, samples/s: 1732.204 1612929507.4945776
train: epoch 121, iter 4300, loss: 2.413867, top_1: 0.664609, top_k: 0.862344, samples/s: 1730.753 1612929522.2857766
train: epoch 121, iter 4400, loss: 2.199638, top_1: 0.672852, top_k: 0.864883, samples/s: 1749.364 1612929536.919714
train: epoch 121, iter 4500, loss: 2.300294, top_1: 0.672500, top_k: 0.864961, samples/s: 1739.206 1612929551.6390696
train: epoch 121, iter 4600, loss: 2.296826, top_1: 0.673242, top_k: 0.862734, samples/s: 1732.436 1612929566.4159682
train: epoch 121, iter 4700, loss: 2.315042, top_1: 0.673672, top_k: 0.864258, samples/s: 1749.718 1612929581.0468397
train: epoch 121, iter 4800, loss: 2.337789, top_1: 0.667695, top_k: 0.859961, samples/s: 1738.997 1612929595.768312
train: epoch 121, iter 4900, loss: 2.378257, top_1: 0.672266, top_k: 0.864766, samples/s: 1728.851 1612929610.5754848
train: epoch 121, iter 5000, loss: 2.312899, top_1: 0.673945, top_k: 0.863281, samples/s: 1728.742 1612929625.3839388
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_121.
validation: epoch 121, iter 195, top_1: 0.704026, top_k: 0.898377, samples/s: 2853.866 1612929643.2811217
train: epoch 122, iter 100, loss: 2.416893, top_1: 0.678203, top_k: 0.868555, samples/s: 1749.050 1612929678.3818948
train: epoch 122, iter 200, loss: 2.307319, top_1: 0.680273, top_k: 0.869023, samples/s: 1760.127 1612929692.926212
train: epoch 122, iter 300, loss: 2.208560, top_1: 0.679414, top_k: 0.865938, samples/s: 1757.388 1612929707.49329
train: epoch 122, iter 400, loss: 2.339965, top_1: 0.677266, top_k: 0.868477, samples/s: 1753.991 1612929722.0885856
train: epoch 122, iter 500, loss: 2.343419, top_1: 0.683242, top_k: 0.869023, samples/s: 1755.226 1612929736.673651
train: epoch 122, iter 600, loss: 2.234227, top_1: 0.673828, top_k: 0.867422, samples/s: 1759.538 1612929751.2228606
train: epoch 122, iter 700, loss: 2.174499, top_1: 0.675195, top_k: 0.866484, samples/s: 1750.125 1612929765.8504055
train: epoch 122, iter 800, loss: 2.274239, top_1: 0.680000, top_k: 0.869375, samples/s: 1752.022 1612929780.4626431
train: epoch 122, iter 900, loss: 2.379346, top_1: 0.673906, top_k: 0.865469, samples/s: 1740.423 1612929795.171141
train: epoch 122, iter 1000, loss: 2.468859, top_1: 0.672383, top_k: 0.861563, samples/s: 1725.878 1612929810.0042048
train: epoch 122, iter 1100, loss: 2.480057, top_1: 0.680078, top_k: 0.863516, samples/s: 1738.818 1612929824.726815
train: epoch 122, iter 1200, loss: 2.414730, top_1: 0.676562, top_k: 0.864414, samples/s: 1738.831 1612929839.4493876
train: epoch 122, iter 1300, loss: 2.334835, top_1: 0.680937, top_k: 0.869297, samples/s: 1737.551 1612929854.1827307
train: epoch 122, iter 1400, loss: 2.256811, top_1: 0.679766, top_k: 0.867734, samples/s: 1733.317 1612929868.9521968
train: epoch 122, iter 1500, loss: 2.194758, top_1: 0.676289, top_k: 0.866953, samples/s: 1736.606 1612929883.693505
train: epoch 122, iter 1600, loss: 2.190198, top_1: 0.679023, top_k: 0.868789, samples/s: 1747.899 1612929898.339758
train: epoch 122, iter 1700, loss: 2.304528, top_1: 0.678438, top_k: 0.867539, samples/s: 1738.090 1612929913.0684636
train: epoch 122, iter 1800, loss: 2.471404, top_1: 0.681445, top_k: 0.870938, samples/s: 1734.931 1612929927.8240974
train: epoch 122, iter 1900, loss: 2.277045, top_1: 0.679961, top_k: 0.867383, samples/s: 1737.087 1612929942.5614836
train: epoch 122, iter 2000, loss: 2.321400, top_1: 0.680820, top_k: 0.870156, samples/s: 1732.674 1612929957.3366528
train: epoch 122, iter 2100, loss: 2.463717, top_1: 0.676289, top_k: 0.868281, samples/s: 1727.212 1612929972.1578364
train: epoch 122, iter 2200, loss: 2.313187, top_1: 0.677891, top_k: 0.869414, samples/s: 1746.490 1612929986.815819
train: epoch 122, iter 2300, loss: 2.394765, top_1: 0.676719, top_k: 0.866055, samples/s: 1729.628 1612930001.61675
train: epoch 122, iter 2400, loss: 2.283213, top_1: 0.673281, top_k: 0.865547, samples/s: 1736.577 1612930016.3587785
train: epoch 122, iter 2500, loss: 2.212372, top_1: 0.673711, top_k: 0.865742, samples/s: 1748.217 1612930031.0018237
train: epoch 122, iter 2600, loss: 2.262488, top_1: 0.678672, top_k: 0.866172, samples/s: 1720.656 1612930045.8803604
train: epoch 122, iter 2700, loss: 2.611987, top_1: 0.670391, top_k: 0.864688, samples/s: 1745.422 1612930060.5468411
train: epoch 122, iter 2800, loss: 2.518672, top_1: 0.672930, top_k: 0.863242, samples/s: 1733.890 1612930075.3113048
train: epoch 122, iter 2900, loss: 2.434908, top_1: 0.674727, top_k: 0.866172, samples/s: 1726.109 1612930090.1423547
train: epoch 122, iter 3000, loss: 2.445941, top_1: 0.676445, top_k: 0.868906, samples/s: 1754.852 1612930104.7305336
train: epoch 122, iter 3100, loss: 2.337578, top_1: 0.674727, top_k: 0.867695, samples/s: 1727.622 1612930119.548543
train: epoch 122, iter 3200, loss: 2.427845, top_1: 0.675117, top_k: 0.866445, samples/s: 1738.671 1612930134.2728753
train: epoch 122, iter 3300, loss: 2.284105, top_1: 0.669063, top_k: 0.863906, samples/s: 1742.436 1612930148.9644856
train: epoch 122, iter 3400, loss: 2.289716, top_1: 0.676328, top_k: 0.867852, samples/s: 1735.190 1612930163.7179232
train: epoch 122, iter 3500, loss: 2.456636, top_1: 0.676680, top_k: 0.864922, samples/s: 1737.439 1612930178.4522965
train: epoch 122, iter 3600, loss: 2.385710, top_1: 0.673867, top_k: 0.867734, samples/s: 1731.282 1612930193.2389925
train: epoch 122, iter 3700, loss: 2.293615, top_1: 0.672227, top_k: 0.862773, samples/s: 1740.489 1612930207.9474835
train: epoch 122, iter 3800, loss: 2.277398, top_1: 0.671875, top_k: 0.866250, samples/s: 1737.654 1612930222.680039
train: epoch 122, iter 3900, loss: 2.568319, top_1: 0.672578, top_k: 0.861367, samples/s: 1741.159 1612930237.3829322
train: epoch 122, iter 4000, loss: 2.484535, top_1: 0.673867, top_k: 0.863516, samples/s: 1728.349 1612930252.194658
train: epoch 122, iter 4100, loss: 2.521303, top_1: 0.665664, top_k: 0.862578, samples/s: 1740.027 1612930266.907115
train: epoch 122, iter 4200, loss: 2.269120, top_1: 0.676484, top_k: 0.867266, samples/s: 1747.130 1612930281.5597157
train: epoch 122, iter 4300, loss: 2.389509, top_1: 0.670469, top_k: 0.862969, samples/s: 1744.609 1612930296.2335434
train: epoch 122, iter 4400, loss: 2.518820, top_1: 0.672188, top_k: 0.861172, samples/s: 1733.353 1612930311.0026078
train: epoch 122, iter 4500, loss: 2.296522, top_1: 0.674180, top_k: 0.866445, samples/s: 1738.851 1612930325.724878
train: epoch 122, iter 4600, loss: 2.152621, top_1: 0.675820, top_k: 0.866328, samples/s: 1747.149 1612930340.3773773
train: epoch 122, iter 4700, loss: 2.377536, top_1: 0.670391, top_k: 0.861055, samples/s: 1741.671 1612930355.0758533
train: epoch 122, iter 4800, loss: 2.239342, top_1: 0.672344, top_k: 0.862578, samples/s: 1732.363 1612930369.8533525
train: epoch 122, iter 4900, loss: 2.276541, top_1: 0.671680, top_k: 0.867109, samples/s: 1743.719 1612930384.53471
train: epoch 122, iter 5000, loss: 2.255634, top_1: 0.676602, top_k: 0.868750, samples/s: 1748.831 1612930399.1730146
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_122.
validation: epoch 122, iter 195, top_1: 0.707372, top_k: 0.899619, samples/s: 2876.261 1612930416.957428
train: epoch 123, iter 100, loss: 2.431664, top_1: 0.679063, top_k: 0.869766, samples/s: 1746.469 1612930451.738327
train: epoch 123, iter 200, loss: 2.098345, top_1: 0.683789, top_k: 0.869648, samples/s: 1748.060 1612930466.3831217
train: epoch 123, iter 300, loss: 2.254876, top_1: 0.675898, top_k: 0.867539, samples/s: 1768.542 1612930480.8583117
train: epoch 123, iter 400, loss: 2.226693, top_1: 0.677773, top_k: 0.866328, samples/s: 1759.127 1612930495.410959
train: epoch 123, iter 500, loss: 2.355080, top_1: 0.687344, top_k: 0.869844, samples/s: 1758.523 1612930509.9686792
train: epoch 123, iter 600, loss: 2.269624, top_1: 0.682852, top_k: 0.868242, samples/s: 1755.636 1612930524.550414
train: epoch 123, iter 700, loss: 2.478631, top_1: 0.680859, top_k: 0.870117, samples/s: 1741.827 1612930539.2474387
train: epoch 123, iter 800, loss: 2.269339, top_1: 0.683242, top_k: 0.871758, samples/s: 1743.127 1612930553.9337273
train: epoch 123, iter 900, loss: 2.414831, top_1: 0.679414, top_k: 0.863828, samples/s: 1749.714 1612930568.564688
train: epoch 123, iter 1000, loss: 2.256338, top_1: 0.685156, top_k: 0.872656, samples/s: 1740.710 1612930583.2712836
train: epoch 123, iter 1100, loss: 2.294576, top_1: 0.684766, top_k: 0.868945, samples/s: 1741.307 1612930597.972955
train: epoch 123, iter 1200, loss: 2.382092, top_1: 0.680352, top_k: 0.868516, samples/s: 1741.893 1612930612.669578
train: epoch 123, iter 1300, loss: 2.391065, top_1: 0.683516, top_k: 0.870859, samples/s: 1729.648 1612930627.470295
train: epoch 123, iter 1400, loss: 2.460462, top_1: 0.680273, top_k: 0.869062, samples/s: 1746.279 1612930642.1300578
train: epoch 123, iter 1500, loss: 2.571565, top_1: 0.679023, top_k: 0.868711, samples/s: 1742.427 1612930656.8222094
train: epoch 123, iter 1600, loss: 2.284107, top_1: 0.678750, top_k: 0.866133, samples/s: 1741.213 1612930671.524542
train: epoch 123, iter 1700, loss: 2.295231, top_1: 0.689648, top_k: 0.870195, samples/s: 1736.926 1612930686.2632453
train: epoch 123, iter 1800, loss: 2.330733, top_1: 0.680234, top_k: 0.868437, samples/s: 1732.421 1612930701.0402584
train: epoch 123, iter 1900, loss: 2.242934, top_1: 0.681250, top_k: 0.870156, samples/s: 1748.218 1612930715.6837008
train: epoch 123, iter 2000, loss: 2.262130, top_1: 0.676523, top_k: 0.867656, samples/s: 1734.135 1612930730.4461095
train: epoch 123, iter 2100, loss: 2.489278, top_1: 0.677930, top_k: 0.867891, samples/s: 1733.500 1612930745.2139142
train: epoch 123, iter 2200, loss: 2.209816, top_1: 0.679219, top_k: 0.868359, samples/s: 1720.976 1612930760.089288
train: epoch 123, iter 2300, loss: 2.391707, top_1: 0.679180, top_k: 0.870820, samples/s: 1738.348 1612930774.8158414
train: epoch 123, iter 2400, loss: 2.278001, top_1: 0.680586, top_k: 0.867734, samples/s: 1738.102 1612930789.5445278
train: epoch 123, iter 2500, loss: 2.413149, top_1: 0.671680, top_k: 0.866563, samples/s: 1737.776 1612930804.2760317
train: epoch 123, iter 2600, loss: 2.069789, top_1: 0.670117, top_k: 0.865781, samples/s: 1740.024 1612930818.988457
train: epoch 123, iter 2700, loss: 2.302703, top_1: 0.680117, top_k: 0.866602, samples/s: 1745.384 1612930833.6557643
train: epoch 123, iter 2800, loss: 2.337113, top_1: 0.674570, top_k: 0.865781, samples/s: 1730.439 1612930848.4496353
train: epoch 123, iter 2900, loss: 2.197556, top_1: 0.678945, top_k: 0.867461, samples/s: 1733.533 1612930863.2172432
train: epoch 123, iter 3000, loss: 2.342418, top_1: 0.674805, top_k: 0.864375, samples/s: 1731.465 1612930878.0023582
train: epoch 123, iter 3100, loss: 2.432532, top_1: 0.673984, top_k: 0.868750, samples/s: 1723.767 1612930892.8535373
train: epoch 123, iter 3200, loss: 2.370965, top_1: 0.679570, top_k: 0.867188, samples/s: 1728.822 1612930907.661389
train: epoch 123, iter 3300, loss: 2.162527, top_1: 0.672539, top_k: 0.864883, samples/s: 1723.350 1612930922.5161433
train: epoch 123, iter 3400, loss: 2.203965, top_1: 0.677852, top_k: 0.868359, samples/s: 1742.539 1612930937.2073145
train: epoch 123, iter 3500, loss: 2.324565, top_1: 0.676562, top_k: 0.867266, samples/s: 1749.096 1612930951.8435116
train: epoch 123, iter 3600, loss: 2.411994, top_1: 0.675195, top_k: 0.868477, samples/s: 1742.785 1612930966.5325627
train: epoch 123, iter 3700, loss: 2.247726, top_1: 0.678750, top_k: 0.865547, samples/s: 1719.969 1612930981.4165611
train: epoch 123, iter 3800, loss: 2.155586, top_1: 0.676211, top_k: 0.866055, samples/s: 1738.657 1612930996.140574
train: epoch 123, iter 3900, loss: 2.317285, top_1: 0.673750, top_k: 0.865820, samples/s: 1732.497 1612931010.9169276
train: epoch 123, iter 4000, loss: 2.354722, top_1: 0.683320, top_k: 0.868516, samples/s: 1734.761 1612931025.6740632
train: epoch 123, iter 4100, loss: 2.360086, top_1: 0.674531, top_k: 0.864922, samples/s: 1739.219 1612931040.3932638
train: epoch 123, iter 4200, loss: 2.370929, top_1: 0.682813, top_k: 0.868359, samples/s: 1743.451 1612931055.0767858
train: epoch 123, iter 4300, loss: 2.178021, top_1: 0.678828, top_k: 0.868164, samples/s: 1742.343 1612931069.7696638
train: epoch 123, iter 4400, loss: 2.264577, top_1: 0.676484, top_k: 0.866758, samples/s: 1743.448 1612931084.4531636
train: epoch 123, iter 4500, loss: 2.500224, top_1: 0.678320, top_k: 0.869141, samples/s: 1737.092 1612931099.1904554
train: epoch 123, iter 4600, loss: 2.331915, top_1: 0.675000, top_k: 0.864688, samples/s: 1730.918 1612931113.9803004
train: epoch 123, iter 4700, loss: 2.349871, top_1: 0.674336, top_k: 0.865039, samples/s: 1745.636 1612931128.6455965
train: epoch 123, iter 4800, loss: 2.258604, top_1: 0.671719, top_k: 0.861914, samples/s: 1741.434 1612931143.3459735
train: epoch 123, iter 4900, loss: 2.258893, top_1: 0.674766, top_k: 0.863594, samples/s: 1732.356 1612931158.1235797
train: epoch 123, iter 5000, loss: 2.263455, top_1: 0.684375, top_k: 0.867227, samples/s: 1741.057 1612931172.8273091
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_123.
validation: epoch 123, iter 195, top_1: 0.707592, top_k: 0.901222, samples/s: 2870.541 1612931190.699469
train: epoch 124, iter 100, loss: 2.469996, top_1: 0.691133, top_k: 0.876367, samples/s: 1754.940 1612931225.449858
train: epoch 124, iter 200, loss: 2.427233, top_1: 0.690000, top_k: 0.872852, samples/s: 1757.244 1612931240.018067
train: epoch 124, iter 300, loss: 2.157724, top_1: 0.687344, top_k: 0.873008, samples/s: 1758.641 1612931254.5749578
train: epoch 124, iter 400, loss: 2.200880, top_1: 0.687070, top_k: 0.869883, samples/s: 1755.912 1612931269.1541078
train: epoch 124, iter 500, loss: 2.204777, top_1: 0.683398, top_k: 0.871563, samples/s: 1752.218 1612931283.7641568
train: epoch 124, iter 600, loss: 2.457886, top_1: 0.682266, top_k: 0.870156, samples/s: 1753.334 1612931298.3648834
train: epoch 124, iter 700, loss: 2.380516, top_1: 0.680195, top_k: 0.866680, samples/s: 1744.822 1612931313.0369866
train: epoch 124, iter 800, loss: 2.340773, top_1: 0.681758, top_k: 0.868945, samples/s: 1746.288 1612931327.696601
train: epoch 124, iter 900, loss: 2.181198, top_1: 0.682070, top_k: 0.870586, samples/s: 1731.224 1612931342.4837663
train: epoch 124, iter 1000, loss: 2.310400, top_1: 0.685859, top_k: 0.871133, samples/s: 1750.254 1612931357.1102579
train: epoch 124, iter 1100, loss: 2.472924, top_1: 0.689297, top_k: 0.871797, samples/s: 1737.300 1612931371.8458211
train: epoch 124, iter 1200, loss: 2.369265, top_1: 0.681445, top_k: 0.868008, samples/s: 1738.313 1612931386.572757
train: epoch 124, iter 1300, loss: 2.349213, top_1: 0.684023, top_k: 0.872656, samples/s: 1737.844 1612931401.303532
train: epoch 124, iter 1400, loss: 2.232374, top_1: 0.682813, top_k: 0.870586, samples/s: 1728.816 1612931416.1113734
train: epoch 124, iter 1500, loss: 2.269320, top_1: 0.682109, top_k: 0.867109, samples/s: 1734.618 1612931430.8697088
train: epoch 124, iter 1600, loss: 2.295224, top_1: 0.683594, top_k: 0.871211, samples/s: 1736.209 1612931445.6144772
train: epoch 124, iter 1700, loss: 2.278536, top_1: 0.682031, top_k: 0.872539, samples/s: 1740.162 1612931460.3257308
train: epoch 124, iter 1800, loss: 2.260825, top_1: 0.680859, top_k: 0.870117, samples/s: 1733.936 1612931475.0898862
train: epoch 124, iter 1900, loss: 2.236679, top_1: 0.681875, top_k: 0.866484, samples/s: 1743.713 1612931489.7711716
train: epoch 124, iter 2000, loss: 2.204897, top_1: 0.680234, top_k: 0.865938, samples/s: 1736.914 1612931504.5099573
train: epoch 124, iter 2100, loss: 2.279456, top_1: 0.680156, top_k: 0.869297, samples/s: 1736.151 1612931519.2552028
train: epoch 124, iter 2200, loss: 2.286942, top_1: 0.681016, top_k: 0.867383, samples/s: 1734.641 1612931534.0133162
train: epoch 124, iter 2300, loss: 2.420718, top_1: 0.676797, top_k: 0.867031, samples/s: 1725.727 1612931548.8476048
train: epoch 124, iter 2400, loss: 2.323563, top_1: 0.674375, top_k: 0.867734, samples/s: 1731.446 1612931563.6329365
train: epoch 124, iter 2500, loss: 2.447585, top_1: 0.679453, top_k: 0.869453, samples/s: 1747.442 1612931578.2829082
train: epoch 124, iter 2600, loss: 2.211921, top_1: 0.684297, top_k: 0.871836, samples/s: 1738.352 1612931593.0095806
train: epoch 124, iter 2700, loss: 2.463948, top_1: 0.685352, top_k: 0.868437, samples/s: 1731.752 1612931607.7923
train: epoch 124, iter 2800, loss: 2.269097, top_1: 0.679844, top_k: 0.869023, samples/s: 1735.012 1612931622.5471268
train: epoch 124, iter 2900, loss: 2.264696, top_1: 0.678555, top_k: 0.869219, samples/s: 1740.619 1612931637.2545938
train: epoch 124, iter 3000, loss: 2.224331, top_1: 0.683828, top_k: 0.868516, samples/s: 1736.350 1612931651.9981244
train: epoch 124, iter 3100, loss: 2.355604, top_1: 0.678008, top_k: 0.865977, samples/s: 1749.022 1612931666.6350222
train: epoch 124, iter 3200, loss: 2.416997, top_1: 0.678438, top_k: 0.868242, samples/s: 1726.472 1612931681.462808
train: epoch 124, iter 3300, loss: 2.170716, top_1: 0.685586, top_k: 0.870820, samples/s: 1727.544 1612931696.2818954
train: epoch 124, iter 3400, loss: 2.250678, top_1: 0.682734, top_k: 0.868125, samples/s: 1734.514 1612931711.0407557
train: epoch 124, iter 3500, loss: 2.125486, top_1: 0.680352, top_k: 0.869766, samples/s: 1742.896 1612931725.7289236
train: epoch 124, iter 3600, loss: 2.339311, top_1: 0.683125, top_k: 0.867930, samples/s: 1742.158 1612931740.4235017
train: epoch 124, iter 3700, loss: 2.328541, top_1: 0.677656, top_k: 0.866133, samples/s: 1741.803 1612931755.1207297
train: epoch 124, iter 3800, loss: 2.341850, top_1: 0.679609, top_k: 0.867266, samples/s: 1747.013 1612931769.7743123
train: epoch 124, iter 3900, loss: 2.392892, top_1: 0.678906, top_k: 0.866250, samples/s: 1730.535 1612931784.5679421
train: epoch 124, iter 4000, loss: 2.369803, top_1: 0.677930, top_k: 0.867656, samples/s: 1747.827 1612931799.214185
train: epoch 124, iter 4100, loss: 2.332355, top_1: 0.677930, top_k: 0.865391, samples/s: 1726.829 1612931814.0391111
train: epoch 124, iter 4200, loss: 2.273495, top_1: 0.679297, top_k: 0.863789, samples/s: 1738.121 1612931828.7676263
train: epoch 124, iter 4300, loss: 2.394691, top_1: 0.677969, top_k: 0.864453, samples/s: 1733.502 1612931843.5355062
train: epoch 124, iter 4400, loss: 2.267395, top_1: 0.677500, top_k: 0.866953, samples/s: 1735.048 1612931858.290021
train: epoch 124, iter 4500, loss: 2.188539, top_1: 0.680781, top_k: 0.868203, samples/s: 1744.124 1612931872.96787
train: epoch 124, iter 4600, loss: 2.267798, top_1: 0.673945, top_k: 0.866094, samples/s: 1723.843 1612931887.8184104
train: epoch 124, iter 4700, loss: 2.367764, top_1: 0.680312, top_k: 0.867891, samples/s: 1722.625 1612931902.679453
train: epoch 124, iter 4800, loss: 2.226564, top_1: 0.678594, top_k: 0.867852, samples/s: 1734.943 1612931917.4349983
train: epoch 124, iter 4900, loss: 2.227252, top_1: 0.682578, top_k: 0.868086, samples/s: 1736.706 1612931932.1758974
train: epoch 124, iter 5000, loss: 2.288437, top_1: 0.682813, top_k: 0.873516, samples/s: 1741.590 1612931946.8748653
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_124.
validation: epoch 124, iter 195, top_1: 0.712059, top_k: 0.902284, samples/s: 2781.693 1612931965.2277849
train: epoch 125, iter 100, loss: 2.384888, top_1: 0.696992, top_k: 0.877227, samples/s: 1754.721 1612932000.0741556
train: epoch 125, iter 200, loss: 2.284989, top_1: 0.693906, top_k: 0.877070, samples/s: 1754.384 1612932014.6659632
train: epoch 125, iter 300, loss: 2.092732, top_1: 0.691523, top_k: 0.874961, samples/s: 1752.714 1612932029.272064
train: epoch 125, iter 400, loss: 2.398798, top_1: 0.684297, top_k: 0.870703, samples/s: 1761.018 1612932043.808911
train: epoch 125, iter 500, loss: 2.447724, top_1: 0.687617, top_k: 0.869375, samples/s: 1753.717 1612932058.4065392
train: epoch 125, iter 600, loss: 2.282449, top_1: 0.683633, top_k: 0.872461, samples/s: 1762.633 1612932072.930238
train: epoch 125, iter 700, loss: 2.497905, top_1: 0.682617, top_k: 0.871133, samples/s: 1741.071 1612932087.6338837
train: epoch 125, iter 800, loss: 2.280671, top_1: 0.688047, top_k: 0.871914, samples/s: 1742.766 1612932102.323157
train: epoch 125, iter 900, loss: 2.128399, top_1: 0.683125, top_k: 0.872617, samples/s: 1733.223 1612932117.093269
train: epoch 125, iter 1000, loss: 2.302222, top_1: 0.680117, top_k: 0.867422, samples/s: 1742.362 1612932131.7859843
train: epoch 125, iter 1100, loss: 2.120853, top_1: 0.681406, top_k: 0.870742, samples/s: 1737.767 1612932146.5175385
train: epoch 125, iter 1200, loss: 2.412048, top_1: 0.683203, top_k: 0.870938, samples/s: 1748.556 1612932161.1581843
train: epoch 125, iter 1300, loss: 2.546072, top_1: 0.686250, top_k: 0.873437, samples/s: 1730.634 1612932175.9505432
train: epoch 125, iter 1400, loss: 2.350336, top_1: 0.681680, top_k: 0.871289, samples/s: 1743.199 1612932190.6360884
train: epoch 125, iter 1500, loss: 2.389982, top_1: 0.684141, top_k: 0.869141, samples/s: 1728.514 1612932205.446565
train: epoch 125, iter 1600, loss: 2.465487, top_1: 0.684102, top_k: 0.869258, samples/s: 1731.091 1612932220.2348552
train: epoch 125, iter 1700, loss: 2.352570, top_1: 0.686562, top_k: 0.874141, samples/s: 1736.901 1612932234.974163
train: epoch 125, iter 1800, loss: 2.154770, top_1: 0.683867, top_k: 0.871719, samples/s: 1740.274 1612932249.684082
train: epoch 125, iter 1900, loss: 2.152763, top_1: 0.682852, top_k: 0.868125, samples/s: 1737.993 1612932264.4138134
train: epoch 125, iter 2000, loss: 2.322698, top_1: 0.683086, top_k: 0.868633, samples/s: 1732.422 1612932279.1907427
train: epoch 125, iter 2100, loss: 2.429564, top_1: 0.686484, top_k: 0.870742, samples/s: 1733.072 1612932293.9621923
train: epoch 125, iter 2200, loss: 2.316850, top_1: 0.679648, top_k: 0.869336, samples/s: 1717.308 1612932308.8692389
train: epoch 125, iter 2300, loss: 2.298147, top_1: 0.685195, top_k: 0.872266, samples/s: 1738.523 1612932323.5943673
train: epoch 125, iter 2400, loss: 2.412430, top_1: 0.681289, top_k: 0.870391, samples/s: 1733.850 1612932338.359255
train: epoch 125, iter 2500, loss: 2.441057, top_1: 0.681797, top_k: 0.869844, samples/s: 1737.817 1612932353.0903573
train: epoch 125, iter 2600, loss: 2.304576, top_1: 0.681250, top_k: 0.869141, samples/s: 1731.346 1612932367.8765159
train: epoch 125, iter 2700, loss: 2.474689, top_1: 0.682930, top_k: 0.871133, samples/s: 1736.367 1612932382.619938
train: epoch 125, iter 2800, loss: 2.239296, top_1: 0.685352, top_k: 0.869219, samples/s: 1731.346 1612932397.406139
train: epoch 125, iter 2900, loss: 2.360459, top_1: 0.685039, top_k: 0.869219, samples/s: 1733.390 1612932412.1749206
train: epoch 125, iter 3000, loss: 2.374412, top_1: 0.681133, top_k: 0.871055, samples/s: 1719.170 1612932427.065867
train: epoch 125, iter 3100, loss: 2.270207, top_1: 0.678672, top_k: 0.870000, samples/s: 1741.741 1612932441.7637188
train: epoch 125, iter 3200, loss: 2.462575, top_1: 0.681523, top_k: 0.867812, samples/s: 1744.031 1612932456.442426
train: epoch 125, iter 3300, loss: 2.396325, top_1: 0.681875, top_k: 0.871836, samples/s: 1727.166 1612932471.2644095
train: epoch 125, iter 3400, loss: 2.365677, top_1: 0.684609, top_k: 0.873906, samples/s: 1738.576 1612932485.9890237
train: epoch 125, iter 3500, loss: 2.165126, top_1: 0.682813, top_k: 0.871328, samples/s: 1736.051 1612932500.7351525
train: epoch 125, iter 3600, loss: 2.293285, top_1: 0.684219, top_k: 0.870352, samples/s: 1717.827 1612932515.6376834
train: epoch 125, iter 3700, loss: 2.301738, top_1: 0.682578, top_k: 0.869453, samples/s: 1759.534 1612932530.1870341
train: epoch 125, iter 3800, loss: 2.377207, top_1: 0.685156, top_k: 0.871133, samples/s: 1743.314 1612932544.8716693
train: epoch 125, iter 3900, loss: 2.297980, top_1: 0.681250, top_k: 0.870781, samples/s: 1725.162 1612932559.7109022
train: epoch 125, iter 4000, loss: 2.461425, top_1: 0.686875, top_k: 0.874102, samples/s: 1733.296 1612932574.4804037
train: epoch 125, iter 4100, loss: 2.337011, top_1: 0.678984, top_k: 0.868867, samples/s: 1740.917 1612932589.1853623
train: epoch 125, iter 4200, loss: 2.266460, top_1: 0.680898, top_k: 0.871172, samples/s: 1736.548 1612932603.927304
train: epoch 125, iter 4300, loss: 2.358929, top_1: 0.688438, top_k: 0.870938, samples/s: 1735.722 1612932618.6761148
train: epoch 125, iter 4400, loss: 2.389327, top_1: 0.685703, top_k: 0.870391, samples/s: 1734.891 1612932633.432062
train: epoch 125, iter 4500, loss: 2.537068, top_1: 0.682305, top_k: 0.870313, samples/s: 1735.489 1612932648.1830103
train: epoch 125, iter 4600, loss: 2.442534, top_1: 0.679844, top_k: 0.871211, samples/s: 1735.830 1612932662.931005
train: epoch 125, iter 4700, loss: 2.211092, top_1: 0.682266, top_k: 0.869180, samples/s: 1738.816 1612932677.6535983
train: epoch 125, iter 4800, loss: 2.324507, top_1: 0.682109, top_k: 0.873906, samples/s: 1727.170 1612932692.4756017
train: epoch 125, iter 4900, loss: 2.119297, top_1: 0.683281, top_k: 0.870430, samples/s: 1737.680 1612932707.2078836
train: epoch 125, iter 5000, loss: 2.257944, top_1: 0.690781, top_k: 0.873750, samples/s: 1744.015 1612932721.8865938
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_125.
validation: epoch 125, iter 195, top_1: 0.713642, top_k: 0.905188, samples/s: 2859.874 1612932739.7748191
train: epoch 126, iter 100, loss: 2.080070, top_1: 0.693633, top_k: 0.879258, samples/s: 1747.132 1612932775.1081033
train: epoch 126, iter 200, loss: 2.303360, top_1: 0.691016, top_k: 0.872656, samples/s: 1756.700 1612932789.6809742
train: epoch 126, iter 300, loss: 2.285213, top_1: 0.684805, top_k: 0.874844, samples/s: 1760.895 1612932804.218942
train: epoch 126, iter 400, loss: 2.319029, top_1: 0.689414, top_k: 0.873398, samples/s: 1759.223 1612932818.7708395
train: epoch 126, iter 500, loss: 2.347228, top_1: 0.691172, top_k: 0.875898, samples/s: 1755.627 1612932833.352557
train: epoch 126, iter 600, loss: 2.184665, top_1: 0.690195, top_k: 0.874180, samples/s: 1750.877 1612932847.973813
train: epoch 126, iter 700, loss: 2.130499, top_1: 0.691289, top_k: 0.873047, samples/s: 1742.196 1612932862.6679013
train: epoch 126, iter 800, loss: 2.145392, top_1: 0.693164, top_k: 0.873555, samples/s: 1741.340 1612932877.369164
train: epoch 126, iter 900, loss: 2.229919, top_1: 0.690117, top_k: 0.874805, samples/s: 1736.864 1612932892.1084318
train: epoch 126, iter 1000, loss: 2.407935, top_1: 0.691094, top_k: 0.873555, samples/s: 1737.240 1612932906.8444417
train: epoch 126, iter 1100, loss: 2.262036, top_1: 0.695664, top_k: 0.874414, samples/s: 1745.649 1612932921.5094657
train: epoch 126, iter 1200, loss: 2.213457, top_1: 0.688203, top_k: 0.867930, samples/s: 1735.287 1612932936.2620285
train: epoch 126, iter 1300, loss: 2.428321, top_1: 0.688555, top_k: 0.873086, samples/s: 1733.856 1612932951.0268521
train: epoch 126, iter 1400, loss: 2.250779, top_1: 0.688516, top_k: 0.872500, samples/s: 1742.216 1612932965.7207851
train: epoch 126, iter 1500, loss: 2.337260, top_1: 0.689688, top_k: 0.873906, samples/s: 1731.826 1612932980.5028074
train: epoch 126, iter 1600, loss: 2.380120, top_1: 0.684453, top_k: 0.871016, samples/s: 1739.756 1612932995.2175205
train: epoch 126, iter 1700, loss: 2.348654, top_1: 0.689102, top_k: 0.873203, samples/s: 1728.082 1612933010.0316951
train: epoch 126, iter 1800, loss: 2.381400, top_1: 0.689766, top_k: 0.871719, samples/s: 1735.412 1612933024.7831988
train: epoch 126, iter 1900, loss: 2.287452, top_1: 0.685937, top_k: 0.870898, samples/s: 1738.392 1612933039.5094483
train: epoch 126, iter 2000, loss: 2.278877, top_1: 0.685156, top_k: 0.873164, samples/s: 1741.028 1612933054.21339
train: epoch 126, iter 2100, loss: 2.200233, top_1: 0.688984, top_k: 0.873711, samples/s: 1726.069 1612933069.0447774
train: epoch 126, iter 2200, loss: 2.301255, top_1: 0.687461, top_k: 0.873984, samples/s: 1732.142 1612933083.8242207
train: epoch 126, iter 2300, loss: 2.520306, top_1: 0.683594, top_k: 0.872461, samples/s: 1732.749 1612933098.5987918
train: epoch 126, iter 2400, loss: 2.207260, top_1: 0.686055, top_k: 0.870195, samples/s: 1735.936 1612933113.345491
train: epoch 126, iter 2500, loss: 2.391371, top_1: 0.686328, top_k: 0.871055, samples/s: 1737.091 1612933128.0830631
train: epoch 126, iter 2600, loss: 2.285707, top_1: 0.684219, top_k: 0.868906, samples/s: 1738.885 1612933142.804883
train: epoch 126, iter 2700, loss: 2.277058, top_1: 0.688594, top_k: 0.874180, samples/s: 1736.078 1612933157.550734
train: epoch 126, iter 2800, loss: 2.415530, top_1: 0.687383, top_k: 0.875039, samples/s: 1728.330 1612933172.362695
train: epoch 126, iter 2900, loss: 2.282091, top_1: 0.682031, top_k: 0.869727, samples/s: 1747.035 1612933187.0161417
train: epoch 126, iter 3000, loss: 2.586991, top_1: 0.690703, top_k: 0.873203, samples/s: 1707.570 1612933202.008155
train: epoch 126, iter 3100, loss: 2.313127, top_1: 0.683203, top_k: 0.870195, samples/s: 1739.623 1612933216.7242708
train: epoch 126, iter 3200, loss: 2.304391, top_1: 0.685039, top_k: 0.871484, samples/s: 1735.628 1612933231.4737363
train: epoch 126, iter 3300, loss: 2.276149, top_1: 0.694414, top_k: 0.877305, samples/s: 1735.940 1612933246.2208068
train: epoch 126, iter 3400, loss: 2.228291, top_1: 0.684336, top_k: 0.869844, samples/s: 1729.661 1612933261.021426
train: epoch 126, iter 3500, loss: 2.244089, top_1: 0.684648, top_k: 0.870313, samples/s: 1747.743 1612933275.668862
train: epoch 126, iter 3600, loss: 2.215364, top_1: 0.683516, top_k: 0.872578, samples/s: 1741.824 1612933290.3665392
train: epoch 126, iter 3700, loss: 2.363254, top_1: 0.683398, top_k: 0.870195, samples/s: 1737.944 1612933305.0961103
train: epoch 126, iter 3800, loss: 2.296069, top_1: 0.684063, top_k: 0.871992, samples/s: 1727.325 1612933319.916715
train: epoch 126, iter 3900, loss: 2.415336, top_1: 0.691367, top_k: 0.873359, samples/s: 1728.703 1612933334.7256014
train: epoch 126, iter 4000, loss: 2.272828, top_1: 0.690664, top_k: 0.875156, samples/s: 1747.635 1612933349.3738778
train: epoch 126, iter 4100, loss: 2.163841, top_1: 0.685820, top_k: 0.872188, samples/s: 1729.851 1612933364.172908
train: epoch 126, iter 4200, loss: 2.302440, top_1: 0.690195, top_k: 0.875156, samples/s: 1746.813 1612933378.8281195
train: epoch 126, iter 4300, loss: 2.240535, top_1: 0.681172, top_k: 0.873203, samples/s: 1731.524 1612933393.612736
train: epoch 126, iter 4400, loss: 2.411875, top_1: 0.681289, top_k: 0.870898, samples/s: 1749.298 1612933408.247258
train: epoch 126, iter 4500, loss: 2.177960, top_1: 0.686406, top_k: 0.870391, samples/s: 1728.704 1612933423.056051
train: epoch 126, iter 4600, loss: 2.311958, top_1: 0.691602, top_k: 0.877617, samples/s: 1739.009 1612933437.7770052
train: epoch 126, iter 4700, loss: 2.313639, top_1: 0.689375, top_k: 0.872031, samples/s: 1747.121 1612933452.4296732
train: epoch 126, iter 4800, loss: 2.480271, top_1: 0.685156, top_k: 0.870352, samples/s: 1736.472 1612933467.1722834
train: epoch 126, iter 4900, loss: 2.393339, top_1: 0.684102, top_k: 0.871055, samples/s: 1738.814 1612933481.8949456
train: epoch 126, iter 5000, loss: 2.348031, top_1: 0.691562, top_k: 0.873164, samples/s: 1738.823 1612933496.6175752
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_126.
validation: epoch 126, iter 195, top_1: 0.715785, top_k: 0.904087, samples/s: 2826.179 1612933514.6747637
train: epoch 127, iter 100, loss: 2.051723, top_1: 0.700508, top_k: 0.880586, samples/s: 1747.476 1612933549.801456
train: epoch 127, iter 200, loss: 2.184303, top_1: 0.694375, top_k: 0.878555, samples/s: 1749.214 1612933564.4366496
train: epoch 127, iter 300, loss: 2.446141, top_1: 0.688281, top_k: 0.873867, samples/s: 1756.463 1612933579.0113213
train: epoch 127, iter 400, loss: 2.321135, top_1: 0.694180, top_k: 0.878086, samples/s: 1748.433 1612933593.6531975
train: epoch 127, iter 500, loss: 2.408480, top_1: 0.692031, top_k: 0.875977, samples/s: 1769.491 1612933608.1204293
train: epoch 127, iter 600, loss: 2.423050, top_1: 0.692305, top_k: 0.873125, samples/s: 1747.224 1612933622.7722352
train: epoch 127, iter 700, loss: 2.254533, top_1: 0.696953, top_k: 0.877734, samples/s: 1754.704 1612933637.3616936
train: epoch 127, iter 800, loss: 2.426702, top_1: 0.694141, top_k: 0.878711, samples/s: 1734.240 1612933652.1231225
train: epoch 127, iter 900, loss: 2.319378, top_1: 0.691367, top_k: 0.874609, samples/s: 1741.412 1612933666.8242633
train: epoch 127, iter 1000, loss: 2.224786, top_1: 0.694180, top_k: 0.877070, samples/s: 1739.437 1612933681.541234
train: epoch 127, iter 1100, loss: 2.264290, top_1: 0.691016, top_k: 0.874258, samples/s: 1727.515 1612933696.360261
train: epoch 127, iter 1200, loss: 2.249048, top_1: 0.690781, top_k: 0.876289, samples/s: 1731.643 1612933711.1438994
train: epoch 127, iter 1300, loss: 2.249645, top_1: 0.691133, top_k: 0.874297, samples/s: 1738.272 1612933725.8710973
train: epoch 127, iter 1400, loss: 2.164555, top_1: 0.692227, top_k: 0.875117, samples/s: 1737.583 1612933740.604289
train: epoch 127, iter 1500, loss: 2.216633, top_1: 0.685977, top_k: 0.874805, samples/s: 1721.668 1612933755.4735072
train: epoch 127, iter 1600, loss: 2.280133, top_1: 0.694766, top_k: 0.876914, samples/s: 1735.228 1612933770.2266865
train: epoch 127, iter 1700, loss: 2.341602, top_1: 0.689453, top_k: 0.874297, samples/s: 1740.778 1612933784.932749
train: epoch 127, iter 1800, loss: 2.296760, top_1: 0.693203, top_k: 0.876758, samples/s: 1744.569 1612933799.6068523
train: epoch 127, iter 1900, loss: 2.349732, top_1: 0.692539, top_k: 0.875859, samples/s: 1730.580 1612933814.3996174
train: epoch 127, iter 2000, loss: 2.353004, top_1: 0.694727, top_k: 0.875156, samples/s: 1741.032 1612933829.1034384
train: epoch 127, iter 2100, loss: 2.329666, top_1: 0.690156, top_k: 0.873633, samples/s: 1738.904 1612933843.8253615
train: epoch 127, iter 2200, loss: 2.511680, top_1: 0.686758, top_k: 0.873398, samples/s: 1736.066 1612933858.5713775
train: epoch 127, iter 2300, loss: 2.258960, top_1: 0.688828, top_k: 0.870820, samples/s: 1749.173 1612933873.2068312
train: epoch 127, iter 2400, loss: 2.348660, top_1: 0.693008, top_k: 0.874648, samples/s: 1730.358 1612933888.0015259
train: epoch 127, iter 2500, loss: 2.419847, top_1: 0.694297, top_k: 0.876680, samples/s: 1736.992 1612933902.7395842
train: epoch 127, iter 2600, loss: 2.254896, top_1: 0.686445, top_k: 0.871836, samples/s: 1735.625 1612933917.4893756
train: epoch 127, iter 2700, loss: 2.303301, top_1: 0.694727, top_k: 0.876758, samples/s: 1742.021 1612933932.1849227
train: epoch 127, iter 2800, loss: 2.365516, top_1: 0.689414, top_k: 0.871836, samples/s: 1737.402 1612933946.9195435
train: epoch 127, iter 2900, loss: 2.256587, top_1: 0.688906, top_k: 0.873203, samples/s: 1740.846 1612933961.6250575
train: epoch 127, iter 3000, loss: 2.260348, top_1: 0.687539, top_k: 0.873125, samples/s: 1727.250 1612933976.4463027
train: epoch 127, iter 3100, loss: 2.160966, top_1: 0.688008, top_k: 0.873398, samples/s: 1739.617 1612933991.162206
train: epoch 127, iter 3200, loss: 2.219249, top_1: 0.689922, top_k: 0.871445, samples/s: 1738.634 1612934005.8864183
train: epoch 127, iter 3300, loss: 2.332759, top_1: 0.689141, top_k: 0.876445, samples/s: 1742.119 1612934020.5811148
train: epoch 127, iter 3400, loss: 2.529397, top_1: 0.687852, top_k: 0.874687, samples/s: 1738.781 1612934035.3040693
train: epoch 127, iter 3500, loss: 2.306691, top_1: 0.693750, top_k: 0.873242, samples/s: 1738.996 1612934050.0252082
train: epoch 127, iter 3600, loss: 2.280467, top_1: 0.687305, top_k: 0.870391, samples/s: 1734.071 1612934064.788185
train: epoch 127, iter 3700, loss: 2.386581, top_1: 0.691406, top_k: 0.873867, samples/s: 1738.548 1612934079.5131009
train: epoch 127, iter 3800, loss: 2.305428, top_1: 0.689219, top_k: 0.874062, samples/s: 1727.997 1612934094.328006
train: epoch 127, iter 3900, loss: 2.305483, top_1: 0.691484, top_k: 0.875820, samples/s: 1744.940 1612934108.9989297
train: epoch 127, iter 4000, loss: 2.332053, top_1: 0.690117, top_k: 0.874727, samples/s: 1737.813 1612934123.7301276
train: epoch 127, iter 4100, loss: 2.285047, top_1: 0.690781, top_k: 0.871797, samples/s: 1745.360 1612934138.3975616
train: epoch 127, iter 4200, loss: 2.121301, top_1: 0.691016, top_k: 0.877383, samples/s: 1739.635 1612934153.1133296
train: epoch 127, iter 4300, loss: 2.277596, top_1: 0.690078, top_k: 0.874570, samples/s: 1733.765 1612934167.8789005
train: epoch 127, iter 4400, loss: 2.426285, top_1: 0.690898, top_k: 0.877266, samples/s: 1736.771 1612934182.6188583
train: epoch 127, iter 4500, loss: 2.180148, top_1: 0.687500, top_k: 0.874531, samples/s: 1744.124 1612934197.2967079
train: epoch 127, iter 4600, loss: 2.270251, top_1: 0.687813, top_k: 0.871016, samples/s: 1740.057 1612934212.0088692
train: epoch 127, iter 4700, loss: 2.399105, top_1: 0.685742, top_k: 0.871289, samples/s: 1737.920 1612934226.7390788
train: epoch 127, iter 4800, loss: 2.398955, top_1: 0.686250, top_k: 0.871602, samples/s: 1745.708 1612934241.4036849
train: epoch 127, iter 4900, loss: 2.487814, top_1: 0.686875, top_k: 0.875625, samples/s: 1742.193 1612934256.0978
train: epoch 127, iter 5000, loss: 2.130119, top_1: 0.695430, top_k: 0.877578, samples/s: 1742.656 1612934270.7879672
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_127.
validation: epoch 127, iter 195, top_1: 0.716226, top_k: 0.904687, samples/s: 2722.048 1612934289.5696445
train: epoch 128, iter 100, loss: 2.301775, top_1: 0.697695, top_k: 0.878359, samples/s: 1757.020 1612934324.2752843
train: epoch 128, iter 200, loss: 2.272633, top_1: 0.694336, top_k: 0.875547, samples/s: 1758.526 1612934338.833039
train: epoch 128, iter 300, loss: 2.367388, top_1: 0.702305, top_k: 0.880586, samples/s: 1750.840 1612934353.4544985
train: epoch 128, iter 400, loss: 2.322834, top_1: 0.696133, top_k: 0.878867, samples/s: 1763.512 1612934367.9709918
train: epoch 128, iter 500, loss: 2.257729, top_1: 0.696367, top_k: 0.878047, samples/s: 1755.113 1612934382.5569365
train: epoch 128, iter 600, loss: 2.395575, top_1: 0.696836, top_k: 0.878633, samples/s: 1761.527 1612934397.0897374
train: epoch 128, iter 700, loss: 2.340822, top_1: 0.693516, top_k: 0.877188, samples/s: 1729.959 1612934411.8877869
train: epoch 128, iter 800, loss: 2.239753, top_1: 0.702070, top_k: 0.881992, samples/s: 1745.510 1612934426.554027
train: epoch 128, iter 900, loss: 2.424669, top_1: 0.693203, top_k: 0.877773, samples/s: 1747.323 1612934441.205024
train: epoch 128, iter 1000, loss: 2.327682, top_1: 0.700156, top_k: 0.878867, samples/s: 1735.701 1612934455.9540355
train: epoch 128, iter 1100, loss: 2.183988, top_1: 0.692344, top_k: 0.876094, samples/s: 1726.919 1612934470.7781837
train: epoch 128, iter 1200, loss: 2.272783, top_1: 0.696250, top_k: 0.876602, samples/s: 1744.325 1612934485.454358
train: epoch 128, iter 1300, loss: 2.396574, top_1: 0.696562, top_k: 0.879766, samples/s: 1729.293 1612934500.2580798
train: epoch 128, iter 1400, loss: 2.243142, top_1: 0.687852, top_k: 0.873164, samples/s: 1749.421 1612934514.8914483
train: epoch 128, iter 1500, loss: 2.121686, top_1: 0.696211, top_k: 0.878320, samples/s: 1733.679 1612934529.6577451
train: epoch 128, iter 1600, loss: 2.353642, top_1: 0.697383, top_k: 0.878594, samples/s: 1731.058 1612934544.446447
train: epoch 128, iter 1700, loss: 2.145955, top_1: 0.692266, top_k: 0.877422, samples/s: 1749.138 1612934559.0821562
train: epoch 128, iter 1800, loss: 2.396513, top_1: 0.694961, top_k: 0.877305, samples/s: 1742.231 1612934573.7759547
train: epoch 128, iter 1900, loss: 2.302285, top_1: 0.694375, top_k: 0.877227, samples/s: 1733.631 1612934588.5427513
train: epoch 128, iter 2000, loss: 2.177634, top_1: 0.693633, top_k: 0.878398, samples/s: 1725.622 1612934603.3779056
train: epoch 128, iter 2100, loss: 2.497257, top_1: 0.691758, top_k: 0.875469, samples/s: 1729.130 1612934618.1830935
train: epoch 128, iter 2200, loss: 2.398919, top_1: 0.693984, top_k: 0.872070, samples/s: 1729.095 1612934632.988521
train: epoch 128, iter 2300, loss: 2.266809, top_1: 0.693984, top_k: 0.876797, samples/s: 1750.196 1612934647.6154041
train: epoch 128, iter 2400, loss: 2.270890, top_1: 0.698867, top_k: 0.877695, samples/s: 1736.916 1612934662.354203
train: epoch 128, iter 2500, loss: 2.102738, top_1: 0.694492, top_k: 0.876367, samples/s: 1742.159 1612934677.0486042
train: epoch 128, iter 2600, loss: 2.248834, top_1: 0.685625, top_k: 0.872500, samples/s: 1734.295 1612934691.809603
train: epoch 128, iter 2700, loss: 2.354057, top_1: 0.697773, top_k: 0.879375, samples/s: 1734.613 1612934706.5679948
train: epoch 128, iter 2800, loss: 2.378419, top_1: 0.692422, top_k: 0.877617, samples/s: 1735.800 1612934721.3163126
train: epoch 128, iter 2900, loss: 2.272603, top_1: 0.691016, top_k: 0.874453, samples/s: 1733.381 1612934736.0850573
train: epoch 128, iter 3000, loss: 2.277143, top_1: 0.694102, top_k: 0.876602, samples/s: 1723.334 1612934750.9399965
train: epoch 128, iter 3100, loss: 2.277557, top_1: 0.691680, top_k: 0.877773, samples/s: 1730.087 1612934765.7369235
train: epoch 128, iter 3200, loss: 2.329401, top_1: 0.695430, top_k: 0.875938, samples/s: 1743.559 1612934780.4194832
train: epoch 128, iter 3300, loss: 2.115748, top_1: 0.693086, top_k: 0.874102, samples/s: 1735.352 1612934795.1715155
train: epoch 128, iter 3400, loss: 2.235289, top_1: 0.691602, top_k: 0.875195, samples/s: 1736.731 1612934809.9119925
train: epoch 128, iter 3500, loss: 2.431184, top_1: 0.692734, top_k: 0.876953, samples/s: 1734.435 1612934824.6718278
train: epoch 128, iter 3600, loss: 2.332745, top_1: 0.690117, top_k: 0.872891, samples/s: 1737.221 1612934839.4079595
train: epoch 128, iter 3700, loss: 2.189259, top_1: 0.687539, top_k: 0.872109, samples/s: 1736.330 1612934854.151666
train: epoch 128, iter 3800, loss: 2.223074, top_1: 0.695742, top_k: 0.877773, samples/s: 1726.477 1612934868.9795823
train: epoch 128, iter 3900, loss: 2.413115, top_1: 0.691250, top_k: 0.877695, samples/s: 1729.831 1612934883.7787106
train: epoch 128, iter 4000, loss: 2.357734, top_1: 0.691211, top_k: 0.872383, samples/s: 1733.191 1612934898.549156
train: epoch 128, iter 4100, loss: 2.347700, top_1: 0.692578, top_k: 0.876406, samples/s: 1738.761 1612934913.2723594
train: epoch 128, iter 4200, loss: 2.225352, top_1: 0.700391, top_k: 0.881680, samples/s: 1738.087 1612934928.0011363
train: epoch 128, iter 4300, loss: 2.183532, top_1: 0.692656, top_k: 0.875352, samples/s: 1734.466 1612934942.760704
train: epoch 128, iter 4400, loss: 2.185997, top_1: 0.688438, top_k: 0.871758, samples/s: 1736.145 1612934957.506014
train: epoch 128, iter 4500, loss: 2.101431, top_1: 0.691797, top_k: 0.874297, samples/s: 1730.260 1612934972.3015118
train: epoch 128, iter 4600, loss: 2.304522, top_1: 0.690625, top_k: 0.872695, samples/s: 1735.107 1612934987.0556538
train: epoch 128, iter 4700, loss: 2.381565, top_1: 0.684688, top_k: 0.869102, samples/s: 1743.456 1612935001.7390232
train: epoch 128, iter 4800, loss: 2.356794, top_1: 0.691367, top_k: 0.876289, samples/s: 1740.641 1612935016.4462771
train: epoch 128, iter 4900, loss: 2.188603, top_1: 0.687148, top_k: 0.874531, samples/s: 1733.650 1612935031.2127936
train: epoch 128, iter 5000, loss: 2.175139, top_1: 0.698672, top_k: 0.881563, samples/s: 1727.229 1612935046.034334
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_128.
validation: epoch 128, iter 195, top_1: 0.719752, top_k: 0.907051, samples/s: 2861.624 1612935063.8455846
train: epoch 129, iter 100, loss: 2.232915, top_1: 0.697773, top_k: 0.882891, samples/s: 1747.463 1612935098.6964583
train: epoch 129, iter 200, loss: 2.131569, top_1: 0.702148, top_k: 0.879531, samples/s: 1762.492 1612935113.2212882
train: epoch 129, iter 300, loss: 2.269461, top_1: 0.703984, top_k: 0.881406, samples/s: 1750.766 1612935127.8434157
train: epoch 129, iter 400, loss: 2.391205, top_1: 0.701406, top_k: 0.881953, samples/s: 1758.047 1612935142.405003
train: epoch 129, iter 500, loss: 2.255559, top_1: 0.699375, top_k: 0.878203, samples/s: 1755.401 1612935156.9886646
train: epoch 129, iter 600, loss: 2.115443, top_1: 0.698594, top_k: 0.880469, samples/s: 1752.686 1612935171.5947719
train: epoch 129, iter 700, loss: 2.209619, top_1: 0.693945, top_k: 0.876992, samples/s: 1732.115 1612935186.374352
train: epoch 129, iter 800, loss: 2.318489, top_1: 0.695664, top_k: 0.878750, samples/s: 1734.931 1612935201.1300437
train: epoch 129, iter 900, loss: 2.288657, top_1: 0.700000, top_k: 0.881719, samples/s: 1731.841 1612935215.91204
train: epoch 129, iter 1000, loss: 2.434583, top_1: 0.695820, top_k: 0.875703, samples/s: 1740.442 1612935230.620932
train: epoch 129, iter 1100, loss: 2.383940, top_1: 0.702852, top_k: 0.880313, samples/s: 1742.334 1612935245.3138356
train: epoch 129, iter 1200, loss: 2.354628, top_1: 0.701445, top_k: 0.880117, samples/s: 1728.927 1612935260.120763
train: epoch 129, iter 1300, loss: 2.220440, top_1: 0.698516, top_k: 0.880664, samples/s: 1736.325 1612935274.8644705
train: epoch 129, iter 1400, loss: 2.535841, top_1: 0.695078, top_k: 0.879297, samples/s: 1742.773 1612935289.5537133
train: epoch 129, iter 1500, loss: 2.263102, top_1: 0.693438, top_k: 0.874219, samples/s: 1730.844 1612935304.3442416
train: epoch 129, iter 1600, loss: 2.141252, top_1: 0.699023, top_k: 0.880781, samples/s: 1732.045 1612935319.124432
train: epoch 129, iter 1700, loss: 2.431009, top_1: 0.695195, top_k: 0.878086, samples/s: 1724.345 1612935333.9706285
train: epoch 129, iter 1800, loss: 2.375285, top_1: 0.698945, top_k: 0.879219, samples/s: 1736.882 1612935348.7096574
train: epoch 129, iter 1900, loss: 2.387174, top_1: 0.694492, top_k: 0.877070, samples/s: 1723.593 1612935363.5623987
train: epoch 129, iter 2000, loss: 2.257980, top_1: 0.696016, top_k: 0.881211, samples/s: 1740.523 1612935378.2705512
train: epoch 129, iter 2100, loss: 2.269299, top_1: 0.698359, top_k: 0.879219, samples/s: 1740.537 1612935392.978632
train: epoch 129, iter 2200, loss: 2.251566, top_1: 0.695156, top_k: 0.877656, samples/s: 1733.076 1612935407.7500656
train: epoch 129, iter 2300, loss: 2.413545, top_1: 0.692422, top_k: 0.873633, samples/s: 1736.730 1612935422.49041
train: epoch 129, iter 2400, loss: 2.210131, top_1: 0.696445, top_k: 0.877734, samples/s: 1730.857 1612935437.2808268
train: epoch 129, iter 2500, loss: 2.274638, top_1: 0.699766, top_k: 0.878516, samples/s: 1743.228 1612935451.9662127
train: epoch 129, iter 2600, loss: 2.149529, top_1: 0.703164, top_k: 0.882148, samples/s: 1735.846 1612935466.714018
train: epoch 129, iter 2700, loss: 2.232892, top_1: 0.695508, top_k: 0.874961, samples/s: 1728.304 1612935481.526263
train: epoch 129, iter 2800, loss: 2.393516, top_1: 0.694141, top_k: 0.876367, samples/s: 1731.547 1612935496.3107398
train: epoch 129, iter 2900, loss: 2.176886, top_1: 0.696953, top_k: 0.877266, samples/s: 1725.029 1612935511.1511178
train: epoch 129, iter 3000, loss: 2.191256, top_1: 0.697656, top_k: 0.876680, samples/s: 1735.733 1612935525.8998532
train: epoch 129, iter 3100, loss: 2.154819, top_1: 0.692422, top_k: 0.876016, samples/s: 1734.182 1612935540.6622112
train: epoch 129, iter 3200, loss: 2.217515, top_1: 0.693594, top_k: 0.876406, samples/s: 1732.774 1612935555.4359665
train: epoch 129, iter 3300, loss: 2.260279, top_1: 0.698281, top_k: 0.881016, samples/s: 1743.759 1612935570.1168404
train: epoch 129, iter 3400, loss: 2.390222, top_1: 0.689727, top_k: 0.877461, samples/s: 1738.632 1612935584.8410196
train: epoch 129, iter 3500, loss: 2.457292, top_1: 0.695977, top_k: 0.876836, samples/s: 1732.486 1612935599.6175764
train: epoch 129, iter 3600, loss: 2.194680, top_1: 0.694258, top_k: 0.876836, samples/s: 1721.560 1612935614.487745
train: epoch 129, iter 3700, loss: 2.344357, top_1: 0.693672, top_k: 0.875195, samples/s: 1723.708 1612935629.3397205
train: epoch 129, iter 3800, loss: 2.213547, top_1: 0.695078, top_k: 0.880234, samples/s: 1740.099 1612935644.051263
train: epoch 129, iter 3900, loss: 2.166867, top_1: 0.697031, top_k: 0.877383, samples/s: 1722.901 1612935658.9098773
train: epoch 129, iter 4000, loss: 2.204422, top_1: 0.699336, top_k: 0.875195, samples/s: 1726.274 1612935673.7395442
train: epoch 129, iter 4100, loss: 2.234313, top_1: 0.694336, top_k: 0.876172, samples/s: 1733.789 1612935688.5049462
train: epoch 129, iter 4200, loss: 2.231507, top_1: 0.687461, top_k: 0.877148, samples/s: 1738.174 1612935703.2329955
train: epoch 129, iter 4300, loss: 2.186004, top_1: 0.690781, top_k: 0.875938, samples/s: 1726.500 1612935718.0607178
train: epoch 129, iter 4400, loss: 2.375554, top_1: 0.692891, top_k: 0.877578, samples/s: 1738.619 1612935732.7849674
train: epoch 129, iter 4500, loss: 2.228010, top_1: 0.691523, top_k: 0.876523, samples/s: 1737.760 1612935747.516559
train: epoch 129, iter 4600, loss: 2.321826, top_1: 0.697383, top_k: 0.877344, samples/s: 1729.767 1612935762.316292
train: epoch 129, iter 4700, loss: 2.081599, top_1: 0.694883, top_k: 0.878867, samples/s: 1735.320 1612935777.068564
train: epoch 129, iter 4800, loss: 2.275870, top_1: 0.699414, top_k: 0.878437, samples/s: 1727.672 1612935791.886257
train: epoch 129, iter 4900, loss: 2.195905, top_1: 0.694180, top_k: 0.877422, samples/s: 1728.809 1612935806.694096
train: epoch 129, iter 5000, loss: 2.282528, top_1: 0.696992, top_k: 0.875000, samples/s: 1740.551 1612935821.4021316
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_129.
validation: epoch 129, iter 195, top_1: 0.717328, top_k: 0.906310, samples/s: 2786.516 1612935839.753274
train: epoch 130, iter 100, loss: 2.185196, top_1: 0.702539, top_k: 0.881602, samples/s: 1723.204 1612935875.4838011
train: epoch 130, iter 200, loss: 2.163728, top_1: 0.706523, top_k: 0.880508, samples/s: 1760.244 1612935890.0272226
train: epoch 130, iter 300, loss: 2.315836, top_1: 0.704961, top_k: 0.882227, samples/s: 1758.759 1612935904.5829172
train: epoch 130, iter 400, loss: 2.114949, top_1: 0.706523, top_k: 0.880469, samples/s: 1756.546 1612935919.1570392
train: epoch 130, iter 500, loss: 2.210546, top_1: 0.700977, top_k: 0.882031, samples/s: 1759.395 1612935933.7074919
train: epoch 130, iter 600, loss: 2.178652, top_1: 0.700781, top_k: 0.880977, samples/s: 1745.330 1612935948.375182
train: epoch 130, iter 700, loss: 2.563025, top_1: 0.701445, top_k: 0.882500, samples/s: 1743.611 1612935963.0573785
train: epoch 130, iter 800, loss: 2.243929, top_1: 0.702812, top_k: 0.883828, samples/s: 1727.540 1612935977.8761415
train: epoch 130, iter 900, loss: 2.188191, top_1: 0.705937, top_k: 0.885000, samples/s: 1738.548 1612935992.6010585
train: epoch 130, iter 1000, loss: 2.204080, top_1: 0.704492, top_k: 0.881641, samples/s: 1735.977 1612936007.3478124
train: epoch 130, iter 1100, loss: 2.307056, top_1: 0.701523, top_k: 0.879727, samples/s: 1734.353 1612936022.1083317
train: epoch 130, iter 1200, loss: 2.292528, top_1: 0.695430, top_k: 0.877422, samples/s: 1737.289 1612936036.8439515
train: epoch 130, iter 1300, loss: 2.032241, top_1: 0.702734, top_k: 0.882422, samples/s: 1732.590 1612936051.6195254
train: epoch 130, iter 1400, loss: 2.405351, top_1: 0.698672, top_k: 0.878711, samples/s: 1728.735 1612936066.428089
train: epoch 130, iter 1500, loss: 2.408758, top_1: 0.702070, top_k: 0.878711, samples/s: 1732.784 1612936081.2020886
train: epoch 130, iter 1600, loss: 2.264748, top_1: 0.697031, top_k: 0.876250, samples/s: 1733.273 1612936095.9717603
train: epoch 130, iter 1700, loss: 2.183031, top_1: 0.697266, top_k: 0.879922, samples/s: 1741.064 1612936110.6754496
train: epoch 130, iter 1800, loss: 2.125324, top_1: 0.703750, top_k: 0.880977, samples/s: 1730.888 1612936125.4653947
train: epoch 130, iter 1900, loss: 2.138752, top_1: 0.702422, top_k: 0.883281, samples/s: 1730.410 1612936140.2595932
train: epoch 130, iter 2000, loss: 2.187835, top_1: 0.699766, top_k: 0.878164, samples/s: 1734.053 1612936155.0227444
train: epoch 130, iter 2100, loss: 2.370367, top_1: 0.695898, top_k: 0.877852, samples/s: 1736.972 1612936169.7609658
train: epoch 130, iter 2200, loss: 2.433774, top_1: 0.696992, top_k: 0.878242, samples/s: 1732.892 1612936184.534017
train: epoch 130, iter 2300, loss: 2.087276, top_1: 0.697500, top_k: 0.880430, samples/s: 1736.978 1612936199.2722201
train: epoch 130, iter 2400, loss: 2.379746, top_1: 0.695273, top_k: 0.875742, samples/s: 1731.847 1612936214.0541143
train: epoch 130, iter 2500, loss: 2.421607, top_1: 0.705508, top_k: 0.883906, samples/s: 1730.899 1612936228.8441303
train: epoch 130, iter 2600, loss: 2.097940, top_1: 0.702266, top_k: 0.879883, samples/s: 1730.069 1612936243.6412616
train: epoch 130, iter 2700, loss: 2.173432, top_1: 0.693750, top_k: 0.876328, samples/s: 1735.167 1612936258.3949003
train: epoch 130, iter 2800, loss: 2.219968, top_1: 0.698516, top_k: 0.879687, samples/s: 1726.182 1612936273.225263
train: epoch 130, iter 2900, loss: 2.248598, top_1: 0.700937, top_k: 0.878047, samples/s: 1729.038 1612936288.0312638
train: epoch 130, iter 3000, loss: 2.214913, top_1: 0.699922, top_k: 0.878984, samples/s: 1749.114 1612936302.6672351
train: epoch 130, iter 3100, loss: 2.218581, top_1: 0.699883, top_k: 0.881328, samples/s: 1738.639 1612936317.3913615
train: epoch 130, iter 3200, loss: 2.322561, top_1: 0.700664, top_k: 0.879336, samples/s: 1723.553 1612936332.2443566
train: epoch 130, iter 3300, loss: 2.302981, top_1: 0.700508, top_k: 0.879023, samples/s: 1727.417 1612936347.0641587
train: epoch 130, iter 3400, loss: 2.323493, top_1: 0.701094, top_k: 0.883164, samples/s: 1723.867 1612936361.9145367
train: epoch 130, iter 3500, loss: 2.078302, top_1: 0.702109, top_k: 0.883945, samples/s: 1722.868 1612936376.7735422
train: epoch 130, iter 3600, loss: 2.328409, top_1: 0.696055, top_k: 0.879570, samples/s: 1741.862 1612936391.4704044
train: epoch 130, iter 3700, loss: 2.396275, top_1: 0.694688, top_k: 0.876719, samples/s: 1730.925 1612936406.2601824
train: epoch 130, iter 3800, loss: 2.263880, top_1: 0.696602, top_k: 0.877656, samples/s: 1738.314 1612936420.9872668
train: epoch 130, iter 3900, loss: 2.202729, top_1: 0.699063, top_k: 0.881836, samples/s: 1739.592 1612936435.7031558
train: epoch 130, iter 4000, loss: 2.320494, top_1: 0.693711, top_k: 0.880469, samples/s: 1744.516 1612936450.3778245
train: epoch 130, iter 4100, loss: 2.297786, top_1: 0.698867, top_k: 0.876875, samples/s: 1712.485 1612936465.3267589
train: epoch 130, iter 4200, loss: 2.383741, top_1: 0.698398, top_k: 0.880391, samples/s: 1736.328 1612936480.0705743
train: epoch 130, iter 4300, loss: 2.292536, top_1: 0.694180, top_k: 0.877031, samples/s: 1742.876 1612936494.7589362
train: epoch 130, iter 4400, loss: 2.244063, top_1: 0.700703, top_k: 0.885117, samples/s: 1730.681 1612936509.5507367
train: epoch 130, iter 4500, loss: 2.064134, top_1: 0.698789, top_k: 0.878047, samples/s: 1741.714 1612936524.2489433
train: epoch 130, iter 4600, loss: 2.339335, top_1: 0.695781, top_k: 0.878203, samples/s: 1738.019 1612936538.9783957
train: epoch 130, iter 4700, loss: 2.248726, top_1: 0.694961, top_k: 0.878437, samples/s: 1734.240 1612936553.7398767
train: epoch 130, iter 4800, loss: 2.330939, top_1: 0.696914, top_k: 0.878555, samples/s: 1737.411 1612936568.474508
train: epoch 130, iter 4900, loss: 2.399691, top_1: 0.698438, top_k: 0.880352, samples/s: 1737.250 1612936583.210382
train: epoch 130, iter 5000, loss: 2.237390, top_1: 0.703633, top_k: 0.881641, samples/s: 1732.301 1612936597.988409
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_130.
validation: epoch 130, iter 195, top_1: 0.723698, top_k: 0.908934, samples/s: 2897.659 1612936615.6657844
train: epoch 131, iter 100, loss: 2.165617, top_1: 0.705039, top_k: 0.882578, samples/s: 1757.231 1612936650.8886435
train: epoch 131, iter 200, loss: 2.177463, top_1: 0.707383, top_k: 0.886016, samples/s: 1749.434 1612936665.5220735
train: epoch 131, iter 300, loss: 2.125785, top_1: 0.708906, top_k: 0.884219, samples/s: 1764.664 1612936680.0289495
train: epoch 131, iter 400, loss: 2.211590, top_1: 0.703594, top_k: 0.883359, samples/s: 1760.759 1612936694.5681584
train: epoch 131, iter 500, loss: 2.213557, top_1: 0.704336, top_k: 0.883203, samples/s: 1760.188 1612936709.1119223
train: epoch 131, iter 600, loss: 2.163196, top_1: 0.701758, top_k: 0.880547, samples/s: 1755.486 1612936723.6948447
train: epoch 131, iter 700, loss: 2.324142, top_1: 0.700508, top_k: 0.879922, samples/s: 1728.898 1612936738.5019777
train: epoch 131, iter 800, loss: 2.187073, top_1: 0.709023, top_k: 0.881211, samples/s: 1726.975 1612936753.3255742
train: epoch 131, iter 900, loss: 1.981506, top_1: 0.709844, top_k: 0.882656, samples/s: 1742.218 1612936768.0194728
train: epoch 131, iter 1000, loss: 2.173753, top_1: 0.703594, top_k: 0.883750, samples/s: 1733.551 1612936782.7868567
train: epoch 131, iter 1100, loss: 2.169787, top_1: 0.701641, top_k: 0.878359, samples/s: 1739.996 1612936797.4994755
train: epoch 131, iter 1200, loss: 2.363623, top_1: 0.709297, top_k: 0.884531, samples/s: 1721.710 1612936812.368519
train: epoch 131, iter 1300, loss: 2.241771, top_1: 0.706680, top_k: 0.880430, samples/s: 1746.026 1612936827.030382
train: epoch 131, iter 1400, loss: 2.266551, top_1: 0.704141, top_k: 0.882422, samples/s: 1737.778 1612936841.7617598
train: epoch 131, iter 1500, loss: 2.205171, top_1: 0.699688, top_k: 0.880469, samples/s: 1717.472 1612936856.6674318
train: epoch 131, iter 1600, loss: 2.268785, top_1: 0.701719, top_k: 0.881367, samples/s: 1730.144 1612936871.4638236
train: epoch 131, iter 1700, loss: 2.115595, top_1: 0.703086, top_k: 0.879180, samples/s: 1737.764 1612936886.195449
train: epoch 131, iter 1800, loss: 2.191796, top_1: 0.703281, top_k: 0.882227, samples/s: 1732.041 1612936900.9756863
train: epoch 131, iter 1900, loss: 2.254483, top_1: 0.701719, top_k: 0.878086, samples/s: 1739.888 1612936915.6893075
train: epoch 131, iter 2000, loss: 2.277638, top_1: 0.700547, top_k: 0.882812, samples/s: 1732.992 1612936930.461468
train: epoch 131, iter 2100, loss: 2.132459, top_1: 0.700508, top_k: 0.881094, samples/s: 1725.475 1612936945.2979248
train: epoch 131, iter 2200, loss: 2.248501, top_1: 0.703398, top_k: 0.880430, samples/s: 1732.526 1612936960.073993
train: epoch 131, iter 2300, loss: 2.289090, top_1: 0.702109, top_k: 0.881250, samples/s: 1728.788 1612936974.8820553
train: epoch 131, iter 2400, loss: 2.151608, top_1: 0.702695, top_k: 0.883164, samples/s: 1728.270 1612936989.694599
train: epoch 131, iter 2500, loss: 2.323035, top_1: 0.704727, top_k: 0.882852, samples/s: 1728.660 1612937004.5037048
train: epoch 131, iter 2600, loss: 2.262288, top_1: 0.701094, top_k: 0.878750, samples/s: 1723.620 1612937019.3562176
train: epoch 131, iter 2700, loss: 2.252897, top_1: 0.702070, top_k: 0.877891, samples/s: 1728.005 1612937034.1709945
train: epoch 131, iter 2800, loss: 2.173071, top_1: 0.698438, top_k: 0.881914, samples/s: 1737.355 1612937048.9060462
train: epoch 131, iter 2900, loss: 2.432617, top_1: 0.698750, top_k: 0.880430, samples/s: 1737.246 1612937063.6420012
train: epoch 131, iter 3000, loss: 2.305360, top_1: 0.706016, top_k: 0.883164, samples/s: 1719.760 1612937078.5278137
train: epoch 131, iter 3100, loss: 2.231122, top_1: 0.700625, top_k: 0.879062, samples/s: 1742.774 1612937093.2170682
train: epoch 131, iter 3200, loss: 2.209826, top_1: 0.702578, top_k: 0.879297, samples/s: 1732.272 1612937107.9953017
train: epoch 131, iter 3300, loss: 2.296452, top_1: 0.697969, top_k: 0.876875, samples/s: 1730.480 1612937122.7888577
train: epoch 131, iter 3400, loss: 2.171695, top_1: 0.700742, top_k: 0.877812, samples/s: 1727.606 1612937137.6070254
train: epoch 131, iter 3500, loss: 2.273800, top_1: 0.695352, top_k: 0.881719, samples/s: 1718.798 1612937152.5012925
train: epoch 131, iter 3600, loss: 2.321877, top_1: 0.698594, top_k: 0.881367, samples/s: 1749.293 1612937167.1356747
train: epoch 131, iter 3700, loss: 2.225892, top_1: 0.700977, top_k: 0.882461, samples/s: 1729.193 1612937181.9402325
train: epoch 131, iter 3800, loss: 2.153085, top_1: 0.703750, top_k: 0.883789, samples/s: 1739.220 1612937196.6594872
train: epoch 131, iter 3900, loss: 2.172004, top_1: 0.703125, top_k: 0.883164, samples/s: 1737.330 1612937211.3947718
train: epoch 131, iter 4000, loss: 2.132593, top_1: 0.700547, top_k: 0.881328, samples/s: 1734.935 1612937226.150394
train: epoch 131, iter 4100, loss: 2.231279, top_1: 0.703867, top_k: 0.878242, samples/s: 1743.155 1612937240.8364067
train: epoch 131, iter 4200, loss: 2.495743, top_1: 0.697656, top_k: 0.879883, samples/s: 1736.749 1612937255.576586
train: epoch 131, iter 4300, loss: 2.221511, top_1: 0.696445, top_k: 0.878945, samples/s: 1732.543 1612937270.3524797
train: epoch 131, iter 4400, loss: 2.218049, top_1: 0.700234, top_k: 0.881445, samples/s: 1727.788 1612937285.1691144
train: epoch 131, iter 4500, loss: 2.257389, top_1: 0.710508, top_k: 0.881914, samples/s: 1717.500 1612937300.0745232
train: epoch 131, iter 4600, loss: 2.224534, top_1: 0.698789, top_k: 0.882578, samples/s: 1741.677 1612937314.7730222
train: epoch 131, iter 4700, loss: 2.331307, top_1: 0.700508, top_k: 0.879141, samples/s: 1734.448 1612937329.5327673
train: epoch 131, iter 4800, loss: 2.501821, top_1: 0.703047, top_k: 0.880078, samples/s: 1734.786 1612937344.289601
train: epoch 131, iter 4900, loss: 2.311098, top_1: 0.698008, top_k: 0.878516, samples/s: 1733.454 1612937359.05787
train: epoch 131, iter 5000, loss: 2.301126, top_1: 0.707266, top_k: 0.885703, samples/s: 1737.042 1612937373.7955256
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_131.
validation: epoch 131, iter 195, top_1: 0.724599, top_k: 0.909014, samples/s: 2857.843 1612937391.7065902
train: epoch 132, iter 100, loss: 2.294119, top_1: 0.711094, top_k: 0.887266, samples/s: 1753.134 1612937426.917759
train: epoch 132, iter 200, loss: 2.212020, top_1: 0.708125, top_k: 0.886328, samples/s: 1757.706 1612937441.4822903
train: epoch 132, iter 300, loss: 2.246119, top_1: 0.705117, top_k: 0.883398, samples/s: 1747.106 1612937456.134906
train: epoch 132, iter 400, loss: 2.217021, top_1: 0.701914, top_k: 0.884375, samples/s: 1766.931 1612937470.623212
train: epoch 132, iter 500, loss: 2.375715, top_1: 0.704688, top_k: 0.886172, samples/s: 1759.585 1612937485.172123
train: epoch 132, iter 600, loss: 2.152160, top_1: 0.710313, top_k: 0.883633, samples/s: 1747.305 1612937499.8233016
train: epoch 132, iter 700, loss: 2.421504, top_1: 0.708047, top_k: 0.883594, samples/s: 1731.638 1612937514.6069162
train: epoch 132, iter 800, loss: 2.325852, top_1: 0.705820, top_k: 0.883125, samples/s: 1733.807 1612937529.3721735
train: epoch 132, iter 900, loss: 2.300836, top_1: 0.705313, top_k: 0.882109, samples/s: 1732.461 1612937544.1488085
train: epoch 132, iter 1000, loss: 2.144706, top_1: 0.700703, top_k: 0.882266, samples/s: 1723.970 1612937558.9983442
train: epoch 132, iter 1100, loss: 2.414715, top_1: 0.708281, top_k: 0.884453, samples/s: 1735.152 1612937573.7520394
train: epoch 132, iter 1200, loss: 2.083455, top_1: 0.708984, top_k: 0.884414, samples/s: 1733.027 1612937588.5238128
train: epoch 132, iter 1300, loss: 2.297995, top_1: 0.707578, top_k: 0.881914, samples/s: 1741.886 1612937603.2205598
train: epoch 132, iter 1400, loss: 2.097234, top_1: 0.704414, top_k: 0.881406, samples/s: 1725.265 1612937618.0589464
train: epoch 132, iter 1500, loss: 2.215742, top_1: 0.706836, top_k: 0.884102, samples/s: 1741.103 1612937632.7622008
train: epoch 132, iter 1600, loss: 2.371580, top_1: 0.707891, top_k: 0.883125, samples/s: 1735.431 1612937647.5135741
train: epoch 132, iter 1700, loss: 2.167585, top_1: 0.704609, top_k: 0.885547, samples/s: 1730.520 1612937662.3067765
train: epoch 132, iter 1800, loss: 2.241002, top_1: 0.711367, top_k: 0.884883, samples/s: 1732.522 1612937677.0829852
train: epoch 132, iter 1900, loss: 2.331397, top_1: 0.707891, top_k: 0.885312, samples/s: 1718.363 1612937691.980848
train: epoch 132, iter 2000, loss: 2.316645, top_1: 0.710195, top_k: 0.887852, samples/s: 1742.873 1612937706.6692407
train: epoch 132, iter 2100, loss: 2.256759, top_1: 0.710352, top_k: 0.883711, samples/s: 1744.269 1612937721.3458445
train: epoch 132, iter 2200, loss: 2.331094, top_1: 0.708555, top_k: 0.885820, samples/s: 1749.810 1612937735.9760463
train: epoch 132, iter 2300, loss: 2.247633, top_1: 0.710469, top_k: 0.880977, samples/s: 1738.634 1612937750.7002168
train: epoch 132, iter 2400, loss: 2.335631, top_1: 0.705156, top_k: 0.884180, samples/s: 1750.366 1612937765.3257837
train: epoch 132, iter 2500, loss: 2.190602, top_1: 0.700586, top_k: 0.882383, samples/s: 1743.395 1612937780.0097177
train: epoch 132, iter 2600, loss: 2.100917, top_1: 0.707930, top_k: 0.886484, samples/s: 1750.272 1612937794.6360154
train: epoch 132, iter 2700, loss: 2.229844, top_1: 0.700664, top_k: 0.882656, samples/s: 1735.701 1612937809.3851435
train: epoch 132, iter 2800, loss: 2.322272, top_1: 0.708906, top_k: 0.883633, samples/s: 1738.750 1612937824.1083202
train: epoch 132, iter 2900, loss: 2.216643, top_1: 0.706406, top_k: 0.884844, samples/s: 1743.912 1612937838.7880697
train: epoch 132, iter 3000, loss: 2.246683, top_1: 0.701094, top_k: 0.879258, samples/s: 1743.001 1612937853.4753532
train: epoch 132, iter 3100, loss: 2.185176, top_1: 0.708633, top_k: 0.884570, samples/s: 1763.870 1612937867.988863
train: epoch 132, iter 3200, loss: 2.336797, top_1: 0.699180, top_k: 0.876758, samples/s: 1748.252 1612937882.6320662
train: epoch 132, iter 3300, loss: 2.063639, top_1: 0.702266, top_k: 0.882305, samples/s: 1735.337 1612937897.3842835
train: epoch 132, iter 3400, loss: 2.194567, top_1: 0.707187, top_k: 0.883516, samples/s: 1766.292 1612937911.8778908
train: epoch 132, iter 3500, loss: 2.488862, top_1: 0.700000, top_k: 0.879883, samples/s: 1748.100 1612937926.5223567
train: epoch 132, iter 3600, loss: 2.183503, top_1: 0.703945, top_k: 0.880586, samples/s: 1748.327 1612937941.1648765
train: epoch 132, iter 3700, loss: 2.154019, top_1: 0.705039, top_k: 0.884844, samples/s: 1752.401 1612937955.773435
train: epoch 132, iter 3800, loss: 2.353712, top_1: 0.704961, top_k: 0.884453, samples/s: 1741.189 1612937970.476025
train: epoch 132, iter 3900, loss: 2.258001, top_1: 0.708086, top_k: 0.884844, samples/s: 1762.374 1612937985.0018466
train: epoch 132, iter 4000, loss: 2.232327, top_1: 0.706641, top_k: 0.880977, samples/s: 1736.487 1612937999.7443879
train: epoch 132, iter 4100, loss: 2.344900, top_1: 0.709492, top_k: 0.884648, samples/s: 1754.177 1612938014.3380768
train: epoch 132, iter 4200, loss: 2.326210, top_1: 0.707344, top_k: 0.881523, samples/s: 1750.786 1612938028.9600642
train: epoch 132, iter 4300, loss: 2.209772, top_1: 0.698164, top_k: 0.882969, samples/s: 1753.403 1612938043.5602627
train: epoch 132, iter 4400, loss: 2.303689, top_1: 0.702930, top_k: 0.881797, samples/s: 1734.461 1612938058.3198738
train: epoch 132, iter 4500, loss: 2.293756, top_1: 0.699492, top_k: 0.880508, samples/s: 1741.481 1612938073.0200515
train: epoch 132, iter 4600, loss: 2.157046, top_1: 0.710938, top_k: 0.886836, samples/s: 1757.085 1612938087.589642
train: epoch 132, iter 4700, loss: 2.186830, top_1: 0.707383, top_k: 0.885078, samples/s: 1751.903 1612938102.202241
train: epoch 132, iter 4800, loss: 1.992704, top_1: 0.707617, top_k: 0.882422, samples/s: 1755.668 1612938116.7836103
train: epoch 132, iter 4900, loss: 2.314669, top_1: 0.710039, top_k: 0.883555, samples/s: 1747.176 1612938131.4358675
train: epoch 132, iter 5000, loss: 2.336924, top_1: 0.710273, top_k: 0.887813, samples/s: 1746.516 1612938146.093631
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_132.
validation: epoch 132, iter 195, top_1: 0.726322, top_k: 0.908814, samples/s: 2803.068 1612938164.3229785
train: epoch 133, iter 100, loss: 2.291031, top_1: 0.718633, top_k: 0.889961, samples/s: 1752.940 1612938199.550263
train: epoch 133, iter 200, loss: 2.261053, top_1: 0.716133, top_k: 0.888828, samples/s: 1759.653 1612938214.098534
train: epoch 133, iter 300, loss: 2.136201, top_1: 0.711719, top_k: 0.886172, samples/s: 1764.878 1612938228.603778
train: epoch 133, iter 400, loss: 2.305040, top_1: 0.712578, top_k: 0.883164, samples/s: 1756.379 1612938243.1792188
train: epoch 133, iter 500, loss: 2.084627, top_1: 0.709766, top_k: 0.882891, samples/s: 1758.104 1612938257.7403548
train: epoch 133, iter 600, loss: 2.301789, top_1: 0.713672, top_k: 0.889141, samples/s: 1746.749 1612938272.3963652
train: epoch 133, iter 700, loss: 2.246903, top_1: 0.712695, top_k: 0.888828, samples/s: 1759.974 1612938286.9418433
train: epoch 133, iter 800, loss: 2.096058, top_1: 0.712187, top_k: 0.886797, samples/s: 1737.532 1612938301.6753516
train: epoch 133, iter 900, loss: 2.144418, top_1: 0.709883, top_k: 0.887813, samples/s: 1727.152 1612938316.4975307
train: epoch 133, iter 1000, loss: 2.265510, top_1: 0.705273, top_k: 0.882539, samples/s: 1745.815 1612938331.1611605
train: epoch 133, iter 1100, loss: 2.109792, top_1: 0.711328, top_k: 0.885664, samples/s: 1738.430 1612938345.8870583
train: epoch 133, iter 1200, loss: 2.125381, top_1: 0.703867, top_k: 0.883906, samples/s: 1727.540 1612938360.7057662
train: epoch 133, iter 1300, loss: 2.201644, top_1: 0.714609, top_k: 0.888477, samples/s: 1728.708 1612938375.5145314
train: epoch 133, iter 1400, loss: 2.264928, top_1: 0.707109, top_k: 0.885391, samples/s: 1727.293 1612938390.335433
train: epoch 133, iter 1500, loss: 2.232342, top_1: 0.712656, top_k: 0.888789, samples/s: 1728.953 1612938405.1420636
train: epoch 133, iter 1600, loss: 2.102848, top_1: 0.711562, top_k: 0.889453, samples/s: 1747.705 1612938419.78986
train: epoch 133, iter 1700, loss: 2.167036, top_1: 0.713789, top_k: 0.889687, samples/s: 1728.124 1612938434.6035717
train: epoch 133, iter 1800, loss: 2.132579, top_1: 0.707656, top_k: 0.884102, samples/s: 1739.437 1612938449.3209548
train: epoch 133, iter 1900, loss: 2.202642, top_1: 0.709453, top_k: 0.887148, samples/s: 1735.119 1612938464.0750449
train: epoch 133, iter 2000, loss: 2.137653, top_1: 0.706797, top_k: 0.881016, samples/s: 1736.456 1612938478.8176565
train: epoch 133, iter 2100, loss: 2.211097, top_1: 0.706562, top_k: 0.884492, samples/s: 1733.061 1612938493.5892873
train: epoch 133, iter 2200, loss: 1.964586, top_1: 0.709063, top_k: 0.885664, samples/s: 1725.944 1612938508.4217732
train: epoch 133, iter 2300, loss: 2.211819, top_1: 0.705117, top_k: 0.885703, samples/s: 1736.019 1612938523.168102
train: epoch 133, iter 2400, loss: 2.234131, top_1: 0.714258, top_k: 0.883555, samples/s: 1724.374 1612938538.0140135
train: epoch 133, iter 2500, loss: 2.128520, top_1: 0.705898, top_k: 0.885000, samples/s: 1717.603 1612938552.9186165
train: epoch 133, iter 2600, loss: 2.049946, top_1: 0.705781, top_k: 0.884648, samples/s: 1733.668 1612938567.68494
train: epoch 133, iter 2700, loss: 2.162470, top_1: 0.709766, top_k: 0.887344, samples/s: 1734.975 1612938582.440222
train: epoch 133, iter 2800, loss: 2.261051, top_1: 0.705937, top_k: 0.883359, samples/s: 1727.310 1612938597.2609468
train: epoch 133, iter 2900, loss: 2.280386, top_1: 0.707227, top_k: 0.885156, samples/s: 1742.952 1612938611.9486043
train: epoch 133, iter 3000, loss: 2.155698, top_1: 0.703711, top_k: 0.883711, samples/s: 1728.372 1612938626.7602854
train: epoch 133, iter 3100, loss: 2.117526, top_1: 0.703086, top_k: 0.879883, samples/s: 1727.122 1612938641.582635
train: epoch 133, iter 3200, loss: 2.386176, top_1: 0.707969, top_k: 0.887188, samples/s: 1724.354 1612938656.428787
train: epoch 133, iter 3300, loss: 2.310431, top_1: 0.709492, top_k: 0.885430, samples/s: 1725.041 1612938671.2690039
train: epoch 133, iter 3400, loss: 2.252944, top_1: 0.705195, top_k: 0.884180, samples/s: 1730.392 1612938686.0633574
train: epoch 133, iter 3500, loss: 2.395090, top_1: 0.704688, top_k: 0.884648, samples/s: 1721.456 1612938700.9345248
train: epoch 133, iter 3600, loss: 2.139840, top_1: 0.708086, top_k: 0.885703, samples/s: 1732.388 1612938715.7117333
train: epoch 133, iter 3700, loss: 2.072972, top_1: 0.706055, top_k: 0.884922, samples/s: 1733.680 1612938730.4780357
train: epoch 133, iter 3800, loss: 2.350999, top_1: 0.704141, top_k: 0.881563, samples/s: 1730.090 1612938745.274932
train: epoch 133, iter 3900, loss: 2.268105, top_1: 0.705937, top_k: 0.883828, samples/s: 1736.834 1612938760.0144286
train: epoch 133, iter 4000, loss: 2.232073, top_1: 0.709766, top_k: 0.887813, samples/s: 1714.944 1612938774.9420135
train: epoch 133, iter 4100, loss: 2.177992, top_1: 0.707500, top_k: 0.884922, samples/s: 1729.980 1612938789.7399
train: epoch 133, iter 4200, loss: 2.123666, top_1: 0.706484, top_k: 0.883984, samples/s: 1726.003 1612938804.5718224
train: epoch 133, iter 4300, loss: 2.107415, top_1: 0.708828, top_k: 0.887891, samples/s: 1733.951 1612938819.3358197
train: epoch 133, iter 4400, loss: 2.295801, top_1: 0.706406, top_k: 0.884883, samples/s: 1741.774 1612938834.0334806
train: epoch 133, iter 4500, loss: 2.325990, top_1: 0.706523, top_k: 0.883828, samples/s: 1729.297 1612938848.8371277
train: epoch 133, iter 4600, loss: 2.149343, top_1: 0.707109, top_k: 0.883008, samples/s: 1733.430 1612938863.6055677
train: epoch 133, iter 4700, loss: 2.395100, top_1: 0.706172, top_k: 0.883789, samples/s: 1744.830 1612938878.2774975
train: epoch 133, iter 4800, loss: 2.291348, top_1: 0.710898, top_k: 0.888672, samples/s: 1748.742 1612938892.9165895
train: epoch 133, iter 4900, loss: 2.284861, top_1: 0.710430, top_k: 0.884023, samples/s: 1738.162 1612938907.6448514
train: epoch 133, iter 5000, loss: 2.112756, top_1: 0.710664, top_k: 0.885273, samples/s: 1738.674 1612938922.368613
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_133.
validation: epoch 133, iter 195, top_1: 0.729227, top_k: 0.913542, samples/s: 2788.934 1612938940.7667346
train: epoch 134, iter 100, loss: 2.272125, top_1: 0.719336, top_k: 0.889687, samples/s: 1750.432 1612938981.0962324
train: epoch 134, iter 200, loss: 2.306204, top_1: 0.715391, top_k: 0.884531, samples/s: 1757.280 1612938995.6643276
train: epoch 134, iter 300, loss: 2.216855, top_1: 0.716211, top_k: 0.890547, samples/s: 1765.856 1612939010.1612148
train: epoch 134, iter 400, loss: 2.217186, top_1: 0.715664, top_k: 0.887773, samples/s: 1758.308 1612939024.720691
train: epoch 134, iter 500, loss: 2.409356, top_1: 0.714141, top_k: 0.885742, samples/s: 1763.308 1612939039.2388465
train: epoch 134, iter 600, loss: 2.152512, top_1: 0.719492, top_k: 0.887305, samples/s: 1756.515 1612939053.8131366
train: epoch 134, iter 700, loss: 2.289706, top_1: 0.718867, top_k: 0.892695, samples/s: 1737.763 1612939068.544817
train: epoch 134, iter 800, loss: 2.304769, top_1: 0.716914, top_k: 0.891289, samples/s: 1734.682 1612939083.3024497
train: epoch 134, iter 900, loss: 2.216597, top_1: 0.717148, top_k: 0.890195, samples/s: 1735.841 1612939098.0504115
train: epoch 134, iter 1000, loss: 2.044295, top_1: 0.713086, top_k: 0.889844, samples/s: 1741.941 1612939112.7466595
train: epoch 134, iter 1100, loss: 2.111958, top_1: 0.714531, top_k: 0.888203, samples/s: 1725.597 1612939127.5820904
train: epoch 134, iter 1200, loss: 2.180817, top_1: 0.705703, top_k: 0.885625, samples/s: 1730.075 1612939142.3791301
train: epoch 134, iter 1300, loss: 2.236177, top_1: 0.714766, top_k: 0.890117, samples/s: 1720.541 1612939157.2581344
train: epoch 134, iter 1400, loss: 2.257220, top_1: 0.714922, top_k: 0.888359, samples/s: 1745.571 1612939171.9238517
train: epoch 134, iter 1500, loss: 1.972041, top_1: 0.718359, top_k: 0.887148, samples/s: 1741.093 1612939186.6273096
train: epoch 134, iter 1600, loss: 2.221379, top_1: 0.715078, top_k: 0.890664, samples/s: 1726.724 1612939201.4531171
train: epoch 134, iter 1700, loss: 2.113891, top_1: 0.714180, top_k: 0.887773, samples/s: 1727.598 1612939216.2712712
train: epoch 134, iter 1800, loss: 2.237695, top_1: 0.712656, top_k: 0.884805, samples/s: 1730.382 1612939231.065714
train: epoch 134, iter 1900, loss: 2.043121, top_1: 0.707109, top_k: 0.885195, samples/s: 1730.667 1612939245.8576791
train: epoch 134, iter 2000, loss: 2.184005, top_1: 0.712852, top_k: 0.886172, samples/s: 1718.335 1612939260.7559252
train: epoch 134, iter 2100, loss: 2.310729, top_1: 0.714531, top_k: 0.887734, samples/s: 1746.340 1612939275.4150977
train: epoch 134, iter 2200, loss: 2.210509, top_1: 0.717539, top_k: 0.889453, samples/s: 1740.737 1612939290.121488
train: epoch 134, iter 2300, loss: 2.262803, top_1: 0.714688, top_k: 0.886563, samples/s: 1721.801 1612939304.9896657
train: epoch 134, iter 2400, loss: 2.327265, top_1: 0.709727, top_k: 0.885898, samples/s: 1740.420 1612939319.698735
train: epoch 134, iter 2500, loss: 2.323353, top_1: 0.708438, top_k: 0.884219, samples/s: 1734.035 1612939334.4620128
train: epoch 134, iter 2600, loss: 2.323597, top_1: 0.716016, top_k: 0.888047, samples/s: 1731.935 1612939349.2431076
train: epoch 134, iter 2700, loss: 2.137360, top_1: 0.716016, top_k: 0.888359, samples/s: 1727.123 1612939364.065445
train: epoch 134, iter 2800, loss: 2.079089, top_1: 0.712461, top_k: 0.886523, samples/s: 1738.430 1612939378.7914188
train: epoch 134, iter 2900, loss: 2.087378, top_1: 0.708750, top_k: 0.885547, samples/s: 1725.444 1612939393.6282146
train: epoch 134, iter 3000, loss: 2.346538, top_1: 0.710703, top_k: 0.885508, samples/s: 1744.586 1612939408.302172
train: epoch 134, iter 3100, loss: 2.122961, top_1: 0.707656, top_k: 0.885859, samples/s: 1747.697 1612939422.9499762
train: epoch 134, iter 3200, loss: 2.396863, top_1: 0.709180, top_k: 0.882852, samples/s: 1738.149 1612939437.6782832
train: epoch 134, iter 3300, loss: 2.301356, top_1: 0.711250, top_k: 0.886797, samples/s: 1734.611 1612939452.436718
train: epoch 134, iter 3400, loss: 2.185041, top_1: 0.712461, top_k: 0.884219, samples/s: 1756.726 1612939467.009263
train: epoch 134, iter 3500, loss: 2.276115, top_1: 0.707969, top_k: 0.884336, samples/s: 1749.269 1612939481.6438916
train: epoch 134, iter 3600, loss: 2.197114, top_1: 0.708945, top_k: 0.885000, samples/s: 1748.791 1612939496.282615
train: epoch 134, iter 3700, loss: 2.342589, top_1: 0.710742, top_k: 0.889141, samples/s: 1744.954 1612939510.953499
train: epoch 134, iter 3800, loss: 2.126875, top_1: 0.706289, top_k: 0.886680, samples/s: 1749.635 1612939525.585056
train: epoch 134, iter 3900, loss: 2.128375, top_1: 0.709688, top_k: 0.882812, samples/s: 1736.628 1612939540.3264775
train: epoch 134, iter 4000, loss: 2.114896, top_1: 0.708633, top_k: 0.887539, samples/s: 1742.163 1612939555.0207436
train: epoch 134, iter 4100, loss: 2.209637, top_1: 0.710313, top_k: 0.883594, samples/s: 1744.948 1612939569.6916635
train: epoch 134, iter 4200, loss: 2.317758, top_1: 0.706914, top_k: 0.884766, samples/s: 1753.572 1612939584.290397
train: epoch 134, iter 4300, loss: 2.107580, top_1: 0.710430, top_k: 0.886367, samples/s: 1732.420 1612939599.0674508
train: epoch 134, iter 4400, loss: 2.351783, top_1: 0.707461, top_k: 0.881602, samples/s: 1754.227 1612939613.660733
train: epoch 134, iter 4500, loss: 2.193932, top_1: 0.709961, top_k: 0.887969, samples/s: 1749.433 1612939628.29405
train: epoch 134, iter 4600, loss: 2.371431, top_1: 0.711992, top_k: 0.881836, samples/s: 1748.857 1612939642.9321997
train: epoch 134, iter 4700, loss: 2.191391, top_1: 0.711562, top_k: 0.886367, samples/s: 1744.031 1612939657.610795
train: epoch 134, iter 4800, loss: 2.255129, top_1: 0.710078, top_k: 0.888281, samples/s: 1750.581 1612939672.2345166
train: epoch 134, iter 4900, loss: 2.223966, top_1: 0.716289, top_k: 0.888867, samples/s: 1748.149 1612939686.8791053
train: epoch 134, iter 5000, loss: 2.412507, top_1: 0.711211, top_k: 0.886563, samples/s: 1751.692 1612939701.4930358
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_134.
validation: epoch 134, iter 195, top_1: 0.732853, top_k: 0.914824, samples/s: 2873.740 1612939719.3161323
train: epoch 135, iter 100, loss: 2.187607, top_1: 0.718594, top_k: 0.890430, samples/s: 1759.056 1612939754.4442682
train: epoch 135, iter 200, loss: 2.095663, top_1: 0.719961, top_k: 0.891641, samples/s: 1750.756 1612939769.0664473
train: epoch 135, iter 300, loss: 2.330752, top_1: 0.716445, top_k: 0.890273, samples/s: 1751.394 1612939783.683453
train: epoch 135, iter 400, loss: 2.214661, top_1: 0.716602, top_k: 0.889844, samples/s: 1763.335 1612939798.2012937
train: epoch 135, iter 500, loss: 2.294856, top_1: 0.716953, top_k: 0.893711, samples/s: 1754.233 1612939812.7946088
train: epoch 135, iter 600, loss: 1.988046, top_1: 0.725078, top_k: 0.892891, samples/s: 1748.266 1612939827.4377053
train: epoch 135, iter 700, loss: 2.192335, top_1: 0.711992, top_k: 0.889727, samples/s: 1735.629 1612939842.1876218
train: epoch 135, iter 800, loss: 2.155045, top_1: 0.718203, top_k: 0.890312, samples/s: 1743.889 1612939856.8671927
train: epoch 135, iter 900, loss: 2.103972, top_1: 0.716797, top_k: 0.889961, samples/s: 1737.972 1612939871.5970523
train: epoch 135, iter 1000, loss: 2.276230, top_1: 0.717383, top_k: 0.891484, samples/s: 1727.140 1612939886.419192
train: epoch 135, iter 1100, loss: 2.127253, top_1: 0.711562, top_k: 0.891133, samples/s: 1739.260 1612939901.1381068
train: epoch 135, iter 1200, loss: 2.159837, top_1: 0.713008, top_k: 0.888320, samples/s: 1720.211 1612939916.0200286
train: epoch 135, iter 1300, loss: 1.977212, top_1: 0.715352, top_k: 0.889727, samples/s: 1730.185 1612939930.8161387
train: epoch 135, iter 1400, loss: 2.310879, top_1: 0.717148, top_k: 0.892461, samples/s: 1734.437 1612939945.5759795
train: epoch 135, iter 1500, loss: 2.211898, top_1: 0.716992, top_k: 0.887227, samples/s: 1727.414 1612939960.395808
train: epoch 135, iter 1600, loss: 2.335846, top_1: 0.716836, top_k: 0.887383, samples/s: 1737.810 1612939975.1270075
train: epoch 135, iter 1700, loss: 2.146184, top_1: 0.717070, top_k: 0.889687, samples/s: 1727.012 1612939989.9535303
train: epoch 135, iter 1800, loss: 2.210299, top_1: 0.711953, top_k: 0.889062, samples/s: 1733.325 1612940004.7195399
train: epoch 135, iter 1900, loss: 2.093929, top_1: 0.719219, top_k: 0.889531, samples/s: 1733.102 1612940019.490766
train: epoch 135, iter 2000, loss: 2.074644, top_1: 0.710664, top_k: 0.888437, samples/s: 1735.108 1612940034.2448697
train: epoch 135, iter 2100, loss: 2.175344, top_1: 0.714805, top_k: 0.887695, samples/s: 1730.968 1612940049.034331
train: epoch 135, iter 2200, loss: 2.033315, top_1: 0.711914, top_k: 0.888242, samples/s: 1736.502 1612940063.7765934
train: epoch 135, iter 2300, loss: 2.243886, top_1: 0.717539, top_k: 0.888477, samples/s: 1735.191 1612940078.5300612
train: epoch 135, iter 2400, loss: 2.264812, top_1: 0.718008, top_k: 0.891797, samples/s: 1732.660 1612940093.305009
train: epoch 135, iter 2500, loss: 2.247226, top_1: 0.714297, top_k: 0.886641, samples/s: 1735.443 1612940108.056348
train: epoch 135, iter 2600, loss: 2.241210, top_1: 0.716836, top_k: 0.885703, samples/s: 1745.597 1612940122.7217815
train: epoch 135, iter 2700, loss: 2.333470, top_1: 0.709492, top_k: 0.887422, samples/s: 1744.672 1612940137.394968
train: epoch 135, iter 2800, loss: 2.140646, top_1: 0.713320, top_k: 0.889766, samples/s: 1754.013 1612940151.9904158
train: epoch 135, iter 2900, loss: 2.013144, top_1: 0.713945, top_k: 0.888086, samples/s: 1749.127 1612940166.625931
train: epoch 135, iter 3000, loss: 2.152113, top_1: 0.715898, top_k: 0.887344, samples/s: 1723.942 1612940181.4756324
train: epoch 135, iter 3100, loss: 2.368559, top_1: 0.718906, top_k: 0.888750, samples/s: 1751.697 1612940196.090026
train: epoch 135, iter 3200, loss: 2.073362, top_1: 0.710430, top_k: 0.888594, samples/s: 1744.231 1612940210.7671897
train: epoch 135, iter 3300, loss: 2.179151, top_1: 0.716094, top_k: 0.889648, samples/s: 1718.076 1612940225.667425
train: epoch 135, iter 3400, loss: 2.064878, top_1: 0.717422, top_k: 0.890781, samples/s: 1772.621 1612940240.109271
train: epoch 135, iter 3500, loss: 2.186494, top_1: 0.715430, top_k: 0.887500, samples/s: 1744.352 1612940254.7854044
train: epoch 135, iter 3600, loss: 2.297664, top_1: 0.707852, top_k: 0.886445, samples/s: 1751.080 1612940269.4047918
train: epoch 135, iter 3700, loss: 2.340423, top_1: 0.712852, top_k: 0.886992, samples/s: 1729.639 1612940284.2056272
train: epoch 135, iter 3800, loss: 2.287405, top_1: 0.705820, top_k: 0.886133, samples/s: 1749.763 1612940298.8360727
train: epoch 135, iter 3900, loss: 2.267683, top_1: 0.713359, top_k: 0.888672, samples/s: 1759.583 1612940313.384987
train: epoch 135, iter 4000, loss: 2.329779, top_1: 0.715352, top_k: 0.890352, samples/s: 1744.324 1612940328.0612144
train: epoch 135, iter 4100, loss: 2.223726, top_1: 0.715508, top_k: 0.886758, samples/s: 1744.106 1612940342.7392428
train: epoch 135, iter 4200, loss: 2.228101, top_1: 0.711836, top_k: 0.888398, samples/s: 1739.800 1612940357.4535062
train: epoch 135, iter 4300, loss: 2.203768, top_1: 0.715781, top_k: 0.888008, samples/s: 1755.471 1612940372.0364928
train: epoch 135, iter 4400, loss: 2.089471, top_1: 0.712539, top_k: 0.888359, samples/s: 1735.951 1612940386.7837224
train: epoch 135, iter 4500, loss: 2.163828, top_1: 0.716719, top_k: 0.889492, samples/s: 1749.918 1612940401.412684
train: epoch 135, iter 4600, loss: 2.021959, top_1: 0.712031, top_k: 0.887031, samples/s: 1746.370 1612940416.0716994
train: epoch 135, iter 4700, loss: 2.392927, top_1: 0.714336, top_k: 0.891172, samples/s: 1739.740 1612940430.78651
train: epoch 135, iter 4800, loss: 2.156318, top_1: 0.713398, top_k: 0.886484, samples/s: 1742.444 1612940445.478583
train: epoch 135, iter 4900, loss: 2.219146, top_1: 0.715547, top_k: 0.887500, samples/s: 1749.573 1612940460.111069
train: epoch 135, iter 5000, loss: 2.242025, top_1: 0.727695, top_k: 0.894023, samples/s: 1739.144 1612940474.8305824
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_135.
validation: epoch 135, iter 195, top_1: 0.732752, top_k: 0.912841, samples/s: 2874.836 1612940492.6320355
train: epoch 136, iter 100, loss: 2.261581, top_1: 0.723984, top_k: 0.892188, samples/s: 1752.448 1612940528.4249177
train: epoch 136, iter 200, loss: 2.204801, top_1: 0.720508, top_k: 0.890742, samples/s: 1760.933 1612940542.962506
train: epoch 136, iter 300, loss: 2.243493, top_1: 0.719609, top_k: 0.891016, samples/s: 1746.837 1612940557.6175542
train: epoch 136, iter 400, loss: 2.202375, top_1: 0.715391, top_k: 0.888867, samples/s: 1766.731 1612940572.107717
train: epoch 136, iter 500, loss: 2.103717, top_1: 0.716523, top_k: 0.890703, samples/s: 1761.516 1612940586.6406224
train: epoch 136, iter 600, loss: 2.083569, top_1: 0.719883, top_k: 0.893125, samples/s: 1754.469 1612940601.231899
train: epoch 136, iter 700, loss: 2.179772, top_1: 0.720781, top_k: 0.892266, samples/s: 1737.161 1612940615.9685507
train: epoch 136, iter 800, loss: 2.198426, top_1: 0.719688, top_k: 0.890859, samples/s: 1737.552 1612940630.7019787
train: epoch 136, iter 900, loss: 2.225858, top_1: 0.723594, top_k: 0.890117, samples/s: 1734.429 1612940645.4618046
train: epoch 136, iter 1000, loss: 2.180421, top_1: 0.719141, top_k: 0.890977, samples/s: 1729.138 1612940660.2668946
train: epoch 136, iter 1100, loss: 2.333522, top_1: 0.714492, top_k: 0.889492, samples/s: 1726.270 1612940675.096589
train: epoch 136, iter 1200, loss: 2.103679, top_1: 0.721328, top_k: 0.892383, samples/s: 1728.549 1612940689.9066591
train: epoch 136, iter 1300, loss: 2.229449, top_1: 0.713281, top_k: 0.887813, samples/s: 1728.921 1612940704.7136118
train: epoch 136, iter 1400, loss: 2.088532, top_1: 0.722734, top_k: 0.890859, samples/s: 1725.265 1612940719.551869
train: epoch 136, iter 1500, loss: 2.225019, top_1: 0.716250, top_k: 0.888359, samples/s: 1730.073 1612940734.348932
train: epoch 136, iter 1600, loss: 2.240191, top_1: 0.717617, top_k: 0.894375, samples/s: 1726.833 1612940749.1737952
train: epoch 136, iter 1700, loss: 2.156602, top_1: 0.719375, top_k: 0.889531, samples/s: 1711.569 1612940764.130838
train: epoch 136, iter 1800, loss: 2.051010, top_1: 0.722969, top_k: 0.891328, samples/s: 1756.906 1612940778.701912
train: epoch 136, iter 1900, loss: 2.043688, top_1: 0.720508, top_k: 0.891016, samples/s: 1738.120 1612940793.4304416
train: epoch 136, iter 2000, loss: 2.104311, top_1: 0.721016, top_k: 0.888750, samples/s: 1726.053 1612940808.261938
train: epoch 136, iter 2100, loss: 2.108472, top_1: 0.714453, top_k: 0.887852, samples/s: 1725.552 1612940823.097777
train: epoch 136, iter 2200, loss: 2.157540, top_1: 0.722148, top_k: 0.892383, samples/s: 1720.557 1612940837.9766915
train: epoch 136, iter 2300, loss: 2.136856, top_1: 0.722656, top_k: 0.892891, samples/s: 1732.907 1612940852.74987
train: epoch 136, iter 2400, loss: 2.035161, top_1: 0.720391, top_k: 0.892109, samples/s: 1739.269 1612940867.4684298
train: epoch 136, iter 2500, loss: 2.323820, top_1: 0.716992, top_k: 0.890859, samples/s: 1717.221 1612940882.3767953
train: epoch 136, iter 2600, loss: 2.141008, top_1: 0.718984, top_k: 0.892383, samples/s: 1704.293 1612940897.397061
train: epoch 136, iter 2700, loss: 2.201425, top_1: 0.720352, top_k: 0.892070, samples/s: 1725.367 1612940912.2350821
train: epoch 136, iter 2800, loss: 2.252284, top_1: 0.722734, top_k: 0.890430, samples/s: 1748.645 1612940926.8743823
train: epoch 136, iter 2900, loss: 2.067307, top_1: 0.715000, top_k: 0.889219, samples/s: 1729.005 1612940941.6806066
train: epoch 136, iter 3000, loss: 2.214732, top_1: 0.717461, top_k: 0.889687, samples/s: 1723.135 1612940956.5375948
train: epoch 136, iter 3100, loss: 2.302112, top_1: 0.717031, top_k: 0.890273, samples/s: 1732.357 1612940971.3149724
train: epoch 136, iter 3200, loss: 2.199827, top_1: 0.718125, top_k: 0.891172, samples/s: 1739.699 1612940986.029977
train: epoch 136, iter 3300, loss: 2.082924, top_1: 0.720391, top_k: 0.891563, samples/s: 1736.998 1612941000.7681277
train: epoch 136, iter 3400, loss: 2.144785, top_1: 0.719063, top_k: 0.891563, samples/s: 1739.626 1612941015.483851
train: epoch 136, iter 3500, loss: 2.339436, top_1: 0.715313, top_k: 0.888242, samples/s: 1727.778 1612941030.3005674
train: epoch 136, iter 3600, loss: 2.151194, top_1: 0.716562, top_k: 0.891133, samples/s: 1759.114 1612941044.8533485
train: epoch 136, iter 3700, loss: 2.331276, top_1: 0.723008, top_k: 0.890820, samples/s: 1750.038 1612941059.481652
train: epoch 136, iter 3800, loss: 1.995537, top_1: 0.717344, top_k: 0.893125, samples/s: 1736.475 1612941074.2241256
train: epoch 136, iter 3900, loss: 2.342411, top_1: 0.719844, top_k: 0.893398, samples/s: 1741.969 1612941088.9202561
train: epoch 136, iter 4000, loss: 2.250906, top_1: 0.718633, top_k: 0.887969, samples/s: 1740.456 1612941103.6289108
train: epoch 136, iter 4100, loss: 2.053950, top_1: 0.718672, top_k: 0.893008, samples/s: 1752.913 1612941118.2332585
train: epoch 136, iter 4200, loss: 2.117640, top_1: 0.719844, top_k: 0.892148, samples/s: 1748.467 1612941132.8745718
train: epoch 136, iter 4300, loss: 2.196739, top_1: 0.713125, top_k: 0.890898, samples/s: 1744.154 1612941147.5529249
train: epoch 136, iter 4400, loss: 2.192531, top_1: 0.716055, top_k: 0.887422, samples/s: 1747.766 1612941162.1994429
train: epoch 136, iter 4500, loss: 2.254230, top_1: 0.721797, top_k: 0.889727, samples/s: 1742.057 1612941176.8947754
train: epoch 136, iter 4600, loss: 2.290541, top_1: 0.712969, top_k: 0.886250, samples/s: 1734.949 1612941191.6502104
train: epoch 136, iter 4700, loss: 2.225024, top_1: 0.714414, top_k: 0.888047, samples/s: 1751.276 1612941206.2681057
train: epoch 136, iter 4800, loss: 2.192477, top_1: 0.714141, top_k: 0.889727, samples/s: 1756.125 1612941220.8457057
train: epoch 136, iter 4900, loss: 2.135018, top_1: 0.711445, top_k: 0.888008, samples/s: 1740.486 1612941235.554282
train: epoch 136, iter 5000, loss: 2.234600, top_1: 0.721133, top_k: 0.893164, samples/s: 1748.870 1612941250.19225
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_136.
validation: epoch 136, iter 195, top_1: 0.734595, top_k: 0.915224, samples/s: 2833.944 1612941268.3636382
train: epoch 137, iter 100, loss: 2.213730, top_1: 0.728086, top_k: 0.893008, samples/s: 1753.309 1612941303.944364
train: epoch 137, iter 200, loss: 2.156211, top_1: 0.725547, top_k: 0.892578, samples/s: 1759.123 1612941318.4970005
train: epoch 137, iter 300, loss: 2.185241, top_1: 0.728867, top_k: 0.897109, samples/s: 1759.554 1612941333.046157
train: epoch 137, iter 400, loss: 2.065591, top_1: 0.721562, top_k: 0.890742, samples/s: 1753.221 1612941347.6481202
train: epoch 137, iter 500, loss: 2.025278, top_1: 0.720898, top_k: 0.890664, samples/s: 1766.966 1612941362.1359978
train: epoch 137, iter 600, loss: 2.250463, top_1: 0.720078, top_k: 0.891484, samples/s: 1748.307 1612941376.7787428
train: epoch 137, iter 700, loss: 2.219866, top_1: 0.726953, top_k: 0.896289, samples/s: 1743.004 1612941391.4660017
train: epoch 137, iter 800, loss: 2.122786, top_1: 0.719102, top_k: 0.890469, samples/s: 1742.813 1612941406.1549277
train: epoch 137, iter 900, loss: 2.133635, top_1: 0.725508, top_k: 0.893437, samples/s: 1741.239 1612941420.857077
train: epoch 137, iter 1000, loss: 2.066590, top_1: 0.720430, top_k: 0.890547, samples/s: 1735.323 1612941435.6094246
train: epoch 137, iter 1100, loss: 2.215326, top_1: 0.724922, top_k: 0.894414, samples/s: 1735.484 1612941450.360322
train: epoch 137, iter 1200, loss: 2.237958, top_1: 0.717109, top_k: 0.891406, samples/s: 1704.191 1612941465.3820636
train: epoch 137, iter 1300, loss: 2.255763, top_1: 0.723125, top_k: 0.891289, samples/s: 1734.998 1612941480.1371636
train: epoch 137, iter 1400, loss: 2.206429, top_1: 0.725234, top_k: 0.894844, samples/s: 1728.738 1612941494.9456053
train: epoch 137, iter 1500, loss: 2.267127, top_1: 0.724180, top_k: 0.891953, samples/s: 1714.767 1612941509.8747432
train: epoch 137, iter 1600, loss: 2.233331, top_1: 0.719531, top_k: 0.890938, samples/s: 1715.549 1612941524.797089
train: epoch 137, iter 1700, loss: 2.233935, top_1: 0.725352, top_k: 0.896680, samples/s: 1737.074 1612941539.5345032
train: epoch 137, iter 1800, loss: 2.017297, top_1: 0.720742, top_k: 0.888555, samples/s: 1731.819 1612941554.3167148
train: epoch 137, iter 1900, loss: 2.048470, top_1: 0.718477, top_k: 0.890039, samples/s: 1716.551 1612941569.2304142
train: epoch 137, iter 2000, loss: 2.125337, top_1: 0.719258, top_k: 0.890820, samples/s: 1717.375 1612941584.1367943
train: epoch 137, iter 2100, loss: 2.205410, top_1: 0.720430, top_k: 0.891758, samples/s: 1732.009 1612941598.9177382
train: epoch 137, iter 2200, loss: 2.142368, top_1: 0.723320, top_k: 0.892617, samples/s: 1719.754 1612941613.8031266
train: epoch 137, iter 2300, loss: 2.093988, top_1: 0.722695, top_k: 0.892344, samples/s: 1741.332 1612941628.5045726
train: epoch 137, iter 2400, loss: 2.142316, top_1: 0.727227, top_k: 0.896055, samples/s: 1729.900 1612941643.30366
train: epoch 137, iter 2500, loss: 2.156826, top_1: 0.717461, top_k: 0.887422, samples/s: 1726.523 1612941658.1306045
train: epoch 137, iter 2600, loss: 2.250496, top_1: 0.719297, top_k: 0.890312, samples/s: 1726.943 1612941672.9544587
train: epoch 137, iter 2700, loss: 2.321268, top_1: 0.721914, top_k: 0.890391, samples/s: 1733.542 1612941687.7218857
train: epoch 137, iter 2800, loss: 2.208843, top_1: 0.720391, top_k: 0.890703, samples/s: 1736.634 1612941702.463046
train: epoch 137, iter 2900, loss: 2.166283, top_1: 0.722852, top_k: 0.890547, samples/s: 1727.872 1612941717.2789516
train: epoch 137, iter 3000, loss: 2.062573, top_1: 0.719063, top_k: 0.894727, samples/s: 1724.342 1612941732.1252198
train: epoch 137, iter 3100, loss: 2.134877, top_1: 0.725547, top_k: 0.894062, samples/s: 1726.743 1612941746.9508128
train: epoch 137, iter 3200, loss: 2.304029, top_1: 0.720859, top_k: 0.892305, samples/s: 1724.935 1612941761.7920473
train: epoch 137, iter 3300, loss: 2.221672, top_1: 0.716094, top_k: 0.888516, samples/s: 1724.460 1612941776.6372306
train: epoch 137, iter 3400, loss: 2.306606, top_1: 0.723750, top_k: 0.893555, samples/s: 1726.324 1612941791.4664168
train: epoch 137, iter 3500, loss: 2.261319, top_1: 0.725430, top_k: 0.895469, samples/s: 1710.263 1612941806.434827
train: epoch 137, iter 3600, loss: 2.329905, top_1: 0.721172, top_k: 0.891328, samples/s: 1753.302 1612941821.0358474
train: epoch 137, iter 3700, loss: 2.092616, top_1: 0.718633, top_k: 0.892305, samples/s: 1738.029 1612941835.765187
train: epoch 137, iter 3800, loss: 2.152244, top_1: 0.722031, top_k: 0.890781, samples/s: 1732.334 1612941850.5429718
train: epoch 137, iter 3900, loss: 2.215723, top_1: 0.717695, top_k: 0.891289, samples/s: 1728.233 1612941865.3557563
train: epoch 137, iter 4000, loss: 2.305479, top_1: 0.720352, top_k: 0.892539, samples/s: 1733.092 1612941880.1270378
train: epoch 137, iter 4100, loss: 2.133033, top_1: 0.720078, top_k: 0.892539, samples/s: 1751.433 1612941894.7440586
train: epoch 137, iter 4200, loss: 2.085741, top_1: 0.718789, top_k: 0.888594, samples/s: 1741.849 1612941909.440664
train: epoch 137, iter 4300, loss: 2.269315, top_1: 0.723008, top_k: 0.889844, samples/s: 1745.770 1612941924.1050994
train: epoch 137, iter 4400, loss: 1.975498, top_1: 0.718906, top_k: 0.890742, samples/s: 1743.074 1612941938.7913873
train: epoch 137, iter 4500, loss: 2.026870, top_1: 0.718789, top_k: 0.889375, samples/s: 1750.889 1612941953.4126568
train: epoch 137, iter 4600, loss: 2.347071, top_1: 0.722617, top_k: 0.888125, samples/s: 1747.862 1612941968.0589855
train: epoch 137, iter 4700, loss: 2.076508, top_1: 0.719023, top_k: 0.891602, samples/s: 1740.383 1612941982.7684274
train: epoch 137, iter 4800, loss: 2.113907, top_1: 0.717344, top_k: 0.890938, samples/s: 1747.932 1612941997.414295
train: epoch 137, iter 4900, loss: 2.250700, top_1: 0.722812, top_k: 0.890039, samples/s: 1746.834 1612942012.069361
train: epoch 137, iter 5000, loss: 2.129516, top_1: 0.723711, top_k: 0.891563, samples/s: 1747.646 1612942026.7176402
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_137.
validation: epoch 137, iter 195, top_1: 0.737260, top_k: 0.917228, samples/s: 2855.208 1612942044.6595316
train: epoch 138, iter 100, loss: 2.204334, top_1: 0.727773, top_k: 0.896133, samples/s: 1742.054 1612942079.5253437
train: epoch 138, iter 200, loss: 2.271291, top_1: 0.730898, top_k: 0.897148, samples/s: 1764.834 1612942094.0311716
train: epoch 138, iter 300, loss: 2.100097, top_1: 0.726797, top_k: 0.892344, samples/s: 1763.114 1612942108.5507162
train: epoch 138, iter 400, loss: 2.068191, top_1: 0.723477, top_k: 0.895781, samples/s: 1757.684 1612942123.1153178
train: epoch 138, iter 500, loss: 2.216674, top_1: 0.727070, top_k: 0.892617, samples/s: 1753.116 1612942137.71828
train: epoch 138, iter 600, loss: 2.296533, top_1: 0.723477, top_k: 0.896133, samples/s: 1732.334 1612942152.4956844
train: epoch 138, iter 700, loss: 2.226682, top_1: 0.726992, top_k: 0.893789, samples/s: 1731.489 1612942167.2805998
train: epoch 138, iter 800, loss: 2.149432, top_1: 0.725547, top_k: 0.894609, samples/s: 1734.991 1612942182.035747
train: epoch 138, iter 900, loss: 2.236880, top_1: 0.727656, top_k: 0.897500, samples/s: 1742.058 1612942196.731028
train: epoch 138, iter 1000, loss: 2.002403, top_1: 0.723789, top_k: 0.892852, samples/s: 1736.437 1612942211.4738684
train: epoch 138, iter 1100, loss: 1.987982, top_1: 0.729844, top_k: 0.895469, samples/s: 1731.271 1612942226.2607007
train: epoch 138, iter 1200, loss: 2.147563, top_1: 0.723711, top_k: 0.892695, samples/s: 1722.382 1612942241.1238582
train: epoch 138, iter 1300, loss: 2.188097, top_1: 0.730859, top_k: 0.897188, samples/s: 1721.539 1612942255.9943275
train: epoch 138, iter 1400, loss: 2.225343, top_1: 0.726211, top_k: 0.895000, samples/s: 1729.211 1612942270.7987103
train: epoch 138, iter 1500, loss: 2.246186, top_1: 0.728555, top_k: 0.894687, samples/s: 1727.392 1612942285.6187458
train: epoch 138, iter 1600, loss: 2.100007, top_1: 0.726328, top_k: 0.893516, samples/s: 1740.177 1612942300.3297987
train: epoch 138, iter 1700, loss: 2.063667, top_1: 0.726562, top_k: 0.893633, samples/s: 1718.138 1612942315.2297134
train: epoch 138, iter 1800, loss: 2.175525, top_1: 0.728086, top_k: 0.893008, samples/s: 1726.679 1612942330.0559037
train: epoch 138, iter 1900, loss: 2.059944, top_1: 0.727969, top_k: 0.894258, samples/s: 1735.216 1612942344.808998
train: epoch 138, iter 2000, loss: 2.169667, top_1: 0.725391, top_k: 0.891758, samples/s: 1725.466 1612942359.645628
train: epoch 138, iter 2100, loss: 2.133493, top_1: 0.722930, top_k: 0.892500, samples/s: 1732.105 1612942374.4252853
train: epoch 138, iter 2200, loss: 2.127927, top_1: 0.733477, top_k: 0.897734, samples/s: 1727.165 1612942389.247369
train: epoch 138, iter 2300, loss: 2.125707, top_1: 0.722578, top_k: 0.892773, samples/s: 1728.441 1612942404.0583265
train: epoch 138, iter 2400, loss: 2.153601, top_1: 0.722656, top_k: 0.892109, samples/s: 1732.194 1612942418.8372846
train: epoch 138, iter 2500, loss: 2.210972, top_1: 0.719375, top_k: 0.893086, samples/s: 1732.017 1612942433.6176941
train: epoch 138, iter 2600, loss: 2.208619, top_1: 0.718477, top_k: 0.892891, samples/s: 1734.031 1612942448.3809812
train: epoch 138, iter 2700, loss: 2.124157, top_1: 0.724336, top_k: 0.894297, samples/s: 1727.636 1612942463.1989138
train: epoch 138, iter 2800, loss: 2.019317, top_1: 0.726133, top_k: 0.891758, samples/s: 1730.706 1612942477.9905996
train: epoch 138, iter 2900, loss: 2.190654, top_1: 0.724961, top_k: 0.896445, samples/s: 1726.356 1612942492.8195193
train: epoch 138, iter 3000, loss: 2.145693, top_1: 0.722070, top_k: 0.892969, samples/s: 1738.514 1612942507.5447822
train: epoch 138, iter 3100, loss: 2.111625, top_1: 0.722070, top_k: 0.891875, samples/s: 1727.789 1612942522.3613944
train: epoch 138, iter 3200, loss: 2.131077, top_1: 0.719531, top_k: 0.891992, samples/s: 1734.526 1612942537.1203852
train: epoch 138, iter 3300, loss: 2.154880, top_1: 0.722617, top_k: 0.892148, samples/s: 1727.091 1612942551.9431207
train: epoch 138, iter 3400, loss: 2.123525, top_1: 0.719258, top_k: 0.889961, samples/s: 1727.235 1612942566.7643955
train: epoch 138, iter 3500, loss: 2.144445, top_1: 0.727148, top_k: 0.894805, samples/s: 1730.055 1612942581.5616431
train: epoch 138, iter 3600, loss: 1.895146, top_1: 0.723359, top_k: 0.895273, samples/s: 1728.957 1612942596.3682687
train: epoch 138, iter 3700, loss: 2.244869, top_1: 0.728047, top_k: 0.894687, samples/s: 1730.684 1612942611.160128
train: epoch 138, iter 3800, loss: 2.240149, top_1: 0.725391, top_k: 0.891680, samples/s: 1729.402 1612942625.96295
train: epoch 138, iter 3900, loss: 2.148299, top_1: 0.727344, top_k: 0.894453, samples/s: 1731.290 1612942640.7496066
train: epoch 138, iter 4000, loss: 2.332685, top_1: 0.725977, top_k: 0.893750, samples/s: 1733.861 1612942655.5142741
train: epoch 138, iter 4100, loss: 2.077729, top_1: 0.724727, top_k: 0.897109, samples/s: 1734.661 1612942670.27226
train: epoch 138, iter 4200, loss: 2.131866, top_1: 0.725313, top_k: 0.891641, samples/s: 1731.055 1612942685.060891
train: epoch 138, iter 4300, loss: 2.101831, top_1: 0.721992, top_k: 0.892383, samples/s: 1728.419 1612942699.8721116
train: epoch 138, iter 4400, loss: 2.068254, top_1: 0.725742, top_k: 0.896602, samples/s: 1717.925 1612942714.7738008
train: epoch 138, iter 4500, loss: 1.953118, top_1: 0.726211, top_k: 0.895508, samples/s: 1732.925 1612942729.5465379
train: epoch 138, iter 4600, loss: 2.350754, top_1: 0.721875, top_k: 0.892500, samples/s: 1727.775 1612942744.3634098
train: epoch 138, iter 4700, loss: 2.030967, top_1: 0.726836, top_k: 0.896641, samples/s: 1737.557 1612942759.0966454
train: epoch 138, iter 4800, loss: 2.059206, top_1: 0.721562, top_k: 0.893906, samples/s: 1736.271 1612942773.8408635
train: epoch 138, iter 4900, loss: 2.071936, top_1: 0.724063, top_k: 0.891055, samples/s: 1744.347 1612942788.5168386
train: epoch 138, iter 5000, loss: 2.101695, top_1: 0.730586, top_k: 0.896289, samples/s: 1748.510 1612942803.1578844
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_138.
validation: epoch 138, iter 195, top_1: 0.739163, top_k: 0.917768, samples/s: 2856.352 1612942821.0324006
train: epoch 139, iter 100, loss: 2.049274, top_1: 0.734102, top_k: 0.895508, samples/s: 1755.948 1612942855.937531
train: epoch 139, iter 200, loss: 2.215197, top_1: 0.727383, top_k: 0.898633, samples/s: 1758.053 1612942870.4991283
train: epoch 139, iter 300, loss: 2.141342, top_1: 0.727617, top_k: 0.895156, samples/s: 1760.958 1612942885.036802
train: epoch 139, iter 400, loss: 2.237270, top_1: 0.730781, top_k: 0.897422, samples/s: 1758.483 1612942899.5946221
train: epoch 139, iter 500, loss: 2.237063, top_1: 0.728984, top_k: 0.895586, samples/s: 1752.889 1612942914.199153
train: epoch 139, iter 600, loss: 2.161729, top_1: 0.730898, top_k: 0.897891, samples/s: 1755.417 1612942928.7825398
train: epoch 139, iter 700, loss: 2.116942, top_1: 0.726992, top_k: 0.895703, samples/s: 1744.538 1612942943.456881
train: epoch 139, iter 800, loss: 2.237030, top_1: 0.725586, top_k: 0.892891, samples/s: 1718.555 1612942958.3531878
train: epoch 139, iter 900, loss: 2.115203, top_1: 0.726094, top_k: 0.893828, samples/s: 1735.207 1612942973.1064808
train: epoch 139, iter 1000, loss: 1.984781, top_1: 0.731797, top_k: 0.899570, samples/s: 1718.052 1612942988.0070782
train: epoch 139, iter 1100, loss: 2.333663, top_1: 0.725273, top_k: 0.893672, samples/s: 1739.094 1612943002.7273796
train: epoch 139, iter 1200, loss: 2.230320, top_1: 0.728359, top_k: 0.895547, samples/s: 1728.902 1612943017.5344303
train: epoch 139, iter 1300, loss: 2.162132, top_1: 0.725781, top_k: 0.894492, samples/s: 1716.337 1612943032.4500012
train: epoch 139, iter 1400, loss: 2.086166, top_1: 0.721016, top_k: 0.893398, samples/s: 1739.981 1612943047.162691
train: epoch 139, iter 1500, loss: 2.106339, top_1: 0.725313, top_k: 0.894570, samples/s: 1727.172 1612943061.9846404
train: epoch 139, iter 1600, loss: 2.228005, top_1: 0.727461, top_k: 0.893906, samples/s: 1732.802 1612943076.758378
train: epoch 139, iter 1700, loss: 2.092697, top_1: 0.725586, top_k: 0.894648, samples/s: 1735.585 1612943091.508504
train: epoch 139, iter 1800, loss: 2.105969, top_1: 0.729531, top_k: 0.896523, samples/s: 1717.320 1612943106.4153998
train: epoch 139, iter 1900, loss: 2.065715, top_1: 0.727969, top_k: 0.897305, samples/s: 1738.439 1612943121.1412444
train: epoch 139, iter 2000, loss: 2.176075, top_1: 0.727461, top_k: 0.894609, samples/s: 1732.036 1612943135.9215262
train: epoch 139, iter 2100, loss: 2.170670, top_1: 0.725195, top_k: 0.893477, samples/s: 1732.723 1612943150.696022
train: epoch 139, iter 2200, loss: 2.190441, top_1: 0.729531, top_k: 0.897031, samples/s: 1738.561 1612943165.4208372
train: epoch 139, iter 2300, loss: 1.931602, top_1: 0.726094, top_k: 0.894414, samples/s: 1732.608 1612943180.1962078
train: epoch 139, iter 2400, loss: 2.035183, top_1: 0.732031, top_k: 0.897344, samples/s: 1730.542 1612943194.9893165
train: epoch 139, iter 2500, loss: 2.181329, top_1: 0.728516, top_k: 0.896055, samples/s: 1721.327 1612943209.8614936
train: epoch 139, iter 2600, loss: 2.144618, top_1: 0.726797, top_k: 0.895977, samples/s: 1731.459 1612943224.6467826
train: epoch 139, iter 2700, loss: 2.027794, top_1: 0.725938, top_k: 0.895000, samples/s: 1719.975 1612943239.5307572
train: epoch 139, iter 2800, loss: 2.064480, top_1: 0.727227, top_k: 0.893125, samples/s: 1729.049 1612943254.336511
train: epoch 139, iter 2900, loss: 2.177094, top_1: 0.732656, top_k: 0.896914, samples/s: 1740.354 1612943269.0462399
train: epoch 139, iter 3000, loss: 2.071612, top_1: 0.726250, top_k: 0.893945, samples/s: 1737.268 1612943283.7819643
train: epoch 139, iter 3100, loss: 2.118350, top_1: 0.725781, top_k: 0.892930, samples/s: 1728.746 1612943298.590397
train: epoch 139, iter 3200, loss: 2.086659, top_1: 0.731094, top_k: 0.894375, samples/s: 1717.846 1612943313.4928412
train: epoch 139, iter 3300, loss: 2.001966, top_1: 0.729492, top_k: 0.896211, samples/s: 1740.179 1612943328.2039275
train: epoch 139, iter 3400, loss: 2.352497, top_1: 0.728945, top_k: 0.897461, samples/s: 1736.530 1612943342.9459627
train: epoch 139, iter 3500, loss: 1.958482, top_1: 0.725625, top_k: 0.895430, samples/s: 1733.162 1612943357.7166815
train: epoch 139, iter 3600, loss: 2.132772, top_1: 0.729180, top_k: 0.897305, samples/s: 1720.188 1612943372.598682
train: epoch 139, iter 3700, loss: 2.000772, top_1: 0.727500, top_k: 0.895938, samples/s: 1739.560 1612943387.3154812
train: epoch 139, iter 3800, loss: 2.178200, top_1: 0.727070, top_k: 0.894922, samples/s: 1730.249 1612943402.1106346
train: epoch 139, iter 3900, loss: 2.123487, top_1: 0.726484, top_k: 0.892852, samples/s: 1753.743 1612943416.7079444
train: epoch 139, iter 4000, loss: 2.153930, top_1: 0.731875, top_k: 0.896289, samples/s: 1745.445 1612943431.375079
train: epoch 139, iter 4100, loss: 2.145799, top_1: 0.728633, top_k: 0.894492, samples/s: 1752.617 1612943445.9814346
train: epoch 139, iter 4200, loss: 2.119824, top_1: 0.727109, top_k: 0.896406, samples/s: 1739.729 1612943460.6963599
train: epoch 139, iter 4300, loss: 2.279265, top_1: 0.725977, top_k: 0.895938, samples/s: 1740.502 1612943475.4048162
train: epoch 139, iter 4400, loss: 2.301641, top_1: 0.727930, top_k: 0.894883, samples/s: 1756.888 1612943489.9762487
train: epoch 139, iter 4500, loss: 2.223344, top_1: 0.724063, top_k: 0.894687, samples/s: 1738.114 1612943504.7045853
train: epoch 139, iter 4600, loss: 2.083660, top_1: 0.722148, top_k: 0.891836, samples/s: 1753.706 1612943519.3023295
train: epoch 139, iter 4700, loss: 2.090275, top_1: 0.725273, top_k: 0.896914, samples/s: 1740.481 1612943534.011254
train: epoch 139, iter 4800, loss: 2.263669, top_1: 0.727461, top_k: 0.896016, samples/s: 1753.690 1612943548.608734
train: epoch 139, iter 4900, loss: 1.950248, top_1: 0.730234, top_k: 0.897031, samples/s: 1751.967 1612943563.220805
train: epoch 139, iter 5000, loss: 2.087322, top_1: 0.732227, top_k: 0.897031, samples/s: 1748.479 1612943577.8620508
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_139.
validation: epoch 139, iter 195, top_1: 0.740385, top_k: 0.918770, samples/s: 2799.609 1612943596.1410165
train: epoch 140, iter 100, loss: 2.107930, top_1: 0.737852, top_k: 0.897539, samples/s: 1748.365 1612943631.2153661
train: epoch 140, iter 200, loss: 2.162920, top_1: 0.735938, top_k: 0.901445, samples/s: 1755.192 1612943645.8006103
train: epoch 140, iter 300, loss: 2.080734, top_1: 0.727070, top_k: 0.898086, samples/s: 1760.996 1612943660.3379207
train: epoch 140, iter 400, loss: 2.013077, top_1: 0.732578, top_k: 0.897891, samples/s: 1752.314 1612943674.9471552
train: epoch 140, iter 500, loss: 2.070942, top_1: 0.733281, top_k: 0.900117, samples/s: 1770.488 1612943689.406466
train: epoch 140, iter 600, loss: 2.086962, top_1: 0.730352, top_k: 0.897734, samples/s: 1755.814 1612943703.986706
train: epoch 140, iter 700, loss: 2.130102, top_1: 0.735625, top_k: 0.899805, samples/s: 1724.136 1612943718.8345168
train: epoch 140, iter 800, loss: 2.217893, top_1: 0.733711, top_k: 0.898828, samples/s: 1751.522 1612943733.4503987
train: epoch 140, iter 900, loss: 2.367144, top_1: 0.728984, top_k: 0.894687, samples/s: 1740.758 1612943748.1566706
train: epoch 140, iter 1000, loss: 2.031502, top_1: 0.727500, top_k: 0.897305, samples/s: 1720.882 1612943763.0327919
train: epoch 140, iter 1100, loss: 2.241515, top_1: 0.726836, top_k: 0.895078, samples/s: 1742.212 1612943777.7266648
train: epoch 140, iter 1200, loss: 2.141194, top_1: 0.731445, top_k: 0.896406, samples/s: 1734.410 1612943792.4867995
train: epoch 140, iter 1300, loss: 2.022837, top_1: 0.737500, top_k: 0.900352, samples/s: 1730.243 1612943807.2823553
train: epoch 140, iter 1400, loss: 2.117670, top_1: 0.731016, top_k: 0.896133, samples/s: 1719.395 1612943822.1713572
train: epoch 140, iter 1500, loss: 2.211285, top_1: 0.731758, top_k: 0.895039, samples/s: 1746.111 1612943836.8324614
train: epoch 140, iter 1600, loss: 2.221308, top_1: 0.730664, top_k: 0.896523, samples/s: 1738.395 1612943851.5587072
train: epoch 140, iter 1700, loss: 2.178418, top_1: 0.728789, top_k: 0.895078, samples/s: 1725.347 1612943866.3962893
train: epoch 140, iter 1800, loss: 2.220215, top_1: 0.730977, top_k: 0.897891, samples/s: 1720.409 1612943881.2764676
train: epoch 140, iter 1900, loss: 2.006336, top_1: 0.731328, top_k: 0.898789, samples/s: 1737.547 1612943896.0099065
train: epoch 140, iter 2000, loss: 1.911587, top_1: 0.734570, top_k: 0.897773, samples/s: 1746.181 1612943910.670425
train: epoch 140, iter 2100, loss: 2.221883, top_1: 0.729570, top_k: 0.896016, samples/s: 1736.176 1612943925.4155338
train: epoch 140, iter 2200, loss: 1.989393, top_1: 0.731055, top_k: 0.897383, samples/s: 1737.085 1612943940.1528645
train: epoch 140, iter 2300, loss: 2.129250, top_1: 0.729141, top_k: 0.899531, samples/s: 1720.325 1612943955.0337143
train: epoch 140, iter 2400, loss: 2.162596, top_1: 0.729961, top_k: 0.895938, samples/s: 1730.840 1612943969.8242843
train: epoch 140, iter 2500, loss: 2.063774, top_1: 0.730352, top_k: 0.898477, samples/s: 1737.117 1612943984.5613508
train: epoch 140, iter 2600, loss: 2.077229, top_1: 0.734219, top_k: 0.898594, samples/s: 1719.435 1612943999.449989
train: epoch 140, iter 2700, loss: 2.152475, top_1: 0.732383, top_k: 0.896758, samples/s: 1743.430 1612944014.1336455
train: epoch 140, iter 2800, loss: 2.072564, top_1: 0.729531, top_k: 0.898359, samples/s: 1733.159 1612944028.904345
train: epoch 140, iter 2900, loss: 2.176835, top_1: 0.728906, top_k: 0.899531, samples/s: 1727.370 1612944043.7246406
train: epoch 140, iter 3000, loss: 2.230633, top_1: 0.729570, top_k: 0.895312, samples/s: 1731.935 1612944058.5057354
train: epoch 140, iter 3100, loss: 2.112175, top_1: 0.727656, top_k: 0.894336, samples/s: 1749.704 1612944073.1368132
train: epoch 140, iter 3200, loss: 2.204051, top_1: 0.729023, top_k: 0.896250, samples/s: 1741.129 1612944087.839844
train: epoch 140, iter 3300, loss: 2.000180, top_1: 0.734805, top_k: 0.895586, samples/s: 1724.423 1612944102.6853704
train: epoch 140, iter 3400, loss: 2.057583, top_1: 0.728867, top_k: 0.897734, samples/s: 1721.757 1612944117.5538926
train: epoch 140, iter 3500, loss: 2.155590, top_1: 0.725977, top_k: 0.895508, samples/s: 1724.472 1612944132.3990886
train: epoch 140, iter 3600, loss: 2.135380, top_1: 0.727383, top_k: 0.898086, samples/s: 1738.581 1612944147.1236827
train: epoch 140, iter 3700, loss: 2.155023, top_1: 0.725781, top_k: 0.893242, samples/s: 1733.530 1612944161.8912876
train: epoch 140, iter 3800, loss: 2.139175, top_1: 0.727656, top_k: 0.894844, samples/s: 1737.303 1612944176.6267111
train: epoch 140, iter 3900, loss: 2.142411, top_1: 0.735156, top_k: 0.898320, samples/s: 1734.514 1612944191.3859007
train: epoch 140, iter 4000, loss: 2.196223, top_1: 0.730000, top_k: 0.895273, samples/s: 1717.234 1612944206.2936263
train: epoch 140, iter 4100, loss: 2.280466, top_1: 0.732422, top_k: 0.897383, samples/s: 1729.354 1612944221.0967975
train: epoch 140, iter 4200, loss: 1.986444, top_1: 0.726211, top_k: 0.896367, samples/s: 1733.945 1612944235.860866
train: epoch 140, iter 4300, loss: 2.134160, top_1: 0.729219, top_k: 0.896016, samples/s: 1738.969 1612944250.5822475
train: epoch 140, iter 4400, loss: 2.106661, top_1: 0.730469, top_k: 0.894883, samples/s: 1735.083 1612944265.3365135
train: epoch 140, iter 4500, loss: 2.243398, top_1: 0.728750, top_k: 0.896992, samples/s: 1732.856 1612944280.1099057
train: epoch 140, iter 4600, loss: 2.103254, top_1: 0.728008, top_k: 0.896406, samples/s: 1738.875 1612944294.832036
train: epoch 140, iter 4700, loss: 2.144474, top_1: 0.729180, top_k: 0.898594, samples/s: 1724.122 1612944309.6802418
train: epoch 140, iter 4800, loss: 2.194028, top_1: 0.730156, top_k: 0.897891, samples/s: 1740.131 1612944324.3917522
train: epoch 140, iter 4900, loss: 2.156875, top_1: 0.730000, top_k: 0.894922, samples/s: 1730.615 1612944339.1840816
train: epoch 140, iter 5000, loss: 2.243933, top_1: 0.732461, top_k: 0.897930, samples/s: 1729.424 1612944353.9867496
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_140.
validation: epoch 140, iter 195, top_1: 0.741146, top_k: 0.918289, samples/s: 2823.945 1612944372.069535
train: epoch 141, iter 100, loss: 2.057494, top_1: 0.739492, top_k: 0.897813, samples/s: 1752.622 1612944406.4369123
train: epoch 141, iter 200, loss: 2.217003, top_1: 0.733750, top_k: 0.897344, samples/s: 1753.353 1612944421.0374932
train: epoch 141, iter 300, loss: 2.165205, top_1: 0.733633, top_k: 0.898516, samples/s: 1765.363 1612944435.5388505
train: epoch 141, iter 400, loss: 2.024501, top_1: 0.737344, top_k: 0.901172, samples/s: 1758.751 1612944450.0945766
train: epoch 141, iter 500, loss: 2.089646, top_1: 0.734805, top_k: 0.898242, samples/s: 1753.600 1612944464.693123
train: epoch 141, iter 600, loss: 2.272886, top_1: 0.738828, top_k: 0.900703, samples/s: 1746.099 1612944479.3543348
train: epoch 141, iter 700, loss: 2.015127, top_1: 0.731797, top_k: 0.898555, samples/s: 1736.423 1612944494.0973368
train: epoch 141, iter 800, loss: 2.085238, top_1: 0.731367, top_k: 0.899023, samples/s: 1731.327 1612944508.8837407
train: epoch 141, iter 900, loss: 2.302024, top_1: 0.729570, top_k: 0.894648, samples/s: 1731.691 1612944523.6669414
train: epoch 141, iter 1000, loss: 2.118349, top_1: 0.735352, top_k: 0.899570, samples/s: 1734.018 1612944538.4302564
train: epoch 141, iter 1100, loss: 2.121572, top_1: 0.729922, top_k: 0.898008, samples/s: 1716.106 1612944553.3478043
train: epoch 141, iter 1200, loss: 2.044859, top_1: 0.737109, top_k: 0.900156, samples/s: 1736.410 1612944568.090873
train: epoch 141, iter 1300, loss: 2.030751, top_1: 0.734727, top_k: 0.900078, samples/s: 1728.807 1612944582.8987834
train: epoch 141, iter 1400, loss: 2.197833, top_1: 0.733398, top_k: 0.899219, samples/s: 1733.020 1612944597.670655
train: epoch 141, iter 1500, loss: 2.113960, top_1: 0.735781, top_k: 0.896797, samples/s: 1729.429 1612944612.473259
train: epoch 141, iter 1600, loss: 2.152659, top_1: 0.731367, top_k: 0.899102, samples/s: 1739.991 1612944627.1859045
train: epoch 141, iter 1700, loss: 2.116133, top_1: 0.736250, top_k: 0.898945, samples/s: 1723.601 1612944642.0385492
train: epoch 141, iter 1800, loss: 2.250191, top_1: 0.734180, top_k: 0.898164, samples/s: 1736.233 1612944656.783157
train: epoch 141, iter 1900, loss: 2.232530, top_1: 0.735781, top_k: 0.900312, samples/s: 1731.494 1612944671.5680888
train: epoch 141, iter 2000, loss: 2.185246, top_1: 0.736563, top_k: 0.900664, samples/s: 1732.740 1612944686.34237
train: epoch 141, iter 2100, loss: 2.230189, top_1: 0.733945, top_k: 0.898008, samples/s: 1730.605 1612944701.134856
train: epoch 141, iter 2200, loss: 2.123666, top_1: 0.730625, top_k: 0.896953, samples/s: 1724.256 1612944715.981867
train: epoch 141, iter 2300, loss: 2.193328, top_1: 0.732070, top_k: 0.896484, samples/s: 1727.910 1612944730.797465
train: epoch 141, iter 2400, loss: 2.096082, top_1: 0.732070, top_k: 0.896328, samples/s: 1714.625 1612944745.7278774
train: epoch 141, iter 2500, loss: 2.092978, top_1: 0.737227, top_k: 0.899336, samples/s: 1739.764 1612944760.4424727
train: epoch 141, iter 2600, loss: 2.127518, top_1: 0.731914, top_k: 0.897813, samples/s: 1734.133 1612944775.2048306
train: epoch 141, iter 2700, loss: 2.081615, top_1: 0.734219, top_k: 0.898594, samples/s: 1733.458 1612944789.9730294
train: epoch 141, iter 2800, loss: 2.132035, top_1: 0.733672, top_k: 0.898672, samples/s: 1732.825 1612944804.7466333
train: epoch 141, iter 2900, loss: 2.126971, top_1: 0.726602, top_k: 0.896367, samples/s: 1727.874 1612944819.562494
train: epoch 141, iter 3000, loss: 2.060012, top_1: 0.735469, top_k: 0.898320, samples/s: 1737.672 1612944834.2948644
train: epoch 141, iter 3100, loss: 2.305387, top_1: 0.735000, top_k: 0.898867, samples/s: 1731.017 1612944849.083901
train: epoch 141, iter 3200, loss: 2.003639, top_1: 0.731914, top_k: 0.900937, samples/s: 1726.154 1612944863.9145198
train: epoch 141, iter 3300, loss: 2.077131, top_1: 0.733203, top_k: 0.899766, samples/s: 1735.358 1612944878.6665246
train: epoch 141, iter 3400, loss: 2.057612, top_1: 0.725430, top_k: 0.893633, samples/s: 1734.525 1612944893.4256217
train: epoch 141, iter 3500, loss: 2.150379, top_1: 0.728477, top_k: 0.894023, samples/s: 1734.325 1612944908.1863854
train: epoch 141, iter 3600, loss: 2.073088, top_1: 0.735391, top_k: 0.898242, samples/s: 1744.350 1612944922.8624134
train: epoch 141, iter 3700, loss: 2.249324, top_1: 0.735117, top_k: 0.900234, samples/s: 1756.167 1612944937.4395204
train: epoch 141, iter 3800, loss: 2.336193, top_1: 0.730781, top_k: 0.900859, samples/s: 1737.038 1612944952.177237
train: epoch 141, iter 3900, loss: 2.201414, top_1: 0.734688, top_k: 0.897109, samples/s: 1745.626 1612944966.842461
train: epoch 141, iter 4000, loss: 2.135180, top_1: 0.732227, top_k: 0.896523, samples/s: 1747.072 1612944981.4955678
train: epoch 141, iter 4100, loss: 2.146937, top_1: 0.726367, top_k: 0.896602, samples/s: 1735.686 1612944996.2448473
train: epoch 141, iter 4200, loss: 1.939893, top_1: 0.733164, top_k: 0.896992, samples/s: 1756.622 1612945010.818215
train: epoch 141, iter 4300, loss: 2.149841, top_1: 0.740000, top_k: 0.898789, samples/s: 1744.827 1612945025.4901037
train: epoch 141, iter 4400, loss: 2.130081, top_1: 0.728633, top_k: 0.895547, samples/s: 1740.709 1612945040.1967554
train: epoch 141, iter 4500, loss: 2.091666, top_1: 0.732266, top_k: 0.898047, samples/s: 1734.820 1612945054.9534702
train: epoch 141, iter 4600, loss: 2.033509, top_1: 0.735391, top_k: 0.898906, samples/s: 1763.506 1612945069.469902
train: epoch 141, iter 4700, loss: 2.068860, top_1: 0.730742, top_k: 0.897656, samples/s: 1746.413 1612945084.1285338
train: epoch 141, iter 4800, loss: 1.980674, top_1: 0.734102, top_k: 0.897969, samples/s: 1750.411 1612945098.7536304
train: epoch 141, iter 4900, loss: 2.140723, top_1: 0.731836, top_k: 0.897266, samples/s: 1747.976 1612945113.3992088
train: epoch 141, iter 5000, loss: 2.128282, top_1: 0.732539, top_k: 0.897305, samples/s: 1754.170 1612945127.9929667
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_141.
validation: epoch 141, iter 195, top_1: 0.745974, top_k: 0.920673, samples/s: 2854.453 1612945145.9461489
train: epoch 142, iter 100, loss: 2.013415, top_1: 0.737852, top_k: 0.902578, samples/s: 1741.404 1612945181.752579
train: epoch 142, iter 200, loss: 2.153167, top_1: 0.735820, top_k: 0.900312, samples/s: 1749.252 1612945196.387348
train: epoch 142, iter 300, loss: 2.125618, top_1: 0.735039, top_k: 0.897188, samples/s: 1765.475 1612945210.887674
train: epoch 142, iter 400, loss: 1.974087, top_1: 0.738047, top_k: 0.902148, samples/s: 1756.290 1612945225.4638746
train: epoch 142, iter 500, loss: 1.999050, top_1: 0.742266, top_k: 0.901172, samples/s: 1756.932 1612945240.034748
train: epoch 142, iter 600, loss: 2.152921, top_1: 0.737773, top_k: 0.901094, samples/s: 1751.167 1612945254.6539438
train: epoch 142, iter 700, loss: 1.983993, top_1: 0.735469, top_k: 0.898594, samples/s: 1756.189 1612945269.2305841
train: epoch 142, iter 800, loss: 1.997711, top_1: 0.741289, top_k: 0.901758, samples/s: 1736.393 1612945283.973784
train: epoch 142, iter 900, loss: 2.128702, top_1: 0.735078, top_k: 0.899336, samples/s: 1731.873 1612945298.7554348
train: epoch 142, iter 1000, loss: 1.967498, top_1: 0.739258, top_k: 0.903320, samples/s: 1734.249 1612945313.5169241
train: epoch 142, iter 1100, loss: 2.162332, top_1: 0.738008, top_k: 0.899687, samples/s: 1742.112 1612945328.2117686
train: epoch 142, iter 1200, loss: 2.142067, top_1: 0.739023, top_k: 0.902422, samples/s: 1724.096 1612945343.0601559
train: epoch 142, iter 1300, loss: 2.124921, top_1: 0.734297, top_k: 0.900391, samples/s: 1742.821 1612945357.7489264
train: epoch 142, iter 1400, loss: 2.204343, top_1: 0.736523, top_k: 0.899844, samples/s: 1731.245 1612945372.5359626
train: epoch 142, iter 1500, loss: 2.027789, top_1: 0.734570, top_k: 0.899766, samples/s: 1740.776 1612945387.2420402
train: epoch 142, iter 1600, loss: 2.022155, top_1: 0.739648, top_k: 0.901484, samples/s: 1738.555 1612945401.966914
train: epoch 142, iter 1700, loss: 2.121110, top_1: 0.740938, top_k: 0.899453, samples/s: 1736.356 1612945416.7104409
train: epoch 142, iter 1800, loss: 2.072489, top_1: 0.737461, top_k: 0.900078, samples/s: 1735.796 1612945431.45866
train: epoch 142, iter 1900, loss: 2.088440, top_1: 0.734297, top_k: 0.898047, samples/s: 1741.562 1612945446.1581028
train: epoch 142, iter 2000, loss: 2.133344, top_1: 0.734297, top_k: 0.899883, samples/s: 1724.690 1612945461.0013826
train: epoch 142, iter 2100, loss: 1.940030, top_1: 0.739414, top_k: 0.904531, samples/s: 1730.698 1612945475.7931247
train: epoch 142, iter 2200, loss: 2.141745, top_1: 0.736016, top_k: 0.898594, samples/s: 1731.217 1612945490.580439
train: epoch 142, iter 2300, loss: 2.044561, top_1: 0.740898, top_k: 0.902852, samples/s: 1739.008 1612945505.3014328
train: epoch 142, iter 2400, loss: 2.173526, top_1: 0.740234, top_k: 0.900078, samples/s: 1738.786 1612945520.0243118
train: epoch 142, iter 2500, loss: 2.157922, top_1: 0.731289, top_k: 0.896328, samples/s: 1724.384 1612945534.8702435
train: epoch 142, iter 2600, loss: 1.979677, top_1: 0.734570, top_k: 0.899297, samples/s: 1732.681 1612945549.6449757
train: epoch 142, iter 2700, loss: 2.174944, top_1: 0.736367, top_k: 0.898203, samples/s: 1736.478 1612945564.3875313
train: epoch 142, iter 2800, loss: 2.077269, top_1: 0.737383, top_k: 0.899492, samples/s: 1740.174 1612945579.0986927
train: epoch 142, iter 2900, loss: 2.075583, top_1: 0.736836, top_k: 0.902617, samples/s: 1738.797 1612945593.8215137
train: epoch 142, iter 3000, loss: 2.104537, top_1: 0.732305, top_k: 0.898047, samples/s: 1738.554 1612945608.5463321
train: epoch 142, iter 3100, loss: 2.074636, top_1: 0.734258, top_k: 0.896758, samples/s: 1728.252 1612945623.3590815
train: epoch 142, iter 3200, loss: 2.006625, top_1: 0.734453, top_k: 0.899023, samples/s: 1737.761 1612945638.0905836
train: epoch 142, iter 3300, loss: 2.122556, top_1: 0.736289, top_k: 0.899414, samples/s: 1739.413 1612945652.8083053
train: epoch 142, iter 3400, loss: 2.159247, top_1: 0.735469, top_k: 0.900742, samples/s: 1732.580 1612945667.5839016
train: epoch 142, iter 3500, loss: 2.060262, top_1: 0.736953, top_k: 0.900352, samples/s: 1732.187 1612945682.3628638
train: epoch 142, iter 3600, loss: 1.978302, top_1: 0.730977, top_k: 0.896836, samples/s: 1742.311 1612945697.056013
train: epoch 142, iter 3700, loss: 2.272703, top_1: 0.738164, top_k: 0.899023, samples/s: 1733.729 1612945711.82184
train: epoch 142, iter 3800, loss: 2.090856, top_1: 0.732891, top_k: 0.898438, samples/s: 1723.244 1612945726.67756
train: epoch 142, iter 3900, loss: 2.147753, top_1: 0.736367, top_k: 0.898555, samples/s: 1743.150 1612945741.3637133
train: epoch 142, iter 4000, loss: 2.147925, top_1: 0.735820, top_k: 0.898828, samples/s: 1738.510 1612945756.088851
train: epoch 142, iter 4100, loss: 2.089413, top_1: 0.735625, top_k: 0.899336, samples/s: 1723.771 1612945770.9400883
train: epoch 142, iter 4200, loss: 2.031980, top_1: 0.732812, top_k: 0.898555, samples/s: 1739.230 1612945785.659237
train: epoch 142, iter 4300, loss: 2.249823, top_1: 0.731523, top_k: 0.896797, samples/s: 1737.687 1612945800.3914566
train: epoch 142, iter 4400, loss: 2.109206, top_1: 0.730234, top_k: 0.896211, samples/s: 1721.956 1612945815.2582233
train: epoch 142, iter 4500, loss: 1.881304, top_1: 0.736523, top_k: 0.901445, samples/s: 1727.571 1612945830.0767186
train: epoch 142, iter 4600, loss: 1.988430, top_1: 0.735039, top_k: 0.897891, samples/s: 1735.901 1612945844.8241162
train: epoch 142, iter 4700, loss: 2.398131, top_1: 0.739453, top_k: 0.901367, samples/s: 1734.323 1612945859.5849428
train: epoch 142, iter 4800, loss: 2.210039, top_1: 0.736094, top_k: 0.899219, samples/s: 1740.733 1612945874.2914264
train: epoch 142, iter 4900, loss: 1.845230, top_1: 0.738008, top_k: 0.899102, samples/s: 1736.098 1612945889.0370612
train: epoch 142, iter 5000, loss: 2.087042, top_1: 0.737305, top_k: 0.902852, samples/s: 1751.226 1612945903.6554382
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_142.
validation: epoch 142, iter 195, top_1: 0.746354, top_k: 0.921514, samples/s: 2820.812 1612945921.7670887
train: epoch 143, iter 100, loss: 2.077967, top_1: 0.740391, top_k: 0.903008, samples/s: 1750.880 1612945956.5457869
train: epoch 143, iter 200, loss: 2.069628, top_1: 0.741758, top_k: 0.902500, samples/s: 1754.010 1612945971.1407776
train: epoch 143, iter 300, loss: 2.001144, top_1: 0.740664, top_k: 0.901914, samples/s: 1757.751 1612945985.7048368
train: epoch 143, iter 400, loss: 2.130117, top_1: 0.740469, top_k: 0.902422, samples/s: 1761.686 1612946000.2365265
train: epoch 143, iter 500, loss: 2.160545, top_1: 0.737969, top_k: 0.902500, samples/s: 1744.968 1612946014.9072037
train: epoch 143, iter 600, loss: 1.974465, top_1: 0.738437, top_k: 0.901680, samples/s: 1758.477 1612946029.4652357
train: epoch 143, iter 700, loss: 2.095246, top_1: 0.742773, top_k: 0.901914, samples/s: 1743.617 1612946044.147296
train: epoch 143, iter 800, loss: 2.118406, top_1: 0.744141, top_k: 0.903672, samples/s: 1742.535 1612946058.8385446
train: epoch 143, iter 900, loss: 2.055233, top_1: 0.741055, top_k: 0.905781, samples/s: 1735.312 1612946073.591017
train: epoch 143, iter 1000, loss: 2.089425, top_1: 0.740664, top_k: 0.905664, samples/s: 1741.259 1612946088.2929475
train: epoch 143, iter 1100, loss: 2.069911, top_1: 0.736406, top_k: 0.903164, samples/s: 1734.838 1612946103.0493608
train: epoch 143, iter 1200, loss: 2.007509, top_1: 0.740273, top_k: 0.899766, samples/s: 1729.557 1612946117.8509316
train: epoch 143, iter 1300, loss: 2.151024, top_1: 0.740664, top_k: 0.900430, samples/s: 1732.933 1612946132.6235986
train: epoch 143, iter 1400, loss: 2.092157, top_1: 0.738047, top_k: 0.901367, samples/s: 1742.780 1612946147.312708
train: epoch 143, iter 1500, loss: 2.058551, top_1: 0.738555, top_k: 0.902461, samples/s: 1745.043 1612946161.9827785
train: epoch 143, iter 1600, loss: 2.247385, top_1: 0.737852, top_k: 0.901172, samples/s: 1722.427 1612946176.845584
train: epoch 143, iter 1700, loss: 1.966567, top_1: 0.742578, top_k: 0.901992, samples/s: 1728.374 1612946191.6571925
train: epoch 143, iter 1800, loss: 2.060840, top_1: 0.733789, top_k: 0.898203, samples/s: 1734.998 1612946206.4122515
train: epoch 143, iter 1900, loss: 2.082814, top_1: 0.735508, top_k: 0.898867, samples/s: 1739.820 1612946221.126432
train: epoch 143, iter 2000, loss: 2.040962, top_1: 0.738437, top_k: 0.902734, samples/s: 1722.684 1612946235.9869215
train: epoch 143, iter 2100, loss: 2.010943, top_1: 0.735352, top_k: 0.901680, samples/s: 1729.044 1612946250.7927623
train: epoch 143, iter 2200, loss: 2.239896, top_1: 0.735039, top_k: 0.900156, samples/s: 1743.080 1612946265.4795153
train: epoch 143, iter 2300, loss: 1.988020, top_1: 0.739531, top_k: 0.901211, samples/s: 1730.379 1612946280.273842
train: epoch 143, iter 2400, loss: 2.090781, top_1: 0.741055, top_k: 0.901602, samples/s: 1732.152 1612946295.0531578
train: epoch 143, iter 2500, loss: 2.114346, top_1: 0.744258, top_k: 0.902578, samples/s: 1738.158 1612946309.78176
train: epoch 143, iter 2600, loss: 2.022305, top_1: 0.739336, top_k: 0.902969, samples/s: 1740.480 1612946324.4900534
train: epoch 143, iter 2700, loss: 2.239516, top_1: 0.737539, top_k: 0.905859, samples/s: 1736.464 1612946339.23261
train: epoch 143, iter 2800, loss: 2.091254, top_1: 0.734180, top_k: 0.899805, samples/s: 1727.648 1612946354.0510452
train: epoch 143, iter 2900, loss: 1.988555, top_1: 0.740195, top_k: 0.900508, samples/s: 1727.815 1612946368.8668246
train: epoch 143, iter 3000, loss: 2.121855, top_1: 0.734453, top_k: 0.900742, samples/s: 1737.733 1612946383.5986981
train: epoch 143, iter 3100, loss: 2.135849, top_1: 0.742969, top_k: 0.902109, samples/s: 1733.229 1612946398.368823
train: epoch 143, iter 3200, loss: 2.083046, top_1: 0.740703, top_k: 0.901914, samples/s: 1723.271 1612946413.224353
train: epoch 143, iter 3300, loss: 1.960712, top_1: 0.740000, top_k: 0.902500, samples/s: 1742.041 1612946427.919689
train: epoch 143, iter 3400, loss: 2.159433, top_1: 0.738086, top_k: 0.902148, samples/s: 1735.455 1612946442.6708302
train: epoch 143, iter 3500, loss: 2.321505, top_1: 0.738008, top_k: 0.900664, samples/s: 1738.790 1612946457.393702
train: epoch 143, iter 3600, loss: 2.122118, top_1: 0.737148, top_k: 0.901914, samples/s: 1737.704 1612946472.1258276
train: epoch 143, iter 3700, loss: 2.210141, top_1: 0.735781, top_k: 0.899414, samples/s: 1730.049 1612946486.9230917
train: epoch 143, iter 3800, loss: 2.160453, top_1: 0.735820, top_k: 0.900273, samples/s: 1731.757 1612946501.705789
train: epoch 143, iter 3900, loss: 2.237609, top_1: 0.738711, top_k: 0.898320, samples/s: 1737.367 1612946516.4407058
train: epoch 143, iter 4000, loss: 2.191951, top_1: 0.737461, top_k: 0.898164, samples/s: 1734.602 1612946531.199129
train: epoch 143, iter 4100, loss: 2.060993, top_1: 0.737187, top_k: 0.902813, samples/s: 1727.518 1612946546.018086
train: epoch 143, iter 4200, loss: 2.006435, top_1: 0.738672, top_k: 0.901172, samples/s: 1727.871 1612946560.8339696
train: epoch 143, iter 4300, loss: 2.108130, top_1: 0.736680, top_k: 0.901602, samples/s: 1721.652 1612946575.7033865
train: epoch 143, iter 4400, loss: 1.928977, top_1: 0.735625, top_k: 0.899023, samples/s: 1738.685 1612946590.42724
train: epoch 143, iter 4500, loss: 2.095298, top_1: 0.735078, top_k: 0.898633, samples/s: 1734.627 1612946605.1854417
train: epoch 143, iter 4600, loss: 2.008261, top_1: 0.735703, top_k: 0.899336, samples/s: 1721.021 1612946620.0603285
train: epoch 143, iter 4700, loss: 2.113544, top_1: 0.737031, top_k: 0.902813, samples/s: 1744.705 1612946634.733303
train: epoch 143, iter 4800, loss: 2.073575, top_1: 0.736289, top_k: 0.898867, samples/s: 1733.634 1612946649.4999273
train: epoch 143, iter 4900, loss: 2.113342, top_1: 0.739141, top_k: 0.902344, samples/s: 1730.411 1612946664.2941003
train: epoch 143, iter 5000, loss: 2.089980, top_1: 0.741797, top_k: 0.903281, samples/s: 1734.684 1612946679.0519361
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_143.
validation: epoch 143, iter 195, top_1: 0.746915, top_k: 0.922396, samples/s: 2826.556 1612946697.1146076
train: epoch 144, iter 100, loss: 2.193600, top_1: 0.742031, top_k: 0.902656, samples/s: 1753.899 1612946731.9940197
train: epoch 144, iter 200, loss: 2.081114, top_1: 0.748320, top_k: 0.905234, samples/s: 1762.501 1612946746.5187967
train: epoch 144, iter 300, loss: 2.196615, top_1: 0.742070, top_k: 0.901953, samples/s: 1756.461 1612946761.0935273
train: epoch 144, iter 400, loss: 2.291529, top_1: 0.736680, top_k: 0.901563, samples/s: 1754.160 1612946775.6874871
train: epoch 144, iter 500, loss: 2.055653, top_1: 0.742812, top_k: 0.900859, samples/s: 1771.229 1612946790.140653
train: epoch 144, iter 600, loss: 2.071480, top_1: 0.741797, top_k: 0.904727, samples/s: 1739.150 1612946804.8605351
train: epoch 144, iter 700, loss: 2.202576, top_1: 0.741641, top_k: 0.901484, samples/s: 1751.580 1612946819.4758284
train: epoch 144, iter 800, loss: 2.056252, top_1: 0.741406, top_k: 0.902969, samples/s: 1731.139 1612946834.2638674
train: epoch 144, iter 900, loss: 2.075535, top_1: 0.739570, top_k: 0.901758, samples/s: 1737.014 1612946849.0017211
train: epoch 144, iter 1000, loss: 2.085431, top_1: 0.740742, top_k: 0.899062, samples/s: 1736.712 1612946863.7423203
train: epoch 144, iter 1100, loss: 1.974004, top_1: 0.741875, top_k: 0.900078, samples/s: 1730.715 1612946878.5338151
train: epoch 144, iter 1200, loss: 2.194782, top_1: 0.741055, top_k: 0.903047, samples/s: 1737.317 1612946893.2692866
train: epoch 144, iter 1300, loss: 1.989459, top_1: 0.742383, top_k: 0.902344, samples/s: 1740.843 1612946907.9747024
train: epoch 144, iter 1400, loss: 2.159637, top_1: 0.741055, top_k: 0.900742, samples/s: 1736.181 1612946922.7196994
train: epoch 144, iter 1500, loss: 2.129323, top_1: 0.740742, top_k: 0.904531, samples/s: 1745.788 1612946937.3836124
train: epoch 144, iter 1600, loss: 2.015631, top_1: 0.739805, top_k: 0.900352, samples/s: 1731.626 1612946952.167384
train: epoch 144, iter 1700, loss: 2.076179, top_1: 0.742695, top_k: 0.903359, samples/s: 1734.747 1612946966.9246032
train: epoch 144, iter 1800, loss: 2.115824, top_1: 0.744180, top_k: 0.902930, samples/s: 1723.013 1612946981.7823524
train: epoch 144, iter 1900, loss: 2.082698, top_1: 0.741680, top_k: 0.904883, samples/s: 1742.940 1612946996.4700363
train: epoch 144, iter 2000, loss: 2.043583, top_1: 0.739219, top_k: 0.904492, samples/s: 1732.968 1612947011.242406
train: epoch 144, iter 2100, loss: 2.085158, top_1: 0.741328, top_k: 0.902227, samples/s: 1731.159 1612947026.0301907
train: epoch 144, iter 2200, loss: 2.060757, top_1: 0.744922, top_k: 0.905664, samples/s: 1731.276 1612947040.8169732
train: epoch 144, iter 2300, loss: 2.202092, top_1: 0.740625, top_k: 0.905703, samples/s: 1740.115 1612947055.528676
train: epoch 144, iter 2400, loss: 2.025805, top_1: 0.743945, top_k: 0.900508, samples/s: 1729.357 1612947070.3318298
train: epoch 144, iter 2500, loss: 2.327875, top_1: 0.744375, top_k: 0.900469, samples/s: 1735.692 1612947085.0809712
train: epoch 144, iter 2600, loss: 2.191164, top_1: 0.740000, top_k: 0.902969, samples/s: 1731.320 1612947099.8674986
train: epoch 144, iter 2700, loss: 2.011857, top_1: 0.737656, top_k: 0.899687, samples/s: 1741.282 1612947114.569223
train: epoch 144, iter 2800, loss: 2.181933, top_1: 0.742734, top_k: 0.901172, samples/s: 1732.135 1612947129.3486555
train: epoch 144, iter 2900, loss: 2.082837, top_1: 0.743047, top_k: 0.905898, samples/s: 1736.416 1612947144.091652
train: epoch 144, iter 3000, loss: 2.155114, top_1: 0.745313, top_k: 0.904922, samples/s: 1726.822 1612947158.9165769
train: epoch 144, iter 3100, loss: 2.136888, top_1: 0.745898, top_k: 0.903555, samples/s: 1733.900 1612947173.6810443
train: epoch 144, iter 3200, loss: 2.162592, top_1: 0.740508, top_k: 0.903516, samples/s: 1729.578 1612947188.4822779
train: epoch 144, iter 3300, loss: 2.119031, top_1: 0.733828, top_k: 0.901680, samples/s: 1714.203 1612947203.416337
train: epoch 144, iter 3400, loss: 2.098191, top_1: 0.743008, top_k: 0.901641, samples/s: 1751.876 1612947218.0293531
train: epoch 144, iter 3500, loss: 2.160497, top_1: 0.737578, top_k: 0.900391, samples/s: 1728.473 1612947232.8399825
train: epoch 144, iter 3600, loss: 2.086080, top_1: 0.736953, top_k: 0.902148, samples/s: 1721.026 1612947247.7149067
train: epoch 144, iter 3700, loss: 2.242871, top_1: 0.737734, top_k: 0.900039, samples/s: 1731.936 1612947262.4960296
train: epoch 144, iter 3800, loss: 2.027979, top_1: 0.738828, top_k: 0.901367, samples/s: 1735.620 1612947277.245765
train: epoch 144, iter 3900, loss: 2.018388, top_1: 0.740352, top_k: 0.905234, samples/s: 1736.932 1612947291.9843972
train: epoch 144, iter 4000, loss: 2.101283, top_1: 0.743203, top_k: 0.905000, samples/s: 1724.132 1612947306.8324518
train: epoch 144, iter 4100, loss: 2.133640, top_1: 0.743203, top_k: 0.902773, samples/s: 1716.010 1612947321.7507963
train: epoch 144, iter 4200, loss: 2.106185, top_1: 0.732734, top_k: 0.897461, samples/s: 1732.433 1612947336.5277128
train: epoch 144, iter 4300, loss: 2.123097, top_1: 0.744102, top_k: 0.905117, samples/s: 1730.626 1612947351.320121
train: epoch 144, iter 4400, loss: 2.050028, top_1: 0.743320, top_k: 0.902930, samples/s: 1733.442 1612947366.088319
train: epoch 144, iter 4500, loss: 2.062380, top_1: 0.743242, top_k: 0.903711, samples/s: 1725.410 1612947380.925418
train: epoch 144, iter 4600, loss: 2.220672, top_1: 0.742188, top_k: 0.902109, samples/s: 1731.621 1612947395.7092772
train: epoch 144, iter 4700, loss: 2.107502, top_1: 0.738516, top_k: 0.901328, samples/s: 1726.681 1612947410.5353305
train: epoch 144, iter 4800, loss: 2.112087, top_1: 0.732422, top_k: 0.898750, samples/s: 1729.421 1612947425.3379986
train: epoch 144, iter 4900, loss: 2.141381, top_1: 0.748125, top_k: 0.904844, samples/s: 1725.641 1612947440.1730917
train: epoch 144, iter 5000, loss: 2.151218, top_1: 0.744492, top_k: 0.905391, samples/s: 1738.421 1612947454.899054
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_144.
validation: epoch 144, iter 195, top_1: 0.739944, top_k: 0.917708, samples/s: 2787.820 1612947473.2504115
train: epoch 145, iter 100, loss: 2.106999, top_1: 0.746563, top_k: 0.905117, samples/s: 1738.315 1612947509.174871
train: epoch 145, iter 200, loss: 2.160277, top_1: 0.747422, top_k: 0.903633, samples/s: 1749.540 1612947523.8073587
train: epoch 145, iter 300, loss: 2.214927, top_1: 0.746758, top_k: 0.901914, samples/s: 1765.192 1612947538.3099163
train: epoch 145, iter 400, loss: 2.013455, top_1: 0.741797, top_k: 0.905039, samples/s: 1749.048 1612947552.9465435
train: epoch 145, iter 500, loss: 2.040619, top_1: 0.745781, top_k: 0.904062, samples/s: 1758.370 1612947567.5054526
train: epoch 145, iter 600, loss: 2.079625, top_1: 0.740781, top_k: 0.901602, samples/s: 1756.776 1612947582.0775588
train: epoch 145, iter 700, loss: 2.240214, top_1: 0.742812, top_k: 0.906523, samples/s: 1744.246 1612947596.7544212
train: epoch 145, iter 800, loss: 2.152436, top_1: 0.741719, top_k: 0.905273, samples/s: 1740.957 1612947611.4589508
train: epoch 145, iter 900, loss: 2.180897, top_1: 0.742070, top_k: 0.903828, samples/s: 1726.513 1612947626.28655
train: epoch 145, iter 1000, loss: 2.128754, top_1: 0.740273, top_k: 0.902891, samples/s: 1729.972 1612947641.084435
train: epoch 145, iter 1100, loss: 2.205260, top_1: 0.740977, top_k: 0.903633, samples/s: 1736.327 1612947655.8282602
train: epoch 145, iter 1200, loss: 2.024496, top_1: 0.745625, top_k: 0.905312, samples/s: 1721.766 1612947670.696736
train: epoch 145, iter 1300, loss: 2.011699, top_1: 0.745820, top_k: 0.902695, samples/s: 1737.965 1612947685.426575
train: epoch 145, iter 1400, loss: 2.032439, top_1: 0.745195, top_k: 0.903555, samples/s: 1734.912 1612947700.182436
train: epoch 145, iter 1500, loss: 2.075708, top_1: 0.745039, top_k: 0.903672, samples/s: 1735.485 1612947714.933263
train: epoch 145, iter 1600, loss: 2.036902, top_1: 0.742188, top_k: 0.903633, samples/s: 1738.017 1612947729.6627066
train: epoch 145, iter 1700, loss: 2.061114, top_1: 0.743477, top_k: 0.903828, samples/s: 1731.366 1612947744.448719
train: epoch 145, iter 1800, loss: 2.111855, top_1: 0.745117, top_k: 0.903750, samples/s: 1727.619 1612947759.2668068
train: epoch 145, iter 1900, loss: 2.051186, top_1: 0.745000, top_k: 0.905547, samples/s: 1726.295 1612947774.0963018
train: epoch 145, iter 2000, loss: 2.225606, top_1: 0.740781, top_k: 0.900781, samples/s: 1735.840 1612947788.8441758
train: epoch 145, iter 2100, loss: 2.078815, top_1: 0.748359, top_k: 0.902109, samples/s: 1733.913 1612947803.6084719
train: epoch 145, iter 2200, loss: 2.225849, top_1: 0.743320, top_k: 0.902148, samples/s: 1733.331 1612947818.377708
train: epoch 145, iter 2300, loss: 2.093542, top_1: 0.743867, top_k: 0.902969, samples/s: 1720.970 1612947833.2530591
train: epoch 145, iter 2400, loss: 2.164443, top_1: 0.741797, top_k: 0.903086, samples/s: 1729.291 1612947848.056758
train: epoch 145, iter 2500, loss: 2.058841, top_1: 0.745859, top_k: 0.907617, samples/s: 1735.962 1612947862.8036702
train: epoch 145, iter 2600, loss: 1.989830, top_1: 0.743320, top_k: 0.903398, samples/s: 1724.022 1612947877.652791
train: epoch 145, iter 2700, loss: 2.143654, top_1: 0.742148, top_k: 0.903945, samples/s: 1744.380 1612947892.3283756
train: epoch 145, iter 2800, loss: 2.077741, top_1: 0.746250, top_k: 0.903828, samples/s: 1734.849 1612947907.084707
train: epoch 145, iter 2900, loss: 2.228191, top_1: 0.745039, top_k: 0.904648, samples/s: 1722.140 1612947921.949884
train: epoch 145, iter 3000, loss: 2.278872, top_1: 0.745234, top_k: 0.904141, samples/s: 1754.364 1612947936.5420828
train: epoch 145, iter 3100, loss: 2.029378, top_1: 0.743242, top_k: 0.901133, samples/s: 1722.005 1612947951.4084256
train: epoch 145, iter 3200, loss: 2.058491, top_1: 0.740078, top_k: 0.901055, samples/s: 1737.198 1612947966.144788
train: epoch 145, iter 3300, loss: 2.121039, top_1: 0.743359, top_k: 0.905547, samples/s: 1736.094 1612947980.890656
train: epoch 145, iter 3400, loss: 2.155674, top_1: 0.743555, top_k: 0.901211, samples/s: 1735.702 1612947995.6397288
train: epoch 145, iter 3500, loss: 2.044229, top_1: 0.748008, top_k: 0.903984, samples/s: 1744.000 1612948010.31853
train: epoch 145, iter 3600, loss: 2.097261, top_1: 0.744258, top_k: 0.903711, samples/s: 1757.500 1612948024.884673
train: epoch 145, iter 3700, loss: 2.074816, top_1: 0.745039, top_k: 0.903633, samples/s: 1742.721 1612948039.5743532
train: epoch 145, iter 3800, loss: 2.058678, top_1: 0.740625, top_k: 0.904102, samples/s: 1750.450 1612948054.1992116
train: epoch 145, iter 3900, loss: 2.011955, top_1: 0.743281, top_k: 0.903594, samples/s: 1735.391 1612948068.9508743
train: epoch 145, iter 4000, loss: 1.926909, top_1: 0.744766, top_k: 0.904570, samples/s: 1758.988 1612948083.5047
train: epoch 145, iter 4100, loss: 2.036155, top_1: 0.739961, top_k: 0.904102, samples/s: 1755.468 1612948098.0877717
train: epoch 145, iter 4200, loss: 2.204965, top_1: 0.744687, top_k: 0.905156, samples/s: 1755.430 1612948112.6710343
train: epoch 145, iter 4300, loss: 2.010438, top_1: 0.742578, top_k: 0.904531, samples/s: 1743.173 1612948127.3569095
train: epoch 145, iter 4400, loss: 2.076593, top_1: 0.741563, top_k: 0.905508, samples/s: 1751.963 1612948141.9691484
train: epoch 145, iter 4500, loss: 1.915336, top_1: 0.743984, top_k: 0.905078, samples/s: 1748.353 1612948156.6114833
train: epoch 145, iter 4600, loss: 2.113491, top_1: 0.741992, top_k: 0.903125, samples/s: 1756.197 1612948171.1884103
train: epoch 145, iter 4700, loss: 2.044724, top_1: 0.742227, top_k: 0.902969, samples/s: 1741.787 1612948185.8859928
train: epoch 145, iter 4800, loss: 2.155798, top_1: 0.740391, top_k: 0.904922, samples/s: 1758.243 1612948200.4459732
train: epoch 145, iter 4900, loss: 2.147577, top_1: 0.738906, top_k: 0.899883, samples/s: 1742.257 1612948215.1395047
train: epoch 145, iter 5000, loss: 2.135766, top_1: 0.748711, top_k: 0.907148, samples/s: 1748.027 1612948229.7846072
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_145.
validation: epoch 145, iter 195, top_1: 0.748297, top_k: 0.921655, samples/s: 2826.496 1612948247.8851213
train: epoch 146, iter 100, loss: 2.280972, top_1: 0.748086, top_k: 0.904648, samples/s: 1746.788 1612948288.179498
train: epoch 146, iter 200, loss: 2.256762, top_1: 0.744414, top_k: 0.902656, samples/s: 1756.762 1612948302.7516823
train: epoch 146, iter 300, loss: 2.054422, top_1: 0.743594, top_k: 0.903633, samples/s: 1759.331 1612948317.3031101
train: epoch 146, iter 400, loss: 2.095080, top_1: 0.747852, top_k: 0.907617, samples/s: 1753.086 1612948331.9054425
train: epoch 146, iter 500, loss: 2.213598, top_1: 0.749531, top_k: 0.905430, samples/s: 1756.409 1612948346.4806807
train: epoch 146, iter 600, loss: 2.110009, top_1: 0.745820, top_k: 0.906484, samples/s: 1748.847 1612948361.1188855
train: epoch 146, iter 700, loss: 2.227812, top_1: 0.747227, top_k: 0.903633, samples/s: 1742.240 1612948375.8130527
train: epoch 146, iter 800, loss: 1.996504, top_1: 0.747773, top_k: 0.904258, samples/s: 1731.474 1612948390.5977197
train: epoch 146, iter 900, loss: 2.024632, top_1: 0.747578, top_k: 0.904570, samples/s: 1754.401 1612948405.1900783
train: epoch 146, iter 1000, loss: 2.299173, top_1: 0.744219, top_k: 0.906875, samples/s: 1748.003 1612948419.8348265
train: epoch 146, iter 1100, loss: 2.052778, top_1: 0.749961, top_k: 0.907422, samples/s: 1720.865 1612948434.7110908
train: epoch 146, iter 1200, loss: 2.152640, top_1: 0.743359, top_k: 0.902148, samples/s: 1735.457 1612948449.4623208
train: epoch 146, iter 1300, loss: 2.169840, top_1: 0.748281, top_k: 0.906055, samples/s: 1753.113 1612948464.0648475
train: epoch 146, iter 1400, loss: 1.914580, top_1: 0.746680, top_k: 0.903984, samples/s: 1738.676 1612948478.7887287
train: epoch 146, iter 1500, loss: 2.044728, top_1: 0.743398, top_k: 0.903320, samples/s: 1737.034 1612948493.5264597
train: epoch 146, iter 1600, loss: 1.966786, top_1: 0.746445, top_k: 0.903867, samples/s: 1732.990 1612948508.2985532
train: epoch 146, iter 1700, loss: 2.087410, top_1: 0.752773, top_k: 0.907695, samples/s: 1746.274 1612948522.958338
train: epoch 146, iter 1800, loss: 1.951894, top_1: 0.748203, top_k: 0.905000, samples/s: 1718.958 1612948537.8510869
train: epoch 146, iter 1900, loss: 2.040545, top_1: 0.746367, top_k: 0.904062, samples/s: 1735.379 1612948552.6029189
train: epoch 146, iter 2000, loss: 2.117334, top_1: 0.743594, top_k: 0.903555, samples/s: 1750.556 1612948567.2277246
train: epoch 146, iter 2100, loss: 2.004507, top_1: 0.745039, top_k: 0.902969, samples/s: 1734.908 1612948581.9826434
train: epoch 146, iter 2200, loss: 2.137250, top_1: 0.745703, top_k: 0.903047, samples/s: 1732.112 1612948596.76259
train: epoch 146, iter 2300, loss: 2.204473, top_1: 0.741094, top_k: 0.900273, samples/s: 1730.316 1612948611.5572817
train: epoch 146, iter 2400, loss: 2.109444, top_1: 0.748945, top_k: 0.905547, samples/s: 1722.210 1612948626.4219031
train: epoch 146, iter 2500, loss: 2.074524, top_1: 0.746055, top_k: 0.906758, samples/s: 1735.346 1612948641.1740446
train: epoch 146, iter 2600, loss: 2.075260, top_1: 0.741484, top_k: 0.903594, samples/s: 1740.344 1612948655.8837416
train: epoch 146, iter 2700, loss: 2.060423, top_1: 0.747578, top_k: 0.903398, samples/s: 1742.284 1612948670.5771093
train: epoch 146, iter 2800, loss: 2.066648, top_1: 0.738711, top_k: 0.902813, samples/s: 1727.052 1612948685.4000254
train: epoch 146, iter 2900, loss: 2.027175, top_1: 0.746250, top_k: 0.903945, samples/s: 1739.397 1612948700.1178336
train: epoch 146, iter 3000, loss: 2.204921, top_1: 0.739297, top_k: 0.903867, samples/s: 1730.825 1612948714.908445
train: epoch 146, iter 3100, loss: 2.148345, top_1: 0.746172, top_k: 0.903281, samples/s: 1738.391 1612948729.634734
train: epoch 146, iter 3200, loss: 2.224368, top_1: 0.743906, top_k: 0.903047, samples/s: 1741.417 1612948744.3353376
train: epoch 146, iter 3300, loss: 2.062681, top_1: 0.746484, top_k: 0.903320, samples/s: 1741.077 1612948759.0389106
train: epoch 146, iter 3400, loss: 2.190156, top_1: 0.744141, top_k: 0.906211, samples/s: 1739.083 1612948773.7592523
train: epoch 146, iter 3500, loss: 2.149616, top_1: 0.745313, top_k: 0.903750, samples/s: 1737.412 1612948788.4938886
train: epoch 146, iter 3600, loss: 1.985753, top_1: 0.743867, top_k: 0.905117, samples/s: 1727.369 1612948803.314091
train: epoch 146, iter 3700, loss: 2.189283, top_1: 0.743203, top_k: 0.904062, samples/s: 1740.582 1612948818.0218034
train: epoch 146, iter 3800, loss: 2.073150, top_1: 0.740820, top_k: 0.902344, samples/s: 1736.613 1612948832.7632158
train: epoch 146, iter 3900, loss: 2.140094, top_1: 0.745313, top_k: 0.903906, samples/s: 1733.152 1612948847.5339115
train: epoch 146, iter 4000, loss: 2.079737, top_1: 0.746914, top_k: 0.904922, samples/s: 1741.342 1612948862.2352211
train: epoch 146, iter 4100, loss: 1.909534, top_1: 0.745586, top_k: 0.905039, samples/s: 1728.845 1612948877.0427833
train: epoch 146, iter 4200, loss: 2.143535, top_1: 0.744648, top_k: 0.903828, samples/s: 1737.990 1612948891.7724817
train: epoch 146, iter 4300, loss: 2.152726, top_1: 0.747617, top_k: 0.905000, samples/s: 1737.601 1612948906.505439
train: epoch 146, iter 4400, loss: 2.115379, top_1: 0.743359, top_k: 0.904570, samples/s: 1738.472 1612948921.2309678
train: epoch 146, iter 4500, loss: 2.062308, top_1: 0.747148, top_k: 0.903906, samples/s: 1725.487 1612948936.0674245
train: epoch 146, iter 4600, loss: 1.934161, top_1: 0.751602, top_k: 0.907617, samples/s: 1721.995 1612948950.9339263
train: epoch 146, iter 4700, loss: 2.128896, top_1: 0.744375, top_k: 0.907500, samples/s: 1745.038 1612948965.6040757
train: epoch 146, iter 4800, loss: 2.005473, top_1: 0.746563, top_k: 0.905078, samples/s: 1744.938 1612948980.2750576
train: epoch 146, iter 4900, loss: 1.960701, top_1: 0.741992, top_k: 0.901758, samples/s: 1730.972 1612948995.0644612
train: epoch 146, iter 5000, loss: 2.081483, top_1: 0.747695, top_k: 0.907305, samples/s: 1742.670 1612949009.7545395
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_146.
validation: epoch 146, iter 195, top_1: 0.750080, top_k: 0.923297, samples/s: 2911.547 1612949027.4031854
train: epoch 147, iter 100, loss: 2.237613, top_1: 0.746680, top_k: 0.907539, samples/s: 1752.557 1612949062.2371247
train: epoch 147, iter 200, loss: 2.044331, top_1: 0.747344, top_k: 0.905508, samples/s: 1749.812 1612949076.8672047
train: epoch 147, iter 300, loss: 2.251992, top_1: 0.748672, top_k: 0.906406, samples/s: 1759.206 1612949091.419289
train: epoch 147, iter 400, loss: 2.028168, top_1: 0.753125, top_k: 0.908164, samples/s: 1760.531 1612949105.9602768
train: epoch 147, iter 500, loss: 2.051118, top_1: 0.749766, top_k: 0.905234, samples/s: 1755.265 1612949120.5450323
train: epoch 147, iter 600, loss: 2.017084, top_1: 0.750195, top_k: 0.904492, samples/s: 1754.603 1612949135.1353595
train: epoch 147, iter 700, loss: 1.882237, top_1: 0.745508, top_k: 0.903867, samples/s: 1742.176 1612949149.8294036
train: epoch 147, iter 800, loss: 1.979001, top_1: 0.746680, top_k: 0.904727, samples/s: 1725.989 1612949164.6615458
train: epoch 147, iter 900, loss: 1.917308, top_1: 0.745898, top_k: 0.904219, samples/s: 1748.079 1612949179.3061163
train: epoch 147, iter 1000, loss: 1.968761, top_1: 0.745664, top_k: 0.904570, samples/s: 1738.044 1612949194.0353723
train: epoch 147, iter 1100, loss: 2.017853, top_1: 0.752930, top_k: 0.906367, samples/s: 1729.194 1612949208.8399963
train: epoch 147, iter 1200, loss: 2.102250, top_1: 0.747539, top_k: 0.902461, samples/s: 1743.042 1612949223.5269325
train: epoch 147, iter 1300, loss: 2.008420, top_1: 0.749844, top_k: 0.907422, samples/s: 1741.953 1612949238.2230678
train: epoch 147, iter 1400, loss: 2.027569, top_1: 0.748477, top_k: 0.906875, samples/s: 1737.539 1612949252.9565482
train: epoch 147, iter 1500, loss: 2.159935, top_1: 0.743164, top_k: 0.900625, samples/s: 1726.795 1612949267.7816508
train: epoch 147, iter 1600, loss: 2.057693, top_1: 0.749219, top_k: 0.906641, samples/s: 1729.817 1612949282.580954
train: epoch 147, iter 1700, loss: 2.261722, top_1: 0.744961, top_k: 0.904805, samples/s: 1725.671 1612949297.4157245
train: epoch 147, iter 1800, loss: 2.073786, top_1: 0.747969, top_k: 0.905391, samples/s: 1732.726 1612949312.1901166
train: epoch 147, iter 1900, loss: 2.119937, top_1: 0.749375, top_k: 0.905156, samples/s: 1744.931 1612949326.861226
train: epoch 147, iter 2000, loss: 2.093645, top_1: 0.749961, top_k: 0.905859, samples/s: 1737.882 1612949341.591815
train: epoch 147, iter 2100, loss: 2.045490, top_1: 0.751289, top_k: 0.905469, samples/s: 1726.595 1612949356.4187522
train: epoch 147, iter 2200, loss: 2.036875, top_1: 0.742305, top_k: 0.903281, samples/s: 1732.293 1612949371.1968215
train: epoch 147, iter 2300, loss: 1.995513, top_1: 0.747031, top_k: 0.902734, samples/s: 1721.435 1612949386.0680726
train: epoch 147, iter 2400, loss: 2.123504, top_1: 0.749531, top_k: 0.908281, samples/s: 1727.668 1612949400.8857126
train: epoch 147, iter 2500, loss: 1.983398, top_1: 0.748203, top_k: 0.909414, samples/s: 1749.263 1612949415.5204918
train: epoch 147, iter 2600, loss: 2.027681, top_1: 0.741992, top_k: 0.905391, samples/s: 1741.559 1612949430.2199242
train: epoch 147, iter 2700, loss: 2.094266, top_1: 0.746250, top_k: 0.905508, samples/s: 1739.844 1612949444.933939
train: epoch 147, iter 2800, loss: 1.960497, top_1: 0.746758, top_k: 0.905742, samples/s: 1730.181 1612949459.730039
train: epoch 147, iter 2900, loss: 2.147620, top_1: 0.746523, top_k: 0.904180, samples/s: 1726.284 1612949474.5595891
train: epoch 147, iter 3000, loss: 2.230481, top_1: 0.743555, top_k: 0.903125, samples/s: 1729.049 1612949489.365385
train: epoch 147, iter 3100, loss: 1.952475, top_1: 0.745703, top_k: 0.904844, samples/s: 1735.920 1612949504.112744
train: epoch 147, iter 3200, loss: 2.128670, top_1: 0.748789, top_k: 0.907852, samples/s: 1729.973 1612949518.9105752
train: epoch 147, iter 3300, loss: 1.977194, top_1: 0.747383, top_k: 0.904727, samples/s: 1734.642 1612949533.668692
train: epoch 147, iter 3400, loss: 2.010416, top_1: 0.751172, top_k: 0.907422, samples/s: 1740.963 1612949548.3732624
train: epoch 147, iter 3500, loss: 2.025071, top_1: 0.746523, top_k: 0.905234, samples/s: 1738.707 1612949563.096738
train: epoch 147, iter 3600, loss: 2.146141, top_1: 0.748242, top_k: 0.907930, samples/s: 1734.265 1612949577.8580806
train: epoch 147, iter 3700, loss: 2.050916, top_1: 0.744766, top_k: 0.907813, samples/s: 1720.626 1612949592.7363605
train: epoch 147, iter 3800, loss: 2.041367, top_1: 0.748125, top_k: 0.905547, samples/s: 1722.801 1612949607.5959065
train: epoch 147, iter 3900, loss: 2.107821, top_1: 0.747695, top_k: 0.906641, samples/s: 1741.305 1612949622.297541
train: epoch 147, iter 4000, loss: 2.076433, top_1: 0.746914, top_k: 0.907617, samples/s: 1723.452 1612949637.1514926
train: epoch 147, iter 4100, loss: 2.087113, top_1: 0.748203, top_k: 0.903906, samples/s: 1742.553 1612949651.842557
train: epoch 147, iter 4200, loss: 2.142463, top_1: 0.743164, top_k: 0.905234, samples/s: 1726.948 1612949666.6663854
train: epoch 147, iter 4300, loss: 2.118737, top_1: 0.746406, top_k: 0.902695, samples/s: 1736.369 1612949681.409767
train: epoch 147, iter 4400, loss: 2.072244, top_1: 0.749687, top_k: 0.904336, samples/s: 1733.244 1612949696.1797302
train: epoch 147, iter 4500, loss: 2.019766, top_1: 0.745938, top_k: 0.909336, samples/s: 1745.266 1612949710.8480353
train: epoch 147, iter 4600, loss: 2.084461, top_1: 0.746836, top_k: 0.906133, samples/s: 1718.755 1612949725.7425144
train: epoch 147, iter 4700, loss: 2.189897, top_1: 0.750273, top_k: 0.902813, samples/s: 1744.910 1612949740.4137278
train: epoch 147, iter 4800, loss: 2.119641, top_1: 0.745977, top_k: 0.904570, samples/s: 1738.632 1612949755.137963
train: epoch 147, iter 4900, loss: 1.956758, top_1: 0.750586, top_k: 0.907188, samples/s: 1740.385 1612949769.8473804
train: epoch 147, iter 5000, loss: 2.114321, top_1: 0.750078, top_k: 0.906133, samples/s: 1723.189 1612949784.7035632
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_147.
validation: epoch 147, iter 195, top_1: 0.749740, top_k: 0.924159, samples/s: 2868.507 1612949802.5093699
train: epoch 148, iter 100, loss: 2.112080, top_1: 0.750313, top_k: 0.906328, samples/s: 1746.977 1612949836.9279895
train: epoch 148, iter 200, loss: 2.080405, top_1: 0.751602, top_k: 0.910156, samples/s: 1766.670 1612949851.4187248
train: epoch 148, iter 300, loss: 1.861713, top_1: 0.746172, top_k: 0.904375, samples/s: 1748.826 1612949866.05699
train: epoch 148, iter 400, loss: 1.992225, top_1: 0.751797, top_k: 0.908906, samples/s: 1759.972 1612949880.6026597
train: epoch 148, iter 500, loss: 2.119660, top_1: 0.749453, top_k: 0.907148, samples/s: 1756.739 1612949895.1750553
train: epoch 148, iter 600, loss: 2.204303, top_1: 0.752070, top_k: 0.909336, samples/s: 1747.585 1612949909.8239393
train: epoch 148, iter 700, loss: 2.194288, top_1: 0.749531, top_k: 0.908164, samples/s: 1735.759 1612949924.5724323
train: epoch 148, iter 800, loss: 1.920726, top_1: 0.750586, top_k: 0.906055, samples/s: 1741.298 1612949939.2741878
train: epoch 148, iter 900, loss: 2.124045, top_1: 0.748125, top_k: 0.902383, samples/s: 1734.254 1612949954.0355127
train: epoch 148, iter 1000, loss: 2.014018, top_1: 0.752070, top_k: 0.907734, samples/s: 1735.184 1612949968.7890399
train: epoch 148, iter 1100, loss: 2.170946, top_1: 0.750000, top_k: 0.904648, samples/s: 1732.607 1612949983.5644035
train: epoch 148, iter 1200, loss: 2.022024, top_1: 0.746367, top_k: 0.904727, samples/s: 1729.758 1612949998.3642764
train: epoch 148, iter 1300, loss: 2.096689, top_1: 0.746211, top_k: 0.903711, samples/s: 1736.831 1612950013.1036475
train: epoch 148, iter 1400, loss: 1.986745, top_1: 0.748008, top_k: 0.905820, samples/s: 1729.501 1612950027.9056978
train: epoch 148, iter 1500, loss: 2.175149, top_1: 0.748750, top_k: 0.904961, samples/s: 1747.540 1612950042.5548449
train: epoch 148, iter 1600, loss: 2.092280, top_1: 0.744141, top_k: 0.907305, samples/s: 1729.367 1612950057.3579245
train: epoch 148, iter 1700, loss: 2.113738, top_1: 0.749141, top_k: 0.905937, samples/s: 1731.417 1612950072.1435523
train: epoch 148, iter 1800, loss: 2.008101, top_1: 0.750898, top_k: 0.906406, samples/s: 1732.070 1612950086.9234684
train: epoch 148, iter 1900, loss: 2.014719, top_1: 0.746211, top_k: 0.905781, samples/s: 1750.208 1612950101.5503516
train: epoch 148, iter 2000, loss: 1.987067, top_1: 0.751328, top_k: 0.905469, samples/s: 1732.963 1612950116.322734
train: epoch 148, iter 2100, loss: 1.937937, top_1: 0.746914, top_k: 0.908398, samples/s: 1727.115 1612950131.1451433
train: epoch 148, iter 2200, loss: 2.002893, top_1: 0.745508, top_k: 0.904766, samples/s: 1742.992 1612950145.8325403
train: epoch 148, iter 2300, loss: 1.995661, top_1: 0.748203, top_k: 0.907969, samples/s: 1739.382 1612950160.5504022
train: epoch 148, iter 2400, loss: 2.026627, top_1: 0.746719, top_k: 0.903281, samples/s: 1728.226 1612950175.3632991
train: epoch 148, iter 2500, loss: 1.970534, top_1: 0.749766, top_k: 0.907500, samples/s: 1731.021 1612950190.1522603
train: epoch 148, iter 2600, loss: 2.007641, top_1: 0.748203, top_k: 0.905820, samples/s: 1741.612 1612950204.8512409
train: epoch 148, iter 2700, loss: 2.102865, top_1: 0.747578, top_k: 0.906094, samples/s: 1735.228 1612950219.6043327
train: epoch 148, iter 2800, loss: 2.056807, top_1: 0.750938, top_k: 0.906289, samples/s: 1731.732 1612950234.387219
train: epoch 148, iter 2900, loss: 2.066174, top_1: 0.751289, top_k: 0.906719, samples/s: 1735.122 1612950249.141287
train: epoch 148, iter 3000, loss: 2.031388, top_1: 0.749023, top_k: 0.903594, samples/s: 1732.121 1612950263.9207783
train: epoch 148, iter 3100, loss: 1.969743, top_1: 0.745508, top_k: 0.905430, samples/s: 1739.907 1612950278.6342893
train: epoch 148, iter 3200, loss: 2.121932, top_1: 0.754180, top_k: 0.906133, samples/s: 1725.202 1612950293.4730635
train: epoch 148, iter 3300, loss: 1.980040, top_1: 0.744219, top_k: 0.906797, samples/s: 1727.938 1612950308.288402
train: epoch 148, iter 3400, loss: 2.074955, top_1: 0.745469, top_k: 0.903164, samples/s: 1739.160 1612950323.0082283
train: epoch 148, iter 3500, loss: 2.016041, top_1: 0.745820, top_k: 0.905312, samples/s: 1734.725 1612950337.765604
train: epoch 148, iter 3600, loss: 1.978751, top_1: 0.748906, top_k: 0.909727, samples/s: 1738.698 1612950352.4892836
train: epoch 148, iter 3700, loss: 2.069199, top_1: 0.750703, top_k: 0.904687, samples/s: 1735.354 1612950367.2412906
train: epoch 148, iter 3800, loss: 2.075846, top_1: 0.754805, top_k: 0.908281, samples/s: 1729.141 1612950382.0462675
train: epoch 148, iter 3900, loss: 1.942969, top_1: 0.750156, top_k: 0.904922, samples/s: 1729.380 1612950396.8492565
train: epoch 148, iter 4000, loss: 1.999737, top_1: 0.752852, top_k: 0.908438, samples/s: 1736.438 1612950411.5920765
train: epoch 148, iter 4100, loss: 1.984607, top_1: 0.748125, top_k: 0.904219, samples/s: 1729.788 1612950426.3916624
train: epoch 148, iter 4200, loss: 2.138576, top_1: 0.742539, top_k: 0.902109, samples/s: 1743.294 1612950441.076488
train: epoch 148, iter 4300, loss: 1.998569, top_1: 0.749492, top_k: 0.907461, samples/s: 1732.868 1612950455.8496373
train: epoch 148, iter 4400, loss: 2.063473, top_1: 0.748828, top_k: 0.906133, samples/s: 1721.425 1612950470.7210114
train: epoch 148, iter 4500, loss: 2.044116, top_1: 0.750586, top_k: 0.907305, samples/s: 1732.603 1612950485.4965322
train: epoch 148, iter 4600, loss: 1.988600, top_1: 0.752305, top_k: 0.906914, samples/s: 1736.025 1612950500.2428422
train: epoch 148, iter 4700, loss: 2.055776, top_1: 0.745586, top_k: 0.906250, samples/s: 1734.009 1612950515.0063388
train: epoch 148, iter 4800, loss: 2.014454, top_1: 0.750586, top_k: 0.905078, samples/s: 1730.740 1612950529.7977057
train: epoch 148, iter 4900, loss: 2.085517, top_1: 0.749492, top_k: 0.907813, samples/s: 1740.288 1612950544.5078537
train: epoch 148, iter 5000, loss: 2.087664, top_1: 0.749492, top_k: 0.909453, samples/s: 1726.554 1612950559.3351038
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_148.
validation: epoch 148, iter 195, top_1: 0.749599, top_k: 0.923498, samples/s: 2852.317 1612950577.1982582
train: epoch 149, iter 100, loss: 2.103979, top_1: 0.746875, top_k: 0.907930, samples/s: 1757.133 1612950611.8050296
train: epoch 149, iter 200, loss: 1.940224, top_1: 0.751523, top_k: 0.910117, samples/s: 1760.151 1612950626.3492117
train: epoch 149, iter 300, loss: 2.152996, top_1: 0.747734, top_k: 0.906563, samples/s: 1758.318 1612950640.908627
train: epoch 149, iter 400, loss: 2.192637, top_1: 0.754609, top_k: 0.910078, samples/s: 1759.294 1612950655.4599342
train: epoch 149, iter 500, loss: 2.262192, top_1: 0.752109, top_k: 0.907773, samples/s: 1758.188 1612950670.0203161
train: epoch 149, iter 600, loss: 2.074193, top_1: 0.748320, top_k: 0.907305, samples/s: 1747.129 1612950684.6729164
train: epoch 149, iter 700, loss: 1.967667, top_1: 0.748086, top_k: 0.906289, samples/s: 1742.288 1612950699.3665135
train: epoch 149, iter 800, loss: 1.915995, top_1: 0.749297, top_k: 0.905703, samples/s: 1734.369 1612950714.1267116
train: epoch 149, iter 900, loss: 2.038167, top_1: 0.750117, top_k: 0.908047, samples/s: 1749.526 1612950728.7592425
train: epoch 149, iter 1000, loss: 2.021393, top_1: 0.752383, top_k: 0.906992, samples/s: 1734.970 1612950743.5145876
train: epoch 149, iter 1100, loss: 1.930250, top_1: 0.753477, top_k: 0.908555, samples/s: 1740.199 1612950758.2254627
train: epoch 149, iter 1200, loss: 1.967949, top_1: 0.751016, top_k: 0.907969, samples/s: 1731.554 1612950773.009916
train: epoch 149, iter 1300, loss: 2.007892, top_1: 0.747266, top_k: 0.904961, samples/s: 1727.194 1612950787.8316185
train: epoch 149, iter 1400, loss: 2.093264, top_1: 0.748906, top_k: 0.906484, samples/s: 1745.212 1612950802.5002775
train: epoch 149, iter 1500, loss: 2.003510, top_1: 0.754609, top_k: 0.908633, samples/s: 1732.144 1612950817.27973
train: epoch 149, iter 1600, loss: 1.959867, top_1: 0.751328, top_k: 0.906289, samples/s: 1735.628 1612950832.029464
train: epoch 149, iter 1700, loss: 1.989577, top_1: 0.749922, top_k: 0.907383, samples/s: 1731.231 1612950846.8165317
train: epoch 149, iter 1800, loss: 2.077019, top_1: 0.747773, top_k: 0.907734, samples/s: 1728.069 1612950861.6307878
train: epoch 149, iter 1900, loss: 1.900883, top_1: 0.752461, top_k: 0.906211, samples/s: 1740.219 1612950876.3415868
train: epoch 149, iter 2000, loss: 2.132583, top_1: 0.750156, top_k: 0.908789, samples/s: 1736.922 1612950891.080349
train: epoch 149, iter 2100, loss: 2.054242, top_1: 0.750977, top_k: 0.905742, samples/s: 1729.634 1612950905.8811753
train: epoch 149, iter 2200, loss: 1.996837, top_1: 0.750156, top_k: 0.905859, samples/s: 1734.509 1612950920.6403534
train: epoch 149, iter 2300, loss: 2.022509, top_1: 0.751250, top_k: 0.906172, samples/s: 1733.202 1612950935.4106708
train: epoch 149, iter 2400, loss: 2.107429, top_1: 0.753867, top_k: 0.909297, samples/s: 1733.080 1612950950.1823351
train: epoch 149, iter 2500, loss: 2.118925, top_1: 0.747930, top_k: 0.907031, samples/s: 1731.784 1612950964.9644797
train: epoch 149, iter 2600, loss: 1.919349, top_1: 0.750234, top_k: 0.909023, samples/s: 1738.538 1612950979.6898797
train: epoch 149, iter 2700, loss: 1.990427, top_1: 0.752422, top_k: 0.908984, samples/s: 1751.512 1612950994.3055055
train: epoch 149, iter 2800, loss: 1.998636, top_1: 0.751367, top_k: 0.905703, samples/s: 1719.361 1612951009.1947527
train: epoch 149, iter 2900, loss: 2.018833, top_1: 0.749219, top_k: 0.904922, samples/s: 1747.000 1612951023.8483992
train: epoch 149, iter 3000, loss: 1.995288, top_1: 0.748086, top_k: 0.905937, samples/s: 1747.793 1612951038.4955115
train: epoch 149, iter 3100, loss: 1.920963, top_1: 0.753789, top_k: 0.908828, samples/s: 1746.218 1612951053.1556811
train: epoch 149, iter 3200, loss: 2.017057, top_1: 0.747930, top_k: 0.905039, samples/s: 1747.377 1612951067.8065844
train: epoch 149, iter 3300, loss: 1.974798, top_1: 0.750273, top_k: 0.909648, samples/s: 1741.775 1612951082.503898
train: epoch 149, iter 3400, loss: 2.027244, top_1: 0.749922, top_k: 0.907305, samples/s: 1754.006 1612951097.0990524
train: epoch 149, iter 3500, loss: 2.084260, top_1: 0.751680, top_k: 0.908086, samples/s: 1750.646 1612951111.722211
train: epoch 149, iter 3600, loss: 2.122546, top_1: 0.748906, top_k: 0.907422, samples/s: 1759.056 1612951126.2757297
train: epoch 149, iter 3700, loss: 2.144636, top_1: 0.750508, top_k: 0.906445, samples/s: 1752.409 1612951140.8839478
train: epoch 149, iter 3800, loss: 2.057879, top_1: 0.753945, top_k: 0.906055, samples/s: 1751.591 1612951155.4992042
train: epoch 149, iter 3900, loss: 1.934356, top_1: 0.749805, top_k: 0.904648, samples/s: 1746.048 1612951170.1609168
train: epoch 149, iter 4000, loss: 2.038133, top_1: 0.750742, top_k: 0.906523, samples/s: 1744.161 1612951184.8384926
train: epoch 149, iter 4100, loss: 2.146554, top_1: 0.749180, top_k: 0.908359, samples/s: 1754.166 1612951199.432385
train: epoch 149, iter 4200, loss: 1.970042, top_1: 0.750156, top_k: 0.904102, samples/s: 1750.398 1612951214.0575948
train: epoch 149, iter 4300, loss: 1.989020, top_1: 0.753711, top_k: 0.908594, samples/s: 1756.987 1612951228.6279614
train: epoch 149, iter 4400, loss: 2.004479, top_1: 0.754609, top_k: 0.906094, samples/s: 1741.272 1612951243.329804
train: epoch 149, iter 4500, loss: 2.083159, top_1: 0.753203, top_k: 0.910508, samples/s: 1744.932 1612951258.0009623
train: epoch 149, iter 4600, loss: 2.071548, top_1: 0.751875, top_k: 0.906641, samples/s: 1762.440 1612951272.5261753
train: epoch 149, iter 4700, loss: 2.213536, top_1: 0.748398, top_k: 0.905781, samples/s: 1757.576 1612951287.0917418
train: epoch 149, iter 4800, loss: 2.039551, top_1: 0.753711, top_k: 0.909570, samples/s: 1752.341 1612951301.7007518
train: epoch 149, iter 4900, loss: 2.086800, top_1: 0.751523, top_k: 0.908398, samples/s: 1743.281 1612951316.3856547
train: epoch 149, iter 5000, loss: 2.058230, top_1: 0.755977, top_k: 0.909414, samples/s: 1753.370 1612951330.9861636
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_149.
validation: epoch 149, iter 195, top_1: 0.750020, top_k: 0.923718, samples/s: 2821.725 1612951349.2020164
train: epoch 150, iter 100, loss: 2.090162, top_1: 0.755078, top_k: 0.910000, samples/s: 1755.313 1612951383.955559
train: epoch 150, iter 200, loss: 2.101755, top_1: 0.743984, top_k: 0.907109, samples/s: 1755.316 1612951398.5400045
train: epoch 150, iter 300, loss: 1.968071, top_1: 0.752773, top_k: 0.909453, samples/s: 1765.022 1612951413.0439246
train: epoch 150, iter 400, loss: 2.048299, top_1: 0.753984, top_k: 0.908398, samples/s: 1757.670 1612951427.608699
train: epoch 150, iter 500, loss: 2.161425, top_1: 0.748203, top_k: 0.909219, samples/s: 1767.778 1612951442.0901506
train: epoch 150, iter 600, loss: 2.106855, top_1: 0.751250, top_k: 0.908945, samples/s: 1751.489 1612951456.7062552
train: epoch 150, iter 700, loss: 1.984245, top_1: 0.750156, top_k: 0.906953, samples/s: 1732.781 1612951471.480233
train: epoch 150, iter 800, loss: 2.122965, top_1: 0.751758, top_k: 0.908906, samples/s: 1747.181 1612951486.1323688
train: epoch 150, iter 900, loss: 1.989783, top_1: 0.749531, top_k: 0.907031, samples/s: 1737.316 1612951500.8677614
train: epoch 150, iter 1000, loss: 1.960683, top_1: 0.752500, top_k: 0.907539, samples/s: 1737.455 1612951515.601965
train: epoch 150, iter 1100, loss: 1.974605, top_1: 0.754492, top_k: 0.908438, samples/s: 1743.974 1612951530.2810545
train: epoch 150, iter 1200, loss: 2.027247, top_1: 0.750742, top_k: 0.905898, samples/s: 1736.528 1612951545.0230718
train: epoch 150, iter 1300, loss: 2.044254, top_1: 0.750859, top_k: 0.908516, samples/s: 1738.092 1612951559.7518983
train: epoch 150, iter 1400, loss: 1.955313, top_1: 0.753359, top_k: 0.908125, samples/s: 1735.756 1612951574.500468
train: epoch 150, iter 1500, loss: 1.927568, top_1: 0.752305, top_k: 0.910000, samples/s: 1734.639 1612951589.2585928
train: epoch 150, iter 1600, loss: 2.078560, top_1: 0.749297, top_k: 0.905234, samples/s: 1735.388 1612951604.010444
train: epoch 150, iter 1700, loss: 2.124843, top_1: 0.748164, top_k: 0.906836, samples/s: 1731.032 1612951618.7992952
train: epoch 150, iter 1800, loss: 2.078608, top_1: 0.750508, top_k: 0.906836, samples/s: 1749.482 1612951633.4321454
train: epoch 150, iter 1900, loss: 2.184865, top_1: 0.750273, top_k: 0.909922, samples/s: 1733.275 1612951648.201888
train: epoch 150, iter 2000, loss: 2.090900, top_1: 0.743320, top_k: 0.904687, samples/s: 1732.703 1612951662.9765074
train: epoch 150, iter 2100, loss: 2.110429, top_1: 0.756211, top_k: 0.908906, samples/s: 1739.378 1612951677.6943917
train: epoch 150, iter 2200, loss: 2.018208, top_1: 0.756211, top_k: 0.908477, samples/s: 1729.087 1612951692.4998755
train: epoch 150, iter 2300, loss: 2.022934, top_1: 0.752383, top_k: 0.908125, samples/s: 1724.729 1612951707.3428202
train: epoch 150, iter 2400, loss: 2.039947, top_1: 0.754609, top_k: 0.908125, samples/s: 1729.434 1612951722.1454823
train: epoch 150, iter 2500, loss: 1.990442, top_1: 0.749297, top_k: 0.909375, samples/s: 1748.814 1612951736.7837787
train: epoch 150, iter 2600, loss: 2.179874, top_1: 0.757500, top_k: 0.909297, samples/s: 1740.281 1612951751.4941173
train: epoch 150, iter 2700, loss: 2.006201, top_1: 0.755391, top_k: 0.908242, samples/s: 1737.064 1612951766.2315536
train: epoch 150, iter 2800, loss: 1.984562, top_1: 0.754883, top_k: 0.909141, samples/s: 1754.360 1612951780.8237736
train: epoch 150, iter 2900, loss: 2.111135, top_1: 0.751563, top_k: 0.906680, samples/s: 1748.765 1612951795.4627671
train: epoch 150, iter 3000, loss: 2.091559, top_1: 0.750391, top_k: 0.908750, samples/s: 1747.144 1612951810.1152096
train: epoch 150, iter 3100, loss: 2.139877, top_1: 0.753086, top_k: 0.907344, samples/s: 1745.010 1612951824.7856033
train: epoch 150, iter 3200, loss: 2.039015, top_1: 0.747617, top_k: 0.906992, samples/s: 1757.223 1612951839.354045
train: epoch 150, iter 3300, loss: 2.052440, top_1: 0.757031, top_k: 0.909219, samples/s: 1739.061 1612951854.074665
train: epoch 150, iter 3400, loss: 2.038753, top_1: 0.750391, top_k: 0.909141, samples/s: 1745.520 1612951868.7406862
train: epoch 150, iter 3500, loss: 2.159013, top_1: 0.753242, top_k: 0.910469, samples/s: 1739.184 1612951883.4602346
train: epoch 150, iter 3600, loss: 2.101181, top_1: 0.750430, top_k: 0.906680, samples/s: 1753.681 1612951898.0581954
train: epoch 150, iter 3700, loss: 2.094121, top_1: 0.748398, top_k: 0.905820, samples/s: 1753.689 1612951912.6559231
train: epoch 150, iter 3800, loss: 2.204231, top_1: 0.754414, top_k: 0.906953, samples/s: 1739.162 1612951927.375676
train: epoch 150, iter 3900, loss: 2.047821, top_1: 0.751445, top_k: 0.904922, samples/s: 1738.977 1612951942.0969667
train: epoch 150, iter 4000, loss: 1.995465, top_1: 0.752539, top_k: 0.908711, samples/s: 1752.908 1612951956.7012446
train: epoch 150, iter 4100, loss: 1.929693, top_1: 0.744023, top_k: 0.906250, samples/s: 1749.440 1612951971.3344867
train: epoch 150, iter 4200, loss: 2.077599, top_1: 0.755781, top_k: 0.912500, samples/s: 1753.318 1612951985.9353812
train: epoch 150, iter 4300, loss: 2.067282, top_1: 0.754414, top_k: 0.907695, samples/s: 1755.513 1612952000.518006
train: epoch 150, iter 4400, loss: 2.135446, top_1: 0.752500, top_k: 0.910469, samples/s: 1748.274 1612952015.1610246
train: epoch 150, iter 4500, loss: 2.052219, top_1: 0.750156, top_k: 0.909531, samples/s: 1756.797 1612952029.733012
train: epoch 150, iter 4600, loss: 2.149021, top_1: 0.751133, top_k: 0.907773, samples/s: 1742.468 1612952044.4248264
train: epoch 150, iter 4700, loss: 2.017447, top_1: 0.754648, top_k: 0.909648, samples/s: 1759.223 1612952058.9766793
train: epoch 150, iter 4800, loss: 2.010009, top_1: 0.753945, top_k: 0.908242, samples/s: 1752.513 1612952073.5843687
train: epoch 150, iter 4900, loss: 2.096091, top_1: 0.752148, top_k: 0.905234, samples/s: 1750.671 1612952088.2073522
train: epoch 150, iter 5000, loss: 2.041127, top_1: 0.753437, top_k: 0.908008, samples/s: 1746.164 1612952102.8679686
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_150.
validation: epoch 150, iter 195, top_1: 0.752564, top_k: 0.924058, samples/s: 2881.319 1612952120.5884647
train: epoch 151, iter 100, loss: 1.942980, top_1: 0.753242, top_k: 0.909766, samples/s: 1740.242 1612952155.8153548
train: epoch 151, iter 200, loss: 2.003089, top_1: 0.753828, top_k: 0.910820, samples/s: 1759.910 1612952170.3614538
train: epoch 151, iter 300, loss: 1.882505, top_1: 0.751563, top_k: 0.907734, samples/s: 1759.980 1612952184.9070833
train: epoch 151, iter 400, loss: 1.926275, top_1: 0.759062, top_k: 0.908906, samples/s: 1754.448 1612952199.4986215
train: epoch 151, iter 500, loss: 2.043865, top_1: 0.753008, top_k: 0.907695, samples/s: 1756.473 1612952214.073328
train: epoch 151, iter 600, loss: 2.058199, top_1: 0.753164, top_k: 0.907969, samples/s: 1761.585 1612952228.6057117
train: epoch 151, iter 700, loss: 2.077230, top_1: 0.756367, top_k: 0.909297, samples/s: 1743.767 1612952243.2864542
train: epoch 151, iter 800, loss: 2.123313, top_1: 0.756016, top_k: 0.908164, samples/s: 1737.105 1612952258.0236282
train: epoch 151, iter 900, loss: 2.141043, top_1: 0.752461, top_k: 0.909297, samples/s: 1739.737 1612952272.738471
train: epoch 151, iter 1000, loss: 2.056462, top_1: 0.756445, top_k: 0.909062, samples/s: 1739.211 1612952287.4578288
train: epoch 151, iter 1100, loss: 1.952942, top_1: 0.750938, top_k: 0.909102, samples/s: 1742.070 1612952302.153004
train: epoch 151, iter 1200, loss: 1.999549, top_1: 0.751602, top_k: 0.907266, samples/s: 1744.300 1612952316.8297608
train: epoch 151, iter 1300, loss: 2.072813, top_1: 0.752578, top_k: 0.907930, samples/s: 1726.886 1612952331.6538038
train: epoch 151, iter 1400, loss: 2.225135, top_1: 0.753320, top_k: 0.908438, samples/s: 1734.392 1612952346.4150567
train: epoch 151, iter 1500, loss: 2.156807, top_1: 0.755391, top_k: 0.910039, samples/s: 1741.697 1612952361.1122227
train: epoch 151, iter 1600, loss: 2.110575, top_1: 0.745625, top_k: 0.903516, samples/s: 1735.634 1612952375.8618674
train: epoch 151, iter 1700, loss: 2.053407, top_1: 0.757656, top_k: 0.911406, samples/s: 1735.456 1612952390.6130376
train: epoch 151, iter 1800, loss: 2.071469, top_1: 0.750156, top_k: 0.907813, samples/s: 1737.068 1612952405.3505502
train: epoch 151, iter 1900, loss: 2.081603, top_1: 0.752461, top_k: 0.907266, samples/s: 1735.506 1612952420.10146
train: epoch 151, iter 2000, loss: 2.053039, top_1: 0.750625, top_k: 0.908242, samples/s: 1731.076 1612952434.88974
train: epoch 151, iter 2100, loss: 2.097041, top_1: 0.752773, top_k: 0.908672, samples/s: 1737.411 1612952449.6243308
train: epoch 151, iter 2200, loss: 2.105466, top_1: 0.752500, top_k: 0.909727, samples/s: 1733.255 1612952464.3942206
train: epoch 151, iter 2300, loss: 2.072797, top_1: 0.756719, top_k: 0.913047, samples/s: 1749.756 1612952479.0248778
train: epoch 151, iter 2400, loss: 2.101312, top_1: 0.750352, top_k: 0.906836, samples/s: 1727.566 1612952493.8434415
train: epoch 151, iter 2500, loss: 2.048862, top_1: 0.752500, top_k: 0.907461, samples/s: 1727.592 1612952508.6616828
train: epoch 151, iter 2600, loss: 2.178554, top_1: 0.751172, top_k: 0.905898, samples/s: 1721.494 1612952523.5324996
train: epoch 151, iter 2700, loss: 2.105622, top_1: 0.753281, top_k: 0.906133, samples/s: 1737.801 1612952538.2637618
train: epoch 151, iter 2800, loss: 2.078603, top_1: 0.751289, top_k: 0.907031, samples/s: 1740.662 1612952552.970811
train: epoch 151, iter 2900, loss: 1.879745, top_1: 0.756797, top_k: 0.908867, samples/s: 1740.180 1612952567.681897
train: epoch 151, iter 3000, loss: 2.048505, top_1: 0.755000, top_k: 0.909023, samples/s: 1746.382 1612952582.3407838
train: epoch 151, iter 3100, loss: 1.939784, top_1: 0.752031, top_k: 0.909297, samples/s: 1730.476 1612952597.1344655
train: epoch 151, iter 3200, loss: 1.846140, top_1: 0.752031, top_k: 0.904180, samples/s: 1728.499 1612952611.9449725
train: epoch 151, iter 3300, loss: 2.116904, top_1: 0.754883, top_k: 0.910039, samples/s: 1731.705 1612952626.7282295
train: epoch 151, iter 3400, loss: 1.892942, top_1: 0.754219, top_k: 0.908672, samples/s: 1746.080 1612952641.3894706
train: epoch 151, iter 3500, loss: 1.971160, top_1: 0.753633, top_k: 0.907422, samples/s: 1736.633 1612952656.1307094
train: epoch 151, iter 3600, loss: 2.188244, top_1: 0.753867, top_k: 0.908672, samples/s: 1729.216 1612952670.935036
train: epoch 151, iter 3700, loss: 2.233360, top_1: 0.749102, top_k: 0.906094, samples/s: 1721.898 1612952685.8023994
train: epoch 151, iter 3800, loss: 1.988197, top_1: 0.749883, top_k: 0.908594, samples/s: 1744.025 1612952700.4811113
train: epoch 151, iter 3900, loss: 2.025434, top_1: 0.746641, top_k: 0.908008, samples/s: 1736.699 1612952715.2216399
train: epoch 151, iter 4000, loss: 2.057400, top_1: 0.750820, top_k: 0.907031, samples/s: 1742.773 1612952729.9108744
train: epoch 151, iter 4100, loss: 2.067516, top_1: 0.751602, top_k: 0.908203, samples/s: 1737.056 1612952744.6484852
train: epoch 151, iter 4200, loss: 2.143798, top_1: 0.751875, top_k: 0.908711, samples/s: 1737.595 1612952759.3814752
train: epoch 151, iter 4300, loss: 2.003011, top_1: 0.756602, top_k: 0.910430, samples/s: 1725.643 1612952774.2165437
train: epoch 151, iter 4400, loss: 2.108094, top_1: 0.754102, top_k: 0.908281, samples/s: 1731.799 1612952788.998909
train: epoch 151, iter 4500, loss: 2.230779, top_1: 0.754141, top_k: 0.908711, samples/s: 1737.154 1612952803.7356372
train: epoch 151, iter 4600, loss: 2.052498, top_1: 0.751719, top_k: 0.909531, samples/s: 1738.967 1612952818.4570334
train: epoch 151, iter 4700, loss: 2.124013, top_1: 0.750586, top_k: 0.908477, samples/s: 1735.860 1612952833.2047627
train: epoch 151, iter 4800, loss: 2.226946, top_1: 0.754727, top_k: 0.910312, samples/s: 1739.491 1612952847.9216492
train: epoch 151, iter 4900, loss: 1.973339, top_1: 0.755039, top_k: 0.911133, samples/s: 1736.763 1612952862.6617017
train: epoch 151, iter 5000, loss: 2.072339, top_1: 0.755469, top_k: 0.909414, samples/s: 1742.380 1612952877.3542814
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_151.
validation: epoch 151, iter 195, top_1: 0.752624, top_k: 0.925881, samples/s: 2796.628 1612952895.6406002
train: epoch 152, iter 100, loss: 2.095278, top_1: 0.750078, top_k: 0.905742, samples/s: 1752.130 1612952930.904965
train: epoch 152, iter 200, loss: 1.930113, top_1: 0.758945, top_k: 0.905781, samples/s: 1755.662 1612952945.4863427
train: epoch 152, iter 300, loss: 2.064100, top_1: 0.752305, top_k: 0.907969, samples/s: 1740.799 1612952960.1922421
train: epoch 152, iter 400, loss: 2.053212, top_1: 0.752852, top_k: 0.906680, samples/s: 1769.645 1612952974.6584668
train: epoch 152, iter 500, loss: 2.044066, top_1: 0.748750, top_k: 0.909297, samples/s: 1753.164 1612952989.2605913
train: epoch 152, iter 600, loss: 2.103826, top_1: 0.755469, top_k: 0.908594, samples/s: 1752.194 1612953003.870882
train: epoch 152, iter 700, loss: 2.026118, top_1: 0.752070, top_k: 0.907656, samples/s: 1739.982 1612953018.5837266
train: epoch 152, iter 800, loss: 2.041689, top_1: 0.752695, top_k: 0.909844, samples/s: 1745.157 1612953033.252868
train: epoch 152, iter 900, loss: 2.108628, top_1: 0.756133, top_k: 0.913320, samples/s: 1734.545 1612953048.011772
train: epoch 152, iter 1000, loss: 2.062645, top_1: 0.757422, top_k: 0.908594, samples/s: 1741.336 1612953062.7131047
train: epoch 152, iter 1100, loss: 1.985308, top_1: 0.752109, top_k: 0.907773, samples/s: 1732.359 1612953077.490664
train: epoch 152, iter 1200, loss: 2.089429, top_1: 0.753984, top_k: 0.908008, samples/s: 1735.363 1612953092.2425725
train: epoch 152, iter 1300, loss: 1.950572, top_1: 0.754336, top_k: 0.906836, samples/s: 1746.045 1612953106.9042892
train: epoch 152, iter 1400, loss: 2.051489, top_1: 0.749844, top_k: 0.908359, samples/s: 1734.979 1612953121.6595528
train: epoch 152, iter 1500, loss: 2.023211, top_1: 0.751172, top_k: 0.905078, samples/s: 1731.900 1612953136.4410298
train: epoch 152, iter 1600, loss: 2.007394, top_1: 0.751719, top_k: 0.910586, samples/s: 1735.211 1612953151.19421
train: epoch 152, iter 1700, loss: 1.988451, top_1: 0.753906, top_k: 0.909336, samples/s: 1732.952 1612953165.96672
train: epoch 152, iter 1800, loss: 2.115814, top_1: 0.753359, top_k: 0.909219, samples/s: 1734.179 1612953180.7287855
train: epoch 152, iter 1900, loss: 2.056922, top_1: 0.749922, top_k: 0.908789, samples/s: 1730.085 1612953195.52567
train: epoch 152, iter 2000, loss: 2.028804, top_1: 0.754648, top_k: 0.907305, samples/s: 1732.926 1612953210.2983873
train: epoch 152, iter 2100, loss: 1.965493, top_1: 0.754258, top_k: 0.909141, samples/s: 1733.695 1612953225.0645356
train: epoch 152, iter 2200, loss: 1.992402, top_1: 0.752773, top_k: 0.910508, samples/s: 1741.169 1612953239.7673645
train: epoch 152, iter 2300, loss: 2.031928, top_1: 0.753437, top_k: 0.908594, samples/s: 1734.464 1612953254.526961
train: epoch 152, iter 2400, loss: 1.958553, top_1: 0.751016, top_k: 0.908789, samples/s: 1739.976 1612953269.2397578
train: epoch 152, iter 2500, loss: 2.146478, top_1: 0.749414, top_k: 0.905781, samples/s: 1728.202 1612953284.0528154
train: epoch 152, iter 2600, loss: 2.000195, top_1: 0.749609, top_k: 0.906641, samples/s: 1731.049 1612953298.8415945
train: epoch 152, iter 2700, loss: 2.004300, top_1: 0.750547, top_k: 0.910781, samples/s: 1723.412 1612953313.6959083
train: epoch 152, iter 2800, loss: 2.007600, top_1: 0.756523, top_k: 0.911445, samples/s: 1746.029 1612953328.3577006
train: epoch 152, iter 2900, loss: 2.029817, top_1: 0.757344, top_k: 0.908828, samples/s: 1741.579 1612953343.0569758
train: epoch 152, iter 3000, loss: 2.119429, top_1: 0.753203, top_k: 0.910664, samples/s: 1736.854 1612953357.7963526
train: epoch 152, iter 3100, loss: 2.107514, top_1: 0.757070, top_k: 0.907266, samples/s: 1722.274 1612953372.6603198
train: epoch 152, iter 3200, loss: 2.069304, top_1: 0.755664, top_k: 0.910508, samples/s: 1741.245 1612953387.3624282
train: epoch 152, iter 3300, loss: 2.130023, top_1: 0.752734, top_k: 0.907227, samples/s: 1741.100 1612953402.0657713
train: epoch 152, iter 3400, loss: 2.167745, top_1: 0.753281, top_k: 0.907227, samples/s: 1736.016 1612953416.8122225
train: epoch 152, iter 3500, loss: 2.130845, top_1: 0.755625, top_k: 0.909492, samples/s: 1734.377 1612953431.572577
train: epoch 152, iter 3600, loss: 2.059629, top_1: 0.755508, top_k: 0.905469, samples/s: 1731.405 1612953446.3582244
train: epoch 152, iter 3700, loss: 2.147929, top_1: 0.754297, top_k: 0.908516, samples/s: 1735.591 1612953461.1082265
train: epoch 152, iter 3800, loss: 2.095025, top_1: 0.751289, top_k: 0.908242, samples/s: 1728.344 1612953475.9201272
train: epoch 152, iter 3900, loss: 1.813972, top_1: 0.753477, top_k: 0.907109, samples/s: 1732.756 1612953490.6942956
train: epoch 152, iter 4000, loss: 2.065631, top_1: 0.751094, top_k: 0.909219, samples/s: 1739.514 1612953505.411061
train: epoch 152, iter 4100, loss: 1.970454, top_1: 0.753320, top_k: 0.909258, samples/s: 1727.581 1612953520.22952
train: epoch 152, iter 4200, loss: 2.143897, top_1: 0.748281, top_k: 0.907695, samples/s: 1727.670 1612953535.0470595
train: epoch 152, iter 4300, loss: 2.119240, top_1: 0.756563, top_k: 0.907969, samples/s: 1728.430 1612953549.8582528
train: epoch 152, iter 4400, loss: 2.124129, top_1: 0.753086, top_k: 0.909180, samples/s: 1721.949 1612953564.7251475
train: epoch 152, iter 4500, loss: 1.996221, top_1: 0.755586, top_k: 0.912070, samples/s: 1748.169 1612953579.368935
train: epoch 152, iter 4600, loss: 2.045310, top_1: 0.750430, top_k: 0.908789, samples/s: 1743.365 1612953594.0531847
train: epoch 152, iter 4700, loss: 1.932903, top_1: 0.752969, top_k: 0.907695, samples/s: 1727.096 1612953608.8757517
train: epoch 152, iter 4800, loss: 2.067434, top_1: 0.754141, top_k: 0.906875, samples/s: 1737.132 1612953623.6126938
train: epoch 152, iter 4900, loss: 2.080150, top_1: 0.756445, top_k: 0.908398, samples/s: 1735.665 1612953638.3620665
train: epoch 152, iter 5000, loss: 2.135338, top_1: 0.752461, top_k: 0.906328, samples/s: 1727.517 1612953653.1810317
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_152.
validation: epoch 152, iter 195, top_1: 0.749079, top_k: 0.924339, samples/s: 2812.151 1612953671.3784184
train: epoch 153, iter 100, loss: 1.994884, top_1: 0.758945, top_k: 0.912500, samples/s: 1756.014 1612953706.0041366
train: epoch 153, iter 200, loss: 2.057975, top_1: 0.752617, top_k: 0.907539, samples/s: 1749.129 1612953720.6399574
train: epoch 153, iter 300, loss: 1.875887, top_1: 0.761055, top_k: 0.910742, samples/s: 1767.629 1612953735.1228273
train: epoch 153, iter 400, loss: 2.119754, top_1: 0.758398, top_k: 0.910508, samples/s: 1756.114 1612953749.7002413
train: epoch 153, iter 500, loss: 1.982937, top_1: 0.755352, top_k: 0.908477, samples/s: 1754.753 1612953764.28921
train: epoch 153, iter 600, loss: 2.049543, top_1: 0.755039, top_k: 0.911992, samples/s: 1734.723 1612953779.046606
train: epoch 153, iter 700, loss: 2.155829, top_1: 0.756836, top_k: 0.910352, samples/s: 1761.390 1612953793.5806725
train: epoch 153, iter 800, loss: 2.002875, top_1: 0.751797, top_k: 0.910742, samples/s: 1746.782 1612953808.2360773
train: epoch 153, iter 900, loss: 2.011210, top_1: 0.755703, top_k: 0.911523, samples/s: 1728.843 1612953823.0436528
train: epoch 153, iter 1000, loss: 1.879322, top_1: 0.755664, top_k: 0.908359, samples/s: 1726.394 1612953837.8722672
train: epoch 153, iter 1100, loss: 2.118344, top_1: 0.754492, top_k: 0.910586, samples/s: 1731.908 1612953852.6537044
train: epoch 153, iter 1200, loss: 2.037432, top_1: 0.746992, top_k: 0.904805, samples/s: 1729.113 1612953867.458981
train: epoch 153, iter 1300, loss: 1.921454, top_1: 0.756016, top_k: 0.912422, samples/s: 1731.697 1612953882.242134
train: epoch 153, iter 1400, loss: 2.162731, top_1: 0.752344, top_k: 0.907266, samples/s: 1749.564 1612953896.8743389
train: epoch 153, iter 1500, loss: 1.987864, top_1: 0.755313, top_k: 0.909609, samples/s: 1738.135 1612953911.6027803
train: epoch 153, iter 1600, loss: 2.040663, top_1: 0.754375, top_k: 0.910820, samples/s: 1724.658 1612953926.4463356
train: epoch 153, iter 1700, loss: 2.032814, top_1: 0.753984, top_k: 0.910078, samples/s: 1737.737 1612953941.1781213
train: epoch 153, iter 1800, loss: 2.031598, top_1: 0.751641, top_k: 0.910312, samples/s: 1733.405 1612953955.9467678
train: epoch 153, iter 1900, loss: 2.112814, top_1: 0.753633, top_k: 0.910391, samples/s: 1728.727 1612953970.755353
train: epoch 153, iter 2000, loss: 2.175683, top_1: 0.752695, top_k: 0.907656, samples/s: 1739.898 1612953985.4688396
train: epoch 153, iter 2100, loss: 2.023313, top_1: 0.754922, top_k: 0.907656, samples/s: 1721.040 1612954000.3435366
train: epoch 153, iter 2200, loss: 2.003992, top_1: 0.753555, top_k: 0.908398, samples/s: 1741.613 1612954015.042537
train: epoch 153, iter 2300, loss: 2.210168, top_1: 0.749961, top_k: 0.909766, samples/s: 1732.103 1612954029.8222673
train: epoch 153, iter 2400, loss: 1.970338, top_1: 0.752617, top_k: 0.905273, samples/s: 1731.541 1612954044.6067688
train: epoch 153, iter 2500, loss: 2.072782, top_1: 0.753633, top_k: 0.909414, samples/s: 1736.960 1612954059.3451977
train: epoch 153, iter 2600, loss: 2.193591, top_1: 0.756367, top_k: 0.910664, samples/s: 1733.881 1612954074.1097903
train: epoch 153, iter 2700, loss: 2.058797, top_1: 0.753867, top_k: 0.909141, samples/s: 1718.715 1612954089.0046868
train: epoch 153, iter 2800, loss: 2.243037, top_1: 0.748008, top_k: 0.906211, samples/s: 1741.607 1612954103.7036452
train: epoch 153, iter 2900, loss: 2.214542, top_1: 0.751328, top_k: 0.907070, samples/s: 1723.460 1612954118.5575552
train: epoch 153, iter 3000, loss: 2.112614, top_1: 0.757812, top_k: 0.908125, samples/s: 1733.669 1612954133.3238995
train: epoch 153, iter 3100, loss: 2.077592, top_1: 0.748789, top_k: 0.908711, samples/s: 1734.931 1612954148.079545
train: epoch 153, iter 3200, loss: 2.148555, top_1: 0.758203, top_k: 0.909297, samples/s: 1738.383 1612954162.80583
train: epoch 153, iter 3300, loss: 2.230378, top_1: 0.751484, top_k: 0.906367, samples/s: 1738.475 1612954177.531448
train: epoch 153, iter 3400, loss: 1.976837, top_1: 0.756250, top_k: 0.908398, samples/s: 1736.821 1612954192.2709796
train: epoch 153, iter 3500, loss: 2.035080, top_1: 0.758516, top_k: 0.908828, samples/s: 1729.865 1612954207.0698454
train: epoch 153, iter 3600, loss: 2.070967, top_1: 0.760508, top_k: 0.913477, samples/s: 1741.162 1612954221.7726145
train: epoch 153, iter 3700, loss: 2.004192, top_1: 0.755117, top_k: 0.909727, samples/s: 1739.072 1612954236.4931188
train: epoch 153, iter 3800, loss: 1.981320, top_1: 0.754687, top_k: 0.909687, samples/s: 1733.217 1612954251.2633636
train: epoch 153, iter 3900, loss: 1.968825, top_1: 0.755391, top_k: 0.908047, samples/s: 1738.790 1612954265.9862952
train: epoch 153, iter 4000, loss: 2.091420, top_1: 0.753086, top_k: 0.906133, samples/s: 1739.266 1612954280.7050872
train: epoch 153, iter 4100, loss: 1.906837, top_1: 0.750742, top_k: 0.907734, samples/s: 1736.949 1612954295.4436038
train: epoch 153, iter 4200, loss: 2.059099, top_1: 0.754453, top_k: 0.905156, samples/s: 1721.284 1612954310.3161933
train: epoch 153, iter 4300, loss: 1.987873, top_1: 0.755195, top_k: 0.908242, samples/s: 1741.724 1612954325.0142572
train: epoch 153, iter 4400, loss: 2.071876, top_1: 0.748789, top_k: 0.907305, samples/s: 1732.266 1612954339.7926319
train: epoch 153, iter 4500, loss: 2.001256, top_1: 0.756094, top_k: 0.909727, samples/s: 1734.048 1612954354.5557296
train: epoch 153, iter 4600, loss: 2.095986, top_1: 0.750234, top_k: 0.906680, samples/s: 1740.385 1612954369.2651265
train: epoch 153, iter 4700, loss: 2.038527, top_1: 0.752695, top_k: 0.907266, samples/s: 1736.361 1612954384.0086076
train: epoch 153, iter 4800, loss: 1.979265, top_1: 0.753516, top_k: 0.908516, samples/s: 1738.308 1612954398.7355917
train: epoch 153, iter 4900, loss: 1.943653, top_1: 0.754180, top_k: 0.909961, samples/s: 1731.167 1612954413.5233393
train: epoch 153, iter 5000, loss: 2.023830, top_1: 0.755820, top_k: 0.911445, samples/s: 1740.173 1612954428.2345386
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_153.
validation: epoch 153, iter 195, top_1: 0.753686, top_k: 0.924920, samples/s: 2903.990 1612954445.8524837
train: epoch 154, iter 100, loss: 2.067585, top_1: 0.753516, top_k: 0.906641, samples/s: 1750.110 1612954480.556367
train: epoch 154, iter 200, loss: 2.119039, top_1: 0.751758, top_k: 0.906523, samples/s: 1761.427 1612954495.0900288
train: epoch 154, iter 300, loss: 2.024218, top_1: 0.754336, top_k: 0.912031, samples/s: 1725.395 1612954509.927287
train: epoch 154, iter 400, loss: 1.916878, top_1: 0.750273, top_k: 0.907852, samples/s: 1766.359 1612954524.4204926
train: epoch 154, iter 500, loss: 2.067676, top_1: 0.748320, top_k: 0.906328, samples/s: 1757.769 1612954538.9841914
train: epoch 154, iter 600, loss: 2.078920, top_1: 0.754570, top_k: 0.909141, samples/s: 1748.844 1612954553.6227825
train: epoch 154, iter 700, loss: 1.994985, top_1: 0.759375, top_k: 0.911211, samples/s: 1733.562 1612954568.3897302
train: epoch 154, iter 800, loss: 1.994689, top_1: 0.752070, top_k: 0.909883, samples/s: 1723.197 1612954583.2459078
train: epoch 154, iter 900, loss: 2.003661, top_1: 0.754766, top_k: 0.910156, samples/s: 1740.087 1612954597.9577239
train: epoch 154, iter 1000, loss: 1.936230, top_1: 0.754805, top_k: 0.906953, samples/s: 1743.194 1612954612.643411
train: epoch 154, iter 1100, loss: 1.973930, top_1: 0.756563, top_k: 0.910547, samples/s: 1722.404 1612954627.506362
train: epoch 154, iter 1200, loss: 1.983582, top_1: 0.754531, top_k: 0.908711, samples/s: 1732.018 1612954642.2868624
train: epoch 154, iter 1300, loss: 2.114151, top_1: 0.754180, top_k: 0.909727, samples/s: 1743.850 1612954656.9675956
train: epoch 154, iter 1400, loss: 2.025954, top_1: 0.751875, top_k: 0.908047, samples/s: 1737.680 1612954671.6993005
train: epoch 154, iter 1500, loss: 2.125290, top_1: 0.749453, top_k: 0.908008, samples/s: 1728.645 1612954686.5085597
train: epoch 154, iter 1600, loss: 2.038962, top_1: 0.750820, top_k: 0.906953, samples/s: 1742.289 1612954701.2018998
train: epoch 154, iter 1700, loss: 2.102417, top_1: 0.750664, top_k: 0.907656, samples/s: 1720.404 1612954716.0821254
train: epoch 154, iter 1800, loss: 2.144875, top_1: 0.758281, top_k: 0.910508, samples/s: 1742.769 1612954730.7714345
train: epoch 154, iter 1900, loss: 2.050980, top_1: 0.759727, top_k: 0.911055, samples/s: 1735.692 1612954745.5205202
train: epoch 154, iter 2000, loss: 1.881893, top_1: 0.754570, top_k: 0.909570, samples/s: 1727.727 1612954760.3377542
train: epoch 154, iter 2100, loss: 2.119886, top_1: 0.759414, top_k: 0.909180, samples/s: 1743.979 1612954775.0168064
train: epoch 154, iter 2200, loss: 2.127402, top_1: 0.751953, top_k: 0.908438, samples/s: 1733.491 1612954789.7846215
train: epoch 154, iter 2300, loss: 2.000271, top_1: 0.753906, top_k: 0.906406, samples/s: 1735.639 1612954804.5342615
train: epoch 154, iter 2400, loss: 1.972059, top_1: 0.752852, top_k: 0.906992, samples/s: 1736.763 1612954819.2743433
train: epoch 154, iter 2500, loss: 2.046930, top_1: 0.754141, top_k: 0.907031, samples/s: 1738.019 1612954834.0037117
train: epoch 154, iter 2600, loss: 2.186366, top_1: 0.754766, top_k: 0.908320, samples/s: 1727.993 1612954848.8185887
train: epoch 154, iter 2700, loss: 2.127968, top_1: 0.752070, top_k: 0.909180, samples/s: 1742.455 1612954863.510825
train: epoch 154, iter 2800, loss: 2.058650, top_1: 0.752891, top_k: 0.907305, samples/s: 1732.894 1612954878.2835453
train: epoch 154, iter 2900, loss: 2.097377, top_1: 0.751992, top_k: 0.909297, samples/s: 1725.803 1612954893.1174557
train: epoch 154, iter 3000, loss: 1.975514, top_1: 0.753789, top_k: 0.908281, samples/s: 1741.940 1612954907.8134687
train: epoch 154, iter 3100, loss: 2.130165, top_1: 0.754531, top_k: 0.907891, samples/s: 1733.580 1612954922.5805452
train: epoch 154, iter 3200, loss: 1.884707, top_1: 0.756133, top_k: 0.910781, samples/s: 1730.327 1612954937.3754632
train: epoch 154, iter 3300, loss: 1.962260, top_1: 0.758242, top_k: 0.911992, samples/s: 1743.577 1612954952.057926
train: epoch 154, iter 3400, loss: 1.998572, top_1: 0.755703, top_k: 0.907852, samples/s: 1738.454 1612954966.783651
train: epoch 154, iter 3500, loss: 2.090268, top_1: 0.749492, top_k: 0.909570, samples/s: 1731.279 1612954981.5703776
train: epoch 154, iter 3600, loss: 2.174792, top_1: 0.740625, top_k: 0.905469, samples/s: 1743.168 1612954996.2563088
train: epoch 154, iter 3700, loss: 2.082809, top_1: 0.753945, top_k: 0.909102, samples/s: 1726.631 1612955011.0828443
train: epoch 154, iter 3800, loss: 2.047458, top_1: 0.750273, top_k: 0.906328, samples/s: 1738.991 1612955025.8040102
train: epoch 154, iter 3900, loss: 2.061798, top_1: 0.756328, top_k: 0.909844, samples/s: 1730.007 1612955040.6016948
train: epoch 154, iter 4000, loss: 2.031867, top_1: 0.759609, top_k: 0.910039, samples/s: 1738.091 1612955055.3305066
train: epoch 154, iter 4100, loss: 1.963258, top_1: 0.756250, top_k: 0.910703, samples/s: 1729.760 1612955070.130212
train: epoch 154, iter 4200, loss: 1.910004, top_1: 0.758984, top_k: 0.910078, samples/s: 1733.585 1612955084.8977776
train: epoch 154, iter 4300, loss: 2.155298, top_1: 0.753828, top_k: 0.906680, samples/s: 1736.775 1612955099.6372464
train: epoch 154, iter 4400, loss: 1.974074, top_1: 0.760938, top_k: 0.910625, samples/s: 1738.158 1612955114.3654737
train: epoch 154, iter 4500, loss: 2.018004, top_1: 0.753320, top_k: 0.911406, samples/s: 1738.574 1612955129.090184
train: epoch 154, iter 4600, loss: 1.981662, top_1: 0.753281, top_k: 0.906914, samples/s: 1735.253 1612955143.843116
train: epoch 154, iter 4700, loss: 1.948772, top_1: 0.748906, top_k: 0.906328, samples/s: 1728.015 1612955158.6577666
train: epoch 154, iter 4800, loss: 1.913552, top_1: 0.750938, top_k: 0.905664, samples/s: 1727.797 1612955173.4743192
train: epoch 154, iter 4900, loss: 2.105564, top_1: 0.752227, top_k: 0.906016, samples/s: 1728.896 1612955188.2815487
train: epoch 154, iter 5000, loss: 2.046205, top_1: 0.753516, top_k: 0.908711, samples/s: 1733.983 1612955203.045215
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_154.
validation: epoch 154, iter 195, top_1: 0.753706, top_k: 0.925381, samples/s: 2833.884 1612955221.1302903
train: epoch 155, iter 100, loss: 1.992870, top_1: 0.754336, top_k: 0.910391, samples/s: 1753.797 1612955255.6311948
train: epoch 155, iter 200, loss: 1.977347, top_1: 0.752578, top_k: 0.907539, samples/s: 1760.802 1612955270.169974
train: epoch 155, iter 300, loss: 2.129262, top_1: 0.755156, top_k: 0.908359, samples/s: 1753.698 1612955284.7677047
train: epoch 155, iter 400, loss: 2.102254, top_1: 0.754961, top_k: 0.909297, samples/s: 1766.643 1612955299.258935
train: epoch 155, iter 500, loss: 2.050752, top_1: 0.748359, top_k: 0.908945, samples/s: 1755.290 1612955313.8429523
train: epoch 155, iter 600, loss: 1.931201, top_1: 0.755938, top_k: 0.910625, samples/s: 1751.705 1612955328.457282
train: epoch 155, iter 700, loss: 2.005412, top_1: 0.757656, top_k: 0.910625, samples/s: 1748.465 1612955343.09877
train: epoch 155, iter 800, loss: 2.008369, top_1: 0.753359, top_k: 0.910859, samples/s: 1741.138 1612955357.8017216
train: epoch 155, iter 900, loss: 1.997214, top_1: 0.752031, top_k: 0.907031, samples/s: 1748.872 1612955372.439772
train: epoch 155, iter 1000, loss: 2.253761, top_1: 0.755664, top_k: 0.911328, samples/s: 1735.504 1612955387.190478
train: epoch 155, iter 1100, loss: 2.245803, top_1: 0.754766, top_k: 0.908242, samples/s: 1732.757 1612955401.9646685
train: epoch 155, iter 1200, loss: 2.107316, top_1: 0.753711, top_k: 0.909023, samples/s: 1737.316 1612955416.7000117
train: epoch 155, iter 1300, loss: 2.018448, top_1: 0.753945, top_k: 0.909531, samples/s: 1730.816 1612955431.4908373
train: epoch 155, iter 1400, loss: 2.044634, top_1: 0.757656, top_k: 0.910117, samples/s: 1743.614 1612955446.172852
train: epoch 155, iter 1500, loss: 2.188199, top_1: 0.751523, top_k: 0.904258, samples/s: 1733.233 1612955460.942961
train: epoch 155, iter 1600, loss: 2.004800, top_1: 0.757070, top_k: 0.910234, samples/s: 1740.149 1612955475.6543674
train: epoch 155, iter 1700, loss: 2.102608, top_1: 0.757852, top_k: 0.910547, samples/s: 1733.295 1612955490.4239347
train: epoch 155, iter 1800, loss: 1.922564, top_1: 0.752891, top_k: 0.904766, samples/s: 1739.514 1612955505.140662
train: epoch 155, iter 1900, loss: 1.904182, top_1: 0.752383, top_k: 0.908711, samples/s: 1742.158 1612955519.8350945
train: epoch 155, iter 2000, loss: 2.058330, top_1: 0.757891, top_k: 0.910547, samples/s: 1732.017 1612955534.6155696
train: epoch 155, iter 2100, loss: 2.057742, top_1: 0.751875, top_k: 0.906016, samples/s: 1734.009 1612955549.3790164
train: epoch 155, iter 2200, loss: 2.007989, top_1: 0.753164, top_k: 0.909805, samples/s: 1743.483 1612955564.0622468
train: epoch 155, iter 2300, loss: 1.964291, top_1: 0.757305, top_k: 0.910312, samples/s: 1733.027 1612955578.8340838
train: epoch 155, iter 2400, loss: 1.991237, top_1: 0.753711, top_k: 0.908906, samples/s: 1745.441 1612955593.5008602
train: epoch 155, iter 2500, loss: 2.011257, top_1: 0.753477, top_k: 0.906836, samples/s: 1728.919 1612955608.30781
train: epoch 155, iter 2600, loss: 2.167011, top_1: 0.756055, top_k: 0.907109, samples/s: 1740.219 1612955623.018597
train: epoch 155, iter 2700, loss: 2.260850, top_1: 0.752695, top_k: 0.910820, samples/s: 1732.504 1612955637.7949212
train: epoch 155, iter 2800, loss: 2.092067, top_1: 0.752305, top_k: 0.907344, samples/s: 1737.284 1612955652.5306032
train: epoch 155, iter 2900, loss: 2.037553, top_1: 0.755195, top_k: 0.912266, samples/s: 1735.592 1612955667.2805662
train: epoch 155, iter 3000, loss: 2.088487, top_1: 0.762461, top_k: 0.912695, samples/s: 1739.181 1612955682.0001147
train: epoch 155, iter 3100, loss: 2.077332, top_1: 0.752461, top_k: 0.908281, samples/s: 1725.560 1612955696.835988
train: epoch 155, iter 3200, loss: 2.050305, top_1: 0.752383, top_k: 0.907695, samples/s: 1723.604 1612955711.6885765
train: epoch 155, iter 3300, loss: 1.983343, top_1: 0.756484, top_k: 0.911680, samples/s: 1739.819 1612955726.4027748
train: epoch 155, iter 3400, loss: 2.000897, top_1: 0.751250, top_k: 0.906211, samples/s: 1733.070 1612955741.1741376
train: epoch 155, iter 3500, loss: 2.024037, top_1: 0.752383, top_k: 0.907734, samples/s: 1732.627 1612955755.9494166
train: epoch 155, iter 3600, loss: 2.248794, top_1: 0.748047, top_k: 0.906328, samples/s: 1734.527 1612955770.7084494
train: epoch 155, iter 3700, loss: 2.061768, top_1: 0.756797, top_k: 0.912305, samples/s: 1733.920 1612955785.4726985
train: epoch 155, iter 3800, loss: 2.071850, top_1: 0.753984, top_k: 0.909141, samples/s: 1743.788 1612955800.1533926
train: epoch 155, iter 3900, loss: 2.057828, top_1: 0.752227, top_k: 0.906094, samples/s: 1734.320 1612955814.9143052
train: epoch 155, iter 4000, loss: 2.077901, top_1: 0.753594, top_k: 0.908438, samples/s: 1742.897 1612955829.602389
train: epoch 155, iter 4100, loss: 2.053594, top_1: 0.755313, top_k: 0.910469, samples/s: 1731.751 1612955844.3851175
train: epoch 155, iter 4200, loss: 2.130757, top_1: 0.756523, top_k: 0.911055, samples/s: 1737.403 1612955859.1197956
train: epoch 155, iter 4300, loss: 1.957999, top_1: 0.749766, top_k: 0.906563, samples/s: 1736.072 1612955873.8657343
train: epoch 155, iter 4400, loss: 1.992536, top_1: 0.757461, top_k: 0.907227, samples/s: 1734.325 1612955888.6265562
train: epoch 155, iter 4500, loss: 2.120384, top_1: 0.755000, top_k: 0.906016, samples/s: 1734.370 1612955903.386932
train: epoch 155, iter 4600, loss: 2.060609, top_1: 0.756875, top_k: 0.909961, samples/s: 1727.389 1612955918.2069662
train: epoch 155, iter 4700, loss: 2.054814, top_1: 0.753672, top_k: 0.910469, samples/s: 1741.902 1612955932.9035854
train: epoch 155, iter 4800, loss: 2.014674, top_1: 0.757422, top_k: 0.908984, samples/s: 1733.647 1612955947.6700807
train: epoch 155, iter 4900, loss: 1.980557, top_1: 0.755352, top_k: 0.910078, samples/s: 1737.752 1612955962.4017904
train: epoch 155, iter 5000, loss: 2.167023, top_1: 0.752773, top_k: 0.908555, samples/s: 1728.636 1612955977.211121
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_155.
validation: epoch 155, iter 195, top_1: 0.753626, top_k: 0.925361, samples/s: 2831.180 1612955995.2699122
train: epoch 156, iter 100, loss: 2.009392, top_1: 0.755508, top_k: 0.910195, samples/s: 1754.797 1612956029.6266987
train: epoch 156, iter 200, loss: 2.005383, top_1: 0.756992, top_k: 0.911133, samples/s: 1757.591 1612956044.1921735
train: epoch 156, iter 300, loss: 2.065359, top_1: 0.754141, top_k: 0.908281, samples/s: 1759.282 1612956058.743354
train: epoch 156, iter 400, loss: 1.906540, top_1: 0.750625, top_k: 0.908867, samples/s: 1740.090 1612956073.4552376
train: epoch 156, iter 500, loss: 1.908389, top_1: 0.756797, top_k: 0.910156, samples/s: 1777.219 1612956087.859823
train: epoch 156, iter 600, loss: 1.929997, top_1: 0.753125, top_k: 0.909141, samples/s: 1731.727 1612956102.6426835
train: epoch 156, iter 700, loss: 1.960312, top_1: 0.757070, top_k: 0.908984, samples/s: 1754.904 1612956117.2304056
train: epoch 156, iter 800, loss: 2.190950, top_1: 0.753086, top_k: 0.909258, samples/s: 1738.034 1612956131.9597757
train: epoch 156, iter 900, loss: 2.144004, top_1: 0.755117, top_k: 0.908281, samples/s: 1740.752 1612956146.6660244
train: epoch 156, iter 1000, loss: 1.966137, top_1: 0.756211, top_k: 0.912852, samples/s: 1733.167 1612956161.4366722
train: epoch 156, iter 1100, loss: 2.036449, top_1: 0.753203, top_k: 0.910547, samples/s: 1738.872 1612956176.1588154
train: epoch 156, iter 1200, loss: 2.064105, top_1: 0.751758, top_k: 0.909609, samples/s: 1732.822 1612956190.9324129
train: epoch 156, iter 1300, loss: 1.883968, top_1: 0.760078, top_k: 0.910117, samples/s: 1739.842 1612956205.6463976
train: epoch 156, iter 1400, loss: 1.972391, top_1: 0.758711, top_k: 0.911758, samples/s: 1730.022 1612956220.4439108
train: epoch 156, iter 1500, loss: 1.988681, top_1: 0.757031, top_k: 0.911602, samples/s: 1737.714 1612956235.1760447
train: epoch 156, iter 1600, loss: 2.006817, top_1: 0.754258, top_k: 0.908164, samples/s: 1736.799 1612956249.915692
train: epoch 156, iter 1700, loss: 2.031332, top_1: 0.751719, top_k: 0.908945, samples/s: 1734.762 1612956264.6727738
train: epoch 156, iter 1800, loss: 1.961018, top_1: 0.754375, top_k: 0.908047, samples/s: 1734.921 1612956279.4284487
train: epoch 156, iter 1900, loss: 1.991316, top_1: 0.752461, top_k: 0.909258, samples/s: 1743.920 1612956294.107969
train: epoch 156, iter 2000, loss: 2.022069, top_1: 0.755156, top_k: 0.908750, samples/s: 1736.488 1612956308.8504107
train: epoch 156, iter 2100, loss: 2.068107, top_1: 0.754961, top_k: 0.911250, samples/s: 1744.987 1612956323.521019
train: epoch 156, iter 2200, loss: 2.161592, top_1: 0.751484, top_k: 0.910547, samples/s: 1732.442 1612956338.2978892
train: epoch 156, iter 2300, loss: 2.103177, top_1: 0.752031, top_k: 0.908047, samples/s: 1730.474 1612956353.091426
train: epoch 156, iter 2400, loss: 1.935256, top_1: 0.754062, top_k: 0.907422, samples/s: 1722.865 1612956367.9504619
train: epoch 156, iter 2500, loss: 2.017460, top_1: 0.757812, top_k: 0.910703, samples/s: 1744.872 1612956382.622021
train: epoch 156, iter 2600, loss: 1.948888, top_1: 0.752422, top_k: 0.908477, samples/s: 1735.943 1612956397.368993
train: epoch 156, iter 2700, loss: 1.993711, top_1: 0.749180, top_k: 0.908281, samples/s: 1731.435 1612956412.1544871
train: epoch 156, iter 2800, loss: 2.064914, top_1: 0.751484, top_k: 0.906719, samples/s: 1727.589 1612956426.972801
train: epoch 156, iter 2900, loss: 1.977906, top_1: 0.747148, top_k: 0.907344, samples/s: 1756.786 1612956441.5448742
train: epoch 156, iter 3000, loss: 1.990152, top_1: 0.752617, top_k: 0.907070, samples/s: 1745.289 1612956456.2129328
train: epoch 156, iter 3100, loss: 2.089005, top_1: 0.750586, top_k: 0.908789, samples/s: 1744.166 1612956470.890424
train: epoch 156, iter 3200, loss: 2.121238, top_1: 0.749453, top_k: 0.911250, samples/s: 1757.970 1612956485.4526784
train: epoch 156, iter 3300, loss: 1.993237, top_1: 0.757188, top_k: 0.909414, samples/s: 1751.390 1612956500.069604
train: epoch 156, iter 3400, loss: 2.021728, top_1: 0.757852, top_k: 0.911445, samples/s: 1748.770 1612956514.7085197
train: epoch 156, iter 3500, loss: 2.142794, top_1: 0.754453, top_k: 0.908984, samples/s: 1744.592 1612956529.3824291
train: epoch 156, iter 3600, loss: 2.079626, top_1: 0.755742, top_k: 0.913125, samples/s: 1748.216 1612956544.0259027
train: epoch 156, iter 3700, loss: 2.062498, top_1: 0.755469, top_k: 0.911367, samples/s: 1758.035 1612956558.587606
train: epoch 156, iter 3800, loss: 2.107689, top_1: 0.751680, top_k: 0.908398, samples/s: 1755.139 1612956573.1733499
train: epoch 156, iter 3900, loss: 2.153781, top_1: 0.751992, top_k: 0.910508, samples/s: 1742.927 1612956587.8613098
train: epoch 156, iter 4000, loss: 2.201943, top_1: 0.755234, top_k: 0.906719, samples/s: 1751.925 1612956602.473825
train: epoch 156, iter 4100, loss: 2.044342, top_1: 0.756914, top_k: 0.910898, samples/s: 1751.555 1612956617.089388
train: epoch 156, iter 4200, loss: 2.019717, top_1: 0.756250, top_k: 0.907656, samples/s: 1746.426 1612956631.747986
train: epoch 156, iter 4300, loss: 2.005723, top_1: 0.757070, top_k: 0.909102, samples/s: 1756.144 1612956646.3252819
train: epoch 156, iter 4400, loss: 2.069480, top_1: 0.754219, top_k: 0.909414, samples/s: 1747.807 1612956660.9722157
train: epoch 156, iter 4500, loss: 2.010565, top_1: 0.750664, top_k: 0.909219, samples/s: 1749.433 1612956675.6055963
train: epoch 156, iter 4600, loss: 2.015378, top_1: 0.752578, top_k: 0.907500, samples/s: 1753.044 1612956690.2086735
train: epoch 156, iter 4700, loss: 2.102123, top_1: 0.754336, top_k: 0.912070, samples/s: 1746.065 1612956704.8703203
train: epoch 156, iter 4800, loss: 1.974040, top_1: 0.754297, top_k: 0.910586, samples/s: 1747.128 1612956719.5228264
train: epoch 156, iter 4900, loss: 1.822409, top_1: 0.750469, top_k: 0.904531, samples/s: 1750.252 1612956734.1492972
train: epoch 156, iter 5000, loss: 2.053581, top_1: 0.754102, top_k: 0.911250, samples/s: 1751.255 1612956748.7674072
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_156.
validation: epoch 156, iter 195, top_1: 0.753325, top_k: 0.925160, samples/s: 2849.441 1612956766.7113194
train: epoch 157, iter 100, loss: 2.128973, top_1: 0.752148, top_k: 0.909414, samples/s: 1749.088 1612956801.5743134
train: epoch 157, iter 200, loss: 2.051645, top_1: 0.752656, top_k: 0.908242, samples/s: 1756.157 1612956816.1518304
train: epoch 157, iter 300, loss: 2.115387, top_1: 0.751523, top_k: 0.908633, samples/s: 1760.724 1612956830.6910472
train: epoch 157, iter 400, loss: 2.005197, top_1: 0.756602, top_k: 0.908750, samples/s: 1755.900 1612956845.2705243
train: epoch 157, iter 500, loss: 2.020631, top_1: 0.752031, top_k: 0.907578, samples/s: 1753.968 1612956859.8660276
train: epoch 157, iter 600, loss: 2.033823, top_1: 0.753594, top_k: 0.909844, samples/s: 1758.947 1612956874.4201858
train: epoch 157, iter 700, loss: 2.087863, top_1: 0.758516, top_k: 0.910859, samples/s: 1751.416 1612956889.0368571
train: epoch 157, iter 800, loss: 2.018840, top_1: 0.754766, top_k: 0.908672, samples/s: 1740.585 1612956903.7445936
train: epoch 157, iter 900, loss: 1.879950, top_1: 0.754102, top_k: 0.907148, samples/s: 1736.021 1612956918.4911418
train: epoch 157, iter 1000, loss: 2.163045, top_1: 0.756406, top_k: 0.907891, samples/s: 1736.722 1612956933.2314277
train: epoch 157, iter 1100, loss: 1.996028, top_1: 0.756406, top_k: 0.911289, samples/s: 1747.101 1612956947.8842483
train: epoch 157, iter 1200, loss: 2.153835, top_1: 0.753477, top_k: 0.906875, samples/s: 1743.476 1612956962.5675454
train: epoch 157, iter 1300, loss: 2.077838, top_1: 0.754023, top_k: 0.907422, samples/s: 1730.078 1612956977.3645527
train: epoch 157, iter 1400, loss: 1.943473, top_1: 0.756172, top_k: 0.908750, samples/s: 1735.755 1612956992.113135
train: epoch 157, iter 1500, loss: 2.062964, top_1: 0.753398, top_k: 0.906172, samples/s: 1739.337 1612957006.831461
train: epoch 157, iter 1600, loss: 1.977513, top_1: 0.753867, top_k: 0.909219, samples/s: 1738.516 1612957021.5566223
train: epoch 157, iter 1700, loss: 2.126162, top_1: 0.752695, top_k: 0.909219, samples/s: 1732.898 1612957036.3295178
train: epoch 157, iter 1800, loss: 2.042955, top_1: 0.754648, top_k: 0.911758, samples/s: 1735.930 1612957051.07669
train: epoch 157, iter 1900, loss: 2.115519, top_1: 0.749687, top_k: 0.905078, samples/s: 1738.360 1612957065.8032002
train: epoch 157, iter 2000, loss: 1.953225, top_1: 0.753047, top_k: 0.907266, samples/s: 1722.816 1612957080.6625602
train: epoch 157, iter 2100, loss: 1.874478, top_1: 0.757461, top_k: 0.910352, samples/s: 1743.678 1612957095.3441904
train: epoch 157, iter 2200, loss: 2.006583, top_1: 0.757266, top_k: 0.911055, samples/s: 1744.149 1612957110.0218198
train: epoch 157, iter 2300, loss: 1.962355, top_1: 0.752500, top_k: 0.908242, samples/s: 1739.485 1612957124.738879
train: epoch 157, iter 2400, loss: 1.995398, top_1: 0.753047, top_k: 0.906953, samples/s: 1741.994 1612957139.4346802
train: epoch 157, iter 2500, loss: 2.149252, top_1: 0.750430, top_k: 0.907617, samples/s: 1738.017 1612957154.1641326
train: epoch 157, iter 2600, loss: 2.069735, top_1: 0.752617, top_k: 0.907109, samples/s: 1740.657 1612957168.8712153
train: epoch 157, iter 2700, loss: 2.000462, top_1: 0.754570, top_k: 0.912656, samples/s: 1727.246 1612957183.6924627
train: epoch 157, iter 2800, loss: 1.901020, top_1: 0.752852, top_k: 0.907617, samples/s: 1722.501 1612957198.5546126
train: epoch 157, iter 2900, loss: 1.989283, top_1: 0.753398, top_k: 0.906367, samples/s: 1738.464 1612957213.2802036
train: epoch 157, iter 3000, loss: 1.924582, top_1: 0.757969, top_k: 0.913398, samples/s: 1746.228 1612957227.940368
train: epoch 157, iter 3100, loss: 1.949125, top_1: 0.756992, top_k: 0.909023, samples/s: 1733.401 1612957242.709015
train: epoch 157, iter 3200, loss: 2.108531, top_1: 0.751992, top_k: 0.907422, samples/s: 1723.854 1612957257.5595524
train: epoch 157, iter 3300, loss: 2.119639, top_1: 0.756328, top_k: 0.910352, samples/s: 1750.871 1612957272.1807787
train: epoch 157, iter 3400, loss: 1.995694, top_1: 0.756172, top_k: 0.909922, samples/s: 1726.865 1612957287.0053105
train: epoch 157, iter 3500, loss: 1.927438, top_1: 0.755156, top_k: 0.907773, samples/s: 1734.326 1612957301.7661095
train: epoch 157, iter 3600, loss: 2.056852, top_1: 0.755820, top_k: 0.908828, samples/s: 1738.294 1612957316.4932318
train: epoch 157, iter 3700, loss: 1.926790, top_1: 0.753125, top_k: 0.910195, samples/s: 1734.106 1612957331.2559044
train: epoch 157, iter 3800, loss: 1.978702, top_1: 0.752031, top_k: 0.908086, samples/s: 1731.874 1612957346.0375185
train: epoch 157, iter 3900, loss: 2.072207, top_1: 0.756484, top_k: 0.909297, samples/s: 1731.547 1612957360.8220253
train: epoch 157, iter 4000, loss: 2.083056, top_1: 0.751914, top_k: 0.908086, samples/s: 1735.540 1612957375.572439
train: epoch 157, iter 4100, loss: 1.911266, top_1: 0.753242, top_k: 0.907578, samples/s: 1717.555 1612957390.477417
train: epoch 157, iter 4200, loss: 1.954618, top_1: 0.750156, top_k: 0.906328, samples/s: 1728.316 1612957405.2894847
train: epoch 157, iter 4300, loss: 1.910314, top_1: 0.757500, top_k: 0.910898, samples/s: 1736.474 1612957420.0320053
train: epoch 157, iter 4400, loss: 2.040228, top_1: 0.755898, top_k: 0.910586, samples/s: 1742.866 1612957434.720557
train: epoch 157, iter 4500, loss: 2.079026, top_1: 0.758555, top_k: 0.908789, samples/s: 1727.497 1612957449.5396433
train: epoch 157, iter 4600, loss: 2.145907, top_1: 0.753867, top_k: 0.909453, samples/s: 1732.374 1612957464.3169434
train: epoch 157, iter 4700, loss: 2.086454, top_1: 0.748320, top_k: 0.907109, samples/s: 1741.425 1612957479.017559
train: epoch 157, iter 4800, loss: 1.920510, top_1: 0.756758, top_k: 0.910820, samples/s: 1725.871 1612957493.8507366
train: epoch 157, iter 4900, loss: 1.859037, top_1: 0.764141, top_k: 0.912188, samples/s: 1732.053 1612957508.6308796
train: epoch 157, iter 5000, loss: 1.871844, top_1: 0.759570, top_k: 0.907773, samples/s: 1728.227 1612957523.4437745
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_157.
validation: epoch 157, iter 195, top_1: 0.754227, top_k: 0.925080, samples/s: 2825.968 1612957541.5286398
train: epoch 158, iter 100, loss: 2.220303, top_1: 0.757812, top_k: 0.907383, samples/s: 1752.223 1612957582.910607
train: epoch 158, iter 200, loss: 1.948195, top_1: 0.753320, top_k: 0.913867, samples/s: 1753.444 1612957597.5103016
train: epoch 158, iter 300, loss: 1.842664, top_1: 0.755547, top_k: 0.910547, samples/s: 1758.034 1612957612.0721385
train: epoch 158, iter 400, loss: 1.898924, top_1: 0.755273, top_k: 0.907227, samples/s: 1744.246 1612957626.7489495
train: epoch 158, iter 500, loss: 1.936553, top_1: 0.756953, top_k: 0.911016, samples/s: 1761.758 1612957641.2798324
train: epoch 158, iter 600, loss: 2.030531, top_1: 0.754727, top_k: 0.907422, samples/s: 1760.546 1612957655.8208349
train: epoch 158, iter 700, loss: 2.102108, top_1: 0.751563, top_k: 0.907500, samples/s: 1755.994 1612957670.3993585
train: epoch 158, iter 800, loss: 1.911467, top_1: 0.752109, top_k: 0.908008, samples/s: 1743.106 1612957685.0858426
train: epoch 158, iter 900, loss: 1.957873, top_1: 0.754805, top_k: 0.908711, samples/s: 1712.666 1612957700.0333464
train: epoch 158, iter 1000, loss: 2.144216, top_1: 0.756641, top_k: 0.910430, samples/s: 1725.533 1612957714.8692486
train: epoch 158, iter 1100, loss: 2.038445, top_1: 0.751563, top_k: 0.909375, samples/s: 1754.835 1612957729.4575493
train: epoch 158, iter 1200, loss: 2.088527, top_1: 0.754570, top_k: 0.910078, samples/s: 1732.567 1612957744.2332642
train: epoch 158, iter 1300, loss: 2.022104, top_1: 0.755313, top_k: 0.910664, samples/s: 1741.093 1612957758.9367373
train: epoch 158, iter 1400, loss: 2.110138, top_1: 0.754414, top_k: 0.909883, samples/s: 1734.823 1612957773.6932547
train: epoch 158, iter 1500, loss: 2.049463, top_1: 0.757539, top_k: 0.910156, samples/s: 1742.249 1612957788.3871737
train: epoch 158, iter 1600, loss: 2.023658, top_1: 0.756172, top_k: 0.907852, samples/s: 1741.361 1612957803.0880458
train: epoch 158, iter 1700, loss: 2.019566, top_1: 0.747734, top_k: 0.907305, samples/s: 1698.862 1612957818.1575067
train: epoch 158, iter 1800, loss: 1.994228, top_1: 0.753125, top_k: 0.908047, samples/s: 1748.003 1612957832.8022494
train: epoch 158, iter 1900, loss: 2.012256, top_1: 0.757383, top_k: 0.907539, samples/s: 1735.967 1612957847.5490506
train: epoch 158, iter 2000, loss: 1.886227, top_1: 0.755859, top_k: 0.907969, samples/s: 1738.173 1612957862.2772198
train: epoch 158, iter 2100, loss: 2.154174, top_1: 0.754727, top_k: 0.910039, samples/s: 1736.105 1612957877.022815
train: epoch 158, iter 2200, loss: 1.966728, top_1: 0.759531, top_k: 0.911680, samples/s: 1730.319 1612957891.8181837
train: epoch 158, iter 2300, loss: 1.924078, top_1: 0.754219, top_k: 0.911641, samples/s: 1735.722 1612957906.5666769
train: epoch 158, iter 2400, loss: 2.017212, top_1: 0.755195, top_k: 0.911250, samples/s: 1733.649 1612957921.3336153
train: epoch 158, iter 2500, loss: 2.086693, top_1: 0.755703, top_k: 0.910039, samples/s: 1737.689 1612957936.065423
train: epoch 158, iter 2600, loss: 1.837041, top_1: 0.752109, top_k: 0.906367, samples/s: 1740.659 1612957950.7725427
train: epoch 158, iter 2700, loss: 1.976238, top_1: 0.749844, top_k: 0.907656, samples/s: 1737.699 1612957965.5046318
train: epoch 158, iter 2800, loss: 2.096140, top_1: 0.751719, top_k: 0.908906, samples/s: 1732.146 1612957980.2839785
train: epoch 158, iter 2900, loss: 1.994312, top_1: 0.755469, top_k: 0.910937, samples/s: 1731.447 1612957995.0692952
train: epoch 158, iter 3000, loss: 2.259843, top_1: 0.756797, top_k: 0.909844, samples/s: 1735.518 1612958009.8199646
train: epoch 158, iter 3100, loss: 2.065033, top_1: 0.750742, top_k: 0.908320, samples/s: 1740.236 1612958024.5305762
train: epoch 158, iter 3200, loss: 2.009084, top_1: 0.755938, top_k: 0.907148, samples/s: 1720.997 1612958039.405722
train: epoch 158, iter 3300, loss: 2.032087, top_1: 0.755352, top_k: 0.908828, samples/s: 1744.712 1612958054.0788713
train: epoch 158, iter 3400, loss: 1.880688, top_1: 0.754727, top_k: 0.909531, samples/s: 1709.245 1612958069.0560715
train: epoch 158, iter 3500, loss: 2.112154, top_1: 0.756602, top_k: 0.909375, samples/s: 1743.997 1612958083.7349172
train: epoch 158, iter 3600, loss: 2.078821, top_1: 0.753047, top_k: 0.906758, samples/s: 1733.860 1612958098.5001125
train: epoch 158, iter 3700, loss: 2.028471, top_1: 0.750664, top_k: 0.907656, samples/s: 1731.879 1612958113.2813191
train: epoch 158, iter 3800, loss: 2.129585, top_1: 0.749375, top_k: 0.905586, samples/s: 1735.316 1612958128.0336163
train: epoch 158, iter 3900, loss: 1.967106, top_1: 0.753984, top_k: 0.908633, samples/s: 1746.736 1612958142.68957
train: epoch 158, iter 4000, loss: 2.015332, top_1: 0.751914, top_k: 0.906289, samples/s: 1745.675 1612958157.3543425
train: epoch 158, iter 4100, loss: 2.081276, top_1: 0.752578, top_k: 0.907461, samples/s: 1722.989 1612958172.2125835
train: epoch 158, iter 4200, loss: 2.067560, top_1: 0.747734, top_k: 0.905117, samples/s: 1731.211 1612958186.9995792
train: epoch 158, iter 4300, loss: 2.075433, top_1: 0.757344, top_k: 0.908086, samples/s: 1747.474 1612958201.6492991
train: epoch 158, iter 4400, loss: 2.065509, top_1: 0.754766, top_k: 0.907031, samples/s: 1712.087 1612958216.6018631
train: epoch 158, iter 4500, loss: 1.987084, top_1: 0.757109, top_k: 0.910742, samples/s: 1756.730 1612958231.1747231
train: epoch 158, iter 4600, loss: 1.990636, top_1: 0.755156, top_k: 0.906914, samples/s: 1732.492 1612958245.950722
train: epoch 158, iter 4700, loss: 2.056165, top_1: 0.757266, top_k: 0.909258, samples/s: 1741.498 1612958260.6507838
train: epoch 158, iter 4800, loss: 1.962170, top_1: 0.755898, top_k: 0.908867, samples/s: 1742.709 1612958275.340529
train: epoch 158, iter 4900, loss: 1.971891, top_1: 0.758203, top_k: 0.910547, samples/s: 1733.993 1612958290.1041262
train: epoch 158, iter 5000, loss: 2.102323, top_1: 0.753047, top_k: 0.907461, samples/s: 1733.499 1612958304.8720033
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_158.
validation: epoch 158, iter 195, top_1: 0.753385, top_k: 0.924900, samples/s: 2828.857 1612958322.9323783
train: epoch 159, iter 100, loss: 2.128010, top_1: 0.752383, top_k: 0.910703, samples/s: 1751.339 1612958358.7421455
train: epoch 159, iter 200, loss: 2.259082, top_1: 0.749414, top_k: 0.906172, samples/s: 1762.553 1612958373.2664804
train: epoch 159, iter 300, loss: 2.072702, top_1: 0.751445, top_k: 0.908945, samples/s: 1760.049 1612958387.811491
train: epoch 159, iter 400, loss: 2.178973, top_1: 0.754258, top_k: 0.910039, samples/s: 1757.941 1612958402.3739808
train: epoch 159, iter 500, loss: 1.973638, top_1: 0.757812, top_k: 0.911523, samples/s: 1755.113 1612958416.9599268
train: epoch 159, iter 600, loss: 2.069878, top_1: 0.754062, top_k: 0.910234, samples/s: 1760.430 1612958431.501895
train: epoch 159, iter 700, loss: 2.016387, top_1: 0.758086, top_k: 0.912930, samples/s: 1750.936 1612958446.122592
train: epoch 159, iter 800, loss: 2.016542, top_1: 0.756250, top_k: 0.910195, samples/s: 1716.642 1612958461.0354693
train: epoch 159, iter 900, loss: 2.214335, top_1: 0.754805, top_k: 0.908594, samples/s: 1724.334 1612958475.8817325
train: epoch 159, iter 1000, loss: 1.976897, top_1: 0.756016, top_k: 0.909258, samples/s: 1745.513 1612958490.5479116
train: epoch 159, iter 1100, loss: 2.125042, top_1: 0.754570, top_k: 0.910195, samples/s: 1743.815 1612958505.2284129
train: epoch 159, iter 1200, loss: 2.186674, top_1: 0.752734, top_k: 0.908828, samples/s: 1727.333 1612958520.04895
train: epoch 159, iter 1300, loss: 1.999307, top_1: 0.750234, top_k: 0.905898, samples/s: 1734.935 1612958534.8045576
train: epoch 159, iter 1400, loss: 2.022894, top_1: 0.752891, top_k: 0.909297, samples/s: 1734.220 1612958549.5662525
train: epoch 159, iter 1500, loss: 2.019107, top_1: 0.754531, top_k: 0.908438, samples/s: 1733.407 1612958564.334781
train: epoch 159, iter 1600, loss: 1.984179, top_1: 0.755625, top_k: 0.909570, samples/s: 1734.744 1612958579.0920625
train: epoch 159, iter 1700, loss: 2.113749, top_1: 0.753867, top_k: 0.907852, samples/s: 1733.599 1612958593.8589568
train: epoch 159, iter 1800, loss: 2.127922, top_1: 0.759805, top_k: 0.908555, samples/s: 1743.922 1612958608.538517
train: epoch 159, iter 1900, loss: 2.109385, top_1: 0.756406, top_k: 0.910937, samples/s: 1728.981 1612958623.3449895
train: epoch 159, iter 2000, loss: 1.972206, top_1: 0.754609, top_k: 0.911094, samples/s: 1731.076 1612958638.1334121
train: epoch 159, iter 2100, loss: 2.164389, top_1: 0.755820, top_k: 0.907305, samples/s: 1738.506 1612958652.858734
train: epoch 159, iter 2200, loss: 1.806190, top_1: 0.757188, top_k: 0.909727, samples/s: 1736.199 1612958667.6036172
train: epoch 159, iter 2300, loss: 1.998776, top_1: 0.757148, top_k: 0.908867, samples/s: 1732.160 1612958682.3828232
train: epoch 159, iter 2400, loss: 1.977067, top_1: 0.753555, top_k: 0.909102, samples/s: 1741.543 1612958697.0824513
train: epoch 159, iter 2500, loss: 1.993969, top_1: 0.751953, top_k: 0.908359, samples/s: 1735.911 1612958711.8297656
train: epoch 159, iter 2600, loss: 2.082197, top_1: 0.751367, top_k: 0.905547, samples/s: 1730.598 1612958726.6223443
train: epoch 159, iter 2700, loss: 2.187483, top_1: 0.752148, top_k: 0.908359, samples/s: 1731.954 1612958741.4032836
train: epoch 159, iter 2800, loss: 2.193695, top_1: 0.754492, top_k: 0.907891, samples/s: 1739.952 1612958756.116338
train: epoch 159, iter 2900, loss: 1.991303, top_1: 0.754609, top_k: 0.908594, samples/s: 1737.355 1612958770.8514132
train: epoch 159, iter 3000, loss: 2.157784, top_1: 0.755039, top_k: 0.908594, samples/s: 1737.370 1612958785.586306
train: epoch 159, iter 3100, loss: 2.043218, top_1: 0.755977, top_k: 0.908711, samples/s: 1728.158 1612958800.3997495
train: epoch 159, iter 3200, loss: 2.202172, top_1: 0.750273, top_k: 0.908828, samples/s: 1733.937 1612958815.1638966
train: epoch 159, iter 3300, loss: 2.006227, top_1: 0.759062, top_k: 0.910039, samples/s: 1736.851 1612958829.903231
train: epoch 159, iter 3400, loss: 2.009497, top_1: 0.757656, top_k: 0.910820, samples/s: 1737.442 1612958844.6374478
train: epoch 159, iter 3500, loss: 2.051134, top_1: 0.759258, top_k: 0.910469, samples/s: 1743.428 1612958859.3211389
train: epoch 159, iter 3600, loss: 2.178313, top_1: 0.755703, top_k: 0.909570, samples/s: 1735.574 1612958874.0713437
train: epoch 159, iter 3700, loss: 1.949920, top_1: 0.756094, top_k: 0.910469, samples/s: 1718.350 1612958888.9694023
train: epoch 159, iter 3800, loss: 1.977994, top_1: 0.753047, top_k: 0.907891, samples/s: 1730.372 1612958903.763911
train: epoch 159, iter 3900, loss: 2.021563, top_1: 0.755820, top_k: 0.910312, samples/s: 1732.009 1612958918.5444102
train: epoch 159, iter 4000, loss: 1.955391, top_1: 0.753008, top_k: 0.910078, samples/s: 1739.975 1612958933.2572289
train: epoch 159, iter 4100, loss: 1.888801, top_1: 0.757930, top_k: 0.910469, samples/s: 1732.493 1612958948.0336084
train: epoch 159, iter 4200, loss: 1.965108, top_1: 0.750781, top_k: 0.908789, samples/s: 1727.885 1612958962.849461
train: epoch 159, iter 4300, loss: 1.947862, top_1: 0.752266, top_k: 0.908594, samples/s: 1743.361 1612958977.5336688
train: epoch 159, iter 4400, loss: 2.061520, top_1: 0.750352, top_k: 0.906758, samples/s: 1729.148 1612958992.3387394
train: epoch 159, iter 4500, loss: 2.041225, top_1: 0.758164, top_k: 0.909219, samples/s: 1736.635 1612959007.0798035
train: epoch 159, iter 4600, loss: 2.056868, top_1: 0.747031, top_k: 0.909141, samples/s: 1733.287 1612959021.8494194
train: epoch 159, iter 4700, loss: 1.994387, top_1: 0.749258, top_k: 0.905312, samples/s: 1719.830 1612959036.734642
train: epoch 159, iter 4800, loss: 2.070675, top_1: 0.754531, top_k: 0.908789, samples/s: 1745.264 1612959051.4028895
train: epoch 159, iter 4900, loss: 2.058050, top_1: 0.753008, top_k: 0.910547, samples/s: 1731.806 1612959066.1852756
train: epoch 159, iter 5000, loss: 2.174814, top_1: 0.749336, top_k: 0.907344, samples/s: 1742.387 1612959080.8777075
Saving model to ./repvggB0/snapshots/model_save/snapshot_epoch_159.
validation: epoch 159, iter 195, top_1: 0.753225, top_k: 0.924800, samples/s: 2814.057 1612959099.0494175
