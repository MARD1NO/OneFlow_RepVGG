==================================================================
Running repvggA2: num_gpu_per_node = 4, num_nodes = 1.
==================================================================
dtype = float32
gpu_num_per_node = 4
num_nodes = 1
node_ips = ['192.168.1.13', '192.168.1.14']
ctrl_port = 50051
model = repvggA2
mixup = False
use_fp16 = None
use_xla = None
channel_last = False
pad_output = None
num_epochs = 160
model_load_dir = None
batch_size_per_device = 64
val_batch_size_per_device = 64
nccl_fusion_threshold_mb = 16
nccl_fusion_max_ops = 24
fuse_bn_relu = True
fuse_bn_add_relu = True
gpu_image_decoder = True
image_path = test_img/tiger.jpg
num_classes = 1000
num_examples = 1281167
num_val_examples = 50000
rgb_mean = [123.68, 116.779, 103.939]
rgb_std = [58.393, 57.12, 57.375]
image_shape = [3, 224, 224]
label_smoothing = 0.1
model_save_dir = ./repvggA2/snapshots/model_save/
log_dir = ./output
loss_print_every_n_iter = 100
image_size = 224
resize_shorter = 256
train_data_dir = /DATA/disk1/ImageNet/ofrecord/train
train_data_part_num = 256
val_data_dir = /DATA/disk1/ImageNet/ofrecord/validation
val_data_part_num = 256
optimizer = sgd
learning_rate = 0.1
wd = 3.0517578125e-05
momentum = 0.9
lr_decay = cosine
lr_decay_rate = 0.94
lr_decay_epochs = 2
warmup_epochs = 5
decay_rate = 0.9
epsilon = 1.0
gradient_clipping = 0.0
------------------------------------------------------------------
Time stamp: 2021-02-07-08:41:24
!!!!!===!!!! ./repvggA2/snapshots/model_save/
[1mWARNING: 'flow.train.CheckPoint' is deprecated. Please use the new API:[0m
flow.train.CheckPoint().save(path) => [1m[92mflow.checkpoint.save(path)[0m
flow.train.CheckPoint().load(path) => [1m[92mflow.load_variables(flow.checkpoint.get(path))[0m
flow.train.CheckPoint().init() is not needed any more.

Loading data from /DATA/disk1/ImageNet/ofrecord/train
No MixUp
loss.shape (1,)
predictions:  (256, 1000)
Optimizer:  SGD
Loading data from /DATA/disk1/ImageNet/ofrecord/validation
Saving model to ./repvggA2/snapshots/model_save/snapshot_initial_model.
Init model on demand.
train: epoch 0, iter 100, loss: 6.819952, top_1: 0.003008, top_k: 0.010820, samples/s: 1348.692 1612658624.2438731
train: epoch 0, iter 200, loss: 6.727110, top_1: 0.006289, top_k: 0.021328, samples/s: 1358.783 1612658643.0846102
train: epoch 0, iter 300, loss: 6.628226, top_1: 0.008516, top_k: 0.031914, samples/s: 1362.980 1612658661.8665738
train: epoch 0, iter 400, loss: 6.578377, top_1: 0.010898, top_k: 0.040859, samples/s: 1361.275 1612658680.6724904
train: epoch 0, iter 500, loss: 6.475618, top_1: 0.013516, top_k: 0.046094, samples/s: 1362.035 1612658699.4678683
train: epoch 0, iter 600, loss: 6.344884, top_1: 0.016172, top_k: 0.058359, samples/s: 1360.844 1612658718.2797246
train: epoch 0, iter 700, loss: 6.406735, top_1: 0.018359, top_k: 0.064883, samples/s: 1359.434 1612658737.111162
train: epoch 0, iter 800, loss: 6.094284, top_1: 0.021914, top_k: 0.075469, samples/s: 1361.519 1612658755.913614
train: epoch 0, iter 900, loss: 6.174789, top_1: 0.025195, top_k: 0.087695, samples/s: 1358.229 1612658774.7617598
train: epoch 0, iter 1000, loss: 6.097972, top_1: 0.030195, top_k: 0.100469, samples/s: 1356.414 1612658793.6350422
train: epoch 0, iter 1100, loss: 5.951076, top_1: 0.035078, top_k: 0.111758, samples/s: 1355.413 1612658812.522353
train: epoch 0, iter 1200, loss: 5.906294, top_1: 0.036289, top_k: 0.119609, samples/s: 1364.337 1612658831.2859478
train: epoch 0, iter 1300, loss: 5.853843, top_1: 0.041484, top_k: 0.130547, samples/s: 1358.612 1612658850.128674
train: epoch 0, iter 1400, loss: 5.856959, top_1: 0.048711, top_k: 0.142070, samples/s: 1358.491 1612658868.9731102
train: epoch 0, iter 1500, loss: 5.736911, top_1: 0.049102, top_k: 0.151016, samples/s: 1356.991 1612658887.838374
train: epoch 0, iter 1600, loss: 5.624772, top_1: 0.055898, top_k: 0.165430, samples/s: 1350.757 1612658906.7907836
train: epoch 0, iter 1700, loss: 5.615620, top_1: 0.058750, top_k: 0.172695, samples/s: 1347.102 1612658925.7944746
train: epoch 0, iter 1800, loss: 5.629639, top_1: 0.065156, top_k: 0.182109, samples/s: 1346.424 1612658944.8078015
train: epoch 0, iter 1900, loss: 5.521286, top_1: 0.068906, top_k: 0.192227, samples/s: 1346.730 1612658963.816878
train: epoch 0, iter 2000, loss: 5.501163, top_1: 0.071680, top_k: 0.201094, samples/s: 1346.128 1612658982.8343277
train: epoch 0, iter 2100, loss: 5.453710, top_1: 0.077813, top_k: 0.212344, samples/s: 1339.461 1612659001.946607
train: epoch 0, iter 2200, loss: 5.440661, top_1: 0.081758, top_k: 0.218047, samples/s: 1341.628 1612659021.027832
train: epoch 0, iter 2300, loss: 5.262109, top_1: 0.089492, top_k: 0.233711, samples/s: 1348.292 1612659040.01482
train: epoch 0, iter 2400, loss: 5.299659, top_1: 0.092930, top_k: 0.236563, samples/s: 1334.196 1612659059.2023857
train: epoch 0, iter 2500, loss: 5.345700, top_1: 0.095977, top_k: 0.250664, samples/s: 1341.286 1612659078.2885644
train: epoch 0, iter 2600, loss: 5.316980, top_1: 0.102773, top_k: 0.257383, samples/s: 1339.238 1612659097.4038515
train: epoch 0, iter 2700, loss: 5.330720, top_1: 0.101836, top_k: 0.264297, samples/s: 1339.876 1612659116.5101314
train: epoch 0, iter 2800, loss: 5.356322, top_1: 0.110664, top_k: 0.273633, samples/s: 1341.286 1612659135.59633
train: epoch 0, iter 2900, loss: 5.037166, top_1: 0.116836, top_k: 0.286758, samples/s: 1339.214 1612659154.7120032
train: epoch 0, iter 3000, loss: 5.212436, top_1: 0.120586, top_k: 0.291289, samples/s: 1339.599 1612659173.822225
train: epoch 0, iter 3100, loss: 5.147522, top_1: 0.126133, top_k: 0.295156, samples/s: 1337.151 1612659192.9673553
train: epoch 0, iter 3200, loss: 5.076201, top_1: 0.124922, top_k: 0.302578, samples/s: 1338.854 1612659212.0882308
train: epoch 0, iter 3300, loss: 5.124994, top_1: 0.132188, top_k: 0.311602, samples/s: 1337.770 1612659231.224499
train: epoch 0, iter 3400, loss: 4.991444, top_1: 0.136094, top_k: 0.319453, samples/s: 1334.285 1612659250.4108362
train: epoch 0, iter 3500, loss: 4.943646, top_1: 0.139453, top_k: 0.324180, samples/s: 1333.640 1612659269.606377
train: epoch 0, iter 3600, loss: 5.072927, top_1: 0.141016, top_k: 0.330859, samples/s: 1341.602 1612659288.688136
train: epoch 0, iter 3700, loss: 4.880427, top_1: 0.145898, top_k: 0.339336, samples/s: 1335.385 1612659307.8586044
train: epoch 0, iter 3800, loss: 4.799361, top_1: 0.152422, top_k: 0.347734, samples/s: 1336.254 1612659327.0165834
train: epoch 0, iter 3900, loss: 5.071044, top_1: 0.152461, top_k: 0.352539, samples/s: 1336.154 1612659346.1760333
train: epoch 0, iter 4000, loss: 4.744877, top_1: 0.161836, top_k: 0.356992, samples/s: 1340.881 1612659365.267956
train: epoch 0, iter 4100, loss: 4.962673, top_1: 0.165703, top_k: 0.365742, samples/s: 1333.574 1612659384.4645123
train: epoch 0, iter 4200, loss: 4.830418, top_1: 0.162500, top_k: 0.368164, samples/s: 1331.471 1612659403.691409
train: epoch 0, iter 4300, loss: 4.875281, top_1: 0.168672, top_k: 0.375977, samples/s: 1336.650 1612659422.8437042
train: epoch 0, iter 4400, loss: 4.775202, top_1: 0.172422, top_k: 0.381172, samples/s: 1341.177 1612659441.9314754
train: epoch 0, iter 4500, loss: 4.814412, top_1: 0.181680, top_k: 0.390664, samples/s: 1325.950 1612659461.2383308
train: epoch 0, iter 4600, loss: 4.867676, top_1: 0.184570, top_k: 0.396562, samples/s: 1339.021 1612659480.356828
train: epoch 0, iter 4700, loss: 4.684956, top_1: 0.184102, top_k: 0.399609, samples/s: 1333.334 1612659499.5568159
train: epoch 0, iter 4800, loss: 4.530636, top_1: 0.188281, top_k: 0.399297, samples/s: 1334.988 1612659518.7330124
train: epoch 0, iter 4900, loss: 4.601195, top_1: 0.190039, top_k: 0.399805, samples/s: 1328.672 1612659538.0003517
train: epoch 0, iter 5000, loss: 4.587304, top_1: 0.192852, top_k: 0.411875, samples/s: 1341.826 1612659557.0788126
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_0.
validation: epoch 0, iter 195, top_1: 0.208514, top_k: 0.440845, samples/s: 2744.682 1612659575.832833
train: epoch 1, iter 100, loss: 4.685017, top_1: 0.198477, top_k: 0.416289, samples/s: 1359.287 1612659610.8590834
train: epoch 1, iter 200, loss: 4.464150, top_1: 0.201758, top_k: 0.426484, samples/s: 1361.694 1612659629.6596112
train: epoch 1, iter 300, loss: 4.479709, top_1: 0.205234, top_k: 0.427344, samples/s: 1356.017 1612659648.5379045
train: epoch 1, iter 400, loss: 4.493902, top_1: 0.208281, top_k: 0.430820, samples/s: 1355.610 1612659667.4223707
train: epoch 1, iter 500, loss: 4.502597, top_1: 0.216953, top_k: 0.440625, samples/s: 1330.150 1612659686.668362
train: epoch 1, iter 600, loss: 4.235225, top_1: 0.218477, top_k: 0.441563, samples/s: 1326.002 1612659705.9745123
train: epoch 1, iter 700, loss: 4.304979, top_1: 0.219688, top_k: 0.443398, samples/s: 1329.911 1612659725.2239122
train: epoch 1, iter 800, loss: 4.604925, top_1: 0.221367, top_k: 0.451484, samples/s: 1330.062 1612659744.4711611
train: epoch 1, iter 900, loss: 4.729686, top_1: 0.214492, top_k: 0.444219, samples/s: 1328.679 1612659763.7383506
train: epoch 1, iter 1000, loss: 4.410707, top_1: 0.223867, top_k: 0.450039, samples/s: 1329.906 1612659782.9878798
train: epoch 1, iter 1100, loss: 4.319785, top_1: 0.227656, top_k: 0.462695, samples/s: 1333.378 1612659802.1872523
train: epoch 1, iter 1200, loss: 4.508903, top_1: 0.234844, top_k: 0.459922, samples/s: 1327.445 1612659821.4724078
train: epoch 1, iter 1300, loss: 4.493593, top_1: 0.233281, top_k: 0.464531, samples/s: 1328.487 1612659840.742448
train: epoch 1, iter 1400, loss: 4.402401, top_1: 0.236875, top_k: 0.471523, samples/s: 1329.114 1612659860.0034187
train: epoch 1, iter 1500, loss: 4.501440, top_1: 0.237070, top_k: 0.469258, samples/s: 1332.482 1612659879.2156243
train: epoch 1, iter 1600, loss: 4.474754, top_1: 0.240234, top_k: 0.475430, samples/s: 1331.203 1612659898.4463985
train: epoch 1, iter 1700, loss: 4.368475, top_1: 0.249336, top_k: 0.480469, samples/s: 1324.387 1612659917.7761242
train: epoch 1, iter 1800, loss: 4.448523, top_1: 0.248125, top_k: 0.481250, samples/s: 1332.087 1612659936.994118
train: epoch 1, iter 1900, loss: 4.325119, top_1: 0.245273, top_k: 0.481914, samples/s: 1331.229 1612659956.2243843
train: epoch 1, iter 2000, loss: 4.252798, top_1: 0.250859, top_k: 0.483125, samples/s: 1330.835 1612659975.4604588
train: epoch 1, iter 2100, loss: 4.386372, top_1: 0.248711, top_k: 0.486367, samples/s: 1331.765 1612659994.6830943
train: epoch 1, iter 2200, loss: 4.321741, top_1: 0.249727, top_k: 0.487344, samples/s: 1327.735 1612660013.964046
train: epoch 1, iter 2300, loss: 4.290577, top_1: 0.256563, top_k: 0.497617, samples/s: 1331.678 1612660033.1878495
train: epoch 1, iter 2400, loss: 4.366383, top_1: 0.257188, top_k: 0.500117, samples/s: 1329.686 1612660052.440582
train: epoch 1, iter 2500, loss: 4.177629, top_1: 0.261211, top_k: 0.500859, samples/s: 1331.353 1612660071.6691184
train: epoch 1, iter 2600, loss: 4.139466, top_1: 0.265352, top_k: 0.502773, samples/s: 1324.671 1612660090.994662
train: epoch 1, iter 2700, loss: 4.286298, top_1: 0.268477, top_k: 0.502578, samples/s: 1335.792 1612660110.1593177
train: epoch 1, iter 2800, loss: 4.081220, top_1: 0.263164, top_k: 0.503633, samples/s: 1327.477 1612660129.4440672
train: epoch 1, iter 2900, loss: 4.377151, top_1: 0.272773, top_k: 0.513086, samples/s: 1332.555 1612660148.655221
train: epoch 1, iter 3000, loss: 4.398256, top_1: 0.270625, top_k: 0.513125, samples/s: 1330.138 1612660167.9013317
train: epoch 1, iter 3100, loss: 4.122043, top_1: 0.267109, top_k: 0.515078, samples/s: 1331.104 1612660187.1334903
train: epoch 1, iter 3200, loss: 4.095342, top_1: 0.281016, top_k: 0.520117, samples/s: 1331.745 1612660206.3567595
train: epoch 1, iter 3300, loss: 4.207055, top_1: 0.273828, top_k: 0.514492, samples/s: 1334.451 1612660225.5403445
train: epoch 1, iter 3400, loss: 4.257187, top_1: 0.278008, top_k: 0.523984, samples/s: 1327.540 1612660244.8241522
train: epoch 1, iter 3500, loss: 4.198089, top_1: 0.281641, top_k: 0.523672, samples/s: 1330.167 1612660264.0702274
train: epoch 1, iter 3600, loss: 3.880421, top_1: 0.284102, top_k: 0.524648, samples/s: 1325.861 1612660283.378011
train: epoch 1, iter 3700, loss: 3.995106, top_1: 0.286914, top_k: 0.527422, samples/s: 1330.101 1612660302.6246767
train: epoch 1, iter 3800, loss: 4.065196, top_1: 0.284922, top_k: 0.527227, samples/s: 1328.390 1612660321.8961174
train: epoch 1, iter 3900, loss: 3.924478, top_1: 0.285352, top_k: 0.527813, samples/s: 1326.376 1612660341.196861
train: epoch 1, iter 4000, loss: 4.096189, top_1: 0.291992, top_k: 0.537500, samples/s: 1335.126 1612660360.3710995
train: epoch 1, iter 4100, loss: 4.172781, top_1: 0.292773, top_k: 0.540469, samples/s: 1333.134 1612660379.5739586
train: epoch 1, iter 4200, loss: 3.818765, top_1: 0.289180, top_k: 0.537695, samples/s: 1325.491 1612660398.8875642
train: epoch 1, iter 4300, loss: 4.183578, top_1: 0.296758, top_k: 0.540156, samples/s: 1329.451 1612660418.1435988
train: epoch 1, iter 4400, loss: 4.091151, top_1: 0.294883, top_k: 0.538867, samples/s: 1333.554 1612660437.3403945
train: epoch 1, iter 4500, loss: 3.952044, top_1: 0.297187, top_k: 0.543477, samples/s: 1320.685 1612660456.724296
train: epoch 1, iter 4600, loss: 3.842079, top_1: 0.299844, top_k: 0.545937, samples/s: 1328.798 1612660475.9897995
train: epoch 1, iter 4700, loss: 4.227325, top_1: 0.298477, top_k: 0.550469, samples/s: 1336.285 1612660495.1473858
train: epoch 1, iter 4800, loss: 4.034710, top_1: 0.300195, top_k: 0.552852, samples/s: 1330.823 1612660514.383637
train: epoch 1, iter 4900, loss: 4.206301, top_1: 0.301406, top_k: 0.543516, samples/s: 1330.584 1612660533.6232753
train: epoch 1, iter 5000, loss: 4.085188, top_1: 0.305664, top_k: 0.552930, samples/s: 1331.603 1612660552.8482695
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_1.
validation: epoch 1, iter 195, top_1: 0.326282, top_k: 0.589323, samples/s: 2750.188 1612660571.5757763
train: epoch 2, iter 100, loss: 4.018083, top_1: 0.312930, top_k: 0.564727, samples/s: 1356.885 1612660607.1731799
train: epoch 2, iter 200, loss: 3.941407, top_1: 0.315352, top_k: 0.562578, samples/s: 1358.617 1612660626.015769
train: epoch 2, iter 300, loss: 4.062853, top_1: 0.314102, top_k: 0.563594, samples/s: 1362.964 1612660644.7983718
train: epoch 2, iter 400, loss: 4.020929, top_1: 0.315977, top_k: 0.568203, samples/s: 1352.924 1612660663.7203412
train: epoch 2, iter 500, loss: 3.842013, top_1: 0.315820, top_k: 0.563906, samples/s: 1342.768 1612660682.7854304
train: epoch 2, iter 600, loss: 3.914781, top_1: 0.310625, top_k: 0.560469, samples/s: 1324.247 1612660702.1172273
train: epoch 2, iter 700, loss: 3.868712, top_1: 0.317500, top_k: 0.567930, samples/s: 1335.473 1612660721.286451
train: epoch 2, iter 800, loss: 3.809113, top_1: 0.321289, top_k: 0.570547, samples/s: 1334.065 1612660740.4759395
train: epoch 2, iter 900, loss: 3.899850, top_1: 0.324258, top_k: 0.572031, samples/s: 1333.730 1612660759.670242
train: epoch 2, iter 1000, loss: 3.829374, top_1: 0.316484, top_k: 0.573789, samples/s: 1329.792 1612660778.9213004
train: epoch 2, iter 1100, loss: 3.877431, top_1: 0.324492, top_k: 0.574453, samples/s: 1332.948 1612660798.1268814
train: epoch 2, iter 1200, loss: 3.923302, top_1: 0.331250, top_k: 0.583867, samples/s: 1331.262 1612660817.3567877
train: epoch 2, iter 1300, loss: 3.864549, top_1: 0.325156, top_k: 0.578438, samples/s: 1335.830 1612660836.5208468
train: epoch 2, iter 1400, loss: 3.944316, top_1: 0.326016, top_k: 0.575859, samples/s: 1331.052 1612660855.7537696
train: epoch 2, iter 1500, loss: 3.755677, top_1: 0.332930, top_k: 0.581562, samples/s: 1332.955 1612660874.9592557
train: epoch 2, iter 1600, loss: 3.832073, top_1: 0.328242, top_k: 0.575586, samples/s: 1327.984 1612660894.2365394
train: epoch 2, iter 1700, loss: 4.010567, top_1: 0.333203, top_k: 0.582578, samples/s: 1338.033 1612660913.3691227
train: epoch 2, iter 1800, loss: 4.010246, top_1: 0.329453, top_k: 0.580352, samples/s: 1331.099 1612660932.6013405
train: epoch 2, iter 1900, loss: 3.922249, top_1: 0.330586, top_k: 0.577461, samples/s: 1334.709 1612660951.781614
train: epoch 2, iter 2000, loss: 3.804067, top_1: 0.335078, top_k: 0.583906, samples/s: 1325.953 1612660971.08847
train: epoch 2, iter 2100, loss: 3.834409, top_1: 0.335117, top_k: 0.584258, samples/s: 1336.847 1612660990.2380705
train: epoch 2, iter 2200, loss: 3.898352, top_1: 0.331562, top_k: 0.585703, samples/s: 1327.552 1612661009.5215828
train: epoch 2, iter 2300, loss: 3.885585, top_1: 0.343281, top_k: 0.590547, samples/s: 1334.643 1612661028.7027671
train: epoch 2, iter 2400, loss: 3.804093, top_1: 0.339727, top_k: 0.591094, samples/s: 1335.996 1612661047.8645103
train: epoch 2, iter 2500, loss: 3.859105, top_1: 0.337383, top_k: 0.589063, samples/s: 1327.632 1612661067.1469128
train: epoch 2, iter 2600, loss: 3.833497, top_1: 0.339687, top_k: 0.589922, samples/s: 1338.775 1612661086.2689238
train: epoch 2, iter 2700, loss: 3.695837, top_1: 0.343438, top_k: 0.590664, samples/s: 1333.030 1612661105.4733133
train: epoch 2, iter 2800, loss: 3.935422, top_1: 0.345508, top_k: 0.596484, samples/s: 1333.668 1612661124.6684122
train: epoch 2, iter 2900, loss: 3.892540, top_1: 0.349141, top_k: 0.596562, samples/s: 1335.938 1612661143.8310413
train: epoch 2, iter 3000, loss: 3.828758, top_1: 0.342187, top_k: 0.590938, samples/s: 1333.610 1612661163.027006
train: epoch 2, iter 3100, loss: 3.749319, top_1: 0.347070, top_k: 0.594414, samples/s: 1331.926 1612661182.2473042
train: epoch 2, iter 3200, loss: 3.663503, top_1: 0.349883, top_k: 0.601719, samples/s: 1336.088 1612661201.4077878
train: epoch 2, iter 3300, loss: 3.661820, top_1: 0.351680, top_k: 0.603789, samples/s: 1336.091 1612661220.5681362
train: epoch 2, iter 3400, loss: 3.806504, top_1: 0.350977, top_k: 0.600703, samples/s: 1329.166 1612661239.828382
train: epoch 2, iter 3500, loss: 3.963149, top_1: 0.348477, top_k: 0.598906, samples/s: 1336.617 1612661258.981147
train: epoch 2, iter 3600, loss: 3.560877, top_1: 0.348203, top_k: 0.599414, samples/s: 1339.365 1612661278.0946798
train: epoch 2, iter 3700, loss: 3.861451, top_1: 0.349766, top_k: 0.605664, samples/s: 1334.255 1612661297.2813704
train: epoch 2, iter 3800, loss: 3.835843, top_1: 0.353984, top_k: 0.600078, samples/s: 1329.364 1612661316.5387154
train: epoch 2, iter 3900, loss: 3.826095, top_1: 0.346445, top_k: 0.599414, samples/s: 1335.719 1612661335.7045252
train: epoch 2, iter 4000, loss: 3.793288, top_1: 0.352070, top_k: 0.601094, samples/s: 1335.586 1612661354.8720503
train: epoch 2, iter 4100, loss: 3.685487, top_1: 0.353750, top_k: 0.605938, samples/s: 1337.245 1612661374.015925
train: epoch 2, iter 4200, loss: 3.898972, top_1: 0.351602, top_k: 0.609062, samples/s: 1334.681 1612661393.196493
train: epoch 2, iter 4300, loss: 3.727756, top_1: 0.355781, top_k: 0.608828, samples/s: 1325.365 1612661412.511935
train: epoch 2, iter 4400, loss: 3.924836, top_1: 0.357734, top_k: 0.612422, samples/s: 1341.432 1612661431.5960603
train: epoch 2, iter 4500, loss: 3.657022, top_1: 0.359102, top_k: 0.608828, samples/s: 1330.175 1612661450.841577
train: epoch 2, iter 4600, loss: 3.905867, top_1: 0.359492, top_k: 0.610664, samples/s: 1330.058 1612661470.088903
train: epoch 2, iter 4700, loss: 3.701427, top_1: 0.357305, top_k: 0.610000, samples/s: 1332.075 1612661489.3070095
train: epoch 2, iter 4800, loss: 3.771364, top_1: 0.361016, top_k: 0.614023, samples/s: 1330.514 1612661508.5476742
train: epoch 2, iter 4900, loss: 3.678283, top_1: 0.360430, top_k: 0.615156, samples/s: 1341.484 1612661527.6310885
train: epoch 2, iter 5000, loss: 3.520089, top_1: 0.367969, top_k: 0.618789, samples/s: 1330.466 1612661546.8724442
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_2.
validation: epoch 2, iter 195, top_1: 0.402804, top_k: 0.672015, samples/s: 2819.514 1612661565.1921444
train: epoch 3, iter 100, loss: 3.632684, top_1: 0.370937, top_k: 0.625156, samples/s: 1361.660 1612661600.1804132
train: epoch 3, iter 200, loss: 3.896888, top_1: 0.371484, top_k: 0.623672, samples/s: 1360.902 1612661618.9916112
train: epoch 3, iter 300, loss: 3.562186, top_1: 0.378164, top_k: 0.631797, samples/s: 1360.655 1612661637.8059795
train: epoch 3, iter 400, loss: 3.755259, top_1: 0.374805, top_k: 0.626445, samples/s: 1351.840 1612661656.7431016
train: epoch 3, iter 500, loss: 3.937289, top_1: 0.377148, top_k: 0.628789, samples/s: 1338.589 1612661675.8676927
train: epoch 3, iter 600, loss: 3.623874, top_1: 0.368945, top_k: 0.623984, samples/s: 1331.073 1612661695.1003299
train: epoch 3, iter 700, loss: 3.625969, top_1: 0.370039, top_k: 0.623164, samples/s: 1327.228 1612661714.388627
train: epoch 3, iter 800, loss: 3.668475, top_1: 0.374414, top_k: 0.624766, samples/s: 1338.147 1612661733.519605
train: epoch 3, iter 900, loss: 3.676137, top_1: 0.374219, top_k: 0.626055, samples/s: 1333.801 1612661752.71288
train: epoch 3, iter 1000, loss: 3.685067, top_1: 0.372461, top_k: 0.623203, samples/s: 1329.253 1612661771.9718688
train: epoch 3, iter 1100, loss: 3.895315, top_1: 0.377539, top_k: 0.628945, samples/s: 1337.195 1612661791.1163347
train: epoch 3, iter 1200, loss: 3.699995, top_1: 0.371797, top_k: 0.623437, samples/s: 1334.255 1612661810.3031423
train: epoch 3, iter 1300, loss: 3.565280, top_1: 0.371641, top_k: 0.624258, samples/s: 1336.381 1612661829.4593542
train: epoch 3, iter 1400, loss: 3.595799, top_1: 0.375039, top_k: 0.626133, samples/s: 1331.306 1612661848.6885793
train: epoch 3, iter 1500, loss: 3.734986, top_1: 0.373203, top_k: 0.627930, samples/s: 1331.446 1612661867.91578
train: epoch 3, iter 1600, loss: 3.683808, top_1: 0.374883, top_k: 0.626875, samples/s: 1330.880 1612661887.151126
train: epoch 3, iter 1700, loss: 3.844139, top_1: 0.375781, top_k: 0.628359, samples/s: 1337.158 1612661906.2962213
train: epoch 3, iter 1800, loss: 3.584335, top_1: 0.380977, top_k: 0.632578, samples/s: 1334.247 1612661925.4830978
train: epoch 3, iter 1900, loss: 3.657803, top_1: 0.378008, top_k: 0.629766, samples/s: 1331.374 1612661944.7113454
train: epoch 3, iter 2000, loss: 3.786286, top_1: 0.379063, top_k: 0.628477, samples/s: 1332.957 1612661963.916854
train: epoch 3, iter 2100, loss: 3.607428, top_1: 0.379297, top_k: 0.632031, samples/s: 1326.429 1612661983.216672
train: epoch 3, iter 2200, loss: 3.538743, top_1: 0.385547, top_k: 0.637305, samples/s: 1334.652 1612662002.3977509
train: epoch 3, iter 2300, loss: 3.677319, top_1: 0.380391, top_k: 0.634375, samples/s: 1338.516 1612662021.5233614
train: epoch 3, iter 2400, loss: 3.443024, top_1: 0.383203, top_k: 0.636719, samples/s: 1328.054 1612662040.7996783
train: epoch 3, iter 2500, loss: 3.680435, top_1: 0.380508, top_k: 0.629844, samples/s: 1340.551 1612662059.8963084
train: epoch 3, iter 2600, loss: 3.858134, top_1: 0.386094, top_k: 0.633398, samples/s: 1331.133 1612662079.1280918
train: epoch 3, iter 2700, loss: 3.733200, top_1: 0.386289, top_k: 0.636953, samples/s: 1341.420 1612662098.2123065
train: epoch 3, iter 2800, loss: 3.748166, top_1: 0.382227, top_k: 0.635898, samples/s: 1335.260 1612662117.3846025
train: epoch 3, iter 2900, loss: 3.522879, top_1: 0.391016, top_k: 0.639453, samples/s: 1332.083 1612662136.602737
train: epoch 3, iter 3000, loss: 3.669409, top_1: 0.386406, top_k: 0.638672, samples/s: 1341.361 1612662155.687751
train: epoch 3, iter 3100, loss: 3.667752, top_1: 0.385352, top_k: 0.635039, samples/s: 1329.341 1612662174.9453878
train: epoch 3, iter 3200, loss: 3.460115, top_1: 0.387383, top_k: 0.639727, samples/s: 1338.337 1612662194.0736692
train: epoch 3, iter 3300, loss: 3.631999, top_1: 0.387383, top_k: 0.635664, samples/s: 1335.111 1612662213.248045
train: epoch 3, iter 3400, loss: 3.831888, top_1: 0.382930, top_k: 0.630117, samples/s: 1331.660 1612662232.472196
train: epoch 3, iter 3500, loss: 3.604882, top_1: 0.384414, top_k: 0.637773, samples/s: 1339.147 1612662251.5888786
train: epoch 3, iter 3600, loss: 3.558232, top_1: 0.386445, top_k: 0.639297, samples/s: 1330.390 1612662270.8313596
train: epoch 3, iter 3700, loss: 3.636235, top_1: 0.388125, top_k: 0.637656, samples/s: 1332.490 1612662290.0434523
train: epoch 3, iter 3800, loss: 3.592999, top_1: 0.385078, top_k: 0.636289, samples/s: 1343.080 1612662309.104145
train: epoch 3, iter 3900, loss: 3.705679, top_1: 0.388516, top_k: 0.637031, samples/s: 1334.076 1612662328.2934723
train: epoch 3, iter 4000, loss: 3.772030, top_1: 0.384062, top_k: 0.635078, samples/s: 1337.596 1612662347.4322517
train: epoch 3, iter 4100, loss: 3.668568, top_1: 0.387852, top_k: 0.636094, samples/s: 1334.581 1612662366.614293
train: epoch 3, iter 4200, loss: 3.629765, top_1: 0.384062, top_k: 0.640430, samples/s: 1332.588 1612662385.8250303
train: epoch 3, iter 4300, loss: 3.449897, top_1: 0.383164, top_k: 0.637891, samples/s: 1336.881 1612662404.9740674
train: epoch 3, iter 4400, loss: 3.430182, top_1: 0.396211, top_k: 0.642266, samples/s: 1336.569 1612662424.1275847
train: epoch 3, iter 4500, loss: 3.561388, top_1: 0.390508, top_k: 0.642344, samples/s: 1331.743 1612662443.3506122
train: epoch 3, iter 4600, loss: 3.484824, top_1: 0.394922, top_k: 0.646094, samples/s: 1337.453 1612662462.4913733
train: epoch 3, iter 4700, loss: 3.443975, top_1: 0.393242, top_k: 0.645352, samples/s: 1334.503 1612662481.6745842
train: epoch 3, iter 4800, loss: 3.559416, top_1: 0.394336, top_k: 0.648594, samples/s: 1343.466 1612662500.7297366
train: epoch 3, iter 4900, loss: 3.523963, top_1: 0.396914, top_k: 0.647031, samples/s: 1335.637 1612662519.8966584
train: epoch 3, iter 5000, loss: 3.470269, top_1: 0.395547, top_k: 0.643320, samples/s: 1331.946 1612662539.1166568
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_3.
validation: epoch 3, iter 195, top_1: 0.416667, top_k: 0.681510, samples/s: 2781.686 1612662557.6651287
train: epoch 4, iter 100, loss: 3.435542, top_1: 0.404531, top_k: 0.657500, samples/s: 1352.623 1612662592.6313767
train: epoch 4, iter 200, loss: 3.488837, top_1: 0.398086, top_k: 0.648516, samples/s: 1369.244 1612662611.3278277
train: epoch 4, iter 300, loss: 3.696169, top_1: 0.397461, top_k: 0.648477, samples/s: 1360.549 1612662630.1437094
train: epoch 4, iter 400, loss: 3.564220, top_1: 0.407422, top_k: 0.655234, samples/s: 1355.083 1612662649.0355358
train: epoch 4, iter 500, loss: 3.631357, top_1: 0.403945, top_k: 0.653477, samples/s: 1334.166 1612662668.2236059
train: epoch 4, iter 600, loss: 3.710489, top_1: 0.410781, top_k: 0.660312, samples/s: 1334.995 1612662687.3996425
train: epoch 4, iter 700, loss: 3.385120, top_1: 0.405313, top_k: 0.651875, samples/s: 1334.829 1612662706.5782013
train: epoch 4, iter 800, loss: 3.741037, top_1: 0.396406, top_k: 0.649844, samples/s: 1329.248 1612662725.8372295
train: epoch 4, iter 900, loss: 3.588915, top_1: 0.391523, top_k: 0.648242, samples/s: 1333.855 1612662745.0296376
train: epoch 4, iter 1000, loss: 3.497721, top_1: 0.398906, top_k: 0.646523, samples/s: 1331.533 1612662764.2555985
train: epoch 4, iter 1100, loss: 3.669300, top_1: 0.401172, top_k: 0.655859, samples/s: 1330.659 1612662783.4941797
train: epoch 4, iter 1200, loss: 3.673146, top_1: 0.405977, top_k: 0.654570, samples/s: 1339.964 1612662802.5991647
train: epoch 4, iter 1300, loss: 3.492521, top_1: 0.397578, top_k: 0.646406, samples/s: 1334.978 1612662821.7755294
train: epoch 4, iter 1400, loss: 3.361357, top_1: 0.398438, top_k: 0.653555, samples/s: 1335.490 1612662840.944568
train: epoch 4, iter 1500, loss: 3.738060, top_1: 0.404375, top_k: 0.656172, samples/s: 1333.918 1612662860.1365607
train: epoch 4, iter 1600, loss: 3.455328, top_1: 0.399727, top_k: 0.654844, samples/s: 1332.075 1612662879.3542695
train: epoch 4, iter 1700, loss: 3.401216, top_1: 0.401680, top_k: 0.656680, samples/s: 1340.880 1612662898.4464998
train: epoch 4, iter 1800, loss: 3.613712, top_1: 0.401836, top_k: 0.650000, samples/s: 1329.099 1612662917.7073624
train: epoch 4, iter 1900, loss: 3.744112, top_1: 0.402578, top_k: 0.654023, samples/s: 1331.295 1612662936.9367738
train: epoch 4, iter 2000, loss: 3.422227, top_1: 0.402695, top_k: 0.657578, samples/s: 1338.356 1612662956.0646899
train: epoch 4, iter 2100, loss: 3.531107, top_1: 0.402891, top_k: 0.657773, samples/s: 1333.956 1612662975.2558246
train: epoch 4, iter 2200, loss: 3.308512, top_1: 0.400625, top_k: 0.654180, samples/s: 1334.464 1612662994.4395092
train: epoch 4, iter 2300, loss: 3.684938, top_1: 0.402695, top_k: 0.655937, samples/s: 1334.047 1612663013.6291752
train: epoch 4, iter 2400, loss: 3.601031, top_1: 0.403711, top_k: 0.654609, samples/s: 1337.449 1612663032.7700777
train: epoch 4, iter 2500, loss: 3.395573, top_1: 0.405469, top_k: 0.658281, samples/s: 1334.231 1612663051.957248
train: epoch 4, iter 2600, loss: 3.629792, top_1: 0.403711, top_k: 0.656289, samples/s: 1332.034 1612663071.175889
train: epoch 4, iter 2700, loss: 3.481693, top_1: 0.401797, top_k: 0.656641, samples/s: 1335.936 1612663090.3384836
train: epoch 4, iter 2800, loss: 3.451730, top_1: 0.402422, top_k: 0.656133, samples/s: 1340.722 1612663109.432728
train: epoch 4, iter 2900, loss: 3.402666, top_1: 0.403672, top_k: 0.656719, samples/s: 1334.707 1612663128.6129744
train: epoch 4, iter 3000, loss: 3.723433, top_1: 0.407422, top_k: 0.660781, samples/s: 1331.452 1612663147.8400304
train: epoch 4, iter 3100, loss: 3.505174, top_1: 0.403164, top_k: 0.657188, samples/s: 1336.108 1612663167.0001805
train: epoch 4, iter 3200, loss: 3.654730, top_1: 0.407578, top_k: 0.659336, samples/s: 1332.992 1612663186.2051356
train: epoch 4, iter 3300, loss: 3.520823, top_1: 0.400625, top_k: 0.652227, samples/s: 1334.675 1612663205.3857937
train: epoch 4, iter 3400, loss: 3.446113, top_1: 0.408398, top_k: 0.658867, samples/s: 1340.339 1612663224.485431
train: epoch 4, iter 3500, loss: 3.420931, top_1: 0.404609, top_k: 0.661758, samples/s: 1334.794 1612663243.6645052
train: epoch 4, iter 3600, loss: 3.514236, top_1: 0.409414, top_k: 0.658594, samples/s: 1331.024 1612663262.8977668
train: epoch 4, iter 3700, loss: 3.548813, top_1: 0.405586, top_k: 0.660195, samples/s: 1345.461 1612663281.924665
train: epoch 4, iter 3800, loss: 3.560935, top_1: 0.407852, top_k: 0.657500, samples/s: 1331.716 1612663301.1480923
train: epoch 4, iter 3900, loss: 3.631709, top_1: 0.403438, top_k: 0.657383, samples/s: 1337.610 1612663320.2867177
train: epoch 4, iter 4000, loss: 3.396037, top_1: 0.407461, top_k: 0.657383, samples/s: 1338.390 1612663339.4140894
train: epoch 4, iter 4100, loss: 3.570637, top_1: 0.407852, top_k: 0.657344, samples/s: 1328.248 1612663358.6875932
train: epoch 4, iter 4200, loss: 3.548314, top_1: 0.407539, top_k: 0.662266, samples/s: 1338.440 1612663377.8144174
train: epoch 4, iter 4300, loss: 3.570163, top_1: 0.412109, top_k: 0.660625, samples/s: 1330.798 1612663397.0509408
train: epoch 4, iter 4400, loss: 3.634830, top_1: 0.409687, top_k: 0.662148, samples/s: 1338.062 1612663416.1830428
train: epoch 4, iter 4500, loss: 3.481731, top_1: 0.406484, top_k: 0.654414, samples/s: 1339.937 1612663435.2885005
train: epoch 4, iter 4600, loss: 3.676864, top_1: 0.405039, top_k: 0.656797, samples/s: 1330.463 1612663454.529824
train: epoch 4, iter 4700, loss: 3.545112, top_1: 0.410547, top_k: 0.655469, samples/s: 1340.202 1612663473.6315007
train: epoch 4, iter 4800, loss: 3.332897, top_1: 0.415664, top_k: 0.662773, samples/s: 1339.662 1612663492.7407856
train: epoch 4, iter 4900, loss: 3.551000, top_1: 0.416016, top_k: 0.660820, samples/s: 1330.401 1612663511.9830787
train: epoch 4, iter 5000, loss: 3.506456, top_1: 0.412734, top_k: 0.665117, samples/s: 1338.264 1612663531.112376
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_4.
validation: epoch 4, iter 195, top_1: 0.442248, top_k: 0.706510, samples/s: 2854.933 1612663549.1650941
train: epoch 5, iter 100, loss: 3.492557, top_1: 0.417695, top_k: 0.668398, samples/s: 1353.919 1612663584.3099546
train: epoch 5, iter 200, loss: 3.436887, top_1: 0.415391, top_k: 0.668320, samples/s: 1366.624 1612663603.0423033
train: epoch 5, iter 300, loss: 3.503253, top_1: 0.408867, top_k: 0.664531, samples/s: 1357.406 1612663621.9017174
train: epoch 5, iter 400, loss: 3.619213, top_1: 0.415352, top_k: 0.664141, samples/s: 1353.313 1612663640.8182516
train: epoch 5, iter 500, loss: 3.538543, top_1: 0.418164, top_k: 0.673438, samples/s: 1341.282 1612663659.9044657
train: epoch 5, iter 600, loss: 3.601050, top_1: 0.417383, top_k: 0.666016, samples/s: 1334.654 1612663679.08546
train: epoch 5, iter 700, loss: 3.511680, top_1: 0.416016, top_k: 0.669336, samples/s: 1330.954 1612663698.3197699
train: epoch 5, iter 800, loss: 3.304250, top_1: 0.419648, top_k: 0.668086, samples/s: 1331.533 1612663717.5457566
train: epoch 5, iter 900, loss: 3.377450, top_1: 0.425273, top_k: 0.671562, samples/s: 1325.120 1612663736.8648312
train: epoch 5, iter 1000, loss: 3.370540, top_1: 0.421875, top_k: 0.671875, samples/s: 1331.147 1612663756.0963054
train: epoch 5, iter 1100, loss: 3.470192, top_1: 0.420156, top_k: 0.670312, samples/s: 1328.425 1612663775.3673127
train: epoch 5, iter 1200, loss: 3.245821, top_1: 0.421055, top_k: 0.674492, samples/s: 1336.391 1612663794.5232828
train: epoch 5, iter 1300, loss: 3.389474, top_1: 0.418711, top_k: 0.669609, samples/s: 1325.890 1612663813.8310883
train: epoch 5, iter 1400, loss: 3.475921, top_1: 0.424375, top_k: 0.674570, samples/s: 1336.602 1612663832.9841616
train: epoch 5, iter 1500, loss: 3.584232, top_1: 0.418203, top_k: 0.669297, samples/s: 1330.076 1612663852.2311454
train: epoch 5, iter 1600, loss: 3.649654, top_1: 0.416523, top_k: 0.667734, samples/s: 1331.191 1612663871.4620924
train: epoch 5, iter 1700, loss: 3.535265, top_1: 0.421758, top_k: 0.672500, samples/s: 1333.225 1612663890.6635907
train: epoch 5, iter 1800, loss: 3.099438, top_1: 0.425977, top_k: 0.675312, samples/s: 1327.831 1612663909.943149
train: epoch 5, iter 1900, loss: 3.385585, top_1: 0.417734, top_k: 0.668125, samples/s: 1334.520 1612663929.126141
train: epoch 5, iter 2000, loss: 3.574502, top_1: 0.419609, top_k: 0.670977, samples/s: 1329.022 1612663948.3883865
train: epoch 5, iter 2100, loss: 3.365748, top_1: 0.421094, top_k: 0.668359, samples/s: 1337.047 1612663967.5350485
train: epoch 5, iter 2200, loss: 3.476267, top_1: 0.427891, top_k: 0.676016, samples/s: 1332.038 1612663986.7537854
train: epoch 5, iter 2300, loss: 3.455567, top_1: 0.425117, top_k: 0.675000, samples/s: 1332.454 1612664005.966371
train: epoch 5, iter 2400, loss: 3.329310, top_1: 0.421406, top_k: 0.676758, samples/s: 1331.733 1612664025.1894467
train: epoch 5, iter 2500, loss: 3.518495, top_1: 0.424844, top_k: 0.673828, samples/s: 1333.718 1612664044.3839283
train: epoch 5, iter 2600, loss: 3.293671, top_1: 0.425820, top_k: 0.677578, samples/s: 1327.743 1612664063.6647885
train: epoch 5, iter 2700, loss: 3.453288, top_1: 0.420859, top_k: 0.671484, samples/s: 1333.339 1612664082.8647792
train: epoch 5, iter 2800, loss: 3.216377, top_1: 0.423281, top_k: 0.674023, samples/s: 1344.460 1612664101.905836
train: epoch 5, iter 2900, loss: 3.532582, top_1: 0.430000, top_k: 0.682383, samples/s: 1329.664 1612664121.1588237
train: epoch 5, iter 3000, loss: 3.328093, top_1: 0.428477, top_k: 0.679336, samples/s: 1327.548 1612664140.4425359
train: epoch 5, iter 3100, loss: 3.383803, top_1: 0.424805, top_k: 0.675820, samples/s: 1324.884 1612664159.7649727
train: epoch 5, iter 3200, loss: 3.221060, top_1: 0.421328, top_k: 0.672578, samples/s: 1342.296 1612664178.837032
train: epoch 5, iter 3300, loss: 3.390490, top_1: 0.424336, top_k: 0.670469, samples/s: 1337.114 1612664197.9824297
train: epoch 5, iter 3400, loss: 3.521475, top_1: 0.423242, top_k: 0.668711, samples/s: 1330.676 1612664217.220994
train: epoch 5, iter 3500, loss: 3.361135, top_1: 0.421992, top_k: 0.677461, samples/s: 1330.253 1612664236.4652555
train: epoch 5, iter 3600, loss: 3.503230, top_1: 0.427031, top_k: 0.678438, samples/s: 1329.974 1612664255.7137444
train: epoch 5, iter 3700, loss: 3.368090, top_1: 0.433320, top_k: 0.678359, samples/s: 1340.257 1612664274.8145154
train: epoch 5, iter 3800, loss: 3.311114, top_1: 0.424023, top_k: 0.672773, samples/s: 1331.563 1612664294.0400667
train: epoch 5, iter 3900, loss: 3.399907, top_1: 0.428164, top_k: 0.675039, samples/s: 1334.645 1612664313.2211926
train: epoch 5, iter 4000, loss: 3.437072, top_1: 0.426289, top_k: 0.679141, samples/s: 1327.149 1612664332.5106468
train: epoch 5, iter 4100, loss: 3.472108, top_1: 0.424883, top_k: 0.675234, samples/s: 1335.767 1612664351.6756868
train: epoch 5, iter 4200, loss: 3.386407, top_1: 0.432734, top_k: 0.680469, samples/s: 1333.344 1612664370.8755467
train: epoch 5, iter 4300, loss: 3.380458, top_1: 0.423984, top_k: 0.675156, samples/s: 1328.559 1612664390.1445603
train: epoch 5, iter 4400, loss: 3.266540, top_1: 0.429258, top_k: 0.678984, samples/s: 1328.195 1612664409.4187891
train: epoch 5, iter 4500, loss: 3.288897, top_1: 0.432031, top_k: 0.679258, samples/s: 1341.769 1612664428.4980578
train: epoch 5, iter 4600, loss: 3.483683, top_1: 0.434648, top_k: 0.685117, samples/s: 1328.801 1612664447.7636123
train: epoch 5, iter 4700, loss: 3.233467, top_1: 0.433945, top_k: 0.684375, samples/s: 1333.695 1612664466.9584177
train: epoch 5, iter 4800, loss: 3.337847, top_1: 0.431289, top_k: 0.686016, samples/s: 1331.970 1612664486.1780286
train: epoch 5, iter 4900, loss: 3.416314, top_1: 0.426133, top_k: 0.676328, samples/s: 1335.350 1612664505.349225
train: epoch 5, iter 5000, loss: 3.568438, top_1: 0.438672, top_k: 0.684258, samples/s: 1328.718 1612664524.6157699
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_5.
validation: epoch 5, iter 195, top_1: 0.472416, top_k: 0.735457, samples/s: 2754.578 1612664543.3026564
train: epoch 6, iter 100, loss: 3.364015, top_1: 0.440977, top_k: 0.689453, samples/s: 1357.528 1612664577.760507
train: epoch 6, iter 200, loss: 3.261642, top_1: 0.439297, top_k: 0.686289, samples/s: 1356.410 1612664596.6337795
train: epoch 6, iter 300, loss: 3.322524, top_1: 0.435430, top_k: 0.684297, samples/s: 1360.522 1612664615.450085
train: epoch 6, iter 400, loss: 3.412040, top_1: 0.439961, top_k: 0.689336, samples/s: 1356.185 1612664634.3265631
train: epoch 6, iter 500, loss: 3.438861, top_1: 0.434063, top_k: 0.677539, samples/s: 1332.398 1612664653.5400426
train: epoch 6, iter 600, loss: 3.349173, top_1: 0.437852, top_k: 0.689023, samples/s: 1339.584 1612664672.6504426
train: epoch 6, iter 700, loss: 3.347912, top_1: 0.437891, top_k: 0.685391, samples/s: 1340.790 1612664691.743715
train: epoch 6, iter 800, loss: 3.174583, top_1: 0.432148, top_k: 0.683828, samples/s: 1337.014 1612664710.8908074
train: epoch 6, iter 900, loss: 3.420383, top_1: 0.439727, top_k: 0.689023, samples/s: 1335.509 1612664730.0595188
train: epoch 6, iter 1000, loss: 3.200833, top_1: 0.439570, top_k: 0.689922, samples/s: 1337.616 1612664749.1981182
train: epoch 6, iter 1100, loss: 3.538579, top_1: 0.436797, top_k: 0.684883, samples/s: 1335.039 1612664768.3735838
train: epoch 6, iter 1200, loss: 3.501046, top_1: 0.440195, top_k: 0.691445, samples/s: 1337.436 1612664787.5146291
train: epoch 6, iter 1300, loss: 3.405195, top_1: 0.440312, top_k: 0.685352, samples/s: 1325.364 1612664806.8301227
train: epoch 6, iter 1400, loss: 3.326616, top_1: 0.440937, top_k: 0.690664, samples/s: 1336.553 1612664825.9838629
train: epoch 6, iter 1500, loss: 3.426761, top_1: 0.439102, top_k: 0.687813, samples/s: 1335.219 1612664845.1567144
train: epoch 6, iter 1600, loss: 3.236604, top_1: 0.440430, top_k: 0.690195, samples/s: 1336.451 1612664864.3119545
train: epoch 6, iter 1700, loss: 3.113151, top_1: 0.438633, top_k: 0.689102, samples/s: 1341.450 1612664883.395815
train: epoch 6, iter 1800, loss: 3.322526, top_1: 0.443555, top_k: 0.688594, samples/s: 1329.561 1612664902.6502328
train: epoch 6, iter 1900, loss: 3.404181, top_1: 0.435547, top_k: 0.685430, samples/s: 1337.152 1612664921.7955096
train: epoch 6, iter 2000, loss: 3.584746, top_1: 0.439063, top_k: 0.692031, samples/s: 1339.037 1612664940.913691
train: epoch 6, iter 2100, loss: 3.440431, top_1: 0.433945, top_k: 0.686680, samples/s: 1336.422 1612664960.0693107
train: epoch 6, iter 2200, loss: 3.346667, top_1: 0.439961, top_k: 0.689531, samples/s: 1336.765 1612664979.2199976
train: epoch 6, iter 2300, loss: 3.570177, top_1: 0.443164, top_k: 0.690430, samples/s: 1339.013 1612664998.3385093
train: epoch 6, iter 2400, loss: 3.414629, top_1: 0.442578, top_k: 0.688867, samples/s: 1325.503 1612665017.6519332
train: epoch 6, iter 2500, loss: 3.326083, top_1: 0.439219, top_k: 0.688047, samples/s: 1341.430 1612665036.7361364
train: epoch 6, iter 2600, loss: 3.300715, top_1: 0.437227, top_k: 0.690781, samples/s: 1342.248 1612665055.808599
train: epoch 6, iter 2700, loss: 3.296664, top_1: 0.437109, top_k: 0.687383, samples/s: 1333.556 1612665075.0053601
train: epoch 6, iter 2800, loss: 3.512370, top_1: 0.441445, top_k: 0.693125, samples/s: 1336.291 1612665094.1628444
train: epoch 6, iter 2900, loss: 3.308479, top_1: 0.445859, top_k: 0.693125, samples/s: 1338.403 1612665113.2901263
train: epoch 6, iter 3000, loss: 3.380024, top_1: 0.441953, top_k: 0.690156, samples/s: 1340.047 1612665132.3938959
train: epoch 6, iter 3100, loss: 3.282265, top_1: 0.445430, top_k: 0.691523, samples/s: 1333.815 1612665151.5870278
train: epoch 6, iter 3200, loss: 3.433144, top_1: 0.439570, top_k: 0.689492, samples/s: 1335.424 1612665170.756935
train: epoch 6, iter 3300, loss: 3.188214, top_1: 0.440430, top_k: 0.692227, samples/s: 1341.483 1612665189.8402684
train: epoch 6, iter 3400, loss: 3.365817, top_1: 0.438789, top_k: 0.687109, samples/s: 1329.746 1612665209.0921037
train: epoch 6, iter 3500, loss: 3.181092, top_1: 0.442891, top_k: 0.690508, samples/s: 1339.709 1612665228.2007267
train: epoch 6, iter 3600, loss: 3.248735, top_1: 0.443711, top_k: 0.690742, samples/s: 1332.769 1612665247.408818
train: epoch 6, iter 3700, loss: 3.400243, top_1: 0.443750, top_k: 0.694570, samples/s: 1342.081 1612665266.4837327
train: epoch 6, iter 3800, loss: 3.482003, top_1: 0.441328, top_k: 0.690508, samples/s: 1340.442 1612665285.5819285
train: epoch 6, iter 3900, loss: 3.255233, top_1: 0.449297, top_k: 0.695000, samples/s: 1333.332 1612665304.781908
train: epoch 6, iter 4000, loss: 3.358043, top_1: 0.445547, top_k: 0.689805, samples/s: 1337.111 1612665323.9276743
train: epoch 6, iter 4100, loss: 3.386572, top_1: 0.442539, top_k: 0.692539, samples/s: 1334.663 1612665343.1085393
train: epoch 6, iter 4200, loss: 3.104685, top_1: 0.446211, top_k: 0.691016, samples/s: 1334.254 1612665362.2952447
train: epoch 6, iter 4300, loss: 3.395026, top_1: 0.450508, top_k: 0.696055, samples/s: 1340.849 1612665381.3876066
train: epoch 6, iter 4400, loss: 3.476570, top_1: 0.441641, top_k: 0.693242, samples/s: 1332.728 1612665400.5963273
train: epoch 6, iter 4500, loss: 3.225073, top_1: 0.443164, top_k: 0.693008, samples/s: 1334.950 1612665419.7731097
train: epoch 6, iter 4600, loss: 3.308774, top_1: 0.447227, top_k: 0.694375, samples/s: 1343.254 1612665438.8312762
train: epoch 6, iter 4700, loss: 3.175936, top_1: 0.445547, top_k: 0.698164, samples/s: 1330.937 1612665458.065826
train: epoch 6, iter 4800, loss: 3.396251, top_1: 0.438672, top_k: 0.685977, samples/s: 1336.465 1612665477.220832
train: epoch 6, iter 4900, loss: 3.253560, top_1: 0.443477, top_k: 0.693125, samples/s: 1335.738 1612665496.386316
train: epoch 6, iter 5000, loss: 3.379373, top_1: 0.443594, top_k: 0.692969, samples/s: 1333.674 1612665515.5813696
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_6.
validation: epoch 6, iter 195, top_1: 0.487861, top_k: 0.747897, samples/s: 2714.255 1612665534.4811566
train: epoch 7, iter 100, loss: 3.237317, top_1: 0.451523, top_k: 0.703086, samples/s: 1357.969 1612665569.3960984
train: epoch 7, iter 200, loss: 3.223800, top_1: 0.455078, top_k: 0.701758, samples/s: 1360.098 1612665588.218288
train: epoch 7, iter 300, loss: 3.251531, top_1: 0.452617, top_k: 0.696211, samples/s: 1357.535 1612665607.0759718
train: epoch 7, iter 400, loss: 3.276692, top_1: 0.454375, top_k: 0.700898, samples/s: 1358.915 1612665625.9145672
train: epoch 7, iter 500, loss: 3.249291, top_1: 0.456016, top_k: 0.702227, samples/s: 1336.489 1612665645.0692277
train: epoch 7, iter 600, loss: 3.403849, top_1: 0.452852, top_k: 0.697578, samples/s: 1337.057 1612665664.21577
train: epoch 7, iter 700, loss: 3.385283, top_1: 0.452656, top_k: 0.700586, samples/s: 1337.383 1612665683.3575583
train: epoch 7, iter 800, loss: 3.330230, top_1: 0.449492, top_k: 0.700391, samples/s: 1335.906 1612665702.5206144
train: epoch 7, iter 900, loss: 3.379380, top_1: 0.450156, top_k: 0.693555, samples/s: 1336.905 1612665721.669294
train: epoch 7, iter 1000, loss: 3.131361, top_1: 0.455977, top_k: 0.698516, samples/s: 1328.073 1612665740.9453382
train: epoch 7, iter 1100, loss: 3.157358, top_1: 0.450664, top_k: 0.699258, samples/s: 1334.304 1612665760.1313741
train: epoch 7, iter 1200, loss: 3.313680, top_1: 0.453125, top_k: 0.699063, samples/s: 1339.845 1612665779.2380679
train: epoch 7, iter 1300, loss: 3.212058, top_1: 0.456289, top_k: 0.700625, samples/s: 1344.628 1612665798.2768822
train: epoch 7, iter 1400, loss: 3.209160, top_1: 0.452188, top_k: 0.698125, samples/s: 1338.344 1612665817.4048972
train: epoch 7, iter 1500, loss: 3.298397, top_1: 0.443945, top_k: 0.693086, samples/s: 1337.013 1612665836.5521295
train: epoch 7, iter 1600, loss: 3.261582, top_1: 0.452109, top_k: 0.700000, samples/s: 1330.810 1612665855.7885916
train: epoch 7, iter 1700, loss: 3.339246, top_1: 0.450508, top_k: 0.700469, samples/s: 1340.807 1612665874.881428
train: epoch 7, iter 1800, loss: 3.418916, top_1: 0.448828, top_k: 0.696055, samples/s: 1339.958 1612665893.986493
train: epoch 7, iter 1900, loss: 3.439878, top_1: 0.447266, top_k: 0.697383, samples/s: 1332.797 1612665913.1943047
train: epoch 7, iter 2000, loss: 3.302592, top_1: 0.447891, top_k: 0.701523, samples/s: 1337.340 1612665932.3367367
train: epoch 7, iter 2100, loss: 3.343249, top_1: 0.447813, top_k: 0.697930, samples/s: 1339.389 1612665951.4499435
train: epoch 7, iter 2200, loss: 3.234363, top_1: 0.452461, top_k: 0.701875, samples/s: 1333.263 1612665970.6509118
train: epoch 7, iter 2300, loss: 3.339776, top_1: 0.450625, top_k: 0.696641, samples/s: 1345.827 1612665989.6726992
train: epoch 7, iter 2400, loss: 3.508321, top_1: 0.452773, top_k: 0.698672, samples/s: 1337.632 1612666008.811002
train: epoch 7, iter 2500, loss: 3.342714, top_1: 0.450000, top_k: 0.695859, samples/s: 1337.817 1612666027.9466517
train: epoch 7, iter 2600, loss: 3.264370, top_1: 0.455781, top_k: 0.701641, samples/s: 1338.016 1612666047.0794065
train: epoch 7, iter 2700, loss: 3.263662, top_1: 0.453789, top_k: 0.702891, samples/s: 1337.623 1612666066.2179043
train: epoch 7, iter 2800, loss: 3.438683, top_1: 0.448359, top_k: 0.701367, samples/s: 1336.937 1612666085.3661084
train: epoch 7, iter 2900, loss: 3.183481, top_1: 0.453711, top_k: 0.697070, samples/s: 1335.941 1612666104.5286028
train: epoch 7, iter 3000, loss: 3.328922, top_1: 0.452070, top_k: 0.700273, samples/s: 1334.738 1612666123.7088685
train: epoch 7, iter 3100, loss: 3.285561, top_1: 0.443906, top_k: 0.698750, samples/s: 1336.478 1612666142.8632274
train: epoch 7, iter 3200, loss: 3.346751, top_1: 0.457539, top_k: 0.702969, samples/s: 1346.308 1612666161.8787503
train: epoch 7, iter 3300, loss: 3.261124, top_1: 0.450352, top_k: 0.699609, samples/s: 1332.828 1612666181.0855076
train: epoch 7, iter 3400, loss: 3.366337, top_1: 0.455430, top_k: 0.703125, samples/s: 1338.498 1612666200.2114456
train: epoch 7, iter 3500, loss: 3.299832, top_1: 0.456875, top_k: 0.701211, samples/s: 1335.133 1612666219.3856113
train: epoch 7, iter 3600, loss: 3.438787, top_1: 0.451641, top_k: 0.697227, samples/s: 1338.435 1612666238.5123575
train: epoch 7, iter 3700, loss: 3.262590, top_1: 0.452734, top_k: 0.699531, samples/s: 1342.095 1612666257.586955
train: epoch 7, iter 3800, loss: 3.232327, top_1: 0.450586, top_k: 0.702578, samples/s: 1342.701 1612666276.6530461
train: epoch 7, iter 3900, loss: 3.293988, top_1: 0.450508, top_k: 0.696602, samples/s: 1337.943 1612666295.786847
train: epoch 7, iter 4000, loss: 3.082587, top_1: 0.452734, top_k: 0.703164, samples/s: 1338.003 1612666314.9198906
train: epoch 7, iter 4100, loss: 3.380895, top_1: 0.456484, top_k: 0.703789, samples/s: 1336.751 1612666334.0707977
train: epoch 7, iter 4200, loss: 3.350374, top_1: 0.454141, top_k: 0.700898, samples/s: 1337.133 1612666353.2162406
train: epoch 7, iter 4300, loss: 3.154613, top_1: 0.456250, top_k: 0.700781, samples/s: 1337.661 1612666372.3541234
train: epoch 7, iter 4400, loss: 3.256778, top_1: 0.449219, top_k: 0.702656, samples/s: 1338.318 1612666391.4825754
train: epoch 7, iter 4500, loss: 3.194144, top_1: 0.451250, top_k: 0.696953, samples/s: 1339.596 1612666410.5928085
train: epoch 7, iter 4600, loss: 3.423461, top_1: 0.452578, top_k: 0.697344, samples/s: 1336.378 1612666429.7491233
train: epoch 7, iter 4700, loss: 3.412955, top_1: 0.457031, top_k: 0.702344, samples/s: 1331.736 1612666448.972199
train: epoch 7, iter 4800, loss: 3.120203, top_1: 0.457539, top_k: 0.703633, samples/s: 1346.107 1612666467.9899285
train: epoch 7, iter 4900, loss: 3.360217, top_1: 0.456172, top_k: 0.707383, samples/s: 1329.142 1612666487.250504
train: epoch 7, iter 5000, loss: 3.132933, top_1: 0.453320, top_k: 0.702734, samples/s: 1342.001 1612666506.3264704
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_7.
validation: epoch 7, iter 195, top_1: 0.495252, top_k: 0.756330, samples/s: 2736.401 1612666525.1360996
train: epoch 8, iter 100, loss: 3.271433, top_1: 0.467617, top_k: 0.714414, samples/s: 1360.771 1612666560.0440676
train: epoch 8, iter 200, loss: 3.149482, top_1: 0.467500, top_k: 0.714492, samples/s: 1360.234 1612666578.8644066
train: epoch 8, iter 300, loss: 3.166765, top_1: 0.462891, top_k: 0.712031, samples/s: 1357.778 1612666597.71873
train: epoch 8, iter 400, loss: 3.309864, top_1: 0.462422, top_k: 0.707031, samples/s: 1353.576 1612666616.6315699
train: epoch 8, iter 500, loss: 3.308470, top_1: 0.463438, top_k: 0.709023, samples/s: 1345.543 1612666635.6573868
train: epoch 8, iter 600, loss: 3.369585, top_1: 0.459922, top_k: 0.705859, samples/s: 1334.955 1612666654.8340182
train: epoch 8, iter 700, loss: 3.210129, top_1: 0.460469, top_k: 0.706172, samples/s: 1332.390 1612666674.0476384
train: epoch 8, iter 800, loss: 3.439746, top_1: 0.462148, top_k: 0.709492, samples/s: 1340.436 1612666693.1458344
train: epoch 8, iter 900, loss: 3.338704, top_1: 0.465547, top_k: 0.713320, samples/s: 1335.194 1612666712.3190796
train: epoch 8, iter 1000, loss: 3.484641, top_1: 0.458867, top_k: 0.705508, samples/s: 1333.546 1612666731.5160823
train: epoch 8, iter 1100, loss: 3.442861, top_1: 0.458320, top_k: 0.706016, samples/s: 1336.746 1612666750.667451
train: epoch 8, iter 1200, loss: 3.316021, top_1: 0.460742, top_k: 0.704844, samples/s: 1334.996 1612666769.8431447
train: epoch 8, iter 1300, loss: 3.311623, top_1: 0.459141, top_k: 0.704414, samples/s: 1333.461 1612666789.0416443
train: epoch 8, iter 1400, loss: 3.220135, top_1: 0.465977, top_k: 0.707891, samples/s: 1335.925 1612666808.2041078
train: epoch 8, iter 1500, loss: 3.052956, top_1: 0.459844, top_k: 0.706758, samples/s: 1335.243 1612666827.376536
train: epoch 8, iter 1600, loss: 3.362711, top_1: 0.459062, top_k: 0.703711, samples/s: 1330.473 1612666846.617816
train: epoch 8, iter 1700, loss: 3.198519, top_1: 0.460039, top_k: 0.712930, samples/s: 1333.917 1612666865.8095188
train: epoch 8, iter 1800, loss: 3.262186, top_1: 0.457578, top_k: 0.707109, samples/s: 1336.541 1612666884.9633355
train: epoch 8, iter 1900, loss: 3.161034, top_1: 0.456562, top_k: 0.702109, samples/s: 1334.602 1612666904.145181
train: epoch 8, iter 2000, loss: 3.147034, top_1: 0.463359, top_k: 0.709766, samples/s: 1335.267 1612666923.3172994
train: epoch 8, iter 2100, loss: 3.033342, top_1: 0.459961, top_k: 0.709844, samples/s: 1337.946 1612666942.4514291
train: epoch 8, iter 2200, loss: 3.409118, top_1: 0.464258, top_k: 0.709375, samples/s: 1333.729 1612666961.6454635
train: epoch 8, iter 2300, loss: 3.305835, top_1: 0.452695, top_k: 0.704648, samples/s: 1334.547 1612666980.8283691
train: epoch 8, iter 2400, loss: 3.395943, top_1: 0.460781, top_k: 0.705820, samples/s: 1337.868 1612666999.9629147
train: epoch 8, iter 2500, loss: 3.223565, top_1: 0.460039, top_k: 0.711172, samples/s: 1336.937 1612667019.1111186
train: epoch 8, iter 2600, loss: 3.320344, top_1: 0.464609, top_k: 0.712109, samples/s: 1332.392 1612667038.3246934
train: epoch 8, iter 2700, loss: 3.202176, top_1: 0.460273, top_k: 0.706133, samples/s: 1334.148 1612667057.5130358
train: epoch 8, iter 2800, loss: 3.320607, top_1: 0.464492, top_k: 0.710273, samples/s: 1334.875 1612667076.6907804
train: epoch 8, iter 2900, loss: 3.223736, top_1: 0.467187, top_k: 0.712930, samples/s: 1344.501 1612667095.7313128
train: epoch 8, iter 3000, loss: 3.456940, top_1: 0.461680, top_k: 0.709102, samples/s: 1332.551 1612667114.9425824
train: epoch 8, iter 3100, loss: 3.252826, top_1: 0.456992, top_k: 0.704336, samples/s: 1340.999 1612667134.03283
train: epoch 8, iter 3200, loss: 3.050349, top_1: 0.461641, top_k: 0.708125, samples/s: 1331.710 1612667153.2562113
train: epoch 8, iter 3300, loss: 3.220568, top_1: 0.463672, top_k: 0.705547, samples/s: 1340.438 1612667172.354453
train: epoch 8, iter 3400, loss: 3.141554, top_1: 0.461211, top_k: 0.711953, samples/s: 1332.478 1612667191.5667958
train: epoch 8, iter 3500, loss: 3.255126, top_1: 0.463047, top_k: 0.707500, samples/s: 1338.681 1612667210.6901126
train: epoch 8, iter 3600, loss: 3.200502, top_1: 0.467070, top_k: 0.710859, samples/s: 1341.888 1612667229.7676868
train: epoch 8, iter 3700, loss: 3.313441, top_1: 0.460391, top_k: 0.709727, samples/s: 1333.665 1612667248.9629083
train: epoch 8, iter 3800, loss: 3.109863, top_1: 0.465000, top_k: 0.709766, samples/s: 1334.992 1612667268.139114
train: epoch 8, iter 3900, loss: 3.482153, top_1: 0.461758, top_k: 0.705781, samples/s: 1335.289 1612667287.3109865
train: epoch 8, iter 4000, loss: 3.202534, top_1: 0.462227, top_k: 0.707656, samples/s: 1338.913 1612667306.4309194
train: epoch 8, iter 4100, loss: 3.339453, top_1: 0.460586, top_k: 0.703633, samples/s: 1338.202 1612667325.561133
train: epoch 8, iter 4200, loss: 3.178388, top_1: 0.463086, top_k: 0.708906, samples/s: 1332.568 1612667344.7721167
train: epoch 8, iter 4300, loss: 3.378269, top_1: 0.457266, top_k: 0.707617, samples/s: 1334.837 1612667363.9505472
train: epoch 8, iter 4400, loss: 3.348762, top_1: 0.460859, top_k: 0.707422, samples/s: 1341.167 1612667383.038349
train: epoch 8, iter 4500, loss: 3.112435, top_1: 0.464414, top_k: 0.708750, samples/s: 1338.233 1612667402.1680713
train: epoch 8, iter 4600, loss: 3.302964, top_1: 0.461992, top_k: 0.710625, samples/s: 1338.649 1612667421.29192
train: epoch 8, iter 4700, loss: 3.141467, top_1: 0.465859, top_k: 0.714570, samples/s: 1329.920 1612667440.54107
train: epoch 8, iter 4800, loss: 3.110301, top_1: 0.465469, top_k: 0.708359, samples/s: 1339.826 1612667459.6480436
train: epoch 8, iter 4900, loss: 3.219879, top_1: 0.459727, top_k: 0.709531, samples/s: 1338.782 1612667478.7698967
train: epoch 8, iter 5000, loss: 3.072272, top_1: 0.462813, top_k: 0.710977, samples/s: 1325.018 1612667498.0903456
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_8.
validation: epoch 8, iter 195, top_1: 0.507091, top_k: 0.758474, samples/s: 2682.219 1612667517.1533487
train: epoch 9, iter 100, loss: 3.227192, top_1: 0.479219, top_k: 0.719844, samples/s: 1359.491 1612667552.4447682
train: epoch 9, iter 200, loss: 3.128936, top_1: 0.473281, top_k: 0.720898, samples/s: 1360.883 1612667571.2560365
train: epoch 9, iter 300, loss: 3.330373, top_1: 0.479336, top_k: 0.722852, samples/s: 1353.637 1612667590.1680331
train: epoch 9, iter 400, loss: 3.117898, top_1: 0.473047, top_k: 0.718516, samples/s: 1361.770 1612667608.967149
train: epoch 9, iter 500, loss: 3.303149, top_1: 0.467344, top_k: 0.713867, samples/s: 1341.717 1612667628.0471287
train: epoch 9, iter 600, loss: 3.087657, top_1: 0.471484, top_k: 0.717227, samples/s: 1331.686 1612667647.2709322
train: epoch 9, iter 700, loss: 3.290758, top_1: 0.468203, top_k: 0.715547, samples/s: 1325.908 1612667666.578406
train: epoch 9, iter 800, loss: 3.303627, top_1: 0.474961, top_k: 0.714414, samples/s: 1335.450 1612667685.7480376
train: epoch 9, iter 900, loss: 3.432416, top_1: 0.468164, top_k: 0.710469, samples/s: 1331.355 1612667704.9766045
train: epoch 9, iter 1000, loss: 3.231651, top_1: 0.466406, top_k: 0.714219, samples/s: 1333.433 1612667724.1751132
train: epoch 9, iter 1100, loss: 3.392408, top_1: 0.470234, top_k: 0.711484, samples/s: 1332.131 1612667743.3923914
train: epoch 9, iter 1200, loss: 3.468603, top_1: 0.462852, top_k: 0.712344, samples/s: 1332.685 1612667762.601791
train: epoch 9, iter 1300, loss: 3.265374, top_1: 0.464219, top_k: 0.710977, samples/s: 1332.102 1612667781.8194602
train: epoch 9, iter 1400, loss: 3.228639, top_1: 0.470898, top_k: 0.712539, samples/s: 1332.656 1612667801.0292192
train: epoch 9, iter 1500, loss: 3.247200, top_1: 0.467539, top_k: 0.716289, samples/s: 1332.171 1612667820.2460277
train: epoch 9, iter 1600, loss: 3.256562, top_1: 0.467461, top_k: 0.714180, samples/s: 1332.531 1612667839.4575226
train: epoch 9, iter 1700, loss: 3.303109, top_1: 0.462422, top_k: 0.710195, samples/s: 1328.491 1612667858.7277827
train: epoch 9, iter 1800, loss: 3.277531, top_1: 0.465703, top_k: 0.711055, samples/s: 1334.861 1612667877.905588
train: epoch 9, iter 1900, loss: 3.381091, top_1: 0.465234, top_k: 0.717383, samples/s: 1335.389 1612667897.0763052
train: epoch 9, iter 2000, loss: 3.210637, top_1: 0.468359, top_k: 0.715117, samples/s: 1334.330 1612667916.26162
train: epoch 9, iter 2100, loss: 3.297476, top_1: 0.470273, top_k: 0.713633, samples/s: 1332.986 1612667935.4666717
train: epoch 9, iter 2200, loss: 3.048605, top_1: 0.468008, top_k: 0.716250, samples/s: 1326.595 1612667954.7641473
train: epoch 9, iter 2300, loss: 3.329946, top_1: 0.467148, top_k: 0.714727, samples/s: 1332.002 1612667973.9833872
train: epoch 9, iter 2400, loss: 3.440450, top_1: 0.467578, top_k: 0.713047, samples/s: 1329.214 1612667993.2428653
train: epoch 9, iter 2500, loss: 3.163409, top_1: 0.466016, top_k: 0.713281, samples/s: 1337.077 1612668012.3890924
train: epoch 9, iter 2600, loss: 3.108126, top_1: 0.469961, top_k: 0.715703, samples/s: 1338.868 1612668031.509779
train: epoch 9, iter 2700, loss: 3.095315, top_1: 0.470273, top_k: 0.715039, samples/s: 1329.076 1612668050.7712512
train: epoch 9, iter 2800, loss: 3.135153, top_1: 0.469883, top_k: 0.713086, samples/s: 1329.842 1612668070.0216846
train: epoch 9, iter 2900, loss: 3.383935, top_1: 0.465039, top_k: 0.713437, samples/s: 1338.460 1612668089.148208
train: epoch 9, iter 3000, loss: 3.095880, top_1: 0.462852, top_k: 0.713281, samples/s: 1325.783 1612668108.4577465
train: epoch 9, iter 3100, loss: 3.239620, top_1: 0.467344, top_k: 0.710664, samples/s: 1335.134 1612668127.6315415
train: epoch 9, iter 3200, loss: 3.244736, top_1: 0.469609, top_k: 0.715000, samples/s: 1331.183 1612668146.8629658
train: epoch 9, iter 3300, loss: 3.253212, top_1: 0.466289, top_k: 0.713477, samples/s: 1331.872 1612668166.0836773
train: epoch 9, iter 3400, loss: 3.290995, top_1: 0.470508, top_k: 0.712656, samples/s: 1332.423 1612668185.296819
train: epoch 9, iter 3500, loss: 3.234302, top_1: 0.461719, top_k: 0.708633, samples/s: 1333.988 1612668204.4873111
train: epoch 9, iter 3600, loss: 2.983842, top_1: 0.472773, top_k: 0.716875, samples/s: 1337.484 1612668223.6277332
train: epoch 9, iter 3700, loss: 3.359944, top_1: 0.474414, top_k: 0.718984, samples/s: 1333.951 1612668242.8189104
train: epoch 9, iter 3800, loss: 3.238740, top_1: 0.463438, top_k: 0.713047, samples/s: 1335.822 1612668261.9830844
train: epoch 9, iter 3900, loss: 3.296813, top_1: 0.472773, top_k: 0.720000, samples/s: 1338.086 1612668281.1148846
train: epoch 9, iter 4000, loss: 3.326010, top_1: 0.470820, top_k: 0.713086, samples/s: 1334.512 1612668300.2983396
train: epoch 9, iter 4100, loss: 3.451222, top_1: 0.467461, top_k: 0.711445, samples/s: 1326.018 1612668319.6038651
train: epoch 9, iter 4200, loss: 3.222465, top_1: 0.466914, top_k: 0.716133, samples/s: 1336.893 1612668338.7527466
train: epoch 9, iter 4300, loss: 3.135747, top_1: 0.466406, top_k: 0.715000, samples/s: 1332.930 1612668357.958569
train: epoch 9, iter 4400, loss: 3.300508, top_1: 0.468320, top_k: 0.714922, samples/s: 1336.788 1612668377.1096056
train: epoch 9, iter 4500, loss: 3.487823, top_1: 0.465117, top_k: 0.715430, samples/s: 1335.348 1612668396.279954
train: epoch 9, iter 4600, loss: 3.256829, top_1: 0.467852, top_k: 0.713555, samples/s: 1335.651 1612668415.4466925
train: epoch 9, iter 4700, loss: 3.143596, top_1: 0.462773, top_k: 0.707734, samples/s: 1331.360 1612668434.6751006
train: epoch 9, iter 4800, loss: 3.268741, top_1: 0.473281, top_k: 0.715977, samples/s: 1324.419 1612668454.0043292
train: epoch 9, iter 4900, loss: 3.136571, top_1: 0.469492, top_k: 0.713594, samples/s: 1341.189 1612668473.0919242
train: epoch 9, iter 5000, loss: 3.286353, top_1: 0.473750, top_k: 0.720391, samples/s: 1329.969 1612668492.3404574
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_9.
validation: epoch 9, iter 195, top_1: 0.514523, top_k: 0.767488, samples/s: 2736.642 1612668511.1398072
train: epoch 10, iter 100, loss: 2.974325, top_1: 0.483125, top_k: 0.728711, samples/s: 1353.996 1612668546.6900256
train: epoch 10, iter 200, loss: 3.078637, top_1: 0.478281, top_k: 0.725273, samples/s: 1360.412 1612668565.5077946
train: epoch 10, iter 300, loss: 3.277963, top_1: 0.473281, top_k: 0.717812, samples/s: 1359.126 1612668584.3434348
train: epoch 10, iter 400, loss: 3.275083, top_1: 0.472187, top_k: 0.717539, samples/s: 1353.905 1612668603.2518115
train: epoch 10, iter 500, loss: 3.119683, top_1: 0.474766, top_k: 0.721133, samples/s: 1337.683 1612668622.3893151
train: epoch 10, iter 600, loss: 3.216710, top_1: 0.479570, top_k: 0.720039, samples/s: 1342.331 1612668641.46065
train: epoch 10, iter 700, loss: 3.209092, top_1: 0.472930, top_k: 0.719297, samples/s: 1340.334 1612668660.5602999
train: epoch 10, iter 800, loss: 3.200055, top_1: 0.480195, top_k: 0.724063, samples/s: 1325.034 1612668679.8805816
train: epoch 10, iter 900, loss: 3.062535, top_1: 0.475000, top_k: 0.718242, samples/s: 1339.832 1612668698.987438
train: epoch 10, iter 1000, loss: 3.286431, top_1: 0.472344, top_k: 0.718867, samples/s: 1341.785 1612668718.0665941
train: epoch 10, iter 1100, loss: 3.326464, top_1: 0.475664, top_k: 0.720117, samples/s: 1328.920 1612668737.3302674
train: epoch 10, iter 1200, loss: 3.208134, top_1: 0.479375, top_k: 0.722148, samples/s: 1335.250 1612668756.502747
train: epoch 10, iter 1300, loss: 3.306588, top_1: 0.473594, top_k: 0.718555, samples/s: 1339.197 1612668775.6186259
train: epoch 10, iter 1400, loss: 3.236143, top_1: 0.478516, top_k: 0.721836, samples/s: 1332.911 1612668794.8247619
train: epoch 10, iter 1500, loss: 3.192515, top_1: 0.473047, top_k: 0.720508, samples/s: 1331.590 1612668814.0498755
train: epoch 10, iter 1600, loss: 3.226972, top_1: 0.470273, top_k: 0.717070, samples/s: 1341.995 1612668833.125924
train: epoch 10, iter 1700, loss: 3.106883, top_1: 0.475234, top_k: 0.718320, samples/s: 1333.761 1612668852.3198006
train: epoch 10, iter 1800, loss: 3.349700, top_1: 0.473359, top_k: 0.717891, samples/s: 1333.951 1612668871.5108771
train: epoch 10, iter 1900, loss: 3.345668, top_1: 0.479414, top_k: 0.719961, samples/s: 1337.112 1612668890.656623
train: epoch 10, iter 2000, loss: 3.018584, top_1: 0.477266, top_k: 0.722070, samples/s: 1342.397 1612668909.7270482
train: epoch 10, iter 2100, loss: 3.181827, top_1: 0.478594, top_k: 0.718516, samples/s: 1326.143 1612668929.031141
train: epoch 10, iter 2200, loss: 3.212983, top_1: 0.471250, top_k: 0.715000, samples/s: 1341.781 1612668948.110278
train: epoch 10, iter 2300, loss: 3.291338, top_1: 0.472734, top_k: 0.719375, samples/s: 1340.615 1612668967.2060008
train: epoch 10, iter 2400, loss: 3.260901, top_1: 0.476211, top_k: 0.721406, samples/s: 1330.967 1612668986.4400778
train: epoch 10, iter 2500, loss: 3.266598, top_1: 0.473906, top_k: 0.718477, samples/s: 1340.488 1612669005.5376356
train: epoch 10, iter 2600, loss: 3.141517, top_1: 0.475586, top_k: 0.715859, samples/s: 1334.079 1612669024.726893
train: epoch 10, iter 2700, loss: 3.139104, top_1: 0.476602, top_k: 0.723906, samples/s: 1339.370 1612669043.840361
train: epoch 10, iter 2800, loss: 3.469124, top_1: 0.470898, top_k: 0.714023, samples/s: 1334.592 1612669063.0222497
train: epoch 10, iter 2900, loss: 3.206028, top_1: 0.475352, top_k: 0.715586, samples/s: 1332.963 1612669082.2275958
train: epoch 10, iter 3000, loss: 3.147954, top_1: 0.476914, top_k: 0.723945, samples/s: 1334.006 1612669101.4178534
train: epoch 10, iter 3100, loss: 3.405097, top_1: 0.473164, top_k: 0.719961, samples/s: 1341.301 1612669120.5038035
train: epoch 10, iter 3200, loss: 3.203234, top_1: 0.478086, top_k: 0.725820, samples/s: 1327.990 1612669139.7811193
train: epoch 10, iter 3300, loss: 3.004114, top_1: 0.471562, top_k: 0.719180, samples/s: 1332.250 1612669158.996731
train: epoch 10, iter 3400, loss: 3.361607, top_1: 0.474766, top_k: 0.718984, samples/s: 1341.364 1612669178.0817633
train: epoch 10, iter 3500, loss: 3.274351, top_1: 0.476719, top_k: 0.719141, samples/s: 1335.368 1612669197.2524872
train: epoch 10, iter 3600, loss: 3.284495, top_1: 0.475352, top_k: 0.716094, samples/s: 1340.418 1612669216.3512886
train: epoch 10, iter 3700, loss: 3.172639, top_1: 0.477422, top_k: 0.721836, samples/s: 1327.820 1612669235.6307697
train: epoch 10, iter 3800, loss: 3.284171, top_1: 0.474062, top_k: 0.719531, samples/s: 1345.216 1612669254.6615665
train: epoch 10, iter 3900, loss: 3.359743, top_1: 0.476836, top_k: 0.719609, samples/s: 1336.408 1612669273.8169413
train: epoch 10, iter 4000, loss: 2.881206, top_1: 0.472422, top_k: 0.720195, samples/s: 1329.130 1612669293.0777493
train: epoch 10, iter 4100, loss: 3.299141, top_1: 0.468398, top_k: 0.714648, samples/s: 1335.951 1612669312.2401097
train: epoch 10, iter 4200, loss: 3.368363, top_1: 0.467500, top_k: 0.715742, samples/s: 1343.774 1612669331.2909324
train: epoch 10, iter 4300, loss: 3.214492, top_1: 0.476641, top_k: 0.722773, samples/s: 1346.573 1612669350.3021476
train: epoch 10, iter 4400, loss: 3.187985, top_1: 0.481016, top_k: 0.721055, samples/s: 1334.654 1612669369.4831545
train: epoch 10, iter 4500, loss: 3.190077, top_1: 0.475313, top_k: 0.720820, samples/s: 1328.415 1612669388.7541955
train: epoch 10, iter 4600, loss: 3.326125, top_1: 0.472852, top_k: 0.717773, samples/s: 1338.909 1612669407.8742528
train: epoch 10, iter 4700, loss: 3.299714, top_1: 0.467109, top_k: 0.717773, samples/s: 1340.262 1612669426.9749594
train: epoch 10, iter 4800, loss: 3.324164, top_1: 0.474141, top_k: 0.721680, samples/s: 1336.705 1612669446.1265688
train: epoch 10, iter 4900, loss: 3.248836, top_1: 0.480156, top_k: 0.727773, samples/s: 1335.299 1612669465.2983453
train: epoch 10, iter 5000, loss: 3.352025, top_1: 0.480469, top_k: 0.726602, samples/s: 1334.581 1612669484.4803786
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_10.
validation: epoch 10, iter 195, top_1: 0.532432, top_k: 0.783814, samples/s: 2687.214 1612669503.6200979
train: epoch 11, iter 100, loss: 3.184137, top_1: 0.482500, top_k: 0.727812, samples/s: 1363.393 1612669538.2911274
train: epoch 11, iter 200, loss: 3.359121, top_1: 0.478828, top_k: 0.727383, samples/s: 1361.837 1612669557.0892534
train: epoch 11, iter 300, loss: 3.198572, top_1: 0.482305, top_k: 0.725742, samples/s: 1359.884 1612669575.914422
train: epoch 11, iter 400, loss: 2.991891, top_1: 0.485508, top_k: 0.729961, samples/s: 1356.996 1612669594.7796376
train: epoch 11, iter 500, loss: 3.073368, top_1: 0.485469, top_k: 0.725859, samples/s: 1337.645 1612669613.9177423
train: epoch 11, iter 600, loss: 3.113498, top_1: 0.478398, top_k: 0.722266, samples/s: 1333.826 1612669633.1106596
train: epoch 11, iter 700, loss: 3.362837, top_1: 0.480586, top_k: 0.727891, samples/s: 1335.677 1612669652.2769678
train: epoch 11, iter 800, loss: 3.008892, top_1: 0.485000, top_k: 0.727578, samples/s: 1332.889 1612669671.4833293
train: epoch 11, iter 900, loss: 3.219758, top_1: 0.475156, top_k: 0.724922, samples/s: 1335.692 1612669690.6494086
train: epoch 11, iter 1000, loss: 3.285200, top_1: 0.473242, top_k: 0.721406, samples/s: 1335.923 1612669709.8122015
train: epoch 11, iter 1100, loss: 3.191521, top_1: 0.480977, top_k: 0.726328, samples/s: 1334.489 1612669728.9956052
train: epoch 11, iter 1200, loss: 3.207777, top_1: 0.482969, top_k: 0.727461, samples/s: 1337.325 1612669748.138294
train: epoch 11, iter 1300, loss: 3.187827, top_1: 0.480859, top_k: 0.725586, samples/s: 1334.691 1612669767.3187234
train: epoch 11, iter 1400, loss: 3.153292, top_1: 0.480977, top_k: 0.723555, samples/s: 1337.396 1612669786.4604454
train: epoch 11, iter 1500, loss: 3.243464, top_1: 0.483867, top_k: 0.725000, samples/s: 1323.271 1612669805.8063874
train: epoch 11, iter 1600, loss: 3.152184, top_1: 0.482109, top_k: 0.725781, samples/s: 1338.653 1612669824.9301775
train: epoch 11, iter 1700, loss: 3.045674, top_1: 0.478867, top_k: 0.721602, samples/s: 1334.569 1612669844.1123867
train: epoch 11, iter 1800, loss: 3.320303, top_1: 0.481328, top_k: 0.728047, samples/s: 1335.929 1612669863.275006
train: epoch 11, iter 1900, loss: 3.151217, top_1: 0.473867, top_k: 0.724805, samples/s: 1332.437 1612669882.4879954
train: epoch 11, iter 2000, loss: 3.243250, top_1: 0.479609, top_k: 0.727773, samples/s: 1337.743 1612669901.6246915
train: epoch 11, iter 2100, loss: 3.301290, top_1: 0.480234, top_k: 0.725977, samples/s: 1332.016 1612669920.843637
train: epoch 11, iter 2200, loss: 3.070914, top_1: 0.483242, top_k: 0.729375, samples/s: 1338.531 1612669939.9690704
train: epoch 11, iter 2300, loss: 3.366327, top_1: 0.479063, top_k: 0.721523, samples/s: 1342.003 1612669959.0450134
train: epoch 11, iter 2400, loss: 3.076005, top_1: 0.474609, top_k: 0.722461, samples/s: 1336.374 1612669978.2013693
train: epoch 11, iter 2500, loss: 3.129454, top_1: 0.480391, top_k: 0.724766, samples/s: 1329.405 1612669997.4581099
train: epoch 11, iter 2600, loss: 3.049551, top_1: 0.484141, top_k: 0.726016, samples/s: 1342.553 1612670016.5262938
train: epoch 11, iter 2700, loss: 3.140887, top_1: 0.481992, top_k: 0.727344, samples/s: 1334.445 1612670035.7102654
train: epoch 11, iter 2800, loss: 3.324909, top_1: 0.486797, top_k: 0.726680, samples/s: 1336.943 1612670054.8583727
train: epoch 11, iter 2900, loss: 3.213570, top_1: 0.481797, top_k: 0.726484, samples/s: 1339.187 1612670073.9745197
train: epoch 11, iter 3000, loss: 3.063424, top_1: 0.478125, top_k: 0.716289, samples/s: 1330.764 1612670093.2115324
train: epoch 11, iter 3100, loss: 3.320172, top_1: 0.478438, top_k: 0.723789, samples/s: 1339.281 1612670112.3263395
train: epoch 11, iter 3200, loss: 3.013914, top_1: 0.478945, top_k: 0.716289, samples/s: 1332.812 1612670131.5337777
train: epoch 11, iter 3300, loss: 3.015644, top_1: 0.483984, top_k: 0.728555, samples/s: 1338.984 1612670150.6527529
train: epoch 11, iter 3400, loss: 3.180235, top_1: 0.476797, top_k: 0.721250, samples/s: 1338.886 1612670169.7731886
train: epoch 11, iter 3500, loss: 3.263474, top_1: 0.474219, top_k: 0.722734, samples/s: 1332.178 1612670188.9898694
train: epoch 11, iter 3600, loss: 3.190480, top_1: 0.482031, top_k: 0.722852, samples/s: 1337.618 1612670208.1283138
train: epoch 11, iter 3700, loss: 3.259553, top_1: 0.482461, top_k: 0.725078, samples/s: 1330.195 1612670227.3736694
train: epoch 11, iter 3800, loss: 3.076779, top_1: 0.479297, top_k: 0.721484, samples/s: 1344.781 1612670246.410136
train: epoch 11, iter 3900, loss: 3.116722, top_1: 0.481289, top_k: 0.726406, samples/s: 1330.721 1612670265.6478922
train: epoch 11, iter 4000, loss: 3.207858, top_1: 0.479297, top_k: 0.720586, samples/s: 1332.222 1612670284.8638926
train: epoch 11, iter 4100, loss: 3.001773, top_1: 0.476094, top_k: 0.723281, samples/s: 1342.908 1612670303.9269602
train: epoch 11, iter 4200, loss: 3.279570, top_1: 0.482344, top_k: 0.728281, samples/s: 1333.184 1612670323.129097
train: epoch 11, iter 4300, loss: 3.202522, top_1: 0.481914, top_k: 0.722578, samples/s: 1337.308 1612670342.272056
train: epoch 11, iter 4400, loss: 3.251940, top_1: 0.477773, top_k: 0.721914, samples/s: 1340.700 1612670361.3665814
train: epoch 11, iter 4500, loss: 3.042356, top_1: 0.481094, top_k: 0.726953, samples/s: 1334.177 1612670380.5544841
train: epoch 11, iter 4600, loss: 3.361161, top_1: 0.484766, top_k: 0.729766, samples/s: 1335.159 1612670399.7282245
train: epoch 11, iter 4700, loss: 3.436519, top_1: 0.488945, top_k: 0.730898, samples/s: 1333.127 1612670418.9311295
train: epoch 11, iter 4800, loss: 3.190673, top_1: 0.476562, top_k: 0.720664, samples/s: 1325.485 1612670438.2448194
train: epoch 11, iter 4900, loss: 3.028133, top_1: 0.476094, top_k: 0.720898, samples/s: 1348.727 1612670457.2257404
train: epoch 11, iter 5000, loss: 3.248952, top_1: 0.480195, top_k: 0.725430, samples/s: 1336.537 1612670476.379658
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_11.
validation: epoch 11, iter 195, top_1: 0.529407, top_k: 0.779828, samples/s: 2644.159 1612670495.7976294
train: epoch 12, iter 100, loss: 3.094283, top_1: 0.491367, top_k: 0.736172, samples/s: 1358.065 1612670531.0512493
train: epoch 12, iter 200, loss: 3.076641, top_1: 0.494688, top_k: 0.740977, samples/s: 1359.641 1612670549.8796692
train: epoch 12, iter 300, loss: 3.004212, top_1: 0.493125, top_k: 0.734922, samples/s: 1357.658 1612670568.7357352
train: epoch 12, iter 400, loss: 3.241958, top_1: 0.489180, top_k: 0.731563, samples/s: 1356.277 1612670587.6108623
train: epoch 12, iter 500, loss: 3.064157, top_1: 0.486797, top_k: 0.733086, samples/s: 1339.467 1612670606.7229538
train: epoch 12, iter 600, loss: 3.023064, top_1: 0.490938, top_k: 0.727305, samples/s: 1326.600 1612670626.0204918
train: epoch 12, iter 700, loss: 3.147506, top_1: 0.487148, top_k: 0.733711, samples/s: 1331.653 1612670645.244729
train: epoch 12, iter 800, loss: 3.605860, top_1: 0.489141, top_k: 0.730938, samples/s: 1342.540 1612670664.31302
train: epoch 12, iter 900, loss: 3.197331, top_1: 0.488984, top_k: 0.733477, samples/s: 1331.534 1612670683.5389338
train: epoch 12, iter 1000, loss: 3.098118, top_1: 0.487148, top_k: 0.731523, samples/s: 1340.590 1612670702.6349876
train: epoch 12, iter 1100, loss: 3.081265, top_1: 0.487383, top_k: 0.728203, samples/s: 1328.227 1612670721.9088993
train: epoch 12, iter 1200, loss: 3.219263, top_1: 0.489336, top_k: 0.728516, samples/s: 1337.113 1612670741.0545757
train: epoch 12, iter 1300, loss: 3.158244, top_1: 0.482969, top_k: 0.728047, samples/s: 1332.688 1612670760.263847
train: epoch 12, iter 1400, loss: 3.175796, top_1: 0.486094, top_k: 0.730078, samples/s: 1329.863 1612670779.5139744
train: epoch 12, iter 1500, loss: 3.067167, top_1: 0.488906, top_k: 0.728789, samples/s: 1331.097 1612670798.7461574
train: epoch 12, iter 1600, loss: 3.300086, top_1: 0.489805, top_k: 0.730898, samples/s: 1337.436 1612670817.887356
train: epoch 12, iter 1700, loss: 3.086782, top_1: 0.483633, top_k: 0.728008, samples/s: 1335.158 1612670837.061076
train: epoch 12, iter 1800, loss: 3.098219, top_1: 0.483359, top_k: 0.730781, samples/s: 1331.135 1612670856.2927897
train: epoch 12, iter 1900, loss: 3.122291, top_1: 0.482500, top_k: 0.728828, samples/s: 1331.049 1612670875.5257535
train: epoch 12, iter 2000, loss: 3.176564, top_1: 0.483438, top_k: 0.727187, samples/s: 1335.958 1612670894.6880298
train: epoch 12, iter 2100, loss: 3.091368, top_1: 0.483086, top_k: 0.727773, samples/s: 1335.196 1612670913.861192
train: epoch 12, iter 2200, loss: 3.377828, top_1: 0.483984, top_k: 0.728633, samples/s: 1334.977 1612670933.0376203
train: epoch 12, iter 2300, loss: 3.324055, top_1: 0.483867, top_k: 0.729297, samples/s: 1326.493 1612670952.3365905
train: epoch 12, iter 2400, loss: 3.079750, top_1: 0.478047, top_k: 0.722891, samples/s: 1334.884 1612670971.5143132
train: epoch 12, iter 2500, loss: 3.116297, top_1: 0.485859, top_k: 0.727305, samples/s: 1320.407 1612670990.902307
train: epoch 12, iter 2600, loss: 2.916590, top_1: 0.483672, top_k: 0.728125, samples/s: 1343.423 1612671009.9580038
train: epoch 12, iter 2700, loss: 3.154404, top_1: 0.480234, top_k: 0.725156, samples/s: 1338.489 1612671029.084106
train: epoch 12, iter 2800, loss: 3.283924, top_1: 0.481992, top_k: 0.725625, samples/s: 1336.296 1612671048.241486
train: epoch 12, iter 2900, loss: 3.201459, top_1: 0.485195, top_k: 0.729102, samples/s: 1335.806 1612671067.4059546
train: epoch 12, iter 3000, loss: 3.185420, top_1: 0.485391, top_k: 0.724961, samples/s: 1334.516 1612671086.588936
train: epoch 12, iter 3100, loss: 3.153700, top_1: 0.488867, top_k: 0.732930, samples/s: 1333.542 1612671105.785978
train: epoch 12, iter 3200, loss: 3.037586, top_1: 0.487891, top_k: 0.732891, samples/s: 1335.375 1612671124.9566336
train: epoch 12, iter 3300, loss: 3.318367, top_1: 0.486953, top_k: 0.729531, samples/s: 1327.228 1612671144.2449074
train: epoch 12, iter 3400, loss: 3.267328, top_1: 0.484492, top_k: 0.731367, samples/s: 1341.472 1612671163.328396
train: epoch 12, iter 3500, loss: 3.167645, top_1: 0.484180, top_k: 0.731250, samples/s: 1332.528 1612671182.5400968
train: epoch 12, iter 3600, loss: 3.256033, top_1: 0.488086, top_k: 0.734141, samples/s: 1335.793 1612671201.7047033
train: epoch 12, iter 3700, loss: 3.135108, top_1: 0.481211, top_k: 0.724063, samples/s: 1336.182 1612671220.8641126
train: epoch 12, iter 3800, loss: 3.105628, top_1: 0.479102, top_k: 0.723008, samples/s: 1335.703 1612671240.0297024
train: epoch 12, iter 3900, loss: 3.098658, top_1: 0.484844, top_k: 0.729180, samples/s: 1337.245 1612671259.1738186
train: epoch 12, iter 4000, loss: 3.003606, top_1: 0.488828, top_k: 0.727852, samples/s: 1331.144 1612671278.4052052
train: epoch 12, iter 4100, loss: 3.034780, top_1: 0.486484, top_k: 0.730039, samples/s: 1336.269 1612671297.5629165
train: epoch 12, iter 4200, loss: 3.167571, top_1: 0.480977, top_k: 0.724141, samples/s: 1336.510 1612671316.7173548
train: epoch 12, iter 4300, loss: 3.430526, top_1: 0.486992, top_k: 0.723516, samples/s: 1333.241 1612671335.9185734
train: epoch 12, iter 4400, loss: 3.138010, top_1: 0.487148, top_k: 0.729922, samples/s: 1334.059 1612671355.10816
train: epoch 12, iter 4500, loss: 3.030352, top_1: 0.487891, top_k: 0.730664, samples/s: 1334.428 1612671374.2924438
train: epoch 12, iter 4600, loss: 3.184932, top_1: 0.487539, top_k: 0.726797, samples/s: 1335.223 1612671393.4652631
train: epoch 12, iter 4700, loss: 3.223044, top_1: 0.481719, top_k: 0.728164, samples/s: 1336.287 1612671412.622822
train: epoch 12, iter 4800, loss: 2.859761, top_1: 0.483164, top_k: 0.724180, samples/s: 1335.810 1612671431.7872784
train: epoch 12, iter 4900, loss: 3.102236, top_1: 0.484609, top_k: 0.725977, samples/s: 1333.566 1612671450.9838529
train: epoch 12, iter 5000, loss: 3.157736, top_1: 0.483398, top_k: 0.728984, samples/s: 1329.453 1612671470.239964
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_12.
validation: epoch 12, iter 195, top_1: 0.537800, top_k: 0.787901, samples/s: 2728.357 1612671489.0026593
train: epoch 13, iter 100, loss: 3.131199, top_1: 0.490508, top_k: 0.737266, samples/s: 1360.754 1612671523.6070127
train: epoch 13, iter 200, loss: 2.989035, top_1: 0.491016, top_k: 0.735430, samples/s: 1359.952 1612671542.4311624
train: epoch 13, iter 300, loss: 3.170949, top_1: 0.490703, top_k: 0.739922, samples/s: 1356.499 1612671561.3032527
train: epoch 13, iter 400, loss: 2.959668, top_1: 0.489961, top_k: 0.732695, samples/s: 1356.167 1612671580.1799357
train: epoch 13, iter 500, loss: 3.050200, top_1: 0.497383, top_k: 0.739766, samples/s: 1334.495 1612671599.363225
train: epoch 13, iter 600, loss: 3.108953, top_1: 0.492852, top_k: 0.730742, samples/s: 1328.637 1612671618.631107
train: epoch 13, iter 700, loss: 3.097365, top_1: 0.489609, top_k: 0.728164, samples/s: 1327.899 1612671637.910141
train: epoch 13, iter 800, loss: 3.324573, top_1: 0.497578, top_k: 0.738828, samples/s: 1327.518 1612671657.1937888
train: epoch 13, iter 900, loss: 3.065434, top_1: 0.490508, top_k: 0.734883, samples/s: 1334.144 1612671676.3826594
train: epoch 13, iter 1000, loss: 3.092403, top_1: 0.487656, top_k: 0.729453, samples/s: 1329.765 1612671695.6337013
train: epoch 13, iter 1100, loss: 3.211411, top_1: 0.487656, top_k: 0.731758, samples/s: 1329.453 1612671714.8896637
train: epoch 13, iter 1200, loss: 3.090763, top_1: 0.495742, top_k: 0.736016, samples/s: 1335.332 1612671734.0609741
train: epoch 13, iter 1300, loss: 3.206653, top_1: 0.492266, top_k: 0.727891, samples/s: 1330.917 1612671753.295851
train: epoch 13, iter 1400, loss: 3.183724, top_1: 0.488750, top_k: 0.731523, samples/s: 1324.908 1612671772.6179297
train: epoch 13, iter 1500, loss: 3.365899, top_1: 0.490391, top_k: 0.730156, samples/s: 1331.991 1612671791.8372433
train: epoch 13, iter 1600, loss: 3.058543, top_1: 0.492773, top_k: 0.733594, samples/s: 1335.540 1612671811.0055149
train: epoch 13, iter 1700, loss: 3.295158, top_1: 0.500234, top_k: 0.737070, samples/s: 1329.178 1612671830.2655678
train: epoch 13, iter 1800, loss: 3.208510, top_1: 0.483398, top_k: 0.725156, samples/s: 1331.222 1612671849.4960701
train: epoch 13, iter 1900, loss: 2.944034, top_1: 0.484805, top_k: 0.727031, samples/s: 1335.659 1612671868.662574
train: epoch 13, iter 2000, loss: 3.186028, top_1: 0.486719, top_k: 0.733828, samples/s: 1329.209 1612671887.9221964
train: epoch 13, iter 2100, loss: 3.077914, top_1: 0.492031, top_k: 0.734453, samples/s: 1327.785 1612671907.20239
train: epoch 13, iter 2200, loss: 3.038546, top_1: 0.493516, top_k: 0.735742, samples/s: 1328.844 1612671926.4673378
train: epoch 13, iter 2300, loss: 3.140392, top_1: 0.491680, top_k: 0.733672, samples/s: 1330.501 1612671945.7081182
train: epoch 13, iter 2400, loss: 3.045680, top_1: 0.490234, top_k: 0.729688, samples/s: 1333.340 1612671964.9080718
train: epoch 13, iter 2500, loss: 3.106563, top_1: 0.492344, top_k: 0.736563, samples/s: 1329.436 1612671984.1643546
train: epoch 13, iter 2600, loss: 3.114684, top_1: 0.492773, top_k: 0.738047, samples/s: 1326.402 1612672003.4647713
train: epoch 13, iter 2700, loss: 3.092272, top_1: 0.490742, top_k: 0.735742, samples/s: 1334.079 1612672022.6539135
train: epoch 13, iter 2800, loss: 3.111478, top_1: 0.491133, top_k: 0.733203, samples/s: 1334.119 1612672041.8426325
train: epoch 13, iter 2900, loss: 3.135958, top_1: 0.492344, top_k: 0.732969, samples/s: 1328.093 1612672061.1185093
train: epoch 13, iter 3000, loss: 3.231688, top_1: 0.482773, top_k: 0.726094, samples/s: 1337.075 1612672080.2646933
train: epoch 13, iter 3100, loss: 3.196303, top_1: 0.491406, top_k: 0.735391, samples/s: 1325.070 1612672099.5843728
train: epoch 13, iter 3200, loss: 3.346232, top_1: 0.490000, top_k: 0.733789, samples/s: 1325.936 1612672118.891506
train: epoch 13, iter 3300, loss: 3.073727, top_1: 0.492930, top_k: 0.735547, samples/s: 1330.363 1612672138.1346567
train: epoch 13, iter 3400, loss: 3.170993, top_1: 0.488164, top_k: 0.729766, samples/s: 1336.087 1612672157.2947748
train: epoch 13, iter 3500, loss: 3.037328, top_1: 0.490156, top_k: 0.732500, samples/s: 1328.034 1612672176.5714185
train: epoch 13, iter 3600, loss: 3.244329, top_1: 0.487773, top_k: 0.728398, samples/s: 1322.291 1612672195.932185
train: epoch 13, iter 3700, loss: 3.113559, top_1: 0.484336, top_k: 0.725508, samples/s: 1342.162 1612672215.005481
train: epoch 13, iter 3800, loss: 3.225853, top_1: 0.486523, top_k: 0.732031, samples/s: 1334.378 1612672234.1903987
train: epoch 13, iter 3900, loss: 3.196171, top_1: 0.487812, top_k: 0.735391, samples/s: 1330.349 1612672253.433473
train: epoch 13, iter 4000, loss: 3.201608, top_1: 0.493008, top_k: 0.731602, samples/s: 1333.372 1612672272.6329331
train: epoch 13, iter 4100, loss: 3.042735, top_1: 0.487617, top_k: 0.727266, samples/s: 1324.887 1612672291.9553125
train: epoch 13, iter 4200, loss: 3.237486, top_1: 0.492891, top_k: 0.733633, samples/s: 1333.842 1612672311.1479952
train: epoch 13, iter 4300, loss: 3.142500, top_1: 0.490117, top_k: 0.732422, samples/s: 1327.574 1612672330.4313505
train: epoch 13, iter 4400, loss: 3.249317, top_1: 0.491445, top_k: 0.731875, samples/s: 1330.302 1612672349.6750364
train: epoch 13, iter 4500, loss: 3.312554, top_1: 0.491484, top_k: 0.730234, samples/s: 1333.116 1612672368.8781846
train: epoch 13, iter 4600, loss: 3.118115, top_1: 0.486367, top_k: 0.730742, samples/s: 1330.574 1612672388.118024
train: epoch 13, iter 4700, loss: 3.033464, top_1: 0.491523, top_k: 0.732070, samples/s: 1331.065 1612672407.350736
train: epoch 13, iter 4800, loss: 3.357912, top_1: 0.488125, top_k: 0.733477, samples/s: 1325.888 1612672426.6585593
train: epoch 13, iter 4900, loss: 3.141110, top_1: 0.491172, top_k: 0.733633, samples/s: 1333.431 1612672445.8571937
train: epoch 13, iter 5000, loss: 3.191876, top_1: 0.490273, top_k: 0.736875, samples/s: 1329.988 1612672465.1054106
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_13.
validation: epoch 13, iter 195, top_1: 0.534014, top_k: 0.786398, samples/s: 2784.009 1612672483.606596
train: epoch 14, iter 100, loss: 2.994915, top_1: 0.503281, top_k: 0.740547, samples/s: 1357.812 1612672524.868203
train: epoch 14, iter 200, loss: 3.062105, top_1: 0.492070, top_k: 0.735664, samples/s: 1361.209 1612672543.6750736
train: epoch 14, iter 300, loss: 3.212791, top_1: 0.494648, top_k: 0.737891, samples/s: 1361.105 1612672562.4832048
train: epoch 14, iter 400, loss: 3.078336, top_1: 0.498125, top_k: 0.739180, samples/s: 1355.893 1612672581.3637683
train: epoch 14, iter 500, loss: 3.032081, top_1: 0.499023, top_k: 0.743477, samples/s: 1346.067 1612672600.38208
train: epoch 14, iter 600, loss: 3.156647, top_1: 0.497422, top_k: 0.739375, samples/s: 1338.976 1612672619.501318
train: epoch 14, iter 700, loss: 3.217296, top_1: 0.490859, top_k: 0.738164, samples/s: 1330.344 1612672638.7443068
train: epoch 14, iter 800, loss: 3.148718, top_1: 0.496211, top_k: 0.738828, samples/s: 1335.329 1612672657.9156759
train: epoch 14, iter 900, loss: 3.244638, top_1: 0.494141, top_k: 0.740469, samples/s: 1334.095 1612672677.105189
train: epoch 14, iter 1000, loss: 3.078436, top_1: 0.494609, top_k: 0.737891, samples/s: 1336.486 1612672696.259426
train: epoch 14, iter 1100, loss: 3.112205, top_1: 0.502656, top_k: 0.740664, samples/s: 1329.912 1612672715.509099
train: epoch 14, iter 1200, loss: 3.074216, top_1: 0.495469, top_k: 0.737969, samples/s: 1337.374 1612672734.6508431
train: epoch 14, iter 1300, loss: 3.010697, top_1: 0.496641, top_k: 0.739961, samples/s: 1333.560 1612672753.8475103
train: epoch 14, iter 1400, loss: 3.075703, top_1: 0.489570, top_k: 0.734961, samples/s: 1335.336 1612672773.0187535
train: epoch 14, iter 1500, loss: 3.233723, top_1: 0.496523, top_k: 0.735156, samples/s: 1330.066 1612672792.2658775
train: epoch 14, iter 1600, loss: 2.803161, top_1: 0.495195, top_k: 0.734609, samples/s: 1341.169 1612672811.353752
train: epoch 14, iter 1700, loss: 3.054243, top_1: 0.497422, top_k: 0.740195, samples/s: 1332.391 1612672830.5672836
train: epoch 14, iter 1800, loss: 3.347709, top_1: 0.491797, top_k: 0.736445, samples/s: 1335.739 1612672849.7327044
train: epoch 14, iter 1900, loss: 3.133614, top_1: 0.487617, top_k: 0.734492, samples/s: 1340.159 1612672868.8350077
train: epoch 14, iter 2000, loss: 2.995520, top_1: 0.487227, top_k: 0.730586, samples/s: 1335.458 1612672888.004412
train: epoch 14, iter 2100, loss: 3.179669, top_1: 0.501328, top_k: 0.737344, samples/s: 1334.363 1612672907.1896567
train: epoch 14, iter 2200, loss: 3.313633, top_1: 0.492500, top_k: 0.731523, samples/s: 1340.333 1612672926.289341
train: epoch 14, iter 2300, loss: 3.226997, top_1: 0.492422, top_k: 0.734766, samples/s: 1326.715 1612672945.5850496
train: epoch 14, iter 2400, loss: 3.162697, top_1: 0.494570, top_k: 0.737148, samples/s: 1335.752 1612672964.7503777
train: epoch 14, iter 2500, loss: 2.927122, top_1: 0.494648, top_k: 0.734453, samples/s: 1339.288 1612672983.8650112
train: epoch 14, iter 2600, loss: 3.131771, top_1: 0.498320, top_k: 0.737773, samples/s: 1332.023 1612673003.0838113
train: epoch 14, iter 2700, loss: 3.135180, top_1: 0.491758, top_k: 0.731055, samples/s: 1334.558 1612673022.2662477
train: epoch 14, iter 2800, loss: 3.223495, top_1: 0.496719, top_k: 0.738711, samples/s: 1337.405 1612673041.407751
train: epoch 14, iter 2900, loss: 2.971613, top_1: 0.492422, top_k: 0.734688, samples/s: 1335.953 1612673060.5701017
train: epoch 14, iter 3000, loss: 3.013867, top_1: 0.489258, top_k: 0.728945, samples/s: 1334.269 1612673079.7566907
train: epoch 14, iter 3100, loss: 3.073974, top_1: 0.492656, top_k: 0.737539, samples/s: 1334.923 1612673098.9337597
train: epoch 14, iter 3200, loss: 3.324037, top_1: 0.492891, top_k: 0.734766, samples/s: 1335.443 1612673118.1034431
train: epoch 14, iter 3300, loss: 3.306382, top_1: 0.489219, top_k: 0.731563, samples/s: 1335.266 1612673137.2756383
train: epoch 14, iter 3400, loss: 3.079205, top_1: 0.495156, top_k: 0.736094, samples/s: 1338.322 1612673156.4041257
train: epoch 14, iter 3500, loss: 3.256030, top_1: 0.491523, top_k: 0.733945, samples/s: 1331.859 1612673175.6253133
train: epoch 14, iter 3600, loss: 2.885259, top_1: 0.492188, top_k: 0.735977, samples/s: 1342.780 1612673194.6902535
train: epoch 14, iter 3700, loss: 3.299734, top_1: 0.493477, top_k: 0.732187, samples/s: 1339.342 1612673213.804098
train: epoch 14, iter 3800, loss: 2.878453, top_1: 0.495586, top_k: 0.740391, samples/s: 1331.445 1612673233.0313609
train: epoch 14, iter 3900, loss: 2.942915, top_1: 0.490586, top_k: 0.732422, samples/s: 1335.328 1612673252.2027194
train: epoch 14, iter 4000, loss: 2.955393, top_1: 0.496367, top_k: 0.736406, samples/s: 1337.653 1612673271.340703
train: epoch 14, iter 4100, loss: 3.057984, top_1: 0.485703, top_k: 0.732773, samples/s: 1336.740 1612673290.4917843
train: epoch 14, iter 4200, loss: 3.147329, top_1: 0.489609, top_k: 0.734688, samples/s: 1336.459 1612673309.646864
train: epoch 14, iter 4300, loss: 3.025725, top_1: 0.490508, top_k: 0.734609, samples/s: 1341.850 1612673328.7249713
train: epoch 14, iter 4400, loss: 3.343853, top_1: 0.490547, top_k: 0.727656, samples/s: 1329.764 1612673347.9765007
train: epoch 14, iter 4500, loss: 3.125633, top_1: 0.495937, top_k: 0.733398, samples/s: 1340.178 1612673367.0784411
train: epoch 14, iter 4600, loss: 3.036988, top_1: 0.494492, top_k: 0.735430, samples/s: 1338.402 1612673386.2057695
train: epoch 14, iter 4700, loss: 3.201679, top_1: 0.496328, top_k: 0.736445, samples/s: 1331.962 1612673405.42555
train: epoch 14, iter 4800, loss: 3.356737, top_1: 0.487812, top_k: 0.728125, samples/s: 1340.758 1612673424.5192008
train: epoch 14, iter 4900, loss: 3.296506, top_1: 0.493555, top_k: 0.737852, samples/s: 1336.491 1612673443.6738
train: epoch 14, iter 5000, loss: 3.110420, top_1: 0.496055, top_k: 0.734844, samples/s: 1335.027 1612673462.8494735
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_14.
validation: epoch 14, iter 195, top_1: 0.544872, top_k: 0.792528, samples/s: 2762.437 1612673481.4977133
train: epoch 15, iter 100, loss: 3.302437, top_1: 0.503633, top_k: 0.746641, samples/s: 1362.387 1612673516.3539715
train: epoch 15, iter 200, loss: 3.008115, top_1: 0.496797, top_k: 0.738086, samples/s: 1363.407 1612673535.130501
train: epoch 15, iter 300, loss: 3.200027, top_1: 0.495781, top_k: 0.741172, samples/s: 1361.494 1612673553.933327
train: epoch 15, iter 400, loss: 3.084460, top_1: 0.503437, top_k: 0.742656, samples/s: 1355.013 1612673572.8261752
train: epoch 15, iter 500, loss: 2.815520, top_1: 0.504375, top_k: 0.742617, samples/s: 1336.116 1612673591.9861436
train: epoch 15, iter 600, loss: 2.871247, top_1: 0.500820, top_k: 0.741797, samples/s: 1336.906 1612673611.134895
train: epoch 15, iter 700, loss: 3.019060, top_1: 0.493984, top_k: 0.740195, samples/s: 1337.501 1612673630.2750309
train: epoch 15, iter 800, loss: 3.140153, top_1: 0.489687, top_k: 0.734844, samples/s: 1333.222 1612673649.4767623
train: epoch 15, iter 900, loss: 2.937396, top_1: 0.504531, top_k: 0.746836, samples/s: 1328.729 1612673668.7431378
train: epoch 15, iter 1000, loss: 3.059559, top_1: 0.500313, top_k: 0.737422, samples/s: 1336.415 1612673687.8988724
train: epoch 15, iter 1100, loss: 2.912998, top_1: 0.503672, top_k: 0.737891, samples/s: 1333.448 1612673707.0972993
train: epoch 15, iter 1200, loss: 3.250992, top_1: 0.499922, top_k: 0.737539, samples/s: 1334.448 1612673726.2811975
train: epoch 15, iter 1300, loss: 3.007390, top_1: 0.498984, top_k: 0.739961, samples/s: 1330.588 1612673745.5208454
train: epoch 15, iter 1400, loss: 2.945917, top_1: 0.499531, top_k: 0.739297, samples/s: 1340.104 1612673764.62379
train: epoch 15, iter 1500, loss: 3.097266, top_1: 0.502070, top_k: 0.740781, samples/s: 1336.165 1612673783.7831063
train: epoch 15, iter 1600, loss: 2.908618, top_1: 0.494961, top_k: 0.737695, samples/s: 1332.144 1612673803.0003705
train: epoch 15, iter 1700, loss: 3.030330, top_1: 0.494336, top_k: 0.732969, samples/s: 1332.245 1612673822.2159379
train: epoch 15, iter 1800, loss: 3.121651, top_1: 0.496172, top_k: 0.739766, samples/s: 1337.572 1612673841.3552225
train: epoch 15, iter 1900, loss: 3.220554, top_1: 0.494648, top_k: 0.737578, samples/s: 1333.184 1612673860.5572495
train: epoch 15, iter 2000, loss: 2.938798, top_1: 0.498594, top_k: 0.736797, samples/s: 1334.059 1612673879.7467866
train: epoch 15, iter 2100, loss: 3.105430, top_1: 0.497773, top_k: 0.737500, samples/s: 1329.717 1612673898.999011
train: epoch 15, iter 2200, loss: 3.237047, top_1: 0.492773, top_k: 0.742539, samples/s: 1335.627 1612673918.1660326
train: epoch 15, iter 2300, loss: 3.124876, top_1: 0.496211, top_k: 0.739375, samples/s: 1329.888 1612673937.4158225
train: epoch 15, iter 2400, loss: 2.901679, top_1: 0.495742, top_k: 0.732656, samples/s: 1345.319 1612673956.4447148
train: epoch 15, iter 2500, loss: 2.924451, top_1: 0.498477, top_k: 0.741016, samples/s: 1334.633 1612673975.6260703
train: epoch 15, iter 2600, loss: 3.165045, top_1: 0.500547, top_k: 0.742695, samples/s: 1330.520 1612673994.866626
train: epoch 15, iter 2700, loss: 3.053996, top_1: 0.490859, top_k: 0.737734, samples/s: 1336.486 1612674014.0217876
train: epoch 15, iter 2800, loss: 3.164176, top_1: 0.494180, top_k: 0.738633, samples/s: 1334.854 1612674033.1995935
train: epoch 15, iter 2900, loss: 3.143608, top_1: 0.499336, top_k: 0.737031, samples/s: 1340.409 1612674052.298177
train: epoch 15, iter 3000, loss: 3.095959, top_1: 0.498164, top_k: 0.739297, samples/s: 1338.917 1612674071.418559
train: epoch 15, iter 3100, loss: 3.024551, top_1: 0.497773, top_k: 0.738047, samples/s: 1330.251 1612674090.662546
train: epoch 15, iter 3200, loss: 3.032884, top_1: 0.496992, top_k: 0.743477, samples/s: 1337.997 1612674109.7956355
train: epoch 15, iter 3300, loss: 2.982391, top_1: 0.500820, top_k: 0.741680, samples/s: 1337.248 1612674128.939448
train: epoch 15, iter 3400, loss: 3.229100, top_1: 0.493008, top_k: 0.737070, samples/s: 1334.629 1612674148.12078
train: epoch 15, iter 3500, loss: 2.892261, top_1: 0.493984, top_k: 0.735430, samples/s: 1337.533 1612674167.2605705
train: epoch 15, iter 3600, loss: 3.256422, top_1: 0.495352, top_k: 0.737344, samples/s: 1338.128 1612674186.3916676
train: epoch 15, iter 3700, loss: 3.033750, top_1: 0.496055, top_k: 0.740742, samples/s: 1336.088 1612674205.5521486
train: epoch 15, iter 3800, loss: 3.088240, top_1: 0.493594, top_k: 0.730547, samples/s: 1335.934 1612674224.7147179
train: epoch 15, iter 3900, loss: 3.114795, top_1: 0.497344, top_k: 0.739570, samples/s: 1337.610 1612674243.853393
train: epoch 15, iter 4000, loss: 3.018625, top_1: 0.492539, top_k: 0.733359, samples/s: 1337.157 1612674262.9984338
train: epoch 15, iter 4100, loss: 3.074922, top_1: 0.495312, top_k: 0.736602, samples/s: 1332.268 1612674282.2138445
train: epoch 15, iter 4200, loss: 3.029365, top_1: 0.494258, top_k: 0.736094, samples/s: 1339.188 1612674301.3298628
train: epoch 15, iter 4300, loss: 2.980594, top_1: 0.495977, top_k: 0.739180, samples/s: 1337.488 1612674320.4702737
train: epoch 15, iter 4400, loss: 3.114199, top_1: 0.497695, top_k: 0.735234, samples/s: 1333.532 1612674339.667358
train: epoch 15, iter 4500, loss: 3.117222, top_1: 0.494531, top_k: 0.736484, samples/s: 1329.318 1612674358.9253955
train: epoch 15, iter 4600, loss: 3.067624, top_1: 0.497422, top_k: 0.742656, samples/s: 1340.639 1612674378.0207953
train: epoch 15, iter 4700, loss: 3.133729, top_1: 0.499180, top_k: 0.742383, samples/s: 1338.239 1612674397.1503417
train: epoch 15, iter 4800, loss: 3.074484, top_1: 0.495586, top_k: 0.739922, samples/s: 1331.743 1612674416.373344
train: epoch 15, iter 4900, loss: 3.192171, top_1: 0.496680, top_k: 0.736328, samples/s: 1336.987 1612674435.520834
train: epoch 15, iter 5000, loss: 3.100398, top_1: 0.495937, top_k: 0.737109, samples/s: 1337.449 1612674454.6617162
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_15.
validation: epoch 15, iter 195, top_1: 0.551222, top_k: 0.797456, samples/s: 2755.532 1612674473.374513
train: epoch 16, iter 100, loss: 3.149258, top_1: 0.513633, top_k: 0.753555, samples/s: 1361.423 1612674508.0946362
train: epoch 16, iter 200, loss: 3.066901, top_1: 0.513320, top_k: 0.750508, samples/s: 1357.015 1612674526.9595304
train: epoch 16, iter 300, loss: 3.086790, top_1: 0.510156, top_k: 0.749219, samples/s: 1362.987 1612674545.7417808
train: epoch 16, iter 400, loss: 2.881541, top_1: 0.502734, top_k: 0.742461, samples/s: 1354.398 1612674564.6431515
train: epoch 16, iter 500, loss: 3.130175, top_1: 0.500664, top_k: 0.741445, samples/s: 1340.477 1612674583.7408526
train: epoch 16, iter 600, loss: 2.956194, top_1: 0.504844, top_k: 0.744766, samples/s: 1339.244 1612674602.8560996
train: epoch 16, iter 700, loss: 3.169343, top_1: 0.498672, top_k: 0.737539, samples/s: 1329.420 1612674622.11271
train: epoch 16, iter 800, loss: 2.884770, top_1: 0.501875, top_k: 0.742695, samples/s: 1329.215 1612674641.3721411
train: epoch 16, iter 900, loss: 2.995182, top_1: 0.510664, top_k: 0.745820, samples/s: 1333.445 1612674660.5705507
train: epoch 16, iter 1000, loss: 2.949826, top_1: 0.507695, top_k: 0.744805, samples/s: 1332.139 1612674679.787698
train: epoch 16, iter 1100, loss: 3.056010, top_1: 0.508516, top_k: 0.747461, samples/s: 1336.320 1612674698.9447935
train: epoch 16, iter 1200, loss: 3.196762, top_1: 0.509922, top_k: 0.750586, samples/s: 1329.237 1612674718.2040195
train: epoch 16, iter 1300, loss: 3.148324, top_1: 0.501484, top_k: 0.739336, samples/s: 1334.856 1612674737.3820624
train: epoch 16, iter 1400, loss: 3.093441, top_1: 0.502461, top_k: 0.739102, samples/s: 1332.809 1612674756.58968
train: epoch 16, iter 1500, loss: 3.225194, top_1: 0.501680, top_k: 0.740469, samples/s: 1336.834 1612674775.7393434
train: epoch 16, iter 1600, loss: 3.195467, top_1: 0.500352, top_k: 0.742461, samples/s: 1336.871 1612674794.888536
train: epoch 16, iter 1700, loss: 2.967108, top_1: 0.496680, top_k: 0.742734, samples/s: 1334.181 1612674814.0763354
train: epoch 16, iter 1800, loss: 3.104725, top_1: 0.496484, top_k: 0.741250, samples/s: 1333.248 1612674833.2776196
train: epoch 16, iter 1900, loss: 3.316905, top_1: 0.493555, top_k: 0.737344, samples/s: 1335.076 1612674852.452505
train: epoch 16, iter 2000, loss: 3.053740, top_1: 0.503203, top_k: 0.742891, samples/s: 1335.967 1612674871.6147327
train: epoch 16, iter 2100, loss: 3.153517, top_1: 0.496563, top_k: 0.742539, samples/s: 1334.210 1612674890.8020577
train: epoch 16, iter 2200, loss: 3.267054, top_1: 0.498711, top_k: 0.741563, samples/s: 1334.761 1612674909.9815228
train: epoch 16, iter 2300, loss: 3.215594, top_1: 0.499570, top_k: 0.736875, samples/s: 1333.980 1612674929.172205
train: epoch 16, iter 2400, loss: 3.135477, top_1: 0.500352, top_k: 0.740547, samples/s: 1334.497 1612674948.3554943
train: epoch 16, iter 2500, loss: 3.014875, top_1: 0.499453, top_k: 0.739297, samples/s: 1333.159 1612674967.5580258
train: epoch 16, iter 2600, loss: 3.081979, top_1: 0.500273, top_k: 0.744453, samples/s: 1337.933 1612674986.6919734
train: epoch 16, iter 2700, loss: 3.150915, top_1: 0.502227, top_k: 0.739219, samples/s: 1334.609 1612675005.873682
train: epoch 16, iter 2800, loss: 3.283959, top_1: 0.496328, top_k: 0.737109, samples/s: 1332.261 1612675025.089087
train: epoch 16, iter 2900, loss: 3.291876, top_1: 0.503672, top_k: 0.739570, samples/s: 1337.535 1612675044.229152
train: epoch 16, iter 3000, loss: 3.219170, top_1: 0.501406, top_k: 0.742578, samples/s: 1339.830 1612675063.3356705
train: epoch 16, iter 3100, loss: 2.904135, top_1: 0.500469, top_k: 0.743086, samples/s: 1337.246 1612675082.4798677
train: epoch 16, iter 3200, loss: 3.065400, top_1: 0.503945, top_k: 0.743398, samples/s: 1335.237 1612675101.6521108
train: epoch 16, iter 3300, loss: 3.077600, top_1: 0.497227, top_k: 0.736289, samples/s: 1334.738 1612675120.8319623
train: epoch 16, iter 3400, loss: 3.024848, top_1: 0.498984, top_k: 0.744727, samples/s: 1335.803 1612675139.9964252
train: epoch 16, iter 3500, loss: 3.317594, top_1: 0.498125, top_k: 0.741055, samples/s: 1334.218 1612675159.1836753
train: epoch 16, iter 3600, loss: 3.251813, top_1: 0.503398, top_k: 0.738047, samples/s: 1337.609 1612675178.3223479
train: epoch 16, iter 3700, loss: 3.043098, top_1: 0.494102, top_k: 0.733555, samples/s: 1333.205 1612675197.5242736
train: epoch 16, iter 3800, loss: 2.979589, top_1: 0.500703, top_k: 0.739531, samples/s: 1339.222 1612675216.6397212
train: epoch 16, iter 3900, loss: 3.294503, top_1: 0.500977, top_k: 0.741367, samples/s: 1341.883 1612675235.7173889
train: epoch 16, iter 4000, loss: 3.168521, top_1: 0.499063, top_k: 0.742695, samples/s: 1329.065 1612675254.9791012
train: epoch 16, iter 4100, loss: 2.926411, top_1: 0.497617, top_k: 0.742422, samples/s: 1338.389 1612675274.1065736
train: epoch 16, iter 4200, loss: 2.935122, top_1: 0.499023, top_k: 0.736992, samples/s: 1334.339 1612675293.2921069
train: epoch 16, iter 4300, loss: 3.205492, top_1: 0.501563, top_k: 0.739648, samples/s: 1342.769 1612675312.357124
train: epoch 16, iter 4400, loss: 3.270867, top_1: 0.500977, top_k: 0.741172, samples/s: 1329.705 1612675331.6095076
train: epoch 16, iter 4500, loss: 2.703838, top_1: 0.499570, top_k: 0.738828, samples/s: 1332.625 1612675350.8197136
train: epoch 16, iter 4600, loss: 3.080395, top_1: 0.500820, top_k: 0.737070, samples/s: 1332.583 1612675370.0305214
train: epoch 16, iter 4700, loss: 3.061852, top_1: 0.499492, top_k: 0.741953, samples/s: 1346.209 1612675389.0469353
train: epoch 16, iter 4800, loss: 2.989107, top_1: 0.502109, top_k: 0.738516, samples/s: 1322.444 1612675408.405045
train: epoch 16, iter 4900, loss: 3.201639, top_1: 0.499570, top_k: 0.741406, samples/s: 1336.921 1612675427.5535305
train: epoch 16, iter 5000, loss: 3.078030, top_1: 0.500117, top_k: 0.744219, samples/s: 1340.421 1612675446.651956
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_16.
validation: epoch 16, iter 195, top_1: 0.543289, top_k: 0.795493, samples/s: 2798.882 1612675465.069088
train: epoch 17, iter 100, loss: 2.981452, top_1: 0.504219, top_k: 0.746289, samples/s: 1361.469 1612675500.0128028
train: epoch 17, iter 200, loss: 2.975623, top_1: 0.510977, top_k: 0.749219, samples/s: 1359.227 1612675518.8470473
train: epoch 17, iter 300, loss: 3.015431, top_1: 0.507656, top_k: 0.749805, samples/s: 1361.228 1612675537.6536126
train: epoch 17, iter 400, loss: 3.112990, top_1: 0.510781, top_k: 0.746602, samples/s: 1357.813 1612675556.5074728
train: epoch 17, iter 500, loss: 2.941164, top_1: 0.511094, top_k: 0.746406, samples/s: 1336.430 1612675575.662974
train: epoch 17, iter 600, loss: 2.842706, top_1: 0.508516, top_k: 0.746602, samples/s: 1328.973 1612675594.9260314
train: epoch 17, iter 700, loss: 3.039503, top_1: 0.501289, top_k: 0.746172, samples/s: 1328.107 1612675614.201616
train: epoch 17, iter 800, loss: 3.150610, top_1: 0.506602, top_k: 0.746484, samples/s: 1336.571 1612675633.3550074
train: epoch 17, iter 900, loss: 3.076398, top_1: 0.508281, top_k: 0.745664, samples/s: 1333.913 1612675652.5466404
train: epoch 17, iter 1000, loss: 3.182870, top_1: 0.505547, top_k: 0.741641, samples/s: 1323.622 1612675671.887475
train: epoch 17, iter 1100, loss: 3.198596, top_1: 0.510078, top_k: 0.744687, samples/s: 1335.134 1612675691.0616257
train: epoch 17, iter 1200, loss: 2.888814, top_1: 0.508906, top_k: 0.747227, samples/s: 1339.408 1612675710.1745706
train: epoch 17, iter 1300, loss: 3.167357, top_1: 0.509141, top_k: 0.746289, samples/s: 1323.388 1612675729.5188758
train: epoch 17, iter 1400, loss: 2.925464, top_1: 0.500586, top_k: 0.745078, samples/s: 1332.454 1612675748.7315388
train: epoch 17, iter 1500, loss: 3.127543, top_1: 0.503125, top_k: 0.740664, samples/s: 1330.840 1612675767.9674542
train: epoch 17, iter 1600, loss: 3.180788, top_1: 0.501016, top_k: 0.741484, samples/s: 1335.193 1612675787.1407232
train: epoch 17, iter 1700, loss: 3.020308, top_1: 0.507227, top_k: 0.743945, samples/s: 1327.334 1612675806.4275403
train: epoch 17, iter 1800, loss: 2.874368, top_1: 0.500273, top_k: 0.746602, samples/s: 1332.878 1612675825.6340394
train: epoch 17, iter 1900, loss: 3.028177, top_1: 0.504336, top_k: 0.744805, samples/s: 1327.247 1612675844.9221313
train: epoch 17, iter 2000, loss: 3.095241, top_1: 0.503594, top_k: 0.745938, samples/s: 1331.952 1612675864.1420674
train: epoch 17, iter 2100, loss: 2.825389, top_1: 0.504805, top_k: 0.743555, samples/s: 1338.750 1612675883.264316
train: epoch 17, iter 2200, loss: 3.080601, top_1: 0.504414, top_k: 0.741563, samples/s: 1330.971 1612675902.4984643
train: epoch 17, iter 2300, loss: 2.987297, top_1: 0.498203, top_k: 0.740898, samples/s: 1336.846 1612675921.6479495
train: epoch 17, iter 2400, loss: 3.031633, top_1: 0.510000, top_k: 0.746641, samples/s: 1337.371 1612675940.7900314
train: epoch 17, iter 2500, loss: 3.032452, top_1: 0.503828, top_k: 0.744727, samples/s: 1320.720 1612675960.1733985
train: epoch 17, iter 2600, loss: 3.115606, top_1: 0.505938, top_k: 0.745391, samples/s: 1336.078 1612675979.333938
train: epoch 17, iter 2700, loss: 3.076100, top_1: 0.501367, top_k: 0.747812, samples/s: 1331.814 1612675998.5558395
train: epoch 17, iter 2800, loss: 3.102266, top_1: 0.507070, top_k: 0.746250, samples/s: 1338.449 1612676017.6824262
train: epoch 17, iter 2900, loss: 2.940826, top_1: 0.502383, top_k: 0.741172, samples/s: 1329.105 1612676036.9435997
train: epoch 17, iter 3000, loss: 2.953368, top_1: 0.503047, top_k: 0.743711, samples/s: 1338.101 1612676056.0750957
train: epoch 17, iter 3100, loss: 2.885588, top_1: 0.502031, top_k: 0.741211, samples/s: 1333.971 1612676075.2659233
train: epoch 17, iter 3200, loss: 3.047675, top_1: 0.502734, top_k: 0.741289, samples/s: 1330.451 1612676094.5075195
train: epoch 17, iter 3300, loss: 3.088259, top_1: 0.506016, top_k: 0.745742, samples/s: 1326.335 1612676113.8088737
train: epoch 17, iter 3400, loss: 3.027358, top_1: 0.508750, top_k: 0.749492, samples/s: 1334.616 1612676132.9904408
train: epoch 17, iter 3500, loss: 3.046004, top_1: 0.501680, top_k: 0.741289, samples/s: 1327.127 1612676152.2801635
train: epoch 17, iter 3600, loss: 3.201977, top_1: 0.502266, top_k: 0.742695, samples/s: 1332.749 1612676171.4886262
train: epoch 17, iter 3700, loss: 2.985294, top_1: 0.504336, top_k: 0.742461, samples/s: 1338.453 1612676190.6151645
train: epoch 17, iter 3800, loss: 3.130409, top_1: 0.500117, top_k: 0.740078, samples/s: 1335.008 1612676209.7910485
train: epoch 17, iter 3900, loss: 3.215252, top_1: 0.509219, top_k: 0.745820, samples/s: 1328.580 1612676229.059749
train: epoch 17, iter 4000, loss: 3.203199, top_1: 0.508203, top_k: 0.742148, samples/s: 1331.464 1612676248.2867038
train: epoch 17, iter 4100, loss: 3.030372, top_1: 0.500703, top_k: 0.738633, samples/s: 1329.448 1612676267.5428221
train: epoch 17, iter 4200, loss: 3.009914, top_1: 0.499492, top_k: 0.740820, samples/s: 1338.253 1612676286.67224
train: epoch 17, iter 4300, loss: 3.120080, top_1: 0.505117, top_k: 0.743906, samples/s: 1331.421 1612676305.8998246
train: epoch 17, iter 4400, loss: 3.037259, top_1: 0.501758, top_k: 0.745156, samples/s: 1334.010 1612676325.0901158
train: epoch 17, iter 4500, loss: 2.969292, top_1: 0.506445, top_k: 0.746875, samples/s: 1326.443 1612676344.3898818
train: epoch 17, iter 4600, loss: 3.182452, top_1: 0.502188, top_k: 0.739336, samples/s: 1330.870 1612676363.6253307
train: epoch 17, iter 4700, loss: 3.164197, top_1: 0.499961, top_k: 0.739766, samples/s: 1330.921 1612676382.860175
train: epoch 17, iter 4800, loss: 3.025065, top_1: 0.502422, top_k: 0.743711, samples/s: 1339.028 1612676401.978481
train: epoch 17, iter 4900, loss: 3.149016, top_1: 0.507266, top_k: 0.744570, samples/s: 1328.774 1612676421.2444055
train: epoch 17, iter 5000, loss: 2.892015, top_1: 0.504883, top_k: 0.746211, samples/s: 1334.994 1612676440.4204803
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_17.
validation: epoch 17, iter 195, top_1: 0.537800, top_k: 0.788862, samples/s: 2740.581 1612676459.2721736
train: epoch 18, iter 100, loss: 3.105906, top_1: 0.516328, top_k: 0.754062, samples/s: 1359.924 1612676493.9815264
train: epoch 18, iter 200, loss: 3.081407, top_1: 0.511328, top_k: 0.752031, samples/s: 1358.561 1612676512.8249872
train: epoch 18, iter 300, loss: 3.015520, top_1: 0.506602, top_k: 0.747383, samples/s: 1357.129 1612676531.6882842
train: epoch 18, iter 400, loss: 3.145804, top_1: 0.507695, top_k: 0.745977, samples/s: 1356.965 1612676550.5539565
train: epoch 18, iter 500, loss: 3.025025, top_1: 0.513281, top_k: 0.751484, samples/s: 1338.099 1612676569.6855617
train: epoch 18, iter 600, loss: 3.065275, top_1: 0.512344, top_k: 0.758008, samples/s: 1333.718 1612676588.8801088
train: epoch 18, iter 700, loss: 3.079684, top_1: 0.508164, top_k: 0.747148, samples/s: 1339.753 1612676607.988071
train: epoch 18, iter 800, loss: 2.890072, top_1: 0.507109, top_k: 0.748945, samples/s: 1336.586 1612676627.1413567
train: epoch 18, iter 900, loss: 2.935137, top_1: 0.500156, top_k: 0.743906, samples/s: 1332.206 1612676646.3576164
train: epoch 18, iter 1000, loss: 3.034849, top_1: 0.509414, top_k: 0.752461, samples/s: 1335.172 1612676665.5310812
train: epoch 18, iter 1100, loss: 3.211721, top_1: 0.512734, top_k: 0.750156, samples/s: 1339.067 1612676684.6488657
train: epoch 18, iter 1200, loss: 3.192788, top_1: 0.508711, top_k: 0.748125, samples/s: 1336.046 1612676703.809919
train: epoch 18, iter 1300, loss: 3.275774, top_1: 0.505273, top_k: 0.745273, samples/s: 1334.001 1612676723.0003693
train: epoch 18, iter 1400, loss: 2.914233, top_1: 0.501484, top_k: 0.746367, samples/s: 1335.285 1612676742.1723042
train: epoch 18, iter 1500, loss: 3.272883, top_1: 0.511250, top_k: 0.746406, samples/s: 1333.458 1612676761.3704407
train: epoch 18, iter 1600, loss: 3.252843, top_1: 0.506328, top_k: 0.749062, samples/s: 1330.203 1612676780.6156654
train: epoch 18, iter 1700, loss: 3.184028, top_1: 0.508086, top_k: 0.744687, samples/s: 1340.010 1612676799.7199569
train: epoch 18, iter 1800, loss: 2.934581, top_1: 0.504961, top_k: 0.743867, samples/s: 1328.762 1612676818.986006
train: epoch 18, iter 1900, loss: 3.152553, top_1: 0.506211, top_k: 0.746953, samples/s: 1345.135 1612676838.0175674
train: epoch 18, iter 2000, loss: 2.849840, top_1: 0.510391, top_k: 0.749297, samples/s: 1330.243 1612676857.262202
train: epoch 18, iter 2100, loss: 3.226747, top_1: 0.505508, top_k: 0.743437, samples/s: 1336.726 1612676876.4134357
train: epoch 18, iter 2200, loss: 2.986025, top_1: 0.507930, top_k: 0.749414, samples/s: 1337.595 1612676895.5523753
train: epoch 18, iter 2300, loss: 3.004826, top_1: 0.507812, top_k: 0.748359, samples/s: 1333.772 1612676914.746011
train: epoch 18, iter 2400, loss: 2.914742, top_1: 0.503047, top_k: 0.744180, samples/s: 1331.658 1612676933.9701023
train: epoch 18, iter 2500, loss: 3.018389, top_1: 0.507344, top_k: 0.745117, samples/s: 1336.050 1612676953.1310852
train: epoch 18, iter 2600, loss: 2.884494, top_1: 0.505586, top_k: 0.740898, samples/s: 1331.818 1612676972.352899
train: epoch 18, iter 2700, loss: 2.926321, top_1: 0.505352, top_k: 0.746016, samples/s: 1342.390 1612676991.4233649
train: epoch 18, iter 2800, loss: 3.062760, top_1: 0.502930, top_k: 0.748359, samples/s: 1335.161 1612677010.597239
train: epoch 18, iter 2900, loss: 3.061978, top_1: 0.507539, top_k: 0.744102, samples/s: 1340.800 1612677029.6901915
train: epoch 18, iter 3000, loss: 2.937119, top_1: 0.502695, top_k: 0.744141, samples/s: 1333.248 1612677048.8914332
train: epoch 18, iter 3100, loss: 2.999182, top_1: 0.507578, top_k: 0.746172, samples/s: 1338.454 1612677068.0179424
train: epoch 18, iter 3200, loss: 3.169353, top_1: 0.506992, top_k: 0.746055, samples/s: 1332.909 1612677087.2240827
train: epoch 18, iter 3300, loss: 2.999732, top_1: 0.509062, top_k: 0.747109, samples/s: 1333.176 1612677106.4263418
train: epoch 18, iter 3400, loss: 3.181547, top_1: 0.504727, top_k: 0.743633, samples/s: 1346.453 1612677125.439281
train: epoch 18, iter 3500, loss: 3.081461, top_1: 0.508477, top_k: 0.749453, samples/s: 1331.983 1612677144.6587703
train: epoch 18, iter 3600, loss: 2.948110, top_1: 0.510859, top_k: 0.750195, samples/s: 1338.178 1612677163.7892396
train: epoch 18, iter 3700, loss: 2.862135, top_1: 0.508320, top_k: 0.750547, samples/s: 1339.586 1612677182.899588
train: epoch 18, iter 3800, loss: 3.082756, top_1: 0.510039, top_k: 0.744180, samples/s: 1338.650 1612677202.023315
train: epoch 18, iter 3900, loss: 3.168590, top_1: 0.500859, top_k: 0.743164, samples/s: 1337.099 1612677221.1693044
train: epoch 18, iter 4000, loss: 3.054066, top_1: 0.505117, top_k: 0.746094, samples/s: 1336.860 1612677240.3186092
train: epoch 18, iter 4100, loss: 2.927019, top_1: 0.501406, top_k: 0.741680, samples/s: 1334.558 1612677259.50109
train: epoch 18, iter 4200, loss: 3.242404, top_1: 0.501992, top_k: 0.741563, samples/s: 1340.219 1612677278.6024494
train: epoch 18, iter 4300, loss: 3.180174, top_1: 0.506563, top_k: 0.744570, samples/s: 1330.656 1612677297.8409646
train: epoch 18, iter 4400, loss: 3.090745, top_1: 0.502227, top_k: 0.743359, samples/s: 1342.944 1612677316.9035614
train: epoch 18, iter 4500, loss: 3.113291, top_1: 0.504336, top_k: 0.746172, samples/s: 1339.613 1612677336.0135648
train: epoch 18, iter 4600, loss: 3.051640, top_1: 0.504648, top_k: 0.741719, samples/s: 1339.381 1612677355.1268966
train: epoch 18, iter 4700, loss: 3.151932, top_1: 0.507891, top_k: 0.748008, samples/s: 1336.584 1612677374.2801702
train: epoch 18, iter 4800, loss: 3.271785, top_1: 0.501953, top_k: 0.748711, samples/s: 1336.617 1612677393.4330058
train: epoch 18, iter 4900, loss: 2.990967, top_1: 0.504805, top_k: 0.745430, samples/s: 1337.965 1612677412.5665712
train: epoch 18, iter 5000, loss: 2.898942, top_1: 0.507695, top_k: 0.746563, samples/s: 1339.522 1612677431.6778429
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_18.
validation: epoch 18, iter 195, top_1: 0.566186, top_k: 0.805048, samples/s: 2760.040 1612677450.3271945
train: epoch 19, iter 100, loss: 3.068815, top_1: 0.520859, top_k: 0.754883, samples/s: 1361.505 1612677485.4759657
train: epoch 19, iter 200, loss: 3.106731, top_1: 0.508203, top_k: 0.751914, samples/s: 1358.655 1612677504.3180854
train: epoch 19, iter 300, loss: 3.086446, top_1: 0.507305, top_k: 0.747500, samples/s: 1354.482 1612677523.2183642
train: epoch 19, iter 400, loss: 3.036241, top_1: 0.512539, top_k: 0.752539, samples/s: 1358.678 1612677542.0602756
train: epoch 19, iter 500, loss: 2.754390, top_1: 0.515625, top_k: 0.755078, samples/s: 1345.532 1612677561.0862055
train: epoch 19, iter 600, loss: 2.894272, top_1: 0.512266, top_k: 0.751953, samples/s: 1329.095 1612677580.3473797
train: epoch 19, iter 700, loss: 3.211335, top_1: 0.510898, top_k: 0.753086, samples/s: 1342.056 1612677599.4225597
train: epoch 19, iter 800, loss: 3.162207, top_1: 0.511211, top_k: 0.750117, samples/s: 1333.633 1612677618.6182177
train: epoch 19, iter 900, loss: 3.025172, top_1: 0.509336, top_k: 0.750078, samples/s: 1336.913 1612677637.7668126
train: epoch 19, iter 1000, loss: 3.050231, top_1: 0.514141, top_k: 0.751211, samples/s: 1337.751 1612677656.9034688
train: epoch 19, iter 1100, loss: 3.187964, top_1: 0.513320, top_k: 0.750000, samples/s: 1337.138 1612677676.048793
train: epoch 19, iter 1200, loss: 3.001196, top_1: 0.513828, top_k: 0.755078, samples/s: 1338.244 1612677695.1783717
train: epoch 19, iter 1300, loss: 3.038151, top_1: 0.512031, top_k: 0.751055, samples/s: 1332.771 1612677714.3864317
train: epoch 19, iter 1400, loss: 2.956847, top_1: 0.508047, top_k: 0.750195, samples/s: 1337.287 1612677733.5296538
train: epoch 19, iter 1500, loss: 3.018163, top_1: 0.506250, top_k: 0.743945, samples/s: 1339.409 1612677752.642603
train: epoch 19, iter 1600, loss: 3.230432, top_1: 0.508086, top_k: 0.747656, samples/s: 1336.231 1612677771.8009331
train: epoch 19, iter 1700, loss: 2.996461, top_1: 0.506563, top_k: 0.746016, samples/s: 1334.331 1612677790.9865828
train: epoch 19, iter 1800, loss: 2.970939, top_1: 0.505586, top_k: 0.743906, samples/s: 1336.989 1612677810.1341567
train: epoch 19, iter 1900, loss: 2.944224, top_1: 0.509648, top_k: 0.747578, samples/s: 1333.314 1612677829.3344314
train: epoch 19, iter 2000, loss: 2.967433, top_1: 0.508594, top_k: 0.748594, samples/s: 1344.558 1612677848.3740666
train: epoch 19, iter 2100, loss: 3.063021, top_1: 0.509141, top_k: 0.746992, samples/s: 1336.637 1612677867.5266023
train: epoch 19, iter 2200, loss: 3.087988, top_1: 0.507188, top_k: 0.747227, samples/s: 1338.628 1612677886.6506622
train: epoch 19, iter 2300, loss: 3.089198, top_1: 0.516719, top_k: 0.753516, samples/s: 1337.535 1612677905.790402
train: epoch 19, iter 2400, loss: 2.900169, top_1: 0.515117, top_k: 0.747305, samples/s: 1335.299 1612677924.9620752
train: epoch 19, iter 2500, loss: 2.750480, top_1: 0.506758, top_k: 0.748828, samples/s: 1336.569 1612677944.115598
train: epoch 19, iter 2600, loss: 2.940298, top_1: 0.508711, top_k: 0.748945, samples/s: 1336.239 1612677963.2739015
train: epoch 19, iter 2700, loss: 2.931613, top_1: 0.512578, top_k: 0.746953, samples/s: 1341.154 1612677982.3619466
train: epoch 19, iter 2800, loss: 3.114182, top_1: 0.505352, top_k: 0.748398, samples/s: 1332.017 1612678001.5809119
train: epoch 19, iter 2900, loss: 2.977784, top_1: 0.505938, top_k: 0.749531, samples/s: 1341.567 1612678020.6631048
train: epoch 19, iter 3000, loss: 2.967980, top_1: 0.510781, top_k: 0.747344, samples/s: 1341.161 1612678039.7510142
train: epoch 19, iter 3100, loss: 3.087898, top_1: 0.505391, top_k: 0.748320, samples/s: 1339.483 1612678058.8628004
train: epoch 19, iter 3200, loss: 3.065879, top_1: 0.500625, top_k: 0.747891, samples/s: 1341.258 1612678077.9493635
train: epoch 19, iter 3300, loss: 3.104759, top_1: 0.503242, top_k: 0.742773, samples/s: 1333.487 1612678097.147189
train: epoch 19, iter 3400, loss: 3.186908, top_1: 0.510742, top_k: 0.748242, samples/s: 1341.532 1612678116.2299185
train: epoch 19, iter 3500, loss: 2.999286, top_1: 0.508750, top_k: 0.751563, samples/s: 1342.436 1612678135.299685
train: epoch 19, iter 3600, loss: 3.146759, top_1: 0.511328, top_k: 0.746289, samples/s: 1337.116 1612678154.445363
train: epoch 19, iter 3700, loss: 3.096885, top_1: 0.506016, top_k: 0.748828, samples/s: 1338.898 1612678173.5655723
train: epoch 19, iter 3800, loss: 3.083239, top_1: 0.509414, top_k: 0.747148, samples/s: 1333.896 1612678192.7574718
train: epoch 19, iter 3900, loss: 2.956481, top_1: 0.513359, top_k: 0.746172, samples/s: 1343.928 1612678211.806116
train: epoch 19, iter 4000, loss: 2.974870, top_1: 0.513359, top_k: 0.748047, samples/s: 1340.386 1612678230.9050837
train: epoch 19, iter 4100, loss: 3.102416, top_1: 0.507539, top_k: 0.747305, samples/s: 1330.021 1612678250.1529253
train: epoch 19, iter 4200, loss: 3.160054, top_1: 0.509453, top_k: 0.752227, samples/s: 1335.007 1612678269.3288279
train: epoch 19, iter 4300, loss: 3.042801, top_1: 0.509336, top_k: 0.747109, samples/s: 1333.944 1612678288.5200243
train: epoch 19, iter 4400, loss: 3.029168, top_1: 0.503867, top_k: 0.743594, samples/s: 1336.121 1612678307.680003
train: epoch 19, iter 4500, loss: 2.965871, top_1: 0.510391, top_k: 0.754141, samples/s: 1340.237 1612678326.7810414
train: epoch 19, iter 4600, loss: 3.297894, top_1: 0.510898, top_k: 0.749922, samples/s: 1336.230 1612678345.9394486
train: epoch 19, iter 4700, loss: 2.898421, top_1: 0.509687, top_k: 0.751328, samples/s: 1341.546 1612678365.0219533
train: epoch 19, iter 4800, loss: 3.019734, top_1: 0.515312, top_k: 0.750820, samples/s: 1339.439 1612678384.1343646
train: epoch 19, iter 4900, loss: 3.040950, top_1: 0.505000, top_k: 0.745469, samples/s: 1333.193 1612678403.336386
train: epoch 19, iter 5000, loss: 3.013778, top_1: 0.501758, top_k: 0.741836, samples/s: 1339.375 1612678422.449838
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_19.
validation: epoch 19, iter 195, top_1: 0.567007, top_k: 0.809816, samples/s: 2716.146 1612678441.3929703
train: epoch 20, iter 100, loss: 2.936627, top_1: 0.517383, top_k: 0.753594, samples/s: 1363.849 1612678476.0096009
train: epoch 20, iter 200, loss: 3.221110, top_1: 0.516133, top_k: 0.750078, samples/s: 1358.823 1612678494.8497593
train: epoch 20, iter 300, loss: 3.121963, top_1: 0.517344, top_k: 0.754219, samples/s: 1359.785 1612678513.6759186
train: epoch 20, iter 400, loss: 3.238248, top_1: 0.516836, top_k: 0.751289, samples/s: 1349.374 1612678532.6482193
train: epoch 20, iter 500, loss: 3.142531, top_1: 0.523164, top_k: 0.758359, samples/s: 1339.785 1612678551.755233
train: epoch 20, iter 600, loss: 3.030609, top_1: 0.517344, top_k: 0.752539, samples/s: 1332.363 1612678570.969228
train: epoch 20, iter 700, loss: 3.126920, top_1: 0.514414, top_k: 0.754375, samples/s: 1340.531 1612678590.066144
train: epoch 20, iter 800, loss: 2.959816, top_1: 0.516563, top_k: 0.757227, samples/s: 1331.709 1612678609.2895339
train: epoch 20, iter 900, loss: 3.075830, top_1: 0.522422, top_k: 0.757539, samples/s: 1329.094 1612678628.5507712
train: epoch 20, iter 1000, loss: 2.933056, top_1: 0.515781, top_k: 0.752891, samples/s: 1322.788 1612678647.903909
train: epoch 20, iter 1100, loss: 3.065184, top_1: 0.512422, top_k: 0.750313, samples/s: 1339.318 1612678667.0180311
train: epoch 20, iter 1200, loss: 2.975268, top_1: 0.510391, top_k: 0.751055, samples/s: 1334.339 1612678686.2036068
train: epoch 20, iter 1300, loss: 3.063169, top_1: 0.511133, top_k: 0.753789, samples/s: 1337.913 1612678705.3378665
train: epoch 20, iter 1400, loss: 3.148056, top_1: 0.504844, top_k: 0.745078, samples/s: 1336.377 1612678724.4941797
train: epoch 20, iter 1500, loss: 3.064621, top_1: 0.513281, top_k: 0.755898, samples/s: 1328.952 1612678743.7574446
train: epoch 20, iter 1600, loss: 2.971402, top_1: 0.509453, top_k: 0.747383, samples/s: 1337.158 1612678762.9025955
train: epoch 20, iter 1700, loss: 3.042339, top_1: 0.510039, top_k: 0.749609, samples/s: 1331.134 1612678782.134228
train: epoch 20, iter 1800, loss: 3.137076, top_1: 0.511055, top_k: 0.747930, samples/s: 1329.587 1612678801.388442
train: epoch 20, iter 1900, loss: 3.055061, top_1: 0.515000, top_k: 0.752734, samples/s: 1341.730 1612678820.4681726
train: epoch 20, iter 2000, loss: 3.138296, top_1: 0.510820, top_k: 0.754844, samples/s: 1334.769 1612678839.6476212
train: epoch 20, iter 2100, loss: 3.175877, top_1: 0.509219, top_k: 0.748594, samples/s: 1336.973 1612678858.7952645
train: epoch 20, iter 2200, loss: 3.038948, top_1: 0.511172, top_k: 0.752852, samples/s: 1331.725 1612678878.0185616
train: epoch 20, iter 2300, loss: 3.140588, top_1: 0.514414, top_k: 0.749141, samples/s: 1336.576 1612678897.172043
train: epoch 20, iter 2400, loss: 3.079848, top_1: 0.518125, top_k: 0.757383, samples/s: 1337.620 1612678916.310334
train: epoch 20, iter 2500, loss: 3.080297, top_1: 0.516523, top_k: 0.750430, samples/s: 1334.082 1612678935.4996047
train: epoch 20, iter 2600, loss: 3.031165, top_1: 0.514766, top_k: 0.750352, samples/s: 1338.100 1612678954.6311617
train: epoch 20, iter 2700, loss: 2.990992, top_1: 0.508594, top_k: 0.749141, samples/s: 1328.558 1612678973.900258
train: epoch 20, iter 2800, loss: 2.836787, top_1: 0.512227, top_k: 0.750078, samples/s: 1336.296 1612678993.0576456
train: epoch 20, iter 2900, loss: 2.950689, top_1: 0.510508, top_k: 0.750664, samples/s: 1336.373 1612679012.2139366
train: epoch 20, iter 3000, loss: 3.012872, top_1: 0.511406, top_k: 0.750156, samples/s: 1337.121 1612679031.3595817
train: epoch 20, iter 3100, loss: 2.884938, top_1: 0.514219, top_k: 0.750469, samples/s: 1337.189 1612679050.5042436
train: epoch 20, iter 3200, loss: 3.105724, top_1: 0.512070, top_k: 0.749102, samples/s: 1335.152 1612679069.6780372
train: epoch 20, iter 3300, loss: 3.153423, top_1: 0.511992, top_k: 0.749336, samples/s: 1340.440 1612679088.7763128
train: epoch 20, iter 3400, loss: 3.134664, top_1: 0.512031, top_k: 0.748945, samples/s: 1330.316 1612679108.019826
train: epoch 20, iter 3500, loss: 3.104781, top_1: 0.511406, top_k: 0.751328, samples/s: 1334.066 1612679127.2092955
train: epoch 20, iter 3600, loss: 2.931559, top_1: 0.512305, top_k: 0.755078, samples/s: 1330.640 1612679146.4481153
train: epoch 20, iter 3700, loss: 3.178427, top_1: 0.509258, top_k: 0.748203, samples/s: 1339.737 1612679165.5563743
train: epoch 20, iter 3800, loss: 3.286717, top_1: 0.508672, top_k: 0.743633, samples/s: 1322.263 1612679184.9170992
train: epoch 20, iter 3900, loss: 3.138543, top_1: 0.510469, top_k: 0.747422, samples/s: 1348.603 1612679203.8997164
train: epoch 20, iter 4000, loss: 3.015156, top_1: 0.504687, top_k: 0.746172, samples/s: 1329.861 1612679223.149934
train: epoch 20, iter 4100, loss: 2.982399, top_1: 0.509883, top_k: 0.751875, samples/s: 1334.107 1612679242.3387375
train: epoch 20, iter 4200, loss: 3.183962, top_1: 0.510664, top_k: 0.750391, samples/s: 1340.072 1612679261.4422424
train: epoch 20, iter 4300, loss: 2.920531, top_1: 0.515469, top_k: 0.752461, samples/s: 1335.475 1612679280.611398
train: epoch 20, iter 4400, loss: 3.159862, top_1: 0.512422, top_k: 0.750859, samples/s: 1337.275 1612679299.7548277
train: epoch 20, iter 4500, loss: 3.140145, top_1: 0.510117, top_k: 0.746328, samples/s: 1333.300 1612679318.9553282
train: epoch 20, iter 4600, loss: 3.019319, top_1: 0.509961, top_k: 0.747656, samples/s: 1329.767 1612679338.206747
train: epoch 20, iter 4700, loss: 3.109712, top_1: 0.508359, top_k: 0.743789, samples/s: 1338.021 1612679357.339568
train: epoch 20, iter 4800, loss: 3.231662, top_1: 0.508906, top_k: 0.750156, samples/s: 1337.158 1612679376.484614
train: epoch 20, iter 4900, loss: 3.087100, top_1: 0.507773, top_k: 0.747656, samples/s: 1334.272 1612679395.6710672
train: epoch 20, iter 5000, loss: 2.789950, top_1: 0.514453, top_k: 0.749687, samples/s: 1335.046 1612679414.8464248
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_20.
validation: epoch 20, iter 195, top_1: 0.566086, top_k: 0.808213, samples/s: 2741.523 1612679433.6669035
train: epoch 21, iter 100, loss: 2.980193, top_1: 0.524180, top_k: 0.761367, samples/s: 1359.372 1612679468.619026
train: epoch 21, iter 200, loss: 2.925442, top_1: 0.531289, top_k: 0.764492, samples/s: 1357.688 1612679487.4745884
train: epoch 21, iter 300, loss: 3.033567, top_1: 0.518828, top_k: 0.757188, samples/s: 1359.708 1612679506.3022077
train: epoch 21, iter 400, loss: 3.042384, top_1: 0.522461, top_k: 0.757461, samples/s: 1356.116 1612679525.179691
train: epoch 21, iter 500, loss: 3.087542, top_1: 0.517461, top_k: 0.758008, samples/s: 1336.441 1612679544.3349886
train: epoch 21, iter 600, loss: 3.062439, top_1: 0.521211, top_k: 0.759570, samples/s: 1331.037 1612679563.5681224
train: epoch 21, iter 700, loss: 3.212934, top_1: 0.517305, top_k: 0.755039, samples/s: 1323.760 1612679582.9069521
train: epoch 21, iter 800, loss: 3.041694, top_1: 0.517305, top_k: 0.752773, samples/s: 1329.722 1612679602.1591203
train: epoch 21, iter 900, loss: 3.046490, top_1: 0.516484, top_k: 0.757070, samples/s: 1334.946 1612679621.3359172
train: epoch 21, iter 1000, loss: 2.889650, top_1: 0.514297, top_k: 0.753242, samples/s: 1334.070 1612679640.525292
train: epoch 21, iter 1100, loss: 3.058928, top_1: 0.510352, top_k: 0.750117, samples/s: 1329.741 1612679659.7772307
train: epoch 21, iter 1200, loss: 3.026489, top_1: 0.523984, top_k: 0.759727, samples/s: 1331.472 1612679679.0040102
train: epoch 21, iter 1300, loss: 3.102060, top_1: 0.512891, top_k: 0.752070, samples/s: 1329.585 1612679698.2581275
train: epoch 21, iter 1400, loss: 2.863602, top_1: 0.513828, top_k: 0.751914, samples/s: 1327.128 1612679717.5478935
train: epoch 21, iter 1500, loss: 2.991515, top_1: 0.515781, top_k: 0.750234, samples/s: 1334.474 1612679736.7315252
train: epoch 21, iter 1600, loss: 3.053769, top_1: 0.510273, top_k: 0.750352, samples/s: 1330.518 1612679755.9721003
train: epoch 21, iter 1700, loss: 2.921587, top_1: 0.518047, top_k: 0.749141, samples/s: 1323.116 1612679775.3204076
train: epoch 21, iter 1800, loss: 3.182485, top_1: 0.509570, top_k: 0.752461, samples/s: 1335.382 1612679794.4909065
train: epoch 21, iter 1900, loss: 2.951357, top_1: 0.517383, top_k: 0.756016, samples/s: 1329.025 1612679813.753206
train: epoch 21, iter 2000, loss: 3.230436, top_1: 0.510195, top_k: 0.752148, samples/s: 1337.937 1612679832.8871036
train: epoch 21, iter 2100, loss: 2.897901, top_1: 0.502734, top_k: 0.746328, samples/s: 1324.242 1612679852.2188995
train: epoch 21, iter 2200, loss: 3.186875, top_1: 0.514375, top_k: 0.753477, samples/s: 1331.177 1612679871.4499848
train: epoch 21, iter 2300, loss: 2.960604, top_1: 0.515078, top_k: 0.753203, samples/s: 1333.921 1612679890.6415954
train: epoch 21, iter 2400, loss: 2.933229, top_1: 0.512617, top_k: 0.752617, samples/s: 1333.473 1612679909.8396137
train: epoch 21, iter 2500, loss: 2.986309, top_1: 0.513125, top_k: 0.752695, samples/s: 1331.456 1612679929.06659
train: epoch 21, iter 2600, loss: 3.110810, top_1: 0.511875, top_k: 0.749766, samples/s: 1333.168 1612679948.2689693
train: epoch 21, iter 2700, loss: 3.047307, top_1: 0.520000, top_k: 0.757344, samples/s: 1334.163 1612679967.4570239
train: epoch 21, iter 2800, loss: 3.079838, top_1: 0.512031, top_k: 0.751055, samples/s: 1335.868 1612679986.6206079
train: epoch 21, iter 2900, loss: 3.149835, top_1: 0.510352, top_k: 0.748398, samples/s: 1335.180 1612680005.7940588
train: epoch 21, iter 3000, loss: 3.085402, top_1: 0.512070, top_k: 0.749687, samples/s: 1330.168 1612680025.039776
train: epoch 21, iter 3100, loss: 3.072402, top_1: 0.513281, top_k: 0.749023, samples/s: 1336.099 1612680044.200034
train: epoch 21, iter 3200, loss: 3.117013, top_1: 0.510938, top_k: 0.749570, samples/s: 1331.922 1612680063.420348
train: epoch 21, iter 3300, loss: 3.048558, top_1: 0.508359, top_k: 0.745430, samples/s: 1333.577 1612680082.6168666
train: epoch 21, iter 3400, loss: 2.906308, top_1: 0.517422, top_k: 0.754883, samples/s: 1336.436 1612680101.7722986
train: epoch 21, iter 3500, loss: 2.956550, top_1: 0.511328, top_k: 0.751328, samples/s: 1330.355 1612680121.0153327
train: epoch 21, iter 3600, loss: 2.988588, top_1: 0.508320, top_k: 0.749727, samples/s: 1330.435 1612680140.2570724
train: epoch 21, iter 3700, loss: 3.025052, top_1: 0.514336, top_k: 0.752852, samples/s: 1341.347 1612680159.3423615
train: epoch 21, iter 3800, loss: 2.963269, top_1: 0.516289, top_k: 0.753281, samples/s: 1328.628 1612680178.6104991
train: epoch 21, iter 3900, loss: 2.992014, top_1: 0.518437, top_k: 0.754492, samples/s: 1332.572 1612680197.8213856
train: epoch 21, iter 4000, loss: 3.233504, top_1: 0.512500, top_k: 0.750273, samples/s: 1337.328 1612680216.9640117
train: epoch 21, iter 4100, loss: 2.955886, top_1: 0.513594, top_k: 0.751250, samples/s: 1338.197 1612680236.09429
train: epoch 21, iter 4200, loss: 3.122844, top_1: 0.513945, top_k: 0.749219, samples/s: 1326.689 1612680255.39041
train: epoch 21, iter 4300, loss: 2.958867, top_1: 0.511055, top_k: 0.748984, samples/s: 1339.993 1612680274.49494
train: epoch 21, iter 4400, loss: 2.934870, top_1: 0.513320, top_k: 0.752617, samples/s: 1336.342 1612680293.6520035
train: epoch 21, iter 4500, loss: 3.021097, top_1: 0.510664, top_k: 0.753359, samples/s: 1327.560 1612680312.9353192
train: epoch 21, iter 4600, loss: 2.817440, top_1: 0.508242, top_k: 0.747930, samples/s: 1336.795 1612680332.0855637
train: epoch 21, iter 4700, loss: 2.968886, top_1: 0.509531, top_k: 0.746523, samples/s: 1339.364 1612680351.1990597
train: epoch 21, iter 4800, loss: 3.031462, top_1: 0.510469, top_k: 0.748086, samples/s: 1327.635 1612680370.481478
train: epoch 21, iter 4900, loss: 3.249803, top_1: 0.509141, top_k: 0.746836, samples/s: 1326.264 1612680389.7841547
train: epoch 21, iter 5000, loss: 2.882281, top_1: 0.511836, top_k: 0.752070, samples/s: 1345.220 1612680408.81421
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_21.
validation: epoch 21, iter 195, top_1: 0.556110, top_k: 0.804307, samples/s: 2765.117 1612680427.4469683
train: epoch 22, iter 100, loss: 2.765154, top_1: 0.533242, top_k: 0.768398, samples/s: 1358.343 1612680462.704535
train: epoch 22, iter 200, loss: 2.949008, top_1: 0.512148, top_k: 0.751055, samples/s: 1363.906 1612680481.4741378
train: epoch 22, iter 300, loss: 2.892946, top_1: 0.516758, top_k: 0.760547, samples/s: 1360.473 1612680500.2911038
train: epoch 22, iter 400, loss: 2.980129, top_1: 0.525273, top_k: 0.761680, samples/s: 1359.457 1612680519.1221135
train: epoch 22, iter 500, loss: 3.033475, top_1: 0.520820, top_k: 0.754180, samples/s: 1339.432 1612680538.2346885
train: epoch 22, iter 600, loss: 3.208035, top_1: 0.524023, top_k: 0.760508, samples/s: 1338.958 1612680557.3540332
train: epoch 22, iter 700, loss: 2.929549, top_1: 0.516836, top_k: 0.754414, samples/s: 1338.296 1612680576.4828362
train: epoch 22, iter 800, loss: 3.030757, top_1: 0.519648, top_k: 0.757188, samples/s: 1337.389 1612680595.6246164
train: epoch 22, iter 900, loss: 2.991862, top_1: 0.518477, top_k: 0.756758, samples/s: 1325.454 1612680614.9388425
train: epoch 22, iter 1000, loss: 2.966741, top_1: 0.519883, top_k: 0.756328, samples/s: 1346.115 1612680633.9565136
train: epoch 22, iter 1100, loss: 3.013898, top_1: 0.512813, top_k: 0.754180, samples/s: 1329.881 1612680653.2063503
train: epoch 22, iter 1200, loss: 2.847177, top_1: 0.519180, top_k: 0.756445, samples/s: 1340.134 1612680672.3088706
train: epoch 22, iter 1300, loss: 3.294818, top_1: 0.517227, top_k: 0.758672, samples/s: 1342.438 1612680691.3787196
train: epoch 22, iter 1400, loss: 2.875990, top_1: 0.517891, top_k: 0.752461, samples/s: 1333.192 1612680710.5807004
train: epoch 22, iter 1500, loss: 3.022842, top_1: 0.518789, top_k: 0.755352, samples/s: 1337.425 1612680729.7219875
train: epoch 22, iter 1600, loss: 3.248052, top_1: 0.518867, top_k: 0.756289, samples/s: 1343.136 1612680748.7818677
train: epoch 22, iter 1700, loss: 3.000632, top_1: 0.517266, top_k: 0.755625, samples/s: 1336.402 1612680767.9378026
train: epoch 22, iter 1800, loss: 2.861980, top_1: 0.517344, top_k: 0.754258, samples/s: 1336.047 1612680787.0988588
train: epoch 22, iter 1900, loss: 3.061049, top_1: 0.523398, top_k: 0.756953, samples/s: 1336.869 1612680806.24795
train: epoch 22, iter 2000, loss: 3.124030, top_1: 0.513672, top_k: 0.752188, samples/s: 1336.083 1612680825.4085383
train: epoch 22, iter 2100, loss: 3.080212, top_1: 0.523516, top_k: 0.753867, samples/s: 1342.113 1612680844.4828327
train: epoch 22, iter 2200, loss: 2.859035, top_1: 0.518477, top_k: 0.755273, samples/s: 1336.976 1612680863.630589
train: epoch 22, iter 2300, loss: 2.892771, top_1: 0.514727, top_k: 0.755898, samples/s: 1335.784 1612680882.795417
train: epoch 22, iter 2400, loss: 3.008646, top_1: 0.521523, top_k: 0.753477, samples/s: 1336.511 1612680901.9496377
train: epoch 22, iter 2500, loss: 3.050332, top_1: 0.514492, top_k: 0.750820, samples/s: 1342.218 1612680921.0225816
train: epoch 22, iter 2600, loss: 2.950761, top_1: 0.517070, top_k: 0.756406, samples/s: 1339.928 1612680940.128099
train: epoch 22, iter 2700, loss: 2.783819, top_1: 0.513828, top_k: 0.754102, samples/s: 1331.158 1612680959.3594375
train: epoch 22, iter 2800, loss: 2.919498, top_1: 0.509727, top_k: 0.751914, samples/s: 1343.425 1612680978.4152668
train: epoch 22, iter 2900, loss: 2.978608, top_1: 0.522539, top_k: 0.757539, samples/s: 1334.444 1612680997.599311
train: epoch 22, iter 3000, loss: 3.098655, top_1: 0.517422, top_k: 0.756992, samples/s: 1337.764 1612681016.7356355
train: epoch 22, iter 3100, loss: 2.947610, top_1: 0.515000, top_k: 0.753867, samples/s: 1340.162 1612681035.8378356
train: epoch 22, iter 3200, loss: 2.910297, top_1: 0.515312, top_k: 0.750977, samples/s: 1339.600 1612681054.94799
train: epoch 22, iter 3300, loss: 2.971908, top_1: 0.514414, top_k: 0.751719, samples/s: 1325.740 1612681074.2579944
train: epoch 22, iter 3400, loss: 2.927483, top_1: 0.514375, top_k: 0.750391, samples/s: 1341.384 1612681093.3427136
train: epoch 22, iter 3500, loss: 3.179829, top_1: 0.513828, top_k: 0.753828, samples/s: 1339.558 1612681112.453486
train: epoch 22, iter 3600, loss: 2.991195, top_1: 0.512852, top_k: 0.751289, samples/s: 1339.142 1612681131.5702724
train: epoch 22, iter 3700, loss: 2.907964, top_1: 0.514336, top_k: 0.755625, samples/s: 1340.565 1612681150.6667018
train: epoch 22, iter 3800, loss: 2.974868, top_1: 0.512109, top_k: 0.753359, samples/s: 1339.971 1612681169.7715712
train: epoch 22, iter 3900, loss: 3.053385, top_1: 0.516875, top_k: 0.754141, samples/s: 1335.204 1612681188.9446826
train: epoch 22, iter 4000, loss: 2.999417, top_1: 0.517383, top_k: 0.754023, samples/s: 1334.134 1612681208.1332345
train: epoch 22, iter 4100, loss: 3.014010, top_1: 0.513203, top_k: 0.755664, samples/s: 1337.425 1612681227.2744203
train: epoch 22, iter 4200, loss: 3.164604, top_1: 0.513906, top_k: 0.753711, samples/s: 1342.470 1612681246.3437338
train: epoch 22, iter 4300, loss: 3.122258, top_1: 0.514102, top_k: 0.751133, samples/s: 1339.006 1612681265.4624112
train: epoch 22, iter 4400, loss: 3.331856, top_1: 0.514570, top_k: 0.753320, samples/s: 1331.937 1612681284.6824982
train: epoch 22, iter 4500, loss: 3.030053, top_1: 0.518437, top_k: 0.755703, samples/s: 1335.535 1612681303.8508503
train: epoch 22, iter 4600, loss: 3.058601, top_1: 0.510898, top_k: 0.751016, samples/s: 1333.459 1612681323.0490575
train: epoch 22, iter 4700, loss: 3.126802, top_1: 0.516875, top_k: 0.752812, samples/s: 1339.188 1612681342.1650908
train: epoch 22, iter 4800, loss: 2.748523, top_1: 0.517500, top_k: 0.752891, samples/s: 1341.689 1612681361.2455673
train: epoch 22, iter 4900, loss: 3.119146, top_1: 0.516445, top_k: 0.755078, samples/s: 1341.891 1612681380.3230884
train: epoch 22, iter 5000, loss: 3.049467, top_1: 0.517578, top_k: 0.755117, samples/s: 1338.170 1612681399.4537332
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_22.
validation: epoch 22, iter 195, top_1: 0.536398, top_k: 0.787380, samples/s: 2770.053 1612681418.0440035
train: epoch 23, iter 100, loss: 2.854825, top_1: 0.528203, top_k: 0.764219, samples/s: 1365.535 1612681452.8198457
train: epoch 23, iter 200, loss: 2.867899, top_1: 0.530195, top_k: 0.764141, samples/s: 1361.196 1612681471.626823
train: epoch 23, iter 300, loss: 2.876605, top_1: 0.518828, top_k: 0.756289, samples/s: 1360.975 1612681490.4368834
train: epoch 23, iter 400, loss: 2.944252, top_1: 0.523438, top_k: 0.758789, samples/s: 1353.855 1612681509.3458178
train: epoch 23, iter 500, loss: 2.872601, top_1: 0.518437, top_k: 0.755195, samples/s: 1343.679 1612681528.397991
train: epoch 23, iter 600, loss: 2.845407, top_1: 0.519102, top_k: 0.758125, samples/s: 1336.664 1612681547.5502956
train: epoch 23, iter 700, loss: 3.009027, top_1: 0.523516, top_k: 0.756211, samples/s: 1341.061 1612681566.6394522
train: epoch 23, iter 800, loss: 2.976056, top_1: 0.518242, top_k: 0.756445, samples/s: 1326.853 1612681585.9332454
train: epoch 23, iter 900, loss: 2.846852, top_1: 0.519766, top_k: 0.757695, samples/s: 1334.481 1612681605.1167605
train: epoch 23, iter 1000, loss: 3.114491, top_1: 0.524727, top_k: 0.761836, samples/s: 1338.324 1612681624.2451193
train: epoch 23, iter 1100, loss: 3.007875, top_1: 0.521133, top_k: 0.759648, samples/s: 1335.825 1612681643.4093275
train: epoch 23, iter 1200, loss: 2.893960, top_1: 0.519648, top_k: 0.759961, samples/s: 1332.339 1612681662.6236699
train: epoch 23, iter 1300, loss: 2.958951, top_1: 0.520234, top_k: 0.755859, samples/s: 1331.878 1612681681.8447623
train: epoch 23, iter 1400, loss: 2.958424, top_1: 0.518672, top_k: 0.755781, samples/s: 1333.802 1612681701.0378757
train: epoch 23, iter 1500, loss: 2.867019, top_1: 0.522813, top_k: 0.759805, samples/s: 1337.102 1612681720.183746
train: epoch 23, iter 1600, loss: 2.962432, top_1: 0.522969, top_k: 0.760742, samples/s: 1334.127 1612681739.372325
train: epoch 23, iter 1700, loss: 3.071459, top_1: 0.518828, top_k: 0.758789, samples/s: 1339.077 1612681758.490018
train: epoch 23, iter 1800, loss: 3.102089, top_1: 0.512539, top_k: 0.750234, samples/s: 1329.147 1612681777.7504327
train: epoch 23, iter 1900, loss: 3.208480, top_1: 0.512891, top_k: 0.750781, samples/s: 1340.418 1612681796.849017
train: epoch 23, iter 2000, loss: 2.755187, top_1: 0.518984, top_k: 0.753633, samples/s: 1336.649 1612681816.0013416
train: epoch 23, iter 2100, loss: 2.974683, top_1: 0.513437, top_k: 0.752305, samples/s: 1335.370 1612681835.1720483
train: epoch 23, iter 2200, loss: 2.973498, top_1: 0.517852, top_k: 0.757383, samples/s: 1336.451 1612681854.327245
train: epoch 23, iter 2300, loss: 3.182181, top_1: 0.515742, top_k: 0.754258, samples/s: 1334.167 1612681873.515293
train: epoch 23, iter 2400, loss: 2.895203, top_1: 0.521836, top_k: 0.758359, samples/s: 1335.250 1612681892.6876812
train: epoch 23, iter 2500, loss: 3.096980, top_1: 0.523906, top_k: 0.756133, samples/s: 1332.802 1612681911.8953383
train: epoch 23, iter 2600, loss: 2.998456, top_1: 0.519219, top_k: 0.756875, samples/s: 1336.704 1612681931.046921
train: epoch 23, iter 2700, loss: 3.012248, top_1: 0.519805, top_k: 0.756055, samples/s: 1334.167 1612681950.2349617
train: epoch 23, iter 2800, loss: 2.989206, top_1: 0.519609, top_k: 0.757305, samples/s: 1333.974 1612681969.4257052
train: epoch 23, iter 2900, loss: 2.930454, top_1: 0.524492, top_k: 0.757617, samples/s: 1336.672 1612681988.577797
train: epoch 23, iter 3000, loss: 2.909925, top_1: 0.522813, top_k: 0.757969, samples/s: 1337.154 1612682007.7228909
train: epoch 23, iter 3100, loss: 3.090854, top_1: 0.517500, top_k: 0.758164, samples/s: 1335.165 1612682026.8965611
train: epoch 23, iter 3200, loss: 2.992234, top_1: 0.518086, top_k: 0.753711, samples/s: 1333.254 1612682046.0977066
train: epoch 23, iter 3300, loss: 3.098102, top_1: 0.515820, top_k: 0.753437, samples/s: 1336.883 1612682065.246718
train: epoch 23, iter 3400, loss: 2.827553, top_1: 0.515039, top_k: 0.754727, samples/s: 1336.157 1612682084.4062026
train: epoch 23, iter 3500, loss: 3.038462, top_1: 0.516680, top_k: 0.754023, samples/s: 1327.989 1612682103.683467
train: epoch 23, iter 3600, loss: 3.197928, top_1: 0.512266, top_k: 0.757266, samples/s: 1333.530 1612682122.880585
train: epoch 23, iter 3700, loss: 3.012356, top_1: 0.516406, top_k: 0.756016, samples/s: 1338.519 1612682142.0062754
train: epoch 23, iter 3800, loss: 3.231318, top_1: 0.515117, top_k: 0.754883, samples/s: 1335.245 1612682161.178732
train: epoch 23, iter 3900, loss: 2.895209, top_1: 0.517891, top_k: 0.756250, samples/s: 1333.452 1612682180.3770223
train: epoch 23, iter 4000, loss: 2.990992, top_1: 0.521250, top_k: 0.757734, samples/s: 1336.974 1612682199.524789
train: epoch 23, iter 4100, loss: 3.116832, top_1: 0.519141, top_k: 0.756875, samples/s: 1333.923 1612682218.7163057
train: epoch 23, iter 4200, loss: 2.834416, top_1: 0.516680, top_k: 0.757227, samples/s: 1334.974 1612682237.8926945
train: epoch 23, iter 4300, loss: 3.012626, top_1: 0.516211, top_k: 0.750195, samples/s: 1335.068 1612682257.0677047
train: epoch 23, iter 4400, loss: 2.982142, top_1: 0.515781, top_k: 0.748828, samples/s: 1332.813 1612682276.2752748
train: epoch 23, iter 4500, loss: 2.948956, top_1: 0.513633, top_k: 0.752461, samples/s: 1336.900 1612682295.4240024
train: epoch 23, iter 4600, loss: 2.794378, top_1: 0.522305, top_k: 0.755508, samples/s: 1336.916 1612682314.5725744
train: epoch 23, iter 4700, loss: 2.933866, top_1: 0.514922, top_k: 0.751797, samples/s: 1339.150 1612682333.6892562
train: epoch 23, iter 4800, loss: 3.113924, top_1: 0.519102, top_k: 0.754375, samples/s: 1334.813 1612682352.8678453
train: epoch 23, iter 4900, loss: 2.999460, top_1: 0.512422, top_k: 0.752617, samples/s: 1337.284 1612682372.011184
train: epoch 23, iter 5000, loss: 2.843808, top_1: 0.515508, top_k: 0.751953, samples/s: 1338.144 1612682391.1421347
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_23.
validation: epoch 23, iter 195, top_1: 0.576062, top_k: 0.814804, samples/s: 2751.151 1612682409.8580854
train: epoch 24, iter 100, loss: 2.968051, top_1: 0.529531, top_k: 0.764687, samples/s: 1357.125 1612682444.5978258
train: epoch 24, iter 200, loss: 3.086010, top_1: 0.527344, top_k: 0.771719, samples/s: 1361.074 1612682463.4068503
train: epoch 24, iter 300, loss: 3.078053, top_1: 0.522305, top_k: 0.759219, samples/s: 1358.204 1612682482.254886
train: epoch 24, iter 400, loss: 2.921219, top_1: 0.529531, top_k: 0.765742, samples/s: 1351.644 1612682501.1951954
train: epoch 24, iter 500, loss: 2.947285, top_1: 0.527070, top_k: 0.758516, samples/s: 1333.352 1612682520.3946285
train: epoch 24, iter 600, loss: 3.150236, top_1: 0.525586, top_k: 0.761172, samples/s: 1338.838 1612682539.515567
train: epoch 24, iter 700, loss: 3.005622, top_1: 0.517305, top_k: 0.755742, samples/s: 1337.923 1612682558.64971
train: epoch 24, iter 800, loss: 3.045086, top_1: 0.522539, top_k: 0.759570, samples/s: 1336.473 1612682577.8046303
train: epoch 24, iter 900, loss: 2.993313, top_1: 0.520117, top_k: 0.757422, samples/s: 1338.676 1612682596.927974
train: epoch 24, iter 1000, loss: 2.904414, top_1: 0.519375, top_k: 0.760938, samples/s: 1330.845 1612682616.1638887
train: epoch 24, iter 1100, loss: 3.092801, top_1: 0.519883, top_k: 0.755273, samples/s: 1330.683 1612682635.4021196
train: epoch 24, iter 1200, loss: 3.164270, top_1: 0.521523, top_k: 0.761016, samples/s: 1336.112 1612682654.562261
train: epoch 24, iter 1300, loss: 2.930521, top_1: 0.525078, top_k: 0.758477, samples/s: 1337.340 1612682673.7046847
train: epoch 24, iter 1400, loss: 2.907468, top_1: 0.521875, top_k: 0.756484, samples/s: 1336.246 1612682692.862844
train: epoch 24, iter 1500, loss: 3.102835, top_1: 0.517227, top_k: 0.755430, samples/s: 1337.318 1612682712.0056853
train: epoch 24, iter 1600, loss: 3.075734, top_1: 0.525898, top_k: 0.760273, samples/s: 1336.328 1612682731.1625867
train: epoch 24, iter 1700, loss: 2.961460, top_1: 0.521289, top_k: 0.757773, samples/s: 1326.417 1612682750.462725
train: epoch 24, iter 1800, loss: 2.940533, top_1: 0.519102, top_k: 0.755352, samples/s: 1334.795 1612682769.6417542
train: epoch 24, iter 1900, loss: 2.903102, top_1: 0.521719, top_k: 0.755625, samples/s: 1335.878 1612682788.8051915
train: epoch 24, iter 2000, loss: 3.213042, top_1: 0.514531, top_k: 0.753984, samples/s: 1336.476 1612682807.9599743
train: epoch 24, iter 2100, loss: 2.759920, top_1: 0.523711, top_k: 0.758672, samples/s: 1335.643 1612682827.1268132
train: epoch 24, iter 2200, loss: 2.850401, top_1: 0.527500, top_k: 0.758437, samples/s: 1338.692 1612682846.2499735
train: epoch 24, iter 2300, loss: 3.126848, top_1: 0.520781, top_k: 0.760703, samples/s: 1331.962 1612682865.4696858
train: epoch 24, iter 2400, loss: 2.931815, top_1: 0.520703, top_k: 0.756094, samples/s: 1334.686 1612682884.6502903
train: epoch 24, iter 2500, loss: 3.032094, top_1: 0.523594, top_k: 0.756367, samples/s: 1338.265 1612682903.7795527
train: epoch 24, iter 2600, loss: 2.919938, top_1: 0.526055, top_k: 0.759609, samples/s: 1335.244 1612682922.9520314
train: epoch 24, iter 2700, loss: 3.177045, top_1: 0.522422, top_k: 0.756641, samples/s: 1341.849 1612682942.0301406
train: epoch 24, iter 2800, loss: 3.197881, top_1: 0.519922, top_k: 0.762188, samples/s: 1332.986 1612682961.2352364
train: epoch 24, iter 2900, loss: 2.898614, top_1: 0.525195, top_k: 0.759727, samples/s: 1336.363 1612682980.3916712
train: epoch 24, iter 3000, loss: 2.969696, top_1: 0.522695, top_k: 0.756953, samples/s: 1336.627 1612682999.54432
train: epoch 24, iter 3100, loss: 2.971985, top_1: 0.516367, top_k: 0.757773, samples/s: 1338.640 1612683018.6682703
train: epoch 24, iter 3200, loss: 2.846030, top_1: 0.519141, top_k: 0.756328, samples/s: 1332.016 1612683037.887217
train: epoch 24, iter 3300, loss: 3.063793, top_1: 0.522109, top_k: 0.759297, samples/s: 1336.773 1612683057.0378292
train: epoch 24, iter 3400, loss: 2.868464, top_1: 0.522617, top_k: 0.759727, samples/s: 1337.369 1612683076.1799047
train: epoch 24, iter 3500, loss: 2.892523, top_1: 0.520156, top_k: 0.757891, samples/s: 1331.817 1612683095.4017189
train: epoch 24, iter 3600, loss: 3.094383, top_1: 0.517070, top_k: 0.756016, samples/s: 1337.583 1612683114.5407305
train: epoch 24, iter 3700, loss: 2.999334, top_1: 0.512734, top_k: 0.751953, samples/s: 1333.728 1612683133.7350104
train: epoch 24, iter 3800, loss: 2.875198, top_1: 0.524414, top_k: 0.758711, samples/s: 1343.987 1612683152.7828486
train: epoch 24, iter 3900, loss: 2.992880, top_1: 0.521719, top_k: 0.757930, samples/s: 1329.244 1612683172.041935
train: epoch 24, iter 4000, loss: 2.845154, top_1: 0.519766, top_k: 0.756523, samples/s: 1329.908 1612683191.2913451
train: epoch 24, iter 4100, loss: 3.004468, top_1: 0.517227, top_k: 0.757109, samples/s: 1336.685 1612683210.4431973
train: epoch 24, iter 4200, loss: 3.164480, top_1: 0.520234, top_k: 0.757461, samples/s: 1342.948 1612683229.5057595
train: epoch 24, iter 4300, loss: 3.147282, top_1: 0.513633, top_k: 0.754570, samples/s: 1338.481 1612683248.631914
train: epoch 24, iter 4400, loss: 2.784513, top_1: 0.515391, top_k: 0.755234, samples/s: 1339.856 1612683267.7384312
train: epoch 24, iter 4500, loss: 2.955691, top_1: 0.512656, top_k: 0.750820, samples/s: 1330.729 1612683286.9760518
train: epoch 24, iter 4600, loss: 3.273054, top_1: 0.522930, top_k: 0.760312, samples/s: 1341.017 1612683306.0660412
train: epoch 24, iter 4700, loss: 3.018012, top_1: 0.515000, top_k: 0.753945, samples/s: 1331.352 1612683325.2946591
train: epoch 24, iter 4800, loss: 3.108057, top_1: 0.515469, top_k: 0.754141, samples/s: 1342.752 1612683344.3599045
train: epoch 24, iter 4900, loss: 2.880935, top_1: 0.517656, top_k: 0.750898, samples/s: 1335.463 1612683363.529324
train: epoch 24, iter 5000, loss: 3.227633, top_1: 0.521953, top_k: 0.758906, samples/s: 1336.303 1612683382.6866837
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_24.
validation: epoch 24, iter 195, top_1: 0.571835, top_k: 0.810256, samples/s: 2756.826 1612683401.3633335
train: epoch 25, iter 100, loss: 2.837035, top_1: 0.535039, top_k: 0.771094, samples/s: 1357.509 1612683436.8331356
train: epoch 25, iter 200, loss: 3.010361, top_1: 0.529180, top_k: 0.763242, samples/s: 1351.580 1612683455.7739663
train: epoch 25, iter 300, loss: 3.019402, top_1: 0.524297, top_k: 0.761367, samples/s: 1360.818 1612683474.5861166
train: epoch 25, iter 400, loss: 3.057944, top_1: 0.530703, top_k: 0.762852, samples/s: 1355.785 1612683493.4681773
train: epoch 25, iter 500, loss: 3.050321, top_1: 0.521406, top_k: 0.759609, samples/s: 1336.747 1612683512.6191378
train: epoch 25, iter 600, loss: 2.626796, top_1: 0.526172, top_k: 0.762539, samples/s: 1332.728 1612683531.8278236
train: epoch 25, iter 700, loss: 2.874815, top_1: 0.521680, top_k: 0.756055, samples/s: 1320.172 1612683551.2193854
train: epoch 25, iter 800, loss: 3.112945, top_1: 0.527852, top_k: 0.765156, samples/s: 1330.651 1612683570.4579601
train: epoch 25, iter 900, loss: 2.982956, top_1: 0.519570, top_k: 0.758789, samples/s: 1324.366 1612683589.7880473
train: epoch 25, iter 1000, loss: 3.164831, top_1: 0.525859, top_k: 0.761289, samples/s: 1335.349 1612683608.95896
train: epoch 25, iter 1100, loss: 3.002224, top_1: 0.521719, top_k: 0.761445, samples/s: 1330.555 1612683628.199104
train: epoch 25, iter 1200, loss: 3.004784, top_1: 0.525039, top_k: 0.760156, samples/s: 1323.835 1612683647.5368583
train: epoch 25, iter 1300, loss: 2.890473, top_1: 0.525625, top_k: 0.763242, samples/s: 1339.503 1612683666.6483812
train: epoch 25, iter 1400, loss: 3.043402, top_1: 0.524102, top_k: 0.755703, samples/s: 1328.483 1612683685.918468
train: epoch 25, iter 1500, loss: 2.963311, top_1: 0.522188, top_k: 0.758750, samples/s: 1328.868 1612683705.1829994
train: epoch 25, iter 1600, loss: 2.999339, top_1: 0.524727, top_k: 0.764023, samples/s: 1330.173 1612683724.428611
train: epoch 25, iter 1700, loss: 3.145441, top_1: 0.528789, top_k: 0.762773, samples/s: 1330.634 1612683743.6675563
train: epoch 25, iter 1800, loss: 2.907358, top_1: 0.529102, top_k: 0.766250, samples/s: 1330.092 1612683762.9143414
train: epoch 25, iter 1900, loss: 3.170807, top_1: 0.519883, top_k: 0.760781, samples/s: 1337.366 1612683782.0564644
train: epoch 25, iter 2000, loss: 3.054474, top_1: 0.519805, top_k: 0.759727, samples/s: 1323.544 1612683801.3985252
train: epoch 25, iter 2100, loss: 3.106033, top_1: 0.517930, top_k: 0.754102, samples/s: 1332.364 1612683820.612479
train: epoch 25, iter 2200, loss: 3.093380, top_1: 0.514141, top_k: 0.752109, samples/s: 1334.182 1612683839.8002293
train: epoch 25, iter 2300, loss: 2.818728, top_1: 0.517969, top_k: 0.758398, samples/s: 1329.125 1612683859.0611186
train: epoch 25, iter 2400, loss: 3.106682, top_1: 0.522148, top_k: 0.759805, samples/s: 1331.615 1612683878.285824
train: epoch 25, iter 2500, loss: 2.887716, top_1: 0.519375, top_k: 0.755508, samples/s: 1328.367 1612683897.5575922
train: epoch 25, iter 2600, loss: 2.873062, top_1: 0.523945, top_k: 0.762773, samples/s: 1337.517 1612683916.6975784
train: epoch 25, iter 2700, loss: 2.931185, top_1: 0.522578, top_k: 0.758125, samples/s: 1328.141 1612683935.972629
train: epoch 25, iter 2800, loss: 2.866540, top_1: 0.525898, top_k: 0.762422, samples/s: 1327.230 1612683955.2609053
train: epoch 25, iter 2900, loss: 2.896301, top_1: 0.520977, top_k: 0.758398, samples/s: 1335.471 1612683974.430202
train: epoch 25, iter 3000, loss: 3.160390, top_1: 0.526094, top_k: 0.760469, samples/s: 1326.777 1612683993.7250056
train: epoch 25, iter 3100, loss: 2.980084, top_1: 0.527031, top_k: 0.758906, samples/s: 1330.866 1612684012.9606526
train: epoch 25, iter 3200, loss: 2.932093, top_1: 0.522227, top_k: 0.758281, samples/s: 1330.315 1612684032.2042217
train: epoch 25, iter 3300, loss: 3.031844, top_1: 0.523125, top_k: 0.755000, samples/s: 1335.436 1612684051.3740387
train: epoch 25, iter 3400, loss: 2.937638, top_1: 0.527227, top_k: 0.759727, samples/s: 1335.026 1612684070.5496361
train: epoch 25, iter 3500, loss: 3.050830, top_1: 0.522930, top_k: 0.759766, samples/s: 1319.993 1612684089.9436746
train: epoch 25, iter 3600, loss: 2.985345, top_1: 0.518477, top_k: 0.755117, samples/s: 1338.826 1612684109.0649056
train: epoch 25, iter 3700, loss: 2.979032, top_1: 0.517383, top_k: 0.757148, samples/s: 1325.004 1612684128.385587
train: epoch 25, iter 3800, loss: 3.045561, top_1: 0.521719, top_k: 0.761719, samples/s: 1334.502 1612684147.5688071
train: epoch 25, iter 3900, loss: 3.084956, top_1: 0.526484, top_k: 0.754336, samples/s: 1335.411 1612684166.7389178
train: epoch 25, iter 4000, loss: 3.215413, top_1: 0.523047, top_k: 0.758125, samples/s: 1327.627 1612684186.0213976
train: epoch 25, iter 4100, loss: 2.881612, top_1: 0.522148, top_k: 0.758867, samples/s: 1329.545 1612684205.2762272
train: epoch 25, iter 4200, loss: 2.971548, top_1: 0.519453, top_k: 0.759922, samples/s: 1334.954 1612684224.4528563
train: epoch 25, iter 4300, loss: 3.053154, top_1: 0.521094, top_k: 0.758398, samples/s: 1331.272 1612684243.6825883
train: epoch 25, iter 4400, loss: 3.055879, top_1: 0.525742, top_k: 0.760195, samples/s: 1329.663 1612684262.9355934
train: epoch 25, iter 4500, loss: 3.006299, top_1: 0.520742, top_k: 0.758398, samples/s: 1338.494 1612684282.0615582
train: epoch 25, iter 4600, loss: 2.914844, top_1: 0.522656, top_k: 0.758086, samples/s: 1330.431 1612684301.3034468
train: epoch 25, iter 4700, loss: 2.964067, top_1: 0.521797, top_k: 0.757852, samples/s: 1328.730 1612684320.5700336
train: epoch 25, iter 4800, loss: 3.191727, top_1: 0.518672, top_k: 0.756992, samples/s: 1331.410 1612684339.7976606
train: epoch 25, iter 4900, loss: 3.008657, top_1: 0.524023, top_k: 0.754687, samples/s: 1333.178 1612684358.9998806
train: epoch 25, iter 5000, loss: 3.059536, top_1: 0.519844, top_k: 0.758984, samples/s: 1333.296 1612684378.200461
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_25.
validation: epoch 25, iter 195, top_1: 0.576623, top_k: 0.819271, samples/s: 2794.308 1612684396.6280012
train: epoch 26, iter 100, loss: 2.887438, top_1: 0.527969, top_k: 0.765469, samples/s: 1361.265 1612684431.9419448
train: epoch 26, iter 200, loss: 3.011883, top_1: 0.533789, top_k: 0.766797, samples/s: 1361.835 1612684450.7403002
train: epoch 26, iter 300, loss: 2.987742, top_1: 0.529023, top_k: 0.765664, samples/s: 1357.411 1612684469.5994558
train: epoch 26, iter 400, loss: 2.821913, top_1: 0.536602, top_k: 0.770117, samples/s: 1354.993 1612684488.4925878
train: epoch 26, iter 500, loss: 3.200606, top_1: 0.534375, top_k: 0.765156, samples/s: 1337.738 1612684507.629322
train: epoch 26, iter 600, loss: 3.206973, top_1: 0.526211, top_k: 0.761797, samples/s: 1325.066 1612684526.9491866
train: epoch 26, iter 700, loss: 3.096239, top_1: 0.529336, top_k: 0.764258, samples/s: 1336.152 1612684546.108611
train: epoch 26, iter 800, loss: 2.907887, top_1: 0.525508, top_k: 0.766953, samples/s: 1326.453 1612684565.408276
train: epoch 26, iter 900, loss: 3.033826, top_1: 0.524062, top_k: 0.762344, samples/s: 1339.565 1612684584.5188775
train: epoch 26, iter 1000, loss: 2.944021, top_1: 0.529844, top_k: 0.761875, samples/s: 1334.152 1612684603.707145
train: epoch 26, iter 1100, loss: 2.785684, top_1: 0.526641, top_k: 0.765781, samples/s: 1331.695 1612684622.9307897
train: epoch 26, iter 1200, loss: 3.357177, top_1: 0.526445, top_k: 0.765352, samples/s: 1336.508 1612684642.0851202
train: epoch 26, iter 1300, loss: 2.985850, top_1: 0.524297, top_k: 0.760508, samples/s: 1332.743 1612684661.2935896
train: epoch 26, iter 1400, loss: 3.029689, top_1: 0.519492, top_k: 0.760469, samples/s: 1332.309 1612684680.50838
train: epoch 26, iter 1500, loss: 3.203691, top_1: 0.523633, top_k: 0.758672, samples/s: 1333.146 1612684699.7111063
train: epoch 26, iter 1600, loss: 2.981896, top_1: 0.529570, top_k: 0.764414, samples/s: 1333.674 1612684718.9062614
train: epoch 26, iter 1700, loss: 3.002231, top_1: 0.518555, top_k: 0.755781, samples/s: 1333.495 1612684738.1038735
train: epoch 26, iter 1800, loss: 3.015990, top_1: 0.526953, top_k: 0.760078, samples/s: 1333.293 1612684757.304394
train: epoch 26, iter 1900, loss: 3.021074, top_1: 0.528906, top_k: 0.758672, samples/s: 1337.076 1612684776.4507082
train: epoch 26, iter 2000, loss: 2.731830, top_1: 0.522773, top_k: 0.760391, samples/s: 1332.345 1612684795.6649554
train: epoch 26, iter 2100, loss: 3.005686, top_1: 0.523125, top_k: 0.759727, samples/s: 1334.371 1612684814.8499672
train: epoch 26, iter 2200, loss: 2.757717, top_1: 0.521719, top_k: 0.760742, samples/s: 1332.255 1612684834.0655575
train: epoch 26, iter 2300, loss: 3.118634, top_1: 0.527813, top_k: 0.762422, samples/s: 1333.828 1612684853.2583673
train: epoch 26, iter 2400, loss: 2.994171, top_1: 0.521563, top_k: 0.758711, samples/s: 1332.351 1612684872.4725296
train: epoch 26, iter 2500, loss: 3.202676, top_1: 0.521953, top_k: 0.762188, samples/s: 1335.533 1612684891.6409607
train: epoch 26, iter 2600, loss: 3.021137, top_1: 0.524961, top_k: 0.761836, samples/s: 1333.740 1612684910.8350816
train: epoch 26, iter 2700, loss: 3.121972, top_1: 0.520977, top_k: 0.761055, samples/s: 1337.091 1612684929.981149
train: epoch 26, iter 2800, loss: 3.045452, top_1: 0.523438, top_k: 0.761250, samples/s: 1337.731 1612684949.1179905
train: epoch 26, iter 2900, loss: 3.164209, top_1: 0.520117, top_k: 0.759531, samples/s: 1332.377 1612684968.3317647
train: epoch 26, iter 3000, loss: 3.021234, top_1: 0.528125, top_k: 0.761445, samples/s: 1330.060 1612684987.5790207
train: epoch 26, iter 3100, loss: 2.920377, top_1: 0.522813, top_k: 0.760938, samples/s: 1331.441 1612685006.806317
train: epoch 26, iter 3200, loss: 3.095565, top_1: 0.524297, top_k: 0.761367, samples/s: 1332.770 1612685026.0144272
train: epoch 26, iter 3300, loss: 3.105971, top_1: 0.522891, top_k: 0.759883, samples/s: 1329.161 1612685045.274786
train: epoch 26, iter 3400, loss: 3.143363, top_1: 0.521211, top_k: 0.757070, samples/s: 1342.740 1612685064.3401794
train: epoch 26, iter 3500, loss: 3.005529, top_1: 0.519805, top_k: 0.758477, samples/s: 1337.789 1612685083.4762373
train: epoch 26, iter 3600, loss: 3.032339, top_1: 0.518711, top_k: 0.760195, samples/s: 1339.906 1612685102.5820756
train: epoch 26, iter 3700, loss: 3.075318, top_1: 0.521992, top_k: 0.757148, samples/s: 1325.493 1612685121.89562
train: epoch 26, iter 3800, loss: 2.868255, top_1: 0.524062, top_k: 0.758945, samples/s: 1330.461 1612685141.1370542
train: epoch 26, iter 3900, loss: 2.872464, top_1: 0.525977, top_k: 0.760938, samples/s: 1339.904 1612685160.2429047
train: epoch 26, iter 4000, loss: 3.144163, top_1: 0.523164, top_k: 0.752422, samples/s: 1335.238 1612685179.4155436
train: epoch 26, iter 4100, loss: 2.894722, top_1: 0.521719, top_k: 0.759180, samples/s: 1331.016 1612685198.6489244
train: epoch 26, iter 4200, loss: 3.180179, top_1: 0.517188, top_k: 0.754961, samples/s: 1341.266 1612685217.735375
train: epoch 26, iter 4300, loss: 3.088597, top_1: 0.525547, top_k: 0.763867, samples/s: 1334.267 1612685236.9219525
train: epoch 26, iter 4400, loss: 2.954659, top_1: 0.519844, top_k: 0.755820, samples/s: 1333.556 1612685256.118791
train: epoch 26, iter 4500, loss: 2.925263, top_1: 0.519883, top_k: 0.759570, samples/s: 1336.764 1612685275.2695143
train: epoch 26, iter 4600, loss: 3.021560, top_1: 0.522500, top_k: 0.757422, samples/s: 1334.495 1612685294.4528344
train: epoch 26, iter 4700, loss: 3.090881, top_1: 0.518984, top_k: 0.755039, samples/s: 1334.617 1612685313.6343687
train: epoch 26, iter 4800, loss: 3.083885, top_1: 0.518437, top_k: 0.758828, samples/s: 1339.649 1612685332.7437747
train: epoch 26, iter 4900, loss: 3.137947, top_1: 0.524180, top_k: 0.759297, samples/s: 1335.536 1612685351.9121735
train: epoch 26, iter 5000, loss: 2.874141, top_1: 0.522656, top_k: 0.758437, samples/s: 1335.628 1612685371.0791893
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_26.
validation: epoch 26, iter 195, top_1: 0.579107, top_k: 0.816326, samples/s: 2825.775 1612685389.3214388
train: epoch 27, iter 100, loss: 2.878430, top_1: 0.538320, top_k: 0.771914, samples/s: 1361.578 1612685424.5543628
train: epoch 27, iter 200, loss: 3.081076, top_1: 0.528750, top_k: 0.760977, samples/s: 1362.544 1612685443.342727
train: epoch 27, iter 300, loss: 3.011393, top_1: 0.534727, top_k: 0.769648, samples/s: 1358.213 1612685462.191127
train: epoch 27, iter 400, loss: 3.045090, top_1: 0.529180, top_k: 0.764219, samples/s: 1354.681 1612685481.08849
train: epoch 27, iter 500, loss: 2.860403, top_1: 0.530000, top_k: 0.766328, samples/s: 1339.692 1612685500.1973379
train: epoch 27, iter 600, loss: 3.012153, top_1: 0.527070, top_k: 0.767461, samples/s: 1326.370 1612685519.4982123
train: epoch 27, iter 700, loss: 2.979880, top_1: 0.530781, top_k: 0.764570, samples/s: 1336.042 1612685538.6592147
train: epoch 27, iter 800, loss: 3.086986, top_1: 0.529727, top_k: 0.764258, samples/s: 1332.001 1612685557.878466
train: epoch 27, iter 900, loss: 2.888928, top_1: 0.527305, top_k: 0.765625, samples/s: 1331.544 1612685577.1042902
train: epoch 27, iter 1000, loss: 3.048929, top_1: 0.535469, top_k: 0.768203, samples/s: 1334.594 1612685596.286138
train: epoch 27, iter 1100, loss: 2.963414, top_1: 0.527070, top_k: 0.764492, samples/s: 1335.966 1612685615.4482894
train: epoch 27, iter 1200, loss: 2.953122, top_1: 0.522305, top_k: 0.760703, samples/s: 1335.643 1612685634.6151042
train: epoch 27, iter 1300, loss: 3.081791, top_1: 0.528906, top_k: 0.761563, samples/s: 1333.540 1612685653.8120935
train: epoch 27, iter 1400, loss: 2.743057, top_1: 0.523008, top_k: 0.761875, samples/s: 1331.776 1612685673.0345418
train: epoch 27, iter 1500, loss: 2.950887, top_1: 0.529141, top_k: 0.764609, samples/s: 1335.998 1612685692.1962159
train: epoch 27, iter 1600, loss: 3.057589, top_1: 0.519336, top_k: 0.760312, samples/s: 1332.940 1612685711.401889
train: epoch 27, iter 1700, loss: 2.912697, top_1: 0.524766, top_k: 0.760820, samples/s: 1333.815 1612685730.5950007
train: epoch 27, iter 1800, loss: 3.074705, top_1: 0.530703, top_k: 0.761445, samples/s: 1330.909 1612685749.8299797
train: epoch 27, iter 1900, loss: 3.043272, top_1: 0.527695, top_k: 0.764531, samples/s: 1339.764 1612685768.9378304
train: epoch 27, iter 2000, loss: 2.933427, top_1: 0.531914, top_k: 0.765469, samples/s: 1335.067 1612685788.1128519
train: epoch 27, iter 2100, loss: 3.110343, top_1: 0.521289, top_k: 0.758047, samples/s: 1327.167 1612685807.4020557
train: epoch 27, iter 2200, loss: 2.833467, top_1: 0.525820, top_k: 0.760820, samples/s: 1339.083 1612685826.5196555
train: epoch 27, iter 2300, loss: 3.120692, top_1: 0.523125, top_k: 0.761328, samples/s: 1333.859 1612685845.7121072
train: epoch 27, iter 2400, loss: 2.921578, top_1: 0.524492, top_k: 0.760977, samples/s: 1334.954 1612685864.888827
train: epoch 27, iter 2500, loss: 3.086337, top_1: 0.527109, top_k: 0.765312, samples/s: 1329.910 1612685884.1381545
train: epoch 27, iter 2600, loss: 3.027601, top_1: 0.525859, top_k: 0.759023, samples/s: 1330.484 1612685903.379279
train: epoch 27, iter 2700, loss: 2.972299, top_1: 0.524062, top_k: 0.758828, samples/s: 1336.612 1612685922.532173
train: epoch 27, iter 2800, loss: 2.962733, top_1: 0.529141, top_k: 0.767305, samples/s: 1332.997 1612685941.7371228
train: epoch 27, iter 2900, loss: 3.161562, top_1: 0.530078, top_k: 0.762070, samples/s: 1340.404 1612685960.8357427
train: epoch 27, iter 3000, loss: 2.930783, top_1: 0.523047, top_k: 0.760469, samples/s: 1333.901 1612685980.0275755
train: epoch 27, iter 3100, loss: 3.026414, top_1: 0.525391, top_k: 0.762266, samples/s: 1334.276 1612685999.2140477
train: epoch 27, iter 3200, loss: 3.083933, top_1: 0.528086, top_k: 0.764180, samples/s: 1336.839 1612686018.3637047
train: epoch 27, iter 3300, loss: 3.080081, top_1: 0.526445, top_k: 0.764492, samples/s: 1335.809 1612686037.5280774
train: epoch 27, iter 3400, loss: 3.026168, top_1: 0.529492, top_k: 0.764570, samples/s: 1336.000 1612686056.6897788
train: epoch 27, iter 3500, loss: 3.165575, top_1: 0.523906, top_k: 0.762695, samples/s: 1332.643 1612686075.8996878
train: epoch 27, iter 3600, loss: 2.927993, top_1: 0.526289, top_k: 0.759023, samples/s: 1335.438 1612686095.0694926
train: epoch 27, iter 3700, loss: 2.708745, top_1: 0.522891, top_k: 0.756836, samples/s: 1339.450 1612686114.1817474
train: epoch 27, iter 3800, loss: 3.019892, top_1: 0.522852, top_k: 0.756836, samples/s: 1333.594 1612686133.3780527
train: epoch 27, iter 3900, loss: 2.888124, top_1: 0.525937, top_k: 0.761406, samples/s: 1339.803 1612686152.4853683
train: epoch 27, iter 4000, loss: 3.017515, top_1: 0.526289, top_k: 0.759922, samples/s: 1337.463 1612686171.626088
train: epoch 27, iter 4100, loss: 2.912579, top_1: 0.524531, top_k: 0.759336, samples/s: 1325.566 1612686190.9386268
train: epoch 27, iter 4200, loss: 3.028078, top_1: 0.526445, top_k: 0.761797, samples/s: 1339.248 1612686210.0537152
train: epoch 27, iter 4300, loss: 2.895984, top_1: 0.522148, top_k: 0.760508, samples/s: 1336.173 1612686229.213022
train: epoch 27, iter 4400, loss: 3.186793, top_1: 0.524062, top_k: 0.758867, samples/s: 1337.013 1612686248.3600886
train: epoch 27, iter 4500, loss: 2.968900, top_1: 0.525859, top_k: 0.762891, samples/s: 1334.897 1612686267.537575
train: epoch 27, iter 4600, loss: 2.972713, top_1: 0.529531, top_k: 0.767969, samples/s: 1336.574 1612686286.691073
train: epoch 27, iter 4700, loss: 3.014427, top_1: 0.531211, top_k: 0.762852, samples/s: 1337.456 1612686305.8318455
train: epoch 27, iter 4800, loss: 3.180766, top_1: 0.523750, top_k: 0.759258, samples/s: 1333.211 1612686325.033659
train: epoch 27, iter 4900, loss: 3.004409, top_1: 0.522422, top_k: 0.759102, samples/s: 1332.282 1612686344.2487304
train: epoch 27, iter 5000, loss: 2.992824, top_1: 0.532461, top_k: 0.767734, samples/s: 1338.627 1612686363.3728795
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_27.
validation: epoch 27, iter 195, top_1: 0.579026, top_k: 0.819732, samples/s: 2703.312 1612686382.4108267
train: epoch 28, iter 100, loss: 3.023790, top_1: 0.536680, top_k: 0.773984, samples/s: 1359.789 1612686417.3147676
train: epoch 28, iter 200, loss: 2.966653, top_1: 0.540508, top_k: 0.769687, samples/s: 1358.042 1612686436.1654835
train: epoch 28, iter 300, loss: 2.831363, top_1: 0.537500, top_k: 0.770781, samples/s: 1357.668 1612686455.0212839
train: epoch 28, iter 400, loss: 3.131885, top_1: 0.536563, top_k: 0.770781, samples/s: 1355.954 1612686473.9009423
train: epoch 28, iter 500, loss: 2.947271, top_1: 0.531602, top_k: 0.768945, samples/s: 1340.839 1612686492.9935074
train: epoch 28, iter 600, loss: 2.927257, top_1: 0.527539, top_k: 0.759297, samples/s: 1332.159 1612686512.210423
train: epoch 28, iter 700, loss: 3.142988, top_1: 0.534453, top_k: 0.768281, samples/s: 1331.096 1612686531.4426394
train: epoch 28, iter 800, loss: 2.914372, top_1: 0.528242, top_k: 0.765352, samples/s: 1335.592 1612686550.610175
train: epoch 28, iter 900, loss: 3.009608, top_1: 0.529375, top_k: 0.760352, samples/s: 1334.356 1612686569.7954752
train: epoch 28, iter 1000, loss: 2.979033, top_1: 0.527344, top_k: 0.769219, samples/s: 1326.221 1612686589.0984507
train: epoch 28, iter 1100, loss: 2.899445, top_1: 0.530273, top_k: 0.767695, samples/s: 1340.699 1612686608.1930087
train: epoch 28, iter 1200, loss: 2.848440, top_1: 0.525273, top_k: 0.764570, samples/s: 1328.573 1612686627.461801
train: epoch 28, iter 1300, loss: 3.060555, top_1: 0.528906, top_k: 0.761992, samples/s: 1340.702 1612686646.5562227
train: epoch 28, iter 1400, loss: 2.973121, top_1: 0.527344, top_k: 0.766523, samples/s: 1334.726 1612686665.736316
train: epoch 28, iter 1500, loss: 2.664552, top_1: 0.530156, top_k: 0.766523, samples/s: 1333.457 1612686684.9344049
train: epoch 28, iter 1600, loss: 2.938948, top_1: 0.527813, top_k: 0.764766, samples/s: 1335.525 1612686704.1028938
train: epoch 28, iter 1700, loss: 3.004068, top_1: 0.525039, top_k: 0.761719, samples/s: 1330.715 1612686723.3406703
train: epoch 28, iter 1800, loss: 2.841235, top_1: 0.525078, top_k: 0.762852, samples/s: 1334.314 1612686742.5266266
train: epoch 28, iter 1900, loss: 3.011268, top_1: 0.531445, top_k: 0.763203, samples/s: 1332.886 1612686761.7330842
train: epoch 28, iter 2000, loss: 2.910249, top_1: 0.525273, top_k: 0.759570, samples/s: 1336.169 1612686780.8922882
train: epoch 28, iter 2100, loss: 2.888704, top_1: 0.527344, top_k: 0.763398, samples/s: 1332.557 1612686800.103494
train: epoch 28, iter 2200, loss: 3.100785, top_1: 0.525742, top_k: 0.762344, samples/s: 1339.878 1612686819.20971
train: epoch 28, iter 2300, loss: 3.121499, top_1: 0.524961, top_k: 0.759453, samples/s: 1331.246 1612686838.4397528
train: epoch 28, iter 2400, loss: 2.977989, top_1: 0.524219, top_k: 0.763242, samples/s: 1329.704 1612686857.6922133
train: epoch 28, iter 2500, loss: 2.851705, top_1: 0.526992, top_k: 0.761445, samples/s: 1338.155 1612686876.8230126
train: epoch 28, iter 2600, loss: 3.117004, top_1: 0.522305, top_k: 0.757500, samples/s: 1333.010 1612686896.0276325
train: epoch 28, iter 2700, loss: 2.931988, top_1: 0.530977, top_k: 0.762344, samples/s: 1340.680 1612686915.1224298
train: epoch 28, iter 2800, loss: 2.926880, top_1: 0.526211, top_k: 0.758594, samples/s: 1333.663 1612686934.3177054
train: epoch 28, iter 2900, loss: 2.811323, top_1: 0.528711, top_k: 0.760469, samples/s: 1337.320 1612686953.4605014
train: epoch 28, iter 3000, loss: 3.093716, top_1: 0.529180, top_k: 0.763477, samples/s: 1338.557 1612686972.5855722
train: epoch 28, iter 3100, loss: 2.986457, top_1: 0.524570, top_k: 0.764648, samples/s: 1338.567 1612686991.710501
train: epoch 28, iter 3200, loss: 2.986049, top_1: 0.530625, top_k: 0.763750, samples/s: 1338.320 1612687010.8389597
train: epoch 28, iter 3300, loss: 2.982180, top_1: 0.526133, top_k: 0.758867, samples/s: 1327.061 1612687030.129737
train: epoch 28, iter 3400, loss: 2.961692, top_1: 0.533750, top_k: 0.761836, samples/s: 1332.327 1612687049.3441582
train: epoch 28, iter 3500, loss: 2.908849, top_1: 0.529727, top_k: 0.761914, samples/s: 1341.194 1612687068.4316218
train: epoch 28, iter 3600, loss: 2.940485, top_1: 0.530000, top_k: 0.762031, samples/s: 1335.273 1612687087.6037529
train: epoch 28, iter 3700, loss: 2.997027, top_1: 0.533594, top_k: 0.770312, samples/s: 1329.782 1612687106.8550565
train: epoch 28, iter 3800, loss: 3.131556, top_1: 0.524492, top_k: 0.760117, samples/s: 1329.459 1612687126.1110895
train: epoch 28, iter 3900, loss: 2.998118, top_1: 0.525312, top_k: 0.760898, samples/s: 1342.968 1612687145.173304
train: epoch 28, iter 4000, loss: 2.854839, top_1: 0.529922, top_k: 0.765039, samples/s: 1328.055 1612687164.4495516
train: epoch 28, iter 4100, loss: 2.924287, top_1: 0.521953, top_k: 0.762305, samples/s: 1339.631 1612687183.559345
train: epoch 28, iter 4200, loss: 2.941567, top_1: 0.523438, top_k: 0.762773, samples/s: 1333.527 1612687202.756567
train: epoch 28, iter 4300, loss: 3.277086, top_1: 0.524023, top_k: 0.760469, samples/s: 1334.160 1612687221.94466
train: epoch 28, iter 4400, loss: 2.988314, top_1: 0.528320, top_k: 0.763008, samples/s: 1333.055 1612687241.1486313
train: epoch 28, iter 4500, loss: 2.946132, top_1: 0.532813, top_k: 0.760000, samples/s: 1340.352 1612687260.2481296
train: epoch 28, iter 4600, loss: 3.036379, top_1: 0.528164, top_k: 0.761680, samples/s: 1340.735 1612687279.3421187
train: epoch 28, iter 4700, loss: 3.152161, top_1: 0.526719, top_k: 0.760078, samples/s: 1332.886 1612687298.5485263
train: epoch 28, iter 4800, loss: 3.119253, top_1: 0.529805, top_k: 0.762617, samples/s: 1333.688 1612687317.7434154
train: epoch 28, iter 4900, loss: 2.956954, top_1: 0.527734, top_k: 0.761445, samples/s: 1340.474 1612687336.8412256
train: epoch 28, iter 5000, loss: 3.021661, top_1: 0.526836, top_k: 0.760586, samples/s: 1324.400 1612687356.170747
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_28.
validation: epoch 28, iter 195, top_1: 0.577704, top_k: 0.819191, samples/s: 2691.068 1612687375.2298896
train: epoch 29, iter 100, loss: 2.981345, top_1: 0.532188, top_k: 0.766406, samples/s: 1361.260 1612687409.8119915
train: epoch 29, iter 200, loss: 2.922184, top_1: 0.538203, top_k: 0.768750, samples/s: 1360.361 1612687428.6304505
train: epoch 29, iter 300, loss: 3.133625, top_1: 0.529805, top_k: 0.764336, samples/s: 1359.928 1612687447.4549901
train: epoch 29, iter 400, loss: 3.025457, top_1: 0.536328, top_k: 0.770859, samples/s: 1356.897 1612687466.3215096
train: epoch 29, iter 500, loss: 2.953395, top_1: 0.531133, top_k: 0.767617, samples/s: 1335.081 1612687485.4964154
train: epoch 29, iter 600, loss: 2.883836, top_1: 0.534258, top_k: 0.766445, samples/s: 1325.529 1612687504.8094163
train: epoch 29, iter 700, loss: 3.077083, top_1: 0.529570, top_k: 0.767344, samples/s: 1333.223 1612687524.011122
train: epoch 29, iter 800, loss: 2.764876, top_1: 0.539258, top_k: 0.772930, samples/s: 1335.685 1612687543.1772692
train: epoch 29, iter 900, loss: 2.885589, top_1: 0.537188, top_k: 0.768398, samples/s: 1324.924 1612687562.4990978
train: epoch 29, iter 1000, loss: 2.948799, top_1: 0.534766, top_k: 0.769687, samples/s: 1326.682 1612687581.7954009
train: epoch 29, iter 1100, loss: 3.085537, top_1: 0.530078, top_k: 0.767734, samples/s: 1336.913 1612687600.9439716
train: epoch 29, iter 1200, loss: 3.052380, top_1: 0.530508, top_k: 0.761836, samples/s: 1331.033 1612687620.1771257
train: epoch 29, iter 1300, loss: 2.892081, top_1: 0.532070, top_k: 0.769023, samples/s: 1332.853 1612687639.384011
train: epoch 29, iter 1400, loss: 3.021720, top_1: 0.531875, top_k: 0.765273, samples/s: 1333.937 1612687658.5753293
train: epoch 29, iter 1500, loss: 3.067197, top_1: 0.526094, top_k: 0.761719, samples/s: 1331.660 1612687677.7994947
train: epoch 29, iter 1600, loss: 2.897157, top_1: 0.536328, top_k: 0.768516, samples/s: 1325.737 1612687697.109548
train: epoch 29, iter 1700, loss: 2.850535, top_1: 0.534883, top_k: 0.763633, samples/s: 1328.114 1612687716.3849049
train: epoch 29, iter 1800, loss: 2.831026, top_1: 0.526250, top_k: 0.763203, samples/s: 1336.206 1612687735.5436213
train: epoch 29, iter 1900, loss: 2.939714, top_1: 0.531055, top_k: 0.768164, samples/s: 1326.007 1612687754.8497643
train: epoch 29, iter 2000, loss: 2.876630, top_1: 0.535312, top_k: 0.764727, samples/s: 1335.036 1612687774.0252533
train: epoch 29, iter 2100, loss: 3.074710, top_1: 0.526133, top_k: 0.763789, samples/s: 1334.799 1612687793.204232
train: epoch 29, iter 2200, loss: 3.016799, top_1: 0.530391, top_k: 0.768086, samples/s: 1327.487 1612687812.4887085
train: epoch 29, iter 2300, loss: 3.078199, top_1: 0.535078, top_k: 0.766797, samples/s: 1335.117 1612687831.6630576
train: epoch 29, iter 2400, loss: 2.755386, top_1: 0.529766, top_k: 0.765508, samples/s: 1332.814 1612687850.8705752
train: epoch 29, iter 2500, loss: 3.174516, top_1: 0.525781, top_k: 0.766563, samples/s: 1325.071 1612687870.190267
train: epoch 29, iter 2600, loss: 2.849273, top_1: 0.530078, top_k: 0.762383, samples/s: 1335.668 1612687889.356701
train: epoch 29, iter 2700, loss: 3.024622, top_1: 0.530078, top_k: 0.762930, samples/s: 1328.367 1612687908.6284788
train: epoch 29, iter 2800, loss: 3.005041, top_1: 0.536680, top_k: 0.768633, samples/s: 1325.831 1612687927.9371228
train: epoch 29, iter 2900, loss: 2.860863, top_1: 0.529023, top_k: 0.762969, samples/s: 1338.257 1612687947.066937
train: epoch 29, iter 3000, loss: 2.937632, top_1: 0.530625, top_k: 0.765391, samples/s: 1332.917 1612687966.2725308
train: epoch 29, iter 3100, loss: 2.851805, top_1: 0.528203, top_k: 0.761055, samples/s: 1329.139 1612687985.5333846
train: epoch 29, iter 3200, loss: 2.834088, top_1: 0.531445, top_k: 0.764102, samples/s: 1332.840 1612688004.7402012
train: epoch 29, iter 3300, loss: 3.023363, top_1: 0.525898, top_k: 0.761680, samples/s: 1332.194 1612688023.9565814
train: epoch 29, iter 3400, loss: 2.919297, top_1: 0.526914, top_k: 0.764375, samples/s: 1328.983 1612688043.2194595
train: epoch 29, iter 3500, loss: 2.767792, top_1: 0.525391, top_k: 0.762539, samples/s: 1331.170 1612688062.450689
train: epoch 29, iter 3600, loss: 3.075481, top_1: 0.525430, top_k: 0.763516, samples/s: 1333.254 1612688081.6518252
train: epoch 29, iter 3700, loss: 2.984299, top_1: 0.523984, top_k: 0.763672, samples/s: 1328.835 1612688100.9167752
train: epoch 29, iter 3800, loss: 2.848122, top_1: 0.528242, top_k: 0.766289, samples/s: 1326.859 1612688120.2104895
train: epoch 29, iter 3900, loss: 2.920396, top_1: 0.531914, top_k: 0.764375, samples/s: 1334.972 1612688139.3869307
train: epoch 29, iter 4000, loss: 2.943065, top_1: 0.534180, top_k: 0.765234, samples/s: 1332.887 1612688158.5933645
train: epoch 29, iter 4100, loss: 3.176142, top_1: 0.528867, top_k: 0.762617, samples/s: 1328.626 1612688177.8613415
train: epoch 29, iter 4200, loss: 2.910884, top_1: 0.529336, top_k: 0.764258, samples/s: 1338.093 1612688196.9934695
train: epoch 29, iter 4300, loss: 3.002812, top_1: 0.530273, top_k: 0.760547, samples/s: 1335.207 1612688216.1661062
train: epoch 29, iter 4400, loss: 2.974824, top_1: 0.529219, top_k: 0.766484, samples/s: 1331.344 1612688235.3953295
train: epoch 29, iter 4500, loss: 3.021590, top_1: 0.523633, top_k: 0.761563, samples/s: 1328.233 1612688254.6685724
train: epoch 29, iter 4600, loss: 3.031315, top_1: 0.531445, top_k: 0.763125, samples/s: 1328.920 1612688273.9323318
train: epoch 29, iter 4700, loss: 2.880497, top_1: 0.529922, top_k: 0.765859, samples/s: 1340.677 1612688293.0271034
train: epoch 29, iter 4800, loss: 2.827979, top_1: 0.523984, top_k: 0.763477, samples/s: 1327.347 1612688312.3137865
train: epoch 29, iter 4900, loss: 2.957629, top_1: 0.523477, top_k: 0.759492, samples/s: 1331.786 1612688331.5361276
train: epoch 29, iter 5000, loss: 2.919178, top_1: 0.528828, top_k: 0.762305, samples/s: 1332.494 1612688350.749161
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_29.
validation: epoch 29, iter 195, top_1: 0.574499, top_k: 0.816186, samples/s: 2735.542 1612688369.6302454
train: epoch 30, iter 100, loss: 3.077129, top_1: 0.530664, top_k: 0.770938, samples/s: 1358.933 1612688409.878531
train: epoch 30, iter 200, loss: 2.926476, top_1: 0.538086, top_k: 0.771016, samples/s: 1359.447 1612688428.709681
train: epoch 30, iter 300, loss: 2.953137, top_1: 0.539648, top_k: 0.773984, samples/s: 1361.047 1612688447.5188074
train: epoch 30, iter 400, loss: 3.038170, top_1: 0.535898, top_k: 0.771055, samples/s: 1359.457 1612688466.350162
train: epoch 30, iter 500, loss: 2.933122, top_1: 0.529336, top_k: 0.769531, samples/s: 1345.132 1612688485.38144
train: epoch 30, iter 600, loss: 3.116035, top_1: 0.535078, top_k: 0.765430, samples/s: 1333.876 1612688504.5736384
train: epoch 30, iter 700, loss: 3.043887, top_1: 0.532500, top_k: 0.768203, samples/s: 1332.017 1612688523.792865
train: epoch 30, iter 800, loss: 3.011063, top_1: 0.528320, top_k: 0.768477, samples/s: 1333.357 1612688542.9921765
train: epoch 30, iter 900, loss: 2.802880, top_1: 0.533555, top_k: 0.768359, samples/s: 1335.249 1612688562.164718
train: epoch 30, iter 1000, loss: 2.910275, top_1: 0.538516, top_k: 0.770586, samples/s: 1331.719 1612688581.3880024
train: epoch 30, iter 1100, loss: 2.791687, top_1: 0.531680, top_k: 0.763984, samples/s: 1319.485 1612688600.7894216
train: epoch 30, iter 1200, loss: 2.858882, top_1: 0.533203, top_k: 0.766992, samples/s: 1345.310 1612688619.8185139
train: epoch 30, iter 1300, loss: 2.945649, top_1: 0.527344, top_k: 0.767813, samples/s: 1329.849 1612688639.0688667
train: epoch 30, iter 1400, loss: 2.888969, top_1: 0.530117, top_k: 0.766523, samples/s: 1338.163 1612688658.19962
train: epoch 30, iter 1500, loss: 3.133650, top_1: 0.532578, top_k: 0.765039, samples/s: 1333.570 1612688677.3962002
train: epoch 30, iter 1600, loss: 2.681983, top_1: 0.536523, top_k: 0.767734, samples/s: 1332.706 1612688696.6053061
train: epoch 30, iter 1700, loss: 2.817875, top_1: 0.528945, top_k: 0.761758, samples/s: 1334.220 1612688715.7924263
train: epoch 30, iter 1800, loss: 2.898841, top_1: 0.527617, top_k: 0.763789, samples/s: 1337.148 1612688734.937668
train: epoch 30, iter 1900, loss: 2.916194, top_1: 0.536641, top_k: 0.768047, samples/s: 1327.788 1612688754.2178276
train: epoch 30, iter 2000, loss: 3.037693, top_1: 0.531289, top_k: 0.766289, samples/s: 1336.983 1612688773.365509
train: epoch 30, iter 2100, loss: 2.706477, top_1: 0.535273, top_k: 0.767969, samples/s: 1338.464 1612688792.4921362
train: epoch 30, iter 2200, loss: 2.979556, top_1: 0.537852, top_k: 0.767852, samples/s: 1327.305 1612688811.7790134
train: epoch 30, iter 2300, loss: 2.808519, top_1: 0.537070, top_k: 0.767930, samples/s: 1335.074 1612688830.9539685
train: epoch 30, iter 2400, loss: 2.996253, top_1: 0.527695, top_k: 0.764453, samples/s: 1340.492 1612688850.051434
train: epoch 30, iter 2500, loss: 2.875644, top_1: 0.526719, top_k: 0.763008, samples/s: 1324.656 1612688869.3772786
train: epoch 30, iter 2600, loss: 2.816916, top_1: 0.531172, top_k: 0.765078, samples/s: 1338.825 1612688888.4984596
train: epoch 30, iter 2700, loss: 3.042537, top_1: 0.525000, top_k: 0.756328, samples/s: 1335.120 1612688907.6727927
train: epoch 30, iter 2800, loss: 2.888015, top_1: 0.529805, top_k: 0.763359, samples/s: 1330.128 1612688926.9190872
train: epoch 30, iter 2900, loss: 2.949622, top_1: 0.531523, top_k: 0.767500, samples/s: 1334.400 1612688946.10372
train: epoch 30, iter 3000, loss: 2.833765, top_1: 0.529805, top_k: 0.766914, samples/s: 1334.798 1612688965.2826746
train: epoch 30, iter 3100, loss: 2.796957, top_1: 0.530547, top_k: 0.766016, samples/s: 1337.377 1612688984.4245458
train: epoch 30, iter 3200, loss: 2.860039, top_1: 0.530859, top_k: 0.768125, samples/s: 1335.002 1612689003.6005485
train: epoch 30, iter 3300, loss: 2.902907, top_1: 0.529531, top_k: 0.761875, samples/s: 1332.040 1612689022.8192525
train: epoch 30, iter 3400, loss: 2.814863, top_1: 0.533086, top_k: 0.763516, samples/s: 1328.689 1612689042.086355
train: epoch 30, iter 3500, loss: 2.877854, top_1: 0.528789, top_k: 0.765664, samples/s: 1333.824 1612689061.2793581
train: epoch 30, iter 3600, loss: 3.013203, top_1: 0.524180, top_k: 0.763789, samples/s: 1345.166 1612689080.310351
train: epoch 30, iter 3700, loss: 2.904599, top_1: 0.534531, top_k: 0.765781, samples/s: 1338.389 1612689099.4378164
train: epoch 30, iter 3800, loss: 3.057272, top_1: 0.534961, top_k: 0.767617, samples/s: 1330.858 1612689118.673607
train: epoch 30, iter 3900, loss: 2.856136, top_1: 0.527852, top_k: 0.766641, samples/s: 1331.591 1612689137.8986628
train: epoch 30, iter 4000, loss: 2.965680, top_1: 0.527500, top_k: 0.761094, samples/s: 1335.610 1612689157.065925
train: epoch 30, iter 4100, loss: 2.755675, top_1: 0.529336, top_k: 0.763555, samples/s: 1333.760 1612689176.2598867
train: epoch 30, iter 4200, loss: 3.100567, top_1: 0.524961, top_k: 0.765742, samples/s: 1338.055 1612689195.3920841
train: epoch 30, iter 4300, loss: 3.162559, top_1: 0.527695, top_k: 0.762930, samples/s: 1335.477 1612689214.5612097
train: epoch 30, iter 4400, loss: 2.957514, top_1: 0.530664, top_k: 0.766328, samples/s: 1336.174 1612689233.7203918
train: epoch 30, iter 4500, loss: 3.012695, top_1: 0.527461, top_k: 0.762773, samples/s: 1337.368 1612689252.8625128
train: epoch 30, iter 4600, loss: 2.909411, top_1: 0.527930, top_k: 0.761445, samples/s: 1336.606 1612689272.015513
train: epoch 30, iter 4700, loss: 2.869225, top_1: 0.532109, top_k: 0.765000, samples/s: 1329.754 1612689291.2671943
train: epoch 30, iter 4800, loss: 2.826402, top_1: 0.535430, top_k: 0.770039, samples/s: 1334.667 1612689310.4479468
train: epoch 30, iter 4900, loss: 2.890821, top_1: 0.528242, top_k: 0.760000, samples/s: 1343.623 1612689329.5010374
train: epoch 30, iter 5000, loss: 2.996239, top_1: 0.529883, top_k: 0.762305, samples/s: 1329.444 1612689348.7571037
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_30.
validation: epoch 30, iter 195, top_1: 0.570353, top_k: 0.813001, samples/s: 2813.546 1612689367.0299237
train: epoch 31, iter 100, loss: 2.697046, top_1: 0.540430, top_k: 0.774648, samples/s: 1360.158 1612689401.8174205
train: epoch 31, iter 200, loss: 2.961227, top_1: 0.539062, top_k: 0.776289, samples/s: 1361.268 1612689420.6233573
train: epoch 31, iter 300, loss: 3.010994, top_1: 0.541133, top_k: 0.777656, samples/s: 1360.130 1612689439.4451506
train: epoch 31, iter 400, loss: 2.749155, top_1: 0.533984, top_k: 0.768828, samples/s: 1349.048 1612689458.4214873
train: epoch 31, iter 500, loss: 2.927449, top_1: 0.540430, top_k: 0.770430, samples/s: 1331.939 1612689477.6416018
train: epoch 31, iter 600, loss: 3.004223, top_1: 0.535156, top_k: 0.771172, samples/s: 1333.964 1612689496.832525
train: epoch 31, iter 700, loss: 3.015597, top_1: 0.533398, top_k: 0.771641, samples/s: 1331.723 1612689516.0556724
train: epoch 31, iter 800, loss: 2.797175, top_1: 0.538867, top_k: 0.770508, samples/s: 1332.776 1612689535.2637095
train: epoch 31, iter 900, loss: 2.894456, top_1: 0.534766, top_k: 0.769570, samples/s: 1333.105 1612689554.4675658
train: epoch 31, iter 1000, loss: 3.017829, top_1: 0.536055, top_k: 0.771484, samples/s: 1335.216 1612689573.6399188
train: epoch 31, iter 1100, loss: 2.939819, top_1: 0.534219, top_k: 0.767383, samples/s: 1334.875 1612689592.817801
train: epoch 31, iter 1200, loss: 3.097674, top_1: 0.530586, top_k: 0.770156, samples/s: 1331.315 1612689612.047204
train: epoch 31, iter 1300, loss: 2.833563, top_1: 0.534492, top_k: 0.767813, samples/s: 1337.920 1612689631.1810875
train: epoch 31, iter 1400, loss: 2.840618, top_1: 0.529844, top_k: 0.765703, samples/s: 1334.854 1612689650.3591967
train: epoch 31, iter 1500, loss: 2.904847, top_1: 0.531992, top_k: 0.762227, samples/s: 1332.171 1612689669.5759034
train: epoch 31, iter 1600, loss: 2.738278, top_1: 0.531602, top_k: 0.768203, samples/s: 1332.058 1612689688.7943506
train: epoch 31, iter 1700, loss: 2.867469, top_1: 0.535117, top_k: 0.772109, samples/s: 1335.862 1612689707.9579594
train: epoch 31, iter 1800, loss: 3.028178, top_1: 0.532500, top_k: 0.763242, samples/s: 1332.008 1612689727.1770701
train: epoch 31, iter 1900, loss: 2.948800, top_1: 0.528672, top_k: 0.764805, samples/s: 1330.262 1612689746.421398
train: epoch 31, iter 2000, loss: 3.075523, top_1: 0.534297, top_k: 0.767695, samples/s: 1333.588 1612689765.61775
train: epoch 31, iter 2100, loss: 3.039941, top_1: 0.532969, top_k: 0.766289, samples/s: 1327.871 1612689784.8967605
train: epoch 31, iter 2200, loss: 3.037344, top_1: 0.533320, top_k: 0.763086, samples/s: 1341.156 1612689803.9847348
train: epoch 31, iter 2300, loss: 2.776679, top_1: 0.535742, top_k: 0.765078, samples/s: 1335.221 1612689823.1576655
train: epoch 31, iter 2400, loss: 2.946605, top_1: 0.527930, top_k: 0.765156, samples/s: 1335.355 1612689842.3285322
train: epoch 31, iter 2500, loss: 2.982019, top_1: 0.532852, top_k: 0.767305, samples/s: 1331.768 1612689861.5511644
train: epoch 31, iter 2600, loss: 3.140580, top_1: 0.531055, top_k: 0.766641, samples/s: 1335.292 1612689880.722957
train: epoch 31, iter 2700, loss: 3.036803, top_1: 0.538867, top_k: 0.769609, samples/s: 1333.066 1612689899.926786
train: epoch 31, iter 2800, loss: 2.776514, top_1: 0.529727, top_k: 0.765742, samples/s: 1343.131 1612689918.9867563
train: epoch 31, iter 2900, loss: 2.906269, top_1: 0.532969, top_k: 0.766211, samples/s: 1329.860 1612689938.236856
train: epoch 31, iter 3000, loss: 2.907249, top_1: 0.531133, top_k: 0.764336, samples/s: 1336.304 1612689957.3942127
train: epoch 31, iter 3100, loss: 2.838609, top_1: 0.533789, top_k: 0.767656, samples/s: 1338.776 1612689976.516079
train: epoch 31, iter 3200, loss: 2.970035, top_1: 0.532109, top_k: 0.766523, samples/s: 1336.772 1612689995.6667519
train: epoch 31, iter 3300, loss: 2.836872, top_1: 0.526602, top_k: 0.764297, samples/s: 1330.746 1612690014.9041474
train: epoch 31, iter 3400, loss: 2.777263, top_1: 0.534570, top_k: 0.767070, samples/s: 1329.563 1612690034.1585433
train: epoch 31, iter 3500, loss: 2.976701, top_1: 0.526172, top_k: 0.763086, samples/s: 1339.915 1612690053.264191
train: epoch 31, iter 3600, loss: 2.857301, top_1: 0.533945, top_k: 0.766367, samples/s: 1339.305 1612690072.3786018
train: epoch 31, iter 3700, loss: 2.819225, top_1: 0.527813, top_k: 0.767188, samples/s: 1340.735 1612690091.4726408
train: epoch 31, iter 3800, loss: 2.807765, top_1: 0.533125, top_k: 0.765117, samples/s: 1337.841 1612690110.6079278
train: epoch 31, iter 3900, loss: 3.038602, top_1: 0.538477, top_k: 0.768750, samples/s: 1328.470 1612690129.8781767
train: epoch 31, iter 4000, loss: 3.031664, top_1: 0.532383, top_k: 0.767461, samples/s: 1334.400 1612690149.0628989
train: epoch 31, iter 4100, loss: 2.950753, top_1: 0.531250, top_k: 0.766758, samples/s: 1340.898 1612690168.1545691
train: epoch 31, iter 4200, loss: 2.898745, top_1: 0.530781, top_k: 0.763437, samples/s: 1338.396 1612690187.2819357
train: epoch 31, iter 4300, loss: 2.857823, top_1: 0.528711, top_k: 0.765820, samples/s: 1335.596 1612690206.4494224
train: epoch 31, iter 4400, loss: 3.135579, top_1: 0.528086, top_k: 0.764531, samples/s: 1336.064 1612690225.6102042
train: epoch 31, iter 4500, loss: 3.052601, top_1: 0.530234, top_k: 0.765117, samples/s: 1335.072 1612690244.7852879
train: epoch 31, iter 4600, loss: 2.952375, top_1: 0.536680, top_k: 0.768789, samples/s: 1333.736 1612690263.9793038
train: epoch 31, iter 4700, loss: 2.963478, top_1: 0.525234, top_k: 0.758398, samples/s: 1334.319 1612690283.1651468
train: epoch 31, iter 4800, loss: 2.917599, top_1: 0.530430, top_k: 0.764375, samples/s: 1330.092 1612690302.4119585
train: epoch 31, iter 4900, loss: 3.001284, top_1: 0.530508, top_k: 0.767539, samples/s: 1340.471 1612690321.5096705
train: epoch 31, iter 5000, loss: 2.961398, top_1: 0.536094, top_k: 0.768555, samples/s: 1335.693 1612690340.6757524
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_31.
validation: epoch 31, iter 195, top_1: 0.585517, top_k: 0.824359, samples/s: 2764.908 1612690359.294825
train: epoch 32, iter 100, loss: 2.859909, top_1: 0.536133, top_k: 0.774922, samples/s: 1361.647 1612690394.2542758
train: epoch 32, iter 200, loss: 2.743597, top_1: 0.539609, top_k: 0.772773, samples/s: 1363.252 1612690413.0328069
train: epoch 32, iter 300, loss: 3.010174, top_1: 0.543789, top_k: 0.771875, samples/s: 1360.634 1612690431.8476236
train: epoch 32, iter 400, loss: 2.799096, top_1: 0.544805, top_k: 0.769844, samples/s: 1353.234 1612690450.7652144
train: epoch 32, iter 500, loss: 2.989796, top_1: 0.544258, top_k: 0.774297, samples/s: 1340.039 1612690469.8691442
train: epoch 32, iter 600, loss: 2.870626, top_1: 0.537852, top_k: 0.771563, samples/s: 1330.033 1612690489.116817
train: epoch 32, iter 700, loss: 2.935451, top_1: 0.545508, top_k: 0.774141, samples/s: 1327.972 1612690508.3942947
train: epoch 32, iter 800, loss: 3.019524, top_1: 0.534609, top_k: 0.771328, samples/s: 1333.579 1612690527.5908058
train: epoch 32, iter 900, loss: 2.907360, top_1: 0.539453, top_k: 0.771250, samples/s: 1335.111 1612690546.7652445
train: epoch 32, iter 1000, loss: 3.025151, top_1: 0.533945, top_k: 0.770898, samples/s: 1340.391 1612690565.86414
train: epoch 32, iter 1100, loss: 2.855700, top_1: 0.536563, top_k: 0.771289, samples/s: 1334.622 1612690585.0455658
train: epoch 32, iter 1200, loss: 2.874464, top_1: 0.533984, top_k: 0.771523, samples/s: 1332.331 1612690604.2600152
train: epoch 32, iter 1300, loss: 3.060290, top_1: 0.538516, top_k: 0.770938, samples/s: 1330.330 1612690623.5033574
train: epoch 32, iter 1400, loss: 2.858690, top_1: 0.530664, top_k: 0.764727, samples/s: 1329.642 1612690642.7567906
train: epoch 32, iter 1500, loss: 2.748488, top_1: 0.537773, top_k: 0.768711, samples/s: 1336.453 1612690661.9118938
train: epoch 32, iter 1600, loss: 3.146306, top_1: 0.535508, top_k: 0.765117, samples/s: 1330.309 1612690681.1555545
train: epoch 32, iter 1700, loss: 3.000586, top_1: 0.537617, top_k: 0.769805, samples/s: 1338.529 1612690700.2810194
train: epoch 32, iter 1800, loss: 2.706504, top_1: 0.537500, top_k: 0.769570, samples/s: 1331.328 1612690719.5099585
train: epoch 32, iter 1900, loss: 2.701317, top_1: 0.536758, top_k: 0.768711, samples/s: 1329.780 1612690738.7612677
train: epoch 32, iter 2000, loss: 2.840034, top_1: 0.528047, top_k: 0.765078, samples/s: 1331.540 1612690757.9870658
train: epoch 32, iter 2100, loss: 2.723020, top_1: 0.531563, top_k: 0.766797, samples/s: 1334.648 1612690777.1681988
train: epoch 32, iter 2200, loss: 2.977991, top_1: 0.539531, top_k: 0.773828, samples/s: 1339.146 1612690796.2848117
train: epoch 32, iter 2300, loss: 2.722183, top_1: 0.532422, top_k: 0.766211, samples/s: 1332.148 1612690815.5019038
train: epoch 32, iter 2400, loss: 2.968832, top_1: 0.540742, top_k: 0.769922, samples/s: 1339.478 1612690834.6138196
train: epoch 32, iter 2500, loss: 2.746731, top_1: 0.538398, top_k: 0.771211, samples/s: 1329.621 1612690853.8674273
train: epoch 32, iter 2600, loss: 2.739676, top_1: 0.532305, top_k: 0.768867, samples/s: 1334.824 1612690873.0460355
train: epoch 32, iter 2700, loss: 2.971638, top_1: 0.525391, top_k: 0.764023, samples/s: 1332.123 1612690892.2634563
train: epoch 32, iter 2800, loss: 2.661877, top_1: 0.534922, top_k: 0.767617, samples/s: 1335.108 1612690911.4379826
train: epoch 32, iter 2900, loss: 2.823511, top_1: 0.528867, top_k: 0.766055, samples/s: 1334.000 1612690930.6283288
train: epoch 32, iter 3000, loss: 2.983993, top_1: 0.535234, top_k: 0.770625, samples/s: 1331.267 1612690949.858189
train: epoch 32, iter 3100, loss: 3.083149, top_1: 0.527305, top_k: 0.764492, samples/s: 1339.560 1612690968.9688835
train: epoch 32, iter 3200, loss: 2.967505, top_1: 0.529258, top_k: 0.763672, samples/s: 1333.194 1612690988.170965
train: epoch 32, iter 3300, loss: 2.857710, top_1: 0.533633, top_k: 0.766328, samples/s: 1337.826 1612691007.3064847
train: epoch 32, iter 3400, loss: 3.044596, top_1: 0.532227, top_k: 0.766172, samples/s: 1328.141 1612691026.5814798
train: epoch 32, iter 3500, loss: 2.914331, top_1: 0.540586, top_k: 0.770742, samples/s: 1339.855 1612691045.6880193
train: epoch 32, iter 3600, loss: 2.867039, top_1: 0.533672, top_k: 0.769141, samples/s: 1338.494 1612691064.8140404
train: epoch 32, iter 3700, loss: 2.969651, top_1: 0.539766, top_k: 0.771367, samples/s: 1337.264 1612691083.957575
train: epoch 32, iter 3800, loss: 3.019319, top_1: 0.532930, top_k: 0.766406, samples/s: 1328.903 1612691103.2216203
train: epoch 32, iter 3900, loss: 2.939818, top_1: 0.534609, top_k: 0.766797, samples/s: 1338.961 1612691122.3408601
train: epoch 32, iter 4000, loss: 2.903821, top_1: 0.536914, top_k: 0.768398, samples/s: 1331.258 1612691141.5708003
train: epoch 32, iter 4100, loss: 3.220083, top_1: 0.533945, top_k: 0.768906, samples/s: 1336.923 1612691160.7192473
train: epoch 32, iter 4200, loss: 2.923414, top_1: 0.537578, top_k: 0.772109, samples/s: 1336.948 1612691179.8673368
train: epoch 32, iter 4300, loss: 2.921660, top_1: 0.542109, top_k: 0.770039, samples/s: 1337.875 1612691199.0022135
train: epoch 32, iter 4400, loss: 2.964021, top_1: 0.528555, top_k: 0.763750, samples/s: 1337.005 1612691218.149478
train: epoch 32, iter 4500, loss: 3.132020, top_1: 0.535937, top_k: 0.767109, samples/s: 1339.515 1612691237.2608173
train: epoch 32, iter 4600, loss: 3.081454, top_1: 0.525508, top_k: 0.765742, samples/s: 1325.330 1612691256.5768495
train: epoch 32, iter 4700, loss: 2.856117, top_1: 0.530703, top_k: 0.764687, samples/s: 1334.901 1612691275.7542171
train: epoch 32, iter 4800, loss: 2.852730, top_1: 0.530195, top_k: 0.765742, samples/s: 1342.419 1612691294.8243115
train: epoch 32, iter 4900, loss: 3.003939, top_1: 0.528750, top_k: 0.762617, samples/s: 1319.688 1612691314.2228165
train: epoch 32, iter 5000, loss: 2.667604, top_1: 0.530039, top_k: 0.768281, samples/s: 1343.198 1612691333.2818272
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_32.
validation: epoch 32, iter 195, top_1: 0.588762, top_k: 0.823678, samples/s: 2745.612 1612691352.0386267
train: epoch 33, iter 100, loss: 2.957155, top_1: 0.539492, top_k: 0.774687, samples/s: 1356.366 1612691386.6473153
train: epoch 33, iter 200, loss: 2.994948, top_1: 0.540820, top_k: 0.772305, samples/s: 1355.303 1612691405.536078
train: epoch 33, iter 300, loss: 2.771837, top_1: 0.542695, top_k: 0.775195, samples/s: 1364.728 1612691424.2944176
train: epoch 33, iter 400, loss: 2.847645, top_1: 0.546953, top_k: 0.778242, samples/s: 1355.049 1612691443.1867437
train: epoch 33, iter 500, loss: 2.919839, top_1: 0.534648, top_k: 0.769570, samples/s: 1323.481 1612691462.5296302
train: epoch 33, iter 600, loss: 3.030942, top_1: 0.538711, top_k: 0.767148, samples/s: 1337.572 1612691481.6688359
train: epoch 33, iter 700, loss: 2.931522, top_1: 0.537383, top_k: 0.771445, samples/s: 1330.233 1612691500.9135993
train: epoch 33, iter 800, loss: 2.684663, top_1: 0.538516, top_k: 0.769805, samples/s: 1327.721 1612691520.1946945
train: epoch 33, iter 900, loss: 2.950013, top_1: 0.543594, top_k: 0.774844, samples/s: 1328.362 1612691539.466604
train: epoch 33, iter 1000, loss: 2.662491, top_1: 0.540547, top_k: 0.774062, samples/s: 1328.624 1612691558.734637
train: epoch 33, iter 1100, loss: 2.973333, top_1: 0.543047, top_k: 0.774375, samples/s: 1319.274 1612691578.1392965
train: epoch 33, iter 1200, loss: 2.919980, top_1: 0.534727, top_k: 0.766602, samples/s: 1332.636 1612691597.3492403
train: epoch 33, iter 1300, loss: 2.875441, top_1: 0.534883, top_k: 0.771406, samples/s: 1342.860 1612691616.4131105
train: epoch 33, iter 1400, loss: 2.909868, top_1: 0.536992, top_k: 0.767070, samples/s: 1330.980 1612691635.646983
train: epoch 33, iter 1500, loss: 2.924389, top_1: 0.540898, top_k: 0.770742, samples/s: 1327.273 1612691654.9347243
train: epoch 33, iter 1600, loss: 2.904332, top_1: 0.539297, top_k: 0.765781, samples/s: 1331.688 1612691674.1584136
train: epoch 33, iter 1700, loss: 2.629395, top_1: 0.536680, top_k: 0.771719, samples/s: 1322.216 1612691693.5198085
train: epoch 33, iter 1800, loss: 2.918546, top_1: 0.535469, top_k: 0.768633, samples/s: 1339.126 1612691712.6367834
train: epoch 33, iter 1900, loss: 2.746584, top_1: 0.540430, top_k: 0.776406, samples/s: 1329.166 1612691731.8970237
train: epoch 33, iter 2000, loss: 2.866364, top_1: 0.535977, top_k: 0.767500, samples/s: 1337.004 1612691751.0442512
train: epoch 33, iter 2100, loss: 2.939783, top_1: 0.536250, top_k: 0.766523, samples/s: 1328.342 1612691770.316385
train: epoch 33, iter 2200, loss: 2.969262, top_1: 0.533711, top_k: 0.767461, samples/s: 1330.423 1612691789.5584452
train: epoch 33, iter 2300, loss: 2.862924, top_1: 0.533984, top_k: 0.769258, samples/s: 1330.039 1612691808.8059742
train: epoch 33, iter 2400, loss: 2.986170, top_1: 0.530469, top_k: 0.762656, samples/s: 1330.436 1612691828.047771
train: epoch 33, iter 2500, loss: 3.098854, top_1: 0.535117, top_k: 0.770391, samples/s: 1326.867 1612691847.3413446
train: epoch 33, iter 2600, loss: 2.967080, top_1: 0.530273, top_k: 0.767656, samples/s: 1334.566 1612691866.5236437
train: epoch 33, iter 2700, loss: 2.933548, top_1: 0.534219, top_k: 0.771328, samples/s: 1336.132 1612691885.6833727
train: epoch 33, iter 2800, loss: 2.713503, top_1: 0.530156, top_k: 0.766445, samples/s: 1325.586 1612691904.9956315
train: epoch 33, iter 2900, loss: 2.885761, top_1: 0.532031, top_k: 0.766016, samples/s: 1336.550 1612691924.149384
train: epoch 33, iter 3000, loss: 2.885341, top_1: 0.532266, top_k: 0.765859, samples/s: 1320.421 1612691943.5371547
train: epoch 33, iter 3100, loss: 3.003854, top_1: 0.537852, top_k: 0.773008, samples/s: 1333.430 1612691962.7358272
train: epoch 33, iter 3200, loss: 2.971970, top_1: 0.537695, top_k: 0.768281, samples/s: 1335.700 1612691981.9017496
train: epoch 33, iter 3300, loss: 3.035573, top_1: 0.531758, top_k: 0.767695, samples/s: 1333.090 1612692001.1052964
train: epoch 33, iter 3400, loss: 2.850492, top_1: 0.542148, top_k: 0.772148, samples/s: 1329.921 1612692020.3544934
train: epoch 33, iter 3500, loss: 2.805012, top_1: 0.540898, top_k: 0.773438, samples/s: 1332.615 1612692039.564995
train: epoch 33, iter 3600, loss: 2.888221, top_1: 0.529570, top_k: 0.763906, samples/s: 1333.704 1612692058.759682
train: epoch 33, iter 3700, loss: 2.905244, top_1: 0.533750, top_k: 0.769180, samples/s: 1330.530 1612692077.999959
train: epoch 33, iter 3800, loss: 2.958817, top_1: 0.529258, top_k: 0.763711, samples/s: 1330.508 1612692097.2407813
train: epoch 33, iter 3900, loss: 2.784558, top_1: 0.534766, top_k: 0.769805, samples/s: 1330.965 1612692116.4748888
train: epoch 33, iter 4000, loss: 3.028304, top_1: 0.536875, top_k: 0.769727, samples/s: 1330.156 1612692135.720746
train: epoch 33, iter 4100, loss: 2.757449, top_1: 0.535352, top_k: 0.772969, samples/s: 1332.083 1612692154.9388251
train: epoch 33, iter 4200, loss: 3.071928, top_1: 0.534180, top_k: 0.770273, samples/s: 1334.647 1612692174.1198719
train: epoch 33, iter 4300, loss: 2.901223, top_1: 0.528750, top_k: 0.759297, samples/s: 1330.935 1612692193.354511
train: epoch 33, iter 4400, loss: 2.950591, top_1: 0.539336, top_k: 0.770078, samples/s: 1334.010 1612692212.5447807
train: epoch 33, iter 4500, loss: 2.974344, top_1: 0.537500, top_k: 0.772227, samples/s: 1333.048 1612692231.7488973
train: epoch 33, iter 4600, loss: 2.835037, top_1: 0.532227, top_k: 0.766523, samples/s: 1328.418 1612692251.0199263
train: epoch 33, iter 4700, loss: 2.993098, top_1: 0.530898, top_k: 0.767930, samples/s: 1331.706 1612692270.2433338
train: epoch 33, iter 4800, loss: 2.962974, top_1: 0.533398, top_k: 0.766875, samples/s: 1330.089 1612692289.4902005
train: epoch 33, iter 4900, loss: 3.055537, top_1: 0.527734, top_k: 0.761875, samples/s: 1334.978 1612692308.666548
train: epoch 33, iter 5000, loss: 3.030309, top_1: 0.535312, top_k: 0.767031, samples/s: 1324.129 1612692328.0001004
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_33.
validation: epoch 33, iter 195, top_1: 0.587460, top_k: 0.823718, samples/s: 2727.868 1612692346.867021
train: epoch 34, iter 100, loss: 2.788087, top_1: 0.549219, top_k: 0.776641, samples/s: 1363.345 1612692381.5692747
train: epoch 34, iter 200, loss: 3.163388, top_1: 0.547188, top_k: 0.774805, samples/s: 1361.666 1612692400.3697844
train: epoch 34, iter 300, loss: 2.772475, top_1: 0.545742, top_k: 0.781172, samples/s: 1360.690 1612692419.183724
train: epoch 34, iter 400, loss: 3.085139, top_1: 0.535977, top_k: 0.770742, samples/s: 1356.629 1612692438.0540383
train: epoch 34, iter 500, loss: 3.131771, top_1: 0.537539, top_k: 0.768906, samples/s: 1333.664 1612692457.2492828
train: epoch 34, iter 600, loss: 2.860210, top_1: 0.541484, top_k: 0.773281, samples/s: 1334.012 1612692476.4395814
train: epoch 34, iter 700, loss: 2.851959, top_1: 0.544453, top_k: 0.775742, samples/s: 1337.412 1612692495.5809786
train: epoch 34, iter 800, loss: 3.022627, top_1: 0.546172, top_k: 0.776602, samples/s: 1328.082 1612692514.8569145
train: epoch 34, iter 900, loss: 2.974162, top_1: 0.546953, top_k: 0.776445, samples/s: 1335.080 1612692534.0317914
train: epoch 34, iter 1000, loss: 2.976734, top_1: 0.540937, top_k: 0.774453, samples/s: 1331.771 1612692553.25436
train: epoch 34, iter 1100, loss: 3.048622, top_1: 0.551992, top_k: 0.774141, samples/s: 1331.861 1612692572.4755049
train: epoch 34, iter 1200, loss: 2.795781, top_1: 0.540312, top_k: 0.771797, samples/s: 1332.169 1612692591.6922867
train: epoch 34, iter 1300, loss: 2.715008, top_1: 0.539141, top_k: 0.773789, samples/s: 1332.965 1612692610.897586
train: epoch 34, iter 1400, loss: 2.987736, top_1: 0.537031, top_k: 0.769727, samples/s: 1335.520 1612692630.0661552
train: epoch 34, iter 1500, loss: 2.874415, top_1: 0.540273, top_k: 0.771016, samples/s: 1334.163 1612692649.2542677
train: epoch 34, iter 1600, loss: 2.986867, top_1: 0.538242, top_k: 0.771211, samples/s: 1333.971 1612692668.4450977
train: epoch 34, iter 1700, loss: 3.116282, top_1: 0.537500, top_k: 0.770469, samples/s: 1333.897 1612692687.6370084
train: epoch 34, iter 1800, loss: 2.730279, top_1: 0.543164, top_k: 0.778555, samples/s: 1332.698 1612692706.8461306
train: epoch 34, iter 1900, loss: 3.099746, top_1: 0.537656, top_k: 0.769961, samples/s: 1334.047 1612692726.0358088
train: epoch 34, iter 2000, loss: 2.735327, top_1: 0.535430, top_k: 0.770352, samples/s: 1331.902 1612692745.256495
train: epoch 34, iter 2100, loss: 2.865178, top_1: 0.535039, top_k: 0.768086, samples/s: 1332.245 1612692764.4721854
train: epoch 34, iter 2200, loss: 2.885617, top_1: 0.543516, top_k: 0.775547, samples/s: 1340.782 1612692783.5655365
train: epoch 34, iter 2300, loss: 3.002727, top_1: 0.534805, top_k: 0.770000, samples/s: 1331.170 1612692802.7967873
train: epoch 34, iter 2400, loss: 3.065963, top_1: 0.539258, top_k: 0.771445, samples/s: 1337.496 1612692821.937
train: epoch 34, iter 2500, loss: 2.990874, top_1: 0.541328, top_k: 0.772227, samples/s: 1332.519 1612692841.1486561
train: epoch 34, iter 2600, loss: 2.970575, top_1: 0.536875, top_k: 0.767305, samples/s: 1338.231 1612692860.2784364
train: epoch 34, iter 2700, loss: 2.831940, top_1: 0.534336, top_k: 0.772109, samples/s: 1339.399 1612692879.3914404
train: epoch 34, iter 2800, loss: 2.976973, top_1: 0.535195, top_k: 0.769023, samples/s: 1340.035 1612692898.495542
train: epoch 34, iter 2900, loss: 2.860054, top_1: 0.536602, top_k: 0.767969, samples/s: 1331.180 1612692917.7275662
train: epoch 34, iter 3000, loss: 2.933505, top_1: 0.534023, top_k: 0.767617, samples/s: 1332.796 1612692936.9342659
train: epoch 34, iter 3100, loss: 2.888915, top_1: 0.533398, top_k: 0.768594, samples/s: 1338.788 1612692956.056301
train: epoch 34, iter 3200, loss: 2.920316, top_1: 0.533320, top_k: 0.768086, samples/s: 1336.695 1612692975.2077742
train: epoch 34, iter 3300, loss: 2.859964, top_1: 0.535586, top_k: 0.770273, samples/s: 1336.634 1612692994.3603554
train: epoch 34, iter 3400, loss: 3.079977, top_1: 0.531484, top_k: 0.765703, samples/s: 1340.797 1612693013.4534338
train: epoch 34, iter 3500, loss: 2.855511, top_1: 0.534141, top_k: 0.770664, samples/s: 1333.981 1612693032.6441627
train: epoch 34, iter 3600, loss: 2.876151, top_1: 0.536914, top_k: 0.768398, samples/s: 1333.799 1612693051.8374417
train: epoch 34, iter 3700, loss: 3.024216, top_1: 0.535312, top_k: 0.773398, samples/s: 1331.590 1612693071.06266
train: epoch 34, iter 3800, loss: 2.922157, top_1: 0.536602, top_k: 0.773125, samples/s: 1335.947 1612693090.2250175
train: epoch 34, iter 3900, loss: 2.977470, top_1: 0.537734, top_k: 0.771055, samples/s: 1339.736 1612693109.3332903
train: epoch 34, iter 4000, loss: 3.127653, top_1: 0.533711, top_k: 0.766055, samples/s: 1334.526 1612693128.5161183
train: epoch 34, iter 4100, loss: 2.874429, top_1: 0.538398, top_k: 0.770039, samples/s: 1338.132 1612693147.6472695
train: epoch 34, iter 4200, loss: 3.050887, top_1: 0.537227, top_k: 0.770820, samples/s: 1326.966 1612693166.9393425
train: epoch 34, iter 4300, loss: 2.948580, top_1: 0.529375, top_k: 0.765547, samples/s: 1338.620 1612693186.0636005
train: epoch 34, iter 4400, loss: 2.838224, top_1: 0.529492, top_k: 0.762461, samples/s: 1330.051 1612693205.3109179
train: epoch 34, iter 4500, loss: 3.141949, top_1: 0.533047, top_k: 0.769336, samples/s: 1339.091 1612693224.4283962
train: epoch 34, iter 4600, loss: 2.933895, top_1: 0.535469, top_k: 0.767813, samples/s: 1338.789 1612693243.5501437
train: epoch 34, iter 4700, loss: 2.887567, top_1: 0.537617, top_k: 0.767070, samples/s: 1330.156 1612693262.795992
train: epoch 34, iter 4800, loss: 2.981704, top_1: 0.534883, top_k: 0.771016, samples/s: 1338.570 1612693281.9208512
train: epoch 34, iter 4900, loss: 2.928142, top_1: 0.534531, top_k: 0.772773, samples/s: 1331.562 1612693301.1464617
train: epoch 34, iter 5000, loss: 2.944915, top_1: 0.539141, top_k: 0.769258, samples/s: 1343.465 1612693320.201599
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_34.
validation: epoch 34, iter 195, top_1: 0.584095, top_k: 0.822256, samples/s: 2788.701 1612693338.6736538
train: epoch 35, iter 100, loss: 3.056876, top_1: 0.553203, top_k: 0.783125, samples/s: 1360.181 1612693374.0264418
train: epoch 35, iter 200, loss: 2.987312, top_1: 0.545586, top_k: 0.779336, samples/s: 1359.937 1612693392.850975
train: epoch 35, iter 300, loss: 2.886021, top_1: 0.545859, top_k: 0.777227, samples/s: 1359.746 1612693411.6778104
train: epoch 35, iter 400, loss: 3.021973, top_1: 0.543594, top_k: 0.777656, samples/s: 1356.894 1612693430.544429
train: epoch 35, iter 500, loss: 3.144241, top_1: 0.542422, top_k: 0.779922, samples/s: 1340.807 1612693449.6377006
train: epoch 35, iter 600, loss: 2.948570, top_1: 0.533906, top_k: 0.771484, samples/s: 1329.589 1612693468.8914907
train: epoch 35, iter 700, loss: 2.884004, top_1: 0.544414, top_k: 0.774883, samples/s: 1338.662 1612693488.015523
train: epoch 35, iter 800, loss: 3.078190, top_1: 0.539453, top_k: 0.772969, samples/s: 1332.061 1612693507.233422
train: epoch 35, iter 900, loss: 2.960077, top_1: 0.542617, top_k: 0.774844, samples/s: 1334.069 1612693526.422852
train: epoch 35, iter 1000, loss: 3.025241, top_1: 0.536250, top_k: 0.771680, samples/s: 1333.008 1612693545.6275263
train: epoch 35, iter 1100, loss: 2.858907, top_1: 0.541836, top_k: 0.779687, samples/s: 1330.384 1612693564.8700478
train: epoch 35, iter 1200, loss: 2.908592, top_1: 0.541992, top_k: 0.774531, samples/s: 1333.897 1612693584.061979
train: epoch 35, iter 1300, loss: 2.895161, top_1: 0.541602, top_k: 0.775000, samples/s: 1336.274 1612693603.2196925
train: epoch 35, iter 1400, loss: 2.794055, top_1: 0.543242, top_k: 0.772383, samples/s: 1331.215 1612693622.450228
train: epoch 35, iter 1500, loss: 2.944468, top_1: 0.540742, top_k: 0.774531, samples/s: 1327.620 1612693641.7328563
train: epoch 35, iter 1600, loss: 2.905044, top_1: 0.543984, top_k: 0.774023, samples/s: 1344.279 1612693660.776517
train: epoch 35, iter 1700, loss: 3.054522, top_1: 0.545234, top_k: 0.777500, samples/s: 1329.900 1612693680.026106
train: epoch 35, iter 1800, loss: 2.854033, top_1: 0.540078, top_k: 0.773516, samples/s: 1336.655 1612693699.1784866
train: epoch 35, iter 1900, loss: 3.017684, top_1: 0.537188, top_k: 0.770664, samples/s: 1336.585 1612693718.3316581
train: epoch 35, iter 2000, loss: 2.859210, top_1: 0.538906, top_k: 0.771055, samples/s: 1335.476 1612693737.5008426
train: epoch 35, iter 2100, loss: 3.054562, top_1: 0.538438, top_k: 0.769453, samples/s: 1333.071 1612693756.7046874
train: epoch 35, iter 2200, loss: 2.625532, top_1: 0.535078, top_k: 0.768242, samples/s: 1333.184 1612693775.9068544
train: epoch 35, iter 2300, loss: 2.941154, top_1: 0.541680, top_k: 0.772383, samples/s: 1334.579 1612693795.0888686
train: epoch 35, iter 2400, loss: 2.852801, top_1: 0.536797, top_k: 0.766094, samples/s: 1335.683 1612693814.2551289
train: epoch 35, iter 2500, loss: 3.190254, top_1: 0.538477, top_k: 0.771523, samples/s: 1330.729 1612693833.4926682
train: epoch 35, iter 2600, loss: 2.986435, top_1: 0.540156, top_k: 0.770039, samples/s: 1335.750 1612693852.6579237
train: epoch 35, iter 2700, loss: 2.895319, top_1: 0.536992, top_k: 0.773164, samples/s: 1338.531 1612693871.7833736
train: epoch 35, iter 2800, loss: 2.862928, top_1: 0.542734, top_k: 0.770352, samples/s: 1336.354 1612693890.9399667
train: epoch 35, iter 2900, loss: 2.898304, top_1: 0.532695, top_k: 0.769883, samples/s: 1333.239 1612693910.1413624
train: epoch 35, iter 3000, loss: 2.882691, top_1: 0.543047, top_k: 0.773516, samples/s: 1337.610 1612693929.279947
train: epoch 35, iter 3100, loss: 3.072114, top_1: 0.536953, top_k: 0.766055, samples/s: 1331.742 1612693948.5028937
train: epoch 35, iter 3200, loss: 2.830203, top_1: 0.539609, top_k: 0.772422, samples/s: 1338.860 1612693967.623612
train: epoch 35, iter 3300, loss: 3.001065, top_1: 0.539883, top_k: 0.773438, samples/s: 1336.750 1612693986.774595
train: epoch 35, iter 3400, loss: 2.914974, top_1: 0.539805, top_k: 0.773164, samples/s: 1330.780 1612694006.0113728
train: epoch 35, iter 3500, loss: 2.846455, top_1: 0.533633, top_k: 0.771914, samples/s: 1333.476 1612694025.2093253
train: epoch 35, iter 3600, loss: 2.979553, top_1: 0.532930, top_k: 0.768906, samples/s: 1335.043 1612694044.3848138
train: epoch 35, iter 3700, loss: 2.962934, top_1: 0.543398, top_k: 0.775039, samples/s: 1338.582 1612694063.5095892
train: epoch 35, iter 3800, loss: 2.951548, top_1: 0.533945, top_k: 0.769648, samples/s: 1335.067 1612694082.6845214
train: epoch 35, iter 3900, loss: 3.015987, top_1: 0.539297, top_k: 0.771563, samples/s: 1330.481 1612694101.9257815
train: epoch 35, iter 4000, loss: 2.869257, top_1: 0.538281, top_k: 0.771758, samples/s: 1337.036 1612694121.0724971
train: epoch 35, iter 4100, loss: 3.010449, top_1: 0.532383, top_k: 0.769219, samples/s: 1343.049 1612694140.1336439
train: epoch 35, iter 4200, loss: 2.969338, top_1: 0.537266, top_k: 0.768672, samples/s: 1328.505 1612694159.4034073
train: epoch 35, iter 4300, loss: 2.925373, top_1: 0.539609, top_k: 0.773945, samples/s: 1337.119 1612694178.5490355
train: epoch 35, iter 4400, loss: 2.789538, top_1: 0.536992, top_k: 0.772148, samples/s: 1333.916 1612694197.7406492
train: epoch 35, iter 4500, loss: 2.905042, top_1: 0.533516, top_k: 0.769531, samples/s: 1330.151 1612694216.9866168
train: epoch 35, iter 4600, loss: 2.845276, top_1: 0.536953, top_k: 0.772930, samples/s: 1339.196 1612694236.1025872
train: epoch 35, iter 4700, loss: 2.981345, top_1: 0.535195, top_k: 0.766055, samples/s: 1331.202 1612694255.3332949
train: epoch 35, iter 4800, loss: 2.970379, top_1: 0.536172, top_k: 0.771406, samples/s: 1340.078 1612694274.436726
train: epoch 35, iter 4900, loss: 2.989536, top_1: 0.540352, top_k: 0.769414, samples/s: 1340.911 1612694293.5281553
train: epoch 35, iter 5000, loss: 2.683251, top_1: 0.544648, top_k: 0.773633, samples/s: 1321.716 1612694312.896944
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_35.
validation: epoch 35, iter 195, top_1: 0.586478, top_k: 0.823878, samples/s: 2791.098 1612694331.261434
train: epoch 36, iter 100, loss: 2.975177, top_1: 0.553398, top_k: 0.786055, samples/s: 1351.241 1612694366.583982
train: epoch 36, iter 200, loss: 2.857970, top_1: 0.548672, top_k: 0.782422, samples/s: 1361.759 1612694385.3832014
train: epoch 36, iter 300, loss: 2.708870, top_1: 0.551016, top_k: 0.785117, samples/s: 1357.366 1612694404.2433612
train: epoch 36, iter 400, loss: 2.926985, top_1: 0.545625, top_k: 0.778125, samples/s: 1354.716 1612694423.1404912
train: epoch 36, iter 500, loss: 2.872368, top_1: 0.542734, top_k: 0.772266, samples/s: 1342.257 1612694442.2125947
train: epoch 36, iter 600, loss: 3.226961, top_1: 0.542344, top_k: 0.777422, samples/s: 1332.558 1612694461.4237494
train: epoch 36, iter 700, loss: 2.962199, top_1: 0.549336, top_k: 0.778906, samples/s: 1329.384 1612694480.6808999
train: epoch 36, iter 800, loss: 2.932783, top_1: 0.544805, top_k: 0.777539, samples/s: 1328.571 1612694499.9496057
train: epoch 36, iter 900, loss: 2.907071, top_1: 0.536992, top_k: 0.771250, samples/s: 1339.916 1612694519.0553496
train: epoch 36, iter 1000, loss: 2.916569, top_1: 0.545742, top_k: 0.776172, samples/s: 1329.170 1612694538.3153954
train: epoch 36, iter 1100, loss: 3.019965, top_1: 0.537656, top_k: 0.772500, samples/s: 1337.570 1612694557.4546864
train: epoch 36, iter 1200, loss: 2.999075, top_1: 0.541328, top_k: 0.770703, samples/s: 1331.542 1612694576.6804578
train: epoch 36, iter 1300, loss: 2.944553, top_1: 0.544141, top_k: 0.777422, samples/s: 1326.326 1612694595.9818928
train: epoch 36, iter 1400, loss: 3.005589, top_1: 0.541641, top_k: 0.775156, samples/s: 1340.958 1612694615.0727363
train: epoch 36, iter 1500, loss: 2.686477, top_1: 0.536055, top_k: 0.770234, samples/s: 1334.636 1612694634.2540002
train: epoch 36, iter 1600, loss: 2.949629, top_1: 0.542461, top_k: 0.771484, samples/s: 1328.962 1612694653.5170827
train: epoch 36, iter 1700, loss: 2.790098, top_1: 0.543086, top_k: 0.776602, samples/s: 1333.312 1612694672.717443
train: epoch 36, iter 1800, loss: 2.871035, top_1: 0.539336, top_k: 0.771328, samples/s: 1335.579 1612694691.8851044
train: epoch 36, iter 1900, loss: 2.930431, top_1: 0.541875, top_k: 0.772461, samples/s: 1330.297 1612694711.1289337
train: epoch 36, iter 2000, loss: 2.941051, top_1: 0.539961, top_k: 0.772500, samples/s: 1334.643 1612694730.310164
train: epoch 36, iter 2100, loss: 2.833039, top_1: 0.535898, top_k: 0.771172, samples/s: 1336.638 1612694749.462675
train: epoch 36, iter 2200, loss: 2.885926, top_1: 0.533633, top_k: 0.772617, samples/s: 1331.816 1612694768.684648
train: epoch 36, iter 2300, loss: 2.925392, top_1: 0.544492, top_k: 0.773633, samples/s: 1337.727 1612694787.8214853
train: epoch 36, iter 2400, loss: 2.866489, top_1: 0.540625, top_k: 0.772656, samples/s: 1329.355 1612694807.0789375
train: epoch 36, iter 2500, loss: 2.933779, top_1: 0.537695, top_k: 0.769453, samples/s: 1337.383 1612694826.2207525
train: epoch 36, iter 2600, loss: 2.828166, top_1: 0.539180, top_k: 0.775234, samples/s: 1331.386 1612694845.4488332
train: epoch 36, iter 2700, loss: 3.008667, top_1: 0.536523, top_k: 0.770586, samples/s: 1336.592 1612694864.6020606
train: epoch 36, iter 2800, loss: 2.955821, top_1: 0.537461, top_k: 0.771133, samples/s: 1330.268 1612694883.846356
train: epoch 36, iter 2900, loss: 3.073222, top_1: 0.540625, top_k: 0.774336, samples/s: 1338.361 1612694902.9741287
train: epoch 36, iter 3000, loss: 2.886146, top_1: 0.541211, top_k: 0.768320, samples/s: 1338.689 1612694922.0973222
train: epoch 36, iter 3100, loss: 3.004744, top_1: 0.534922, top_k: 0.768555, samples/s: 1334.808 1612694941.2761066
train: epoch 36, iter 3200, loss: 2.870025, top_1: 0.542734, top_k: 0.773555, samples/s: 1328.267 1612694960.549398
train: epoch 36, iter 3300, loss: 2.897944, top_1: 0.542500, top_k: 0.773477, samples/s: 1339.105 1612694979.6665814
train: epoch 36, iter 3400, loss: 2.881472, top_1: 0.538945, top_k: 0.771641, samples/s: 1336.517 1612694998.8208487
train: epoch 36, iter 3500, loss: 3.101679, top_1: 0.536328, top_k: 0.770117, samples/s: 1329.699 1612695018.0733302
train: epoch 36, iter 3600, loss: 2.855030, top_1: 0.536836, top_k: 0.774297, samples/s: 1339.038 1612695037.1915863
train: epoch 36, iter 3700, loss: 2.993808, top_1: 0.539141, top_k: 0.772813, samples/s: 1329.976 1612695056.4400191
train: epoch 36, iter 3800, loss: 3.009022, top_1: 0.543750, top_k: 0.773711, samples/s: 1333.088 1612695075.6435385
train: epoch 36, iter 3900, loss: 3.139555, top_1: 0.535352, top_k: 0.769102, samples/s: 1336.719 1612695094.7948961
train: epoch 36, iter 4000, loss: 2.979245, top_1: 0.540000, top_k: 0.773086, samples/s: 1342.471 1612695113.864313
train: epoch 36, iter 4100, loss: 2.777563, top_1: 0.540273, top_k: 0.770898, samples/s: 1335.327 1612695133.0355382
train: epoch 36, iter 4200, loss: 3.304184, top_1: 0.533750, top_k: 0.771680, samples/s: 1333.065 1612695152.2394042
train: epoch 36, iter 4300, loss: 2.866986, top_1: 0.536602, top_k: 0.767305, samples/s: 1338.942 1612695171.3590224
train: epoch 36, iter 4400, loss: 2.969386, top_1: 0.533789, top_k: 0.769336, samples/s: 1330.925 1612695190.5937786
train: epoch 36, iter 4500, loss: 3.093482, top_1: 0.536289, top_k: 0.774102, samples/s: 1335.163 1612695209.7674766
train: epoch 36, iter 4600, loss: 2.789573, top_1: 0.535273, top_k: 0.771719, samples/s: 1333.530 1612695228.9645853
train: epoch 36, iter 4700, loss: 3.009360, top_1: 0.537617, top_k: 0.772383, samples/s: 1337.086 1612695248.1107683
train: epoch 36, iter 4800, loss: 2.954683, top_1: 0.537227, top_k: 0.768242, samples/s: 1339.581 1612695267.2211416
train: epoch 36, iter 4900, loss: 2.884406, top_1: 0.540937, top_k: 0.772617, samples/s: 1330.100 1612695286.467852
train: epoch 36, iter 5000, loss: 2.599019, top_1: 0.543789, top_k: 0.775703, samples/s: 1338.855 1612695305.5886397
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_36.
validation: epoch 36, iter 195, top_1: 0.588321, top_k: 0.827624, samples/s: 2812.203 1612695323.942204
train: epoch 37, iter 100, loss: 2.894648, top_1: 0.546562, top_k: 0.779258, samples/s: 1355.604 1612695359.478604
train: epoch 37, iter 200, loss: 3.064706, top_1: 0.542578, top_k: 0.778359, samples/s: 1360.648 1612695378.2931435
train: epoch 37, iter 300, loss: 2.831723, top_1: 0.549648, top_k: 0.781680, samples/s: 1356.864 1612695397.1605666
train: epoch 37, iter 400, loss: 3.077445, top_1: 0.548203, top_k: 0.779570, samples/s: 1350.337 1612695416.1184819
train: epoch 37, iter 500, loss: 2.770707, top_1: 0.545898, top_k: 0.779922, samples/s: 1335.871 1612695435.2819762
train: epoch 37, iter 600, loss: 2.777054, top_1: 0.553164, top_k: 0.779492, samples/s: 1324.606 1612695454.6084497
train: epoch 37, iter 700, loss: 2.684149, top_1: 0.543008, top_k: 0.777930, samples/s: 1331.591 1612695473.8335888
train: epoch 37, iter 800, loss: 2.637888, top_1: 0.541875, top_k: 0.777617, samples/s: 1329.410 1612695493.0903602
train: epoch 37, iter 900, loss: 3.029504, top_1: 0.539375, top_k: 0.772422, samples/s: 1333.362 1612695512.2902555
train: epoch 37, iter 1000, loss: 2.819840, top_1: 0.539883, top_k: 0.774961, samples/s: 1322.445 1612695531.6479275
train: epoch 37, iter 1100, loss: 2.944043, top_1: 0.546758, top_k: 0.777656, samples/s: 1331.629 1612695550.8726025
train: epoch 37, iter 1200, loss: 2.820117, top_1: 0.545508, top_k: 0.776992, samples/s: 1332.468 1612695570.0849686
train: epoch 37, iter 1300, loss: 2.706117, top_1: 0.545391, top_k: 0.780781, samples/s: 1324.536 1612695589.4124873
train: epoch 37, iter 1400, loss: 2.965672, top_1: 0.536758, top_k: 0.771680, samples/s: 1336.003 1612695608.574129
train: epoch 37, iter 1500, loss: 2.718835, top_1: 0.544141, top_k: 0.775078, samples/s: 1332.252 1612695627.7897174
train: epoch 37, iter 1600, loss: 3.103005, top_1: 0.544648, top_k: 0.776484, samples/s: 1328.845 1612695647.0545447
train: epoch 37, iter 1700, loss: 2.804331, top_1: 0.544453, top_k: 0.774453, samples/s: 1326.563 1612695666.352534
train: epoch 37, iter 1800, loss: 2.748688, top_1: 0.540039, top_k: 0.774062, samples/s: 1332.268 1612695685.5678985
train: epoch 37, iter 1900, loss: 3.010588, top_1: 0.538164, top_k: 0.775430, samples/s: 1330.169 1612695704.813622
train: epoch 37, iter 2000, loss: 3.057112, top_1: 0.541562, top_k: 0.773203, samples/s: 1333.369 1612695724.013059
train: epoch 37, iter 2100, loss: 2.868951, top_1: 0.540117, top_k: 0.770273, samples/s: 1329.927 1612695743.2622867
train: epoch 37, iter 2200, loss: 2.921767, top_1: 0.544141, top_k: 0.775430, samples/s: 1328.042 1612695762.5387824
train: epoch 37, iter 2300, loss: 2.769226, top_1: 0.542148, top_k: 0.775234, samples/s: 1332.475 1612695781.7511404
train: epoch 37, iter 2400, loss: 2.937232, top_1: 0.537070, top_k: 0.771445, samples/s: 1329.090 1612695801.0124114
train: epoch 37, iter 2500, loss: 2.876865, top_1: 0.536797, top_k: 0.768750, samples/s: 1330.314 1612695820.2559872
train: epoch 37, iter 2600, loss: 2.705737, top_1: 0.542109, top_k: 0.774922, samples/s: 1337.408 1612695839.397587
train: epoch 37, iter 2700, loss: 2.975659, top_1: 0.529258, top_k: 0.772617, samples/s: 1334.863 1612695858.575497
train: epoch 37, iter 2800, loss: 3.039301, top_1: 0.547188, top_k: 0.776484, samples/s: 1328.430 1612695877.8463616
train: epoch 37, iter 2900, loss: 2.821524, top_1: 0.540508, top_k: 0.774687, samples/s: 1326.483 1612695897.1456048
train: epoch 37, iter 3000, loss: 2.774887, top_1: 0.540039, top_k: 0.773047, samples/s: 1337.868 1612695916.2805493
train: epoch 37, iter 3100, loss: 2.894987, top_1: 0.539805, top_k: 0.772500, samples/s: 1334.802 1612695935.4593582
train: epoch 37, iter 3200, loss: 2.830554, top_1: 0.543477, top_k: 0.774141, samples/s: 1332.964 1612695954.6647122
train: epoch 37, iter 3300, loss: 2.672627, top_1: 0.543125, top_k: 0.772148, samples/s: 1332.470 1612695973.8770852
train: epoch 37, iter 3400, loss: 2.939218, top_1: 0.539922, top_k: 0.773008, samples/s: 1332.580 1612695993.0879326
train: epoch 37, iter 3500, loss: 2.868515, top_1: 0.541484, top_k: 0.774805, samples/s: 1334.442 1612696012.2719827
train: epoch 37, iter 3600, loss: 3.015881, top_1: 0.538047, top_k: 0.767383, samples/s: 1334.073 1612696031.4613414
train: epoch 37, iter 3700, loss: 2.951849, top_1: 0.538438, top_k: 0.771016, samples/s: 1334.420 1612696050.6457143
train: epoch 37, iter 3800, loss: 2.814766, top_1: 0.539570, top_k: 0.770938, samples/s: 1330.920 1612696069.8806095
train: epoch 37, iter 3900, loss: 2.738729, top_1: 0.545859, top_k: 0.779883, samples/s: 1333.209 1612696089.082306
train: epoch 37, iter 4000, loss: 3.010060, top_1: 0.541328, top_k: 0.770703, samples/s: 1333.051 1612696108.2863774
train: epoch 37, iter 4100, loss: 2.940717, top_1: 0.546055, top_k: 0.778477, samples/s: 1330.947 1612696127.5208724
train: epoch 37, iter 4200, loss: 2.981794, top_1: 0.543594, top_k: 0.774414, samples/s: 1334.668 1612696146.7016666
train: epoch 37, iter 4300, loss: 3.010203, top_1: 0.535664, top_k: 0.771406, samples/s: 1333.596 1612696165.8978672
train: epoch 37, iter 4400, loss: 2.898709, top_1: 0.540000, top_k: 0.772070, samples/s: 1331.818 1612696185.1197548
train: epoch 37, iter 4500, loss: 2.899045, top_1: 0.535391, top_k: 0.769414, samples/s: 1330.195 1612696204.3650274
train: epoch 37, iter 4600, loss: 2.676848, top_1: 0.538438, top_k: 0.774180, samples/s: 1334.871 1612696223.5428462
train: epoch 37, iter 4700, loss: 2.943813, top_1: 0.543398, top_k: 0.774492, samples/s: 1332.697 1612696242.7520616
train: epoch 37, iter 4800, loss: 2.805931, top_1: 0.538438, top_k: 0.770508, samples/s: 1330.164 1612696261.997762
train: epoch 37, iter 4900, loss: 2.956054, top_1: 0.536680, top_k: 0.770781, samples/s: 1332.351 1612696281.2119842
train: epoch 37, iter 5000, loss: 2.945889, top_1: 0.547383, top_k: 0.776445, samples/s: 1329.956 1612696300.4607375
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_37.
validation: epoch 37, iter 195, top_1: 0.595653, top_k: 0.831591, samples/s: 2850.849 1612696318.509126
train: epoch 38, iter 100, loss: 2.912054, top_1: 0.543750, top_k: 0.778828, samples/s: 1356.745 1612696353.4139392
train: epoch 38, iter 200, loss: 2.820585, top_1: 0.551523, top_k: 0.781836, samples/s: 1359.641 1612696372.242338
train: epoch 38, iter 300, loss: 2.958486, top_1: 0.550312, top_k: 0.779961, samples/s: 1358.307 1612696391.0893662
train: epoch 38, iter 400, loss: 2.823015, top_1: 0.553125, top_k: 0.783789, samples/s: 1357.536 1612696409.947094
train: epoch 38, iter 500, loss: 3.091989, top_1: 0.540312, top_k: 0.776484, samples/s: 1335.868 1612696429.110631
train: epoch 38, iter 600, loss: 2.832082, top_1: 0.541836, top_k: 0.775273, samples/s: 1334.841 1612696448.2889593
train: epoch 38, iter 700, loss: 3.044443, top_1: 0.542539, top_k: 0.777266, samples/s: 1334.537 1612696467.4716198
train: epoch 38, iter 800, loss: 2.936966, top_1: 0.544687, top_k: 0.779336, samples/s: 1327.918 1612696486.7504091
train: epoch 38, iter 900, loss: 2.703704, top_1: 0.552891, top_k: 0.780273, samples/s: 1332.573 1612696505.9608803
train: epoch 38, iter 1000, loss: 2.739991, top_1: 0.538984, top_k: 0.771367, samples/s: 1336.785 1612696525.111672
train: epoch 38, iter 1100, loss: 2.861851, top_1: 0.540664, top_k: 0.777500, samples/s: 1334.919 1612696544.2884796
train: epoch 38, iter 1200, loss: 2.878119, top_1: 0.543438, top_k: 0.774453, samples/s: 1332.986 1612696563.4934695
train: epoch 38, iter 1300, loss: 2.786768, top_1: 0.543594, top_k: 0.776836, samples/s: 1337.367 1612696582.6355464
train: epoch 38, iter 1400, loss: 2.835642, top_1: 0.544961, top_k: 0.776641, samples/s: 1330.665 1612696601.8740523
train: epoch 38, iter 1500, loss: 2.849550, top_1: 0.548086, top_k: 0.780937, samples/s: 1328.255 1612696621.147488
train: epoch 38, iter 1600, loss: 2.966539, top_1: 0.544219, top_k: 0.778125, samples/s: 1332.795 1612696640.3552415
train: epoch 38, iter 1700, loss: 2.954936, top_1: 0.542266, top_k: 0.776133, samples/s: 1338.689 1612696659.478446
train: epoch 38, iter 1800, loss: 2.989340, top_1: 0.543672, top_k: 0.775117, samples/s: 1333.813 1612696678.6715362
train: epoch 38, iter 1900, loss: 2.926018, top_1: 0.544375, top_k: 0.775586, samples/s: 1336.079 1612696697.8320503
train: epoch 38, iter 2000, loss: 2.821649, top_1: 0.546250, top_k: 0.775352, samples/s: 1334.295 1612696717.0182297
train: epoch 38, iter 2100, loss: 2.935255, top_1: 0.542969, top_k: 0.775312, samples/s: 1336.546 1612696736.1721127
train: epoch 38, iter 2200, loss: 2.817272, top_1: 0.545352, top_k: 0.779375, samples/s: 1335.192 1612696755.3454468
train: epoch 38, iter 2300, loss: 3.014722, top_1: 0.542383, top_k: 0.773242, samples/s: 1335.527 1612696774.5138521
train: epoch 38, iter 2400, loss: 3.123254, top_1: 0.542500, top_k: 0.773281, samples/s: 1336.317 1612696793.6710112
train: epoch 38, iter 2500, loss: 2.929028, top_1: 0.538359, top_k: 0.772188, samples/s: 1335.765 1612696812.8360338
train: epoch 38, iter 2600, loss: 2.882987, top_1: 0.543008, top_k: 0.772227, samples/s: 1333.954 1612696832.0270672
train: epoch 38, iter 2700, loss: 2.880241, top_1: 0.537148, top_k: 0.773867, samples/s: 1336.812 1612696851.1771731
train: epoch 38, iter 2800, loss: 2.818034, top_1: 0.541836, top_k: 0.774687, samples/s: 1334.531 1612696870.3599322
train: epoch 38, iter 2900, loss: 2.972038, top_1: 0.543984, top_k: 0.773672, samples/s: 1331.825 1612696889.5819147
train: epoch 38, iter 3000, loss: 2.957189, top_1: 0.540703, top_k: 0.774023, samples/s: 1337.770 1612696908.7179778
train: epoch 38, iter 3100, loss: 3.035294, top_1: 0.545195, top_k: 0.773203, samples/s: 1338.420 1612696927.8453267
train: epoch 38, iter 3200, loss: 3.054187, top_1: 0.540156, top_k: 0.774805, samples/s: 1327.552 1612696947.1285994
train: epoch 38, iter 3300, loss: 2.930589, top_1: 0.537773, top_k: 0.769492, samples/s: 1340.143 1612696966.2310722
train: epoch 38, iter 3400, loss: 2.801930, top_1: 0.543320, top_k: 0.776172, samples/s: 1340.814 1612696985.323954
train: epoch 38, iter 3500, loss: 2.901552, top_1: 0.543203, top_k: 0.774414, samples/s: 1328.226 1612697004.5977693
train: epoch 38, iter 3600, loss: 2.960021, top_1: 0.543398, top_k: 0.774844, samples/s: 1335.225 1612697023.7705784
train: epoch 38, iter 3700, loss: 2.825992, top_1: 0.544844, top_k: 0.777539, samples/s: 1336.643 1612697042.9229743
train: epoch 38, iter 3800, loss: 2.921721, top_1: 0.543047, top_k: 0.773281, samples/s: 1337.997 1612697062.0560653
train: epoch 38, iter 3900, loss: 3.018575, top_1: 0.540664, top_k: 0.772031, samples/s: 1334.332 1612697081.241679
train: epoch 38, iter 4000, loss: 2.750504, top_1: 0.544023, top_k: 0.774336, samples/s: 1333.435 1612697100.4402273
train: epoch 38, iter 4100, loss: 2.857143, top_1: 0.542656, top_k: 0.774453, samples/s: 1335.250 1612697119.6127057
train: epoch 38, iter 4200, loss: 3.202329, top_1: 0.539531, top_k: 0.770586, samples/s: 1330.870 1612697138.8481972
train: epoch 38, iter 4300, loss: 2.831028, top_1: 0.539609, top_k: 0.775781, samples/s: 1336.623 1612697158.0009422
train: epoch 38, iter 4400, loss: 2.894111, top_1: 0.542578, top_k: 0.774922, samples/s: 1338.269 1612697177.1302404
train: epoch 38, iter 4500, loss: 2.982017, top_1: 0.539102, top_k: 0.772109, samples/s: 1330.179 1612697196.375701
train: epoch 38, iter 4600, loss: 2.834628, top_1: 0.537109, top_k: 0.770078, samples/s: 1337.682 1612697215.5132575
train: epoch 38, iter 4700, loss: 2.876431, top_1: 0.538242, top_k: 0.771094, samples/s: 1337.833 1612697234.648716
train: epoch 38, iter 4800, loss: 3.091510, top_1: 0.541719, top_k: 0.773047, samples/s: 1332.747 1612697253.85725
train: epoch 38, iter 4900, loss: 2.945588, top_1: 0.540977, top_k: 0.771953, samples/s: 1335.382 1612697273.0276551
train: epoch 38, iter 5000, loss: 2.614849, top_1: 0.543555, top_k: 0.773789, samples/s: 1335.075 1612697292.2026105
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_38.
validation: epoch 38, iter 195, top_1: 0.589002, top_k: 0.825681, samples/s: 2742.100 1612697310.973546
train: epoch 39, iter 100, loss: 2.862653, top_1: 0.558516, top_k: 0.791875, samples/s: 1358.367 1612697345.802772
train: epoch 39, iter 200, loss: 2.932485, top_1: 0.556094, top_k: 0.782734, samples/s: 1357.004 1612697364.6678069
train: epoch 39, iter 300, loss: 2.960057, top_1: 0.543789, top_k: 0.778125, samples/s: 1365.193 1612697383.4197013
train: epoch 39, iter 400, loss: 2.855155, top_1: 0.550703, top_k: 0.781914, samples/s: 1354.352 1612697402.3217824
train: epoch 39, iter 500, loss: 2.725722, top_1: 0.552813, top_k: 0.785937, samples/s: 1332.005 1612697421.5408778
train: epoch 39, iter 600, loss: 2.835390, top_1: 0.546836, top_k: 0.778516, samples/s: 1332.271 1612697440.7561932
train: epoch 39, iter 700, loss: 2.937662, top_1: 0.548086, top_k: 0.778906, samples/s: 1337.174 1612697459.9010937
train: epoch 39, iter 800, loss: 2.902441, top_1: 0.548359, top_k: 0.783984, samples/s: 1336.347 1612697479.0577471
train: epoch 39, iter 900, loss: 2.807314, top_1: 0.546172, top_k: 0.778906, samples/s: 1323.990 1612697498.3932354
train: epoch 39, iter 1000, loss: 2.886045, top_1: 0.544648, top_k: 0.780742, samples/s: 1331.832 1612697517.6149328
train: epoch 39, iter 1100, loss: 2.885699, top_1: 0.544414, top_k: 0.777305, samples/s: 1334.238 1612697536.801917
train: epoch 39, iter 1200, loss: 2.839212, top_1: 0.543008, top_k: 0.775156, samples/s: 1338.605 1612697555.926273
train: epoch 39, iter 1300, loss: 3.064509, top_1: 0.546055, top_k: 0.773477, samples/s: 1331.080 1612697575.1588697
train: epoch 39, iter 1400, loss: 2.916257, top_1: 0.543320, top_k: 0.775312, samples/s: 1335.003 1612697594.3347774
train: epoch 39, iter 1500, loss: 3.016044, top_1: 0.546055, top_k: 0.780664, samples/s: 1337.642 1612697613.472962
train: epoch 39, iter 1600, loss: 2.772926, top_1: 0.553047, top_k: 0.779180, samples/s: 1334.187 1612697632.6606197
train: epoch 39, iter 1700, loss: 2.951929, top_1: 0.540859, top_k: 0.776406, samples/s: 1331.480 1612697651.8873959
train: epoch 39, iter 1800, loss: 2.973727, top_1: 0.539648, top_k: 0.777109, samples/s: 1332.013 1612697671.1063793
train: epoch 39, iter 1900, loss: 2.941482, top_1: 0.540195, top_k: 0.775430, samples/s: 1332.415 1612697690.3196762
train: epoch 39, iter 2000, loss: 3.062837, top_1: 0.543125, top_k: 0.773125, samples/s: 1333.286 1612697709.5203621
train: epoch 39, iter 2100, loss: 2.767177, top_1: 0.544883, top_k: 0.776992, samples/s: 1339.189 1612697728.6363297
train: epoch 39, iter 2200, loss: 2.835039, top_1: 0.540469, top_k: 0.770820, samples/s: 1323.672 1612697747.9764903
train: epoch 39, iter 2300, loss: 3.109725, top_1: 0.540273, top_k: 0.774844, samples/s: 1328.053 1612697767.2528374
train: epoch 39, iter 2400, loss: 2.807651, top_1: 0.541719, top_k: 0.772031, samples/s: 1338.439 1612697786.3796384
train: epoch 39, iter 2500, loss: 2.674775, top_1: 0.547500, top_k: 0.774414, samples/s: 1340.465 1612697805.4774215
train: epoch 39, iter 2600, loss: 2.761385, top_1: 0.539297, top_k: 0.772773, samples/s: 1329.863 1612697824.7275689
train: epoch 39, iter 2700, loss: 2.902984, top_1: 0.544258, top_k: 0.778477, samples/s: 1334.206 1612697843.915004
train: epoch 39, iter 2800, loss: 2.858916, top_1: 0.539336, top_k: 0.772969, samples/s: 1323.868 1612697863.2522423
train: epoch 39, iter 2900, loss: 3.004198, top_1: 0.548281, top_k: 0.777852, samples/s: 1328.715 1612697882.5189729
train: epoch 39, iter 3000, loss: 2.890025, top_1: 0.548984, top_k: 0.781367, samples/s: 1335.085 1612697901.693789
train: epoch 39, iter 3100, loss: 2.848970, top_1: 0.544766, top_k: 0.775039, samples/s: 1330.284 1612697920.9378722
train: epoch 39, iter 3200, loss: 2.917374, top_1: 0.546250, top_k: 0.779414, samples/s: 1331.400 1612697940.1656694
train: epoch 39, iter 3300, loss: 2.774155, top_1: 0.544258, top_k: 0.772813, samples/s: 1338.670 1612697959.2891269
train: epoch 39, iter 3400, loss: 2.917322, top_1: 0.538008, top_k: 0.771641, samples/s: 1330.837 1612697978.5251374
train: epoch 39, iter 3500, loss: 2.938690, top_1: 0.545039, top_k: 0.776328, samples/s: 1332.824 1612697997.7326
train: epoch 39, iter 3600, loss: 2.826894, top_1: 0.546641, top_k: 0.776328, samples/s: 1327.778 1612698017.0128858
train: epoch 39, iter 3700, loss: 2.753969, top_1: 0.546211, top_k: 0.776016, samples/s: 1334.148 1612698036.201086
train: epoch 39, iter 3800, loss: 2.924858, top_1: 0.549922, top_k: 0.779141, samples/s: 1330.385 1612698055.4436214
train: epoch 39, iter 3900, loss: 2.860726, top_1: 0.545391, top_k: 0.780234, samples/s: 1333.619 1612698074.639598
train: epoch 39, iter 4000, loss: 2.826527, top_1: 0.540820, top_k: 0.774336, samples/s: 1332.109 1612698093.857221
train: epoch 39, iter 4100, loss: 3.023310, top_1: 0.536367, top_k: 0.768984, samples/s: 1334.687 1612698113.0377178
train: epoch 39, iter 4200, loss: 3.118220, top_1: 0.545625, top_k: 0.776758, samples/s: 1324.996 1612698132.358547
train: epoch 39, iter 4300, loss: 2.611792, top_1: 0.543984, top_k: 0.772734, samples/s: 1337.894 1612698151.493106
train: epoch 39, iter 4400, loss: 2.987045, top_1: 0.544453, top_k: 0.774453, samples/s: 1332.163 1612698170.7098906
train: epoch 39, iter 4500, loss: 2.734453, top_1: 0.540117, top_k: 0.774805, samples/s: 1328.432 1612698189.980751
train: epoch 39, iter 4600, loss: 2.798504, top_1: 0.537930, top_k: 0.771641, samples/s: 1329.511 1612698209.235949
train: epoch 39, iter 4700, loss: 2.585431, top_1: 0.542305, top_k: 0.772422, samples/s: 1333.058 1612698228.4399145
train: epoch 39, iter 4800, loss: 2.786555, top_1: 0.539297, top_k: 0.777070, samples/s: 1332.571 1612698247.6508944
train: epoch 39, iter 4900, loss: 2.708741, top_1: 0.545820, top_k: 0.773008, samples/s: 1332.749 1612698266.8593643
train: epoch 39, iter 5000, loss: 2.743227, top_1: 0.546836, top_k: 0.781523, samples/s: 1332.196 1612698286.0757086
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_39.
validation: epoch 39, iter 195, top_1: 0.602684, top_k: 0.833914, samples/s: 2814.900 1612698304.3911338
train: epoch 40, iter 100, loss: 2.777364, top_1: 0.547852, top_k: 0.783359, samples/s: 1360.384 1612698338.8893054
train: epoch 40, iter 200, loss: 2.815544, top_1: 0.548555, top_k: 0.777734, samples/s: 1357.797 1612698357.7433562
train: epoch 40, iter 300, loss: 2.867949, top_1: 0.546055, top_k: 0.780430, samples/s: 1361.567 1612698376.54518
train: epoch 40, iter 400, loss: 2.888667, top_1: 0.550937, top_k: 0.783047, samples/s: 1339.843 1612698395.651895
train: epoch 40, iter 500, loss: 2.691829, top_1: 0.547500, top_k: 0.780547, samples/s: 1339.200 1612698414.7677855
train: epoch 40, iter 600, loss: 2.970060, top_1: 0.546250, top_k: 0.775391, samples/s: 1327.157 1612698434.0571394
train: epoch 40, iter 700, loss: 2.843149, top_1: 0.546211, top_k: 0.778281, samples/s: 1329.319 1612698453.315133
train: epoch 40, iter 800, loss: 2.803020, top_1: 0.544883, top_k: 0.773750, samples/s: 1329.191 1612698472.5750093
train: epoch 40, iter 900, loss: 2.779163, top_1: 0.548477, top_k: 0.782305, samples/s: 1326.731 1612698491.870494
train: epoch 40, iter 1000, loss: 2.943543, top_1: 0.551680, top_k: 0.785156, samples/s: 1331.964 1612698511.0903022
train: epoch 40, iter 1100, loss: 2.848398, top_1: 0.550469, top_k: 0.782617, samples/s: 1323.354 1612698530.4350166
train: epoch 40, iter 1200, loss: 2.966125, top_1: 0.552422, top_k: 0.779609, samples/s: 1331.658 1612698549.6592407
train: epoch 40, iter 1300, loss: 3.011322, top_1: 0.546992, top_k: 0.777227, samples/s: 1328.087 1612698568.9350646
train: epoch 40, iter 1400, loss: 2.797492, top_1: 0.545430, top_k: 0.774609, samples/s: 1325.219 1612698588.252587
train: epoch 40, iter 1500, loss: 2.942319, top_1: 0.546875, top_k: 0.774062, samples/s: 1332.319 1612698607.467217
train: epoch 40, iter 1600, loss: 2.922709, top_1: 0.547383, top_k: 0.777539, samples/s: 1326.655 1612698626.76392
train: epoch 40, iter 1700, loss: 2.980402, top_1: 0.544258, top_k: 0.777461, samples/s: 1323.120 1612698646.1121342
train: epoch 40, iter 1800, loss: 2.704960, top_1: 0.555742, top_k: 0.782344, samples/s: 1326.177 1612698665.4157708
train: epoch 40, iter 1900, loss: 2.733282, top_1: 0.549023, top_k: 0.779805, samples/s: 1333.404 1612698684.614704
train: epoch 40, iter 2000, loss: 2.861229, top_1: 0.551680, top_k: 0.779492, samples/s: 1330.400 1612698703.8569968
train: epoch 40, iter 2100, loss: 2.919279, top_1: 0.543320, top_k: 0.771641, samples/s: 1330.927 1612698723.0917084
train: epoch 40, iter 2200, loss: 2.816577, top_1: 0.541406, top_k: 0.774258, samples/s: 1325.471 1612698742.4055905
train: epoch 40, iter 2300, loss: 2.804689, top_1: 0.542148, top_k: 0.775430, samples/s: 1326.321 1612698761.7071104
train: epoch 40, iter 2400, loss: 2.978476, top_1: 0.546289, top_k: 0.779492, samples/s: 1325.965 1612698781.013865
train: epoch 40, iter 2500, loss: 2.697191, top_1: 0.547031, top_k: 0.780430, samples/s: 1334.297 1612698800.1999762
train: epoch 40, iter 2600, loss: 3.029846, top_1: 0.554883, top_k: 0.782070, samples/s: 1330.431 1612698819.4418638
train: epoch 40, iter 2700, loss: 2.941823, top_1: 0.543828, top_k: 0.778203, samples/s: 1328.288 1612698838.7147956
train: epoch 40, iter 2800, loss: 2.789999, top_1: 0.546562, top_k: 0.781094, samples/s: 1326.475 1612698858.0140324
train: epoch 40, iter 2900, loss: 2.913122, top_1: 0.544492, top_k: 0.778867, samples/s: 1326.357 1612698877.3150492
train: epoch 40, iter 3000, loss: 3.078123, top_1: 0.542852, top_k: 0.773164, samples/s: 1328.097 1612698896.5907338
train: epoch 40, iter 3100, loss: 2.750338, top_1: 0.546016, top_k: 0.777461, samples/s: 1335.994 1612698915.7525332
train: epoch 40, iter 3200, loss: 2.832714, top_1: 0.543164, top_k: 0.776758, samples/s: 1330.327 1612698934.995973
train: epoch 40, iter 3300, loss: 3.017148, top_1: 0.545391, top_k: 0.778242, samples/s: 1323.775 1612698954.334535
train: epoch 40, iter 3400, loss: 2.684339, top_1: 0.551680, top_k: 0.781016, samples/s: 1332.044 1612698973.5531356
train: epoch 40, iter 3500, loss: 2.845335, top_1: 0.543828, top_k: 0.777344, samples/s: 1331.105 1612698992.785246
train: epoch 40, iter 3600, loss: 2.772001, top_1: 0.540273, top_k: 0.771875, samples/s: 1316.704 1612699012.2278323
train: epoch 40, iter 3700, loss: 2.800428, top_1: 0.538398, top_k: 0.775937, samples/s: 1333.369 1612699031.4272583
train: epoch 40, iter 3800, loss: 2.988917, top_1: 0.541797, top_k: 0.773750, samples/s: 1333.489 1612699050.6250126
train: epoch 40, iter 3900, loss: 2.731997, top_1: 0.546406, top_k: 0.772422, samples/s: 1323.934 1612699069.9613526
train: epoch 40, iter 4000, loss: 2.911026, top_1: 0.541406, top_k: 0.775664, samples/s: 1331.074 1612699089.1938586
train: epoch 40, iter 4100, loss: 2.910053, top_1: 0.539336, top_k: 0.773828, samples/s: 1329.298 1612699108.4522696
train: epoch 40, iter 4200, loss: 2.852305, top_1: 0.538828, top_k: 0.775859, samples/s: 1328.397 1612699127.723546
train: epoch 40, iter 4300, loss: 2.980179, top_1: 0.534453, top_k: 0.766172, samples/s: 1330.959 1612699146.9578135
train: epoch 40, iter 4400, loss: 2.869766, top_1: 0.541055, top_k: 0.776484, samples/s: 1330.639 1612699166.1966379
train: epoch 40, iter 4500, loss: 3.049418, top_1: 0.541953, top_k: 0.775547, samples/s: 1321.223 1612699185.572671
train: epoch 40, iter 4600, loss: 2.820618, top_1: 0.543594, top_k: 0.776953, samples/s: 1330.924 1612699204.8074033
train: epoch 40, iter 4700, loss: 2.842080, top_1: 0.544375, top_k: 0.773125, samples/s: 1331.425 1612699224.0348988
train: epoch 40, iter 4800, loss: 2.904128, top_1: 0.537422, top_k: 0.773828, samples/s: 1327.253 1612699243.322929
train: epoch 40, iter 4900, loss: 2.807854, top_1: 0.540234, top_k: 0.776953, samples/s: 1334.045 1612699262.5127099
train: epoch 40, iter 5000, loss: 2.997717, top_1: 0.545000, top_k: 0.776172, samples/s: 1330.310 1612699281.7563014
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_40.
validation: epoch 40, iter 195, top_1: 0.589904, top_k: 0.826943, samples/s: 2721.049 1612699300.6601713
train: epoch 41, iter 100, loss: 2.895844, top_1: 0.549766, top_k: 0.781758, samples/s: 1358.723 1612699335.068647
train: epoch 41, iter 200, loss: 2.707460, top_1: 0.553867, top_k: 0.783203, samples/s: 1357.149 1612699353.9316387
train: epoch 41, iter 300, loss: 2.727743, top_1: 0.555469, top_k: 0.784609, samples/s: 1359.711 1612699372.7591882
train: epoch 41, iter 400, loss: 2.663652, top_1: 0.550078, top_k: 0.781250, samples/s: 1338.029 1612699391.891856
train: epoch 41, iter 500, loss: 2.944637, top_1: 0.551172, top_k: 0.780625, samples/s: 1321.519 1612699411.263462
train: epoch 41, iter 600, loss: 2.784901, top_1: 0.550352, top_k: 0.781055, samples/s: 1317.990 1612699430.6870792
train: epoch 41, iter 700, loss: 2.958860, top_1: 0.547578, top_k: 0.780742, samples/s: 1325.236 1612699450.0043614
train: epoch 41, iter 800, loss: 2.926637, top_1: 0.551445, top_k: 0.780859, samples/s: 1321.028 1612699469.383124
train: epoch 41, iter 900, loss: 2.751983, top_1: 0.547383, top_k: 0.777188, samples/s: 1324.391 1612699488.7127619
train: epoch 41, iter 1000, loss: 2.696981, top_1: 0.549023, top_k: 0.779180, samples/s: 1320.490 1612699508.0995712
train: epoch 41, iter 1100, loss: 2.835226, top_1: 0.553516, top_k: 0.783281, samples/s: 1326.154 1612699527.403448
train: epoch 41, iter 1200, loss: 3.014221, top_1: 0.553867, top_k: 0.787148, samples/s: 1323.158 1612699546.7511013
train: epoch 41, iter 1300, loss: 3.067739, top_1: 0.546523, top_k: 0.777813, samples/s: 1320.988 1612699566.1305797
train: epoch 41, iter 1400, loss: 2.920569, top_1: 0.551875, top_k: 0.781406, samples/s: 1324.227 1612699585.4626143
train: epoch 41, iter 1500, loss: 2.900953, top_1: 0.545078, top_k: 0.778516, samples/s: 1325.332 1612699604.7785292
train: epoch 41, iter 1600, loss: 2.893523, top_1: 0.546406, top_k: 0.777539, samples/s: 1323.858 1612699624.1158893
train: epoch 41, iter 1700, loss: 2.799560, top_1: 0.544492, top_k: 0.780898, samples/s: 1324.080 1612699643.4501338
train: epoch 41, iter 1800, loss: 2.830999, top_1: 0.555547, top_k: 0.783438, samples/s: 1325.865 1612699662.7583554
train: epoch 41, iter 1900, loss: 2.788231, top_1: 0.551133, top_k: 0.784727, samples/s: 1330.220 1612699682.003288
train: epoch 41, iter 2000, loss: 2.853671, top_1: 0.550391, top_k: 0.781563, samples/s: 1321.873 1612699701.3696346
train: epoch 41, iter 2100, loss: 2.825408, top_1: 0.549102, top_k: 0.774180, samples/s: 1323.560 1612699720.7114918
train: epoch 41, iter 2200, loss: 2.964785, top_1: 0.542188, top_k: 0.774414, samples/s: 1323.794 1612699740.0498128
train: epoch 41, iter 2300, loss: 2.743838, top_1: 0.551484, top_k: 0.778438, samples/s: 1330.525 1612699759.2902825
train: epoch 41, iter 2400, loss: 2.765853, top_1: 0.547305, top_k: 0.780859, samples/s: 1324.927 1612699778.6121588
train: epoch 41, iter 2500, loss: 2.847094, top_1: 0.542109, top_k: 0.776250, samples/s: 1316.217 1612699798.061799
train: epoch 41, iter 2600, loss: 2.837706, top_1: 0.547695, top_k: 0.778711, samples/s: 1327.892 1612699817.3405197
train: epoch 41, iter 2700, loss: 3.005842, top_1: 0.546797, top_k: 0.780234, samples/s: 1327.224 1612699836.628966
train: epoch 41, iter 2800, loss: 3.009206, top_1: 0.548008, top_k: 0.779453, samples/s: 1325.199 1612699855.9467475
train: epoch 41, iter 2900, loss: 2.856255, top_1: 0.547266, top_k: 0.779844, samples/s: 1327.777 1612699875.227081
train: epoch 41, iter 3000, loss: 2.809221, top_1: 0.546406, top_k: 0.777109, samples/s: 1326.208 1612699894.5301962
train: epoch 41, iter 3100, loss: 3.078112, top_1: 0.545156, top_k: 0.777656, samples/s: 1328.428 1612699913.8011153
train: epoch 41, iter 3200, loss: 2.790713, top_1: 0.549219, top_k: 0.777656, samples/s: 1327.766 1612699933.081661
train: epoch 41, iter 3300, loss: 3.026214, top_1: 0.547539, top_k: 0.774766, samples/s: 1322.697 1612699952.4360056
train: epoch 41, iter 3400, loss: 2.946836, top_1: 0.548359, top_k: 0.777969, samples/s: 1320.281 1612699971.8258111
train: epoch 41, iter 3500, loss: 2.909669, top_1: 0.544141, top_k: 0.777422, samples/s: 1324.589 1612699991.1526656
train: epoch 41, iter 3600, loss: 2.963850, top_1: 0.543984, top_k: 0.773477, samples/s: 1330.162 1612700010.3984008
train: epoch 41, iter 3700, loss: 2.770279, top_1: 0.538828, top_k: 0.773984, samples/s: 1327.619 1612700029.6809773
train: epoch 41, iter 3800, loss: 2.836296, top_1: 0.546602, top_k: 0.776133, samples/s: 1317.168 1612700049.1166215
train: epoch 41, iter 3900, loss: 2.914611, top_1: 0.541250, top_k: 0.776641, samples/s: 1332.034 1612700068.3353477
train: epoch 41, iter 4000, loss: 2.755580, top_1: 0.550742, top_k: 0.780391, samples/s: 1331.987 1612700087.5547507
train: epoch 41, iter 4100, loss: 2.895864, top_1: 0.544063, top_k: 0.775195, samples/s: 1322.596 1612700106.9106195
train: epoch 41, iter 4200, loss: 2.806325, top_1: 0.550117, top_k: 0.778047, samples/s: 1317.945 1612700126.3348572
train: epoch 41, iter 4300, loss: 2.813127, top_1: 0.549648, top_k: 0.776602, samples/s: 1326.450 1612700145.6345198
train: epoch 41, iter 4400, loss: 2.808915, top_1: 0.549648, top_k: 0.778281, samples/s: 1327.198 1612700164.9232652
train: epoch 41, iter 4500, loss: 2.969005, top_1: 0.546055, top_k: 0.775664, samples/s: 1320.189 1612700184.3144374
train: epoch 41, iter 4600, loss: 3.098805, top_1: 0.542539, top_k: 0.777813, samples/s: 1327.793 1612700203.59459
train: epoch 41, iter 4700, loss: 2.981159, top_1: 0.543125, top_k: 0.773359, samples/s: 1325.209 1612700222.9122202
train: epoch 41, iter 4800, loss: 2.926828, top_1: 0.542617, top_k: 0.774414, samples/s: 1324.905 1612700242.2343698
train: epoch 41, iter 4900, loss: 2.902474, top_1: 0.541914, top_k: 0.776250, samples/s: 1321.881 1612700261.600729
train: epoch 41, iter 5000, loss: 2.890397, top_1: 0.544414, top_k: 0.772695, samples/s: 1327.562 1612700280.8842118
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_41.
validation: epoch 41, iter 195, top_1: 0.596675, top_k: 0.832893, samples/s: 2778.669 1612700299.4164355
train: epoch 42, iter 100, loss: 2.924278, top_1: 0.559023, top_k: 0.787813, samples/s: 1360.392 1612700334.8965366
train: epoch 42, iter 200, loss: 2.651437, top_1: 0.556641, top_k: 0.783242, samples/s: 1359.190 1612700353.731564
train: epoch 42, iter 300, loss: 3.014627, top_1: 0.551328, top_k: 0.783281, samples/s: 1357.330 1612700372.5918744
train: epoch 42, iter 400, loss: 2.782928, top_1: 0.550859, top_k: 0.782539, samples/s: 1349.181 1612700391.5666814
train: epoch 42, iter 500, loss: 3.075268, top_1: 0.554258, top_k: 0.780039, samples/s: 1326.924 1612700410.8590157
train: epoch 42, iter 600, loss: 2.765392, top_1: 0.548281, top_k: 0.783281, samples/s: 1325.058 1612700430.1788685
train: epoch 42, iter 700, loss: 2.761362, top_1: 0.555625, top_k: 0.785234, samples/s: 1323.736 1612700449.5180717
train: epoch 42, iter 800, loss: 2.825721, top_1: 0.552695, top_k: 0.781484, samples/s: 1326.496 1612700468.8170521
train: epoch 42, iter 900, loss: 3.024577, top_1: 0.542578, top_k: 0.777070, samples/s: 1326.576 1612700488.1148717
train: epoch 42, iter 1000, loss: 2.791351, top_1: 0.552734, top_k: 0.780742, samples/s: 1327.785 1612700507.3951042
train: epoch 42, iter 1100, loss: 2.921499, top_1: 0.552617, top_k: 0.779805, samples/s: 1326.143 1612700526.6991487
train: epoch 42, iter 1200, loss: 2.851529, top_1: 0.545352, top_k: 0.776367, samples/s: 1323.238 1612700546.0456593
train: epoch 42, iter 1300, loss: 2.771581, top_1: 0.552461, top_k: 0.776875, samples/s: 1331.489 1612700565.2722986
train: epoch 42, iter 1400, loss: 2.957211, top_1: 0.540742, top_k: 0.774180, samples/s: 1315.495 1612700584.7329588
train: epoch 42, iter 1500, loss: 2.863526, top_1: 0.549805, top_k: 0.779844, samples/s: 1328.608 1612700604.0008614
train: epoch 42, iter 1600, loss: 2.733289, top_1: 0.545508, top_k: 0.777344, samples/s: 1327.989 1612700623.2781894
train: epoch 42, iter 1700, loss: 2.786747, top_1: 0.549180, top_k: 0.780703, samples/s: 1325.098 1612700642.5977988
train: epoch 42, iter 1800, loss: 2.886345, top_1: 0.548320, top_k: 0.779492, samples/s: 1331.536 1612700661.8234344
train: epoch 42, iter 1900, loss: 2.694437, top_1: 0.551484, top_k: 0.782656, samples/s: 1329.027 1612700681.0855885
train: epoch 42, iter 2000, loss: 3.026961, top_1: 0.544453, top_k: 0.778984, samples/s: 1325.985 1612700700.3920166
train: epoch 42, iter 2100, loss: 3.070591, top_1: 0.549453, top_k: 0.778242, samples/s: 1324.872 1612700719.7146943
train: epoch 42, iter 2200, loss: 2.992151, top_1: 0.543438, top_k: 0.774609, samples/s: 1330.690 1612700738.9527698
train: epoch 42, iter 2300, loss: 2.764560, top_1: 0.550664, top_k: 0.778750, samples/s: 1330.479 1612700758.1939948
train: epoch 42, iter 2400, loss: 2.734382, top_1: 0.543867, top_k: 0.775625, samples/s: 1323.679 1612700777.5340807
train: epoch 42, iter 2500, loss: 3.010118, top_1: 0.550859, top_k: 0.776680, samples/s: 1326.140 1612700796.8381927
train: epoch 42, iter 2600, loss: 2.933617, top_1: 0.552031, top_k: 0.782500, samples/s: 1328.590 1612700816.1066763
train: epoch 42, iter 2700, loss: 2.832895, top_1: 0.544414, top_k: 0.777656, samples/s: 1326.164 1612700835.4105644
train: epoch 42, iter 2800, loss: 2.878260, top_1: 0.549766, top_k: 0.778945, samples/s: 1328.823 1612700854.6756754
train: epoch 42, iter 2900, loss: 2.936727, top_1: 0.549336, top_k: 0.779727, samples/s: 1328.827 1612700873.9408314
train: epoch 42, iter 3000, loss: 2.980426, top_1: 0.548867, top_k: 0.776406, samples/s: 1329.631 1612700893.1944194
train: epoch 42, iter 3100, loss: 2.924757, top_1: 0.547383, top_k: 0.782305, samples/s: 1328.541 1612700912.4635673
train: epoch 42, iter 3200, loss: 2.955377, top_1: 0.549727, top_k: 0.778789, samples/s: 1326.272 1612700931.7656903
train: epoch 42, iter 3300, loss: 2.789883, top_1: 0.552227, top_k: 0.778633, samples/s: 1332.932 1612700950.9714825
train: epoch 42, iter 3400, loss: 2.875267, top_1: 0.548906, top_k: 0.781250, samples/s: 1318.852 1612700970.3823454
train: epoch 42, iter 3500, loss: 2.847724, top_1: 0.547773, top_k: 0.780469, samples/s: 1330.626 1612700989.6214056
train: epoch 42, iter 3600, loss: 2.786862, top_1: 0.545391, top_k: 0.778594, samples/s: 1325.709 1612701008.9317799
train: epoch 42, iter 3700, loss: 2.762523, top_1: 0.544883, top_k: 0.772969, samples/s: 1326.271 1612701028.2341144
train: epoch 42, iter 3800, loss: 2.989565, top_1: 0.542891, top_k: 0.777656, samples/s: 1321.100 1612701047.6118631
train: epoch 42, iter 3900, loss: 2.837780, top_1: 0.546406, top_k: 0.781563, samples/s: 1329.507 1612701066.8671048
train: epoch 42, iter 4000, loss: 2.718762, top_1: 0.547852, top_k: 0.779336, samples/s: 1328.465 1612701086.1379988
train: epoch 42, iter 4100, loss: 2.860703, top_1: 0.541406, top_k: 0.778633, samples/s: 1330.300 1612701105.381247
train: epoch 42, iter 4200, loss: 2.911155, top_1: 0.545234, top_k: 0.779648, samples/s: 1326.815 1612701124.6759331
train: epoch 42, iter 4300, loss: 2.943498, top_1: 0.552773, top_k: 0.778984, samples/s: 1323.823 1612701144.0135329
train: epoch 42, iter 4400, loss: 2.815279, top_1: 0.547813, top_k: 0.777656, samples/s: 1329.347 1612701163.2710786
train: epoch 42, iter 4500, loss: 2.880149, top_1: 0.546875, top_k: 0.776797, samples/s: 1325.908 1612701182.5786126
train: epoch 42, iter 4600, loss: 2.836252, top_1: 0.548047, top_k: 0.778281, samples/s: 1325.794 1612701201.8878126
train: epoch 42, iter 4700, loss: 2.757079, top_1: 0.548750, top_k: 0.782031, samples/s: 1324.414 1612701221.217064
train: epoch 42, iter 4800, loss: 2.774441, top_1: 0.543789, top_k: 0.774023, samples/s: 1323.146 1612701240.564876
train: epoch 42, iter 4900, loss: 2.966720, top_1: 0.548281, top_k: 0.778828, samples/s: 1330.714 1612701259.8026717
train: epoch 42, iter 5000, loss: 2.868976, top_1: 0.549844, top_k: 0.779258, samples/s: 1324.874 1612701279.125271
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_42.
validation: epoch 42, iter 195, top_1: 0.596434, top_k: 0.830709, samples/s: 2753.533 1612701297.8042092
train: epoch 43, iter 100, loss: 3.112276, top_1: 0.553672, top_k: 0.784961, samples/s: 1360.954 1612701332.9607213
train: epoch 43, iter 200, loss: 2.852134, top_1: 0.565742, top_k: 0.793359, samples/s: 1359.395 1612701351.79257
train: epoch 43, iter 300, loss: 3.041795, top_1: 0.551875, top_k: 0.785703, samples/s: 1360.002 1612701370.6161797
train: epoch 43, iter 400, loss: 2.853109, top_1: 0.555586, top_k: 0.779531, samples/s: 1340.627 1612701389.71164
train: epoch 43, iter 500, loss: 3.045908, top_1: 0.554766, top_k: 0.782617, samples/s: 1322.295 1612701409.0719502
train: epoch 43, iter 600, loss: 2.873422, top_1: 0.550781, top_k: 0.780625, samples/s: 1330.223 1612701428.3169386
train: epoch 43, iter 700, loss: 2.865021, top_1: 0.555234, top_k: 0.783750, samples/s: 1323.349 1612701447.6616898
train: epoch 43, iter 800, loss: 2.750377, top_1: 0.554570, top_k: 0.781953, samples/s: 1316.584 1612701467.105946
train: epoch 43, iter 900, loss: 2.927392, top_1: 0.546367, top_k: 0.777461, samples/s: 1328.051 1612701486.3822742
train: epoch 43, iter 1000, loss: 2.792882, top_1: 0.556797, top_k: 0.786992, samples/s: 1319.944 1612701505.777082
train: epoch 43, iter 1100, loss: 2.981197, top_1: 0.552891, top_k: 0.783750, samples/s: 1331.071 1612701525.0097075
train: epoch 43, iter 1200, loss: 2.993258, top_1: 0.545781, top_k: 0.778633, samples/s: 1324.440 1612701544.338696
train: epoch 43, iter 1300, loss: 2.997167, top_1: 0.546406, top_k: 0.779766, samples/s: 1327.916 1612701563.616971
train: epoch 43, iter 1400, loss: 2.718922, top_1: 0.550898, top_k: 0.783242, samples/s: 1323.561 1612701582.9588768
train: epoch 43, iter 1500, loss: 2.832672, top_1: 0.549336, top_k: 0.776055, samples/s: 1333.089 1612701602.162207
train: epoch 43, iter 1600, loss: 2.956800, top_1: 0.550352, top_k: 0.778984, samples/s: 1323.233 1612701621.5087602
train: epoch 43, iter 1700, loss: 2.945053, top_1: 0.552656, top_k: 0.784141, samples/s: 1325.652 1612701640.8200176
train: epoch 43, iter 1800, loss: 3.053509, top_1: 0.546328, top_k: 0.777891, samples/s: 1325.900 1612701660.1276543
train: epoch 43, iter 1900, loss: 2.711138, top_1: 0.552109, top_k: 0.781563, samples/s: 1331.145 1612701679.3592393
train: epoch 43, iter 2000, loss: 2.881353, top_1: 0.546562, top_k: 0.777031, samples/s: 1327.902 1612701698.6378303
train: epoch 43, iter 2100, loss: 2.931260, top_1: 0.550937, top_k: 0.779844, samples/s: 1318.235 1612701718.0576978
train: epoch 43, iter 2200, loss: 2.692709, top_1: 0.545391, top_k: 0.781836, samples/s: 1324.076 1612701737.391886
train: epoch 43, iter 2300, loss: 2.822390, top_1: 0.546367, top_k: 0.779609, samples/s: 1335.265 1612701756.5641897
train: epoch 43, iter 2400, loss: 2.675338, top_1: 0.548672, top_k: 0.780352, samples/s: 1329.504 1612701775.8194098
train: epoch 43, iter 2500, loss: 2.856975, top_1: 0.549609, top_k: 0.784336, samples/s: 1323.633 1612701795.160125
train: epoch 43, iter 2600, loss: 2.859530, top_1: 0.545312, top_k: 0.774453, samples/s: 1322.761 1612701814.5137205
train: epoch 43, iter 2700, loss: 3.040055, top_1: 0.550469, top_k: 0.779961, samples/s: 1324.275 1612701833.8449533
train: epoch 43, iter 2800, loss: 2.770528, top_1: 0.553047, top_k: 0.781406, samples/s: 1325.431 1612701853.159441
train: epoch 43, iter 2900, loss: 2.947798, top_1: 0.549492, top_k: 0.774687, samples/s: 1325.690 1612701872.4701211
train: epoch 43, iter 3000, loss: 2.925824, top_1: 0.546445, top_k: 0.780117, samples/s: 1326.617 1612701891.7673297
train: epoch 43, iter 3100, loss: 2.885507, top_1: 0.549141, top_k: 0.779102, samples/s: 1326.173 1612701911.0709722
train: epoch 43, iter 3200, loss: 2.945549, top_1: 0.546172, top_k: 0.776914, samples/s: 1322.603 1612701930.4267766
train: epoch 43, iter 3300, loss: 2.974281, top_1: 0.547734, top_k: 0.776719, samples/s: 1326.071 1612701949.7319176
train: epoch 43, iter 3400, loss: 3.015609, top_1: 0.543867, top_k: 0.776602, samples/s: 1318.347 1612701969.1501045
train: epoch 43, iter 3500, loss: 3.102374, top_1: 0.549648, top_k: 0.779062, samples/s: 1331.016 1612701988.3836098
train: epoch 43, iter 3600, loss: 2.972110, top_1: 0.544336, top_k: 0.774922, samples/s: 1320.387 1612702007.771793
train: epoch 43, iter 3700, loss: 2.755928, top_1: 0.544922, top_k: 0.777773, samples/s: 1331.513 1612702026.9980717
train: epoch 43, iter 3800, loss: 2.969954, top_1: 0.552148, top_k: 0.778047, samples/s: 1333.252 1612702046.1992571
train: epoch 43, iter 3900, loss: 2.771059, top_1: 0.547227, top_k: 0.782695, samples/s: 1325.421 1612702065.5138366
train: epoch 43, iter 4000, loss: 2.764023, top_1: 0.549453, top_k: 0.777070, samples/s: 1325.255 1612702084.8308754
train: epoch 43, iter 4100, loss: 2.919836, top_1: 0.550156, top_k: 0.777617, samples/s: 1332.246 1612702104.0465434
train: epoch 43, iter 4200, loss: 2.882096, top_1: 0.549648, top_k: 0.780430, samples/s: 1330.916 1612702123.28149
train: epoch 43, iter 4300, loss: 2.793512, top_1: 0.541641, top_k: 0.772891, samples/s: 1325.296 1612702142.5978465
train: epoch 43, iter 4400, loss: 2.990893, top_1: 0.552500, top_k: 0.783047, samples/s: 1322.405 1612702161.9565158
train: epoch 43, iter 4500, loss: 2.934132, top_1: 0.547852, top_k: 0.779336, samples/s: 1326.561 1612702181.2545383
train: epoch 43, iter 4600, loss: 2.926105, top_1: 0.546953, top_k: 0.776445, samples/s: 1323.663 1612702200.5948107
train: epoch 43, iter 4700, loss: 2.815447, top_1: 0.549219, top_k: 0.776445, samples/s: 1328.050 1612702219.8712478
train: epoch 43, iter 4800, loss: 2.790833, top_1: 0.549297, top_k: 0.781367, samples/s: 1329.868 1612702239.1213503
train: epoch 43, iter 4900, loss: 2.965406, top_1: 0.547500, top_k: 0.776133, samples/s: 1327.516 1612702258.4053974
train: epoch 43, iter 5000, loss: 2.779849, top_1: 0.541133, top_k: 0.774883, samples/s: 1322.637 1612702277.760637
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_43.
validation: epoch 43, iter 195, top_1: 0.587360, top_k: 0.826262, samples/s: 2683.475 1612702296.9266813
train: epoch 44, iter 100, loss: 2.893716, top_1: 0.558711, top_k: 0.786055, samples/s: 1357.032 1612702332.3450017
train: epoch 44, iter 200, loss: 2.777100, top_1: 0.560977, top_k: 0.788828, samples/s: 1362.459 1612702351.1345732
train: epoch 44, iter 300, loss: 2.824834, top_1: 0.556406, top_k: 0.785703, samples/s: 1351.059 1612702370.0827
train: epoch 44, iter 400, loss: 2.894024, top_1: 0.553945, top_k: 0.782852, samples/s: 1348.195 1612702389.070988
train: epoch 44, iter 500, loss: 2.800188, top_1: 0.553477, top_k: 0.783711, samples/s: 1324.882 1612702408.3934755
train: epoch 44, iter 600, loss: 2.955185, top_1: 0.554180, top_k: 0.784297, samples/s: 1322.378 1612702427.7525387
train: epoch 44, iter 700, loss: 3.084972, top_1: 0.552891, top_k: 0.783867, samples/s: 1330.113 1612702446.9990792
train: epoch 44, iter 800, loss: 2.882666, top_1: 0.557187, top_k: 0.784961, samples/s: 1325.551 1612702466.3118129
train: epoch 44, iter 900, loss: 2.997737, top_1: 0.556719, top_k: 0.785195, samples/s: 1328.271 1612702485.5849113
train: epoch 44, iter 1000, loss: 2.943081, top_1: 0.555312, top_k: 0.781914, samples/s: 1327.684 1612702504.866663
train: epoch 44, iter 1100, loss: 2.721029, top_1: 0.555391, top_k: 0.782695, samples/s: 1322.638 1612702524.2218735
train: epoch 44, iter 1200, loss: 2.914739, top_1: 0.550898, top_k: 0.780039, samples/s: 1316.148 1612702543.6726134
train: epoch 44, iter 1300, loss: 2.827606, top_1: 0.555508, top_k: 0.784219, samples/s: 1331.617 1612702562.8973773
train: epoch 44, iter 1400, loss: 2.725698, top_1: 0.553750, top_k: 0.780039, samples/s: 1329.602 1612702582.1511977
train: epoch 44, iter 1500, loss: 2.859258, top_1: 0.556758, top_k: 0.784961, samples/s: 1328.520 1612702601.4208128
train: epoch 44, iter 1600, loss: 2.817271, top_1: 0.554141, top_k: 0.789180, samples/s: 1325.033 1612702620.7410874
train: epoch 44, iter 1700, loss: 2.872303, top_1: 0.548945, top_k: 0.784336, samples/s: 1329.567 1612702639.995465
train: epoch 44, iter 1800, loss: 2.892818, top_1: 0.555430, top_k: 0.784258, samples/s: 1328.164 1612702659.2702181
train: epoch 44, iter 1900, loss: 2.852423, top_1: 0.552617, top_k: 0.779180, samples/s: 1327.737 1612702678.5510662
train: epoch 44, iter 2000, loss: 2.845819, top_1: 0.549375, top_k: 0.780625, samples/s: 1325.327 1612702697.867066
train: epoch 44, iter 2100, loss: 2.982821, top_1: 0.552031, top_k: 0.779336, samples/s: 1327.824 1612702717.1467597
train: epoch 44, iter 2200, loss: 2.856317, top_1: 0.551094, top_k: 0.778867, samples/s: 1325.746 1612702736.4566128
train: epoch 44, iter 2300, loss: 3.039181, top_1: 0.547305, top_k: 0.781406, samples/s: 1330.324 1612702755.700075
train: epoch 44, iter 2400, loss: 2.871351, top_1: 0.550937, top_k: 0.779023, samples/s: 1317.345 1612702775.133185
train: epoch 44, iter 2500, loss: 2.773527, top_1: 0.551016, top_k: 0.784648, samples/s: 1322.446 1612702794.4911306
train: epoch 44, iter 2600, loss: 2.879301, top_1: 0.549102, top_k: 0.781367, samples/s: 1320.796 1612702813.8733737
train: epoch 44, iter 2700, loss: 2.655286, top_1: 0.556406, top_k: 0.783242, samples/s: 1335.339 1612702833.0445268
train: epoch 44, iter 2800, loss: 2.781993, top_1: 0.556758, top_k: 0.784922, samples/s: 1336.819 1612702852.1953127
train: epoch 44, iter 2900, loss: 2.859360, top_1: 0.552891, top_k: 0.782070, samples/s: 1321.373 1612702871.568388
train: epoch 44, iter 3000, loss: 2.904824, top_1: 0.555312, top_k: 0.783320, samples/s: 1328.587 1612702890.8374755
train: epoch 44, iter 3100, loss: 2.838477, top_1: 0.548438, top_k: 0.778633, samples/s: 1328.941 1612702910.1003132
train: epoch 44, iter 3200, loss: 3.065330, top_1: 0.548516, top_k: 0.779453, samples/s: 1328.477 1612702929.370534
train: epoch 44, iter 3300, loss: 3.082994, top_1: 0.550586, top_k: 0.780078, samples/s: 1328.685 1612702948.6377277
train: epoch 44, iter 3400, loss: 3.008515, top_1: 0.544961, top_k: 0.777930, samples/s: 1318.355 1612702968.0558136
train: epoch 44, iter 3500, loss: 2.798942, top_1: 0.546250, top_k: 0.777461, samples/s: 1329.987 1612702987.304139
train: epoch 44, iter 3600, loss: 2.870304, top_1: 0.548555, top_k: 0.781055, samples/s: 1330.417 1612703006.5462782
train: epoch 44, iter 3700, loss: 2.840931, top_1: 0.543867, top_k: 0.775781, samples/s: 1319.637 1612703025.9455278
train: epoch 44, iter 3800, loss: 2.798987, top_1: 0.551719, top_k: 0.782227, samples/s: 1327.528 1612703045.2295103
train: epoch 44, iter 3900, loss: 2.893788, top_1: 0.544141, top_k: 0.773750, samples/s: 1318.445 1612703064.6462739
train: epoch 44, iter 4000, loss: 2.700376, top_1: 0.550742, top_k: 0.785000, samples/s: 1321.123 1612703084.023824
train: epoch 44, iter 4100, loss: 2.998350, top_1: 0.548906, top_k: 0.778477, samples/s: 1334.302 1612703103.2098799
train: epoch 44, iter 4200, loss: 2.986412, top_1: 0.546328, top_k: 0.778555, samples/s: 1325.843 1612703122.5182827
train: epoch 44, iter 4300, loss: 2.846133, top_1: 0.549375, top_k: 0.778047, samples/s: 1330.594 1612703141.757806
train: epoch 44, iter 4400, loss: 2.969366, top_1: 0.544844, top_k: 0.777266, samples/s: 1327.916 1612703161.0362723
train: epoch 44, iter 4500, loss: 3.105759, top_1: 0.554414, top_k: 0.784805, samples/s: 1323.652 1612703180.3765445
train: epoch 44, iter 4600, loss: 3.000355, top_1: 0.547227, top_k: 0.781797, samples/s: 1320.515 1612703199.7629201
train: epoch 44, iter 4700, loss: 3.045788, top_1: 0.549414, top_k: 0.778320, samples/s: 1334.550 1612703218.9454818
train: epoch 44, iter 4800, loss: 2.944873, top_1: 0.545430, top_k: 0.775859, samples/s: 1326.577 1612703238.2432718
train: epoch 44, iter 4900, loss: 3.055919, top_1: 0.551211, top_k: 0.781172, samples/s: 1314.976 1612703257.7112408
train: epoch 44, iter 5000, loss: 2.654210, top_1: 0.550156, top_k: 0.784023, samples/s: 1328.361 1612703276.9831
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_44.
validation: epoch 44, iter 195, top_1: 0.598137, top_k: 0.830970, samples/s: 2841.434 1612703295.0898418
train: epoch 45, iter 100, loss: 2.958953, top_1: 0.556953, top_k: 0.785977, samples/s: 1362.187 1612703330.0218048
train: epoch 45, iter 200, loss: 2.732720, top_1: 0.560312, top_k: 0.789375, samples/s: 1360.953 1612703348.8320591
train: epoch 45, iter 300, loss: 2.974353, top_1: 0.557266, top_k: 0.782813, samples/s: 1353.607 1612703367.7444444
train: epoch 45, iter 400, loss: 2.976377, top_1: 0.557187, top_k: 0.784375, samples/s: 1338.355 1612703386.8724813
train: epoch 45, iter 500, loss: 2.853192, top_1: 0.559258, top_k: 0.788984, samples/s: 1322.793 1612703406.2254472
train: epoch 45, iter 600, loss: 2.838687, top_1: 0.560586, top_k: 0.789883, samples/s: 1327.444 1612703425.5106258
train: epoch 45, iter 700, loss: 2.743113, top_1: 0.556953, top_k: 0.784961, samples/s: 1320.274 1612703444.9005651
train: epoch 45, iter 800, loss: 2.893498, top_1: 0.555586, top_k: 0.783906, samples/s: 1322.371 1612703464.2596564
train: epoch 45, iter 900, loss: 2.799154, top_1: 0.551055, top_k: 0.781641, samples/s: 1316.308 1612703483.7080832
train: epoch 45, iter 1000, loss: 2.809965, top_1: 0.555625, top_k: 0.785039, samples/s: 1324.878 1612703503.0305707
train: epoch 45, iter 1100, loss: 2.881684, top_1: 0.560937, top_k: 0.788008, samples/s: 1320.123 1612703522.422663
train: epoch 45, iter 1200, loss: 2.926898, top_1: 0.550273, top_k: 0.782422, samples/s: 1325.400 1612703541.7376442
train: epoch 45, iter 1300, loss: 2.836859, top_1: 0.548242, top_k: 0.780312, samples/s: 1323.176 1612703561.0850294
train: epoch 45, iter 1400, loss: 2.978667, top_1: 0.552500, top_k: 0.785898, samples/s: 1312.989 1612703580.5825288
train: epoch 45, iter 1500, loss: 2.842831, top_1: 0.562617, top_k: 0.787422, samples/s: 1325.671 1612703599.8934755
train: epoch 45, iter 1600, loss: 2.803583, top_1: 0.557617, top_k: 0.784062, samples/s: 1322.828 1612703619.245931
train: epoch 45, iter 1700, loss: 2.766088, top_1: 0.554688, top_k: 0.785156, samples/s: 1318.506 1612703638.661883
train: epoch 45, iter 1800, loss: 2.788419, top_1: 0.553398, top_k: 0.781953, samples/s: 1313.050 1612703658.1584923
train: epoch 45, iter 1900, loss: 3.066176, top_1: 0.550937, top_k: 0.780898, samples/s: 1331.556 1612703677.3840537
train: epoch 45, iter 2000, loss: 2.805880, top_1: 0.554219, top_k: 0.782227, samples/s: 1328.910 1612703696.648009
train: epoch 45, iter 2100, loss: 2.908104, top_1: 0.551484, top_k: 0.784648, samples/s: 1321.872 1612703716.0144358
train: epoch 45, iter 2200, loss: 2.799705, top_1: 0.548555, top_k: 0.777656, samples/s: 1314.870 1612703735.484093
train: epoch 45, iter 2300, loss: 2.883903, top_1: 0.556836, top_k: 0.785156, samples/s: 1323.235 1612703754.8306093
train: epoch 45, iter 2400, loss: 2.937643, top_1: 0.551445, top_k: 0.785898, samples/s: 1325.631 1612703774.1421201
train: epoch 45, iter 2500, loss: 2.766103, top_1: 0.548086, top_k: 0.779023, samples/s: 1323.494 1612703793.4848645
train: epoch 45, iter 2600, loss: 2.918047, top_1: 0.552227, top_k: 0.786055, samples/s: 1324.324 1612703812.8155613
train: epoch 45, iter 2700, loss: 2.631940, top_1: 0.551328, top_k: 0.783750, samples/s: 1310.940 1612703832.3435166
train: epoch 45, iter 2800, loss: 2.776501, top_1: 0.554688, top_k: 0.782266, samples/s: 1319.786 1612703851.7405288
train: epoch 45, iter 2900, loss: 2.884357, top_1: 0.555117, top_k: 0.782578, samples/s: 1326.852 1612703871.034418
train: epoch 45, iter 3000, loss: 2.901025, top_1: 0.552617, top_k: 0.780547, samples/s: 1327.839 1612703890.313809
train: epoch 45, iter 3100, loss: 2.781205, top_1: 0.553320, top_k: 0.780117, samples/s: 1319.211 1612703909.719352
train: epoch 45, iter 3200, loss: 2.803020, top_1: 0.559805, top_k: 0.785273, samples/s: 1324.068 1612703929.0536392
train: epoch 45, iter 3300, loss: 2.820809, top_1: 0.550195, top_k: 0.777695, samples/s: 1323.624 1612703948.3944962
train: epoch 45, iter 3400, loss: 2.872828, top_1: 0.548086, top_k: 0.780117, samples/s: 1325.101 1612703967.7138238
train: epoch 45, iter 3500, loss: 2.717085, top_1: 0.552969, top_k: 0.784258, samples/s: 1321.131 1612703987.0911837
train: epoch 45, iter 3600, loss: 2.980577, top_1: 0.551719, top_k: 0.778047, samples/s: 1327.492 1612704006.3756351
train: epoch 45, iter 3700, loss: 2.951080, top_1: 0.550977, top_k: 0.779961, samples/s: 1322.532 1612704025.7324145
train: epoch 45, iter 3800, loss: 2.716117, top_1: 0.550547, top_k: 0.781953, samples/s: 1319.405 1612704045.1350899
train: epoch 45, iter 3900, loss: 2.832401, top_1: 0.552734, top_k: 0.779805, samples/s: 1327.391 1612704064.4210923
train: epoch 45, iter 4000, loss: 2.966678, top_1: 0.556289, top_k: 0.783125, samples/s: 1331.468 1612704083.6480193
train: epoch 45, iter 4100, loss: 2.744393, top_1: 0.555391, top_k: 0.781445, samples/s: 1324.466 1612704102.976548
train: epoch 45, iter 4200, loss: 2.857926, top_1: 0.544531, top_k: 0.779922, samples/s: 1316.914 1612704122.4159284
train: epoch 45, iter 4300, loss: 2.849047, top_1: 0.546250, top_k: 0.777695, samples/s: 1323.515 1612704141.758338
train: epoch 45, iter 4400, loss: 2.979857, top_1: 0.545234, top_k: 0.778906, samples/s: 1324.328 1612704161.0888493
train: epoch 45, iter 4500, loss: 2.842286, top_1: 0.543828, top_k: 0.782969, samples/s: 1316.743 1612704180.5307713
train: epoch 45, iter 4600, loss: 3.005279, top_1: 0.552031, top_k: 0.783633, samples/s: 1324.288 1612704199.8619509
train: epoch 45, iter 4700, loss: 2.988177, top_1: 0.551133, top_k: 0.780117, samples/s: 1317.156 1612704219.2977233
train: epoch 45, iter 4800, loss: 2.775867, top_1: 0.552969, top_k: 0.780937, samples/s: 1329.841 1612704238.548314
train: epoch 45, iter 4900, loss: 2.908464, top_1: 0.548242, top_k: 0.776914, samples/s: 1324.440 1612704257.8770754
train: epoch 45, iter 5000, loss: 2.814692, top_1: 0.559141, top_k: 0.783125, samples/s: 1322.110 1612704277.2400522
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_45.
validation: epoch 45, iter 195, top_1: 0.600240, top_k: 0.835917, samples/s: 2738.207 1612704296.0566823
train: epoch 46, iter 100, loss: 2.771766, top_1: 0.567344, top_k: 0.794102, samples/s: 1363.083 1612704336.5174217
train: epoch 46, iter 200, loss: 2.782873, top_1: 0.561992, top_k: 0.790117, samples/s: 1362.299 1612704355.3091166
train: epoch 46, iter 300, loss: 2.775118, top_1: 0.567852, top_k: 0.791602, samples/s: 1360.024 1612704374.1323678
train: epoch 46, iter 400, loss: 2.864377, top_1: 0.559297, top_k: 0.788594, samples/s: 1350.133 1612704393.0934021
train: epoch 46, iter 500, loss: 2.753760, top_1: 0.556992, top_k: 0.788008, samples/s: 1327.100 1612704412.3835752
train: epoch 46, iter 600, loss: 2.819321, top_1: 0.559648, top_k: 0.786250, samples/s: 1331.163 1612704431.6148875
train: epoch 46, iter 700, loss: 2.787526, top_1: 0.560977, top_k: 0.787109, samples/s: 1327.985 1612704450.8922815
train: epoch 46, iter 800, loss: 2.806847, top_1: 0.560898, top_k: 0.787266, samples/s: 1313.704 1612704470.3790898
train: epoch 46, iter 900, loss: 2.858145, top_1: 0.563672, top_k: 0.788359, samples/s: 1327.301 1612704489.6663415
train: epoch 46, iter 1000, loss: 2.650450, top_1: 0.557656, top_k: 0.787148, samples/s: 1326.828 1612704508.9604924
train: epoch 46, iter 1100, loss: 2.862560, top_1: 0.552148, top_k: 0.779219, samples/s: 1324.734 1612704528.285113
train: epoch 46, iter 1200, loss: 2.675767, top_1: 0.556758, top_k: 0.785195, samples/s: 1327.076 1612704547.5756512
train: epoch 46, iter 1300, loss: 2.895241, top_1: 0.560039, top_k: 0.785312, samples/s: 1329.171 1612704566.8358278
train: epoch 46, iter 1400, loss: 2.845305, top_1: 0.560156, top_k: 0.789687, samples/s: 1322.309 1612704586.1958442
train: epoch 46, iter 1500, loss: 2.781157, top_1: 0.549687, top_k: 0.782969, samples/s: 1328.798 1612704605.4614446
train: epoch 46, iter 1600, loss: 3.008638, top_1: 0.557461, top_k: 0.788477, samples/s: 1324.849 1612704624.7843752
train: epoch 46, iter 1700, loss: 2.725445, top_1: 0.553633, top_k: 0.785547, samples/s: 1327.151 1612704644.0737798
train: epoch 46, iter 1800, loss: 2.778937, top_1: 0.551289, top_k: 0.785859, samples/s: 1327.619 1612704663.3564389
train: epoch 46, iter 1900, loss: 3.110450, top_1: 0.557148, top_k: 0.785312, samples/s: 1326.363 1612704682.6573148
train: epoch 46, iter 2000, loss: 2.995247, top_1: 0.556250, top_k: 0.785469, samples/s: 1324.049 1612704701.991952
train: epoch 46, iter 2100, loss: 2.612898, top_1: 0.550039, top_k: 0.782969, samples/s: 1328.661 1612704721.2595124
train: epoch 46, iter 2200, loss: 2.783628, top_1: 0.553164, top_k: 0.781211, samples/s: 1329.080 1612704740.520966
train: epoch 46, iter 2300, loss: 2.621386, top_1: 0.544258, top_k: 0.779648, samples/s: 1325.636 1612704759.8324704
train: epoch 46, iter 2400, loss: 2.928205, top_1: 0.556836, top_k: 0.785625, samples/s: 1322.672 1612704779.1872067
train: epoch 46, iter 2500, loss: 2.912163, top_1: 0.555508, top_k: 0.783945, samples/s: 1325.619 1612704798.4988818
train: epoch 46, iter 2600, loss: 2.820505, top_1: 0.551172, top_k: 0.779141, samples/s: 1326.773 1612704817.7938237
train: epoch 46, iter 2700, loss: 2.899290, top_1: 0.552422, top_k: 0.784375, samples/s: 1322.283 1612704837.1543372
train: epoch 46, iter 2800, loss: 2.927406, top_1: 0.553906, top_k: 0.783984, samples/s: 1320.958 1612704856.5341618
train: epoch 46, iter 2900, loss: 2.888106, top_1: 0.548398, top_k: 0.778320, samples/s: 1331.423 1612704875.761714
train: epoch 46, iter 3000, loss: 2.916457, top_1: 0.552109, top_k: 0.780937, samples/s: 1325.445 1612704895.0760732
train: epoch 46, iter 3100, loss: 2.683945, top_1: 0.554180, top_k: 0.785820, samples/s: 1328.138 1612704914.3513675
train: epoch 46, iter 3200, loss: 2.916238, top_1: 0.550469, top_k: 0.779570, samples/s: 1325.720 1612704933.6613867
train: epoch 46, iter 3300, loss: 2.959381, top_1: 0.548477, top_k: 0.777383, samples/s: 1325.768 1612704952.9713337
train: epoch 46, iter 3400, loss: 2.951573, top_1: 0.549961, top_k: 0.780469, samples/s: 1325.408 1612704972.2857673
train: epoch 46, iter 3500, loss: 2.844447, top_1: 0.553789, top_k: 0.781172, samples/s: 1322.800 1612704991.6385908
train: epoch 46, iter 3600, loss: 2.704801, top_1: 0.559219, top_k: 0.789648, samples/s: 1329.942 1612705010.8875613
train: epoch 46, iter 3700, loss: 2.833780, top_1: 0.548047, top_k: 0.780195, samples/s: 1325.997 1612705030.1938243
train: epoch 46, iter 3800, loss: 2.605193, top_1: 0.551562, top_k: 0.784180, samples/s: 1324.361 1612705049.5238678
train: epoch 46, iter 3900, loss: 2.815721, top_1: 0.551445, top_k: 0.781797, samples/s: 1326.225 1612705068.8268287
train: epoch 46, iter 4000, loss: 2.893676, top_1: 0.547148, top_k: 0.780234, samples/s: 1324.210 1612705088.1590738
train: epoch 46, iter 4100, loss: 2.970720, top_1: 0.549414, top_k: 0.779375, samples/s: 1327.375 1612705107.4452665
train: epoch 46, iter 4200, loss: 2.879015, top_1: 0.546250, top_k: 0.779883, samples/s: 1327.921 1612705126.7235305
train: epoch 46, iter 4300, loss: 2.864603, top_1: 0.550977, top_k: 0.782695, samples/s: 1334.058 1612705145.913044
train: epoch 46, iter 4400, loss: 2.878809, top_1: 0.552891, top_k: 0.778125, samples/s: 1321.783 1612705165.2809033
train: epoch 46, iter 4500, loss: 3.014745, top_1: 0.549766, top_k: 0.778086, samples/s: 1328.782 1612705184.5466623
train: epoch 46, iter 4600, loss: 2.984659, top_1: 0.547930, top_k: 0.780117, samples/s: 1327.829 1612705203.82627
train: epoch 46, iter 4700, loss: 2.972296, top_1: 0.544766, top_k: 0.776094, samples/s: 1330.267 1612705223.0704465
train: epoch 46, iter 4800, loss: 2.861789, top_1: 0.549531, top_k: 0.782344, samples/s: 1329.432 1612705242.3268309
train: epoch 46, iter 4900, loss: 3.032235, top_1: 0.550078, top_k: 0.779570, samples/s: 1328.931 1612705261.5903912
train: epoch 46, iter 5000, loss: 2.700923, top_1: 0.554063, top_k: 0.784062, samples/s: 1328.761 1612705280.8565197
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_46.
validation: epoch 46, iter 195, top_1: 0.600100, top_k: 0.833694, samples/s: 2771.325 1612705299.4433646
train: epoch 47, iter 100, loss: 2.709789, top_1: 0.562422, top_k: 0.788047, samples/s: 1363.788 1612705334.142628
train: epoch 47, iter 200, loss: 2.808220, top_1: 0.560898, top_k: 0.793086, samples/s: 1360.296 1612705352.9621048
train: epoch 47, iter 300, loss: 2.940824, top_1: 0.564922, top_k: 0.792070, samples/s: 1354.383 1612705371.8636625
train: epoch 47, iter 400, loss: 2.856245, top_1: 0.559453, top_k: 0.790117, samples/s: 1346.345 1612705390.8781474
train: epoch 47, iter 500, loss: 2.821745, top_1: 0.556406, top_k: 0.787383, samples/s: 1327.659 1612705410.1601455
train: epoch 47, iter 600, loss: 2.919410, top_1: 0.560820, top_k: 0.790156, samples/s: 1326.117 1612705429.4646857
train: epoch 47, iter 700, loss: 2.875036, top_1: 0.561016, top_k: 0.791016, samples/s: 1325.926 1612705448.7719553
train: epoch 47, iter 800, loss: 2.714194, top_1: 0.560312, top_k: 0.784766, samples/s: 1322.657 1612705468.1269104
train: epoch 47, iter 900, loss: 3.022055, top_1: 0.552734, top_k: 0.786016, samples/s: 1327.242 1612705487.4150248
train: epoch 47, iter 1000, loss: 2.783518, top_1: 0.559219, top_k: 0.790820, samples/s: 1325.362 1612705506.7305694
train: epoch 47, iter 1100, loss: 2.761773, top_1: 0.560547, top_k: 0.784297, samples/s: 1328.617 1612705525.998677
train: epoch 47, iter 1200, loss: 2.589737, top_1: 0.556875, top_k: 0.780039, samples/s: 1326.320 1612705545.3001964
train: epoch 47, iter 1300, loss: 2.808586, top_1: 0.561367, top_k: 0.788945, samples/s: 1321.416 1612705564.6734335
train: epoch 47, iter 1400, loss: 2.830855, top_1: 0.555781, top_k: 0.786563, samples/s: 1331.608 1612705583.8982546
train: epoch 47, iter 1500, loss: 2.937883, top_1: 0.554180, top_k: 0.782852, samples/s: 1328.849 1612705603.163014
train: epoch 47, iter 1600, loss: 2.771206, top_1: 0.558438, top_k: 0.787617, samples/s: 1321.419 1612705622.5361423
train: epoch 47, iter 1700, loss: 2.988710, top_1: 0.552813, top_k: 0.782734, samples/s: 1331.948 1612705641.756055
train: epoch 47, iter 1800, loss: 2.850260, top_1: 0.554766, top_k: 0.785273, samples/s: 1325.288 1612705661.0726385
train: epoch 47, iter 1900, loss: 2.883632, top_1: 0.551094, top_k: 0.783750, samples/s: 1331.363 1612705680.3010163
train: epoch 47, iter 2000, loss: 2.861357, top_1: 0.554688, top_k: 0.781992, samples/s: 1328.053 1612705699.577418
train: epoch 47, iter 2100, loss: 2.947865, top_1: 0.558359, top_k: 0.785664, samples/s: 1329.522 1612705718.8323953
train: epoch 47, iter 2200, loss: 2.939767, top_1: 0.547969, top_k: 0.780312, samples/s: 1321.128 1612705738.2097688
train: epoch 47, iter 2300, loss: 2.817062, top_1: 0.547031, top_k: 0.778125, samples/s: 1324.689 1612705757.5350795
train: epoch 47, iter 2400, loss: 2.741503, top_1: 0.550273, top_k: 0.780781, samples/s: 1326.553 1612705776.8332303
train: epoch 47, iter 2500, loss: 2.800281, top_1: 0.549766, top_k: 0.779883, samples/s: 1323.527 1612705796.1755686
train: epoch 47, iter 2600, loss: 2.873255, top_1: 0.556875, top_k: 0.785039, samples/s: 1331.900 1612705815.396121
train: epoch 47, iter 2700, loss: 2.952714, top_1: 0.555156, top_k: 0.783789, samples/s: 1334.546 1612705834.5786827
train: epoch 47, iter 2800, loss: 2.970942, top_1: 0.549805, top_k: 0.783828, samples/s: 1324.617 1612705853.905043
train: epoch 47, iter 2900, loss: 2.881180, top_1: 0.558242, top_k: 0.787617, samples/s: 1320.562 1612705873.2916377
train: epoch 47, iter 3000, loss: 2.931867, top_1: 0.549727, top_k: 0.779375, samples/s: 1328.435 1612705892.5615766
train: epoch 47, iter 3100, loss: 2.826866, top_1: 0.559688, top_k: 0.788047, samples/s: 1333.134 1612705911.7646532
train: epoch 47, iter 3200, loss: 3.043213, top_1: 0.553555, top_k: 0.780937, samples/s: 1327.864 1612705931.0435407
train: epoch 47, iter 3300, loss: 2.944128, top_1: 0.552461, top_k: 0.784102, samples/s: 1335.176 1612705950.216993
train: epoch 47, iter 3400, loss: 2.886210, top_1: 0.550039, top_k: 0.780117, samples/s: 1325.527 1612705969.5300224
train: epoch 47, iter 3500, loss: 2.718284, top_1: 0.550273, top_k: 0.781328, samples/s: 1325.893 1612705988.837798
train: epoch 47, iter 3600, loss: 2.777549, top_1: 0.552734, top_k: 0.783594, samples/s: 1330.558 1612706008.077808
train: epoch 47, iter 3700, loss: 2.728952, top_1: 0.556641, top_k: 0.785625, samples/s: 1329.499 1612706027.333249
train: epoch 47, iter 3800, loss: 2.942837, top_1: 0.551680, top_k: 0.782969, samples/s: 1328.641 1612706046.6010392
train: epoch 47, iter 3900, loss: 2.811452, top_1: 0.551289, top_k: 0.780117, samples/s: 1328.952 1612706065.8643012
train: epoch 47, iter 4000, loss: 2.900797, top_1: 0.550977, top_k: 0.781289, samples/s: 1319.565 1612706085.264618
train: epoch 47, iter 4100, loss: 2.943569, top_1: 0.551953, top_k: 0.779687, samples/s: 1330.367 1612706104.507432
train: epoch 47, iter 4200, loss: 2.832765, top_1: 0.549453, top_k: 0.784023, samples/s: 1329.844 1612706123.7577956
train: epoch 47, iter 4300, loss: 2.825943, top_1: 0.555156, top_k: 0.778359, samples/s: 1328.033 1612706143.0344858
train: epoch 47, iter 4400, loss: 3.016298, top_1: 0.557500, top_k: 0.784062, samples/s: 1328.775 1612706162.30034
train: epoch 47, iter 4500, loss: 2.877065, top_1: 0.553047, top_k: 0.780039, samples/s: 1330.191 1612706181.5456545
train: epoch 47, iter 4600, loss: 2.779612, top_1: 0.550508, top_k: 0.784375, samples/s: 1322.435 1612706200.9039054
train: epoch 47, iter 4700, loss: 3.021143, top_1: 0.553477, top_k: 0.781641, samples/s: 1328.361 1612706220.1757545
train: epoch 47, iter 4800, loss: 2.695779, top_1: 0.546992, top_k: 0.779102, samples/s: 1328.275 1612706239.448939
train: epoch 47, iter 4900, loss: 2.790845, top_1: 0.552070, top_k: 0.781563, samples/s: 1323.081 1612706258.7976904
train: epoch 47, iter 5000, loss: 2.818296, top_1: 0.554297, top_k: 0.784102, samples/s: 1332.950 1612706278.0032215
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_47.
validation: epoch 47, iter 195, top_1: 0.606751, top_k: 0.838962, samples/s: 2785.725 1612706296.4987712
train: epoch 48, iter 100, loss: 2.827063, top_1: 0.566133, top_k: 0.791641, samples/s: 1362.440 1612706331.3273911
train: epoch 48, iter 200, loss: 2.853271, top_1: 0.566641, top_k: 0.789492, samples/s: 1360.190 1612706350.1482742
train: epoch 48, iter 300, loss: 2.786296, top_1: 0.559883, top_k: 0.791289, samples/s: 1353.165 1612706369.0669632
train: epoch 48, iter 400, loss: 2.867018, top_1: 0.563438, top_k: 0.787422, samples/s: 1342.798 1612706388.131597
train: epoch 48, iter 500, loss: 2.868453, top_1: 0.559766, top_k: 0.787852, samples/s: 1328.598 1612706407.3999932
train: epoch 48, iter 600, loss: 2.801872, top_1: 0.563359, top_k: 0.790273, samples/s: 1324.677 1612706426.7254615
train: epoch 48, iter 700, loss: 2.852765, top_1: 0.555039, top_k: 0.784141, samples/s: 1328.547 1612706445.994666
train: epoch 48, iter 800, loss: 2.981959, top_1: 0.555859, top_k: 0.787930, samples/s: 1328.355 1612706465.2666473
train: epoch 48, iter 900, loss: 2.869349, top_1: 0.557344, top_k: 0.787148, samples/s: 1328.482 1612706484.5367227
train: epoch 48, iter 1000, loss: 2.939281, top_1: 0.560742, top_k: 0.788203, samples/s: 1327.214 1612706503.8253326
train: epoch 48, iter 1100, loss: 2.775488, top_1: 0.558477, top_k: 0.784102, samples/s: 1318.617 1612706523.2395341
train: epoch 48, iter 1200, loss: 2.811406, top_1: 0.559492, top_k: 0.789023, samples/s: 1320.560 1612706542.6252396
train: epoch 48, iter 1300, loss: 2.885112, top_1: 0.556055, top_k: 0.784570, samples/s: 1328.230 1612706561.8990715
train: epoch 48, iter 1400, loss: 3.111865, top_1: 0.559180, top_k: 0.788398, samples/s: 1325.502 1612706581.2124715
train: epoch 48, iter 1500, loss: 2.936710, top_1: 0.563789, top_k: 0.788750, samples/s: 1330.182 1612706600.4579778
train: epoch 48, iter 1600, loss: 3.040050, top_1: 0.559492, top_k: 0.785625, samples/s: 1320.435 1612706619.8454866
train: epoch 48, iter 1700, loss: 2.952186, top_1: 0.555508, top_k: 0.784297, samples/s: 1325.542 1612706639.1583703
train: epoch 48, iter 1800, loss: 2.658322, top_1: 0.558242, top_k: 0.787422, samples/s: 1324.303 1612706658.489271
train: epoch 48, iter 1900, loss: 2.805118, top_1: 0.551484, top_k: 0.786406, samples/s: 1323.820 1612706677.8273168
train: epoch 48, iter 2000, loss: 2.745548, top_1: 0.556016, top_k: 0.788750, samples/s: 1334.414 1612706697.0117474
train: epoch 48, iter 2100, loss: 3.101669, top_1: 0.559063, top_k: 0.787227, samples/s: 1316.152 1612706716.4623535
train: epoch 48, iter 2200, loss: 2.839515, top_1: 0.555820, top_k: 0.784687, samples/s: 1333.617 1612706735.6582623
train: epoch 48, iter 2300, loss: 2.933103, top_1: 0.561016, top_k: 0.789570, samples/s: 1325.344 1612706754.9740345
train: epoch 48, iter 2400, loss: 2.689787, top_1: 0.561484, top_k: 0.787891, samples/s: 1324.523 1612706774.3017297
train: epoch 48, iter 2500, loss: 2.916220, top_1: 0.553555, top_k: 0.782188, samples/s: 1327.805 1612706793.5817244
train: epoch 48, iter 2600, loss: 2.734897, top_1: 0.555898, top_k: 0.784180, samples/s: 1331.968 1612706812.801302
train: epoch 48, iter 2700, loss: 2.804028, top_1: 0.555703, top_k: 0.785117, samples/s: 1330.208 1612706832.0464504
train: epoch 48, iter 2800, loss: 2.872376, top_1: 0.555664, top_k: 0.783789, samples/s: 1331.932 1612706851.2666142
train: epoch 48, iter 2900, loss: 2.891417, top_1: 0.555703, top_k: 0.782188, samples/s: 1327.838 1612706870.5461125
train: epoch 48, iter 3000, loss: 2.880077, top_1: 0.552930, top_k: 0.785469, samples/s: 1320.097 1612706889.938579
train: epoch 48, iter 3100, loss: 2.792812, top_1: 0.556133, top_k: 0.783438, samples/s: 1323.525 1612706909.280888
train: epoch 48, iter 3200, loss: 2.860411, top_1: 0.557344, top_k: 0.786406, samples/s: 1327.343 1612706928.5675757
train: epoch 48, iter 3300, loss: 2.724000, top_1: 0.554219, top_k: 0.782461, samples/s: 1327.834 1612706947.8470926
train: epoch 48, iter 3400, loss: 2.833744, top_1: 0.556016, top_k: 0.787773, samples/s: 1326.896 1612706967.1402922
train: epoch 48, iter 3500, loss: 2.902553, top_1: 0.549922, top_k: 0.781953, samples/s: 1328.703 1612706986.4070942
train: epoch 48, iter 3600, loss: 2.814530, top_1: 0.553008, top_k: 0.784727, samples/s: 1327.332 1612707005.6939642
train: epoch 48, iter 3700, loss: 2.895597, top_1: 0.557695, top_k: 0.782227, samples/s: 1329.042 1612707024.9559484
train: epoch 48, iter 3800, loss: 2.818319, top_1: 0.553594, top_k: 0.783008, samples/s: 1325.028 1612707044.276253
train: epoch 48, iter 3900, loss: 2.754917, top_1: 0.558047, top_k: 0.782031, samples/s: 1324.892 1612707063.5986338
train: epoch 48, iter 4000, loss: 3.015115, top_1: 0.548789, top_k: 0.781641, samples/s: 1327.078 1612707082.889127
train: epoch 48, iter 4100, loss: 2.864682, top_1: 0.553555, top_k: 0.783906, samples/s: 1326.758 1612707102.184261
train: epoch 48, iter 4200, loss: 2.871871, top_1: 0.550234, top_k: 0.783281, samples/s: 1326.865 1612707121.4778316
train: epoch 48, iter 4300, loss: 2.752949, top_1: 0.554609, top_k: 0.787813, samples/s: 1324.737 1612707140.8025408
train: epoch 48, iter 4400, loss: 2.706335, top_1: 0.562266, top_k: 0.786016, samples/s: 1325.312 1612707160.1186776
train: epoch 48, iter 4500, loss: 2.810568, top_1: 0.553477, top_k: 0.785156, samples/s: 1324.411 1612707179.4479795
train: epoch 48, iter 4600, loss: 2.705704, top_1: 0.551211, top_k: 0.784102, samples/s: 1323.117 1612707198.7963219
train: epoch 48, iter 4700, loss: 2.822934, top_1: 0.550742, top_k: 0.786992, samples/s: 1331.402 1612707218.0241237
train: epoch 48, iter 4800, loss: 3.023735, top_1: 0.551367, top_k: 0.778789, samples/s: 1327.533 1612707237.3079991
train: epoch 48, iter 4900, loss: 2.935313, top_1: 0.549531, top_k: 0.780234, samples/s: 1327.701 1612707256.5894163
train: epoch 48, iter 5000, loss: 2.860249, top_1: 0.561641, top_k: 0.785508, samples/s: 1327.915 1612707275.8677797
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_48.
validation: epoch 48, iter 195, top_1: 0.606751, top_k: 0.837560, samples/s: 2839.404 1612707293.9916835
train: epoch 49, iter 100, loss: 2.504246, top_1: 0.573516, top_k: 0.800078, samples/s: 1362.765 1612707328.4644353
train: epoch 49, iter 200, loss: 2.826615, top_1: 0.569063, top_k: 0.791992, samples/s: 1356.040 1612707347.3430324
train: epoch 49, iter 300, loss: 2.854009, top_1: 0.562891, top_k: 0.789648, samples/s: 1358.561 1612707366.1868107
train: epoch 49, iter 400, loss: 2.889311, top_1: 0.566641, top_k: 0.794766, samples/s: 1334.957 1612707385.3630297
train: epoch 49, iter 500, loss: 2.722507, top_1: 0.563281, top_k: 0.792227, samples/s: 1324.411 1612707404.6923747
train: epoch 49, iter 600, loss: 2.910636, top_1: 0.564531, top_k: 0.789648, samples/s: 1320.351 1612707424.08151
train: epoch 49, iter 700, loss: 2.806857, top_1: 0.560391, top_k: 0.784023, samples/s: 1321.104 1612707443.4588892
train: epoch 49, iter 800, loss: 2.808451, top_1: 0.561172, top_k: 0.788711, samples/s: 1329.383 1612707462.7160156
train: epoch 49, iter 900, loss: 2.914126, top_1: 0.558359, top_k: 0.787734, samples/s: 1323.955 1612707482.0519562
train: epoch 49, iter 1000, loss: 2.768052, top_1: 0.566367, top_k: 0.793125, samples/s: 1314.813 1612707501.5223846
train: epoch 49, iter 1100, loss: 2.802126, top_1: 0.554805, top_k: 0.781914, samples/s: 1319.406 1612707520.9251
train: epoch 49, iter 1200, loss: 2.924507, top_1: 0.557969, top_k: 0.782969, samples/s: 1321.872 1612707540.2915692
train: epoch 49, iter 1300, loss: 2.720321, top_1: 0.567305, top_k: 0.793711, samples/s: 1323.621 1612707559.632434
train: epoch 49, iter 1400, loss: 2.811000, top_1: 0.562383, top_k: 0.789883, samples/s: 1322.097 1612707578.9956088
train: epoch 49, iter 1500, loss: 2.905415, top_1: 0.557852, top_k: 0.786367, samples/s: 1322.771 1612707598.3489718
train: epoch 49, iter 1600, loss: 2.846753, top_1: 0.559141, top_k: 0.792031, samples/s: 1320.214 1612707617.7397954
train: epoch 49, iter 1700, loss: 2.750239, top_1: 0.557500, top_k: 0.786953, samples/s: 1326.539 1612707637.0380976
train: epoch 49, iter 1800, loss: 2.956990, top_1: 0.561992, top_k: 0.787305, samples/s: 1327.759 1612707656.3187814
train: epoch 49, iter 1900, loss: 2.693151, top_1: 0.555039, top_k: 0.783984, samples/s: 1300.673 1612707676.0007606
train: epoch 49, iter 2000, loss: 2.816846, top_1: 0.556445, top_k: 0.784883, samples/s: 1338.927 1612707695.1205804
train: epoch 49, iter 2100, loss: 2.593517, top_1: 0.561914, top_k: 0.792344, samples/s: 1324.984 1612707714.4415977
train: epoch 49, iter 2200, loss: 2.738853, top_1: 0.559883, top_k: 0.787422, samples/s: 1324.082 1612707733.7757258
train: epoch 49, iter 2300, loss: 2.727049, top_1: 0.562422, top_k: 0.789375, samples/s: 1325.740 1612707753.0857074
train: epoch 49, iter 2400, loss: 2.948184, top_1: 0.559531, top_k: 0.788320, samples/s: 1322.529 1612707772.442538
train: epoch 49, iter 2500, loss: 2.950477, top_1: 0.557617, top_k: 0.784883, samples/s: 1321.711 1612707791.8113265
train: epoch 49, iter 2600, loss: 2.863812, top_1: 0.552148, top_k: 0.782891, samples/s: 1327.949 1612707811.0892258
train: epoch 49, iter 2700, loss: 2.757340, top_1: 0.554063, top_k: 0.784414, samples/s: 1326.389 1612707830.3898292
train: epoch 49, iter 2800, loss: 2.773678, top_1: 0.560664, top_k: 0.788750, samples/s: 1322.917 1612707849.7409246
train: epoch 49, iter 2900, loss: 2.735041, top_1: 0.558633, top_k: 0.786953, samples/s: 1323.508 1612707869.0834594
train: epoch 49, iter 3000, loss: 2.981406, top_1: 0.552578, top_k: 0.778750, samples/s: 1328.327 1612707888.3558173
train: epoch 49, iter 3100, loss: 3.078339, top_1: 0.552578, top_k: 0.784453, samples/s: 1317.857 1612707907.7812855
train: epoch 49, iter 3200, loss: 2.851123, top_1: 0.554336, top_k: 0.782344, samples/s: 1327.076 1612707927.0717633
train: epoch 49, iter 3300, loss: 2.811224, top_1: 0.552695, top_k: 0.787656, samples/s: 1321.091 1612707946.4501262
train: epoch 49, iter 3400, loss: 3.147469, top_1: 0.554375, top_k: 0.785117, samples/s: 1323.487 1612707965.7926009
train: epoch 49, iter 3500, loss: 2.833684, top_1: 0.554609, top_k: 0.780234, samples/s: 1324.673 1612707985.1181164
train: epoch 49, iter 3600, loss: 2.813864, top_1: 0.555469, top_k: 0.784531, samples/s: 1328.631 1612708004.3860059
train: epoch 49, iter 3700, loss: 2.991587, top_1: 0.555820, top_k: 0.783164, samples/s: 1321.225 1612708023.7620313
train: epoch 49, iter 3800, loss: 2.949291, top_1: 0.555195, top_k: 0.784414, samples/s: 1319.632 1612708043.1613166
train: epoch 49, iter 3900, loss: 2.784103, top_1: 0.555898, top_k: 0.782813, samples/s: 1328.142 1612708062.436363
train: epoch 49, iter 4000, loss: 2.817359, top_1: 0.558945, top_k: 0.785547, samples/s: 1328.123 1612708081.711727
train: epoch 49, iter 4100, loss: 3.019701, top_1: 0.557930, top_k: 0.786563, samples/s: 1327.904 1612708100.9902334
train: epoch 49, iter 4200, loss: 2.850041, top_1: 0.553867, top_k: 0.783945, samples/s: 1319.782 1612708120.3874927
train: epoch 49, iter 4300, loss: 2.894526, top_1: 0.561641, top_k: 0.786367, samples/s: 1321.549 1612708139.758524
train: epoch 49, iter 4400, loss: 2.893660, top_1: 0.558906, top_k: 0.784961, samples/s: 1332.768 1612708158.9667218
train: epoch 49, iter 4500, loss: 2.764768, top_1: 0.561602, top_k: 0.789609, samples/s: 1313.420 1612708178.457796
train: epoch 49, iter 4600, loss: 2.897393, top_1: 0.555117, top_k: 0.785234, samples/s: 1332.352 1612708197.6719458
train: epoch 49, iter 4700, loss: 2.782245, top_1: 0.556406, top_k: 0.785000, samples/s: 1322.430 1612708217.030298
train: epoch 49, iter 4800, loss: 2.811593, top_1: 0.552344, top_k: 0.783516, samples/s: 1323.654 1612708236.3706598
train: epoch 49, iter 4900, loss: 2.752602, top_1: 0.553945, top_k: 0.785312, samples/s: 1322.678 1612708255.7253182
train: epoch 49, iter 5000, loss: 2.751236, top_1: 0.557539, top_k: 0.782969, samples/s: 1319.618 1612708275.1248202
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_49.
validation: epoch 49, iter 195, top_1: 0.603365, top_k: 0.837400, samples/s: 2767.349 1612708293.69161
train: epoch 50, iter 100, loss: 2.515049, top_1: 0.576641, top_k: 0.800117, samples/s: 1358.297 1612708328.2797828
train: epoch 50, iter 200, loss: 2.647994, top_1: 0.568750, top_k: 0.795234, samples/s: 1359.048 1612708347.1164756
train: epoch 50, iter 300, loss: 2.646932, top_1: 0.571406, top_k: 0.797773, samples/s: 1358.380 1612708365.9624832
train: epoch 50, iter 400, loss: 2.763887, top_1: 0.565547, top_k: 0.791055, samples/s: 1341.180 1612708385.050202
train: epoch 50, iter 500, loss: 2.655902, top_1: 0.564922, top_k: 0.792031, samples/s: 1333.109 1612708404.2534015
train: epoch 50, iter 600, loss: 2.751468, top_1: 0.564336, top_k: 0.789805, samples/s: 1323.469 1612708423.5964894
train: epoch 50, iter 700, loss: 2.926036, top_1: 0.558984, top_k: 0.787695, samples/s: 1325.479 1612708442.9102392
train: epoch 50, iter 800, loss: 2.711137, top_1: 0.560234, top_k: 0.787344, samples/s: 1318.690 1612708462.3234365
train: epoch 50, iter 900, loss: 2.624722, top_1: 0.562031, top_k: 0.789805, samples/s: 1339.919 1612708481.429063
train: epoch 50, iter 1000, loss: 2.662890, top_1: 0.559844, top_k: 0.793516, samples/s: 1318.908 1612708500.8391454
train: epoch 50, iter 1100, loss: 2.682037, top_1: 0.554766, top_k: 0.788125, samples/s: 1324.749 1612708520.1635485
train: epoch 50, iter 1200, loss: 2.881418, top_1: 0.561328, top_k: 0.785625, samples/s: 1328.556 1612708539.4325182
train: epoch 50, iter 1300, loss: 2.973567, top_1: 0.560000, top_k: 0.790391, samples/s: 1329.711 1612708558.6848207
train: epoch 50, iter 1400, loss: 2.832003, top_1: 0.559023, top_k: 0.785937, samples/s: 1331.544 1612708577.9106667
train: epoch 50, iter 1500, loss: 2.839909, top_1: 0.560430, top_k: 0.789297, samples/s: 1328.967 1612708597.1737647
train: epoch 50, iter 1600, loss: 2.690833, top_1: 0.557656, top_k: 0.789805, samples/s: 1325.815 1612708616.4826176
train: epoch 50, iter 1700, loss: 2.785894, top_1: 0.560625, top_k: 0.785273, samples/s: 1332.580 1612708635.693497
train: epoch 50, iter 1800, loss: 2.876093, top_1: 0.567930, top_k: 0.792695, samples/s: 1329.320 1612708654.9515278
train: epoch 50, iter 1900, loss: 2.847907, top_1: 0.556406, top_k: 0.786680, samples/s: 1328.886 1612708674.2156756
train: epoch 50, iter 2000, loss: 2.729749, top_1: 0.562344, top_k: 0.792344, samples/s: 1323.424 1612708693.5594287
train: epoch 50, iter 2100, loss: 2.882994, top_1: 0.555703, top_k: 0.783828, samples/s: 1326.924 1612708712.8522358
train: epoch 50, iter 2200, loss: 2.761149, top_1: 0.559219, top_k: 0.786836, samples/s: 1326.535 1612708732.1505911
train: epoch 50, iter 2300, loss: 2.916374, top_1: 0.557930, top_k: 0.786289, samples/s: 1331.673 1612708751.3745162
train: epoch 50, iter 2400, loss: 2.904798, top_1: 0.558672, top_k: 0.784180, samples/s: 1328.880 1612708770.638909
train: epoch 50, iter 2500, loss: 2.900717, top_1: 0.565625, top_k: 0.785859, samples/s: 1328.675 1612708789.9061916
train: epoch 50, iter 2600, loss: 2.812462, top_1: 0.560156, top_k: 0.785820, samples/s: 1328.116 1612708809.1817272
train: epoch 50, iter 2700, loss: 2.857430, top_1: 0.551172, top_k: 0.782109, samples/s: 1328.316 1612708828.4542274
train: epoch 50, iter 2800, loss: 2.851192, top_1: 0.552813, top_k: 0.785430, samples/s: 1328.900 1612708847.7182655
train: epoch 50, iter 2900, loss: 2.818736, top_1: 0.559102, top_k: 0.784727, samples/s: 1330.225 1612708866.9631028
train: epoch 50, iter 3000, loss: 2.994402, top_1: 0.551367, top_k: 0.785234, samples/s: 1327.954 1612708886.2408237
train: epoch 50, iter 3100, loss: 2.735356, top_1: 0.560508, top_k: 0.784492, samples/s: 1330.035 1612708905.4884503
train: epoch 50, iter 3200, loss: 2.680760, top_1: 0.559727, top_k: 0.788594, samples/s: 1330.102 1612708924.7350922
train: epoch 50, iter 3300, loss: 2.882185, top_1: 0.554063, top_k: 0.784570, samples/s: 1327.103 1612708944.0252552
train: epoch 50, iter 3400, loss: 2.882613, top_1: 0.555508, top_k: 0.782969, samples/s: 1335.255 1612708963.1976404
train: epoch 50, iter 3500, loss: 2.925660, top_1: 0.560312, top_k: 0.786641, samples/s: 1327.344 1612708982.4842703
train: epoch 50, iter 3600, loss: 2.724766, top_1: 0.559375, top_k: 0.787344, samples/s: 1321.904 1612709001.850361
train: epoch 50, iter 3700, loss: 2.839841, top_1: 0.555664, top_k: 0.786602, samples/s: 1337.223 1612709020.9943829
train: epoch 50, iter 3800, loss: 2.943023, top_1: 0.552227, top_k: 0.783242, samples/s: 1326.823 1612709040.2886553
train: epoch 50, iter 3900, loss: 2.742157, top_1: 0.555352, top_k: 0.787148, samples/s: 1330.861 1612709059.5242887
train: epoch 50, iter 4000, loss: 2.855540, top_1: 0.556367, top_k: 0.787148, samples/s: 1331.902 1612709078.7449348
train: epoch 50, iter 4100, loss: 2.799215, top_1: 0.557773, top_k: 0.783281, samples/s: 1322.067 1612709098.1085153
train: epoch 50, iter 4200, loss: 2.826003, top_1: 0.550234, top_k: 0.780234, samples/s: 1335.866 1612709117.2721808
train: epoch 50, iter 4300, loss: 2.665285, top_1: 0.551133, top_k: 0.780586, samples/s: 1331.054 1612709136.5050275
train: epoch 50, iter 4400, loss: 2.855995, top_1: 0.567109, top_k: 0.788086, samples/s: 1323.843 1612709155.8426428
train: epoch 50, iter 4500, loss: 3.100432, top_1: 0.555586, top_k: 0.782500, samples/s: 1328.091 1612709175.118413
train: epoch 50, iter 4600, loss: 2.788056, top_1: 0.557305, top_k: 0.790820, samples/s: 1329.202 1612709194.378137
train: epoch 50, iter 4700, loss: 3.096377, top_1: 0.555234, top_k: 0.784102, samples/s: 1326.655 1612709213.6747367
train: epoch 50, iter 4800, loss: 2.860572, top_1: 0.552305, top_k: 0.787109, samples/s: 1326.366 1612709232.9756448
train: epoch 50, iter 4900, loss: 2.742573, top_1: 0.558438, top_k: 0.785352, samples/s: 1328.196 1612709252.2498982
train: epoch 50, iter 5000, loss: 2.996682, top_1: 0.560078, top_k: 0.786523, samples/s: 1329.271 1612709271.5085378
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_50.
validation: epoch 50, iter 195, top_1: 0.604888, top_k: 0.838882, samples/s: 2798.351 1612709289.9220202
train: epoch 51, iter 100, loss: 2.621251, top_1: 0.563359, top_k: 0.793906, samples/s: 1361.494 1612709325.0379124
train: epoch 51, iter 200, loss: 2.675413, top_1: 0.567617, top_k: 0.794453, samples/s: 1358.359 1612709343.8845491
train: epoch 51, iter 300, loss: 2.946523, top_1: 0.556016, top_k: 0.785703, samples/s: 1359.580 1612709362.713428
train: epoch 51, iter 400, loss: 3.028420, top_1: 0.560898, top_k: 0.789922, samples/s: 1341.478 1612709381.796951
train: epoch 51, iter 500, loss: 3.035627, top_1: 0.571484, top_k: 0.794492, samples/s: 1329.141 1612709401.0574834
train: epoch 51, iter 600, loss: 2.792416, top_1: 0.565781, top_k: 0.790664, samples/s: 1327.313 1612709420.344506
train: epoch 51, iter 700, loss: 2.805031, top_1: 0.565117, top_k: 0.793867, samples/s: 1328.192 1612709439.618854
train: epoch 51, iter 800, loss: 2.807978, top_1: 0.564727, top_k: 0.791836, samples/s: 1326.153 1612709458.9227917
train: epoch 51, iter 900, loss: 2.836657, top_1: 0.565352, top_k: 0.791797, samples/s: 1325.749 1612709478.2326813
train: epoch 51, iter 1000, loss: 2.764498, top_1: 0.565273, top_k: 0.791094, samples/s: 1326.785 1612709497.5274339
train: epoch 51, iter 1100, loss: 2.694019, top_1: 0.557695, top_k: 0.787461, samples/s: 1327.382 1612709516.8134649
train: epoch 51, iter 1200, loss: 2.818342, top_1: 0.566758, top_k: 0.792617, samples/s: 1328.877 1612709536.077907
train: epoch 51, iter 1300, loss: 2.838196, top_1: 0.559063, top_k: 0.790117, samples/s: 1326.504 1612709555.3767517
train: epoch 51, iter 1400, loss: 2.947967, top_1: 0.563164, top_k: 0.788477, samples/s: 1330.780 1612709574.6136022
train: epoch 51, iter 1500, loss: 2.866825, top_1: 0.572422, top_k: 0.794453, samples/s: 1328.627 1612709593.8816526
train: epoch 51, iter 1600, loss: 2.855108, top_1: 0.555937, top_k: 0.782344, samples/s: 1330.421 1612709613.1236737
train: epoch 51, iter 1700, loss: 2.781278, top_1: 0.568125, top_k: 0.792969, samples/s: 1328.535 1612709632.3929338
train: epoch 51, iter 1800, loss: 2.942992, top_1: 0.561719, top_k: 0.792891, samples/s: 1325.646 1612709651.7043266
train: epoch 51, iter 1900, loss: 2.811369, top_1: 0.560195, top_k: 0.792148, samples/s: 1328.593 1612709670.9727633
train: epoch 51, iter 2000, loss: 2.637244, top_1: 0.563008, top_k: 0.791562, samples/s: 1333.566 1612709690.1694443
train: epoch 51, iter 2100, loss: 2.573514, top_1: 0.560430, top_k: 0.790234, samples/s: 1328.169 1612709709.444075
train: epoch 51, iter 2200, loss: 2.716513, top_1: 0.561328, top_k: 0.788672, samples/s: 1329.469 1612709728.6999214
train: epoch 51, iter 2300, loss: 2.988437, top_1: 0.568750, top_k: 0.792422, samples/s: 1326.129 1612709748.0042624
train: epoch 51, iter 2400, loss: 2.813345, top_1: 0.558906, top_k: 0.786719, samples/s: 1324.867 1612709767.3269236
train: epoch 51, iter 2500, loss: 3.007724, top_1: 0.563398, top_k: 0.789297, samples/s: 1326.686 1612709786.623151
train: epoch 51, iter 2600, loss: 2.768230, top_1: 0.563477, top_k: 0.789141, samples/s: 1327.213 1612709805.91162
train: epoch 51, iter 2700, loss: 2.720258, top_1: 0.557461, top_k: 0.784844, samples/s: 1325.071 1612709825.2314293
train: epoch 51, iter 2800, loss: 2.928245, top_1: 0.552109, top_k: 0.779961, samples/s: 1329.488 1612709844.4868941
train: epoch 51, iter 2900, loss: 2.845917, top_1: 0.551992, top_k: 0.785977, samples/s: 1326.539 1612709863.7853436
train: epoch 51, iter 3000, loss: 2.783897, top_1: 0.559648, top_k: 0.790508, samples/s: 1331.620 1612709883.0099704
train: epoch 51, iter 3100, loss: 2.849913, top_1: 0.560508, top_k: 0.788594, samples/s: 1326.931 1612709902.3025932
train: epoch 51, iter 3200, loss: 2.914230, top_1: 0.555000, top_k: 0.782461, samples/s: 1334.579 1612709921.4846454
train: epoch 51, iter 3300, loss: 2.616046, top_1: 0.556797, top_k: 0.786367, samples/s: 1326.675 1612709940.781038
train: epoch 51, iter 3400, loss: 2.939399, top_1: 0.556680, top_k: 0.785703, samples/s: 1325.184 1612709960.0991392
train: epoch 51, iter 3500, loss: 2.935666, top_1: 0.561836, top_k: 0.786719, samples/s: 1337.893 1612709979.233645
train: epoch 51, iter 3600, loss: 2.960254, top_1: 0.562852, top_k: 0.788711, samples/s: 1329.305 1612709998.491822
train: epoch 51, iter 3700, loss: 2.954229, top_1: 0.558281, top_k: 0.784180, samples/s: 1328.203 1612710017.7660098
train: epoch 51, iter 3800, loss: 2.718033, top_1: 0.558203, top_k: 0.787383, samples/s: 1331.933 1612710036.9862106
train: epoch 51, iter 3900, loss: 2.653092, top_1: 0.556523, top_k: 0.784102, samples/s: 1328.226 1612710056.2600164
train: epoch 51, iter 4000, loss: 2.816088, top_1: 0.558789, top_k: 0.786484, samples/s: 1328.285 1612710075.53297
train: epoch 51, iter 4100, loss: 2.874429, top_1: 0.556992, top_k: 0.786992, samples/s: 1324.795 1612710094.8567326
train: epoch 51, iter 4200, loss: 2.887654, top_1: 0.552383, top_k: 0.783594, samples/s: 1327.800 1612710114.1367323
train: epoch 51, iter 4300, loss: 2.690642, top_1: 0.553438, top_k: 0.782734, samples/s: 1327.625 1612710133.4193563
train: epoch 51, iter 4400, loss: 2.898436, top_1: 0.556328, top_k: 0.785586, samples/s: 1326.833 1612710152.713356
train: epoch 51, iter 4500, loss: 2.951690, top_1: 0.555391, top_k: 0.784805, samples/s: 1335.817 1612710171.8776557
train: epoch 51, iter 4600, loss: 2.626465, top_1: 0.559609, top_k: 0.790156, samples/s: 1325.411 1612710191.1924887
train: epoch 51, iter 4700, loss: 2.774284, top_1: 0.560312, top_k: 0.786563, samples/s: 1330.539 1612710210.4328098
train: epoch 51, iter 4800, loss: 2.672940, top_1: 0.562187, top_k: 0.785742, samples/s: 1328.141 1612710229.7078154
train: epoch 51, iter 4900, loss: 2.834523, top_1: 0.556445, top_k: 0.783320, samples/s: 1330.945 1612710248.9422805
train: epoch 51, iter 5000, loss: 2.881286, top_1: 0.563008, top_k: 0.789648, samples/s: 1338.044 1612710268.0747228
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_51.
validation: epoch 51, iter 195, top_1: 0.607372, top_k: 0.840224, samples/s: 2836.225 1612710286.2413588
train: epoch 52, iter 100, loss: 2.830482, top_1: 0.568594, top_k: 0.794805, samples/s: 1357.056 1612710321.0880947
train: epoch 52, iter 200, loss: 2.811720, top_1: 0.563398, top_k: 0.790117, samples/s: 1361.476 1612710339.8911989
train: epoch 52, iter 300, loss: 2.811086, top_1: 0.571836, top_k: 0.795195, samples/s: 1353.802 1612710358.8008769
train: epoch 52, iter 400, loss: 3.090590, top_1: 0.568555, top_k: 0.796211, samples/s: 1345.040 1612710377.8338118
train: epoch 52, iter 500, loss: 2.792570, top_1: 0.563906, top_k: 0.791836, samples/s: 1328.213 1612710397.1077797
train: epoch 52, iter 600, loss: 2.805510, top_1: 0.564727, top_k: 0.793984, samples/s: 1316.354 1612710416.5554214
train: epoch 52, iter 700, loss: 2.764908, top_1: 0.568047, top_k: 0.796992, samples/s: 1324.006 1612710435.890745
train: epoch 52, iter 800, loss: 2.860311, top_1: 0.573320, top_k: 0.797266, samples/s: 1323.049 1612710455.2399218
train: epoch 52, iter 900, loss: 2.961772, top_1: 0.563398, top_k: 0.792031, samples/s: 1329.372 1612710474.4971528
train: epoch 52, iter 1000, loss: 2.854105, top_1: 0.563477, top_k: 0.787422, samples/s: 1331.622 1612710493.7218287
train: epoch 52, iter 1100, loss: 2.768214, top_1: 0.557617, top_k: 0.787031, samples/s: 1316.601 1612710513.165814
train: epoch 52, iter 1200, loss: 2.869334, top_1: 0.568945, top_k: 0.793086, samples/s: 1330.061 1612710532.4130685
train: epoch 52, iter 1300, loss: 2.629103, top_1: 0.568242, top_k: 0.793555, samples/s: 1331.609 1612710551.6379194
train: epoch 52, iter 1400, loss: 2.892603, top_1: 0.567813, top_k: 0.791133, samples/s: 1322.102 1612710571.0010257
train: epoch 52, iter 1500, loss: 2.851670, top_1: 0.555664, top_k: 0.784609, samples/s: 1324.589 1612710590.3280268
train: epoch 52, iter 1600, loss: 2.635887, top_1: 0.561328, top_k: 0.789687, samples/s: 1329.025 1612710609.5900824
train: epoch 52, iter 1700, loss: 2.824344, top_1: 0.560117, top_k: 0.787031, samples/s: 1329.923 1612710628.8392732
train: epoch 52, iter 1800, loss: 2.664155, top_1: 0.563672, top_k: 0.789062, samples/s: 1327.379 1612710648.1253822
train: epoch 52, iter 1900, loss: 2.733162, top_1: 0.563516, top_k: 0.790781, samples/s: 1329.290 1612710667.3837888
train: epoch 52, iter 2000, loss: 2.576585, top_1: 0.558320, top_k: 0.787227, samples/s: 1320.645 1612710686.7683523
train: epoch 52, iter 2100, loss: 2.936072, top_1: 0.558984, top_k: 0.790586, samples/s: 1330.363 1612710706.011111
train: epoch 52, iter 2200, loss: 2.843013, top_1: 0.568516, top_k: 0.790195, samples/s: 1330.771 1612710725.2481642
train: epoch 52, iter 2300, loss: 2.894539, top_1: 0.556016, top_k: 0.793633, samples/s: 1320.753 1612710744.6309767
train: epoch 52, iter 2400, loss: 2.777467, top_1: 0.555000, top_k: 0.785898, samples/s: 1325.558 1612710763.9436352
train: epoch 52, iter 2500, loss: 2.703774, top_1: 0.563984, top_k: 0.786875, samples/s: 1322.159 1612710783.3058648
train: epoch 52, iter 2600, loss: 2.730897, top_1: 0.564570, top_k: 0.791211, samples/s: 1333.058 1612710802.5098536
train: epoch 52, iter 2700, loss: 3.044153, top_1: 0.564102, top_k: 0.790547, samples/s: 1335.950 1612710821.6722617
train: epoch 52, iter 2800, loss: 2.812272, top_1: 0.559805, top_k: 0.791016, samples/s: 1326.955 1612710840.9648921
train: epoch 52, iter 2900, loss: 2.878517, top_1: 0.560117, top_k: 0.789687, samples/s: 1322.819 1612710860.3172493
train: epoch 52, iter 3000, loss: 2.698954, top_1: 0.558281, top_k: 0.786289, samples/s: 1332.649 1612710879.527322
train: epoch 52, iter 3100, loss: 2.829189, top_1: 0.557891, top_k: 0.783828, samples/s: 1327.075 1612710898.8176363
train: epoch 52, iter 3200, loss: 2.669763, top_1: 0.561797, top_k: 0.786328, samples/s: 1332.199 1612710918.0339353
train: epoch 52, iter 3300, loss: 2.598324, top_1: 0.559375, top_k: 0.786172, samples/s: 1326.192 1612710937.3372736
train: epoch 52, iter 3400, loss: 2.866949, top_1: 0.560312, top_k: 0.792188, samples/s: 1325.844 1612710956.6457767
train: epoch 52, iter 3500, loss: 2.877052, top_1: 0.566328, top_k: 0.791172, samples/s: 1321.807 1612710976.0131407
train: epoch 52, iter 3600, loss: 2.912264, top_1: 0.564102, top_k: 0.788867, samples/s: 1330.203 1612710995.2584565
train: epoch 52, iter 3700, loss: 2.930146, top_1: 0.560312, top_k: 0.790820, samples/s: 1331.073 1612711014.4909856
train: epoch 52, iter 3800, loss: 2.877740, top_1: 0.553750, top_k: 0.784531, samples/s: 1334.031 1612711033.6809216
train: epoch 52, iter 3900, loss: 2.820215, top_1: 0.569102, top_k: 0.793203, samples/s: 1325.876 1612711052.9889436
train: epoch 52, iter 4000, loss: 3.016184, top_1: 0.557813, top_k: 0.786563, samples/s: 1322.312 1612711072.348913
train: epoch 52, iter 4100, loss: 2.746231, top_1: 0.560312, top_k: 0.790078, samples/s: 1329.195 1612711091.6086946
train: epoch 52, iter 4200, loss: 3.068860, top_1: 0.556680, top_k: 0.786406, samples/s: 1325.932 1612711110.9159088
train: epoch 52, iter 4300, loss: 2.784441, top_1: 0.562578, top_k: 0.787891, samples/s: 1330.689 1612711130.1540313
train: epoch 52, iter 4400, loss: 2.680979, top_1: 0.557891, top_k: 0.785586, samples/s: 1331.160 1612711149.3854465
train: epoch 52, iter 4500, loss: 2.666896, top_1: 0.556406, top_k: 0.785742, samples/s: 1324.477 1612711168.7138205
train: epoch 52, iter 4600, loss: 2.792224, top_1: 0.557539, top_k: 0.786758, samples/s: 1334.436 1612711187.8979545
train: epoch 52, iter 4700, loss: 3.044344, top_1: 0.555781, top_k: 0.784375, samples/s: 1330.215 1612711207.1429017
train: epoch 52, iter 4800, loss: 2.871845, top_1: 0.554922, top_k: 0.786836, samples/s: 1328.193 1612711226.4172769
train: epoch 52, iter 4900, loss: 2.753172, top_1: 0.556328, top_k: 0.786133, samples/s: 1322.025 1612711245.7814991
train: epoch 52, iter 5000, loss: 2.774246, top_1: 0.563359, top_k: 0.792188, samples/s: 1326.799 1612711265.0760162
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_52.
validation: epoch 52, iter 195, top_1: 0.613201, top_k: 0.843049, samples/s: 2819.470 1612711283.3551602
train: epoch 53, iter 100, loss: 2.859804, top_1: 0.570547, top_k: 0.798281, samples/s: 1354.481 1612711318.4006965
train: epoch 53, iter 200, loss: 2.767611, top_1: 0.569023, top_k: 0.794258, samples/s: 1362.807 1612711337.185423
train: epoch 53, iter 300, loss: 2.717385, top_1: 0.565664, top_k: 0.794258, samples/s: 1357.418 1612711356.0447943
train: epoch 53, iter 400, loss: 2.775702, top_1: 0.566172, top_k: 0.798008, samples/s: 1336.798 1612711375.1949239
train: epoch 53, iter 500, loss: 3.096334, top_1: 0.569023, top_k: 0.794687, samples/s: 1322.735 1612711394.5488372
train: epoch 53, iter 600, loss: 2.798940, top_1: 0.569141, top_k: 0.793203, samples/s: 1326.863 1612711413.8424523
train: epoch 53, iter 700, loss: 2.748053, top_1: 0.572109, top_k: 0.798359, samples/s: 1325.868 1612711433.1505122
train: epoch 53, iter 800, loss: 2.736206, top_1: 0.566484, top_k: 0.790977, samples/s: 1322.433 1612711452.508791
train: epoch 53, iter 900, loss: 2.784590, top_1: 0.568281, top_k: 0.790859, samples/s: 1325.892 1612711471.8166416
train: epoch 53, iter 1000, loss: 2.568067, top_1: 0.575625, top_k: 0.797969, samples/s: 1323.571 1612711491.1581988
train: epoch 53, iter 1100, loss: 2.735930, top_1: 0.566484, top_k: 0.792148, samples/s: 1316.249 1612711510.607445
train: epoch 53, iter 1200, loss: 2.522928, top_1: 0.566172, top_k: 0.792969, samples/s: 1320.732 1612711529.9905386
train: epoch 53, iter 1300, loss: 2.873277, top_1: 0.562695, top_k: 0.791797, samples/s: 1321.411 1612711549.3638299
train: epoch 53, iter 1400, loss: 2.821257, top_1: 0.557695, top_k: 0.783672, samples/s: 1328.314 1612711568.6363811
train: epoch 53, iter 1500, loss: 2.941852, top_1: 0.562187, top_k: 0.794453, samples/s: 1327.313 1612711587.923411
train: epoch 53, iter 1600, loss: 2.712813, top_1: 0.565898, top_k: 0.790820, samples/s: 1313.964 1612711607.406534
train: epoch 53, iter 1700, loss: 2.901822, top_1: 0.565195, top_k: 0.792773, samples/s: 1326.340 1612711626.7076752
train: epoch 53, iter 1800, loss: 2.809467, top_1: 0.562539, top_k: 0.787461, samples/s: 1324.751 1612711646.0320969
train: epoch 53, iter 1900, loss: 2.788125, top_1: 0.568242, top_k: 0.790352, samples/s: 1323.878 1612711665.369249
train: epoch 53, iter 2000, loss: 2.927253, top_1: 0.563906, top_k: 0.792188, samples/s: 1322.530 1612711684.7260244
train: epoch 53, iter 2100, loss: 2.688972, top_1: 0.563242, top_k: 0.787031, samples/s: 1318.753 1612711704.1383457
train: epoch 53, iter 2200, loss: 2.766159, top_1: 0.561523, top_k: 0.790391, samples/s: 1329.966 1612711723.3869934
train: epoch 53, iter 2300, loss: 2.897362, top_1: 0.562773, top_k: 0.791016, samples/s: 1322.914 1612711742.7381716
train: epoch 53, iter 2400, loss: 2.836521, top_1: 0.567930, top_k: 0.791992, samples/s: 1325.233 1612711762.055566
train: epoch 53, iter 2500, loss: 2.547777, top_1: 0.562891, top_k: 0.791875, samples/s: 1316.816 1612711781.4963932
train: epoch 53, iter 2600, loss: 3.078460, top_1: 0.562695, top_k: 0.787734, samples/s: 1324.783 1612711800.820332
train: epoch 53, iter 2700, loss: 2.700878, top_1: 0.559922, top_k: 0.788945, samples/s: 1329.348 1612711820.0778487
train: epoch 53, iter 2800, loss: 2.748084, top_1: 0.563477, top_k: 0.789805, samples/s: 1319.948 1612711839.4725828
train: epoch 53, iter 2900, loss: 2.847978, top_1: 0.560937, top_k: 0.790781, samples/s: 1326.297 1612711858.7744358
train: epoch 53, iter 3000, loss: 2.750116, top_1: 0.565937, top_k: 0.787578, samples/s: 1328.702 1612711878.0413735
train: epoch 53, iter 3100, loss: 2.584751, top_1: 0.560312, top_k: 0.791445, samples/s: 1323.030 1612711897.390941
train: epoch 53, iter 3200, loss: 2.879150, top_1: 0.560508, top_k: 0.786797, samples/s: 1322.803 1612711916.7437346
train: epoch 53, iter 3300, loss: 2.772463, top_1: 0.562422, top_k: 0.789570, samples/s: 1322.958 1612711936.0942528
train: epoch 53, iter 3400, loss: 2.631925, top_1: 0.559688, top_k: 0.789414, samples/s: 1325.100 1612711955.4139526
train: epoch 53, iter 3500, loss: 2.779305, top_1: 0.558711, top_k: 0.788789, samples/s: 1327.984 1612711974.6909606
train: epoch 53, iter 3600, loss: 2.854282, top_1: 0.561953, top_k: 0.792344, samples/s: 1326.242 1612711993.9936213
train: epoch 53, iter 3700, loss: 2.911994, top_1: 0.559414, top_k: 0.784219, samples/s: 1326.465 1612712013.2929647
train: epoch 53, iter 3800, loss: 2.790363, top_1: 0.558125, top_k: 0.786602, samples/s: 1323.648 1612712032.6334395
train: epoch 53, iter 3900, loss: 2.857585, top_1: 0.558867, top_k: 0.784375, samples/s: 1323.918 1612712051.9705474
train: epoch 53, iter 4000, loss: 3.004870, top_1: 0.562187, top_k: 0.787891, samples/s: 1321.947 1612712071.3354845
train: epoch 53, iter 4100, loss: 2.923386, top_1: 0.558633, top_k: 0.786211, samples/s: 1323.785 1612712090.6738868
train: epoch 53, iter 4200, loss: 2.726059, top_1: 0.562930, top_k: 0.788008, samples/s: 1323.660 1612712110.0142164
train: epoch 53, iter 4300, loss: 2.828832, top_1: 0.560039, top_k: 0.787578, samples/s: 1318.335 1612712129.4325979
train: epoch 53, iter 4400, loss: 2.889453, top_1: 0.562617, top_k: 0.787617, samples/s: 1326.316 1612712148.7341976
train: epoch 53, iter 4500, loss: 3.015514, top_1: 0.566914, top_k: 0.792422, samples/s: 1319.981 1612712168.1283746
train: epoch 53, iter 4600, loss: 2.867463, top_1: 0.558438, top_k: 0.786602, samples/s: 1330.142 1612712187.3744497
train: epoch 53, iter 4700, loss: 2.912203, top_1: 0.555078, top_k: 0.785391, samples/s: 1322.410 1612712206.7331886
train: epoch 53, iter 4800, loss: 2.767437, top_1: 0.562344, top_k: 0.791914, samples/s: 1326.669 1612712226.029489
train: epoch 53, iter 4900, loss: 2.617656, top_1: 0.555664, top_k: 0.786992, samples/s: 1326.473 1612712245.3287911
train: epoch 53, iter 5000, loss: 2.834478, top_1: 0.560078, top_k: 0.789180, samples/s: 1326.460 1612712264.6282852
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_53.
validation: epoch 53, iter 195, top_1: 0.610757, top_k: 0.840104, samples/s: 2784.570 1612712283.1865995
train: epoch 54, iter 100, loss: 2.720865, top_1: 0.578789, top_k: 0.802891, samples/s: 1359.139 1612712317.8668036
train: epoch 54, iter 200, loss: 2.723809, top_1: 0.572852, top_k: 0.797695, samples/s: 1358.230 1612712336.7147222
train: epoch 54, iter 300, loss: 2.476038, top_1: 0.570000, top_k: 0.798320, samples/s: 1364.046 1612712355.4824455
train: epoch 54, iter 400, loss: 2.826244, top_1: 0.570156, top_k: 0.792734, samples/s: 1343.080 1612712374.5430799
train: epoch 54, iter 500, loss: 2.863640, top_1: 0.566406, top_k: 0.792188, samples/s: 1332.670 1612712393.7526448
train: epoch 54, iter 600, loss: 2.739999, top_1: 0.571250, top_k: 0.798555, samples/s: 1319.699 1612712413.151083
train: epoch 54, iter 700, loss: 2.991597, top_1: 0.572148, top_k: 0.797266, samples/s: 1323.453 1612712432.494381
train: epoch 54, iter 800, loss: 2.709280, top_1: 0.568359, top_k: 0.793320, samples/s: 1331.707 1612712451.71779
train: epoch 54, iter 900, loss: 2.737801, top_1: 0.566641, top_k: 0.791719, samples/s: 1317.266 1612712471.1520767
train: epoch 54, iter 1000, loss: 2.924178, top_1: 0.560234, top_k: 0.785742, samples/s: 1329.616 1612712490.405669
train: epoch 54, iter 1100, loss: 2.874397, top_1: 0.568477, top_k: 0.791484, samples/s: 1327.663 1612712509.6876943
train: epoch 54, iter 1200, loss: 2.841236, top_1: 0.573008, top_k: 0.797305, samples/s: 1333.686 1612712528.882648
train: epoch 54, iter 1300, loss: 2.774571, top_1: 0.568398, top_k: 0.791680, samples/s: 1321.630 1612712548.2526484
train: epoch 54, iter 1400, loss: 2.912973, top_1: 0.571133, top_k: 0.796641, samples/s: 1334.875 1612712567.4304295
train: epoch 54, iter 1500, loss: 2.882389, top_1: 0.562383, top_k: 0.791602, samples/s: 1318.357 1612712586.8486247
train: epoch 54, iter 1600, loss: 2.711642, top_1: 0.561562, top_k: 0.790039, samples/s: 1327.220 1612712606.137038
train: epoch 54, iter 1700, loss: 2.819582, top_1: 0.561250, top_k: 0.788750, samples/s: 1326.779 1612712625.4318335
train: epoch 54, iter 1800, loss: 2.792639, top_1: 0.565078, top_k: 0.793320, samples/s: 1332.977 1612712644.6370726
train: epoch 54, iter 1900, loss: 2.849835, top_1: 0.570937, top_k: 0.791406, samples/s: 1321.720 1612712664.005712
train: epoch 54, iter 2000, loss: 2.748484, top_1: 0.569375, top_k: 0.796133, samples/s: 1330.422 1612712683.2476737
train: epoch 54, iter 2100, loss: 2.725101, top_1: 0.572266, top_k: 0.799922, samples/s: 1323.458 1612712702.5909715
train: epoch 54, iter 2200, loss: 2.805895, top_1: 0.561602, top_k: 0.789961, samples/s: 1320.758 1612712721.973786
train: epoch 54, iter 2300, loss: 2.797215, top_1: 0.562187, top_k: 0.787852, samples/s: 1323.242 1612712741.320221
train: epoch 54, iter 2400, loss: 2.986349, top_1: 0.564102, top_k: 0.790430, samples/s: 1324.673 1612712760.6457374
train: epoch 54, iter 2500, loss: 2.757982, top_1: 0.568438, top_k: 0.790469, samples/s: 1325.444 1612712779.9599795
train: epoch 54, iter 2600, loss: 2.666555, top_1: 0.559688, top_k: 0.792031, samples/s: 1328.076 1612712799.2360406
train: epoch 54, iter 2700, loss: 2.847812, top_1: 0.565195, top_k: 0.792461, samples/s: 1324.508 1612712818.563975
train: epoch 54, iter 2800, loss: 2.945106, top_1: 0.563750, top_k: 0.790742, samples/s: 1326.205 1612712837.8671894
train: epoch 54, iter 2900, loss: 2.909331, top_1: 0.561133, top_k: 0.784687, samples/s: 1328.781 1612712857.1329226
train: epoch 54, iter 3000, loss: 2.627360, top_1: 0.561484, top_k: 0.789102, samples/s: 1324.952 1612712876.4543414
train: epoch 54, iter 3100, loss: 2.726144, top_1: 0.560937, top_k: 0.791328, samples/s: 1323.503 1612712895.7970207
train: epoch 54, iter 3200, loss: 2.871035, top_1: 0.557695, top_k: 0.784648, samples/s: 1325.212 1612712915.1147091
train: epoch 54, iter 3300, loss: 2.997474, top_1: 0.564648, top_k: 0.792500, samples/s: 1333.307 1612712934.3149889
train: epoch 54, iter 3400, loss: 2.842330, top_1: 0.566133, top_k: 0.790039, samples/s: 1328.105 1612712953.590609
train: epoch 54, iter 3500, loss: 2.643533, top_1: 0.570937, top_k: 0.796172, samples/s: 1327.899 1612712972.8692112
train: epoch 54, iter 3600, loss: 2.841753, top_1: 0.556680, top_k: 0.781719, samples/s: 1325.478 1612712992.182964
train: epoch 54, iter 3700, loss: 2.770788, top_1: 0.565234, top_k: 0.791367, samples/s: 1331.101 1612713011.4151466
train: epoch 54, iter 3800, loss: 2.818241, top_1: 0.563242, top_k: 0.792813, samples/s: 1326.664 1612713030.7117867
train: epoch 54, iter 3900, loss: 2.684702, top_1: 0.563711, top_k: 0.793516, samples/s: 1324.083 1612713050.0458074
train: epoch 54, iter 4000, loss: 2.744728, top_1: 0.566914, top_k: 0.793789, samples/s: 1329.276 1612713069.3044395
train: epoch 54, iter 4100, loss: 2.874582, top_1: 0.559688, top_k: 0.787539, samples/s: 1329.805 1612713088.555426
train: epoch 54, iter 4200, loss: 2.915658, top_1: 0.558320, top_k: 0.786289, samples/s: 1330.662 1612713107.7939641
train: epoch 54, iter 4300, loss: 2.727986, top_1: 0.566211, top_k: 0.790234, samples/s: 1327.604 1612713127.0768201
train: epoch 54, iter 4400, loss: 2.855579, top_1: 0.561992, top_k: 0.789180, samples/s: 1329.232 1612713146.336048
train: epoch 54, iter 4500, loss: 2.874280, top_1: 0.564297, top_k: 0.788984, samples/s: 1328.151 1612713165.610962
train: epoch 54, iter 4600, loss: 2.863222, top_1: 0.566172, top_k: 0.789531, samples/s: 1320.723 1612713184.9943833
train: epoch 54, iter 4700, loss: 2.857663, top_1: 0.558438, top_k: 0.788281, samples/s: 1330.111 1612713204.240874
train: epoch 54, iter 4800, loss: 2.801093, top_1: 0.561523, top_k: 0.787852, samples/s: 1335.015 1612713223.4166365
train: epoch 54, iter 4900, loss: 2.694554, top_1: 0.561758, top_k: 0.790469, samples/s: 1327.529 1612713242.7005315
train: epoch 54, iter 5000, loss: 2.775062, top_1: 0.562930, top_k: 0.790547, samples/s: 1327.823 1612713261.9802065
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_54.
validation: epoch 54, iter 195, top_1: 0.612600, top_k: 0.841426, samples/s: 2805.118 1612713280.3584204
train: epoch 55, iter 100, loss: 2.722014, top_1: 0.567109, top_k: 0.797813, samples/s: 1359.692 1612713315.1885703
train: epoch 55, iter 200, loss: 2.800186, top_1: 0.574727, top_k: 0.799531, samples/s: 1359.279 1612713334.0221179
train: epoch 55, iter 300, loss: 2.947140, top_1: 0.568438, top_k: 0.792227, samples/s: 1357.903 1612713352.8747208
train: epoch 55, iter 400, loss: 2.893601, top_1: 0.574961, top_k: 0.796992, samples/s: 1341.198 1612713371.9621367
train: epoch 55, iter 500, loss: 2.725480, top_1: 0.577344, top_k: 0.800664, samples/s: 1329.908 1612713391.2115912
train: epoch 55, iter 600, loss: 2.774200, top_1: 0.575234, top_k: 0.798633, samples/s: 1327.836 1612713410.4910176
train: epoch 55, iter 700, loss: 2.727784, top_1: 0.574648, top_k: 0.798242, samples/s: 1322.408 1612713429.8497007
train: epoch 55, iter 800, loss: 2.801487, top_1: 0.562031, top_k: 0.787305, samples/s: 1323.357 1612713449.19444
train: epoch 55, iter 900, loss: 2.754028, top_1: 0.562383, top_k: 0.795156, samples/s: 1322.862 1612713468.5463746
train: epoch 55, iter 1000, loss: 2.954302, top_1: 0.574063, top_k: 0.799922, samples/s: 1320.749 1612713487.9292977
train: epoch 55, iter 1100, loss: 2.792749, top_1: 0.564922, top_k: 0.796406, samples/s: 1335.719 1612713507.0950038
train: epoch 55, iter 1200, loss: 2.555348, top_1: 0.570625, top_k: 0.795312, samples/s: 1328.141 1612713526.3700745
train: epoch 55, iter 1300, loss: 2.876594, top_1: 0.565664, top_k: 0.793906, samples/s: 1328.018 1612713545.6469183
train: epoch 55, iter 1400, loss: 2.685083, top_1: 0.561602, top_k: 0.789570, samples/s: 1325.412 1612713564.9617152
train: epoch 55, iter 1500, loss: 2.765904, top_1: 0.565078, top_k: 0.794844, samples/s: 1327.146 1612713584.251193
train: epoch 55, iter 1600, loss: 2.898201, top_1: 0.566133, top_k: 0.791484, samples/s: 1324.971 1612713603.5723584
train: epoch 55, iter 1700, loss: 2.709250, top_1: 0.569570, top_k: 0.795312, samples/s: 1325.936 1612713622.8795357
train: epoch 55, iter 1800, loss: 2.855824, top_1: 0.564414, top_k: 0.791836, samples/s: 1326.418 1612713642.1797018
train: epoch 55, iter 1900, loss: 2.877721, top_1: 0.567305, top_k: 0.793398, samples/s: 1329.826 1612713661.4302607
train: epoch 55, iter 2000, loss: 2.916965, top_1: 0.565391, top_k: 0.792539, samples/s: 1328.547 1612713680.6993918
train: epoch 55, iter 2100, loss: 2.705634, top_1: 0.566680, top_k: 0.789922, samples/s: 1315.358 1612713700.1617994
train: epoch 55, iter 2200, loss: 2.988074, top_1: 0.568281, top_k: 0.796680, samples/s: 1329.089 1612713719.4232109
train: epoch 55, iter 2300, loss: 2.666981, top_1: 0.562344, top_k: 0.790508, samples/s: 1329.334 1612713738.6809692
train: epoch 55, iter 2400, loss: 2.847099, top_1: 0.565352, top_k: 0.791602, samples/s: 1330.885 1612713757.9162312
train: epoch 55, iter 2500, loss: 2.917689, top_1: 0.564102, top_k: 0.792188, samples/s: 1328.543 1612713777.185397
train: epoch 55, iter 2600, loss: 2.713241, top_1: 0.569180, top_k: 0.794023, samples/s: 1331.399 1612713796.413308
train: epoch 55, iter 2700, loss: 2.692189, top_1: 0.568203, top_k: 0.789648, samples/s: 1329.937 1612713815.6623316
train: epoch 55, iter 2800, loss: 2.774448, top_1: 0.562891, top_k: 0.788359, samples/s: 1329.771 1612713834.9138093
train: epoch 55, iter 2900, loss: 2.567938, top_1: 0.564688, top_k: 0.791758, samples/s: 1324.537 1612713854.241358
train: epoch 55, iter 3000, loss: 2.589360, top_1: 0.571250, top_k: 0.794570, samples/s: 1329.510 1612713873.4965427
train: epoch 55, iter 3100, loss: 2.957664, top_1: 0.560156, top_k: 0.789453, samples/s: 1324.542 1612713892.8239975
train: epoch 55, iter 3200, loss: 2.903222, top_1: 0.561445, top_k: 0.790234, samples/s: 1327.350 1612713912.1105633
train: epoch 55, iter 3300, loss: 2.800330, top_1: 0.561016, top_k: 0.787461, samples/s: 1332.793 1612713931.3183265
train: epoch 55, iter 3400, loss: 2.841934, top_1: 0.564102, top_k: 0.790625, samples/s: 1331.966 1612713950.5379827
train: epoch 55, iter 3500, loss: 2.900481, top_1: 0.562930, top_k: 0.790469, samples/s: 1326.105 1612713969.8427095
train: epoch 55, iter 3600, loss: 2.801552, top_1: 0.560430, top_k: 0.787422, samples/s: 1323.444 1612713989.1860971
train: epoch 55, iter 3700, loss: 2.898747, top_1: 0.562422, top_k: 0.793672, samples/s: 1329.792 1612714008.437289
train: epoch 55, iter 3800, loss: 2.670929, top_1: 0.561367, top_k: 0.787109, samples/s: 1332.167 1612714027.6540499
train: epoch 55, iter 3900, loss: 2.740090, top_1: 0.561953, top_k: 0.790117, samples/s: 1322.222 1612714047.015463
train: epoch 55, iter 4000, loss: 2.798651, top_1: 0.566055, top_k: 0.790781, samples/s: 1326.812 1612714066.3097699
train: epoch 55, iter 4100, loss: 2.683777, top_1: 0.566484, top_k: 0.791836, samples/s: 1331.681 1612714085.533652
train: epoch 55, iter 4200, loss: 2.919610, top_1: 0.565898, top_k: 0.795117, samples/s: 1326.401 1612714104.8340247
train: epoch 55, iter 4300, loss: 2.826408, top_1: 0.563438, top_k: 0.791758, samples/s: 1324.386 1612714124.163699
train: epoch 55, iter 4400, loss: 2.690893, top_1: 0.560156, top_k: 0.785781, samples/s: 1337.016 1612714143.310839
train: epoch 55, iter 4500, loss: 2.951480, top_1: 0.559258, top_k: 0.790820, samples/s: 1315.531 1612714162.7705748
train: epoch 55, iter 4600, loss: 2.766707, top_1: 0.565508, top_k: 0.791172, samples/s: 1331.929 1612714181.9908445
train: epoch 55, iter 4700, loss: 3.112291, top_1: 0.559023, top_k: 0.788906, samples/s: 1328.992 1612714201.2535322
train: epoch 55, iter 4800, loss: 2.846186, top_1: 0.561250, top_k: 0.789141, samples/s: 1328.181 1612714220.5280817
train: epoch 55, iter 4900, loss: 2.772467, top_1: 0.563203, top_k: 0.794492, samples/s: 1330.328 1612714239.771495
train: epoch 55, iter 5000, loss: 2.940311, top_1: 0.561406, top_k: 0.790547, samples/s: 1323.258 1612714259.1176841
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_55.
validation: epoch 55, iter 195, top_1: 0.621354, top_k: 0.847175, samples/s: 2827.270 1612714277.3311844
train: epoch 56, iter 100, loss: 2.881918, top_1: 0.576055, top_k: 0.798398, samples/s: 1358.051 1612714312.207246
train: epoch 56, iter 200, loss: 2.667124, top_1: 0.576133, top_k: 0.799414, samples/s: 1361.205 1612714331.0139494
train: epoch 56, iter 300, loss: 3.009108, top_1: 0.569180, top_k: 0.794648, samples/s: 1362.103 1612714349.8084426
train: epoch 56, iter 400, loss: 2.739543, top_1: 0.572969, top_k: 0.796523, samples/s: 1339.181 1612714368.9245617
train: epoch 56, iter 500, loss: 2.737884, top_1: 0.572109, top_k: 0.797969, samples/s: 1330.620 1612714388.1637604
train: epoch 56, iter 600, loss: 2.778889, top_1: 0.577539, top_k: 0.798867, samples/s: 1329.603 1612714407.4175868
train: epoch 56, iter 700, loss: 2.724110, top_1: 0.576367, top_k: 0.799922, samples/s: 1318.409 1612714426.8352726
train: epoch 56, iter 800, loss: 2.816880, top_1: 0.566328, top_k: 0.793789, samples/s: 1327.274 1612714446.12261
train: epoch 56, iter 900, loss: 2.803013, top_1: 0.567187, top_k: 0.793594, samples/s: 1320.898 1612714465.5033321
train: epoch 56, iter 1000, loss: 2.695775, top_1: 0.570234, top_k: 0.795352, samples/s: 1327.647 1612714484.7855902
train: epoch 56, iter 1100, loss: 2.684293, top_1: 0.573867, top_k: 0.798242, samples/s: 1326.051 1612714504.0916123
train: epoch 56, iter 1200, loss: 2.814885, top_1: 0.572695, top_k: 0.795898, samples/s: 1327.093 1612714523.3813043
train: epoch 56, iter 1300, loss: 2.804319, top_1: 0.567539, top_k: 0.798047, samples/s: 1327.235 1612714542.669517
train: epoch 56, iter 1400, loss: 2.871184, top_1: 0.569727, top_k: 0.794297, samples/s: 1323.914 1612714562.0061266
train: epoch 56, iter 1500, loss: 2.832163, top_1: 0.568984, top_k: 0.793906, samples/s: 1331.779 1612714581.2285917
train: epoch 56, iter 1600, loss: 3.029826, top_1: 0.572266, top_k: 0.796836, samples/s: 1326.291 1612714600.5304651
train: epoch 56, iter 1700, loss: 2.816578, top_1: 0.569570, top_k: 0.794219, samples/s: 1328.030 1612714619.8071399
train: epoch 56, iter 1800, loss: 2.601175, top_1: 0.559375, top_k: 0.783242, samples/s: 1327.654 1612714639.089338
train: epoch 56, iter 1900, loss: 2.794276, top_1: 0.568047, top_k: 0.793672, samples/s: 1325.593 1612714658.4013846
train: epoch 56, iter 2000, loss: 2.678868, top_1: 0.564766, top_k: 0.790391, samples/s: 1328.600 1612714677.669784
train: epoch 56, iter 2100, loss: 2.781677, top_1: 0.567148, top_k: 0.791797, samples/s: 1327.075 1612714696.960333
train: epoch 56, iter 2200, loss: 2.671454, top_1: 0.565703, top_k: 0.795234, samples/s: 1326.483 1612714716.2595298
train: epoch 56, iter 2300, loss: 2.664979, top_1: 0.563867, top_k: 0.790312, samples/s: 1320.346 1612714735.6483867
train: epoch 56, iter 2400, loss: 2.954797, top_1: 0.570586, top_k: 0.797266, samples/s: 1339.825 1612714754.7553108
train: epoch 56, iter 2500, loss: 2.710171, top_1: 0.570703, top_k: 0.793359, samples/s: 1319.163 1612714774.1615427
train: epoch 56, iter 2600, loss: 3.005548, top_1: 0.569297, top_k: 0.796016, samples/s: 1326.710 1612714793.4574516
train: epoch 56, iter 2700, loss: 2.751862, top_1: 0.563672, top_k: 0.795156, samples/s: 1329.246 1612714812.716425
train: epoch 56, iter 2800, loss: 2.865449, top_1: 0.567148, top_k: 0.796445, samples/s: 1328.994 1612714831.979243
train: epoch 56, iter 2900, loss: 2.857973, top_1: 0.568203, top_k: 0.792461, samples/s: 1326.917 1612714851.271995
train: epoch 56, iter 3000, loss: 2.904709, top_1: 0.565078, top_k: 0.792656, samples/s: 1327.333 1612714870.558768
train: epoch 56, iter 3100, loss: 2.799243, top_1: 0.567461, top_k: 0.792813, samples/s: 1333.132 1612714889.7617776
train: epoch 56, iter 3200, loss: 2.574353, top_1: 0.562734, top_k: 0.791133, samples/s: 1332.175 1612714908.9783525
train: epoch 56, iter 3300, loss: 2.912406, top_1: 0.566445, top_k: 0.788438, samples/s: 1330.422 1612714928.2204244
train: epoch 56, iter 3400, loss: 2.729169, top_1: 0.560508, top_k: 0.789609, samples/s: 1326.087 1612714947.5252986
train: epoch 56, iter 3500, loss: 2.694986, top_1: 0.566953, top_k: 0.795312, samples/s: 1324.082 1612714966.8594651
train: epoch 56, iter 3600, loss: 2.806281, top_1: 0.564609, top_k: 0.787148, samples/s: 1328.831 1612714986.124486
train: epoch 56, iter 3700, loss: 2.866944, top_1: 0.565664, top_k: 0.792109, samples/s: 1330.646 1612715005.363285
train: epoch 56, iter 3800, loss: 2.827822, top_1: 0.563945, top_k: 0.790586, samples/s: 1332.397 1612715024.5768135
train: epoch 56, iter 3900, loss: 2.862319, top_1: 0.565703, top_k: 0.794961, samples/s: 1330.855 1612715043.8125288
train: epoch 56, iter 4000, loss: 2.767306, top_1: 0.560508, top_k: 0.787539, samples/s: 1330.513 1612715063.0532942
train: epoch 56, iter 4100, loss: 2.875296, top_1: 0.564375, top_k: 0.791484, samples/s: 1328.550 1612715082.3224177
train: epoch 56, iter 4200, loss: 2.757032, top_1: 0.565781, top_k: 0.791523, samples/s: 1332.134 1612715101.5396805
train: epoch 56, iter 4300, loss: 2.961995, top_1: 0.561484, top_k: 0.793164, samples/s: 1328.231 1612715120.8134124
train: epoch 56, iter 4400, loss: 2.863066, top_1: 0.566133, top_k: 0.792539, samples/s: 1330.070 1612715140.0604708
train: epoch 56, iter 4500, loss: 2.973432, top_1: 0.565781, top_k: 0.791328, samples/s: 1331.067 1612715159.293229
train: epoch 56, iter 4600, loss: 2.739483, top_1: 0.567695, top_k: 0.789102, samples/s: 1326.215 1612715178.5962517
train: epoch 56, iter 4700, loss: 2.844235, top_1: 0.567148, top_k: 0.794648, samples/s: 1327.703 1612715197.8777013
train: epoch 56, iter 4800, loss: 2.838949, top_1: 0.564492, top_k: 0.790547, samples/s: 1331.354 1612715217.1062424
train: epoch 56, iter 4900, loss: 2.891025, top_1: 0.561641, top_k: 0.791094, samples/s: 1325.113 1612715236.425309
train: epoch 56, iter 5000, loss: 2.727860, top_1: 0.567852, top_k: 0.795273, samples/s: 1334.338 1612715255.6108468
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_56.
validation: epoch 56, iter 195, top_1: 0.612881, top_k: 0.842568, samples/s: 2728.143 1612715274.475575
train: epoch 57, iter 100, loss: 2.753338, top_1: 0.577305, top_k: 0.799844, samples/s: 1357.550 1612715309.430684
train: epoch 57, iter 200, loss: 2.653691, top_1: 0.575078, top_k: 0.797422, samples/s: 1363.401 1612715328.207247
train: epoch 57, iter 300, loss: 2.791917, top_1: 0.574453, top_k: 0.795195, samples/s: 1355.660 1612715347.0910363
train: epoch 57, iter 400, loss: 2.756992, top_1: 0.573320, top_k: 0.796875, samples/s: 1341.207 1612715366.1783109
train: epoch 57, iter 500, loss: 2.506095, top_1: 0.576211, top_k: 0.796914, samples/s: 1327.629 1612715385.4608583
train: epoch 57, iter 600, loss: 2.597499, top_1: 0.576250, top_k: 0.798008, samples/s: 1326.936 1612715404.7533803
train: epoch 57, iter 700, loss: 2.848045, top_1: 0.571992, top_k: 0.798750, samples/s: 1322.489 1612715424.11088
train: epoch 57, iter 800, loss: 2.726892, top_1: 0.572617, top_k: 0.801953, samples/s: 1318.619 1612715443.5251236
train: epoch 57, iter 900, loss: 2.685624, top_1: 0.567070, top_k: 0.794687, samples/s: 1329.797 1612715462.7762341
train: epoch 57, iter 1000, loss: 2.864633, top_1: 0.574414, top_k: 0.798359, samples/s: 1328.216 1612715482.050099
train: epoch 57, iter 1100, loss: 2.675688, top_1: 0.563086, top_k: 0.794297, samples/s: 1311.680 1612715501.5670607
train: epoch 57, iter 1200, loss: 2.840832, top_1: 0.563164, top_k: 0.789336, samples/s: 1329.799 1612715520.8181021
train: epoch 57, iter 1300, loss: 2.732095, top_1: 0.568086, top_k: 0.791406, samples/s: 1320.935 1612715540.1984005
train: epoch 57, iter 1400, loss: 2.752517, top_1: 0.571328, top_k: 0.793906, samples/s: 1323.150 1612715559.5461211
train: epoch 57, iter 1500, loss: 3.008096, top_1: 0.572109, top_k: 0.793984, samples/s: 1330.868 1612715578.7816842
train: epoch 57, iter 1600, loss: 2.829298, top_1: 0.577187, top_k: 0.800977, samples/s: 1324.441 1612715598.1105995
train: epoch 57, iter 1700, loss: 2.753807, top_1: 0.566797, top_k: 0.797695, samples/s: 1322.316 1612715617.4705691
train: epoch 57, iter 1800, loss: 2.770313, top_1: 0.567852, top_k: 0.794492, samples/s: 1324.607 1612715636.7970386
train: epoch 57, iter 1900, loss: 2.866731, top_1: 0.573906, top_k: 0.794648, samples/s: 1321.500 1612715656.1689615
train: epoch 57, iter 2000, loss: 2.851289, top_1: 0.561719, top_k: 0.790312, samples/s: 1321.647 1612715675.5388145
train: epoch 57, iter 2100, loss: 2.808526, top_1: 0.569180, top_k: 0.791211, samples/s: 1330.397 1612715694.7811615
train: epoch 57, iter 2200, loss: 2.762648, top_1: 0.563750, top_k: 0.794609, samples/s: 1321.768 1612715714.149176
train: epoch 57, iter 2300, loss: 2.730379, top_1: 0.568984, top_k: 0.794805, samples/s: 1331.838 1612715733.3706698
train: epoch 57, iter 2400, loss: 2.733050, top_1: 0.571133, top_k: 0.793516, samples/s: 1326.446 1612715752.6704416
train: epoch 57, iter 2500, loss: 2.772935, top_1: 0.570703, top_k: 0.794375, samples/s: 1325.049 1612715771.9904726
train: epoch 57, iter 2600, loss: 2.809448, top_1: 0.566406, top_k: 0.791680, samples/s: 1322.892 1612715791.3420265
train: epoch 57, iter 2700, loss: 2.779989, top_1: 0.569883, top_k: 0.794492, samples/s: 1326.614 1612715810.639235
train: epoch 57, iter 2800, loss: 2.789083, top_1: 0.568906, top_k: 0.796641, samples/s: 1326.033 1612715829.9449077
train: epoch 57, iter 2900, loss: 2.813641, top_1: 0.566719, top_k: 0.793242, samples/s: 1323.719 1612715849.2843933
train: epoch 57, iter 3000, loss: 2.775783, top_1: 0.568125, top_k: 0.794258, samples/s: 1326.032 1612715868.5901458
train: epoch 57, iter 3100, loss: 2.670105, top_1: 0.559844, top_k: 0.789844, samples/s: 1330.079 1612715887.8370469
train: epoch 57, iter 3200, loss: 2.783108, top_1: 0.559805, top_k: 0.785000, samples/s: 1319.188 1612715907.2429368
train: epoch 57, iter 3300, loss: 2.853826, top_1: 0.567031, top_k: 0.794297, samples/s: 1323.157 1612715926.5906115
train: epoch 57, iter 3400, loss: 2.788229, top_1: 0.567187, top_k: 0.791914, samples/s: 1330.548 1612715945.8308063
train: epoch 57, iter 3500, loss: 2.808227, top_1: 0.568477, top_k: 0.795703, samples/s: 1332.028 1612715965.0495648
train: epoch 57, iter 3600, loss: 2.828343, top_1: 0.569883, top_k: 0.793242, samples/s: 1321.848 1612715984.4163837
train: epoch 57, iter 3700, loss: 2.820754, top_1: 0.563125, top_k: 0.792148, samples/s: 1330.851 1612716003.6523387
train: epoch 57, iter 3800, loss: 2.868091, top_1: 0.567930, top_k: 0.789766, samples/s: 1322.737 1612716023.0060546
train: epoch 57, iter 3900, loss: 2.909996, top_1: 0.566133, top_k: 0.790781, samples/s: 1334.549 1612716042.1885188
train: epoch 57, iter 4000, loss: 2.699696, top_1: 0.564063, top_k: 0.791055, samples/s: 1328.348 1612716061.4605865
train: epoch 57, iter 4100, loss: 2.795664, top_1: 0.564180, top_k: 0.790664, samples/s: 1323.850 1612716080.798254
train: epoch 57, iter 4200, loss: 2.788304, top_1: 0.566406, top_k: 0.795352, samples/s: 1326.224 1612716100.1011035
train: epoch 57, iter 4300, loss: 2.701839, top_1: 0.567617, top_k: 0.796289, samples/s: 1326.814 1612716119.3954375
train: epoch 57, iter 4400, loss: 2.770361, top_1: 0.569844, top_k: 0.793359, samples/s: 1324.588 1612716138.7222567
train: epoch 57, iter 4500, loss: 2.798483, top_1: 0.565352, top_k: 0.785977, samples/s: 1324.358 1612716158.0523324
train: epoch 57, iter 4600, loss: 2.776406, top_1: 0.565391, top_k: 0.791211, samples/s: 1325.585 1612716177.3645482
train: epoch 57, iter 4700, loss: 2.893268, top_1: 0.566289, top_k: 0.793242, samples/s: 1324.138 1612716196.6979036
train: epoch 57, iter 4800, loss: 2.647633, top_1: 0.572617, top_k: 0.797461, samples/s: 1334.323 1612716215.8836148
train: epoch 57, iter 4900, loss: 2.836429, top_1: 0.567617, top_k: 0.790898, samples/s: 1316.636 1612716235.3270988
train: epoch 57, iter 5000, loss: 2.687745, top_1: 0.570547, top_k: 0.796133, samples/s: 1330.233 1612716254.5719147
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_57.
validation: epoch 57, iter 195, top_1: 0.611318, top_k: 0.841667, samples/s: 2748.132 1612716273.3082123
train: epoch 58, iter 100, loss: 2.707716, top_1: 0.585352, top_k: 0.806641, samples/s: 1360.234 1612716308.3270507
train: epoch 58, iter 200, loss: 2.849720, top_1: 0.582812, top_k: 0.802695, samples/s: 1356.004 1612716327.2060668
train: epoch 58, iter 300, loss: 2.662618, top_1: 0.575273, top_k: 0.802188, samples/s: 1362.432 1612716345.9960012
train: epoch 58, iter 400, loss: 2.838329, top_1: 0.568086, top_k: 0.795625, samples/s: 1349.996 1612716364.9589987
train: epoch 58, iter 500, loss: 2.621071, top_1: 0.570742, top_k: 0.798047, samples/s: 1332.544 1612716384.1703956
train: epoch 58, iter 600, loss: 2.714318, top_1: 0.574375, top_k: 0.796289, samples/s: 1330.665 1612716403.4089966
train: epoch 58, iter 700, loss: 2.907518, top_1: 0.568516, top_k: 0.796680, samples/s: 1332.420 1612716422.622092
train: epoch 58, iter 800, loss: 2.708006, top_1: 0.575937, top_k: 0.799453, samples/s: 1328.442 1612716441.8927448
train: epoch 58, iter 900, loss: 2.818006, top_1: 0.570195, top_k: 0.794883, samples/s: 1328.201 1612716461.1669862
train: epoch 58, iter 1000, loss: 2.770210, top_1: 0.578984, top_k: 0.799766, samples/s: 1324.006 1612716480.502185
train: epoch 58, iter 1100, loss: 2.958102, top_1: 0.578672, top_k: 0.798164, samples/s: 1331.596 1612716499.7272239
train: epoch 58, iter 1200, loss: 2.717186, top_1: 0.571758, top_k: 0.794766, samples/s: 1330.787 1612716518.9640515
train: epoch 58, iter 1300, loss: 2.795958, top_1: 0.568867, top_k: 0.795195, samples/s: 1335.097 1612716538.138666
train: epoch 58, iter 1400, loss: 2.878335, top_1: 0.571484, top_k: 0.798828, samples/s: 1326.947 1612716557.4310036
train: epoch 58, iter 1500, loss: 2.744856, top_1: 0.566797, top_k: 0.793438, samples/s: 1326.819 1612716576.7252698
train: epoch 58, iter 1600, loss: 2.927566, top_1: 0.567422, top_k: 0.796328, samples/s: 1323.592 1612716596.0666225
train: epoch 58, iter 1700, loss: 2.894861, top_1: 0.573945, top_k: 0.798281, samples/s: 1332.571 1612716615.277624
train: epoch 58, iter 1800, loss: 2.619761, top_1: 0.574648, top_k: 0.799609, samples/s: 1324.429 1612716634.6066394
train: epoch 58, iter 1900, loss: 2.887661, top_1: 0.569141, top_k: 0.796836, samples/s: 1325.018 1612716653.9271364
train: epoch 58, iter 2000, loss: 2.570904, top_1: 0.571016, top_k: 0.796172, samples/s: 1329.581 1612716673.181328
train: epoch 58, iter 2100, loss: 2.926698, top_1: 0.569805, top_k: 0.796680, samples/s: 1327.666 1612716692.4633434
train: epoch 58, iter 2200, loss: 2.835352, top_1: 0.573125, top_k: 0.793164, samples/s: 1332.284 1612716711.6784153
train: epoch 58, iter 2300, loss: 2.715837, top_1: 0.567930, top_k: 0.793477, samples/s: 1332.184 1612716730.8949516
train: epoch 58, iter 2400, loss: 2.566409, top_1: 0.573008, top_k: 0.796094, samples/s: 1331.734 1612716750.1180127
train: epoch 58, iter 2500, loss: 2.776868, top_1: 0.563398, top_k: 0.787734, samples/s: 1328.602 1612716769.3864284
train: epoch 58, iter 2600, loss: 2.698229, top_1: 0.566094, top_k: 0.791250, samples/s: 1329.229 1612716788.645668
train: epoch 58, iter 2700, loss: 2.905172, top_1: 0.570820, top_k: 0.795117, samples/s: 1330.858 1612716807.8813787
train: epoch 58, iter 2800, loss: 2.747881, top_1: 0.569375, top_k: 0.796523, samples/s: 1328.343 1612716827.1535637
train: epoch 58, iter 2900, loss: 2.828720, top_1: 0.573516, top_k: 0.797891, samples/s: 1326.914 1612716846.446429
train: epoch 58, iter 3000, loss: 2.756828, top_1: 0.565508, top_k: 0.794141, samples/s: 1325.803 1612716865.7555132
train: epoch 58, iter 3100, loss: 2.694963, top_1: 0.569414, top_k: 0.796250, samples/s: 1328.904 1612716885.0195243
train: epoch 58, iter 3200, loss: 2.952436, top_1: 0.562656, top_k: 0.790586, samples/s: 1330.313 1612716904.2630715
train: epoch 58, iter 3300, loss: 3.009654, top_1: 0.565703, top_k: 0.792734, samples/s: 1330.306 1612716923.506781
train: epoch 58, iter 3400, loss: 2.833214, top_1: 0.568203, top_k: 0.795547, samples/s: 1330.856 1612716942.74247
train: epoch 58, iter 3500, loss: 2.754876, top_1: 0.572305, top_k: 0.796133, samples/s: 1334.938 1612716961.919428
train: epoch 58, iter 3600, loss: 2.747478, top_1: 0.569492, top_k: 0.792461, samples/s: 1319.583 1612716981.3194578
train: epoch 58, iter 3700, loss: 2.508800, top_1: 0.567148, top_k: 0.795039, samples/s: 1330.541 1612717000.5597749
train: epoch 58, iter 3800, loss: 2.793108, top_1: 0.565625, top_k: 0.792500, samples/s: 1334.125 1612717019.7483625
train: epoch 58, iter 3900, loss: 2.758046, top_1: 0.566719, top_k: 0.791953, samples/s: 1324.347 1612717039.078638
train: epoch 58, iter 4000, loss: 2.783140, top_1: 0.565273, top_k: 0.790234, samples/s: 1329.698 1612717058.3312194
train: epoch 58, iter 4100, loss: 2.690504, top_1: 0.571602, top_k: 0.796953, samples/s: 1330.906 1612717077.566214
train: epoch 58, iter 4200, loss: 2.726261, top_1: 0.568359, top_k: 0.793945, samples/s: 1332.631 1612717096.776295
train: epoch 58, iter 4300, loss: 2.767631, top_1: 0.566523, top_k: 0.794727, samples/s: 1330.772 1612717116.0133092
train: epoch 58, iter 4400, loss: 2.894843, top_1: 0.569141, top_k: 0.794063, samples/s: 1330.632 1612717135.2522676
train: epoch 58, iter 4500, loss: 2.890162, top_1: 0.563633, top_k: 0.791797, samples/s: 1328.549 1612717154.5214503
train: epoch 58, iter 4600, loss: 2.983335, top_1: 0.569336, top_k: 0.793633, samples/s: 1328.644 1612717173.7892027
train: epoch 58, iter 4700, loss: 2.783011, top_1: 0.567148, top_k: 0.795000, samples/s: 1329.062 1612717193.0508144
train: epoch 58, iter 4800, loss: 2.837277, top_1: 0.569727, top_k: 0.794063, samples/s: 1338.068 1612717212.1829185
train: epoch 58, iter 4900, loss: 2.789374, top_1: 0.564883, top_k: 0.792617, samples/s: 1324.800 1612717231.5065415
train: epoch 58, iter 5000, loss: 2.826017, top_1: 0.569453, top_k: 0.797500, samples/s: 1331.820 1612717250.7284274
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_58.
validation: epoch 58, iter 195, top_1: 0.607352, top_k: 0.839904, samples/s: 2803.216 1612717269.121157
train: epoch 59, iter 100, loss: 2.667038, top_1: 0.581406, top_k: 0.804102, samples/s: 1354.833 1612717303.721861
train: epoch 59, iter 200, loss: 2.695520, top_1: 0.575117, top_k: 0.798047, samples/s: 1354.986 1612717322.615115
train: epoch 59, iter 300, loss: 2.806880, top_1: 0.578516, top_k: 0.803477, samples/s: 1361.274 1612717341.4209654
train: epoch 59, iter 400, loss: 2.881446, top_1: 0.576641, top_k: 0.804961, samples/s: 1340.306 1612717360.5211442
train: epoch 59, iter 500, loss: 2.735011, top_1: 0.578125, top_k: 0.800391, samples/s: 1340.029 1612717379.6251917
train: epoch 59, iter 600, loss: 2.796671, top_1: 0.577969, top_k: 0.800391, samples/s: 1322.342 1612717398.984768
train: epoch 59, iter 700, loss: 2.625603, top_1: 0.570781, top_k: 0.801094, samples/s: 1323.272 1612717418.330696
train: epoch 59, iter 800, loss: 2.798910, top_1: 0.571250, top_k: 0.795273, samples/s: 1333.575 1612717437.5272806
train: epoch 59, iter 900, loss: 2.754886, top_1: 0.571484, top_k: 0.797422, samples/s: 1331.475 1612717456.7540724
train: epoch 59, iter 1000, loss: 2.768080, top_1: 0.572695, top_k: 0.797227, samples/s: 1324.058 1612717476.0885627
train: epoch 59, iter 1100, loss: 2.767579, top_1: 0.573555, top_k: 0.800508, samples/s: 1330.361 1612717495.331487
train: epoch 59, iter 1200, loss: 2.807042, top_1: 0.574922, top_k: 0.802578, samples/s: 1331.332 1612717514.5603223
train: epoch 59, iter 1300, loss: 2.733329, top_1: 0.577031, top_k: 0.796719, samples/s: 1326.679 1612717533.8566267
train: epoch 59, iter 1400, loss: 2.818163, top_1: 0.570742, top_k: 0.797969, samples/s: 1324.262 1612717553.1880996
train: epoch 59, iter 1500, loss: 2.596951, top_1: 0.579336, top_k: 0.803164, samples/s: 1334.349 1612717572.3734987
train: epoch 59, iter 1600, loss: 2.699868, top_1: 0.573906, top_k: 0.800977, samples/s: 1333.513 1612717591.5708933
train: epoch 59, iter 1700, loss: 2.821500, top_1: 0.578789, top_k: 0.798828, samples/s: 1329.853 1612717610.8212056
train: epoch 59, iter 1800, loss: 2.652525, top_1: 0.573203, top_k: 0.796250, samples/s: 1332.066 1612717630.0394049
train: epoch 59, iter 1900, loss: 2.759661, top_1: 0.572695, top_k: 0.796992, samples/s: 1326.021 1612717649.3452892
train: epoch 59, iter 2000, loss: 2.801831, top_1: 0.568242, top_k: 0.796875, samples/s: 1331.524 1612717668.5714204
train: epoch 59, iter 2100, loss: 2.776009, top_1: 0.573047, top_k: 0.793867, samples/s: 1327.865 1612717687.8505273
train: epoch 59, iter 2200, loss: 2.685668, top_1: 0.577266, top_k: 0.798555, samples/s: 1336.893 1612717706.9993627
train: epoch 59, iter 2300, loss: 2.802768, top_1: 0.567422, top_k: 0.790508, samples/s: 1328.848 1612717726.2641547
train: epoch 59, iter 2400, loss: 2.929154, top_1: 0.565977, top_k: 0.794453, samples/s: 1331.023 1612717745.4974551
train: epoch 59, iter 2500, loss: 2.727409, top_1: 0.565312, top_k: 0.788477, samples/s: 1325.711 1612717764.8079176
train: epoch 59, iter 2600, loss: 2.820467, top_1: 0.568594, top_k: 0.792773, samples/s: 1335.763 1612717783.9729917
train: epoch 59, iter 2700, loss: 2.798392, top_1: 0.572734, top_k: 0.796172, samples/s: 1330.988 1612717803.20679
train: epoch 59, iter 2800, loss: 2.695151, top_1: 0.568750, top_k: 0.792773, samples/s: 1330.804 1612717822.443346
train: epoch 59, iter 2900, loss: 2.693761, top_1: 0.570898, top_k: 0.799336, samples/s: 1322.522 1612717841.8003187
train: epoch 59, iter 3000, loss: 2.809216, top_1: 0.570547, top_k: 0.795859, samples/s: 1331.218 1612717861.0307724
train: epoch 59, iter 3100, loss: 2.692505, top_1: 0.569375, top_k: 0.799141, samples/s: 1330.444 1612717880.2724252
train: epoch 59, iter 3200, loss: 2.715832, top_1: 0.566719, top_k: 0.791211, samples/s: 1331.767 1612717899.4949985
train: epoch 59, iter 3300, loss: 2.948979, top_1: 0.572227, top_k: 0.796328, samples/s: 1328.312 1612717918.7675796
train: epoch 59, iter 3400, loss: 2.880102, top_1: 0.558867, top_k: 0.791328, samples/s: 1331.688 1612717937.991316
train: epoch 59, iter 3500, loss: 2.689730, top_1: 0.569609, top_k: 0.794219, samples/s: 1324.293 1612717957.3223748
train: epoch 59, iter 3600, loss: 2.774909, top_1: 0.573945, top_k: 0.799219, samples/s: 1331.947 1612717976.5423715
train: epoch 59, iter 3700, loss: 2.857082, top_1: 0.570781, top_k: 0.799023, samples/s: 1334.204 1612717995.7298324
train: epoch 59, iter 3800, loss: 2.935222, top_1: 0.568008, top_k: 0.794570, samples/s: 1333.569 1612718014.926479
train: epoch 59, iter 3900, loss: 2.853501, top_1: 0.568477, top_k: 0.794687, samples/s: 1322.873 1612718034.278317
train: epoch 59, iter 4000, loss: 2.712805, top_1: 0.571289, top_k: 0.800117, samples/s: 1329.403 1612718053.535085
train: epoch 59, iter 4100, loss: 2.821763, top_1: 0.565586, top_k: 0.791758, samples/s: 1334.578 1612718072.7171464
train: epoch 59, iter 4200, loss: 2.703920, top_1: 0.574766, top_k: 0.796836, samples/s: 1323.262 1612718092.0632484
train: epoch 59, iter 4300, loss: 2.998646, top_1: 0.568594, top_k: 0.797539, samples/s: 1328.985 1612718111.3261023
train: epoch 59, iter 4400, loss: 2.887821, top_1: 0.574492, top_k: 0.794922, samples/s: 1328.250 1612718130.5996404
train: epoch 59, iter 4500, loss: 2.858459, top_1: 0.568867, top_k: 0.791250, samples/s: 1333.935 1612718149.79093
train: epoch 59, iter 4600, loss: 2.591043, top_1: 0.567227, top_k: 0.794102, samples/s: 1330.525 1612718169.031478
train: epoch 59, iter 4700, loss: 2.773780, top_1: 0.570391, top_k: 0.792813, samples/s: 1330.748 1612718188.268748
train: epoch 59, iter 4800, loss: 2.717079, top_1: 0.558125, top_k: 0.788789, samples/s: 1331.086 1612718207.5012252
train: epoch 59, iter 4900, loss: 2.657067, top_1: 0.569141, top_k: 0.795820, samples/s: 1328.016 1612718226.7780132
train: epoch 59, iter 5000, loss: 2.729236, top_1: 0.571211, top_k: 0.793633, samples/s: 1334.296 1612718245.9642105
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_59.
validation: epoch 59, iter 195, top_1: 0.612380, top_k: 0.845192, samples/s: 2737.924 1612718264.7669318
train: epoch 60, iter 100, loss: 2.741177, top_1: 0.575039, top_k: 0.802422, samples/s: 1361.491 1612718299.2799392
train: epoch 60, iter 200, loss: 2.703402, top_1: 0.581797, top_k: 0.804180, samples/s: 1360.875 1612718318.0913453
train: epoch 60, iter 300, loss: 2.729398, top_1: 0.578906, top_k: 0.804375, samples/s: 1358.233 1612718336.9393065
train: epoch 60, iter 400, loss: 2.802485, top_1: 0.572109, top_k: 0.802109, samples/s: 1341.603 1612718356.0209987
train: epoch 60, iter 500, loss: 2.741341, top_1: 0.581992, top_k: 0.805195, samples/s: 1334.660 1612718375.2019317
train: epoch 60, iter 600, loss: 2.865423, top_1: 0.576758, top_k: 0.795859, samples/s: 1323.235 1612718394.54843
train: epoch 60, iter 700, loss: 2.796923, top_1: 0.576406, top_k: 0.800000, samples/s: 1328.733 1612718413.8148775
train: epoch 60, iter 800, loss: 2.750139, top_1: 0.578086, top_k: 0.797852, samples/s: 1325.639 1612718433.12634
train: epoch 60, iter 900, loss: 2.611330, top_1: 0.576797, top_k: 0.802031, samples/s: 1329.190 1612718452.3862126
train: epoch 60, iter 1000, loss: 2.725708, top_1: 0.568594, top_k: 0.799336, samples/s: 1324.630 1612718471.7123184
train: epoch 60, iter 1100, loss: 2.756156, top_1: 0.577187, top_k: 0.797070, samples/s: 1342.631 1612718490.7794745
train: epoch 60, iter 1200, loss: 2.726547, top_1: 0.571484, top_k: 0.799414, samples/s: 1323.793 1612718510.1177146
train: epoch 60, iter 1300, loss: 2.607434, top_1: 0.577812, top_k: 0.803164, samples/s: 1331.140 1612718529.3494449
train: epoch 60, iter 1400, loss: 2.797274, top_1: 0.576641, top_k: 0.802578, samples/s: 1331.000 1612718548.5830295
train: epoch 60, iter 1500, loss: 2.703693, top_1: 0.578281, top_k: 0.800937, samples/s: 1328.549 1612718567.8521569
train: epoch 60, iter 1600, loss: 2.753646, top_1: 0.575391, top_k: 0.804727, samples/s: 1328.447 1612718587.1228287
train: epoch 60, iter 1700, loss: 2.695190, top_1: 0.573203, top_k: 0.801328, samples/s: 1332.568 1612718606.3337963
train: epoch 60, iter 1800, loss: 2.857789, top_1: 0.574844, top_k: 0.794805, samples/s: 1326.082 1612718625.6391852
train: epoch 60, iter 1900, loss: 2.690814, top_1: 0.573555, top_k: 0.799648, samples/s: 1328.158 1612718644.913811
train: epoch 60, iter 2000, loss: 2.576650, top_1: 0.576445, top_k: 0.798359, samples/s: 1337.168 1612718664.058872
train: epoch 60, iter 2100, loss: 2.724183, top_1: 0.569297, top_k: 0.794219, samples/s: 1325.084 1612718683.3781514
train: epoch 60, iter 2200, loss: 2.883586, top_1: 0.577500, top_k: 0.798242, samples/s: 1340.349 1612718702.4775712
train: epoch 60, iter 2300, loss: 2.766728, top_1: 0.569648, top_k: 0.795391, samples/s: 1327.378 1612718721.7637444
train: epoch 60, iter 2400, loss: 2.756342, top_1: 0.574063, top_k: 0.796250, samples/s: 1334.637 1612718740.9450192
train: epoch 60, iter 2500, loss: 2.904856, top_1: 0.570469, top_k: 0.800742, samples/s: 1327.627 1612718760.2275534
train: epoch 60, iter 2600, loss: 2.763505, top_1: 0.570352, top_k: 0.798789, samples/s: 1333.332 1612718779.4275036
train: epoch 60, iter 2700, loss: 2.760464, top_1: 0.570273, top_k: 0.795625, samples/s: 1329.341 1612718798.6851966
train: epoch 60, iter 2800, loss: 2.719861, top_1: 0.572773, top_k: 0.795703, samples/s: 1335.651 1612718817.8518376
train: epoch 60, iter 2900, loss: 2.540503, top_1: 0.573125, top_k: 0.797773, samples/s: 1327.271 1612718837.1396053
train: epoch 60, iter 3000, loss: 2.657369, top_1: 0.571602, top_k: 0.798281, samples/s: 1334.805 1612718856.318408
train: epoch 60, iter 3100, loss: 2.742070, top_1: 0.569492, top_k: 0.793008, samples/s: 1329.731 1612718875.5703866
train: epoch 60, iter 3200, loss: 2.565570, top_1: 0.575195, top_k: 0.795859, samples/s: 1331.225 1612718894.8008528
train: epoch 60, iter 3300, loss: 2.760291, top_1: 0.569688, top_k: 0.796719, samples/s: 1326.575 1612718914.098668
train: epoch 60, iter 3400, loss: 3.032047, top_1: 0.570742, top_k: 0.791836, samples/s: 1340.299 1612718933.1988747
train: epoch 60, iter 3500, loss: 2.656497, top_1: 0.575078, top_k: 0.799023, samples/s: 1335.379 1612718952.369445
train: epoch 60, iter 3600, loss: 2.733378, top_1: 0.570000, top_k: 0.797227, samples/s: 1333.098 1612718971.5728068
train: epoch 60, iter 3700, loss: 2.680982, top_1: 0.567461, top_k: 0.794648, samples/s: 1330.381 1612718990.815413
train: epoch 60, iter 3800, loss: 2.839493, top_1: 0.565039, top_k: 0.792305, samples/s: 1333.297 1612719010.0159862
train: epoch 60, iter 3900, loss: 2.786767, top_1: 0.574375, top_k: 0.798359, samples/s: 1330.113 1612719029.26246
train: epoch 60, iter 4000, loss: 2.895051, top_1: 0.570664, top_k: 0.793906, samples/s: 1321.825 1612719048.6296139
train: epoch 60, iter 4100, loss: 2.878876, top_1: 0.572461, top_k: 0.795703, samples/s: 1328.723 1612719067.8962076
train: epoch 60, iter 4200, loss: 2.744807, top_1: 0.569453, top_k: 0.797578, samples/s: 1335.714 1612719087.0620148
train: epoch 60, iter 4300, loss: 2.685875, top_1: 0.572187, top_k: 0.796016, samples/s: 1329.782 1612719106.3133025
train: epoch 60, iter 4400, loss: 2.846628, top_1: 0.565273, top_k: 0.794180, samples/s: 1331.930 1612719125.5336394
train: epoch 60, iter 4500, loss: 2.718314, top_1: 0.568828, top_k: 0.796562, samples/s: 1328.938 1612719144.7970026
train: epoch 60, iter 4600, loss: 2.883099, top_1: 0.564531, top_k: 0.795430, samples/s: 1340.019 1612719163.9011862
train: epoch 60, iter 4700, loss: 2.616678, top_1: 0.572930, top_k: 0.798906, samples/s: 1326.324 1612719183.2026467
train: epoch 60, iter 4800, loss: 2.884735, top_1: 0.571562, top_k: 0.796133, samples/s: 1331.145 1612719202.43427
train: epoch 60, iter 4900, loss: 2.815544, top_1: 0.565859, top_k: 0.791641, samples/s: 1333.030 1612719221.6386218
train: epoch 60, iter 5000, loss: 2.709731, top_1: 0.577461, top_k: 0.801133, samples/s: 1333.545 1612719240.8356352
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_60.
validation: epoch 60, iter 195, top_1: 0.621294, top_k: 0.847416, samples/s: 2791.496 1612719259.310851
train: epoch 61, iter 100, loss: 2.903617, top_1: 0.576406, top_k: 0.801406, samples/s: 1355.250 1612719294.082574
train: epoch 61, iter 200, loss: 2.669456, top_1: 0.587383, top_k: 0.808242, samples/s: 1362.458 1612719312.8721113
train: epoch 61, iter 300, loss: 2.726577, top_1: 0.578477, top_k: 0.803984, samples/s: 1355.360 1612719331.7600496
train: epoch 61, iter 400, loss: 2.886801, top_1: 0.573555, top_k: 0.799727, samples/s: 1349.080 1612719350.7359912
train: epoch 61, iter 500, loss: 2.715428, top_1: 0.580703, top_k: 0.804961, samples/s: 1325.030 1612719370.0563147
train: epoch 61, iter 600, loss: 2.779992, top_1: 0.583086, top_k: 0.803086, samples/s: 1332.372 1612719389.2701752
train: epoch 61, iter 700, loss: 2.690904, top_1: 0.580977, top_k: 0.806328, samples/s: 1326.203 1612719408.5733356
train: epoch 61, iter 800, loss: 2.732623, top_1: 0.578398, top_k: 0.804453, samples/s: 1324.303 1612719427.904265
train: epoch 61, iter 900, loss: 2.749599, top_1: 0.584492, top_k: 0.807227, samples/s: 1328.347 1612719447.1764033
train: epoch 61, iter 1000, loss: 2.597616, top_1: 0.582500, top_k: 0.801602, samples/s: 1326.569 1612719466.4742563
train: epoch 61, iter 1100, loss: 2.964306, top_1: 0.570078, top_k: 0.797344, samples/s: 1326.386 1612719485.7748802
train: epoch 61, iter 1200, loss: 2.721349, top_1: 0.571055, top_k: 0.799922, samples/s: 1324.074 1612719505.1091187
train: epoch 61, iter 1300, loss: 2.636073, top_1: 0.575117, top_k: 0.800547, samples/s: 1318.596 1612719524.523682
train: epoch 61, iter 1400, loss: 2.745178, top_1: 0.578828, top_k: 0.801445, samples/s: 1338.193 1612719543.6539986
train: epoch 61, iter 1500, loss: 2.722565, top_1: 0.573203, top_k: 0.800586, samples/s: 1326.514 1612719562.9526882
train: epoch 61, iter 1600, loss: 2.626676, top_1: 0.578477, top_k: 0.804336, samples/s: 1327.477 1612719582.237399
train: epoch 61, iter 1700, loss: 2.748670, top_1: 0.572695, top_k: 0.799492, samples/s: 1325.847 1612719601.5457861
train: epoch 61, iter 1800, loss: 2.793850, top_1: 0.577539, top_k: 0.800781, samples/s: 1331.021 1612719620.7792192
train: epoch 61, iter 1900, loss: 2.587294, top_1: 0.580977, top_k: 0.802773, samples/s: 1330.399 1612719640.0215273
train: epoch 61, iter 2000, loss: 2.591287, top_1: 0.571133, top_k: 0.795234, samples/s: 1328.600 1612719659.2898777
train: epoch 61, iter 2100, loss: 2.654609, top_1: 0.571094, top_k: 0.796055, samples/s: 1327.562 1612719678.5733433
train: epoch 61, iter 2200, loss: 2.923833, top_1: 0.575039, top_k: 0.799727, samples/s: 1322.416 1612719697.9319224
train: epoch 61, iter 2300, loss: 2.652645, top_1: 0.571211, top_k: 0.793438, samples/s: 1332.644 1612719717.1419594
train: epoch 61, iter 2400, loss: 2.877223, top_1: 0.570391, top_k: 0.795508, samples/s: 1326.070 1612719736.446994
train: epoch 61, iter 2500, loss: 2.769654, top_1: 0.571367, top_k: 0.795195, samples/s: 1327.560 1612719755.730454
train: epoch 61, iter 2600, loss: 2.876254, top_1: 0.574375, top_k: 0.798438, samples/s: 1321.886 1612719775.0968332
train: epoch 61, iter 2700, loss: 2.889313, top_1: 0.567305, top_k: 0.791602, samples/s: 1331.255 1612719794.3266964
train: epoch 61, iter 2800, loss: 2.801062, top_1: 0.574922, top_k: 0.799727, samples/s: 1330.006 1612719813.5748124
train: epoch 61, iter 2900, loss: 2.834210, top_1: 0.574141, top_k: 0.796875, samples/s: 1329.557 1612719832.829274
train: epoch 61, iter 3000, loss: 2.720671, top_1: 0.570312, top_k: 0.794297, samples/s: 1331.089 1612719852.0616822
train: epoch 61, iter 3100, loss: 2.634093, top_1: 0.581016, top_k: 0.801328, samples/s: 1330.865 1612719871.2973206
train: epoch 61, iter 3200, loss: 2.794605, top_1: 0.570781, top_k: 0.793711, samples/s: 1332.025 1612719890.5161734
train: epoch 61, iter 3300, loss: 2.852858, top_1: 0.568281, top_k: 0.792383, samples/s: 1322.573 1612719909.8723223
train: epoch 61, iter 3400, loss: 2.810137, top_1: 0.575586, top_k: 0.801133, samples/s: 1331.844 1612719929.0938401
train: epoch 61, iter 3500, loss: 2.709496, top_1: 0.566523, top_k: 0.793789, samples/s: 1329.842 1612719948.3442628
train: epoch 61, iter 3600, loss: 2.964192, top_1: 0.569648, top_k: 0.795898, samples/s: 1330.430 1612719967.5860953
train: epoch 61, iter 3700, loss: 2.623255, top_1: 0.572070, top_k: 0.794023, samples/s: 1331.568 1612719986.8115454
train: epoch 61, iter 3800, loss: 2.872087, top_1: 0.575313, top_k: 0.802422, samples/s: 1326.295 1612720006.1134717
train: epoch 61, iter 3900, loss: 2.747360, top_1: 0.569258, top_k: 0.799063, samples/s: 1328.763 1612720025.3794935
train: epoch 61, iter 4000, loss: 2.657055, top_1: 0.569648, top_k: 0.794922, samples/s: 1332.676 1612720044.5889964
train: epoch 61, iter 4100, loss: 2.644817, top_1: 0.577969, top_k: 0.803555, samples/s: 1332.342 1612720063.8032963
train: epoch 61, iter 4200, loss: 2.762605, top_1: 0.576562, top_k: 0.799180, samples/s: 1329.818 1612720083.0540667
train: epoch 61, iter 4300, loss: 2.928355, top_1: 0.564102, top_k: 0.791406, samples/s: 1323.983 1612720102.3896346
train: epoch 61, iter 4400, loss: 2.677549, top_1: 0.570234, top_k: 0.796602, samples/s: 1335.548 1612720121.5577438
train: epoch 61, iter 4500, loss: 2.816966, top_1: 0.574219, top_k: 0.799531, samples/s: 1323.705 1612720140.8974254
train: epoch 61, iter 4600, loss: 2.867062, top_1: 0.569453, top_k: 0.792148, samples/s: 1329.226 1612720160.1567879
train: epoch 61, iter 4700, loss: 2.725745, top_1: 0.566172, top_k: 0.795273, samples/s: 1325.918 1612720179.4641337
train: epoch 61, iter 4800, loss: 2.822211, top_1: 0.574648, top_k: 0.796055, samples/s: 1330.032 1612720198.7117743
train: epoch 61, iter 4900, loss: 2.764076, top_1: 0.569805, top_k: 0.795664, samples/s: 1332.854 1612720217.9186912
train: epoch 61, iter 5000, loss: 2.703847, top_1: 0.571680, top_k: 0.798203, samples/s: 1324.310 1612720237.249535
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_61.
validation: epoch 61, iter 195, top_1: 0.623377, top_k: 0.850000, samples/s: 2693.153 1612720256.3469791
train: epoch 62, iter 100, loss: 2.782148, top_1: 0.580664, top_k: 0.802578, samples/s: 1358.078 1612720296.106535
train: epoch 62, iter 200, loss: 2.579836, top_1: 0.588945, top_k: 0.812500, samples/s: 1358.098 1612720314.9564886
train: epoch 62, iter 300, loss: 2.731402, top_1: 0.584414, top_k: 0.803594, samples/s: 1357.137 1612720333.8197103
train: epoch 62, iter 400, loss: 2.672846, top_1: 0.575117, top_k: 0.802031, samples/s: 1357.220 1612720352.6818
train: epoch 62, iter 500, loss: 2.793102, top_1: 0.578906, top_k: 0.805859, samples/s: 1344.884 1612720371.7167926
train: epoch 62, iter 600, loss: 2.500703, top_1: 0.577578, top_k: 0.803906, samples/s: 1329.201 1612720390.9764833
train: epoch 62, iter 700, loss: 2.769196, top_1: 0.583555, top_k: 0.806680, samples/s: 1321.777 1612720410.3443563
train: epoch 62, iter 800, loss: 2.793209, top_1: 0.579961, top_k: 0.803750, samples/s: 1340.957 1612720429.4352002
train: epoch 62, iter 900, loss: 2.751965, top_1: 0.580937, top_k: 0.804375, samples/s: 1323.265 1612720448.7813678
train: epoch 62, iter 1000, loss: 2.755577, top_1: 0.573594, top_k: 0.799570, samples/s: 1334.562 1612720467.9636066
train: epoch 62, iter 1100, loss: 2.650245, top_1: 0.578008, top_k: 0.800312, samples/s: 1329.240 1612720487.2227345
train: epoch 62, iter 1200, loss: 2.798529, top_1: 0.573398, top_k: 0.801406, samples/s: 1334.818 1612720506.4014132
train: epoch 62, iter 1300, loss: 2.877366, top_1: 0.572852, top_k: 0.799102, samples/s: 1333.915 1612720525.593101
train: epoch 62, iter 1400, loss: 2.755450, top_1: 0.575000, top_k: 0.799687, samples/s: 1332.348 1612720544.8072302
train: epoch 62, iter 1500, loss: 2.836028, top_1: 0.580508, top_k: 0.801719, samples/s: 1334.908 1612720563.9845707
train: epoch 62, iter 1600, loss: 2.587252, top_1: 0.576641, top_k: 0.797969, samples/s: 1334.263 1612720583.1712337
train: epoch 62, iter 1700, loss: 2.744034, top_1: 0.575625, top_k: 0.802461, samples/s: 1331.376 1612720602.399409
train: epoch 62, iter 1800, loss: 2.878198, top_1: 0.576406, top_k: 0.799297, samples/s: 1326.394 1612720621.6999195
train: epoch 62, iter 1900, loss: 2.691201, top_1: 0.576797, top_k: 0.799766, samples/s: 1331.182 1612720640.9309664
train: epoch 62, iter 2000, loss: 2.796187, top_1: 0.575898, top_k: 0.798711, samples/s: 1323.271 1612720660.277031
train: epoch 62, iter 2100, loss: 2.637991, top_1: 0.575508, top_k: 0.798945, samples/s: 1333.969 1612720679.4678893
train: epoch 62, iter 2200, loss: 2.731666, top_1: 0.570703, top_k: 0.796875, samples/s: 1333.184 1612720698.6698942
train: epoch 62, iter 2300, loss: 2.640048, top_1: 0.572461, top_k: 0.799844, samples/s: 1339.171 1612720717.7862139
train: epoch 62, iter 2400, loss: 2.508934, top_1: 0.577109, top_k: 0.799805, samples/s: 1327.660 1612720737.0682676
train: epoch 62, iter 2500, loss: 2.884039, top_1: 0.574180, top_k: 0.798633, samples/s: 1330.253 1612720756.3127246
train: epoch 62, iter 2600, loss: 2.851813, top_1: 0.575820, top_k: 0.797305, samples/s: 1330.261 1612720775.5570889
train: epoch 62, iter 2700, loss: 2.771714, top_1: 0.575625, top_k: 0.798047, samples/s: 1331.203 1612720794.7877727
train: epoch 62, iter 2800, loss: 2.541687, top_1: 0.573242, top_k: 0.801133, samples/s: 1326.911 1612720814.0807033
train: epoch 62, iter 2900, loss: 2.929961, top_1: 0.572344, top_k: 0.798281, samples/s: 1337.662 1612720833.218623
train: epoch 62, iter 3000, loss: 2.741261, top_1: 0.574531, top_k: 0.796914, samples/s: 1335.904 1612720852.38163
train: epoch 62, iter 3100, loss: 2.845625, top_1: 0.573516, top_k: 0.800273, samples/s: 1330.031 1612720871.629361
train: epoch 62, iter 3200, loss: 2.593379, top_1: 0.577422, top_k: 0.802188, samples/s: 1325.860 1612720890.9375882
train: epoch 62, iter 3300, loss: 2.870546, top_1: 0.568359, top_k: 0.793242, samples/s: 1330.389 1612720910.1800191
train: epoch 62, iter 3400, loss: 2.767280, top_1: 0.575313, top_k: 0.796055, samples/s: 1333.968 1612720929.3708785
train: epoch 62, iter 3500, loss: 2.798110, top_1: 0.571367, top_k: 0.792773, samples/s: 1336.820 1612720948.5208406
train: epoch 62, iter 3600, loss: 2.751199, top_1: 0.570352, top_k: 0.801016, samples/s: 1326.992 1612720967.812555
train: epoch 62, iter 3700, loss: 2.683229, top_1: 0.579102, top_k: 0.801016, samples/s: 1331.214 1612720987.0431194
train: epoch 62, iter 3800, loss: 2.816624, top_1: 0.568906, top_k: 0.796055, samples/s: 1332.502 1612721006.2550972
train: epoch 62, iter 3900, loss: 2.802130, top_1: 0.574375, top_k: 0.801914, samples/s: 1330.787 1612721025.4918454
train: epoch 62, iter 4000, loss: 2.833534, top_1: 0.577266, top_k: 0.798906, samples/s: 1332.654 1612721044.7016194
train: epoch 62, iter 4100, loss: 2.872413, top_1: 0.572187, top_k: 0.797930, samples/s: 1331.446 1612721063.928916
train: epoch 62, iter 4200, loss: 2.841612, top_1: 0.570508, top_k: 0.796250, samples/s: 1338.616 1612721083.0531368
train: epoch 62, iter 4300, loss: 2.672327, top_1: 0.573203, top_k: 0.797695, samples/s: 1315.947 1612721102.5067317
train: epoch 62, iter 4400, loss: 2.810780, top_1: 0.571992, top_k: 0.798555, samples/s: 1339.242 1612721121.622082
train: epoch 62, iter 4500, loss: 2.861127, top_1: 0.573398, top_k: 0.794844, samples/s: 1329.993 1612721140.870254
train: epoch 62, iter 4600, loss: 2.743615, top_1: 0.567891, top_k: 0.796094, samples/s: 1336.816 1612721160.0203097
train: epoch 62, iter 4700, loss: 2.795287, top_1: 0.579141, top_k: 0.799336, samples/s: 1335.879 1612721179.183648
train: epoch 62, iter 4800, loss: 2.776972, top_1: 0.577461, top_k: 0.801211, samples/s: 1334.570 1612721198.3659391
train: epoch 62, iter 4900, loss: 2.759460, top_1: 0.575313, top_k: 0.800977, samples/s: 1330.267 1612721217.610157
train: epoch 62, iter 5000, loss: 2.723628, top_1: 0.570469, top_k: 0.796406, samples/s: 1332.591 1612721236.8208065
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_62.
validation: epoch 62, iter 195, top_1: 0.619431, top_k: 0.850240, samples/s: 2779.088 1612721255.3964815
train: epoch 63, iter 100, loss: 2.728438, top_1: 0.587539, top_k: 0.804492, samples/s: 1357.511 1612721290.168982
train: epoch 63, iter 200, loss: 2.740559, top_1: 0.592969, top_k: 0.812383, samples/s: 1359.201 1612721309.0035853
train: epoch 63, iter 300, loss: 2.751560, top_1: 0.584766, top_k: 0.807617, samples/s: 1360.268 1612721327.823428
train: epoch 63, iter 400, loss: 2.801364, top_1: 0.579141, top_k: 0.805469, samples/s: 1343.468 1612721346.878584
train: epoch 63, iter 500, loss: 2.931712, top_1: 0.589258, top_k: 0.806523, samples/s: 1335.752 1612721366.0437849
train: epoch 63, iter 600, loss: 2.667009, top_1: 0.578672, top_k: 0.804063, samples/s: 1331.533 1612721385.269757
train: epoch 63, iter 700, loss: 2.840090, top_1: 0.581992, top_k: 0.803906, samples/s: 1330.928 1612721404.5044513
train: epoch 63, iter 800, loss: 2.657849, top_1: 0.581328, top_k: 0.802031, samples/s: 1331.875 1612721423.7255208
train: epoch 63, iter 900, loss: 2.707758, top_1: 0.585664, top_k: 0.805195, samples/s: 1324.697 1612721443.050637
train: epoch 63, iter 1000, loss: 2.628100, top_1: 0.577578, top_k: 0.802617, samples/s: 1333.783 1612721462.2441928
train: epoch 63, iter 1100, loss: 2.659651, top_1: 0.582187, top_k: 0.804219, samples/s: 1332.340 1612721481.4584963
train: epoch 63, iter 1200, loss: 2.642235, top_1: 0.577930, top_k: 0.801836, samples/s: 1333.669 1612721500.6537352
train: epoch 63, iter 1300, loss: 2.829951, top_1: 0.574023, top_k: 0.798633, samples/s: 1331.667 1612721519.8777401
train: epoch 63, iter 1400, loss: 2.782405, top_1: 0.576523, top_k: 0.801914, samples/s: 1330.539 1612721539.118071
train: epoch 63, iter 1500, loss: 2.806637, top_1: 0.580664, top_k: 0.803398, samples/s: 1331.775 1612721558.3405256
train: epoch 63, iter 1600, loss: 2.774312, top_1: 0.581289, top_k: 0.800078, samples/s: 1330.190 1612721577.5858555
train: epoch 63, iter 1700, loss: 2.762195, top_1: 0.574609, top_k: 0.801719, samples/s: 1333.110 1612721596.789107
train: epoch 63, iter 1800, loss: 2.725069, top_1: 0.574023, top_k: 0.797070, samples/s: 1334.521 1612721615.9719622
train: epoch 63, iter 1900, loss: 2.590902, top_1: 0.575625, top_k: 0.798359, samples/s: 1332.270 1612721635.1872945
train: epoch 63, iter 2000, loss: 2.580591, top_1: 0.580391, top_k: 0.803555, samples/s: 1333.922 1612721654.378824
train: epoch 63, iter 2100, loss: 2.659776, top_1: 0.574414, top_k: 0.798789, samples/s: 1328.912 1612721673.6427026
train: epoch 63, iter 2200, loss: 2.697555, top_1: 0.574844, top_k: 0.800156, samples/s: 1333.761 1612721692.836635
train: epoch 63, iter 2300, loss: 2.770442, top_1: 0.576328, top_k: 0.799844, samples/s: 1339.125 1612721711.9535284
train: epoch 63, iter 2400, loss: 2.760752, top_1: 0.576328, top_k: 0.802891, samples/s: 1324.298 1612721731.2845538
train: epoch 63, iter 2500, loss: 2.914110, top_1: 0.574023, top_k: 0.799805, samples/s: 1335.843 1612721750.4484904
train: epoch 63, iter 2600, loss: 2.934932, top_1: 0.579961, top_k: 0.802188, samples/s: 1331.574 1612721769.673791
train: epoch 63, iter 2700, loss: 2.830440, top_1: 0.575508, top_k: 0.799727, samples/s: 1331.070 1612721788.9064562
train: epoch 63, iter 2800, loss: 2.827753, top_1: 0.579766, top_k: 0.803984, samples/s: 1331.789 1612721808.1287467
train: epoch 63, iter 2900, loss: 2.658497, top_1: 0.566953, top_k: 0.796914, samples/s: 1338.752 1612721827.2510564
train: epoch 63, iter 3000, loss: 2.622074, top_1: 0.573867, top_k: 0.801406, samples/s: 1329.955 1612721846.4997652
train: epoch 63, iter 3100, loss: 2.702129, top_1: 0.574766, top_k: 0.800859, samples/s: 1336.374 1612721865.6560855
train: epoch 63, iter 3200, loss: 2.774635, top_1: 0.576367, top_k: 0.804375, samples/s: 1335.182 1612721884.8294969
train: epoch 63, iter 3300, loss: 2.888964, top_1: 0.577344, top_k: 0.797578, samples/s: 1336.634 1612721903.9821432
train: epoch 63, iter 3400, loss: 2.662825, top_1: 0.577031, top_k: 0.803633, samples/s: 1324.594 1612721923.3087933
train: epoch 63, iter 3500, loss: 2.773962, top_1: 0.570859, top_k: 0.797148, samples/s: 1334.349 1612721942.4942093
train: epoch 63, iter 3600, loss: 2.667568, top_1: 0.576445, top_k: 0.801133, samples/s: 1337.278 1612721961.637574
train: epoch 63, iter 3700, loss: 2.781534, top_1: 0.577852, top_k: 0.803008, samples/s: 1331.416 1612721980.8651597
train: epoch 63, iter 3800, loss: 2.784874, top_1: 0.575117, top_k: 0.801055, samples/s: 1335.474 1612722000.034439
train: epoch 63, iter 3900, loss: 2.836112, top_1: 0.569883, top_k: 0.795547, samples/s: 1331.988 1612722019.2537878
train: epoch 63, iter 4000, loss: 2.918740, top_1: 0.574688, top_k: 0.800117, samples/s: 1325.517 1612722038.5674138
train: epoch 63, iter 4100, loss: 2.647200, top_1: 0.577773, top_k: 0.798750, samples/s: 1345.783 1612722057.5894673
train: epoch 63, iter 4200, loss: 2.650713, top_1: 0.568945, top_k: 0.796328, samples/s: 1334.814 1612722076.7685397
train: epoch 63, iter 4300, loss: 2.824798, top_1: 0.576367, top_k: 0.799531, samples/s: 1333.083 1612722095.9717288
train: epoch 63, iter 4400, loss: 2.805444, top_1: 0.574219, top_k: 0.795234, samples/s: 1334.791 1612722115.1507132
train: epoch 63, iter 4500, loss: 2.925535, top_1: 0.576367, top_k: 0.797695, samples/s: 1331.911 1612722134.3713377
train: epoch 63, iter 4600, loss: 2.645916, top_1: 0.573672, top_k: 0.801055, samples/s: 1333.002 1612722153.5759993
train: epoch 63, iter 4700, loss: 2.813430, top_1: 0.573672, top_k: 0.794961, samples/s: 1341.173 1612722172.6637652
train: epoch 63, iter 4800, loss: 2.850392, top_1: 0.575664, top_k: 0.798125, samples/s: 1336.002 1612722191.8254035
train: epoch 63, iter 4900, loss: 2.871155, top_1: 0.573594, top_k: 0.797148, samples/s: 1334.990 1612722211.0015907
train: epoch 63, iter 5000, loss: 2.741192, top_1: 0.580000, top_k: 0.800195, samples/s: 1333.826 1612722230.194549
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_63.
validation: epoch 63, iter 195, top_1: 0.622957, top_k: 0.852504, samples/s: 2777.750 1612722248.7390513
train: epoch 64, iter 100, loss: 2.499613, top_1: 0.590508, top_k: 0.811836, samples/s: 1354.345 1612722283.635545
train: epoch 64, iter 200, loss: 2.825830, top_1: 0.586406, top_k: 0.807422, samples/s: 1360.194 1612722302.4563718
train: epoch 64, iter 300, loss: 2.795594, top_1: 0.586133, top_k: 0.807695, samples/s: 1357.260 1612722321.3180299
train: epoch 64, iter 400, loss: 2.686175, top_1: 0.583750, top_k: 0.803828, samples/s: 1332.458 1612722340.5306458
train: epoch 64, iter 500, loss: 2.682780, top_1: 0.580977, top_k: 0.800742, samples/s: 1352.665 1612722359.45611
train: epoch 64, iter 600, loss: 2.707276, top_1: 0.586914, top_k: 0.807578, samples/s: 1325.094 1612722378.7755084
train: epoch 64, iter 700, loss: 2.779310, top_1: 0.582031, top_k: 0.806172, samples/s: 1331.130 1612722398.007287
train: epoch 64, iter 800, loss: 2.825485, top_1: 0.587187, top_k: 0.805312, samples/s: 1333.681 1612722417.2023265
train: epoch 64, iter 900, loss: 2.744408, top_1: 0.585391, top_k: 0.805742, samples/s: 1330.110 1612722436.4488354
train: epoch 64, iter 1000, loss: 2.602223, top_1: 0.585547, top_k: 0.806211, samples/s: 1333.884 1612722455.6410007
train: epoch 64, iter 1100, loss: 3.018204, top_1: 0.580430, top_k: 0.802969, samples/s: 1325.174 1612722474.959127
train: epoch 64, iter 1200, loss: 2.839543, top_1: 0.580937, top_k: 0.803398, samples/s: 1332.936 1612722494.164815
train: epoch 64, iter 1300, loss: 2.786396, top_1: 0.581016, top_k: 0.803984, samples/s: 1327.421 1612722513.4503329
train: epoch 64, iter 1400, loss: 3.010448, top_1: 0.575273, top_k: 0.800391, samples/s: 1333.901 1612722532.642175
train: epoch 64, iter 1500, loss: 2.773670, top_1: 0.574961, top_k: 0.799297, samples/s: 1326.846 1612722551.9361053
train: epoch 64, iter 1600, loss: 2.865173, top_1: 0.580508, top_k: 0.801797, samples/s: 1327.252 1612722571.2240725
train: epoch 64, iter 1700, loss: 2.522913, top_1: 0.577773, top_k: 0.801055, samples/s: 1337.133 1612722590.3694777
train: epoch 64, iter 1800, loss: 2.710665, top_1: 0.581172, top_k: 0.802383, samples/s: 1332.081 1612722609.5875638
train: epoch 64, iter 1900, loss: 2.723909, top_1: 0.577070, top_k: 0.804063, samples/s: 1326.780 1612722628.882352
train: epoch 64, iter 2000, loss: 2.718800, top_1: 0.582539, top_k: 0.804102, samples/s: 1334.338 1612722648.06792
train: epoch 64, iter 2100, loss: 2.701984, top_1: 0.582227, top_k: 0.801484, samples/s: 1332.230 1612722667.2837982
train: epoch 64, iter 2200, loss: 2.602747, top_1: 0.582852, top_k: 0.807773, samples/s: 1331.152 1612722686.515268
train: epoch 64, iter 2300, loss: 2.886438, top_1: 0.583008, top_k: 0.804414, samples/s: 1330.355 1612722705.758349
train: epoch 64, iter 2400, loss: 2.926670, top_1: 0.578594, top_k: 0.803555, samples/s: 1327.724 1612722725.0394173
train: epoch 64, iter 2500, loss: 2.793598, top_1: 0.579375, top_k: 0.800781, samples/s: 1331.001 1612722744.273001
train: epoch 64, iter 2600, loss: 2.845514, top_1: 0.579883, top_k: 0.802461, samples/s: 1334.362 1612722763.4583235
train: epoch 64, iter 2700, loss: 2.740469, top_1: 0.578711, top_k: 0.799922, samples/s: 1329.259 1612722782.7170458
train: epoch 64, iter 2800, loss: 2.824882, top_1: 0.583594, top_k: 0.803711, samples/s: 1333.721 1612722801.9115245
train: epoch 64, iter 2900, loss: 2.586955, top_1: 0.578594, top_k: 0.801797, samples/s: 1324.174 1612722821.2442713
train: epoch 64, iter 3000, loss: 2.812719, top_1: 0.575547, top_k: 0.800156, samples/s: 1333.017 1612722840.448894
train: epoch 64, iter 3100, loss: 2.928431, top_1: 0.575352, top_k: 0.802109, samples/s: 1339.895 1612722859.5548408
train: epoch 64, iter 3200, loss: 2.662816, top_1: 0.575781, top_k: 0.798047, samples/s: 1325.018 1612722878.875288
train: epoch 64, iter 3300, loss: 2.835618, top_1: 0.576055, top_k: 0.800000, samples/s: 1331.424 1612722898.1028812
train: epoch 64, iter 3400, loss: 2.911730, top_1: 0.568086, top_k: 0.796328, samples/s: 1337.422 1612722917.2441957
train: epoch 64, iter 3500, loss: 2.860106, top_1: 0.573789, top_k: 0.798320, samples/s: 1326.260 1612722936.5465088
train: epoch 64, iter 3600, loss: 2.900239, top_1: 0.578672, top_k: 0.797148, samples/s: 1335.431 1612722955.7163866
train: epoch 64, iter 3700, loss: 2.521989, top_1: 0.577656, top_k: 0.801680, samples/s: 1331.813 1612722974.9382708
train: epoch 64, iter 3800, loss: 2.677265, top_1: 0.578906, top_k: 0.800586, samples/s: 1332.244 1612722994.1540291
train: epoch 64, iter 3900, loss: 2.699716, top_1: 0.575117, top_k: 0.799102, samples/s: 1332.519 1612723013.3657053
train: epoch 64, iter 4000, loss: 2.682873, top_1: 0.578359, top_k: 0.799570, samples/s: 1331.786 1612723032.5880132
train: epoch 64, iter 4100, loss: 2.471494, top_1: 0.574961, top_k: 0.798281, samples/s: 1331.713 1612723051.8113632
train: epoch 64, iter 4200, loss: 2.722809, top_1: 0.577305, top_k: 0.799141, samples/s: 1329.788 1612723071.0625713
train: epoch 64, iter 4300, loss: 2.659980, top_1: 0.575742, top_k: 0.799258, samples/s: 1329.913 1612723090.3119907
train: epoch 64, iter 4400, loss: 2.771647, top_1: 0.580117, top_k: 0.802695, samples/s: 1334.534 1612723109.4947414
train: epoch 64, iter 4500, loss: 2.751260, top_1: 0.573359, top_k: 0.797070, samples/s: 1329.004 1612723128.7572858
train: epoch 64, iter 4600, loss: 2.924769, top_1: 0.573281, top_k: 0.798555, samples/s: 1334.306 1612723147.9433281
train: epoch 64, iter 4700, loss: 2.710078, top_1: 0.567305, top_k: 0.793555, samples/s: 1335.099 1612723167.1178231
train: epoch 64, iter 4800, loss: 2.874190, top_1: 0.574531, top_k: 0.798945, samples/s: 1330.766 1612723186.354909
train: epoch 64, iter 4900, loss: 2.628895, top_1: 0.579102, top_k: 0.799570, samples/s: 1334.320 1612723205.540655
train: epoch 64, iter 5000, loss: 2.661988, top_1: 0.577187, top_k: 0.801445, samples/s: 1330.268 1612723224.7849092
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_64.
validation: epoch 64, iter 195, top_1: 0.620893, top_k: 0.848878, samples/s: 2800.457 1612723243.2022662
train: epoch 65, iter 100, loss: 2.554163, top_1: 0.589883, top_k: 0.808867, samples/s: 1359.118 1612723277.994067
train: epoch 65, iter 200, loss: 2.741915, top_1: 0.590781, top_k: 0.804297, samples/s: 1357.226 1612723296.856045
train: epoch 65, iter 300, loss: 2.776785, top_1: 0.583398, top_k: 0.807852, samples/s: 1356.977 1612723315.721522
train: epoch 65, iter 400, loss: 2.753631, top_1: 0.583789, top_k: 0.807852, samples/s: 1345.666 1612723334.745581
train: epoch 65, iter 500, loss: 2.780096, top_1: 0.583984, top_k: 0.807734, samples/s: 1332.064 1612723353.9638152
train: epoch 65, iter 600, loss: 2.630301, top_1: 0.585000, top_k: 0.808672, samples/s: 1322.453 1612723373.3217926
train: epoch 65, iter 700, loss: 2.880973, top_1: 0.585625, top_k: 0.804531, samples/s: 1331.095 1612723392.554015
train: epoch 65, iter 800, loss: 2.705652, top_1: 0.588906, top_k: 0.806562, samples/s: 1325.466 1612723411.867985
train: epoch 65, iter 900, loss: 2.814330, top_1: 0.579375, top_k: 0.799609, samples/s: 1322.734 1612723431.2218819
train: epoch 65, iter 1000, loss: 2.552090, top_1: 0.584570, top_k: 0.805352, samples/s: 1326.421 1612723450.5219297
train: epoch 65, iter 1100, loss: 2.650126, top_1: 0.584883, top_k: 0.806445, samples/s: 1332.476 1612723469.734294
train: epoch 65, iter 1200, loss: 2.807014, top_1: 0.591445, top_k: 0.811641, samples/s: 1314.440 1612723489.2102685
train: epoch 65, iter 1300, loss: 2.784864, top_1: 0.578789, top_k: 0.800937, samples/s: 1327.495 1612723508.494708
train: epoch 65, iter 1400, loss: 2.506358, top_1: 0.584141, top_k: 0.805273, samples/s: 1327.456 1612723527.7797263
train: epoch 65, iter 1500, loss: 3.003296, top_1: 0.582734, top_k: 0.805820, samples/s: 1328.778 1612723547.0454597
train: epoch 65, iter 1600, loss: 2.669103, top_1: 0.582773, top_k: 0.798984, samples/s: 1328.261 1612723566.31879
train: epoch 65, iter 1700, loss: 2.700888, top_1: 0.575625, top_k: 0.797930, samples/s: 1328.475 1612723585.5890276
train: epoch 65, iter 1800, loss: 2.779056, top_1: 0.579805, top_k: 0.803320, samples/s: 1326.890 1612723604.8822613
train: epoch 65, iter 1900, loss: 2.738507, top_1: 0.579609, top_k: 0.803867, samples/s: 1331.522 1612723624.1084163
train: epoch 65, iter 2000, loss: 2.759113, top_1: 0.581367, top_k: 0.804102, samples/s: 1304.001 1612723643.7402523
train: epoch 65, iter 2100, loss: 2.599302, top_1: 0.580547, top_k: 0.801680, samples/s: 1350.451 1612723662.6969268
train: epoch 65, iter 2200, loss: 2.803562, top_1: 0.585195, top_k: 0.803398, samples/s: 1331.934 1612723681.9170446
train: epoch 65, iter 2300, loss: 2.600690, top_1: 0.578477, top_k: 0.800430, samples/s: 1321.899 1612723701.2831914
train: epoch 65, iter 2400, loss: 2.714417, top_1: 0.578320, top_k: 0.803477, samples/s: 1333.303 1612723720.4836214
train: epoch 65, iter 2500, loss: 2.513629, top_1: 0.578125, top_k: 0.799648, samples/s: 1329.886 1612723739.733386
train: epoch 65, iter 2600, loss: 2.656886, top_1: 0.575625, top_k: 0.800977, samples/s: 1325.436 1612723759.047712
train: epoch 65, iter 2700, loss: 2.798722, top_1: 0.579258, top_k: 0.802969, samples/s: 1333.843 1612723778.240384
train: epoch 65, iter 2800, loss: 2.896954, top_1: 0.581211, top_k: 0.801992, samples/s: 1328.984 1612723797.5032232
train: epoch 65, iter 2900, loss: 2.743044, top_1: 0.581680, top_k: 0.807031, samples/s: 1328.398 1612723816.7745836
train: epoch 65, iter 3000, loss: 2.821956, top_1: 0.580586, top_k: 0.804023, samples/s: 1330.574 1612723836.0144413
train: epoch 65, iter 3100, loss: 2.807174, top_1: 0.577148, top_k: 0.802617, samples/s: 1331.347 1612723855.2430995
train: epoch 65, iter 3200, loss: 2.776462, top_1: 0.576641, top_k: 0.798516, samples/s: 1329.030 1612723874.5052388
train: epoch 65, iter 3300, loss: 2.763652, top_1: 0.583008, top_k: 0.798359, samples/s: 1329.137 1612723893.7662325
train: epoch 65, iter 3400, loss: 2.806473, top_1: 0.578125, top_k: 0.800859, samples/s: 1329.455 1612723913.0218632
train: epoch 65, iter 3500, loss: 2.776482, top_1: 0.578281, top_k: 0.801719, samples/s: 1325.742 1612723932.3317475
train: epoch 65, iter 3600, loss: 2.877383, top_1: 0.580117, top_k: 0.803086, samples/s: 1331.046 1612723951.5647428
train: epoch 65, iter 3700, loss: 2.655003, top_1: 0.580742, top_k: 0.802813, samples/s: 1330.215 1612723970.810124
train: epoch 65, iter 3800, loss: 2.638932, top_1: 0.574023, top_k: 0.795781, samples/s: 1328.929 1612723990.0734334
train: epoch 65, iter 3900, loss: 2.900146, top_1: 0.575586, top_k: 0.801328, samples/s: 1329.860 1612724009.3235788
train: epoch 65, iter 4000, loss: 2.680954, top_1: 0.576445, top_k: 0.798867, samples/s: 1332.198 1612724028.5400794
train: epoch 65, iter 4100, loss: 2.965558, top_1: 0.573828, top_k: 0.795234, samples/s: 1321.592 1612724047.9104898
train: epoch 65, iter 4200, loss: 2.869509, top_1: 0.573398, top_k: 0.800352, samples/s: 1332.514 1612724067.122753
train: epoch 65, iter 4300, loss: 2.600179, top_1: 0.578398, top_k: 0.800547, samples/s: 1331.592 1612724086.3473818
train: epoch 65, iter 4400, loss: 2.659543, top_1: 0.579375, top_k: 0.803086, samples/s: 1331.082 1612724105.579895
train: epoch 65, iter 4500, loss: 2.789963, top_1: 0.569063, top_k: 0.798281, samples/s: 1323.053 1612724124.929059
train: epoch 65, iter 4600, loss: 2.716908, top_1: 0.576367, top_k: 0.803164, samples/s: 1332.868 1612724144.135803
train: epoch 65, iter 4700, loss: 2.801666, top_1: 0.576953, top_k: 0.803203, samples/s: 1329.336 1612724163.3934784
train: epoch 65, iter 4800, loss: 2.728985, top_1: 0.584258, top_k: 0.803633, samples/s: 1322.962 1612724182.7440443
train: epoch 65, iter 4900, loss: 2.536269, top_1: 0.579648, top_k: 0.801484, samples/s: 1332.804 1612724201.9516735
train: epoch 65, iter 5000, loss: 2.709282, top_1: 0.573320, top_k: 0.797773, samples/s: 1327.648 1612724221.2339036
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_65.
validation: epoch 65, iter 195, top_1: 0.629227, top_k: 0.853265, samples/s: 2756.188 1612724239.947851
train: epoch 66, iter 100, loss: 2.651074, top_1: 0.589023, top_k: 0.812695, samples/s: 1352.238 1612724274.408864
train: epoch 66, iter 200, loss: 2.502728, top_1: 0.592227, top_k: 0.812305, samples/s: 1364.867 1612724293.1654177
train: epoch 66, iter 300, loss: 2.633695, top_1: 0.584570, top_k: 0.807500, samples/s: 1359.375 1612724311.997455
train: epoch 66, iter 400, loss: 2.596582, top_1: 0.582422, top_k: 0.809688, samples/s: 1349.523 1612724330.9671044
train: epoch 66, iter 500, loss: 2.478746, top_1: 0.586406, top_k: 0.805937, samples/s: 1332.709 1612724350.176145
train: epoch 66, iter 600, loss: 2.850986, top_1: 0.590820, top_k: 0.807344, samples/s: 1334.998 1612724369.3521347
train: epoch 66, iter 700, loss: 2.515991, top_1: 0.589297, top_k: 0.810898, samples/s: 1330.398 1612724388.5945125
train: epoch 66, iter 800, loss: 2.687212, top_1: 0.588945, top_k: 0.806836, samples/s: 1331.153 1612724407.8259518
train: epoch 66, iter 900, loss: 2.689322, top_1: 0.586133, top_k: 0.806641, samples/s: 1336.542 1612724426.9798481
train: epoch 66, iter 1000, loss: 2.711794, top_1: 0.583008, top_k: 0.805898, samples/s: 1327.106 1612724446.2699537
train: epoch 66, iter 1100, loss: 2.611977, top_1: 0.583750, top_k: 0.802891, samples/s: 1330.507 1612724465.5107343
train: epoch 66, iter 1200, loss: 2.740987, top_1: 0.581719, top_k: 0.804648, samples/s: 1328.505 1612724484.7805674
train: epoch 66, iter 1300, loss: 2.546776, top_1: 0.587383, top_k: 0.808086, samples/s: 1334.442 1612724503.964552
train: epoch 66, iter 1400, loss: 2.577902, top_1: 0.587461, top_k: 0.807578, samples/s: 1337.215 1612724523.1088123
train: epoch 66, iter 1500, loss: 2.973596, top_1: 0.576367, top_k: 0.800859, samples/s: 1329.078 1612724542.3703241
train: epoch 66, iter 1600, loss: 2.716059, top_1: 0.587305, top_k: 0.806602, samples/s: 1324.481 1612724561.6986177
train: epoch 66, iter 1700, loss: 2.658407, top_1: 0.583320, top_k: 0.803047, samples/s: 1329.762 1612724580.9501927
train: epoch 66, iter 1800, loss: 2.696649, top_1: 0.585234, top_k: 0.806055, samples/s: 1330.114 1612724600.1967053
train: epoch 66, iter 1900, loss: 2.715898, top_1: 0.578516, top_k: 0.801680, samples/s: 1326.449 1612724619.4963973
train: epoch 66, iter 2000, loss: 2.718098, top_1: 0.581797, top_k: 0.801094, samples/s: 1339.236 1612724638.6117167
train: epoch 66, iter 2100, loss: 2.884399, top_1: 0.578672, top_k: 0.804766, samples/s: 1330.611 1612724657.850993
train: epoch 66, iter 2200, loss: 2.831031, top_1: 0.582812, top_k: 0.806016, samples/s: 1328.442 1612724677.121657
train: epoch 66, iter 2300, loss: 2.777735, top_1: 0.580508, top_k: 0.803711, samples/s: 1331.267 1612724696.351449
train: epoch 66, iter 2400, loss: 2.765162, top_1: 0.583359, top_k: 0.807109, samples/s: 1332.533 1612724715.5630155
train: epoch 66, iter 2500, loss: 2.595698, top_1: 0.580820, top_k: 0.801328, samples/s: 1333.338 1612724734.7629666
train: epoch 66, iter 2600, loss: 2.744348, top_1: 0.584023, top_k: 0.806836, samples/s: 1332.458 1612724753.975587
train: epoch 66, iter 2700, loss: 2.634161, top_1: 0.575664, top_k: 0.801016, samples/s: 1332.016 1612724773.1945114
train: epoch 66, iter 2800, loss: 2.612684, top_1: 0.581562, top_k: 0.804883, samples/s: 1326.369 1612724792.4953935
train: epoch 66, iter 2900, loss: 2.690628, top_1: 0.576758, top_k: 0.800820, samples/s: 1331.321 1612724811.7243695
train: epoch 66, iter 3000, loss: 2.624441, top_1: 0.580742, top_k: 0.807422, samples/s: 1335.356 1612724830.895256
train: epoch 66, iter 3100, loss: 2.785930, top_1: 0.581641, top_k: 0.801094, samples/s: 1328.811 1612724850.1605952
train: epoch 66, iter 3200, loss: 2.767047, top_1: 0.577539, top_k: 0.802227, samples/s: 1335.188 1612724869.33398
train: epoch 66, iter 3300, loss: 2.671210, top_1: 0.584648, top_k: 0.803750, samples/s: 1334.010 1612724888.5241933
train: epoch 66, iter 3400, loss: 2.735811, top_1: 0.579922, top_k: 0.803242, samples/s: 1338.411 1612724907.6513684
train: epoch 66, iter 3500, loss: 2.736456, top_1: 0.577578, top_k: 0.801445, samples/s: 1332.967 1612724926.8566139
train: epoch 66, iter 3600, loss: 2.735516, top_1: 0.580039, top_k: 0.801953, samples/s: 1331.400 1612724946.0845735
train: epoch 66, iter 3700, loss: 2.734373, top_1: 0.575586, top_k: 0.798906, samples/s: 1330.258 1612724965.3289437
train: epoch 66, iter 3800, loss: 2.716280, top_1: 0.580859, top_k: 0.796875, samples/s: 1331.852 1612724984.55041
train: epoch 66, iter 3900, loss: 2.827066, top_1: 0.577031, top_k: 0.800078, samples/s: 1333.396 1612725003.7493665
train: epoch 66, iter 4000, loss: 2.764653, top_1: 0.573750, top_k: 0.797500, samples/s: 1331.627 1612725022.9740186
train: epoch 66, iter 4100, loss: 2.721019, top_1: 0.577695, top_k: 0.798359, samples/s: 1331.479 1612725042.2006798
train: epoch 66, iter 4200, loss: 2.784847, top_1: 0.581328, top_k: 0.802695, samples/s: 1329.560 1612725061.4551792
train: epoch 66, iter 4300, loss: 2.919108, top_1: 0.571914, top_k: 0.799648, samples/s: 1333.608 1612725080.6512432
train: epoch 66, iter 4400, loss: 2.717257, top_1: 0.583398, top_k: 0.805820, samples/s: 1334.441 1612725099.8353508
train: epoch 66, iter 4500, loss: 2.742770, top_1: 0.577617, top_k: 0.799258, samples/s: 1332.654 1612725119.045111
train: epoch 66, iter 4600, loss: 2.706512, top_1: 0.577266, top_k: 0.801250, samples/s: 1334.458 1612725138.2289
train: epoch 66, iter 4700, loss: 2.827419, top_1: 0.575469, top_k: 0.803203, samples/s: 1334.374 1612725157.4139364
train: epoch 66, iter 4800, loss: 2.688712, top_1: 0.578047, top_k: 0.797773, samples/s: 1334.598 1612725176.5957875
train: epoch 66, iter 4900, loss: 2.940304, top_1: 0.574688, top_k: 0.799180, samples/s: 1333.988 1612725195.786318
train: epoch 66, iter 5000, loss: 2.577023, top_1: 0.582852, top_k: 0.804375, samples/s: 1333.125 1612725214.9894052
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_66.
validation: epoch 66, iter 195, top_1: 0.623237, top_k: 0.849679, samples/s: 2785.966 1612725233.5329695
train: epoch 67, iter 100, loss: 2.621439, top_1: 0.600195, top_k: 0.820898, samples/s: 1355.105 1612725268.3674774
train: epoch 67, iter 200, loss: 2.655352, top_1: 0.588242, top_k: 0.810430, samples/s: 1361.936 1612725287.1643114
train: epoch 67, iter 300, loss: 2.626765, top_1: 0.585234, top_k: 0.808828, samples/s: 1361.131 1612725305.9720101
train: epoch 67, iter 400, loss: 2.790817, top_1: 0.589180, top_k: 0.808086, samples/s: 1347.190 1612725324.974616
train: epoch 67, iter 500, loss: 2.651742, top_1: 0.588516, top_k: 0.809844, samples/s: 1330.974 1612725344.2085512
train: epoch 67, iter 600, loss: 2.850054, top_1: 0.583672, top_k: 0.804883, samples/s: 1328.753 1612725363.4747415
train: epoch 67, iter 700, loss: 2.624465, top_1: 0.590508, top_k: 0.809141, samples/s: 1330.953 1612725382.709127
train: epoch 67, iter 800, loss: 2.463831, top_1: 0.588555, top_k: 0.806719, samples/s: 1326.405 1612725402.009362
train: epoch 67, iter 900, loss: 2.559450, top_1: 0.584961, top_k: 0.807422, samples/s: 1336.235 1612725421.1676884
train: epoch 67, iter 1000, loss: 2.608559, top_1: 0.586250, top_k: 0.810078, samples/s: 1330.709 1612725440.4055257
train: epoch 67, iter 1100, loss: 2.605896, top_1: 0.582461, top_k: 0.809844, samples/s: 1335.933 1612725459.568165
train: epoch 67, iter 1200, loss: 2.755161, top_1: 0.586250, top_k: 0.805937, samples/s: 1323.344 1612725478.9131005
train: epoch 67, iter 1300, loss: 2.687098, top_1: 0.591406, top_k: 0.804375, samples/s: 1329.659 1612725498.1662393
train: epoch 67, iter 1400, loss: 2.722111, top_1: 0.583125, top_k: 0.804180, samples/s: 1334.079 1612725517.3554854
train: epoch 67, iter 1500, loss: 2.716980, top_1: 0.587773, top_k: 0.808594, samples/s: 1334.209 1612725536.5428576
train: epoch 67, iter 1600, loss: 2.646205, top_1: 0.578555, top_k: 0.802617, samples/s: 1325.621 1612725555.8544989
train: epoch 67, iter 1700, loss: 2.732171, top_1: 0.583828, top_k: 0.810039, samples/s: 1330.144 1612725575.1006186
train: epoch 67, iter 1800, loss: 2.754485, top_1: 0.580977, top_k: 0.802305, samples/s: 1331.831 1612725594.3222287
train: epoch 67, iter 1900, loss: 2.701115, top_1: 0.590391, top_k: 0.808125, samples/s: 1337.954 1612725613.4559412
train: epoch 67, iter 2000, loss: 2.671323, top_1: 0.589180, top_k: 0.806797, samples/s: 1324.822 1612725632.7793775
train: epoch 67, iter 2100, loss: 2.779751, top_1: 0.583359, top_k: 0.807031, samples/s: 1331.927 1612725651.9995265
train: epoch 67, iter 2200, loss: 2.650004, top_1: 0.583164, top_k: 0.800312, samples/s: 1330.572 1612725671.2394161
train: epoch 67, iter 2300, loss: 2.698513, top_1: 0.584063, top_k: 0.804844, samples/s: 1333.446 1612725690.4377625
train: epoch 67, iter 2400, loss: 2.720286, top_1: 0.579648, top_k: 0.806094, samples/s: 1330.937 1612725709.6723278
train: epoch 67, iter 2500, loss: 2.633491, top_1: 0.586250, top_k: 0.805547, samples/s: 1334.555 1612725728.8547564
train: epoch 67, iter 2600, loss: 3.011576, top_1: 0.585352, top_k: 0.804961, samples/s: 1332.255 1612725748.0703444
train: epoch 67, iter 2700, loss: 2.699411, top_1: 0.582266, top_k: 0.803516, samples/s: 1332.693 1612725767.2795856
train: epoch 67, iter 2800, loss: 2.753525, top_1: 0.579805, top_k: 0.800000, samples/s: 1335.537 1612725786.4478436
train: epoch 67, iter 2900, loss: 2.677264, top_1: 0.577852, top_k: 0.803320, samples/s: 1327.391 1612725805.733955
train: epoch 67, iter 3000, loss: 2.680677, top_1: 0.583789, top_k: 0.808281, samples/s: 1335.488 1612725824.9028137
train: epoch 67, iter 3100, loss: 2.662159, top_1: 0.581875, top_k: 0.803945, samples/s: 1331.656 1612725844.1270545
train: epoch 67, iter 3200, loss: 2.611255, top_1: 0.582031, top_k: 0.804492, samples/s: 1337.067 1612725863.2733843
train: epoch 67, iter 3300, loss: 2.741754, top_1: 0.582930, top_k: 0.803281, samples/s: 1327.787 1612725882.5536191
train: epoch 67, iter 3400, loss: 2.774247, top_1: 0.580977, top_k: 0.803047, samples/s: 1333.502 1612725901.7511396
train: epoch 67, iter 3500, loss: 2.738936, top_1: 0.582500, top_k: 0.801602, samples/s: 1331.882 1612725920.9720595
train: epoch 67, iter 3600, loss: 2.968213, top_1: 0.579336, top_k: 0.804961, samples/s: 1332.652 1612725940.1819234
train: epoch 67, iter 3700, loss: 2.739890, top_1: 0.578828, top_k: 0.800195, samples/s: 1334.885 1612725959.3595605
train: epoch 67, iter 3800, loss: 2.961328, top_1: 0.579180, top_k: 0.798789, samples/s: 1335.202 1612725978.5326834
train: epoch 67, iter 3900, loss: 2.664619, top_1: 0.577539, top_k: 0.803711, samples/s: 1333.392 1612725997.7319045
train: epoch 67, iter 4000, loss: 2.819437, top_1: 0.576992, top_k: 0.800859, samples/s: 1335.853 1612726016.895724
train: epoch 67, iter 4100, loss: 2.856534, top_1: 0.575117, top_k: 0.799609, samples/s: 1329.403 1612726036.1524744
train: epoch 67, iter 4200, loss: 2.810688, top_1: 0.585625, top_k: 0.807070, samples/s: 1328.330 1612726055.4247391
train: epoch 67, iter 4300, loss: 2.672509, top_1: 0.581172, top_k: 0.800078, samples/s: 1333.131 1612726074.627692
train: epoch 67, iter 4400, loss: 2.761483, top_1: 0.580078, top_k: 0.801367, samples/s: 1333.922 1612726093.8191562
train: epoch 67, iter 4500, loss: 2.769666, top_1: 0.581406, top_k: 0.803594, samples/s: 1337.276 1612726112.9625473
train: epoch 67, iter 4600, loss: 2.692119, top_1: 0.581250, top_k: 0.802422, samples/s: 1323.141 1612726132.3104937
train: epoch 67, iter 4700, loss: 2.614190, top_1: 0.581016, top_k: 0.802148, samples/s: 1329.968 1612726151.5590243
train: epoch 67, iter 4800, loss: 2.733579, top_1: 0.578125, top_k: 0.801055, samples/s: 1337.106 1612726170.7049046
train: epoch 67, iter 4900, loss: 2.611233, top_1: 0.578125, top_k: 0.802266, samples/s: 1330.571 1612726189.9447324
train: epoch 67, iter 5000, loss: 2.591423, top_1: 0.585352, top_k: 0.805508, samples/s: 1329.580 1612726209.199004
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_67.
validation: epoch 67, iter 195, top_1: 0.624018, top_k: 0.850240, samples/s: 2831.827 1612726227.4352148
train: epoch 68, iter 100, loss: 2.952542, top_1: 0.587109, top_k: 0.809492, samples/s: 1355.435 1612726262.4059453
train: epoch 68, iter 200, loss: 2.741773, top_1: 0.589023, top_k: 0.808477, samples/s: 1358.589 1612726281.2491539
train: epoch 68, iter 300, loss: 2.572093, top_1: 0.592109, top_k: 0.813789, samples/s: 1362.465 1612726300.038509
train: epoch 68, iter 400, loss: 2.705601, top_1: 0.585625, top_k: 0.809297, samples/s: 1351.296 1612726318.9833019
train: epoch 68, iter 500, loss: 2.762907, top_1: 0.595234, top_k: 0.810195, samples/s: 1326.227 1612726338.2861145
train: epoch 68, iter 600, loss: 2.815606, top_1: 0.587305, top_k: 0.807500, samples/s: 1330.278 1612726357.5302866
train: epoch 68, iter 700, loss: 2.668109, top_1: 0.592891, top_k: 0.815859, samples/s: 1318.488 1612726376.9464602
train: epoch 68, iter 800, loss: 2.678065, top_1: 0.593867, top_k: 0.807148, samples/s: 1336.384 1612726396.102644
train: epoch 68, iter 900, loss: 2.784492, top_1: 0.585195, top_k: 0.809570, samples/s: 1324.427 1612726415.4317496
train: epoch 68, iter 1000, loss: 2.583109, top_1: 0.583125, top_k: 0.805430, samples/s: 1337.691 1612726434.5692408
train: epoch 68, iter 1100, loss: 2.584062, top_1: 0.586211, top_k: 0.808789, samples/s: 1322.102 1612726453.9323683
train: epoch 68, iter 1200, loss: 2.876973, top_1: 0.587422, top_k: 0.808203, samples/s: 1339.815 1612726473.0393648
train: epoch 68, iter 1300, loss: 2.647789, top_1: 0.582422, top_k: 0.806641, samples/s: 1331.031 1612726492.2725718
train: epoch 68, iter 1400, loss: 2.616336, top_1: 0.584297, top_k: 0.808906, samples/s: 1323.266 1612726511.618638
train: epoch 68, iter 1500, loss: 2.964058, top_1: 0.589961, top_k: 0.809805, samples/s: 1335.952 1612726530.781058
train: epoch 68, iter 1600, loss: 2.707409, top_1: 0.586328, top_k: 0.804609, samples/s: 1329.617 1612726550.0347183
train: epoch 68, iter 1700, loss: 2.481711, top_1: 0.585859, top_k: 0.808711, samples/s: 1331.031 1612726569.2678812
train: epoch 68, iter 1800, loss: 2.704188, top_1: 0.585234, top_k: 0.804961, samples/s: 1327.853 1612726588.5472007
train: epoch 68, iter 1900, loss: 2.637098, top_1: 0.581914, top_k: 0.805273, samples/s: 1332.652 1612726607.7569478
train: epoch 68, iter 2000, loss: 2.839741, top_1: 0.589219, top_k: 0.805547, samples/s: 1324.530 1612726627.0845714
train: epoch 68, iter 2100, loss: 2.706459, top_1: 0.583125, top_k: 0.805391, samples/s: 1337.583 1612726646.2235527
train: epoch 68, iter 2200, loss: 2.768096, top_1: 0.586641, top_k: 0.804258, samples/s: 1333.196 1612726665.4255824
train: epoch 68, iter 2300, loss: 2.696375, top_1: 0.587109, top_k: 0.806836, samples/s: 1330.031 1612726684.6732972
train: epoch 68, iter 2400, loss: 2.797617, top_1: 0.583438, top_k: 0.803516, samples/s: 1328.926 1612726703.936898
train: epoch 68, iter 2500, loss: 2.789667, top_1: 0.582539, top_k: 0.807031, samples/s: 1328.670 1612726723.20428
train: epoch 68, iter 2600, loss: 2.790330, top_1: 0.585195, top_k: 0.805469, samples/s: 1330.930 1612726742.4389849
train: epoch 68, iter 2700, loss: 2.569037, top_1: 0.579766, top_k: 0.798906, samples/s: 1334.529 1612726761.6217735
train: epoch 68, iter 2800, loss: 2.638870, top_1: 0.586875, top_k: 0.808711, samples/s: 1331.002 1612726780.8553808
train: epoch 68, iter 2900, loss: 2.764330, top_1: 0.582891, top_k: 0.803633, samples/s: 1335.507 1612726800.0241823
train: epoch 68, iter 3000, loss: 2.865148, top_1: 0.581406, top_k: 0.802188, samples/s: 1324.758 1612726819.3484454
train: epoch 68, iter 3100, loss: 2.711719, top_1: 0.582969, top_k: 0.804805, samples/s: 1330.414 1612726838.5905771
train: epoch 68, iter 3200, loss: 2.617610, top_1: 0.583281, top_k: 0.809023, samples/s: 1338.375 1612726857.7182546
train: epoch 68, iter 3300, loss: 2.578141, top_1: 0.580898, top_k: 0.805312, samples/s: 1332.427 1612726876.9312973
train: epoch 68, iter 3400, loss: 2.594873, top_1: 0.579180, top_k: 0.803516, samples/s: 1333.304 1612726896.1317563
train: epoch 68, iter 3500, loss: 2.573041, top_1: 0.584180, top_k: 0.806562, samples/s: 1332.483 1612726915.3440177
train: epoch 68, iter 3600, loss: 2.751292, top_1: 0.582891, top_k: 0.804141, samples/s: 1324.833 1612726934.6671367
train: epoch 68, iter 3700, loss: 2.854439, top_1: 0.585703, top_k: 0.802617, samples/s: 1327.761 1612726953.947747
train: epoch 68, iter 3800, loss: 2.935243, top_1: 0.583359, top_k: 0.802188, samples/s: 1332.333 1612726973.1621726
train: epoch 68, iter 3900, loss: 2.678762, top_1: 0.581719, top_k: 0.805977, samples/s: 1333.109 1612726992.3653588
train: epoch 68, iter 4000, loss: 2.747522, top_1: 0.580898, top_k: 0.804023, samples/s: 1332.323 1612727011.579955
train: epoch 68, iter 4100, loss: 2.777027, top_1: 0.582187, top_k: 0.800391, samples/s: 1325.218 1612727030.8975594
train: epoch 68, iter 4200, loss: 2.597519, top_1: 0.580117, top_k: 0.804219, samples/s: 1334.941 1612727050.0744452
train: epoch 68, iter 4300, loss: 2.572156, top_1: 0.584531, top_k: 0.803320, samples/s: 1334.292 1612727069.2606714
train: epoch 68, iter 4400, loss: 2.815041, top_1: 0.579883, top_k: 0.801992, samples/s: 1333.659 1612727088.4559195
train: epoch 68, iter 4500, loss: 2.795400, top_1: 0.583438, top_k: 0.804102, samples/s: 1331.090 1612727107.6884096
train: epoch 68, iter 4600, loss: 2.837833, top_1: 0.582461, top_k: 0.804531, samples/s: 1336.712 1612727126.8397717
train: epoch 68, iter 4700, loss: 2.627526, top_1: 0.584805, top_k: 0.803047, samples/s: 1329.753 1612727146.091438
train: epoch 68, iter 4800, loss: 2.575500, top_1: 0.579805, top_k: 0.801758, samples/s: 1335.519 1612727165.2599823
train: epoch 68, iter 4900, loss: 2.554205, top_1: 0.578594, top_k: 0.800664, samples/s: 1324.741 1612727184.5846202
train: epoch 68, iter 5000, loss: 2.759556, top_1: 0.580586, top_k: 0.805586, samples/s: 1325.009 1612727203.9051602
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_68.
validation: epoch 68, iter 195, top_1: 0.634515, top_k: 0.854407, samples/s: 2777.612 1612727222.3753252
train: epoch 69, iter 100, loss: 2.717234, top_1: 0.596758, top_k: 0.817187, samples/s: 1362.570 1612727256.998197
train: epoch 69, iter 200, loss: 2.553925, top_1: 0.604844, top_k: 0.821797, samples/s: 1361.351 1612727275.803163
train: epoch 69, iter 300, loss: 2.601684, top_1: 0.592969, top_k: 0.812070, samples/s: 1352.317 1612727294.73346
train: epoch 69, iter 400, loss: 2.697592, top_1: 0.595352, top_k: 0.812500, samples/s: 1353.660 1612727313.645113
train: epoch 69, iter 500, loss: 2.477978, top_1: 0.587852, top_k: 0.811406, samples/s: 1327.233 1612727332.9334223
train: epoch 69, iter 600, loss: 2.638310, top_1: 0.590469, top_k: 0.810273, samples/s: 1322.896 1612727352.2848783
train: epoch 69, iter 700, loss: 2.517101, top_1: 0.585625, top_k: 0.808945, samples/s: 1326.428 1612727371.5848374
train: epoch 69, iter 800, loss: 2.643555, top_1: 0.591094, top_k: 0.813320, samples/s: 1327.234 1612727390.8730426
train: epoch 69, iter 900, loss: 2.924431, top_1: 0.586602, top_k: 0.807305, samples/s: 1323.965 1612727410.2089152
train: epoch 69, iter 1000, loss: 2.791686, top_1: 0.590156, top_k: 0.809609, samples/s: 1316.173 1612727429.659199
train: epoch 69, iter 1100, loss: 2.776269, top_1: 0.582070, top_k: 0.806719, samples/s: 1334.207 1612727448.846619
train: epoch 69, iter 1200, loss: 2.783593, top_1: 0.586172, top_k: 0.808359, samples/s: 1327.886 1612727468.1253963
train: epoch 69, iter 1300, loss: 2.504649, top_1: 0.591875, top_k: 0.811602, samples/s: 1324.893 1612727487.4477
train: epoch 69, iter 1400, loss: 2.592451, top_1: 0.586523, top_k: 0.808242, samples/s: 1327.636 1612727506.730083
train: epoch 69, iter 1500, loss: 2.638268, top_1: 0.590703, top_k: 0.812070, samples/s: 1325.154 1612727526.0485852
train: epoch 69, iter 1600, loss: 2.546673, top_1: 0.584141, top_k: 0.807930, samples/s: 1325.660 1612727545.3597958
train: epoch 69, iter 1700, loss: 2.607895, top_1: 0.593477, top_k: 0.811562, samples/s: 1325.612 1612727564.6717038
train: epoch 69, iter 1800, loss: 3.008735, top_1: 0.583828, top_k: 0.805312, samples/s: 1324.345 1612727584.0019608
train: epoch 69, iter 1900, loss: 2.721437, top_1: 0.582695, top_k: 0.805547, samples/s: 1326.649 1612727603.2986205
train: epoch 69, iter 2000, loss: 2.549361, top_1: 0.585625, top_k: 0.808438, samples/s: 1325.539 1612727622.6115324
train: epoch 69, iter 2100, loss: 2.621269, top_1: 0.583398, top_k: 0.808086, samples/s: 1329.176 1612727641.8715742
train: epoch 69, iter 2200, loss: 2.701650, top_1: 0.580977, top_k: 0.803594, samples/s: 1324.707 1612727661.196688
train: epoch 69, iter 2300, loss: 2.680029, top_1: 0.583281, top_k: 0.802617, samples/s: 1327.210 1612727680.4851837
train: epoch 69, iter 2400, loss: 2.658390, top_1: 0.580156, top_k: 0.805781, samples/s: 1323.142 1612727699.8330727
train: epoch 69, iter 2500, loss: 2.798892, top_1: 0.589961, top_k: 0.809922, samples/s: 1327.776 1612727719.1134202
train: epoch 69, iter 2600, loss: 2.708543, top_1: 0.592031, top_k: 0.811445, samples/s: 1328.748 1612727738.379706
train: epoch 69, iter 2700, loss: 2.652358, top_1: 0.591016, top_k: 0.806367, samples/s: 1325.307 1612727757.6960118
train: epoch 69, iter 2800, loss: 2.907932, top_1: 0.584961, top_k: 0.805469, samples/s: 1326.513 1612727776.9947462
train: epoch 69, iter 2900, loss: 2.663053, top_1: 0.579688, top_k: 0.805078, samples/s: 1327.939 1612727796.272736
train: epoch 69, iter 3000, loss: 2.708745, top_1: 0.580117, top_k: 0.801367, samples/s: 1325.503 1612727815.586101
train: epoch 69, iter 3100, loss: 2.968296, top_1: 0.583477, top_k: 0.802891, samples/s: 1325.810 1612727834.8950467
train: epoch 69, iter 3200, loss: 2.770988, top_1: 0.584922, top_k: 0.807148, samples/s: 1327.498 1612727854.1795208
train: epoch 69, iter 3300, loss: 2.938189, top_1: 0.577187, top_k: 0.800391, samples/s: 1328.336 1612727873.4517703
train: epoch 69, iter 3400, loss: 2.770764, top_1: 0.583633, top_k: 0.805430, samples/s: 1323.222 1612727892.7983847
train: epoch 69, iter 3500, loss: 2.699278, top_1: 0.585977, top_k: 0.807461, samples/s: 1330.824 1612727912.034656
train: epoch 69, iter 3600, loss: 2.784345, top_1: 0.583867, top_k: 0.804609, samples/s: 1323.545 1612727931.3766077
train: epoch 69, iter 3700, loss: 2.560239, top_1: 0.584023, top_k: 0.804961, samples/s: 1328.535 1612727950.6460955
train: epoch 69, iter 3800, loss: 2.544150, top_1: 0.587891, top_k: 0.805000, samples/s: 1324.490 1612727969.9741879
train: epoch 69, iter 3900, loss: 2.771391, top_1: 0.586602, top_k: 0.807070, samples/s: 1330.853 1612727989.2099369
train: epoch 69, iter 4000, loss: 2.999110, top_1: 0.584844, top_k: 0.802578, samples/s: 1326.622 1612728008.5070577
train: epoch 69, iter 4100, loss: 2.780308, top_1: 0.587734, top_k: 0.808750, samples/s: 1325.087 1612728027.826605
train: epoch 69, iter 4200, loss: 2.694613, top_1: 0.582734, top_k: 0.806797, samples/s: 1329.041 1612728047.0885506
train: epoch 69, iter 4300, loss: 2.627792, top_1: 0.583867, top_k: 0.807031, samples/s: 1323.147 1612728066.4364305
train: epoch 69, iter 4400, loss: 2.605163, top_1: 0.579258, top_k: 0.802305, samples/s: 1324.898 1612728085.758614
train: epoch 69, iter 4500, loss: 2.813667, top_1: 0.582539, top_k: 0.804883, samples/s: 1333.934 1612728104.9500833
train: epoch 69, iter 4600, loss: 2.625113, top_1: 0.582656, top_k: 0.804297, samples/s: 1328.368 1612728124.2217839
train: epoch 69, iter 4700, loss: 2.739982, top_1: 0.585547, top_k: 0.806016, samples/s: 1325.950 1612728143.5286741
train: epoch 69, iter 4800, loss: 2.731005, top_1: 0.578633, top_k: 0.801367, samples/s: 1325.155 1612728162.847203
train: epoch 69, iter 4900, loss: 2.504329, top_1: 0.582734, top_k: 0.802813, samples/s: 1324.006 1612728182.1823974
train: epoch 69, iter 5000, loss: 2.657819, top_1: 0.581719, top_k: 0.808711, samples/s: 1328.079 1612728201.4584308
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_69.
validation: epoch 69, iter 195, top_1: 0.622236, top_k: 0.850681, samples/s: 2796.238 1612728219.8876543
train: epoch 70, iter 100, loss: 2.806965, top_1: 0.597852, top_k: 0.819336, samples/s: 1361.201 1612728254.497824
train: epoch 70, iter 200, loss: 2.560187, top_1: 0.597266, top_k: 0.814336, samples/s: 1362.062 1612728273.292983
train: epoch 70, iter 300, loss: 2.701320, top_1: 0.596719, top_k: 0.816641, samples/s: 1360.248 1612728292.1128795
train: epoch 70, iter 400, loss: 2.545131, top_1: 0.596992, top_k: 0.813125, samples/s: 1341.523 1612728311.1956956
train: epoch 70, iter 500, loss: 2.607213, top_1: 0.586211, top_k: 0.811836, samples/s: 1331.902 1612728330.4163575
train: epoch 70, iter 600, loss: 2.597103, top_1: 0.596992, top_k: 0.814453, samples/s: 1326.191 1612728349.7197747
train: epoch 70, iter 700, loss: 2.755819, top_1: 0.591406, top_k: 0.811328, samples/s: 1333.423 1612728368.918472
train: epoch 70, iter 800, loss: 2.615055, top_1: 0.591328, top_k: 0.807422, samples/s: 1320.346 1612728388.3072717
train: epoch 70, iter 900, loss: 2.688934, top_1: 0.590977, top_k: 0.810469, samples/s: 1330.458 1612728407.548841
train: epoch 70, iter 1000, loss: 2.850993, top_1: 0.592109, top_k: 0.810859, samples/s: 1334.933 1612728426.725789
train: epoch 70, iter 1100, loss: 2.827734, top_1: 0.587617, top_k: 0.809648, samples/s: 1328.117 1612728446.0012398
train: epoch 70, iter 1200, loss: 2.700981, top_1: 0.593359, top_k: 0.811367, samples/s: 1326.204 1612728465.3044593
train: epoch 70, iter 1300, loss: 2.750814, top_1: 0.593125, top_k: 0.813789, samples/s: 1325.702 1612728484.6149092
train: epoch 70, iter 1400, loss: 2.571528, top_1: 0.587383, top_k: 0.808516, samples/s: 1336.399 1612728503.7708662
train: epoch 70, iter 1500, loss: 2.569963, top_1: 0.586680, top_k: 0.808516, samples/s: 1331.288 1612728523.000404
train: epoch 70, iter 1600, loss: 2.621779, top_1: 0.589531, top_k: 0.809531, samples/s: 1332.461 1612728542.2129192
train: epoch 70, iter 1700, loss: 2.702556, top_1: 0.590352, top_k: 0.810000, samples/s: 1329.826 1612728561.463621
train: epoch 70, iter 1800, loss: 2.654975, top_1: 0.589727, top_k: 0.806484, samples/s: 1330.819 1612728580.6998456
train: epoch 70, iter 1900, loss: 2.922458, top_1: 0.583555, top_k: 0.802813, samples/s: 1328.531 1612728599.9692948
train: epoch 70, iter 2000, loss: 2.687633, top_1: 0.586758, top_k: 0.807422, samples/s: 1331.463 1612728619.196328
train: epoch 70, iter 2100, loss: 2.485990, top_1: 0.587227, top_k: 0.807148, samples/s: 1330.145 1612728638.4422777
train: epoch 70, iter 2200, loss: 2.602638, top_1: 0.587187, top_k: 0.805820, samples/s: 1331.064 1612728657.6750262
train: epoch 70, iter 2300, loss: 2.547368, top_1: 0.590547, top_k: 0.806641, samples/s: 1329.340 1612728676.9326694
train: epoch 70, iter 2400, loss: 2.873156, top_1: 0.588750, top_k: 0.808438, samples/s: 1324.281 1612728696.2639496
train: epoch 70, iter 2500, loss: 2.637663, top_1: 0.587031, top_k: 0.805586, samples/s: 1335.344 1612728715.4350204
train: epoch 70, iter 2600, loss: 2.699627, top_1: 0.592461, top_k: 0.813555, samples/s: 1331.727 1612728734.6581938
train: epoch 70, iter 2700, loss: 2.656015, top_1: 0.587383, top_k: 0.808516, samples/s: 1326.100 1612728753.9642973
train: epoch 70, iter 2800, loss: 2.804692, top_1: 0.588555, top_k: 0.809648, samples/s: 1332.219 1612728773.1790595
train: epoch 70, iter 2900, loss: 2.547009, top_1: 0.584961, top_k: 0.808047, samples/s: 1327.828 1612728792.4585462
train: epoch 70, iter 3000, loss: 2.529791, top_1: 0.580781, top_k: 0.805117, samples/s: 1329.244 1612728811.7176733
train: epoch 70, iter 3100, loss: 2.694911, top_1: 0.581602, top_k: 0.804883, samples/s: 1328.227 1612728830.9914649
train: epoch 70, iter 3200, loss: 2.681164, top_1: 0.582695, top_k: 0.806680, samples/s: 1328.447 1612728850.2620432
train: epoch 70, iter 3300, loss: 2.601633, top_1: 0.587617, top_k: 0.806523, samples/s: 1318.174 1612728869.682869
train: epoch 70, iter 3400, loss: 2.736704, top_1: 0.586094, top_k: 0.809336, samples/s: 1345.236 1612728888.7129836
train: epoch 70, iter 3500, loss: 2.672783, top_1: 0.583320, top_k: 0.806758, samples/s: 1328.843 1612728907.977837
train: epoch 70, iter 3600, loss: 2.771707, top_1: 0.586211, top_k: 0.809805, samples/s: 1328.373 1612728927.2495673
train: epoch 70, iter 3700, loss: 2.649219, top_1: 0.582656, top_k: 0.805820, samples/s: 1328.692 1612728946.5166106
train: epoch 70, iter 3800, loss: 2.623559, top_1: 0.582891, top_k: 0.806172, samples/s: 1329.625 1612728965.770173
train: epoch 70, iter 3900, loss: 2.760734, top_1: 0.584531, top_k: 0.807031, samples/s: 1332.744 1612728984.9787395
train: epoch 70, iter 4000, loss: 2.647099, top_1: 0.588984, top_k: 0.805937, samples/s: 1335.746 1612729004.1440258
train: epoch 70, iter 4100, loss: 2.535052, top_1: 0.583438, top_k: 0.805508, samples/s: 1335.443 1612729023.3136609
train: epoch 70, iter 4200, loss: 2.729292, top_1: 0.585195, top_k: 0.808008, samples/s: 1327.367 1612729042.5999615
train: epoch 70, iter 4300, loss: 2.726320, top_1: 0.584648, top_k: 0.807656, samples/s: 1333.658 1612729061.7952888
train: epoch 70, iter 4400, loss: 2.886606, top_1: 0.574805, top_k: 0.801172, samples/s: 1334.278 1612729080.9816833
train: epoch 70, iter 4500, loss: 2.798670, top_1: 0.576836, top_k: 0.805508, samples/s: 1327.604 1612729100.2645428
train: epoch 70, iter 4600, loss: 2.649345, top_1: 0.586133, top_k: 0.808906, samples/s: 1331.354 1612729119.493102
train: epoch 70, iter 4700, loss: 2.764102, top_1: 0.583320, top_k: 0.805820, samples/s: 1329.145 1612729138.7535837
train: epoch 70, iter 4800, loss: 2.826898, top_1: 0.589492, top_k: 0.809258, samples/s: 1330.881 1612729157.9889514
train: epoch 70, iter 4900, loss: 2.797463, top_1: 0.584805, top_k: 0.802500, samples/s: 1329.880 1612729177.2388704
train: epoch 70, iter 5000, loss: 2.628007, top_1: 0.589688, top_k: 0.808984, samples/s: 1327.792 1612729196.5189328
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_70.
validation: epoch 70, iter 195, top_1: 0.630369, top_k: 0.854006, samples/s: 2749.700 1612729215.2276864
train: epoch 71, iter 100, loss: 2.948412, top_1: 0.600234, top_k: 0.816016, samples/s: 1361.063 1612729249.902811
train: epoch 71, iter 200, loss: 2.637322, top_1: 0.591172, top_k: 0.808320, samples/s: 1360.269 1612729268.7227352
train: epoch 71, iter 300, loss: 2.569675, top_1: 0.596211, top_k: 0.814258, samples/s: 1359.139 1612729287.5580435
train: epoch 71, iter 400, loss: 2.676544, top_1: 0.596172, top_k: 0.813398, samples/s: 1349.614 1612729306.5264385
train: epoch 71, iter 500, loss: 2.572486, top_1: 0.595430, top_k: 0.813125, samples/s: 1323.510 1612729325.8689518
train: epoch 71, iter 600, loss: 2.696167, top_1: 0.596406, top_k: 0.817109, samples/s: 1331.285 1612729345.0984838
train: epoch 71, iter 700, loss: 2.555323, top_1: 0.595078, top_k: 0.816797, samples/s: 1330.521 1612729364.3390222
train: epoch 71, iter 800, loss: 2.682725, top_1: 0.588906, top_k: 0.810156, samples/s: 1330.364 1612729383.5819242
train: epoch 71, iter 900, loss: 2.627711, top_1: 0.594375, top_k: 0.815586, samples/s: 1334.200 1612729402.7694044
train: epoch 71, iter 1000, loss: 2.803900, top_1: 0.586992, top_k: 0.809648, samples/s: 1320.776 1612729422.151996
train: epoch 71, iter 1100, loss: 2.591911, top_1: 0.590898, top_k: 0.811953, samples/s: 1333.637 1612729441.3476374
train: epoch 71, iter 1200, loss: 2.570339, top_1: 0.597773, top_k: 0.816758, samples/s: 1323.031 1612729460.6970992
train: epoch 71, iter 1300, loss: 2.684429, top_1: 0.594297, top_k: 0.811641, samples/s: 1330.002 1612729479.9451783
train: epoch 71, iter 1400, loss: 2.705661, top_1: 0.591641, top_k: 0.813086, samples/s: 1322.320 1612729499.3052044
train: epoch 71, iter 1500, loss: 2.651326, top_1: 0.587305, top_k: 0.807070, samples/s: 1330.939 1612729518.5396187
train: epoch 71, iter 1600, loss: 2.727048, top_1: 0.586992, top_k: 0.806055, samples/s: 1318.281 1612729537.9589274
train: epoch 71, iter 1700, loss: 2.668064, top_1: 0.591484, top_k: 0.809609, samples/s: 1337.985 1612729557.092162
train: epoch 71, iter 1800, loss: 2.544738, top_1: 0.588477, top_k: 0.810547, samples/s: 1333.547 1612729576.2890365
train: epoch 71, iter 1900, loss: 2.578653, top_1: 0.593516, top_k: 0.811055, samples/s: 1326.454 1612729595.5887048
train: epoch 71, iter 2000, loss: 2.711972, top_1: 0.588086, top_k: 0.810820, samples/s: 1325.577 1612729614.900958
train: epoch 71, iter 2100, loss: 2.772442, top_1: 0.588125, top_k: 0.809102, samples/s: 1333.770 1612729634.0946636
train: epoch 71, iter 2200, loss: 2.748836, top_1: 0.586445, top_k: 0.808203, samples/s: 1327.700 1612729653.3761313
train: epoch 71, iter 2300, loss: 2.864636, top_1: 0.590313, top_k: 0.810156, samples/s: 1331.594 1612729672.601312
train: epoch 71, iter 2400, loss: 2.901289, top_1: 0.590820, top_k: 0.808164, samples/s: 1326.416 1612729691.901384
train: epoch 71, iter 2500, loss: 2.738949, top_1: 0.585977, top_k: 0.807813, samples/s: 1330.384 1612729711.1439233
train: epoch 71, iter 2600, loss: 2.709546, top_1: 0.589023, top_k: 0.807383, samples/s: 1332.102 1612729730.3616598
train: epoch 71, iter 2700, loss: 2.800849, top_1: 0.585547, top_k: 0.803789, samples/s: 1331.809 1612729749.5836356
train: epoch 71, iter 2800, loss: 2.711253, top_1: 0.584844, top_k: 0.807617, samples/s: 1328.599 1612729768.8520916
train: epoch 71, iter 2900, loss: 2.907185, top_1: 0.589844, top_k: 0.809063, samples/s: 1332.401 1612729788.0655408
train: epoch 71, iter 3000, loss: 2.684646, top_1: 0.591211, top_k: 0.808047, samples/s: 1327.621 1612729807.3481514
train: epoch 71, iter 3100, loss: 2.654605, top_1: 0.586367, top_k: 0.804922, samples/s: 1329.900 1612729826.5976715
train: epoch 71, iter 3200, loss: 2.750054, top_1: 0.580156, top_k: 0.805664, samples/s: 1334.694 1612729845.778102
train: epoch 71, iter 3300, loss: 2.760216, top_1: 0.591055, top_k: 0.811836, samples/s: 1328.499 1612729865.048033
train: epoch 71, iter 3400, loss: 2.773474, top_1: 0.581172, top_k: 0.804063, samples/s: 1333.911 1612729884.2396426
train: epoch 71, iter 3500, loss: 2.622472, top_1: 0.586758, top_k: 0.808281, samples/s: 1326.972 1612729903.5316737
train: epoch 71, iter 3600, loss: 2.628584, top_1: 0.586914, top_k: 0.808242, samples/s: 1331.396 1612729922.7596757
train: epoch 71, iter 3700, loss: 2.731969, top_1: 0.579023, top_k: 0.804336, samples/s: 1332.206 1612729941.9759064
train: epoch 71, iter 3800, loss: 2.647353, top_1: 0.587148, top_k: 0.810000, samples/s: 1325.163 1612729961.2942612
train: epoch 71, iter 3900, loss: 2.838244, top_1: 0.583203, top_k: 0.805352, samples/s: 1334.515 1612729980.4773312
train: epoch 71, iter 4000, loss: 2.710851, top_1: 0.587187, top_k: 0.808594, samples/s: 1329.082 1612729999.738786
train: epoch 71, iter 4100, loss: 2.635243, top_1: 0.583125, top_k: 0.808555, samples/s: 1323.936 1612730019.0749502
train: epoch 71, iter 4200, loss: 2.654717, top_1: 0.589063, top_k: 0.810430, samples/s: 1328.975 1612730038.337968
train: epoch 71, iter 4300, loss: 2.688733, top_1: 0.589180, top_k: 0.808984, samples/s: 1334.054 1612730057.527569
train: epoch 71, iter 4400, loss: 2.888609, top_1: 0.582891, top_k: 0.802734, samples/s: 1322.287 1612730076.8879614
train: epoch 71, iter 4500, loss: 2.774756, top_1: 0.582461, top_k: 0.806328, samples/s: 1332.353 1612730096.102135
train: epoch 71, iter 4600, loss: 2.693822, top_1: 0.585781, top_k: 0.807305, samples/s: 1322.729 1612730115.4560676
train: epoch 71, iter 4700, loss: 2.655310, top_1: 0.589492, top_k: 0.813086, samples/s: 1337.024 1612730134.6030111
train: epoch 71, iter 4800, loss: 2.715660, top_1: 0.589570, top_k: 0.807539, samples/s: 1330.882 1612730153.8384118
train: epoch 71, iter 4900, loss: 2.656186, top_1: 0.589648, top_k: 0.809766, samples/s: 1330.842 1612730173.0743034
train: epoch 71, iter 5000, loss: 2.661565, top_1: 0.579609, top_k: 0.801875, samples/s: 1329.898 1612730192.323955
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_71.
validation: epoch 71, iter 195, top_1: 0.625701, top_k: 0.850541, samples/s: 2774.944 1612730210.8908155
train: epoch 72, iter 100, loss: 2.690234, top_1: 0.596250, top_k: 0.812891, samples/s: 1364.935 1612730246.3014355
train: epoch 72, iter 200, loss: 2.608136, top_1: 0.601602, top_k: 0.816875, samples/s: 1359.779 1612730265.1281033
train: epoch 72, iter 300, loss: 2.676204, top_1: 0.595781, top_k: 0.816211, samples/s: 1361.088 1612730283.9365928
train: epoch 72, iter 400, loss: 2.634694, top_1: 0.593945, top_k: 0.812969, samples/s: 1347.936 1612730302.9285436
train: epoch 72, iter 500, loss: 2.532760, top_1: 0.593906, top_k: 0.815352, samples/s: 1332.310 1612730322.1432774
train: epoch 72, iter 600, loss: 2.716775, top_1: 0.600039, top_k: 0.812031, samples/s: 1319.958 1612730341.537822
train: epoch 72, iter 700, loss: 2.630943, top_1: 0.592969, top_k: 0.810469, samples/s: 1326.794 1612730360.8324523
train: epoch 72, iter 800, loss: 2.570773, top_1: 0.588555, top_k: 0.813750, samples/s: 1330.530 1612730380.0729346
train: epoch 72, iter 900, loss: 2.802751, top_1: 0.592617, top_k: 0.811016, samples/s: 1325.723 1612730399.3831143
train: epoch 72, iter 1000, loss: 2.939928, top_1: 0.597031, top_k: 0.812148, samples/s: 1329.622 1612730418.636726
train: epoch 72, iter 1100, loss: 2.622535, top_1: 0.594648, top_k: 0.811914, samples/s: 1324.028 1612730437.971621
train: epoch 72, iter 1200, loss: 2.604692, top_1: 0.596953, top_k: 0.813750, samples/s: 1329.186 1612730457.2315443
train: epoch 72, iter 1300, loss: 2.791644, top_1: 0.593672, top_k: 0.813086, samples/s: 1325.271 1612730476.548338
train: epoch 72, iter 1400, loss: 2.685638, top_1: 0.592695, top_k: 0.815039, samples/s: 1326.070 1612730495.853514
train: epoch 72, iter 1500, loss: 2.824466, top_1: 0.595234, top_k: 0.813984, samples/s: 1328.873 1612730515.1179926
train: epoch 72, iter 1600, loss: 2.707386, top_1: 0.595117, top_k: 0.811367, samples/s: 1327.747 1612730534.398775
train: epoch 72, iter 1700, loss: 2.554195, top_1: 0.595508, top_k: 0.812539, samples/s: 1330.504 1612730553.639539
train: epoch 72, iter 1800, loss: 2.912053, top_1: 0.587617, top_k: 0.809453, samples/s: 1326.158 1612730572.9435017
train: epoch 72, iter 1900, loss: 2.632039, top_1: 0.586953, top_k: 0.807266, samples/s: 1325.123 1612730592.26238
train: epoch 72, iter 2000, loss: 2.758098, top_1: 0.591133, top_k: 0.809844, samples/s: 1335.241 1612730611.435011
train: epoch 72, iter 2100, loss: 2.534014, top_1: 0.588398, top_k: 0.810586, samples/s: 1319.351 1612730630.8385642
train: epoch 72, iter 2200, loss: 2.754640, top_1: 0.593086, top_k: 0.812148, samples/s: 1337.727 1612730649.9753735
train: epoch 72, iter 2300, loss: 2.535593, top_1: 0.585586, top_k: 0.810547, samples/s: 1324.342 1612730669.3057334
train: epoch 72, iter 2400, loss: 2.703689, top_1: 0.586562, top_k: 0.807578, samples/s: 1330.772 1612730688.542687
train: epoch 72, iter 2500, loss: 2.708630, top_1: 0.592539, top_k: 0.811289, samples/s: 1329.954 1612730707.7915375
train: epoch 72, iter 2600, loss: 2.522605, top_1: 0.585781, top_k: 0.808984, samples/s: 1323.168 1612730727.138995
train: epoch 72, iter 2700, loss: 2.630897, top_1: 0.592578, top_k: 0.811016, samples/s: 1324.877 1612730746.4615285
train: epoch 72, iter 2800, loss: 2.767299, top_1: 0.588672, top_k: 0.807461, samples/s: 1335.377 1612730765.6322167
train: epoch 72, iter 2900, loss: 2.517241, top_1: 0.592422, top_k: 0.809531, samples/s: 1321.339 1612730785.0064383
train: epoch 72, iter 3000, loss: 2.823184, top_1: 0.592812, top_k: 0.808594, samples/s: 1332.118 1612730804.224025
train: epoch 72, iter 3100, loss: 2.780440, top_1: 0.586562, top_k: 0.808555, samples/s: 1332.641 1612730823.4339705
train: epoch 72, iter 3200, loss: 2.809376, top_1: 0.586562, top_k: 0.806328, samples/s: 1317.109 1612730842.8705223
train: epoch 72, iter 3300, loss: 2.658550, top_1: 0.588281, top_k: 0.808672, samples/s: 1331.735 1612730862.0935345
train: epoch 72, iter 3400, loss: 2.651463, top_1: 0.584531, top_k: 0.805625, samples/s: 1331.340 1612730881.3222392
train: epoch 72, iter 3500, loss: 2.742666, top_1: 0.585625, top_k: 0.806562, samples/s: 1331.826 1612730900.5440164
train: epoch 72, iter 3600, loss: 2.695566, top_1: 0.583359, top_k: 0.805352, samples/s: 1323.881 1612730919.8810892
train: epoch 72, iter 3700, loss: 2.736165, top_1: 0.591914, top_k: 0.811523, samples/s: 1331.950 1612730939.1009889
train: epoch 72, iter 3800, loss: 2.917899, top_1: 0.589805, top_k: 0.814297, samples/s: 1327.585 1612730958.3841891
train: epoch 72, iter 3900, loss: 2.855185, top_1: 0.586875, top_k: 0.810742, samples/s: 1324.595 1612730977.7107847
train: epoch 72, iter 4000, loss: 2.679280, top_1: 0.594727, top_k: 0.811211, samples/s: 1329.827 1612730996.961426
train: epoch 72, iter 4100, loss: 2.619051, top_1: 0.585547, top_k: 0.808867, samples/s: 1328.282 1612731016.2345223
train: epoch 72, iter 4200, loss: 2.537058, top_1: 0.595430, top_k: 0.809844, samples/s: 1335.043 1612731035.4098144
train: epoch 72, iter 4300, loss: 2.650280, top_1: 0.585234, top_k: 0.804453, samples/s: 1318.076 1612731054.8321128
train: epoch 72, iter 4400, loss: 2.882328, top_1: 0.586602, top_k: 0.811758, samples/s: 1332.243 1612731074.0477808
train: epoch 72, iter 4500, loss: 2.707942, top_1: 0.590977, top_k: 0.810977, samples/s: 1323.625 1612731093.3886352
train: epoch 72, iter 4600, loss: 2.677258, top_1: 0.585703, top_k: 0.808555, samples/s: 1331.737 1612731112.611675
train: epoch 72, iter 4700, loss: 2.648120, top_1: 0.590273, top_k: 0.809180, samples/s: 1334.021 1612731131.801758
train: epoch 72, iter 4800, loss: 2.823029, top_1: 0.588633, top_k: 0.808047, samples/s: 1316.825 1612731151.2424831
train: epoch 72, iter 4900, loss: 2.544813, top_1: 0.583516, top_k: 0.807383, samples/s: 1331.005 1612731170.4760048
train: epoch 72, iter 5000, loss: 2.695261, top_1: 0.590898, top_k: 0.806953, samples/s: 1328.807 1612731189.7414107
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_72.
validation: epoch 72, iter 195, top_1: 0.642167, top_k: 0.861779, samples/s: 2762.456 1612731208.3783622
train: epoch 73, iter 100, loss: 2.785676, top_1: 0.601133, top_k: 0.818516, samples/s: 1353.639 1612731243.910644
train: epoch 73, iter 200, loss: 2.844132, top_1: 0.592187, top_k: 0.813477, samples/s: 1359.932 1612731262.7350733
train: epoch 73, iter 300, loss: 2.628048, top_1: 0.598516, top_k: 0.819258, samples/s: 1358.096 1612731281.58502
train: epoch 73, iter 400, loss: 2.706045, top_1: 0.591680, top_k: 0.812656, samples/s: 1346.671 1612731300.5948098
train: epoch 73, iter 500, loss: 2.632958, top_1: 0.598047, top_k: 0.817891, samples/s: 1318.034 1612731320.0177166
train: epoch 73, iter 600, loss: 2.505863, top_1: 0.603906, top_k: 0.820625, samples/s: 1327.430 1612731339.3030987
train: epoch 73, iter 700, loss: 2.652744, top_1: 0.594180, top_k: 0.817227, samples/s: 1320.593 1612731358.6882863
train: epoch 73, iter 800, loss: 2.646538, top_1: 0.599180, top_k: 0.815273, samples/s: 1325.908 1612731377.9958413
train: epoch 73, iter 900, loss: 2.671679, top_1: 0.594844, top_k: 0.816992, samples/s: 1332.057 1612731397.214247
train: epoch 73, iter 1000, loss: 2.810219, top_1: 0.592578, top_k: 0.811172, samples/s: 1314.321 1612731416.6920462
train: epoch 73, iter 1100, loss: 2.640716, top_1: 0.594844, top_k: 0.813906, samples/s: 1320.276 1612731436.0818057
train: epoch 73, iter 1200, loss: 2.639017, top_1: 0.594922, top_k: 0.815000, samples/s: 1329.881 1612731455.3317182
train: epoch 73, iter 1300, loss: 2.625179, top_1: 0.596328, top_k: 0.815508, samples/s: 1328.871 1612731474.5961738
train: epoch 73, iter 1400, loss: 2.591065, top_1: 0.599180, top_k: 0.817969, samples/s: 1323.930 1612731493.9324899
train: epoch 73, iter 1500, loss: 2.661497, top_1: 0.595586, top_k: 0.811953, samples/s: 1322.873 1612731513.2843425
train: epoch 73, iter 1600, loss: 2.832751, top_1: 0.589336, top_k: 0.808203, samples/s: 1321.767 1612731532.652382
train: epoch 73, iter 1700, loss: 2.701656, top_1: 0.594414, top_k: 0.815000, samples/s: 1328.313 1612731551.9249842
train: epoch 73, iter 1800, loss: 2.663528, top_1: 0.586953, top_k: 0.810469, samples/s: 1319.664 1612731571.3237767
train: epoch 73, iter 1900, loss: 2.593582, top_1: 0.590313, top_k: 0.808945, samples/s: 1323.057 1612731590.6729667
train: epoch 73, iter 2000, loss: 2.697332, top_1: 0.593164, top_k: 0.811328, samples/s: 1326.392 1612731609.973384
train: epoch 73, iter 2100, loss: 2.764276, top_1: 0.588633, top_k: 0.808008, samples/s: 1324.776 1612731629.2974007
train: epoch 73, iter 2200, loss: 2.632977, top_1: 0.595508, top_k: 0.813086, samples/s: 1325.591 1612731648.6095893
train: epoch 73, iter 2300, loss: 2.575838, top_1: 0.595352, top_k: 0.813203, samples/s: 1320.424 1612731667.9973273
train: epoch 73, iter 2400, loss: 2.663736, top_1: 0.595820, top_k: 0.811719, samples/s: 1325.628 1612731687.3089736
train: epoch 73, iter 2500, loss: 2.735300, top_1: 0.588555, top_k: 0.813906, samples/s: 1329.870 1612731706.5589128
train: epoch 73, iter 2600, loss: 2.588727, top_1: 0.593516, top_k: 0.813398, samples/s: 1320.695 1612731725.9425874
train: epoch 73, iter 2700, loss: 2.579982, top_1: 0.589453, top_k: 0.811016, samples/s: 1330.764 1612731745.1796646
train: epoch 73, iter 2800, loss: 2.701557, top_1: 0.585820, top_k: 0.806953, samples/s: 1327.397 1612731764.4655495
train: epoch 73, iter 2900, loss: 2.677661, top_1: 0.585195, top_k: 0.804023, samples/s: 1321.355 1612731783.839625
train: epoch 73, iter 3000, loss: 2.711969, top_1: 0.588203, top_k: 0.806953, samples/s: 1323.561 1612731803.1814358
train: epoch 73, iter 3100, loss: 2.532793, top_1: 0.590586, top_k: 0.810664, samples/s: 1327.723 1612731822.4624686
train: epoch 73, iter 3200, loss: 2.828196, top_1: 0.591836, top_k: 0.811523, samples/s: 1323.387 1612731841.8067663
train: epoch 73, iter 3300, loss: 2.801944, top_1: 0.585234, top_k: 0.808516, samples/s: 1333.403 1612731861.00579
train: epoch 73, iter 3400, loss: 2.528355, top_1: 0.592148, top_k: 0.810820, samples/s: 1324.354 1612731880.3359444
train: epoch 73, iter 3500, loss: 2.767763, top_1: 0.591172, top_k: 0.813398, samples/s: 1324.005 1612731899.6713119
train: epoch 73, iter 3600, loss: 2.684881, top_1: 0.591367, top_k: 0.812109, samples/s: 1320.424 1612731919.05899
train: epoch 73, iter 3700, loss: 2.613163, top_1: 0.589922, top_k: 0.809688, samples/s: 1322.075 1612731938.4224548
train: epoch 73, iter 3800, loss: 2.917099, top_1: 0.591484, top_k: 0.811875, samples/s: 1324.297 1612731957.7534392
train: epoch 73, iter 3900, loss: 2.831687, top_1: 0.591328, top_k: 0.810234, samples/s: 1325.636 1612731977.064922
train: epoch 73, iter 4000, loss: 2.829865, top_1: 0.589180, top_k: 0.810078, samples/s: 1322.774 1612731996.4182396
train: epoch 73, iter 4100, loss: 2.732775, top_1: 0.590977, top_k: 0.812813, samples/s: 1326.143 1612732015.7223115
train: epoch 73, iter 4200, loss: 2.653315, top_1: 0.586328, top_k: 0.807031, samples/s: 1325.092 1612732035.0417557
train: epoch 73, iter 4300, loss: 2.569585, top_1: 0.586953, top_k: 0.810937, samples/s: 1328.111 1612732054.3172197
train: epoch 73, iter 4400, loss: 2.882256, top_1: 0.587383, top_k: 0.810625, samples/s: 1326.671 1612732073.6136508
train: epoch 73, iter 4500, loss: 2.745880, top_1: 0.589063, top_k: 0.807578, samples/s: 1327.100 1612732092.90388
train: epoch 73, iter 4600, loss: 2.618530, top_1: 0.586055, top_k: 0.809102, samples/s: 1326.310 1612732112.2055335
train: epoch 73, iter 4700, loss: 2.710614, top_1: 0.587695, top_k: 0.810625, samples/s: 1329.586 1612732131.4596603
train: epoch 73, iter 4800, loss: 2.708555, top_1: 0.590547, top_k: 0.806367, samples/s: 1326.733 1612732150.755319
train: epoch 73, iter 4900, loss: 2.893773, top_1: 0.586992, top_k: 0.807852, samples/s: 1321.255 1612732170.130626
train: epoch 73, iter 5000, loss: 2.674916, top_1: 0.591562, top_k: 0.810117, samples/s: 1324.596 1612732189.457307
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_73.
validation: epoch 73, iter 195, top_1: 0.642808, top_k: 0.859936, samples/s: 2790.890 1612732207.9811914
train: epoch 74, iter 100, loss: 2.765265, top_1: 0.596875, top_k: 0.816055, samples/s: 1364.311 1612732243.213709
train: epoch 74, iter 200, loss: 2.661816, top_1: 0.604297, top_k: 0.818750, samples/s: 1362.082 1612732262.0084364
train: epoch 74, iter 300, loss: 2.755903, top_1: 0.603047, top_k: 0.822930, samples/s: 1357.522 1612732280.8663626
train: epoch 74, iter 400, loss: 2.530869, top_1: 0.597266, top_k: 0.815117, samples/s: 1352.575 1612732299.7932658
train: epoch 74, iter 500, loss: 2.580526, top_1: 0.598906, top_k: 0.818789, samples/s: 1323.173 1612732319.1406777
train: epoch 74, iter 600, loss: 2.574794, top_1: 0.598320, top_k: 0.814414, samples/s: 1332.594 1612732338.351342
train: epoch 74, iter 700, loss: 2.490043, top_1: 0.601406, top_k: 0.816211, samples/s: 1321.804 1612732357.7187812
train: epoch 74, iter 800, loss: 2.608068, top_1: 0.602500, top_k: 0.818320, samples/s: 1329.573 1612732376.9730306
train: epoch 74, iter 900, loss: 2.658088, top_1: 0.598008, top_k: 0.812461, samples/s: 1329.036 1612732396.2351031
train: epoch 74, iter 1000, loss: 2.813869, top_1: 0.595977, top_k: 0.815781, samples/s: 1329.392 1612732415.4920967
train: epoch 74, iter 1100, loss: 2.729174, top_1: 0.601016, top_k: 0.815820, samples/s: 1331.239 1612732434.7222779
train: epoch 74, iter 1200, loss: 2.577748, top_1: 0.597305, top_k: 0.815625, samples/s: 1327.921 1612732454.0005534
train: epoch 74, iter 1300, loss: 2.684510, top_1: 0.590391, top_k: 0.812852, samples/s: 1327.490 1612732473.2850149
train: epoch 74, iter 1400, loss: 2.588619, top_1: 0.593125, top_k: 0.814063, samples/s: 1327.499 1612732492.5694013
train: epoch 74, iter 1500, loss: 2.654279, top_1: 0.592930, top_k: 0.813867, samples/s: 1328.576 1612732511.8381927
train: epoch 74, iter 1600, loss: 2.581197, top_1: 0.597227, top_k: 0.816992, samples/s: 1324.879 1612732531.1607025
train: epoch 74, iter 1700, loss: 2.775879, top_1: 0.596055, top_k: 0.809961, samples/s: 1333.953 1612732550.3517272
train: epoch 74, iter 1800, loss: 2.780926, top_1: 0.592305, top_k: 0.813945, samples/s: 1335.418 1612732569.5217547
train: epoch 74, iter 1900, loss: 2.678409, top_1: 0.592070, top_k: 0.808867, samples/s: 1326.519 1612732588.8203971
train: epoch 74, iter 2000, loss: 2.682831, top_1: 0.590820, top_k: 0.813125, samples/s: 1322.773 1612732608.173672
train: epoch 74, iter 2100, loss: 2.813739, top_1: 0.588242, top_k: 0.810352, samples/s: 1335.344 1612732627.3448448
train: epoch 74, iter 2200, loss: 2.685570, top_1: 0.597773, top_k: 0.813789, samples/s: 1336.751 1612732646.4956844
train: epoch 74, iter 2300, loss: 2.530319, top_1: 0.596211, top_k: 0.813438, samples/s: 1329.208 1612732665.7552686
train: epoch 74, iter 2400, loss: 2.661469, top_1: 0.596328, top_k: 0.811602, samples/s: 1324.426 1612732685.0844665
train: epoch 74, iter 2500, loss: 2.668723, top_1: 0.592461, top_k: 0.812383, samples/s: 1324.915 1612732704.4064322
train: epoch 74, iter 2600, loss: 2.599743, top_1: 0.590820, top_k: 0.813594, samples/s: 1335.228 1612732723.579158
train: epoch 74, iter 2700, loss: 2.781967, top_1: 0.592852, top_k: 0.811797, samples/s: 1338.046 1612732742.7115207
train: epoch 74, iter 2800, loss: 2.739186, top_1: 0.598555, top_k: 0.814023, samples/s: 1330.808 1612732761.948017
train: epoch 74, iter 2900, loss: 2.786301, top_1: 0.589336, top_k: 0.814414, samples/s: 1330.583 1612732781.187687
train: epoch 74, iter 3000, loss: 2.722760, top_1: 0.591562, top_k: 0.809648, samples/s: 1330.048 1612732800.4350712
train: epoch 74, iter 3100, loss: 2.734523, top_1: 0.593398, top_k: 0.812344, samples/s: 1329.874 1612732819.6850626
train: epoch 74, iter 3200, loss: 2.639740, top_1: 0.588555, top_k: 0.813242, samples/s: 1326.581 1612732838.9827945
train: epoch 74, iter 3300, loss: 2.716432, top_1: 0.588906, top_k: 0.811641, samples/s: 1329.559 1612732858.2372556
train: epoch 74, iter 3400, loss: 2.830118, top_1: 0.588516, top_k: 0.809492, samples/s: 1329.502 1612732877.492636
train: epoch 74, iter 3500, loss: 2.660159, top_1: 0.590000, top_k: 0.811836, samples/s: 1330.685 1612732896.7308168
train: epoch 74, iter 3600, loss: 2.444140, top_1: 0.593945, top_k: 0.812617, samples/s: 1330.856 1612732915.9665232
train: epoch 74, iter 3700, loss: 2.593282, top_1: 0.593789, top_k: 0.813906, samples/s: 1329.589 1612732935.2206059
train: epoch 74, iter 3800, loss: 2.844599, top_1: 0.592852, top_k: 0.811133, samples/s: 1331.044 1612732954.4536572
train: epoch 74, iter 3900, loss: 2.716583, top_1: 0.595117, top_k: 0.813281, samples/s: 1329.018 1612732973.716056
train: epoch 74, iter 4000, loss: 2.604775, top_1: 0.595391, top_k: 0.808945, samples/s: 1331.330 1612732992.9448779
train: epoch 74, iter 4100, loss: 2.657589, top_1: 0.588242, top_k: 0.809492, samples/s: 1330.004 1612733012.1929817
train: epoch 74, iter 4200, loss: 2.707376, top_1: 0.593516, top_k: 0.812695, samples/s: 1329.564 1612733031.4473944
train: epoch 74, iter 4300, loss: 2.728389, top_1: 0.585000, top_k: 0.806367, samples/s: 1329.744 1612733050.6992383
train: epoch 74, iter 4400, loss: 2.705290, top_1: 0.595469, top_k: 0.810000, samples/s: 1332.579 1612733069.9101167
train: epoch 74, iter 4500, loss: 2.630661, top_1: 0.595156, top_k: 0.815469, samples/s: 1331.908 1612733089.1306884
train: epoch 74, iter 4600, loss: 2.623925, top_1: 0.584023, top_k: 0.805898, samples/s: 1335.238 1612733108.3033206
train: epoch 74, iter 4700, loss: 2.602751, top_1: 0.590820, top_k: 0.810977, samples/s: 1321.242 1612733127.6789806
train: epoch 74, iter 4800, loss: 2.753366, top_1: 0.586211, top_k: 0.809102, samples/s: 1329.226 1612733146.9382572
train: epoch 74, iter 4900, loss: 2.624035, top_1: 0.598906, top_k: 0.814727, samples/s: 1330.000 1612733166.1864784
train: epoch 74, iter 5000, loss: 2.648478, top_1: 0.592344, top_k: 0.814570, samples/s: 1335.189 1612733185.3596938
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_74.
validation: epoch 74, iter 195, top_1: 0.640425, top_k: 0.861138, samples/s: 2800.708 1612733203.7436087
train: epoch 75, iter 100, loss: 2.610897, top_1: 0.603008, top_k: 0.817109, samples/s: 1362.151 1612733239.2248535
train: epoch 75, iter 200, loss: 2.636522, top_1: 0.595664, top_k: 0.814258, samples/s: 1360.108 1612733258.0469897
train: epoch 75, iter 300, loss: 2.733662, top_1: 0.592383, top_k: 0.815469, samples/s: 1361.720 1612733276.8466544
train: epoch 75, iter 400, loss: 2.821338, top_1: 0.604141, top_k: 0.819492, samples/s: 1343.829 1612733295.8967545
train: epoch 75, iter 500, loss: 2.508622, top_1: 0.597969, top_k: 0.817813, samples/s: 1339.249 1612733315.011939
train: epoch 75, iter 600, loss: 2.725252, top_1: 0.601797, top_k: 0.818633, samples/s: 1321.398 1612733334.3852715
train: epoch 75, iter 700, loss: 2.567045, top_1: 0.596992, top_k: 0.815664, samples/s: 1327.917 1612733353.663586
train: epoch 75, iter 800, loss: 2.640300, top_1: 0.597305, top_k: 0.816250, samples/s: 1326.285 1612733372.9656556
train: epoch 75, iter 900, loss: 2.648861, top_1: 0.600078, top_k: 0.817930, samples/s: 1338.395 1612733392.0930507
train: epoch 75, iter 1000, loss: 2.719793, top_1: 0.600781, top_k: 0.814180, samples/s: 1325.374 1612733411.4084086
train: epoch 75, iter 1100, loss: 2.719874, top_1: 0.596094, top_k: 0.812461, samples/s: 1331.679 1612733430.6321611
train: epoch 75, iter 1200, loss: 2.863572, top_1: 0.594414, top_k: 0.816172, samples/s: 1329.628 1612733449.8856728
train: epoch 75, iter 1300, loss: 2.692442, top_1: 0.594727, top_k: 0.812109, samples/s: 1326.407 1612733469.1859539
train: epoch 75, iter 1400, loss: 2.629215, top_1: 0.599727, top_k: 0.818711, samples/s: 1327.629 1612733488.4684644
train: epoch 75, iter 1500, loss: 2.686865, top_1: 0.596680, top_k: 0.812578, samples/s: 1334.652 1612733507.649488
train: epoch 75, iter 1600, loss: 2.742025, top_1: 0.591328, top_k: 0.813906, samples/s: 1329.433 1612733526.9058433
train: epoch 75, iter 1700, loss: 2.674535, top_1: 0.596797, top_k: 0.816602, samples/s: 1331.224 1612733546.136189
train: epoch 75, iter 1800, loss: 2.623752, top_1: 0.595195, top_k: 0.813359, samples/s: 1331.107 1612733565.3683283
train: epoch 75, iter 1900, loss: 2.646972, top_1: 0.593516, top_k: 0.812813, samples/s: 1329.864 1612733584.61846
train: epoch 75, iter 2000, loss: 2.797478, top_1: 0.595156, top_k: 0.811875, samples/s: 1330.053 1612733603.865854
train: epoch 75, iter 2100, loss: 2.850882, top_1: 0.591211, top_k: 0.811992, samples/s: 1325.388 1612733623.1809516
train: epoch 75, iter 2200, loss: 2.775829, top_1: 0.591406, top_k: 0.814219, samples/s: 1332.140 1612733642.3980513
train: epoch 75, iter 2300, loss: 2.677067, top_1: 0.592695, top_k: 0.814375, samples/s: 1331.255 1612733661.6280668
train: epoch 75, iter 2400, loss: 2.742077, top_1: 0.595078, top_k: 0.811953, samples/s: 1326.000 1612733680.934254
train: epoch 75, iter 2500, loss: 2.629557, top_1: 0.595547, top_k: 0.814453, samples/s: 1326.513 1612733700.232957
train: epoch 75, iter 2600, loss: 2.686897, top_1: 0.600117, top_k: 0.817070, samples/s: 1336.661 1612733719.3852136
train: epoch 75, iter 2700, loss: 2.650239, top_1: 0.591719, top_k: 0.814609, samples/s: 1332.508 1612733738.5970936
train: epoch 75, iter 2800, loss: 2.626373, top_1: 0.596211, top_k: 0.812617, samples/s: 1330.466 1612733757.8384569
train: epoch 75, iter 2900, loss: 2.676429, top_1: 0.596094, top_k: 0.813828, samples/s: 1328.598 1612733777.1068308
train: epoch 75, iter 3000, loss: 2.938926, top_1: 0.589648, top_k: 0.809844, samples/s: 1333.654 1612733796.3022308
train: epoch 75, iter 3100, loss: 2.673803, top_1: 0.600117, top_k: 0.817500, samples/s: 1331.767 1612733815.5248473
train: epoch 75, iter 3200, loss: 2.642411, top_1: 0.588906, top_k: 0.811367, samples/s: 1331.075 1612733834.757401
train: epoch 75, iter 3300, loss: 2.782600, top_1: 0.598789, top_k: 0.818828, samples/s: 1330.710 1612733853.9952137
train: epoch 75, iter 3400, loss: 2.784488, top_1: 0.593164, top_k: 0.812266, samples/s: 1329.283 1612733873.2537682
train: epoch 75, iter 3500, loss: 2.719021, top_1: 0.594141, top_k: 0.813906, samples/s: 1328.868 1612733892.5182462
train: epoch 75, iter 3600, loss: 2.731110, top_1: 0.593437, top_k: 0.809570, samples/s: 1332.604 1612733911.7288058
train: epoch 75, iter 3700, loss: 2.611359, top_1: 0.593242, top_k: 0.808438, samples/s: 1328.813 1612733930.9941082
train: epoch 75, iter 3800, loss: 2.624571, top_1: 0.592695, top_k: 0.814297, samples/s: 1335.623 1612733950.1612208
train: epoch 75, iter 3900, loss: 2.780488, top_1: 0.596016, top_k: 0.813125, samples/s: 1334.917 1612733969.3384352
train: epoch 75, iter 4000, loss: 2.711495, top_1: 0.596797, top_k: 0.812266, samples/s: 1331.392 1612733988.5663936
train: epoch 75, iter 4100, loss: 2.677586, top_1: 0.593086, top_k: 0.812734, samples/s: 1324.472 1612734007.894882
train: epoch 75, iter 4200, loss: 2.810060, top_1: 0.588047, top_k: 0.812578, samples/s: 1335.000 1612734027.0708575
train: epoch 75, iter 4300, loss: 2.698739, top_1: 0.586445, top_k: 0.811719, samples/s: 1324.971 1612734046.3920386
train: epoch 75, iter 4400, loss: 2.674349, top_1: 0.590039, top_k: 0.811211, samples/s: 1329.204 1612734065.6517882
train: epoch 75, iter 4500, loss: 2.597304, top_1: 0.598047, top_k: 0.815117, samples/s: 1334.686 1612734084.832242
train: epoch 75, iter 4600, loss: 2.783075, top_1: 0.588477, top_k: 0.807617, samples/s: 1328.589 1612734104.1008441
train: epoch 75, iter 4700, loss: 2.597912, top_1: 0.595313, top_k: 0.813711, samples/s: 1330.613 1612734123.3400466
train: epoch 75, iter 4800, loss: 2.580722, top_1: 0.594297, top_k: 0.811484, samples/s: 1330.485 1612734142.5811996
train: epoch 75, iter 4900, loss: 2.656703, top_1: 0.584922, top_k: 0.807852, samples/s: 1328.654 1612734161.8488107
train: epoch 75, iter 5000, loss: 2.510819, top_1: 0.594531, top_k: 0.807852, samples/s: 1338.822 1612734180.970076
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_75.
validation: epoch 75, iter 195, top_1: 0.636458, top_k: 0.857612, samples/s: 2871.771 1612734198.9309306
train: epoch 76, iter 100, loss: 2.580732, top_1: 0.601680, top_k: 0.818047, samples/s: 1357.574 1612734233.885553
train: epoch 76, iter 200, loss: 2.736298, top_1: 0.601953, top_k: 0.818789, samples/s: 1360.148 1612734252.707388
train: epoch 76, iter 300, loss: 2.590672, top_1: 0.605273, top_k: 0.818906, samples/s: 1354.789 1612734271.6029472
train: epoch 76, iter 400, loss: 2.471959, top_1: 0.602930, top_k: 0.820000, samples/s: 1346.417 1612734290.6163642
train: epoch 76, iter 500, loss: 2.630291, top_1: 0.597891, top_k: 0.818828, samples/s: 1337.873 1612734309.7512019
train: epoch 76, iter 600, loss: 2.675509, top_1: 0.603633, top_k: 0.820078, samples/s: 1324.127 1612734329.0846906
train: epoch 76, iter 700, loss: 2.646142, top_1: 0.597383, top_k: 0.819961, samples/s: 1329.443 1612734348.3409772
train: epoch 76, iter 800, loss: 2.884091, top_1: 0.603477, top_k: 0.818672, samples/s: 1334.196 1612734367.5285265
train: epoch 76, iter 900, loss: 2.623805, top_1: 0.600938, top_k: 0.817344, samples/s: 1331.858 1612734386.749843
train: epoch 76, iter 1000, loss: 2.673551, top_1: 0.595742, top_k: 0.819219, samples/s: 1328.946 1612734406.0132246
train: epoch 76, iter 1100, loss: 2.463172, top_1: 0.600156, top_k: 0.815625, samples/s: 1324.741 1612734425.3376966
train: epoch 76, iter 1200, loss: 2.730361, top_1: 0.603594, top_k: 0.819844, samples/s: 1326.243 1612734444.6403377
train: epoch 76, iter 1300, loss: 2.639388, top_1: 0.595820, top_k: 0.812031, samples/s: 1327.949 1612734463.9182286
train: epoch 76, iter 1400, loss: 2.597916, top_1: 0.594609, top_k: 0.813945, samples/s: 1330.458 1612734483.1596887
train: epoch 76, iter 1500, loss: 2.620286, top_1: 0.596680, top_k: 0.814648, samples/s: 1328.734 1612734502.4261222
train: epoch 76, iter 1600, loss: 2.700301, top_1: 0.595938, top_k: 0.816016, samples/s: 1328.308 1612734521.698785
train: epoch 76, iter 1700, loss: 2.804958, top_1: 0.600859, top_k: 0.815273, samples/s: 1325.297 1612734541.0152895
train: epoch 76, iter 1800, loss: 2.557392, top_1: 0.598516, top_k: 0.817070, samples/s: 1331.975 1612734560.2348053
train: epoch 76, iter 1900, loss: 2.807251, top_1: 0.599922, top_k: 0.815898, samples/s: 1331.825 1612734579.4564915
train: epoch 76, iter 2000, loss: 2.795993, top_1: 0.594492, top_k: 0.814883, samples/s: 1328.608 1612734598.7247875
train: epoch 76, iter 2100, loss: 2.726470, top_1: 0.598828, top_k: 0.815195, samples/s: 1329.041 1612734617.9868157
train: epoch 76, iter 2200, loss: 2.770028, top_1: 0.597773, top_k: 0.815469, samples/s: 1332.467 1612734637.199475
train: epoch 76, iter 2300, loss: 2.500183, top_1: 0.597187, top_k: 0.811797, samples/s: 1326.712 1612734656.4951077
train: epoch 76, iter 2400, loss: 2.598359, top_1: 0.599492, top_k: 0.818281, samples/s: 1326.289 1612734675.797101
train: epoch 76, iter 2500, loss: 2.649487, top_1: 0.597773, top_k: 0.815391, samples/s: 1333.221 1612734694.9986966
train: epoch 76, iter 2600, loss: 2.562705, top_1: 0.596016, top_k: 0.817539, samples/s: 1332.629 1612734714.2089038
train: epoch 76, iter 2700, loss: 2.644238, top_1: 0.596445, top_k: 0.814180, samples/s: 1320.995 1612734733.5881715
train: epoch 76, iter 2800, loss: 2.624362, top_1: 0.599258, top_k: 0.817695, samples/s: 1334.673 1612734752.7689075
train: epoch 76, iter 2900, loss: 2.481919, top_1: 0.596953, top_k: 0.817852, samples/s: 1333.055 1612734771.972953
train: epoch 76, iter 3000, loss: 2.589002, top_1: 0.598125, top_k: 0.817422, samples/s: 1326.854 1612734791.2666576
train: epoch 76, iter 3100, loss: 2.862636, top_1: 0.595508, top_k: 0.814570, samples/s: 1332.152 1612734810.483726
train: epoch 76, iter 3200, loss: 2.753345, top_1: 0.589844, top_k: 0.812695, samples/s: 1332.540 1612734829.695122
train: epoch 76, iter 3300, loss: 2.510013, top_1: 0.592070, top_k: 0.816250, samples/s: 1327.310 1612734848.9822931
train: epoch 76, iter 3400, loss: 2.648958, top_1: 0.591367, top_k: 0.809336, samples/s: 1325.898 1612734868.2899084
train: epoch 76, iter 3500, loss: 2.792380, top_1: 0.598516, top_k: 0.817344, samples/s: 1330.575 1612734887.5297463
train: epoch 76, iter 3600, loss: 2.726336, top_1: 0.593867, top_k: 0.811289, samples/s: 1327.932 1612734906.8078797
train: epoch 76, iter 3700, loss: 2.697629, top_1: 0.590313, top_k: 0.812461, samples/s: 1325.801 1612734926.1169019
train: epoch 76, iter 3800, loss: 2.773475, top_1: 0.595664, top_k: 0.818281, samples/s: 1341.650 1612734945.197884
train: epoch 76, iter 3900, loss: 2.465618, top_1: 0.598906, top_k: 0.815586, samples/s: 1328.730 1612734964.4644644
train: epoch 76, iter 4000, loss: 2.812475, top_1: 0.595156, top_k: 0.811367, samples/s: 1329.572 1612734983.7187521
train: epoch 76, iter 4100, loss: 2.444091, top_1: 0.594414, top_k: 0.811836, samples/s: 1330.488 1612735002.9598267
train: epoch 76, iter 4200, loss: 2.714031, top_1: 0.593242, top_k: 0.811797, samples/s: 1329.344 1612735022.2173948
train: epoch 76, iter 4300, loss: 2.735599, top_1: 0.597187, top_k: 0.817969, samples/s: 1331.895 1612735041.4382083
train: epoch 76, iter 4400, loss: 2.668998, top_1: 0.596094, top_k: 0.813242, samples/s: 1330.236 1612735060.6828938
train: epoch 76, iter 4500, loss: 2.720935, top_1: 0.596055, top_k: 0.813047, samples/s: 1330.716 1612735079.9206092
train: epoch 76, iter 4600, loss: 2.859021, top_1: 0.590508, top_k: 0.807969, samples/s: 1331.839 1612735099.1422412
train: epoch 76, iter 4700, loss: 2.715245, top_1: 0.591094, top_k: 0.810312, samples/s: 1326.541 1612735118.4405718
train: epoch 76, iter 4800, loss: 2.738540, top_1: 0.593633, top_k: 0.812031, samples/s: 1330.254 1612735137.6849957
train: epoch 76, iter 4900, loss: 2.603554, top_1: 0.594805, top_k: 0.809258, samples/s: 1327.840 1612735156.9643385
train: epoch 76, iter 5000, loss: 2.651682, top_1: 0.600898, top_k: 0.814766, samples/s: 1328.088 1612735176.2401714
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_76.
validation: epoch 76, iter 195, top_1: 0.645793, top_k: 0.862941, samples/s: 2788.361 1612735194.8157253
train: epoch 77, iter 100, loss: 2.639958, top_1: 0.607578, top_k: 0.822227, samples/s: 1360.935 1612735229.5914805
train: epoch 77, iter 200, loss: 2.682866, top_1: 0.607852, top_k: 0.825625, samples/s: 1361.918 1612735248.3886595
train: epoch 77, iter 300, loss: 2.628605, top_1: 0.598203, top_k: 0.814570, samples/s: 1355.903 1612735267.268882
train: epoch 77, iter 400, loss: 2.842084, top_1: 0.603711, top_k: 0.822070, samples/s: 1342.421 1612735286.3388996
train: epoch 77, iter 500, loss: 2.706483, top_1: 0.600742, top_k: 0.816172, samples/s: 1330.202 1612735305.584102
train: epoch 77, iter 600, loss: 2.509173, top_1: 0.606523, top_k: 0.820703, samples/s: 1326.159 1612735324.888127
train: epoch 77, iter 700, loss: 2.613116, top_1: 0.604219, top_k: 0.822812, samples/s: 1320.305 1612735344.2775054
train: epoch 77, iter 800, loss: 2.526316, top_1: 0.604609, top_k: 0.819375, samples/s: 1322.826 1612735363.6299434
train: epoch 77, iter 900, loss: 2.645549, top_1: 0.601836, top_k: 0.817695, samples/s: 1322.197 1612735382.991685
train: epoch 77, iter 1000, loss: 2.745169, top_1: 0.600703, top_k: 0.816445, samples/s: 1330.355 1612735402.2347505
train: epoch 77, iter 1100, loss: 2.647650, top_1: 0.603594, top_k: 0.821406, samples/s: 1329.632 1612735421.4881139
train: epoch 77, iter 1200, loss: 2.569129, top_1: 0.597187, top_k: 0.817266, samples/s: 1321.373 1612735440.8619382
train: epoch 77, iter 1300, loss: 2.695896, top_1: 0.600117, top_k: 0.818750, samples/s: 1330.183 1612735460.107413
train: epoch 77, iter 1400, loss: 2.625364, top_1: 0.602734, top_k: 0.819648, samples/s: 1325.062 1612735479.427213
train: epoch 77, iter 1500, loss: 2.513615, top_1: 0.601172, top_k: 0.816680, samples/s: 1324.374 1612735498.757136
train: epoch 77, iter 1600, loss: 2.720281, top_1: 0.599961, top_k: 0.815039, samples/s: 1319.861 1612735518.1531358
train: epoch 77, iter 1700, loss: 2.732769, top_1: 0.596055, top_k: 0.815430, samples/s: 1322.901 1612735537.5044885
train: epoch 77, iter 1800, loss: 2.651636, top_1: 0.604531, top_k: 0.818398, samples/s: 1332.109 1612735556.7222695
train: epoch 77, iter 1900, loss: 2.661140, top_1: 0.599414, top_k: 0.817734, samples/s: 1329.276 1612735575.9807835
train: epoch 77, iter 2000, loss: 2.752491, top_1: 0.597969, top_k: 0.816289, samples/s: 1310.689 1612735595.5124345
train: epoch 77, iter 2100, loss: 2.586537, top_1: 0.599570, top_k: 0.814883, samples/s: 1326.864 1612735614.8060753
train: epoch 77, iter 2200, loss: 2.742165, top_1: 0.596914, top_k: 0.814453, samples/s: 1325.199 1612735634.1239674
train: epoch 77, iter 2300, loss: 2.619166, top_1: 0.598008, top_k: 0.816602, samples/s: 1327.052 1612735653.4147952
train: epoch 77, iter 2400, loss: 2.759237, top_1: 0.597500, top_k: 0.815820, samples/s: 1319.150 1612735672.821228
train: epoch 77, iter 2500, loss: 2.690909, top_1: 0.593945, top_k: 0.815352, samples/s: 1325.237 1612735692.1385372
train: epoch 77, iter 2600, loss: 2.727290, top_1: 0.592812, top_k: 0.811875, samples/s: 1330.768 1612735711.3756745
train: epoch 77, iter 2700, loss: 2.740162, top_1: 0.599414, top_k: 0.815352, samples/s: 1326.197 1612735730.6789198
train: epoch 77, iter 2800, loss: 2.521513, top_1: 0.594063, top_k: 0.812461, samples/s: 1325.966 1612735749.985657
train: epoch 77, iter 2900, loss: 2.612271, top_1: 0.598047, top_k: 0.817461, samples/s: 1332.582 1612735769.1963878
train: epoch 77, iter 3000, loss: 2.618279, top_1: 0.602656, top_k: 0.816406, samples/s: 1320.211 1612735788.5873353
train: epoch 77, iter 3100, loss: 2.556179, top_1: 0.600000, top_k: 0.819648, samples/s: 1326.460 1612735807.8866868
train: epoch 77, iter 3200, loss: 2.439955, top_1: 0.595234, top_k: 0.812969, samples/s: 1329.124 1612735827.1475718
train: epoch 77, iter 3300, loss: 2.656994, top_1: 0.586562, top_k: 0.810469, samples/s: 1318.094 1612735846.5694976
train: epoch 77, iter 3400, loss: 2.699693, top_1: 0.597383, top_k: 0.813633, samples/s: 1328.113 1612735865.84495
train: epoch 77, iter 3500, loss: 2.706874, top_1: 0.600352, top_k: 0.818047, samples/s: 1329.882 1612735885.0948002
train: epoch 77, iter 3600, loss: 2.804578, top_1: 0.600117, top_k: 0.812070, samples/s: 1321.252 1612735904.4704292
train: epoch 77, iter 3700, loss: 2.524841, top_1: 0.593359, top_k: 0.815820, samples/s: 1331.774 1612735923.6928194
train: epoch 77, iter 3800, loss: 2.735929, top_1: 0.597422, top_k: 0.816562, samples/s: 1326.456 1612735942.9923894
train: epoch 77, iter 3900, loss: 2.690893, top_1: 0.593516, top_k: 0.816797, samples/s: 1322.738 1612735962.346244
train: epoch 77, iter 4000, loss: 2.472457, top_1: 0.601758, top_k: 0.817813, samples/s: 1324.027 1612735981.6811254
train: epoch 77, iter 4100, loss: 2.672175, top_1: 0.598750, top_k: 0.812734, samples/s: 1334.597 1612736000.8629494
train: epoch 77, iter 4200, loss: 2.683476, top_1: 0.600781, top_k: 0.819570, samples/s: 1325.864 1612736020.171113
train: epoch 77, iter 4300, loss: 2.613158, top_1: 0.595195, top_k: 0.809336, samples/s: 1326.348 1612736039.4722104
train: epoch 77, iter 4400, loss: 2.865669, top_1: 0.596172, top_k: 0.813711, samples/s: 1325.962 1612736058.7789984
train: epoch 77, iter 4500, loss: 2.585261, top_1: 0.594414, top_k: 0.811172, samples/s: 1321.168 1612736078.1558087
train: epoch 77, iter 4600, loss: 2.560301, top_1: 0.593906, top_k: 0.813086, samples/s: 1322.811 1612736097.5084841
train: epoch 77, iter 4700, loss: 2.538087, top_1: 0.594063, top_k: 0.815508, samples/s: 1327.433 1612736116.7938104
train: epoch 77, iter 4800, loss: 2.498299, top_1: 0.602578, top_k: 0.816289, samples/s: 1329.893 1612736136.043553
train: epoch 77, iter 4900, loss: 2.574681, top_1: 0.596914, top_k: 0.816016, samples/s: 1330.123 1612736155.289868
train: epoch 77, iter 5000, loss: 2.542440, top_1: 0.603008, top_k: 0.816641, samples/s: 1315.316 1612736174.7528212
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_77.
validation: epoch 77, iter 195, top_1: 0.645052, top_k: 0.863682, samples/s: 2712.544 1612736193.703789
train: epoch 78, iter 100, loss: 2.663084, top_1: 0.610391, top_k: 0.821992, samples/s: 1352.577 1612736234.4586694
train: epoch 78, iter 200, loss: 2.525346, top_1: 0.609414, top_k: 0.825000, samples/s: 1358.646 1612736253.30093
train: epoch 78, iter 300, loss: 2.605824, top_1: 0.610039, top_k: 0.824961, samples/s: 1360.171 1612736272.1220496
train: epoch 78, iter 400, loss: 2.617126, top_1: 0.618594, top_k: 0.829258, samples/s: 1355.920 1612736291.0023582
train: epoch 78, iter 500, loss: 2.482225, top_1: 0.602187, top_k: 0.820937, samples/s: 1334.087 1612736310.1914318
train: epoch 78, iter 600, loss: 2.618815, top_1: 0.599531, top_k: 0.816758, samples/s: 1330.667 1612736329.4298766
train: epoch 78, iter 700, loss: 2.543491, top_1: 0.606953, top_k: 0.819688, samples/s: 1328.388 1612736348.701407
train: epoch 78, iter 800, loss: 2.544688, top_1: 0.603633, top_k: 0.817695, samples/s: 1329.493 1612736367.9567513
train: epoch 78, iter 900, loss: 2.429591, top_1: 0.607656, top_k: 0.821562, samples/s: 1333.463 1612736387.1549037
train: epoch 78, iter 1000, loss: 2.506277, top_1: 0.608906, top_k: 0.819844, samples/s: 1329.108 1612736406.4159214
train: epoch 78, iter 1100, loss: 2.540508, top_1: 0.605859, top_k: 0.818633, samples/s: 1323.308 1612736425.7614365
train: epoch 78, iter 1200, loss: 2.497586, top_1: 0.602266, top_k: 0.817109, samples/s: 1326.861 1612736445.0550342
train: epoch 78, iter 1300, loss: 2.561071, top_1: 0.604609, top_k: 0.820859, samples/s: 1329.098 1612736464.3163328
train: epoch 78, iter 1400, loss: 2.605100, top_1: 0.596836, top_k: 0.817617, samples/s: 1325.565 1612736483.6287444
train: epoch 78, iter 1500, loss: 2.548864, top_1: 0.598047, top_k: 0.816875, samples/s: 1329.555 1612736502.8833232
train: epoch 78, iter 1600, loss: 2.495565, top_1: 0.598281, top_k: 0.815156, samples/s: 1330.720 1612736522.1210315
train: epoch 78, iter 1700, loss: 2.668488, top_1: 0.602773, top_k: 0.816367, samples/s: 1331.840 1612736541.3425741
train: epoch 78, iter 1800, loss: 2.764989, top_1: 0.597695, top_k: 0.817578, samples/s: 1325.329 1612736560.6585107
train: epoch 78, iter 1900, loss: 2.925997, top_1: 0.599141, top_k: 0.816016, samples/s: 1332.797 1612736579.8663156
train: epoch 78, iter 2000, loss: 2.623477, top_1: 0.598984, top_k: 0.815898, samples/s: 1333.142 1612736599.069038
train: epoch 78, iter 2100, loss: 2.600028, top_1: 0.599727, top_k: 0.816523, samples/s: 1327.493 1612736618.3535511
train: epoch 78, iter 2200, loss: 2.851920, top_1: 0.592578, top_k: 0.815117, samples/s: 1327.097 1612736637.643735
train: epoch 78, iter 2300, loss: 2.669553, top_1: 0.599453, top_k: 0.812227, samples/s: 1329.028 1612736656.9059026
train: epoch 78, iter 2400, loss: 2.778498, top_1: 0.599219, top_k: 0.814023, samples/s: 1331.546 1612736676.13167
train: epoch 78, iter 2500, loss: 2.551799, top_1: 0.593477, top_k: 0.810664, samples/s: 1322.864 1612736695.4836283
train: epoch 78, iter 2600, loss: 2.750081, top_1: 0.591953, top_k: 0.809141, samples/s: 1332.613 1612736714.6940525
train: epoch 78, iter 2700, loss: 2.555567, top_1: 0.601719, top_k: 0.821914, samples/s: 1323.780 1612736734.03259
train: epoch 78, iter 2800, loss: 2.729005, top_1: 0.605352, top_k: 0.819609, samples/s: 1331.263 1612736753.2625413
train: epoch 78, iter 2900, loss: 2.766896, top_1: 0.606641, top_k: 0.818594, samples/s: 1332.067 1612736772.4807096
train: epoch 78, iter 3000, loss: 2.604719, top_1: 0.593555, top_k: 0.813281, samples/s: 1332.787 1612736791.6886334
train: epoch 78, iter 3100, loss: 2.510038, top_1: 0.600117, top_k: 0.816133, samples/s: 1332.745 1612736810.897076
train: epoch 78, iter 3200, loss: 2.651387, top_1: 0.603437, top_k: 0.820703, samples/s: 1332.363 1612736830.1110458
train: epoch 78, iter 3300, loss: 2.649538, top_1: 0.598945, top_k: 0.816523, samples/s: 1328.843 1612736849.3759286
train: epoch 78, iter 3400, loss: 2.640180, top_1: 0.597656, top_k: 0.813477, samples/s: 1324.281 1612736868.707118
train: epoch 78, iter 3500, loss: 2.523409, top_1: 0.600664, top_k: 0.814414, samples/s: 1332.665 1612736887.9167526
train: epoch 78, iter 3600, loss: 2.637870, top_1: 0.596055, top_k: 0.813711, samples/s: 1332.065 1612736907.1351137
train: epoch 78, iter 3700, loss: 2.647970, top_1: 0.596641, top_k: 0.813555, samples/s: 1331.339 1612736926.363853
train: epoch 78, iter 3800, loss: 2.800605, top_1: 0.600820, top_k: 0.817852, samples/s: 1332.244 1612736945.5795023
train: epoch 78, iter 3900, loss: 2.505748, top_1: 0.596211, top_k: 0.816914, samples/s: 1331.263 1612736964.8093517
train: epoch 78, iter 4000, loss: 2.573942, top_1: 0.598516, top_k: 0.815352, samples/s: 1331.243 1612736984.039493
train: epoch 78, iter 4100, loss: 2.884924, top_1: 0.600859, top_k: 0.811445, samples/s: 1322.727 1612737003.3934534
train: epoch 78, iter 4200, loss: 2.689682, top_1: 0.595430, top_k: 0.813945, samples/s: 1338.858 1612737022.5142856
train: epoch 78, iter 4300, loss: 2.853262, top_1: 0.600586, top_k: 0.819492, samples/s: 1329.101 1612737041.775359
train: epoch 78, iter 4400, loss: 2.586942, top_1: 0.594805, top_k: 0.816016, samples/s: 1329.793 1612737061.0265172
train: epoch 78, iter 4500, loss: 2.613770, top_1: 0.603125, top_k: 0.819336, samples/s: 1329.353 1612737080.2839754
train: epoch 78, iter 4600, loss: 2.553216, top_1: 0.601562, top_k: 0.815742, samples/s: 1329.393 1612737099.5409381
train: epoch 78, iter 4700, loss: 2.695058, top_1: 0.601758, top_k: 0.820156, samples/s: 1325.669 1612737118.851928
train: epoch 78, iter 4800, loss: 2.775752, top_1: 0.595156, top_k: 0.814336, samples/s: 1335.293 1612737138.0237753
train: epoch 78, iter 4900, loss: 2.568655, top_1: 0.595625, top_k: 0.817500, samples/s: 1325.167 1612737157.3420892
train: epoch 78, iter 5000, loss: 2.453817, top_1: 0.601602, top_k: 0.818711, samples/s: 1334.185 1612737176.5298252
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_78.
validation: epoch 78, iter 195, top_1: 0.642308, top_k: 0.860016, samples/s: 2700.519 1612737195.593555
train: epoch 79, iter 100, loss: 2.700606, top_1: 0.608789, top_k: 0.820742, samples/s: 1355.086 1612737230.373061
train: epoch 79, iter 200, loss: 2.578665, top_1: 0.604805, top_k: 0.821562, samples/s: 1356.757 1612737249.2418528
train: epoch 79, iter 300, loss: 2.472983, top_1: 0.605273, top_k: 0.824297, samples/s: 1360.177 1612737268.0627036
train: epoch 79, iter 400, loss: 2.753540, top_1: 0.612578, top_k: 0.826875, samples/s: 1346.146 1612737287.0799165
train: epoch 79, iter 500, loss: 2.584538, top_1: 0.604570, top_k: 0.819375, samples/s: 1330.826 1612737306.3160625
train: epoch 79, iter 600, loss: 2.603617, top_1: 0.609219, top_k: 0.820977, samples/s: 1325.209 1612737325.6338983
train: epoch 79, iter 700, loss: 2.736683, top_1: 0.609531, top_k: 0.825117, samples/s: 1330.255 1612737344.8782613
train: epoch 79, iter 800, loss: 2.703499, top_1: 0.601094, top_k: 0.818945, samples/s: 1328.322 1612737364.1506245
train: epoch 79, iter 900, loss: 2.484863, top_1: 0.610938, top_k: 0.822812, samples/s: 1336.269 1612737383.308491
train: epoch 79, iter 1000, loss: 2.547242, top_1: 0.606641, top_k: 0.821172, samples/s: 1328.324 1612737402.5808556
train: epoch 79, iter 1100, loss: 2.553660, top_1: 0.602539, top_k: 0.820820, samples/s: 1331.882 1612737421.8017707
train: epoch 79, iter 1200, loss: 2.640388, top_1: 0.604883, top_k: 0.819922, samples/s: 1330.608 1612737441.0411394
train: epoch 79, iter 1300, loss: 2.610652, top_1: 0.598437, top_k: 0.819336, samples/s: 1328.019 1612737460.3179414
train: epoch 79, iter 1400, loss: 2.649302, top_1: 0.604844, top_k: 0.820820, samples/s: 1329.529 1612737479.5729551
train: epoch 79, iter 1500, loss: 2.698664, top_1: 0.598477, top_k: 0.815898, samples/s: 1330.705 1612737498.8109803
train: epoch 79, iter 1600, loss: 2.593328, top_1: 0.605625, top_k: 0.822539, samples/s: 1328.929 1612737518.0744379
train: epoch 79, iter 1700, loss: 2.634209, top_1: 0.602617, top_k: 0.818594, samples/s: 1328.718 1612737537.3411746
train: epoch 79, iter 1800, loss: 2.571176, top_1: 0.601953, top_k: 0.817969, samples/s: 1330.925 1612737556.5758643
train: epoch 79, iter 1900, loss: 2.436526, top_1: 0.603984, top_k: 0.816992, samples/s: 1330.862 1612737575.8115628
train: epoch 79, iter 2000, loss: 2.534706, top_1: 0.599727, top_k: 0.818633, samples/s: 1329.466 1612737595.0674255
train: epoch 79, iter 2100, loss: 2.599998, top_1: 0.610039, top_k: 0.821367, samples/s: 1330.289 1612737614.3113372
train: epoch 79, iter 2200, loss: 2.622312, top_1: 0.595508, top_k: 0.815469, samples/s: 1328.739 1612737633.5778244
train: epoch 79, iter 2300, loss: 2.781882, top_1: 0.602539, top_k: 0.818594, samples/s: 1330.193 1612737652.8230274
train: epoch 79, iter 2400, loss: 2.717191, top_1: 0.598906, top_k: 0.817148, samples/s: 1334.350 1612737672.0084667
train: epoch 79, iter 2500, loss: 2.784209, top_1: 0.598086, top_k: 0.819492, samples/s: 1327.475 1612737691.2931192
train: epoch 79, iter 2600, loss: 2.573885, top_1: 0.604062, top_k: 0.818555, samples/s: 1327.868 1612737710.5721416
train: epoch 79, iter 2700, loss: 2.743049, top_1: 0.600703, top_k: 0.820508, samples/s: 1342.533 1612737729.6405673
train: epoch 79, iter 2800, loss: 2.639125, top_1: 0.600898, top_k: 0.815352, samples/s: 1319.620 1612737749.0400963
train: epoch 79, iter 2900, loss: 2.449981, top_1: 0.603047, top_k: 0.817383, samples/s: 1328.474 1612737768.3103876
train: epoch 79, iter 3000, loss: 2.588097, top_1: 0.599727, top_k: 0.813320, samples/s: 1334.442 1612737787.4944217
train: epoch 79, iter 3100, loss: 2.654986, top_1: 0.600508, top_k: 0.819727, samples/s: 1325.699 1612737806.8050318
train: epoch 79, iter 3200, loss: 2.697197, top_1: 0.595547, top_k: 0.812422, samples/s: 1336.585 1612737825.9582372
train: epoch 79, iter 3300, loss: 2.640573, top_1: 0.602969, top_k: 0.818711, samples/s: 1321.115 1612737845.3358257
train: epoch 79, iter 3400, loss: 2.607345, top_1: 0.601992, top_k: 0.819922, samples/s: 1331.461 1612737864.562906
train: epoch 79, iter 3500, loss: 2.607259, top_1: 0.592461, top_k: 0.814375, samples/s: 1332.674 1612737883.772393
train: epoch 79, iter 3600, loss: 2.596988, top_1: 0.604023, top_k: 0.820469, samples/s: 1333.303 1612737902.972756
train: epoch 79, iter 3700, loss: 2.572359, top_1: 0.601641, top_k: 0.816328, samples/s: 1334.732 1612737922.152631
train: epoch 79, iter 3800, loss: 2.631342, top_1: 0.598242, top_k: 0.815742, samples/s: 1330.113 1612737941.39918
train: epoch 79, iter 3900, loss: 2.635355, top_1: 0.599844, top_k: 0.815156, samples/s: 1329.480 1612737960.654756
train: epoch 79, iter 4000, loss: 2.679472, top_1: 0.599570, top_k: 0.821953, samples/s: 1327.604 1612737979.93762
train: epoch 79, iter 4100, loss: 2.318429, top_1: 0.595664, top_k: 0.816602, samples/s: 1332.784 1612737999.1455975
train: epoch 79, iter 4200, loss: 2.657851, top_1: 0.602031, top_k: 0.817109, samples/s: 1333.165 1612738018.3479993
train: epoch 79, iter 4300, loss: 2.719755, top_1: 0.598477, top_k: 0.818125, samples/s: 1333.235 1612738037.5493665
train: epoch 79, iter 4400, loss: 2.835030, top_1: 0.595234, top_k: 0.814570, samples/s: 1328.700 1612738056.816427
train: epoch 79, iter 4500, loss: 2.738069, top_1: 0.602812, top_k: 0.818711, samples/s: 1333.229 1612738076.0179162
train: epoch 79, iter 4600, loss: 2.782135, top_1: 0.597539, top_k: 0.814844, samples/s: 1330.895 1612738095.253105
train: epoch 79, iter 4700, loss: 2.558197, top_1: 0.592773, top_k: 0.813945, samples/s: 1329.452 1612738114.509067
train: epoch 79, iter 4800, loss: 2.422007, top_1: 0.601367, top_k: 0.816641, samples/s: 1335.148 1612738133.6830842
train: epoch 79, iter 4900, loss: 2.676886, top_1: 0.599570, top_k: 0.816562, samples/s: 1331.497 1612738152.9095528
train: epoch 79, iter 5000, loss: 2.525919, top_1: 0.602109, top_k: 0.817266, samples/s: 1329.458 1612738172.1655064
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_79.
validation: epoch 79, iter 195, top_1: 0.652905, top_k: 0.869111, samples/s: 2755.901 1612738190.8593252
train: epoch 80, iter 100, loss: 2.511993, top_1: 0.612930, top_k: 0.826953, samples/s: 1358.775 1612738225.5946703
train: epoch 80, iter 200, loss: 2.431479, top_1: 0.610039, top_k: 0.824883, samples/s: 1357.967 1612738244.446457
train: epoch 80, iter 300, loss: 2.462988, top_1: 0.604688, top_k: 0.821758, samples/s: 1362.712 1612738263.232516
train: epoch 80, iter 400, loss: 2.533926, top_1: 0.611016, top_k: 0.824375, samples/s: 1345.134 1612738282.2639997
train: epoch 80, iter 500, loss: 2.441154, top_1: 0.608047, top_k: 0.821836, samples/s: 1338.345 1612738301.3922157
train: epoch 80, iter 600, loss: 2.553934, top_1: 0.610195, top_k: 0.824453, samples/s: 1312.759 1612738320.8930755
train: epoch 80, iter 700, loss: 2.556699, top_1: 0.612383, top_k: 0.827891, samples/s: 1340.405 1612738339.9918356
train: epoch 80, iter 800, loss: 2.699165, top_1: 0.608281, top_k: 0.822500, samples/s: 1329.357 1612738359.2492213
train: epoch 80, iter 900, loss: 2.727174, top_1: 0.606367, top_k: 0.821992, samples/s: 1331.215 1612738378.479729
train: epoch 80, iter 1000, loss: 2.678405, top_1: 0.602461, top_k: 0.819648, samples/s: 1332.594 1612738397.6904166
train: epoch 80, iter 1100, loss: 2.792198, top_1: 0.607852, top_k: 0.826484, samples/s: 1334.016 1612738416.880527
train: epoch 80, iter 1200, loss: 2.810262, top_1: 0.603242, top_k: 0.819570, samples/s: 1326.816 1612738436.1748636
train: epoch 80, iter 1300, loss: 2.491822, top_1: 0.605938, top_k: 0.823711, samples/s: 1324.534 1612738455.5024111
train: epoch 80, iter 1400, loss: 2.645416, top_1: 0.603750, top_k: 0.818711, samples/s: 1326.708 1612738474.7982857
train: epoch 80, iter 1500, loss: 2.689811, top_1: 0.604297, top_k: 0.820039, samples/s: 1335.641 1612738493.965109
train: epoch 80, iter 1600, loss: 2.665698, top_1: 0.604883, top_k: 0.821797, samples/s: 1329.300 1612738513.2233703
train: epoch 80, iter 1700, loss: 2.548577, top_1: 0.603906, top_k: 0.820781, samples/s: 1332.649 1612738532.4332478
train: epoch 80, iter 1800, loss: 2.583699, top_1: 0.608672, top_k: 0.821016, samples/s: 1330.362 1612738551.6761036
train: epoch 80, iter 1900, loss: 2.817247, top_1: 0.606797, top_k: 0.822656, samples/s: 1322.799 1612738571.0290604
train: epoch 80, iter 2000, loss: 2.553052, top_1: 0.606602, top_k: 0.827031, samples/s: 1329.662 1612738590.2820413
train: epoch 80, iter 2100, loss: 2.554432, top_1: 0.606328, top_k: 0.822930, samples/s: 1326.873 1612738609.575554
train: epoch 80, iter 2200, loss: 2.522595, top_1: 0.606797, top_k: 0.819922, samples/s: 1333.549 1612738628.772389
train: epoch 80, iter 2300, loss: 2.649725, top_1: 0.605586, top_k: 0.822266, samples/s: 1328.909 1612738648.0363023
train: epoch 80, iter 2400, loss: 2.643328, top_1: 0.606367, top_k: 0.819531, samples/s: 1327.084 1612738667.3267229
train: epoch 80, iter 2500, loss: 2.754277, top_1: 0.603867, top_k: 0.821055, samples/s: 1335.692 1612738686.4928353
train: epoch 80, iter 2600, loss: 2.509131, top_1: 0.604766, top_k: 0.819453, samples/s: 1333.682 1612738705.6878266
train: epoch 80, iter 2700, loss: 2.557193, top_1: 0.601523, top_k: 0.821758, samples/s: 1332.528 1612738724.899507
train: epoch 80, iter 2800, loss: 2.752583, top_1: 0.602617, top_k: 0.820234, samples/s: 1329.917 1612738744.148709
train: epoch 80, iter 2900, loss: 2.817872, top_1: 0.604141, top_k: 0.820039, samples/s: 1326.175 1612738763.4523766
train: epoch 80, iter 3000, loss: 2.685716, top_1: 0.601562, top_k: 0.817656, samples/s: 1337.414 1612738782.59377
train: epoch 80, iter 3100, loss: 2.546275, top_1: 0.604297, top_k: 0.819688, samples/s: 1325.169 1612738801.9121003
train: epoch 80, iter 3200, loss: 2.673862, top_1: 0.607773, top_k: 0.819531, samples/s: 1328.507 1612738821.1818466
train: epoch 80, iter 3300, loss: 2.536772, top_1: 0.604102, top_k: 0.817344, samples/s: 1328.601 1612738840.4501913
train: epoch 80, iter 3400, loss: 2.754943, top_1: 0.609023, top_k: 0.824414, samples/s: 1331.480 1612738859.6769123
train: epoch 80, iter 3500, loss: 2.684824, top_1: 0.600938, top_k: 0.819297, samples/s: 1331.784 1612738878.8993149
train: epoch 80, iter 3600, loss: 2.502332, top_1: 0.601094, top_k: 0.818984, samples/s: 1330.639 1612738898.1381505
train: epoch 80, iter 3700, loss: 2.610074, top_1: 0.603437, top_k: 0.822031, samples/s: 1329.336 1612738917.3959298
train: epoch 80, iter 3800, loss: 2.600251, top_1: 0.599727, top_k: 0.816875, samples/s: 1318.924 1612738936.8057907
train: epoch 80, iter 3900, loss: 2.738693, top_1: 0.600547, top_k: 0.817031, samples/s: 1338.027 1612738955.9383724
train: epoch 80, iter 4000, loss: 2.615592, top_1: 0.606523, top_k: 0.820234, samples/s: 1325.629 1612738975.2498708
train: epoch 80, iter 4100, loss: 2.595851, top_1: 0.597617, top_k: 0.817266, samples/s: 1333.541 1612738994.4468722
train: epoch 80, iter 4200, loss: 2.558265, top_1: 0.604648, top_k: 0.819922, samples/s: 1329.003 1612739013.7094262
train: epoch 80, iter 4300, loss: 2.729512, top_1: 0.603125, top_k: 0.817266, samples/s: 1335.900 1612739032.872582
train: epoch 80, iter 4400, loss: 2.803020, top_1: 0.603906, top_k: 0.818711, samples/s: 1326.823 1612739052.1667635
train: epoch 80, iter 4500, loss: 2.608671, top_1: 0.597812, top_k: 0.816797, samples/s: 1331.866 1612739071.3878992
train: epoch 80, iter 4600, loss: 2.607236, top_1: 0.606055, top_k: 0.816758, samples/s: 1338.674 1612739090.5112996
train: epoch 80, iter 4700, loss: 2.504749, top_1: 0.598633, top_k: 0.819453, samples/s: 1327.546 1612739109.7950685
train: epoch 80, iter 4800, loss: 2.843382, top_1: 0.599766, top_k: 0.815078, samples/s: 1326.274 1612739129.0973222
train: epoch 80, iter 4900, loss: 2.589563, top_1: 0.593672, top_k: 0.813359, samples/s: 1331.413 1612739148.324879
train: epoch 80, iter 5000, loss: 2.674842, top_1: 0.604961, top_k: 0.821641, samples/s: 1331.378 1612739167.5530763
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_80.
validation: epoch 80, iter 195, top_1: 0.648738, top_k: 0.866106, samples/s: 2711.791 1612739186.5580108
train: epoch 81, iter 100, loss: 2.668538, top_1: 0.621953, top_k: 0.831367, samples/s: 1357.471 1612739222.5348363
train: epoch 81, iter 200, loss: 2.659403, top_1: 0.615273, top_k: 0.825234, samples/s: 1360.005 1612739241.3582594
train: epoch 81, iter 300, loss: 2.580150, top_1: 0.610000, top_k: 0.823320, samples/s: 1359.804 1612739260.1845753
train: epoch 81, iter 400, loss: 2.504781, top_1: 0.611211, top_k: 0.826289, samples/s: 1346.138 1612739279.2019324
train: epoch 81, iter 500, loss: 2.594429, top_1: 0.614883, top_k: 0.826445, samples/s: 1329.309 1612739298.4599674
train: epoch 81, iter 600, loss: 2.629969, top_1: 0.610625, top_k: 0.825273, samples/s: 1326.017 1612739317.765904
train: epoch 81, iter 700, loss: 2.605828, top_1: 0.610898, top_k: 0.827852, samples/s: 1331.557 1612739336.9915926
train: epoch 81, iter 800, loss: 2.512422, top_1: 0.607891, top_k: 0.823203, samples/s: 1324.934 1612739356.3132997
train: epoch 81, iter 900, loss: 2.782263, top_1: 0.604844, top_k: 0.825586, samples/s: 1329.947 1612739375.5622787
train: epoch 81, iter 1000, loss: 2.547287, top_1: 0.603242, top_k: 0.822227, samples/s: 1323.507 1612739394.904717
train: epoch 81, iter 1100, loss: 2.642104, top_1: 0.606367, top_k: 0.816445, samples/s: 1320.474 1612739414.291649
train: epoch 81, iter 1200, loss: 2.560405, top_1: 0.610078, top_k: 0.825039, samples/s: 1327.939 1612739433.5696592
train: epoch 81, iter 1300, loss: 2.592062, top_1: 0.611758, top_k: 0.823008, samples/s: 1328.922 1612739452.8334663
train: epoch 81, iter 1400, loss: 2.693892, top_1: 0.608398, top_k: 0.826250, samples/s: 1322.534 1612739472.1901565
train: epoch 81, iter 1500, loss: 2.829324, top_1: 0.605859, top_k: 0.821484, samples/s: 1330.200 1612739491.4353738
train: epoch 81, iter 1600, loss: 2.565463, top_1: 0.608945, top_k: 0.821172, samples/s: 1327.710 1612739510.7167196
train: epoch 81, iter 1700, loss: 2.816731, top_1: 0.609141, top_k: 0.825859, samples/s: 1329.828 1612739529.967315
train: epoch 81, iter 1800, loss: 2.709863, top_1: 0.605430, top_k: 0.821953, samples/s: 1328.761 1612739549.2334082
train: epoch 81, iter 1900, loss: 2.494997, top_1: 0.606992, top_k: 0.821797, samples/s: 1326.021 1612739568.5393362
train: epoch 81, iter 2000, loss: 2.724936, top_1: 0.607031, top_k: 0.821016, samples/s: 1322.943 1612739587.8901212
train: epoch 81, iter 2100, loss: 2.574884, top_1: 0.605898, top_k: 0.820156, samples/s: 1323.983 1612739607.2256963
train: epoch 81, iter 2200, loss: 2.595213, top_1: 0.604297, top_k: 0.821484, samples/s: 1333.928 1612739626.4171321
train: epoch 81, iter 2300, loss: 2.644734, top_1: 0.603203, top_k: 0.819102, samples/s: 1327.122 1612739645.7069523
train: epoch 81, iter 2400, loss: 2.655323, top_1: 0.604062, top_k: 0.818438, samples/s: 1326.058 1612739665.01232
train: epoch 81, iter 2500, loss: 2.645922, top_1: 0.602383, top_k: 0.818984, samples/s: 1328.732 1612739684.2787826
train: epoch 81, iter 2600, loss: 2.593638, top_1: 0.603984, top_k: 0.823281, samples/s: 1326.462 1612739703.5782633
train: epoch 81, iter 2700, loss: 2.909986, top_1: 0.605898, top_k: 0.819023, samples/s: 1326.267 1612739722.8805916
train: epoch 81, iter 2800, loss: 2.556819, top_1: 0.606133, top_k: 0.821680, samples/s: 1324.005 1612739742.2158384
train: epoch 81, iter 2900, loss: 2.886454, top_1: 0.602852, top_k: 0.819102, samples/s: 1335.653 1612739761.38246
train: epoch 81, iter 3000, loss: 2.479011, top_1: 0.602500, top_k: 0.818281, samples/s: 1329.788 1612739780.6336906
train: epoch 81, iter 3100, loss: 2.721754, top_1: 0.607891, top_k: 0.817891, samples/s: 1328.331 1612739799.9059472
train: epoch 81, iter 3200, loss: 2.439876, top_1: 0.604844, top_k: 0.819258, samples/s: 1330.413 1612739819.1480982
train: epoch 81, iter 3300, loss: 2.587347, top_1: 0.608906, top_k: 0.820625, samples/s: 1328.582 1612739838.4167857
train: epoch 81, iter 3400, loss: 2.809623, top_1: 0.597891, top_k: 0.821172, samples/s: 1328.454 1612739857.6872973
train: epoch 81, iter 3500, loss: 2.780928, top_1: 0.598984, top_k: 0.817187, samples/s: 1327.699 1612739876.9688387
train: epoch 81, iter 3600, loss: 2.632621, top_1: 0.601953, top_k: 0.815820, samples/s: 1329.852 1612739896.2190535
train: epoch 81, iter 3700, loss: 2.687771, top_1: 0.604414, top_k: 0.818477, samples/s: 1323.196 1612739915.566116
train: epoch 81, iter 3800, loss: 2.575657, top_1: 0.600117, top_k: 0.818828, samples/s: 1330.765 1612739934.8032694
train: epoch 81, iter 3900, loss: 2.572858, top_1: 0.603398, top_k: 0.819141, samples/s: 1330.090 1612739954.0499833
train: epoch 81, iter 4000, loss: 2.815353, top_1: 0.600781, top_k: 0.817266, samples/s: 1325.296 1612739973.3664663
train: epoch 81, iter 4100, loss: 2.551673, top_1: 0.603477, top_k: 0.819844, samples/s: 1331.675 1612739992.5903316
train: epoch 81, iter 4200, loss: 2.589592, top_1: 0.601953, top_k: 0.820352, samples/s: 1333.989 1612740011.7808847
train: epoch 81, iter 4300, loss: 2.601577, top_1: 0.605195, top_k: 0.817930, samples/s: 1323.411 1612740031.1248384
train: epoch 81, iter 4400, loss: 2.346883, top_1: 0.595625, top_k: 0.816328, samples/s: 1327.925 1612740050.4030607
train: epoch 81, iter 4500, loss: 2.635243, top_1: 0.604492, top_k: 0.817344, samples/s: 1328.661 1612740069.6705973
train: epoch 81, iter 4600, loss: 2.671720, top_1: 0.601367, top_k: 0.817031, samples/s: 1329.834 1612740088.921188
train: epoch 81, iter 4700, loss: 2.662462, top_1: 0.599805, top_k: 0.817305, samples/s: 1327.483 1612740108.2058504
train: epoch 81, iter 4800, loss: 2.429928, top_1: 0.606523, top_k: 0.818984, samples/s: 1325.634 1612740127.517237
train: epoch 81, iter 4900, loss: 2.799983, top_1: 0.602031, top_k: 0.818984, samples/s: 1334.168 1612740146.7052844
train: epoch 81, iter 5000, loss: 2.423443, top_1: 0.610430, top_k: 0.823750, samples/s: 1329.284 1612740165.963761
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_81.
validation: epoch 81, iter 195, top_1: 0.653265, top_k: 0.869211, samples/s: 2831.314 1612740184.1648586
train: epoch 82, iter 100, loss: 2.623206, top_1: 0.615742, top_k: 0.827578, samples/s: 1360.604 1612740219.296089
train: epoch 82, iter 200, loss: 2.720360, top_1: 0.612891, top_k: 0.822930, samples/s: 1354.996 1612740238.18907
train: epoch 82, iter 300, loss: 2.860940, top_1: 0.607617, top_k: 0.822617, samples/s: 1367.464 1612740256.9099035
train: epoch 82, iter 400, loss: 2.598333, top_1: 0.614141, top_k: 0.828281, samples/s: 1348.873 1612740275.8886664
train: epoch 82, iter 500, loss: 2.504656, top_1: 0.613984, top_k: 0.825820, samples/s: 1330.082 1612740295.1356592
train: epoch 82, iter 600, loss: 2.773334, top_1: 0.606641, top_k: 0.823672, samples/s: 1329.065 1612740314.3973122
train: epoch 82, iter 700, loss: 2.708803, top_1: 0.604961, top_k: 0.822031, samples/s: 1332.926 1612740333.6032615
train: epoch 82, iter 800, loss: 2.698465, top_1: 0.610703, top_k: 0.824883, samples/s: 1328.621 1612740352.871267
train: epoch 82, iter 900, loss: 2.597649, top_1: 0.616992, top_k: 0.827734, samples/s: 1331.945 1612740372.0912626
train: epoch 82, iter 1000, loss: 2.765600, top_1: 0.601484, top_k: 0.821250, samples/s: 1331.639 1612740391.3157427
train: epoch 82, iter 1100, loss: 2.694178, top_1: 0.605547, top_k: 0.822773, samples/s: 1333.962 1612740410.506684
train: epoch 82, iter 1200, loss: 2.454873, top_1: 0.607734, top_k: 0.824180, samples/s: 1330.856 1612740429.742443
train: epoch 82, iter 1300, loss: 2.495110, top_1: 0.615391, top_k: 0.823477, samples/s: 1331.388 1612740448.9704914
train: epoch 82, iter 1400, loss: 2.710441, top_1: 0.615742, top_k: 0.824922, samples/s: 1328.664 1612740468.2379706
train: epoch 82, iter 1500, loss: 2.682334, top_1: 0.607891, top_k: 0.820937, samples/s: 1332.090 1612740487.4559045
train: epoch 82, iter 1600, loss: 2.588953, top_1: 0.600234, top_k: 0.818789, samples/s: 1330.579 1612740506.6955879
train: epoch 82, iter 1700, loss: 2.687807, top_1: 0.605820, top_k: 0.820430, samples/s: 1331.916 1612740525.9160514
train: epoch 82, iter 1800, loss: 2.607915, top_1: 0.607461, top_k: 0.820898, samples/s: 1330.303 1612740545.1598313
train: epoch 82, iter 1900, loss: 2.517059, top_1: 0.603828, top_k: 0.821484, samples/s: 1328.959 1612740564.422994
train: epoch 82, iter 2000, loss: 2.623483, top_1: 0.603711, top_k: 0.819883, samples/s: 1332.421 1612740583.6361349
train: epoch 82, iter 2100, loss: 2.396813, top_1: 0.609375, top_k: 0.822734, samples/s: 1333.130 1612740602.8390648
train: epoch 82, iter 2200, loss: 2.670612, top_1: 0.605078, top_k: 0.820664, samples/s: 1330.786 1612740622.075829
train: epoch 82, iter 2300, loss: 2.692867, top_1: 0.612539, top_k: 0.826328, samples/s: 1332.845 1612740641.2828267
train: epoch 82, iter 2400, loss: 2.501565, top_1: 0.601641, top_k: 0.818945, samples/s: 1329.969 1612740660.5314355
train: epoch 82, iter 2500, loss: 2.706144, top_1: 0.606836, top_k: 0.823164, samples/s: 1333.057 1612740679.7354233
train: epoch 82, iter 2600, loss: 2.516795, top_1: 0.606094, top_k: 0.821602, samples/s: 1329.985 1612740698.983744
train: epoch 82, iter 2700, loss: 2.557305, top_1: 0.605156, top_k: 0.820469, samples/s: 1326.436 1612740718.2836695
train: epoch 82, iter 2800, loss: 2.526159, top_1: 0.606953, top_k: 0.826562, samples/s: 1335.185 1612740737.4569516
train: epoch 82, iter 2900, loss: 2.585439, top_1: 0.607422, top_k: 0.821914, samples/s: 1329.289 1612740756.7153552
train: epoch 82, iter 3000, loss: 2.537461, top_1: 0.605742, top_k: 0.818945, samples/s: 1330.323 1612740775.9588048
train: epoch 82, iter 3100, loss: 2.477527, top_1: 0.609531, top_k: 0.823672, samples/s: 1323.606 1612740795.299958
train: epoch 82, iter 3200, loss: 2.737116, top_1: 0.606367, top_k: 0.820430, samples/s: 1338.719 1612740814.4226673
train: epoch 82, iter 3300, loss: 2.476926, top_1: 0.604570, top_k: 0.823711, samples/s: 1330.256 1612740833.667066
train: epoch 82, iter 3400, loss: 2.626234, top_1: 0.611094, top_k: 0.826719, samples/s: 1330.531 1612740852.9075341
train: epoch 82, iter 3500, loss: 2.750460, top_1: 0.606914, top_k: 0.822617, samples/s: 1329.559 1612740872.1620414
train: epoch 82, iter 3600, loss: 2.669351, top_1: 0.608594, top_k: 0.822969, samples/s: 1330.797 1612740891.3986533
train: epoch 82, iter 3700, loss: 2.795583, top_1: 0.602969, top_k: 0.817500, samples/s: 1336.666 1612740910.550747
train: epoch 82, iter 3800, loss: 2.799098, top_1: 0.604102, top_k: 0.819570, samples/s: 1327.086 1612740929.8411338
train: epoch 82, iter 3900, loss: 2.585095, top_1: 0.606055, top_k: 0.824141, samples/s: 1340.492 1612740948.93863
train: epoch 82, iter 4000, loss: 2.535258, top_1: 0.609648, top_k: 0.819727, samples/s: 1319.464 1612740968.340362
train: epoch 82, iter 4100, loss: 2.736554, top_1: 0.601641, top_k: 0.817773, samples/s: 1334.636 1612740987.5216577
train: epoch 82, iter 4200, loss: 2.794417, top_1: 0.610977, top_k: 0.822539, samples/s: 1334.217 1612741006.7089603
train: epoch 82, iter 4300, loss: 2.698704, top_1: 0.604219, top_k: 0.819453, samples/s: 1335.718 1612741025.8747225
train: epoch 82, iter 4400, loss: 2.620466, top_1: 0.604883, top_k: 0.819180, samples/s: 1329.360 1612741045.1321187
train: epoch 82, iter 4500, loss: 2.534540, top_1: 0.601406, top_k: 0.815234, samples/s: 1329.515 1612741064.387249
train: epoch 82, iter 4600, loss: 2.634487, top_1: 0.601758, top_k: 0.817383, samples/s: 1334.221 1612741083.5744119
train: epoch 82, iter 4700, loss: 2.798767, top_1: 0.601875, top_k: 0.820859, samples/s: 1323.109 1612741102.9227896
train: epoch 82, iter 4800, loss: 2.680960, top_1: 0.597148, top_k: 0.817266, samples/s: 1337.094 1612741122.0688267
train: epoch 82, iter 4900, loss: 2.780309, top_1: 0.604688, top_k: 0.814688, samples/s: 1329.183 1612741141.3287847
train: epoch 82, iter 5000, loss: 2.794747, top_1: 0.605742, top_k: 0.819805, samples/s: 1342.946 1612741160.3912992
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_82.
validation: epoch 82, iter 195, top_1: 0.653486, top_k: 0.869091, samples/s: 2853.100 1612741178.5376146
train: epoch 83, iter 100, loss: 2.590611, top_1: 0.613320, top_k: 0.826719, samples/s: 1358.628 1612741213.575545
train: epoch 83, iter 200, loss: 2.620747, top_1: 0.618945, top_k: 0.829336, samples/s: 1358.488 1612741232.4200084
train: epoch 83, iter 300, loss: 2.581976, top_1: 0.616211, top_k: 0.832031, samples/s: 1360.126 1612741251.2418082
train: epoch 83, iter 400, loss: 2.594316, top_1: 0.609375, top_k: 0.826367, samples/s: 1353.546 1612741270.1551518
train: epoch 83, iter 500, loss: 2.734096, top_1: 0.607852, top_k: 0.827891, samples/s: 1332.371 1612741289.3689103
train: epoch 83, iter 600, loss: 2.328884, top_1: 0.617500, top_k: 0.831562, samples/s: 1332.081 1612741308.5869935
train: epoch 83, iter 700, loss: 2.523787, top_1: 0.620977, top_k: 0.832500, samples/s: 1326.612 1612741327.8842995
train: epoch 83, iter 800, loss: 2.693767, top_1: 0.617695, top_k: 0.827383, samples/s: 1334.445 1612741347.0682182
train: epoch 83, iter 900, loss: 2.782212, top_1: 0.607148, top_k: 0.824883, samples/s: 1332.605 1612741366.2787094
train: epoch 83, iter 1000, loss: 2.626066, top_1: 0.608984, top_k: 0.824063, samples/s: 1336.466 1612741385.4337687
train: epoch 83, iter 1100, loss: 2.503199, top_1: 0.616055, top_k: 0.826406, samples/s: 1321.688 1612741404.8028896
train: epoch 83, iter 1200, loss: 2.735885, top_1: 0.609922, top_k: 0.825508, samples/s: 1334.402 1612741423.9875405
train: epoch 83, iter 1300, loss: 2.498665, top_1: 0.609062, top_k: 0.820039, samples/s: 1328.424 1612741443.2585976
train: epoch 83, iter 1400, loss: 2.521035, top_1: 0.604570, top_k: 0.820664, samples/s: 1332.564 1612741462.469547
train: epoch 83, iter 1500, loss: 2.492886, top_1: 0.607617, top_k: 0.823906, samples/s: 1338.588 1612741481.5941703
train: epoch 83, iter 1600, loss: 2.506163, top_1: 0.613984, top_k: 0.826953, samples/s: 1328.325 1612741500.8666468
train: epoch 83, iter 1700, loss: 2.775608, top_1: 0.610859, top_k: 0.823398, samples/s: 1328.964 1612741520.1297352
train: epoch 83, iter 1800, loss: 2.704069, top_1: 0.611563, top_k: 0.824375, samples/s: 1328.168 1612741539.4044168
train: epoch 83, iter 1900, loss: 2.670390, top_1: 0.606758, top_k: 0.821289, samples/s: 1339.691 1612741558.5133207
train: epoch 83, iter 2000, loss: 2.540026, top_1: 0.609453, top_k: 0.826250, samples/s: 1333.409 1612741577.7121835
train: epoch 83, iter 2100, loss: 2.673613, top_1: 0.607187, top_k: 0.822656, samples/s: 1332.365 1612741596.9262354
train: epoch 83, iter 2200, loss: 2.611316, top_1: 0.607422, top_k: 0.820664, samples/s: 1326.376 1612741616.2268229
train: epoch 83, iter 2300, loss: 2.460281, top_1: 0.608477, top_k: 0.824375, samples/s: 1335.744 1612741635.3922436
train: epoch 83, iter 2400, loss: 2.641878, top_1: 0.609883, top_k: 0.825078, samples/s: 1327.894 1612741654.6709344
train: epoch 83, iter 2500, loss: 2.769818, top_1: 0.608906, top_k: 0.823672, samples/s: 1335.227 1612741673.843658
train: epoch 83, iter 2600, loss: 2.563222, top_1: 0.609062, top_k: 0.825508, samples/s: 1325.572 1612741693.1560204
train: epoch 83, iter 2700, loss: 2.542027, top_1: 0.607148, top_k: 0.822969, samples/s: 1333.215 1612741712.3577688
train: epoch 83, iter 2800, loss: 2.577770, top_1: 0.615703, top_k: 0.825039, samples/s: 1331.472 1612741731.5845592
train: epoch 83, iter 2900, loss: 2.668511, top_1: 0.608945, top_k: 0.820664, samples/s: 1332.235 1612741750.8003871
train: epoch 83, iter 3000, loss: 2.525176, top_1: 0.605820, top_k: 0.823203, samples/s: 1333.534 1612741769.9976194
train: epoch 83, iter 3100, loss: 2.730038, top_1: 0.607148, top_k: 0.824336, samples/s: 1321.474 1612741789.3698707
train: epoch 83, iter 3200, loss: 2.422216, top_1: 0.604883, top_k: 0.818711, samples/s: 1340.351 1612741808.469289
train: epoch 83, iter 3300, loss: 2.752215, top_1: 0.610391, top_k: 0.822344, samples/s: 1337.074 1612741827.6156034
train: epoch 83, iter 3400, loss: 2.718811, top_1: 0.603320, top_k: 0.821328, samples/s: 1330.456 1612741846.8570883
train: epoch 83, iter 3500, loss: 2.742251, top_1: 0.613477, top_k: 0.824688, samples/s: 1330.542 1612741866.097461
train: epoch 83, iter 3600, loss: 2.795251, top_1: 0.611367, top_k: 0.824023, samples/s: 1331.068 1612741885.3300803
train: epoch 83, iter 3700, loss: 2.659915, top_1: 0.605742, top_k: 0.818789, samples/s: 1330.807 1612741904.566572
train: epoch 83, iter 3800, loss: 2.877419, top_1: 0.605352, top_k: 0.817656, samples/s: 1335.306 1612741923.7381444
train: epoch 83, iter 3900, loss: 2.586462, top_1: 0.603906, top_k: 0.818984, samples/s: 1334.025 1612741942.9281955
train: epoch 83, iter 4000, loss: 2.649621, top_1: 0.608633, top_k: 0.824727, samples/s: 1331.925 1612741962.1485868
train: epoch 83, iter 4100, loss: 2.626187, top_1: 0.607461, top_k: 0.821875, samples/s: 1333.987 1612741981.339113
train: epoch 83, iter 4200, loss: 2.658024, top_1: 0.605938, top_k: 0.821094, samples/s: 1332.313 1612742000.5537968
train: epoch 83, iter 4300, loss: 2.727855, top_1: 0.607461, top_k: 0.822852, samples/s: 1333.038 1612742019.7581527
train: epoch 83, iter 4400, loss: 2.450922, top_1: 0.601484, top_k: 0.818945, samples/s: 1335.280 1612742038.930115
train: epoch 83, iter 4500, loss: 2.674317, top_1: 0.603398, top_k: 0.820000, samples/s: 1337.954 1612742058.0638125
train: epoch 83, iter 4600, loss: 2.531430, top_1: 0.609961, top_k: 0.820508, samples/s: 1328.498 1612742077.3336675
train: epoch 83, iter 4700, loss: 2.442108, top_1: 0.612227, top_k: 0.825195, samples/s: 1326.663 1612742096.6302602
train: epoch 83, iter 4800, loss: 2.600495, top_1: 0.599570, top_k: 0.818594, samples/s: 1333.870 1612742115.8224823
train: epoch 83, iter 4900, loss: 2.651493, top_1: 0.601055, top_k: 0.818398, samples/s: 1337.785 1612742134.9585433
train: epoch 83, iter 5000, loss: 2.523042, top_1: 0.610781, top_k: 0.822812, samples/s: 1325.258 1612742154.2756126
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_83.
validation: epoch 83, iter 195, top_1: 0.656931, top_k: 0.869311, samples/s: 2802.952 1612742172.586461
train: epoch 84, iter 100, loss: 2.573647, top_1: 0.617969, top_k: 0.830859, samples/s: 1362.424 1612742207.5729415
train: epoch 84, iter 200, loss: 2.645769, top_1: 0.619336, top_k: 0.832695, samples/s: 1360.087 1612742226.3952937
train: epoch 84, iter 300, loss: 2.466542, top_1: 0.618125, top_k: 0.829805, samples/s: 1357.981 1612742245.2467885
train: epoch 84, iter 400, loss: 2.734769, top_1: 0.617383, top_k: 0.829453, samples/s: 1353.639 1612742264.15873
train: epoch 84, iter 500, loss: 2.647710, top_1: 0.615430, top_k: 0.826016, samples/s: 1329.185 1612742283.4186625
train: epoch 84, iter 600, loss: 2.911098, top_1: 0.613398, top_k: 0.826445, samples/s: 1329.730 1612742302.6707015
train: epoch 84, iter 700, loss: 2.473776, top_1: 0.618437, top_k: 0.832148, samples/s: 1328.469 1612742321.941017
train: epoch 84, iter 800, loss: 2.656593, top_1: 0.616289, top_k: 0.827695, samples/s: 1332.868 1612742341.1476734
train: epoch 84, iter 900, loss: 2.727825, top_1: 0.610547, top_k: 0.823594, samples/s: 1329.736 1612742360.399652
train: epoch 84, iter 1000, loss: 2.652290, top_1: 0.610273, top_k: 0.826680, samples/s: 1326.183 1612742379.7031326
train: epoch 84, iter 1100, loss: 2.563682, top_1: 0.619609, top_k: 0.830273, samples/s: 1331.273 1612742398.932923
train: epoch 84, iter 1200, loss: 2.387186, top_1: 0.619805, top_k: 0.826719, samples/s: 1332.080 1612742418.1510031
train: epoch 84, iter 1300, loss: 2.500546, top_1: 0.603242, top_k: 0.817344, samples/s: 1328.250 1612742437.4245105
train: epoch 84, iter 1400, loss: 2.489077, top_1: 0.617617, top_k: 0.830664, samples/s: 1331.061 1612742456.6571941
train: epoch 84, iter 1500, loss: 2.612648, top_1: 0.619687, top_k: 0.831406, samples/s: 1333.123 1612742475.8602648
train: epoch 84, iter 1600, loss: 2.494649, top_1: 0.604844, top_k: 0.818750, samples/s: 1331.782 1612742495.0825715
train: epoch 84, iter 1700, loss: 2.581449, top_1: 0.617148, top_k: 0.828281, samples/s: 1334.762 1612742514.2620144
train: epoch 84, iter 1800, loss: 2.784505, top_1: 0.611797, top_k: 0.825039, samples/s: 1334.394 1612742533.4468238
train: epoch 84, iter 1900, loss: 2.639191, top_1: 0.608789, top_k: 0.823672, samples/s: 1325.324 1612742552.76294
train: epoch 84, iter 2000, loss: 2.738784, top_1: 0.615508, top_k: 0.830664, samples/s: 1331.902 1612742571.9834743
train: epoch 84, iter 2100, loss: 2.633782, top_1: 0.610508, top_k: 0.824648, samples/s: 1337.804 1612742591.1192665
train: epoch 84, iter 2200, loss: 2.543303, top_1: 0.609102, top_k: 0.822812, samples/s: 1326.399 1612742610.4196405
train: epoch 84, iter 2300, loss: 2.658487, top_1: 0.612109, top_k: 0.828242, samples/s: 1329.931 1612742629.6687758
train: epoch 84, iter 2400, loss: 2.681164, top_1: 0.607852, top_k: 0.821562, samples/s: 1331.108 1612742648.9008515
train: epoch 84, iter 2500, loss: 2.308593, top_1: 0.607578, top_k: 0.823477, samples/s: 1337.844 1612742668.0361426
train: epoch 84, iter 2600, loss: 2.922939, top_1: 0.607031, top_k: 0.821719, samples/s: 1329.603 1612742687.2899907
train: epoch 84, iter 2700, loss: 2.603091, top_1: 0.604609, top_k: 0.823438, samples/s: 1335.314 1612742706.4615102
train: epoch 84, iter 2800, loss: 2.536361, top_1: 0.609023, top_k: 0.823828, samples/s: 1334.446 1612742725.6455462
train: epoch 84, iter 2900, loss: 2.683805, top_1: 0.610156, top_k: 0.826992, samples/s: 1327.869 1612742744.9245071
train: epoch 84, iter 3000, loss: 2.657847, top_1: 0.607344, top_k: 0.821680, samples/s: 1331.097 1612742764.1569335
train: epoch 84, iter 3100, loss: 2.881083, top_1: 0.603945, top_k: 0.820664, samples/s: 1332.593 1612742783.3674886
train: epoch 84, iter 3200, loss: 2.632065, top_1: 0.607227, top_k: 0.821914, samples/s: 1330.739 1612742802.6048825
train: epoch 84, iter 3300, loss: 2.615927, top_1: 0.603828, top_k: 0.820195, samples/s: 1333.612 1612742821.8009474
train: epoch 84, iter 3400, loss: 2.628098, top_1: 0.609414, top_k: 0.822070, samples/s: 1333.198 1612742841.0028176
train: epoch 84, iter 3500, loss: 2.537279, top_1: 0.615508, top_k: 0.823672, samples/s: 1330.363 1612742860.245656
train: epoch 84, iter 3600, loss: 2.440606, top_1: 0.607930, top_k: 0.822695, samples/s: 1333.053 1612742879.4497607
train: epoch 84, iter 3700, loss: 2.601778, top_1: 0.604453, top_k: 0.820703, samples/s: 1332.673 1612742898.6593978
train: epoch 84, iter 3800, loss: 2.545558, top_1: 0.612578, top_k: 0.827969, samples/s: 1333.323 1612742917.859371
train: epoch 84, iter 3900, loss: 2.520805, top_1: 0.607969, top_k: 0.821367, samples/s: 1332.292 1612742937.0743506
train: epoch 84, iter 4000, loss: 2.575455, top_1: 0.614141, top_k: 0.824883, samples/s: 1334.621 1612742956.2558193
train: epoch 84, iter 4100, loss: 2.861802, top_1: 0.605820, top_k: 0.820742, samples/s: 1327.865 1612742975.5350413
train: epoch 84, iter 4200, loss: 2.553385, top_1: 0.610117, top_k: 0.825586, samples/s: 1341.185 1612742994.622499
train: epoch 84, iter 4300, loss: 2.549615, top_1: 0.609375, top_k: 0.824219, samples/s: 1333.911 1612743013.8142605
train: epoch 84, iter 4400, loss: 2.690297, top_1: 0.607578, top_k: 0.826953, samples/s: 1333.490 1612743033.011984
train: epoch 84, iter 4500, loss: 2.643508, top_1: 0.613477, top_k: 0.827422, samples/s: 1330.368 1612743052.2547038
train: epoch 84, iter 4600, loss: 2.642323, top_1: 0.608008, top_k: 0.818320, samples/s: 1336.152 1612743071.4142826
train: epoch 84, iter 4700, loss: 2.574739, top_1: 0.609727, top_k: 0.822461, samples/s: 1334.153 1612743090.602467
train: epoch 84, iter 4800, loss: 2.783296, top_1: 0.602852, top_k: 0.820273, samples/s: 1334.533 1612743109.7851486
train: epoch 84, iter 4900, loss: 2.525270, top_1: 0.603711, top_k: 0.820859, samples/s: 1331.014 1612743129.0186403
train: epoch 84, iter 5000, loss: 2.544162, top_1: 0.613867, top_k: 0.827070, samples/s: 1333.714 1612743148.2131186
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_84.
validation: epoch 84, iter 195, top_1: 0.653786, top_k: 0.867308, samples/s: 2796.111 1612743166.6711252
train: epoch 85, iter 100, loss: 2.498848, top_1: 0.618594, top_k: 0.831211, samples/s: 1351.100 1612743202.0042193
train: epoch 85, iter 200, loss: 2.686293, top_1: 0.622344, top_k: 0.832969, samples/s: 1361.031 1612743220.8134284
train: epoch 85, iter 300, loss: 2.549456, top_1: 0.613320, top_k: 0.829453, samples/s: 1358.350 1612743239.6598883
train: epoch 85, iter 400, loss: 2.628369, top_1: 0.617070, top_k: 0.831445, samples/s: 1350.466 1612743258.6163034
train: epoch 85, iter 500, loss: 2.657253, top_1: 0.618437, top_k: 0.829180, samples/s: 1334.727 1612743277.7961907
train: epoch 85, iter 600, loss: 2.428668, top_1: 0.619570, top_k: 0.828711, samples/s: 1316.618 1612743297.2399757
train: epoch 85, iter 700, loss: 2.465763, top_1: 0.621250, top_k: 0.835000, samples/s: 1329.422 1612743316.4964418
train: epoch 85, iter 800, loss: 2.716417, top_1: 0.618984, top_k: 0.827344, samples/s: 1324.522 1612743335.824203
train: epoch 85, iter 900, loss: 2.613789, top_1: 0.614727, top_k: 0.829180, samples/s: 1329.213 1612743355.0837204
train: epoch 85, iter 1000, loss: 2.648774, top_1: 0.616328, top_k: 0.830742, samples/s: 1324.745 1612743374.4081974
train: epoch 85, iter 1100, loss: 2.509021, top_1: 0.614297, top_k: 0.829609, samples/s: 1330.741 1612743393.6455753
train: epoch 85, iter 1200, loss: 2.661956, top_1: 0.614258, top_k: 0.827109, samples/s: 1331.562 1612743412.8711278
train: epoch 85, iter 1300, loss: 2.607856, top_1: 0.612266, top_k: 0.827539, samples/s: 1321.566 1612743432.2421215
train: epoch 85, iter 1400, loss: 2.668795, top_1: 0.614766, top_k: 0.828906, samples/s: 1326.019 1612743451.5479782
train: epoch 85, iter 1500, loss: 2.599231, top_1: 0.612422, top_k: 0.825313, samples/s: 1331.410 1612743470.7757475
train: epoch 85, iter 1600, loss: 2.641804, top_1: 0.614141, top_k: 0.827969, samples/s: 1325.162 1612743490.0941937
train: epoch 85, iter 1700, loss: 2.817388, top_1: 0.615078, top_k: 0.829336, samples/s: 1323.385 1612743509.438443
train: epoch 85, iter 1800, loss: 2.735304, top_1: 0.608555, top_k: 0.821328, samples/s: 1333.006 1612743528.6431692
train: epoch 85, iter 1900, loss: 2.766064, top_1: 0.613008, top_k: 0.823438, samples/s: 1331.543 1612743547.8690155
train: epoch 85, iter 2000, loss: 2.673184, top_1: 0.611875, top_k: 0.824531, samples/s: 1312.653 1612743567.3715131
train: epoch 85, iter 2100, loss: 2.510342, top_1: 0.614609, top_k: 0.828789, samples/s: 1334.701 1612743586.5518434
train: epoch 85, iter 2200, loss: 2.590765, top_1: 0.611445, top_k: 0.825273, samples/s: 1326.969 1612743605.8438642
train: epoch 85, iter 2300, loss: 2.668281, top_1: 0.617109, top_k: 0.826211, samples/s: 1325.387 1612743625.159047
train: epoch 85, iter 2400, loss: 2.672840, top_1: 0.604727, top_k: 0.818750, samples/s: 1328.684 1612743644.426177
train: epoch 85, iter 2500, loss: 2.503591, top_1: 0.614688, top_k: 0.825820, samples/s: 1332.193 1612743663.6427026
train: epoch 85, iter 2600, loss: 2.658929, top_1: 0.614961, top_k: 0.828242, samples/s: 1331.496 1612743682.869084
train: epoch 85, iter 2700, loss: 2.656662, top_1: 0.615977, top_k: 0.827930, samples/s: 1331.075 1612743702.1017215
train: epoch 85, iter 2800, loss: 2.543919, top_1: 0.613789, top_k: 0.826445, samples/s: 1321.245 1612743721.477351
train: epoch 85, iter 2900, loss: 2.739372, top_1: 0.612578, top_k: 0.827617, samples/s: 1328.511 1612743740.7470534
train: epoch 85, iter 3000, loss: 2.466056, top_1: 0.611016, top_k: 0.827852, samples/s: 1330.436 1612743759.9888768
train: epoch 85, iter 3100, loss: 2.552231, top_1: 0.610977, top_k: 0.825703, samples/s: 1327.768 1612743779.2693517
train: epoch 85, iter 3200, loss: 2.403539, top_1: 0.608633, top_k: 0.818906, samples/s: 1325.399 1612743798.5842764
train: epoch 85, iter 3300, loss: 2.526757, top_1: 0.610039, top_k: 0.823359, samples/s: 1330.051 1612743817.831628
train: epoch 85, iter 3400, loss: 2.577589, top_1: 0.610938, top_k: 0.825078, samples/s: 1327.450 1612743837.1167812
train: epoch 85, iter 3500, loss: 2.598358, top_1: 0.612773, top_k: 0.825547, samples/s: 1326.480 1612743856.4160254
train: epoch 85, iter 3600, loss: 2.699699, top_1: 0.608437, top_k: 0.825156, samples/s: 1328.062 1612743875.6922345
train: epoch 85, iter 3700, loss: 2.712438, top_1: 0.613906, top_k: 0.826367, samples/s: 1328.037 1612743894.968694
train: epoch 85, iter 3800, loss: 2.638872, top_1: 0.616680, top_k: 0.826367, samples/s: 1330.619 1612743914.207865
train: epoch 85, iter 3900, loss: 2.615603, top_1: 0.614688, top_k: 0.828281, samples/s: 1324.938 1612743933.5295763
train: epoch 85, iter 4000, loss: 2.440768, top_1: 0.612344, top_k: 0.824648, samples/s: 1334.207 1612743952.7169456
train: epoch 85, iter 4100, loss: 2.683925, top_1: 0.610117, top_k: 0.824766, samples/s: 1321.367 1612743972.0907931
train: epoch 85, iter 4200, loss: 2.630389, top_1: 0.615078, top_k: 0.823945, samples/s: 1329.954 1612743991.339587
train: epoch 85, iter 4300, loss: 2.690116, top_1: 0.608828, top_k: 0.822891, samples/s: 1333.656 1612744010.534959
train: epoch 85, iter 4400, loss: 2.484277, top_1: 0.613398, top_k: 0.824492, samples/s: 1324.029 1612744029.869883
train: epoch 85, iter 4500, loss: 2.578705, top_1: 0.605742, top_k: 0.818086, samples/s: 1324.367 1612744049.1999793
train: epoch 85, iter 4600, loss: 2.441163, top_1: 0.610000, top_k: 0.822656, samples/s: 1335.049 1612744068.3752897
train: epoch 85, iter 4700, loss: 2.479203, top_1: 0.610820, top_k: 0.823984, samples/s: 1323.856 1612744087.7126696
train: epoch 85, iter 4800, loss: 2.647403, top_1: 0.603594, top_k: 0.824453, samples/s: 1330.840 1612744106.948594
train: epoch 85, iter 4900, loss: 2.614837, top_1: 0.608164, top_k: 0.824844, samples/s: 1335.907 1612744126.111659
train: epoch 85, iter 5000, loss: 2.649499, top_1: 0.613164, top_k: 0.827617, samples/s: 1325.686 1612744145.422413
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_85.
validation: epoch 85, iter 195, top_1: 0.656250, top_k: 0.871214, samples/s: 2782.144 1612744163.93319
train: epoch 86, iter 100, loss: 2.497700, top_1: 0.622070, top_k: 0.830898, samples/s: 1366.294 1612744199.1761744
train: epoch 86, iter 200, loss: 2.523529, top_1: 0.616758, top_k: 0.829063, samples/s: 1360.640 1612744217.9910736
train: epoch 86, iter 300, loss: 2.624447, top_1: 0.622305, top_k: 0.833125, samples/s: 1358.486 1612744236.8354192
train: epoch 86, iter 400, loss: 2.652425, top_1: 0.623281, top_k: 0.836602, samples/s: 1350.789 1612744255.7872252
train: epoch 86, iter 500, loss: 2.517982, top_1: 0.617109, top_k: 0.831250, samples/s: 1338.414 1612744274.9143353
train: epoch 86, iter 600, loss: 2.629692, top_1: 0.611367, top_k: 0.823516, samples/s: 1327.127 1612744294.204159
train: epoch 86, iter 700, loss: 2.595481, top_1: 0.611328, top_k: 0.826992, samples/s: 1336.250 1612744313.362349
train: epoch 86, iter 800, loss: 2.642336, top_1: 0.621680, top_k: 0.836250, samples/s: 1319.319 1612744332.7662022
train: epoch 86, iter 900, loss: 2.654984, top_1: 0.617422, top_k: 0.829336, samples/s: 1341.559 1612744351.848442
train: epoch 86, iter 1000, loss: 2.655033, top_1: 0.618750, top_k: 0.831133, samples/s: 1326.571 1612744371.146351
train: epoch 86, iter 1100, loss: 2.493101, top_1: 0.612539, top_k: 0.826406, samples/s: 1330.458 1612744390.3878095
train: epoch 86, iter 1200, loss: 2.411357, top_1: 0.614180, top_k: 0.829688, samples/s: 1332.394 1612744409.601372
train: epoch 86, iter 1300, loss: 2.481679, top_1: 0.614961, top_k: 0.828672, samples/s: 1330.602 1612744428.840826
train: epoch 86, iter 1400, loss: 2.595304, top_1: 0.614844, top_k: 0.827891, samples/s: 1330.226 1612744448.0856624
train: epoch 86, iter 1500, loss: 2.633946, top_1: 0.618047, top_k: 0.825039, samples/s: 1326.037 1612744467.3912845
train: epoch 86, iter 1600, loss: 2.508442, top_1: 0.616836, top_k: 0.828047, samples/s: 1333.008 1612744486.5959473
train: epoch 86, iter 1700, loss: 2.569159, top_1: 0.618516, top_k: 0.827383, samples/s: 1337.704 1612744505.7332041
train: epoch 86, iter 1800, loss: 2.445957, top_1: 0.614258, top_k: 0.828086, samples/s: 1330.882 1612744524.9685636
train: epoch 86, iter 1900, loss: 2.625584, top_1: 0.617188, top_k: 0.831328, samples/s: 1332.491 1612744544.1807013
train: epoch 86, iter 2000, loss: 2.440045, top_1: 0.607891, top_k: 0.824141, samples/s: 1328.483 1612744563.4509192
train: epoch 86, iter 2100, loss: 2.429078, top_1: 0.617695, top_k: 0.826172, samples/s: 1332.731 1612744582.659483
train: epoch 86, iter 2200, loss: 2.663144, top_1: 0.616719, top_k: 0.826719, samples/s: 1337.618 1612744601.7980375
train: epoch 86, iter 2300, loss: 2.575162, top_1: 0.610977, top_k: 0.822578, samples/s: 1330.705 1612744621.0359492
train: epoch 86, iter 2400, loss: 2.629964, top_1: 0.617109, top_k: 0.830703, samples/s: 1330.839 1612744640.2719214
train: epoch 86, iter 2500, loss: 2.655855, top_1: 0.613555, top_k: 0.827578, samples/s: 1325.254 1612744659.5889442
train: epoch 86, iter 2600, loss: 2.567679, top_1: 0.610820, top_k: 0.828633, samples/s: 1333.822 1612744678.7819452
train: epoch 86, iter 2700, loss: 2.392924, top_1: 0.609570, top_k: 0.825547, samples/s: 1333.903 1612744697.9737108
train: epoch 86, iter 2800, loss: 2.599843, top_1: 0.609023, top_k: 0.822812, samples/s: 1335.472 1612744717.1429553
train: epoch 86, iter 2900, loss: 2.563137, top_1: 0.613086, top_k: 0.821602, samples/s: 1335.804 1612744736.3074534
train: epoch 86, iter 3000, loss: 2.576772, top_1: 0.613125, top_k: 0.822734, samples/s: 1330.404 1612744755.5497267
train: epoch 86, iter 3100, loss: 2.705519, top_1: 0.609453, top_k: 0.823906, samples/s: 1330.961 1612744774.783951
train: epoch 86, iter 3200, loss: 2.599347, top_1: 0.609141, top_k: 0.827109, samples/s: 1332.043 1612744794.002541
train: epoch 86, iter 3300, loss: 2.445969, top_1: 0.614688, top_k: 0.830000, samples/s: 1333.731 1612744813.196823
train: epoch 86, iter 3400, loss: 2.507038, top_1: 0.608555, top_k: 0.825625, samples/s: 1334.361 1612744832.3821235
train: epoch 86, iter 3500, loss: 2.598606, top_1: 0.613125, top_k: 0.828555, samples/s: 1333.112 1612744851.585328
train: epoch 86, iter 3600, loss: 2.716226, top_1: 0.612305, top_k: 0.827500, samples/s: 1334.844 1612744870.7635193
train: epoch 86, iter 3700, loss: 2.663274, top_1: 0.615078, top_k: 0.830313, samples/s: 1329.911 1612744890.0134115
train: epoch 86, iter 3800, loss: 2.660560, top_1: 0.615195, top_k: 0.826484, samples/s: 1338.461 1612744909.1393683
train: epoch 86, iter 3900, loss: 2.543992, top_1: 0.615938, top_k: 0.827422, samples/s: 1326.164 1612744928.443594
train: epoch 86, iter 4000, loss: 2.559646, top_1: 0.608945, top_k: 0.823281, samples/s: 1334.440 1612744947.6273038
train: epoch 86, iter 4100, loss: 2.579033, top_1: 0.607148, top_k: 0.824219, samples/s: 1332.037 1612744966.8459816
train: epoch 86, iter 4200, loss: 2.360039, top_1: 0.606367, top_k: 0.822383, samples/s: 1329.869 1612744986.0960042
train: epoch 86, iter 4300, loss: 2.794850, top_1: 0.608594, top_k: 0.822695, samples/s: 1328.346 1612745005.3680758
train: epoch 86, iter 4400, loss: 2.635191, top_1: 0.607148, top_k: 0.823086, samples/s: 1338.672 1612745024.4914613
train: epoch 86, iter 4500, loss: 2.577423, top_1: 0.611172, top_k: 0.825742, samples/s: 1327.397 1612745043.7773604
train: epoch 86, iter 4600, loss: 2.448425, top_1: 0.611914, top_k: 0.821797, samples/s: 1337.539 1612745062.9170558
train: epoch 86, iter 4700, loss: 2.533594, top_1: 0.610156, top_k: 0.825703, samples/s: 1329.383 1612745082.1740384
train: epoch 86, iter 4800, loss: 2.555570, top_1: 0.606133, top_k: 0.819531, samples/s: 1336.874 1612745101.3232296
train: epoch 86, iter 4900, loss: 2.393496, top_1: 0.609297, top_k: 0.821875, samples/s: 1325.903 1612745120.6307986
train: epoch 86, iter 5000, loss: 2.546402, top_1: 0.614219, top_k: 0.829766, samples/s: 1331.871 1612745139.8518817
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_86.
validation: epoch 86, iter 195, top_1: 0.653966, top_k: 0.867989, samples/s: 2741.761 1612745158.6596673
train: epoch 87, iter 100, loss: 2.495997, top_1: 0.629297, top_k: 0.836992, samples/s: 1365.012 1612745193.5616937
train: epoch 87, iter 200, loss: 2.510671, top_1: 0.623477, top_k: 0.837187, samples/s: 1360.793 1612745212.3745787
train: epoch 87, iter 300, loss: 2.578711, top_1: 0.621797, top_k: 0.832187, samples/s: 1361.892 1612745231.171577
train: epoch 87, iter 400, loss: 2.673169, top_1: 0.627695, top_k: 0.834063, samples/s: 1352.882 1612745250.0942771
train: epoch 87, iter 500, loss: 2.557221, top_1: 0.629336, top_k: 0.835117, samples/s: 1329.464 1612745269.350108
train: epoch 87, iter 600, loss: 2.575931, top_1: 0.626289, top_k: 0.835039, samples/s: 1327.641 1612745288.632414
train: epoch 87, iter 700, loss: 2.357723, top_1: 0.622734, top_k: 0.832461, samples/s: 1330.305 1612745307.876059
train: epoch 87, iter 800, loss: 2.483940, top_1: 0.620039, top_k: 0.830313, samples/s: 1332.342 1612745327.090356
train: epoch 87, iter 900, loss: 2.550891, top_1: 0.620078, top_k: 0.835977, samples/s: 1331.826 1612745346.3121305
train: epoch 87, iter 1000, loss: 2.542633, top_1: 0.615234, top_k: 0.828047, samples/s: 1331.051 1612745365.5450976
train: epoch 87, iter 1100, loss: 2.713969, top_1: 0.614102, top_k: 0.823906, samples/s: 1333.056 1612745384.7490537
train: epoch 87, iter 1200, loss: 2.540792, top_1: 0.621250, top_k: 0.830977, samples/s: 1333.000 1612745403.9538267
train: epoch 87, iter 1300, loss: 2.664216, top_1: 0.617305, top_k: 0.830234, samples/s: 1320.520 1612745423.3401341
train: epoch 87, iter 1400, loss: 2.384153, top_1: 0.623750, top_k: 0.831133, samples/s: 1326.701 1612745442.6361165
train: epoch 87, iter 1500, loss: 2.436697, top_1: 0.620117, top_k: 0.834063, samples/s: 1331.442 1612745461.863414
train: epoch 87, iter 1600, loss: 2.838785, top_1: 0.619492, top_k: 0.829727, samples/s: 1338.980 1612745480.9823942
train: epoch 87, iter 1700, loss: 2.603294, top_1: 0.620313, top_k: 0.829219, samples/s: 1335.938 1612745500.1449952
train: epoch 87, iter 1800, loss: 2.516942, top_1: 0.624219, top_k: 0.831250, samples/s: 1321.399 1612745519.518453
train: epoch 87, iter 1900, loss: 2.591882, top_1: 0.621484, top_k: 0.829180, samples/s: 1329.439 1612745538.7747052
train: epoch 87, iter 2000, loss: 2.523418, top_1: 0.617969, top_k: 0.827070, samples/s: 1342.627 1612745557.8416967
train: epoch 87, iter 2100, loss: 2.560793, top_1: 0.614805, top_k: 0.830352, samples/s: 1325.039 1612745577.1618876
train: epoch 87, iter 2200, loss: 2.584787, top_1: 0.618008, top_k: 0.827773, samples/s: 1326.629 1612745596.4589403
train: epoch 87, iter 2300, loss: 2.600099, top_1: 0.614492, top_k: 0.825156, samples/s: 1332.722 1612745615.6678078
train: epoch 87, iter 2400, loss: 2.717995, top_1: 0.613867, top_k: 0.827852, samples/s: 1328.345 1612745634.9398618
train: epoch 87, iter 2500, loss: 2.553608, top_1: 0.614844, top_k: 0.830273, samples/s: 1334.979 1612745654.1161916
train: epoch 87, iter 2600, loss: 2.419143, top_1: 0.610352, top_k: 0.824336, samples/s: 1328.698 1612745673.3832338
train: epoch 87, iter 2700, loss: 2.625717, top_1: 0.613867, top_k: 0.828594, samples/s: 1331.565 1612745692.608695
train: epoch 87, iter 2800, loss: 2.622634, top_1: 0.612344, top_k: 0.826328, samples/s: 1338.030 1612745711.7413416
train: epoch 87, iter 2900, loss: 2.595916, top_1: 0.614102, top_k: 0.831992, samples/s: 1335.543 1612745730.9094682
train: epoch 87, iter 3000, loss: 2.518073, top_1: 0.616875, top_k: 0.828945, samples/s: 1329.619 1612745750.1632366
train: epoch 87, iter 3100, loss: 2.555469, top_1: 0.614141, top_k: 0.829375, samples/s: 1329.588 1612745769.4171996
train: epoch 87, iter 3200, loss: 2.650148, top_1: 0.610352, top_k: 0.828750, samples/s: 1336.969 1612745788.565022
train: epoch 87, iter 3300, loss: 2.487938, top_1: 0.614844, top_k: 0.826367, samples/s: 1336.391 1612745807.7210586
train: epoch 87, iter 3400, loss: 2.492947, top_1: 0.618281, top_k: 0.828164, samples/s: 1327.834 1612745827.000553
train: epoch 87, iter 3500, loss: 2.535139, top_1: 0.617305, top_k: 0.827109, samples/s: 1321.111 1612745846.378186
train: epoch 87, iter 3600, loss: 2.433231, top_1: 0.611797, top_k: 0.825273, samples/s: 1348.342 1612745865.3645363
train: epoch 87, iter 3700, loss: 2.480972, top_1: 0.616172, top_k: 0.826797, samples/s: 1331.740 1612745884.587498
train: epoch 87, iter 3800, loss: 2.468517, top_1: 0.612031, top_k: 0.826055, samples/s: 1315.166 1612745904.0526679
train: epoch 87, iter 3900, loss: 2.457400, top_1: 0.612383, top_k: 0.826133, samples/s: 1350.057 1612745923.0148137
train: epoch 87, iter 4000, loss: 2.527400, top_1: 0.613398, top_k: 0.825937, samples/s: 1336.655 1612745942.1671464
train: epoch 87, iter 4100, loss: 2.500131, top_1: 0.614922, top_k: 0.827617, samples/s: 1325.112 1612745961.4862604
train: epoch 87, iter 4200, loss: 2.668544, top_1: 0.617070, top_k: 0.828164, samples/s: 1332.393 1612745980.6997638
train: epoch 87, iter 4300, loss: 2.487592, top_1: 0.613008, top_k: 0.825430, samples/s: 1338.709 1612745999.8227024
train: epoch 87, iter 4400, loss: 2.464483, top_1: 0.612930, top_k: 0.826133, samples/s: 1328.825 1612746019.08786
train: epoch 87, iter 4500, loss: 2.548514, top_1: 0.612539, top_k: 0.826094, samples/s: 1335.347 1612746038.2589073
train: epoch 87, iter 4600, loss: 2.752520, top_1: 0.617070, top_k: 0.827109, samples/s: 1334.975 1612746057.4353647
train: epoch 87, iter 4700, loss: 2.502884, top_1: 0.618789, top_k: 0.828516, samples/s: 1335.193 1612746076.608497
train: epoch 87, iter 4800, loss: 2.489893, top_1: 0.610586, top_k: 0.825391, samples/s: 1325.999 1612746095.9147494
train: epoch 87, iter 4900, loss: 2.687771, top_1: 0.611055, top_k: 0.825703, samples/s: 1332.940 1612746115.1204853
train: epoch 87, iter 5000, loss: 2.463118, top_1: 0.622461, top_k: 0.829063, samples/s: 1331.881 1612746134.3413322
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_87.
validation: epoch 87, iter 195, top_1: 0.658393, top_k: 0.870793, samples/s: 2803.639 1612746152.6692798
train: epoch 88, iter 100, loss: 2.544199, top_1: 0.632500, top_k: 0.837930, samples/s: 1363.233 1612746187.4236217
train: epoch 88, iter 200, loss: 2.353922, top_1: 0.620859, top_k: 0.833867, samples/s: 1358.761 1612746206.2644145
train: epoch 88, iter 300, loss: 2.688260, top_1: 0.624336, top_k: 0.834141, samples/s: 1359.421 1612746225.095835
train: epoch 88, iter 400, loss: 2.485295, top_1: 0.623164, top_k: 0.832148, samples/s: 1341.664 1612746244.176727
train: epoch 88, iter 500, loss: 2.574280, top_1: 0.612930, top_k: 0.827227, samples/s: 1336.298 1612746263.3340404
train: epoch 88, iter 600, loss: 2.742112, top_1: 0.624687, top_k: 0.830547, samples/s: 1323.666 1612746282.674268
train: epoch 88, iter 700, loss: 2.587488, top_1: 0.622344, top_k: 0.832305, samples/s: 1333.930 1612746301.8656776
train: epoch 88, iter 800, loss: 2.740339, top_1: 0.624297, top_k: 0.835117, samples/s: 1325.972 1612746321.1722884
train: epoch 88, iter 900, loss: 2.469380, top_1: 0.616563, top_k: 0.826211, samples/s: 1336.520 1612746340.3265002
train: epoch 88, iter 1000, loss: 2.628178, top_1: 0.621094, top_k: 0.832734, samples/s: 1333.372 1612746359.5260093
train: epoch 88, iter 1100, loss: 2.647420, top_1: 0.615898, top_k: 0.833555, samples/s: 1323.430 1612746378.8696148
train: epoch 88, iter 1200, loss: 2.477736, top_1: 0.624062, top_k: 0.834648, samples/s: 1329.888 1612746398.1196074
train: epoch 88, iter 1300, loss: 2.466464, top_1: 0.619766, top_k: 0.831367, samples/s: 1333.403 1612746417.3184657
train: epoch 88, iter 1400, loss: 2.568867, top_1: 0.624766, top_k: 0.828750, samples/s: 1328.295 1612746436.5912073
train: epoch 88, iter 1500, loss: 2.569596, top_1: 0.619531, top_k: 0.829336, samples/s: 1329.012 1612746455.8536103
train: epoch 88, iter 1600, loss: 2.710334, top_1: 0.620547, top_k: 0.831172, samples/s: 1331.581 1612746475.0793204
train: epoch 88, iter 1700, loss: 2.419361, top_1: 0.623047, top_k: 0.832734, samples/s: 1328.844 1612746494.3437886
train: epoch 88, iter 1800, loss: 2.544470, top_1: 0.619609, top_k: 0.828984, samples/s: 1330.358 1612746513.5870552
train: epoch 88, iter 1900, loss: 2.585856, top_1: 0.619219, top_k: 0.827930, samples/s: 1329.833 1612746532.8372214
train: epoch 88, iter 2000, loss: 2.553246, top_1: 0.622266, top_k: 0.827305, samples/s: 1330.102 1612746552.0839188
train: epoch 88, iter 2100, loss: 2.716655, top_1: 0.621914, top_k: 0.833320, samples/s: 1326.754 1612746571.3791404
train: epoch 88, iter 2200, loss: 2.376152, top_1: 0.613359, top_k: 0.827461, samples/s: 1330.486 1612746590.6201787
train: epoch 88, iter 2300, loss: 2.581880, top_1: 0.618828, top_k: 0.832266, samples/s: 1332.027 1612746609.8389828
train: epoch 88, iter 2400, loss: 2.738209, top_1: 0.618633, top_k: 0.827695, samples/s: 1328.233 1612746629.1127474
train: epoch 88, iter 2500, loss: 2.727793, top_1: 0.621328, top_k: 0.836016, samples/s: 1331.872 1612746648.3337653
train: epoch 88, iter 2600, loss: 2.513660, top_1: 0.613125, top_k: 0.827266, samples/s: 1331.123 1612746667.5657198
train: epoch 88, iter 2700, loss: 2.638213, top_1: 0.614141, top_k: 0.826484, samples/s: 1336.988 1612746686.7131739
train: epoch 88, iter 2800, loss: 2.587532, top_1: 0.619727, top_k: 0.829297, samples/s: 1326.273 1612746706.0153723
train: epoch 88, iter 2900, loss: 2.787689, top_1: 0.617461, top_k: 0.830469, samples/s: 1329.930 1612746725.264501
train: epoch 88, iter 3000, loss: 2.608738, top_1: 0.614805, top_k: 0.826406, samples/s: 1332.956 1612746744.4699347
train: epoch 88, iter 3100, loss: 2.575046, top_1: 0.616445, top_k: 0.825430, samples/s: 1331.078 1612746763.7025626
train: epoch 88, iter 3200, loss: 2.636753, top_1: 0.616875, top_k: 0.827383, samples/s: 1333.677 1612746782.8976007
train: epoch 88, iter 3300, loss: 2.487718, top_1: 0.611289, top_k: 0.828242, samples/s: 1330.889 1612746802.1331563
train: epoch 88, iter 3400, loss: 2.438498, top_1: 0.617188, top_k: 0.827617, samples/s: 1330.136 1612746821.3790085
train: epoch 88, iter 3500, loss: 2.666388, top_1: 0.616484, top_k: 0.826719, samples/s: 1335.092 1612746840.554332
train: epoch 88, iter 3600, loss: 2.571230, top_1: 0.609805, top_k: 0.825430, samples/s: 1330.361 1612746859.7965949
train: epoch 88, iter 3700, loss: 2.582052, top_1: 0.621250, top_k: 0.831602, samples/s: 1335.116 1612746878.9710205
train: epoch 88, iter 3800, loss: 2.599848, top_1: 0.614219, top_k: 0.824961, samples/s: 1331.555 1612746898.1966336
train: epoch 88, iter 3900, loss: 2.503357, top_1: 0.616719, top_k: 0.826953, samples/s: 1332.907 1612746917.4027262
train: epoch 88, iter 4000, loss: 2.782416, top_1: 0.618633, top_k: 0.827656, samples/s: 1331.014 1612746936.6362536
train: epoch 88, iter 4100, loss: 2.583452, top_1: 0.614922, top_k: 0.827852, samples/s: 1332.689 1612746955.8455212
train: epoch 88, iter 4200, loss: 2.489478, top_1: 0.619414, top_k: 0.828867, samples/s: 1333.371 1612746975.0449107
train: epoch 88, iter 4300, loss: 2.478050, top_1: 0.618867, top_k: 0.831719, samples/s: 1330.955 1612746994.2793581
train: epoch 88, iter 4400, loss: 2.607589, top_1: 0.615469, top_k: 0.827969, samples/s: 1335.419 1612747013.449248
train: epoch 88, iter 4500, loss: 2.633194, top_1: 0.615508, top_k: 0.826250, samples/s: 1332.201 1612747032.6655586
train: epoch 88, iter 4600, loss: 2.556479, top_1: 0.618906, top_k: 0.827305, samples/s: 1333.912 1612747051.8572664
train: epoch 88, iter 4700, loss: 2.553837, top_1: 0.610273, top_k: 0.826289, samples/s: 1334.957 1612747071.0338693
train: epoch 88, iter 4800, loss: 2.481165, top_1: 0.612734, top_k: 0.826875, samples/s: 1334.736 1612747090.213734
train: epoch 88, iter 4900, loss: 2.615466, top_1: 0.619492, top_k: 0.829375, samples/s: 1330.417 1612747109.4558094
train: epoch 88, iter 5000, loss: 2.594392, top_1: 0.622852, top_k: 0.833203, samples/s: 1330.977 1612747128.6898208
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_88.
validation: epoch 88, iter 195, top_1: 0.658694, top_k: 0.872456, samples/s: 2794.598 1612747147.1185842
train: epoch 89, iter 100, loss: 2.599977, top_1: 0.632227, top_k: 0.832383, samples/s: 1359.544 1612747181.88673
train: epoch 89, iter 200, loss: 2.688859, top_1: 0.629414, top_k: 0.836523, samples/s: 1355.614 1612747200.7713344
train: epoch 89, iter 300, loss: 2.533063, top_1: 0.620625, top_k: 0.833320, samples/s: 1361.941 1612747219.567796
train: epoch 89, iter 400, loss: 2.481905, top_1: 0.626602, top_k: 0.836367, samples/s: 1350.529 1612747238.523286
train: epoch 89, iter 500, loss: 2.583989, top_1: 0.619453, top_k: 0.835039, samples/s: 1332.477 1612747257.7356615
train: epoch 89, iter 600, loss: 2.493218, top_1: 0.626914, top_k: 0.835313, samples/s: 1319.783 1612747277.1327596
train: epoch 89, iter 700, loss: 2.640383, top_1: 0.622617, top_k: 0.835469, samples/s: 1324.399 1612747296.462283
train: epoch 89, iter 800, loss: 2.522090, top_1: 0.625586, top_k: 0.832930, samples/s: 1325.564 1612747315.7749147
train: epoch 89, iter 900, loss: 2.589461, top_1: 0.626914, top_k: 0.834336, samples/s: 1327.568 1612747335.058295
train: epoch 89, iter 1000, loss: 2.624799, top_1: 0.626992, top_k: 0.840117, samples/s: 1323.732 1612747354.3974469
train: epoch 89, iter 1100, loss: 2.486327, top_1: 0.615391, top_k: 0.830039, samples/s: 1333.280 1612747373.5982664
train: epoch 89, iter 1200, loss: 2.424722, top_1: 0.624805, top_k: 0.833711, samples/s: 1324.089 1612747392.932303
train: epoch 89, iter 1300, loss: 2.677224, top_1: 0.620586, top_k: 0.835664, samples/s: 1327.541 1612747412.2160838
train: epoch 89, iter 1400, loss: 2.492572, top_1: 0.624219, top_k: 0.832852, samples/s: 1333.138 1612747431.4188316
train: epoch 89, iter 1500, loss: 2.470423, top_1: 0.620273, top_k: 0.832422, samples/s: 1324.474 1612747450.7473035
train: epoch 89, iter 1600, loss: 2.690662, top_1: 0.624648, top_k: 0.832422, samples/s: 1325.224 1612747470.0647948
train: epoch 89, iter 1700, loss: 2.614875, top_1: 0.620859, top_k: 0.834414, samples/s: 1323.367 1612747489.409371
train: epoch 89, iter 1800, loss: 2.525353, top_1: 0.622969, top_k: 0.829063, samples/s: 1326.104 1612747508.7140088
train: epoch 89, iter 1900, loss: 2.444705, top_1: 0.623945, top_k: 0.834258, samples/s: 1325.412 1612747528.0288074
train: epoch 89, iter 2000, loss: 2.789450, top_1: 0.626797, top_k: 0.831055, samples/s: 1324.791 1612747547.352563
train: epoch 89, iter 2100, loss: 2.677376, top_1: 0.618164, top_k: 0.830078, samples/s: 1327.844 1612747566.6319554
train: epoch 89, iter 2200, loss: 2.410493, top_1: 0.621914, top_k: 0.832422, samples/s: 1326.988 1612747585.9237862
train: epoch 89, iter 2300, loss: 2.517678, top_1: 0.624297, top_k: 0.838516, samples/s: 1327.070 1612747605.2144663
train: epoch 89, iter 2400, loss: 2.566637, top_1: 0.615078, top_k: 0.826328, samples/s: 1326.910 1612747624.5073051
train: epoch 89, iter 2500, loss: 2.657181, top_1: 0.621563, top_k: 0.832461, samples/s: 1322.366 1612747643.8665867
train: epoch 89, iter 2600, loss: 2.608535, top_1: 0.619414, top_k: 0.826289, samples/s: 1326.356 1612747663.1676414
train: epoch 89, iter 2700, loss: 2.556562, top_1: 0.620391, top_k: 0.831758, samples/s: 1332.006 1612747682.3866718
train: epoch 89, iter 2800, loss: 2.616273, top_1: 0.614375, top_k: 0.828594, samples/s: 1331.394 1612747701.614695
train: epoch 89, iter 2900, loss: 2.606086, top_1: 0.619922, top_k: 0.832930, samples/s: 1329.415 1612747720.8713517
train: epoch 89, iter 3000, loss: 2.643285, top_1: 0.618437, top_k: 0.828477, samples/s: 1319.067 1612747740.2789323
train: epoch 89, iter 3100, loss: 2.456746, top_1: 0.614062, top_k: 0.827266, samples/s: 1331.282 1612747759.5085182
train: epoch 89, iter 3200, loss: 2.504228, top_1: 0.620156, top_k: 0.829258, samples/s: 1331.521 1612747778.7346866
train: epoch 89, iter 3300, loss: 2.586960, top_1: 0.613203, top_k: 0.827031, samples/s: 1319.747 1612747798.1357121
train: epoch 89, iter 3400, loss: 2.464779, top_1: 0.616797, top_k: 0.829102, samples/s: 1326.691 1612747817.4284344
train: epoch 89, iter 3500, loss: 2.549755, top_1: 0.620273, top_k: 0.830352, samples/s: 1322.621 1612747836.7839692
train: epoch 89, iter 3600, loss: 2.480983, top_1: 0.615898, top_k: 0.823516, samples/s: 1327.516 1612747856.0680206
train: epoch 89, iter 3700, loss: 2.599838, top_1: 0.620078, top_k: 0.823203, samples/s: 1333.220 1612747875.2696476
train: epoch 89, iter 3800, loss: 2.351387, top_1: 0.620234, top_k: 0.832656, samples/s: 1321.682 1612747894.6389048
train: epoch 89, iter 3900, loss: 2.576586, top_1: 0.612773, top_k: 0.822812, samples/s: 1329.095 1612747913.900194
train: epoch 89, iter 4000, loss: 2.556409, top_1: 0.610586, top_k: 0.826406, samples/s: 1326.127 1612747933.2044644
train: epoch 89, iter 4100, loss: 2.610258, top_1: 0.623164, top_k: 0.831250, samples/s: 1325.878 1612747952.5124857
train: epoch 89, iter 4200, loss: 2.719282, top_1: 0.620313, top_k: 0.830352, samples/s: 1336.906 1612747971.661137
train: epoch 89, iter 4300, loss: 2.506701, top_1: 0.620781, top_k: 0.831875, samples/s: 1322.442 1612747991.019267
train: epoch 89, iter 4400, loss: 2.658203, top_1: 0.616328, top_k: 0.829258, samples/s: 1321.832 1612748010.3863227
train: epoch 89, iter 4500, loss: 2.560402, top_1: 0.619219, top_k: 0.831211, samples/s: 1328.899 1612748029.650448
train: epoch 89, iter 4600, loss: 2.585088, top_1: 0.622188, top_k: 0.827891, samples/s: 1327.754 1612748048.9312305
train: epoch 89, iter 4700, loss: 2.601240, top_1: 0.618203, top_k: 0.824727, samples/s: 1326.872 1612748068.224613
train: epoch 89, iter 4800, loss: 2.500459, top_1: 0.619453, top_k: 0.827695, samples/s: 1327.069 1612748087.5152173
train: epoch 89, iter 4900, loss: 2.641237, top_1: 0.618008, top_k: 0.830977, samples/s: 1333.113 1612748106.7183769
train: epoch 89, iter 5000, loss: 2.417799, top_1: 0.619453, top_k: 0.831133, samples/s: 1328.928 1612748125.982096
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_89.
validation: epoch 89, iter 195, top_1: 0.655689, top_k: 0.870593, samples/s: 2683.174 1612748145.1501627
train: epoch 90, iter 100, loss: 2.475055, top_1: 0.628125, top_k: 0.838477, samples/s: 1361.652 1612748179.9746623
train: epoch 90, iter 200, loss: 2.522564, top_1: 0.632734, top_k: 0.839063, samples/s: 1356.264 1612748198.850112
train: epoch 90, iter 300, loss: 2.708132, top_1: 0.622461, top_k: 0.832656, samples/s: 1360.698 1612748217.6639078
train: epoch 90, iter 400, loss: 2.372424, top_1: 0.624766, top_k: 0.836250, samples/s: 1339.821 1612748236.7709098
train: epoch 90, iter 500, loss: 2.588255, top_1: 0.627969, top_k: 0.836406, samples/s: 1341.792 1612748255.8498232
train: epoch 90, iter 600, loss: 2.333598, top_1: 0.623125, top_k: 0.835000, samples/s: 1334.318 1612748275.0356905
train: epoch 90, iter 700, loss: 2.540529, top_1: 0.618984, top_k: 0.833828, samples/s: 1330.648 1612748294.2744553
train: epoch 90, iter 800, loss: 2.647640, top_1: 0.627148, top_k: 0.838047, samples/s: 1324.776 1612748313.5984852
train: epoch 90, iter 900, loss: 2.388433, top_1: 0.625938, top_k: 0.834805, samples/s: 1325.154 1612748332.9169345
train: epoch 90, iter 1000, loss: 2.432995, top_1: 0.626445, top_k: 0.836406, samples/s: 1335.893 1612748352.0801945
train: epoch 90, iter 1100, loss: 2.479639, top_1: 0.627852, top_k: 0.836172, samples/s: 1330.780 1612748371.3170843
train: epoch 90, iter 1200, loss: 2.575665, top_1: 0.620391, top_k: 0.834102, samples/s: 1328.891 1612748390.581222
train: epoch 90, iter 1300, loss: 2.381826, top_1: 0.622734, top_k: 0.836406, samples/s: 1330.782 1612748409.8179722
train: epoch 90, iter 1400, loss: 2.438596, top_1: 0.621836, top_k: 0.833164, samples/s: 1330.965 1612748429.052225
train: epoch 90, iter 1500, loss: 2.713866, top_1: 0.621289, top_k: 0.832227, samples/s: 1330.899 1612748448.2872832
train: epoch 90, iter 1600, loss: 2.452915, top_1: 0.626445, top_k: 0.832500, samples/s: 1324.148 1612748467.6204853
train: epoch 90, iter 1700, loss: 2.666435, top_1: 0.629375, top_k: 0.838984, samples/s: 1334.508 1612748486.8036175
train: epoch 90, iter 1800, loss: 2.472937, top_1: 0.617617, top_k: 0.830117, samples/s: 1331.465 1612748506.0304883
train: epoch 90, iter 1900, loss: 2.351868, top_1: 0.626133, top_k: 0.833789, samples/s: 1329.282 1612748525.288994
train: epoch 90, iter 2000, loss: 2.447833, top_1: 0.621523, top_k: 0.837187, samples/s: 1331.813 1612748544.5109491
train: epoch 90, iter 2100, loss: 2.423001, top_1: 0.615938, top_k: 0.828516, samples/s: 1333.202 1612748563.7128499
train: epoch 90, iter 2200, loss: 2.539574, top_1: 0.625078, top_k: 0.835156, samples/s: 1332.412 1612748582.9260707
train: epoch 90, iter 2300, loss: 2.360368, top_1: 0.621719, top_k: 0.830937, samples/s: 1331.416 1612748602.153744
train: epoch 90, iter 2400, loss: 2.582942, top_1: 0.623984, top_k: 0.830078, samples/s: 1332.338 1612748621.368069
train: epoch 90, iter 2500, loss: 2.626894, top_1: 0.625430, top_k: 0.832422, samples/s: 1330.938 1612748640.6026516
train: epoch 90, iter 2600, loss: 2.648130, top_1: 0.622031, top_k: 0.832422, samples/s: 1331.094 1612748659.8349204
train: epoch 90, iter 2700, loss: 2.277844, top_1: 0.621445, top_k: 0.834141, samples/s: 1329.794 1612748679.0860236
train: epoch 90, iter 2800, loss: 2.383357, top_1: 0.622344, top_k: 0.830977, samples/s: 1331.237 1612748698.3162763
train: epoch 90, iter 2900, loss: 2.659309, top_1: 0.618203, top_k: 0.829375, samples/s: 1333.269 1612748717.5172503
train: epoch 90, iter 3000, loss: 2.714415, top_1: 0.620508, top_k: 0.834883, samples/s: 1331.874 1612748736.7382421
train: epoch 90, iter 3100, loss: 2.718167, top_1: 0.618086, top_k: 0.830508, samples/s: 1326.435 1612748756.038183
train: epoch 90, iter 3200, loss: 2.604776, top_1: 0.618008, top_k: 0.831719, samples/s: 1336.704 1612748775.1896863
train: epoch 90, iter 3300, loss: 2.643994, top_1: 0.619687, top_k: 0.830898, samples/s: 1325.099 1612748794.5090215
train: epoch 90, iter 3400, loss: 2.530798, top_1: 0.621133, top_k: 0.829688, samples/s: 1332.885 1612748813.715418
train: epoch 90, iter 3500, loss: 2.766367, top_1: 0.622070, top_k: 0.831914, samples/s: 1337.058 1612748832.8619843
train: epoch 90, iter 3600, loss: 2.618785, top_1: 0.616680, top_k: 0.831367, samples/s: 1323.968 1612748852.1977518
train: epoch 90, iter 3700, loss: 2.475104, top_1: 0.616953, top_k: 0.830625, samples/s: 1335.838 1612748871.3618238
train: epoch 90, iter 3800, loss: 2.525126, top_1: 0.624687, top_k: 0.837109, samples/s: 1332.310 1612748890.5765722
train: epoch 90, iter 3900, loss: 2.647986, top_1: 0.623242, top_k: 0.835313, samples/s: 1328.309 1612748909.8491771
train: epoch 90, iter 4000, loss: 2.571068, top_1: 0.619687, top_k: 0.827461, samples/s: 1331.204 1612748929.0798678
train: epoch 90, iter 4100, loss: 2.855963, top_1: 0.614805, top_k: 0.825586, samples/s: 1337.457 1612748948.2206988
train: epoch 90, iter 4200, loss: 2.604557, top_1: 0.623047, top_k: 0.830859, samples/s: 1328.629 1612748967.4886587
train: epoch 90, iter 4300, loss: 2.628655, top_1: 0.621016, top_k: 0.829844, samples/s: 1327.657 1612748986.770741
train: epoch 90, iter 4400, loss: 2.492780, top_1: 0.616328, top_k: 0.828984, samples/s: 1329.131 1612749006.0315568
train: epoch 90, iter 4500, loss: 2.544958, top_1: 0.619180, top_k: 0.829648, samples/s: 1334.014 1612749025.2216315
train: epoch 90, iter 4600, loss: 2.649910, top_1: 0.623555, top_k: 0.834414, samples/s: 1333.402 1612749044.4206994
train: epoch 90, iter 4700, loss: 2.545085, top_1: 0.621719, top_k: 0.835313, samples/s: 1326.714 1612749063.716448
train: epoch 90, iter 4800, loss: 2.526048, top_1: 0.625430, top_k: 0.831875, samples/s: 1334.386 1612749082.9013011
train: epoch 90, iter 4900, loss: 2.530342, top_1: 0.622695, top_k: 0.830156, samples/s: 1329.036 1612749102.163442
train: epoch 90, iter 5000, loss: 2.396177, top_1: 0.622969, top_k: 0.834961, samples/s: 1333.848 1612749121.3559737
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_90.
validation: epoch 90, iter 195, top_1: 0.655569, top_k: 0.870112, samples/s: 2752.264 1612749140.0769424
train: epoch 91, iter 100, loss: 2.641846, top_1: 0.630156, top_k: 0.838633, samples/s: 1359.330 1612749175.4558012
train: epoch 91, iter 200, loss: 2.289439, top_1: 0.626914, top_k: 0.834141, samples/s: 1365.436 1612749194.2046652
train: epoch 91, iter 300, loss: 2.563522, top_1: 0.635000, top_k: 0.840430, samples/s: 1354.952 1612749213.0982177
train: epoch 91, iter 400, loss: 2.431839, top_1: 0.630508, top_k: 0.837695, samples/s: 1350.309 1612749232.0566552
train: epoch 91, iter 500, loss: 2.551516, top_1: 0.627891, top_k: 0.833750, samples/s: 1331.780 1612749251.2791088
train: epoch 91, iter 600, loss: 2.431382, top_1: 0.628008, top_k: 0.838242, samples/s: 1330.462 1612749270.5205653
train: epoch 91, iter 700, loss: 2.540825, top_1: 0.630938, top_k: 0.839727, samples/s: 1331.049 1612749289.7534947
train: epoch 91, iter 800, loss: 2.458866, top_1: 0.629570, top_k: 0.835664, samples/s: 1333.025 1612749308.9579227
train: epoch 91, iter 900, loss: 2.704146, top_1: 0.634453, top_k: 0.840469, samples/s: 1327.280 1612749328.2454405
train: epoch 91, iter 1000, loss: 2.452615, top_1: 0.621992, top_k: 0.834141, samples/s: 1326.646 1612749347.542242
train: epoch 91, iter 1100, loss: 2.540207, top_1: 0.621992, top_k: 0.833633, samples/s: 1331.331 1612749366.771235
train: epoch 91, iter 1200, loss: 2.511142, top_1: 0.620391, top_k: 0.834805, samples/s: 1328.010 1612749386.0481288
train: epoch 91, iter 1300, loss: 2.457674, top_1: 0.626328, top_k: 0.837031, samples/s: 1331.585 1612749405.2733176
train: epoch 91, iter 1400, loss: 2.708866, top_1: 0.630430, top_k: 0.838164, samples/s: 1325.289 1612749424.5899355
train: epoch 91, iter 1500, loss: 2.605797, top_1: 0.628008, top_k: 0.836523, samples/s: 1337.944 1612749443.7236586
train: epoch 91, iter 1600, loss: 2.369730, top_1: 0.618633, top_k: 0.830703, samples/s: 1323.412 1612749463.0676725
train: epoch 91, iter 1700, loss: 2.593240, top_1: 0.620508, top_k: 0.831836, samples/s: 1339.230 1612749482.1830733
train: epoch 91, iter 1800, loss: 2.653020, top_1: 0.619375, top_k: 0.832383, samples/s: 1330.854 1612749501.4189079
train: epoch 91, iter 1900, loss: 2.550263, top_1: 0.619609, top_k: 0.830703, samples/s: 1328.573 1612749520.687632
train: epoch 91, iter 2000, loss: 2.583299, top_1: 0.622969, top_k: 0.834531, samples/s: 1330.604 1612749539.9270797
train: epoch 91, iter 2100, loss: 2.461804, top_1: 0.628203, top_k: 0.833242, samples/s: 1328.428 1612749559.1979213
train: epoch 91, iter 2200, loss: 2.511064, top_1: 0.627461, top_k: 0.837461, samples/s: 1329.787 1612749578.449124
train: epoch 91, iter 2300, loss: 2.524257, top_1: 0.628008, top_k: 0.835625, samples/s: 1330.262 1612749597.6935203
train: epoch 91, iter 2400, loss: 2.750852, top_1: 0.626563, top_k: 0.837109, samples/s: 1330.223 1612749616.938411
train: epoch 91, iter 2500, loss: 2.476476, top_1: 0.619805, top_k: 0.827734, samples/s: 1330.878 1612749636.1738172
train: epoch 91, iter 2600, loss: 2.437299, top_1: 0.627539, top_k: 0.836797, samples/s: 1332.126 1612749655.3912473
train: epoch 91, iter 2700, loss: 2.446591, top_1: 0.629062, top_k: 0.838633, samples/s: 1331.895 1612749674.6119754
train: epoch 91, iter 2800, loss: 2.454332, top_1: 0.625078, top_k: 0.834180, samples/s: 1329.601 1612749693.8658252
train: epoch 91, iter 2900, loss: 2.519220, top_1: 0.623008, top_k: 0.833242, samples/s: 1336.752 1612749713.01673
train: epoch 91, iter 3000, loss: 2.594089, top_1: 0.624805, top_k: 0.831445, samples/s: 1318.279 1612749732.4359624
train: epoch 91, iter 3100, loss: 2.589812, top_1: 0.624531, top_k: 0.835273, samples/s: 1337.534 1612749751.5756834
train: epoch 91, iter 3200, loss: 2.617289, top_1: 0.623555, top_k: 0.832578, samples/s: 1327.486 1612749770.8602715
train: epoch 91, iter 3300, loss: 2.535485, top_1: 0.620078, top_k: 0.830703, samples/s: 1334.114 1612749790.0489924
train: epoch 91, iter 3400, loss: 2.508846, top_1: 0.625781, top_k: 0.833828, samples/s: 1323.315 1612749809.3944507
train: epoch 91, iter 3500, loss: 2.658665, top_1: 0.617148, top_k: 0.832070, samples/s: 1335.167 1612749828.5680244
train: epoch 91, iter 3600, loss: 2.676534, top_1: 0.621367, top_k: 0.834453, samples/s: 1328.066 1612749847.844141
train: epoch 91, iter 3700, loss: 2.637140, top_1: 0.620273, top_k: 0.832891, samples/s: 1335.673 1612749867.01056
train: epoch 91, iter 3800, loss: 2.484703, top_1: 0.625898, top_k: 0.835664, samples/s: 1329.230 1612749886.2697809
train: epoch 91, iter 3900, loss: 2.601769, top_1: 0.621641, top_k: 0.833047, samples/s: 1334.856 1612749905.4478564
train: epoch 91, iter 4000, loss: 2.492925, top_1: 0.616719, top_k: 0.829727, samples/s: 1329.567 1612749924.7022529
train: epoch 91, iter 4100, loss: 2.524722, top_1: 0.622734, top_k: 0.830508, samples/s: 1326.608 1612749943.9996688
train: epoch 91, iter 4200, loss: 2.555035, top_1: 0.625000, top_k: 0.833516, samples/s: 1326.170 1612749963.3033674
train: epoch 91, iter 4300, loss: 2.779389, top_1: 0.619687, top_k: 0.832227, samples/s: 1331.129 1612749982.5351973
train: epoch 91, iter 4400, loss: 2.577458, top_1: 0.620938, top_k: 0.833125, samples/s: 1337.502 1612750001.6753292
train: epoch 91, iter 4500, loss: 2.529808, top_1: 0.621016, top_k: 0.830586, samples/s: 1321.724 1612750021.0439909
train: epoch 91, iter 4600, loss: 2.492743, top_1: 0.622344, top_k: 0.830898, samples/s: 1328.862 1612750040.3084962
train: epoch 91, iter 4700, loss: 2.496521, top_1: 0.621289, top_k: 0.835195, samples/s: 1335.121 1612750059.4828317
train: epoch 91, iter 4800, loss: 2.593315, top_1: 0.621719, top_k: 0.830469, samples/s: 1326.792 1612750078.7775037
train: epoch 91, iter 4900, loss: 2.462920, top_1: 0.618711, top_k: 0.828672, samples/s: 1334.784 1612750097.9565768
train: epoch 91, iter 5000, loss: 2.652195, top_1: 0.630508, top_k: 0.838672, samples/s: 1323.344 1612750117.3015711
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_91.
validation: epoch 91, iter 195, top_1: 0.661218, top_k: 0.875561, samples/s: 2774.473 1612750135.849954
train: epoch 92, iter 100, loss: 2.483893, top_1: 0.628633, top_k: 0.840391, samples/s: 1359.309 1612750170.557272
train: epoch 92, iter 200, loss: 2.574337, top_1: 0.632969, top_k: 0.836641, samples/s: 1363.499 1612750189.332697
train: epoch 92, iter 300, loss: 2.515720, top_1: 0.634570, top_k: 0.842773, samples/s: 1361.623 1612750208.133513
train: epoch 92, iter 400, loss: 2.732229, top_1: 0.638516, top_k: 0.841680, samples/s: 1341.913 1612750227.2107532
train: epoch 92, iter 500, loss: 2.522092, top_1: 0.634492, top_k: 0.837617, samples/s: 1329.031 1612750246.4729357
train: epoch 92, iter 600, loss: 2.438025, top_1: 0.633359, top_k: 0.841211, samples/s: 1329.163 1612750265.7331583
train: epoch 92, iter 700, loss: 2.479918, top_1: 0.630820, top_k: 0.837852, samples/s: 1332.580 1612750284.9439695
train: epoch 92, iter 800, loss: 2.299774, top_1: 0.633711, top_k: 0.840391, samples/s: 1321.999 1612750304.308668
train: epoch 92, iter 900, loss: 2.375937, top_1: 0.628125, top_k: 0.836523, samples/s: 1327.207 1612750323.5973008
train: epoch 92, iter 1000, loss: 2.611135, top_1: 0.628281, top_k: 0.834453, samples/s: 1323.062 1612750342.9463065
train: epoch 92, iter 1100, loss: 2.432966, top_1: 0.628125, top_k: 0.839141, samples/s: 1332.673 1612750362.1557832
train: epoch 92, iter 1200, loss: 2.518176, top_1: 0.630898, top_k: 0.840078, samples/s: 1330.769 1612750381.392787
train: epoch 92, iter 1300, loss: 2.455449, top_1: 0.628008, top_k: 0.836641, samples/s: 1321.008 1612750400.7719176
train: epoch 92, iter 1400, loss: 2.372051, top_1: 0.624102, top_k: 0.833555, samples/s: 1328.556 1612750420.0410137
train: epoch 92, iter 1500, loss: 2.392881, top_1: 0.621641, top_k: 0.834648, samples/s: 1322.635 1612750439.3962684
train: epoch 92, iter 1600, loss: 2.576692, top_1: 0.626641, top_k: 0.837344, samples/s: 1333.004 1612750458.6010907
train: epoch 92, iter 1700, loss: 2.630008, top_1: 0.625547, top_k: 0.837227, samples/s: 1327.127 1612750477.890829
train: epoch 92, iter 1800, loss: 2.389583, top_1: 0.624336, top_k: 0.834336, samples/s: 1328.183 1612750497.1652517
train: epoch 92, iter 1900, loss: 2.520456, top_1: 0.630313, top_k: 0.835820, samples/s: 1329.803 1612750516.4162657
train: epoch 92, iter 2000, loss: 2.402964, top_1: 0.627695, top_k: 0.839219, samples/s: 1324.384 1612750535.74605
train: epoch 92, iter 2100, loss: 2.450985, top_1: 0.627578, top_k: 0.832656, samples/s: 1335.410 1612750554.9160955
train: epoch 92, iter 2200, loss: 2.381142, top_1: 0.625430, top_k: 0.834883, samples/s: 1324.210 1612750574.2484534
train: epoch 92, iter 2300, loss: 2.543092, top_1: 0.625625, top_k: 0.831445, samples/s: 1322.369 1612750593.6075563
train: epoch 92, iter 2400, loss: 2.423168, top_1: 0.625625, top_k: 0.836992, samples/s: 1328.559 1612750612.8766177
train: epoch 92, iter 2500, loss: 2.432921, top_1: 0.630820, top_k: 0.838320, samples/s: 1332.976 1612750632.0817714
train: epoch 92, iter 2600, loss: 2.409932, top_1: 0.623164, top_k: 0.837148, samples/s: 1332.669 1612750651.2912958
train: epoch 92, iter 2700, loss: 2.907728, top_1: 0.627617, top_k: 0.834609, samples/s: 1322.143 1612750670.6538787
train: epoch 92, iter 2800, loss: 2.488364, top_1: 0.627969, top_k: 0.834688, samples/s: 1327.955 1612750689.9315922
train: epoch 92, iter 2900, loss: 2.764094, top_1: 0.625039, top_k: 0.833477, samples/s: 1329.640 1612750709.184883
train: epoch 92, iter 3000, loss: 2.616072, top_1: 0.630000, top_k: 0.833867, samples/s: 1320.112 1612750728.577179
train: epoch 92, iter 3100, loss: 2.507843, top_1: 0.624844, top_k: 0.837266, samples/s: 1337.149 1612750747.7224243
train: epoch 92, iter 3200, loss: 2.588790, top_1: 0.625195, top_k: 0.831719, samples/s: 1325.628 1612750767.0340168
train: epoch 92, iter 3300, loss: 2.491489, top_1: 0.623125, top_k: 0.836484, samples/s: 1330.647 1612750786.2727904
train: epoch 92, iter 3400, loss: 2.623021, top_1: 0.623047, top_k: 0.833242, samples/s: 1334.013 1612750805.463018
train: epoch 92, iter 3500, loss: 2.709876, top_1: 0.624375, top_k: 0.835391, samples/s: 1315.634 1612750824.921339
train: epoch 92, iter 3600, loss: 2.492249, top_1: 0.621797, top_k: 0.832187, samples/s: 1334.092 1612750844.110458
train: epoch 92, iter 3700, loss: 2.572668, top_1: 0.628164, top_k: 0.832266, samples/s: 1324.902 1612750863.4325302
train: epoch 92, iter 3800, loss: 2.513246, top_1: 0.626914, top_k: 0.833633, samples/s: 1330.523 1612750882.6730819
train: epoch 92, iter 3900, loss: 2.407064, top_1: 0.622383, top_k: 0.835898, samples/s: 1327.054 1612750901.963973
train: epoch 92, iter 4000, loss: 2.426128, top_1: 0.626797, top_k: 0.833438, samples/s: 1329.919 1612750921.2133048
train: epoch 92, iter 4100, loss: 2.561317, top_1: 0.622578, top_k: 0.836211, samples/s: 1330.029 1612750940.4609861
train: epoch 92, iter 4200, loss: 2.492820, top_1: 0.620078, top_k: 0.830352, samples/s: 1326.566 1612750959.7588823
train: epoch 92, iter 4300, loss: 2.441657, top_1: 0.623125, top_k: 0.835664, samples/s: 1330.510 1612750978.9996207
train: epoch 92, iter 4400, loss: 2.550293, top_1: 0.624531, top_k: 0.830898, samples/s: 1331.287 1612750998.2291887
train: epoch 92, iter 4500, loss: 2.677177, top_1: 0.623633, top_k: 0.833164, samples/s: 1325.000 1612751017.5499287
train: epoch 92, iter 4600, loss: 2.376257, top_1: 0.620117, top_k: 0.832461, samples/s: 1329.885 1612751036.7997177
train: epoch 92, iter 4700, loss: 2.545634, top_1: 0.621875, top_k: 0.829766, samples/s: 1326.223 1612751056.1027257
train: epoch 92, iter 4800, loss: 2.674305, top_1: 0.620586, top_k: 0.833203, samples/s: 1330.797 1612751075.3392534
train: epoch 92, iter 4900, loss: 2.541566, top_1: 0.624141, top_k: 0.835117, samples/s: 1325.986 1612751094.6456163
train: epoch 92, iter 5000, loss: 2.489542, top_1: 0.633828, top_k: 0.836367, samples/s: 1334.655 1612751113.8265896
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_92.
validation: epoch 92, iter 195, top_1: 0.671054, top_k: 0.879788, samples/s: 2790.971 1612751132.2921367
train: epoch 93, iter 100, loss: 2.458032, top_1: 0.634844, top_k: 0.838047, samples/s: 1354.118 1612751173.0794718
train: epoch 93, iter 200, loss: 2.614761, top_1: 0.640508, top_k: 0.843281, samples/s: 1361.903 1612751191.8766
train: epoch 93, iter 300, loss: 2.466084, top_1: 0.638789, top_k: 0.838711, samples/s: 1361.673 1612751210.6769593
train: epoch 93, iter 400, loss: 2.547311, top_1: 0.633164, top_k: 0.842031, samples/s: 1351.941 1612751229.612754
train: epoch 93, iter 500, loss: 2.823779, top_1: 0.630625, top_k: 0.840313, samples/s: 1332.898 1612751248.8189921
train: epoch 93, iter 600, loss: 2.285991, top_1: 0.630938, top_k: 0.836484, samples/s: 1325.067 1612751268.1388435
train: epoch 93, iter 700, loss: 2.466095, top_1: 0.636367, top_k: 0.839688, samples/s: 1325.737 1612751287.448811
train: epoch 93, iter 800, loss: 2.701168, top_1: 0.634687, top_k: 0.839570, samples/s: 1329.152 1612751306.70925
train: epoch 93, iter 900, loss: 2.480852, top_1: 0.633359, top_k: 0.838594, samples/s: 1321.880 1612751326.0755177
train: epoch 93, iter 1000, loss: 2.524897, top_1: 0.637656, top_k: 0.843672, samples/s: 1325.503 1612751345.3889298
train: epoch 93, iter 1100, loss: 2.571116, top_1: 0.625547, top_k: 0.835469, samples/s: 1318.956 1612751364.79823
train: epoch 93, iter 1200, loss: 2.441478, top_1: 0.630117, top_k: 0.839023, samples/s: 1327.753 1612751384.0789278
train: epoch 93, iter 1300, loss: 2.358920, top_1: 0.625742, top_k: 0.833125, samples/s: 1321.163 1612751403.4559054
train: epoch 93, iter 1400, loss: 2.626295, top_1: 0.631836, top_k: 0.837578, samples/s: 1328.060 1612751422.7320905
train: epoch 93, iter 1500, loss: 2.496548, top_1: 0.629414, top_k: 0.836484, samples/s: 1329.811 1612751441.9828856
train: epoch 93, iter 1600, loss: 2.618789, top_1: 0.626406, top_k: 0.835117, samples/s: 1327.971 1612751461.2604203
train: epoch 93, iter 1700, loss: 2.670292, top_1: 0.625625, top_k: 0.835273, samples/s: 1317.569 1612751480.6901789
train: epoch 93, iter 1800, loss: 2.437363, top_1: 0.631797, top_k: 0.842656, samples/s: 1325.954 1612751499.9970486
train: epoch 93, iter 1900, loss: 2.649413, top_1: 0.625781, top_k: 0.834453, samples/s: 1328.351 1612751519.269076
train: epoch 93, iter 2000, loss: 2.481253, top_1: 0.627891, top_k: 0.834258, samples/s: 1327.373 1612751538.5552495
train: epoch 93, iter 2100, loss: 2.486761, top_1: 0.628047, top_k: 0.835820, samples/s: 1329.019 1612751557.81762
train: epoch 93, iter 2200, loss: 2.377026, top_1: 0.631602, top_k: 0.838125, samples/s: 1327.922 1612751577.0960093
train: epoch 93, iter 2300, loss: 2.552836, top_1: 0.625391, top_k: 0.831289, samples/s: 1326.105 1612751596.4005177
train: epoch 93, iter 2400, loss: 2.473970, top_1: 0.634414, top_k: 0.840156, samples/s: 1322.554 1612751615.7570074
train: epoch 93, iter 2500, loss: 2.434777, top_1: 0.631406, top_k: 0.833516, samples/s: 1325.068 1612751635.0767384
train: epoch 93, iter 2600, loss: 2.627871, top_1: 0.630156, top_k: 0.837305, samples/s: 1328.992 1612751654.3394532
train: epoch 93, iter 2700, loss: 2.610251, top_1: 0.624023, top_k: 0.836328, samples/s: 1317.938 1612751673.7637608
train: epoch 93, iter 2800, loss: 2.627826, top_1: 0.625391, top_k: 0.837187, samples/s: 1325.307 1612751693.0800297
train: epoch 93, iter 2900, loss: 2.464614, top_1: 0.625430, top_k: 0.834570, samples/s: 1326.158 1612751712.3839407
train: epoch 93, iter 3000, loss: 2.335531, top_1: 0.624961, top_k: 0.835703, samples/s: 1334.109 1612751731.5727515
train: epoch 93, iter 3100, loss: 2.639530, top_1: 0.629102, top_k: 0.835977, samples/s: 1318.805 1612751750.9842768
train: epoch 93, iter 3200, loss: 2.572895, top_1: 0.630352, top_k: 0.839023, samples/s: 1324.480 1612751770.3125737
train: epoch 93, iter 3300, loss: 2.687570, top_1: 0.629492, top_k: 0.833555, samples/s: 1327.411 1612751789.598335
train: epoch 93, iter 3400, loss: 2.312268, top_1: 0.628242, top_k: 0.834375, samples/s: 1327.206 1612751808.8868895
train: epoch 93, iter 3500, loss: 2.490126, top_1: 0.625469, top_k: 0.833984, samples/s: 1325.120 1612751828.2059548
train: epoch 93, iter 3600, loss: 2.612033, top_1: 0.624141, top_k: 0.834414, samples/s: 1323.868 1612751847.5432265
train: epoch 93, iter 3700, loss: 2.495702, top_1: 0.626367, top_k: 0.836211, samples/s: 1330.135 1612751866.7894063
train: epoch 93, iter 3800, loss: 2.616571, top_1: 0.626680, top_k: 0.835391, samples/s: 1321.898 1612751886.155514
train: epoch 93, iter 3900, loss: 2.392415, top_1: 0.622305, top_k: 0.833359, samples/s: 1328.803 1612751905.4209247
train: epoch 93, iter 4000, loss: 2.556076, top_1: 0.622695, top_k: 0.833555, samples/s: 1326.469 1612751924.7202585
train: epoch 93, iter 4100, loss: 2.584631, top_1: 0.625117, top_k: 0.835313, samples/s: 1321.797 1612751944.087891
train: epoch 93, iter 4200, loss: 2.755929, top_1: 0.619180, top_k: 0.831641, samples/s: 1327.298 1612751963.3751564
train: epoch 93, iter 4300, loss: 2.428459, top_1: 0.627578, top_k: 0.832930, samples/s: 1332.359 1612751982.58917
train: epoch 93, iter 4400, loss: 2.570285, top_1: 0.623555, top_k: 0.836172, samples/s: 1323.218 1612752001.9359381
train: epoch 93, iter 4500, loss: 2.348563, top_1: 0.622656, top_k: 0.835586, samples/s: 1319.657 1612752021.3349626
train: epoch 93, iter 4600, loss: 2.468458, top_1: 0.630625, top_k: 0.837344, samples/s: 1325.550 1612752040.6477134
train: epoch 93, iter 4700, loss: 2.739978, top_1: 0.627852, top_k: 0.834063, samples/s: 1322.222 1612752060.00902
train: epoch 93, iter 4800, loss: 2.486032, top_1: 0.626094, top_k: 0.832227, samples/s: 1326.828 1612752079.3031485
train: epoch 93, iter 4900, loss: 2.481279, top_1: 0.623516, top_k: 0.834219, samples/s: 1323.606 1612752098.644298
train: epoch 93, iter 5000, loss: 2.636136, top_1: 0.628867, top_k: 0.838516, samples/s: 1330.970 1612752117.8783767
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_93.
validation: epoch 93, iter 195, top_1: 0.660737, top_k: 0.874239, samples/s: 2746.588 1612752136.6268082
train: epoch 94, iter 100, loss: 2.506006, top_1: 0.633516, top_k: 0.842852, samples/s: 1365.540 1612752172.1901755
train: epoch 94, iter 200, loss: 2.658269, top_1: 0.636641, top_k: 0.841055, samples/s: 1357.987 1612752191.0415776
train: epoch 94, iter 300, loss: 2.507719, top_1: 0.632617, top_k: 0.839414, samples/s: 1361.942 1612752209.838284
train: epoch 94, iter 400, loss: 2.423457, top_1: 0.636094, top_k: 0.837500, samples/s: 1347.619 1612752228.834754
train: epoch 94, iter 500, loss: 2.425853, top_1: 0.638398, top_k: 0.842812, samples/s: 1326.393 1612752248.1352742
train: epoch 94, iter 600, loss: 2.392909, top_1: 0.637852, top_k: 0.844922, samples/s: 1330.305 1612752267.3788664
train: epoch 94, iter 700, loss: 2.537995, top_1: 0.636094, top_k: 0.843008, samples/s: 1325.039 1612752286.699111
train: epoch 94, iter 800, loss: 2.565433, top_1: 0.638789, top_k: 0.838945, samples/s: 1327.099 1612752305.98929
train: epoch 94, iter 900, loss: 2.594666, top_1: 0.640508, top_k: 0.840508, samples/s: 1326.029 1612752325.2949827
train: epoch 94, iter 1000, loss: 2.326044, top_1: 0.637734, top_k: 0.840859, samples/s: 1325.840 1612752344.6035626
train: epoch 94, iter 1100, loss: 2.533638, top_1: 0.633789, top_k: 0.839961, samples/s: 1329.057 1612752363.865297
train: epoch 94, iter 1200, loss: 2.683569, top_1: 0.630000, top_k: 0.836484, samples/s: 1333.889 1612752383.0572987
train: epoch 94, iter 1300, loss: 2.493568, top_1: 0.624180, top_k: 0.836797, samples/s: 1321.525 1612752402.4288356
train: epoch 94, iter 1400, loss: 2.435067, top_1: 0.630781, top_k: 0.840469, samples/s: 1330.109 1612752421.6754386
train: epoch 94, iter 1500, loss: 2.530758, top_1: 0.634961, top_k: 0.838633, samples/s: 1330.269 1612752440.91966
train: epoch 94, iter 1600, loss: 2.518322, top_1: 0.634297, top_k: 0.840352, samples/s: 1322.437 1612752460.277932
train: epoch 94, iter 1700, loss: 2.534832, top_1: 0.625781, top_k: 0.835742, samples/s: 1340.379 1612752479.3768878
train: epoch 94, iter 1800, loss: 2.668386, top_1: 0.630156, top_k: 0.838711, samples/s: 1331.883 1612752498.5978146
train: epoch 94, iter 1900, loss: 2.542929, top_1: 0.623789, top_k: 0.836133, samples/s: 1329.815 1612752517.8486834
train: epoch 94, iter 2000, loss: 2.534379, top_1: 0.627734, top_k: 0.836992, samples/s: 1331.229 1612752537.0789776
train: epoch 94, iter 2100, loss: 2.403558, top_1: 0.624023, top_k: 0.834883, samples/s: 1328.345 1612752556.3511229
train: epoch 94, iter 2200, loss: 2.549278, top_1: 0.624844, top_k: 0.833555, samples/s: 1325.794 1612752575.6602302
train: epoch 94, iter 2300, loss: 2.497567, top_1: 0.631797, top_k: 0.838633, samples/s: 1327.737 1612752594.9411542
train: epoch 94, iter 2400, loss: 2.532904, top_1: 0.633047, top_k: 0.843320, samples/s: 1332.563 1612752614.152331
train: epoch 94, iter 2500, loss: 2.550784, top_1: 0.631953, top_k: 0.838398, samples/s: 1323.221 1612752633.4990466
train: epoch 94, iter 2600, loss: 2.436504, top_1: 0.634219, top_k: 0.837266, samples/s: 1325.681 1612752652.8099475
train: epoch 94, iter 2700, loss: 2.520888, top_1: 0.626680, top_k: 0.835898, samples/s: 1332.894 1612752672.016161
train: epoch 94, iter 2800, loss: 2.471263, top_1: 0.632852, top_k: 0.836602, samples/s: 1324.680 1612752691.3416424
train: epoch 94, iter 2900, loss: 2.300179, top_1: 0.631875, top_k: 0.837734, samples/s: 1330.848 1612752710.5774405
train: epoch 94, iter 3000, loss: 2.527451, top_1: 0.627344, top_k: 0.839492, samples/s: 1335.851 1612752729.7413075
train: epoch 94, iter 3100, loss: 2.543536, top_1: 0.625273, top_k: 0.834023, samples/s: 1324.430 1612752749.070322
train: epoch 94, iter 3200, loss: 2.673604, top_1: 0.634258, top_k: 0.838477, samples/s: 1327.184 1612752768.3592947
train: epoch 94, iter 3300, loss: 2.512137, top_1: 0.628320, top_k: 0.836836, samples/s: 1315.954 1612752787.8128676
train: epoch 94, iter 3400, loss: 2.507960, top_1: 0.626523, top_k: 0.838008, samples/s: 1328.592 1612752807.081425
train: epoch 94, iter 3500, loss: 2.491135, top_1: 0.627227, top_k: 0.835000, samples/s: 1332.991 1612752826.2863061
train: epoch 94, iter 3600, loss: 2.694919, top_1: 0.625742, top_k: 0.834297, samples/s: 1327.993 1612752845.5635507
train: epoch 94, iter 3700, loss: 2.592010, top_1: 0.624414, top_k: 0.836172, samples/s: 1325.531 1612752864.8765466
train: epoch 94, iter 3800, loss: 2.527529, top_1: 0.626641, top_k: 0.835703, samples/s: 1333.990 1612752884.067085
train: epoch 94, iter 3900, loss: 2.460048, top_1: 0.624922, top_k: 0.833125, samples/s: 1332.774 1612752903.2751734
train: epoch 94, iter 4000, loss: 2.734280, top_1: 0.625430, top_k: 0.835195, samples/s: 1325.127 1612752922.5941257
train: epoch 94, iter 4100, loss: 2.410131, top_1: 0.627734, top_k: 0.834258, samples/s: 1330.271 1612752941.8382602
train: epoch 94, iter 4200, loss: 2.541646, top_1: 0.627344, top_k: 0.837578, samples/s: 1335.684 1612752961.004524
train: epoch 94, iter 4300, loss: 2.676239, top_1: 0.628945, top_k: 0.836133, samples/s: 1323.795 1612752980.3429177
train: epoch 94, iter 4400, loss: 2.499828, top_1: 0.628828, top_k: 0.835000, samples/s: 1328.523 1612752999.6123724
train: epoch 94, iter 4500, loss: 2.484133, top_1: 0.632148, top_k: 0.838047, samples/s: 1323.614 1612753018.953333
train: epoch 94, iter 4600, loss: 2.414743, top_1: 0.627383, top_k: 0.836367, samples/s: 1342.503 1612753038.022279
train: epoch 94, iter 4700, loss: 2.686172, top_1: 0.623789, top_k: 0.833164, samples/s: 1321.506 1612753057.3940861
train: epoch 94, iter 4800, loss: 2.526430, top_1: 0.626133, top_k: 0.835586, samples/s: 1332.206 1612753076.610246
train: epoch 94, iter 4900, loss: 2.458338, top_1: 0.626211, top_k: 0.831758, samples/s: 1332.382 1612753095.8239655
train: epoch 94, iter 5000, loss: 2.351104, top_1: 0.637813, top_k: 0.842969, samples/s: 1326.181 1612753115.1276126
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_94.
validation: epoch 94, iter 195, top_1: 0.670032, top_k: 0.877905, samples/s: 2782.235 1612753133.6104536
train: epoch 95, iter 100, loss: 2.546414, top_1: 0.645742, top_k: 0.848906, samples/s: 1359.446 1612753168.7409687
train: epoch 95, iter 200, loss: 2.498866, top_1: 0.640703, top_k: 0.841836, samples/s: 1367.634 1612753187.4594183
train: epoch 95, iter 300, loss: 2.494530, top_1: 0.640000, top_k: 0.844844, samples/s: 1360.449 1612753206.276626
train: epoch 95, iter 400, loss: 2.762728, top_1: 0.640859, top_k: 0.843086, samples/s: 1347.330 1612753225.2771318
train: epoch 95, iter 500, loss: 2.573972, top_1: 0.635586, top_k: 0.839922, samples/s: 1325.445 1612753244.591405
train: epoch 95, iter 600, loss: 2.675603, top_1: 0.634102, top_k: 0.838008, samples/s: 1323.152 1612753263.9391496
train: epoch 95, iter 700, loss: 2.343755, top_1: 0.636328, top_k: 0.843086, samples/s: 1336.054 1612753283.1000867
train: epoch 95, iter 800, loss: 2.660804, top_1: 0.637656, top_k: 0.841953, samples/s: 1319.890 1612753302.495616
train: epoch 95, iter 900, loss: 2.449688, top_1: 0.634141, top_k: 0.840391, samples/s: 1334.112 1612753321.684471
train: epoch 95, iter 1000, loss: 2.314932, top_1: 0.635000, top_k: 0.842422, samples/s: 1321.672 1612753341.0538464
train: epoch 95, iter 1100, loss: 2.504185, top_1: 0.637695, top_k: 0.841484, samples/s: 1318.817 1612753360.465268
train: epoch 95, iter 1200, loss: 2.503896, top_1: 0.637734, top_k: 0.841953, samples/s: 1336.042 1612753379.6262555
train: epoch 95, iter 1300, loss: 2.467638, top_1: 0.631289, top_k: 0.841875, samples/s: 1331.854 1612753398.847654
train: epoch 95, iter 1400, loss: 2.647393, top_1: 0.632930, top_k: 0.840742, samples/s: 1329.154 1612753418.10797
train: epoch 95, iter 1500, loss: 2.464888, top_1: 0.624727, top_k: 0.834375, samples/s: 1331.703 1612753437.3314877
train: epoch 95, iter 1600, loss: 2.492967, top_1: 0.633516, top_k: 0.841172, samples/s: 1331.124 1612753456.5633347
train: epoch 95, iter 1700, loss: 2.565796, top_1: 0.630391, top_k: 0.838281, samples/s: 1324.789 1612753475.887147
train: epoch 95, iter 1800, loss: 2.549012, top_1: 0.636328, top_k: 0.841797, samples/s: 1325.144 1612753495.205781
train: epoch 95, iter 1900, loss: 2.648864, top_1: 0.633242, top_k: 0.839063, samples/s: 1324.487 1612753514.5341063
train: epoch 95, iter 2000, loss: 2.460047, top_1: 0.630820, top_k: 0.842930, samples/s: 1331.284 1612753533.7636626
train: epoch 95, iter 2100, loss: 2.693851, top_1: 0.637461, top_k: 0.840938, samples/s: 1329.169 1612753553.0238247
train: epoch 95, iter 2200, loss: 2.366373, top_1: 0.636055, top_k: 0.840586, samples/s: 1333.054 1612753572.2277966
train: epoch 95, iter 2300, loss: 2.488883, top_1: 0.641641, top_k: 0.845195, samples/s: 1333.108 1612753591.4310412
train: epoch 95, iter 2400, loss: 2.537175, top_1: 0.634648, top_k: 0.839531, samples/s: 1329.960 1612753610.6797001
train: epoch 95, iter 2500, loss: 2.494469, top_1: 0.631758, top_k: 0.839414, samples/s: 1332.102 1612753629.8974814
train: epoch 95, iter 2600, loss: 2.578008, top_1: 0.632109, top_k: 0.840234, samples/s: 1329.445 1612753649.1536808
train: epoch 95, iter 2700, loss: 2.541872, top_1: 0.629375, top_k: 0.838008, samples/s: 1331.631 1612753668.3781748
train: epoch 95, iter 2800, loss: 2.709046, top_1: 0.628867, top_k: 0.836328, samples/s: 1325.127 1612753687.697193
train: epoch 95, iter 2900, loss: 2.326121, top_1: 0.631016, top_k: 0.835039, samples/s: 1332.984 1612753706.9020925
train: epoch 95, iter 3000, loss: 2.552898, top_1: 0.632812, top_k: 0.841055, samples/s: 1332.148 1612753726.1192346
train: epoch 95, iter 3100, loss: 2.575471, top_1: 0.637578, top_k: 0.841289, samples/s: 1328.402 1612753745.3905041
train: epoch 95, iter 3200, loss: 2.676550, top_1: 0.628750, top_k: 0.839336, samples/s: 1330.889 1612753764.6257737
train: epoch 95, iter 3300, loss: 2.474474, top_1: 0.627969, top_k: 0.836406, samples/s: 1330.888 1612753783.8610425
train: epoch 95, iter 3400, loss: 2.522632, top_1: 0.633398, top_k: 0.836523, samples/s: 1333.933 1612753803.0523965
train: epoch 95, iter 3500, loss: 2.483124, top_1: 0.629648, top_k: 0.839219, samples/s: 1329.320 1612753822.3103626
train: epoch 95, iter 3600, loss: 2.592871, top_1: 0.628398, top_k: 0.835469, samples/s: 1328.729 1612753841.5768754
train: epoch 95, iter 3700, loss: 2.602225, top_1: 0.630547, top_k: 0.836602, samples/s: 1324.371 1612753860.906909
train: epoch 95, iter 3800, loss: 2.400100, top_1: 0.623633, top_k: 0.837031, samples/s: 1336.192 1612753880.065757
train: epoch 95, iter 3900, loss: 2.550256, top_1: 0.632148, top_k: 0.839844, samples/s: 1331.814 1612753899.287718
train: epoch 95, iter 4000, loss: 2.468811, top_1: 0.629453, top_k: 0.837148, samples/s: 1329.449 1612753918.5437663
train: epoch 95, iter 4100, loss: 2.503656, top_1: 0.629414, top_k: 0.835547, samples/s: 1324.922 1612753937.865624
train: epoch 95, iter 4200, loss: 2.536429, top_1: 0.630234, top_k: 0.835820, samples/s: 1334.549 1612753957.0482078
train: epoch 95, iter 4300, loss: 2.521624, top_1: 0.629336, top_k: 0.837109, samples/s: 1336.276 1612753976.2058861
train: epoch 95, iter 4400, loss: 2.399751, top_1: 0.630195, top_k: 0.838398, samples/s: 1333.024 1612753995.4103324
train: epoch 95, iter 4500, loss: 2.684855, top_1: 0.628516, top_k: 0.835117, samples/s: 1319.311 1612754014.8144119
train: epoch 95, iter 4600, loss: 2.600722, top_1: 0.629453, top_k: 0.831836, samples/s: 1335.595 1612754033.9818985
train: epoch 95, iter 4700, loss: 2.518959, top_1: 0.631211, top_k: 0.839531, samples/s: 1331.338 1612754053.2106402
train: epoch 95, iter 4800, loss: 2.525093, top_1: 0.629180, top_k: 0.835547, samples/s: 1330.208 1612754072.4557865
train: epoch 95, iter 4900, loss: 2.397475, top_1: 0.628516, top_k: 0.837734, samples/s: 1330.466 1612754091.6971252
train: epoch 95, iter 5000, loss: 2.357294, top_1: 0.638320, top_k: 0.842930, samples/s: 1330.744 1612754110.9345274
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_95.
validation: epoch 95, iter 195, top_1: 0.665064, top_k: 0.877083, samples/s: 2814.472 1612754129.2420359
train: epoch 96, iter 100, loss: 2.522107, top_1: 0.638828, top_k: 0.846172, samples/s: 1366.286 1612754163.770294
train: epoch 96, iter 200, loss: 2.340610, top_1: 0.647266, top_k: 0.850547, samples/s: 1362.002 1612754182.5662353
train: epoch 96, iter 300, loss: 2.474810, top_1: 0.641250, top_k: 0.841289, samples/s: 1360.207 1612754201.3868234
train: epoch 96, iter 400, loss: 2.517439, top_1: 0.633984, top_k: 0.844922, samples/s: 1343.928 1612754220.435461
train: epoch 96, iter 500, loss: 2.673535, top_1: 0.642188, top_k: 0.844570, samples/s: 1333.740 1612754239.6295822
train: epoch 96, iter 600, loss: 2.346680, top_1: 0.632969, top_k: 0.841562, samples/s: 1327.845 1612754258.9090302
train: epoch 96, iter 700, loss: 2.613105, top_1: 0.640156, top_k: 0.843242, samples/s: 1323.346 1612754278.2539136
train: epoch 96, iter 800, loss: 2.508138, top_1: 0.640625, top_k: 0.842656, samples/s: 1323.811 1612754297.592038
train: epoch 96, iter 900, loss: 2.486542, top_1: 0.641055, top_k: 0.845000, samples/s: 1326.641 1612754316.8888614
train: epoch 96, iter 1000, loss: 2.587519, top_1: 0.633164, top_k: 0.841172, samples/s: 1336.509 1612754336.0433364
train: epoch 96, iter 1100, loss: 2.452599, top_1: 0.638320, top_k: 0.842578, samples/s: 1323.804 1612754355.3815298
train: epoch 96, iter 1200, loss: 2.422700, top_1: 0.634258, top_k: 0.838906, samples/s: 1323.346 1612754374.7263641
train: epoch 96, iter 1300, loss: 2.497045, top_1: 0.639414, top_k: 0.844609, samples/s: 1327.374 1612754394.0125246
train: epoch 96, iter 1400, loss: 2.532556, top_1: 0.632734, top_k: 0.839805, samples/s: 1335.244 1612754413.1850665
train: epoch 96, iter 1500, loss: 2.596585, top_1: 0.638320, top_k: 0.842734, samples/s: 1331.620 1612754432.409808
train: epoch 96, iter 1600, loss: 2.683763, top_1: 0.637969, top_k: 0.842578, samples/s: 1326.736 1612754451.7052898
train: epoch 96, iter 1700, loss: 2.561320, top_1: 0.637578, top_k: 0.842891, samples/s: 1322.757 1612754471.0588062
train: epoch 96, iter 1800, loss: 2.602179, top_1: 0.638750, top_k: 0.844297, samples/s: 1328.703 1612754490.325664
train: epoch 96, iter 1900, loss: 2.416540, top_1: 0.637813, top_k: 0.840508, samples/s: 1331.518 1612754509.5519063
train: epoch 96, iter 2000, loss: 2.564165, top_1: 0.635938, top_k: 0.842383, samples/s: 1331.126 1612754528.7837317
train: epoch 96, iter 2100, loss: 2.220518, top_1: 0.634453, top_k: 0.837578, samples/s: 1328.065 1612754548.059872
train: epoch 96, iter 2200, loss: 2.597271, top_1: 0.629453, top_k: 0.840938, samples/s: 1320.763 1612754567.4426532
train: epoch 96, iter 2300, loss: 2.587397, top_1: 0.636641, top_k: 0.841953, samples/s: 1317.249 1612754586.8770514
train: epoch 96, iter 2400, loss: 2.405789, top_1: 0.628828, top_k: 0.838750, samples/s: 1337.194 1612754606.0216656
train: epoch 96, iter 2500, loss: 2.582036, top_1: 0.635312, top_k: 0.839648, samples/s: 1338.717 1612754625.1445065
train: epoch 96, iter 2600, loss: 2.503599, top_1: 0.631563, top_k: 0.843008, samples/s: 1322.616 1612754644.4999492
train: epoch 96, iter 2700, loss: 2.483558, top_1: 0.629141, top_k: 0.841602, samples/s: 1330.750 1612754663.7372794
train: epoch 96, iter 2800, loss: 2.422917, top_1: 0.632539, top_k: 0.841133, samples/s: 1328.812 1612754683.0025382
train: epoch 96, iter 2900, loss: 2.503131, top_1: 0.628281, top_k: 0.837187, samples/s: 1329.538 1612754702.257404
train: epoch 96, iter 3000, loss: 2.510557, top_1: 0.636680, top_k: 0.839531, samples/s: 1333.749 1612754721.4514003
train: epoch 96, iter 3100, loss: 2.444173, top_1: 0.628828, top_k: 0.835586, samples/s: 1320.142 1612754740.8432894
train: epoch 96, iter 3200, loss: 2.660211, top_1: 0.631797, top_k: 0.839492, samples/s: 1335.728 1612754760.0088704
train: epoch 96, iter 3300, loss: 2.473530, top_1: 0.634102, top_k: 0.838477, samples/s: 1332.042 1612754779.2275188
train: epoch 96, iter 3400, loss: 2.499561, top_1: 0.636602, top_k: 0.844570, samples/s: 1327.560 1612754798.5110564
train: epoch 96, iter 3500, loss: 2.567018, top_1: 0.634062, top_k: 0.839336, samples/s: 1324.973 1612754817.832197
train: epoch 96, iter 3600, loss: 2.626245, top_1: 0.628398, top_k: 0.837930, samples/s: 1331.042 1612754837.0651183
train: epoch 96, iter 3700, loss: 2.754098, top_1: 0.631914, top_k: 0.838945, samples/s: 1328.195 1612754856.339527
train: epoch 96, iter 3800, loss: 2.570777, top_1: 0.635742, top_k: 0.842617, samples/s: 1324.658 1612754875.665139
train: epoch 96, iter 3900, loss: 2.494826, top_1: 0.627812, top_k: 0.839023, samples/s: 1328.904 1612754894.9291468
train: epoch 96, iter 4000, loss: 2.684931, top_1: 0.631836, top_k: 0.839141, samples/s: 1331.086 1612754914.16162
train: epoch 96, iter 4100, loss: 2.555590, top_1: 0.630625, top_k: 0.836992, samples/s: 1331.974 1612754933.3812137
train: epoch 96, iter 4200, loss: 2.357121, top_1: 0.625586, top_k: 0.839648, samples/s: 1327.442 1612754952.6663988
train: epoch 96, iter 4300, loss: 2.582922, top_1: 0.633594, top_k: 0.839297, samples/s: 1323.479 1612754972.009325
train: epoch 96, iter 4400, loss: 2.415519, top_1: 0.634453, top_k: 0.838320, samples/s: 1337.337 1612754991.1519778
train: epoch 96, iter 4500, loss: 2.567822, top_1: 0.629922, top_k: 0.838828, samples/s: 1331.051 1612755010.3848176
train: epoch 96, iter 4600, loss: 2.624786, top_1: 0.626758, top_k: 0.837773, samples/s: 1326.654 1612755029.6814663
train: epoch 96, iter 4700, loss: 2.624015, top_1: 0.632734, top_k: 0.838125, samples/s: 1328.778 1612755048.9473104
train: epoch 96, iter 4800, loss: 2.461502, top_1: 0.634258, top_k: 0.835039, samples/s: 1327.451 1612755068.2323372
train: epoch 96, iter 4900, loss: 2.605595, top_1: 0.632617, top_k: 0.839531, samples/s: 1328.953 1612755087.4957323
train: epoch 96, iter 5000, loss: 2.518419, top_1: 0.639062, top_k: 0.843516, samples/s: 1327.352 1612755106.7822108
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_96.
validation: epoch 96, iter 195, top_1: 0.676903, top_k: 0.885216, samples/s: 2847.131 1612755124.8934162
train: epoch 97, iter 100, loss: 2.395995, top_1: 0.641367, top_k: 0.847070, samples/s: 1357.238 1612755159.7112556
train: epoch 97, iter 200, loss: 2.475049, top_1: 0.641445, top_k: 0.845703, samples/s: 1358.531 1612755178.5554175
train: epoch 97, iter 300, loss: 2.570740, top_1: 0.641172, top_k: 0.843555, samples/s: 1358.339 1612755197.4016607
train: epoch 97, iter 400, loss: 2.302169, top_1: 0.643164, top_k: 0.846250, samples/s: 1342.997 1612755216.463508
train: epoch 97, iter 500, loss: 2.537265, top_1: 0.641797, top_k: 0.846367, samples/s: 1320.458 1612755235.8507168
train: epoch 97, iter 600, loss: 2.241400, top_1: 0.643359, top_k: 0.849297, samples/s: 1326.190 1612755255.154191
train: epoch 97, iter 700, loss: 2.470256, top_1: 0.637852, top_k: 0.841523, samples/s: 1322.130 1612755274.5168788
train: epoch 97, iter 800, loss: 2.396143, top_1: 0.642695, top_k: 0.844570, samples/s: 1319.383 1612755293.9199364
train: epoch 97, iter 900, loss: 2.536631, top_1: 0.640273, top_k: 0.847070, samples/s: 1322.572 1612755313.276045
train: epoch 97, iter 1000, loss: 2.515189, top_1: 0.636719, top_k: 0.840977, samples/s: 1329.282 1612755332.534561
train: epoch 97, iter 1100, loss: 2.414915, top_1: 0.638750, top_k: 0.840586, samples/s: 1319.288 1612755351.9390147
train: epoch 97, iter 1200, loss: 2.428467, top_1: 0.641211, top_k: 0.844023, samples/s: 1324.930 1612755371.260766
train: epoch 97, iter 1300, loss: 2.630098, top_1: 0.635781, top_k: 0.842656, samples/s: 1324.334 1612755390.591354
train: epoch 97, iter 1400, loss: 2.550829, top_1: 0.637422, top_k: 0.842539, samples/s: 1323.271 1612755409.937271
train: epoch 97, iter 1500, loss: 2.579814, top_1: 0.637578, top_k: 0.842031, samples/s: 1316.986 1612755429.3756254
train: epoch 97, iter 1600, loss: 2.352782, top_1: 0.635273, top_k: 0.840859, samples/s: 1332.710 1612755448.5845594
train: epoch 97, iter 1700, loss: 2.373583, top_1: 0.643594, top_k: 0.845078, samples/s: 1324.371 1612755467.9144402
train: epoch 97, iter 1800, loss: 2.419019, top_1: 0.642656, top_k: 0.845742, samples/s: 1320.526 1612755487.3007069
train: epoch 97, iter 1900, loss: 2.388706, top_1: 0.636602, top_k: 0.842773, samples/s: 1329.373 1612755506.5579116
train: epoch 97, iter 2000, loss: 2.432719, top_1: 0.637227, top_k: 0.845273, samples/s: 1320.937 1612755525.9380474
train: epoch 97, iter 2100, loss: 2.588677, top_1: 0.640859, top_k: 0.843437, samples/s: 1321.792 1612755545.30577
train: epoch 97, iter 2200, loss: 2.443614, top_1: 0.635977, top_k: 0.845000, samples/s: 1322.381 1612755564.6648
train: epoch 97, iter 2300, loss: 2.458414, top_1: 0.636758, top_k: 0.839102, samples/s: 1330.089 1612755583.9115438
train: epoch 97, iter 2400, loss: 2.356253, top_1: 0.638047, top_k: 0.841055, samples/s: 1328.193 1612755603.1858625
train: epoch 97, iter 2500, loss: 2.425948, top_1: 0.639687, top_k: 0.841406, samples/s: 1319.537 1612755622.5866935
train: epoch 97, iter 2600, loss: 2.415525, top_1: 0.633945, top_k: 0.839844, samples/s: 1323.153 1612755641.934338
train: epoch 97, iter 2700, loss: 2.525929, top_1: 0.636055, top_k: 0.844414, samples/s: 1322.482 1612755661.2919447
train: epoch 97, iter 2800, loss: 2.476180, top_1: 0.633945, top_k: 0.836875, samples/s: 1331.423 1612755680.5194552
train: epoch 97, iter 2900, loss: 2.456324, top_1: 0.634844, top_k: 0.839688, samples/s: 1325.435 1612755699.8338776
train: epoch 97, iter 3000, loss: 2.573097, top_1: 0.636641, top_k: 0.840273, samples/s: 1322.822 1612755719.1864386
train: epoch 97, iter 3100, loss: 2.618237, top_1: 0.632656, top_k: 0.840820, samples/s: 1320.424 1612755738.5741181
train: epoch 97, iter 3200, loss: 2.475406, top_1: 0.633984, top_k: 0.840547, samples/s: 1324.850 1612755757.8970878
train: epoch 97, iter 3300, loss: 2.403412, top_1: 0.634102, top_k: 0.842812, samples/s: 1320.953 1612755777.2771223
train: epoch 97, iter 3400, loss: 2.641234, top_1: 0.628164, top_k: 0.839336, samples/s: 1322.936 1612755796.6278982
train: epoch 97, iter 3500, loss: 2.459667, top_1: 0.635820, top_k: 0.841289, samples/s: 1320.542 1612755816.0139685
train: epoch 97, iter 3600, loss: 2.458949, top_1: 0.634297, top_k: 0.840313, samples/s: 1332.177 1612755835.2306342
train: epoch 97, iter 3700, loss: 2.609272, top_1: 0.636445, top_k: 0.837930, samples/s: 1322.493 1612755854.5879173
train: epoch 97, iter 3800, loss: 2.605193, top_1: 0.632266, top_k: 0.837266, samples/s: 1324.549 1612755873.9153135
train: epoch 97, iter 3900, loss: 2.649727, top_1: 0.639922, top_k: 0.842461, samples/s: 1324.517 1612755893.2430935
train: epoch 97, iter 4000, loss: 2.518904, top_1: 0.628008, top_k: 0.838906, samples/s: 1320.986 1612755912.6225395
train: epoch 97, iter 4100, loss: 2.460725, top_1: 0.631133, top_k: 0.839219, samples/s: 1325.678 1612755931.9333918
train: epoch 97, iter 4200, loss: 2.444289, top_1: 0.633320, top_k: 0.838906, samples/s: 1325.616 1612755951.245156
train: epoch 97, iter 4300, loss: 2.655301, top_1: 0.631172, top_k: 0.839219, samples/s: 1325.097 1612755970.5645442
train: epoch 97, iter 4400, loss: 2.615953, top_1: 0.637227, top_k: 0.839141, samples/s: 1321.843 1612755989.9313903
train: epoch 97, iter 4500, loss: 2.488060, top_1: 0.630039, top_k: 0.836875, samples/s: 1322.835 1612756009.2837756
train: epoch 97, iter 4600, loss: 2.516877, top_1: 0.637539, top_k: 0.841328, samples/s: 1327.322 1612756028.5707617
train: epoch 97, iter 4700, loss: 2.637478, top_1: 0.633789, top_k: 0.841641, samples/s: 1329.920 1612756047.820013
train: epoch 97, iter 4800, loss: 2.499276, top_1: 0.633437, top_k: 0.837812, samples/s: 1327.601 1612756067.102944
train: epoch 97, iter 4900, loss: 2.720895, top_1: 0.627188, top_k: 0.839414, samples/s: 1313.577 1612756086.5916839
train: epoch 97, iter 5000, loss: 2.327442, top_1: 0.629062, top_k: 0.838906, samples/s: 1328.001 1612756105.8687782
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_97.
validation: epoch 97, iter 195, top_1: 0.680709, top_k: 0.885797, samples/s: 2784.486 1612756124.3908622
train: epoch 98, iter 100, loss: 2.294042, top_1: 0.643828, top_k: 0.848867, samples/s: 1361.203 1612756159.0068738
train: epoch 98, iter 200, loss: 2.263105, top_1: 0.641328, top_k: 0.849375, samples/s: 1358.800 1612756177.8471768
train: epoch 98, iter 300, loss: 2.534395, top_1: 0.641602, top_k: 0.844727, samples/s: 1355.638 1612756196.7311156
train: epoch 98, iter 400, loss: 2.444322, top_1: 0.648711, top_k: 0.849336, samples/s: 1347.474 1612756215.7296596
train: epoch 98, iter 500, loss: 2.234487, top_1: 0.642188, top_k: 0.848242, samples/s: 1326.184 1612756235.0331812
train: epoch 98, iter 600, loss: 2.506388, top_1: 0.638711, top_k: 0.845586, samples/s: 1326.482 1612756254.332298
train: epoch 98, iter 700, loss: 2.600763, top_1: 0.641211, top_k: 0.841992, samples/s: 1327.113 1612756273.6222627
train: epoch 98, iter 800, loss: 2.512558, top_1: 0.642461, top_k: 0.843281, samples/s: 1324.804 1612756292.9458616
train: epoch 98, iter 900, loss: 2.443529, top_1: 0.644883, top_k: 0.848398, samples/s: 1320.147 1612756312.3377457
train: epoch 98, iter 1000, loss: 2.540674, top_1: 0.639453, top_k: 0.841758, samples/s: 1328.816 1612756331.602989
train: epoch 98, iter 1100, loss: 2.396112, top_1: 0.640625, top_k: 0.846211, samples/s: 1329.927 1612756350.852163
train: epoch 98, iter 1200, loss: 2.658387, top_1: 0.646602, top_k: 0.849063, samples/s: 1321.063 1612756370.230425
train: epoch 98, iter 1300, loss: 2.436085, top_1: 0.640742, top_k: 0.845430, samples/s: 1328.101 1612756389.5060391
train: epoch 98, iter 1400, loss: 2.701684, top_1: 0.643164, top_k: 0.848008, samples/s: 1328.641 1612756408.7738693
train: epoch 98, iter 1500, loss: 2.410544, top_1: 0.644883, top_k: 0.846875, samples/s: 1324.522 1612756428.1016014
train: epoch 98, iter 1600, loss: 2.554690, top_1: 0.639062, top_k: 0.843555, samples/s: 1328.294 1612756447.3745492
train: epoch 98, iter 1700, loss: 2.761510, top_1: 0.633789, top_k: 0.843867, samples/s: 1335.187 1612756466.5477898
train: epoch 98, iter 1800, loss: 2.338877, top_1: 0.638008, top_k: 0.842578, samples/s: 1327.605 1612756485.8306365
train: epoch 98, iter 1900, loss: 2.427927, top_1: 0.649961, top_k: 0.848086, samples/s: 1322.408 1612756505.1892974
train: epoch 98, iter 2000, loss: 2.293326, top_1: 0.635273, top_k: 0.844258, samples/s: 1325.878 1612756524.4973168
train: epoch 98, iter 2100, loss: 2.355561, top_1: 0.642148, top_k: 0.846055, samples/s: 1333.296 1612756543.6978023
train: epoch 98, iter 2200, loss: 2.538195, top_1: 0.639453, top_k: 0.843125, samples/s: 1329.420 1612756562.9542677
train: epoch 98, iter 2300, loss: 2.503615, top_1: 0.640352, top_k: 0.841641, samples/s: 1332.375 1612756582.1680694
train: epoch 98, iter 2400, loss: 2.568905, top_1: 0.638750, top_k: 0.843086, samples/s: 1334.448 1612756601.3520837
train: epoch 98, iter 2500, loss: 2.472183, top_1: 0.638555, top_k: 0.846484, samples/s: 1322.842 1612756620.7042925
train: epoch 98, iter 2600, loss: 2.420186, top_1: 0.637578, top_k: 0.843359, samples/s: 1326.525 1612756640.0028653
train: epoch 98, iter 2700, loss: 2.553654, top_1: 0.633359, top_k: 0.839180, samples/s: 1325.447 1612756659.3171077
train: epoch 98, iter 2800, loss: 2.492099, top_1: 0.640586, top_k: 0.843320, samples/s: 1336.402 1612756678.4729757
train: epoch 98, iter 2900, loss: 2.314488, top_1: 0.635117, top_k: 0.839570, samples/s: 1327.404 1612756697.7587347
train: epoch 98, iter 3000, loss: 2.440942, top_1: 0.635156, top_k: 0.838711, samples/s: 1330.467 1612756717.0001078
train: epoch 98, iter 3100, loss: 2.470398, top_1: 0.634570, top_k: 0.842344, samples/s: 1327.479 1612756736.284832
train: epoch 98, iter 3200, loss: 2.443842, top_1: 0.634414, top_k: 0.844375, samples/s: 1326.045 1612756755.5904043
train: epoch 98, iter 3300, loss: 2.448219, top_1: 0.633008, top_k: 0.842305, samples/s: 1332.135 1612756774.8075652
train: epoch 98, iter 3400, loss: 2.349343, top_1: 0.639141, top_k: 0.841328, samples/s: 1331.186 1612756794.0385437
train: epoch 98, iter 3500, loss: 2.390727, top_1: 0.635508, top_k: 0.837539, samples/s: 1330.218 1612756813.2835608
train: epoch 98, iter 3600, loss: 2.450033, top_1: 0.640977, top_k: 0.843164, samples/s: 1327.365 1612756832.569925
train: epoch 98, iter 3700, loss: 2.417015, top_1: 0.637695, top_k: 0.843047, samples/s: 1333.004 1612756851.7747092
train: epoch 98, iter 3800, loss: 2.508062, top_1: 0.637305, top_k: 0.843594, samples/s: 1329.789 1612756871.0257633
train: epoch 98, iter 3900, loss: 2.409763, top_1: 0.636328, top_k: 0.840078, samples/s: 1330.977 1612756890.2598288
train: epoch 98, iter 4000, loss: 2.580119, top_1: 0.636836, top_k: 0.840742, samples/s: 1331.879 1612756909.4807742
train: epoch 98, iter 4100, loss: 2.441880, top_1: 0.634805, top_k: 0.842383, samples/s: 1330.095 1612756928.7275133
train: epoch 98, iter 4200, loss: 2.444468, top_1: 0.634922, top_k: 0.843633, samples/s: 1327.647 1612756948.0097034
train: epoch 98, iter 4300, loss: 2.452820, top_1: 0.635117, top_k: 0.838828, samples/s: 1328.259 1612756967.2830417
train: epoch 98, iter 4400, loss: 2.526571, top_1: 0.635781, top_k: 0.841719, samples/s: 1323.491 1612756986.625863
train: epoch 98, iter 4500, loss: 2.434988, top_1: 0.635234, top_k: 0.841953, samples/s: 1341.288 1612757005.711954
train: epoch 98, iter 4600, loss: 2.412704, top_1: 0.638398, top_k: 0.841250, samples/s: 1330.748 1612757024.9493732
train: epoch 98, iter 4700, loss: 2.456949, top_1: 0.637227, top_k: 0.839766, samples/s: 1314.761 1612757044.4205322
train: epoch 98, iter 4800, loss: 2.441990, top_1: 0.634531, top_k: 0.839961, samples/s: 1334.715 1612757063.6005867
train: epoch 98, iter 4900, loss: 2.467036, top_1: 0.639727, top_k: 0.842891, samples/s: 1328.347 1612757082.8727279
train: epoch 98, iter 5000, loss: 2.424626, top_1: 0.641914, top_k: 0.841602, samples/s: 1333.702 1612757102.067413
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_98.
validation: epoch 98, iter 195, top_1: 0.678446, top_k: 0.885116, samples/s: 2783.259 1612757120.6144416
train: epoch 99, iter 100, loss: 2.409294, top_1: 0.652070, top_k: 0.853008, samples/s: 1363.031 1612757155.2732267
train: epoch 99, iter 200, loss: 2.465075, top_1: 0.651602, top_k: 0.851445, samples/s: 1361.065 1612757174.0819924
train: epoch 99, iter 300, loss: 2.622715, top_1: 0.646133, top_k: 0.848398, samples/s: 1358.013 1612757192.933092
train: epoch 99, iter 400, loss: 2.568957, top_1: 0.646992, top_k: 0.845273, samples/s: 1354.057 1612757211.8391898
train: epoch 99, iter 500, loss: 2.509428, top_1: 0.643477, top_k: 0.844648, samples/s: 1325.244 1612757231.1564503
train: epoch 99, iter 600, loss: 2.515190, top_1: 0.644258, top_k: 0.846133, samples/s: 1317.226 1612757250.5911994
train: epoch 99, iter 700, loss: 2.438580, top_1: 0.646992, top_k: 0.849414, samples/s: 1335.441 1612757269.7608745
train: epoch 99, iter 800, loss: 2.497117, top_1: 0.641875, top_k: 0.845742, samples/s: 1322.308 1612757289.1209967
train: epoch 99, iter 900, loss: 2.462575, top_1: 0.644492, top_k: 0.849375, samples/s: 1328.598 1612757308.3893888
train: epoch 99, iter 1000, loss: 2.498712, top_1: 0.642227, top_k: 0.845742, samples/s: 1332.383 1612757327.6030695
train: epoch 99, iter 1100, loss: 2.597868, top_1: 0.644453, top_k: 0.846484, samples/s: 1322.179 1612757346.965055
train: epoch 99, iter 1200, loss: 2.394302, top_1: 0.642734, top_k: 0.845938, samples/s: 1321.737 1612757366.3335102
train: epoch 99, iter 1300, loss: 2.272240, top_1: 0.645234, top_k: 0.846250, samples/s: 1330.864 1612757385.5692227
train: epoch 99, iter 1400, loss: 2.473886, top_1: 0.645000, top_k: 0.846094, samples/s: 1329.052 1612757404.8310635
train: epoch 99, iter 1500, loss: 2.306940, top_1: 0.638633, top_k: 0.844492, samples/s: 1330.325 1612757424.0744596
train: epoch 99, iter 1600, loss: 2.351904, top_1: 0.639570, top_k: 0.845313, samples/s: 1318.849 1612757443.4853063
train: epoch 99, iter 1700, loss: 2.438564, top_1: 0.644062, top_k: 0.843047, samples/s: 1325.987 1612757462.791651
train: epoch 99, iter 1800, loss: 2.569289, top_1: 0.637422, top_k: 0.844648, samples/s: 1330.400 1612757482.034055
train: epoch 99, iter 1900, loss: 2.502694, top_1: 0.639023, top_k: 0.843281, samples/s: 1326.326 1612757501.335604
train: epoch 99, iter 2000, loss: 2.627528, top_1: 0.641016, top_k: 0.847773, samples/s: 1330.536 1612757520.5758257
train: epoch 99, iter 2100, loss: 2.594094, top_1: 0.639844, top_k: 0.845938, samples/s: 1329.818 1612757539.8265228
train: epoch 99, iter 2200, loss: 2.735599, top_1: 0.642578, top_k: 0.847891, samples/s: 1329.995 1612757559.0748184
train: epoch 99, iter 2300, loss: 2.450595, top_1: 0.647773, top_k: 0.847031, samples/s: 1328.102 1612757578.3503573
train: epoch 99, iter 2400, loss: 2.318611, top_1: 0.638203, top_k: 0.844766, samples/s: 1330.102 1612757597.5969927
train: epoch 99, iter 2500, loss: 2.456958, top_1: 0.643594, top_k: 0.848555, samples/s: 1322.677 1612757616.9516745
train: epoch 99, iter 2600, loss: 2.453022, top_1: 0.638750, top_k: 0.845117, samples/s: 1332.843 1612757636.1587496
train: epoch 99, iter 2700, loss: 2.258148, top_1: 0.635820, top_k: 0.841758, samples/s: 1329.263 1612757655.4176085
train: epoch 99, iter 2800, loss: 2.526269, top_1: 0.634922, top_k: 0.843906, samples/s: 1327.633 1612757674.7000368
train: epoch 99, iter 2900, loss: 2.340850, top_1: 0.641484, top_k: 0.843320, samples/s: 1333.375 1612757693.8993719
train: epoch 99, iter 3000, loss: 2.342466, top_1: 0.633906, top_k: 0.839063, samples/s: 1328.922 1612757713.1631472
train: epoch 99, iter 3100, loss: 2.579947, top_1: 0.637539, top_k: 0.840977, samples/s: 1330.479 1612757732.4043367
train: epoch 99, iter 3200, loss: 2.615009, top_1: 0.635586, top_k: 0.843945, samples/s: 1327.974 1612757751.681908
train: epoch 99, iter 3300, loss: 2.347894, top_1: 0.638672, top_k: 0.843281, samples/s: 1324.201 1612757771.0143147
train: epoch 99, iter 3400, loss: 2.500274, top_1: 0.635273, top_k: 0.841250, samples/s: 1332.756 1612757790.2225204
train: epoch 99, iter 3500, loss: 2.625690, top_1: 0.633750, top_k: 0.839531, samples/s: 1329.164 1612757809.482798
train: epoch 99, iter 3600, loss: 2.600282, top_1: 0.633359, top_k: 0.842656, samples/s: 1331.629 1612757828.7073529
train: epoch 99, iter 3700, loss: 2.379921, top_1: 0.643437, top_k: 0.845156, samples/s: 1326.872 1612757848.0008378
train: epoch 99, iter 3800, loss: 2.372710, top_1: 0.642344, top_k: 0.842617, samples/s: 1326.157 1612757867.3047888
train: epoch 99, iter 3900, loss: 2.546494, top_1: 0.636133, top_k: 0.841836, samples/s: 1332.096 1612757886.5225956
train: epoch 99, iter 4000, loss: 2.488579, top_1: 0.634023, top_k: 0.844102, samples/s: 1326.575 1612757905.8204172
train: epoch 99, iter 4100, loss: 2.619547, top_1: 0.643672, top_k: 0.842227, samples/s: 1326.651 1612757925.1170833
train: epoch 99, iter 4200, loss: 2.441382, top_1: 0.634180, top_k: 0.840156, samples/s: 1327.001 1612757944.4086816
train: epoch 99, iter 4300, loss: 2.362360, top_1: 0.638164, top_k: 0.844258, samples/s: 1333.506 1612757963.6063128
train: epoch 99, iter 4400, loss: 2.467396, top_1: 0.640117, top_k: 0.840586, samples/s: 1329.201 1612757982.865974
train: epoch 99, iter 4500, loss: 2.488163, top_1: 0.632266, top_k: 0.842266, samples/s: 1332.857 1612758002.0728414
train: epoch 99, iter 4600, loss: 2.650101, top_1: 0.640820, top_k: 0.842891, samples/s: 1329.886 1612758021.3225307
train: epoch 99, iter 4700, loss: 2.465965, top_1: 0.636133, top_k: 0.843320, samples/s: 1327.284 1612758040.6100473
train: epoch 99, iter 4800, loss: 2.486555, top_1: 0.638242, top_k: 0.843086, samples/s: 1323.236 1612758059.9565492
train: epoch 99, iter 4900, loss: 2.504388, top_1: 0.636211, top_k: 0.840391, samples/s: 1331.206 1612758079.1873505
train: epoch 99, iter 5000, loss: 2.471790, top_1: 0.643125, top_k: 0.846445, samples/s: 1329.201 1612758098.4469662
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_99.
validation: epoch 99, iter 195, top_1: 0.680669, top_k: 0.886358, samples/s: 2719.397 1612758117.3389757
train: epoch 100, iter 100, loss: 2.501658, top_1: 0.647930, top_k: 0.845391, samples/s: 1360.760 1612758152.5357976
train: epoch 100, iter 200, loss: 2.468501, top_1: 0.644961, top_k: 0.849375, samples/s: 1360.426 1612758171.3534207
train: epoch 100, iter 300, loss: 2.456904, top_1: 0.649375, top_k: 0.851016, samples/s: 1358.828 1612758190.1932073
train: epoch 100, iter 400, loss: 2.384531, top_1: 0.650820, top_k: 0.851875, samples/s: 1344.165 1612758209.2385721
train: epoch 100, iter 500, loss: 2.389464, top_1: 0.643047, top_k: 0.845078, samples/s: 1322.508 1612758228.595727
train: epoch 100, iter 600, loss: 2.558071, top_1: 0.650859, top_k: 0.848359, samples/s: 1334.705 1612758247.775945
train: epoch 100, iter 700, loss: 2.460066, top_1: 0.651875, top_k: 0.851836, samples/s: 1322.639 1612758267.1311219
train: epoch 100, iter 800, loss: 2.615076, top_1: 0.650977, top_k: 0.850547, samples/s: 1330.249 1612758286.3756926
train: epoch 100, iter 900, loss: 2.322785, top_1: 0.641445, top_k: 0.843203, samples/s: 1323.439 1612758305.7193012
train: epoch 100, iter 1000, loss: 2.588281, top_1: 0.654844, top_k: 0.850313, samples/s: 1332.074 1612758324.937402
train: epoch 100, iter 1100, loss: 2.461840, top_1: 0.646367, top_k: 0.846758, samples/s: 1325.468 1612758344.2513115
train: epoch 100, iter 1200, loss: 2.495441, top_1: 0.640586, top_k: 0.844609, samples/s: 1326.392 1612758363.5517952
train: epoch 100, iter 1300, loss: 2.181035, top_1: 0.648516, top_k: 0.849258, samples/s: 1323.436 1612758382.8954055
train: epoch 100, iter 1400, loss: 2.481494, top_1: 0.639883, top_k: 0.845078, samples/s: 1321.205 1612758402.27164
train: epoch 100, iter 1500, loss: 2.357852, top_1: 0.645898, top_k: 0.846602, samples/s: 1325.221 1612758421.5891736
train: epoch 100, iter 1600, loss: 2.519457, top_1: 0.652695, top_k: 0.852227, samples/s: 1326.744 1612758440.8845649
train: epoch 100, iter 1700, loss: 2.435127, top_1: 0.642148, top_k: 0.848984, samples/s: 1331.173 1612758460.1156862
train: epoch 100, iter 1800, loss: 2.243494, top_1: 0.644648, top_k: 0.848437, samples/s: 1321.235 1612758479.4915009
train: epoch 100, iter 1900, loss: 2.359200, top_1: 0.640977, top_k: 0.846406, samples/s: 1322.543 1612758498.8481631
train: epoch 100, iter 2000, loss: 2.549223, top_1: 0.644336, top_k: 0.844297, samples/s: 1332.734 1612758518.0567276
train: epoch 100, iter 2100, loss: 2.633340, top_1: 0.642813, top_k: 0.844688, samples/s: 1328.395 1612758537.3281562
train: epoch 100, iter 2200, loss: 2.433932, top_1: 0.636836, top_k: 0.843828, samples/s: 1325.797 1612758556.6373012
train: epoch 100, iter 2300, loss: 2.361518, top_1: 0.635078, top_k: 0.842773, samples/s: 1329.465 1612758575.8931763
train: epoch 100, iter 2400, loss: 2.391901, top_1: 0.643047, top_k: 0.846602, samples/s: 1325.000 1612758595.2138615
train: epoch 100, iter 2500, loss: 2.527016, top_1: 0.645156, top_k: 0.845078, samples/s: 1328.716 1612758614.4806387
train: epoch 100, iter 2600, loss: 2.626752, top_1: 0.641641, top_k: 0.846484, samples/s: 1328.800 1612758633.7461505
train: epoch 100, iter 2700, loss: 2.557738, top_1: 0.643633, top_k: 0.846016, samples/s: 1329.507 1612758653.0013628
train: epoch 100, iter 2800, loss: 2.588224, top_1: 0.638437, top_k: 0.841602, samples/s: 1327.743 1612758672.2822502
train: epoch 100, iter 2900, loss: 2.319870, top_1: 0.642266, top_k: 0.845938, samples/s: 1329.254 1612758691.54114
train: epoch 100, iter 3000, loss: 2.321491, top_1: 0.644531, top_k: 0.847305, samples/s: 1329.181 1612758710.8010788
train: epoch 100, iter 3100, loss: 2.607644, top_1: 0.633789, top_k: 0.845508, samples/s: 1328.261 1612758730.0744445
train: epoch 100, iter 3200, loss: 2.451349, top_1: 0.643008, top_k: 0.848945, samples/s: 1328.579 1612758749.3431866
train: epoch 100, iter 3300, loss: 2.391154, top_1: 0.640977, top_k: 0.845000, samples/s: 1328.050 1612758768.6195211
train: epoch 100, iter 3400, loss: 2.440842, top_1: 0.641484, top_k: 0.843633, samples/s: 1328.509 1612758787.889257
train: epoch 100, iter 3500, loss: 2.337415, top_1: 0.644297, top_k: 0.845508, samples/s: 1323.720 1612758807.2287023
train: epoch 100, iter 3600, loss: 2.583459, top_1: 0.641094, top_k: 0.844023, samples/s: 1332.068 1612758826.4469156
train: epoch 100, iter 3700, loss: 2.257073, top_1: 0.637500, top_k: 0.845742, samples/s: 1322.429 1612758845.8052204
train: epoch 100, iter 3800, loss: 2.487329, top_1: 0.642031, top_k: 0.844102, samples/s: 1336.908 1612758864.9539278
train: epoch 100, iter 3900, loss: 2.461471, top_1: 0.639883, top_k: 0.845156, samples/s: 1325.406 1612758884.268769
train: epoch 100, iter 4000, loss: 2.431715, top_1: 0.642969, top_k: 0.848633, samples/s: 1326.697 1612758903.5648208
train: epoch 100, iter 4100, loss: 2.417507, top_1: 0.636445, top_k: 0.840625, samples/s: 1327.887 1612758922.843506
train: epoch 100, iter 4200, loss: 2.611108, top_1: 0.641563, top_k: 0.844648, samples/s: 1327.642 1612758942.1258082
train: epoch 100, iter 4300, loss: 2.483284, top_1: 0.640352, top_k: 0.843867, samples/s: 1323.571 1612758961.4675214
train: epoch 100, iter 4400, loss: 2.360064, top_1: 0.638594, top_k: 0.844063, samples/s: 1334.710 1612758980.6476612
train: epoch 100, iter 4500, loss: 2.615815, top_1: 0.638945, top_k: 0.840234, samples/s: 1319.804 1612759000.0445516
train: epoch 100, iter 4600, loss: 2.524713, top_1: 0.637227, top_k: 0.845313, samples/s: 1337.096 1612759019.1904757
train: epoch 100, iter 4700, loss: 2.561968, top_1: 0.640547, top_k: 0.842305, samples/s: 1329.535 1612759038.445263
train: epoch 100, iter 4800, loss: 2.744668, top_1: 0.636992, top_k: 0.844141, samples/s: 1322.543 1612759057.802015
train: epoch 100, iter 4900, loss: 2.478598, top_1: 0.641133, top_k: 0.841641, samples/s: 1326.091 1612759077.1067622
train: epoch 100, iter 5000, loss: 2.566307, top_1: 0.646367, top_k: 0.845586, samples/s: 1328.750 1612759096.3729906
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_100.
validation: epoch 100, iter 195, top_1: 0.676903, top_k: 0.884034, samples/s: 2791.339 1612759114.8676355
train: epoch 101, iter 100, loss: 2.429332, top_1: 0.654336, top_k: 0.854648, samples/s: 1360.079 1612759150.5427122
train: epoch 101, iter 200, loss: 2.507931, top_1: 0.653438, top_k: 0.852383, samples/s: 1361.860 1612759169.340512
train: epoch 101, iter 300, loss: 2.469347, top_1: 0.651992, top_k: 0.851797, samples/s: 1358.167 1612759188.1893983
train: epoch 101, iter 400, loss: 2.477856, top_1: 0.647734, top_k: 0.847930, samples/s: 1344.873 1612759207.2247252
train: epoch 101, iter 500, loss: 2.555713, top_1: 0.645703, top_k: 0.847344, samples/s: 1323.159 1612759226.5723412
train: epoch 101, iter 600, loss: 2.514300, top_1: 0.652734, top_k: 0.853320, samples/s: 1324.262 1612759245.9038363
train: epoch 101, iter 700, loss: 2.530555, top_1: 0.651719, top_k: 0.850195, samples/s: 1323.603 1612759265.2449882
train: epoch 101, iter 800, loss: 2.646576, top_1: 0.645352, top_k: 0.846055, samples/s: 1321.324 1612759284.6195161
train: epoch 101, iter 900, loss: 2.235562, top_1: 0.645938, top_k: 0.848281, samples/s: 1326.360 1612759303.9204774
train: epoch 101, iter 1000, loss: 2.538571, top_1: 0.643477, top_k: 0.848906, samples/s: 1323.727 1612759323.2598023
train: epoch 101, iter 1100, loss: 2.423639, top_1: 0.647656, top_k: 0.849453, samples/s: 1322.185 1612759342.6216574
train: epoch 101, iter 1200, loss: 2.374108, top_1: 0.642383, top_k: 0.842930, samples/s: 1316.505 1612759362.0671587
train: epoch 101, iter 1300, loss: 2.565964, top_1: 0.646172, top_k: 0.848594, samples/s: 1328.073 1612759381.3431063
train: epoch 101, iter 1400, loss: 2.277253, top_1: 0.647891, top_k: 0.848594, samples/s: 1325.269 1612759400.6599882
train: epoch 101, iter 1500, loss: 2.503009, top_1: 0.645508, top_k: 0.845000, samples/s: 1323.877 1612759419.9971282
train: epoch 101, iter 1600, loss: 2.519947, top_1: 0.645703, top_k: 0.848047, samples/s: 1321.124 1612759439.3745992
train: epoch 101, iter 1700, loss: 2.347662, top_1: 0.647305, top_k: 0.849492, samples/s: 1322.281 1612759458.7350183
train: epoch 101, iter 1800, loss: 2.443001, top_1: 0.645039, top_k: 0.848984, samples/s: 1325.459 1612759478.0491023
train: epoch 101, iter 1900, loss: 2.520812, top_1: 0.648516, top_k: 0.847656, samples/s: 1321.708 1612759497.417944
train: epoch 101, iter 2000, loss: 2.670347, top_1: 0.649375, top_k: 0.847578, samples/s: 1321.673 1612759516.7873785
train: epoch 101, iter 2100, loss: 2.551292, top_1: 0.644570, top_k: 0.842891, samples/s: 1322.038 1612759536.1513624
train: epoch 101, iter 2200, loss: 2.456392, top_1: 0.646641, top_k: 0.846211, samples/s: 1321.360 1612759555.5253935
train: epoch 101, iter 2300, loss: 2.702838, top_1: 0.644258, top_k: 0.844023, samples/s: 1324.407 1612759574.8550432
train: epoch 101, iter 2400, loss: 2.671568, top_1: 0.645859, top_k: 0.849258, samples/s: 1324.159 1612759594.1878314
train: epoch 101, iter 2500, loss: 2.600367, top_1: 0.641172, top_k: 0.843789, samples/s: 1323.741 1612759613.5273502
train: epoch 101, iter 2600, loss: 2.540871, top_1: 0.640977, top_k: 0.845664, samples/s: 1324.274 1612759632.858353
train: epoch 101, iter 2700, loss: 2.536463, top_1: 0.643203, top_k: 0.844531, samples/s: 1325.661 1612759652.1694493
train: epoch 101, iter 2800, loss: 2.481493, top_1: 0.644062, top_k: 0.849883, samples/s: 1317.923 1612759671.5938594
train: epoch 101, iter 2900, loss: 2.516308, top_1: 0.642813, top_k: 0.845000, samples/s: 1324.147 1612759690.9270923
train: epoch 101, iter 3000, loss: 2.394529, top_1: 0.647148, top_k: 0.848477, samples/s: 1324.597 1612759710.2537117
train: epoch 101, iter 3100, loss: 2.522897, top_1: 0.643398, top_k: 0.845078, samples/s: 1322.656 1612759729.6088893
train: epoch 101, iter 3200, loss: 2.381629, top_1: 0.644102, top_k: 0.846641, samples/s: 1323.107 1612759748.95708
train: epoch 101, iter 3300, loss: 2.596316, top_1: 0.638828, top_k: 0.843633, samples/s: 1324.695 1612759768.2822824
train: epoch 101, iter 3400, loss: 2.461363, top_1: 0.646094, top_k: 0.847266, samples/s: 1321.428 1612759787.6553135
train: epoch 101, iter 3500, loss: 2.547879, top_1: 0.648555, top_k: 0.845898, samples/s: 1323.954 1612759806.991335
train: epoch 101, iter 3600, loss: 2.410501, top_1: 0.644609, top_k: 0.844063, samples/s: 1323.337 1612759826.3364081
train: epoch 101, iter 3700, loss: 2.191393, top_1: 0.644805, top_k: 0.848672, samples/s: 1327.267 1612759845.6240637
train: epoch 101, iter 3800, loss: 2.430389, top_1: 0.640391, top_k: 0.842617, samples/s: 1320.637 1612759865.008659
train: epoch 101, iter 3900, loss: 2.409900, top_1: 0.644453, top_k: 0.847266, samples/s: 1327.755 1612759884.289325
train: epoch 101, iter 4000, loss: 2.475929, top_1: 0.649883, top_k: 0.847461, samples/s: 1326.202 1612759903.5926354
train: epoch 101, iter 4100, loss: 2.371015, top_1: 0.644062, top_k: 0.844141, samples/s: 1327.837 1612759922.8720539
train: epoch 101, iter 4200, loss: 2.545237, top_1: 0.643242, top_k: 0.844492, samples/s: 1326.816 1612759942.166356
train: epoch 101, iter 4300, loss: 2.645556, top_1: 0.641914, top_k: 0.848203, samples/s: 1321.696 1612759961.5354526
train: epoch 101, iter 4400, loss: 2.503467, top_1: 0.643437, top_k: 0.844609, samples/s: 1329.545 1612759980.7901285
train: epoch 101, iter 4500, loss: 2.488189, top_1: 0.648906, top_k: 0.845313, samples/s: 1314.305 1612760000.2681816
train: epoch 101, iter 4600, loss: 2.460895, top_1: 0.644180, top_k: 0.843984, samples/s: 1327.769 1612760019.5486138
train: epoch 101, iter 4700, loss: 2.651934, top_1: 0.640000, top_k: 0.848477, samples/s: 1322.815 1612760038.9012558
train: epoch 101, iter 4800, loss: 2.550545, top_1: 0.638320, top_k: 0.842383, samples/s: 1326.613 1612760058.1984878
train: epoch 101, iter 4900, loss: 2.216884, top_1: 0.641719, top_k: 0.848047, samples/s: 1319.329 1612760077.6024275
train: epoch 101, iter 5000, loss: 2.379795, top_1: 0.651016, top_k: 0.852305, samples/s: 1327.954 1612760096.8801894
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_101.
validation: epoch 101, iter 195, top_1: 0.680950, top_k: 0.884475, samples/s: 2688.495 1612760116.0161355
train: epoch 102, iter 100, loss: 2.418345, top_1: 0.654336, top_k: 0.852344, samples/s: 1353.338 1612760151.1210701
train: epoch 102, iter 200, loss: 2.152531, top_1: 0.654961, top_k: 0.854141, samples/s: 1366.907 1612760169.8493664
train: epoch 102, iter 300, loss: 2.424864, top_1: 0.656719, top_k: 0.855664, samples/s: 1360.388 1612760188.6675558
train: epoch 102, iter 400, loss: 2.298633, top_1: 0.647969, top_k: 0.851211, samples/s: 1338.617 1612760207.791801
train: epoch 102, iter 500, loss: 2.570647, top_1: 0.647813, top_k: 0.849883, samples/s: 1329.486 1612760227.04735
train: epoch 102, iter 600, loss: 2.380882, top_1: 0.643398, top_k: 0.848320, samples/s: 1325.423 1612760246.361929
train: epoch 102, iter 700, loss: 2.373848, top_1: 0.662148, top_k: 0.855859, samples/s: 1323.088 1612760265.7105718
train: epoch 102, iter 800, loss: 2.317836, top_1: 0.649609, top_k: 0.850117, samples/s: 1326.710 1612760285.0064678
train: epoch 102, iter 900, loss: 2.554488, top_1: 0.653320, top_k: 0.850820, samples/s: 1327.291 1612760304.2938795
train: epoch 102, iter 1000, loss: 2.483781, top_1: 0.648438, top_k: 0.851250, samples/s: 1330.569 1612760323.533716
train: epoch 102, iter 1100, loss: 2.481903, top_1: 0.644805, top_k: 0.846992, samples/s: 1330.502 1612760342.7745721
train: epoch 102, iter 1200, loss: 2.454501, top_1: 0.648047, top_k: 0.847773, samples/s: 1327.414 1612760362.0602407
train: epoch 102, iter 1300, loss: 2.367275, top_1: 0.649375, top_k: 0.847852, samples/s: 1326.393 1612760381.3607044
train: epoch 102, iter 1400, loss: 2.365169, top_1: 0.652031, top_k: 0.853945, samples/s: 1327.136 1612760400.6503246
train: epoch 102, iter 1500, loss: 2.449396, top_1: 0.647656, top_k: 0.852539, samples/s: 1327.957 1612760419.9280252
train: epoch 102, iter 1600, loss: 2.557221, top_1: 0.646484, top_k: 0.850586, samples/s: 1324.133 1612760439.261496
train: epoch 102, iter 1700, loss: 2.330053, top_1: 0.650312, top_k: 0.848750, samples/s: 1323.247 1612760458.6078422
train: epoch 102, iter 1800, loss: 2.388058, top_1: 0.648281, top_k: 0.848516, samples/s: 1324.703 1612760477.93293
train: epoch 102, iter 1900, loss: 2.572891, top_1: 0.648203, top_k: 0.851016, samples/s: 1328.757 1612760497.198991
train: epoch 102, iter 2000, loss: 2.440265, top_1: 0.645781, top_k: 0.845508, samples/s: 1319.820 1612760516.5956929
train: epoch 102, iter 2100, loss: 2.461832, top_1: 0.644961, top_k: 0.848945, samples/s: 1332.690 1612760535.8048396
train: epoch 102, iter 2200, loss: 2.518364, top_1: 0.644375, top_k: 0.849180, samples/s: 1335.978 1612760554.9668365
train: epoch 102, iter 2300, loss: 2.524097, top_1: 0.651016, top_k: 0.848828, samples/s: 1329.400 1612760574.2236593
train: epoch 102, iter 2400, loss: 2.394998, top_1: 0.649414, top_k: 0.848086, samples/s: 1323.543 1612760593.5656717
train: epoch 102, iter 2500, loss: 2.513956, top_1: 0.647188, top_k: 0.849492, samples/s: 1330.478 1612760612.8069258
train: epoch 102, iter 2600, loss: 2.461972, top_1: 0.646016, top_k: 0.849258, samples/s: 1325.355 1612760632.122521
train: epoch 102, iter 2700, loss: 2.431651, top_1: 0.652148, top_k: 0.851172, samples/s: 1325.526 1612760651.435591
train: epoch 102, iter 2800, loss: 2.605832, top_1: 0.648750, top_k: 0.850039, samples/s: 1327.862 1612760670.714656
train: epoch 102, iter 2900, loss: 2.616216, top_1: 0.648555, top_k: 0.845859, samples/s: 1334.299 1612760689.9008229
train: epoch 102, iter 3000, loss: 2.424114, top_1: 0.637773, top_k: 0.845391, samples/s: 1327.590 1612760709.1838772
train: epoch 102, iter 3100, loss: 2.424999, top_1: 0.640664, top_k: 0.845156, samples/s: 1326.435 1612760728.483735
train: epoch 102, iter 3200, loss: 2.521388, top_1: 0.645469, top_k: 0.846289, samples/s: 1328.240 1612760747.757292
train: epoch 102, iter 3300, loss: 2.511576, top_1: 0.644883, top_k: 0.850156, samples/s: 1324.314 1612760767.0881085
train: epoch 102, iter 3400, loss: 2.404624, top_1: 0.649805, top_k: 0.848906, samples/s: 1332.995 1612760786.2929246
train: epoch 102, iter 3500, loss: 2.524999, top_1: 0.645742, top_k: 0.850938, samples/s: 1327.285 1612760805.5804186
train: epoch 102, iter 3600, loss: 2.425795, top_1: 0.647773, top_k: 0.844648, samples/s: 1328.953 1612760824.843757
train: epoch 102, iter 3700, loss: 2.472283, top_1: 0.638398, top_k: 0.844609, samples/s: 1331.577 1612760844.069088
train: epoch 102, iter 3800, loss: 2.456524, top_1: 0.641289, top_k: 0.845469, samples/s: 1327.740 1612760863.3499906
train: epoch 102, iter 3900, loss: 2.487273, top_1: 0.645469, top_k: 0.849414, samples/s: 1327.790 1612760882.6301022
train: epoch 102, iter 4000, loss: 2.294447, top_1: 0.646523, top_k: 0.846406, samples/s: 1328.308 1612760901.9027417
train: epoch 102, iter 4100, loss: 2.451244, top_1: 0.645508, top_k: 0.845391, samples/s: 1332.043 1612760921.1213014
train: epoch 102, iter 4200, loss: 2.399287, top_1: 0.648047, top_k: 0.848047, samples/s: 1331.007 1612760940.3548667
train: epoch 102, iter 4300, loss: 2.643862, top_1: 0.640234, top_k: 0.843203, samples/s: 1326.801 1612760959.6493897
train: epoch 102, iter 4400, loss: 2.378766, top_1: 0.648750, top_k: 0.848320, samples/s: 1331.279 1612760978.8790855
train: epoch 102, iter 4500, loss: 2.391864, top_1: 0.646523, top_k: 0.849648, samples/s: 1332.087 1612760998.0970566
train: epoch 102, iter 4600, loss: 2.579710, top_1: 0.644570, top_k: 0.850117, samples/s: 1317.070 1612761017.5341563
train: epoch 102, iter 4700, loss: 2.440923, top_1: 0.643828, top_k: 0.848125, samples/s: 1337.364 1612761036.6762319
train: epoch 102, iter 4800, loss: 2.598895, top_1: 0.647461, top_k: 0.849805, samples/s: 1331.690 1612761055.8999703
train: epoch 102, iter 4900, loss: 2.289338, top_1: 0.644023, top_k: 0.847852, samples/s: 1327.546 1612761075.183604
train: epoch 102, iter 5000, loss: 2.474820, top_1: 0.653828, top_k: 0.853906, samples/s: 1330.769 1612761094.4206874
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_102.
validation: epoch 102, iter 195, top_1: 0.685337, top_k: 0.887921, samples/s: 2738.528 1612761113.1954505
train: epoch 103, iter 100, loss: 2.381607, top_1: 0.653516, top_k: 0.851953, samples/s: 1356.240 1612761147.9062836
train: epoch 103, iter 200, loss: 2.553665, top_1: 0.651992, top_k: 0.849492, samples/s: 1362.729 1612761166.6921208
train: epoch 103, iter 300, loss: 2.309486, top_1: 0.660586, top_k: 0.857500, samples/s: 1357.347 1612761185.5523422
train: epoch 103, iter 400, loss: 2.353436, top_1: 0.660195, top_k: 0.858242, samples/s: 1351.855 1612761204.4892535
train: epoch 103, iter 500, loss: 2.348370, top_1: 0.660469, top_k: 0.856875, samples/s: 1326.004 1612761223.7953694
train: epoch 103, iter 600, loss: 2.493190, top_1: 0.653711, top_k: 0.850820, samples/s: 1327.854 1612761243.074702
train: epoch 103, iter 700, loss: 2.616344, top_1: 0.654687, top_k: 0.853164, samples/s: 1326.236 1612761262.3773668
train: epoch 103, iter 800, loss: 2.264046, top_1: 0.653711, top_k: 0.853437, samples/s: 1332.054 1612761281.5957723
train: epoch 103, iter 900, loss: 2.750770, top_1: 0.655664, top_k: 0.853359, samples/s: 1328.660 1612761300.8633215
train: epoch 103, iter 1000, loss: 2.245266, top_1: 0.652031, top_k: 0.851641, samples/s: 1334.609 1612761320.0450273
train: epoch 103, iter 1100, loss: 2.410118, top_1: 0.654336, top_k: 0.851797, samples/s: 1322.818 1612761339.3976526
train: epoch 103, iter 1200, loss: 2.306099, top_1: 0.653555, top_k: 0.851680, samples/s: 1329.742 1612761358.6494715
train: epoch 103, iter 1300, loss: 2.481086, top_1: 0.646172, top_k: 0.848047, samples/s: 1326.238 1612761377.9521463
train: epoch 103, iter 1400, loss: 2.447609, top_1: 0.651094, top_k: 0.849219, samples/s: 1327.211 1612761397.2407658
train: epoch 103, iter 1500, loss: 2.251127, top_1: 0.651211, top_k: 0.851562, samples/s: 1327.239 1612761416.5289178
train: epoch 103, iter 1600, loss: 2.367302, top_1: 0.648438, top_k: 0.851133, samples/s: 1330.266 1612761435.7731552
train: epoch 103, iter 1700, loss: 2.587970, top_1: 0.651992, top_k: 0.853594, samples/s: 1331.403 1612761455.0010388
train: epoch 103, iter 1800, loss: 2.268728, top_1: 0.652461, top_k: 0.852617, samples/s: 1332.584 1612761474.211791
train: epoch 103, iter 1900, loss: 2.470147, top_1: 0.648789, top_k: 0.852187, samples/s: 1331.402 1612761493.439638
train: epoch 103, iter 2000, loss: 2.513923, top_1: 0.646953, top_k: 0.850469, samples/s: 1326.766 1612761512.734667
train: epoch 103, iter 2100, loss: 2.474220, top_1: 0.651211, top_k: 0.854766, samples/s: 1332.957 1612761531.9401429
train: epoch 103, iter 2200, loss: 2.431460, top_1: 0.651484, top_k: 0.846562, samples/s: 1329.450 1612761551.196193
train: epoch 103, iter 2300, loss: 2.723091, top_1: 0.654141, top_k: 0.852148, samples/s: 1326.014 1612761570.5021858
train: epoch 103, iter 2400, loss: 2.261168, top_1: 0.645625, top_k: 0.849023, samples/s: 1327.490 1612761589.7867665
train: epoch 103, iter 2500, loss: 2.459689, top_1: 0.649883, top_k: 0.852344, samples/s: 1329.187 1612761609.0465689
train: epoch 103, iter 2600, loss: 2.267616, top_1: 0.651289, top_k: 0.849492, samples/s: 1327.755 1612761628.327233
train: epoch 103, iter 2700, loss: 2.412673, top_1: 0.649961, top_k: 0.849570, samples/s: 1331.842 1612761647.5487914
train: epoch 103, iter 2800, loss: 2.383946, top_1: 0.654570, top_k: 0.850898, samples/s: 1336.340 1612761666.705566
train: epoch 103, iter 2900, loss: 2.434213, top_1: 0.649687, top_k: 0.852812, samples/s: 1323.847 1612761686.043127
train: epoch 103, iter 3000, loss: 2.664576, top_1: 0.647695, top_k: 0.849141, samples/s: 1328.764 1612761705.309118
train: epoch 103, iter 3100, loss: 2.539903, top_1: 0.652969, top_k: 0.849414, samples/s: 1335.277 1612761724.481221
train: epoch 103, iter 3200, loss: 2.313339, top_1: 0.651016, top_k: 0.852930, samples/s: 1330.705 1612761743.719149
train: epoch 103, iter 3300, loss: 2.307941, top_1: 0.649961, top_k: 0.851445, samples/s: 1331.044 1612761762.9522204
train: epoch 103, iter 3400, loss: 2.355028, top_1: 0.653164, top_k: 0.853281, samples/s: 1335.103 1612761782.1267402
train: epoch 103, iter 3500, loss: 2.632041, top_1: 0.646094, top_k: 0.848281, samples/s: 1331.296 1612761801.356046
train: epoch 103, iter 3600, loss: 2.472752, top_1: 0.642500, top_k: 0.849648, samples/s: 1329.073 1612761820.6176224
train: epoch 103, iter 3700, loss: 2.731334, top_1: 0.648320, top_k: 0.848203, samples/s: 1330.648 1612761839.8563278
train: epoch 103, iter 3800, loss: 2.476269, top_1: 0.648867, top_k: 0.848125, samples/s: 1325.273 1612761859.1732576
train: epoch 103, iter 3900, loss: 2.370807, top_1: 0.646094, top_k: 0.847773, samples/s: 1332.492 1612761878.3852818
train: epoch 103, iter 4000, loss: 2.609668, top_1: 0.647383, top_k: 0.846992, samples/s: 1339.109 1612761897.5024667
train: epoch 103, iter 4100, loss: 2.371784, top_1: 0.645312, top_k: 0.850742, samples/s: 1335.775 1612761916.667385
train: epoch 103, iter 4200, loss: 2.437238, top_1: 0.648711, top_k: 0.851523, samples/s: 1325.827 1612761935.9760675
train: epoch 103, iter 4300, loss: 2.403855, top_1: 0.643945, top_k: 0.847148, samples/s: 1335.445 1612761955.145702
train: epoch 103, iter 4400, loss: 2.397850, top_1: 0.645898, top_k: 0.848398, samples/s: 1328.001 1612761974.422802
train: epoch 103, iter 4500, loss: 2.439218, top_1: 0.648477, top_k: 0.851953, samples/s: 1334.258 1612761993.609504
train: epoch 103, iter 4600, loss: 2.443396, top_1: 0.648398, top_k: 0.851055, samples/s: 1332.319 1612762012.8240752
train: epoch 103, iter 4700, loss: 2.510314, top_1: 0.645781, top_k: 0.848594, samples/s: 1334.098 1612762032.0130608
train: epoch 103, iter 4800, loss: 2.467989, top_1: 0.645781, top_k: 0.848242, samples/s: 1330.724 1612762051.2507458
train: epoch 103, iter 4900, loss: 2.549170, top_1: 0.643516, top_k: 0.849219, samples/s: 1332.435 1612762070.4637034
train: epoch 103, iter 5000, loss: 2.328297, top_1: 0.648906, top_k: 0.847305, samples/s: 1333.031 1612762089.6680021
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_103.
validation: epoch 103, iter 195, top_1: 0.684455, top_k: 0.889383, samples/s: 2802.039 1612762108.0579598
train: epoch 104, iter 100, loss: 2.286141, top_1: 0.662070, top_k: 0.857266, samples/s: 1355.897 1612762142.9341161
train: epoch 104, iter 200, loss: 2.379048, top_1: 0.655508, top_k: 0.851172, samples/s: 1358.855 1612762161.7737322
train: epoch 104, iter 300, loss: 2.377758, top_1: 0.663203, top_k: 0.856719, samples/s: 1361.899 1612762180.5708246
train: epoch 104, iter 400, loss: 2.465522, top_1: 0.654961, top_k: 0.857187, samples/s: 1350.573 1612762199.5256813
train: epoch 104, iter 500, loss: 2.516767, top_1: 0.654531, top_k: 0.851445, samples/s: 1334.415 1612762218.710182
train: epoch 104, iter 600, loss: 2.470441, top_1: 0.652695, top_k: 0.848047, samples/s: 1325.974 1612762238.0167584
train: epoch 104, iter 700, loss: 2.364388, top_1: 0.654922, top_k: 0.855234, samples/s: 1327.036 1612762257.3079221
train: epoch 104, iter 800, loss: 2.461443, top_1: 0.655273, top_k: 0.855508, samples/s: 1330.752 1612762276.5450966
train: epoch 104, iter 900, loss: 2.372417, top_1: 0.653906, top_k: 0.855430, samples/s: 1334.622 1612762295.7265816
train: epoch 104, iter 1000, loss: 2.267644, top_1: 0.652695, top_k: 0.854492, samples/s: 1324.616 1612762315.0528998
train: epoch 104, iter 1100, loss: 2.407894, top_1: 0.663008, top_k: 0.855078, samples/s: 1324.764 1612762334.37715
train: epoch 104, iter 1200, loss: 2.499486, top_1: 0.652969, top_k: 0.856211, samples/s: 1337.911 1612762353.5113494
train: epoch 104, iter 1300, loss: 2.615057, top_1: 0.650234, top_k: 0.851289, samples/s: 1324.943 1612762372.8329365
train: epoch 104, iter 1400, loss: 2.374075, top_1: 0.659609, top_k: 0.857891, samples/s: 1336.047 1612762391.9939702
train: epoch 104, iter 1500, loss: 2.564358, top_1: 0.657188, top_k: 0.853984, samples/s: 1323.191 1612762411.3411083
train: epoch 104, iter 1600, loss: 2.448283, top_1: 0.655859, top_k: 0.853359, samples/s: 1330.635 1612762430.5800767
train: epoch 104, iter 1700, loss: 2.397996, top_1: 0.660508, top_k: 0.856094, samples/s: 1337.080 1612762449.726329
train: epoch 104, iter 1800, loss: 2.425103, top_1: 0.654570, top_k: 0.853242, samples/s: 1328.310 1612762468.9988763
train: epoch 104, iter 1900, loss: 2.382139, top_1: 0.652305, top_k: 0.848359, samples/s: 1332.536 1612762488.2104597
train: epoch 104, iter 2000, loss: 2.478007, top_1: 0.649961, top_k: 0.850781, samples/s: 1328.953 1612762507.4736598
train: epoch 104, iter 2100, loss: 2.385320, top_1: 0.653945, top_k: 0.852383, samples/s: 1330.876 1612762526.7090669
train: epoch 104, iter 2200, loss: 2.414803, top_1: 0.653164, top_k: 0.853945, samples/s: 1322.749 1612762546.062704
train: epoch 104, iter 2300, loss: 2.543100, top_1: 0.651055, top_k: 0.853047, samples/s: 1341.149 1612762565.1508358
train: epoch 104, iter 2400, loss: 2.454978, top_1: 0.653789, top_k: 0.850117, samples/s: 1326.791 1612762584.4455006
train: epoch 104, iter 2500, loss: 2.533020, top_1: 0.648594, top_k: 0.852617, samples/s: 1333.608 1612762603.6415708
train: epoch 104, iter 2600, loss: 2.370042, top_1: 0.649141, top_k: 0.851172, samples/s: 1334.123 1612762622.8302207
train: epoch 104, iter 2700, loss: 2.410249, top_1: 0.652461, top_k: 0.849688, samples/s: 1330.202 1612762642.075384
train: epoch 104, iter 2800, loss: 2.596424, top_1: 0.646953, top_k: 0.847852, samples/s: 1326.915 1612762661.3682153
train: epoch 104, iter 2900, loss: 2.503622, top_1: 0.649414, top_k: 0.848828, samples/s: 1335.184 1612762680.5416138
train: epoch 104, iter 3000, loss: 2.473068, top_1: 0.651367, top_k: 0.853828, samples/s: 1327.122 1612762699.8315856
train: epoch 104, iter 3100, loss: 2.356986, top_1: 0.656289, top_k: 0.854336, samples/s: 1332.610 1612762719.0419447
train: epoch 104, iter 3200, loss: 2.493661, top_1: 0.648359, top_k: 0.850000, samples/s: 1327.713 1612762738.3231559
train: epoch 104, iter 3300, loss: 2.460745, top_1: 0.651914, top_k: 0.852852, samples/s: 1338.937 1612762757.4428065
train: epoch 104, iter 3400, loss: 2.541739, top_1: 0.654375, top_k: 0.851133, samples/s: 1336.702 1612762776.5944223
train: epoch 104, iter 3500, loss: 2.469205, top_1: 0.653047, top_k: 0.852812, samples/s: 1330.530 1612762795.8348837
train: epoch 104, iter 3600, loss: 2.454342, top_1: 0.650664, top_k: 0.850469, samples/s: 1326.987 1612762815.126788
train: epoch 104, iter 3700, loss: 2.386795, top_1: 0.652734, top_k: 0.848555, samples/s: 1330.999 1612762834.360379
train: epoch 104, iter 3800, loss: 2.301030, top_1: 0.656133, top_k: 0.855234, samples/s: 1331.339 1612762853.5892198
train: epoch 104, iter 3900, loss: 2.375484, top_1: 0.651016, top_k: 0.851250, samples/s: 1331.891 1612762872.8099346
train: epoch 104, iter 4000, loss: 2.482088, top_1: 0.649648, top_k: 0.853789, samples/s: 1336.690 1612762891.9617748
train: epoch 104, iter 4100, loss: 2.375805, top_1: 0.650586, top_k: 0.852812, samples/s: 1333.024 1612762911.166218
train: epoch 104, iter 4200, loss: 2.486605, top_1: 0.649961, top_k: 0.849219, samples/s: 1328.485 1612762930.4362519
train: epoch 104, iter 4300, loss: 2.325096, top_1: 0.646680, top_k: 0.849727, samples/s: 1333.877 1612762949.6284184
train: epoch 104, iter 4400, loss: 2.446277, top_1: 0.644375, top_k: 0.845664, samples/s: 1333.901 1612762968.8202856
train: epoch 104, iter 4500, loss: 2.419180, top_1: 0.655977, top_k: 0.854766, samples/s: 1333.783 1612762988.0138202
train: epoch 104, iter 4600, loss: 2.387238, top_1: 0.643164, top_k: 0.848555, samples/s: 1334.259 1612763007.2004561
train: epoch 104, iter 4700, loss: 2.541845, top_1: 0.645391, top_k: 0.848984, samples/s: 1333.749 1612763026.3945138
train: epoch 104, iter 4800, loss: 2.419515, top_1: 0.647539, top_k: 0.848242, samples/s: 1331.557 1612763045.6201746
train: epoch 104, iter 4900, loss: 2.389413, top_1: 0.651211, top_k: 0.849922, samples/s: 1329.539 1612763064.874916
train: epoch 104, iter 5000, loss: 2.350894, top_1: 0.653164, top_k: 0.849570, samples/s: 1333.601 1612763084.0710804
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_104.
validation: epoch 104, iter 195, top_1: 0.683794, top_k: 0.887520, samples/s: 2835.662 1612763102.2426445
train: epoch 105, iter 100, loss: 2.295567, top_1: 0.660352, top_k: 0.859141, samples/s: 1362.349 1612763137.5210278
train: epoch 105, iter 200, loss: 2.219179, top_1: 0.665469, top_k: 0.858008, samples/s: 1356.353 1612763156.3951929
train: epoch 105, iter 300, loss: 2.531977, top_1: 0.655977, top_k: 0.855430, samples/s: 1361.300 1612763175.200886
train: epoch 105, iter 400, loss: 2.537263, top_1: 0.662422, top_k: 0.860313, samples/s: 1346.573 1612763194.2118835
train: epoch 105, iter 500, loss: 2.458112, top_1: 0.661094, top_k: 0.856758, samples/s: 1326.671 1612763213.5083356
train: epoch 105, iter 600, loss: 2.400267, top_1: 0.665195, top_k: 0.857461, samples/s: 1330.726 1612763232.7459087
train: epoch 105, iter 700, loss: 2.436180, top_1: 0.658828, top_k: 0.859570, samples/s: 1330.054 1612763251.9933562
train: epoch 105, iter 800, loss: 2.207829, top_1: 0.656172, top_k: 0.857187, samples/s: 1329.426 1612763271.2497578
train: epoch 105, iter 900, loss: 2.383578, top_1: 0.656719, top_k: 0.856914, samples/s: 1323.151 1612763290.5974674
train: epoch 105, iter 1000, loss: 2.384719, top_1: 0.657109, top_k: 0.854258, samples/s: 1324.957 1612763309.9188247
train: epoch 105, iter 1100, loss: 2.186158, top_1: 0.654375, top_k: 0.856328, samples/s: 1328.049 1612763329.195201
train: epoch 105, iter 1200, loss: 2.384351, top_1: 0.655156, top_k: 0.855273, samples/s: 1329.664 1612763348.448268
train: epoch 105, iter 1300, loss: 2.569869, top_1: 0.659102, top_k: 0.854141, samples/s: 1325.295 1612763367.7646692
train: epoch 105, iter 1400, loss: 2.224816, top_1: 0.657656, top_k: 0.853125, samples/s: 1333.337 1612763386.964733
train: epoch 105, iter 1500, loss: 2.399442, top_1: 0.654492, top_k: 0.853477, samples/s: 1326.329 1612763406.2659996
train: epoch 105, iter 1600, loss: 2.373252, top_1: 0.657500, top_k: 0.856797, samples/s: 1327.163 1612763425.5552473
train: epoch 105, iter 1700, loss: 2.481477, top_1: 0.662539, top_k: 0.859141, samples/s: 1332.305 1612763444.7701974
train: epoch 105, iter 1800, loss: 2.318726, top_1: 0.657266, top_k: 0.855703, samples/s: 1336.201 1612763463.9289162
train: epoch 105, iter 1900, loss: 2.331051, top_1: 0.648633, top_k: 0.850703, samples/s: 1322.945 1612763483.2796779
train: epoch 105, iter 2000, loss: 2.312409, top_1: 0.649648, top_k: 0.851758, samples/s: 1321.825 1612763502.6468327
train: epoch 105, iter 2100, loss: 2.729856, top_1: 0.652188, top_k: 0.851797, samples/s: 1330.695 1612763521.8849213
train: epoch 105, iter 2200, loss: 2.435634, top_1: 0.650039, top_k: 0.851328, samples/s: 1332.345 1612763541.0991805
train: epoch 105, iter 2300, loss: 2.383569, top_1: 0.650625, top_k: 0.855898, samples/s: 1332.608 1612763560.3095918
train: epoch 105, iter 2400, loss: 2.340433, top_1: 0.653867, top_k: 0.853672, samples/s: 1323.255 1612763579.655787
train: epoch 105, iter 2500, loss: 2.488811, top_1: 0.656797, top_k: 0.854805, samples/s: 1328.991 1612763598.91857
train: epoch 105, iter 2600, loss: 2.397994, top_1: 0.658789, top_k: 0.854883, samples/s: 1332.200 1612763618.1348476
train: epoch 105, iter 2700, loss: 2.558900, top_1: 0.650430, top_k: 0.850938, samples/s: 1325.432 1612763637.449338
train: epoch 105, iter 2800, loss: 2.207433, top_1: 0.654102, top_k: 0.851797, samples/s: 1331.942 1612763656.6693645
train: epoch 105, iter 2900, loss: 2.301665, top_1: 0.653281, top_k: 0.852617, samples/s: 1330.083 1612763675.91636
train: epoch 105, iter 3000, loss: 2.421808, top_1: 0.651719, top_k: 0.850469, samples/s: 1321.381 1612763695.2900093
train: epoch 105, iter 3100, loss: 2.450895, top_1: 0.648672, top_k: 0.852187, samples/s: 1331.622 1612763714.5146277
train: epoch 105, iter 3200, loss: 2.461277, top_1: 0.657227, top_k: 0.853477, samples/s: 1330.273 1612763733.758798
train: epoch 105, iter 3300, loss: 2.387608, top_1: 0.647188, top_k: 0.848711, samples/s: 1327.762 1612763753.039358
train: epoch 105, iter 3400, loss: 2.368845, top_1: 0.655039, top_k: 0.853242, samples/s: 1333.684 1612763772.234359
train: epoch 105, iter 3500, loss: 2.275147, top_1: 0.658398, top_k: 0.853281, samples/s: 1331.714 1612763791.4576693
train: epoch 105, iter 3600, loss: 2.421059, top_1: 0.650977, top_k: 0.851914, samples/s: 1323.031 1612763810.8071833
train: epoch 105, iter 3700, loss: 2.556358, top_1: 0.656328, top_k: 0.854258, samples/s: 1327.023 1612763830.0985658
train: epoch 105, iter 3800, loss: 2.363768, top_1: 0.648594, top_k: 0.849102, samples/s: 1330.494 1612763849.3394558
train: epoch 105, iter 3900, loss: 2.266052, top_1: 0.654844, top_k: 0.854180, samples/s: 1327.787 1612763868.6197739
train: epoch 105, iter 4000, loss: 2.345061, top_1: 0.652148, top_k: 0.851680, samples/s: 1330.792 1612763887.8563874
train: epoch 105, iter 4100, loss: 2.435678, top_1: 0.655156, top_k: 0.852383, samples/s: 1330.537 1612763907.0967166
train: epoch 105, iter 4200, loss: 2.385187, top_1: 0.652227, top_k: 0.851875, samples/s: 1332.927 1612763926.3025827
train: epoch 105, iter 4300, loss: 2.290892, top_1: 0.647969, top_k: 0.849531, samples/s: 1332.316 1612763945.517194
train: epoch 105, iter 4400, loss: 2.577671, top_1: 0.647188, top_k: 0.847344, samples/s: 1327.423 1612763964.8026843
train: epoch 105, iter 4500, loss: 2.627086, top_1: 0.652734, top_k: 0.850938, samples/s: 1328.382 1612763984.0742686
train: epoch 105, iter 4600, loss: 2.389849, top_1: 0.657734, top_k: 0.859062, samples/s: 1331.109 1612764003.3064437
train: epoch 105, iter 4700, loss: 2.393262, top_1: 0.652344, top_k: 0.852773, samples/s: 1329.311 1612764022.5644796
train: epoch 105, iter 4800, loss: 2.473580, top_1: 0.648125, top_k: 0.846914, samples/s: 1329.301 1612764041.8227394
train: epoch 105, iter 4900, loss: 2.559737, top_1: 0.651719, top_k: 0.848984, samples/s: 1328.590 1612764061.0912747
train: epoch 105, iter 5000, loss: 2.380562, top_1: 0.657305, top_k: 0.856445, samples/s: 1330.070 1612764080.3383384
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_105.
validation: epoch 105, iter 195, top_1: 0.690605, top_k: 0.891046, samples/s: 2747.943 1612764099.078471
train: epoch 106, iter 100, loss: 2.405862, top_1: 0.665469, top_k: 0.862930, samples/s: 1359.148 1612764134.0380523
train: epoch 106, iter 200, loss: 2.355685, top_1: 0.659492, top_k: 0.855977, samples/s: 1357.841 1612764152.8915234
train: epoch 106, iter 300, loss: 2.549466, top_1: 0.663438, top_k: 0.860352, samples/s: 1358.465 1612764171.736108
train: epoch 106, iter 400, loss: 2.523513, top_1: 0.658477, top_k: 0.858437, samples/s: 1358.738 1612764190.577191
train: epoch 106, iter 500, loss: 2.360048, top_1: 0.664844, top_k: 0.860234, samples/s: 1329.826 1612764209.8278065
train: epoch 106, iter 600, loss: 2.452824, top_1: 0.660664, top_k: 0.859336, samples/s: 1336.562 1612764228.9814644
train: epoch 106, iter 700, loss: 2.379345, top_1: 0.661445, top_k: 0.857031, samples/s: 1331.067 1612764248.2141519
train: epoch 106, iter 800, loss: 2.532065, top_1: 0.651094, top_k: 0.851484, samples/s: 1325.889 1612764267.5219173
train: epoch 106, iter 900, loss: 2.414173, top_1: 0.663984, top_k: 0.856719, samples/s: 1336.496 1612764286.676558
train: epoch 106, iter 1000, loss: 2.535079, top_1: 0.663945, top_k: 0.856289, samples/s: 1335.252 1612764305.848913
train: epoch 106, iter 1100, loss: 2.355792, top_1: 0.651016, top_k: 0.850625, samples/s: 1331.988 1612764325.068294
train: epoch 106, iter 1200, loss: 2.489998, top_1: 0.657773, top_k: 0.856719, samples/s: 1334.667 1612764344.2490764
train: epoch 106, iter 1300, loss: 2.398641, top_1: 0.662383, top_k: 0.857695, samples/s: 1331.592 1612764363.4741783
train: epoch 106, iter 1400, loss: 2.434124, top_1: 0.655937, top_k: 0.857266, samples/s: 1325.571 1612764382.786652
train: epoch 106, iter 1500, loss: 2.212281, top_1: 0.654570, top_k: 0.852266, samples/s: 1335.021 1612764401.9623413
train: epoch 106, iter 1600, loss: 2.429085, top_1: 0.659258, top_k: 0.857617, samples/s: 1330.706 1612764421.2002685
train: epoch 106, iter 1700, loss: 2.379743, top_1: 0.656250, top_k: 0.856719, samples/s: 1330.460 1612764440.4417162
train: epoch 106, iter 1800, loss: 2.350788, top_1: 0.657773, top_k: 0.857305, samples/s: 1333.214 1612764459.6434221
train: epoch 106, iter 1900, loss: 2.254215, top_1: 0.658633, top_k: 0.857227, samples/s: 1330.059 1612764478.8907218
train: epoch 106, iter 2000, loss: 2.466355, top_1: 0.654453, top_k: 0.850664, samples/s: 1331.773 1612764498.1131918
train: epoch 106, iter 2100, loss: 2.338293, top_1: 0.658984, top_k: 0.853555, samples/s: 1337.388 1612764517.2549803
train: epoch 106, iter 2200, loss: 2.399507, top_1: 0.658164, top_k: 0.855391, samples/s: 1333.144 1612764536.457756
train: epoch 106, iter 2300, loss: 2.392756, top_1: 0.653008, top_k: 0.855117, samples/s: 1331.601 1612764555.6827936
train: epoch 106, iter 2400, loss: 2.522737, top_1: 0.661289, top_k: 0.855781, samples/s: 1331.033 1612764574.9159076
train: epoch 106, iter 2500, loss: 2.416015, top_1: 0.657344, top_k: 0.856563, samples/s: 1334.870 1612764594.093812
train: epoch 106, iter 2600, loss: 2.330608, top_1: 0.655273, top_k: 0.854648, samples/s: 1331.220 1612764613.32427
train: epoch 106, iter 2700, loss: 2.089765, top_1: 0.655547, top_k: 0.852891, samples/s: 1328.668 1612764632.5916944
train: epoch 106, iter 2800, loss: 2.331210, top_1: 0.655781, top_k: 0.853516, samples/s: 1333.455 1612764651.7899249
train: epoch 106, iter 2900, loss: 2.266469, top_1: 0.653984, top_k: 0.853672, samples/s: 1335.836 1612764670.9540482
train: epoch 106, iter 3000, loss: 2.556192, top_1: 0.660977, top_k: 0.855430, samples/s: 1334.484 1612764690.1374593
train: epoch 106, iter 3100, loss: 2.471476, top_1: 0.656328, top_k: 0.854258, samples/s: 1326.166 1612764709.4412231
train: epoch 106, iter 3200, loss: 2.492262, top_1: 0.654922, top_k: 0.853359, samples/s: 1337.827 1612764728.5767763
train: epoch 106, iter 3300, loss: 2.500895, top_1: 0.647773, top_k: 0.849414, samples/s: 1335.539 1612764747.7450294
train: epoch 106, iter 3400, loss: 2.417770, top_1: 0.653828, top_k: 0.855391, samples/s: 1334.141 1612764766.9333577
train: epoch 106, iter 3500, loss: 2.310693, top_1: 0.657852, top_k: 0.856367, samples/s: 1337.521 1612764786.0732512
train: epoch 106, iter 3600, loss: 2.299231, top_1: 0.656250, top_k: 0.854570, samples/s: 1332.202 1612764805.2895753
train: epoch 106, iter 3700, loss: 2.188807, top_1: 0.659648, top_k: 0.853008, samples/s: 1332.788 1612764824.497402
train: epoch 106, iter 3800, loss: 2.562097, top_1: 0.650664, top_k: 0.854453, samples/s: 1333.068 1612764843.7012947
train: epoch 106, iter 3900, loss: 2.325840, top_1: 0.650273, top_k: 0.854258, samples/s: 1332.809 1612764862.9087927
train: epoch 106, iter 4000, loss: 2.516368, top_1: 0.656367, top_k: 0.855625, samples/s: 1339.223 1612764882.0244107
train: epoch 106, iter 4100, loss: 2.317863, top_1: 0.653711, top_k: 0.851680, samples/s: 1327.009 1612764901.3159544
train: epoch 106, iter 4200, loss: 2.397435, top_1: 0.654922, top_k: 0.854219, samples/s: 1336.550 1612764920.4696777
train: epoch 106, iter 4300, loss: 2.662897, top_1: 0.652695, top_k: 0.854648, samples/s: 1336.158 1612764939.6290705
train: epoch 106, iter 4400, loss: 2.504511, top_1: 0.654922, top_k: 0.854727, samples/s: 1334.307 1612764958.8150423
train: epoch 106, iter 4500, loss: 2.207169, top_1: 0.649844, top_k: 0.847812, samples/s: 1335.639 1612764977.9818983
train: epoch 106, iter 4600, loss: 2.598215, top_1: 0.659180, top_k: 0.855781, samples/s: 1333.067 1612764997.1858273
train: epoch 106, iter 4700, loss: 2.633152, top_1: 0.652930, top_k: 0.854297, samples/s: 1340.318 1612765016.285672
train: epoch 106, iter 4800, loss: 2.357401, top_1: 0.654258, top_k: 0.854023, samples/s: 1334.136 1612765035.474175
train: epoch 106, iter 4900, loss: 2.307378, top_1: 0.653555, top_k: 0.853203, samples/s: 1328.366 1612765054.7459204
train: epoch 106, iter 5000, loss: 2.311484, top_1: 0.652617, top_k: 0.853711, samples/s: 1334.083 1612765073.9352124
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_106.
validation: epoch 106, iter 195, top_1: 0.690124, top_k: 0.890044, samples/s: 2781.690 1612765092.4415975
train: epoch 107, iter 100, loss: 2.607364, top_1: 0.663867, top_k: 0.858242, samples/s: 1360.762 1612765127.1446774
train: epoch 107, iter 200, loss: 2.500311, top_1: 0.665977, top_k: 0.859648, samples/s: 1356.937 1612765146.0107725
train: epoch 107, iter 300, loss: 2.331580, top_1: 0.665664, top_k: 0.859805, samples/s: 1363.847 1612765164.7812634
train: epoch 107, iter 400, loss: 2.365656, top_1: 0.669180, top_k: 0.863594, samples/s: 1355.096 1612765183.6728256
train: epoch 107, iter 500, loss: 2.486090, top_1: 0.662188, top_k: 0.858750, samples/s: 1333.864 1612765202.8652246
train: epoch 107, iter 600, loss: 2.468280, top_1: 0.667031, top_k: 0.858711, samples/s: 1335.881 1612765222.0285301
train: epoch 107, iter 700, loss: 2.457480, top_1: 0.661055, top_k: 0.857734, samples/s: 1312.335 1612765241.5357153
train: epoch 107, iter 800, loss: 2.437231, top_1: 0.658438, top_k: 0.856680, samples/s: 1348.268 1612765260.5231023
train: epoch 107, iter 900, loss: 2.487020, top_1: 0.657852, top_k: 0.855703, samples/s: 1337.176 1612765279.667913
train: epoch 107, iter 1000, loss: 2.320812, top_1: 0.660742, top_k: 0.857500, samples/s: 1321.769 1612765299.0358508
train: epoch 107, iter 1100, loss: 2.364043, top_1: 0.663086, top_k: 0.859492, samples/s: 1325.599 1612765318.3479085
train: epoch 107, iter 1200, loss: 2.411852, top_1: 0.660859, top_k: 0.857422, samples/s: 1339.616 1612765337.4578364
train: epoch 107, iter 1300, loss: 2.333467, top_1: 0.666875, top_k: 0.858984, samples/s: 1338.357 1612765356.5858033
train: epoch 107, iter 1400, loss: 2.363580, top_1: 0.661563, top_k: 0.857109, samples/s: 1331.430 1612765375.813376
train: epoch 107, iter 1500, loss: 2.501685, top_1: 0.659922, top_k: 0.856484, samples/s: 1328.179 1612765395.087778
train: epoch 107, iter 1600, loss: 2.503000, top_1: 0.653242, top_k: 0.856289, samples/s: 1329.034 1612765414.3499167
train: epoch 107, iter 1700, loss: 2.562839, top_1: 0.657539, top_k: 0.857617, samples/s: 1343.047 1612765433.4110398
train: epoch 107, iter 1800, loss: 2.322288, top_1: 0.662461, top_k: 0.858672, samples/s: 1329.616 1612765452.6647272
train: epoch 107, iter 1900, loss: 2.273241, top_1: 0.661836, top_k: 0.858789, samples/s: 1327.743 1612765471.9455264
train: epoch 107, iter 2000, loss: 2.212766, top_1: 0.666562, top_k: 0.861211, samples/s: 1334.970 1612765491.1220288
train: epoch 107, iter 2100, loss: 2.350192, top_1: 0.660664, top_k: 0.854922, samples/s: 1335.096 1612765510.2965891
train: epoch 107, iter 2200, loss: 2.581057, top_1: 0.657148, top_k: 0.857500, samples/s: 1334.701 1612765529.4769175
train: epoch 107, iter 2300, loss: 2.499878, top_1: 0.654492, top_k: 0.856367, samples/s: 1330.226 1612765548.7218344
train: epoch 107, iter 2400, loss: 2.368198, top_1: 0.657773, top_k: 0.858203, samples/s: 1320.453 1612765568.1091738
train: epoch 107, iter 2500, loss: 2.454523, top_1: 0.656016, top_k: 0.855195, samples/s: 1339.525 1612765587.220337
train: epoch 107, iter 2600, loss: 2.371282, top_1: 0.660664, top_k: 0.860664, samples/s: 1336.677 1612765606.3723168
train: epoch 107, iter 2700, loss: 2.360160, top_1: 0.657969, top_k: 0.857383, samples/s: 1331.727 1612765625.5954745
train: epoch 107, iter 2800, loss: 2.358722, top_1: 0.658320, top_k: 0.856523, samples/s: 1335.411 1612765644.7656279
train: epoch 107, iter 2900, loss: 2.265621, top_1: 0.656367, top_k: 0.854922, samples/s: 1331.908 1612765663.9861014
train: epoch 107, iter 3000, loss: 2.428279, top_1: 0.659180, top_k: 0.854414, samples/s: 1333.509 1612765683.1835754
train: epoch 107, iter 3100, loss: 2.354818, top_1: 0.662539, top_k: 0.857305, samples/s: 1334.005 1612765702.3739717
train: epoch 107, iter 3200, loss: 2.435543, top_1: 0.660703, top_k: 0.856914, samples/s: 1325.938 1612765721.6810257
train: epoch 107, iter 3300, loss: 2.189158, top_1: 0.651992, top_k: 0.853359, samples/s: 1335.146 1612765740.855016
train: epoch 107, iter 3400, loss: 2.330375, top_1: 0.655312, top_k: 0.853516, samples/s: 1333.626 1612765760.050699
train: epoch 107, iter 3500, loss: 2.270295, top_1: 0.656797, top_k: 0.857148, samples/s: 1336.335 1612765779.2075734
train: epoch 107, iter 3600, loss: 2.289121, top_1: 0.657500, top_k: 0.851094, samples/s: 1330.273 1612765798.4518
train: epoch 107, iter 3700, loss: 2.398455, top_1: 0.651172, top_k: 0.853906, samples/s: 1334.540 1612765817.6344101
train: epoch 107, iter 3800, loss: 2.328448, top_1: 0.652656, top_k: 0.852148, samples/s: 1335.272 1612765836.8065774
train: epoch 107, iter 3900, loss: 2.656488, top_1: 0.652227, top_k: 0.853906, samples/s: 1325.489 1612765856.120151
train: epoch 107, iter 4000, loss: 2.494166, top_1: 0.658555, top_k: 0.853281, samples/s: 1337.953 1612765875.253914
train: epoch 107, iter 4100, loss: 2.475086, top_1: 0.659219, top_k: 0.854805, samples/s: 1337.536 1612765894.3935235
train: epoch 107, iter 4200, loss: 2.527343, top_1: 0.659570, top_k: 0.857773, samples/s: 1318.827 1612765913.8047297
train: epoch 107, iter 4300, loss: 2.324973, top_1: 0.659687, top_k: 0.854062, samples/s: 1338.611 1612765932.9290168
train: epoch 107, iter 4400, loss: 2.300532, top_1: 0.655898, top_k: 0.853594, samples/s: 1339.185 1612765952.0452096
train: epoch 107, iter 4500, loss: 2.494486, top_1: 0.655312, top_k: 0.850820, samples/s: 1336.764 1612765971.1958907
train: epoch 107, iter 4600, loss: 2.366318, top_1: 0.655742, top_k: 0.857148, samples/s: 1323.491 1612765990.5387125
train: epoch 107, iter 4700, loss: 2.460672, top_1: 0.649609, top_k: 0.857109, samples/s: 1338.915 1612766009.658651
train: epoch 107, iter 4800, loss: 2.406001, top_1: 0.655625, top_k: 0.855000, samples/s: 1326.632 1612766028.9556253
train: epoch 107, iter 4900, loss: 2.539299, top_1: 0.656992, top_k: 0.857656, samples/s: 1339.290 1612766048.0702493
train: epoch 107, iter 5000, loss: 2.387571, top_1: 0.664062, top_k: 0.861250, samples/s: 1329.327 1612766067.3280778
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_107.
validation: epoch 107, iter 195, top_1: 0.696534, top_k: 0.894992, samples/s: 2798.074 1612766085.7937267
train: epoch 108, iter 100, loss: 2.363404, top_1: 0.669570, top_k: 0.860977, samples/s: 1357.477 1612766120.4034517
train: epoch 108, iter 200, loss: 2.358740, top_1: 0.668047, top_k: 0.862656, samples/s: 1358.691 1612766139.2450593
train: epoch 108, iter 300, loss: 2.230072, top_1: 0.670078, top_k: 0.862695, samples/s: 1363.111 1612766158.0258133
train: epoch 108, iter 400, loss: 2.241998, top_1: 0.672461, top_k: 0.862266, samples/s: 1349.512 1612766176.9954119
train: epoch 108, iter 500, loss: 2.250326, top_1: 0.668750, top_k: 0.861328, samples/s: 1334.618 1612766196.1769192
train: epoch 108, iter 600, loss: 2.529037, top_1: 0.666406, top_k: 0.859141, samples/s: 1325.636 1612766215.4884245
train: epoch 108, iter 700, loss: 2.476743, top_1: 0.664258, top_k: 0.857383, samples/s: 1337.887 1612766234.623106
train: epoch 108, iter 800, loss: 2.322225, top_1: 0.668242, top_k: 0.862578, samples/s: 1329.997 1612766253.8712788
train: epoch 108, iter 900, loss: 2.493066, top_1: 0.668164, top_k: 0.862852, samples/s: 1336.069 1612766273.0319705
train: epoch 108, iter 1000, loss: 2.369467, top_1: 0.668047, top_k: 0.863320, samples/s: 1328.317 1612766292.3044784
train: epoch 108, iter 1100, loss: 2.392807, top_1: 0.664414, top_k: 0.864453, samples/s: 1328.518 1612766311.5740979
train: epoch 108, iter 1200, loss: 2.368789, top_1: 0.666367, top_k: 0.858516, samples/s: 1335.374 1612766330.7446852
train: epoch 108, iter 1300, loss: 2.296777, top_1: 0.658203, top_k: 0.859961, samples/s: 1336.030 1612766349.9060097
train: epoch 108, iter 1400, loss: 2.512556, top_1: 0.667383, top_k: 0.862344, samples/s: 1330.556 1612766369.1460624
train: epoch 108, iter 1500, loss: 2.296890, top_1: 0.661016, top_k: 0.858047, samples/s: 1329.760 1612766388.397626
train: epoch 108, iter 1600, loss: 2.365177, top_1: 0.660508, top_k: 0.857344, samples/s: 1328.495 1612766407.6675453
train: epoch 108, iter 1700, loss: 2.411222, top_1: 0.662422, top_k: 0.859531, samples/s: 1331.206 1612766426.8983305
train: epoch 108, iter 1800, loss: 2.291926, top_1: 0.662930, top_k: 0.860430, samples/s: 1337.568 1612766446.0374832
train: epoch 108, iter 1900, loss: 2.320699, top_1: 0.667656, top_k: 0.862070, samples/s: 1330.014 1612766465.2853675
train: epoch 108, iter 2000, loss: 2.307115, top_1: 0.654648, top_k: 0.855000, samples/s: 1325.877 1612766484.5933433
train: epoch 108, iter 2100, loss: 2.318552, top_1: 0.658164, top_k: 0.854336, samples/s: 1337.299 1612766503.7363808
train: epoch 108, iter 2200, loss: 2.318651, top_1: 0.658789, top_k: 0.858672, samples/s: 1332.186 1612766522.952933
train: epoch 108, iter 2300, loss: 2.301430, top_1: 0.668125, top_k: 0.863906, samples/s: 1332.557 1612766542.1641417
train: epoch 108, iter 2400, loss: 2.349720, top_1: 0.660703, top_k: 0.858008, samples/s: 1333.501 1612766561.3617454
train: epoch 108, iter 2500, loss: 2.273578, top_1: 0.661797, top_k: 0.859023, samples/s: 1333.522 1612766580.5589952
train: epoch 108, iter 2600, loss: 2.450681, top_1: 0.659219, top_k: 0.856992, samples/s: 1332.969 1612766599.7642674
train: epoch 108, iter 2700, loss: 2.324445, top_1: 0.658359, top_k: 0.855078, samples/s: 1332.028 1612766618.9830446
train: epoch 108, iter 2800, loss: 2.407048, top_1: 0.662461, top_k: 0.857812, samples/s: 1334.292 1612766638.1692402
train: epoch 108, iter 2900, loss: 2.256972, top_1: 0.660039, top_k: 0.860117, samples/s: 1333.051 1612766657.373297
train: epoch 108, iter 3000, loss: 2.309708, top_1: 0.664883, top_k: 0.860938, samples/s: 1334.315 1612766676.5591786
train: epoch 108, iter 3100, loss: 2.395915, top_1: 0.661992, top_k: 0.858203, samples/s: 1336.848 1612766695.708741
train: epoch 108, iter 3200, loss: 2.206001, top_1: 0.661641, top_k: 0.857930, samples/s: 1333.783 1612766714.902291
train: epoch 108, iter 3300, loss: 2.422338, top_1: 0.663516, top_k: 0.856797, samples/s: 1334.363 1612766734.0874043
train: epoch 108, iter 3400, loss: 2.317166, top_1: 0.662617, top_k: 0.857617, samples/s: 1331.964 1612766753.307207
train: epoch 108, iter 3500, loss: 2.416664, top_1: 0.657031, top_k: 0.857422, samples/s: 1326.767 1612766772.602155
train: epoch 108, iter 3600, loss: 2.335496, top_1: 0.658594, top_k: 0.855742, samples/s: 1340.038 1612766791.7062032
train: epoch 108, iter 3700, loss: 2.304696, top_1: 0.658203, top_k: 0.857852, samples/s: 1332.556 1612766810.9172888
train: epoch 108, iter 3800, loss: 2.302469, top_1: 0.658477, top_k: 0.856445, samples/s: 1329.933 1612766830.1664643
train: epoch 108, iter 3900, loss: 2.305367, top_1: 0.655000, top_k: 0.853984, samples/s: 1341.551 1612766849.2487805
train: epoch 108, iter 4000, loss: 2.185994, top_1: 0.661367, top_k: 0.859453, samples/s: 1332.794 1612766868.456576
train: epoch 108, iter 4100, loss: 2.370852, top_1: 0.661445, top_k: 0.855117, samples/s: 1336.963 1612766887.6044185
train: epoch 108, iter 4200, loss: 2.278370, top_1: 0.656328, top_k: 0.857031, samples/s: 1332.310 1612766906.8191833
train: epoch 108, iter 4300, loss: 2.340913, top_1: 0.659922, top_k: 0.855586, samples/s: 1337.047 1612766925.9658465
train: epoch 108, iter 4400, loss: 2.413054, top_1: 0.659336, top_k: 0.850078, samples/s: 1334.182 1612766945.1536105
train: epoch 108, iter 4500, loss: 2.390459, top_1: 0.661445, top_k: 0.858359, samples/s: 1336.330 1612766964.3106463
train: epoch 108, iter 4600, loss: 2.532151, top_1: 0.660000, top_k: 0.854727, samples/s: 1330.508 1612766983.551336
train: epoch 108, iter 4700, loss: 2.345817, top_1: 0.661211, top_k: 0.857617, samples/s: 1332.050 1612767002.7698917
train: epoch 108, iter 4800, loss: 2.445739, top_1: 0.663711, top_k: 0.856992, samples/s: 1332.188 1612767021.986327
train: epoch 108, iter 4900, loss: 2.433233, top_1: 0.659258, top_k: 0.857305, samples/s: 1335.745 1612767041.1517382
train: epoch 108, iter 5000, loss: 2.322371, top_1: 0.664844, top_k: 0.857812, samples/s: 1333.584 1612767060.3481
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_108.
validation: epoch 108, iter 195, top_1: 0.695212, top_k: 0.893930, samples/s: 2767.643 1612767078.9768665
train: epoch 109, iter 100, loss: 2.114450, top_1: 0.673164, top_k: 0.862422, samples/s: 1357.322 1612767120.1490254
train: epoch 109, iter 200, loss: 2.365320, top_1: 0.671992, top_k: 0.862070, samples/s: 1360.565 1612767138.9647863
train: epoch 109, iter 300, loss: 2.359151, top_1: 0.670859, top_k: 0.861992, samples/s: 1361.846 1612767157.7630148
train: epoch 109, iter 400, loss: 2.418149, top_1: 0.672188, top_k: 0.863125, samples/s: 1356.456 1612767176.6355038
train: epoch 109, iter 500, loss: 2.374274, top_1: 0.671719, top_k: 0.863984, samples/s: 1335.737 1612767195.8009157
train: epoch 109, iter 600, loss: 2.395520, top_1: 0.677070, top_k: 0.864297, samples/s: 1333.549 1612767214.9977703
train: epoch 109, iter 700, loss: 2.498355, top_1: 0.665078, top_k: 0.861406, samples/s: 1326.229 1612767234.301206
train: epoch 109, iter 800, loss: 2.523423, top_1: 0.668672, top_k: 0.860820, samples/s: 1325.184 1612767253.6186967
train: epoch 109, iter 900, loss: 2.429277, top_1: 0.667500, top_k: 0.860742, samples/s: 1333.664 1612767272.8139548
train: epoch 109, iter 1000, loss: 2.356272, top_1: 0.663750, top_k: 0.858906, samples/s: 1332.697 1612767292.0230975
train: epoch 109, iter 1100, loss: 2.546451, top_1: 0.669180, top_k: 0.861758, samples/s: 1332.132 1612767311.2403994
train: epoch 109, iter 1200, loss: 2.221606, top_1: 0.669844, top_k: 0.864414, samples/s: 1323.864 1612767330.577783
train: epoch 109, iter 1300, loss: 2.329779, top_1: 0.666055, top_k: 0.862812, samples/s: 1328.189 1612767349.852194
train: epoch 109, iter 1400, loss: 2.299466, top_1: 0.671367, top_k: 0.860195, samples/s: 1332.127 1612767369.069493
train: epoch 109, iter 1500, loss: 2.424402, top_1: 0.665547, top_k: 0.864062, samples/s: 1336.597 1612767388.2226746
train: epoch 109, iter 1600, loss: 2.347218, top_1: 0.666094, top_k: 0.860156, samples/s: 1323.770 1612767407.5613244
train: epoch 109, iter 1700, loss: 2.359548, top_1: 0.664102, top_k: 0.858984, samples/s: 1323.074 1612767426.91028
train: epoch 109, iter 1800, loss: 2.357620, top_1: 0.662969, top_k: 0.861523, samples/s: 1339.089 1612767446.0277739
train: epoch 109, iter 1900, loss: 2.368321, top_1: 0.670664, top_k: 0.863477, samples/s: 1324.796 1612767465.3514557
train: epoch 109, iter 2000, loss: 2.421353, top_1: 0.664336, top_k: 0.862656, samples/s: 1329.076 1612767484.6129344
train: epoch 109, iter 2100, loss: 2.324137, top_1: 0.664922, top_k: 0.861172, samples/s: 1333.499 1612767503.8105774
train: epoch 109, iter 2200, loss: 2.469296, top_1: 0.663047, top_k: 0.857070, samples/s: 1326.832 1612767523.104672
train: epoch 109, iter 2300, loss: 2.417746, top_1: 0.666484, top_k: 0.859102, samples/s: 1330.593 1612767542.3442366
train: epoch 109, iter 2400, loss: 2.398874, top_1: 0.663086, top_k: 0.861836, samples/s: 1328.145 1612767561.619178
train: epoch 109, iter 2500, loss: 2.238922, top_1: 0.661055, top_k: 0.857500, samples/s: 1327.947 1612767580.8970184
train: epoch 109, iter 2600, loss: 2.300848, top_1: 0.665039, top_k: 0.861875, samples/s: 1329.425 1612767600.153468
train: epoch 109, iter 2700, loss: 2.294748, top_1: 0.664102, top_k: 0.862070, samples/s: 1338.989 1612767619.2724164
train: epoch 109, iter 2800, loss: 2.384346, top_1: 0.661445, top_k: 0.857656, samples/s: 1325.853 1612767638.580795
train: epoch 109, iter 2900, loss: 2.607685, top_1: 0.663047, top_k: 0.859375, samples/s: 1327.620 1612767657.8633194
train: epoch 109, iter 3000, loss: 2.496874, top_1: 0.659492, top_k: 0.859336, samples/s: 1331.650 1612767677.0875897
train: epoch 109, iter 3100, loss: 2.432945, top_1: 0.662266, top_k: 0.856992, samples/s: 1333.995 1612767696.2782001
train: epoch 109, iter 3200, loss: 2.388197, top_1: 0.661992, top_k: 0.860742, samples/s: 1326.843 1612767715.572099
train: epoch 109, iter 3300, loss: 2.399108, top_1: 0.662891, top_k: 0.858164, samples/s: 1331.412 1612767734.7997108
train: epoch 109, iter 3400, loss: 2.482972, top_1: 0.657109, top_k: 0.855781, samples/s: 1332.595 1612767754.0103312
train: epoch 109, iter 3500, loss: 2.287864, top_1: 0.662930, top_k: 0.860508, samples/s: 1328.707 1612767773.2772071
train: epoch 109, iter 3600, loss: 2.424361, top_1: 0.664531, top_k: 0.859844, samples/s: 1337.571 1612767792.4164104
train: epoch 109, iter 3700, loss: 2.441844, top_1: 0.663516, top_k: 0.857187, samples/s: 1321.633 1612767811.7863245
train: epoch 109, iter 3800, loss: 2.312130, top_1: 0.661367, top_k: 0.859844, samples/s: 1326.948 1612767831.078724
train: epoch 109, iter 3900, loss: 2.399070, top_1: 0.653594, top_k: 0.855195, samples/s: 1330.066 1612767850.3259313
train: epoch 109, iter 4000, loss: 2.374659, top_1: 0.658477, top_k: 0.854453, samples/s: 1329.396 1612767869.5827384
train: epoch 109, iter 4100, loss: 2.411511, top_1: 0.660781, top_k: 0.858672, samples/s: 1329.739 1612767888.834746
train: epoch 109, iter 4200, loss: 2.221025, top_1: 0.659844, top_k: 0.855547, samples/s: 1323.844 1612767908.1723578
train: epoch 109, iter 4300, loss: 2.487177, top_1: 0.659609, top_k: 0.853047, samples/s: 1334.389 1612767927.3571253
train: epoch 109, iter 4400, loss: 2.448705, top_1: 0.660898, top_k: 0.854062, samples/s: 1336.678 1612767946.5090652
train: epoch 109, iter 4500, loss: 2.415201, top_1: 0.660078, top_k: 0.857969, samples/s: 1319.287 1612767965.913496
train: epoch 109, iter 4600, loss: 2.421061, top_1: 0.663047, top_k: 0.859883, samples/s: 1335.086 1612767985.0883381
train: epoch 109, iter 4700, loss: 2.389369, top_1: 0.661328, top_k: 0.858242, samples/s: 1329.301 1612768004.3464944
train: epoch 109, iter 4800, loss: 2.348052, top_1: 0.660977, top_k: 0.857930, samples/s: 1332.522 1612768023.5582383
train: epoch 109, iter 4900, loss: 2.502241, top_1: 0.659727, top_k: 0.855898, samples/s: 1328.580 1612768042.8269398
train: epoch 109, iter 5000, loss: 2.340029, top_1: 0.665508, top_k: 0.860781, samples/s: 1325.706 1612768062.1373541
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_109.
validation: epoch 109, iter 195, top_1: 0.694872, top_k: 0.893630, samples/s: 2776.139 1612768080.6049185
train: epoch 110, iter 100, loss: 2.385476, top_1: 0.669492, top_k: 0.865234, samples/s: 1361.275 1612768115.4756572
train: epoch 110, iter 200, loss: 2.388867, top_1: 0.676211, top_k: 0.869023, samples/s: 1360.939 1612768134.2861502
train: epoch 110, iter 300, loss: 2.297707, top_1: 0.677188, top_k: 0.865859, samples/s: 1366.012 1612768153.0271158
train: epoch 110, iter 400, loss: 2.357965, top_1: 0.675469, top_k: 0.865781, samples/s: 1350.996 1612768171.9757874
train: epoch 110, iter 500, loss: 2.475799, top_1: 0.667305, top_k: 0.861953, samples/s: 1339.607 1612768191.0859258
train: epoch 110, iter 600, loss: 2.317004, top_1: 0.674922, top_k: 0.865078, samples/s: 1336.036 1612768210.2471282
train: epoch 110, iter 700, loss: 2.270263, top_1: 0.671250, top_k: 0.866641, samples/s: 1336.156 1612768229.4065268
train: epoch 110, iter 800, loss: 2.238345, top_1: 0.672383, top_k: 0.863203, samples/s: 1330.440 1612768248.64828
train: epoch 110, iter 900, loss: 2.325904, top_1: 0.671562, top_k: 0.864492, samples/s: 1334.359 1612768267.8334603
train: epoch 110, iter 1000, loss: 2.128300, top_1: 0.676523, top_k: 0.862891, samples/s: 1337.030 1612768286.980371
train: epoch 110, iter 1100, loss: 2.304208, top_1: 0.669258, top_k: 0.862773, samples/s: 1337.069 1612768306.126727
train: epoch 110, iter 1200, loss: 2.340091, top_1: 0.671836, top_k: 0.864336, samples/s: 1335.734 1612768325.2923014
train: epoch 110, iter 1300, loss: 2.257045, top_1: 0.668867, top_k: 0.862187, samples/s: 1328.120 1612768344.5676248
train: epoch 110, iter 1400, loss: 2.444062, top_1: 0.670625, top_k: 0.864336, samples/s: 1327.960 1612768363.8454008
train: epoch 110, iter 1500, loss: 2.398459, top_1: 0.663164, top_k: 0.857109, samples/s: 1337.431 1612768382.9865716
train: epoch 110, iter 1600, loss: 2.438996, top_1: 0.665273, top_k: 0.859727, samples/s: 1330.024 1612768402.2342265
train: epoch 110, iter 1700, loss: 2.316512, top_1: 0.671484, top_k: 0.865586, samples/s: 1341.107 1612768421.3229616
train: epoch 110, iter 1800, loss: 2.419935, top_1: 0.664414, top_k: 0.859883, samples/s: 1327.844 1612768440.6023538
train: epoch 110, iter 1900, loss: 2.213473, top_1: 0.666719, top_k: 0.857695, samples/s: 1335.684 1612768459.7685182
train: epoch 110, iter 2000, loss: 2.135460, top_1: 0.666445, top_k: 0.861055, samples/s: 1331.620 1612768478.9935176
train: epoch 110, iter 2100, loss: 2.347129, top_1: 0.671367, top_k: 0.862070, samples/s: 1336.586 1612768498.1465063
train: epoch 110, iter 2200, loss: 2.426099, top_1: 0.663711, top_k: 0.862031, samples/s: 1336.168 1612768517.3060386
train: epoch 110, iter 2300, loss: 2.427181, top_1: 0.664844, top_k: 0.862031, samples/s: 1336.294 1612768536.463321
train: epoch 110, iter 2400, loss: 2.301177, top_1: 0.666602, top_k: 0.858359, samples/s: 1336.410 1612768555.6190546
train: epoch 110, iter 2500, loss: 2.140636, top_1: 0.669687, top_k: 0.863437, samples/s: 1334.699 1612768574.7994413
train: epoch 110, iter 2600, loss: 2.298567, top_1: 0.661367, top_k: 0.859414, samples/s: 1338.250 1612768593.9289641
train: epoch 110, iter 2700, loss: 2.253190, top_1: 0.667617, top_k: 0.861719, samples/s: 1335.039 1612768613.1043146
train: epoch 110, iter 2800, loss: 2.404393, top_1: 0.661758, top_k: 0.857031, samples/s: 1332.684 1612768632.3137083
train: epoch 110, iter 2900, loss: 2.486556, top_1: 0.660898, top_k: 0.858750, samples/s: 1332.664 1612768651.523344
train: epoch 110, iter 3000, loss: 2.363841, top_1: 0.662227, top_k: 0.860898, samples/s: 1334.321 1612768670.709128
train: epoch 110, iter 3100, loss: 2.410592, top_1: 0.658438, top_k: 0.858672, samples/s: 1335.754 1612768689.874408
train: epoch 110, iter 3200, loss: 2.246272, top_1: 0.670352, top_k: 0.860977, samples/s: 1332.056 1612768709.0927353
train: epoch 110, iter 3300, loss: 2.448591, top_1: 0.663047, top_k: 0.860117, samples/s: 1341.479 1612768728.1761649
train: epoch 110, iter 3400, loss: 2.493501, top_1: 0.664766, top_k: 0.862812, samples/s: 1334.800 1612768747.3550284
train: epoch 110, iter 3500, loss: 2.401253, top_1: 0.665781, top_k: 0.860664, samples/s: 1336.698 1612768766.5067585
train: epoch 110, iter 3600, loss: 2.259927, top_1: 0.664961, top_k: 0.858359, samples/s: 1336.912 1612768785.6553462
train: epoch 110, iter 3700, loss: 2.363921, top_1: 0.659219, top_k: 0.856172, samples/s: 1333.289 1612768804.8559449
train: epoch 110, iter 3800, loss: 2.478499, top_1: 0.666602, top_k: 0.859375, samples/s: 1342.057 1612768823.9311318
train: epoch 110, iter 3900, loss: 2.320149, top_1: 0.662500, top_k: 0.861563, samples/s: 1335.921 1612768843.0940638
train: epoch 110, iter 4000, loss: 2.431806, top_1: 0.662617, top_k: 0.858711, samples/s: 1334.547 1612768862.2764692
train: epoch 110, iter 4100, loss: 2.556525, top_1: 0.665625, top_k: 0.858359, samples/s: 1331.889 1612768881.4973412
train: epoch 110, iter 4200, loss: 2.474980, top_1: 0.665000, top_k: 0.862656, samples/s: 1339.902 1612768900.6032412
train: epoch 110, iter 4300, loss: 2.355885, top_1: 0.666250, top_k: 0.859453, samples/s: 1344.765 1612768919.639974
train: epoch 110, iter 4400, loss: 2.363425, top_1: 0.664922, top_k: 0.860508, samples/s: 1327.212 1612768938.9285681
train: epoch 110, iter 4500, loss: 2.397621, top_1: 0.664023, top_k: 0.860508, samples/s: 1333.138 1612768958.1313255
train: epoch 110, iter 4600, loss: 2.446154, top_1: 0.666133, top_k: 0.860625, samples/s: 1337.426 1612768977.2726352
train: epoch 110, iter 4700, loss: 2.428553, top_1: 0.665273, top_k: 0.857852, samples/s: 1339.083 1612768996.3901243
train: epoch 110, iter 4800, loss: 2.294834, top_1: 0.663945, top_k: 0.861016, samples/s: 1331.820 1612769015.6119943
train: epoch 110, iter 4900, loss: 2.486731, top_1: 0.658672, top_k: 0.855977, samples/s: 1332.119 1612769034.8294814
train: epoch 110, iter 5000, loss: 2.509440, top_1: 0.675547, top_k: 0.867773, samples/s: 1338.196 1612769053.9596877
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_110.
validation: epoch 110, iter 195, top_1: 0.698598, top_k: 0.897436, samples/s: 2796.686 1612769072.374918
train: epoch 111, iter 100, loss: 2.334477, top_1: 0.674180, top_k: 0.867227, samples/s: 1364.037 1612769107.1523297
train: epoch 111, iter 200, loss: 2.405348, top_1: 0.676406, top_k: 0.867305, samples/s: 1360.423 1612769125.9701154
train: epoch 111, iter 300, loss: 2.455463, top_1: 0.675625, top_k: 0.865586, samples/s: 1359.682 1612769144.7979681
train: epoch 111, iter 400, loss: 2.413595, top_1: 0.675586, top_k: 0.866484, samples/s: 1354.479 1612769163.6981535
train: epoch 111, iter 500, loss: 2.389578, top_1: 0.683984, top_k: 0.871211, samples/s: 1340.635 1612769182.7935793
train: epoch 111, iter 600, loss: 2.235504, top_1: 0.673789, top_k: 0.866133, samples/s: 1336.693 1612769201.945389
train: epoch 111, iter 700, loss: 2.436811, top_1: 0.672813, top_k: 0.867461, samples/s: 1328.967 1612769221.2084124
train: epoch 111, iter 800, loss: 2.287759, top_1: 0.671641, top_k: 0.863672, samples/s: 1334.483 1612769240.3919115
train: epoch 111, iter 900, loss: 2.336162, top_1: 0.674336, top_k: 0.868477, samples/s: 1338.587 1612769259.5165412
train: epoch 111, iter 1000, loss: 2.391692, top_1: 0.673203, top_k: 0.862656, samples/s: 1328.824 1612769278.781676
train: epoch 111, iter 1100, loss: 2.302155, top_1: 0.671406, top_k: 0.861719, samples/s: 1340.035 1612769297.8857408
train: epoch 111, iter 1200, loss: 2.314037, top_1: 0.676289, top_k: 0.864805, samples/s: 1333.821 1612769317.0786865
train: epoch 111, iter 1300, loss: 2.335250, top_1: 0.669102, top_k: 0.864141, samples/s: 1325.940 1612769336.3857632
train: epoch 111, iter 1400, loss: 2.413466, top_1: 0.669687, top_k: 0.863867, samples/s: 1335.989 1612769355.5475216
train: epoch 111, iter 1500, loss: 2.204840, top_1: 0.675195, top_k: 0.865820, samples/s: 1337.492 1612769374.6878088
train: epoch 111, iter 1600, loss: 2.308609, top_1: 0.671953, top_k: 0.861836, samples/s: 1329.652 1612769393.9410076
train: epoch 111, iter 1700, loss: 2.453144, top_1: 0.669844, top_k: 0.864844, samples/s: 1333.197 1612769413.142955
train: epoch 111, iter 1800, loss: 2.363737, top_1: 0.668555, top_k: 0.863320, samples/s: 1331.893 1612769432.3637955
train: epoch 111, iter 1900, loss: 2.374570, top_1: 0.667578, top_k: 0.861914, samples/s: 1334.280 1612769451.5500698
train: epoch 111, iter 2000, loss: 2.549790, top_1: 0.670195, top_k: 0.862891, samples/s: 1336.402 1612769470.7059634
train: epoch 111, iter 2100, loss: 2.371380, top_1: 0.666875, top_k: 0.868086, samples/s: 1328.006 1612769489.9829845
train: epoch 111, iter 2200, loss: 2.377368, top_1: 0.668594, top_k: 0.860430, samples/s: 1333.736 1612769509.177307
train: epoch 111, iter 2300, loss: 2.257585, top_1: 0.669609, top_k: 0.863398, samples/s: 1336.406 1612769528.333045
train: epoch 111, iter 2400, loss: 2.398926, top_1: 0.666562, top_k: 0.863047, samples/s: 1334.362 1612769547.5182562
train: epoch 111, iter 2500, loss: 2.363674, top_1: 0.669023, top_k: 0.863984, samples/s: 1331.396 1612769566.7463055
train: epoch 111, iter 2600, loss: 2.457883, top_1: 0.669180, top_k: 0.860781, samples/s: 1338.361 1612769585.874097
train: epoch 111, iter 2700, loss: 2.462362, top_1: 0.666094, top_k: 0.862812, samples/s: 1336.595 1612769605.0272603
train: epoch 111, iter 2800, loss: 2.292278, top_1: 0.670508, top_k: 0.863359, samples/s: 1336.904 1612769624.1759775
train: epoch 111, iter 2900, loss: 2.088328, top_1: 0.669805, top_k: 0.862695, samples/s: 1328.447 1612769643.4466712
train: epoch 111, iter 3000, loss: 2.310558, top_1: 0.663594, top_k: 0.858906, samples/s: 1339.069 1612769662.5643096
train: epoch 111, iter 3100, loss: 2.264962, top_1: 0.669805, top_k: 0.861367, samples/s: 1338.016 1612769681.697192
train: epoch 111, iter 3200, loss: 2.289494, top_1: 0.669102, top_k: 0.863398, samples/s: 1337.561 1612769700.836433
train: epoch 111, iter 3300, loss: 2.501305, top_1: 0.667578, top_k: 0.861875, samples/s: 1329.307 1612769720.0945947
train: epoch 111, iter 3400, loss: 2.351339, top_1: 0.667188, top_k: 0.865820, samples/s: 1341.015 1612769739.1846437
train: epoch 111, iter 3500, loss: 2.541116, top_1: 0.667578, top_k: 0.864180, samples/s: 1334.569 1612769758.3668907
train: epoch 111, iter 3600, loss: 2.439827, top_1: 0.669766, top_k: 0.867344, samples/s: 1336.059 1612769777.5276568
train: epoch 111, iter 3700, loss: 2.376721, top_1: 0.669023, top_k: 0.863242, samples/s: 1329.004 1612769796.7902145
train: epoch 111, iter 3800, loss: 2.328407, top_1: 0.662383, top_k: 0.862266, samples/s: 1333.492 1612769815.9880147
train: epoch 111, iter 3900, loss: 2.411588, top_1: 0.666602, top_k: 0.863594, samples/s: 1335.079 1612769835.162798
train: epoch 111, iter 4000, loss: 2.338997, top_1: 0.670430, top_k: 0.862266, samples/s: 1331.395 1612769854.390805
train: epoch 111, iter 4100, loss: 2.235376, top_1: 0.663359, top_k: 0.861563, samples/s: 1334.302 1612769873.5768025
train: epoch 111, iter 4200, loss: 2.339959, top_1: 0.666836, top_k: 0.856484, samples/s: 1336.273 1612769892.7345707
train: epoch 111, iter 4300, loss: 2.367004, top_1: 0.665859, top_k: 0.860547, samples/s: 1339.839 1612769911.8413756
train: epoch 111, iter 4400, loss: 2.538503, top_1: 0.668750, top_k: 0.862773, samples/s: 1336.702 1612769930.9929626
train: epoch 111, iter 4500, loss: 2.484807, top_1: 0.667773, top_k: 0.861250, samples/s: 1324.362 1612769950.3230152
train: epoch 111, iter 4600, loss: 2.257277, top_1: 0.670000, top_k: 0.859453, samples/s: 1338.993 1612769969.4418654
train: epoch 111, iter 4700, loss: 2.361041, top_1: 0.662344, top_k: 0.859297, samples/s: 1327.649 1612769988.724144
train: epoch 111, iter 4800, loss: 2.289351, top_1: 0.664297, top_k: 0.859258, samples/s: 1337.641 1612770007.8623602
train: epoch 111, iter 4900, loss: 2.487591, top_1: 0.666641, top_k: 0.860117, samples/s: 1339.791 1612770026.9697683
train: epoch 111, iter 5000, loss: 2.233617, top_1: 0.668516, top_k: 0.863320, samples/s: 1331.171 1612770046.2009408
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_111.
validation: epoch 111, iter 195, top_1: 0.700962, top_k: 0.897276, samples/s: 2836.591 1612770064.436014
train: epoch 112, iter 100, loss: 2.353634, top_1: 0.669141, top_k: 0.860625, samples/s: 1361.851 1612770098.8910913
train: epoch 112, iter 200, loss: 2.375263, top_1: 0.670781, top_k: 0.862734, samples/s: 1357.951 1612770117.7432966
train: epoch 112, iter 300, loss: 2.395905, top_1: 0.675781, top_k: 0.868359, samples/s: 1363.418 1612770136.5193462
train: epoch 112, iter 400, loss: 2.489199, top_1: 0.673945, top_k: 0.865469, samples/s: 1344.152 1612770155.5648406
train: epoch 112, iter 500, loss: 2.305526, top_1: 0.677188, top_k: 0.871406, samples/s: 1345.394 1612770174.5927758
train: epoch 112, iter 600, loss: 2.236224, top_1: 0.677461, top_k: 0.867930, samples/s: 1334.354 1612770193.778013
train: epoch 112, iter 700, loss: 2.349622, top_1: 0.680078, top_k: 0.865273, samples/s: 1329.256 1612770213.0370047
train: epoch 112, iter 800, loss: 2.289175, top_1: 0.676172, top_k: 0.871680, samples/s: 1336.304 1612770232.194227
train: epoch 112, iter 900, loss: 2.332366, top_1: 0.672617, top_k: 0.866563, samples/s: 1331.405 1612770251.4220781
train: epoch 112, iter 1000, loss: 2.382374, top_1: 0.675547, top_k: 0.867305, samples/s: 1320.736 1612770270.8051753
train: epoch 112, iter 1100, loss: 2.379119, top_1: 0.679219, top_k: 0.866992, samples/s: 1339.614 1612770289.9151814
train: epoch 112, iter 1200, loss: 2.319809, top_1: 0.674570, top_k: 0.865430, samples/s: 1333.938 1612770309.1064546
train: epoch 112, iter 1300, loss: 2.261273, top_1: 0.676445, top_k: 0.864805, samples/s: 1332.400 1612770328.3199265
train: epoch 112, iter 1400, loss: 2.463112, top_1: 0.672188, top_k: 0.864922, samples/s: 1334.061 1612770347.5094779
train: epoch 112, iter 1500, loss: 2.419042, top_1: 0.680000, top_k: 0.872305, samples/s: 1332.447 1612770366.7222114
train: epoch 112, iter 1600, loss: 2.336280, top_1: 0.673438, top_k: 0.866250, samples/s: 1334.124 1612770385.9108226
train: epoch 112, iter 1700, loss: 2.381834, top_1: 0.665664, top_k: 0.859414, samples/s: 1327.725 1612770405.19192
train: epoch 112, iter 1800, loss: 2.308827, top_1: 0.673203, top_k: 0.865195, samples/s: 1332.906 1612770424.3981113
train: epoch 112, iter 1900, loss: 2.349561, top_1: 0.673594, top_k: 0.866094, samples/s: 1334.730 1612770443.57799
train: epoch 112, iter 2000, loss: 2.473454, top_1: 0.674766, top_k: 0.869297, samples/s: 1332.963 1612770462.7834003
train: epoch 112, iter 2100, loss: 2.419065, top_1: 0.673320, top_k: 0.863789, samples/s: 1333.003 1612770481.9880974
train: epoch 112, iter 2200, loss: 2.288388, top_1: 0.669375, top_k: 0.864375, samples/s: 1339.397 1612770501.1011848
train: epoch 112, iter 2300, loss: 2.153905, top_1: 0.674141, top_k: 0.866992, samples/s: 1335.840 1612770520.2651572
train: epoch 112, iter 2400, loss: 2.262769, top_1: 0.667344, top_k: 0.862578, samples/s: 1337.010 1612770539.4123287
train: epoch 112, iter 2500, loss: 2.340633, top_1: 0.670195, top_k: 0.860938, samples/s: 1330.199 1612770558.6575723
train: epoch 112, iter 2600, loss: 2.374857, top_1: 0.669297, top_k: 0.862852, samples/s: 1335.465 1612770577.8269908
train: epoch 112, iter 2700, loss: 2.393202, top_1: 0.669844, top_k: 0.858281, samples/s: 1334.121 1612770597.0156164
train: epoch 112, iter 2800, loss: 2.190187, top_1: 0.670156, top_k: 0.865781, samples/s: 1337.596 1612770616.15444
train: epoch 112, iter 2900, loss: 2.393469, top_1: 0.672773, top_k: 0.863047, samples/s: 1332.487 1612770635.3666117
train: epoch 112, iter 3000, loss: 2.457034, top_1: 0.672695, top_k: 0.864297, samples/s: 1340.038 1612770654.4705307
train: epoch 112, iter 3100, loss: 2.525031, top_1: 0.667227, top_k: 0.863125, samples/s: 1335.713 1612770673.6363227
train: epoch 112, iter 3200, loss: 2.334160, top_1: 0.670391, top_k: 0.863281, samples/s: 1336.702 1612770692.787943
train: epoch 112, iter 3300, loss: 2.598613, top_1: 0.672109, top_k: 0.863437, samples/s: 1334.608 1612770711.969658
train: epoch 112, iter 3400, loss: 2.369253, top_1: 0.670039, top_k: 0.864297, samples/s: 1334.216 1612770731.1569397
train: epoch 112, iter 3500, loss: 2.394288, top_1: 0.674063, top_k: 0.866719, samples/s: 1334.948 1612770750.3337345
train: epoch 112, iter 3600, loss: 2.294285, top_1: 0.672461, top_k: 0.866367, samples/s: 1332.826 1612770769.5410502
train: epoch 112, iter 3700, loss: 2.421302, top_1: 0.674883, top_k: 0.863516, samples/s: 1332.619 1612770788.7514045
train: epoch 112, iter 3800, loss: 2.463798, top_1: 0.667383, top_k: 0.860547, samples/s: 1333.768 1612770807.945133
train: epoch 112, iter 3900, loss: 2.430241, top_1: 0.667891, top_k: 0.861445, samples/s: 1332.460 1612770827.1576502
train: epoch 112, iter 4000, loss: 2.396519, top_1: 0.668555, top_k: 0.861445, samples/s: 1333.543 1612770846.3546324
train: epoch 112, iter 4100, loss: 2.335124, top_1: 0.667617, top_k: 0.860313, samples/s: 1333.320 1612770865.5547838
train: epoch 112, iter 4200, loss: 2.393563, top_1: 0.668008, top_k: 0.861133, samples/s: 1331.912 1612770884.7752964
train: epoch 112, iter 4300, loss: 2.600061, top_1: 0.669023, top_k: 0.859180, samples/s: 1331.657 1612770903.9994667
train: epoch 112, iter 4400, loss: 2.461512, top_1: 0.662070, top_k: 0.860273, samples/s: 1331.248 1612770923.2296262
train: epoch 112, iter 4500, loss: 2.360415, top_1: 0.674844, top_k: 0.864922, samples/s: 1337.296 1612770942.372616
train: epoch 112, iter 4600, loss: 2.403705, top_1: 0.669609, top_k: 0.861563, samples/s: 1333.018 1612770961.5771446
train: epoch 112, iter 4700, loss: 2.414136, top_1: 0.669023, top_k: 0.860742, samples/s: 1339.261 1612770980.6921575
train: epoch 112, iter 4800, loss: 2.371351, top_1: 0.669297, top_k: 0.864961, samples/s: 1325.956 1612770999.9990702
train: epoch 112, iter 4900, loss: 2.495673, top_1: 0.666250, top_k: 0.862539, samples/s: 1339.974 1612771019.1039689
train: epoch 112, iter 5000, loss: 2.499031, top_1: 0.673828, top_k: 0.863672, samples/s: 1336.322 1612771038.2609653
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_112.
validation: epoch 112, iter 195, top_1: 0.704748, top_k: 0.900180, samples/s: 2827.137 1612771056.4783988
train: epoch 113, iter 100, loss: 2.177919, top_1: 0.682539, top_k: 0.873984, samples/s: 1357.928 1612771091.3123636
train: epoch 113, iter 200, loss: 2.233103, top_1: 0.684336, top_k: 0.870664, samples/s: 1362.520 1612771110.1011992
train: epoch 113, iter 300, loss: 2.300024, top_1: 0.687187, top_k: 0.872383, samples/s: 1362.632 1612771128.888199
train: epoch 113, iter 400, loss: 2.228908, top_1: 0.678203, top_k: 0.868516, samples/s: 1354.209 1612771147.7922475
train: epoch 113, iter 500, loss: 2.394470, top_1: 0.684766, top_k: 0.869414, samples/s: 1334.058 1612771166.9817617
train: epoch 113, iter 600, loss: 2.226007, top_1: 0.678359, top_k: 0.869922, samples/s: 1324.736 1612771186.3064
train: epoch 113, iter 700, loss: 2.382585, top_1: 0.683125, top_k: 0.870938, samples/s: 1334.659 1612771205.4873092
train: epoch 113, iter 800, loss: 2.510425, top_1: 0.676133, top_k: 0.865625, samples/s: 1323.010 1612771224.8371034
train: epoch 113, iter 900, loss: 2.379937, top_1: 0.680742, top_k: 0.869336, samples/s: 1331.579 1612771244.0624328
train: epoch 113, iter 1000, loss: 2.346840, top_1: 0.673906, top_k: 0.865508, samples/s: 1329.649 1612771263.3156211
train: epoch 113, iter 1100, loss: 2.297247, top_1: 0.671406, top_k: 0.868242, samples/s: 1331.280 1612771282.545299
train: epoch 113, iter 1200, loss: 2.397925, top_1: 0.676445, top_k: 0.869258, samples/s: 1332.650 1612771301.7551253
train: epoch 113, iter 1300, loss: 2.516855, top_1: 0.675430, top_k: 0.867461, samples/s: 1326.854 1612771321.0488982
train: epoch 113, iter 1400, loss: 2.471567, top_1: 0.674414, top_k: 0.866211, samples/s: 1328.310 1612771340.321536
train: epoch 113, iter 1500, loss: 2.534737, top_1: 0.673047, top_k: 0.867500, samples/s: 1335.680 1612771359.4878788
train: epoch 113, iter 1600, loss: 2.218740, top_1: 0.677773, top_k: 0.866172, samples/s: 1332.526 1612771378.6993546
train: epoch 113, iter 1700, loss: 2.544573, top_1: 0.672891, top_k: 0.865781, samples/s: 1331.372 1612771397.92764
train: epoch 113, iter 1800, loss: 2.267559, top_1: 0.672070, top_k: 0.868242, samples/s: 1331.977 1612771417.1472163
train: epoch 113, iter 1900, loss: 2.278291, top_1: 0.676055, top_k: 0.864648, samples/s: 1322.425 1612771436.5055664
train: epoch 113, iter 2000, loss: 2.413122, top_1: 0.680820, top_k: 0.870547, samples/s: 1334.967 1612771455.6821156
train: epoch 113, iter 2100, loss: 2.370473, top_1: 0.675430, top_k: 0.865352, samples/s: 1334.431 1612771474.8664093
train: epoch 113, iter 2200, loss: 2.322000, top_1: 0.673438, top_k: 0.865352, samples/s: 1330.662 1612771494.1048021
train: epoch 113, iter 2300, loss: 2.152536, top_1: 0.676211, top_k: 0.866914, samples/s: 1333.156 1612771513.307415
train: epoch 113, iter 2400, loss: 2.204955, top_1: 0.676602, top_k: 0.866445, samples/s: 1334.653 1612771532.4883792
train: epoch 113, iter 2500, loss: 2.503485, top_1: 0.670898, top_k: 0.864531, samples/s: 1328.326 1612771551.7608292
train: epoch 113, iter 2600, loss: 2.307975, top_1: 0.673320, top_k: 0.866172, samples/s: 1327.604 1612771571.0437167
train: epoch 113, iter 2700, loss: 2.350223, top_1: 0.674336, top_k: 0.864414, samples/s: 1329.123 1612771590.3044486
train: epoch 113, iter 2800, loss: 2.433197, top_1: 0.673047, top_k: 0.869570, samples/s: 1333.959 1612771609.4954848
train: epoch 113, iter 2900, loss: 2.028093, top_1: 0.674922, top_k: 0.866680, samples/s: 1334.397 1612771628.6801918
train: epoch 113, iter 3000, loss: 2.220641, top_1: 0.673438, top_k: 0.864727, samples/s: 1324.547 1612771648.0074918
train: epoch 113, iter 3100, loss: 2.336524, top_1: 0.671406, top_k: 0.862812, samples/s: 1323.745 1612771667.3465474
train: epoch 113, iter 3200, loss: 2.568558, top_1: 0.669453, top_k: 0.862773, samples/s: 1332.062 1612771686.5649004
train: epoch 113, iter 3300, loss: 2.205138, top_1: 0.674375, top_k: 0.864805, samples/s: 1326.238 1612771705.867657
train: epoch 113, iter 3400, loss: 2.396859, top_1: 0.674883, top_k: 0.867773, samples/s: 1326.978 1612771725.1596036
train: epoch 113, iter 3500, loss: 2.431959, top_1: 0.670898, top_k: 0.863984, samples/s: 1332.902 1612771744.3657603
train: epoch 113, iter 3600, loss: 2.435729, top_1: 0.670703, top_k: 0.863867, samples/s: 1330.062 1612771763.6130068
train: epoch 113, iter 3700, loss: 2.215177, top_1: 0.677852, top_k: 0.865898, samples/s: 1329.195 1612771782.8728142
train: epoch 113, iter 3800, loss: 2.506012, top_1: 0.673242, top_k: 0.864883, samples/s: 1334.791 1612771802.0517917
train: epoch 113, iter 3900, loss: 2.152219, top_1: 0.668203, top_k: 0.863125, samples/s: 1330.618 1612771821.2909603
train: epoch 113, iter 4000, loss: 2.266031, top_1: 0.671484, top_k: 0.864805, samples/s: 1329.904 1612771840.540472
train: epoch 113, iter 4100, loss: 2.238276, top_1: 0.671289, top_k: 0.863555, samples/s: 1330.033 1612771859.7881637
train: epoch 113, iter 4200, loss: 2.348626, top_1: 0.673398, top_k: 0.865859, samples/s: 1331.725 1612771879.0113378
train: epoch 113, iter 4300, loss: 2.309876, top_1: 0.671523, top_k: 0.863867, samples/s: 1330.607 1612771898.2506676
train: epoch 113, iter 4400, loss: 2.297314, top_1: 0.681328, top_k: 0.869141, samples/s: 1328.752 1612771917.5168815
train: epoch 113, iter 4500, loss: 2.293168, top_1: 0.670000, top_k: 0.865664, samples/s: 1325.970 1612771936.823504
train: epoch 113, iter 4600, loss: 2.449125, top_1: 0.667148, top_k: 0.863633, samples/s: 1331.769 1612771956.0460346
train: epoch 113, iter 4700, loss: 2.452941, top_1: 0.672617, top_k: 0.863359, samples/s: 1332.818 1612771975.2534657
train: epoch 113, iter 4800, loss: 2.335239, top_1: 0.675234, top_k: 0.865391, samples/s: 1332.033 1612771994.472277
train: epoch 113, iter 4900, loss: 2.290740, top_1: 0.668711, top_k: 0.862969, samples/s: 1324.076 1612772013.8064158
train: epoch 113, iter 5000, loss: 2.168684, top_1: 0.682109, top_k: 0.871094, samples/s: 1333.397 1612772033.0054944
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_113.
validation: epoch 113, iter 195, top_1: 0.708474, top_k: 0.900881, samples/s: 2689.438 1612772052.143306
train: epoch 114, iter 100, loss: 2.330143, top_1: 0.677070, top_k: 0.867031, samples/s: 1361.390 1612772087.198365
train: epoch 114, iter 200, loss: 2.307758, top_1: 0.683984, top_k: 0.875430, samples/s: 1360.375 1612772106.016702
train: epoch 114, iter 300, loss: 2.355422, top_1: 0.690312, top_k: 0.874687, samples/s: 1362.197 1612772124.8098524
train: epoch 114, iter 400, loss: 2.214645, top_1: 0.679883, top_k: 0.869727, samples/s: 1355.294 1612772143.6988003
train: epoch 114, iter 500, loss: 2.472028, top_1: 0.683008, top_k: 0.871875, samples/s: 1331.280 1612772162.9284015
train: epoch 114, iter 600, loss: 2.203269, top_1: 0.678672, top_k: 0.868711, samples/s: 1332.780 1612772182.1363244
train: epoch 114, iter 700, loss: 2.221761, top_1: 0.677500, top_k: 0.868203, samples/s: 1334.694 1612772201.3167539
train: epoch 114, iter 800, loss: 2.279486, top_1: 0.679297, top_k: 0.867734, samples/s: 1332.971 1612772220.5220258
train: epoch 114, iter 900, loss: 2.223454, top_1: 0.686875, top_k: 0.873516, samples/s: 1333.936 1612772239.713392
train: epoch 114, iter 1000, loss: 2.434008, top_1: 0.685703, top_k: 0.870547, samples/s: 1331.926 1612772258.9336383
train: epoch 114, iter 1100, loss: 2.212208, top_1: 0.684258, top_k: 0.873047, samples/s: 1332.611 1612772278.1440034
train: epoch 114, iter 1200, loss: 2.147401, top_1: 0.680547, top_k: 0.870898, samples/s: 1336.386 1612772297.3001902
train: epoch 114, iter 1300, loss: 2.118841, top_1: 0.679063, top_k: 0.866094, samples/s: 1320.140 1612772316.6920679
train: epoch 114, iter 1400, loss: 2.176909, top_1: 0.678828, top_k: 0.869375, samples/s: 1348.315 1612772335.678733
train: epoch 114, iter 1500, loss: 2.144026, top_1: 0.676602, top_k: 0.865547, samples/s: 1329.905 1612772354.9281864
train: epoch 114, iter 1600, loss: 2.254963, top_1: 0.676172, top_k: 0.870391, samples/s: 1333.632 1612772374.1239502
train: epoch 114, iter 1700, loss: 2.394939, top_1: 0.679102, top_k: 0.869219, samples/s: 1331.713 1612772393.347275
train: epoch 114, iter 1800, loss: 2.471624, top_1: 0.674844, top_k: 0.867109, samples/s: 1332.936 1612772412.5530083
train: epoch 114, iter 1900, loss: 2.211802, top_1: 0.675430, top_k: 0.866523, samples/s: 1335.829 1612772431.7170982
train: epoch 114, iter 2000, loss: 2.196206, top_1: 0.681172, top_k: 0.868359, samples/s: 1330.947 1612772450.9515674
train: epoch 114, iter 2100, loss: 2.334141, top_1: 0.672734, top_k: 0.869453, samples/s: 1335.337 1612772470.1227722
train: epoch 114, iter 2200, loss: 2.479493, top_1: 0.681094, top_k: 0.867773, samples/s: 1339.014 1612772489.2413054
train: epoch 114, iter 2300, loss: 2.222270, top_1: 0.673047, top_k: 0.866133, samples/s: 1328.364 1612772508.5131526
train: epoch 114, iter 2400, loss: 2.485769, top_1: 0.681484, top_k: 0.868164, samples/s: 1329.679 1612772527.7658734
train: epoch 114, iter 2500, loss: 2.528428, top_1: 0.684063, top_k: 0.872383, samples/s: 1338.406 1612772546.8931026
train: epoch 114, iter 2600, loss: 2.410702, top_1: 0.678984, top_k: 0.867812, samples/s: 1334.030 1612772566.0830553
train: epoch 114, iter 2700, loss: 2.539534, top_1: 0.679063, top_k: 0.869453, samples/s: 1330.490 1612772585.3240898
train: epoch 114, iter 2800, loss: 2.467206, top_1: 0.682227, top_k: 0.871289, samples/s: 1336.642 1612772604.4765747
train: epoch 114, iter 2900, loss: 2.325134, top_1: 0.678164, top_k: 0.865859, samples/s: 1327.010 1612772623.7680635
train: epoch 114, iter 3000, loss: 2.306217, top_1: 0.676875, top_k: 0.866602, samples/s: 1333.591 1612772642.964379
train: epoch 114, iter 3100, loss: 2.412197, top_1: 0.679063, top_k: 0.868477, samples/s: 1338.122 1612772662.0956938
train: epoch 114, iter 3200, loss: 2.499004, top_1: 0.679805, top_k: 0.868320, samples/s: 1335.768 1612772681.2608109
train: epoch 114, iter 3300, loss: 2.211878, top_1: 0.676016, top_k: 0.865195, samples/s: 1324.561 1612772700.5879183
train: epoch 114, iter 3400, loss: 2.338904, top_1: 0.676250, top_k: 0.868437, samples/s: 1337.426 1612772719.7290463
train: epoch 114, iter 3500, loss: 2.220104, top_1: 0.672930, top_k: 0.864961, samples/s: 1336.888 1612772738.8780398
train: epoch 114, iter 3600, loss: 2.367425, top_1: 0.681094, top_k: 0.869687, samples/s: 1334.850 1612772758.0561776
train: epoch 114, iter 3700, loss: 2.305916, top_1: 0.673047, top_k: 0.867227, samples/s: 1322.613 1612772777.4119024
train: epoch 114, iter 3800, loss: 2.465666, top_1: 0.675195, top_k: 0.864531, samples/s: 1339.896 1612772796.5177817
train: epoch 114, iter 3900, loss: 2.144487, top_1: 0.673516, top_k: 0.866875, samples/s: 1336.598 1612772815.6708846
train: epoch 114, iter 4000, loss: 2.374212, top_1: 0.676758, top_k: 0.868086, samples/s: 1329.443 1612772834.9270973
train: epoch 114, iter 4100, loss: 2.481511, top_1: 0.670078, top_k: 0.864492, samples/s: 1339.323 1612772854.0412376
train: epoch 114, iter 4200, loss: 2.315422, top_1: 0.677383, top_k: 0.867500, samples/s: 1334.956 1612772873.217849
train: epoch 114, iter 4300, loss: 2.302386, top_1: 0.674687, top_k: 0.868672, samples/s: 1337.051 1612772892.3645115
train: epoch 114, iter 4400, loss: 2.444574, top_1: 0.673867, top_k: 0.863672, samples/s: 1325.391 1612772911.679512
train: epoch 114, iter 4500, loss: 2.295058, top_1: 0.676094, top_k: 0.866953, samples/s: 1331.195 1612772930.9104147
train: epoch 114, iter 4600, loss: 2.281632, top_1: 0.681602, top_k: 0.870352, samples/s: 1331.613 1612772950.1352098
train: epoch 114, iter 4700, loss: 2.480359, top_1: 0.672773, top_k: 0.864219, samples/s: 1343.497 1612772969.1899292
train: epoch 114, iter 4800, loss: 2.353554, top_1: 0.675430, top_k: 0.865898, samples/s: 1317.459 1612772988.6213217
train: epoch 114, iter 4900, loss: 2.296114, top_1: 0.681367, top_k: 0.869844, samples/s: 1344.737 1612773007.6584277
train: epoch 114, iter 5000, loss: 2.217466, top_1: 0.678906, top_k: 0.870625, samples/s: 1332.310 1612773026.8733141
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_114.
validation: epoch 114, iter 195, top_1: 0.710437, top_k: 0.901522, samples/s: 2786.839 1612773045.3497126
train: epoch 115, iter 100, loss: 2.362905, top_1: 0.682617, top_k: 0.869961, samples/s: 1360.488 1612773080.031842
train: epoch 115, iter 200, loss: 2.274895, top_1: 0.690937, top_k: 0.876523, samples/s: 1354.988 1612773098.9249127
train: epoch 115, iter 300, loss: 2.360216, top_1: 0.685859, top_k: 0.874062, samples/s: 1365.914 1612773117.6669528
train: epoch 115, iter 400, loss: 2.240856, top_1: 0.687852, top_k: 0.873086, samples/s: 1351.880 1612773136.603503
train: epoch 115, iter 500, loss: 2.322890, top_1: 0.688047, top_k: 0.872852, samples/s: 1331.133 1612773155.8352547
train: epoch 115, iter 600, loss: 2.120562, top_1: 0.686133, top_k: 0.874570, samples/s: 1332.010 1612773175.054427
train: epoch 115, iter 700, loss: 2.229511, top_1: 0.681758, top_k: 0.870938, samples/s: 1329.623 1612773194.3079407
train: epoch 115, iter 800, loss: 2.190424, top_1: 0.687539, top_k: 0.875430, samples/s: 1330.287 1612773213.5518548
train: epoch 115, iter 900, loss: 2.305300, top_1: 0.681641, top_k: 0.865625, samples/s: 1330.850 1612773232.7876759
train: epoch 115, iter 1000, loss: 2.298600, top_1: 0.681562, top_k: 0.869492, samples/s: 1339.296 1612773251.902212
train: epoch 115, iter 1100, loss: 2.477858, top_1: 0.687187, top_k: 0.871406, samples/s: 1324.744 1612773271.2268045
train: epoch 115, iter 1200, loss: 2.290800, top_1: 0.675508, top_k: 0.868750, samples/s: 1325.781 1612773290.5360715
train: epoch 115, iter 1300, loss: 2.294943, top_1: 0.679609, top_k: 0.871523, samples/s: 1332.865 1612773309.7428272
train: epoch 115, iter 1400, loss: 2.162513, top_1: 0.682070, top_k: 0.872227, samples/s: 1332.269 1612773328.9581568
train: epoch 115, iter 1500, loss: 2.337811, top_1: 0.684219, top_k: 0.869961, samples/s: 1332.454 1612773348.170865
train: epoch 115, iter 1600, loss: 2.483089, top_1: 0.673789, top_k: 0.866289, samples/s: 1331.944 1612773367.3908803
train: epoch 115, iter 1700, loss: 2.366186, top_1: 0.673906, top_k: 0.865078, samples/s: 1331.814 1612773386.6127844
train: epoch 115, iter 1800, loss: 2.375175, top_1: 0.679766, top_k: 0.873828, samples/s: 1335.166 1612773405.7864075
train: epoch 115, iter 1900, loss: 2.254453, top_1: 0.686172, top_k: 0.870664, samples/s: 1329.569 1612773425.0407667
train: epoch 115, iter 2000, loss: 2.259670, top_1: 0.685703, top_k: 0.869180, samples/s: 1335.900 1612773444.203924
train: epoch 115, iter 2100, loss: 2.204093, top_1: 0.678242, top_k: 0.867461, samples/s: 1333.927 1612773463.3953464
train: epoch 115, iter 2200, loss: 2.296252, top_1: 0.676992, top_k: 0.868320, samples/s: 1331.157 1612773482.626698
train: epoch 115, iter 2300, loss: 2.185773, top_1: 0.678516, top_k: 0.868086, samples/s: 1333.665 1612773501.8219645
train: epoch 115, iter 2400, loss: 2.301326, top_1: 0.680781, top_k: 0.871641, samples/s: 1329.330 1612773521.0797548
train: epoch 115, iter 2500, loss: 2.323260, top_1: 0.682734, top_k: 0.869453, samples/s: 1337.514 1612773540.219816
train: epoch 115, iter 2600, loss: 2.245125, top_1: 0.676719, top_k: 0.866563, samples/s: 1334.202 1612773559.4073622
train: epoch 115, iter 2700, loss: 2.375824, top_1: 0.681523, top_k: 0.871328, samples/s: 1338.306 1612773578.535926
train: epoch 115, iter 2800, loss: 2.406873, top_1: 0.679336, top_k: 0.866680, samples/s: 1328.536 1612773597.8052056
train: epoch 115, iter 2900, loss: 2.426632, top_1: 0.682383, top_k: 0.869922, samples/s: 1339.852 1612773616.9118698
train: epoch 115, iter 3000, loss: 2.423136, top_1: 0.675508, top_k: 0.868398, samples/s: 1333.933 1612773636.1031642
train: epoch 115, iter 3100, loss: 2.436555, top_1: 0.677383, top_k: 0.866719, samples/s: 1333.594 1612773655.2994103
train: epoch 115, iter 3200, loss: 2.263495, top_1: 0.680078, top_k: 0.870039, samples/s: 1334.186 1612773674.4872062
train: epoch 115, iter 3300, loss: 2.441486, top_1: 0.678164, top_k: 0.867734, samples/s: 1334.635 1612773693.6684148
train: epoch 115, iter 3400, loss: 2.365863, top_1: 0.682383, top_k: 0.870117, samples/s: 1330.779 1612773712.9053311
train: epoch 115, iter 3500, loss: 2.202811, top_1: 0.685000, top_k: 0.870586, samples/s: 1334.464 1612773732.0890453
train: epoch 115, iter 3600, loss: 2.366874, top_1: 0.679688, top_k: 0.869141, samples/s: 1330.362 1612773751.3319516
train: epoch 115, iter 3700, loss: 2.299976, top_1: 0.677617, top_k: 0.867891, samples/s: 1339.106 1612773770.4491107
train: epoch 115, iter 3800, loss: 2.294390, top_1: 0.673477, top_k: 0.867500, samples/s: 1330.927 1612773789.6838553
train: epoch 115, iter 3900, loss: 2.299903, top_1: 0.678281, top_k: 0.866641, samples/s: 1331.863 1612773808.9050694
train: epoch 115, iter 4000, loss: 2.249029, top_1: 0.677188, top_k: 0.868633, samples/s: 1334.132 1612773828.0935261
train: epoch 115, iter 4100, loss: 2.340347, top_1: 0.675547, top_k: 0.869687, samples/s: 1333.987 1612773847.2841833
train: epoch 115, iter 4200, loss: 2.349932, top_1: 0.676406, top_k: 0.865547, samples/s: 1331.342 1612773866.512814
train: epoch 115, iter 4300, loss: 2.347929, top_1: 0.671289, top_k: 0.865352, samples/s: 1333.903 1612773885.7046914
train: epoch 115, iter 4400, loss: 2.435115, top_1: 0.672070, top_k: 0.868320, samples/s: 1336.542 1612773904.8585684
train: epoch 115, iter 4500, loss: 2.377490, top_1: 0.676172, top_k: 0.868867, samples/s: 1335.089 1612773924.033319
train: epoch 115, iter 4600, loss: 2.399975, top_1: 0.675039, top_k: 0.867578, samples/s: 1331.875 1612773943.2542949
train: epoch 115, iter 4700, loss: 2.316182, top_1: 0.673047, top_k: 0.866133, samples/s: 1330.909 1612773962.4892616
train: epoch 115, iter 4800, loss: 2.354223, top_1: 0.675937, top_k: 0.867656, samples/s: 1325.728 1612773981.7994251
train: epoch 115, iter 4900, loss: 2.485772, top_1: 0.674453, top_k: 0.866758, samples/s: 1336.885 1612774000.94839
train: epoch 115, iter 5000, loss: 2.018600, top_1: 0.686875, top_k: 0.874687, samples/s: 1328.920 1612774020.2123237
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_115.
validation: epoch 115, iter 195, top_1: 0.705829, top_k: 0.900020, samples/s: 2739.962 1612774038.9442818
train: epoch 116, iter 100, loss: 2.191971, top_1: 0.696055, top_k: 0.882539, samples/s: 1349.159 1612774073.7618465
train: epoch 116, iter 200, loss: 2.360388, top_1: 0.690547, top_k: 0.879492, samples/s: 1363.677 1612774092.5346756
train: epoch 116, iter 300, loss: 2.189080, top_1: 0.684102, top_k: 0.873398, samples/s: 1361.912 1612774111.3318038
train: epoch 116, iter 400, loss: 2.316944, top_1: 0.683555, top_k: 0.872734, samples/s: 1350.614 1612774130.2859714
train: epoch 116, iter 500, loss: 2.279296, top_1: 0.692734, top_k: 0.875664, samples/s: 1341.648 1612774149.3670263
train: epoch 116, iter 600, loss: 2.299671, top_1: 0.682227, top_k: 0.872344, samples/s: 1324.555 1612774168.6942308
train: epoch 116, iter 700, loss: 2.296535, top_1: 0.684414, top_k: 0.874805, samples/s: 1332.254 1612774187.9097927
train: epoch 116, iter 800, loss: 2.222844, top_1: 0.680664, top_k: 0.869844, samples/s: 1336.353 1612774207.0663998
train: epoch 116, iter 900, loss: 2.321774, top_1: 0.691523, top_k: 0.876992, samples/s: 1333.482 1612774226.2642784
train: epoch 116, iter 1000, loss: 2.226211, top_1: 0.683945, top_k: 0.874023, samples/s: 1324.996 1612774245.5851195
train: epoch 116, iter 1100, loss: 2.330188, top_1: 0.682969, top_k: 0.871406, samples/s: 1339.514 1612774264.6964808
train: epoch 116, iter 1200, loss: 2.185587, top_1: 0.681758, top_k: 0.873320, samples/s: 1336.137 1612774283.8562276
train: epoch 116, iter 1300, loss: 2.387865, top_1: 0.685312, top_k: 0.872461, samples/s: 1318.935 1612774303.2658262
train: epoch 116, iter 1400, loss: 2.215585, top_1: 0.685937, top_k: 0.871484, samples/s: 1338.557 1612774322.3909092
train: epoch 116, iter 1500, loss: 2.227235, top_1: 0.684570, top_k: 0.874336, samples/s: 1328.863 1612774341.6554904
train: epoch 116, iter 1600, loss: 2.346484, top_1: 0.681836, top_k: 0.871289, samples/s: 1333.407 1612774360.854394
train: epoch 116, iter 1700, loss: 2.269896, top_1: 0.682695, top_k: 0.870078, samples/s: 1336.771 1612774380.0050802
train: epoch 116, iter 1800, loss: 2.511778, top_1: 0.678945, top_k: 0.871250, samples/s: 1322.166 1612774399.36721
train: epoch 116, iter 1900, loss: 2.305488, top_1: 0.685625, top_k: 0.870234, samples/s: 1330.373 1612774418.609958
train: epoch 116, iter 2000, loss: 2.286711, top_1: 0.688516, top_k: 0.875469, samples/s: 1329.815 1612774437.8607068
train: epoch 116, iter 2100, loss: 2.407375, top_1: 0.682734, top_k: 0.872188, samples/s: 1329.325 1612774457.1186101
train: epoch 116, iter 2200, loss: 2.383333, top_1: 0.682773, top_k: 0.868789, samples/s: 1326.698 1612774476.4146473
train: epoch 116, iter 2300, loss: 2.240051, top_1: 0.682266, top_k: 0.870508, samples/s: 1334.824 1612774495.5932086
train: epoch 116, iter 2400, loss: 2.371739, top_1: 0.680508, top_k: 0.870820, samples/s: 1332.375 1612774514.8070285
train: epoch 116, iter 2500, loss: 2.444231, top_1: 0.680898, top_k: 0.869570, samples/s: 1335.034 1612774533.9825544
train: epoch 116, iter 2600, loss: 2.464320, top_1: 0.684844, top_k: 0.871484, samples/s: 1333.817 1612774553.1756475
train: epoch 116, iter 2700, loss: 2.409426, top_1: 0.687148, top_k: 0.875195, samples/s: 1333.323 1612774572.3757594
train: epoch 116, iter 2800, loss: 2.427564, top_1: 0.679727, top_k: 0.868633, samples/s: 1331.708 1612774591.5992334
train: epoch 116, iter 2900, loss: 2.291602, top_1: 0.686875, top_k: 0.870156, samples/s: 1333.048 1612774610.8032892
train: epoch 116, iter 3000, loss: 2.329900, top_1: 0.679258, top_k: 0.868555, samples/s: 1330.153 1612774630.0492187
train: epoch 116, iter 3100, loss: 2.374708, top_1: 0.677461, top_k: 0.867695, samples/s: 1329.166 1612774649.30939
train: epoch 116, iter 3200, loss: 2.162538, top_1: 0.683047, top_k: 0.873203, samples/s: 1335.900 1612774668.4724905
train: epoch 116, iter 3300, loss: 2.400965, top_1: 0.687773, top_k: 0.875586, samples/s: 1333.328 1612774687.672602
train: epoch 116, iter 3400, loss: 2.385399, top_1: 0.680937, top_k: 0.870547, samples/s: 1327.607 1612774706.9553847
train: epoch 116, iter 3500, loss: 2.348907, top_1: 0.677773, top_k: 0.868672, samples/s: 1332.576 1612774726.166357
train: epoch 116, iter 3600, loss: 2.210131, top_1: 0.684922, top_k: 0.871211, samples/s: 1332.931 1612774745.3721113
train: epoch 116, iter 3700, loss: 2.321794, top_1: 0.680273, top_k: 0.872031, samples/s: 1331.991 1612774764.5915246
train: epoch 116, iter 3800, loss: 2.348606, top_1: 0.679883, top_k: 0.869102, samples/s: 1333.367 1612774783.7910392
train: epoch 116, iter 3900, loss: 2.407654, top_1: 0.682148, top_k: 0.869531, samples/s: 1338.516 1612774802.9166803
train: epoch 116, iter 4000, loss: 2.282392, top_1: 0.679336, top_k: 0.868398, samples/s: 1332.136 1612774822.13399
train: epoch 116, iter 4100, loss: 2.357077, top_1: 0.680352, top_k: 0.869219, samples/s: 1328.721 1612774841.4005184
train: epoch 116, iter 4200, loss: 2.521104, top_1: 0.684727, top_k: 0.869570, samples/s: 1338.517 1612774860.5262551
train: epoch 116, iter 4300, loss: 2.111804, top_1: 0.679766, top_k: 0.870703, samples/s: 1328.066 1612774879.8023648
train: epoch 116, iter 4400, loss: 2.332072, top_1: 0.681953, top_k: 0.873594, samples/s: 1343.286 1612774898.860084
train: epoch 116, iter 4500, loss: 2.460246, top_1: 0.677539, top_k: 0.869219, samples/s: 1331.212 1612774918.0906832
train: epoch 116, iter 4600, loss: 2.183586, top_1: 0.677188, top_k: 0.867891, samples/s: 1331.888 1612774937.3114855
train: epoch 116, iter 4700, loss: 2.280116, top_1: 0.683203, top_k: 0.869805, samples/s: 1335.309 1612774956.4831407
train: epoch 116, iter 4800, loss: 2.305553, top_1: 0.679219, top_k: 0.870625, samples/s: 1331.345 1612774975.7117548
train: epoch 116, iter 4900, loss: 2.361516, top_1: 0.678125, top_k: 0.868164, samples/s: 1336.547 1612774994.865627
train: epoch 116, iter 5000, loss: 2.275403, top_1: 0.690742, top_k: 0.874727, samples/s: 1334.023 1612775014.0557218
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_116.
validation: epoch 116, iter 195, top_1: 0.710637, top_k: 0.904006, samples/s: 2764.362 1612775032.683741
train: epoch 117, iter 100, loss: 2.151723, top_1: 0.696172, top_k: 0.880508, samples/s: 1355.763 1612775067.1910446
train: epoch 117, iter 200, loss: 2.346006, top_1: 0.690898, top_k: 0.875313, samples/s: 1360.475 1612775086.0082657
train: epoch 117, iter 300, loss: 2.319849, top_1: 0.696406, top_k: 0.877344, samples/s: 1368.701 1612775104.7118542
train: epoch 117, iter 400, loss: 2.410588, top_1: 0.694492, top_k: 0.877227, samples/s: 1349.319 1612775123.684374
train: epoch 117, iter 500, loss: 2.261657, top_1: 0.685273, top_k: 0.876172, samples/s: 1330.789 1612775142.92103
train: epoch 117, iter 600, loss: 2.250645, top_1: 0.689688, top_k: 0.873867, samples/s: 1334.433 1612775162.1052318
train: epoch 117, iter 700, loss: 2.202263, top_1: 0.686992, top_k: 0.873594, samples/s: 1331.342 1612775181.3339627
train: epoch 117, iter 800, loss: 2.382612, top_1: 0.686523, top_k: 0.873242, samples/s: 1333.915 1612775200.5256221
train: epoch 117, iter 900, loss: 2.330547, top_1: 0.687891, top_k: 0.873516, samples/s: 1333.147 1612775219.728275
train: epoch 117, iter 1000, loss: 2.332918, top_1: 0.684766, top_k: 0.877109, samples/s: 1331.377 1612775238.956493
train: epoch 117, iter 1100, loss: 2.174015, top_1: 0.687773, top_k: 0.874531, samples/s: 1326.851 1612775258.250322
train: epoch 117, iter 1200, loss: 2.332777, top_1: 0.687969, top_k: 0.876758, samples/s: 1330.056 1612775277.4976213
train: epoch 117, iter 1300, loss: 2.121870, top_1: 0.689180, top_k: 0.873359, samples/s: 1330.577 1612775296.7373579
train: epoch 117, iter 1400, loss: 2.369309, top_1: 0.685469, top_k: 0.873437, samples/s: 1330.043 1612775315.9849105
train: epoch 117, iter 1500, loss: 2.321973, top_1: 0.693242, top_k: 0.876875, samples/s: 1330.134 1612775335.2310987
train: epoch 117, iter 1600, loss: 2.121967, top_1: 0.693516, top_k: 0.875977, samples/s: 1330.269 1612775354.4753366
train: epoch 117, iter 1700, loss: 2.544481, top_1: 0.684102, top_k: 0.872969, samples/s: 1333.663 1612775373.6705227
train: epoch 117, iter 1800, loss: 2.285720, top_1: 0.685508, top_k: 0.873906, samples/s: 1329.336 1612775392.928307
train: epoch 117, iter 1900, loss: 2.285250, top_1: 0.688945, top_k: 0.872812, samples/s: 1330.180 1612775412.1738205
train: epoch 117, iter 2000, loss: 2.256631, top_1: 0.687187, top_k: 0.872852, samples/s: 1333.925 1612775431.3653169
train: epoch 117, iter 2100, loss: 2.327604, top_1: 0.688516, top_k: 0.874336, samples/s: 1333.262 1612775450.5663462
train: epoch 117, iter 2200, loss: 2.182889, top_1: 0.686133, top_k: 0.874102, samples/s: 1327.603 1612775469.849234
train: epoch 117, iter 2300, loss: 2.284175, top_1: 0.681484, top_k: 0.871758, samples/s: 1332.101 1612775489.0669255
train: epoch 117, iter 2400, loss: 2.244375, top_1: 0.681250, top_k: 0.869062, samples/s: 1332.485 1612775508.2792733
train: epoch 117, iter 2500, loss: 2.150656, top_1: 0.686289, top_k: 0.875000, samples/s: 1331.537 1612775527.5050745
train: epoch 117, iter 2600, loss: 2.127135, top_1: 0.685234, top_k: 0.870859, samples/s: 1329.638 1612775546.758516
train: epoch 117, iter 2700, loss: 2.365981, top_1: 0.685703, top_k: 0.873125, samples/s: 1325.915 1612775566.065856
train: epoch 117, iter 2800, loss: 2.161151, top_1: 0.680352, top_k: 0.869648, samples/s: 1334.931 1612775585.242952
train: epoch 117, iter 2900, loss: 2.194849, top_1: 0.686836, top_k: 0.871758, samples/s: 1333.754 1612775604.4368134
train: epoch 117, iter 3000, loss: 2.383247, top_1: 0.684414, top_k: 0.869961, samples/s: 1327.645 1612775623.719091
train: epoch 117, iter 3100, loss: 2.259907, top_1: 0.688555, top_k: 0.875156, samples/s: 1330.106 1612775642.9657056
train: epoch 117, iter 3200, loss: 2.192691, top_1: 0.687383, top_k: 0.874453, samples/s: 1336.105 1612775662.1258545
train: epoch 117, iter 3300, loss: 2.246915, top_1: 0.682383, top_k: 0.871836, samples/s: 1333.678 1612775681.3209324
train: epoch 117, iter 3400, loss: 2.400146, top_1: 0.686094, top_k: 0.873008, samples/s: 1325.616 1612775700.6326509
train: epoch 117, iter 3500, loss: 2.395567, top_1: 0.687305, top_k: 0.871680, samples/s: 1331.273 1612775719.8623595
train: epoch 117, iter 3600, loss: 2.374199, top_1: 0.682891, top_k: 0.872500, samples/s: 1333.132 1612775739.0652466
train: epoch 117, iter 3700, loss: 2.249846, top_1: 0.682227, top_k: 0.871992, samples/s: 1325.484 1612775758.3791413
train: epoch 117, iter 3800, loss: 2.155784, top_1: 0.683594, top_k: 0.871172, samples/s: 1334.042 1612775777.568826
train: epoch 117, iter 3900, loss: 2.057674, top_1: 0.682969, top_k: 0.872305, samples/s: 1328.456 1612775796.8392568
train: epoch 117, iter 4000, loss: 2.388192, top_1: 0.683867, top_k: 0.874375, samples/s: 1327.700 1612775816.1207836
train: epoch 117, iter 4100, loss: 2.335338, top_1: 0.687461, top_k: 0.867852, samples/s: 1334.341 1612775835.3062892
train: epoch 117, iter 4200, loss: 2.253624, top_1: 0.682578, top_k: 0.872266, samples/s: 1337.708 1612775854.443465
train: epoch 117, iter 4300, loss: 2.321197, top_1: 0.679727, top_k: 0.868516, samples/s: 1324.970 1612775873.764675
train: epoch 117, iter 4400, loss: 2.266130, top_1: 0.684102, top_k: 0.872383, samples/s: 1333.928 1612775892.9562483
train: epoch 117, iter 4500, loss: 2.256056, top_1: 0.680508, top_k: 0.869492, samples/s: 1336.669 1612775912.1081915
train: epoch 117, iter 4600, loss: 2.279418, top_1: 0.681641, top_k: 0.869375, samples/s: 1324.760 1612775931.432488
train: epoch 117, iter 4700, loss: 2.483801, top_1: 0.683516, top_k: 0.870742, samples/s: 1327.140 1612775950.7220592
train: epoch 117, iter 4800, loss: 2.176977, top_1: 0.685391, top_k: 0.872031, samples/s: 1329.913 1612775969.9714
train: epoch 117, iter 4900, loss: 2.213166, top_1: 0.682734, top_k: 0.869570, samples/s: 1327.024 1612775989.2626495
train: epoch 117, iter 5000, loss: 2.285164, top_1: 0.691953, top_k: 0.875508, samples/s: 1338.973 1612776008.3818421
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_117.
validation: epoch 117, iter 195, top_1: 0.710517, top_k: 0.901643, samples/s: 2855.288 1612776026.4639812
train: epoch 118, iter 100, loss: 2.230386, top_1: 0.695664, top_k: 0.878008, samples/s: 1356.503 1612776061.2983232
train: epoch 118, iter 200, loss: 2.281973, top_1: 0.691680, top_k: 0.877500, samples/s: 1365.001 1612776080.0527537
train: epoch 118, iter 300, loss: 2.414374, top_1: 0.695781, top_k: 0.876680, samples/s: 1366.391 1612776098.7882905
train: epoch 118, iter 400, loss: 2.315837, top_1: 0.692227, top_k: 0.878711, samples/s: 1355.536 1612776117.673958
train: epoch 118, iter 500, loss: 2.331742, top_1: 0.688555, top_k: 0.875977, samples/s: 1331.708 1612776136.897232
train: epoch 118, iter 600, loss: 2.118457, top_1: 0.691445, top_k: 0.874297, samples/s: 1331.492 1612776156.1237304
train: epoch 118, iter 700, loss: 2.122971, top_1: 0.689297, top_k: 0.874609, samples/s: 1338.834 1612776175.244895
train: epoch 118, iter 800, loss: 2.264860, top_1: 0.692461, top_k: 0.871250, samples/s: 1321.718 1612776194.6136513
train: epoch 118, iter 900, loss: 2.335772, top_1: 0.689023, top_k: 0.875195, samples/s: 1343.422 1612776213.6694076
train: epoch 118, iter 1000, loss: 2.328778, top_1: 0.697344, top_k: 0.879141, samples/s: 1327.683 1612776232.9511106
train: epoch 118, iter 1100, loss: 2.351137, top_1: 0.692148, top_k: 0.878359, samples/s: 1329.146 1612776252.2116401
train: epoch 118, iter 1200, loss: 2.377427, top_1: 0.689336, top_k: 0.874453, samples/s: 1333.376 1612776271.411025
train: epoch 118, iter 1300, loss: 2.425696, top_1: 0.687422, top_k: 0.872266, samples/s: 1336.355 1612776290.567674
train: epoch 118, iter 1400, loss: 2.503816, top_1: 0.690352, top_k: 0.875430, samples/s: 1336.215 1612776309.726173
train: epoch 118, iter 1500, loss: 2.501029, top_1: 0.683594, top_k: 0.875078, samples/s: 1326.217 1612776329.0292356
train: epoch 118, iter 1600, loss: 2.369931, top_1: 0.686445, top_k: 0.878008, samples/s: 1333.190 1612776348.2312617
train: epoch 118, iter 1700, loss: 2.139549, top_1: 0.691602, top_k: 0.875547, samples/s: 1332.987 1612776367.4362733
train: epoch 118, iter 1800, loss: 2.234022, top_1: 0.688711, top_k: 0.878203, samples/s: 1329.978 1612776386.6847253
train: epoch 118, iter 1900, loss: 2.244380, top_1: 0.690391, top_k: 0.874883, samples/s: 1338.818 1612776405.8060133
train: epoch 118, iter 2000, loss: 2.160183, top_1: 0.690000, top_k: 0.871406, samples/s: 1339.564 1612776424.9167206
train: epoch 118, iter 2100, loss: 2.231095, top_1: 0.687227, top_k: 0.874180, samples/s: 1335.885 1612776444.0802376
train: epoch 118, iter 2200, loss: 2.440897, top_1: 0.688242, top_k: 0.873203, samples/s: 1336.289 1612776463.237633
train: epoch 118, iter 2300, loss: 2.202971, top_1: 0.690234, top_k: 0.874219, samples/s: 1334.784 1612776482.4166877
train: epoch 118, iter 2400, loss: 2.208599, top_1: 0.693047, top_k: 0.877930, samples/s: 1333.945 1612776501.6079493
train: epoch 118, iter 2500, loss: 2.229142, top_1: 0.690703, top_k: 0.874336, samples/s: 1334.328 1612776520.7936192
train: epoch 118, iter 2600, loss: 2.276436, top_1: 0.688945, top_k: 0.874609, samples/s: 1334.152 1612776539.9818308
train: epoch 118, iter 2700, loss: 2.335393, top_1: 0.689141, top_k: 0.877148, samples/s: 1333.716 1612776559.1764188
train: epoch 118, iter 2800, loss: 2.445465, top_1: 0.692813, top_k: 0.874648, samples/s: 1336.457 1612776578.3314955
train: epoch 118, iter 2900, loss: 2.294796, top_1: 0.684297, top_k: 0.876758, samples/s: 1334.131 1612776597.520003
train: epoch 118, iter 3000, loss: 2.409270, top_1: 0.689414, top_k: 0.877109, samples/s: 1336.868 1612776616.669226
train: epoch 118, iter 3100, loss: 2.305841, top_1: 0.681445, top_k: 0.871367, samples/s: 1336.392 1612776635.82524
train: epoch 118, iter 3200, loss: 2.405651, top_1: 0.677422, top_k: 0.869102, samples/s: 1335.803 1612776654.9897892
train: epoch 118, iter 3300, loss: 2.304006, top_1: 0.683672, top_k: 0.871133, samples/s: 1334.901 1612776674.1672335
train: epoch 118, iter 3400, loss: 2.255515, top_1: 0.690117, top_k: 0.872344, samples/s: 1334.583 1612776693.349258
train: epoch 118, iter 3500, loss: 2.329871, top_1: 0.686094, top_k: 0.872539, samples/s: 1333.465 1612776712.5473623
train: epoch 118, iter 3600, loss: 2.412572, top_1: 0.689102, top_k: 0.873086, samples/s: 1331.772 1612776731.7698584
train: epoch 118, iter 3700, loss: 2.266641, top_1: 0.688281, top_k: 0.873359, samples/s: 1338.608 1612776750.8941731
train: epoch 118, iter 3800, loss: 2.242556, top_1: 0.687656, top_k: 0.875273, samples/s: 1334.312 1612776770.080202
train: epoch 118, iter 3900, loss: 2.241796, top_1: 0.677969, top_k: 0.871445, samples/s: 1329.471 1612776789.335863
train: epoch 118, iter 4000, loss: 2.374709, top_1: 0.688672, top_k: 0.873594, samples/s: 1339.375 1612776808.4493287
train: epoch 118, iter 4100, loss: 2.525026, top_1: 0.685664, top_k: 0.870273, samples/s: 1326.540 1612776827.7476604
train: epoch 118, iter 4200, loss: 2.224696, top_1: 0.689609, top_k: 0.872734, samples/s: 1333.151 1612776846.950281
train: epoch 118, iter 4300, loss: 2.276414, top_1: 0.687344, top_k: 0.873828, samples/s: 1341.828 1612776866.0286753
train: epoch 118, iter 4400, loss: 2.306551, top_1: 0.685508, top_k: 0.873594, samples/s: 1327.967 1612776885.3062677
train: epoch 118, iter 4500, loss: 2.336307, top_1: 0.685039, top_k: 0.874141, samples/s: 1338.244 1612776904.4358706
train: epoch 118, iter 4600, loss: 2.144965, top_1: 0.681797, top_k: 0.871211, samples/s: 1338.735 1612776923.5583923
train: epoch 118, iter 4700, loss: 2.173611, top_1: 0.684375, top_k: 0.873008, samples/s: 1335.426 1612776942.728292
train: epoch 118, iter 4800, loss: 2.352618, top_1: 0.685703, top_k: 0.870938, samples/s: 1328.121 1612776962.0036206
train: epoch 118, iter 4900, loss: 2.403305, top_1: 0.689336, top_k: 0.872148, samples/s: 1336.530 1612776981.1577182
train: epoch 118, iter 5000, loss: 2.185590, top_1: 0.691562, top_k: 0.875547, samples/s: 1339.613 1612777000.267796
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_118.
validation: epoch 118, iter 195, top_1: 0.713782, top_k: 0.903786, samples/s: 2830.761 1612777018.4221776
train: epoch 119, iter 100, loss: 2.304615, top_1: 0.696875, top_k: 0.878047, samples/s: 1365.727 1612777053.0913434
train: epoch 119, iter 200, loss: 2.083397, top_1: 0.697344, top_k: 0.876875, samples/s: 1364.887 1612777071.8475447
train: epoch 119, iter 300, loss: 2.192702, top_1: 0.694961, top_k: 0.876055, samples/s: 1362.232 1612777090.6400719
train: epoch 119, iter 400, loss: 2.333271, top_1: 0.691758, top_k: 0.878164, samples/s: 1355.061 1612777109.5322766
train: epoch 119, iter 500, loss: 2.249885, top_1: 0.691758, top_k: 0.877461, samples/s: 1340.973 1612777128.6228132
train: epoch 119, iter 600, loss: 2.353652, top_1: 0.694648, top_k: 0.876289, samples/s: 1327.307 1612777147.9100802
train: epoch 119, iter 700, loss: 2.151145, top_1: 0.695625, top_k: 0.876563, samples/s: 1334.108 1612777167.0988317
train: epoch 119, iter 800, loss: 2.510515, top_1: 0.689805, top_k: 0.875938, samples/s: 1335.821 1612777186.2631366
train: epoch 119, iter 900, loss: 2.190196, top_1: 0.693633, top_k: 0.879219, samples/s: 1334.110 1612777205.452002
train: epoch 119, iter 1000, loss: 2.272571, top_1: 0.693633, top_k: 0.875313, samples/s: 1334.106 1612777224.6408079
train: epoch 119, iter 1100, loss: 2.309872, top_1: 0.692383, top_k: 0.878906, samples/s: 1333.158 1612777243.843352
train: epoch 119, iter 1200, loss: 2.202947, top_1: 0.695117, top_k: 0.878477, samples/s: 1334.417 1612777263.02774
train: epoch 119, iter 1300, loss: 2.155520, top_1: 0.695586, top_k: 0.880664, samples/s: 1336.292 1612777282.185198
train: epoch 119, iter 1400, loss: 2.103069, top_1: 0.693750, top_k: 0.876758, samples/s: 1334.239 1612777301.3721497
train: epoch 119, iter 1500, loss: 2.269205, top_1: 0.696328, top_k: 0.878633, samples/s: 1332.315 1612777320.5868762
train: epoch 119, iter 1600, loss: 2.280285, top_1: 0.692695, top_k: 0.873945, samples/s: 1332.773 1612777339.795007
train: epoch 119, iter 1700, loss: 2.156822, top_1: 0.696719, top_k: 0.877812, samples/s: 1336.333 1612777358.9518096
train: epoch 119, iter 1800, loss: 2.293685, top_1: 0.693789, top_k: 0.878477, samples/s: 1329.907 1612777378.201299
train: epoch 119, iter 1900, loss: 2.139435, top_1: 0.692773, top_k: 0.876328, samples/s: 1335.097 1612777397.3759255
train: epoch 119, iter 2000, loss: 2.228862, top_1: 0.684688, top_k: 0.874805, samples/s: 1333.136 1612777416.5787513
train: epoch 119, iter 2100, loss: 2.088955, top_1: 0.694961, top_k: 0.877734, samples/s: 1331.678 1612777435.80268
train: epoch 119, iter 2200, loss: 2.404612, top_1: 0.693945, top_k: 0.877305, samples/s: 1336.196 1612777454.961501
train: epoch 119, iter 2300, loss: 2.201739, top_1: 0.693789, top_k: 0.878828, samples/s: 1333.226 1612777474.163048
train: epoch 119, iter 2400, loss: 2.319619, top_1: 0.691758, top_k: 0.875352, samples/s: 1337.692 1612777493.3004746
train: epoch 119, iter 2500, loss: 2.184623, top_1: 0.694688, top_k: 0.877031, samples/s: 1336.071 1612777512.4611552
train: epoch 119, iter 2600, loss: 2.129969, top_1: 0.691484, top_k: 0.876875, samples/s: 1336.395 1612777531.6171994
train: epoch 119, iter 2700, loss: 2.234684, top_1: 0.689609, top_k: 0.876680, samples/s: 1337.352 1612777550.759477
train: epoch 119, iter 2800, loss: 2.227581, top_1: 0.693008, top_k: 0.872305, samples/s: 1333.891 1612777569.951522
train: epoch 119, iter 2900, loss: 2.403295, top_1: 0.696602, top_k: 0.877188, samples/s: 1340.691 1612777589.0461097
train: epoch 119, iter 3000, loss: 2.395189, top_1: 0.691680, top_k: 0.873203, samples/s: 1327.851 1612777608.3252888
train: epoch 119, iter 3100, loss: 2.300333, top_1: 0.692969, top_k: 0.876797, samples/s: 1334.598 1612777627.5071204
train: epoch 119, iter 3200, loss: 2.349986, top_1: 0.694023, top_k: 0.877500, samples/s: 1341.469 1612777646.5906696
train: epoch 119, iter 3300, loss: 2.243897, top_1: 0.691562, top_k: 0.874297, samples/s: 1331.842 1612777665.8122404
train: epoch 119, iter 3400, loss: 2.282999, top_1: 0.687187, top_k: 0.872070, samples/s: 1338.280 1612777684.941284
train: epoch 119, iter 3500, loss: 2.334071, top_1: 0.690781, top_k: 0.876602, samples/s: 1336.811 1612777704.0913055
train: epoch 119, iter 3600, loss: 2.406811, top_1: 0.689688, top_k: 0.875430, samples/s: 1332.773 1612777723.2994378
train: epoch 119, iter 3700, loss: 2.286092, top_1: 0.687695, top_k: 0.873828, samples/s: 1333.059 1612777742.5034695
train: epoch 119, iter 3800, loss: 2.256455, top_1: 0.690508, top_k: 0.873789, samples/s: 1334.962 1612777761.6798801
train: epoch 119, iter 3900, loss: 2.293967, top_1: 0.691055, top_k: 0.875273, samples/s: 1337.490 1612777780.820186
train: epoch 119, iter 4000, loss: 2.256750, top_1: 0.685977, top_k: 0.875195, samples/s: 1333.463 1612777800.018377
train: epoch 119, iter 4100, loss: 2.157878, top_1: 0.691953, top_k: 0.876758, samples/s: 1338.912 1612777819.138346
train: epoch 119, iter 4200, loss: 2.266233, top_1: 0.687383, top_k: 0.872734, samples/s: 1332.107 1612777838.3560963
train: epoch 119, iter 4300, loss: 2.295777, top_1: 0.688945, top_k: 0.876523, samples/s: 1334.079 1612777857.5453036
train: epoch 119, iter 4400, loss: 2.317093, top_1: 0.688242, top_k: 0.875781, samples/s: 1336.865 1612777876.6946049
train: epoch 119, iter 4500, loss: 2.317103, top_1: 0.689102, top_k: 0.874492, samples/s: 1340.891 1612777895.7863915
train: epoch 119, iter 4600, loss: 2.245980, top_1: 0.689297, top_k: 0.871289, samples/s: 1336.554 1612777914.940187
train: epoch 119, iter 4700, loss: 2.298109, top_1: 0.682109, top_k: 0.871758, samples/s: 1332.712 1612777934.1490755
train: epoch 119, iter 4800, loss: 2.260617, top_1: 0.689688, top_k: 0.873867, samples/s: 1334.350 1612777953.334402
train: epoch 119, iter 4900, loss: 2.364606, top_1: 0.687891, top_k: 0.873672, samples/s: 1339.953 1612777972.4395733
train: epoch 119, iter 5000, loss: 2.259178, top_1: 0.694492, top_k: 0.879805, samples/s: 1338.383 1612777991.5670965
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_119.
validation: epoch 119, iter 195, top_1: 0.717668, top_k: 0.906030, samples/s: 2826.911 1612778009.8008215
train: epoch 120, iter 100, loss: 2.283340, top_1: 0.700703, top_k: 0.882227, samples/s: 1362.732 1612778044.8403966
train: epoch 120, iter 200, loss: 2.389541, top_1: 0.707266, top_k: 0.884844, samples/s: 1363.319 1612778063.618079
train: epoch 120, iter 300, loss: 2.173579, top_1: 0.700547, top_k: 0.880820, samples/s: 1360.957 1612778082.4283893
train: epoch 120, iter 400, loss: 2.341675, top_1: 0.703555, top_k: 0.878945, samples/s: 1356.072 1612778101.306378
train: epoch 120, iter 500, loss: 2.380837, top_1: 0.701523, top_k: 0.881914, samples/s: 1341.561 1612778120.3887339
train: epoch 120, iter 600, loss: 2.383029, top_1: 0.696445, top_k: 0.880742, samples/s: 1332.244 1612778139.6043558
train: epoch 120, iter 700, loss: 2.174269, top_1: 0.698711, top_k: 0.881484, samples/s: 1330.390 1612778158.8467996
train: epoch 120, iter 800, loss: 2.126526, top_1: 0.701562, top_k: 0.878711, samples/s: 1328.151 1612778178.121717
train: epoch 120, iter 900, loss: 2.197982, top_1: 0.700117, top_k: 0.880508, samples/s: 1334.345 1612778197.3072104
train: epoch 120, iter 1000, loss: 2.256806, top_1: 0.692891, top_k: 0.880664, samples/s: 1343.222 1612778216.3658588
train: epoch 120, iter 1100, loss: 2.468111, top_1: 0.698398, top_k: 0.879414, samples/s: 1324.217 1612778235.6980777
train: epoch 120, iter 1200, loss: 2.194275, top_1: 0.698789, top_k: 0.878242, samples/s: 1340.861 1612778254.7902784
train: epoch 120, iter 1300, loss: 2.270787, top_1: 0.692500, top_k: 0.875117, samples/s: 1329.629 1612778274.0437121
train: epoch 120, iter 1400, loss: 2.214957, top_1: 0.695703, top_k: 0.882891, samples/s: 1328.738 1612778293.3101368
train: epoch 120, iter 1500, loss: 2.308072, top_1: 0.702109, top_k: 0.883437, samples/s: 1332.506 1612778312.5220861
train: epoch 120, iter 1600, loss: 2.170390, top_1: 0.698711, top_k: 0.878516, samples/s: 1335.040 1612778331.6975312
train: epoch 120, iter 1700, loss: 2.165715, top_1: 0.696719, top_k: 0.878164, samples/s: 1325.887 1612778351.0053086
train: epoch 120, iter 1800, loss: 2.329620, top_1: 0.692891, top_k: 0.874336, samples/s: 1338.787 1612778370.127098
train: epoch 120, iter 1900, loss: 2.302915, top_1: 0.687773, top_k: 0.878164, samples/s: 1338.106 1612778389.258668
train: epoch 120, iter 2000, loss: 2.139676, top_1: 0.694766, top_k: 0.879141, samples/s: 1333.760 1612778408.4525502
train: epoch 120, iter 2100, loss: 2.260827, top_1: 0.693438, top_k: 0.878906, samples/s: 1327.306 1612778427.7396588
train: epoch 120, iter 2200, loss: 2.197655, top_1: 0.696562, top_k: 0.879219, samples/s: 1323.913 1612778447.0762925
train: epoch 120, iter 2300, loss: 2.249378, top_1: 0.698320, top_k: 0.880820, samples/s: 1334.336 1612778466.2619314
train: epoch 120, iter 2400, loss: 2.261381, top_1: 0.692539, top_k: 0.876523, samples/s: 1346.409 1612778485.275395
train: epoch 120, iter 2500, loss: 2.299071, top_1: 0.696523, top_k: 0.878789, samples/s: 1334.779 1612778504.4547088
train: epoch 120, iter 2600, loss: 2.255153, top_1: 0.695664, top_k: 0.877734, samples/s: 1333.465 1612778523.6527622
train: epoch 120, iter 2700, loss: 2.238114, top_1: 0.695273, top_k: 0.876328, samples/s: 1329.806 1612778542.9036348
train: epoch 120, iter 2800, loss: 2.359815, top_1: 0.691602, top_k: 0.877500, samples/s: 1330.560 1612778562.1437142
train: epoch 120, iter 2900, loss: 2.223651, top_1: 0.700117, top_k: 0.878711, samples/s: 1329.539 1612778581.3985045
train: epoch 120, iter 3000, loss: 2.209987, top_1: 0.696367, top_k: 0.876836, samples/s: 1336.326 1612778600.5554955
train: epoch 120, iter 3100, loss: 2.450426, top_1: 0.687383, top_k: 0.872930, samples/s: 1334.975 1612778619.731916
train: epoch 120, iter 3200, loss: 2.288543, top_1: 0.694414, top_k: 0.875938, samples/s: 1331.396 1612778638.959822
train: epoch 120, iter 3300, loss: 2.293700, top_1: 0.693984, top_k: 0.877812, samples/s: 1334.236 1612778658.146826
train: epoch 120, iter 3400, loss: 2.198098, top_1: 0.694180, top_k: 0.878086, samples/s: 1332.946 1612778677.3524039
train: epoch 120, iter 3500, loss: 2.257932, top_1: 0.691484, top_k: 0.877969, samples/s: 1338.199 1612778696.4826632
train: epoch 120, iter 3600, loss: 2.296655, top_1: 0.688008, top_k: 0.877422, samples/s: 1330.258 1612778715.726959
train: epoch 120, iter 3700, loss: 2.442276, top_1: 0.697617, top_k: 0.879727, samples/s: 1331.998 1612778734.9462025
train: epoch 120, iter 3800, loss: 2.222960, top_1: 0.690781, top_k: 0.876914, samples/s: 1331.701 1612778754.1697583
train: epoch 120, iter 3900, loss: 2.188965, top_1: 0.698477, top_k: 0.878594, samples/s: 1333.207 1612778773.3715844
train: epoch 120, iter 4000, loss: 2.493401, top_1: 0.691992, top_k: 0.872031, samples/s: 1335.457 1612778792.5410469
train: epoch 120, iter 4100, loss: 2.538751, top_1: 0.686562, top_k: 0.873984, samples/s: 1334.050 1612778811.730687
train: epoch 120, iter 4200, loss: 2.249780, top_1: 0.695000, top_k: 0.876758, samples/s: 1333.201 1612778830.9326277
train: epoch 120, iter 4300, loss: 2.420115, top_1: 0.693086, top_k: 0.877070, samples/s: 1333.593 1612778850.1288857
train: epoch 120, iter 4400, loss: 2.319725, top_1: 0.694805, top_k: 0.879336, samples/s: 1336.439 1612778869.284266
train: epoch 120, iter 4500, loss: 2.439201, top_1: 0.690586, top_k: 0.877539, samples/s: 1332.298 1612778888.4991431
train: epoch 120, iter 4600, loss: 2.226597, top_1: 0.695273, top_k: 0.879531, samples/s: 1331.503 1612778907.725563
train: epoch 120, iter 4700, loss: 2.345340, top_1: 0.694023, top_k: 0.877773, samples/s: 1337.736 1612778926.8623831
train: epoch 120, iter 4800, loss: 2.213928, top_1: 0.693008, top_k: 0.877422, samples/s: 1324.275 1612778946.193746
train: epoch 120, iter 4900, loss: 2.184645, top_1: 0.690195, top_k: 0.874961, samples/s: 1344.479 1612778965.2345436
train: epoch 120, iter 5000, loss: 2.122785, top_1: 0.695234, top_k: 0.880195, samples/s: 1337.481 1612778984.3749602
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_120.
validation: epoch 120, iter 195, top_1: 0.719151, top_k: 0.906831, samples/s: 2779.485 1612779003.0126092
train: epoch 121, iter 100, loss: 2.071461, top_1: 0.705000, top_k: 0.885703, samples/s: 1361.242 1612779037.7849457
train: epoch 121, iter 200, loss: 2.160679, top_1: 0.706289, top_k: 0.887148, samples/s: 1362.670 1612779056.5716887
train: epoch 121, iter 300, loss: 2.284538, top_1: 0.703828, top_k: 0.883086, samples/s: 1361.312 1612779075.3769603
train: epoch 121, iter 400, loss: 2.222987, top_1: 0.702539, top_k: 0.881094, samples/s: 1351.759 1612779094.3152876
train: epoch 121, iter 500, loss: 2.157426, top_1: 0.708203, top_k: 0.881875, samples/s: 1333.398 1612779113.5143194
train: epoch 121, iter 600, loss: 2.259017, top_1: 0.704883, top_k: 0.879336, samples/s: 1335.969 1612779132.6764474
train: epoch 121, iter 700, loss: 2.317168, top_1: 0.705039, top_k: 0.883984, samples/s: 1323.756 1612779152.0153122
train: epoch 121, iter 800, loss: 2.139386, top_1: 0.704141, top_k: 0.882188, samples/s: 1325.347 1612779171.331014
train: epoch 121, iter 900, loss: 2.188629, top_1: 0.702187, top_k: 0.883008, samples/s: 1330.656 1612779190.5697138
train: epoch 121, iter 1000, loss: 2.341257, top_1: 0.700937, top_k: 0.878164, samples/s: 1331.155 1612779209.8010883
train: epoch 121, iter 1100, loss: 2.370353, top_1: 0.695703, top_k: 0.879570, samples/s: 1329.523 1612779229.0561507
train: epoch 121, iter 1200, loss: 2.299984, top_1: 0.701875, top_k: 0.881328, samples/s: 1326.445 1612779248.355793
train: epoch 121, iter 1300, loss: 2.259581, top_1: 0.700664, top_k: 0.881797, samples/s: 1331.167 1612779267.5870986
train: epoch 121, iter 1400, loss: 2.094329, top_1: 0.698945, top_k: 0.884141, samples/s: 1334.532 1612779286.7698553
train: epoch 121, iter 1500, loss: 2.408055, top_1: 0.701562, top_k: 0.883008, samples/s: 1327.726 1612779306.0509458
train: epoch 121, iter 1600, loss: 2.214083, top_1: 0.698789, top_k: 0.881680, samples/s: 1332.334 1612779325.2653108
train: epoch 121, iter 1700, loss: 2.176541, top_1: 0.696172, top_k: 0.877852, samples/s: 1323.986 1612779344.6009352
train: epoch 121, iter 1800, loss: 2.223349, top_1: 0.697734, top_k: 0.882539, samples/s: 1336.916 1612779363.7494218
train: epoch 121, iter 1900, loss: 2.242826, top_1: 0.697227, top_k: 0.877500, samples/s: 1334.359 1612779382.9346795
train: epoch 121, iter 2000, loss: 2.208784, top_1: 0.692227, top_k: 0.876953, samples/s: 1335.146 1612779402.1085515
train: epoch 121, iter 2100, loss: 2.202906, top_1: 0.695820, top_k: 0.881172, samples/s: 1331.607 1612779421.333434
train: epoch 121, iter 2200, loss: 2.239192, top_1: 0.693281, top_k: 0.878633, samples/s: 1327.861 1612779440.612627
train: epoch 121, iter 2300, loss: 2.320351, top_1: 0.698125, top_k: 0.882578, samples/s: 1331.403 1612779459.8404057
train: epoch 121, iter 2400, loss: 2.293142, top_1: 0.700078, top_k: 0.879961, samples/s: 1329.922 1612779479.0896425
train: epoch 121, iter 2500, loss: 2.211936, top_1: 0.697578, top_k: 0.881484, samples/s: 1329.448 1612779498.3458443
train: epoch 121, iter 2600, loss: 2.350923, top_1: 0.698477, top_k: 0.882227, samples/s: 1329.201 1612779517.6054552
train: epoch 121, iter 2700, loss: 2.344016, top_1: 0.701758, top_k: 0.882500, samples/s: 1330.810 1612779536.8420005
train: epoch 121, iter 2800, loss: 2.293693, top_1: 0.690273, top_k: 0.878789, samples/s: 1331.567 1612779556.0673473
train: epoch 121, iter 2900, loss: 2.389753, top_1: 0.700391, top_k: 0.878711, samples/s: 1338.439 1612779575.1940775
train: epoch 121, iter 3000, loss: 2.316032, top_1: 0.697500, top_k: 0.876602, samples/s: 1328.898 1612779594.4582613
train: epoch 121, iter 3100, loss: 2.262434, top_1: 0.694180, top_k: 0.880039, samples/s: 1339.734 1612779613.5664942
train: epoch 121, iter 3200, loss: 2.105916, top_1: 0.699531, top_k: 0.877812, samples/s: 1331.279 1612779632.7960668
train: epoch 121, iter 3300, loss: 2.298109, top_1: 0.695820, top_k: 0.879023, samples/s: 1326.227 1612779652.099041
train: epoch 121, iter 3400, loss: 2.191149, top_1: 0.698477, top_k: 0.878398, samples/s: 1335.752 1612779671.2642515
train: epoch 121, iter 3500, loss: 2.414753, top_1: 0.687031, top_k: 0.874297, samples/s: 1336.182 1612779690.4233465
train: epoch 121, iter 3600, loss: 2.291589, top_1: 0.690039, top_k: 0.878437, samples/s: 1331.429 1612779709.650761
train: epoch 121, iter 3700, loss: 2.213832, top_1: 0.695273, top_k: 0.876523, samples/s: 1330.722 1612779728.888456
train: epoch 121, iter 3800, loss: 2.347983, top_1: 0.698711, top_k: 0.882969, samples/s: 1330.840 1612779748.1243706
train: epoch 121, iter 3900, loss: 2.295409, top_1: 0.695625, top_k: 0.878398, samples/s: 1329.035 1612779767.3864875
train: epoch 121, iter 4000, loss: 2.357749, top_1: 0.692578, top_k: 0.879297, samples/s: 1329.655 1612779786.6395657
train: epoch 121, iter 4100, loss: 2.347453, top_1: 0.693359, top_k: 0.875664, samples/s: 1332.409 1612779805.8529985
train: epoch 121, iter 4200, loss: 2.362450, top_1: 0.697734, top_k: 0.879062, samples/s: 1333.938 1612779825.0442562
train: epoch 121, iter 4300, loss: 2.375880, top_1: 0.686992, top_k: 0.876836, samples/s: 1332.158 1612779844.2611954
train: epoch 121, iter 4400, loss: 2.365953, top_1: 0.701250, top_k: 0.882734, samples/s: 1330.360 1612779863.5041003
train: epoch 121, iter 4500, loss: 2.289328, top_1: 0.699102, top_k: 0.880391, samples/s: 1331.401 1612779882.7319767
train: epoch 121, iter 4600, loss: 2.257165, top_1: 0.697969, top_k: 0.881250, samples/s: 1332.364 1612779901.945877
train: epoch 121, iter 4700, loss: 2.295405, top_1: 0.699414, top_k: 0.881523, samples/s: 1332.578 1612779921.1568203
train: epoch 121, iter 4800, loss: 2.237484, top_1: 0.692539, top_k: 0.876992, samples/s: 1332.036 1612779940.3754761
train: epoch 121, iter 4900, loss: 2.230030, top_1: 0.694023, top_k: 0.877773, samples/s: 1333.506 1612779959.5730076
train: epoch 121, iter 5000, loss: 2.309077, top_1: 0.706289, top_k: 0.881953, samples/s: 1332.626 1612779978.783246
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_121.
validation: epoch 121, iter 195, top_1: 0.720733, top_k: 0.909335, samples/s: 2908.591 1612779996.5169575
train: epoch 122, iter 100, loss: 2.338834, top_1: 0.705391, top_k: 0.883281, samples/s: 1355.212 1612780031.2012985
train: epoch 122, iter 200, loss: 2.181572, top_1: 0.699805, top_k: 0.883789, samples/s: 1363.025 1612780049.9831045
train: epoch 122, iter 300, loss: 2.291561, top_1: 0.703750, top_k: 0.882227, samples/s: 1362.315 1612780068.77455
train: epoch 122, iter 400, loss: 2.050944, top_1: 0.709844, top_k: 0.887578, samples/s: 1352.150 1612780087.7074523
train: epoch 122, iter 500, loss: 2.181956, top_1: 0.706328, top_k: 0.884258, samples/s: 1342.324 1612780106.7787323
train: epoch 122, iter 600, loss: 2.194038, top_1: 0.695547, top_k: 0.878047, samples/s: 1330.793 1612780126.0156457
train: epoch 122, iter 700, loss: 2.121624, top_1: 0.700898, top_k: 0.880039, samples/s: 1335.335 1612780145.1866806
train: epoch 122, iter 800, loss: 2.234515, top_1: 0.703477, top_k: 0.882188, samples/s: 1334.271 1612780164.3735292
train: epoch 122, iter 900, loss: 2.247583, top_1: 0.699844, top_k: 0.880195, samples/s: 1329.366 1612780183.6305082
train: epoch 122, iter 1000, loss: 2.244279, top_1: 0.698242, top_k: 0.879336, samples/s: 1340.920 1612780202.7217972
train: epoch 122, iter 1100, loss: 2.359816, top_1: 0.702617, top_k: 0.882383, samples/s: 1332.003 1612780221.9410005
train: epoch 122, iter 1200, loss: 2.127084, top_1: 0.703047, top_k: 0.883203, samples/s: 1340.168 1612780241.0430844
train: epoch 122, iter 1300, loss: 2.079263, top_1: 0.699570, top_k: 0.881133, samples/s: 1329.508 1612780260.2983134
train: epoch 122, iter 1400, loss: 2.052453, top_1: 0.702461, top_k: 0.883984, samples/s: 1333.760 1612780279.4921172
train: epoch 122, iter 1500, loss: 2.182046, top_1: 0.700586, top_k: 0.883672, samples/s: 1338.693 1612780298.6152909
train: epoch 122, iter 1600, loss: 2.041208, top_1: 0.699336, top_k: 0.879883, samples/s: 1332.548 1612780317.8266792
train: epoch 122, iter 1700, loss: 2.208468, top_1: 0.700859, top_k: 0.881133, samples/s: 1338.142 1612780336.9575677
train: epoch 122, iter 1800, loss: 2.203110, top_1: 0.702578, top_k: 0.884531, samples/s: 1335.033 1612780356.1332319
train: epoch 122, iter 1900, loss: 2.207490, top_1: 0.706641, top_k: 0.887148, samples/s: 1333.226 1612780375.3347194
train: epoch 122, iter 2000, loss: 2.266144, top_1: 0.701172, top_k: 0.880547, samples/s: 1333.227 1612780394.5362005
train: epoch 122, iter 2100, loss: 2.376455, top_1: 0.699023, top_k: 0.880469, samples/s: 1333.582 1612780413.7326083
train: epoch 122, iter 2200, loss: 2.316735, top_1: 0.704883, top_k: 0.885000, samples/s: 1343.718 1612780432.784354
train: epoch 122, iter 2300, loss: 2.454180, top_1: 0.701211, top_k: 0.882617, samples/s: 1333.430 1612780451.9828997
train: epoch 122, iter 2400, loss: 2.432263, top_1: 0.699219, top_k: 0.880234, samples/s: 1334.422 1612780471.16724
train: epoch 122, iter 2500, loss: 2.083893, top_1: 0.702578, top_k: 0.882891, samples/s: 1338.370 1612780490.2950404
train: epoch 122, iter 2600, loss: 2.059443, top_1: 0.703516, top_k: 0.883281, samples/s: 1339.553 1612780509.4058292
train: epoch 122, iter 2700, loss: 2.151664, top_1: 0.698789, top_k: 0.883867, samples/s: 1338.188 1612780528.536184
train: epoch 122, iter 2800, loss: 2.287489, top_1: 0.700781, top_k: 0.882969, samples/s: 1329.186 1612780547.796074
train: epoch 122, iter 2900, loss: 2.138633, top_1: 0.699336, top_k: 0.879453, samples/s: 1334.229 1612780566.9832165
train: epoch 122, iter 3000, loss: 2.130480, top_1: 0.693789, top_k: 0.878203, samples/s: 1334.308 1612780586.1691523
train: epoch 122, iter 3100, loss: 2.256229, top_1: 0.699531, top_k: 0.880547, samples/s: 1341.277 1612780605.2554638
train: epoch 122, iter 3200, loss: 2.056469, top_1: 0.698008, top_k: 0.880898, samples/s: 1331.809 1612780624.4774184
train: epoch 122, iter 3300, loss: 2.183763, top_1: 0.698516, top_k: 0.885000, samples/s: 1329.726 1612780643.7295544
train: epoch 122, iter 3400, loss: 2.492941, top_1: 0.701797, top_k: 0.879687, samples/s: 1340.127 1612780662.8321748
train: epoch 122, iter 3500, loss: 2.161142, top_1: 0.700000, top_k: 0.880469, samples/s: 1336.972 1612780681.9799304
train: epoch 122, iter 3600, loss: 2.282659, top_1: 0.699375, top_k: 0.879609, samples/s: 1344.103 1612780701.0260186
train: epoch 122, iter 3700, loss: 2.223500, top_1: 0.700195, top_k: 0.881563, samples/s: 1340.180 1612780720.128004
train: epoch 122, iter 3800, loss: 2.340876, top_1: 0.698945, top_k: 0.880781, samples/s: 1330.039 1612780739.3755133
train: epoch 122, iter 3900, loss: 2.098494, top_1: 0.696406, top_k: 0.878984, samples/s: 1334.416 1612780758.5599236
train: epoch 122, iter 4000, loss: 2.339287, top_1: 0.693555, top_k: 0.879062, samples/s: 1334.546 1612780777.7424693
train: epoch 122, iter 4100, loss: 2.277815, top_1: 0.693750, top_k: 0.876328, samples/s: 1337.844 1612780796.877761
train: epoch 122, iter 4200, loss: 2.258427, top_1: 0.697930, top_k: 0.876992, samples/s: 1337.844 1612780816.013008
train: epoch 122, iter 4300, loss: 2.295532, top_1: 0.697930, top_k: 0.881328, samples/s: 1330.829 1612780835.2491467
train: epoch 122, iter 4400, loss: 2.151038, top_1: 0.701445, top_k: 0.882031, samples/s: 1343.763 1612780854.3001556
train: epoch 122, iter 4500, loss: 2.224837, top_1: 0.697852, top_k: 0.876563, samples/s: 1335.731 1612780873.465689
train: epoch 122, iter 4600, loss: 2.185716, top_1: 0.703359, top_k: 0.878828, samples/s: 1335.854 1612780892.6294527
train: epoch 122, iter 4700, loss: 2.049831, top_1: 0.697578, top_k: 0.881641, samples/s: 1337.003 1612780911.776716
train: epoch 122, iter 4800, loss: 2.223184, top_1: 0.701797, top_k: 0.881133, samples/s: 1336.438 1612780930.932101
train: epoch 122, iter 4900, loss: 2.105723, top_1: 0.692422, top_k: 0.877852, samples/s: 1338.008 1612780950.06513
train: epoch 122, iter 5000, loss: 2.124288, top_1: 0.702969, top_k: 0.884023, samples/s: 1337.628 1612780969.2033792
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_122.
validation: epoch 122, iter 195, top_1: 0.724139, top_k: 0.910597, samples/s: 2751.784 1612780987.9327805
train: epoch 123, iter 100, loss: 2.339353, top_1: 0.705078, top_k: 0.884687, samples/s: 1363.781 1612781022.4250321
train: epoch 123, iter 200, loss: 2.119041, top_1: 0.705937, top_k: 0.884766, samples/s: 1365.610 1612781041.1713727
train: epoch 123, iter 300, loss: 2.176159, top_1: 0.707539, top_k: 0.881641, samples/s: 1362.204 1612781059.9642787
train: epoch 123, iter 400, loss: 2.108386, top_1: 0.706094, top_k: 0.885586, samples/s: 1351.643 1612781078.9042602
train: epoch 123, iter 500, loss: 2.113893, top_1: 0.711992, top_k: 0.887266, samples/s: 1336.911 1612781098.0529127
train: epoch 123, iter 600, loss: 2.274086, top_1: 0.709141, top_k: 0.884180, samples/s: 1339.269 1612781117.1677766
train: epoch 123, iter 700, loss: 2.356662, top_1: 0.709961, top_k: 0.885508, samples/s: 1335.254 1612781136.3402116
train: epoch 123, iter 800, loss: 2.199561, top_1: 0.708477, top_k: 0.886172, samples/s: 1332.891 1612781155.546585
train: epoch 123, iter 900, loss: 2.468723, top_1: 0.708398, top_k: 0.883203, samples/s: 1335.094 1612781174.7211795
train: epoch 123, iter 1000, loss: 2.185993, top_1: 0.712031, top_k: 0.887070, samples/s: 1340.727 1612781193.815327
train: epoch 123, iter 1100, loss: 2.283270, top_1: 0.708398, top_k: 0.884531, samples/s: 1338.077 1612781212.947232
train: epoch 123, iter 1200, loss: 2.022815, top_1: 0.710391, top_k: 0.886367, samples/s: 1334.508 1612781232.1303654
train: epoch 123, iter 1300, loss: 2.155916, top_1: 0.711367, top_k: 0.889297, samples/s: 1327.008 1612781251.4219134
train: epoch 123, iter 1400, loss: 2.290235, top_1: 0.702383, top_k: 0.882773, samples/s: 1337.943 1612781270.555752
train: epoch 123, iter 1500, loss: 2.161011, top_1: 0.705469, top_k: 0.885117, samples/s: 1330.476 1612781289.7970462
train: epoch 123, iter 1600, loss: 2.226635, top_1: 0.704023, top_k: 0.883320, samples/s: 1336.862 1612781308.94639
train: epoch 123, iter 1700, loss: 2.228816, top_1: 0.705469, top_k: 0.884961, samples/s: 1335.516 1612781328.1149359
train: epoch 123, iter 1800, loss: 2.240513, top_1: 0.705391, top_k: 0.881953, samples/s: 1338.382 1612781347.2424521
train: epoch 123, iter 1900, loss: 2.111310, top_1: 0.710586, top_k: 0.886797, samples/s: 1330.428 1612781366.4844358
train: epoch 123, iter 2000, loss: 2.250339, top_1: 0.705508, top_k: 0.886016, samples/s: 1334.849 1612781385.6625814
train: epoch 123, iter 2100, loss: 2.232931, top_1: 0.697969, top_k: 0.882773, samples/s: 1342.786 1612781404.7274232
train: epoch 123, iter 2200, loss: 2.281583, top_1: 0.706641, top_k: 0.881836, samples/s: 1333.843 1612781423.9201353
train: epoch 123, iter 2300, loss: 2.188409, top_1: 0.706875, top_k: 0.887656, samples/s: 1325.988 1612781443.226564
train: epoch 123, iter 2400, loss: 2.197558, top_1: 0.704297, top_k: 0.884062, samples/s: 1345.600 1612781462.2515242
train: epoch 123, iter 2500, loss: 2.326799, top_1: 0.701914, top_k: 0.882539, samples/s: 1339.695 1612781481.3602412
train: epoch 123, iter 2600, loss: 2.304698, top_1: 0.699219, top_k: 0.882891, samples/s: 1339.113 1612781500.477434
train: epoch 123, iter 2700, loss: 2.370779, top_1: 0.702305, top_k: 0.885781, samples/s: 1329.258 1612781519.7364461
train: epoch 123, iter 2800, loss: 2.158263, top_1: 0.701211, top_k: 0.880273, samples/s: 1337.444 1612781538.8773038
train: epoch 123, iter 2900, loss: 2.344750, top_1: 0.704414, top_k: 0.884219, samples/s: 1330.890 1612781558.1125157
train: epoch 123, iter 3000, loss: 2.221140, top_1: 0.704180, top_k: 0.884570, samples/s: 1342.143 1612781577.1865177
train: epoch 123, iter 3100, loss: 2.164160, top_1: 0.697422, top_k: 0.881484, samples/s: 1334.612 1612781596.3680744
train: epoch 123, iter 3200, loss: 2.190040, top_1: 0.702266, top_k: 0.883359, samples/s: 1336.788 1612781615.5185423
train: epoch 123, iter 3300, loss: 2.352336, top_1: 0.697852, top_k: 0.880625, samples/s: 1332.116 1612781634.7360458
train: epoch 123, iter 3400, loss: 2.357334, top_1: 0.702070, top_k: 0.880742, samples/s: 1331.793 1612781653.9582152
train: epoch 123, iter 3500, loss: 2.293855, top_1: 0.704492, top_k: 0.883437, samples/s: 1335.629 1612781673.1252751
train: epoch 123, iter 3600, loss: 2.288278, top_1: 0.705039, top_k: 0.884336, samples/s: 1337.293 1612781692.268423
train: epoch 123, iter 3700, loss: 2.063889, top_1: 0.703203, top_k: 0.881914, samples/s: 1337.759 1612781711.4048865
train: epoch 123, iter 3800, loss: 2.306668, top_1: 0.704375, top_k: 0.882812, samples/s: 1335.356 1612781730.5757582
train: epoch 123, iter 3900, loss: 2.374707, top_1: 0.701875, top_k: 0.882578, samples/s: 1329.342 1612781749.833399
train: epoch 123, iter 4000, loss: 2.116009, top_1: 0.703242, top_k: 0.882109, samples/s: 1344.017 1612781768.8808367
train: epoch 123, iter 4100, loss: 2.181574, top_1: 0.698047, top_k: 0.880195, samples/s: 1336.492 1612781788.0354867
train: epoch 123, iter 4200, loss: 2.282765, top_1: 0.704336, top_k: 0.884023, samples/s: 1334.747 1612781807.215103
train: epoch 123, iter 4300, loss: 2.262902, top_1: 0.699766, top_k: 0.881914, samples/s: 1339.824 1612781826.3220763
train: epoch 123, iter 4400, loss: 2.116861, top_1: 0.704805, top_k: 0.884687, samples/s: 1337.536 1612781845.4617224
train: epoch 123, iter 4500, loss: 2.114663, top_1: 0.704414, top_k: 0.882734, samples/s: 1333.174 1612781864.66402
train: epoch 123, iter 4600, loss: 2.036774, top_1: 0.703320, top_k: 0.883867, samples/s: 1339.963 1612781883.7690716
train: epoch 123, iter 4700, loss: 2.265759, top_1: 0.699414, top_k: 0.882617, samples/s: 1327.256 1612781903.0569232
train: epoch 123, iter 4800, loss: 2.301135, top_1: 0.698203, top_k: 0.878008, samples/s: 1345.723 1612781922.0801418
train: epoch 123, iter 4900, loss: 2.350382, top_1: 0.701172, top_k: 0.880430, samples/s: 1337.466 1612781941.2209275
train: epoch 123, iter 5000, loss: 2.085700, top_1: 0.705156, top_k: 0.882148, samples/s: 1336.474 1612781960.3757095
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_123.
validation: epoch 123, iter 195, top_1: 0.724679, top_k: 0.913662, samples/s: 2718.877 1612781979.3151827
train: epoch 124, iter 100, loss: 2.352677, top_1: 0.715273, top_k: 0.889023, samples/s: 1361.788 1612782013.8770447
train: epoch 124, iter 200, loss: 1.966829, top_1: 0.715898, top_k: 0.890273, samples/s: 1359.853 1612782032.7028337
train: epoch 124, iter 300, loss: 1.964121, top_1: 0.713477, top_k: 0.889531, samples/s: 1366.462 1612782051.4371064
train: epoch 124, iter 400, loss: 2.298611, top_1: 0.715938, top_k: 0.890312, samples/s: 1354.824 1612782070.3325381
train: epoch 124, iter 500, loss: 2.210721, top_1: 0.712187, top_k: 0.891055, samples/s: 1333.190 1612782089.534605
train: epoch 124, iter 600, loss: 2.254060, top_1: 0.704180, top_k: 0.883398, samples/s: 1329.194 1612782108.7944033
train: epoch 124, iter 700, loss: 2.336131, top_1: 0.709688, top_k: 0.885586, samples/s: 1340.746 1612782127.8883066
train: epoch 124, iter 800, loss: 2.196889, top_1: 0.702500, top_k: 0.881953, samples/s: 1336.493 1612782147.042891
train: epoch 124, iter 900, loss: 2.136280, top_1: 0.712461, top_k: 0.887891, samples/s: 1336.413 1612782166.198596
train: epoch 124, iter 1000, loss: 2.251011, top_1: 0.709063, top_k: 0.884531, samples/s: 1329.620 1612782185.4521916
train: epoch 124, iter 1100, loss: 2.388119, top_1: 0.715859, top_k: 0.888906, samples/s: 1330.014 1612782204.7001827
train: epoch 124, iter 1200, loss: 2.161009, top_1: 0.706719, top_k: 0.885000, samples/s: 1333.663 1612782223.8953514
train: epoch 124, iter 1300, loss: 2.197717, top_1: 0.710859, top_k: 0.888906, samples/s: 1337.693 1612782243.0327427
train: epoch 124, iter 1400, loss: 2.092023, top_1: 0.705195, top_k: 0.885312, samples/s: 1329.775 1612782262.2842314
train: epoch 124, iter 1500, loss: 2.347888, top_1: 0.706680, top_k: 0.885391, samples/s: 1340.508 1612782281.381357
train: epoch 124, iter 1600, loss: 2.130293, top_1: 0.705313, top_k: 0.883281, samples/s: 1334.983 1612782300.5577226
train: epoch 124, iter 1700, loss: 2.322772, top_1: 0.707891, top_k: 0.885586, samples/s: 1333.292 1612782319.7583597
train: epoch 124, iter 1800, loss: 2.041780, top_1: 0.709063, top_k: 0.887031, samples/s: 1339.026 1612782338.8766258
train: epoch 124, iter 1900, loss: 2.212035, top_1: 0.709727, top_k: 0.883281, samples/s: 1333.733 1612782358.0709527
train: epoch 124, iter 2000, loss: 2.291451, top_1: 0.702539, top_k: 0.881992, samples/s: 1333.992 1612782377.2614348
train: epoch 124, iter 2100, loss: 2.430969, top_1: 0.708633, top_k: 0.887383, samples/s: 1331.947 1612782396.4814003
train: epoch 124, iter 2200, loss: 2.309388, top_1: 0.707344, top_k: 0.884375, samples/s: 1341.431 1612782415.5654504
train: epoch 124, iter 2300, loss: 2.130123, top_1: 0.703359, top_k: 0.882305, samples/s: 1335.133 1612782434.739603
train: epoch 124, iter 2400, loss: 2.169470, top_1: 0.704766, top_k: 0.883594, samples/s: 1336.335 1612782453.896555
train: epoch 124, iter 2500, loss: 2.223758, top_1: 0.707852, top_k: 0.885586, samples/s: 1333.187 1612782473.0986555
train: epoch 124, iter 2600, loss: 2.298175, top_1: 0.703984, top_k: 0.885781, samples/s: 1333.526 1612782492.2957718
train: epoch 124, iter 2700, loss: 2.057776, top_1: 0.709922, top_k: 0.885820, samples/s: 1338.873 1612782511.4163997
train: epoch 124, iter 2800, loss: 2.303290, top_1: 0.709609, top_k: 0.885820, samples/s: 1336.486 1612782530.5710394
train: epoch 124, iter 2900, loss: 2.104477, top_1: 0.703594, top_k: 0.884062, samples/s: 1332.122 1612782549.7885056
train: epoch 124, iter 3000, loss: 2.366856, top_1: 0.705234, top_k: 0.883086, samples/s: 1335.643 1612782568.9553688
train: epoch 124, iter 3100, loss: 2.169588, top_1: 0.704883, top_k: 0.881289, samples/s: 1334.052 1612782588.145059
train: epoch 124, iter 3200, loss: 2.098310, top_1: 0.709102, top_k: 0.885234, samples/s: 1333.856 1612782607.3375025
train: epoch 124, iter 3300, loss: 2.236118, top_1: 0.707578, top_k: 0.886367, samples/s: 1336.803 1612782626.487661
train: epoch 124, iter 3400, loss: 2.122202, top_1: 0.706328, top_k: 0.884844, samples/s: 1332.594 1612782645.6983218
train: epoch 124, iter 3500, loss: 2.296574, top_1: 0.707734, top_k: 0.887383, samples/s: 1334.717 1612782664.8783953
train: epoch 124, iter 3600, loss: 2.160654, top_1: 0.708516, top_k: 0.886445, samples/s: 1338.524 1612782684.0039575
train: epoch 124, iter 3700, loss: 2.080348, top_1: 0.701797, top_k: 0.882344, samples/s: 1327.927 1612782703.282221
train: epoch 124, iter 3800, loss: 2.168282, top_1: 0.705547, top_k: 0.884492, samples/s: 1334.280 1612782722.4684978
train: epoch 124, iter 3900, loss: 2.074122, top_1: 0.706562, top_k: 0.884492, samples/s: 1336.763 1612782741.6192672
train: epoch 124, iter 4000, loss: 2.161370, top_1: 0.709805, top_k: 0.886719, samples/s: 1336.473 1612782760.7741463
train: epoch 124, iter 4100, loss: 2.125841, top_1: 0.705820, top_k: 0.884023, samples/s: 1338.810 1612782779.8955922
train: epoch 124, iter 4200, loss: 2.286653, top_1: 0.703945, top_k: 0.881797, samples/s: 1337.502 1612782799.0357494
train: epoch 124, iter 4300, loss: 2.016144, top_1: 0.708672, top_k: 0.885039, samples/s: 1326.170 1612782818.339461
train: epoch 124, iter 4400, loss: 2.110229, top_1: 0.701992, top_k: 0.884219, samples/s: 1339.873 1612782837.4458017
train: epoch 124, iter 4500, loss: 2.276349, top_1: 0.704453, top_k: 0.886289, samples/s: 1339.676 1612782856.5547886
train: epoch 124, iter 4600, loss: 2.145433, top_1: 0.701211, top_k: 0.883047, samples/s: 1337.113 1612782875.7006128
train: epoch 124, iter 4700, loss: 2.127886, top_1: 0.702695, top_k: 0.881719, samples/s: 1330.439 1612782894.9423523
train: epoch 124, iter 4800, loss: 2.207329, top_1: 0.701211, top_k: 0.881875, samples/s: 1338.243 1612782914.0718942
train: epoch 124, iter 4900, loss: 2.271678, top_1: 0.705586, top_k: 0.881133, samples/s: 1336.142 1612782933.2315536
train: epoch 124, iter 5000, loss: 2.351295, top_1: 0.711602, top_k: 0.889219, samples/s: 1338.077 1612782952.36348
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_124.
validation: epoch 124, iter 195, top_1: 0.724079, top_k: 0.910256, samples/s: 2768.278 1612782970.9904895
train: epoch 125, iter 100, loss: 2.286054, top_1: 0.719727, top_k: 0.888359, samples/s: 1361.100 1612783011.9302511
train: epoch 125, iter 200, loss: 2.122860, top_1: 0.720898, top_k: 0.892813, samples/s: 1355.769 1612783030.8126547
train: epoch 125, iter 300, loss: 2.265961, top_1: 0.713086, top_k: 0.888945, samples/s: 1369.898 1612783049.499988
train: epoch 125, iter 400, loss: 2.201507, top_1: 0.712109, top_k: 0.888711, samples/s: 1357.700 1612783068.355443
train: epoch 125, iter 500, loss: 2.066515, top_1: 0.716602, top_k: 0.888477, samples/s: 1340.294 1612783087.4557116
train: epoch 125, iter 600, loss: 2.266390, top_1: 0.710391, top_k: 0.887188, samples/s: 1329.005 1612783106.7182117
train: epoch 125, iter 700, loss: 2.029519, top_1: 0.711641, top_k: 0.887031, samples/s: 1331.108 1612783125.9503467
train: epoch 125, iter 800, loss: 2.140508, top_1: 0.715000, top_k: 0.889414, samples/s: 1330.201 1612783145.1955492
train: epoch 125, iter 900, loss: 2.315033, top_1: 0.711055, top_k: 0.888555, samples/s: 1336.789 1612783164.3459222
train: epoch 125, iter 1000, loss: 2.253310, top_1: 0.709141, top_k: 0.882852, samples/s: 1334.335 1612783183.5314384
train: epoch 125, iter 1100, loss: 2.022088, top_1: 0.708867, top_k: 0.883437, samples/s: 1327.011 1612783202.8229744
train: epoch 125, iter 1200, loss: 2.324588, top_1: 0.706641, top_k: 0.886602, samples/s: 1333.644 1612783222.0185158
train: epoch 125, iter 1300, loss: 2.265149, top_1: 0.713984, top_k: 0.889023, samples/s: 1335.059 1612783241.1936696
train: epoch 125, iter 1400, loss: 2.134751, top_1: 0.712734, top_k: 0.889453, samples/s: 1322.539 1612783260.5504491
train: epoch 125, iter 1500, loss: 2.228174, top_1: 0.714063, top_k: 0.886602, samples/s: 1336.969 1612783279.6981862
train: epoch 125, iter 1600, loss: 2.177193, top_1: 0.712852, top_k: 0.888281, samples/s: 1321.916 1612783299.0639684
train: epoch 125, iter 1700, loss: 2.240159, top_1: 0.704766, top_k: 0.886328, samples/s: 1335.985 1612783318.2259078
train: epoch 125, iter 1800, loss: 2.262578, top_1: 0.706758, top_k: 0.888945, samples/s: 1331.419 1612783337.4534879
train: epoch 125, iter 1900, loss: 2.252256, top_1: 0.714063, top_k: 0.890938, samples/s: 1338.059 1612783356.5856967
train: epoch 125, iter 2000, loss: 2.352509, top_1: 0.704063, top_k: 0.884453, samples/s: 1332.550 1612783375.7969284
train: epoch 125, iter 2100, loss: 2.169532, top_1: 0.707773, top_k: 0.884961, samples/s: 1327.577 1612783395.0802822
train: epoch 125, iter 2200, loss: 2.167172, top_1: 0.705742, top_k: 0.881094, samples/s: 1333.643 1612783414.2758913
train: epoch 125, iter 2300, loss: 2.150356, top_1: 0.710039, top_k: 0.885977, samples/s: 1322.818 1612783433.6284108
train: epoch 125, iter 2400, loss: 2.172942, top_1: 0.712187, top_k: 0.888398, samples/s: 1336.756 1612783452.7793033
train: epoch 125, iter 2500, loss: 2.159302, top_1: 0.713437, top_k: 0.887148, samples/s: 1327.317 1612783472.066364
train: epoch 125, iter 2600, loss: 2.094700, top_1: 0.708008, top_k: 0.885469, samples/s: 1332.949 1612783491.2719011
train: epoch 125, iter 2700, loss: 2.124855, top_1: 0.711133, top_k: 0.890312, samples/s: 1332.564 1612783510.4829388
train: epoch 125, iter 2800, loss: 2.211504, top_1: 0.710234, top_k: 0.888477, samples/s: 1336.721 1612783529.634245
train: epoch 125, iter 2900, loss: 2.106858, top_1: 0.713984, top_k: 0.889414, samples/s: 1332.887 1612783548.8406472
train: epoch 125, iter 3000, loss: 2.311761, top_1: 0.706562, top_k: 0.883984, samples/s: 1323.140 1612783568.1885238
train: epoch 125, iter 3100, loss: 2.326438, top_1: 0.710625, top_k: 0.890039, samples/s: 1340.738 1612783587.2824748
train: epoch 125, iter 3200, loss: 2.334285, top_1: 0.708359, top_k: 0.886094, samples/s: 1333.981 1612783606.4732215
train: epoch 125, iter 3300, loss: 2.213252, top_1: 0.710078, top_k: 0.887305, samples/s: 1330.748 1612783625.7104728
train: epoch 125, iter 3400, loss: 2.248936, top_1: 0.704883, top_k: 0.884922, samples/s: 1334.676 1612783644.8911285
train: epoch 125, iter 3500, loss: 2.203157, top_1: 0.705625, top_k: 0.883945, samples/s: 1332.261 1612783664.106611
train: epoch 125, iter 3600, loss: 2.258780, top_1: 0.709609, top_k: 0.885938, samples/s: 1332.134 1612783683.3238804
train: epoch 125, iter 3700, loss: 2.025521, top_1: 0.712539, top_k: 0.888711, samples/s: 1332.300 1612783702.5388067
train: epoch 125, iter 3800, loss: 2.176605, top_1: 0.705273, top_k: 0.883203, samples/s: 1333.008 1612783721.7435827
train: epoch 125, iter 3900, loss: 2.075640, top_1: 0.708281, top_k: 0.889844, samples/s: 1329.994 1612783740.9916716
train: epoch 125, iter 4000, loss: 2.163139, top_1: 0.716953, top_k: 0.888047, samples/s: 1333.725 1612783760.186077
train: epoch 125, iter 4100, loss: 2.037136, top_1: 0.708711, top_k: 0.884492, samples/s: 1334.011 1612783779.3763037
train: epoch 125, iter 4200, loss: 2.079382, top_1: 0.707812, top_k: 0.888398, samples/s: 1336.264 1612783798.5342205
train: epoch 125, iter 4300, loss: 2.291531, top_1: 0.706328, top_k: 0.884219, samples/s: 1335.931 1612783817.696877
train: epoch 125, iter 4400, loss: 2.024018, top_1: 0.711211, top_k: 0.886641, samples/s: 1325.587 1612783837.0090458
train: epoch 125, iter 4500, loss: 2.207126, top_1: 0.713320, top_k: 0.887500, samples/s: 1331.604 1612783856.2340326
train: epoch 125, iter 4600, loss: 2.084186, top_1: 0.708633, top_k: 0.884727, samples/s: 1335.653 1612783875.4006588
train: epoch 125, iter 4700, loss: 2.381369, top_1: 0.707031, top_k: 0.884219, samples/s: 1333.747 1612783894.5947149
train: epoch 125, iter 4800, loss: 2.180520, top_1: 0.704023, top_k: 0.881992, samples/s: 1337.013 1612783913.7418895
train: epoch 125, iter 4900, loss: 2.188036, top_1: 0.701914, top_k: 0.882031, samples/s: 1328.835 1612783933.0068777
train: epoch 125, iter 5000, loss: 2.166739, top_1: 0.717500, top_k: 0.886719, samples/s: 1327.241 1612783952.295067
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_125.
validation: epoch 125, iter 195, top_1: 0.729848, top_k: 0.913882, samples/s: 2757.757 1612783970.859143
train: epoch 126, iter 100, loss: 2.327018, top_1: 0.723594, top_k: 0.892188, samples/s: 1358.941 1612784005.817034
train: epoch 126, iter 200, loss: 2.057945, top_1: 0.722617, top_k: 0.894102, samples/s: 1362.542 1612784024.6053836
train: epoch 126, iter 300, loss: 2.215383, top_1: 0.711719, top_k: 0.889414, samples/s: 1361.715 1612784043.4051974
train: epoch 126, iter 400, loss: 2.133332, top_1: 0.716758, top_k: 0.891914, samples/s: 1356.848 1612784062.2725098
train: epoch 126, iter 500, loss: 2.107046, top_1: 0.719805, top_k: 0.893047, samples/s: 1335.272 1612784081.4445686
train: epoch 126, iter 600, loss: 2.287546, top_1: 0.714336, top_k: 0.892109, samples/s: 1335.658 1612784100.6112201
train: epoch 126, iter 700, loss: 2.306137, top_1: 0.715977, top_k: 0.891289, samples/s: 1335.503 1612784119.779959
train: epoch 126, iter 800, loss: 2.252416, top_1: 0.719336, top_k: 0.891016, samples/s: 1331.679 1612784139.0038052
train: epoch 126, iter 900, loss: 2.087065, top_1: 0.720078, top_k: 0.891953, samples/s: 1334.094 1612784158.1929262
train: epoch 126, iter 1000, loss: 2.146229, top_1: 0.715039, top_k: 0.888320, samples/s: 1339.998 1612784177.2974517
train: epoch 126, iter 1100, loss: 2.117511, top_1: 0.719414, top_k: 0.889336, samples/s: 1334.166 1612784196.485446
train: epoch 126, iter 1200, loss: 2.052947, top_1: 0.713086, top_k: 0.886641, samples/s: 1331.647 1612784215.709798
train: epoch 126, iter 1300, loss: 2.066416, top_1: 0.713633, top_k: 0.885664, samples/s: 1336.072 1612784234.8703942
train: epoch 126, iter 1400, loss: 2.206608, top_1: 0.713516, top_k: 0.890039, samples/s: 1334.794 1612784254.0493543
train: epoch 126, iter 1500, loss: 2.318976, top_1: 0.717383, top_k: 0.890859, samples/s: 1344.998 1612784273.0828497
train: epoch 126, iter 1600, loss: 2.096423, top_1: 0.713555, top_k: 0.890586, samples/s: 1335.701 1612784292.2487721
train: epoch 126, iter 1700, loss: 2.087266, top_1: 0.712852, top_k: 0.889062, samples/s: 1332.448 1612784311.4615984
train: epoch 126, iter 1800, loss: 2.146148, top_1: 0.717656, top_k: 0.892148, samples/s: 1345.712 1612784330.4849741
train: epoch 126, iter 1900, loss: 2.327362, top_1: 0.714219, top_k: 0.890781, samples/s: 1331.878 1612784349.705997
train: epoch 126, iter 2000, loss: 2.218496, top_1: 0.711055, top_k: 0.890781, samples/s: 1339.282 1612784368.8206758
train: epoch 126, iter 2100, loss: 1.953664, top_1: 0.712969, top_k: 0.888008, samples/s: 1339.383 1612784387.9340234
train: epoch 126, iter 2200, loss: 2.298644, top_1: 0.712734, top_k: 0.888672, samples/s: 1338.553 1612784407.05905
train: epoch 126, iter 2300, loss: 2.296764, top_1: 0.713125, top_k: 0.887305, samples/s: 1327.427 1612784426.3445208
train: epoch 126, iter 2400, loss: 2.160147, top_1: 0.716758, top_k: 0.889844, samples/s: 1334.738 1612784445.524296
train: epoch 126, iter 2500, loss: 2.293301, top_1: 0.710547, top_k: 0.886914, samples/s: 1341.561 1612784464.6065726
train: epoch 126, iter 2600, loss: 2.111863, top_1: 0.709063, top_k: 0.888945, samples/s: 1338.866 1612784483.7272213
train: epoch 126, iter 2700, loss: 2.123517, top_1: 0.714727, top_k: 0.889297, samples/s: 1332.055 1612784502.945667
train: epoch 126, iter 2800, loss: 2.163845, top_1: 0.710898, top_k: 0.890508, samples/s: 1339.139 1612784522.0624604
train: epoch 126, iter 2900, loss: 2.188291, top_1: 0.711211, top_k: 0.884844, samples/s: 1339.507 1612784541.1739361
train: epoch 126, iter 3000, loss: 2.158111, top_1: 0.713047, top_k: 0.888945, samples/s: 1339.807 1612784560.2811778
train: epoch 126, iter 3100, loss: 2.218277, top_1: 0.711914, top_k: 0.886328, samples/s: 1335.952 1612784579.443534
train: epoch 126, iter 3200, loss: 2.075937, top_1: 0.712930, top_k: 0.889961, samples/s: 1329.340 1612784598.7012568
train: epoch 126, iter 3300, loss: 2.268661, top_1: 0.714023, top_k: 0.889336, samples/s: 1342.647 1612784617.7679996
train: epoch 126, iter 3400, loss: 2.108749, top_1: 0.714531, top_k: 0.889258, samples/s: 1328.661 1612784637.035486
train: epoch 126, iter 3500, loss: 2.190599, top_1: 0.711680, top_k: 0.886602, samples/s: 1337.593 1612784656.1743844
train: epoch 126, iter 3600, loss: 2.111363, top_1: 0.709961, top_k: 0.887148, samples/s: 1334.018 1612784675.3645613
train: epoch 126, iter 3700, loss: 2.121330, top_1: 0.714453, top_k: 0.887500, samples/s: 1340.660 1612784694.459614
train: epoch 126, iter 3800, loss: 2.229473, top_1: 0.711797, top_k: 0.884883, samples/s: 1326.857 1612784713.7533472
train: epoch 126, iter 3900, loss: 2.122357, top_1: 0.715859, top_k: 0.890195, samples/s: 1335.411 1612784732.9234982
train: epoch 126, iter 4000, loss: 2.286961, top_1: 0.706680, top_k: 0.885508, samples/s: 1340.188 1612784752.0252144
train: epoch 126, iter 4100, loss: 2.264262, top_1: 0.708008, top_k: 0.886523, samples/s: 1334.345 1612784771.2106946
train: epoch 126, iter 4200, loss: 2.062828, top_1: 0.715234, top_k: 0.891016, samples/s: 1334.128 1612784790.3992712
train: epoch 126, iter 4300, loss: 2.238270, top_1: 0.703711, top_k: 0.884453, samples/s: 1342.602 1612784809.4666803
train: epoch 126, iter 4400, loss: 2.322393, top_1: 0.707656, top_k: 0.885508, samples/s: 1335.400 1612784828.6370347
train: epoch 126, iter 4500, loss: 2.072583, top_1: 0.712344, top_k: 0.888437, samples/s: 1341.108 1612784847.7256668
train: epoch 126, iter 4600, loss: 2.156426, top_1: 0.709141, top_k: 0.890000, samples/s: 1342.837 1612784866.7900977
train: epoch 126, iter 4700, loss: 2.190879, top_1: 0.716055, top_k: 0.888828, samples/s: 1332.182 1612784886.0064304
train: epoch 126, iter 4800, loss: 2.232351, top_1: 0.712031, top_k: 0.887070, samples/s: 1334.957 1612784905.183469
train: epoch 126, iter 4900, loss: 2.223252, top_1: 0.710117, top_k: 0.886875, samples/s: 1341.790 1612784924.261994
train: epoch 126, iter 5000, loss: 2.252748, top_1: 0.716016, top_k: 0.889414, samples/s: 1332.606 1612784943.4725456
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_126.
validation: epoch 126, iter 195, top_1: 0.729567, top_k: 0.914623, samples/s: 2711.816 1612784962.4320953
train: epoch 127, iter 100, loss: 2.224175, top_1: 0.724141, top_k: 0.892461, samples/s: 1357.966 1612784997.449697
train: epoch 127, iter 200, loss: 2.282073, top_1: 0.717852, top_k: 0.890117, samples/s: 1364.157 1612785016.215848
train: epoch 127, iter 300, loss: 2.240740, top_1: 0.718047, top_k: 0.890273, samples/s: 1359.463 1612785035.0468185
train: epoch 127, iter 400, loss: 2.194345, top_1: 0.717852, top_k: 0.893477, samples/s: 1359.704 1612785053.874389
train: epoch 127, iter 500, loss: 2.126852, top_1: 0.723047, top_k: 0.890664, samples/s: 1343.774 1612785072.9252357
train: epoch 127, iter 600, loss: 2.169452, top_1: 0.719375, top_k: 0.890586, samples/s: 1329.745 1612785092.1769946
train: epoch 127, iter 700, loss: 2.167105, top_1: 0.719414, top_k: 0.891563, samples/s: 1340.879 1612785111.2689886
train: epoch 127, iter 800, loss: 2.148018, top_1: 0.721992, top_k: 0.892539, samples/s: 1333.531 1612785130.466096
train: epoch 127, iter 900, loss: 2.135237, top_1: 0.722617, top_k: 0.890039, samples/s: 1337.679 1612785149.6037192
train: epoch 127, iter 1000, loss: 2.199491, top_1: 0.717148, top_k: 0.890703, samples/s: 1339.742 1612785168.7119098
train: epoch 127, iter 1100, loss: 2.119572, top_1: 0.718398, top_k: 0.888555, samples/s: 1338.930 1612785187.8316636
train: epoch 127, iter 1200, loss: 2.001836, top_1: 0.718750, top_k: 0.893203, samples/s: 1335.968 1612785206.9938436
train: epoch 127, iter 1300, loss: 2.165855, top_1: 0.715625, top_k: 0.888008, samples/s: 1336.571 1612785226.1472852
train: epoch 127, iter 1400, loss: 2.169843, top_1: 0.715938, top_k: 0.889414, samples/s: 1328.108 1612785245.422796
train: epoch 127, iter 1500, loss: 2.146441, top_1: 0.713594, top_k: 0.889414, samples/s: 1336.120 1612785264.5827324
train: epoch 127, iter 1600, loss: 2.112440, top_1: 0.712031, top_k: 0.888984, samples/s: 1337.116 1612785283.728419
train: epoch 127, iter 1700, loss: 2.148459, top_1: 0.720781, top_k: 0.892500, samples/s: 1333.720 1612785302.922834
train: epoch 127, iter 1800, loss: 2.330639, top_1: 0.720156, top_k: 0.892031, samples/s: 1337.288 1612785322.0661154
train: epoch 127, iter 1900, loss: 2.111242, top_1: 0.716055, top_k: 0.888789, samples/s: 1334.730 1612785341.246095
train: epoch 127, iter 2000, loss: 2.131166, top_1: 0.718828, top_k: 0.892109, samples/s: 1333.371 1612785360.445503
train: epoch 127, iter 2100, loss: 2.156400, top_1: 0.712617, top_k: 0.889180, samples/s: 1339.024 1612785379.5639024
train: epoch 127, iter 2200, loss: 2.167593, top_1: 0.711953, top_k: 0.888633, samples/s: 1338.376 1612785398.6915953
train: epoch 127, iter 2300, loss: 2.200782, top_1: 0.716797, top_k: 0.891133, samples/s: 1335.365 1612785417.862335
train: epoch 127, iter 2400, loss: 2.242898, top_1: 0.720039, top_k: 0.890312, samples/s: 1341.346 1612785436.947682
train: epoch 127, iter 2500, loss: 2.296910, top_1: 0.716133, top_k: 0.890078, samples/s: 1331.354 1612785456.1761448
train: epoch 127, iter 2600, loss: 2.096351, top_1: 0.713320, top_k: 0.888047, samples/s: 1330.103 1612785475.4228382
train: epoch 127, iter 2700, loss: 2.303519, top_1: 0.721445, top_k: 0.891563, samples/s: 1340.241 1612785494.5238914
train: epoch 127, iter 2800, loss: 2.275684, top_1: 0.711367, top_k: 0.888164, samples/s: 1339.461 1612785513.6360455
train: epoch 127, iter 2900, loss: 2.205865, top_1: 0.714883, top_k: 0.889883, samples/s: 1322.359 1612785532.99537
train: epoch 127, iter 3000, loss: 2.090077, top_1: 0.711133, top_k: 0.888594, samples/s: 1345.599 1612785552.0203705
train: epoch 127, iter 3100, loss: 2.241022, top_1: 0.714805, top_k: 0.889961, samples/s: 1340.590 1612785571.116449
train: epoch 127, iter 3200, loss: 2.286739, top_1: 0.715859, top_k: 0.889102, samples/s: 1330.384 1612785590.359043
train: epoch 127, iter 3300, loss: 2.122105, top_1: 0.716523, top_k: 0.893437, samples/s: 1339.600 1612785609.469182
train: epoch 127, iter 3400, loss: 2.140391, top_1: 0.711172, top_k: 0.891094, samples/s: 1336.676 1612785628.6211042
train: epoch 127, iter 3500, loss: 2.032845, top_1: 0.717344, top_k: 0.887148, samples/s: 1333.353 1612785647.8208182
train: epoch 127, iter 3600, loss: 2.183433, top_1: 0.715039, top_k: 0.891680, samples/s: 1340.067 1612785666.9244084
train: epoch 127, iter 3700, loss: 2.179432, top_1: 0.718828, top_k: 0.890117, samples/s: 1337.297 1612785686.0674388
train: epoch 127, iter 3800, loss: 2.056699, top_1: 0.715977, top_k: 0.891680, samples/s: 1338.573 1612785705.192308
train: epoch 127, iter 3900, loss: 2.105689, top_1: 0.713281, top_k: 0.889766, samples/s: 1339.932 1612785724.2977328
train: epoch 127, iter 4000, loss: 2.395373, top_1: 0.715000, top_k: 0.889414, samples/s: 1332.368 1612785743.5117028
train: epoch 127, iter 4100, loss: 2.091564, top_1: 0.718086, top_k: 0.888672, samples/s: 1338.514 1612785762.6373816
train: epoch 127, iter 4200, loss: 2.104821, top_1: 0.713945, top_k: 0.892773, samples/s: 1337.862 1612785781.7724538
train: epoch 127, iter 4300, loss: 2.125370, top_1: 0.714492, top_k: 0.890273, samples/s: 1334.212 1612785800.9597516
train: epoch 127, iter 4400, loss: 2.099844, top_1: 0.715859, top_k: 0.888477, samples/s: 1345.448 1612785819.9868798
train: epoch 127, iter 4500, loss: 2.152814, top_1: 0.714492, top_k: 0.889766, samples/s: 1337.306 1612785839.1297994
train: epoch 127, iter 4600, loss: 2.209093, top_1: 0.712695, top_k: 0.892695, samples/s: 1331.319 1612785858.3588939
train: epoch 127, iter 4700, loss: 2.186927, top_1: 0.716289, top_k: 0.887070, samples/s: 1331.434 1612785877.5862892
train: epoch 127, iter 4800, loss: 2.310284, top_1: 0.713945, top_k: 0.889922, samples/s: 1341.758 1612785896.6656706
train: epoch 127, iter 4900, loss: 2.205573, top_1: 0.713672, top_k: 0.887344, samples/s: 1334.967 1612785915.8423848
train: epoch 127, iter 5000, loss: 2.175315, top_1: 0.716406, top_k: 0.889844, samples/s: 1345.888 1612785934.8631232
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_127.
validation: epoch 127, iter 195, top_1: 0.732953, top_k: 0.916146, samples/s: 2737.822 1612785953.6630867
train: epoch 128, iter 100, loss: 2.200953, top_1: 0.726641, top_k: 0.894727, samples/s: 1361.989 1612785988.464542
train: epoch 128, iter 200, loss: 2.154232, top_1: 0.724023, top_k: 0.894883, samples/s: 1364.983 1612786007.2194448
train: epoch 128, iter 300, loss: 2.110945, top_1: 0.724063, top_k: 0.894531, samples/s: 1360.028 1612786026.042403
train: epoch 128, iter 400, loss: 2.296496, top_1: 0.725117, top_k: 0.894922, samples/s: 1356.497 1612786044.914602
train: epoch 128, iter 500, loss: 2.200119, top_1: 0.722422, top_k: 0.892852, samples/s: 1340.604 1612786064.010415
train: epoch 128, iter 600, loss: 2.169194, top_1: 0.717734, top_k: 0.891367, samples/s: 1329.545 1612786083.2651954
train: epoch 128, iter 700, loss: 2.059384, top_1: 0.723516, top_k: 0.893984, samples/s: 1342.736 1612786102.3307343
train: epoch 128, iter 800, loss: 2.092646, top_1: 0.721445, top_k: 0.893437, samples/s: 1331.129 1612786121.562477
train: epoch 128, iter 900, loss: 2.350711, top_1: 0.715664, top_k: 0.891953, samples/s: 1326.260 1612786140.86499
train: epoch 128, iter 1000, loss: 2.091325, top_1: 0.722656, top_k: 0.897227, samples/s: 1334.453 1612786160.0487711
train: epoch 128, iter 1100, loss: 2.125069, top_1: 0.723086, top_k: 0.892070, samples/s: 1341.957 1612786179.125449
train: epoch 128, iter 1200, loss: 2.143856, top_1: 0.721484, top_k: 0.894336, samples/s: 1337.884 1612786198.2600977
train: epoch 128, iter 1300, loss: 2.146325, top_1: 0.720977, top_k: 0.894141, samples/s: 1333.984 1612786217.4507146
train: epoch 128, iter 1400, loss: 2.197012, top_1: 0.719414, top_k: 0.889336, samples/s: 1336.014 1612786236.6122627
train: epoch 128, iter 1500, loss: 2.191228, top_1: 0.723125, top_k: 0.895469, samples/s: 1335.440 1612786255.7819552
train: epoch 128, iter 1600, loss: 2.366783, top_1: 0.719727, top_k: 0.893633, samples/s: 1338.683 1612786274.9052274
train: epoch 128, iter 1700, loss: 2.221879, top_1: 0.721055, top_k: 0.894961, samples/s: 1324.928 1612786294.227007
train: epoch 128, iter 1800, loss: 2.192750, top_1: 0.721445, top_k: 0.891758, samples/s: 1342.178 1612786313.3004515
train: epoch 128, iter 1900, loss: 2.131834, top_1: 0.718789, top_k: 0.887578, samples/s: 1338.862 1612786332.4212022
train: epoch 128, iter 2000, loss: 2.127593, top_1: 0.721289, top_k: 0.892578, samples/s: 1329.062 1612786351.6829388
train: epoch 128, iter 2100, loss: 2.213338, top_1: 0.716719, top_k: 0.888906, samples/s: 1333.618 1612786370.8787808
train: epoch 128, iter 2200, loss: 2.323411, top_1: 0.720469, top_k: 0.892422, samples/s: 1338.285 1612786390.0078013
train: epoch 128, iter 2300, loss: 2.044833, top_1: 0.716797, top_k: 0.891797, samples/s: 1326.473 1612786409.3071735
train: epoch 128, iter 2400, loss: 2.022021, top_1: 0.720938, top_k: 0.891836, samples/s: 1344.137 1612786428.3527703
train: epoch 128, iter 2500, loss: 1.944528, top_1: 0.719844, top_k: 0.891758, samples/s: 1331.114 1612786447.5848238
train: epoch 128, iter 2600, loss: 2.140526, top_1: 0.713555, top_k: 0.887891, samples/s: 1330.740 1612786466.8222532
train: epoch 128, iter 2700, loss: 2.222831, top_1: 0.721172, top_k: 0.892461, samples/s: 1351.293 1612786485.766985
train: epoch 128, iter 2800, loss: 1.977504, top_1: 0.715742, top_k: 0.892969, samples/s: 1335.716 1612786504.9328043
train: epoch 128, iter 2900, loss: 2.149093, top_1: 0.712773, top_k: 0.888828, samples/s: 1329.251 1612786524.1917212
train: epoch 128, iter 3000, loss: 2.272919, top_1: 0.720781, top_k: 0.894805, samples/s: 1339.102 1612786543.309039
train: epoch 128, iter 3100, loss: 2.224949, top_1: 0.713906, top_k: 0.891094, samples/s: 1342.496 1612786562.3779767
train: epoch 128, iter 3200, loss: 2.173994, top_1: 0.720430, top_k: 0.889844, samples/s: 1340.663 1612786581.4729629
train: epoch 128, iter 3300, loss: 2.248014, top_1: 0.717969, top_k: 0.887383, samples/s: 1327.037 1612786600.7640917
train: epoch 128, iter 3400, loss: 2.208812, top_1: 0.715898, top_k: 0.886797, samples/s: 1338.466 1612786619.8904707
train: epoch 128, iter 3500, loss: 2.371258, top_1: 0.716992, top_k: 0.892578, samples/s: 1343.237 1612786638.9489098
train: epoch 128, iter 3600, loss: 2.087730, top_1: 0.714570, top_k: 0.890820, samples/s: 1329.985 1612786658.1972566
train: epoch 128, iter 3700, loss: 2.146477, top_1: 0.716484, top_k: 0.889570, samples/s: 1335.665 1612786677.3637197
train: epoch 128, iter 3800, loss: 2.023135, top_1: 0.719023, top_k: 0.893711, samples/s: 1342.695 1612786696.429872
train: epoch 128, iter 3900, loss: 2.337668, top_1: 0.722344, top_k: 0.894531, samples/s: 1340.921 1612786715.5211592
train: epoch 128, iter 4000, loss: 2.105791, top_1: 0.720391, top_k: 0.894141, samples/s: 1333.746 1612786734.7153049
train: epoch 128, iter 4100, loss: 2.132965, top_1: 0.721797, top_k: 0.893125, samples/s: 1330.211 1612786753.9603832
train: epoch 128, iter 4200, loss: 2.222782, top_1: 0.719570, top_k: 0.891133, samples/s: 1336.875 1612786773.1094956
train: epoch 128, iter 4300, loss: 2.133128, top_1: 0.718359, top_k: 0.891680, samples/s: 1338.801 1612786792.231037
train: epoch 128, iter 4400, loss: 1.979212, top_1: 0.719375, top_k: 0.890898, samples/s: 1331.924 1612786811.4514139
train: epoch 128, iter 4500, loss: 2.304145, top_1: 0.716992, top_k: 0.890391, samples/s: 1337.269 1612786830.5948887
train: epoch 128, iter 4600, loss: 2.133562, top_1: 0.724258, top_k: 0.895117, samples/s: 1337.495 1612786849.7351463
train: epoch 128, iter 4700, loss: 2.356016, top_1: 0.715039, top_k: 0.890820, samples/s: 1336.661 1612786868.8873308
train: epoch 128, iter 4800, loss: 2.169704, top_1: 0.713828, top_k: 0.890312, samples/s: 1336.826 1612786888.0371957
train: epoch 128, iter 4900, loss: 2.208116, top_1: 0.716836, top_k: 0.892070, samples/s: 1336.560 1612786907.1907911
train: epoch 128, iter 5000, loss: 2.000856, top_1: 0.726406, top_k: 0.895000, samples/s: 1337.189 1612786926.3354397
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_128.
validation: epoch 128, iter 195, top_1: 0.733013, top_k: 0.915905, samples/s: 2745.848 1612786945.0830832
train: epoch 129, iter 100, loss: 2.304060, top_1: 0.725859, top_k: 0.893125, samples/s: 1361.247 1612786980.2946546
train: epoch 129, iter 200, loss: 2.213535, top_1: 0.726719, top_k: 0.894102, samples/s: 1361.120 1612786999.102659
train: epoch 129, iter 300, loss: 2.194618, top_1: 0.727344, top_k: 0.896055, samples/s: 1359.457 1612787017.93372
train: epoch 129, iter 400, loss: 2.157470, top_1: 0.728672, top_k: 0.896328, samples/s: 1360.375 1612787036.7520354
train: epoch 129, iter 500, loss: 2.085853, top_1: 0.728008, top_k: 0.896758, samples/s: 1334.268 1612787055.9385865
train: epoch 129, iter 600, loss: 2.193858, top_1: 0.726953, top_k: 0.896172, samples/s: 1330.189 1612787075.184
train: epoch 129, iter 700, loss: 2.294225, top_1: 0.723555, top_k: 0.895586, samples/s: 1331.288 1612787094.4134705
train: epoch 129, iter 800, loss: 2.155503, top_1: 0.726836, top_k: 0.897188, samples/s: 1332.012 1612787113.632491
train: epoch 129, iter 900, loss: 2.136034, top_1: 0.730859, top_k: 0.898047, samples/s: 1329.531 1612787132.8874693
train: epoch 129, iter 1000, loss: 2.191846, top_1: 0.726133, top_k: 0.892500, samples/s: 1340.518 1612787151.9845083
train: epoch 129, iter 1100, loss: 2.073021, top_1: 0.727930, top_k: 0.895352, samples/s: 1327.359 1612787171.2709515
train: epoch 129, iter 1200, loss: 2.211651, top_1: 0.724414, top_k: 0.895352, samples/s: 1328.159 1612787190.5457747
train: epoch 129, iter 1300, loss: 2.128534, top_1: 0.724336, top_k: 0.894961, samples/s: 1338.304 1612787209.6744554
train: epoch 129, iter 1400, loss: 2.242207, top_1: 0.725898, top_k: 0.890742, samples/s: 1332.761 1612787228.8827562
train: epoch 129, iter 1500, loss: 1.999343, top_1: 0.722109, top_k: 0.897070, samples/s: 1332.140 1612787248.0999014
train: epoch 129, iter 1600, loss: 2.239597, top_1: 0.721016, top_k: 0.893359, samples/s: 1334.532 1612787267.2826486
train: epoch 129, iter 1700, loss: 2.055147, top_1: 0.721250, top_k: 0.893594, samples/s: 1334.887 1612787286.460319
train: epoch 129, iter 1800, loss: 2.078891, top_1: 0.721133, top_k: 0.891602, samples/s: 1326.682 1612787305.75658
train: epoch 129, iter 1900, loss: 2.204795, top_1: 0.728203, top_k: 0.896836, samples/s: 1342.903 1612787324.8197424
train: epoch 129, iter 2000, loss: 2.283957, top_1: 0.718945, top_k: 0.889805, samples/s: 1325.845 1612787344.1281471
train: epoch 129, iter 2100, loss: 2.117008, top_1: 0.725742, top_k: 0.896680, samples/s: 1332.375 1612787363.341998
train: epoch 129, iter 2200, loss: 2.295006, top_1: 0.719180, top_k: 0.890547, samples/s: 1334.974 1612787382.5183477
train: epoch 129, iter 2300, loss: 2.189530, top_1: 0.718437, top_k: 0.893203, samples/s: 1335.924 1612787401.681118
train: epoch 129, iter 2400, loss: 2.110806, top_1: 0.722578, top_k: 0.892813, samples/s: 1326.956 1612787420.9734528
train: epoch 129, iter 2500, loss: 2.158360, top_1: 0.726641, top_k: 0.895508, samples/s: 1333.767 1612787440.1671574
train: epoch 129, iter 2600, loss: 2.133605, top_1: 0.722656, top_k: 0.895586, samples/s: 1332.363 1612787459.3811927
train: epoch 129, iter 2700, loss: 2.097586, top_1: 0.717656, top_k: 0.891836, samples/s: 1332.387 1612787478.5947683
train: epoch 129, iter 2800, loss: 2.099633, top_1: 0.725469, top_k: 0.895039, samples/s: 1329.767 1612787497.8462796
train: epoch 129, iter 2900, loss: 2.058408, top_1: 0.719688, top_k: 0.892461, samples/s: 1339.140 1612787516.963077
train: epoch 129, iter 3000, loss: 2.071809, top_1: 0.725117, top_k: 0.894062, samples/s: 1336.777 1612787536.1136196
train: epoch 129, iter 3100, loss: 2.145617, top_1: 0.717227, top_k: 0.891289, samples/s: 1328.011 1612787555.3905563
train: epoch 129, iter 3200, loss: 2.163662, top_1: 0.722578, top_k: 0.893906, samples/s: 1335.383 1612787574.5611103
train: epoch 129, iter 3300, loss: 2.089950, top_1: 0.722070, top_k: 0.894023, samples/s: 1335.028 1612787593.7366977
train: epoch 129, iter 3400, loss: 2.237795, top_1: 0.713437, top_k: 0.888477, samples/s: 1331.488 1612787612.9632988
train: epoch 129, iter 3500, loss: 2.253652, top_1: 0.720273, top_k: 0.893242, samples/s: 1327.058 1612787632.2540915
train: epoch 129, iter 3600, loss: 2.080746, top_1: 0.720391, top_k: 0.893125, samples/s: 1336.443 1612787651.4094152
train: epoch 129, iter 3700, loss: 2.228182, top_1: 0.715938, top_k: 0.892539, samples/s: 1327.052 1612787670.7003574
train: epoch 129, iter 3800, loss: 2.244733, top_1: 0.726523, top_k: 0.895508, samples/s: 1336.391 1612787689.8563719
train: epoch 129, iter 3900, loss: 2.285242, top_1: 0.718086, top_k: 0.890117, samples/s: 1330.895 1612787709.0915408
train: epoch 129, iter 4000, loss: 2.102130, top_1: 0.719961, top_k: 0.890664, samples/s: 1334.779 1612787728.270871
train: epoch 129, iter 4100, loss: 2.135548, top_1: 0.717383, top_k: 0.891758, samples/s: 1338.121 1612787747.4020784
train: epoch 129, iter 4200, loss: 2.169666, top_1: 0.722070, top_k: 0.890352, samples/s: 1325.692 1612787766.7127597
train: epoch 129, iter 4300, loss: 2.073329, top_1: 0.723242, top_k: 0.895039, samples/s: 1342.695 1612787785.778922
train: epoch 129, iter 4400, loss: 2.177703, top_1: 0.721250, top_k: 0.892266, samples/s: 1334.410 1612787804.9634671
train: epoch 129, iter 4500, loss: 2.025795, top_1: 0.721719, top_k: 0.892695, samples/s: 1330.258 1612787824.2078207
train: epoch 129, iter 4600, loss: 1.958443, top_1: 0.719102, top_k: 0.894297, samples/s: 1334.322 1612787843.393642
train: epoch 129, iter 4700, loss: 2.047805, top_1: 0.722500, top_k: 0.894219, samples/s: 1336.862 1612787862.5429063
train: epoch 129, iter 4800, loss: 2.115363, top_1: 0.720664, top_k: 0.893555, samples/s: 1332.142 1612787881.7601016
train: epoch 129, iter 4900, loss: 2.049708, top_1: 0.724609, top_k: 0.892500, samples/s: 1336.926 1612787900.9084837
train: epoch 129, iter 5000, loss: 2.085735, top_1: 0.726367, top_k: 0.896289, samples/s: 1330.249 1612787920.153055
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_129.
validation: epoch 129, iter 195, top_1: 0.736158, top_k: 0.917167, samples/s: 2759.496 1612787938.739663
train: epoch 130, iter 100, loss: 1.999533, top_1: 0.729141, top_k: 0.896094, samples/s: 1359.417 1612787974.1066399
train: epoch 130, iter 200, loss: 2.150655, top_1: 0.728828, top_k: 0.898359, samples/s: 1364.915 1612787992.8624544
train: epoch 130, iter 300, loss: 2.105343, top_1: 0.728750, top_k: 0.899648, samples/s: 1354.445 1612788011.7632153
train: epoch 130, iter 400, loss: 2.036068, top_1: 0.734883, top_k: 0.898359, samples/s: 1367.333 1612788030.4857483
train: epoch 130, iter 500, loss: 2.224026, top_1: 0.727539, top_k: 0.896602, samples/s: 1334.985 1612788049.6619625
train: epoch 130, iter 600, loss: 2.084573, top_1: 0.729453, top_k: 0.898789, samples/s: 1333.922 1612788068.8535283
train: epoch 130, iter 700, loss: 2.040656, top_1: 0.729727, top_k: 0.899062, samples/s: 1335.517 1612788088.0221496
train: epoch 130, iter 800, loss: 2.153747, top_1: 0.728945, top_k: 0.898750, samples/s: 1337.042 1612788107.168848
train: epoch 130, iter 900, loss: 2.242158, top_1: 0.732227, top_k: 0.897227, samples/s: 1340.117 1612788126.271632
train: epoch 130, iter 1000, loss: 2.148146, top_1: 0.728242, top_k: 0.896445, samples/s: 1335.511 1612788145.4403841
train: epoch 130, iter 1100, loss: 2.144944, top_1: 0.728555, top_k: 0.897109, samples/s: 1328.973 1612788164.7033277
train: epoch 130, iter 1200, loss: 1.971222, top_1: 0.721602, top_k: 0.895469, samples/s: 1336.902 1612788183.8520713
train: epoch 130, iter 1300, loss: 2.185974, top_1: 0.728008, top_k: 0.895039, samples/s: 1337.644 1612788202.9902513
train: epoch 130, iter 1400, loss: 2.087538, top_1: 0.723359, top_k: 0.894180, samples/s: 1330.023 1612788222.2380295
train: epoch 130, iter 1500, loss: 1.979805, top_1: 0.731367, top_k: 0.898320, samples/s: 1333.357 1612788241.4377105
train: epoch 130, iter 1600, loss: 2.193058, top_1: 0.726523, top_k: 0.895898, samples/s: 1343.387 1612788260.4940221
train: epoch 130, iter 1700, loss: 2.172392, top_1: 0.731094, top_k: 0.898633, samples/s: 1335.732 1612788279.6595147
train: epoch 130, iter 1800, loss: 2.175493, top_1: 0.727852, top_k: 0.895977, samples/s: 1335.959 1612788298.821741
train: epoch 130, iter 1900, loss: 2.111378, top_1: 0.734102, top_k: 0.897773, samples/s: 1336.649 1612788317.9741266
train: epoch 130, iter 2000, loss: 2.066937, top_1: 0.726328, top_k: 0.893867, samples/s: 1336.431 1612788337.1296053
train: epoch 130, iter 2100, loss: 2.182486, top_1: 0.726367, top_k: 0.894609, samples/s: 1341.426 1612788356.213787
train: epoch 130, iter 2200, loss: 2.081032, top_1: 0.725781, top_k: 0.895195, samples/s: 1337.200 1612788375.358295
train: epoch 130, iter 2300, loss: 2.082041, top_1: 0.725430, top_k: 0.896172, samples/s: 1332.201 1612788394.5746393
train: epoch 130, iter 2400, loss: 2.061095, top_1: 0.730039, top_k: 0.895156, samples/s: 1343.220 1612788413.6333048
train: epoch 130, iter 2500, loss: 2.066347, top_1: 0.729570, top_k: 0.896523, samples/s: 1337.487 1612788432.7736304
train: epoch 130, iter 2600, loss: 2.140450, top_1: 0.729453, top_k: 0.897656, samples/s: 1330.112 1612788452.0202038
train: epoch 130, iter 2700, loss: 2.344024, top_1: 0.719609, top_k: 0.889492, samples/s: 1339.364 1612788471.1336768
train: epoch 130, iter 2800, loss: 2.102706, top_1: 0.726523, top_k: 0.895352, samples/s: 1331.068 1612788490.3664
train: epoch 130, iter 2900, loss: 2.163487, top_1: 0.729180, top_k: 0.897070, samples/s: 1333.221 1612788509.5680802
train: epoch 130, iter 3000, loss: 2.132161, top_1: 0.727383, top_k: 0.894922, samples/s: 1339.446 1612788528.6803484
train: epoch 130, iter 3100, loss: 2.010169, top_1: 0.727070, top_k: 0.896445, samples/s: 1337.761 1612788547.8169425
train: epoch 130, iter 3200, loss: 2.043582, top_1: 0.731875, top_k: 0.897852, samples/s: 1336.461 1612788566.971884
train: epoch 130, iter 3300, loss: 1.998144, top_1: 0.724883, top_k: 0.894336, samples/s: 1335.704 1612788586.137854
train: epoch 130, iter 3400, loss: 2.088807, top_1: 0.724180, top_k: 0.893789, samples/s: 1329.499 1612788605.3931496
train: epoch 130, iter 3500, loss: 2.191699, top_1: 0.730195, top_k: 0.898047, samples/s: 1340.595 1612788624.4891872
train: epoch 130, iter 3600, loss: 2.104645, top_1: 0.722422, top_k: 0.893281, samples/s: 1334.134 1612788643.6776354
train: epoch 130, iter 3700, loss: 2.255744, top_1: 0.723086, top_k: 0.894687, samples/s: 1338.359 1612788662.8055332
train: epoch 130, iter 3800, loss: 2.132099, top_1: 0.719648, top_k: 0.890664, samples/s: 1339.673 1612788681.9147248
train: epoch 130, iter 3900, loss: 2.323531, top_1: 0.726914, top_k: 0.894180, samples/s: 1331.415 1612788701.1424026
train: epoch 130, iter 4000, loss: 2.124020, top_1: 0.721602, top_k: 0.896719, samples/s: 1325.425 1612788720.4569979
train: epoch 130, iter 4100, loss: 2.167488, top_1: 0.723750, top_k: 0.893125, samples/s: 1338.540 1612788739.5822475
train: epoch 130, iter 4200, loss: 2.112036, top_1: 0.722773, top_k: 0.892578, samples/s: 1340.560 1612788758.6787374
train: epoch 130, iter 4300, loss: 2.042807, top_1: 0.723633, top_k: 0.896211, samples/s: 1339.441 1612788777.7912009
train: epoch 130, iter 4400, loss: 2.046926, top_1: 0.730703, top_k: 0.899414, samples/s: 1333.753 1612788796.9851797
train: epoch 130, iter 4500, loss: 2.229105, top_1: 0.727266, top_k: 0.896641, samples/s: 1335.082 1612788816.1599698
train: epoch 130, iter 4600, loss: 2.158758, top_1: 0.720117, top_k: 0.896367, samples/s: 1339.031 1612788835.2783346
train: epoch 130, iter 4700, loss: 2.159607, top_1: 0.721719, top_k: 0.895508, samples/s: 1335.765 1612788854.4433117
train: epoch 130, iter 4800, loss: 2.152348, top_1: 0.718437, top_k: 0.891406, samples/s: 1331.408 1612788873.6710927
train: epoch 130, iter 4900, loss: 2.136117, top_1: 0.725273, top_k: 0.893789, samples/s: 1341.519 1612788892.753929
train: epoch 130, iter 5000, loss: 2.096202, top_1: 0.731914, top_k: 0.899727, samples/s: 1335.235 1612788911.9266694
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_130.
validation: epoch 130, iter 195, top_1: 0.738882, top_k: 0.919010, samples/s: 2783.597 1612788930.413833
train: epoch 131, iter 100, loss: 2.096769, top_1: 0.734375, top_k: 0.902305, samples/s: 1357.964 1612788965.8484926
train: epoch 131, iter 200, loss: 2.208784, top_1: 0.736602, top_k: 0.900742, samples/s: 1361.439 1612788984.6520965
train: epoch 131, iter 300, loss: 2.032043, top_1: 0.737461, top_k: 0.900195, samples/s: 1363.233 1612789003.431356
train: epoch 131, iter 400, loss: 1.989734, top_1: 0.727344, top_k: 0.894883, samples/s: 1356.270 1612789022.306314
train: epoch 131, iter 500, loss: 2.058437, top_1: 0.727344, top_k: 0.898711, samples/s: 1342.583 1612789041.3743892
train: epoch 131, iter 600, loss: 2.048826, top_1: 0.730313, top_k: 0.897070, samples/s: 1330.632 1612789060.6130104
train: epoch 131, iter 700, loss: 2.125450, top_1: 0.737734, top_k: 0.903242, samples/s: 1338.578 1612789079.7377818
train: epoch 131, iter 800, loss: 2.110981, top_1: 0.730469, top_k: 0.898945, samples/s: 1335.841 1612789098.9017053
train: epoch 131, iter 900, loss: 2.017565, top_1: 0.736602, top_k: 0.901055, samples/s: 1339.178 1612789118.0179214
train: epoch 131, iter 1000, loss: 2.217323, top_1: 0.731133, top_k: 0.898828, samples/s: 1342.367 1612789137.088763
train: epoch 131, iter 1100, loss: 2.020863, top_1: 0.731250, top_k: 0.899414, samples/s: 1332.837 1612789156.2959006
train: epoch 131, iter 1200, loss: 2.143739, top_1: 0.733711, top_k: 0.900117, samples/s: 1333.743 1612789175.4899645
train: epoch 131, iter 1300, loss: 2.105069, top_1: 0.726836, top_k: 0.897813, samples/s: 1336.634 1612789194.6425798
train: epoch 131, iter 1400, loss: 2.082434, top_1: 0.735859, top_k: 0.896875, samples/s: 1339.290 1612789213.7572253
train: epoch 131, iter 1500, loss: 2.148791, top_1: 0.722461, top_k: 0.895625, samples/s: 1337.197 1612789232.9016807
train: epoch 131, iter 1600, loss: 2.166411, top_1: 0.728555, top_k: 0.898633, samples/s: 1336.018 1612789252.0631611
train: epoch 131, iter 1700, loss: 2.255786, top_1: 0.730313, top_k: 0.896172, samples/s: 1338.406 1612789271.1903427
train: epoch 131, iter 1800, loss: 2.118895, top_1: 0.729102, top_k: 0.898398, samples/s: 1334.991 1612789290.3665717
train: epoch 131, iter 1900, loss: 2.207518, top_1: 0.727734, top_k: 0.896172, samples/s: 1335.658 1612789309.5332189
train: epoch 131, iter 2000, loss: 2.051919, top_1: 0.726133, top_k: 0.896250, samples/s: 1340.482 1612789328.6307735
train: epoch 131, iter 2100, loss: 2.091576, top_1: 0.730195, top_k: 0.898750, samples/s: 1335.997 1612789347.7924929
train: epoch 131, iter 2200, loss: 2.063106, top_1: 0.729805, top_k: 0.897422, samples/s: 1333.706 1612789366.9870749
train: epoch 131, iter 2300, loss: 2.123408, top_1: 0.730508, top_k: 0.898359, samples/s: 1340.771 1612789386.080574
train: epoch 131, iter 2400, loss: 2.046683, top_1: 0.728789, top_k: 0.897578, samples/s: 1335.851 1612789405.2443662
train: epoch 131, iter 2500, loss: 1.976424, top_1: 0.729258, top_k: 0.898164, samples/s: 1331.350 1612789424.473033
train: epoch 131, iter 2600, loss: 2.190503, top_1: 0.727734, top_k: 0.896289, samples/s: 1336.249 1612789443.6310272
train: epoch 131, iter 2700, loss: 2.095438, top_1: 0.733789, top_k: 0.899102, samples/s: 1338.711 1612789462.753921
train: epoch 131, iter 2800, loss: 2.192828, top_1: 0.726094, top_k: 0.896914, samples/s: 1339.616 1612789481.863965
train: epoch 131, iter 2900, loss: 1.957006, top_1: 0.726875, top_k: 0.892656, samples/s: 1336.859 1612789501.0132308
train: epoch 131, iter 3000, loss: 2.074389, top_1: 0.731602, top_k: 0.897031, samples/s: 1337.424 1612789520.1545606
train: epoch 131, iter 3100, loss: 2.082770, top_1: 0.726797, top_k: 0.896445, samples/s: 1340.761 1612789539.2481906
train: epoch 131, iter 3200, loss: 1.982798, top_1: 0.731602, top_k: 0.895039, samples/s: 1338.313 1612789558.3767033
train: epoch 131, iter 3300, loss: 2.134685, top_1: 0.730273, top_k: 0.896914, samples/s: 1330.134 1612789577.6229768
train: epoch 131, iter 3400, loss: 2.185619, top_1: 0.730898, top_k: 0.897305, samples/s: 1335.248 1612789596.7953904
train: epoch 131, iter 3500, loss: 2.112475, top_1: 0.725898, top_k: 0.893555, samples/s: 1338.572 1612789615.9202704
train: epoch 131, iter 3600, loss: 2.033526, top_1: 0.729102, top_k: 0.898828, samples/s: 1340.738 1612789635.014178
train: epoch 131, iter 3700, loss: 2.024797, top_1: 0.727852, top_k: 0.897539, samples/s: 1338.291 1612789654.1431062
train: epoch 131, iter 3800, loss: 2.151984, top_1: 0.729492, top_k: 0.897227, samples/s: 1335.110 1612789673.3175592
train: epoch 131, iter 3900, loss: 2.118856, top_1: 0.729648, top_k: 0.896445, samples/s: 1344.665 1612789692.3557122
train: epoch 131, iter 4000, loss: 2.038764, top_1: 0.727656, top_k: 0.896953, samples/s: 1335.328 1612789711.527067
train: epoch 131, iter 4100, loss: 2.249961, top_1: 0.732969, top_k: 0.898203, samples/s: 1334.997 1612789730.703093
train: epoch 131, iter 4200, loss: 2.210000, top_1: 0.725313, top_k: 0.897148, samples/s: 1336.228 1612789749.8615022
train: epoch 131, iter 4300, loss: 2.042360, top_1: 0.722031, top_k: 0.895469, samples/s: 1335.799 1612789769.0261328
train: epoch 131, iter 4400, loss: 1.998933, top_1: 0.728594, top_k: 0.896719, samples/s: 1340.540 1612789788.1229222
train: epoch 131, iter 4500, loss: 2.090425, top_1: 0.729844, top_k: 0.899844, samples/s: 1335.956 1612789807.2852283
train: epoch 131, iter 4600, loss: 2.180544, top_1: 0.722734, top_k: 0.891836, samples/s: 1335.822 1612789826.4494393
train: epoch 131, iter 4700, loss: 2.030924, top_1: 0.731406, top_k: 0.897734, samples/s: 1340.626 1612789845.5450175
train: epoch 131, iter 4800, loss: 2.272929, top_1: 0.727383, top_k: 0.896055, samples/s: 1335.894 1612789864.708221
train: epoch 131, iter 4900, loss: 2.097193, top_1: 0.725781, top_k: 0.897578, samples/s: 1339.121 1612789883.8252225
train: epoch 131, iter 5000, loss: 2.066974, top_1: 0.736172, top_k: 0.899687, samples/s: 1338.689 1612789902.948413
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_131.
validation: epoch 131, iter 195, top_1: 0.737300, top_k: 0.919351, samples/s: 2784.046 1612789921.5099783
train: epoch 132, iter 100, loss: 2.034251, top_1: 0.742539, top_k: 0.905820, samples/s: 1365.104 1612789956.0692627
train: epoch 132, iter 200, loss: 2.084153, top_1: 0.737344, top_k: 0.901211, samples/s: 1362.739 1612789974.8549092
train: epoch 132, iter 300, loss: 2.208710, top_1: 0.736055, top_k: 0.902383, samples/s: 1362.379 1612789993.6456158
train: epoch 132, iter 400, loss: 1.934060, top_1: 0.734141, top_k: 0.902422, samples/s: 1357.095 1612790012.5094526
train: epoch 132, iter 500, loss: 2.138135, top_1: 0.735742, top_k: 0.900469, samples/s: 1333.953 1612790031.700581
train: epoch 132, iter 600, loss: 2.254444, top_1: 0.738672, top_k: 0.902188, samples/s: 1320.437 1612790051.0881307
train: epoch 132, iter 700, loss: 2.031089, top_1: 0.738164, top_k: 0.899297, samples/s: 1340.462 1612790070.1858919
train: epoch 132, iter 800, loss: 2.357227, top_1: 0.730820, top_k: 0.897734, samples/s: 1330.106 1612790089.432488
train: epoch 132, iter 900, loss: 1.996908, top_1: 0.732812, top_k: 0.900312, samples/s: 1333.059 1612790108.6364436
train: epoch 132, iter 1000, loss: 1.933559, top_1: 0.730234, top_k: 0.896094, samples/s: 1335.293 1612790127.8083804
train: epoch 132, iter 1100, loss: 2.166746, top_1: 0.736367, top_k: 0.901797, samples/s: 1342.397 1612790146.8786268
train: epoch 132, iter 1200, loss: 2.137793, top_1: 0.738750, top_k: 0.900742, samples/s: 1329.233 1612790166.1379225
train: epoch 132, iter 1300, loss: 2.002156, top_1: 0.738906, top_k: 0.902344, samples/s: 1333.305 1612790185.338401
train: epoch 132, iter 1400, loss: 2.105066, top_1: 0.731094, top_k: 0.896953, samples/s: 1333.136 1612790204.5412066
train: epoch 132, iter 1500, loss: 2.176888, top_1: 0.732422, top_k: 0.896016, samples/s: 1330.116 1612790223.7876773
train: epoch 132, iter 1600, loss: 2.088632, top_1: 0.734023, top_k: 0.897773, samples/s: 1338.308 1612790242.9162412
train: epoch 132, iter 1700, loss: 1.967432, top_1: 0.730117, top_k: 0.896367, samples/s: 1336.276 1612790262.0739436
train: epoch 132, iter 1800, loss: 2.256818, top_1: 0.735859, top_k: 0.900234, samples/s: 1339.859 1612790281.1804712
train: epoch 132, iter 1900, loss: 1.970687, top_1: 0.738750, top_k: 0.903711, samples/s: 1332.421 1612790300.3936136
train: epoch 132, iter 2000, loss: 2.201829, top_1: 0.737148, top_k: 0.901445, samples/s: 1332.380 1612790319.6072955
train: epoch 132, iter 2100, loss: 2.025055, top_1: 0.736211, top_k: 0.897930, samples/s: 1333.699 1612790338.8021135
train: epoch 132, iter 2200, loss: 2.027780, top_1: 0.732031, top_k: 0.901953, samples/s: 1340.137 1612790357.9045577
train: epoch 132, iter 2300, loss: 2.123265, top_1: 0.737734, top_k: 0.899570, samples/s: 1335.397 1612790377.074877
train: epoch 132, iter 2400, loss: 2.198496, top_1: 0.733047, top_k: 0.898398, samples/s: 1334.811 1612790396.253676
train: epoch 132, iter 2500, loss: 2.117294, top_1: 0.729023, top_k: 0.896680, samples/s: 1335.479 1612790415.42284
train: epoch 132, iter 2600, loss: 1.996415, top_1: 0.734922, top_k: 0.901133, samples/s: 1336.962 1612790434.5706856
train: epoch 132, iter 2700, loss: 2.151783, top_1: 0.730664, top_k: 0.899297, samples/s: 1330.933 1612790453.8054752
train: epoch 132, iter 2800, loss: 2.052324, top_1: 0.737109, top_k: 0.899805, samples/s: 1334.294 1612790472.991616
train: epoch 132, iter 2900, loss: 2.089561, top_1: 0.734570, top_k: 0.901094, samples/s: 1341.357 1612790492.0766766
train: epoch 132, iter 3000, loss: 1.937664, top_1: 0.729844, top_k: 0.896328, samples/s: 1339.219 1612790511.1923018
train: epoch 132, iter 3100, loss: 2.042362, top_1: 0.732344, top_k: 0.899414, samples/s: 1332.840 1612790530.399359
train: epoch 132, iter 3200, loss: 1.984067, top_1: 0.731328, top_k: 0.899453, samples/s: 1338.552 1612790549.5245466
train: epoch 132, iter 3300, loss: 2.221433, top_1: 0.730313, top_k: 0.897539, samples/s: 1329.827 1612790568.7752044
train: epoch 132, iter 3400, loss: 2.101562, top_1: 0.730977, top_k: 0.897891, samples/s: 1332.715 1612790587.9840896
train: epoch 132, iter 3500, loss: 1.954827, top_1: 0.729805, top_k: 0.898164, samples/s: 1328.922 1612790607.2478287
train: epoch 132, iter 3600, loss: 2.162427, top_1: 0.728203, top_k: 0.898438, samples/s: 1338.578 1612790626.3726666
train: epoch 132, iter 3700, loss: 2.114207, top_1: 0.730156, top_k: 0.896523, samples/s: 1325.049 1612790645.6926665
train: epoch 132, iter 3800, loss: 2.077124, top_1: 0.731719, top_k: 0.901602, samples/s: 1334.164 1612790664.8806903
train: epoch 132, iter 3900, loss: 2.015080, top_1: 0.733945, top_k: 0.900977, samples/s: 1340.103 1612790683.9836473
train: epoch 132, iter 4000, loss: 2.221541, top_1: 0.733047, top_k: 0.899805, samples/s: 1331.868 1612790703.204809
train: epoch 132, iter 4100, loss: 2.103671, top_1: 0.733867, top_k: 0.899492, samples/s: 1334.029 1612790722.3948267
train: epoch 132, iter 4200, loss: 2.295714, top_1: 0.731367, top_k: 0.896211, samples/s: 1330.947 1612790741.6294227
train: epoch 132, iter 4300, loss: 2.149063, top_1: 0.729922, top_k: 0.895625, samples/s: 1337.642 1612790760.7674084
train: epoch 132, iter 4400, loss: 2.045185, top_1: 0.728086, top_k: 0.897070, samples/s: 1337.700 1612790779.9047303
train: epoch 132, iter 4500, loss: 2.056995, top_1: 0.732695, top_k: 0.899062, samples/s: 1332.955 1612790799.1102622
train: epoch 132, iter 4600, loss: 2.101858, top_1: 0.737109, top_k: 0.902773, samples/s: 1333.557 1612790818.3069055
train: epoch 132, iter 4700, loss: 2.088684, top_1: 0.736953, top_k: 0.902031, samples/s: 1330.835 1612790837.5430183
train: epoch 132, iter 4800, loss: 2.161679, top_1: 0.733437, top_k: 0.901563, samples/s: 1338.018 1612790856.6757648
train: epoch 132, iter 4900, loss: 2.252925, top_1: 0.736328, top_k: 0.900234, samples/s: 1332.869 1612790875.882429
train: epoch 132, iter 5000, loss: 2.072415, top_1: 0.737852, top_k: 0.903398, samples/s: 1329.934 1612790895.131534
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_132.
validation: epoch 132, iter 195, top_1: 0.740445, top_k: 0.921094, samples/s: 2754.584 1612790913.8225398
train: epoch 133, iter 100, loss: 2.057262, top_1: 0.742461, top_k: 0.906797, samples/s: 1355.883 1612790948.8869684
train: epoch 133, iter 200, loss: 2.214800, top_1: 0.741055, top_k: 0.904648, samples/s: 1363.981 1612790967.6554735
train: epoch 133, iter 300, loss: 2.071366, top_1: 0.742188, top_k: 0.903828, samples/s: 1359.568 1612790986.484986
train: epoch 133, iter 400, loss: 2.115326, top_1: 0.738867, top_k: 0.901797, samples/s: 1355.592 1612791005.3697252
train: epoch 133, iter 500, loss: 2.180868, top_1: 0.735039, top_k: 0.902266, samples/s: 1337.370 1612791024.5118413
train: epoch 133, iter 600, loss: 2.194038, top_1: 0.742539, top_k: 0.901484, samples/s: 1323.673 1612791043.8519473
train: epoch 133, iter 700, loss: 2.130357, top_1: 0.737773, top_k: 0.904492, samples/s: 1327.172 1612791063.1410801
train: epoch 133, iter 800, loss: 2.246253, top_1: 0.741133, top_k: 0.904805, samples/s: 1322.226 1612791082.5023818
train: epoch 133, iter 900, loss: 2.248243, top_1: 0.734805, top_k: 0.899531, samples/s: 1326.694 1612791101.7984097
train: epoch 133, iter 1000, loss: 2.367217, top_1: 0.733984, top_k: 0.900586, samples/s: 1332.837 1612791121.0056293
train: epoch 133, iter 1100, loss: 2.035942, top_1: 0.737734, top_k: 0.901914, samples/s: 1323.750 1612791140.3445706
train: epoch 133, iter 1200, loss: 2.260972, top_1: 0.738906, top_k: 0.901680, samples/s: 1337.191 1612791159.4891818
train: epoch 133, iter 1300, loss: 2.013826, top_1: 0.743242, top_k: 0.902930, samples/s: 1327.770 1612791178.7696798
train: epoch 133, iter 1400, loss: 2.101743, top_1: 0.735352, top_k: 0.900195, samples/s: 1326.701 1612791198.0656126
train: epoch 133, iter 1500, loss: 1.989899, top_1: 0.737930, top_k: 0.903984, samples/s: 1328.039 1612791217.3421507
train: epoch 133, iter 1600, loss: 2.063150, top_1: 0.738789, top_k: 0.900937, samples/s: 1326.637 1612791236.6390753
train: epoch 133, iter 1700, loss: 2.153251, top_1: 0.739648, top_k: 0.901914, samples/s: 1330.980 1612791255.87303
train: epoch 133, iter 1800, loss: 2.032285, top_1: 0.734219, top_k: 0.898047, samples/s: 1326.301 1612791275.1748962
train: epoch 133, iter 1900, loss: 2.044383, top_1: 0.736563, top_k: 0.903203, samples/s: 1329.296 1612791294.4331408
train: epoch 133, iter 2000, loss: 2.028393, top_1: 0.737305, top_k: 0.901289, samples/s: 1327.558 1612791313.716715
train: epoch 133, iter 2100, loss: 2.282690, top_1: 0.732930, top_k: 0.900352, samples/s: 1332.881 1612791332.923271
train: epoch 133, iter 2200, loss: 2.242647, top_1: 0.739688, top_k: 0.900898, samples/s: 1324.244 1612791352.2549777
train: epoch 133, iter 2300, loss: 2.201283, top_1: 0.730781, top_k: 0.897617, samples/s: 1336.491 1612791371.4096606
train: epoch 133, iter 2400, loss: 2.199923, top_1: 0.737969, top_k: 0.898438, samples/s: 1326.744 1612791390.705029
train: epoch 133, iter 2500, loss: 2.054811, top_1: 0.736328, top_k: 0.903125, samples/s: 1324.778 1612791410.0290384
train: epoch 133, iter 2600, loss: 2.366522, top_1: 0.736055, top_k: 0.901563, samples/s: 1333.459 1612791429.2271547
train: epoch 133, iter 2700, loss: 2.074334, top_1: 0.739766, top_k: 0.901953, samples/s: 1330.412 1612791448.469363
train: epoch 133, iter 2800, loss: 1.928241, top_1: 0.736836, top_k: 0.899570, samples/s: 1330.546 1612791467.7095466
train: epoch 133, iter 2900, loss: 2.009689, top_1: 0.737305, top_k: 0.900391, samples/s: 1334.008 1612791486.8998866
train: epoch 133, iter 3000, loss: 2.122902, top_1: 0.730664, top_k: 0.897109, samples/s: 1332.397 1612791506.1133168
train: epoch 133, iter 3100, loss: 2.164677, top_1: 0.732812, top_k: 0.899023, samples/s: 1323.705 1612791525.4529834
train: epoch 133, iter 3200, loss: 1.998285, top_1: 0.732070, top_k: 0.899062, samples/s: 1336.344 1612791544.6098385
train: epoch 133, iter 3300, loss: 2.049684, top_1: 0.739297, top_k: 0.902930, samples/s: 1333.080 1612791563.8134298
train: epoch 133, iter 3400, loss: 2.071499, top_1: 0.732148, top_k: 0.898984, samples/s: 1333.454 1612791583.0116417
train: epoch 133, iter 3500, loss: 2.150351, top_1: 0.734688, top_k: 0.899336, samples/s: 1329.096 1612791602.2729092
train: epoch 133, iter 3600, loss: 2.130811, top_1: 0.733906, top_k: 0.900430, samples/s: 1329.474 1612791621.5286505
train: epoch 133, iter 3700, loss: 2.048146, top_1: 0.736016, top_k: 0.897930, samples/s: 1336.901 1612791640.6774037
train: epoch 133, iter 3800, loss: 2.131377, top_1: 0.733359, top_k: 0.901016, samples/s: 1320.935 1612791660.0576177
train: epoch 133, iter 3900, loss: 2.284180, top_1: 0.729297, top_k: 0.895664, samples/s: 1323.820 1612791679.39565
train: epoch 133, iter 4000, loss: 1.914475, top_1: 0.739766, top_k: 0.903320, samples/s: 1339.503 1612791698.5070949
train: epoch 133, iter 4100, loss: 2.189867, top_1: 0.731953, top_k: 0.899258, samples/s: 1331.137 1612791717.7387815
train: epoch 133, iter 4200, loss: 2.182530, top_1: 0.734922, top_k: 0.899687, samples/s: 1328.494 1612791737.0088353
train: epoch 133, iter 4300, loss: 2.278622, top_1: 0.732187, top_k: 0.898516, samples/s: 1340.673 1612791756.1036086
train: epoch 133, iter 4400, loss: 2.035963, top_1: 0.734102, top_k: 0.901719, samples/s: 1325.676 1612791775.4145155
train: epoch 133, iter 4500, loss: 2.108323, top_1: 0.733789, top_k: 0.900273, samples/s: 1339.517 1612791794.5258691
train: epoch 133, iter 4600, loss: 2.216318, top_1: 0.739180, top_k: 0.901758, samples/s: 1323.647 1612791813.8664212
train: epoch 133, iter 4700, loss: 2.288312, top_1: 0.730977, top_k: 0.898125, samples/s: 1332.762 1612791833.0746007
train: epoch 133, iter 4800, loss: 2.243515, top_1: 0.737383, top_k: 0.901680, samples/s: 1326.347 1612791852.3757799
train: epoch 133, iter 4900, loss: 2.150555, top_1: 0.739922, top_k: 0.901133, samples/s: 1334.352 1612791871.5611224
train: epoch 133, iter 5000, loss: 2.040376, top_1: 0.742109, top_k: 0.901094, samples/s: 1338.936 1612791890.6807756
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_133.
validation: epoch 133, iter 195, top_1: 0.742388, top_k: 0.920673, samples/s: 2765.530 1612791909.3971531
train: epoch 134, iter 100, loss: 1.854118, top_1: 0.749687, top_k: 0.905078, samples/s: 1365.583 1612791944.8145552
train: epoch 134, iter 200, loss: 2.074834, top_1: 0.739336, top_k: 0.901445, samples/s: 1358.692 1612791963.6560838
train: epoch 134, iter 300, loss: 2.122942, top_1: 0.741172, top_k: 0.901992, samples/s: 1361.063 1612791982.4649372
train: epoch 134, iter 400, loss: 2.069404, top_1: 0.741797, top_k: 0.904727, samples/s: 1359.213 1612792001.2993896
train: epoch 134, iter 500, loss: 2.120767, top_1: 0.739297, top_k: 0.900156, samples/s: 1334.702 1612792020.4796307
train: epoch 134, iter 600, loss: 2.016995, top_1: 0.745430, top_k: 0.904883, samples/s: 1338.108 1612792039.61118
train: epoch 134, iter 700, loss: 2.048167, top_1: 0.744961, top_k: 0.904492, samples/s: 1336.530 1612792058.7652457
train: epoch 134, iter 800, loss: 2.011024, top_1: 0.743437, top_k: 0.904062, samples/s: 1329.640 1612792078.0185728
train: epoch 134, iter 900, loss: 1.973186, top_1: 0.744609, top_k: 0.904102, samples/s: 1337.153 1612792097.1637473
train: epoch 134, iter 1000, loss: 2.177586, top_1: 0.746133, top_k: 0.903438, samples/s: 1333.252 1612792116.364921
train: epoch 134, iter 1100, loss: 1.946350, top_1: 0.741250, top_k: 0.902617, samples/s: 1332.974 1612792135.5701385
train: epoch 134, iter 1200, loss: 2.081881, top_1: 0.737969, top_k: 0.899297, samples/s: 1332.483 1612792154.782285
train: epoch 134, iter 1300, loss: 2.286455, top_1: 0.741680, top_k: 0.903945, samples/s: 1337.110 1612792173.9280987
train: epoch 134, iter 1400, loss: 2.134072, top_1: 0.741992, top_k: 0.903438, samples/s: 1334.107 1612792193.1169724
train: epoch 134, iter 1500, loss: 2.042518, top_1: 0.742148, top_k: 0.904102, samples/s: 1327.388 1612792212.4029322
train: epoch 134, iter 1600, loss: 2.109875, top_1: 0.743359, top_k: 0.905547, samples/s: 1331.665 1612792231.626984
train: epoch 134, iter 1700, loss: 1.974366, top_1: 0.742031, top_k: 0.902070, samples/s: 1336.877 1612792250.776071
train: epoch 134, iter 1800, loss: 1.951715, top_1: 0.742422, top_k: 0.901641, samples/s: 1335.847 1612792269.9400265
train: epoch 134, iter 1900, loss: 2.139252, top_1: 0.736914, top_k: 0.905469, samples/s: 1333.387 1612792289.1392436
train: epoch 134, iter 2000, loss: 2.146181, top_1: 0.737305, top_k: 0.902266, samples/s: 1337.547 1612792308.2787015
train: epoch 134, iter 2100, loss: 1.880161, top_1: 0.742773, top_k: 0.905547, samples/s: 1338.987 1612792327.3976257
train: epoch 134, iter 2200, loss: 2.058508, top_1: 0.744570, top_k: 0.907695, samples/s: 1333.496 1612792346.5953248
train: epoch 134, iter 2300, loss: 1.899785, top_1: 0.739688, top_k: 0.901836, samples/s: 1331.724 1612792365.8185375
train: epoch 134, iter 2400, loss: 1.902753, top_1: 0.742070, top_k: 0.904648, samples/s: 1332.141 1612792385.0357323
train: epoch 134, iter 2500, loss: 2.036121, top_1: 0.736953, top_k: 0.905000, samples/s: 1336.535 1612792404.189772
train: epoch 134, iter 2600, loss: 2.032522, top_1: 0.738359, top_k: 0.902266, samples/s: 1331.136 1612792423.4214327
train: epoch 134, iter 2700, loss: 2.225632, top_1: 0.743164, top_k: 0.904336, samples/s: 1336.498 1612792442.5759056
train: epoch 134, iter 2800, loss: 2.129102, top_1: 0.737812, top_k: 0.900547, samples/s: 1332.882 1612792461.782451
train: epoch 134, iter 2900, loss: 2.042819, top_1: 0.737266, top_k: 0.904180, samples/s: 1335.292 1612792480.954324
train: epoch 134, iter 3000, loss: 2.022339, top_1: 0.740742, top_k: 0.903047, samples/s: 1339.607 1612792500.0643535
train: epoch 134, iter 3100, loss: 2.020312, top_1: 0.739492, top_k: 0.901484, samples/s: 1327.326 1612792519.3512366
train: epoch 134, iter 3200, loss: 2.255232, top_1: 0.739727, top_k: 0.902422, samples/s: 1336.922 1612792538.499682
train: epoch 134, iter 3300, loss: 1.981150, top_1: 0.740664, top_k: 0.903281, samples/s: 1331.936 1612792557.7199104
train: epoch 134, iter 3400, loss: 1.975182, top_1: 0.742188, top_k: 0.900781, samples/s: 1340.600 1612792576.8157697
train: epoch 134, iter 3500, loss: 1.973378, top_1: 0.737148, top_k: 0.901641, samples/s: 1339.785 1612792595.9233925
train: epoch 134, iter 3600, loss: 1.897064, top_1: 0.737617, top_k: 0.899102, samples/s: 1331.650 1612792615.1476257
train: epoch 134, iter 3700, loss: 2.007500, top_1: 0.741328, top_k: 0.902539, samples/s: 1334.476 1612792634.3311808
train: epoch 134, iter 3800, loss: 2.183835, top_1: 0.739648, top_k: 0.900000, samples/s: 1331.516 1612792653.5573723
train: epoch 134, iter 3900, loss: 2.299593, top_1: 0.736406, top_k: 0.899297, samples/s: 1336.366 1612792672.7138364
train: epoch 134, iter 4000, loss: 2.152934, top_1: 0.735430, top_k: 0.901055, samples/s: 1338.357 1612792691.8416972
train: epoch 134, iter 4100, loss: 2.023645, top_1: 0.734961, top_k: 0.901328, samples/s: 1335.707 1612792711.0076733
train: epoch 134, iter 4200, loss: 2.128228, top_1: 0.735859, top_k: 0.900937, samples/s: 1336.167 1612792730.1670187
train: epoch 134, iter 4300, loss: 2.105782, top_1: 0.735313, top_k: 0.899414, samples/s: 1334.639 1612792749.3481014
train: epoch 134, iter 4400, loss: 2.004835, top_1: 0.738359, top_k: 0.900312, samples/s: 1335.683 1612792768.5143523
train: epoch 134, iter 4500, loss: 2.196787, top_1: 0.741367, top_k: 0.902539, samples/s: 1330.553 1612792787.7545164
train: epoch 134, iter 4600, loss: 1.974818, top_1: 0.739609, top_k: 0.898906, samples/s: 1338.405 1612792806.881718
train: epoch 134, iter 4700, loss: 2.010369, top_1: 0.733555, top_k: 0.899062, samples/s: 1333.093 1612792826.085164
train: epoch 134, iter 4800, loss: 2.056433, top_1: 0.737187, top_k: 0.900547, samples/s: 1336.203 1612792845.2439363
train: epoch 134, iter 4900, loss: 2.084949, top_1: 0.746680, top_k: 0.906602, samples/s: 1338.385 1612792864.371451
train: epoch 134, iter 5000, loss: 2.137500, top_1: 0.742695, top_k: 0.902500, samples/s: 1339.463 1612792883.4836416
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_134.
validation: epoch 134, iter 195, top_1: 0.742768, top_k: 0.921975, samples/s: 2793.749 1612792901.938924
train: epoch 135, iter 100, loss: 2.110551, top_1: 0.748398, top_k: 0.906094, samples/s: 1366.177 1612792936.7420614
train: epoch 135, iter 200, loss: 2.001193, top_1: 0.750000, top_k: 0.905078, samples/s: 1356.253 1612792955.617818
train: epoch 135, iter 300, loss: 2.205941, top_1: 0.745352, top_k: 0.907109, samples/s: 1371.403 1612792974.2845452
train: epoch 135, iter 400, loss: 2.014579, top_1: 0.743164, top_k: 0.904375, samples/s: 1355.420 1612792993.1716528
train: epoch 135, iter 500, loss: 1.870348, top_1: 0.746328, top_k: 0.905547, samples/s: 1333.336 1612793012.3716831
train: epoch 135, iter 600, loss: 2.109535, top_1: 0.746836, top_k: 0.906211, samples/s: 1341.284 1612793031.4578066
train: epoch 135, iter 700, loss: 2.111165, top_1: 0.745000, top_k: 0.904180, samples/s: 1333.012 1612793050.662449
train: epoch 135, iter 800, loss: 2.037704, top_1: 0.746289, top_k: 0.906563, samples/s: 1329.697 1612793069.9149098
train: epoch 135, iter 900, loss: 1.979265, top_1: 0.746211, top_k: 0.906445, samples/s: 1335.000 1612793089.0910382
train: epoch 135, iter 1000, loss: 1.920805, top_1: 0.745820, top_k: 0.906523, samples/s: 1336.107 1612793108.2511349
train: epoch 135, iter 1100, loss: 1.954942, top_1: 0.746250, top_k: 0.903359, samples/s: 1341.487 1612793127.3344464
train: epoch 135, iter 1200, loss: 2.087489, top_1: 0.742695, top_k: 0.907383, samples/s: 1331.242 1612793146.5646453
train: epoch 135, iter 1300, loss: 2.088320, top_1: 0.744258, top_k: 0.904023, samples/s: 1344.622 1612793165.6033497
train: epoch 135, iter 1400, loss: 2.080865, top_1: 0.743086, top_k: 0.905039, samples/s: 1329.757 1612793184.8549862
train: epoch 135, iter 1500, loss: 2.042433, top_1: 0.745039, top_k: 0.904062, samples/s: 1334.624 1612793204.03655
train: epoch 135, iter 1600, loss: 1.979291, top_1: 0.741602, top_k: 0.904102, samples/s: 1337.075 1612793223.1827374
train: epoch 135, iter 1700, loss: 1.957003, top_1: 0.744687, top_k: 0.903125, samples/s: 1334.808 1612793242.3615334
train: epoch 135, iter 1800, loss: 2.117529, top_1: 0.743320, top_k: 0.905625, samples/s: 1334.723 1612793261.541541
train: epoch 135, iter 1900, loss: 2.081759, top_1: 0.739141, top_k: 0.902969, samples/s: 1335.861 1612793280.705208
train: epoch 135, iter 2000, loss: 2.109877, top_1: 0.745117, top_k: 0.904648, samples/s: 1336.362 1612793299.8616917
train: epoch 135, iter 2100, loss: 2.176591, top_1: 0.747422, top_k: 0.906563, samples/s: 1334.233 1612793319.0487177
train: epoch 135, iter 2200, loss: 2.095306, top_1: 0.745781, top_k: 0.908750, samples/s: 1332.322 1612793338.2633529
train: epoch 135, iter 2300, loss: 1.995105, top_1: 0.750430, top_k: 0.906836, samples/s: 1341.883 1612793357.3409357
train: epoch 135, iter 2400, loss: 2.010763, top_1: 0.749141, top_k: 0.906758, samples/s: 1332.010 1612793376.5600724
train: epoch 135, iter 2500, loss: 2.097095, top_1: 0.742422, top_k: 0.903633, samples/s: 1337.041 1612793395.7068164
train: epoch 135, iter 2600, loss: 2.063611, top_1: 0.740820, top_k: 0.905156, samples/s: 1337.959 1612793414.8403494
train: epoch 135, iter 2700, loss: 2.112003, top_1: 0.739453, top_k: 0.902734, samples/s: 1338.750 1612793433.962735
train: epoch 135, iter 2800, loss: 2.032514, top_1: 0.742695, top_k: 0.904453, samples/s: 1336.958 1612793453.1106803
train: epoch 135, iter 2900, loss: 2.172300, top_1: 0.742812, top_k: 0.901641, samples/s: 1339.391 1612793472.2238948
train: epoch 135, iter 3000, loss: 2.114490, top_1: 0.744727, top_k: 0.903789, samples/s: 1336.791 1612793491.3741546
train: epoch 135, iter 3100, loss: 1.937148, top_1: 0.743047, top_k: 0.905000, samples/s: 1335.649 1612793510.5409226
train: epoch 135, iter 3200, loss: 2.167195, top_1: 0.740313, top_k: 0.907813, samples/s: 1329.619 1612793529.7945647
train: epoch 135, iter 3300, loss: 2.067543, top_1: 0.743789, top_k: 0.903828, samples/s: 1341.051 1612793548.8839834
train: epoch 135, iter 3400, loss: 2.168382, top_1: 0.745898, top_k: 0.908477, samples/s: 1340.664 1612793567.9790428
train: epoch 135, iter 3500, loss: 2.252190, top_1: 0.743477, top_k: 0.903438, samples/s: 1333.360 1612793587.178675
train: epoch 135, iter 3600, loss: 2.163753, top_1: 0.741836, top_k: 0.902031, samples/s: 1343.018 1612793606.2401533
train: epoch 135, iter 3700, loss: 2.097024, top_1: 0.743711, top_k: 0.902969, samples/s: 1332.753 1612793625.4486034
train: epoch 135, iter 3800, loss: 1.986848, top_1: 0.739648, top_k: 0.903008, samples/s: 1343.164 1612793644.5080514
train: epoch 135, iter 3900, loss: 2.034947, top_1: 0.743867, top_k: 0.903711, samples/s: 1338.586 1612793663.6326866
train: epoch 135, iter 4000, loss: 1.904635, top_1: 0.746406, top_k: 0.908086, samples/s: 1336.830 1612793682.7824638
train: epoch 135, iter 4100, loss: 2.052320, top_1: 0.743086, top_k: 0.903438, samples/s: 1335.221 1612793701.9552944
train: epoch 135, iter 4200, loss: 2.189778, top_1: 0.742656, top_k: 0.904375, samples/s: 1332.975 1612793721.1605523
train: epoch 135, iter 4300, loss: 2.011276, top_1: 0.747930, top_k: 0.907188, samples/s: 1340.816 1612793740.2533062
train: epoch 135, iter 4400, loss: 2.045319, top_1: 0.740781, top_k: 0.902891, samples/s: 1336.408 1612793759.409226
train: epoch 135, iter 4500, loss: 1.990580, top_1: 0.745117, top_k: 0.906211, samples/s: 1336.039 1612793778.5703087
train: epoch 135, iter 4600, loss: 2.037721, top_1: 0.742227, top_k: 0.906484, samples/s: 1333.611 1612793797.76635
train: epoch 135, iter 4700, loss: 2.115416, top_1: 0.738672, top_k: 0.901523, samples/s: 1337.767 1612793816.9026964
train: epoch 135, iter 4800, loss: 2.096688, top_1: 0.744219, top_k: 0.905234, samples/s: 1329.920 1612793836.1519887
train: epoch 135, iter 4900, loss: 2.131159, top_1: 0.735117, top_k: 0.903594, samples/s: 1340.476 1612793855.2496886
train: epoch 135, iter 5000, loss: 2.027623, top_1: 0.753477, top_k: 0.910117, samples/s: 1342.473 1612793874.3189414
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_135.
validation: epoch 135, iter 195, top_1: 0.748377, top_k: 0.923217, samples/s: 2892.406 1612793892.1554134
train: epoch 136, iter 100, loss: 1.992014, top_1: 0.753047, top_k: 0.908828, samples/s: 1363.030 1612793927.0426073
train: epoch 136, iter 200, loss: 1.969525, top_1: 0.753867, top_k: 0.906914, samples/s: 1359.691 1612793945.87067
train: epoch 136, iter 300, loss: 2.126990, top_1: 0.746328, top_k: 0.905117, samples/s: 1366.652 1612793964.6025324
train: epoch 136, iter 400, loss: 2.019313, top_1: 0.746289, top_k: 0.904531, samples/s: 1354.059 1612793983.5084372
train: epoch 136, iter 500, loss: 1.999982, top_1: 0.744141, top_k: 0.907539, samples/s: 1337.848 1612794002.6436634
train: epoch 136, iter 600, loss: 2.149943, top_1: 0.752031, top_k: 0.907813, samples/s: 1322.921 1612794021.9947612
train: epoch 136, iter 700, loss: 2.199280, top_1: 0.750273, top_k: 0.907773, samples/s: 1342.525 1612794041.0633523
train: epoch 136, iter 800, loss: 2.089041, top_1: 0.751406, top_k: 0.907930, samples/s: 1336.376 1612794060.2196605
train: epoch 136, iter 900, loss: 1.949303, top_1: 0.750352, top_k: 0.907227, samples/s: 1336.830 1612794079.3694134
train: epoch 136, iter 1000, loss: 1.914582, top_1: 0.748242, top_k: 0.906836, samples/s: 1336.593 1612794098.5226493
train: epoch 136, iter 1100, loss: 2.053668, top_1: 0.744609, top_k: 0.902188, samples/s: 1335.402 1612794117.6927876
train: epoch 136, iter 1200, loss: 2.058350, top_1: 0.746719, top_k: 0.904297, samples/s: 1333.577 1612794136.8893428
train: epoch 136, iter 1300, loss: 1.997590, top_1: 0.745898, top_k: 0.908594, samples/s: 1332.851 1612794156.0962293
train: epoch 136, iter 1400, loss: 1.892697, top_1: 0.752500, top_k: 0.908789, samples/s: 1333.065 1612794175.3001242
train: epoch 136, iter 1500, loss: 1.978075, top_1: 0.749922, top_k: 0.906680, samples/s: 1336.042 1612794194.461277
train: epoch 136, iter 1600, loss: 2.006979, top_1: 0.745820, top_k: 0.905742, samples/s: 1339.653 1612794213.5706286
train: epoch 136, iter 1700, loss: 1.987642, top_1: 0.748867, top_k: 0.907344, samples/s: 1336.191 1612794232.7295427
train: epoch 136, iter 1800, loss: 2.121770, top_1: 0.747500, top_k: 0.905000, samples/s: 1335.417 1612794251.8996398
train: epoch 136, iter 1900, loss: 1.954824, top_1: 0.748750, top_k: 0.906055, samples/s: 1329.286 1612794271.1580398
train: epoch 136, iter 2000, loss: 2.001404, top_1: 0.752617, top_k: 0.906875, samples/s: 1338.043 1612794290.2904766
train: epoch 136, iter 2100, loss: 2.109416, top_1: 0.744297, top_k: 0.905430, samples/s: 1338.888 1612794309.410815
train: epoch 136, iter 2200, loss: 1.983928, top_1: 0.748906, top_k: 0.906992, samples/s: 1334.657 1612794328.5918646
train: epoch 136, iter 2300, loss: 2.048465, top_1: 0.743828, top_k: 0.904687, samples/s: 1339.561 1612794347.7026021
train: epoch 136, iter 2400, loss: 1.968313, top_1: 0.743906, top_k: 0.904687, samples/s: 1338.148 1612794366.8335245
train: epoch 136, iter 2500, loss: 2.079158, top_1: 0.748633, top_k: 0.907500, samples/s: 1336.278 1612794385.9911835
train: epoch 136, iter 2600, loss: 2.087779, top_1: 0.744531, top_k: 0.906133, samples/s: 1334.732 1612794405.1710467
train: epoch 136, iter 2700, loss: 2.103102, top_1: 0.747656, top_k: 0.907969, samples/s: 1333.335 1612794424.3710089
train: epoch 136, iter 2800, loss: 2.074691, top_1: 0.750391, top_k: 0.906641, samples/s: 1336.018 1612794443.5323827
train: epoch 136, iter 2900, loss: 2.029296, top_1: 0.742188, top_k: 0.902617, samples/s: 1338.422 1612794462.659449
train: epoch 136, iter 3000, loss: 1.805371, top_1: 0.743750, top_k: 0.908477, samples/s: 1325.231 1612794481.9768207
train: epoch 136, iter 3100, loss: 2.075482, top_1: 0.743555, top_k: 0.902852, samples/s: 1345.994 1612794500.9962692
train: epoch 136, iter 3200, loss: 2.158286, top_1: 0.748437, top_k: 0.906523, samples/s: 1341.337 1612794520.0817194
train: epoch 136, iter 3300, loss: 2.224696, top_1: 0.743750, top_k: 0.907617, samples/s: 1336.310 1612794539.2388885
train: epoch 136, iter 3400, loss: 2.055162, top_1: 0.744687, top_k: 0.905586, samples/s: 1337.596 1612794558.3777068
train: epoch 136, iter 3500, loss: 2.015030, top_1: 0.738867, top_k: 0.903398, samples/s: 1328.648 1612794577.6454482
train: epoch 136, iter 3600, loss: 2.039593, top_1: 0.743047, top_k: 0.905195, samples/s: 1336.516 1612794596.799717
train: epoch 136, iter 3700, loss: 2.017252, top_1: 0.747734, top_k: 0.906250, samples/s: 1335.392 1612794615.9700503
train: epoch 136, iter 3800, loss: 1.985919, top_1: 0.746484, top_k: 0.903242, samples/s: 1333.419 1612794635.1688755
train: epoch 136, iter 3900, loss: 2.078133, top_1: 0.746719, top_k: 0.906445, samples/s: 1341.935 1612794654.2458162
train: epoch 136, iter 4000, loss: 2.044765, top_1: 0.743008, top_k: 0.905625, samples/s: 1334.291 1612794673.431976
train: epoch 136, iter 4100, loss: 2.060530, top_1: 0.751016, top_k: 0.908906, samples/s: 1333.214 1612794692.6336844
train: epoch 136, iter 4200, loss: 2.031207, top_1: 0.752305, top_k: 0.909531, samples/s: 1335.923 1612794711.79653
train: epoch 136, iter 4300, loss: 2.117710, top_1: 0.740977, top_k: 0.905781, samples/s: 1335.002 1612794730.9725387
train: epoch 136, iter 4400, loss: 2.162933, top_1: 0.745039, top_k: 0.909609, samples/s: 1339.179 1612794750.088871
train: epoch 136, iter 4500, loss: 2.110109, top_1: 0.749492, top_k: 0.907773, samples/s: 1337.230 1612794769.2328167
train: epoch 136, iter 4600, loss: 1.954115, top_1: 0.743867, top_k: 0.906211, samples/s: 1338.965 1612794788.3519728
train: epoch 136, iter 4700, loss: 2.176033, top_1: 0.745000, top_k: 0.903594, samples/s: 1337.191 1612794807.4966784
train: epoch 136, iter 4800, loss: 1.771322, top_1: 0.744102, top_k: 0.905469, samples/s: 1335.430 1612794826.6664486
train: epoch 136, iter 4900, loss: 2.079687, top_1: 0.742188, top_k: 0.904023, samples/s: 1336.604 1612794845.819449
train: epoch 136, iter 5000, loss: 1.974421, top_1: 0.746250, top_k: 0.905234, samples/s: 1335.654 1612794864.986172
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_136.
validation: epoch 136, iter 195, top_1: 0.749099, top_k: 0.923578, samples/s: 2816.060 1612794883.2800379
train: epoch 137, iter 100, loss: 1.896354, top_1: 0.757695, top_k: 0.911289, samples/s: 1358.674 1612794917.652064
train: epoch 137, iter 200, loss: 1.995570, top_1: 0.748984, top_k: 0.906758, samples/s: 1362.286 1612794936.4442267
train: epoch 137, iter 300, loss: 2.053058, top_1: 0.758711, top_k: 0.911953, samples/s: 1363.983 1612794955.2124815
train: epoch 137, iter 400, loss: 2.055169, top_1: 0.748633, top_k: 0.904414, samples/s: 1355.750 1612794974.0954425
train: epoch 137, iter 500, loss: 2.112718, top_1: 0.753750, top_k: 0.911250, samples/s: 1330.367 1612794993.3378894
train: epoch 137, iter 600, loss: 2.137544, top_1: 0.748594, top_k: 0.906875, samples/s: 1329.641 1612795012.591809
train: epoch 137, iter 700, loss: 1.994670, top_1: 0.750078, top_k: 0.908398, samples/s: 1335.149 1612795031.76502
train: epoch 137, iter 800, loss: 2.008651, top_1: 0.749453, top_k: 0.906445, samples/s: 1330.486 1612795051.006103
train: epoch 137, iter 900, loss: 1.949288, top_1: 0.749844, top_k: 0.911055, samples/s: 1334.040 1612795070.1960168
train: epoch 137, iter 1000, loss: 2.036774, top_1: 0.749375, top_k: 0.906523, samples/s: 1330.928 1612795089.430743
train: epoch 137, iter 1100, loss: 2.097484, top_1: 0.752695, top_k: 0.910859, samples/s: 1322.904 1612795108.782127
train: epoch 137, iter 1200, loss: 2.039153, top_1: 0.748398, top_k: 0.906328, samples/s: 1336.065 1612795127.9428182
train: epoch 137, iter 1300, loss: 2.012915, top_1: 0.751602, top_k: 0.910000, samples/s: 1332.554 1612795147.1540413
train: epoch 137, iter 1400, loss: 2.162010, top_1: 0.752773, top_k: 0.907344, samples/s: 1322.689 1612795166.508536
train: epoch 137, iter 1500, loss: 2.059746, top_1: 0.750430, top_k: 0.907617, samples/s: 1329.373 1612795185.7656834
train: epoch 137, iter 1600, loss: 1.963199, top_1: 0.753477, top_k: 0.910781, samples/s: 1328.264 1612795205.0390654
train: epoch 137, iter 1700, loss: 2.160204, top_1: 0.750547, top_k: 0.908164, samples/s: 1334.640 1612795224.220247
train: epoch 137, iter 1800, loss: 2.022717, top_1: 0.747734, top_k: 0.905391, samples/s: 1328.893 1612795243.4843667
train: epoch 137, iter 1900, loss: 2.043677, top_1: 0.750313, top_k: 0.909336, samples/s: 1335.949 1612795262.6467307
train: epoch 137, iter 2000, loss: 2.000682, top_1: 0.747852, top_k: 0.909336, samples/s: 1320.007 1612795282.0406063
train: epoch 137, iter 2100, loss: 2.107877, top_1: 0.749141, top_k: 0.907969, samples/s: 1332.857 1612795301.2474945
train: epoch 137, iter 2200, loss: 2.047022, top_1: 0.753555, top_k: 0.908750, samples/s: 1327.924 1612795320.5257099
train: epoch 137, iter 2300, loss: 2.106513, top_1: 0.745625, top_k: 0.905117, samples/s: 1327.727 1612795339.8068547
train: epoch 137, iter 2400, loss: 2.008424, top_1: 0.753125, top_k: 0.912344, samples/s: 1332.103 1612795359.0244482
train: epoch 137, iter 2500, loss: 1.950726, top_1: 0.746406, top_k: 0.907773, samples/s: 1329.858 1612795378.274635
train: epoch 137, iter 2600, loss: 2.183344, top_1: 0.749687, top_k: 0.905898, samples/s: 1328.682 1612795397.5419095
train: epoch 137, iter 2700, loss: 2.057701, top_1: 0.753711, top_k: 0.911953, samples/s: 1335.715 1612795416.7076254
train: epoch 137, iter 2800, loss: 1.894559, top_1: 0.748750, top_k: 0.906680, samples/s: 1333.338 1612795435.907639
train: epoch 137, iter 2900, loss: 1.974987, top_1: 0.751406, top_k: 0.909570, samples/s: 1327.779 1612795455.1879663
train: epoch 137, iter 3000, loss: 1.968930, top_1: 0.750859, top_k: 0.909570, samples/s: 1337.373 1612795474.3299196
train: epoch 137, iter 3100, loss: 1.817530, top_1: 0.751563, top_k: 0.909102, samples/s: 1328.598 1612795493.5983577
train: epoch 137, iter 3200, loss: 1.966794, top_1: 0.745586, top_k: 0.908125, samples/s: 1328.487 1612795512.868407
train: epoch 137, iter 3300, loss: 2.143924, top_1: 0.747539, top_k: 0.907695, samples/s: 1335.138 1612795532.042387
train: epoch 137, iter 3400, loss: 1.870052, top_1: 0.751602, top_k: 0.908789, samples/s: 1325.980 1612795551.3489614
train: epoch 137, iter 3500, loss: 2.080407, top_1: 0.756797, top_k: 0.912383, samples/s: 1333.258 1612795570.5500205
train: epoch 137, iter 3600, loss: 2.035807, top_1: 0.754453, top_k: 0.910781, samples/s: 1325.709 1612795589.860428
train: epoch 137, iter 3700, loss: 2.203899, top_1: 0.745000, top_k: 0.907227, samples/s: 1326.930 1612795609.1531081
train: epoch 137, iter 3800, loss: 1.906252, top_1: 0.749062, top_k: 0.907813, samples/s: 1335.432 1612795628.3229434
train: epoch 137, iter 3900, loss: 2.103818, top_1: 0.750938, top_k: 0.907773, samples/s: 1331.976 1612795647.5424545
train: epoch 137, iter 4000, loss: 2.162895, top_1: 0.747148, top_k: 0.905430, samples/s: 1325.463 1612795666.8564463
train: epoch 137, iter 4100, loss: 2.009429, top_1: 0.750742, top_k: 0.907383, samples/s: 1331.994 1612795686.075766
train: epoch 137, iter 4200, loss: 2.028688, top_1: 0.749414, top_k: 0.906953, samples/s: 1334.196 1612795705.2633295
train: epoch 137, iter 4300, loss: 2.076203, top_1: 0.745391, top_k: 0.906680, samples/s: 1330.709 1612795724.501269
train: epoch 137, iter 4400, loss: 2.101110, top_1: 0.748711, top_k: 0.907070, samples/s: 1334.300 1612795743.6873453
train: epoch 137, iter 4500, loss: 2.192434, top_1: 0.744922, top_k: 0.909102, samples/s: 1324.664 1612795763.0130007
train: epoch 137, iter 4600, loss: 1.933397, top_1: 0.745703, top_k: 0.904102, samples/s: 1337.507 1612795782.1530938
train: epoch 137, iter 4700, loss: 2.030044, top_1: 0.748867, top_k: 0.904180, samples/s: 1332.379 1612795801.3667672
train: epoch 137, iter 4800, loss: 1.929314, top_1: 0.751445, top_k: 0.909570, samples/s: 1330.304 1612795820.6105618
train: epoch 137, iter 4900, loss: 2.110729, top_1: 0.752969, top_k: 0.908750, samples/s: 1326.013 1612795839.9165792
train: epoch 137, iter 5000, loss: 2.140339, top_1: 0.752422, top_k: 0.911055, samples/s: 1329.404 1612795859.1732895
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_137.
validation: epoch 137, iter 195, top_1: 0.750921, top_k: 0.925300, samples/s: 2820.639 1612795877.432397
train: epoch 138, iter 100, loss: 1.978413, top_1: 0.753789, top_k: 0.907500, samples/s: 1364.883 1612795912.2004008
train: epoch 138, iter 200, loss: 2.014778, top_1: 0.761016, top_k: 0.912539, samples/s: 1360.509 1612795931.0170066
train: epoch 138, iter 300, loss: 2.024570, top_1: 0.758359, top_k: 0.912031, samples/s: 1361.968 1612795949.8132403
train: epoch 138, iter 400, loss: 2.127236, top_1: 0.751406, top_k: 0.911875, samples/s: 1354.099 1612795968.7187798
train: epoch 138, iter 500, loss: 1.994558, top_1: 0.755117, top_k: 0.907969, samples/s: 1340.013 1612795987.8230646
train: epoch 138, iter 600, loss: 1.958109, top_1: 0.753789, top_k: 0.911211, samples/s: 1335.652 1612796006.9897006
train: epoch 138, iter 700, loss: 2.015222, top_1: 0.753867, top_k: 0.909844, samples/s: 1326.972 1612796026.2817988
train: epoch 138, iter 800, loss: 1.907077, top_1: 0.757773, top_k: 0.912656, samples/s: 1334.233 1612796045.4688578
train: epoch 138, iter 900, loss: 1.982699, top_1: 0.752773, top_k: 0.909531, samples/s: 1333.256 1612796064.6699772
train: epoch 138, iter 1000, loss: 1.913799, top_1: 0.756953, top_k: 0.912266, samples/s: 1332.212 1612796083.8861582
train: epoch 138, iter 1100, loss: 2.143395, top_1: 0.751133, top_k: 0.908164, samples/s: 1334.765 1612796103.065526
train: epoch 138, iter 1200, loss: 2.111195, top_1: 0.751289, top_k: 0.909609, samples/s: 1334.661 1612796122.2463822
train: epoch 138, iter 1300, loss: 2.063725, top_1: 0.755273, top_k: 0.907813, samples/s: 1342.015 1612796141.3222218
train: epoch 138, iter 1400, loss: 1.937938, top_1: 0.754844, top_k: 0.911016, samples/s: 1334.095 1612796160.511281
train: epoch 138, iter 1500, loss: 1.882486, top_1: 0.754844, top_k: 0.910352, samples/s: 1329.287 1612796179.7696455
train: epoch 138, iter 1600, loss: 2.043766, top_1: 0.750117, top_k: 0.907383, samples/s: 1341.218 1612796198.8568177
train: epoch 138, iter 1700, loss: 1.865816, top_1: 0.753359, top_k: 0.909648, samples/s: 1335.272 1612796218.02896
train: epoch 138, iter 1800, loss: 1.936906, top_1: 0.756289, top_k: 0.911484, samples/s: 1335.311 1612796237.2004797
train: epoch 138, iter 1900, loss: 1.996809, top_1: 0.751445, top_k: 0.909062, samples/s: 1336.330 1612796256.3574667
train: epoch 138, iter 2000, loss: 2.083240, top_1: 0.751172, top_k: 0.908711, samples/s: 1332.640 1612796275.5675163
train: epoch 138, iter 2100, loss: 2.011175, top_1: 0.752617, top_k: 0.904687, samples/s: 1331.224 1612796294.797927
train: epoch 138, iter 2200, loss: 2.131697, top_1: 0.759492, top_k: 0.912461, samples/s: 1334.661 1612796313.9787693
train: epoch 138, iter 2300, loss: 2.017191, top_1: 0.752969, top_k: 0.909883, samples/s: 1340.384 1612796333.0778198
train: epoch 138, iter 2400, loss: 1.922315, top_1: 0.752188, top_k: 0.909453, samples/s: 1336.854 1612796352.2272594
train: epoch 138, iter 2500, loss: 2.010311, top_1: 0.751719, top_k: 0.909453, samples/s: 1329.335 1612796371.4849157
train: epoch 138, iter 2600, loss: 2.038222, top_1: 0.751484, top_k: 0.911797, samples/s: 1334.655 1612796390.666017
train: epoch 138, iter 2700, loss: 2.086461, top_1: 0.753945, top_k: 0.908086, samples/s: 1339.583 1612796409.7763355
train: epoch 138, iter 2800, loss: 2.065920, top_1: 0.753516, top_k: 0.908906, samples/s: 1330.175 1612796429.0219746
train: epoch 138, iter 2900, loss: 2.000618, top_1: 0.753477, top_k: 0.910742, samples/s: 1335.629 1612796448.1889763
train: epoch 138, iter 3000, loss: 1.966921, top_1: 0.752656, top_k: 0.908047, samples/s: 1338.454 1612796467.3155215
train: epoch 138, iter 3100, loss: 2.092571, top_1: 0.753359, top_k: 0.912656, samples/s: 1334.222 1612796486.5028546
train: epoch 138, iter 3200, loss: 1.963042, top_1: 0.754297, top_k: 0.909414, samples/s: 1334.430 1612796505.6870039
train: epoch 138, iter 3300, loss: 1.995794, top_1: 0.753398, top_k: 0.909727, samples/s: 1337.003 1612796524.834264
train: epoch 138, iter 3400, loss: 2.008451, top_1: 0.750078, top_k: 0.906367, samples/s: 1334.395 1612796544.0189826
train: epoch 138, iter 3500, loss: 2.114705, top_1: 0.756406, top_k: 0.908828, samples/s: 1336.322 1612796563.1760578
train: epoch 138, iter 3600, loss: 2.078538, top_1: 0.753164, top_k: 0.910625, samples/s: 1337.476 1612796582.3165836
train: epoch 138, iter 3700, loss: 1.978973, top_1: 0.756211, top_k: 0.910547, samples/s: 1335.864 1612796601.4803069
train: epoch 138, iter 3800, loss: 2.235515, top_1: 0.754766, top_k: 0.910547, samples/s: 1333.925 1612796620.6716943
train: epoch 138, iter 3900, loss: 1.977756, top_1: 0.754414, top_k: 0.907188, samples/s: 1332.331 1612796639.8862112
train: epoch 138, iter 4000, loss: 1.937244, top_1: 0.754023, top_k: 0.909687, samples/s: 1339.686 1612796658.9950519
train: epoch 138, iter 4100, loss: 2.142692, top_1: 0.749648, top_k: 0.908203, samples/s: 1325.474 1612796678.308907
train: epoch 138, iter 4200, loss: 1.973012, top_1: 0.746797, top_k: 0.905898, samples/s: 1340.230 1612796697.410164
train: epoch 138, iter 4300, loss: 1.991154, top_1: 0.756445, top_k: 0.911211, samples/s: 1338.147 1612796716.5410354
train: epoch 138, iter 4400, loss: 2.009157, top_1: 0.749805, top_k: 0.910352, samples/s: 1331.631 1612796735.76569
train: epoch 138, iter 4500, loss: 1.863664, top_1: 0.750000, top_k: 0.908164, samples/s: 1339.918 1612796754.8712416
train: epoch 138, iter 4600, loss: 2.145172, top_1: 0.751055, top_k: 0.908984, samples/s: 1341.308 1612796773.9570842
train: epoch 138, iter 4700, loss: 2.090425, top_1: 0.753203, top_k: 0.907656, samples/s: 1334.973 1612796793.1335502
train: epoch 138, iter 4800, loss: 2.083078, top_1: 0.749453, top_k: 0.908281, samples/s: 1329.999 1612796812.381743
train: epoch 138, iter 4900, loss: 2.037995, top_1: 0.754219, top_k: 0.910078, samples/s: 1337.680 1612796831.5193179
train: epoch 138, iter 5000, loss: 1.973075, top_1: 0.762891, top_k: 0.911719, samples/s: 1333.786 1612796850.7127302
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_138.
validation: epoch 138, iter 195, top_1: 0.751162, top_k: 0.925821, samples/s: 2793.407 1612796869.15233
train: epoch 139, iter 100, loss: 1.991432, top_1: 0.762266, top_k: 0.916367, samples/s: 1361.331 1612796903.816217
train: epoch 139, iter 200, loss: 2.134313, top_1: 0.756445, top_k: 0.909922, samples/s: 1362.067 1612796922.611205
train: epoch 139, iter 300, loss: 1.965010, top_1: 0.759961, top_k: 0.909883, samples/s: 1360.120 1612796941.4330313
train: epoch 139, iter 400, loss: 2.060564, top_1: 0.760586, top_k: 0.914414, samples/s: 1357.325 1612796960.2939208
train: epoch 139, iter 500, loss: 2.131656, top_1: 0.758906, top_k: 0.910937, samples/s: 1340.224 1612796979.3949
train: epoch 139, iter 600, loss: 1.920295, top_1: 0.762539, top_k: 0.914766, samples/s: 1328.039 1612796998.6715128
train: epoch 139, iter 700, loss: 2.016272, top_1: 0.763320, top_k: 0.913125, samples/s: 1329.452 1612797017.92759
train: epoch 139, iter 800, loss: 2.151314, top_1: 0.757422, top_k: 0.911875, samples/s: 1336.101 1612797037.0877357
train: epoch 139, iter 900, loss: 1.876482, top_1: 0.753437, top_k: 0.909414, samples/s: 1337.152 1612797056.2329907
train: epoch 139, iter 1000, loss: 1.970628, top_1: 0.753477, top_k: 0.912070, samples/s: 1333.384 1612797075.4321818
train: epoch 139, iter 1100, loss: 1.985889, top_1: 0.754023, top_k: 0.908242, samples/s: 1333.285 1612797094.6329222
train: epoch 139, iter 1200, loss: 2.009949, top_1: 0.757383, top_k: 0.910195, samples/s: 1332.441 1612797113.8457348
train: epoch 139, iter 1300, loss: 2.091863, top_1: 0.753945, top_k: 0.908281, samples/s: 1339.973 1612797132.9506679
train: epoch 139, iter 1400, loss: 1.998869, top_1: 0.753164, top_k: 0.912188, samples/s: 1334.545 1612797152.1332324
train: epoch 139, iter 1500, loss: 2.070548, top_1: 0.756680, top_k: 0.909258, samples/s: 1335.793 1612797171.2978103
train: epoch 139, iter 1600, loss: 1.931672, top_1: 0.760938, top_k: 0.912617, samples/s: 1338.683 1612797190.421095
train: epoch 139, iter 1700, loss: 1.862285, top_1: 0.754062, top_k: 0.908750, samples/s: 1333.593 1612797209.617387
train: epoch 139, iter 1800, loss: 1.896886, top_1: 0.756680, top_k: 0.910781, samples/s: 1333.337 1612797228.8173544
train: epoch 139, iter 1900, loss: 2.156458, top_1: 0.756406, top_k: 0.912656, samples/s: 1335.591 1612797247.9848754
train: epoch 139, iter 2000, loss: 2.062309, top_1: 0.757070, top_k: 0.912852, samples/s: 1337.883 1612797267.1195495
train: epoch 139, iter 2100, loss: 1.917948, top_1: 0.754453, top_k: 0.905156, samples/s: 1338.046 1612797286.2519352
train: epoch 139, iter 2200, loss: 2.085124, top_1: 0.757422, top_k: 0.912266, samples/s: 1335.667 1612797305.418371
train: epoch 139, iter 2300, loss: 1.857240, top_1: 0.753984, top_k: 0.911289, samples/s: 1333.893 1612797324.6103792
train: epoch 139, iter 2400, loss: 2.048884, top_1: 0.756875, top_k: 0.911641, samples/s: 1333.804 1612797343.8036492
train: epoch 139, iter 2500, loss: 2.131310, top_1: 0.762031, top_k: 0.914414, samples/s: 1343.162 1612797362.863105
train: epoch 139, iter 2600, loss: 2.012931, top_1: 0.755195, top_k: 0.909922, samples/s: 1335.993 1612797382.024825
train: epoch 139, iter 2700, loss: 1.895179, top_1: 0.749687, top_k: 0.908047, samples/s: 1334.894 1612797401.202424
train: epoch 139, iter 2800, loss: 2.034386, top_1: 0.756016, top_k: 0.912266, samples/s: 1338.276 1612797420.3315372
train: epoch 139, iter 2900, loss: 2.074653, top_1: 0.760000, top_k: 0.913359, samples/s: 1333.802 1612797439.5247831
train: epoch 139, iter 3000, loss: 1.956006, top_1: 0.757734, top_k: 0.909687, samples/s: 1335.016 1612797458.7005813
train: epoch 139, iter 3100, loss: 2.134651, top_1: 0.757383, top_k: 0.912539, samples/s: 1336.358 1612797477.857078
train: epoch 139, iter 3200, loss: 2.017437, top_1: 0.760664, top_k: 0.911563, samples/s: 1337.589 1612797496.9959853
train: epoch 139, iter 3300, loss: 2.016246, top_1: 0.754687, top_k: 0.909414, samples/s: 1340.411 1612797516.0946746
train: epoch 139, iter 3400, loss: 1.954537, top_1: 0.759102, top_k: 0.914766, samples/s: 1326.573 1612797535.3925364
train: epoch 139, iter 3500, loss: 2.022569, top_1: 0.753203, top_k: 0.904883, samples/s: 1344.996 1612797554.426004
train: epoch 139, iter 3600, loss: 2.025945, top_1: 0.753828, top_k: 0.911641, samples/s: 1335.890 1612797573.5892673
train: epoch 139, iter 3700, loss: 1.891710, top_1: 0.755352, top_k: 0.910703, samples/s: 1330.017 1612797592.8370838
train: epoch 139, iter 3800, loss: 1.920388, top_1: 0.756953, top_k: 0.910977, samples/s: 1334.496 1612797612.020348
train: epoch 139, iter 3900, loss: 2.271125, top_1: 0.754180, top_k: 0.909531, samples/s: 1341.926 1612797631.0974882
train: epoch 139, iter 4000, loss: 2.026986, top_1: 0.761211, top_k: 0.914414, samples/s: 1332.747 1612797650.3059115
train: epoch 139, iter 4100, loss: 1.937321, top_1: 0.755820, top_k: 0.914492, samples/s: 1335.038 1612797669.481322
train: epoch 139, iter 4200, loss: 1.984840, top_1: 0.754219, top_k: 0.910078, samples/s: 1338.249 1612797688.610828
train: epoch 139, iter 4300, loss: 2.072429, top_1: 0.757852, top_k: 0.912695, samples/s: 1333.446 1612797707.8091624
train: epoch 139, iter 4400, loss: 2.064263, top_1: 0.758672, top_k: 0.912305, samples/s: 1343.090 1612797726.8697405
train: epoch 139, iter 4500, loss: 2.086966, top_1: 0.753477, top_k: 0.909687, samples/s: 1337.039 1612797746.01651
train: epoch 139, iter 4600, loss: 2.000090, top_1: 0.755234, top_k: 0.910469, samples/s: 1336.886 1612797765.1654546
train: epoch 139, iter 4700, loss: 1.947242, top_1: 0.758086, top_k: 0.913008, samples/s: 1335.736 1612797784.330911
train: epoch 139, iter 4800, loss: 1.973925, top_1: 0.753594, top_k: 0.912461, samples/s: 1333.382 1612797803.530293
train: epoch 139, iter 4900, loss: 2.104235, top_1: 0.761680, top_k: 0.912656, samples/s: 1333.501 1612797822.7278914
train: epoch 139, iter 5000, loss: 2.038137, top_1: 0.761523, top_k: 0.915820, samples/s: 1343.373 1612797841.7843025
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_139.
validation: epoch 139, iter 195, top_1: 0.750601, top_k: 0.926663, samples/s: 2796.550 1612797860.2816112
train: epoch 140, iter 100, loss: 1.976215, top_1: 0.765195, top_k: 0.915898, samples/s: 1362.605 1612797894.6125965
train: epoch 140, iter 200, loss: 2.164163, top_1: 0.762852, top_k: 0.916250, samples/s: 1363.284 1612797913.3907788
train: epoch 140, iter 300, loss: 2.039755, top_1: 0.763789, top_k: 0.915156, samples/s: 1357.761 1612797932.2452407
train: epoch 140, iter 400, loss: 1.804708, top_1: 0.767617, top_k: 0.917188, samples/s: 1356.620 1612797951.115681
train: epoch 140, iter 500, loss: 2.098587, top_1: 0.762539, top_k: 0.914805, samples/s: 1341.151 1612797970.2037325
train: epoch 140, iter 600, loss: 2.026948, top_1: 0.760273, top_k: 0.912109, samples/s: 1328.500 1612797989.4735532
train: epoch 140, iter 700, loss: 1.973922, top_1: 0.762891, top_k: 0.915937, samples/s: 1337.096 1612798008.6195915
train: epoch 140, iter 800, loss: 1.928471, top_1: 0.765508, top_k: 0.917578, samples/s: 1338.889 1612798027.7398717
train: epoch 140, iter 900, loss: 1.948134, top_1: 0.759883, top_k: 0.911641, samples/s: 1332.197 1612798046.9562743
train: epoch 140, iter 1000, loss: 2.082263, top_1: 0.759883, top_k: 0.914258, samples/s: 1331.824 1612798066.1780906
train: epoch 140, iter 1100, loss: 2.074903, top_1: 0.759180, top_k: 0.909531, samples/s: 1331.756 1612798085.4008226
train: epoch 140, iter 1200, loss: 2.068718, top_1: 0.761484, top_k: 0.913516, samples/s: 1332.861 1612798104.6076014
train: epoch 140, iter 1300, loss: 1.961167, top_1: 0.763477, top_k: 0.914805, samples/s: 1330.908 1612798123.8425822
train: epoch 140, iter 1400, loss: 2.017236, top_1: 0.761016, top_k: 0.913281, samples/s: 1333.024 1612798143.0469942
train: epoch 140, iter 1500, loss: 1.973974, top_1: 0.760312, top_k: 0.911875, samples/s: 1340.751 1612798162.1408598
train: epoch 140, iter 1600, loss: 2.112194, top_1: 0.759961, top_k: 0.913945, samples/s: 1330.105 1612798181.3874242
train: epoch 140, iter 1700, loss: 1.941875, top_1: 0.755234, top_k: 0.910039, samples/s: 1337.705 1612798200.5246866
train: epoch 140, iter 1800, loss: 2.139230, top_1: 0.758945, top_k: 0.908281, samples/s: 1338.567 1612798219.649603
train: epoch 140, iter 1900, loss: 1.961770, top_1: 0.764141, top_k: 0.915508, samples/s: 1336.293 1612798238.8070498
train: epoch 140, iter 2000, loss: 1.942015, top_1: 0.763086, top_k: 0.913477, samples/s: 1333.006 1612798258.011751
train: epoch 140, iter 2100, loss: 1.927805, top_1: 0.760430, top_k: 0.913945, samples/s: 1329.854 1612798277.2621062
train: epoch 140, iter 2200, loss: 1.954320, top_1: 0.759414, top_k: 0.911758, samples/s: 1341.654 1612798296.343011
train: epoch 140, iter 2300, loss: 1.952493, top_1: 0.757500, top_k: 0.912773, samples/s: 1334.875 1612798315.5207396
train: epoch 140, iter 2400, loss: 2.012264, top_1: 0.758008, top_k: 0.913594, samples/s: 1335.493 1612798334.6897163
train: epoch 140, iter 2500, loss: 1.910149, top_1: 0.757539, top_k: 0.910781, samples/s: 1336.505 1612798353.8441894
train: epoch 140, iter 2600, loss: 1.962686, top_1: 0.764062, top_k: 0.916133, samples/s: 1334.804 1612798373.0229983
train: epoch 140, iter 2700, loss: 2.064588, top_1: 0.760820, top_k: 0.910898, samples/s: 1337.717 1612798392.1601167
train: epoch 140, iter 2800, loss: 2.020508, top_1: 0.754219, top_k: 0.911367, samples/s: 1330.252 1612798411.404605
train: epoch 140, iter 2900, loss: 1.995309, top_1: 0.760156, top_k: 0.915312, samples/s: 1338.545 1612798430.529836
train: epoch 140, iter 3000, loss: 1.906756, top_1: 0.758906, top_k: 0.913477, samples/s: 1339.664 1612798449.6390593
train: epoch 140, iter 3100, loss: 2.050983, top_1: 0.756328, top_k: 0.909961, samples/s: 1339.521 1612798468.7504137
train: epoch 140, iter 3200, loss: 1.966261, top_1: 0.758008, top_k: 0.912617, samples/s: 1338.768 1612798487.872464
train: epoch 140, iter 3300, loss: 1.957731, top_1: 0.755938, top_k: 0.911328, samples/s: 1325.415 1612798507.187104
train: epoch 140, iter 3400, loss: 2.035452, top_1: 0.757852, top_k: 0.910820, samples/s: 1333.689 1612798526.3820112
train: epoch 140, iter 3500, loss: 2.037042, top_1: 0.756641, top_k: 0.909844, samples/s: 1339.740 1612798545.4901643
train: epoch 140, iter 3600, loss: 1.904669, top_1: 0.755977, top_k: 0.914961, samples/s: 1327.014 1612798564.7815895
train: epoch 140, iter 3700, loss: 2.099036, top_1: 0.754102, top_k: 0.909453, samples/s: 1344.530 1612798583.821703
train: epoch 140, iter 3800, loss: 2.013461, top_1: 0.759727, top_k: 0.912852, samples/s: 1330.812 1612798603.058129
train: epoch 140, iter 3900, loss: 1.929437, top_1: 0.757734, top_k: 0.908477, samples/s: 1337.107 1612798622.2039783
train: epoch 140, iter 4000, loss: 1.815460, top_1: 0.762422, top_k: 0.913242, samples/s: 1333.099 1612798641.4073255
train: epoch 140, iter 4100, loss: 2.000808, top_1: 0.759844, top_k: 0.914023, samples/s: 1334.413 1612798660.5917146
train: epoch 140, iter 4200, loss: 2.027089, top_1: 0.761719, top_k: 0.914375, samples/s: 1336.837 1612798679.741427
train: epoch 140, iter 4300, loss: 2.027320, top_1: 0.761055, top_k: 0.912813, samples/s: 1334.950 1612798698.9182625
train: epoch 140, iter 4400, loss: 1.985364, top_1: 0.755117, top_k: 0.911563, samples/s: 1337.899 1612798718.0526984
train: epoch 140, iter 4500, loss: 2.168344, top_1: 0.758359, top_k: 0.915703, samples/s: 1338.756 1612798737.1749237
train: epoch 140, iter 4600, loss: 2.081471, top_1: 0.759180, top_k: 0.911875, samples/s: 1334.549 1612798756.357484
train: epoch 140, iter 4700, loss: 1.960346, top_1: 0.762578, top_k: 0.915664, samples/s: 1341.918 1612798775.4345818
train: epoch 140, iter 4800, loss: 2.086480, top_1: 0.759180, top_k: 0.910664, samples/s: 1337.316 1612798794.577421
train: epoch 140, iter 4900, loss: 2.068939, top_1: 0.761719, top_k: 0.914141, samples/s: 1327.532 1612798813.8612874
train: epoch 140, iter 5000, loss: 2.040084, top_1: 0.761680, top_k: 0.912461, samples/s: 1341.948 1612798832.9380221
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_140.
validation: epoch 140, iter 195, top_1: 0.753866, top_k: 0.928185, samples/s: 2770.130 1612798851.5303721
train: epoch 141, iter 100, loss: 1.970714, top_1: 0.768945, top_k: 0.915352, samples/s: 1360.353 1612798892.0598283
train: epoch 141, iter 200, loss: 1.785365, top_1: 0.764844, top_k: 0.914570, samples/s: 1358.715 1612798910.901359
train: epoch 141, iter 300, loss: 1.957744, top_1: 0.764375, top_k: 0.917891, samples/s: 1357.908 1612798929.7535641
train: epoch 141, iter 400, loss: 1.844229, top_1: 0.769375, top_k: 0.918750, samples/s: 1358.952 1612798948.5916572
train: epoch 141, iter 500, loss: 1.920269, top_1: 0.767383, top_k: 0.915312, samples/s: 1343.166 1612798967.651135
train: epoch 141, iter 600, loss: 1.991196, top_1: 0.771250, top_k: 0.917500, samples/s: 1336.584 1612798986.8043902
train: epoch 141, iter 700, loss: 2.047743, top_1: 0.759687, top_k: 0.914297, samples/s: 1331.978 1612799006.0238955
train: epoch 141, iter 800, loss: 2.067720, top_1: 0.763398, top_k: 0.913047, samples/s: 1331.501 1612799025.2503152
train: epoch 141, iter 900, loss: 1.926230, top_1: 0.764453, top_k: 0.915391, samples/s: 1320.341 1612799044.6392624
train: epoch 141, iter 1000, loss: 1.952725, top_1: 0.764453, top_k: 0.916328, samples/s: 1336.731 1612799063.790511
train: epoch 141, iter 1100, loss: 2.025095, top_1: 0.765312, top_k: 0.915156, samples/s: 1333.929 1612799082.9818728
train: epoch 141, iter 1200, loss: 2.005828, top_1: 0.763203, top_k: 0.915391, samples/s: 1334.194 1612799102.1695085
train: epoch 141, iter 1300, loss: 1.944985, top_1: 0.763008, top_k: 0.910156, samples/s: 1330.915 1612799121.4043624
train: epoch 141, iter 1400, loss: 1.854056, top_1: 0.761211, top_k: 0.912852, samples/s: 1332.459 1612799140.6169949
train: epoch 141, iter 1500, loss: 2.130864, top_1: 0.766133, top_k: 0.913008, samples/s: 1331.634 1612799159.8415258
train: epoch 141, iter 1600, loss: 1.927181, top_1: 0.761953, top_k: 0.915117, samples/s: 1325.304 1612799179.1578948
train: epoch 141, iter 1700, loss: 1.986251, top_1: 0.767109, top_k: 0.914102, samples/s: 1339.858 1612799198.264381
train: epoch 141, iter 1800, loss: 2.027030, top_1: 0.763945, top_k: 0.915859, samples/s: 1331.795 1612799217.486474
train: epoch 141, iter 1900, loss: 2.060528, top_1: 0.766094, top_k: 0.915781, samples/s: 1329.828 1612799236.7370849
train: epoch 141, iter 2000, loss: 2.017874, top_1: 0.764453, top_k: 0.915156, samples/s: 1335.769 1612799255.902061
train: epoch 141, iter 2100, loss: 2.088132, top_1: 0.761484, top_k: 0.912344, samples/s: 1323.367 1612799275.246711
train: epoch 141, iter 2200, loss: 1.904410, top_1: 0.766523, top_k: 0.915234, samples/s: 1331.846 1612799294.4681118
train: epoch 141, iter 2300, loss: 2.023049, top_1: 0.762773, top_k: 0.914375, samples/s: 1331.854 1612799313.6894555
train: epoch 141, iter 2400, loss: 2.012742, top_1: 0.763633, top_k: 0.912617, samples/s: 1333.969 1612799332.8803267
train: epoch 141, iter 2500, loss: 1.872493, top_1: 0.767773, top_k: 0.913281, samples/s: 1331.580 1612799352.1055639
train: epoch 141, iter 2600, loss: 2.020032, top_1: 0.763633, top_k: 0.915000, samples/s: 1333.132 1612799371.308513
train: epoch 141, iter 2700, loss: 1.975076, top_1: 0.767969, top_k: 0.916680, samples/s: 1334.822 1612799390.4870372
train: epoch 141, iter 2800, loss: 2.038822, top_1: 0.759492, top_k: 0.910117, samples/s: 1326.602 1612799409.7845263
train: epoch 141, iter 2900, loss: 2.019521, top_1: 0.760742, top_k: 0.915352, samples/s: 1332.921 1612799428.9904776
train: epoch 141, iter 3000, loss: 1.902838, top_1: 0.761563, top_k: 0.912344, samples/s: 1337.426 1612799448.1316547
train: epoch 141, iter 3100, loss: 1.874635, top_1: 0.767188, top_k: 0.918633, samples/s: 1328.630 1612799467.3996642
train: epoch 141, iter 3200, loss: 2.075645, top_1: 0.763437, top_k: 0.914062, samples/s: 1333.101 1612799486.6030335
train: epoch 141, iter 3300, loss: 1.780692, top_1: 0.765859, top_k: 0.917070, samples/s: 1328.520 1612799505.8725646
train: epoch 141, iter 3400, loss: 1.913111, top_1: 0.764648, top_k: 0.912773, samples/s: 1335.371 1612799525.0433574
train: epoch 141, iter 3500, loss: 1.971899, top_1: 0.761914, top_k: 0.913594, samples/s: 1328.741 1612799544.3095908
train: epoch 141, iter 3600, loss: 2.058796, top_1: 0.763242, top_k: 0.917109, samples/s: 1336.831 1612799563.459415
train: epoch 141, iter 3700, loss: 2.148147, top_1: 0.762305, top_k: 0.912031, samples/s: 1335.143 1612799582.6333764
train: epoch 141, iter 3800, loss: 2.030173, top_1: 0.764453, top_k: 0.915781, samples/s: 1332.471 1612799601.845789
train: epoch 141, iter 3900, loss: 2.113224, top_1: 0.761289, top_k: 0.913672, samples/s: 1319.630 1612799621.2452943
train: epoch 141, iter 4000, loss: 2.010528, top_1: 0.763242, top_k: 0.911914, samples/s: 1339.755 1612799640.3531857
train: epoch 141, iter 4100, loss: 1.917430, top_1: 0.764219, top_k: 0.914453, samples/s: 1340.139 1612799659.4555998
train: epoch 141, iter 4200, loss: 1.857959, top_1: 0.766445, top_k: 0.915859, samples/s: 1334.846 1612799678.633922
train: epoch 141, iter 4300, loss: 1.935740, top_1: 0.763594, top_k: 0.914414, samples/s: 1326.734 1612799697.9293904
train: epoch 141, iter 4400, loss: 1.960875, top_1: 0.758008, top_k: 0.913828, samples/s: 1331.241 1612799717.1596437
train: epoch 141, iter 4500, loss: 1.926083, top_1: 0.765781, top_k: 0.916367, samples/s: 1337.291 1612799736.302705
train: epoch 141, iter 4600, loss: 1.846228, top_1: 0.758672, top_k: 0.914219, samples/s: 1326.610 1612799755.600021
train: epoch 141, iter 4700, loss: 1.966458, top_1: 0.760938, top_k: 0.912891, samples/s: 1335.804 1612799774.7645512
train: epoch 141, iter 4800, loss: 2.031927, top_1: 0.764375, top_k: 0.914062, samples/s: 1336.682 1612799793.916449
train: epoch 141, iter 4900, loss: 2.184312, top_1: 0.759414, top_k: 0.913008, samples/s: 1334.654 1612799813.0974455
train: epoch 141, iter 5000, loss: 1.962330, top_1: 0.762891, top_k: 0.915234, samples/s: 1333.094 1612799832.300843
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_141.
validation: epoch 141, iter 195, top_1: 0.749179, top_k: 0.926342, samples/s: 2807.132 1612799850.663035
train: epoch 142, iter 100, loss: 2.036930, top_1: 0.770938, top_k: 0.918242, samples/s: 1360.942 1612799885.5239873
train: epoch 142, iter 200, loss: 1.977897, top_1: 0.768867, top_k: 0.919648, samples/s: 1359.511 1612799904.3541844
train: epoch 142, iter 300, loss: 2.018844, top_1: 0.765859, top_k: 0.914023, samples/s: 1362.702 1612799923.140382
train: epoch 142, iter 400, loss: 1.922208, top_1: 0.768242, top_k: 0.916406, samples/s: 1358.077 1612799941.9905736
train: epoch 142, iter 500, loss: 1.960990, top_1: 0.764766, top_k: 0.916875, samples/s: 1342.520 1612799961.0592377
train: epoch 142, iter 600, loss: 2.017473, top_1: 0.765938, top_k: 0.918750, samples/s: 1327.338 1612799980.345942
train: epoch 142, iter 700, loss: 2.114329, top_1: 0.765977, top_k: 0.915000, samples/s: 1338.304 1612799999.4746356
train: epoch 142, iter 800, loss: 2.103859, top_1: 0.762734, top_k: 0.913125, samples/s: 1331.055 1612800018.7075126
train: epoch 142, iter 900, loss: 1.848165, top_1: 0.768516, top_k: 0.915234, samples/s: 1333.105 1612800037.9107256
train: epoch 142, iter 1000, loss: 1.863435, top_1: 0.767695, top_k: 0.915742, samples/s: 1338.762 1612800057.0329213
train: epoch 142, iter 1100, loss: 2.039313, top_1: 0.765312, top_k: 0.916367, samples/s: 1328.208 1612800076.307018
train: epoch 142, iter 1200, loss: 2.007473, top_1: 0.771367, top_k: 0.920195, samples/s: 1333.255 1612800095.5081758
train: epoch 142, iter 1300, loss: 2.015519, top_1: 0.764922, top_k: 0.915625, samples/s: 1337.637 1612800114.646363
train: epoch 142, iter 1400, loss: 1.888075, top_1: 0.772305, top_k: 0.918242, samples/s: 1337.559 1612800133.7856596
train: epoch 142, iter 1500, loss: 1.977043, top_1: 0.767656, top_k: 0.919063, samples/s: 1335.678 1612800152.951968
train: epoch 142, iter 1600, loss: 2.092918, top_1: 0.765664, top_k: 0.913281, samples/s: 1339.633 1612800172.0616555
train: epoch 142, iter 1700, loss: 1.899565, top_1: 0.766680, top_k: 0.918164, samples/s: 1329.186 1612800191.321564
train: epoch 142, iter 1800, loss: 1.938721, top_1: 0.766992, top_k: 0.916641, samples/s: 1334.964 1612800210.498232
train: epoch 142, iter 1900, loss: 1.947847, top_1: 0.761328, top_k: 0.912539, samples/s: 1338.656 1612800229.621769
train: epoch 142, iter 2000, loss: 2.021654, top_1: 0.771523, top_k: 0.919063, samples/s: 1333.007 1612800248.826606
train: epoch 142, iter 2100, loss: 2.072099, top_1: 0.774297, top_k: 0.920547, samples/s: 1336.838 1612800267.9762197
train: epoch 142, iter 2200, loss: 2.009432, top_1: 0.766680, top_k: 0.915820, samples/s: 1336.275 1612800287.1338787
train: epoch 142, iter 2300, loss: 1.972117, top_1: 0.765469, top_k: 0.913008, samples/s: 1336.800 1612800306.2840536
train: epoch 142, iter 2400, loss: 2.097512, top_1: 0.770430, top_k: 0.917109, samples/s: 1336.952 1612800325.432178
train: epoch 142, iter 2500, loss: 1.993074, top_1: 0.767227, top_k: 0.914766, samples/s: 1338.884 1612800344.5524886
train: epoch 142, iter 2600, loss: 1.838193, top_1: 0.764492, top_k: 0.911484, samples/s: 1330.643 1612800363.7913108
train: epoch 142, iter 2700, loss: 1.936315, top_1: 0.767539, top_k: 0.915625, samples/s: 1327.650 1612800383.0735247
train: epoch 142, iter 2800, loss: 1.905068, top_1: 0.768828, top_k: 0.915039, samples/s: 1342.901 1612800402.1367075
train: epoch 142, iter 2900, loss: 1.906497, top_1: 0.765938, top_k: 0.915391, samples/s: 1327.634 1612800421.4191408
train: epoch 142, iter 3000, loss: 1.929930, top_1: 0.766875, top_k: 0.915586, samples/s: 1327.234 1612800440.7073748
train: epoch 142, iter 3100, loss: 2.031086, top_1: 0.767148, top_k: 0.915898, samples/s: 1338.014 1612800459.8402793
train: epoch 142, iter 3200, loss: 1.962631, top_1: 0.765859, top_k: 0.913828, samples/s: 1337.256 1612800478.9838767
train: epoch 142, iter 3300, loss: 1.972144, top_1: 0.763281, top_k: 0.914336, samples/s: 1335.230 1612800498.1566548
train: epoch 142, iter 3400, loss: 2.011387, top_1: 0.768164, top_k: 0.916328, samples/s: 1333.772 1612800517.3503485
train: epoch 142, iter 3500, loss: 2.120563, top_1: 0.766250, top_k: 0.916602, samples/s: 1330.807 1612800536.5868344
train: epoch 142, iter 3600, loss: 1.951832, top_1: 0.760430, top_k: 0.915742, samples/s: 1343.778 1612800555.6376264
train: epoch 142, iter 3700, loss: 1.935604, top_1: 0.769219, top_k: 0.916875, samples/s: 1338.579 1612800574.7623892
train: epoch 142, iter 3800, loss: 2.057821, top_1: 0.765430, top_k: 0.917734, samples/s: 1342.372 1612800593.8331087
train: epoch 142, iter 3900, loss: 1.930999, top_1: 0.764531, top_k: 0.914297, samples/s: 1344.495 1612800612.8736653
train: epoch 142, iter 4000, loss: 2.173497, top_1: 0.768633, top_k: 0.915937, samples/s: 1330.141 1612800632.1197622
train: epoch 142, iter 4100, loss: 2.030898, top_1: 0.764570, top_k: 0.914258, samples/s: 1340.312 1612800651.2197492
train: epoch 142, iter 4200, loss: 1.890436, top_1: 0.762148, top_k: 0.916992, samples/s: 1342.074 1612800670.2947457
train: epoch 142, iter 4300, loss: 1.991613, top_1: 0.763555, top_k: 0.915977, samples/s: 1336.700 1612800689.4463499
train: epoch 142, iter 4400, loss: 1.909314, top_1: 0.761172, top_k: 0.912148, samples/s: 1334.767 1612800708.6257603
train: epoch 142, iter 4500, loss: 1.914310, top_1: 0.766289, top_k: 0.917656, samples/s: 1340.444 1612800727.7239048
train: epoch 142, iter 4600, loss: 1.898625, top_1: 0.765742, top_k: 0.913867, samples/s: 1337.512 1612800746.863881
train: epoch 142, iter 4700, loss: 1.905979, top_1: 0.769922, top_k: 0.916445, samples/s: 1339.340 1612800765.977811
train: epoch 142, iter 4800, loss: 1.967266, top_1: 0.769805, top_k: 0.917617, samples/s: 1335.352 1612800785.1487277
train: epoch 142, iter 4900, loss: 2.050013, top_1: 0.768281, top_k: 0.914609, samples/s: 1335.147 1612800804.3226874
train: epoch 142, iter 5000, loss: 2.183804, top_1: 0.769336, top_k: 0.915742, samples/s: 1339.896 1612800823.4286065
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_142.
validation: epoch 142, iter 195, top_1: 0.756510, top_k: 0.928726, samples/s: 2835.135 1612800841.6282928
train: epoch 143, iter 100, loss: 1.934439, top_1: 0.771133, top_k: 0.916133, samples/s: 1358.860 1612800876.3455892
train: epoch 143, iter 200, loss: 1.906099, top_1: 0.771953, top_k: 0.918438, samples/s: 1361.480 1612800895.1488888
train: epoch 143, iter 300, loss: 2.163675, top_1: 0.771953, top_k: 0.918125, samples/s: 1360.494 1612800913.9653661
train: epoch 143, iter 400, loss: 1.893699, top_1: 0.770781, top_k: 0.917148, samples/s: 1357.180 1612800932.8279688
train: epoch 143, iter 500, loss: 1.912278, top_1: 0.763672, top_k: 0.916133, samples/s: 1336.877 1612800951.9770682
train: epoch 143, iter 600, loss: 1.859174, top_1: 0.771797, top_k: 0.917852, samples/s: 1334.748 1612800971.1567101
train: epoch 143, iter 700, loss: 2.036496, top_1: 0.769727, top_k: 0.917070, samples/s: 1337.560 1612800990.2960007
train: epoch 143, iter 800, loss: 1.858600, top_1: 0.777891, top_k: 0.919180, samples/s: 1338.984 1612801009.4150076
train: epoch 143, iter 900, loss: 1.857757, top_1: 0.775273, top_k: 0.920430, samples/s: 1336.905 1612801028.5637321
train: epoch 143, iter 1000, loss: 2.171875, top_1: 0.767813, top_k: 0.918555, samples/s: 1333.960 1612801047.7547252
train: epoch 143, iter 1100, loss: 1.961674, top_1: 0.768086, top_k: 0.917422, samples/s: 1335.846 1612801066.9186103
train: epoch 143, iter 1200, loss: 2.039489, top_1: 0.768242, top_k: 0.917344, samples/s: 1343.258 1612801085.9767258
train: epoch 143, iter 1300, loss: 1.948245, top_1: 0.769961, top_k: 0.915977, samples/s: 1330.292 1612801105.2205877
train: epoch 143, iter 1400, loss: 1.852651, top_1: 0.771719, top_k: 0.920117, samples/s: 1337.800 1612801124.3565931
train: epoch 143, iter 1500, loss: 1.879958, top_1: 0.768125, top_k: 0.918750, samples/s: 1334.781 1612801143.5357342
train: epoch 143, iter 1600, loss: 1.870677, top_1: 0.769023, top_k: 0.918477, samples/s: 1336.080 1612801162.6962082
train: epoch 143, iter 1700, loss: 1.913897, top_1: 0.771055, top_k: 0.916562, samples/s: 1342.167 1612801181.7698827
train: epoch 143, iter 1800, loss: 1.898983, top_1: 0.771211, top_k: 0.915547, samples/s: 1338.747 1612801200.8922534
train: epoch 143, iter 1900, loss: 1.975090, top_1: 0.769414, top_k: 0.916289, samples/s: 1338.624 1612801220.0163722
train: epoch 143, iter 2000, loss: 1.974135, top_1: 0.767969, top_k: 0.918711, samples/s: 1333.732 1612801239.2105672
train: epoch 143, iter 2100, loss: 1.949098, top_1: 0.773320, top_k: 0.919336, samples/s: 1339.734 1612801258.3188283
train: epoch 143, iter 2200, loss: 1.992315, top_1: 0.770898, top_k: 0.918242, samples/s: 1332.418 1612801277.532089
train: epoch 143, iter 2300, loss: 2.035953, top_1: 0.766641, top_k: 0.916875, samples/s: 1340.732 1612801296.626067
train: epoch 143, iter 2400, loss: 2.008584, top_1: 0.767227, top_k: 0.916641, samples/s: 1336.917 1612801315.7746391
train: epoch 143, iter 2500, loss: 2.001469, top_1: 0.769375, top_k: 0.917227, samples/s: 1334.919 1612801334.9518192
train: epoch 143, iter 2600, loss: 1.895390, top_1: 0.768906, top_k: 0.918906, samples/s: 1336.861 1612801354.1011975
train: epoch 143, iter 2700, loss: 2.104134, top_1: 0.766328, top_k: 0.917773, samples/s: 1331.679 1612801373.3250835
train: epoch 143, iter 2800, loss: 2.156131, top_1: 0.771055, top_k: 0.918320, samples/s: 1339.900 1612801392.430891
train: epoch 143, iter 2900, loss: 1.999153, top_1: 0.770703, top_k: 0.918203, samples/s: 1339.603 1612801411.5411253
train: epoch 143, iter 3000, loss: 2.067926, top_1: 0.769102, top_k: 0.915977, samples/s: 1331.908 1612801430.7615867
train: epoch 143, iter 3100, loss: 2.011858, top_1: 0.773203, top_k: 0.919570, samples/s: 1337.302 1612801449.904612
train: epoch 143, iter 3200, loss: 2.006974, top_1: 0.768359, top_k: 0.915391, samples/s: 1339.887 1612801469.0107331
train: epoch 143, iter 3300, loss: 1.969771, top_1: 0.767813, top_k: 0.916406, samples/s: 1336.456 1612801488.1658962
train: epoch 143, iter 3400, loss: 1.870242, top_1: 0.770469, top_k: 0.917695, samples/s: 1336.161 1612801507.3252182
train: epoch 143, iter 3500, loss: 1.847865, top_1: 0.772656, top_k: 0.921172, samples/s: 1345.564 1612801526.3507407
train: epoch 143, iter 3600, loss: 1.962307, top_1: 0.765078, top_k: 0.916094, samples/s: 1323.239 1612801545.6972535
train: epoch 143, iter 3700, loss: 2.061783, top_1: 0.771211, top_k: 0.915625, samples/s: 1351.615 1612801564.637489
train: epoch 143, iter 3800, loss: 1.935456, top_1: 0.767617, top_k: 0.915469, samples/s: 1337.141 1612801583.7828455
train: epoch 143, iter 3900, loss: 2.134377, top_1: 0.767070, top_k: 0.918164, samples/s: 1335.709 1612801602.948636
train: epoch 143, iter 4000, loss: 1.957698, top_1: 0.767813, top_k: 0.916172, samples/s: 1343.069 1612801622.0094602
train: epoch 143, iter 4100, loss: 2.129049, top_1: 0.770352, top_k: 0.920781, samples/s: 1336.755 1612801641.1603491
train: epoch 143, iter 4200, loss: 1.914329, top_1: 0.765508, top_k: 0.914102, samples/s: 1336.690 1612801660.312097
train: epoch 143, iter 4300, loss: 1.904355, top_1: 0.768555, top_k: 0.914922, samples/s: 1341.169 1612801679.3999796
train: epoch 143, iter 4400, loss: 1.837624, top_1: 0.767266, top_k: 0.916680, samples/s: 1330.709 1612801698.6378245
train: epoch 143, iter 4500, loss: 2.020986, top_1: 0.769766, top_k: 0.915469, samples/s: 1344.685 1612801717.6757886
train: epoch 143, iter 4600, loss: 1.878901, top_1: 0.768437, top_k: 0.916758, samples/s: 1339.002 1612801736.7944484
train: epoch 143, iter 4700, loss: 1.913504, top_1: 0.767383, top_k: 0.918672, samples/s: 1329.922 1612801756.0436902
train: epoch 143, iter 4800, loss: 1.841363, top_1: 0.771484, top_k: 0.918203, samples/s: 1339.628 1612801775.1535294
train: epoch 143, iter 4900, loss: 1.928957, top_1: 0.773164, top_k: 0.917813, samples/s: 1339.776 1612801794.2611961
train: epoch 143, iter 5000, loss: 1.913889, top_1: 0.771563, top_k: 0.919063, samples/s: 1341.162 1612801813.3491201
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_143.
validation: epoch 143, iter 195, top_1: 0.758694, top_k: 0.929447, samples/s: 2794.469 1612801831.7879357
train: epoch 144, iter 100, loss: 1.984836, top_1: 0.778242, top_k: 0.919727, samples/s: 1363.856 1612801866.3131776
train: epoch 144, iter 200, loss: 1.938735, top_1: 0.776133, top_k: 0.918945, samples/s: 1356.188 1612801885.189583
train: epoch 144, iter 300, loss: 1.932578, top_1: 0.774570, top_k: 0.918242, samples/s: 1363.416 1612801903.9660993
train: epoch 144, iter 400, loss: 2.027337, top_1: 0.776328, top_k: 0.918984, samples/s: 1356.068 1612801922.8440654
train: epoch 144, iter 500, loss: 1.918496, top_1: 0.773945, top_k: 0.918711, samples/s: 1338.958 1612801941.9634466
train: epoch 144, iter 600, loss: 1.892577, top_1: 0.772695, top_k: 0.920977, samples/s: 1333.731 1612801961.1576548
train: epoch 144, iter 700, loss: 1.903399, top_1: 0.775391, top_k: 0.916328, samples/s: 1338.523 1612801980.283253
train: epoch 144, iter 800, loss: 1.880672, top_1: 0.773711, top_k: 0.917305, samples/s: 1340.442 1612801999.38146
train: epoch 144, iter 900, loss: 2.095708, top_1: 0.772734, top_k: 0.920625, samples/s: 1318.281 1612802018.8006623
train: epoch 144, iter 1000, loss: 1.996757, top_1: 0.768633, top_k: 0.918633, samples/s: 1345.286 1612802037.8300872
train: epoch 144, iter 1100, loss: 1.876068, top_1: 0.775352, top_k: 0.919531, samples/s: 1335.250 1612802057.0024703
train: epoch 144, iter 1200, loss: 2.181649, top_1: 0.772695, top_k: 0.917813, samples/s: 1331.295 1612802076.2319846
train: epoch 144, iter 1300, loss: 1.944462, top_1: 0.771758, top_k: 0.918125, samples/s: 1338.744 1612802095.3542829
train: epoch 144, iter 1400, loss: 1.824667, top_1: 0.777500, top_k: 0.921562, samples/s: 1334.821 1612802114.5329113
train: epoch 144, iter 1500, loss: 2.011098, top_1: 0.770156, top_k: 0.917813, samples/s: 1336.271 1612802133.6906762
train: epoch 144, iter 1600, loss: 1.870329, top_1: 0.775352, top_k: 0.916797, samples/s: 1338.185 1612802152.8211765
train: epoch 144, iter 1700, loss: 1.909839, top_1: 0.773594, top_k: 0.919219, samples/s: 1340.398 1612802171.9199557
train: epoch 144, iter 1800, loss: 1.912724, top_1: 0.771250, top_k: 0.919727, samples/s: 1333.409 1612802191.118827
train: epoch 144, iter 1900, loss: 1.970324, top_1: 0.770586, top_k: 0.918711, samples/s: 1338.768 1612802210.240857
train: epoch 144, iter 2000, loss: 2.047646, top_1: 0.772422, top_k: 0.919453, samples/s: 1338.440 1612802229.367641
train: epoch 144, iter 2100, loss: 1.982049, top_1: 0.769102, top_k: 0.916250, samples/s: 1329.981 1612802248.615969
train: epoch 144, iter 2200, loss: 1.968204, top_1: 0.773438, top_k: 0.919023, samples/s: 1338.573 1612802267.7408476
train: epoch 144, iter 2300, loss: 2.030114, top_1: 0.769414, top_k: 0.914414, samples/s: 1340.681 1612802286.835624
train: epoch 144, iter 2400, loss: 1.906371, top_1: 0.772461, top_k: 0.915820, samples/s: 1333.147 1612802306.0382895
train: epoch 144, iter 2500, loss: 2.045491, top_1: 0.773633, top_k: 0.916602, samples/s: 1339.755 1612802325.1463895
train: epoch 144, iter 2600, loss: 1.909899, top_1: 0.776641, top_k: 0.920703, samples/s: 1340.795 1612802344.239397
train: epoch 144, iter 2700, loss: 1.987500, top_1: 0.764336, top_k: 0.914609, samples/s: 1326.571 1612802363.5373166
train: epoch 144, iter 2800, loss: 1.988308, top_1: 0.769062, top_k: 0.918633, samples/s: 1338.074 1612802382.669308
train: epoch 144, iter 2900, loss: 1.981281, top_1: 0.774336, top_k: 0.919063, samples/s: 1333.667 1612802401.8645208
train: epoch 144, iter 3000, loss: 1.842354, top_1: 0.773242, top_k: 0.920312, samples/s: 1344.384 1612802420.9066548
train: epoch 144, iter 3100, loss: 1.862062, top_1: 0.774180, top_k: 0.920898, samples/s: 1341.932 1612802439.9837234
train: epoch 144, iter 3200, loss: 2.006010, top_1: 0.768711, top_k: 0.915000, samples/s: 1333.389 1612802459.182781
train: epoch 144, iter 3300, loss: 2.026748, top_1: 0.766523, top_k: 0.916445, samples/s: 1330.943 1612802478.4172747
train: epoch 144, iter 3400, loss: 2.064220, top_1: 0.769609, top_k: 0.917266, samples/s: 1330.274 1612802497.661492
train: epoch 144, iter 3500, loss: 2.016720, top_1: 0.769023, top_k: 0.917891, samples/s: 1339.406 1612802516.7744231
train: epoch 144, iter 3600, loss: 1.836350, top_1: 0.767383, top_k: 0.916875, samples/s: 1333.001 1612802535.9791808
train: epoch 144, iter 3700, loss: 1.952407, top_1: 0.769414, top_k: 0.915703, samples/s: 1341.236 1612802555.0661442
train: epoch 144, iter 3800, loss: 1.955686, top_1: 0.772148, top_k: 0.917656, samples/s: 1333.033 1612802574.2704835
train: epoch 144, iter 3900, loss: 2.027568, top_1: 0.769883, top_k: 0.920508, samples/s: 1334.892 1612802593.4480574
train: epoch 144, iter 4000, loss: 1.904755, top_1: 0.775000, top_k: 0.922422, samples/s: 1344.476 1612802612.4889064
train: epoch 144, iter 4100, loss: 1.990282, top_1: 0.770898, top_k: 0.919180, samples/s: 1334.501 1612802631.6721268
train: epoch 144, iter 4200, loss: 1.883938, top_1: 0.769648, top_k: 0.914570, samples/s: 1334.849 1612802650.8502233
train: epoch 144, iter 4300, loss: 2.020395, top_1: 0.775000, top_k: 0.919023, samples/s: 1342.991 1612802669.9122443
train: epoch 144, iter 4400, loss: 1.974065, top_1: 0.772695, top_k: 0.920977, samples/s: 1334.650 1612802689.0932071
train: epoch 144, iter 4500, loss: 2.004342, top_1: 0.774062, top_k: 0.919453, samples/s: 1337.964 1612802708.2267861
train: epoch 144, iter 4600, loss: 1.903578, top_1: 0.773750, top_k: 0.917539, samples/s: 1336.243 1612802727.3849847
train: epoch 144, iter 4700, loss: 1.967894, top_1: 0.770273, top_k: 0.918398, samples/s: 1334.278 1612802746.5714622
train: epoch 144, iter 4800, loss: 2.001024, top_1: 0.771250, top_k: 0.918906, samples/s: 1342.521 1612802765.639999
train: epoch 144, iter 4900, loss: 2.023254, top_1: 0.771016, top_k: 0.919063, samples/s: 1335.908 1612802784.803001
train: epoch 144, iter 5000, loss: 1.992343, top_1: 0.776406, top_k: 0.923125, samples/s: 1339.606 1612802803.913058
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_144.
validation: epoch 144, iter 195, top_1: 0.757532, top_k: 0.928786, samples/s: 2801.899 1612802822.292716
train: epoch 145, iter 100, loss: 1.964248, top_1: 0.775977, top_k: 0.918359, samples/s: 1362.229 1612802857.0148706
train: epoch 145, iter 200, loss: 1.980488, top_1: 0.776172, top_k: 0.921562, samples/s: 1361.749 1612802875.8142686
train: epoch 145, iter 300, loss: 1.959639, top_1: 0.775312, top_k: 0.918672, samples/s: 1362.572 1612802894.6021934
train: epoch 145, iter 400, loss: 2.098112, top_1: 0.774062, top_k: 0.918359, samples/s: 1354.961 1612802913.4957206
train: epoch 145, iter 500, loss: 2.037007, top_1: 0.776719, top_k: 0.922148, samples/s: 1337.359 1612802932.637914
train: epoch 145, iter 600, loss: 2.094125, top_1: 0.772070, top_k: 0.920625, samples/s: 1326.916 1612802951.9307628
train: epoch 145, iter 700, loss: 2.064394, top_1: 0.773398, top_k: 0.920000, samples/s: 1342.499 1612802970.9996421
train: epoch 145, iter 800, loss: 1.854748, top_1: 0.773555, top_k: 0.920508, samples/s: 1328.704 1612802990.2667925
train: epoch 145, iter 900, loss: 1.853963, top_1: 0.775156, top_k: 0.920547, samples/s: 1328.003 1612803009.5436025
train: epoch 145, iter 1000, loss: 1.948665, top_1: 0.776172, top_k: 0.919336, samples/s: 1338.294 1612803028.6724873
train: epoch 145, iter 1100, loss: 2.025605, top_1: 0.771133, top_k: 0.919141, samples/s: 1333.748 1612803047.866536
train: epoch 145, iter 1200, loss: 1.815965, top_1: 0.778242, top_k: 0.920117, samples/s: 1335.095 1612803067.0411284
train: epoch 145, iter 1300, loss: 1.923268, top_1: 0.779375, top_k: 0.918750, samples/s: 1326.086 1612803086.3461404
train: epoch 145, iter 1400, loss: 1.901387, top_1: 0.775391, top_k: 0.919297, samples/s: 1338.855 1612803105.4668887
train: epoch 145, iter 1500, loss: 1.933422, top_1: 0.779297, top_k: 0.921289, samples/s: 1327.015 1612803124.758315
train: epoch 145, iter 1600, loss: 2.109803, top_1: 0.776523, top_k: 0.919922, samples/s: 1335.718 1612803143.9240186
train: epoch 145, iter 1700, loss: 1.799429, top_1: 0.775469, top_k: 0.921133, samples/s: 1334.761 1612803163.1035318
train: epoch 145, iter 1800, loss: 1.904158, top_1: 0.776367, top_k: 0.921250, samples/s: 1332.419 1612803182.3166602
train: epoch 145, iter 1900, loss: 2.133613, top_1: 0.775430, top_k: 0.920977, samples/s: 1331.011 1612803201.5502396
train: epoch 145, iter 2000, loss: 2.047455, top_1: 0.773672, top_k: 0.919570, samples/s: 1331.674 1612803220.7741292
train: epoch 145, iter 2100, loss: 1.873226, top_1: 0.775430, top_k: 0.921016, samples/s: 1341.002 1612803239.864342
train: epoch 145, iter 2200, loss: 1.820994, top_1: 0.776133, top_k: 0.921953, samples/s: 1330.214 1612803259.1093433
train: epoch 145, iter 2300, loss: 1.900711, top_1: 0.775820, top_k: 0.919258, samples/s: 1333.989 1612803278.2999082
train: epoch 145, iter 2400, loss: 1.969612, top_1: 0.768320, top_k: 0.917500, samples/s: 1333.020 1612803297.5044398
train: epoch 145, iter 2500, loss: 1.917601, top_1: 0.773867, top_k: 0.920430, samples/s: 1331.480 1612803316.7312288
train: epoch 145, iter 2600, loss: 1.965473, top_1: 0.772227, top_k: 0.918789, samples/s: 1343.211 1612803335.7899606
train: epoch 145, iter 2700, loss: 1.975447, top_1: 0.774414, top_k: 0.918438, samples/s: 1327.639 1612803355.0724092
train: epoch 145, iter 2800, loss: 1.876234, top_1: 0.772422, top_k: 0.917070, samples/s: 1337.831 1612803374.2077568
train: epoch 145, iter 2900, loss: 1.922565, top_1: 0.783516, top_k: 0.919141, samples/s: 1337.336 1612803393.3502948
train: epoch 145, iter 3000, loss: 2.066173, top_1: 0.771914, top_k: 0.918008, samples/s: 1330.588 1612803412.5899289
train: epoch 145, iter 3100, loss: 1.982400, top_1: 0.772109, top_k: 0.919609, samples/s: 1331.585 1612803431.815128
train: epoch 145, iter 3200, loss: 1.967556, top_1: 0.772109, top_k: 0.921602, samples/s: 1339.377 1612803450.928434
train: epoch 145, iter 3300, loss: 2.035448, top_1: 0.773555, top_k: 0.920117, samples/s: 1339.364 1612803470.0419972
train: epoch 145, iter 3400, loss: 1.833925, top_1: 0.772969, top_k: 0.918945, samples/s: 1334.475 1612803489.2255952
train: epoch 145, iter 3500, loss: 2.093574, top_1: 0.775742, top_k: 0.919180, samples/s: 1328.762 1612803508.4916627
train: epoch 145, iter 3600, loss: 1.879994, top_1: 0.772148, top_k: 0.919141, samples/s: 1333.760 1612803527.6855323
train: epoch 145, iter 3700, loss: 1.821746, top_1: 0.775117, top_k: 0.915977, samples/s: 1331.928 1612803546.9058325
train: epoch 145, iter 3800, loss: 1.985132, top_1: 0.774727, top_k: 0.919063, samples/s: 1341.794 1612803565.9846766
train: epoch 145, iter 3900, loss: 1.968159, top_1: 0.767695, top_k: 0.917383, samples/s: 1329.007 1612803585.247274
train: epoch 145, iter 4000, loss: 1.804893, top_1: 0.772734, top_k: 0.917695, samples/s: 1334.809 1612803604.4259593
train: epoch 145, iter 4100, loss: 2.076301, top_1: 0.769492, top_k: 0.917188, samples/s: 1334.295 1612803623.6121094
train: epoch 145, iter 4200, loss: 1.881795, top_1: 0.778359, top_k: 0.918438, samples/s: 1330.729 1612803642.8496997
train: epoch 145, iter 4300, loss: 2.097292, top_1: 0.770000, top_k: 0.915937, samples/s: 1337.697 1612803661.9871402
train: epoch 145, iter 4400, loss: 1.862965, top_1: 0.772656, top_k: 0.919766, samples/s: 1337.302 1612803681.130124
train: epoch 145, iter 4500, loss: 2.029533, top_1: 0.771055, top_k: 0.919883, samples/s: 1326.525 1612803700.4286566
train: epoch 145, iter 4600, loss: 1.900764, top_1: 0.774609, top_k: 0.918555, samples/s: 1335.721 1612803719.5943341
train: epoch 145, iter 4700, loss: 1.885208, top_1: 0.776563, top_k: 0.917891, samples/s: 1338.945 1612803738.7139058
train: epoch 145, iter 4800, loss: 1.924402, top_1: 0.773633, top_k: 0.922227, samples/s: 1337.778 1612803757.8500395
train: epoch 145, iter 4900, loss: 1.930359, top_1: 0.770898, top_k: 0.919570, samples/s: 1325.981 1612803777.1565282
train: epoch 145, iter 5000, loss: 1.862899, top_1: 0.775195, top_k: 0.920547, samples/s: 1341.278 1612803796.2427993
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_145.
validation: epoch 145, iter 195, top_1: 0.755970, top_k: 0.927444, samples/s: 2723.928 1612803815.1258702
train: epoch 146, iter 100, loss: 1.890840, top_1: 0.777344, top_k: 0.921875, samples/s: 1362.889 1612803850.0753326
train: epoch 146, iter 200, loss: 2.009317, top_1: 0.781680, top_k: 0.923438, samples/s: 1364.074 1612803868.8428986
train: epoch 146, iter 300, loss: 1.908737, top_1: 0.775781, top_k: 0.920469, samples/s: 1362.335 1612803887.634069
train: epoch 146, iter 400, loss: 1.948083, top_1: 0.779883, top_k: 0.923945, samples/s: 1361.348 1612803906.4387941
train: epoch 146, iter 500, loss: 1.822590, top_1: 0.778945, top_k: 0.923438, samples/s: 1335.017 1612803925.614559
train: epoch 146, iter 600, loss: 1.976358, top_1: 0.777461, top_k: 0.922266, samples/s: 1331.499 1612803944.8410115
train: epoch 146, iter 700, loss: 1.928797, top_1: 0.778984, top_k: 0.921289, samples/s: 1339.839 1612803963.9478676
train: epoch 146, iter 800, loss: 1.961832, top_1: 0.777773, top_k: 0.920508, samples/s: 1342.253 1612803983.0202625
train: epoch 146, iter 900, loss: 1.846422, top_1: 0.775117, top_k: 0.920156, samples/s: 1335.480 1612804002.1893952
train: epoch 146, iter 1000, loss: 1.848236, top_1: 0.785000, top_k: 0.924609, samples/s: 1336.745 1612804021.3403623
train: epoch 146, iter 1100, loss: 2.011725, top_1: 0.777500, top_k: 0.920586, samples/s: 1337.639 1612804040.4786565
train: epoch 146, iter 1200, loss: 1.832807, top_1: 0.778125, top_k: 0.920625, samples/s: 1334.986 1612804059.6547635
train: epoch 146, iter 1300, loss: 1.973305, top_1: 0.777188, top_k: 0.918203, samples/s: 1332.072 1612804078.8729517
train: epoch 146, iter 1400, loss: 1.904847, top_1: 0.776328, top_k: 0.920195, samples/s: 1339.976 1612804097.9778159
train: epoch 146, iter 1500, loss: 1.959426, top_1: 0.772344, top_k: 0.918398, samples/s: 1333.589 1612804117.1740806
train: epoch 146, iter 1600, loss: 2.013401, top_1: 0.776563, top_k: 0.918906, samples/s: 1337.855 1612804136.3092108
train: epoch 146, iter 1700, loss: 1.974011, top_1: 0.784102, top_k: 0.923789, samples/s: 1340.612 1612804155.4049768
train: epoch 146, iter 1800, loss: 2.087441, top_1: 0.778164, top_k: 0.921797, samples/s: 1333.090 1612804174.6084983
train: epoch 146, iter 1900, loss: 1.920600, top_1: 0.776602, top_k: 0.920117, samples/s: 1340.336 1612804193.708207
train: epoch 146, iter 2000, loss: 1.861194, top_1: 0.778438, top_k: 0.921992, samples/s: 1333.458 1612804212.9064217
train: epoch 146, iter 2100, loss: 2.044341, top_1: 0.774453, top_k: 0.919883, samples/s: 1341.575 1612804231.988392
train: epoch 146, iter 2200, loss: 2.025630, top_1: 0.781406, top_k: 0.922656, samples/s: 1335.476 1612804251.1575959
train: epoch 146, iter 2300, loss: 1.941637, top_1: 0.777266, top_k: 0.921133, samples/s: 1333.760 1612804270.3514776
train: epoch 146, iter 2400, loss: 1.840103, top_1: 0.776016, top_k: 0.922773, samples/s: 1343.505 1612804289.4060552
train: epoch 146, iter 2500, loss: 1.969774, top_1: 0.778477, top_k: 0.920391, samples/s: 1336.975 1612804308.5538204
train: epoch 146, iter 2600, loss: 1.975435, top_1: 0.773984, top_k: 0.918359, samples/s: 1340.326 1612804327.6535888
train: epoch 146, iter 2700, loss: 1.892051, top_1: 0.775352, top_k: 0.920742, samples/s: 1338.191 1612804346.783889
train: epoch 146, iter 2800, loss: 1.856044, top_1: 0.774922, top_k: 0.920664, samples/s: 1337.197 1612804365.9284093
train: epoch 146, iter 2900, loss: 2.015576, top_1: 0.776641, top_k: 0.920391, samples/s: 1340.296 1612804385.028683
train: epoch 146, iter 3000, loss: 1.814648, top_1: 0.777188, top_k: 0.918828, samples/s: 1337.201 1612804404.1732647
train: epoch 146, iter 3100, loss: 1.976613, top_1: 0.777188, top_k: 0.918359, samples/s: 1338.047 1612804423.3054996
train: epoch 146, iter 3200, loss: 1.948133, top_1: 0.773203, top_k: 0.919102, samples/s: 1339.639 1612804442.4151738
train: epoch 146, iter 3300, loss: 1.784801, top_1: 0.774961, top_k: 0.916758, samples/s: 1338.927 1612804461.5349042
train: epoch 146, iter 3400, loss: 1.941115, top_1: 0.775547, top_k: 0.921289, samples/s: 1340.504 1612804480.632262
train: epoch 146, iter 3500, loss: 2.062838, top_1: 0.780000, top_k: 0.922031, samples/s: 1338.232 1612804499.7619662
train: epoch 146, iter 3600, loss: 1.988521, top_1: 0.777852, top_k: 0.920391, samples/s: 1333.285 1612804518.9626744
train: epoch 146, iter 3700, loss: 1.996604, top_1: 0.775703, top_k: 0.923516, samples/s: 1340.645 1612804538.057919
train: epoch 146, iter 3800, loss: 2.051589, top_1: 0.778359, top_k: 0.922188, samples/s: 1342.349 1612804557.1290247
train: epoch 146, iter 3900, loss: 1.983096, top_1: 0.775898, top_k: 0.917148, samples/s: 1337.900 1612804576.2634187
train: epoch 146, iter 4000, loss: 1.980532, top_1: 0.775273, top_k: 0.920703, samples/s: 1341.130 1612804595.35184
train: epoch 146, iter 4100, loss: 1.929916, top_1: 0.779727, top_k: 0.922266, samples/s: 1340.261 1612804614.452544
train: epoch 146, iter 4200, loss: 1.911897, top_1: 0.774336, top_k: 0.920664, samples/s: 1333.838 1612804633.6453376
train: epoch 146, iter 4300, loss: 1.840950, top_1: 0.780273, top_k: 0.920547, samples/s: 1344.016 1612804652.6927466
train: epoch 146, iter 4400, loss: 1.980798, top_1: 0.776016, top_k: 0.921016, samples/s: 1338.500 1612804671.8186245
train: epoch 146, iter 4500, loss: 1.915415, top_1: 0.778047, top_k: 0.919336, samples/s: 1337.218 1612804690.962818
train: epoch 146, iter 4600, loss: 1.906755, top_1: 0.778398, top_k: 0.921250, samples/s: 1341.037 1612804710.0525634
train: epoch 146, iter 4700, loss: 2.048628, top_1: 0.775742, top_k: 0.919492, samples/s: 1345.229 1612804729.082736
train: epoch 146, iter 4800, loss: 2.047105, top_1: 0.784297, top_k: 0.921406, samples/s: 1331.988 1612804748.302105
train: epoch 146, iter 4900, loss: 2.013949, top_1: 0.777891, top_k: 0.923242, samples/s: 1338.526 1612804767.4276829
train: epoch 146, iter 5000, loss: 1.992004, top_1: 0.776953, top_k: 0.921211, samples/s: 1341.871 1612804786.505513
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_146.
validation: epoch 146, iter 195, top_1: 0.761518, top_k: 0.930669, samples/s: 2731.032 1612804805.3663461
train: epoch 147, iter 100, loss: 1.633927, top_1: 0.779453, top_k: 0.921172, samples/s: 1363.536 1612804839.9385188
train: epoch 147, iter 200, loss: 1.833488, top_1: 0.779180, top_k: 0.921875, samples/s: 1362.371 1612804858.7292812
train: epoch 147, iter 300, loss: 1.895281, top_1: 0.782461, top_k: 0.924844, samples/s: 1362.899 1612804877.5126302
train: epoch 147, iter 400, loss: 1.830448, top_1: 0.784258, top_k: 0.923047, samples/s: 1358.559 1612804896.3561275
train: epoch 147, iter 500, loss: 1.800396, top_1: 0.784141, top_k: 0.923242, samples/s: 1338.579 1612804915.4808884
train: epoch 147, iter 600, loss: 1.961757, top_1: 0.780000, top_k: 0.922539, samples/s: 1342.968 1612804934.543212
train: epoch 147, iter 700, loss: 1.736164, top_1: 0.783047, top_k: 0.922891, samples/s: 1336.066 1612804953.703847
train: epoch 147, iter 800, loss: 1.902079, top_1: 0.782188, top_k: 0.920859, samples/s: 1331.930 1612804972.9241138
train: epoch 147, iter 900, loss: 2.020883, top_1: 0.778320, top_k: 0.921641, samples/s: 1342.409 1612804991.9943616
train: epoch 147, iter 1000, loss: 2.034263, top_1: 0.777656, top_k: 0.921016, samples/s: 1339.749 1612805011.102378
train: epoch 147, iter 1100, loss: 2.013560, top_1: 0.774922, top_k: 0.919023, samples/s: 1339.646 1612805030.2119186
train: epoch 147, iter 1200, loss: 1.994656, top_1: 0.777227, top_k: 0.921016, samples/s: 1331.473 1612805049.438704
train: epoch 147, iter 1300, loss: 1.907624, top_1: 0.781055, top_k: 0.921016, samples/s: 1337.031 1612805068.5856826
train: epoch 147, iter 1400, loss: 1.985152, top_1: 0.779297, top_k: 0.919648, samples/s: 1336.829 1612805087.735426
train: epoch 147, iter 1500, loss: 1.976595, top_1: 0.778516, top_k: 0.919609, samples/s: 1329.203 1612805106.99505
train: epoch 147, iter 1600, loss: 1.850701, top_1: 0.777305, top_k: 0.919648, samples/s: 1347.475 1612805125.9936132
train: epoch 147, iter 1700, loss: 2.027914, top_1: 0.779414, top_k: 0.922070, samples/s: 1337.135 1612805145.138963
train: epoch 147, iter 1800, loss: 1.839077, top_1: 0.778281, top_k: 0.919297, samples/s: 1336.142 1612805164.2986743
train: epoch 147, iter 1900, loss: 1.946786, top_1: 0.780742, top_k: 0.921992, samples/s: 1336.170 1612805183.4578884
train: epoch 147, iter 2000, loss: 1.801106, top_1: 0.778477, top_k: 0.920234, samples/s: 1338.474 1612805202.5840986
train: epoch 147, iter 2100, loss: 2.047768, top_1: 0.780391, top_k: 0.922422, samples/s: 1338.928 1612805221.7038977
train: epoch 147, iter 2200, loss: 2.044101, top_1: 0.775117, top_k: 0.921836, samples/s: 1335.418 1612805240.8738987
train: epoch 147, iter 2300, loss: 2.018032, top_1: 0.781914, top_k: 0.921602, samples/s: 1335.072 1612805260.0489304
train: epoch 147, iter 2400, loss: 1.890475, top_1: 0.785117, top_k: 0.922148, samples/s: 1342.220 1612805279.1218858
train: epoch 147, iter 2500, loss: 1.958851, top_1: 0.779180, top_k: 0.922383, samples/s: 1336.697 1612805298.2734878
train: epoch 147, iter 2600, loss: 2.081400, top_1: 0.780703, top_k: 0.921719, samples/s: 1339.516 1612805317.3849044
train: epoch 147, iter 2700, loss: 1.936365, top_1: 0.774609, top_k: 0.922734, samples/s: 1340.809 1612805336.4778383
train: epoch 147, iter 2800, loss: 1.929071, top_1: 0.780977, top_k: 0.922148, samples/s: 1338.369 1612805355.6056006
train: epoch 147, iter 2900, loss: 1.952404, top_1: 0.777148, top_k: 0.920195, samples/s: 1341.272 1612805374.6919396
train: epoch 147, iter 3000, loss: 1.803248, top_1: 0.778711, top_k: 0.920078, samples/s: 1322.877 1612805394.0437837
train: epoch 147, iter 3100, loss: 1.905671, top_1: 0.778633, top_k: 0.919063, samples/s: 1341.764 1612805413.123143
train: epoch 147, iter 3200, loss: 1.875910, top_1: 0.782227, top_k: 0.924805, samples/s: 1343.119 1612805432.183205
train: epoch 147, iter 3300, loss: 1.837500, top_1: 0.779375, top_k: 0.920625, samples/s: 1341.900 1612805451.2605634
train: epoch 147, iter 3400, loss: 1.872646, top_1: 0.779805, top_k: 0.922578, samples/s: 1341.139 1612805470.3489473
train: epoch 147, iter 3500, loss: 2.002084, top_1: 0.775547, top_k: 0.919570, samples/s: 1338.423 1612805489.4758701
train: epoch 147, iter 3600, loss: 1.897130, top_1: 0.778320, top_k: 0.922539, samples/s: 1336.350 1612805508.6325917
train: epoch 147, iter 3700, loss: 2.093571, top_1: 0.780000, top_k: 0.922695, samples/s: 1339.616 1612805527.7424164
train: epoch 147, iter 3800, loss: 1.921186, top_1: 0.774492, top_k: 0.920117, samples/s: 1337.249 1612805546.8862565
train: epoch 147, iter 3900, loss: 2.015429, top_1: 0.776406, top_k: 0.922813, samples/s: 1333.852 1612805566.0787249
train: epoch 147, iter 4000, loss: 1.975407, top_1: 0.778281, top_k: 0.923281, samples/s: 1341.799 1612805585.157643
train: epoch 147, iter 4100, loss: 2.003395, top_1: 0.785078, top_k: 0.922109, samples/s: 1343.971 1612805604.2056186
train: epoch 147, iter 4200, loss: 1.938092, top_1: 0.783320, top_k: 0.923008, samples/s: 1334.779 1612805623.3849456
train: epoch 147, iter 4300, loss: 2.028403, top_1: 0.774375, top_k: 0.924805, samples/s: 1343.198 1612805642.4438777
train: epoch 147, iter 4400, loss: 1.821368, top_1: 0.777227, top_k: 0.919687, samples/s: 1336.063 1612805661.6046484
train: epoch 147, iter 4500, loss: 1.933435, top_1: 0.780273, top_k: 0.921133, samples/s: 1339.585 1612805680.7150478
train: epoch 147, iter 4600, loss: 1.879310, top_1: 0.781094, top_k: 0.922500, samples/s: 1339.447 1612805699.8273494
train: epoch 147, iter 4700, loss: 1.937109, top_1: 0.775859, top_k: 0.919141, samples/s: 1334.135 1612805719.015862
train: epoch 147, iter 4800, loss: 2.110802, top_1: 0.776602, top_k: 0.920703, samples/s: 1341.623 1612805738.0972438
train: epoch 147, iter 4900, loss: 1.947341, top_1: 0.778320, top_k: 0.920547, samples/s: 1342.425 1612805757.167216
train: epoch 147, iter 5000, loss: 1.829658, top_1: 0.777148, top_k: 0.920820, samples/s: 1336.800 1612805776.3174083
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_147.
validation: epoch 147, iter 195, top_1: 0.760437, top_k: 0.931250, samples/s: 2787.928 1612805794.7953298
train: epoch 148, iter 100, loss: 1.903129, top_1: 0.779648, top_k: 0.922500, samples/s: 1361.816 1612805829.5994658
train: epoch 148, iter 200, loss: 1.930746, top_1: 0.785000, top_k: 0.923359, samples/s: 1361.439 1612805848.403273
train: epoch 148, iter 300, loss: 1.823782, top_1: 0.781250, top_k: 0.925039, samples/s: 1361.246 1612805867.2093961
train: epoch 148, iter 400, loss: 1.908765, top_1: 0.781719, top_k: 0.923828, samples/s: 1358.713 1612805886.0507698
train: epoch 148, iter 500, loss: 2.038030, top_1: 0.785977, top_k: 0.924805, samples/s: 1338.093 1612805905.1824248
train: epoch 148, iter 600, loss: 1.951703, top_1: 0.779453, top_k: 0.918672, samples/s: 1342.896 1612805924.2457483
train: epoch 148, iter 700, loss: 2.022274, top_1: 0.783438, top_k: 0.924258, samples/s: 1338.205 1612805943.3759153
train: epoch 148, iter 800, loss: 2.094581, top_1: 0.780820, top_k: 0.923047, samples/s: 1341.525 1612805962.458606
train: epoch 148, iter 900, loss: 1.927494, top_1: 0.778789, top_k: 0.921523, samples/s: 1327.448 1612805981.743692
train: epoch 148, iter 1000, loss: 1.830272, top_1: 0.786680, top_k: 0.924336, samples/s: 1334.874 1612806000.921576
train: epoch 148, iter 1100, loss: 2.019253, top_1: 0.776758, top_k: 0.918867, samples/s: 1337.818 1612806020.057177
train: epoch 148, iter 1200, loss: 1.886864, top_1: 0.783125, top_k: 0.922930, samples/s: 1339.229 1612806039.1726682
train: epoch 148, iter 1300, loss: 1.985355, top_1: 0.779297, top_k: 0.921484, samples/s: 1338.785 1612806058.294538
train: epoch 148, iter 1400, loss: 1.959911, top_1: 0.781563, top_k: 0.921914, samples/s: 1332.557 1612806077.5057178
train: epoch 148, iter 1500, loss: 1.891453, top_1: 0.777891, top_k: 0.921523, samples/s: 1338.763 1612806096.6278317
train: epoch 148, iter 1600, loss: 1.952724, top_1: 0.776914, top_k: 0.923984, samples/s: 1338.311 1612806115.756422
train: epoch 148, iter 1700, loss: 2.037161, top_1: 0.779727, top_k: 0.923203, samples/s: 1336.569 1612806134.909944
train: epoch 148, iter 1800, loss: 1.916790, top_1: 0.779766, top_k: 0.920586, samples/s: 1336.472 1612806154.0648499
train: epoch 148, iter 1900, loss: 1.986930, top_1: 0.781289, top_k: 0.922969, samples/s: 1335.510 1612806173.2335284
train: epoch 148, iter 2000, loss: 1.845634, top_1: 0.784375, top_k: 0.925078, samples/s: 1332.930 1612806192.4394355
train: epoch 148, iter 2100, loss: 1.971700, top_1: 0.780547, top_k: 0.921211, samples/s: 1340.332 1612806211.5391154
train: epoch 148, iter 2200, loss: 1.801361, top_1: 0.783867, top_k: 0.923750, samples/s: 1334.900 1612806230.71669
train: epoch 148, iter 2300, loss: 1.984135, top_1: 0.780820, top_k: 0.919375, samples/s: 1334.208 1612806249.904018
train: epoch 148, iter 2400, loss: 1.915802, top_1: 0.774922, top_k: 0.921250, samples/s: 1339.286 1612806269.0187407
train: epoch 148, iter 2500, loss: 1.845853, top_1: 0.783125, top_k: 0.922930, samples/s: 1340.599 1612806288.1146193
train: epoch 148, iter 2600, loss: 1.918300, top_1: 0.779609, top_k: 0.920000, samples/s: 1330.137 1612806307.3607597
train: epoch 148, iter 2700, loss: 1.926717, top_1: 0.780664, top_k: 0.920898, samples/s: 1338.448 1612806326.4874146
train: epoch 148, iter 2800, loss: 1.980819, top_1: 0.779336, top_k: 0.921680, samples/s: 1337.880 1612806345.622154
train: epoch 148, iter 2900, loss: 1.922875, top_1: 0.785508, top_k: 0.923711, samples/s: 1338.927 1612806364.7419453
train: epoch 148, iter 3000, loss: 2.089594, top_1: 0.778203, top_k: 0.918984, samples/s: 1334.391 1612806383.9266462
train: epoch 148, iter 3100, loss: 1.947802, top_1: 0.783281, top_k: 0.922500, samples/s: 1336.324 1612806403.0837831
train: epoch 148, iter 3200, loss: 1.888301, top_1: 0.786602, top_k: 0.922031, samples/s: 1333.240 1612806422.2851245
train: epoch 148, iter 3300, loss: 1.909439, top_1: 0.780469, top_k: 0.923438, samples/s: 1342.864 1612806441.3488014
train: epoch 148, iter 3400, loss: 1.884703, top_1: 0.779297, top_k: 0.922109, samples/s: 1336.119 1612806460.5088155
train: epoch 148, iter 3500, loss: 1.831561, top_1: 0.777461, top_k: 0.922148, samples/s: 1335.405 1612806479.6789181
train: epoch 148, iter 3600, loss: 2.060308, top_1: 0.778789, top_k: 0.920156, samples/s: 1333.328 1612806498.878996
train: epoch 148, iter 3700, loss: 1.931059, top_1: 0.783398, top_k: 0.922891, samples/s: 1343.130 1612806517.9389591
train: epoch 148, iter 3800, loss: 1.885880, top_1: 0.784023, top_k: 0.919570, samples/s: 1340.125 1612806537.0416532
train: epoch 148, iter 3900, loss: 1.936377, top_1: 0.779102, top_k: 0.921211, samples/s: 1337.612 1612806556.1803079
train: epoch 148, iter 4000, loss: 1.932303, top_1: 0.776992, top_k: 0.921211, samples/s: 1337.430 1612806575.3214738
train: epoch 148, iter 4100, loss: 2.087060, top_1: 0.773867, top_k: 0.919023, samples/s: 1332.145 1612806594.5386617
train: epoch 148, iter 4200, loss: 1.923112, top_1: 0.775234, top_k: 0.920391, samples/s: 1334.748 1612806613.718231
train: epoch 148, iter 4300, loss: 1.858518, top_1: 0.783867, top_k: 0.924297, samples/s: 1336.167 1612806632.877483
train: epoch 148, iter 4400, loss: 2.027169, top_1: 0.777891, top_k: 0.920703, samples/s: 1339.170 1612806651.9938626
train: epoch 148, iter 4500, loss: 1.899622, top_1: 0.778477, top_k: 0.920820, samples/s: 1337.213 1612806671.1381576
train: epoch 148, iter 4600, loss: 2.035774, top_1: 0.780898, top_k: 0.925117, samples/s: 1331.487 1612806690.3647323
train: epoch 148, iter 4700, loss: 1.925765, top_1: 0.780000, top_k: 0.921484, samples/s: 1337.852 1612806709.5000174
train: epoch 148, iter 4800, loss: 1.979330, top_1: 0.779453, top_k: 0.921484, samples/s: 1333.610 1612806728.6959403
train: epoch 148, iter 4900, loss: 1.924682, top_1: 0.784375, top_k: 0.925117, samples/s: 1340.069 1612806747.7995024
train: epoch 148, iter 5000, loss: 2.002965, top_1: 0.783555, top_k: 0.927305, samples/s: 1339.190 1612806766.9154189
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_148.
validation: epoch 148, iter 195, top_1: 0.762941, top_k: 0.931591, samples/s: 2735.596 1612806785.7462962
train: epoch 149, iter 100, loss: 1.811073, top_1: 0.776406, top_k: 0.919453, samples/s: 1359.756 1612806821.0284257
train: epoch 149, iter 200, loss: 1.923918, top_1: 0.782188, top_k: 0.922578, samples/s: 1351.926 1612806839.9644992
train: epoch 149, iter 300, loss: 2.027781, top_1: 0.782930, top_k: 0.923750, samples/s: 1366.101 1612806858.7036662
train: epoch 149, iter 400, loss: 1.920333, top_1: 0.779336, top_k: 0.923359, samples/s: 1354.592 1612806877.6023672
train: epoch 149, iter 500, loss: 1.877608, top_1: 0.782617, top_k: 0.923398, samples/s: 1337.671 1612806896.7400742
train: epoch 149, iter 600, loss: 1.818197, top_1: 0.781211, top_k: 0.924883, samples/s: 1329.899 1612806915.9897177
train: epoch 149, iter 700, loss: 1.946406, top_1: 0.777539, top_k: 0.920078, samples/s: 1331.555 1612806935.2153072
train: epoch 149, iter 800, loss: 1.793720, top_1: 0.780703, top_k: 0.922383, samples/s: 1327.444 1612806954.5004966
train: epoch 149, iter 900, loss: 1.983128, top_1: 0.781289, top_k: 0.921172, samples/s: 1333.609 1612806973.6965294
train: epoch 149, iter 1000, loss: 1.861217, top_1: 0.780234, top_k: 0.920312, samples/s: 1334.420 1612806992.8808906
train: epoch 149, iter 1100, loss: 1.878558, top_1: 0.786094, top_k: 0.925625, samples/s: 1325.951 1612807012.1877882
train: epoch 149, iter 1200, loss: 1.834352, top_1: 0.780664, top_k: 0.919180, samples/s: 1330.913 1612807031.4227648
train: epoch 149, iter 1300, loss: 1.889997, top_1: 0.779648, top_k: 0.923711, samples/s: 1328.870 1612807050.6872134
train: epoch 149, iter 1400, loss: 1.871102, top_1: 0.776484, top_k: 0.919766, samples/s: 1338.281 1612807069.816222
train: epoch 149, iter 1500, loss: 1.964481, top_1: 0.784414, top_k: 0.923711, samples/s: 1334.253 1612807089.0030293
train: epoch 149, iter 1600, loss: 1.819800, top_1: 0.782344, top_k: 0.923438, samples/s: 1323.768 1612807108.3417923
train: epoch 149, iter 1700, loss: 2.007962, top_1: 0.784727, top_k: 0.925000, samples/s: 1329.743 1612807127.5936565
train: epoch 149, iter 1800, loss: 1.985545, top_1: 0.780195, top_k: 0.920469, samples/s: 1335.472 1612807146.7628026
train: epoch 149, iter 1900, loss: 1.889759, top_1: 0.784141, top_k: 0.923711, samples/s: 1331.744 1612807165.9857724
train: epoch 149, iter 2000, loss: 2.006838, top_1: 0.783047, top_k: 0.922344, samples/s: 1335.148 1612807185.1596406
train: epoch 149, iter 2100, loss: 1.933875, top_1: 0.781484, top_k: 0.923789, samples/s: 1330.070 1612807204.4067376
train: epoch 149, iter 2200, loss: 1.926802, top_1: 0.779922, top_k: 0.921172, samples/s: 1335.183 1612807223.5801322
train: epoch 149, iter 2300, loss: 1.806303, top_1: 0.785234, top_k: 0.923281, samples/s: 1331.440 1612807242.8075047
train: epoch 149, iter 2400, loss: 1.832741, top_1: 0.781836, top_k: 0.923242, samples/s: 1332.787 1612807262.0153823
train: epoch 149, iter 2500, loss: 1.858550, top_1: 0.780547, top_k: 0.923242, samples/s: 1327.676 1612807281.2971497
train: epoch 149, iter 2600, loss: 1.900979, top_1: 0.780000, top_k: 0.922188, samples/s: 1333.266 1612807300.4980946
train: epoch 149, iter 2700, loss: 1.830609, top_1: 0.783281, top_k: 0.922266, samples/s: 1325.506 1612807319.8114755
train: epoch 149, iter 2800, loss: 1.901813, top_1: 0.780703, top_k: 0.920391, samples/s: 1341.829 1612807338.8899727
train: epoch 149, iter 2900, loss: 2.015105, top_1: 0.782070, top_k: 0.925039, samples/s: 1334.046 1612807358.0796974
train: epoch 149, iter 3000, loss: 1.946093, top_1: 0.783594, top_k: 0.923750, samples/s: 1328.345 1612807377.3517637
train: epoch 149, iter 3100, loss: 1.999219, top_1: 0.784961, top_k: 0.922266, samples/s: 1321.744 1612807396.7202377
train: epoch 149, iter 3200, loss: 2.052344, top_1: 0.782070, top_k: 0.924609, samples/s: 1342.971 1612807415.7824495
train: epoch 149, iter 3300, loss: 1.879411, top_1: 0.782383, top_k: 0.921602, samples/s: 1330.152 1612807435.028387
train: epoch 149, iter 3400, loss: 2.041964, top_1: 0.778398, top_k: 0.920937, samples/s: 1332.929 1612807454.2341335
train: epoch 149, iter 3500, loss: 1.853975, top_1: 0.782773, top_k: 0.925078, samples/s: 1333.136 1612807473.4369507
train: epoch 149, iter 3600, loss: 1.947094, top_1: 0.780391, top_k: 0.921602, samples/s: 1329.722 1612807492.6891487
train: epoch 149, iter 3700, loss: 2.065430, top_1: 0.786094, top_k: 0.926680, samples/s: 1336.409 1612807511.8449416
train: epoch 149, iter 3800, loss: 1.916782, top_1: 0.779102, top_k: 0.919180, samples/s: 1329.689 1612807531.0975862
train: epoch 149, iter 3900, loss: 1.862544, top_1: 0.784258, top_k: 0.925312, samples/s: 1335.117 1612807550.2719777
train: epoch 149, iter 4000, loss: 1.877028, top_1: 0.781602, top_k: 0.922539, samples/s: 1328.726 1612807569.538448
train: epoch 149, iter 4100, loss: 1.805726, top_1: 0.782617, top_k: 0.924687, samples/s: 1332.194 1612807588.7548482
train: epoch 149, iter 4200, loss: 1.897583, top_1: 0.778828, top_k: 0.920781, samples/s: 1328.620 1612807608.0230453
train: epoch 149, iter 4300, loss: 1.945040, top_1: 0.781953, top_k: 0.920742, samples/s: 1340.937 1612807627.1141183
train: epoch 149, iter 4400, loss: 1.721317, top_1: 0.784141, top_k: 0.923984, samples/s: 1333.125 1612807646.3171213
train: epoch 149, iter 4500, loss: 2.044726, top_1: 0.786875, top_k: 0.923672, samples/s: 1330.799 1612807665.5537565
train: epoch 149, iter 4600, loss: 2.036644, top_1: 0.781133, top_k: 0.922305, samples/s: 1329.691 1612807684.806283
train: epoch 149, iter 4700, loss: 1.970196, top_1: 0.784102, top_k: 0.920898, samples/s: 1330.894 1612807704.041415
train: epoch 149, iter 4800, loss: 1.868216, top_1: 0.781445, top_k: 0.924102, samples/s: 1335.255 1612807723.2138755
train: epoch 149, iter 4900, loss: 1.974694, top_1: 0.781719, top_k: 0.924219, samples/s: 1335.832 1612807742.377939
train: epoch 149, iter 5000, loss: 1.943179, top_1: 0.784219, top_k: 0.922695, samples/s: 1327.979 1612807761.6552908
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_149.
validation: epoch 149, iter 195, top_1: 0.763502, top_k: 0.932071, samples/s: 2743.023 1612807780.415592
train: epoch 150, iter 100, loss: 1.882096, top_1: 0.782578, top_k: 0.923867, samples/s: 1362.862 1612807815.9598567
train: epoch 150, iter 200, loss: 1.844298, top_1: 0.782578, top_k: 0.920312, samples/s: 1352.265 1612807834.89109
train: epoch 150, iter 300, loss: 1.898693, top_1: 0.785977, top_k: 0.921641, samples/s: 1367.232 1612807853.6149666
train: epoch 150, iter 400, loss: 1.874986, top_1: 0.782070, top_k: 0.922227, samples/s: 1353.720 1612807872.5258796
train: epoch 150, iter 500, loss: 1.980163, top_1: 0.782969, top_k: 0.923906, samples/s: 1349.425 1612807891.4968834
train: epoch 150, iter 600, loss: 2.198874, top_1: 0.778477, top_k: 0.923125, samples/s: 1329.341 1612807910.754595
train: epoch 150, iter 700, loss: 1.970312, top_1: 0.785195, top_k: 0.925117, samples/s: 1342.145 1612807929.8284838
train: epoch 150, iter 800, loss: 1.996561, top_1: 0.783906, top_k: 0.922188, samples/s: 1334.154 1612807949.0167234
train: epoch 150, iter 900, loss: 1.989472, top_1: 0.783281, top_k: 0.923164, samples/s: 1334.446 1612807968.2007167
train: epoch 150, iter 1000, loss: 1.885509, top_1: 0.787305, top_k: 0.924023, samples/s: 1335.170 1612807987.374256
train: epoch 150, iter 1100, loss: 1.991676, top_1: 0.780937, top_k: 0.921445, samples/s: 1332.299 1612808006.5891635
train: epoch 150, iter 1200, loss: 1.989666, top_1: 0.784180, top_k: 0.924883, samples/s: 1337.660 1612808025.727061
train: epoch 150, iter 1300, loss: 1.877465, top_1: 0.779609, top_k: 0.921250, samples/s: 1327.539 1612808045.0109167
train: epoch 150, iter 1400, loss: 1.965451, top_1: 0.781328, top_k: 0.924336, samples/s: 1334.175 1612808064.1987612
train: epoch 150, iter 1500, loss: 1.910192, top_1: 0.780781, top_k: 0.923906, samples/s: 1342.971 1612808083.2610443
train: epoch 150, iter 1600, loss: 1.871910, top_1: 0.783086, top_k: 0.921797, samples/s: 1332.045 1612808102.47965
train: epoch 150, iter 1700, loss: 1.894199, top_1: 0.780000, top_k: 0.922500, samples/s: 1337.300 1612808121.6226256
train: epoch 150, iter 1800, loss: 2.072960, top_1: 0.781719, top_k: 0.921836, samples/s: 1339.399 1612808140.7356775
train: epoch 150, iter 1900, loss: 1.982487, top_1: 0.784219, top_k: 0.924727, samples/s: 1332.353 1612808159.9498408
train: epoch 150, iter 2000, loss: 1.956088, top_1: 0.782578, top_k: 0.921289, samples/s: 1339.248 1612808179.0650723
train: epoch 150, iter 2100, loss: 1.894260, top_1: 0.783398, top_k: 0.921680, samples/s: 1339.263 1612808198.1799796
train: epoch 150, iter 2200, loss: 1.875246, top_1: 0.789961, top_k: 0.926172, samples/s: 1334.660 1612808217.3608932
train: epoch 150, iter 2300, loss: 1.972453, top_1: 0.778750, top_k: 0.920820, samples/s: 1334.859 1612808236.5389774
train: epoch 150, iter 2400, loss: 1.872464, top_1: 0.782344, top_k: 0.922578, samples/s: 1333.502 1612808255.7365332
train: epoch 150, iter 2500, loss: 1.820174, top_1: 0.783438, top_k: 0.922344, samples/s: 1327.715 1612808275.0177755
train: epoch 150, iter 2600, loss: 1.926887, top_1: 0.784336, top_k: 0.924453, samples/s: 1337.837 1612808294.153219
train: epoch 150, iter 2700, loss: 2.005870, top_1: 0.785195, top_k: 0.923750, samples/s: 1340.862 1612808313.2453368
train: epoch 150, iter 2800, loss: 1.960887, top_1: 0.788672, top_k: 0.924336, samples/s: 1339.007 1612808332.3639765
train: epoch 150, iter 2900, loss: 1.996143, top_1: 0.779609, top_k: 0.920820, samples/s: 1330.249 1612808351.6085024
train: epoch 150, iter 3000, loss: 2.040381, top_1: 0.781133, top_k: 0.920586, samples/s: 1340.209 1612808370.710007
train: epoch 150, iter 3100, loss: 1.976698, top_1: 0.783555, top_k: 0.923789, samples/s: 1338.262 1612808389.8393624
train: epoch 150, iter 3200, loss: 1.918904, top_1: 0.781016, top_k: 0.920820, samples/s: 1336.229 1612808408.9978514
train: epoch 150, iter 3300, loss: 2.056277, top_1: 0.785977, top_k: 0.923047, samples/s: 1337.399 1612808428.1393752
train: epoch 150, iter 3400, loss: 1.859991, top_1: 0.785352, top_k: 0.923984, samples/s: 1332.669 1612808447.3488903
train: epoch 150, iter 3500, loss: 1.901269, top_1: 0.783203, top_k: 0.925117, samples/s: 1337.428 1612808466.4901712
train: epoch 150, iter 3600, loss: 2.119861, top_1: 0.783594, top_k: 0.922539, samples/s: 1338.425 1612808485.6171143
train: epoch 150, iter 3700, loss: 1.763998, top_1: 0.785703, top_k: 0.924414, samples/s: 1335.832 1612808504.781215
train: epoch 150, iter 3800, loss: 1.871128, top_1: 0.786758, top_k: 0.923359, samples/s: 1337.820 1612808523.9168212
train: epoch 150, iter 3900, loss: 1.948998, top_1: 0.778164, top_k: 0.921484, samples/s: 1336.095 1612808543.077139
train: epoch 150, iter 4000, loss: 1.956793, top_1: 0.779180, top_k: 0.920937, samples/s: 1332.471 1612808562.2895684
train: epoch 150, iter 4100, loss: 2.049010, top_1: 0.778438, top_k: 0.923281, samples/s: 1340.586 1612808581.385659
train: epoch 150, iter 4200, loss: 1.773718, top_1: 0.787813, top_k: 0.927578, samples/s: 1330.064 1612808600.6328478
train: epoch 150, iter 4300, loss: 1.920503, top_1: 0.787383, top_k: 0.921680, samples/s: 1334.297 1612808619.8189619
train: epoch 150, iter 4400, loss: 1.886014, top_1: 0.783008, top_k: 0.922969, samples/s: 1339.743 1612808638.9271123
train: epoch 150, iter 4500, loss: 2.172217, top_1: 0.781328, top_k: 0.921016, samples/s: 1339.399 1612808658.0401986
train: epoch 150, iter 4600, loss: 1.965418, top_1: 0.782578, top_k: 0.923477, samples/s: 1338.718 1612808677.1629462
train: epoch 150, iter 4700, loss: 1.882880, top_1: 0.780898, top_k: 0.925547, samples/s: 1334.734 1612808696.3428323
train: epoch 150, iter 4800, loss: 1.946408, top_1: 0.781953, top_k: 0.921523, samples/s: 1335.739 1612808715.50821
train: epoch 150, iter 4900, loss: 1.782487, top_1: 0.785547, top_k: 0.923789, samples/s: 1334.069 1612808734.697664
train: epoch 150, iter 5000, loss: 1.984561, top_1: 0.786016, top_k: 0.924805, samples/s: 1337.505 1612808753.8378084
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_150.
validation: epoch 150, iter 195, top_1: 0.762861, top_k: 0.931270, samples/s: 2800.415 1612808772.213665
train: epoch 151, iter 100, loss: 1.916940, top_1: 0.782813, top_k: 0.923047, samples/s: 1357.200 1612808806.9406338
train: epoch 151, iter 200, loss: 1.969802, top_1: 0.784180, top_k: 0.924492, samples/s: 1353.003 1612808825.861659
train: epoch 151, iter 300, loss: 1.871740, top_1: 0.782617, top_k: 0.925312, samples/s: 1368.056 1612808844.574089
train: epoch 151, iter 400, loss: 1.827540, top_1: 0.786719, top_k: 0.925664, samples/s: 1354.368 1612808863.475897
train: epoch 151, iter 500, loss: 1.880840, top_1: 0.783633, top_k: 0.925234, samples/s: 1341.367 1612808882.5610304
train: epoch 151, iter 600, loss: 1.942195, top_1: 0.784922, top_k: 0.925586, samples/s: 1328.498 1612808901.8309333
train: epoch 151, iter 700, loss: 1.877778, top_1: 0.788008, top_k: 0.926641, samples/s: 1337.425 1612808920.9721212
train: epoch 151, iter 800, loss: 1.860260, top_1: 0.786328, top_k: 0.921406, samples/s: 1338.939 1612808940.091688
train: epoch 151, iter 900, loss: 1.949515, top_1: 0.787031, top_k: 0.924414, samples/s: 1329.820 1612808959.3424299
train: epoch 151, iter 1000, loss: 1.767802, top_1: 0.787188, top_k: 0.924258, samples/s: 1340.154 1612808978.4447029
train: epoch 151, iter 1100, loss: 2.007946, top_1: 0.783828, top_k: 0.922930, samples/s: 1341.235 1612808997.5316188
train: epoch 151, iter 1200, loss: 2.026174, top_1: 0.786172, top_k: 0.927188, samples/s: 1331.726 1612809016.754823
train: epoch 151, iter 1300, loss: 1.988960, top_1: 0.787656, top_k: 0.923906, samples/s: 1328.570 1612809036.023669
train: epoch 151, iter 1400, loss: 1.945360, top_1: 0.788438, top_k: 0.927656, samples/s: 1339.746 1612809055.1317325
train: epoch 151, iter 1500, loss: 1.849489, top_1: 0.784570, top_k: 0.925742, samples/s: 1341.653 1612809074.212615
train: epoch 151, iter 1600, loss: 1.876636, top_1: 0.781445, top_k: 0.924844, samples/s: 1336.165 1612809093.371935
train: epoch 151, iter 1700, loss: 1.791425, top_1: 0.787070, top_k: 0.924883, samples/s: 1338.267 1612809112.501275
train: epoch 151, iter 1800, loss: 1.790262, top_1: 0.786016, top_k: 0.926133, samples/s: 1335.369 1612809131.671934
train: epoch 151, iter 1900, loss: 1.889454, top_1: 0.782031, top_k: 0.922188, samples/s: 1331.438 1612809150.8992884
train: epoch 151, iter 2000, loss: 1.904850, top_1: 0.783203, top_k: 0.924023, samples/s: 1337.508 1612809170.0393436
train: epoch 151, iter 2100, loss: 1.829482, top_1: 0.787031, top_k: 0.924687, samples/s: 1338.253 1612809189.1687589
train: epoch 151, iter 2200, loss: 1.907583, top_1: 0.778555, top_k: 0.920273, samples/s: 1337.689 1612809208.306216
train: epoch 151, iter 2300, loss: 1.850341, top_1: 0.787891, top_k: 0.926367, samples/s: 1339.099 1612809227.4235868
train: epoch 151, iter 2400, loss: 1.911923, top_1: 0.784336, top_k: 0.921836, samples/s: 1330.590 1612809246.6631916
train: epoch 151, iter 2500, loss: 1.796769, top_1: 0.783398, top_k: 0.922930, samples/s: 1335.956 1612809265.825448
train: epoch 151, iter 2600, loss: 1.931466, top_1: 0.782266, top_k: 0.921914, samples/s: 1332.427 1612809285.0384786
train: epoch 151, iter 2700, loss: 1.833522, top_1: 0.783086, top_k: 0.923398, samples/s: 1338.218 1612809304.1684473
train: epoch 151, iter 2800, loss: 1.833686, top_1: 0.785156, top_k: 0.923828, samples/s: 1341.232 1612809323.2553797
train: epoch 151, iter 2900, loss: 2.022040, top_1: 0.783867, top_k: 0.922656, samples/s: 1334.576 1612809342.4374685
train: epoch 151, iter 3000, loss: 1.937091, top_1: 0.784258, top_k: 0.925898, samples/s: 1332.461 1612809361.6500602
train: epoch 151, iter 3100, loss: 1.879549, top_1: 0.782734, top_k: 0.921914, samples/s: 1334.665 1612809380.8308487
train: epoch 151, iter 3200, loss: 2.046809, top_1: 0.781602, top_k: 0.920820, samples/s: 1340.977 1612809399.9214106
train: epoch 151, iter 3300, loss: 1.807810, top_1: 0.789258, top_k: 0.924297, samples/s: 1332.786 1612809419.1293924
train: epoch 151, iter 3400, loss: 1.968569, top_1: 0.787305, top_k: 0.925156, samples/s: 1335.145 1612809438.3033044
train: epoch 151, iter 3500, loss: 1.907474, top_1: 0.784961, top_k: 0.924922, samples/s: 1334.870 1612809457.4811916
train: epoch 151, iter 3600, loss: 1.881711, top_1: 0.784922, top_k: 0.922891, samples/s: 1337.396 1612809476.6228356
train: epoch 151, iter 3700, loss: 1.981647, top_1: 0.780977, top_k: 0.921289, samples/s: 1339.763 1612809495.7306712
train: epoch 151, iter 3800, loss: 2.025921, top_1: 0.779258, top_k: 0.922852, samples/s: 1338.014 1612809514.8635392
train: epoch 151, iter 3900, loss: 1.944997, top_1: 0.783438, top_k: 0.922891, samples/s: 1335.942 1612809534.0260253
train: epoch 151, iter 4000, loss: 1.965965, top_1: 0.780859, top_k: 0.923086, samples/s: 1338.382 1612809553.1536033
train: epoch 151, iter 4100, loss: 1.819780, top_1: 0.783320, top_k: 0.923789, samples/s: 1331.764 1612809572.3762114
train: epoch 151, iter 4200, loss: 1.896658, top_1: 0.785898, top_k: 0.924023, samples/s: 1336.514 1612809591.5305204
train: epoch 151, iter 4300, loss: 1.919158, top_1: 0.784766, top_k: 0.922461, samples/s: 1342.432 1612809610.600392
train: epoch 151, iter 4400, loss: 1.869340, top_1: 0.787109, top_k: 0.927148, samples/s: 1328.041 1612809629.8769674
train: epoch 151, iter 4500, loss: 1.840534, top_1: 0.787539, top_k: 0.923789, samples/s: 1335.098 1612809649.0515907
train: epoch 151, iter 4600, loss: 1.890356, top_1: 0.781992, top_k: 0.922773, samples/s: 1342.178 1612809668.1250162
train: epoch 151, iter 4700, loss: 2.053043, top_1: 0.781680, top_k: 0.923633, samples/s: 1332.335 1612809687.3394418
train: epoch 151, iter 4800, loss: 2.017290, top_1: 0.786328, top_k: 0.924102, samples/s: 1339.865 1612809706.4458115
train: epoch 151, iter 4900, loss: 1.949251, top_1: 0.781133, top_k: 0.923281, samples/s: 1337.590 1612809725.584858
train: epoch 151, iter 5000, loss: 1.881759, top_1: 0.782813, top_k: 0.921875, samples/s: 1341.558 1612809744.666999
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_151.
validation: epoch 151, iter 195, top_1: 0.763522, top_k: 0.931771, samples/s: 2759.009 1612809763.3301125
train: epoch 152, iter 100, loss: 1.894438, top_1: 0.784414, top_k: 0.921992, samples/s: 1359.949 1612809797.581461
train: epoch 152, iter 200, loss: 1.951572, top_1: 0.788438, top_k: 0.922969, samples/s: 1361.212 1612809816.3881416
train: epoch 152, iter 300, loss: 1.951761, top_1: 0.783008, top_k: 0.923594, samples/s: 1362.512 1612809835.1772146
train: epoch 152, iter 400, loss: 1.975808, top_1: 0.786172, top_k: 0.925391, samples/s: 1356.086 1612809854.0548751
train: epoch 152, iter 500, loss: 1.747992, top_1: 0.784023, top_k: 0.925508, samples/s: 1341.177 1612809873.142528
train: epoch 152, iter 600, loss: 2.047107, top_1: 0.784180, top_k: 0.927109, samples/s: 1331.974 1612809892.3620958
train: epoch 152, iter 700, loss: 2.093811, top_1: 0.782656, top_k: 0.922695, samples/s: 1333.494 1612809911.559771
train: epoch 152, iter 800, loss: 1.886032, top_1: 0.783242, top_k: 0.923125, samples/s: 1328.817 1612809930.8250968
train: epoch 152, iter 900, loss: 1.972013, top_1: 0.792188, top_k: 0.927227, samples/s: 1333.191 1612809950.0271485
train: epoch 152, iter 1000, loss: 1.966067, top_1: 0.784414, top_k: 0.922734, samples/s: 1332.343 1612809969.2413645
train: epoch 152, iter 1100, loss: 1.902879, top_1: 0.783438, top_k: 0.924609, samples/s: 1335.766 1612809988.406388
train: epoch 152, iter 1200, loss: 1.844981, top_1: 0.783906, top_k: 0.925000, samples/s: 1334.590 1612810007.5883372
train: epoch 152, iter 1300, loss: 1.886399, top_1: 0.780391, top_k: 0.921289, samples/s: 1330.000 1612810026.8364296
train: epoch 152, iter 1400, loss: 1.988701, top_1: 0.785859, top_k: 0.925547, samples/s: 1336.646 1612810045.988936
train: epoch 152, iter 1500, loss: 1.901164, top_1: 0.788359, top_k: 0.924141, samples/s: 1332.275 1612810065.204193
train: epoch 152, iter 1600, loss: 1.811813, top_1: 0.787773, top_k: 0.923867, samples/s: 1335.073 1612810084.3791234
train: epoch 152, iter 1700, loss: 1.902831, top_1: 0.788477, top_k: 0.923516, samples/s: 1337.028 1612810103.526083
train: epoch 152, iter 1800, loss: 1.774547, top_1: 0.785703, top_k: 0.925937, samples/s: 1334.776 1612810122.7053123
train: epoch 152, iter 1900, loss: 1.926974, top_1: 0.784922, top_k: 0.922695, samples/s: 1336.539 1612810141.8593473
train: epoch 152, iter 2000, loss: 1.816589, top_1: 0.782461, top_k: 0.922656, samples/s: 1331.793 1612810161.0814815
train: epoch 152, iter 2100, loss: 1.900274, top_1: 0.787070, top_k: 0.924961, samples/s: 1335.461 1612810180.250836
train: epoch 152, iter 2200, loss: 1.931463, top_1: 0.785273, top_k: 0.925195, samples/s: 1330.155 1612810199.4967186
train: epoch 152, iter 2300, loss: 1.815407, top_1: 0.784258, top_k: 0.924531, samples/s: 1338.561 1612810218.6218772
train: epoch 152, iter 2400, loss: 2.003236, top_1: 0.781758, top_k: 0.923555, samples/s: 1335.746 1612810237.787063
train: epoch 152, iter 2500, loss: 1.943706, top_1: 0.779883, top_k: 0.919141, samples/s: 1329.248 1612810257.046076
train: epoch 152, iter 2600, loss: 1.958906, top_1: 0.783203, top_k: 0.923984, samples/s: 1343.152 1612810276.1057792
train: epoch 152, iter 2700, loss: 1.806697, top_1: 0.785586, top_k: 0.924297, samples/s: 1335.411 1612810295.2758856
train: epoch 152, iter 2800, loss: 1.898993, top_1: 0.785312, top_k: 0.923398, samples/s: 1332.104 1612810314.4936368
train: epoch 152, iter 2900, loss: 1.977188, top_1: 0.785664, top_k: 0.924414, samples/s: 1329.298 1612810333.751856
train: epoch 152, iter 3000, loss: 2.083225, top_1: 0.785352, top_k: 0.924375, samples/s: 1340.078 1612810352.8552828
train: epoch 152, iter 3100, loss: 1.808243, top_1: 0.787813, top_k: 0.924961, samples/s: 1339.494 1612810371.9669209
train: epoch 152, iter 3200, loss: 1.988525, top_1: 0.783984, top_k: 0.923906, samples/s: 1339.430 1612810391.0795803
train: epoch 152, iter 3300, loss: 1.962620, top_1: 0.786484, top_k: 0.923906, samples/s: 1336.096 1612810410.2398772
train: epoch 152, iter 3400, loss: 1.980709, top_1: 0.784531, top_k: 0.923047, samples/s: 1329.641 1612810429.4931738
train: epoch 152, iter 3500, loss: 1.985101, top_1: 0.786211, top_k: 0.924922, samples/s: 1339.571 1612810448.6037865
train: epoch 152, iter 3600, loss: 2.083474, top_1: 0.785000, top_k: 0.923984, samples/s: 1344.607 1612810467.6428306
train: epoch 152, iter 3700, loss: 1.927551, top_1: 0.786523, top_k: 0.923125, samples/s: 1325.461 1612810486.956845
train: epoch 152, iter 3800, loss: 1.851650, top_1: 0.784766, top_k: 0.923555, samples/s: 1342.110 1612810506.0313213
train: epoch 152, iter 3900, loss: 1.801863, top_1: 0.789609, top_k: 0.922188, samples/s: 1334.481 1612810525.214797
train: epoch 152, iter 4000, loss: 1.968483, top_1: 0.787188, top_k: 0.925625, samples/s: 1338.318 1612810544.3432803
train: epoch 152, iter 4100, loss: 1.885182, top_1: 0.788789, top_k: 0.924375, samples/s: 1338.824 1612810563.4645603
train: epoch 152, iter 4200, loss: 1.810786, top_1: 0.781055, top_k: 0.922930, samples/s: 1339.075 1612810582.58223
train: epoch 152, iter 4300, loss: 2.004367, top_1: 0.781602, top_k: 0.921250, samples/s: 1334.132 1612810601.7707248
train: epoch 152, iter 4400, loss: 1.896293, top_1: 0.785703, top_k: 0.925469, samples/s: 1331.736 1612810620.9937747
train: epoch 152, iter 4500, loss: 1.957599, top_1: 0.784609, top_k: 0.923125, samples/s: 1333.435 1612810640.1922526
train: epoch 152, iter 4600, loss: 1.989312, top_1: 0.784258, top_k: 0.923789, samples/s: 1342.480 1612810659.261423
train: epoch 152, iter 4700, loss: 1.766854, top_1: 0.783438, top_k: 0.924023, samples/s: 1337.118 1612810678.4070754
train: epoch 152, iter 4800, loss: 2.019639, top_1: 0.787148, top_k: 0.925000, samples/s: 1333.578 1612810697.6036472
train: epoch 152, iter 4900, loss: 2.044446, top_1: 0.786641, top_k: 0.924687, samples/s: 1336.500 1612810716.758188
train: epoch 152, iter 5000, loss: 1.977281, top_1: 0.784062, top_k: 0.925391, samples/s: 1341.226 1612810735.8450928
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_152.
validation: epoch 152, iter 195, top_1: 0.764303, top_k: 0.932612, samples/s: 2739.782 1612810754.637409
train: epoch 153, iter 100, loss: 1.899796, top_1: 0.787617, top_k: 0.926250, samples/s: 1355.900 1612810789.794898
train: epoch 153, iter 200, loss: 2.002759, top_1: 0.788516, top_k: 0.923867, samples/s: 1362.347 1612810808.5858686
train: epoch 153, iter 300, loss: 1.899926, top_1: 0.791172, top_k: 0.924922, samples/s: 1360.032 1612810827.4090517
train: epoch 153, iter 400, loss: 1.966623, top_1: 0.785859, top_k: 0.922500, samples/s: 1355.694 1612810846.2922785
train: epoch 153, iter 500, loss: 1.808759, top_1: 0.789023, top_k: 0.925703, samples/s: 1336.235 1612810865.450676
train: epoch 153, iter 600, loss: 1.808851, top_1: 0.788203, top_k: 0.923594, samples/s: 1329.501 1612810884.7059376
train: epoch 153, iter 700, loss: 1.893456, top_1: 0.783867, top_k: 0.923555, samples/s: 1329.218 1612810903.965381
train: epoch 153, iter 800, loss: 1.785743, top_1: 0.785781, top_k: 0.927500, samples/s: 1335.004 1612810923.1413312
train: epoch 153, iter 900, loss: 1.839143, top_1: 0.783945, top_k: 0.922695, samples/s: 1319.336 1612810942.5451803
train: epoch 153, iter 1000, loss: 1.952832, top_1: 0.786328, top_k: 0.924766, samples/s: 1335.986 1612810961.706952
train: epoch 153, iter 1100, loss: 2.070018, top_1: 0.784961, top_k: 0.924922, samples/s: 1331.762 1612810980.9295619
train: epoch 153, iter 1200, loss: 1.961022, top_1: 0.780312, top_k: 0.921914, samples/s: 1335.552 1612811000.0977027
train: epoch 153, iter 1300, loss: 1.922526, top_1: 0.786367, top_k: 0.923711, samples/s: 1328.908 1612811019.361592
train: epoch 153, iter 1400, loss: 1.817224, top_1: 0.781602, top_k: 0.921250, samples/s: 1323.605 1612811038.70271
train: epoch 153, iter 1500, loss: 1.911152, top_1: 0.784141, top_k: 0.922031, samples/s: 1341.138 1612811057.7909706
train: epoch 153, iter 1600, loss: 1.831225, top_1: 0.784648, top_k: 0.923398, samples/s: 1327.830 1612811077.0705392
train: epoch 153, iter 1700, loss: 2.037618, top_1: 0.783164, top_k: 0.923672, samples/s: 1332.640 1612811096.2806063
train: epoch 153, iter 1800, loss: 1.991579, top_1: 0.781484, top_k: 0.923672, samples/s: 1330.300 1612811115.5243855
train: epoch 153, iter 1900, loss: 1.857275, top_1: 0.786367, top_k: 0.925469, samples/s: 1327.574 1612811134.807709
train: epoch 153, iter 2000, loss: 2.031808, top_1: 0.782305, top_k: 0.924609, samples/s: 1343.797 1612811153.8581078
train: epoch 153, iter 2100, loss: 1.844023, top_1: 0.786641, top_k: 0.925352, samples/s: 1332.994 1612811173.0629926
train: epoch 153, iter 2200, loss: 1.950693, top_1: 0.789180, top_k: 0.926289, samples/s: 1331.058 1612811192.2958622
train: epoch 153, iter 2300, loss: 1.990762, top_1: 0.783750, top_k: 0.922305, samples/s: 1329.850 1612811211.5462387
train: epoch 153, iter 2400, loss: 1.811197, top_1: 0.789883, top_k: 0.925625, samples/s: 1323.280 1612811230.8919904
train: epoch 153, iter 2500, loss: 2.012429, top_1: 0.783555, top_k: 0.925430, samples/s: 1340.159 1612811249.99423
train: epoch 153, iter 2600, loss: 1.893558, top_1: 0.784414, top_k: 0.923789, samples/s: 1327.267 1612811269.2820146
train: epoch 153, iter 2700, loss: 1.875327, top_1: 0.784375, top_k: 0.924258, samples/s: 1328.365 1612811288.5538466
train: epoch 153, iter 2800, loss: 1.937236, top_1: 0.783555, top_k: 0.922656, samples/s: 1335.456 1612811307.7232347
train: epoch 153, iter 2900, loss: 1.978410, top_1: 0.784609, top_k: 0.922969, samples/s: 1339.579 1612811326.833762
train: epoch 153, iter 3000, loss: 1.959277, top_1: 0.791094, top_k: 0.924961, samples/s: 1329.156 1612811346.094049
train: epoch 153, iter 3100, loss: 1.871633, top_1: 0.784727, top_k: 0.923398, samples/s: 1334.722 1612811365.2741337
train: epoch 153, iter 3200, loss: 1.968085, top_1: 0.788906, top_k: 0.926797, samples/s: 1335.640 1612811384.4409866
train: epoch 153, iter 3300, loss: 1.952689, top_1: 0.785586, top_k: 0.927070, samples/s: 1335.166 1612811403.6146128
train: epoch 153, iter 3400, loss: 1.877332, top_1: 0.790703, top_k: 0.927227, samples/s: 1334.630 1612811422.7959511
train: epoch 153, iter 3500, loss: 1.972014, top_1: 0.789805, top_k: 0.924102, samples/s: 1331.139 1612811442.027622
train: epoch 153, iter 3600, loss: 1.875781, top_1: 0.787930, top_k: 0.927578, samples/s: 1329.045 1612811461.289565
train: epoch 153, iter 3700, loss: 1.945654, top_1: 0.783594, top_k: 0.925703, samples/s: 1334.996 1612811480.4656594
train: epoch 153, iter 3800, loss: 1.827975, top_1: 0.787266, top_k: 0.925039, samples/s: 1335.399 1612811499.6358936
train: epoch 153, iter 3900, loss: 1.831640, top_1: 0.785234, top_k: 0.923945, samples/s: 1334.771 1612811518.8152173
train: epoch 153, iter 4000, loss: 1.974614, top_1: 0.784336, top_k: 0.924648, samples/s: 1334.843 1612811537.9935384
train: epoch 153, iter 4100, loss: 1.991100, top_1: 0.787422, top_k: 0.925391, samples/s: 1331.968 1612811557.2131965
train: epoch 153, iter 4200, loss: 2.062316, top_1: 0.787656, top_k: 0.923008, samples/s: 1334.141 1612811576.4015834
train: epoch 153, iter 4300, loss: 1.921670, top_1: 0.785430, top_k: 0.925078, samples/s: 1333.692 1612811595.596488
train: epoch 153, iter 4400, loss: 1.947866, top_1: 0.784531, top_k: 0.922461, samples/s: 1336.598 1612811614.7495537
train: epoch 153, iter 4500, loss: 1.905287, top_1: 0.786914, top_k: 0.924063, samples/s: 1330.650 1612811633.988293
train: epoch 153, iter 4600, loss: 1.800719, top_1: 0.786445, top_k: 0.923867, samples/s: 1329.952 1612811653.2370799
train: epoch 153, iter 4700, loss: 1.797801, top_1: 0.788398, top_k: 0.927031, samples/s: 1330.993 1612811672.470862
train: epoch 153, iter 4800, loss: 1.974862, top_1: 0.786641, top_k: 0.921914, samples/s: 1336.373 1612811691.6271782
train: epoch 153, iter 4900, loss: 1.781111, top_1: 0.787930, top_k: 0.923750, samples/s: 1325.594 1612811710.9393373
train: epoch 153, iter 5000, loss: 2.005576, top_1: 0.783516, top_k: 0.923945, samples/s: 1332.435 1612811730.1522257
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_153.
validation: epoch 153, iter 195, top_1: 0.764383, top_k: 0.932312, samples/s: 2840.162 1612811748.2949467
train: epoch 154, iter 100, loss: 1.943396, top_1: 0.790273, top_k: 0.926016, samples/s: 1361.727 1612811783.483943
train: epoch 154, iter 200, loss: 1.985235, top_1: 0.788203, top_k: 0.925625, samples/s: 1361.398 1612811802.2881207
train: epoch 154, iter 300, loss: 1.930511, top_1: 0.787891, top_k: 0.924570, samples/s: 1359.195 1612811821.1227956
train: epoch 154, iter 400, loss: 1.937972, top_1: 0.789609, top_k: 0.927813, samples/s: 1356.696 1612811839.9921112
train: epoch 154, iter 500, loss: 1.809100, top_1: 0.784492, top_k: 0.924180, samples/s: 1338.525 1612811859.1177363
train: epoch 154, iter 600, loss: 1.854207, top_1: 0.783164, top_k: 0.925625, samples/s: 1328.719 1612811878.3843734
train: epoch 154, iter 700, loss: 1.920293, top_1: 0.790937, top_k: 0.926445, samples/s: 1334.952 1612811897.5611262
train: epoch 154, iter 800, loss: 1.992941, top_1: 0.788555, top_k: 0.924766, samples/s: 1331.846 1612811916.7824655
train: epoch 154, iter 900, loss: 1.927686, top_1: 0.787461, top_k: 0.926367, samples/s: 1335.392 1612811935.9529452
train: epoch 154, iter 1000, loss: 2.021636, top_1: 0.786602, top_k: 0.925547, samples/s: 1332.435 1612811955.1659415
train: epoch 154, iter 1100, loss: 1.881362, top_1: 0.783047, top_k: 0.927578, samples/s: 1338.886 1612811974.2862153
train: epoch 154, iter 1200, loss: 1.955850, top_1: 0.786680, top_k: 0.926875, samples/s: 1339.086 1612811993.4037478
train: epoch 154, iter 1300, loss: 1.948384, top_1: 0.786758, top_k: 0.925352, samples/s: 1337.753 1612812012.5403564
train: epoch 154, iter 1400, loss: 1.919931, top_1: 0.784102, top_k: 0.921797, samples/s: 1336.443 1612812031.6955943
train: epoch 154, iter 1500, loss: 1.951663, top_1: 0.785508, top_k: 0.925117, samples/s: 1327.098 1612812050.985799
train: epoch 154, iter 1600, loss: 2.025932, top_1: 0.783398, top_k: 0.921250, samples/s: 1334.284 1612812070.1721537
train: epoch 154, iter 1700, loss: 1.862185, top_1: 0.789531, top_k: 0.925820, samples/s: 1335.518 1612812089.3407323
train: epoch 154, iter 1800, loss: 1.841393, top_1: 0.784687, top_k: 0.925625, samples/s: 1335.458 1612812108.5102382
train: epoch 154, iter 1900, loss: 1.833276, top_1: 0.788594, top_k: 0.924141, samples/s: 1334.533 1612812127.692953
train: epoch 154, iter 2000, loss: 1.957411, top_1: 0.784922, top_k: 0.923789, samples/s: 1336.758 1612812146.84373
train: epoch 154, iter 2100, loss: 1.874452, top_1: 0.792656, top_k: 0.926875, samples/s: 1336.360 1612812166.0002263
train: epoch 154, iter 2200, loss: 1.885674, top_1: 0.784687, top_k: 0.924336, samples/s: 1340.302 1612812185.1004558
train: epoch 154, iter 2300, loss: 1.866833, top_1: 0.789492, top_k: 0.925000, samples/s: 1342.237 1612812204.1730936
train: epoch 154, iter 2400, loss: 1.773923, top_1: 0.791445, top_k: 0.923398, samples/s: 1326.519 1612812223.471659
train: epoch 154, iter 2500, loss: 1.949872, top_1: 0.786406, top_k: 0.924727, samples/s: 1336.301 1612812242.6290944
train: epoch 154, iter 2600, loss: 1.978672, top_1: 0.786719, top_k: 0.926094, samples/s: 1332.516 1612812261.8408241
train: epoch 154, iter 2700, loss: 1.883289, top_1: 0.787109, top_k: 0.924687, samples/s: 1335.967 1612812281.0030224
train: epoch 154, iter 2800, loss: 1.885727, top_1: 0.786992, top_k: 0.923398, samples/s: 1341.620 1612812300.0844014
train: epoch 154, iter 2900, loss: 1.891330, top_1: 0.789336, top_k: 0.927461, samples/s: 1336.231 1612812319.242729
train: epoch 154, iter 3000, loss: 1.895363, top_1: 0.790039, top_k: 0.924453, samples/s: 1335.483 1612812338.411829
train: epoch 154, iter 3100, loss: 1.893256, top_1: 0.785781, top_k: 0.924531, samples/s: 1338.659 1612812357.5354517
train: epoch 154, iter 3200, loss: 1.916440, top_1: 0.786172, top_k: 0.925156, samples/s: 1333.554 1612812376.732369
train: epoch 154, iter 3300, loss: 1.819841, top_1: 0.788398, top_k: 0.926602, samples/s: 1342.913 1612812395.7953498
train: epoch 154, iter 3400, loss: 1.776965, top_1: 0.788984, top_k: 0.924648, samples/s: 1337.740 1612812414.932184
train: epoch 154, iter 3500, loss: 1.999961, top_1: 0.788633, top_k: 0.924375, samples/s: 1339.225 1612812434.0476239
train: epoch 154, iter 3600, loss: 2.070230, top_1: 0.781016, top_k: 0.923359, samples/s: 1336.896 1612812453.1964843
train: epoch 154, iter 3700, loss: 1.992863, top_1: 0.782773, top_k: 0.922344, samples/s: 1339.966 1612812472.301448
train: epoch 154, iter 3800, loss: 1.990575, top_1: 0.785195, top_k: 0.924336, samples/s: 1335.472 1612812491.4707065
train: epoch 154, iter 3900, loss: 1.923535, top_1: 0.783164, top_k: 0.923359, samples/s: 1335.554 1612812510.63877
train: epoch 154, iter 4000, loss: 1.855032, top_1: 0.790352, top_k: 0.926055, samples/s: 1340.394 1612812529.7376034
train: epoch 154, iter 4100, loss: 1.982854, top_1: 0.787969, top_k: 0.926758, samples/s: 1342.481 1612812548.8067892
train: epoch 154, iter 4200, loss: 2.129666, top_1: 0.787656, top_k: 0.926953, samples/s: 1326.149 1612812568.1108396
train: epoch 154, iter 4300, loss: 1.960045, top_1: 0.785586, top_k: 0.922852, samples/s: 1346.943 1612812587.1168609
train: epoch 154, iter 4400, loss: 1.862388, top_1: 0.788438, top_k: 0.925195, samples/s: 1337.516 1612812606.2567065
train: epoch 154, iter 4500, loss: 1.846006, top_1: 0.786914, top_k: 0.924453, samples/s: 1328.460 1612812625.5271604
train: epoch 154, iter 4600, loss: 1.977510, top_1: 0.785859, top_k: 0.923477, samples/s: 1344.193 1612812644.5720696
train: epoch 154, iter 4700, loss: 1.904639, top_1: 0.787266, top_k: 0.926367, samples/s: 1338.057 1612812663.7043371
train: epoch 154, iter 4800, loss: 1.948469, top_1: 0.784531, top_k: 0.923516, samples/s: 1332.084 1612812682.9222825
train: epoch 154, iter 4900, loss: 1.792387, top_1: 0.788477, top_k: 0.925742, samples/s: 1338.512 1612812702.047978
train: epoch 154, iter 5000, loss: 1.966441, top_1: 0.786719, top_k: 0.925664, samples/s: 1339.191 1612812721.1640928
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_154.
validation: epoch 154, iter 195, top_1: 0.765004, top_k: 0.932893, samples/s: 2771.204 1612812739.7468271
train: epoch 155, iter 100, loss: 1.845658, top_1: 0.790977, top_k: 0.924883, samples/s: 1364.427 1612812774.8322644
train: epoch 155, iter 200, loss: 1.811761, top_1: 0.789258, top_k: 0.926797, samples/s: 1361.115 1612812793.6402268
train: epoch 155, iter 300, loss: 1.844043, top_1: 0.784414, top_k: 0.924141, samples/s: 1364.025 1612812812.4082477
train: epoch 155, iter 400, loss: 1.799747, top_1: 0.788438, top_k: 0.926094, samples/s: 1353.803 1612812831.3180268
train: epoch 155, iter 500, loss: 1.902857, top_1: 0.783320, top_k: 0.927422, samples/s: 1342.559 1612812850.386028
train: epoch 155, iter 600, loss: 1.912399, top_1: 0.785937, top_k: 0.924531, samples/s: 1336.995 1612812869.5334656
train: epoch 155, iter 700, loss: 1.967673, top_1: 0.786250, top_k: 0.926562, samples/s: 1343.081 1612812888.5940964
train: epoch 155, iter 800, loss: 1.883603, top_1: 0.788359, top_k: 0.927148, samples/s: 1333.841 1612812907.7868142
train: epoch 155, iter 900, loss: 1.914657, top_1: 0.783516, top_k: 0.923516, samples/s: 1327.693 1612812927.06842
train: epoch 155, iter 1000, loss: 1.898315, top_1: 0.789648, top_k: 0.924727, samples/s: 1337.507 1612812946.2083974
train: epoch 155, iter 1100, loss: 1.845167, top_1: 0.785703, top_k: 0.925234, samples/s: 1334.102 1612812965.3974185
train: epoch 155, iter 1200, loss: 1.860537, top_1: 0.784805, top_k: 0.922891, samples/s: 1342.583 1612812984.4651277
train: epoch 155, iter 1300, loss: 1.869197, top_1: 0.783945, top_k: 0.924883, samples/s: 1327.550 1612813003.7488184
train: epoch 155, iter 1400, loss: 1.905325, top_1: 0.789805, top_k: 0.924648, samples/s: 1335.909 1612813022.9117792
train: epoch 155, iter 1500, loss: 1.912821, top_1: 0.790234, top_k: 0.927188, samples/s: 1335.339 1612813042.0828834
train: epoch 155, iter 1600, loss: 1.926460, top_1: 0.788906, top_k: 0.926055, samples/s: 1341.086 1612813061.1719306
train: epoch 155, iter 1700, loss: 1.847783, top_1: 0.786016, top_k: 0.923633, samples/s: 1328.811 1612813080.437312
train: epoch 155, iter 1800, loss: 1.989249, top_1: 0.785898, top_k: 0.923359, samples/s: 1332.699 1612813099.6463938
train: epoch 155, iter 1900, loss: 1.938976, top_1: 0.784414, top_k: 0.921328, samples/s: 1331.229 1612813118.8767235
train: epoch 155, iter 2000, loss: 1.961190, top_1: 0.786602, top_k: 0.924414, samples/s: 1333.009 1612813138.0814352
train: epoch 155, iter 2100, loss: 1.900450, top_1: 0.784805, top_k: 0.924844, samples/s: 1334.458 1612813157.2651944
train: epoch 155, iter 2200, loss: 1.848600, top_1: 0.785977, top_k: 0.926719, samples/s: 1335.201 1612813176.4383862
train: epoch 155, iter 2300, loss: 1.880845, top_1: 0.789727, top_k: 0.926914, samples/s: 1335.676 1612813195.6046638
train: epoch 155, iter 2400, loss: 1.840625, top_1: 0.787383, top_k: 0.925273, samples/s: 1335.572 1612813214.772479
train: epoch 155, iter 2500, loss: 2.009057, top_1: 0.786055, top_k: 0.923633, samples/s: 1337.167 1612813233.9174788
train: epoch 155, iter 2600, loss: 1.989849, top_1: 0.786992, top_k: 0.924961, samples/s: 1334.558 1612813253.099852
train: epoch 155, iter 2700, loss: 1.877445, top_1: 0.786953, top_k: 0.924141, samples/s: 1329.128 1612813272.3606987
train: epoch 155, iter 2800, loss: 1.785724, top_1: 0.784102, top_k: 0.926445, samples/s: 1335.745 1612813291.5259523
train: epoch 155, iter 2900, loss: 1.887805, top_1: 0.788086, top_k: 0.925430, samples/s: 1338.600 1612813310.6503606
train: epoch 155, iter 3000, loss: 1.837198, top_1: 0.793047, top_k: 0.926680, samples/s: 1334.062 1612813329.8399
train: epoch 155, iter 3100, loss: 1.878904, top_1: 0.781953, top_k: 0.923359, samples/s: 1333.338 1612813349.0398016
train: epoch 155, iter 3200, loss: 1.990934, top_1: 0.786523, top_k: 0.923203, samples/s: 1333.101 1612813368.2432847
train: epoch 155, iter 3300, loss: 1.810777, top_1: 0.790000, top_k: 0.928594, samples/s: 1335.561 1612813387.41119
train: epoch 155, iter 3400, loss: 2.016230, top_1: 0.782578, top_k: 0.924219, samples/s: 1331.795 1612813406.6333508
train: epoch 155, iter 3500, loss: 2.036113, top_1: 0.782969, top_k: 0.923984, samples/s: 1333.067 1612813425.8372645
train: epoch 155, iter 3600, loss: 2.067661, top_1: 0.784883, top_k: 0.923633, samples/s: 1334.406 1612813445.0218327
train: epoch 155, iter 3700, loss: 1.896094, top_1: 0.784258, top_k: 0.925000, samples/s: 1336.040 1612813464.182808
train: epoch 155, iter 3800, loss: 1.958590, top_1: 0.785625, top_k: 0.922266, samples/s: 1334.915 1612813483.3600583
train: epoch 155, iter 3900, loss: 1.827182, top_1: 0.788008, top_k: 0.926484, samples/s: 1334.431 1612813502.5442717
train: epoch 155, iter 4000, loss: 1.950409, top_1: 0.786406, top_k: 0.924805, samples/s: 1332.851 1612813521.751348
train: epoch 155, iter 4100, loss: 1.916717, top_1: 0.789062, top_k: 0.926719, samples/s: 1333.861 1612813540.943819
train: epoch 155, iter 4200, loss: 2.030089, top_1: 0.786523, top_k: 0.926914, samples/s: 1337.383 1612813560.085543
train: epoch 155, iter 4300, loss: 1.814017, top_1: 0.783711, top_k: 0.923555, samples/s: 1337.015 1612813579.2326503
train: epoch 155, iter 4400, loss: 1.836947, top_1: 0.782617, top_k: 0.923086, samples/s: 1336.863 1612813598.381935
train: epoch 155, iter 4500, loss: 1.947509, top_1: 0.786328, top_k: 0.924531, samples/s: 1332.217 1612813617.5980208
train: epoch 155, iter 4600, loss: 1.824119, top_1: 0.787227, top_k: 0.925664, samples/s: 1335.644 1612813636.7647922
train: epoch 155, iter 4700, loss: 1.830092, top_1: 0.790977, top_k: 0.927188, samples/s: 1334.377 1612813655.949821
train: epoch 155, iter 4800, loss: 1.896342, top_1: 0.784922, top_k: 0.924805, samples/s: 1336.809 1612813675.0999017
train: epoch 155, iter 4900, loss: 1.835651, top_1: 0.784297, top_k: 0.925000, samples/s: 1338.626 1612813694.2239327
train: epoch 155, iter 5000, loss: 1.858156, top_1: 0.788164, top_k: 0.927539, samples/s: 1338.133 1612813713.3550875
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_155.
validation: epoch 155, iter 195, top_1: 0.765144, top_k: 0.933153, samples/s: 2726.735 1612813732.2384617
train: epoch 156, iter 100, loss: 2.015333, top_1: 0.786523, top_k: 0.923086, samples/s: 1358.789 1612813767.1148753
train: epoch 156, iter 200, loss: 1.699914, top_1: 0.788984, top_k: 0.926992, samples/s: 1364.286 1612813785.879191
train: epoch 156, iter 300, loss: 1.793374, top_1: 0.785586, top_k: 0.923477, samples/s: 1361.004 1612813804.6888876
train: epoch 156, iter 400, loss: 1.964190, top_1: 0.787188, top_k: 0.926094, samples/s: 1357.607 1612813823.545554
train: epoch 156, iter 500, loss: 1.967463, top_1: 0.789062, top_k: 0.925078, samples/s: 1330.715 1612813842.783328
train: epoch 156, iter 600, loss: 1.863718, top_1: 0.789023, top_k: 0.926953, samples/s: 1334.695 1612813861.9637384
train: epoch 156, iter 700, loss: 1.970462, top_1: 0.788086, top_k: 0.924922, samples/s: 1329.626 1612813881.2173195
train: epoch 156, iter 800, loss: 2.131677, top_1: 0.784961, top_k: 0.925547, samples/s: 1322.926 1612813900.568304
train: epoch 156, iter 900, loss: 2.028788, top_1: 0.788711, top_k: 0.923945, samples/s: 1330.223 1612813919.81321
train: epoch 156, iter 1000, loss: 1.931052, top_1: 0.788047, top_k: 0.926836, samples/s: 1343.158 1612813938.8728073
train: epoch 156, iter 1100, loss: 1.833368, top_1: 0.786328, top_k: 0.925195, samples/s: 1328.747 1612813958.1390224
train: epoch 156, iter 1200, loss: 1.981072, top_1: 0.786758, top_k: 0.922930, samples/s: 1329.220 1612813977.3984406
train: epoch 156, iter 1300, loss: 1.830099, top_1: 0.785937, top_k: 0.924531, samples/s: 1328.429 1612813996.6693149
train: epoch 156, iter 1400, loss: 1.852529, top_1: 0.792656, top_k: 0.925391, samples/s: 1335.699 1612814015.835314
train: epoch 156, iter 1500, loss: 1.921320, top_1: 0.787773, top_k: 0.926094, samples/s: 1337.290 1612814034.9785087
train: epoch 156, iter 1600, loss: 1.979388, top_1: 0.788984, top_k: 0.926836, samples/s: 1327.579 1612814054.2618113
train: epoch 156, iter 1700, loss: 1.949619, top_1: 0.785430, top_k: 0.923008, samples/s: 1336.167 1612814073.421023
train: epoch 156, iter 1800, loss: 1.777717, top_1: 0.791484, top_k: 0.927109, samples/s: 1335.761 1612814092.5861995
train: epoch 156, iter 1900, loss: 1.828622, top_1: 0.786680, top_k: 0.925391, samples/s: 1336.104 1612814111.7463002
train: epoch 156, iter 2000, loss: 1.969060, top_1: 0.785430, top_k: 0.922188, samples/s: 1322.130 1612814131.1089897
train: epoch 156, iter 2100, loss: 1.666748, top_1: 0.788789, top_k: 0.924414, samples/s: 1333.515 1612814150.3063743
train: epoch 156, iter 2200, loss: 1.910895, top_1: 0.783672, top_k: 0.924180, samples/s: 1330.962 1612814169.5406756
train: epoch 156, iter 2300, loss: 1.855059, top_1: 0.783008, top_k: 0.923867, samples/s: 1337.285 1612814188.6838973
train: epoch 156, iter 2400, loss: 1.888971, top_1: 0.786055, top_k: 0.925781, samples/s: 1334.425 1612814207.86827
train: epoch 156, iter 2500, loss: 1.967851, top_1: 0.787539, top_k: 0.923320, samples/s: 1333.465 1612814227.066363
train: epoch 156, iter 2600, loss: 1.950170, top_1: 0.786953, top_k: 0.924336, samples/s: 1332.366 1612814246.2802596
train: epoch 156, iter 2700, loss: 1.948012, top_1: 0.782617, top_k: 0.921562, samples/s: 1325.320 1612814265.5963955
train: epoch 156, iter 2800, loss: 1.974693, top_1: 0.788125, top_k: 0.925391, samples/s: 1342.781 1612814284.6612525
train: epoch 156, iter 2900, loss: 1.937008, top_1: 0.783867, top_k: 0.924531, samples/s: 1335.396 1612814303.8315763
train: epoch 156, iter 3000, loss: 2.032321, top_1: 0.787539, top_k: 0.923789, samples/s: 1334.240 1612814323.018511
train: epoch 156, iter 3100, loss: 1.847573, top_1: 0.785703, top_k: 0.923789, samples/s: 1335.224 1612814342.191336
train: epoch 156, iter 3200, loss: 1.851378, top_1: 0.786367, top_k: 0.925898, samples/s: 1336.140 1612814361.35098
train: epoch 156, iter 3300, loss: 1.867341, top_1: 0.789883, top_k: 0.926289, samples/s: 1333.122 1612814380.5540078
train: epoch 156, iter 3400, loss: 1.747687, top_1: 0.788398, top_k: 0.928164, samples/s: 1337.487 1612814399.6943588
train: epoch 156, iter 3500, loss: 1.791563, top_1: 0.788438, top_k: 0.925352, samples/s: 1335.033 1612814418.869978
train: epoch 156, iter 3600, loss: 1.941023, top_1: 0.787461, top_k: 0.925117, samples/s: 1332.849 1612814438.0769486
train: epoch 156, iter 3700, loss: 1.849685, top_1: 0.790195, top_k: 0.925977, samples/s: 1336.099 1612814457.237146
train: epoch 156, iter 3800, loss: 1.809514, top_1: 0.785156, top_k: 0.922539, samples/s: 1333.299 1612814476.437664
train: epoch 156, iter 3900, loss: 1.984953, top_1: 0.785039, top_k: 0.924883, samples/s: 1330.982 1612814495.6716876
train: epoch 156, iter 4000, loss: 1.917148, top_1: 0.786289, top_k: 0.923711, samples/s: 1339.287 1612814514.7862148
train: epoch 156, iter 4100, loss: 1.881098, top_1: 0.789102, top_k: 0.925391, samples/s: 1334.473 1612814533.9698176
train: epoch 156, iter 4200, loss: 1.873660, top_1: 0.786953, top_k: 0.925781, samples/s: 1336.714 1612814553.121319
train: epoch 156, iter 4300, loss: 2.080501, top_1: 0.785781, top_k: 0.923555, samples/s: 1325.623 1612814572.4330218
train: epoch 156, iter 4400, loss: 1.821682, top_1: 0.786484, top_k: 0.926016, samples/s: 1342.458 1612814591.5024965
train: epoch 156, iter 4500, loss: 1.879542, top_1: 0.787656, top_k: 0.927344, samples/s: 1337.363 1612814610.644571
train: epoch 156, iter 4600, loss: 1.866160, top_1: 0.786055, top_k: 0.924063, samples/s: 1329.630 1612814629.898107
train: epoch 156, iter 4700, loss: 1.944273, top_1: 0.785430, top_k: 0.923750, samples/s: 1336.029 1612814649.059411
train: epoch 156, iter 4800, loss: 1.939774, top_1: 0.787695, top_k: 0.925898, samples/s: 1339.364 1612814668.172937
train: epoch 156, iter 4900, loss: 2.043879, top_1: 0.783945, top_k: 0.922695, samples/s: 1338.169 1612814687.3034666
train: epoch 156, iter 5000, loss: 2.073716, top_1: 0.780820, top_k: 0.922930, samples/s: 1329.011 1612814706.5659416
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_156.
validation: epoch 156, iter 195, top_1: 0.764744, top_k: 0.932913, samples/s: 2737.632 1612814725.372501
train: epoch 157, iter 100, loss: 1.991562, top_1: 0.783945, top_k: 0.928047, samples/s: 1360.492 1612814765.7497268
train: epoch 157, iter 200, loss: 1.984631, top_1: 0.784180, top_k: 0.921797, samples/s: 1360.865 1612814784.5614712
train: epoch 157, iter 300, loss: 1.883232, top_1: 0.785625, top_k: 0.923906, samples/s: 1360.098 1612814803.3834348
train: epoch 157, iter 400, loss: 2.004765, top_1: 0.791406, top_k: 0.926016, samples/s: 1360.553 1612814822.1992486
train: epoch 157, iter 500, loss: 1.827611, top_1: 0.786133, top_k: 0.923945, samples/s: 1338.441 1612814841.3259797
train: epoch 157, iter 600, loss: 1.935155, top_1: 0.787891, top_k: 0.928594, samples/s: 1340.395 1612814860.4248257
train: epoch 157, iter 700, loss: 1.928570, top_1: 0.785234, top_k: 0.924219, samples/s: 1327.193 1612814879.7137246
train: epoch 157, iter 800, loss: 2.092421, top_1: 0.787227, top_k: 0.924727, samples/s: 1337.958 1612814898.8473675
train: epoch 157, iter 900, loss: 2.088280, top_1: 0.786250, top_k: 0.924922, samples/s: 1329.721 1612814918.0995085
train: epoch 157, iter 1000, loss: 1.807956, top_1: 0.785000, top_k: 0.924492, samples/s: 1329.427 1612814937.3559272
train: epoch 157, iter 1100, loss: 1.876920, top_1: 0.786328, top_k: 0.924492, samples/s: 1334.444 1612814956.5399132
train: epoch 157, iter 1200, loss: 1.909363, top_1: 0.786875, top_k: 0.923906, samples/s: 1334.345 1612814975.7253532
train: epoch 157, iter 1300, loss: 1.920629, top_1: 0.785039, top_k: 0.923672, samples/s: 1334.048 1612814994.91511
train: epoch 157, iter 1400, loss: 1.946765, top_1: 0.787930, top_k: 0.924375, samples/s: 1330.692 1612815014.1531844
train: epoch 157, iter 1500, loss: 1.960112, top_1: 0.783828, top_k: 0.921211, samples/s: 1329.138 1612815033.413766
train: epoch 157, iter 1600, loss: 1.989820, top_1: 0.788555, top_k: 0.924570, samples/s: 1333.689 1612815052.6086519
train: epoch 157, iter 1700, loss: 1.926854, top_1: 0.784180, top_k: 0.925547, samples/s: 1323.353 1612815071.9535356
train: epoch 157, iter 1800, loss: 1.980154, top_1: 0.783164, top_k: 0.922813, samples/s: 1336.948 1612815091.101599
train: epoch 157, iter 1900, loss: 1.908331, top_1: 0.783281, top_k: 0.922695, samples/s: 1332.314 1612815110.3162518
train: epoch 157, iter 2000, loss: 1.887500, top_1: 0.785000, top_k: 0.924648, samples/s: 1336.142 1612815129.47601
train: epoch 157, iter 2100, loss: 1.974482, top_1: 0.791094, top_k: 0.926758, samples/s: 1331.234 1612815148.7062194
train: epoch 157, iter 2200, loss: 1.778621, top_1: 0.785078, top_k: 0.925195, samples/s: 1333.228 1612815167.907785
train: epoch 157, iter 2300, loss: 2.002175, top_1: 0.785234, top_k: 0.922891, samples/s: 1330.574 1612815187.147492
train: epoch 157, iter 2400, loss: 2.011122, top_1: 0.789023, top_k: 0.922656, samples/s: 1332.249 1612815206.3632271
train: epoch 157, iter 2500, loss: 1.811058, top_1: 0.783633, top_k: 0.923828, samples/s: 1329.957 1612815225.6119306
train: epoch 157, iter 2600, loss: 2.013143, top_1: 0.787383, top_k: 0.927422, samples/s: 1334.027 1612815244.80188
train: epoch 157, iter 2700, loss: 1.940580, top_1: 0.789414, top_k: 0.927891, samples/s: 1339.714 1612815263.9104764
train: epoch 157, iter 2800, loss: 2.006918, top_1: 0.787188, top_k: 0.925234, samples/s: 1322.772 1612815283.2637327
train: epoch 157, iter 2900, loss: 1.943421, top_1: 0.785859, top_k: 0.927344, samples/s: 1337.140 1612815302.4091454
train: epoch 157, iter 3000, loss: 1.833648, top_1: 0.785234, top_k: 0.922227, samples/s: 1336.914 1612815321.5577168
train: epoch 157, iter 3100, loss: 2.163927, top_1: 0.786992, top_k: 0.924844, samples/s: 1324.676 1612815340.8831413
train: epoch 157, iter 3200, loss: 1.878286, top_1: 0.787070, top_k: 0.923398, samples/s: 1338.707 1612815360.0060534
train: epoch 157, iter 3300, loss: 1.997168, top_1: 0.784375, top_k: 0.924531, samples/s: 1329.144 1612815379.266634
train: epoch 157, iter 3400, loss: 1.876432, top_1: 0.786563, top_k: 0.925937, samples/s: 1338.762 1612815398.3887055
train: epoch 157, iter 3500, loss: 1.916894, top_1: 0.787383, top_k: 0.924727, samples/s: 1324.925 1612815417.7106228
train: epoch 157, iter 3600, loss: 1.830617, top_1: 0.789453, top_k: 0.925898, samples/s: 1329.702 1612815436.9630597
train: epoch 157, iter 3700, loss: 2.014109, top_1: 0.786758, top_k: 0.926875, samples/s: 1329.780 1612815456.2143607
train: epoch 157, iter 3800, loss: 1.911880, top_1: 0.784297, top_k: 0.924805, samples/s: 1335.480 1612815475.3834975
train: epoch 157, iter 3900, loss: 1.828881, top_1: 0.786445, top_k: 0.925664, samples/s: 1329.615 1612815494.6371338
train: epoch 157, iter 4000, loss: 1.889119, top_1: 0.787891, top_k: 0.924063, samples/s: 1328.170 1612815513.9118557
train: epoch 157, iter 4100, loss: 1.938309, top_1: 0.787617, top_k: 0.926406, samples/s: 1333.228 1612815533.1132967
train: epoch 157, iter 4200, loss: 1.766073, top_1: 0.785195, top_k: 0.924531, samples/s: 1328.081 1612815552.3892841
train: epoch 157, iter 4300, loss: 1.900607, top_1: 0.786953, top_k: 0.925586, samples/s: 1330.140 1612815571.6353865
train: epoch 157, iter 4400, loss: 1.946167, top_1: 0.787422, top_k: 0.924258, samples/s: 1334.129 1612815590.8238919
train: epoch 157, iter 4500, loss: 1.882429, top_1: 0.788828, top_k: 0.925195, samples/s: 1331.503 1612815610.0503204
train: epoch 157, iter 4600, loss: 1.958613, top_1: 0.781055, top_k: 0.923516, samples/s: 1331.318 1612815629.2793913
train: epoch 157, iter 4700, loss: 1.861104, top_1: 0.790039, top_k: 0.925781, samples/s: 1336.583 1612815648.4326797
train: epoch 157, iter 4800, loss: 1.992713, top_1: 0.786719, top_k: 0.925937, samples/s: 1329.075 1612815667.6943233
train: epoch 157, iter 4900, loss: 1.982495, top_1: 0.786758, top_k: 0.923984, samples/s: 1327.001 1612815686.9858608
train: epoch 157, iter 5000, loss: 1.918991, top_1: 0.787578, top_k: 0.924531, samples/s: 1333.236 1612815706.1872866
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_157.
validation: epoch 157, iter 195, top_1: 0.764483, top_k: 0.932712, samples/s: 2786.709 1612815724.6573386
train: epoch 158, iter 100, loss: 1.944422, top_1: 0.788867, top_k: 0.924102, samples/s: 1359.147 1612815759.502645
train: epoch 158, iter 200, loss: 1.993049, top_1: 0.788633, top_k: 0.927109, samples/s: 1359.467 1612815778.3337595
train: epoch 158, iter 300, loss: 1.945922, top_1: 0.786797, top_k: 0.923867, samples/s: 1360.524 1612815797.1498423
train: epoch 158, iter 400, loss: 2.042170, top_1: 0.784453, top_k: 0.924297, samples/s: 1360.398 1612815815.9678123
train: epoch 158, iter 500, loss: 1.972483, top_1: 0.786094, top_k: 0.924414, samples/s: 1333.378 1612815835.1672068
train: epoch 158, iter 600, loss: 1.861873, top_1: 0.786133, top_k: 0.924414, samples/s: 1339.633 1612815854.2768896
train: epoch 158, iter 700, loss: 1.889890, top_1: 0.786563, top_k: 0.924687, samples/s: 1335.526 1612815873.4454298
train: epoch 158, iter 800, loss: 1.952889, top_1: 0.784180, top_k: 0.925352, samples/s: 1336.835 1612815892.595096
train: epoch 158, iter 900, loss: 1.943180, top_1: 0.788047, top_k: 0.924102, samples/s: 1335.248 1612815911.7675738
train: epoch 158, iter 1000, loss: 1.942432, top_1: 0.788594, top_k: 0.926992, samples/s: 1334.453 1612815930.9514425
train: epoch 158, iter 1100, loss: 1.829873, top_1: 0.780781, top_k: 0.923555, samples/s: 1336.927 1612815950.0998769
train: epoch 158, iter 1200, loss: 1.786153, top_1: 0.790039, top_k: 0.927383, samples/s: 1327.715 1612815969.381113
train: epoch 158, iter 1300, loss: 1.927243, top_1: 0.786641, top_k: 0.925859, samples/s: 1337.851 1612815988.5162852
train: epoch 158, iter 1400, loss: 1.950441, top_1: 0.792383, top_k: 0.927227, samples/s: 1339.395 1612816007.629403
train: epoch 158, iter 1500, loss: 1.867777, top_1: 0.789219, top_k: 0.925586, samples/s: 1330.657 1612816026.8680084
train: epoch 158, iter 1600, loss: 1.947724, top_1: 0.786211, top_k: 0.926914, samples/s: 1340.150 1612816045.9703357
train: epoch 158, iter 1700, loss: 1.872176, top_1: 0.780195, top_k: 0.924141, samples/s: 1339.073 1612816065.0880125
train: epoch 158, iter 1800, loss: 2.057574, top_1: 0.783789, top_k: 0.921445, samples/s: 1329.352 1612816084.345512
train: epoch 158, iter 1900, loss: 2.051876, top_1: 0.786641, top_k: 0.923906, samples/s: 1333.964 1612816103.5364618
train: epoch 158, iter 2000, loss: 1.798043, top_1: 0.787813, top_k: 0.925469, samples/s: 1339.991 1612816122.6411004
train: epoch 158, iter 2100, loss: 1.893034, top_1: 0.791602, top_k: 0.925000, samples/s: 1332.178 1612816141.8577328
train: epoch 158, iter 2200, loss: 1.891426, top_1: 0.787188, top_k: 0.926211, samples/s: 1333.809 1612816161.0508666
train: epoch 158, iter 2300, loss: 1.896188, top_1: 0.785859, top_k: 0.926562, samples/s: 1336.836 1612816180.2005968
train: epoch 158, iter 2400, loss: 2.037730, top_1: 0.788516, top_k: 0.927578, samples/s: 1340.157 1612816199.302857
train: epoch 158, iter 2500, loss: 1.875852, top_1: 0.787891, top_k: 0.922930, samples/s: 1333.958 1612816218.4938257
train: epoch 158, iter 2600, loss: 1.895532, top_1: 0.788086, top_k: 0.926211, samples/s: 1344.083 1612816237.5402896
train: epoch 158, iter 2700, loss: 1.801164, top_1: 0.782773, top_k: 0.925000, samples/s: 1335.063 1612816256.7153604
train: epoch 158, iter 2800, loss: 1.864700, top_1: 0.787539, top_k: 0.923711, samples/s: 1337.144 1612816275.8606281
train: epoch 158, iter 2900, loss: 1.865938, top_1: 0.784453, top_k: 0.925391, samples/s: 1342.529 1612816294.929116
train: epoch 158, iter 3000, loss: 1.875517, top_1: 0.789453, top_k: 0.926680, samples/s: 1331.625 1612816314.1538124
train: epoch 158, iter 3100, loss: 1.931191, top_1: 0.780937, top_k: 0.923359, samples/s: 1337.476 1612816333.2943485
train: epoch 158, iter 3200, loss: 1.838703, top_1: 0.790430, top_k: 0.924063, samples/s: 1339.510 1612816352.4057825
train: epoch 158, iter 3300, loss: 1.878861, top_1: 0.789062, top_k: 0.926641, samples/s: 1336.306 1612816371.5630736
train: epoch 158, iter 3400, loss: 1.923512, top_1: 0.788672, top_k: 0.924297, samples/s: 1342.991 1612816390.6251493
train: epoch 158, iter 3500, loss: 1.772726, top_1: 0.789922, top_k: 0.924531, samples/s: 1342.599 1612816409.692535
train: epoch 158, iter 3600, loss: 2.088549, top_1: 0.786992, top_k: 0.924180, samples/s: 1333.093 1612816428.8959913
train: epoch 158, iter 3700, loss: 1.939823, top_1: 0.783828, top_k: 0.922539, samples/s: 1336.970 1612816448.0437746
train: epoch 158, iter 3800, loss: 1.945142, top_1: 0.785078, top_k: 0.922891, samples/s: 1341.782 1612816467.1228638
train: epoch 158, iter 3900, loss: 1.790382, top_1: 0.781289, top_k: 0.923906, samples/s: 1331.280 1612816486.35242
train: epoch 158, iter 4000, loss: 2.056653, top_1: 0.783438, top_k: 0.925195, samples/s: 1341.808 1612816505.4311545
train: epoch 158, iter 4100, loss: 2.019647, top_1: 0.785625, top_k: 0.926094, samples/s: 1339.804 1612816524.5384548
train: epoch 158, iter 4200, loss: 1.909200, top_1: 0.787539, top_k: 0.925469, samples/s: 1335.788 1612816543.7031255
train: epoch 158, iter 4300, loss: 1.937912, top_1: 0.783477, top_k: 0.926836, samples/s: 1338.314 1612816562.8316884
train: epoch 158, iter 4400, loss: 1.894233, top_1: 0.784219, top_k: 0.921172, samples/s: 1338.655 1612816581.9553487
train: epoch 158, iter 4500, loss: 1.812866, top_1: 0.786016, top_k: 0.927070, samples/s: 1337.832 1612816601.0907936
train: epoch 158, iter 4600, loss: 1.820081, top_1: 0.785234, top_k: 0.923672, samples/s: 1340.979 1612816620.181387
train: epoch 158, iter 4700, loss: 1.810043, top_1: 0.792070, top_k: 0.927109, samples/s: 1328.640 1612816639.4492714
train: epoch 158, iter 4800, loss: 1.873862, top_1: 0.786641, top_k: 0.924102, samples/s: 1348.733 1612816658.4299622
train: epoch 158, iter 4900, loss: 1.852549, top_1: 0.787813, top_k: 0.925625, samples/s: 1337.937 1612816677.5639312
train: epoch 158, iter 5000, loss: 1.992661, top_1: 0.786250, top_k: 0.925625, samples/s: 1339.269 1612816696.6788254
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_158.
validation: epoch 158, iter 195, top_1: 0.765124, top_k: 0.933093, samples/s: 2781.355 1612816715.1914625
train: epoch 159, iter 100, loss: 1.839301, top_1: 0.786797, top_k: 0.927617, samples/s: 1358.699 1612816750.032091
train: epoch 159, iter 200, loss: 1.869194, top_1: 0.782617, top_k: 0.920742, samples/s: 1359.976 1612816768.8559415
train: epoch 159, iter 300, loss: 1.792012, top_1: 0.784961, top_k: 0.925977, samples/s: 1364.259 1612816787.6206899
train: epoch 159, iter 400, loss: 1.887291, top_1: 0.785195, top_k: 0.925781, samples/s: 1361.764 1612816806.4198647
train: epoch 159, iter 500, loss: 2.070214, top_1: 0.791406, top_k: 0.928008, samples/s: 1337.785 1612816825.555991
train: epoch 159, iter 600, loss: 1.875662, top_1: 0.787109, top_k: 0.927617, samples/s: 1336.378 1612816844.7121952
train: epoch 159, iter 700, loss: 1.946879, top_1: 0.786094, top_k: 0.925703, samples/s: 1336.413 1612816863.8680036
train: epoch 159, iter 800, loss: 1.875041, top_1: 0.783867, top_k: 0.925039, samples/s: 1331.594 1612816883.0931242
train: epoch 159, iter 900, loss: 2.005909, top_1: 0.787461, top_k: 0.923633, samples/s: 1343.664 1612816902.1454253
train: epoch 159, iter 1000, loss: 1.945392, top_1: 0.785273, top_k: 0.923633, samples/s: 1331.372 1612816921.373696
train: epoch 159, iter 1100, loss: 2.069779, top_1: 0.780000, top_k: 0.922305, samples/s: 1334.744 1612816940.5534852
train: epoch 159, iter 1200, loss: 1.923864, top_1: 0.790820, top_k: 0.925039, samples/s: 1336.622 1612816959.7062266
train: epoch 159, iter 1300, loss: 1.966915, top_1: 0.785898, top_k: 0.925859, samples/s: 1343.746 1612816978.7574255
train: epoch 159, iter 1400, loss: 1.826089, top_1: 0.787109, top_k: 0.924531, samples/s: 1334.120 1612816997.9460595
train: epoch 159, iter 1500, loss: 1.931632, top_1: 0.788047, top_k: 0.926289, samples/s: 1335.106 1612817017.1206608
train: epoch 159, iter 1600, loss: 1.746196, top_1: 0.788789, top_k: 0.925859, samples/s: 1341.639 1612817036.201751
train: epoch 159, iter 1700, loss: 1.790632, top_1: 0.786133, top_k: 0.922773, samples/s: 1337.257 1612817055.3454003
train: epoch 159, iter 1800, loss: 1.927945, top_1: 0.786914, top_k: 0.924570, samples/s: 1338.312 1612817074.473936
train: epoch 159, iter 1900, loss: 1.845684, top_1: 0.789336, top_k: 0.923711, samples/s: 1335.368 1612817093.6447208
train: epoch 159, iter 2000, loss: 1.964030, top_1: 0.790195, top_k: 0.927695, samples/s: 1331.776 1612817112.8672528
train: epoch 159, iter 2100, loss: 1.922674, top_1: 0.786836, top_k: 0.927227, samples/s: 1346.303 1612817131.882212
train: epoch 159, iter 2200, loss: 1.957461, top_1: 0.788008, top_k: 0.926211, samples/s: 1338.059 1612817151.0143874
train: epoch 159, iter 2300, loss: 1.875310, top_1: 0.790703, top_k: 0.924453, samples/s: 1336.083 1612817170.1749198
train: epoch 159, iter 2400, loss: 1.898959, top_1: 0.782656, top_k: 0.923203, samples/s: 1343.069 1612817189.2357411
train: epoch 159, iter 2500, loss: 1.901253, top_1: 0.783203, top_k: 0.925781, samples/s: 1333.429 1612817208.4343066
train: epoch 159, iter 2600, loss: 1.946136, top_1: 0.783320, top_k: 0.920430, samples/s: 1336.432 1612817227.5897794
train: epoch 159, iter 2700, loss: 1.957949, top_1: 0.786797, top_k: 0.925273, samples/s: 1343.425 1612817246.6457033
train: epoch 159, iter 2800, loss: 1.871817, top_1: 0.784844, top_k: 0.923125, samples/s: 1330.262 1612817265.8899603
train: epoch 159, iter 2900, loss: 1.941116, top_1: 0.788438, top_k: 0.925273, samples/s: 1344.077 1612817284.9364831
train: epoch 159, iter 3000, loss: 1.894948, top_1: 0.785625, top_k: 0.924219, samples/s: 1340.703 1612817304.0308857
train: epoch 159, iter 3100, loss: 1.898082, top_1: 0.791484, top_k: 0.927461, samples/s: 1336.026 1612817323.1921644
train: epoch 159, iter 3200, loss: 1.877154, top_1: 0.784062, top_k: 0.923477, samples/s: 1332.787 1612817342.4000325
train: epoch 159, iter 3300, loss: 1.882129, top_1: 0.788398, top_k: 0.925156, samples/s: 1343.832 1612817361.4500968
train: epoch 159, iter 3400, loss: 1.800394, top_1: 0.789844, top_k: 0.923789, samples/s: 1342.151 1612817380.5240135
train: epoch 159, iter 3500, loss: 1.827063, top_1: 0.791211, top_k: 0.927617, samples/s: 1337.762 1612817399.6604319
train: epoch 159, iter 3600, loss: 1.818120, top_1: 0.788945, top_k: 0.926484, samples/s: 1329.060 1612817418.9221869
train: epoch 159, iter 3700, loss: 1.946908, top_1: 0.787734, top_k: 0.924922, samples/s: 1340.606 1612817438.0180159
train: epoch 159, iter 3800, loss: 1.894468, top_1: 0.784062, top_k: 0.924687, samples/s: 1342.948 1612817457.0804396
train: epoch 159, iter 3900, loss: 2.012029, top_1: 0.788516, top_k: 0.925156, samples/s: 1337.523 1612817476.220307
train: epoch 159, iter 4000, loss: 1.887506, top_1: 0.788203, top_k: 0.924492, samples/s: 1341.672 1612817495.3013752
train: epoch 159, iter 4100, loss: 1.954666, top_1: 0.783945, top_k: 0.926094, samples/s: 1338.930 1612817514.4207776
train: epoch 159, iter 4200, loss: 1.928648, top_1: 0.787695, top_k: 0.924687, samples/s: 1340.768 1612817533.5146115
train: epoch 159, iter 4300, loss: 1.873815, top_1: 0.783516, top_k: 0.923320, samples/s: 1337.092 1612817552.6603518
train: epoch 159, iter 4400, loss: 1.899549, top_1: 0.786992, top_k: 0.923242, samples/s: 1339.248 1612817571.7754972
train: epoch 159, iter 4500, loss: 1.914249, top_1: 0.785000, top_k: 0.923516, samples/s: 1336.864 1612817590.9248197
train: epoch 159, iter 4600, loss: 2.058047, top_1: 0.783008, top_k: 0.923359, samples/s: 1346.091 1612817609.9428904
train: epoch 159, iter 4700, loss: 2.050446, top_1: 0.785273, top_k: 0.925352, samples/s: 1339.048 1612817629.0609512
train: epoch 159, iter 4800, loss: 1.933518, top_1: 0.783477, top_k: 0.922109, samples/s: 1338.240 1612817648.1905696
train: epoch 159, iter 4900, loss: 1.953161, top_1: 0.789609, top_k: 0.925312, samples/s: 1343.391 1612817667.246808
train: epoch 159, iter 5000, loss: 2.022490, top_1: 0.783398, top_k: 0.924063, samples/s: 1339.089 1612817686.3643022
Saving model to ./repvggA2/snapshots/model_save/snapshot_epoch_159.
validation: epoch 159, iter 195, top_1: 0.764784, top_k: 0.932772, samples/s: 2747.388 1612817705.103491
