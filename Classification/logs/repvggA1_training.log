==================================================================
Running repvggA1: num_gpu_per_node = 4, num_nodes = 1.
==================================================================
dtype = float32
gpu_num_per_node = 4
num_nodes = 1
node_ips = ['192.168.1.13', '192.168.1.14']
ctrl_port = 50051
model = repvggA1
mixup = False
use_fp16 = None
use_xla = None
channel_last = False
pad_output = None
num_epochs = 160
model_load_dir = None
batch_size_per_device = 64
val_batch_size_per_device = 64
nccl_fusion_threshold_mb = 16
nccl_fusion_max_ops = 24
fuse_bn_relu = True
fuse_bn_add_relu = True
gpu_image_decoder = True
image_path = test_img/tiger.jpg
num_classes = 1000
num_examples = 1281167
num_val_examples = 50000
rgb_mean = [123.68, 116.779, 103.939]
rgb_std = [58.393, 57.12, 57.375]
image_shape = [3, 224, 224]
label_smoothing = 0.1
model_save_dir = ./repvggA1/snapshots/model_save/
log_dir = ./output
loss_print_every_n_iter = 100
image_size = 224
resize_shorter = 256
train_data_dir = /DATA/disk1/ImageNet/ofrecord/train
train_data_part_num = 256
val_data_dir = /DATA/disk1/ImageNet/ofrecord/validation
val_data_part_num = 256
optimizer = sgd
learning_rate = 0.1
wd = 3.0517578125e-05
momentum = 0.9
lr_decay = cosine
lr_decay_rate = 0.94
lr_decay_epochs = 2
warmup_epochs = 5
decay_rate = 0.9
epsilon = 1.0
gradient_clipping = 0.0
------------------------------------------------------------------
Time stamp: 2021-02-03-19:47:16
!!!!!===!!!! ./repvggA1/snapshots/model_save/
[1mWARNING: 'flow.train.CheckPoint' is deprecated. Please use the new API:[0m
flow.train.CheckPoint().save(path) => [1m[92mflow.checkpoint.save(path)[0m
flow.train.CheckPoint().load(path) => [1m[92mflow.load_variables(flow.checkpoint.get(path))[0m
flow.train.CheckPoint().init() is not needed any more.

Loading data from /DATA/disk1/ImageNet/ofrecord/train
No MixUp
loss.shape (1,)
predictions:  (256, 1000)
Optimizer:  SGD
Loading data from /DATA/disk1/ImageNet/ofrecord/validation
Saving model to ./repvggA1/snapshots/model_save/snapshot_initial_model.
Init model on demand.
train: epoch 0, iter 100, loss: 6.877288, top_1: 0.002227, top_k: 0.010313, samples/s: 2220.873 1612352968.4618165
train: epoch 0, iter 200, loss: 6.762180, top_1: 0.004102, top_k: 0.016992, samples/s: 2248.691 1612352979.8462882
train: epoch 0, iter 300, loss: 6.699406, top_1: 0.006055, top_k: 0.023438, samples/s: 2251.209 1612352991.2177489
train: epoch 0, iter 400, loss: 6.520050, top_1: 0.009609, top_k: 0.034766, samples/s: 2249.304 1612353002.5990474
train: epoch 0, iter 500, loss: 6.523681, top_1: 0.011523, top_k: 0.042188, samples/s: 2254.082 1612353013.9562745
train: epoch 0, iter 600, loss: 6.429646, top_1: 0.014570, top_k: 0.051211, samples/s: 2241.361 1612353025.377856
train: epoch 0, iter 700, loss: 6.293820, top_1: 0.016328, top_k: 0.059687, samples/s: 2224.885 1612353036.8841467
train: epoch 0, iter 800, loss: 6.249969, top_1: 0.020508, top_k: 0.069609, samples/s: 2256.002 1612353048.2315693
train: epoch 0, iter 900, loss: 6.252979, top_1: 0.022695, top_k: 0.077461, samples/s: 2239.509 1612353059.6626577
train: epoch 0, iter 1000, loss: 6.105825, top_1: 0.026250, top_k: 0.090430, samples/s: 2249.138 1612353071.044786
train: epoch 0, iter 1100, loss: 5.957555, top_1: 0.030195, top_k: 0.099453, samples/s: 2259.598 1612353082.3742442
train: epoch 0, iter 1200, loss: 6.026103, top_1: 0.034492, top_k: 0.112148, samples/s: 2242.141 1612353093.7918942
train: epoch 0, iter 1300, loss: 5.896599, top_1: 0.037109, top_k: 0.116172, samples/s: 2256.640 1612353105.1362681
train: epoch 0, iter 1400, loss: 5.912488, top_1: 0.041094, top_k: 0.130352, samples/s: 2251.615 1612353116.5058663
train: epoch 0, iter 1500, loss: 5.924819, top_1: 0.042422, top_k: 0.129531, samples/s: 2250.586 1612353127.880657
train: epoch 0, iter 1600, loss: 5.854551, top_1: 0.049844, top_k: 0.147187, samples/s: 2249.451 1612353139.2612228
train: epoch 0, iter 1700, loss: 5.663827, top_1: 0.051953, top_k: 0.157109, samples/s: 2255.759 1612353150.6099107
train: epoch 0, iter 1800, loss: 5.635177, top_1: 0.054805, top_k: 0.163750, samples/s: 2251.965 1612353161.9777727
train: epoch 0, iter 1900, loss: 5.636653, top_1: 0.057930, top_k: 0.171992, samples/s: 2242.147 1612353173.395463
train: epoch 0, iter 2000, loss: 5.678414, top_1: 0.061211, top_k: 0.176992, samples/s: 2241.129 1612353184.818217
train: epoch 0, iter 2100, loss: 5.666942, top_1: 0.066055, top_k: 0.185703, samples/s: 2255.309 1612353196.1692069
train: epoch 0, iter 2200, loss: 5.462518, top_1: 0.070195, top_k: 0.195508, samples/s: 2248.068 1612353207.5568714
train: epoch 0, iter 2300, loss: 5.544308, top_1: 0.076367, top_k: 0.210352, samples/s: 2248.617 1612353218.9415476
train: epoch 0, iter 2400, loss: 5.348870, top_1: 0.079648, top_k: 0.210820, samples/s: 2213.350 1612353230.5077069
train: epoch 0, iter 2500, loss: 5.573528, top_1: 0.081641, top_k: 0.218164, samples/s: 2281.031 1612353241.7307618
train: epoch 0, iter 2600, loss: 5.397285, top_1: 0.084258, top_k: 0.227773, samples/s: 2255.885 1612353253.0788038
train: epoch 0, iter 2700, loss: 5.330755, top_1: 0.086719, top_k: 0.231211, samples/s: 2243.432 1612353264.4899678
train: epoch 0, iter 2800, loss: 5.308804, top_1: 0.092344, top_k: 0.240547, samples/s: 2246.065 1612353275.8876574
train: epoch 0, iter 2900, loss: 5.293206, top_1: 0.098594, top_k: 0.252031, samples/s: 2224.910 1612353287.393745
train: epoch 0, iter 3000, loss: 5.284571, top_1: 0.098750, top_k: 0.254102, samples/s: 2238.640 1612353298.8292294
train: epoch 0, iter 3100, loss: 5.223365, top_1: 0.105352, top_k: 0.266289, samples/s: 2230.795 1612353310.3049479
train: epoch 0, iter 3200, loss: 5.108665, top_1: 0.102734, top_k: 0.264609, samples/s: 2258.522 1612353321.6397905
train: epoch 0, iter 3300, loss: 5.280503, top_1: 0.112578, top_k: 0.274805, samples/s: 2244.001 1612353333.0479748
train: epoch 0, iter 3400, loss: 5.016358, top_1: 0.114531, top_k: 0.277813, samples/s: 2246.068 1612353344.445695
train: epoch 0, iter 3500, loss: 5.249190, top_1: 0.115195, top_k: 0.285313, samples/s: 2240.910 1612353355.8696077
train: epoch 0, iter 3600, loss: 5.055402, top_1: 0.120195, top_k: 0.293203, samples/s: 2227.526 1612353367.3621862
train: epoch 0, iter 3700, loss: 5.078960, top_1: 0.123828, top_k: 0.298242, samples/s: 2241.849 1612353378.7813585
train: epoch 0, iter 3800, loss: 4.968098, top_1: 0.129336, top_k: 0.311133, samples/s: 2234.107 1612353390.2400854
train: epoch 0, iter 3900, loss: 4.883256, top_1: 0.130547, top_k: 0.310000, samples/s: 2239.443 1612353401.6714451
train: epoch 0, iter 4000, loss: 4.923770, top_1: 0.136328, top_k: 0.318867, samples/s: 2236.341 1612353413.1187282
train: epoch 0, iter 4100, loss: 5.266141, top_1: 0.141328, top_k: 0.327578, samples/s: 2238.004 1612353424.5575101
train: epoch 0, iter 4200, loss: 5.144047, top_1: 0.140313, top_k: 0.329922, samples/s: 2238.664 1612353435.9929686
train: epoch 0, iter 4300, loss: 4.947419, top_1: 0.146094, top_k: 0.341445, samples/s: 2249.362 1612353447.3738687
train: epoch 0, iter 4400, loss: 4.891943, top_1: 0.145625, top_k: 0.339453, samples/s: 2229.608 1612353458.8557196
train: epoch 0, iter 4500, loss: 4.891805, top_1: 0.151406, top_k: 0.347031, samples/s: 2238.073 1612353470.2943282
train: epoch 0, iter 4600, loss: 4.915634, top_1: 0.156680, top_k: 0.351953, samples/s: 2223.394 1612353481.8080812
train: epoch 0, iter 4700, loss: 4.786708, top_1: 0.159375, top_k: 0.357070, samples/s: 2224.822 1612353493.3146107
train: epoch 0, iter 4800, loss: 4.765894, top_1: 0.165391, top_k: 0.358242, samples/s: 2194.183 1612353504.9818795
train: epoch 0, iter 4900, loss: 4.818213, top_1: 0.164609, top_k: 0.362500, samples/s: 2229.535 1612353516.4640203
train: epoch 0, iter 5000, loss: 4.698748, top_1: 0.163242, top_k: 0.370352, samples/s: 2233.354 1612353527.9266403
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_0.
validation: epoch 0, iter 195, top_1: 0.169391, top_k: 0.382592, samples/s: 2931.187 1612353545.304064
train: epoch 1, iter 100, loss: 4.771574, top_1: 0.166367, top_k: 0.377695, samples/s: 2246.711 1612353572.9113023
train: epoch 1, iter 200, loss: 4.714197, top_1: 0.174414, top_k: 0.380000, samples/s: 2255.655 1612353584.2607117
train: epoch 1, iter 300, loss: 4.769867, top_1: 0.177969, top_k: 0.390977, samples/s: 2249.230 1612353595.6421976
train: epoch 1, iter 400, loss: 4.668834, top_1: 0.180820, top_k: 0.389922, samples/s: 2255.660 1612353606.9914274
train: epoch 1, iter 500, loss: 4.642234, top_1: 0.184727, top_k: 0.396953, samples/s: 2247.011 1612353618.3846366
train: epoch 1, iter 600, loss: 4.749056, top_1: 0.185859, top_k: 0.397852, samples/s: 2248.535 1612353629.769527
train: epoch 1, iter 700, loss: 4.740279, top_1: 0.187461, top_k: 0.402695, samples/s: 2228.193 1612353641.2589495
train: epoch 1, iter 800, loss: 4.682241, top_1: 0.189336, top_k: 0.402969, samples/s: 2237.500 1612353652.699974
train: epoch 1, iter 900, loss: 4.718364, top_1: 0.198164, top_k: 0.406719, samples/s: 2241.359 1612353664.1216393
train: epoch 1, iter 1000, loss: 4.615405, top_1: 0.195352, top_k: 0.413516, samples/s: 2238.471 1612353675.557991
train: epoch 1, iter 1100, loss: 4.509976, top_1: 0.198398, top_k: 0.416602, samples/s: 2190.959 1612353687.2424798
train: epoch 1, iter 1200, loss: 4.568878, top_1: 0.202187, top_k: 0.420391, samples/s: 2212.294 1612353698.8140898
train: epoch 1, iter 1300, loss: 4.747480, top_1: 0.204609, top_k: 0.422187, samples/s: 2222.324 1612353710.3335578
train: epoch 1, iter 1400, loss: 4.597251, top_1: 0.203125, top_k: 0.422617, samples/s: 2190.120 1612353722.0224001
train: epoch 1, iter 1500, loss: 4.660420, top_1: 0.207422, top_k: 0.425938, samples/s: 2197.159 1612353733.6739082
train: epoch 1, iter 1600, loss: 4.307741, top_1: 0.214219, top_k: 0.436016, samples/s: 2242.344 1612353745.0904388
train: epoch 1, iter 1700, loss: 4.235396, top_1: 0.216250, top_k: 0.439219, samples/s: 2226.107 1612353756.590387
train: epoch 1, iter 1800, loss: 4.539079, top_1: 0.213125, top_k: 0.438945, samples/s: 2221.744 1612353768.112827
train: epoch 1, iter 1900, loss: 4.468713, top_1: 0.216523, top_k: 0.436484, samples/s: 2208.241 1612353779.705842
train: epoch 1, iter 2000, loss: 4.458648, top_1: 0.217539, top_k: 0.442109, samples/s: 2218.353 1612353791.2459052
train: epoch 1, iter 2100, loss: 4.560091, top_1: 0.221094, top_k: 0.442344, samples/s: 2195.268 1612353802.907314
train: epoch 1, iter 2200, loss: 4.504951, top_1: 0.221758, top_k: 0.449883, samples/s: 2213.250 1612353814.4739804
train: epoch 1, iter 2300, loss: 4.421361, top_1: 0.228320, top_k: 0.456172, samples/s: 2207.691 1612353826.0698032
train: epoch 1, iter 2400, loss: 4.364615, top_1: 0.222852, top_k: 0.455430, samples/s: 2233.687 1612353837.530728
train: epoch 1, iter 2500, loss: 4.620540, top_1: 0.228945, top_k: 0.455352, samples/s: 2240.824 1612353848.9550817
train: epoch 1, iter 2600, loss: 4.581478, top_1: 0.231484, top_k: 0.458359, samples/s: 2229.976 1612353860.4349904
train: epoch 1, iter 2700, loss: 4.437496, top_1: 0.234375, top_k: 0.463242, samples/s: 2225.265 1612353871.9392445
train: epoch 1, iter 2800, loss: 4.649098, top_1: 0.233086, top_k: 0.460938, samples/s: 2229.245 1612353883.422949
train: epoch 1, iter 2900, loss: 4.180894, top_1: 0.241797, top_k: 0.471367, samples/s: 2233.637 1612353894.884162
train: epoch 1, iter 3000, loss: 4.395714, top_1: 0.240234, top_k: 0.465156, samples/s: 2233.532 1612353906.345749
train: epoch 1, iter 3100, loss: 4.487538, top_1: 0.240859, top_k: 0.479414, samples/s: 2231.076 1612353917.8201299
train: epoch 1, iter 3200, loss: 4.251818, top_1: 0.240078, top_k: 0.473477, samples/s: 2223.929 1612353929.331268
train: epoch 1, iter 3300, loss: 4.324537, top_1: 0.242344, top_k: 0.473164, samples/s: 2244.126 1612353940.738744
train: epoch 1, iter 3400, loss: 4.393685, top_1: 0.252930, top_k: 0.487031, samples/s: 2221.643 1612353952.261768
train: epoch 1, iter 3500, loss: 4.340156, top_1: 0.246719, top_k: 0.480977, samples/s: 2227.150 1612353963.7562926
train: epoch 1, iter 3600, loss: 4.188256, top_1: 0.253828, top_k: 0.492109, samples/s: 2227.737 1612353975.2477844
train: epoch 1, iter 3700, loss: 4.219411, top_1: 0.250820, top_k: 0.485625, samples/s: 2233.675 1612353986.70871
train: epoch 1, iter 3800, loss: 4.226050, top_1: 0.253828, top_k: 0.485898, samples/s: 2240.017 1612353998.1371813
train: epoch 1, iter 3900, loss: 4.260707, top_1: 0.250859, top_k: 0.487891, samples/s: 2231.260 1612354009.6105828
train: epoch 1, iter 4000, loss: 4.346892, top_1: 0.257305, top_k: 0.495195, samples/s: 2198.614 1612354021.2542071
train: epoch 1, iter 4100, loss: 4.358306, top_1: 0.259805, top_k: 0.493398, samples/s: 2210.923 1612354032.833069
train: epoch 1, iter 4200, loss: 4.149427, top_1: 0.257305, top_k: 0.497969, samples/s: 2213.267 1612354044.399738
train: epoch 1, iter 4300, loss: 4.216978, top_1: 0.259141, top_k: 0.498711, samples/s: 2242.718 1612354055.8144724
train: epoch 1, iter 4400, loss: 4.287607, top_1: 0.263750, top_k: 0.505078, samples/s: 2225.405 1612354067.3179474
train: epoch 1, iter 4500, loss: 4.046389, top_1: 0.265391, top_k: 0.507656, samples/s: 2231.170 1612354078.7917962
train: epoch 1, iter 4600, loss: 4.201117, top_1: 0.273867, top_k: 0.508945, samples/s: 2214.826 1612354090.3502352
train: epoch 1, iter 4700, loss: 4.354925, top_1: 0.266562, top_k: 0.512930, samples/s: 2257.075 1612354101.692312
train: epoch 1, iter 4800, loss: 4.407261, top_1: 0.267813, top_k: 0.507617, samples/s: 2230.895 1612354113.1675456
train: epoch 1, iter 4900, loss: 4.389691, top_1: 0.268203, top_k: 0.503906, samples/s: 2254.163 1612354124.524317
train: epoch 1, iter 5000, loss: 4.208260, top_1: 0.271523, top_k: 0.512852, samples/s: 2223.644 1612354136.0369825
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_1.
validation: epoch 1, iter 195, top_1: 0.286398, top_k: 0.546695, samples/s: 2871.624 1612354153.779788
train: epoch 2, iter 100, loss: 4.085277, top_1: 0.285039, top_k: 0.524297, samples/s: 2220.966 1612354181.4199867
train: epoch 2, iter 200, loss: 3.882785, top_1: 0.283633, top_k: 0.523320, samples/s: 2251.002 1612354192.7925787
train: epoch 2, iter 300, loss: 4.205516, top_1: 0.278242, top_k: 0.524062, samples/s: 2245.386 1612354204.1940055
train: epoch 2, iter 400, loss: 4.284907, top_1: 0.284648, top_k: 0.529258, samples/s: 2247.621 1612354215.5835552
train: epoch 2, iter 500, loss: 4.142523, top_1: 0.283438, top_k: 0.525625, samples/s: 2288.151 1612354226.7715783
train: epoch 2, iter 600, loss: 4.012404, top_1: 0.282891, top_k: 0.526094, samples/s: 2247.185 1612354238.1636677
train: epoch 2, iter 700, loss: 4.021394, top_1: 0.286758, top_k: 0.529336, samples/s: 2232.499 1612354249.6306226
train: epoch 2, iter 800, loss: 4.202466, top_1: 0.284766, top_k: 0.529453, samples/s: 2272.432 1612354260.8960383
train: epoch 2, iter 900, loss: 4.032878, top_1: 0.286289, top_k: 0.528242, samples/s: 2245.522 1612354272.2965102
train: epoch 2, iter 1000, loss: 3.867523, top_1: 0.290156, top_k: 0.537383, samples/s: 2251.068 1612354283.6689005
train: epoch 2, iter 1100, loss: 4.170580, top_1: 0.289492, top_k: 0.533242, samples/s: 2248.455 1612354295.0545042
train: epoch 2, iter 1200, loss: 4.088479, top_1: 0.294375, top_k: 0.543242, samples/s: 2227.577 1612354306.5467913
train: epoch 2, iter 1300, loss: 4.116879, top_1: 0.293281, top_k: 0.538828, samples/s: 2238.767 1612354317.9816728
train: epoch 2, iter 1400, loss: 3.955859, top_1: 0.291367, top_k: 0.535352, samples/s: 2218.969 1612354329.5185404
train: epoch 2, iter 1500, loss: 4.253404, top_1: 0.302461, top_k: 0.543320, samples/s: 2232.427 1612354340.985982
train: epoch 2, iter 1600, loss: 4.033369, top_1: 0.293359, top_k: 0.534609, samples/s: 2244.243 1612354352.3929062
train: epoch 2, iter 1700, loss: 4.312866, top_1: 0.298711, top_k: 0.543672, samples/s: 2248.949 1612354363.7759464
train: epoch 2, iter 1800, loss: 3.940540, top_1: 0.297539, top_k: 0.546523, samples/s: 2185.677 1612354375.488588
train: epoch 2, iter 1900, loss: 4.031966, top_1: 0.297266, top_k: 0.539258, samples/s: 2224.803 1612354386.9952462
train: epoch 2, iter 2000, loss: 3.833457, top_1: 0.300391, top_k: 0.551133, samples/s: 2229.705 1612354398.4766057
train: epoch 2, iter 2100, loss: 4.252861, top_1: 0.308437, top_k: 0.552813, samples/s: 2240.574 1612354409.9022126
train: epoch 2, iter 2200, loss: 4.234440, top_1: 0.298320, top_k: 0.544141, samples/s: 2232.925 1612354421.3669984
train: epoch 2, iter 2300, loss: 4.003478, top_1: 0.306406, top_k: 0.556602, samples/s: 2237.026 1612354432.8107357
train: epoch 2, iter 2400, loss: 4.067744, top_1: 0.305586, top_k: 0.549414, samples/s: 2239.945 1612354444.2395954
train: epoch 2, iter 2500, loss: 3.991834, top_1: 0.305430, top_k: 0.551094, samples/s: 2226.811 1612354455.7358596
train: epoch 2, iter 2600, loss: 4.081444, top_1: 0.305508, top_k: 0.549531, samples/s: 2234.136 1612354467.1944833
train: epoch 2, iter 2700, loss: 4.040514, top_1: 0.309531, top_k: 0.552891, samples/s: 2250.160 1612354478.5713758
train: epoch 2, iter 2800, loss: 4.035688, top_1: 0.312031, top_k: 0.550039, samples/s: 2207.353 1612354490.1689982
train: epoch 2, iter 2900, loss: 4.109778, top_1: 0.308711, top_k: 0.555977, samples/s: 2240.853 1612354501.5932844
train: epoch 2, iter 3000, loss: 4.151527, top_1: 0.307852, top_k: 0.551289, samples/s: 2242.976 1612354513.0066013
train: epoch 2, iter 3100, loss: 3.966472, top_1: 0.313516, top_k: 0.558359, samples/s: 2232.370 1612354524.474409
train: epoch 2, iter 3200, loss: 4.085600, top_1: 0.318320, top_k: 0.566016, samples/s: 2227.597 1612354535.9664812
train: epoch 2, iter 3300, loss: 4.076589, top_1: 0.313047, top_k: 0.561250, samples/s: 2236.492 1612354547.412971
train: epoch 2, iter 3400, loss: 4.027547, top_1: 0.322305, top_k: 0.568789, samples/s: 2243.451 1612354558.8239906
train: epoch 2, iter 3500, loss: 3.947623, top_1: 0.314609, top_k: 0.560859, samples/s: 2231.790 1612354570.294547
train: epoch 2, iter 3600, loss: 4.032702, top_1: 0.320508, top_k: 0.564766, samples/s: 2219.510 1612354581.8286116
train: epoch 2, iter 3700, loss: 3.800698, top_1: 0.321250, top_k: 0.575703, samples/s: 2225.973 1612354593.329226
train: epoch 2, iter 3800, loss: 4.346551, top_1: 0.318437, top_k: 0.566172, samples/s: 2239.357 1612354604.76108
train: epoch 2, iter 3900, loss: 3.938876, top_1: 0.315547, top_k: 0.564531, samples/s: 2221.829 1612354616.2831814
train: epoch 2, iter 4000, loss: 3.938454, top_1: 0.321719, top_k: 0.567734, samples/s: 2230.604 1612354627.7598765
train: epoch 2, iter 4100, loss: 3.816475, top_1: 0.320195, top_k: 0.567109, samples/s: 2244.255 1612354639.16671
train: epoch 2, iter 4200, loss: 3.904582, top_1: 0.321641, top_k: 0.571719, samples/s: 2226.765 1612354650.6632125
train: epoch 2, iter 4300, loss: 4.036363, top_1: 0.324844, top_k: 0.573320, samples/s: 2236.512 1612354662.109612
train: epoch 2, iter 4400, loss: 3.899169, top_1: 0.327266, top_k: 0.574023, samples/s: 2216.893 1612354673.6573045
train: epoch 2, iter 4500, loss: 3.990129, top_1: 0.320703, top_k: 0.566562, samples/s: 2248.011 1612354685.0451503
train: epoch 2, iter 4600, loss: 3.864381, top_1: 0.327578, top_k: 0.577578, samples/s: 2240.347 1612354696.4720302
train: epoch 2, iter 4700, loss: 3.823917, top_1: 0.322852, top_k: 0.576562, samples/s: 2237.789 1612354707.9119394
train: epoch 2, iter 4800, loss: 3.889606, top_1: 0.326758, top_k: 0.578281, samples/s: 2219.446 1612354719.446259
train: epoch 2, iter 4900, loss: 3.996244, top_1: 0.328242, top_k: 0.575742, samples/s: 2220.492 1612354730.975273
train: epoch 2, iter 5000, loss: 3.810428, top_1: 0.330078, top_k: 0.578828, samples/s: 2219.291 1612354742.5105224
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_2.
validation: epoch 2, iter 195, top_1: 0.356410, top_k: 0.622035, samples/s: 2923.979 1612354759.9222627
train: epoch 3, iter 100, loss: 3.854577, top_1: 0.339727, top_k: 0.589141, samples/s: 2241.323 1612354787.4174576
train: epoch 3, iter 200, loss: 3.782585, top_1: 0.338477, top_k: 0.585117, samples/s: 2261.022 1612354798.7395837
train: epoch 3, iter 300, loss: 3.670414, top_1: 0.339023, top_k: 0.589727, samples/s: 2257.645 1612354810.0788455
train: epoch 3, iter 400, loss: 4.038689, top_1: 0.337500, top_k: 0.588945, samples/s: 2245.642 1612354821.478709
train: epoch 3, iter 500, loss: 3.639574, top_1: 0.346367, top_k: 0.590117, samples/s: 2242.068 1612354832.8967543
train: epoch 3, iter 600, loss: 4.060300, top_1: 0.333359, top_k: 0.582930, samples/s: 2267.358 1612354844.1875231
train: epoch 3, iter 700, loss: 3.753471, top_1: 0.340977, top_k: 0.590938, samples/s: 2252.329 1612354855.5534003
train: epoch 3, iter 800, loss: 3.970226, top_1: 0.339570, top_k: 0.589375, samples/s: 2234.709 1612354867.009048
train: epoch 3, iter 900, loss: 3.911564, top_1: 0.338125, top_k: 0.587500, samples/s: 2221.313 1612354878.5337403
train: epoch 3, iter 1000, loss: 3.713403, top_1: 0.338125, top_k: 0.588359, samples/s: 2207.743 1612354890.129319
train: epoch 3, iter 1100, loss: 3.768135, top_1: 0.335469, top_k: 0.583750, samples/s: 2207.869 1612354901.7243013
train: epoch 3, iter 1200, loss: 3.851418, top_1: 0.344961, top_k: 0.589844, samples/s: 2243.708 1612354913.1339293
train: epoch 3, iter 1300, loss: 3.666629, top_1: 0.339219, top_k: 0.587383, samples/s: 2241.044 1612354924.5571342
train: epoch 3, iter 1400, loss: 3.805910, top_1: 0.343086, top_k: 0.592227, samples/s: 2230.604 1612354936.0338862
train: epoch 3, iter 1500, loss: 3.794015, top_1: 0.337344, top_k: 0.588125, samples/s: 2226.654 1612354947.530907
train: epoch 3, iter 1600, loss: 3.986046, top_1: 0.336406, top_k: 0.589844, samples/s: 2237.816 1612354958.9706264
train: epoch 3, iter 1700, loss: 3.751620, top_1: 0.342070, top_k: 0.593437, samples/s: 2228.571 1612354970.4578469
train: epoch 3, iter 1800, loss: 4.065168, top_1: 0.347656, top_k: 0.592383, samples/s: 2232.633 1612354981.9241276
train: epoch 3, iter 1900, loss: 3.598611, top_1: 0.343828, top_k: 0.591641, samples/s: 2241.830 1612354993.3433337
train: epoch 3, iter 2000, loss: 3.835397, top_1: 0.346602, top_k: 0.591445, samples/s: 2240.940 1612355004.767162
train: epoch 3, iter 2100, loss: 3.847039, top_1: 0.347344, top_k: 0.593047, samples/s: 2214.101 1612355016.3293734
train: epoch 3, iter 2200, loss: 3.768887, top_1: 0.347422, top_k: 0.600039, samples/s: 2226.527 1612355027.8271015
train: epoch 3, iter 2300, loss: 3.849139, top_1: 0.351953, top_k: 0.597930, samples/s: 2210.970 1612355039.4057345
train: epoch 3, iter 2400, loss: 3.814703, top_1: 0.346016, top_k: 0.598594, samples/s: 2248.565 1612355050.7908318
train: epoch 3, iter 2500, loss: 3.679359, top_1: 0.342539, top_k: 0.593008, samples/s: 2234.436 1612355062.247864
train: epoch 3, iter 2600, loss: 3.652080, top_1: 0.348438, top_k: 0.600195, samples/s: 2212.453 1612355073.8186688
train: epoch 3, iter 2700, loss: 3.839922, top_1: 0.347266, top_k: 0.596641, samples/s: 2231.902 1612355085.2887454
train: epoch 3, iter 2800, loss: 3.957426, top_1: 0.349336, top_k: 0.601719, samples/s: 2240.616 1612355096.7141397
train: epoch 3, iter 2900, loss: 3.761331, top_1: 0.350039, top_k: 0.602070, samples/s: 2232.265 1612355108.1823099
train: epoch 3, iter 3000, loss: 3.890772, top_1: 0.348203, top_k: 0.594375, samples/s: 2255.321 1612355119.5332778
train: epoch 3, iter 3100, loss: 3.901931, top_1: 0.349062, top_k: 0.594141, samples/s: 2203.817 1612355131.1494505
train: epoch 3, iter 3200, loss: 3.899345, top_1: 0.356875, top_k: 0.605156, samples/s: 2237.529 1612355142.5907166
train: epoch 3, iter 3300, loss: 3.746890, top_1: 0.354805, top_k: 0.603125, samples/s: 2236.966 1612355154.0347137
train: epoch 3, iter 3400, loss: 4.068259, top_1: 0.351328, top_k: 0.599023, samples/s: 2234.297 1612355165.4924755
train: epoch 3, iter 3500, loss: 3.911319, top_1: 0.351055, top_k: 0.600742, samples/s: 2209.457 1612355177.0790348
train: epoch 3, iter 3600, loss: 3.870918, top_1: 0.346641, top_k: 0.599961, samples/s: 2239.132 1612355188.512068
train: epoch 3, iter 3700, loss: 4.004926, top_1: 0.351602, top_k: 0.597305, samples/s: 2231.434 1612355199.9844732
train: epoch 3, iter 3800, loss: 3.741354, top_1: 0.350898, top_k: 0.601953, samples/s: 2234.371 1612355211.4418612
train: epoch 3, iter 3900, loss: 3.605193, top_1: 0.349766, top_k: 0.598320, samples/s: 2237.739 1612355222.8819814
train: epoch 3, iter 4000, loss: 3.798207, top_1: 0.351758, top_k: 0.599492, samples/s: 2206.687 1612355234.4830854
train: epoch 3, iter 4100, loss: 3.613452, top_1: 0.353672, top_k: 0.603359, samples/s: 2228.895 1612355245.9686236
train: epoch 3, iter 4200, loss: 3.843117, top_1: 0.355195, top_k: 0.602891, samples/s: 2237.343 1612355257.4107773
train: epoch 3, iter 4300, loss: 3.683161, top_1: 0.355078, top_k: 0.606094, samples/s: 2217.319 1612355268.9562762
train: epoch 3, iter 4400, loss: 3.483994, top_1: 0.353438, top_k: 0.606953, samples/s: 2254.257 1612355280.312593
train: epoch 3, iter 4500, loss: 3.987348, top_1: 0.359141, top_k: 0.610898, samples/s: 2242.917 1612355291.7262173
train: epoch 3, iter 4600, loss: 3.877783, top_1: 0.358086, top_k: 0.603047, samples/s: 2227.719 1612355303.2178042
train: epoch 3, iter 4700, loss: 3.465171, top_1: 0.358516, top_k: 0.609414, samples/s: 2238.550 1612355314.6537995
train: epoch 3, iter 4800, loss: 3.778384, top_1: 0.359961, top_k: 0.608555, samples/s: 2225.151 1612355326.1585686
train: epoch 3, iter 4900, loss: 3.661978, top_1: 0.359375, top_k: 0.612500, samples/s: 2243.265 1612355337.5705216
train: epoch 3, iter 5000, loss: 3.643468, top_1: 0.359375, top_k: 0.608828, samples/s: 2220.866 1612355349.0975943
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_3.
validation: epoch 3, iter 195, top_1: 0.384495, top_k: 0.650821, samples/s: 2970.995 1612355366.2643857
train: epoch 4, iter 100, loss: 3.670564, top_1: 0.363750, top_k: 0.615664, samples/s: 2209.774 1612355394.1621966
train: epoch 4, iter 200, loss: 3.754784, top_1: 0.365312, top_k: 0.615273, samples/s: 2249.866 1612355405.54062
train: epoch 4, iter 300, loss: 3.865474, top_1: 0.365898, top_k: 0.618672, samples/s: 2257.861 1612355416.8788285
train: epoch 4, iter 400, loss: 3.724040, top_1: 0.366445, top_k: 0.618242, samples/s: 2265.711 1612355428.1776772
train: epoch 4, iter 500, loss: 3.716112, top_1: 0.364336, top_k: 0.617930, samples/s: 2254.990 1612355439.530331
train: epoch 4, iter 600, loss: 3.702222, top_1: 0.376289, top_k: 0.619805, samples/s: 2254.696 1612355450.884359
train: epoch 4, iter 700, loss: 3.670666, top_1: 0.366914, top_k: 0.614727, samples/s: 2244.157 1612355462.291799
train: epoch 4, iter 800, loss: 3.856533, top_1: 0.362539, top_k: 0.611797, samples/s: 2231.143 1612355473.765627
train: epoch 4, iter 900, loss: 3.519811, top_1: 0.367891, top_k: 0.615898, samples/s: 2235.965 1612355485.2149239
train: epoch 4, iter 1000, loss: 3.729018, top_1: 0.364023, top_k: 0.619062, samples/s: 2210.970 1612355496.7935355
train: epoch 4, iter 1100, loss: 3.660869, top_1: 0.365391, top_k: 0.619375, samples/s: 2201.691 1612355508.4209647
train: epoch 4, iter 1200, loss: 3.627733, top_1: 0.365938, top_k: 0.612852, samples/s: 2202.383 1612355520.0447724
train: epoch 4, iter 1300, loss: 3.542488, top_1: 0.361602, top_k: 0.613633, samples/s: 2219.813 1612355531.5772562
train: epoch 4, iter 1400, loss: 3.805024, top_1: 0.368711, top_k: 0.619570, samples/s: 2214.575 1612355543.1369884
train: epoch 4, iter 1500, loss: 3.845364, top_1: 0.372383, top_k: 0.618359, samples/s: 2230.823 1612355554.6125553
train: epoch 4, iter 1600, loss: 3.634204, top_1: 0.370273, top_k: 0.618086, samples/s: 2266.020 1612355565.909944
train: epoch 4, iter 1700, loss: 3.702582, top_1: 0.365898, top_k: 0.613828, samples/s: 2223.132 1612355577.4251988
train: epoch 4, iter 1800, loss: 3.729992, top_1: 0.368945, top_k: 0.620547, samples/s: 2252.946 1612355588.7881029
train: epoch 4, iter 1900, loss: 3.608072, top_1: 0.370352, top_k: 0.620938, samples/s: 2215.197 1612355600.3446856
train: epoch 4, iter 2000, loss: 3.698081, top_1: 0.369258, top_k: 0.618242, samples/s: 2229.970 1612355611.8246038
train: epoch 4, iter 2100, loss: 3.828519, top_1: 0.368437, top_k: 0.614258, samples/s: 2228.078 1612355623.31433
train: epoch 4, iter 2200, loss: 3.632058, top_1: 0.361367, top_k: 0.614688, samples/s: 2241.905 1612355634.7333076
train: epoch 4, iter 2300, loss: 3.494003, top_1: 0.374531, top_k: 0.625547, samples/s: 2223.894 1612355646.2446394
train: epoch 4, iter 2400, loss: 3.702287, top_1: 0.371719, top_k: 0.620352, samples/s: 2226.080 1612355657.7446766
train: epoch 4, iter 2500, loss: 3.785805, top_1: 0.365469, top_k: 0.615938, samples/s: 2245.534 1612355669.1449633
train: epoch 4, iter 2600, loss: 3.819166, top_1: 0.367930, top_k: 0.619141, samples/s: 2240.575 1612355680.5706027
train: epoch 4, iter 2700, loss: 3.764152, top_1: 0.368203, top_k: 0.620664, samples/s: 2229.573 1612355692.052756
train: epoch 4, iter 2800, loss: 3.638930, top_1: 0.366641, top_k: 0.616445, samples/s: 2221.559 1612355703.5760176
train: epoch 4, iter 2900, loss: 3.662726, top_1: 0.371406, top_k: 0.618477, samples/s: 2222.232 1612355715.0962083
train: epoch 4, iter 3000, loss: 3.803131, top_1: 0.368945, top_k: 0.622812, samples/s: 2234.773 1612355726.5513897
train: epoch 4, iter 3100, loss: 3.661740, top_1: 0.374258, top_k: 0.622969, samples/s: 2240.539 1612355737.9771316
train: epoch 4, iter 3200, loss: 3.730469, top_1: 0.369375, top_k: 0.621875, samples/s: 2227.177 1612355749.4716206
train: epoch 4, iter 3300, loss: 3.596811, top_1: 0.374297, top_k: 0.623125, samples/s: 2255.944 1612355760.819365
train: epoch 4, iter 3400, loss: 3.552745, top_1: 0.374531, top_k: 0.626328, samples/s: 2246.106 1612355772.2168493
train: epoch 4, iter 3500, loss: 3.823696, top_1: 0.375469, top_k: 0.626992, samples/s: 2216.016 1612355783.7691224
train: epoch 4, iter 3600, loss: 3.555850, top_1: 0.369805, top_k: 0.621875, samples/s: 2220.931 1612355795.2958407
train: epoch 4, iter 3700, loss: 3.710100, top_1: 0.376680, top_k: 0.622109, samples/s: 2242.536 1612355806.7114694
train: epoch 4, iter 3800, loss: 3.570911, top_1: 0.375000, top_k: 0.621289, samples/s: 2231.498 1612355818.1835399
train: epoch 4, iter 3900, loss: 3.592761, top_1: 0.369258, top_k: 0.621797, samples/s: 2235.104 1612355829.637245
train: epoch 4, iter 4000, loss: 3.687659, top_1: 0.373906, top_k: 0.623125, samples/s: 2238.500 1612355841.0734174
train: epoch 4, iter 4100, loss: 3.809076, top_1: 0.371641, top_k: 0.624961, samples/s: 2236.196 1612355852.5213993
train: epoch 4, iter 4200, loss: 3.774464, top_1: 0.376602, top_k: 0.624961, samples/s: 2246.598 1612355863.9164555
train: epoch 4, iter 4300, loss: 3.737773, top_1: 0.378945, top_k: 0.626719, samples/s: 2243.247 1612355875.328458
train: epoch 4, iter 4400, loss: 3.958962, top_1: 0.380430, top_k: 0.632539, samples/s: 2224.795 1612355886.835108
train: epoch 4, iter 4500, loss: 3.910130, top_1: 0.373594, top_k: 0.627578, samples/s: 2247.981 1612355898.2231116
train: epoch 4, iter 4600, loss: 3.753021, top_1: 0.370039, top_k: 0.625742, samples/s: 2222.536 1612355909.7415385
train: epoch 4, iter 4700, loss: 3.762015, top_1: 0.376367, top_k: 0.627695, samples/s: 2232.082 1612355921.2106674
train: epoch 4, iter 4800, loss: 3.731552, top_1: 0.378633, top_k: 0.625547, samples/s: 2232.616 1612355932.6769414
train: epoch 4, iter 4900, loss: 3.522248, top_1: 0.374063, top_k: 0.627695, samples/s: 2228.855 1612355944.162793
train: epoch 4, iter 5000, loss: 3.617741, top_1: 0.375664, top_k: 0.629023, samples/s: 2231.175 1612355955.6364906
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_4.
validation: epoch 4, iter 195, top_1: 0.415405, top_k: 0.681050, samples/s: 2956.708 1612355972.8386405
train: epoch 5, iter 100, loss: 3.740373, top_1: 0.384297, top_k: 0.635195, samples/s: 2225.084 1612356000.7025027
train: epoch 5, iter 200, loss: 3.632861, top_1: 0.380586, top_k: 0.633164, samples/s: 2265.126 1612356012.004274
train: epoch 5, iter 300, loss: 3.638586, top_1: 0.380234, top_k: 0.635156, samples/s: 2253.951 1612356023.3620722
train: epoch 5, iter 400, loss: 3.537288, top_1: 0.380117, top_k: 0.630352, samples/s: 2261.217 1612356034.6834023
train: epoch 5, iter 500, loss: 3.529244, top_1: 0.387695, top_k: 0.636875, samples/s: 2257.223 1612356046.0247717
train: epoch 5, iter 600, loss: 3.732534, top_1: 0.381641, top_k: 0.632773, samples/s: 2255.021 1612356057.3772755
train: epoch 5, iter 700, loss: 3.842252, top_1: 0.386758, top_k: 0.635664, samples/s: 2235.038 1612356068.8312619
train: epoch 5, iter 800, loss: 3.532089, top_1: 0.384219, top_k: 0.636445, samples/s: 2222.916 1612356080.3476384
train: epoch 5, iter 900, loss: 3.746473, top_1: 0.384531, top_k: 0.634141, samples/s: 2239.431 1612356091.7791986
train: epoch 5, iter 1000, loss: 3.785751, top_1: 0.383594, top_k: 0.636328, samples/s: 2231.052 1612356103.2534535
train: epoch 5, iter 1100, loss: 3.618142, top_1: 0.389062, top_k: 0.639062, samples/s: 2213.763 1612356114.8175757
train: epoch 5, iter 1200, loss: 3.632828, top_1: 0.384531, top_k: 0.632500, samples/s: 2232.624 1612356126.2838106
train: epoch 5, iter 1300, loss: 3.538309, top_1: 0.388164, top_k: 0.633750, samples/s: 2256.072 1612356137.6309552
train: epoch 5, iter 1400, loss: 3.723984, top_1: 0.391172, top_k: 0.644453, samples/s: 2227.737 1612356149.1224322
train: epoch 5, iter 1500, loss: 3.698836, top_1: 0.383047, top_k: 0.638984, samples/s: 2229.726 1612356160.60369
train: epoch 5, iter 1600, loss: 3.519168, top_1: 0.380937, top_k: 0.633555, samples/s: 2219.503 1612356172.137898
train: epoch 5, iter 1700, loss: 3.519812, top_1: 0.385703, top_k: 0.633086, samples/s: 2237.919 1612356183.5770981
train: epoch 5, iter 1800, loss: 3.603472, top_1: 0.394688, top_k: 0.643945, samples/s: 2250.909 1612356194.9501724
train: epoch 5, iter 1900, loss: 3.636761, top_1: 0.386094, top_k: 0.637500, samples/s: 2242.765 1612356206.3647225
train: epoch 5, iter 2000, loss: 3.724730, top_1: 0.386523, top_k: 0.634219, samples/s: 2230.938 1612356217.8396735
train: epoch 5, iter 2100, loss: 3.744950, top_1: 0.390117, top_k: 0.646289, samples/s: 2225.932 1612356229.340493
train: epoch 5, iter 2200, loss: 3.556749, top_1: 0.388555, top_k: 0.643359, samples/s: 2239.910 1612356240.7694952
train: epoch 5, iter 2300, loss: 3.482570, top_1: 0.393594, top_k: 0.642852, samples/s: 2236.235 1612356252.2173634
train: epoch 5, iter 2400, loss: 3.750679, top_1: 0.386289, top_k: 0.636680, samples/s: 2237.992 1612356263.6561146
train: epoch 5, iter 2500, loss: 3.792400, top_1: 0.393516, top_k: 0.647969, samples/s: 2233.121 1612356275.1199703
train: epoch 5, iter 2600, loss: 3.731068, top_1: 0.397695, top_k: 0.647539, samples/s: 2252.957 1612356286.4827473
train: epoch 5, iter 2700, loss: 3.684317, top_1: 0.391719, top_k: 0.638516, samples/s: 2244.187 1612356297.889999
train: epoch 5, iter 2800, loss: 3.323106, top_1: 0.392695, top_k: 0.637695, samples/s: 2240.742 1612356309.3147736
train: epoch 5, iter 2900, loss: 3.534905, top_1: 0.393320, top_k: 0.644883, samples/s: 2243.497 1612356320.7255957
train: epoch 5, iter 3000, loss: 3.634918, top_1: 0.395156, top_k: 0.642500, samples/s: 2230.627 1612356332.2021983
train: epoch 5, iter 3100, loss: 3.523350, top_1: 0.393555, top_k: 0.643984, samples/s: 2216.882 1612356343.7499561
train: epoch 5, iter 3200, loss: 3.476256, top_1: 0.389961, top_k: 0.642383, samples/s: 2238.952 1612356355.1837914
train: epoch 5, iter 3300, loss: 3.564632, top_1: 0.390547, top_k: 0.642148, samples/s: 2222.388 1612356366.7030282
train: epoch 5, iter 3400, loss: 3.532026, top_1: 0.393594, top_k: 0.642305, samples/s: 2242.288 1612356378.1199083
train: epoch 5, iter 3500, loss: 3.589655, top_1: 0.394570, top_k: 0.649531, samples/s: 2232.069 1612356389.589109
train: epoch 5, iter 3600, loss: 3.483367, top_1: 0.396328, top_k: 0.647930, samples/s: 2231.234 1612356401.0625565
train: epoch 5, iter 3700, loss: 3.644598, top_1: 0.394453, top_k: 0.647031, samples/s: 2246.989 1612356412.4555357
train: epoch 5, iter 3800, loss: 3.555920, top_1: 0.394609, top_k: 0.645117, samples/s: 2222.410 1612356423.9745553
train: epoch 5, iter 3900, loss: 3.741341, top_1: 0.392930, top_k: 0.643711, samples/s: 2246.483 1612356435.3702056
train: epoch 5, iter 4000, loss: 3.603040, top_1: 0.393008, top_k: 0.642969, samples/s: 2208.859 1612356446.9599047
train: epoch 5, iter 4100, loss: 3.672413, top_1: 0.388594, top_k: 0.639336, samples/s: 2259.975 1612356458.287453
train: epoch 5, iter 4200, loss: 3.557523, top_1: 0.398086, top_k: 0.649102, samples/s: 2225.933 1612356469.7882097
train: epoch 5, iter 4300, loss: 3.521558, top_1: 0.394688, top_k: 0.644766, samples/s: 2221.277 1612356481.3131065
train: epoch 5, iter 4400, loss: 3.573385, top_1: 0.393008, top_k: 0.644297, samples/s: 2224.523 1612356492.821244
train: epoch 5, iter 4500, loss: 3.517530, top_1: 0.395000, top_k: 0.646172, samples/s: 2236.417 1612356504.26809
train: epoch 5, iter 4600, loss: 3.583295, top_1: 0.398047, top_k: 0.650664, samples/s: 2232.337 1612356515.7359166
train: epoch 5, iter 4700, loss: 3.753466, top_1: 0.396250, top_k: 0.651016, samples/s: 2246.014 1612356527.1338902
train: epoch 5, iter 4800, loss: 3.769698, top_1: 0.402148, top_k: 0.652578, samples/s: 2225.246 1612356538.6381927
train: epoch 5, iter 4900, loss: 3.561367, top_1: 0.396719, top_k: 0.652188, samples/s: 2235.999 1612356550.08726
train: epoch 5, iter 5000, loss: 3.508218, top_1: 0.402305, top_k: 0.651758, samples/s: 2243.995 1612356561.4955251
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_5.
validation: epoch 5, iter 195, top_1: 0.429567, top_k: 0.694832, samples/s: 2884.823 1612356579.116501
train: epoch 6, iter 100, loss: 3.692355, top_1: 0.409336, top_k: 0.658555, samples/s: 2249.784 1612356606.6168404
train: epoch 6, iter 200, loss: 3.390966, top_1: 0.406211, top_k: 0.659375, samples/s: 2251.180 1612356617.9886572
train: epoch 6, iter 300, loss: 3.778803, top_1: 0.401484, top_k: 0.649922, samples/s: 2248.791 1612356629.3725908
train: epoch 6, iter 400, loss: 3.573130, top_1: 0.404922, top_k: 0.659141, samples/s: 2248.298 1612356640.7588882
train: epoch 6, iter 500, loss: 3.643230, top_1: 0.401094, top_k: 0.649531, samples/s: 2256.719 1612356652.102806
train: epoch 6, iter 600, loss: 3.436191, top_1: 0.408633, top_k: 0.656836, samples/s: 2247.705 1612356663.4922018
train: epoch 6, iter 700, loss: 3.721899, top_1: 0.402500, top_k: 0.654492, samples/s: 2252.936 1612356674.8555574
train: epoch 6, iter 800, loss: 3.675118, top_1: 0.396719, top_k: 0.650078, samples/s: 2235.125 1612356686.3087
train: epoch 6, iter 900, loss: 3.529057, top_1: 0.408008, top_k: 0.655937, samples/s: 2246.892 1612356697.702463
train: epoch 6, iter 1000, loss: 3.638041, top_1: 0.408047, top_k: 0.656328, samples/s: 2234.227 1612356709.1602335
train: epoch 6, iter 1100, loss: 3.430253, top_1: 0.401523, top_k: 0.657148, samples/s: 2217.803 1612356720.7032409
train: epoch 6, iter 1200, loss: 3.397041, top_1: 0.406055, top_k: 0.656914, samples/s: 2238.900 1612356732.1373773
train: epoch 6, iter 1300, loss: 3.649477, top_1: 0.407773, top_k: 0.659805, samples/s: 2237.223 1612356743.580127
train: epoch 6, iter 1400, loss: 3.536123, top_1: 0.409375, top_k: 0.662578, samples/s: 2221.681 1612356755.1030018
train: epoch 6, iter 1500, loss: 3.412497, top_1: 0.409141, top_k: 0.658750, samples/s: 2246.318 1612356766.4993608
train: epoch 6, iter 1600, loss: 3.471757, top_1: 0.406602, top_k: 0.656758, samples/s: 2229.946 1612356777.979477
train: epoch 6, iter 1700, loss: 3.563554, top_1: 0.403242, top_k: 0.657344, samples/s: 2242.294 1612356789.3963587
train: epoch 6, iter 1800, loss: 3.673044, top_1: 0.407305, top_k: 0.653750, samples/s: 2219.211 1612356800.9321146
train: epoch 6, iter 1900, loss: 3.578841, top_1: 0.406523, top_k: 0.653398, samples/s: 2218.759 1612356812.4699798
train: epoch 6, iter 2000, loss: 3.401626, top_1: 0.412148, top_k: 0.658281, samples/s: 2229.002 1612356823.9550176
train: epoch 6, iter 2100, loss: 3.429813, top_1: 0.407656, top_k: 0.659492, samples/s: 2249.334 1612356835.3361375
train: epoch 6, iter 2200, loss: 3.264791, top_1: 0.408320, top_k: 0.656484, samples/s: 2235.358 1612356846.7884297
train: epoch 6, iter 2300, loss: 3.591703, top_1: 0.406094, top_k: 0.654805, samples/s: 2233.846 1612356858.2485151
train: epoch 6, iter 2400, loss: 3.611881, top_1: 0.403125, top_k: 0.656445, samples/s: 2249.554 1612356869.6286
train: epoch 6, iter 2500, loss: 3.565640, top_1: 0.408594, top_k: 0.655430, samples/s: 2253.642 1612356880.9879112
train: epoch 6, iter 2600, loss: 3.345797, top_1: 0.404727, top_k: 0.656992, samples/s: 2208.733 1612356892.578409
train: epoch 6, iter 2700, loss: 3.776711, top_1: 0.406914, top_k: 0.654805, samples/s: 2247.344 1612356903.9694471
train: epoch 6, iter 2800, loss: 3.505014, top_1: 0.412734, top_k: 0.659648, samples/s: 2223.636 1612356915.4821618
train: epoch 6, iter 2900, loss: 3.463788, top_1: 0.407969, top_k: 0.654141, samples/s: 2223.994 1612356926.9930418
train: epoch 6, iter 3000, loss: 3.514795, top_1: 0.404961, top_k: 0.657695, samples/s: 2244.571 1612356938.3982658
train: epoch 6, iter 3100, loss: 3.433711, top_1: 0.407305, top_k: 0.655391, samples/s: 2238.981 1612356949.832005
train: epoch 6, iter 3200, loss: 3.475826, top_1: 0.412969, top_k: 0.656602, samples/s: 2229.245 1612356961.3156934
train: epoch 6, iter 3300, loss: 3.549385, top_1: 0.405391, top_k: 0.655664, samples/s: 2243.688 1612356972.7255585
train: epoch 6, iter 3400, loss: 3.565589, top_1: 0.408711, top_k: 0.656094, samples/s: 2242.275 1612356984.142513
train: epoch 6, iter 3500, loss: 3.385638, top_1: 0.412266, top_k: 0.666211, samples/s: 2249.101 1612356995.5248203
train: epoch 6, iter 3600, loss: 3.616197, top_1: 0.410469, top_k: 0.658008, samples/s: 2235.020 1612357006.9789298
train: epoch 6, iter 3700, loss: 3.540962, top_1: 0.406602, top_k: 0.664336, samples/s: 2245.572 1612357018.3790588
train: epoch 6, iter 3800, loss: 3.506292, top_1: 0.408164, top_k: 0.661914, samples/s: 2197.392 1612357030.0292275
train: epoch 6, iter 3900, loss: 3.318484, top_1: 0.414531, top_k: 0.659844, samples/s: 2250.007 1612357041.4071405
train: epoch 6, iter 4000, loss: 3.600784, top_1: 0.412539, top_k: 0.664375, samples/s: 2217.993 1612357052.9489288
train: epoch 6, iter 4100, loss: 3.686890, top_1: 0.416289, top_k: 0.666445, samples/s: 2243.857 1612357064.357972
train: epoch 6, iter 4200, loss: 3.611231, top_1: 0.414648, top_k: 0.657109, samples/s: 2248.650 1612357075.7424831
train: epoch 6, iter 4300, loss: 3.613525, top_1: 0.415000, top_k: 0.663086, samples/s: 2228.068 1612357087.232243
train: epoch 6, iter 4400, loss: 3.391543, top_1: 0.405898, top_k: 0.657578, samples/s: 2208.694 1612357098.8228512
train: epoch 6, iter 4500, loss: 3.496078, top_1: 0.411484, top_k: 0.661250, samples/s: 2240.994 1612357110.246381
train: epoch 6, iter 4600, loss: 3.473055, top_1: 0.411133, top_k: 0.660977, samples/s: 2234.556 1612357121.702782
train: epoch 6, iter 4700, loss: 3.542568, top_1: 0.408711, top_k: 0.663086, samples/s: 2223.220 1612357133.2176335
train: epoch 6, iter 4800, loss: 3.352674, top_1: 0.411641, top_k: 0.662930, samples/s: 2230.157 1612357144.696558
train: epoch 6, iter 4900, loss: 3.396081, top_1: 0.414727, top_k: 0.668750, samples/s: 2243.711 1612357156.1063366
train: epoch 6, iter 5000, loss: 3.404795, top_1: 0.408281, top_k: 0.661523, samples/s: 2239.495 1612357167.5374615
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_6.
validation: epoch 6, iter 195, top_1: 0.455208, top_k: 0.719291, samples/s: 2884.275 1612357185.1458578
train: epoch 7, iter 100, loss: 3.359305, top_1: 0.418906, top_k: 0.665273, samples/s: 2236.411 1612357212.7465646
train: epoch 7, iter 200, loss: 3.421825, top_1: 0.420469, top_k: 0.668711, samples/s: 2233.921 1612357224.2062461
train: epoch 7, iter 300, loss: 3.638093, top_1: 0.413086, top_k: 0.663984, samples/s: 2253.727 1612357235.5652905
train: epoch 7, iter 400, loss: 3.439459, top_1: 0.425039, top_k: 0.674727, samples/s: 2250.522 1612357246.9403017
train: epoch 7, iter 500, loss: 3.585634, top_1: 0.423281, top_k: 0.668594, samples/s: 2250.546 1612357258.3153973
train: epoch 7, iter 600, loss: 3.291817, top_1: 0.419961, top_k: 0.668945, samples/s: 2243.032 1612357269.7285428
train: epoch 7, iter 700, loss: 3.440782, top_1: 0.413086, top_k: 0.666250, samples/s: 2272.402 1612357280.9940915
train: epoch 7, iter 800, loss: 3.570615, top_1: 0.417305, top_k: 0.663789, samples/s: 2241.005 1612357292.4175758
train: epoch 7, iter 900, loss: 3.333207, top_1: 0.421406, top_k: 0.668320, samples/s: 2247.622 1612357303.807297
train: epoch 7, iter 1000, loss: 3.556536, top_1: 0.423359, top_k: 0.670977, samples/s: 2232.479 1612357315.2744243
train: epoch 7, iter 1100, loss: 3.432608, top_1: 0.421523, top_k: 0.670117, samples/s: 2247.664 1612357326.6640174
train: epoch 7, iter 1200, loss: 3.430245, top_1: 0.418359, top_k: 0.668320, samples/s: 2228.466 1612357338.1517456
train: epoch 7, iter 1300, loss: 3.483352, top_1: 0.423633, top_k: 0.671211, samples/s: 2238.350 1612357349.5888326
train: epoch 7, iter 1400, loss: 3.568296, top_1: 0.420586, top_k: 0.666758, samples/s: 2243.947 1612357360.997208
train: epoch 7, iter 1500, loss: 3.400887, top_1: 0.419687, top_k: 0.667969, samples/s: 2226.590 1612357372.4946349
train: epoch 7, iter 1600, loss: 3.388106, top_1: 0.418281, top_k: 0.671094, samples/s: 2243.638 1612357383.9046075
train: epoch 7, iter 1700, loss: 3.642685, top_1: 0.416992, top_k: 0.668320, samples/s: 2237.646 1612357395.3452582
train: epoch 7, iter 1800, loss: 3.651807, top_1: 0.412734, top_k: 0.664336, samples/s: 2218.826 1612357406.8828194
train: epoch 7, iter 1900, loss: 3.574780, top_1: 0.420273, top_k: 0.665703, samples/s: 2236.432 1612357418.3297195
train: epoch 7, iter 2000, loss: 3.541318, top_1: 0.423906, top_k: 0.678203, samples/s: 2232.402 1612357429.7971406
train: epoch 7, iter 2100, loss: 3.524536, top_1: 0.424453, top_k: 0.669961, samples/s: 2239.827 1612357441.2266514
train: epoch 7, iter 2200, loss: 3.506908, top_1: 0.420625, top_k: 0.667891, samples/s: 2236.155 1612357452.674715
train: epoch 7, iter 2300, loss: 3.632801, top_1: 0.418242, top_k: 0.665547, samples/s: 2248.912 1612357464.0580957
train: epoch 7, iter 2400, loss: 3.432468, top_1: 0.422383, top_k: 0.666172, samples/s: 2218.408 1612357475.597846
train: epoch 7, iter 2500, loss: 3.250139, top_1: 0.419687, top_k: 0.671211, samples/s: 2242.453 1612357487.013994
train: epoch 7, iter 2600, loss: 3.396381, top_1: 0.424141, top_k: 0.671016, samples/s: 2243.250 1612357498.4260445
train: epoch 7, iter 2700, loss: 3.432361, top_1: 0.417539, top_k: 0.671406, samples/s: 2241.772 1612357509.8455403
train: epoch 7, iter 2800, loss: 3.534411, top_1: 0.415195, top_k: 0.666133, samples/s: 2207.858 1612357521.4404502
train: epoch 7, iter 2900, loss: 3.359594, top_1: 0.418086, top_k: 0.667578, samples/s: 2245.517 1612357532.84093
train: epoch 7, iter 3000, loss: 3.565763, top_1: 0.418203, top_k: 0.664102, samples/s: 2248.121 1612357544.2282085
train: epoch 7, iter 3100, loss: 3.467933, top_1: 0.417383, top_k: 0.671914, samples/s: 2239.062 1612357555.6616142
train: epoch 7, iter 3200, loss: 3.385998, top_1: 0.425977, top_k: 0.674844, samples/s: 2241.879 1612357567.080583
train: epoch 7, iter 3300, loss: 3.135822, top_1: 0.422969, top_k: 0.669805, samples/s: 2229.327 1612357578.5638494
train: epoch 7, iter 3400, loss: 3.419841, top_1: 0.419648, top_k: 0.671328, samples/s: 2248.167 1612357589.9509022
train: epoch 7, iter 3500, loss: 3.356879, top_1: 0.423555, top_k: 0.673125, samples/s: 2232.417 1612357601.4183888
train: epoch 7, iter 3600, loss: 3.542509, top_1: 0.418945, top_k: 0.669609, samples/s: 2247.626 1612357612.8081486
train: epoch 7, iter 3700, loss: 3.569705, top_1: 0.418477, top_k: 0.670195, samples/s: 2227.290 1612357624.3019512
train: epoch 7, iter 3800, loss: 3.486236, top_1: 0.417227, top_k: 0.666250, samples/s: 2261.626 1612357635.6211605
train: epoch 7, iter 3900, loss: 3.291442, top_1: 0.420039, top_k: 0.669727, samples/s: 2231.169 1612357647.0950541
train: epoch 7, iter 4000, loss: 3.385752, top_1: 0.421953, top_k: 0.672109, samples/s: 2236.170 1612357658.5432372
train: epoch 7, iter 4100, loss: 3.399093, top_1: 0.419258, top_k: 0.668359, samples/s: 2223.941 1612357670.05424
train: epoch 7, iter 4200, loss: 3.414901, top_1: 0.425312, top_k: 0.670352, samples/s: 2236.613 1612357681.5000944
train: epoch 7, iter 4300, loss: 3.330805, top_1: 0.421680, top_k: 0.674297, samples/s: 2236.507 1612357692.946552
train: epoch 7, iter 4400, loss: 3.595524, top_1: 0.419063, top_k: 0.669805, samples/s: 2217.433 1612357704.4914813
train: epoch 7, iter 4500, loss: 3.401731, top_1: 0.418789, top_k: 0.669414, samples/s: 2244.591 1612357715.8966665
train: epoch 7, iter 4600, loss: 3.437043, top_1: 0.423906, top_k: 0.666719, samples/s: 2244.887 1612357727.3003323
train: epoch 7, iter 4700, loss: 3.439446, top_1: 0.425547, top_k: 0.679844, samples/s: 2237.627 1612357738.741005
train: epoch 7, iter 4800, loss: 3.652860, top_1: 0.426680, top_k: 0.674766, samples/s: 2230.805 1612357750.2167153
train: epoch 7, iter 4900, loss: 3.515196, top_1: 0.430430, top_k: 0.678672, samples/s: 2233.181 1612357761.6801467
train: epoch 7, iter 5000, loss: 3.376006, top_1: 0.418594, top_k: 0.672813, samples/s: 2220.593 1612357773.2089252
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_7.
validation: epoch 7, iter 195, top_1: 0.460978, top_k: 0.718269, samples/s: 2887.795 1612357790.864676
train: epoch 8, iter 100, loss: 3.267110, top_1: 0.431016, top_k: 0.681055, samples/s: 2255.815 1612357818.2734048
train: epoch 8, iter 200, loss: 3.487679, top_1: 0.435664, top_k: 0.687031, samples/s: 2237.541 1612357829.7146776
train: epoch 8, iter 300, loss: 3.404769, top_1: 0.426367, top_k: 0.677422, samples/s: 2245.951 1612357841.1130483
train: epoch 8, iter 400, loss: 3.414524, top_1: 0.428555, top_k: 0.679180, samples/s: 2259.290 1612357852.4439023
train: epoch 8, iter 500, loss: 3.515976, top_1: 0.431563, top_k: 0.677070, samples/s: 2260.617 1612357863.7681892
train: epoch 8, iter 600, loss: 3.572126, top_1: 0.429336, top_k: 0.679297, samples/s: 2259.252 1612357875.0993903
train: epoch 8, iter 700, loss: 3.352821, top_1: 0.431055, top_k: 0.676797, samples/s: 2244.368 1612357886.5056684
train: epoch 8, iter 800, loss: 3.330051, top_1: 0.433086, top_k: 0.683047, samples/s: 2257.466 1612357897.8458195
train: epoch 8, iter 900, loss: 3.360663, top_1: 0.433125, top_k: 0.682227, samples/s: 2231.179 1612357909.3195584
train: epoch 8, iter 1000, loss: 3.348514, top_1: 0.426680, top_k: 0.672617, samples/s: 2227.219 1612357920.8137114
train: epoch 8, iter 1100, loss: 3.638936, top_1: 0.427812, top_k: 0.674531, samples/s: 2224.392 1612357932.3224761
train: epoch 8, iter 1200, loss: 3.430356, top_1: 0.426758, top_k: 0.675898, samples/s: 2226.862 1612357943.818474
train: epoch 8, iter 1300, loss: 3.644178, top_1: 0.427031, top_k: 0.674883, samples/s: 2239.223 1612357955.2511034
train: epoch 8, iter 1400, loss: 3.472542, top_1: 0.433008, top_k: 0.680859, samples/s: 2223.487 1612357966.7645555
train: epoch 8, iter 1500, loss: 3.440504, top_1: 0.428906, top_k: 0.678398, samples/s: 2245.049 1612357978.1674163
train: epoch 8, iter 1600, loss: 3.272042, top_1: 0.427734, top_k: 0.676289, samples/s: 2242.467 1612357989.5834117
train: epoch 8, iter 1700, loss: 3.239451, top_1: 0.426641, top_k: 0.679922, samples/s: 2230.485 1612358001.0607414
train: epoch 8, iter 1800, loss: 3.331300, top_1: 0.431211, top_k: 0.677930, samples/s: 2248.679 1612358012.4452004
train: epoch 8, iter 1900, loss: 3.340227, top_1: 0.431523, top_k: 0.678945, samples/s: 2199.822 1612358024.082444
train: epoch 8, iter 2000, loss: 3.374001, top_1: 0.427695, top_k: 0.678672, samples/s: 2241.392 1612358035.5038936
train: epoch 8, iter 2100, loss: 3.284319, top_1: 0.429492, top_k: 0.678398, samples/s: 2234.113 1612358046.962604
train: epoch 8, iter 2200, loss: 3.352218, top_1: 0.430156, top_k: 0.678242, samples/s: 2246.646 1612358058.3574176
train: epoch 8, iter 2300, loss: 3.597508, top_1: 0.428164, top_k: 0.676836, samples/s: 2249.568 1612358069.737303
train: epoch 8, iter 2400, loss: 3.380253, top_1: 0.429375, top_k: 0.678867, samples/s: 2229.804 1612358081.218253
train: epoch 8, iter 2500, loss: 3.457112, top_1: 0.430117, top_k: 0.679336, samples/s: 2262.236 1612358092.5344555
train: epoch 8, iter 2600, loss: 3.659291, top_1: 0.429336, top_k: 0.679648, samples/s: 2197.597 1612358104.1834583
train: epoch 8, iter 2700, loss: 3.350578, top_1: 0.429453, top_k: 0.681953, samples/s: 2277.198 1612358115.4253852
train: epoch 8, iter 2800, loss: 3.598052, top_1: 0.428867, top_k: 0.682617, samples/s: 2236.028 1612358126.8743026
train: epoch 8, iter 2900, loss: 3.503553, top_1: 0.431641, top_k: 0.677852, samples/s: 2244.973 1612358138.27747
train: epoch 8, iter 3000, loss: 3.266314, top_1: 0.431484, top_k: 0.680625, samples/s: 2259.659 1612358149.606651
train: epoch 8, iter 3100, loss: 3.403350, top_1: 0.434844, top_k: 0.684805, samples/s: 2238.363 1612358161.043586
train: epoch 8, iter 3200, loss: 3.571362, top_1: 0.433945, top_k: 0.678164, samples/s: 2259.758 1612358172.3722253
train: epoch 8, iter 3300, loss: 3.321741, top_1: 0.430977, top_k: 0.677773, samples/s: 2237.916 1612358183.8114629
train: epoch 8, iter 3400, loss: 3.447099, top_1: 0.431953, top_k: 0.681406, samples/s: 2246.251 1612358195.2082047
train: epoch 8, iter 3500, loss: 3.548392, top_1: 0.429922, top_k: 0.680742, samples/s: 2241.210 1612358206.6305816
train: epoch 8, iter 3600, loss: 3.698848, top_1: 0.426719, top_k: 0.679414, samples/s: 2230.606 1612358218.107377
train: epoch 8, iter 3700, loss: 3.330575, top_1: 0.433906, top_k: 0.682734, samples/s: 2271.366 1612358229.3780396
train: epoch 8, iter 3800, loss: 3.381946, top_1: 0.432422, top_k: 0.680312, samples/s: 2233.763 1612358240.838527
train: epoch 8, iter 3900, loss: 3.296083, top_1: 0.427617, top_k: 0.678984, samples/s: 2253.231 1612358252.2001178
train: epoch 8, iter 4000, loss: 3.312408, top_1: 0.429648, top_k: 0.676016, samples/s: 2264.041 1612358263.507182
train: epoch 8, iter 4100, loss: 3.541486, top_1: 0.430039, top_k: 0.681367, samples/s: 2252.377 1612358274.87312
train: epoch 8, iter 4200, loss: 3.429616, top_1: 0.431172, top_k: 0.678086, samples/s: 2257.310 1612358286.213931
train: epoch 8, iter 4300, loss: 3.418382, top_1: 0.426289, top_k: 0.677344, samples/s: 2251.562 1612358297.5839622
train: epoch 8, iter 4400, loss: 3.419411, top_1: 0.431602, top_k: 0.679922, samples/s: 2255.243 1612358308.9352314
train: epoch 8, iter 4500, loss: 3.391252, top_1: 0.437227, top_k: 0.679453, samples/s: 2233.516 1612358320.396854
train: epoch 8, iter 4600, loss: 3.490793, top_1: 0.433320, top_k: 0.681211, samples/s: 2248.198 1612358331.7837312
train: epoch 8, iter 4700, loss: 3.345952, top_1: 0.435312, top_k: 0.681133, samples/s: 2241.375 1612358343.2054
train: epoch 8, iter 4800, loss: 3.511304, top_1: 0.432266, top_k: 0.681289, samples/s: 2261.656 1612358354.5244515
train: epoch 8, iter 4900, loss: 3.538105, top_1: 0.432891, top_k: 0.681602, samples/s: 2239.006 1612358365.9582021
train: epoch 8, iter 5000, loss: 3.207239, top_1: 0.434414, top_k: 0.680508, samples/s: 2265.756 1612358377.2567492
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_8.
validation: epoch 8, iter 195, top_1: 0.468389, top_k: 0.727524, samples/s: 2805.551 1612358395.4333773
train: epoch 9, iter 100, loss: 3.424197, top_1: 0.442422, top_k: 0.692344, samples/s: 2239.344 1612358422.8715634
train: epoch 9, iter 200, loss: 3.362320, top_1: 0.440469, top_k: 0.689883, samples/s: 2257.732 1612358434.2103274
train: epoch 9, iter 300, loss: 3.358618, top_1: 0.444766, top_k: 0.693359, samples/s: 2257.918 1612358445.5482404
train: epoch 9, iter 400, loss: 3.486050, top_1: 0.438711, top_k: 0.684727, samples/s: 2240.688 1612358456.9733155
train: epoch 9, iter 500, loss: 3.332350, top_1: 0.436484, top_k: 0.687930, samples/s: 2271.657 1612358468.2425654
train: epoch 9, iter 600, loss: 3.301057, top_1: 0.441094, top_k: 0.683438, samples/s: 2229.628 1612358479.7243154
train: epoch 9, iter 700, loss: 3.297351, top_1: 0.433203, top_k: 0.682266, samples/s: 2249.714 1612358491.1046774
train: epoch 9, iter 800, loss: 3.361754, top_1: 0.437422, top_k: 0.685078, samples/s: 2258.688 1612358502.4375682
train: epoch 9, iter 900, loss: 3.405678, top_1: 0.433125, top_k: 0.681445, samples/s: 2227.323 1612358513.9317782
train: epoch 9, iter 1000, loss: 3.219203, top_1: 0.441289, top_k: 0.688672, samples/s: 2228.314 1612358525.4196787
train: epoch 9, iter 1100, loss: 3.515710, top_1: 0.442500, top_k: 0.685352, samples/s: 2213.771 1612358536.9837458
train: epoch 9, iter 1200, loss: 3.220548, top_1: 0.436289, top_k: 0.688320, samples/s: 2232.891 1612358548.4486213
train: epoch 9, iter 1300, loss: 3.369090, top_1: 0.433477, top_k: 0.683594, samples/s: 2232.969 1612358559.9132028
train: epoch 9, iter 1400, loss: 3.227283, top_1: 0.439883, top_k: 0.685898, samples/s: 2219.964 1612358571.4448614
train: epoch 9, iter 1500, loss: 3.252909, top_1: 0.439258, top_k: 0.686992, samples/s: 2254.209 1612358582.801399
train: epoch 9, iter 1600, loss: 3.389652, top_1: 0.434961, top_k: 0.683086, samples/s: 2235.404 1612358594.2535648
train: epoch 9, iter 1700, loss: 3.205917, top_1: 0.434023, top_k: 0.682305, samples/s: 2236.337 1612358605.70077
train: epoch 9, iter 1800, loss: 3.461540, top_1: 0.435469, top_k: 0.683047, samples/s: 2246.846 1612358617.0945835
train: epoch 9, iter 1900, loss: 3.383847, top_1: 0.439258, top_k: 0.687773, samples/s: 2239.749 1612358628.524373
train: epoch 9, iter 2000, loss: 3.556837, top_1: 0.437578, top_k: 0.682031, samples/s: 2228.594 1612358640.0114772
train: epoch 9, iter 2100, loss: 3.031700, top_1: 0.438320, top_k: 0.687266, samples/s: 2226.279 1612358651.510418
train: epoch 9, iter 2200, loss: 3.262578, top_1: 0.438906, top_k: 0.689102, samples/s: 2234.869 1612358662.965235
train: epoch 9, iter 2300, loss: 3.376020, top_1: 0.443281, top_k: 0.690781, samples/s: 2229.409 1612358674.4481812
train: epoch 9, iter 2400, loss: 3.401819, top_1: 0.438398, top_k: 0.683164, samples/s: 2248.190 1612358685.835042
train: epoch 9, iter 2500, loss: 3.597364, top_1: 0.437773, top_k: 0.686250, samples/s: 2235.821 1612358697.2849743
train: epoch 9, iter 2600, loss: 3.468449, top_1: 0.445937, top_k: 0.686680, samples/s: 2218.335 1612358708.8252544
train: epoch 9, iter 2700, loss: 3.446693, top_1: 0.441406, top_k: 0.685898, samples/s: 2249.452 1612358720.205797
train: epoch 9, iter 2800, loss: 3.451168, top_1: 0.430430, top_k: 0.680391, samples/s: 2227.656 1612358731.697631
train: epoch 9, iter 2900, loss: 3.320120, top_1: 0.432344, top_k: 0.687578, samples/s: 2238.018 1612358743.136334
train: epoch 9, iter 3000, loss: 3.371281, top_1: 0.436172, top_k: 0.685547, samples/s: 2229.024 1612358754.6212144
train: epoch 9, iter 3100, loss: 3.515743, top_1: 0.440508, top_k: 0.689883, samples/s: 2241.823 1612358766.0405147
train: epoch 9, iter 3200, loss: 3.511773, top_1: 0.438125, top_k: 0.685117, samples/s: 2235.947 1612358777.4897642
train: epoch 9, iter 3300, loss: 3.381428, top_1: 0.438984, top_k: 0.686641, samples/s: 2185.947 1612358789.2009993
train: epoch 9, iter 3400, loss: 3.248399, top_1: 0.440156, top_k: 0.684844, samples/s: 2215.337 1612358800.7567804
train: epoch 9, iter 3500, loss: 3.420989, top_1: 0.437266, top_k: 0.687969, samples/s: 2245.843 1612358812.1555498
train: epoch 9, iter 3600, loss: 3.424233, top_1: 0.438828, top_k: 0.688320, samples/s: 2243.223 1612358823.5677652
train: epoch 9, iter 3700, loss: 3.265446, top_1: 0.441328, top_k: 0.685703, samples/s: 2244.867 1612358834.9714742
train: epoch 9, iter 3800, loss: 3.286418, top_1: 0.438633, top_k: 0.686719, samples/s: 2230.488 1612358846.4487903
train: epoch 9, iter 3900, loss: 3.317786, top_1: 0.438008, top_k: 0.687656, samples/s: 2243.887 1612358857.857615
train: epoch 9, iter 4000, loss: 3.149621, top_1: 0.441133, top_k: 0.686406, samples/s: 2218.224 1612358869.3984241
train: epoch 9, iter 4100, loss: 3.530884, top_1: 0.440547, top_k: 0.685117, samples/s: 2220.322 1612358880.9281862
train: epoch 9, iter 4200, loss: 3.412401, top_1: 0.437383, top_k: 0.685586, samples/s: 2247.288 1612358892.3197033
train: epoch 9, iter 4300, loss: 3.366664, top_1: 0.437188, top_k: 0.684727, samples/s: 2245.927 1612358903.7181304
train: epoch 9, iter 4400, loss: 3.369652, top_1: 0.438828, top_k: 0.686484, samples/s: 2220.139 1612358915.2490833
train: epoch 9, iter 4500, loss: 3.500834, top_1: 0.433633, top_k: 0.685703, samples/s: 2239.607 1612358926.6796367
train: epoch 9, iter 4600, loss: 3.571666, top_1: 0.435703, top_k: 0.689063, samples/s: 2231.570 1612358938.1513164
train: epoch 9, iter 4700, loss: 3.228881, top_1: 0.437383, top_k: 0.683086, samples/s: 2229.871 1612358949.6317904
train: epoch 9, iter 4800, loss: 3.258704, top_1: 0.442656, top_k: 0.688828, samples/s: 2229.799 1612358961.1125994
train: epoch 9, iter 4900, loss: 3.474856, top_1: 0.440742, top_k: 0.689805, samples/s: 2227.062 1612358972.6075463
train: epoch 9, iter 5000, loss: 3.156588, top_1: 0.449805, top_k: 0.691914, samples/s: 2253.101 1612358983.9697526
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_9.
validation: epoch 9, iter 195, top_1: 0.483774, top_k: 0.743510, samples/s: 2831.680 1612359001.9229095
train: epoch 10, iter 100, loss: 3.370929, top_1: 0.450234, top_k: 0.694805, samples/s: 2246.102 1612359029.0341027
train: epoch 10, iter 200, loss: 3.044050, top_1: 0.447891, top_k: 0.698281, samples/s: 2255.587 1612359040.3836792
train: epoch 10, iter 300, loss: 3.470162, top_1: 0.447344, top_k: 0.693867, samples/s: 2250.119 1612359051.760886
train: epoch 10, iter 400, loss: 3.359758, top_1: 0.442812, top_k: 0.690625, samples/s: 2255.991 1612359063.1083965
train: epoch 10, iter 500, loss: 3.296913, top_1: 0.444609, top_k: 0.691562, samples/s: 2242.822 1612359074.522667
train: epoch 10, iter 600, loss: 3.578550, top_1: 0.443867, top_k: 0.694063, samples/s: 2253.538 1612359085.8825138
train: epoch 10, iter 700, loss: 3.233455, top_1: 0.449414, top_k: 0.692070, samples/s: 2243.060 1612359097.2955246
train: epoch 10, iter 800, loss: 3.066851, top_1: 0.441719, top_k: 0.692422, samples/s: 2236.635 1612359108.7413735
train: epoch 10, iter 900, loss: 3.491163, top_1: 0.448086, top_k: 0.689219, samples/s: 2247.657 1612359120.1309395
train: epoch 10, iter 1000, loss: 3.572994, top_1: 0.442773, top_k: 0.690430, samples/s: 2227.892 1612359131.621579
train: epoch 10, iter 1100, loss: 3.306065, top_1: 0.442578, top_k: 0.691328, samples/s: 2213.042 1612359143.1893628
train: epoch 10, iter 1200, loss: 3.390483, top_1: 0.444727, top_k: 0.693672, samples/s: 2228.934 1612359154.6747098
train: epoch 10, iter 1300, loss: 3.283648, top_1: 0.448320, top_k: 0.691484, samples/s: 2190.765 1612359166.3601303
train: epoch 10, iter 1400, loss: 3.439433, top_1: 0.447070, top_k: 0.692148, samples/s: 2206.842 1612359177.960401
train: epoch 10, iter 1500, loss: 3.391279, top_1: 0.445703, top_k: 0.692109, samples/s: 2217.769 1612359189.5035024
train: epoch 10, iter 1600, loss: 3.474153, top_1: 0.446250, top_k: 0.696055, samples/s: 2219.917 1612359201.0354671
train: epoch 10, iter 1700, loss: 3.355675, top_1: 0.443516, top_k: 0.691172, samples/s: 2224.783 1612359212.542213
train: epoch 10, iter 1800, loss: 3.406095, top_1: 0.441836, top_k: 0.689609, samples/s: 2209.391 1612359224.129177
train: epoch 10, iter 1900, loss: 3.439175, top_1: 0.443672, top_k: 0.692969, samples/s: 2204.217 1612359235.7432227
train: epoch 10, iter 2000, loss: 3.284018, top_1: 0.442148, top_k: 0.694102, samples/s: 2218.752 1612359247.2812974
train: epoch 10, iter 2100, loss: 3.426474, top_1: 0.448125, top_k: 0.695898, samples/s: 2199.266 1612359258.9215481
train: epoch 10, iter 2200, loss: 3.308688, top_1: 0.449023, top_k: 0.690742, samples/s: 2234.248 1612359270.37955
train: epoch 10, iter 2300, loss: 3.349528, top_1: 0.448516, top_k: 0.693516, samples/s: 2220.460 1612359281.9086692
train: epoch 10, iter 2400, loss: 3.187705, top_1: 0.443789, top_k: 0.689453, samples/s: 2202.485 1612359293.53188
train: epoch 10, iter 2500, loss: 3.222206, top_1: 0.442930, top_k: 0.692773, samples/s: 2204.698 1612359305.1434276
train: epoch 10, iter 2600, loss: 3.292667, top_1: 0.443828, top_k: 0.694766, samples/s: 2207.002 1612359316.7428622
train: epoch 10, iter 2700, loss: 3.435502, top_1: 0.443828, top_k: 0.691875, samples/s: 2219.566 1612359328.2767203
train: epoch 10, iter 2800, loss: 3.331697, top_1: 0.442266, top_k: 0.690234, samples/s: 2206.732 1612359339.8775399
train: epoch 10, iter 2900, loss: 3.444737, top_1: 0.444922, top_k: 0.692227, samples/s: 2192.605 1612359351.5531452
train: epoch 10, iter 3000, loss: 3.234261, top_1: 0.445586, top_k: 0.698203, samples/s: 2234.668 1612359363.0089698
train: epoch 10, iter 3100, loss: 3.332999, top_1: 0.444336, top_k: 0.695195, samples/s: 2222.184 1612359374.5292444
train: epoch 10, iter 3200, loss: 3.380150, top_1: 0.443711, top_k: 0.693789, samples/s: 2232.633 1612359385.995442
train: epoch 10, iter 3300, loss: 3.259431, top_1: 0.443750, top_k: 0.696172, samples/s: 2185.296 1612359397.710134
train: epoch 10, iter 3400, loss: 3.548673, top_1: 0.442812, top_k: 0.692266, samples/s: 2220.936 1612359409.2367878
train: epoch 10, iter 3500, loss: 3.335178, top_1: 0.447383, top_k: 0.692578, samples/s: 2204.818 1612359420.8477354
train: epoch 10, iter 3600, loss: 3.512985, top_1: 0.446641, top_k: 0.692422, samples/s: 2213.615 1612359432.4128382
train: epoch 10, iter 3700, loss: 3.296800, top_1: 0.446836, top_k: 0.693516, samples/s: 2216.015 1612359443.9647892
train: epoch 10, iter 3800, loss: 3.463877, top_1: 0.442656, top_k: 0.688477, samples/s: 2203.118 1612359455.584691
train: epoch 10, iter 3900, loss: 3.493768, top_1: 0.446133, top_k: 0.699453, samples/s: 2199.494 1612359467.2237494
train: epoch 10, iter 4000, loss: 3.205436, top_1: 0.446328, top_k: 0.689219, samples/s: 2213.290 1612359478.790573
train: epoch 10, iter 4100, loss: 3.557721, top_1: 0.446484, top_k: 0.692109, samples/s: 2219.103 1612359490.3264034
train: epoch 10, iter 4200, loss: 3.427734, top_1: 0.442812, top_k: 0.688789, samples/s: 2204.209 1612359501.940553
train: epoch 10, iter 4300, loss: 3.302205, top_1: 0.450547, top_k: 0.692891, samples/s: 2219.232 1612359513.4760711
train: epoch 10, iter 4400, loss: 3.059381, top_1: 0.449688, top_k: 0.693477, samples/s: 2217.703 1612359525.0196218
train: epoch 10, iter 4500, loss: 3.453313, top_1: 0.445625, top_k: 0.693359, samples/s: 2202.969 1612359536.6402214
train: epoch 10, iter 4600, loss: 3.283682, top_1: 0.438984, top_k: 0.687969, samples/s: 2225.989 1612359548.1407292
train: epoch 10, iter 4700, loss: 3.325685, top_1: 0.440898, top_k: 0.691133, samples/s: 2206.858 1612359559.7410064
train: epoch 10, iter 4800, loss: 3.317909, top_1: 0.448555, top_k: 0.693438, samples/s: 2214.774 1612359571.2996924
train: epoch 10, iter 4900, loss: 3.258374, top_1: 0.445234, top_k: 0.696016, samples/s: 2207.189 1612359582.8981853
train: epoch 10, iter 5000, loss: 3.230287, top_1: 0.448125, top_k: 0.688125, samples/s: 2201.235 1612359594.5280612
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_10.
validation: epoch 10, iter 195, top_1: 0.496835, top_k: 0.754607, samples/s: 2870.656 1612359612.1568027
train: epoch 11, iter 100, loss: 3.289002, top_1: 0.456016, top_k: 0.703711, samples/s: 2233.606 1612359639.8383477
train: epoch 11, iter 200, loss: 3.353883, top_1: 0.452266, top_k: 0.696094, samples/s: 2253.707 1612359651.1978502
train: epoch 11, iter 300, loss: 3.265861, top_1: 0.455781, top_k: 0.699258, samples/s: 2256.362 1612359662.543099
train: epoch 11, iter 400, loss: 3.097041, top_1: 0.454648, top_k: 0.702344, samples/s: 2249.459 1612359673.9236286
train: epoch 11, iter 500, loss: 3.068301, top_1: 0.452148, top_k: 0.696484, samples/s: 2229.189 1612359685.407648
train: epoch 11, iter 600, loss: 3.300827, top_1: 0.456055, top_k: 0.702344, samples/s: 2258.535 1612359696.7424011
train: epoch 11, iter 700, loss: 3.387376, top_1: 0.452070, top_k: 0.701211, samples/s: 2228.667 1612359708.2290754
train: epoch 11, iter 800, loss: 3.449264, top_1: 0.450586, top_k: 0.694258, samples/s: 2240.060 1612359719.6573603
train: epoch 11, iter 900, loss: 3.406650, top_1: 0.447617, top_k: 0.697344, samples/s: 2207.424 1612359731.2546742
train: epoch 11, iter 1000, loss: 3.239713, top_1: 0.448320, top_k: 0.698594, samples/s: 2205.140 1612359742.8639548
train: epoch 11, iter 1100, loss: 3.307591, top_1: 0.453320, top_k: 0.696211, samples/s: 2235.702 1612359754.314427
train: epoch 11, iter 1200, loss: 3.366522, top_1: 0.454453, top_k: 0.698984, samples/s: 2215.176 1612359765.8710434
train: epoch 11, iter 1300, loss: 3.328495, top_1: 0.451406, top_k: 0.697461, samples/s: 2203.776 1612359777.4874146
train: epoch 11, iter 1400, loss: 3.224681, top_1: 0.449414, top_k: 0.696758, samples/s: 2203.141 1612359789.1072
train: epoch 11, iter 1500, loss: 3.290606, top_1: 0.456523, top_k: 0.700547, samples/s: 2231.250 1612359800.5806265
train: epoch 11, iter 1600, loss: 3.383579, top_1: 0.450469, top_k: 0.699609, samples/s: 2199.110 1612359812.221654
train: epoch 11, iter 1700, loss: 3.291928, top_1: 0.448594, top_k: 0.697109, samples/s: 2201.710 1612359823.8489962
train: epoch 11, iter 1800, loss: 3.353319, top_1: 0.452109, top_k: 0.695273, samples/s: 2213.793 1612359835.4128797
train: epoch 11, iter 1900, loss: 3.331544, top_1: 0.447969, top_k: 0.692813, samples/s: 2202.326 1612359847.0369413
train: epoch 11, iter 2000, loss: 3.451668, top_1: 0.452070, top_k: 0.697656, samples/s: 2236.962 1612359858.481012
train: epoch 11, iter 2100, loss: 3.358376, top_1: 0.450937, top_k: 0.701523, samples/s: 2208.668 1612359870.0717795
train: epoch 11, iter 2200, loss: 3.480038, top_1: 0.457969, top_k: 0.698750, samples/s: 2200.755 1612359881.704128
train: epoch 11, iter 2300, loss: 3.314267, top_1: 0.444414, top_k: 0.694102, samples/s: 2215.661 1612359893.2582254
train: epoch 11, iter 2400, loss: 3.302307, top_1: 0.451641, top_k: 0.697109, samples/s: 2203.238 1612359904.8774803
train: epoch 11, iter 2500, loss: 3.235261, top_1: 0.456562, top_k: 0.702383, samples/s: 2204.326 1612359916.4909515
train: epoch 11, iter 2600, loss: 3.397045, top_1: 0.450391, top_k: 0.696914, samples/s: 2198.756 1612359928.1340375
train: epoch 11, iter 2700, loss: 3.520211, top_1: 0.450547, top_k: 0.705508, samples/s: 2217.540 1612359939.678315
train: epoch 11, iter 2800, loss: 3.200413, top_1: 0.452969, top_k: 0.703398, samples/s: 2230.348 1612359951.1562908
train: epoch 11, iter 2900, loss: 3.113495, top_1: 0.458945, top_k: 0.699297, samples/s: 2201.247 1612359962.7861354
train: epoch 11, iter 3000, loss: 3.242764, top_1: 0.443984, top_k: 0.692773, samples/s: 2197.981 1612359974.4332337
train: epoch 11, iter 3100, loss: 3.580805, top_1: 0.446406, top_k: 0.695937, samples/s: 2211.813 1612359986.0073419
train: epoch 11, iter 3200, loss: 3.293253, top_1: 0.450195, top_k: 0.698047, samples/s: 2215.082 1612359997.5644696
train: epoch 11, iter 3300, loss: 3.318871, top_1: 0.451562, top_k: 0.696836, samples/s: 2216.659 1612360009.113374
train: epoch 11, iter 3400, loss: 3.538935, top_1: 0.447852, top_k: 0.693281, samples/s: 2187.292 1612360020.8175054
train: epoch 11, iter 3500, loss: 3.393317, top_1: 0.445430, top_k: 0.695195, samples/s: 2212.176 1612360032.3897076
train: epoch 11, iter 3600, loss: 3.424223, top_1: 0.451172, top_k: 0.699531, samples/s: 2226.345 1612360043.8883219
train: epoch 11, iter 3700, loss: 3.292715, top_1: 0.454141, top_k: 0.700000, samples/s: 2206.595 1612360055.4900098
train: epoch 11, iter 3800, loss: 3.316322, top_1: 0.448789, top_k: 0.695391, samples/s: 2236.988 1612360066.93388
train: epoch 11, iter 3900, loss: 3.410981, top_1: 0.452188, top_k: 0.697422, samples/s: 2238.807 1612360078.3685703
train: epoch 11, iter 4000, loss: 3.299654, top_1: 0.455156, top_k: 0.701367, samples/s: 2195.449 1612360090.0290132
train: epoch 11, iter 4100, loss: 3.362581, top_1: 0.447813, top_k: 0.697148, samples/s: 2230.958 1612360101.5039268
train: epoch 11, iter 4200, loss: 3.375304, top_1: 0.446289, top_k: 0.692500, samples/s: 2226.468 1612360113.0019858
train: epoch 11, iter 4300, loss: 3.218463, top_1: 0.451914, top_k: 0.697617, samples/s: 2246.731 1612360124.3963625
train: epoch 11, iter 4400, loss: 3.031791, top_1: 0.451797, top_k: 0.695078, samples/s: 2225.934 1612360135.8971002
train: epoch 11, iter 4500, loss: 3.318337, top_1: 0.454727, top_k: 0.697773, samples/s: 2226.102 1612360147.3969972
train: epoch 11, iter 4600, loss: 3.191200, top_1: 0.449688, top_k: 0.693477, samples/s: 2251.006 1612360158.7697709
train: epoch 11, iter 4700, loss: 3.310546, top_1: 0.451992, top_k: 0.702773, samples/s: 2233.594 1612360170.231052
train: epoch 11, iter 4800, loss: 3.432674, top_1: 0.451367, top_k: 0.699063, samples/s: 2211.956 1612360181.804545
train: epoch 11, iter 4900, loss: 3.247678, top_1: 0.450234, top_k: 0.698516, samples/s: 2276.804 1612360193.048349
train: epoch 11, iter 5000, loss: 3.382983, top_1: 0.451719, top_k: 0.696641, samples/s: 2224.249 1612360204.557824
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_11.
validation: epoch 11, iter 195, top_1: 0.493610, top_k: 0.752624, samples/s: 2761.362 1612360223.0201166
train: epoch 12, iter 100, loss: 3.277386, top_1: 0.457656, top_k: 0.704219, samples/s: 2232.204 1612360250.6599035
train: epoch 12, iter 200, loss: 3.299486, top_1: 0.463164, top_k: 0.709141, samples/s: 2264.942 1612360261.962786
train: epoch 12, iter 300, loss: 3.218174, top_1: 0.460195, top_k: 0.702812, samples/s: 2255.346 1612360273.3134897
train: epoch 12, iter 400, loss: 3.391763, top_1: 0.464102, top_k: 0.708867, samples/s: 2251.620 1612360284.682998
train: epoch 12, iter 500, loss: 3.115989, top_1: 0.461133, top_k: 0.701406, samples/s: 2247.973 1612360296.071049
train: epoch 12, iter 600, loss: 3.423230, top_1: 0.460586, top_k: 0.705977, samples/s: 2256.285 1612360307.4171793
train: epoch 12, iter 700, loss: 3.080303, top_1: 0.456289, top_k: 0.702969, samples/s: 2225.224 1612360318.9215865
train: epoch 12, iter 800, loss: 3.269771, top_1: 0.465547, top_k: 0.704766, samples/s: 2275.524 1612360330.1717427
train: epoch 12, iter 900, loss: 3.066732, top_1: 0.462031, top_k: 0.709688, samples/s: 2216.385 1612360341.7221317
train: epoch 12, iter 1000, loss: 3.324836, top_1: 0.455430, top_k: 0.700781, samples/s: 2248.141 1612360353.1092758
train: epoch 12, iter 1100, loss: 3.424698, top_1: 0.458789, top_k: 0.705781, samples/s: 2240.357 1612360364.5360582
train: epoch 12, iter 1200, loss: 3.481699, top_1: 0.452930, top_k: 0.700586, samples/s: 2242.041 1612360375.9541962
train: epoch 12, iter 1300, loss: 3.275904, top_1: 0.452773, top_k: 0.701992, samples/s: 2226.357 1612360387.4527962
train: epoch 12, iter 1400, loss: 3.327503, top_1: 0.459922, top_k: 0.705352, samples/s: 2243.136 1612360398.8654518
train: epoch 12, iter 1500, loss: 3.433489, top_1: 0.457305, top_k: 0.701367, samples/s: 2216.202 1612360410.4167275
train: epoch 12, iter 1600, loss: 3.340626, top_1: 0.460898, top_k: 0.704492, samples/s: 2233.800 1612360421.8769815
train: epoch 12, iter 1700, loss: 3.299019, top_1: 0.453555, top_k: 0.696953, samples/s: 2259.356 1612360433.2076304
train: epoch 12, iter 1800, loss: 3.380063, top_1: 0.453359, top_k: 0.700977, samples/s: 2231.590 1612360444.6793735
train: epoch 12, iter 1900, loss: 3.345380, top_1: 0.452031, top_k: 0.699297, samples/s: 2232.224 1612360456.147687
train: epoch 12, iter 2000, loss: 3.167401, top_1: 0.461094, top_k: 0.705664, samples/s: 2248.973 1612360467.5306497
train: epoch 12, iter 2100, loss: 3.407212, top_1: 0.451289, top_k: 0.699766, samples/s: 2234.915 1612360478.9851778
train: epoch 12, iter 2200, loss: 3.378274, top_1: 0.454531, top_k: 0.704219, samples/s: 2237.906 1612360490.424578
train: epoch 12, iter 2300, loss: 3.421462, top_1: 0.453398, top_k: 0.704336, samples/s: 2246.858 1612360501.8181705
train: epoch 12, iter 2400, loss: 3.412063, top_1: 0.448398, top_k: 0.699102, samples/s: 2246.757 1612360513.2123601
train: epoch 12, iter 2500, loss: 3.430203, top_1: 0.456445, top_k: 0.700898, samples/s: 2222.235 1612360524.7323725
train: epoch 12, iter 2600, loss: 3.322319, top_1: 0.451289, top_k: 0.702500, samples/s: 2246.981 1612360536.12543
train: epoch 12, iter 2700, loss: 3.296880, top_1: 0.454648, top_k: 0.704805, samples/s: 2243.798 1612360547.5346115
train: epoch 12, iter 2800, loss: 3.272170, top_1: 0.457148, top_k: 0.704336, samples/s: 2227.151 1612360559.0291877
train: epoch 12, iter 2900, loss: 3.373259, top_1: 0.454219, top_k: 0.697656, samples/s: 2250.999 1612360570.4018438
train: epoch 12, iter 3000, loss: 3.371062, top_1: 0.460273, top_k: 0.704258, samples/s: 2228.567 1612360581.8890593
train: epoch 12, iter 3100, loss: 3.393572, top_1: 0.457969, top_k: 0.700898, samples/s: 2245.012 1612360593.292085
train: epoch 12, iter 3200, loss: 3.424595, top_1: 0.453359, top_k: 0.699570, samples/s: 2233.716 1612360604.7528152
train: epoch 12, iter 3300, loss: 3.248343, top_1: 0.456875, top_k: 0.707500, samples/s: 2233.941 1612360616.2124484
train: epoch 12, iter 3400, loss: 3.313651, top_1: 0.455039, top_k: 0.698594, samples/s: 2243.356 1612360627.6238523
train: epoch 12, iter 3500, loss: 3.172247, top_1: 0.453398, top_k: 0.698359, samples/s: 2229.631 1612360639.1056397
train: epoch 12, iter 3600, loss: 3.227692, top_1: 0.458086, top_k: 0.703164, samples/s: 2240.263 1612360650.5328772
train: epoch 12, iter 3700, loss: 3.241011, top_1: 0.456836, top_k: 0.701367, samples/s: 2244.292 1612360661.9396167
train: epoch 12, iter 3800, loss: 3.319140, top_1: 0.453711, top_k: 0.698906, samples/s: 2163.223 1612360673.7737677
train: epoch 12, iter 3900, loss: 3.315030, top_1: 0.458203, top_k: 0.697422, samples/s: 2251.237 1612360685.1452467
train: epoch 12, iter 4000, loss: 3.186572, top_1: 0.458086, top_k: 0.702109, samples/s: 2231.896 1612360696.6152678
train: epoch 12, iter 4100, loss: 3.445204, top_1: 0.455703, top_k: 0.702422, samples/s: 2251.857 1612360707.9837053
train: epoch 12, iter 4200, loss: 3.328419, top_1: 0.454102, top_k: 0.701016, samples/s: 2245.089 1612360719.3863556
train: epoch 12, iter 4300, loss: 3.230259, top_1: 0.458477, top_k: 0.707383, samples/s: 2216.017 1612360730.9386091
train: epoch 12, iter 4400, loss: 3.209253, top_1: 0.460625, top_k: 0.703203, samples/s: 2258.807 1612360742.2720838
train: epoch 12, iter 4500, loss: 3.178839, top_1: 0.460156, top_k: 0.706133, samples/s: 2223.332 1612360753.7864754
train: epoch 12, iter 4600, loss: 3.133701, top_1: 0.458984, top_k: 0.703828, samples/s: 2247.371 1612360765.1773553
train: epoch 12, iter 4700, loss: 3.382688, top_1: 0.454180, top_k: 0.702344, samples/s: 2233.592 1612360776.6387665
train: epoch 12, iter 4800, loss: 3.388121, top_1: 0.453359, top_k: 0.700625, samples/s: 2246.648 1612360788.0334623
train: epoch 12, iter 4900, loss: 3.166025, top_1: 0.458047, top_k: 0.707383, samples/s: 2253.908 1612360799.3916183
train: epoch 12, iter 5000, loss: 3.276364, top_1: 0.455508, top_k: 0.701523, samples/s: 2238.795 1612360810.826347
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_12.
validation: epoch 12, iter 195, top_1: 0.486859, top_k: 0.745473, samples/s: 2833.995 1612360828.77022
train: epoch 13, iter 100, loss: 3.104039, top_1: 0.466016, top_k: 0.711953, samples/s: 2243.888 1612360857.3093586
train: epoch 13, iter 200, loss: 3.238524, top_1: 0.463359, top_k: 0.709336, samples/s: 2258.725 1612360868.6430953
train: epoch 13, iter 300, loss: 3.168247, top_1: 0.460781, top_k: 0.706836, samples/s: 2258.669 1612360879.977246
train: epoch 13, iter 400, loss: 3.401629, top_1: 0.456328, top_k: 0.704453, samples/s: 2259.141 1612360891.3090277
train: epoch 13, iter 500, loss: 3.231652, top_1: 0.461875, top_k: 0.708750, samples/s: 2253.951 1612360902.666768
train: epoch 13, iter 600, loss: 3.217049, top_1: 0.461367, top_k: 0.711641, samples/s: 2263.140 1612360913.9785213
train: epoch 13, iter 700, loss: 3.189448, top_1: 0.462422, top_k: 0.706094, samples/s: 2258.352 1612360925.3141959
train: epoch 13, iter 800, loss: 3.391897, top_1: 0.465039, top_k: 0.712383, samples/s: 2255.462 1612360936.6644301
train: epoch 13, iter 900, loss: 3.400575, top_1: 0.456680, top_k: 0.708438, samples/s: 2242.925 1612360948.0782118
train: epoch 13, iter 1000, loss: 3.265445, top_1: 0.461875, top_k: 0.708398, samples/s: 2218.557 1612360959.6171243
train: epoch 13, iter 1100, loss: 3.180327, top_1: 0.457852, top_k: 0.704141, samples/s: 2220.107 1612360971.1482396
train: epoch 13, iter 1200, loss: 3.108117, top_1: 0.460234, top_k: 0.707656, samples/s: 2224.905 1612360982.6543157
train: epoch 13, iter 1300, loss: 3.217871, top_1: 0.466133, top_k: 0.710625, samples/s: 2224.500 1612360994.1624951
train: epoch 13, iter 1400, loss: 3.102931, top_1: 0.459023, top_k: 0.704727, samples/s: 2245.683 1612361005.5621278
train: epoch 13, iter 1500, loss: 3.302530, top_1: 0.453672, top_k: 0.705508, samples/s: 2235.100 1612361017.015817
train: epoch 13, iter 1600, loss: 3.153686, top_1: 0.462500, top_k: 0.707500, samples/s: 2238.347 1612361028.452692
train: epoch 13, iter 1700, loss: 3.069837, top_1: 0.466914, top_k: 0.708438, samples/s: 2234.789 1612361039.9079285
train: epoch 13, iter 1800, loss: 3.159662, top_1: 0.458945, top_k: 0.707148, samples/s: 2230.603 1612361051.3846571
train: epoch 13, iter 1900, loss: 3.258011, top_1: 0.459023, top_k: 0.700820, samples/s: 2260.133 1612361062.711388
train: epoch 13, iter 2000, loss: 3.360115, top_1: 0.456055, top_k: 0.702695, samples/s: 2236.327 1612361074.1588588
train: epoch 13, iter 2100, loss: 3.015014, top_1: 0.462070, top_k: 0.705508, samples/s: 2229.263 1612361085.6423538
train: epoch 13, iter 2200, loss: 3.261770, top_1: 0.462773, top_k: 0.711250, samples/s: 2237.760 1612361097.0824232
train: epoch 13, iter 2300, loss: 3.236440, top_1: 0.461484, top_k: 0.705391, samples/s: 2230.235 1612361108.5609696
train: epoch 13, iter 2400, loss: 3.268488, top_1: 0.462695, top_k: 0.710547, samples/s: 2239.453 1612361119.9923935
train: epoch 13, iter 2500, loss: 3.338953, top_1: 0.465977, top_k: 0.707578, samples/s: 2236.315 1612361131.4398353
train: epoch 13, iter 2600, loss: 3.175971, top_1: 0.460469, top_k: 0.706367, samples/s: 2243.208 1612361142.8520212
train: epoch 13, iter 2700, loss: 3.289217, top_1: 0.466914, top_k: 0.713516, samples/s: 2243.196 1612361154.2643094
train: epoch 13, iter 2800, loss: 3.297348, top_1: 0.463086, top_k: 0.713047, samples/s: 2228.104 1612361165.7538462
train: epoch 13, iter 2900, loss: 3.201385, top_1: 0.462500, top_k: 0.709531, samples/s: 2250.562 1612361177.1287913
train: epoch 13, iter 3000, loss: 3.273630, top_1: 0.455469, top_k: 0.699766, samples/s: 2238.066 1612361188.5673144
train: epoch 13, iter 3100, loss: 3.099990, top_1: 0.465000, top_k: 0.711523, samples/s: 2234.948 1612361200.0217366
train: epoch 13, iter 3200, loss: 3.237250, top_1: 0.458516, top_k: 0.700625, samples/s: 2245.321 1612361211.4231853
train: epoch 13, iter 3300, loss: 3.330692, top_1: 0.459688, top_k: 0.703086, samples/s: 2235.069 1612361222.8771212
train: epoch 13, iter 3400, loss: 3.284434, top_1: 0.459805, top_k: 0.707187, samples/s: 2264.735 1612361234.1806946
train: epoch 13, iter 3500, loss: 3.400762, top_1: 0.458672, top_k: 0.706641, samples/s: 2248.094 1612361245.5680683
train: epoch 13, iter 3600, loss: 3.055287, top_1: 0.461602, top_k: 0.705469, samples/s: 2250.148 1612361256.9451203
train: epoch 13, iter 3700, loss: 3.247512, top_1: 0.462734, top_k: 0.702187, samples/s: 2223.527 1612361268.458344
train: epoch 13, iter 3800, loss: 3.486608, top_1: 0.458008, top_k: 0.702148, samples/s: 2249.617 1612361279.838116
train: epoch 13, iter 3900, loss: 3.214830, top_1: 0.458828, top_k: 0.702656, samples/s: 2240.879 1612361291.2622757
train: epoch 13, iter 4000, loss: 3.335383, top_1: 0.464961, top_k: 0.707695, samples/s: 2231.286 1612361302.7353947
train: epoch 13, iter 4100, loss: 3.329572, top_1: 0.461875, top_k: 0.703594, samples/s: 2238.275 1612361314.1727455
train: epoch 13, iter 4200, loss: 3.133415, top_1: 0.460195, top_k: 0.704648, samples/s: 2251.482 1612361325.5430818
train: epoch 13, iter 4300, loss: 3.178629, top_1: 0.466328, top_k: 0.712422, samples/s: 2252.802 1612361336.9066656
train: epoch 13, iter 4400, loss: 3.293875, top_1: 0.460977, top_k: 0.707891, samples/s: 2236.200 1612361348.3546934
train: epoch 13, iter 4500, loss: 3.310243, top_1: 0.461445, top_k: 0.706758, samples/s: 2213.463 1612361359.920341
train: epoch 13, iter 4600, loss: 3.224681, top_1: 0.456719, top_k: 0.700000, samples/s: 2262.611 1612361371.234659
train: epoch 13, iter 4700, loss: 3.249969, top_1: 0.454492, top_k: 0.700586, samples/s: 2250.407 1612361382.6103835
train: epoch 13, iter 4800, loss: 3.312450, top_1: 0.460586, top_k: 0.708711, samples/s: 2235.421 1612361394.0623384
train: epoch 13, iter 4900, loss: 3.094870, top_1: 0.460547, top_k: 0.704609, samples/s: 2218.258 1612361405.602881
train: epoch 13, iter 5000, loss: 3.063911, top_1: 0.462539, top_k: 0.707070, samples/s: 2248.563 1612361416.9879363
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_13.
validation: epoch 13, iter 195, top_1: 0.508974, top_k: 0.764363, samples/s: 2923.966 1612361434.4243038
train: epoch 14, iter 100, loss: 3.279533, top_1: 0.471758, top_k: 0.715742, samples/s: 2229.231 1612361467.2871313
train: epoch 14, iter 200, loss: 3.172736, top_1: 0.465938, top_k: 0.709375, samples/s: 2255.822 1612361478.6353953
train: epoch 14, iter 300, loss: 3.273152, top_1: 0.463633, top_k: 0.709570, samples/s: 2259.584 1612361489.964803
train: epoch 14, iter 400, loss: 2.943174, top_1: 0.472187, top_k: 0.710977, samples/s: 2258.937 1612361501.2975793
train: epoch 14, iter 500, loss: 3.154799, top_1: 0.474258, top_k: 0.715508, samples/s: 2249.773 1612361512.6764872
train: epoch 14, iter 600, loss: 3.194711, top_1: 0.467539, top_k: 0.709961, samples/s: 2273.669 1612361523.9358246
train: epoch 14, iter 700, loss: 3.382656, top_1: 0.467539, top_k: 0.711836, samples/s: 2253.666 1612361535.2951994
train: epoch 14, iter 800, loss: 3.136724, top_1: 0.472773, top_k: 0.714023, samples/s: 2247.288 1612361546.6866488
train: epoch 14, iter 900, loss: 3.226798, top_1: 0.470039, top_k: 0.712734, samples/s: 2262.034 1612361558.0038214
train: epoch 14, iter 1000, loss: 3.432917, top_1: 0.462383, top_k: 0.713789, samples/s: 2247.955 1612361569.3919616
train: epoch 14, iter 1100, loss: 3.479945, top_1: 0.467734, top_k: 0.711445, samples/s: 2227.001 1612361580.8872495
train: epoch 14, iter 1200, loss: 3.086946, top_1: 0.468789, top_k: 0.715703, samples/s: 2232.189 1612361592.3560557
train: epoch 14, iter 1300, loss: 3.196590, top_1: 0.470195, top_k: 0.713789, samples/s: 2223.434 1612361603.8695962
train: epoch 14, iter 1400, loss: 3.406515, top_1: 0.459922, top_k: 0.710625, samples/s: 2221.576 1612361615.3929722
train: epoch 14, iter 1500, loss: 3.177052, top_1: 0.462930, top_k: 0.709102, samples/s: 2241.857 1612361626.8121033
train: epoch 14, iter 1600, loss: 3.131436, top_1: 0.466367, top_k: 0.712930, samples/s: 2234.115 1612361638.270716
train: epoch 14, iter 1700, loss: 3.161417, top_1: 0.464883, top_k: 0.707461, samples/s: 2247.384 1612361649.6618567
train: epoch 14, iter 1800, loss: 3.152906, top_1: 0.465859, top_k: 0.707891, samples/s: 2242.610 1612361661.077065
train: epoch 14, iter 1900, loss: 3.311690, top_1: 0.465313, top_k: 0.712031, samples/s: 2223.905 1612361672.5883622
train: epoch 14, iter 2000, loss: 3.253424, top_1: 0.467148, top_k: 0.710313, samples/s: 2229.789 1612361684.0691366
train: epoch 14, iter 2100, loss: 3.224597, top_1: 0.465273, top_k: 0.712930, samples/s: 2241.887 1612361695.4881473
train: epoch 14, iter 2200, loss: 3.276282, top_1: 0.465820, top_k: 0.709844, samples/s: 2242.846 1612361706.9021711
train: epoch 14, iter 2300, loss: 3.334191, top_1: 0.458750, top_k: 0.709531, samples/s: 2251.747 1612361718.271115
train: epoch 14, iter 2400, loss: 3.169065, top_1: 0.467187, top_k: 0.710977, samples/s: 2234.697 1612361729.7268374
train: epoch 14, iter 2500, loss: 3.499884, top_1: 0.467773, top_k: 0.714258, samples/s: 2207.510 1612361741.3236022
train: epoch 14, iter 2600, loss: 3.215694, top_1: 0.463594, top_k: 0.711016, samples/s: 2259.988 1612361752.651151
train: epoch 14, iter 2700, loss: 3.113476, top_1: 0.468047, top_k: 0.709297, samples/s: 2230.008 1612361764.1309197
train: epoch 14, iter 2800, loss: 3.219388, top_1: 0.466328, top_k: 0.708984, samples/s: 2240.750 1612361775.5556061
train: epoch 14, iter 2900, loss: 3.119301, top_1: 0.465703, top_k: 0.707812, samples/s: 2246.452 1612361786.9513798
train: epoch 14, iter 3000, loss: 3.447924, top_1: 0.454375, top_k: 0.701875, samples/s: 2248.162 1612361798.3389733
train: epoch 14, iter 3100, loss: 3.229336, top_1: 0.469219, top_k: 0.711875, samples/s: 2252.438 1612361809.7039974
train: epoch 14, iter 3200, loss: 3.206829, top_1: 0.465625, top_k: 0.711016, samples/s: 2251.465 1612361821.0753028
train: epoch 14, iter 3300, loss: 3.374144, top_1: 0.458750, top_k: 0.705625, samples/s: 2228.421 1612361832.5622847
train: epoch 14, iter 3400, loss: 3.209676, top_1: 0.469844, top_k: 0.708828, samples/s: 2243.743 1612361843.9717374
train: epoch 14, iter 3500, loss: 3.373271, top_1: 0.470859, top_k: 0.712656, samples/s: 2250.505 1612361855.3469555
train: epoch 14, iter 3600, loss: 3.181561, top_1: 0.466484, top_k: 0.707656, samples/s: 2239.972 1612361866.7756712
train: epoch 14, iter 3700, loss: 3.216827, top_1: 0.464414, top_k: 0.709258, samples/s: 2231.862 1612361878.245929
train: epoch 14, iter 3800, loss: 3.073328, top_1: 0.464492, top_k: 0.709570, samples/s: 2242.813 1612361889.660161
train: epoch 14, iter 3900, loss: 3.197752, top_1: 0.461055, top_k: 0.704492, samples/s: 2235.259 1612361901.1130078
train: epoch 14, iter 4000, loss: 3.205546, top_1: 0.464531, top_k: 0.708750, samples/s: 2255.025 1612361912.4654593
train: epoch 14, iter 4100, loss: 3.288286, top_1: 0.461133, top_k: 0.711211, samples/s: 2246.551 1612361923.8606837
train: epoch 14, iter 4200, loss: 3.229410, top_1: 0.464492, top_k: 0.708320, samples/s: 2250.979 1612361935.2334623
train: epoch 14, iter 4300, loss: 3.241964, top_1: 0.464023, top_k: 0.711406, samples/s: 2239.869 1612361946.6627626
train: epoch 14, iter 4400, loss: 3.196479, top_1: 0.458594, top_k: 0.709453, samples/s: 2244.783 1612361958.0669239
train: epoch 14, iter 4500, loss: 3.320856, top_1: 0.472695, top_k: 0.713945, samples/s: 2234.295 1612361969.5247107
train: epoch 14, iter 4600, loss: 3.326062, top_1: 0.470000, top_k: 0.709180, samples/s: 2244.203 1612361980.931951
train: epoch 14, iter 4700, loss: 3.176512, top_1: 0.465898, top_k: 0.705977, samples/s: 2232.696 1612361992.3978405
train: epoch 14, iter 4800, loss: 3.103666, top_1: 0.465898, top_k: 0.711758, samples/s: 2270.800 1612362003.671396
train: epoch 14, iter 4900, loss: 3.249126, top_1: 0.468438, top_k: 0.711367, samples/s: 2230.485 1612362015.1486936
train: epoch 14, iter 5000, loss: 3.200502, top_1: 0.466719, top_k: 0.712852, samples/s: 2220.516 1612362026.6776567
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_14.
validation: epoch 14, iter 195, top_1: 0.489864, top_k: 0.750681, samples/s: 2923.937 1612362044.0280893
train: epoch 15, iter 100, loss: 3.334711, top_1: 0.470938, top_k: 0.715703, samples/s: 2218.663 1612362072.2260659
train: epoch 15, iter 200, loss: 3.143717, top_1: 0.468086, top_k: 0.710703, samples/s: 2269.932 1612362083.5039644
train: epoch 15, iter 300, loss: 3.259050, top_1: 0.471250, top_k: 0.717031, samples/s: 2259.111 1612362094.8357923
train: epoch 15, iter 400, loss: 3.235864, top_1: 0.471797, top_k: 0.714766, samples/s: 2241.698 1612362106.255713
train: epoch 15, iter 500, loss: 3.367847, top_1: 0.476758, top_k: 0.716719, samples/s: 2271.928 1612362117.5236726
train: epoch 15, iter 600, loss: 3.188532, top_1: 0.472539, top_k: 0.718672, samples/s: 2262.859 1612362128.8368807
train: epoch 15, iter 700, loss: 3.102537, top_1: 0.471953, top_k: 0.717969, samples/s: 2253.135 1612362140.1987426
train: epoch 15, iter 800, loss: 3.194592, top_1: 0.468945, top_k: 0.710234, samples/s: 2252.296 1612362151.5649264
train: epoch 15, iter 900, loss: 3.135511, top_1: 0.473828, top_k: 0.719453, samples/s: 2248.054 1612362162.952542
train: epoch 15, iter 1000, loss: 3.251480, top_1: 0.474375, top_k: 0.720156, samples/s: 2249.432 1612362174.3333514
train: epoch 15, iter 1100, loss: 3.456083, top_1: 0.476016, top_k: 0.716445, samples/s: 2217.844 1612362185.8759966
train: epoch 15, iter 1200, loss: 3.434357, top_1: 0.469102, top_k: 0.713984, samples/s: 2222.896 1612362197.3924985
train: epoch 15, iter 1300, loss: 3.287116, top_1: 0.471094, top_k: 0.714883, samples/s: 2242.180 1612362208.8099518
train: epoch 15, iter 1400, loss: 3.014336, top_1: 0.472539, top_k: 0.714922, samples/s: 2235.003 1612362220.2640815
train: epoch 15, iter 1500, loss: 3.383170, top_1: 0.471953, top_k: 0.715938, samples/s: 2262.857 1612362231.5772283
train: epoch 15, iter 1600, loss: 3.346163, top_1: 0.474453, top_k: 0.715625, samples/s: 2249.974 1612362242.955068
train: epoch 15, iter 1700, loss: 3.063194, top_1: 0.469687, top_k: 0.715313, samples/s: 2238.172 1612362254.393014
train: epoch 15, iter 1800, loss: 3.237268, top_1: 0.468438, top_k: 0.714648, samples/s: 2242.245 1612362265.8101234
train: epoch 15, iter 1900, loss: 3.220498, top_1: 0.471641, top_k: 0.710820, samples/s: 2243.093 1612362277.2229788
train: epoch 15, iter 2000, loss: 3.371576, top_1: 0.467891, top_k: 0.712227, samples/s: 2222.698 1612362288.7405105
train: epoch 15, iter 2100, loss: 3.263891, top_1: 0.476016, top_k: 0.715273, samples/s: 2215.274 1612362300.2966597
train: epoch 15, iter 2200, loss: 3.267165, top_1: 0.471602, top_k: 0.715195, samples/s: 2235.332 1612362311.7490745
train: epoch 15, iter 2300, loss: 3.267637, top_1: 0.466367, top_k: 0.710664, samples/s: 2234.641 1612362323.205035
train: epoch 15, iter 2400, loss: 3.195403, top_1: 0.465508, top_k: 0.711289, samples/s: 2256.476 1612362334.5502586
train: epoch 15, iter 2500, loss: 3.316485, top_1: 0.469883, top_k: 0.713672, samples/s: 2223.565 1612362346.0631757
train: epoch 15, iter 2600, loss: 3.284062, top_1: 0.468711, top_k: 0.716875, samples/s: 2241.736 1612362357.4828954
train: epoch 15, iter 2700, loss: 3.235546, top_1: 0.466992, top_k: 0.715977, samples/s: 2247.359 1612362368.874089
train: epoch 15, iter 2800, loss: 3.211881, top_1: 0.471328, top_k: 0.713125, samples/s: 2243.307 1612362380.2857997
train: epoch 15, iter 2900, loss: 3.217222, top_1: 0.467734, top_k: 0.712891, samples/s: 2228.884 1612362391.7713382
train: epoch 15, iter 3000, loss: 3.298140, top_1: 0.467148, top_k: 0.717148, samples/s: 2233.159 1612362403.2349937
train: epoch 15, iter 3100, loss: 3.038934, top_1: 0.472383, top_k: 0.714258, samples/s: 2234.383 1612362414.692325
train: epoch 15, iter 3200, loss: 3.109482, top_1: 0.469297, top_k: 0.716211, samples/s: 2231.835 1612362426.1626046
train: epoch 15, iter 3300, loss: 3.173819, top_1: 0.472891, top_k: 0.714922, samples/s: 2235.011 1612362437.6167383
train: epoch 15, iter 3400, loss: 3.189313, top_1: 0.470078, top_k: 0.714219, samples/s: 2254.446 1612362448.9720237
train: epoch 15, iter 3500, loss: 3.344553, top_1: 0.465391, top_k: 0.708047, samples/s: 2243.185 1612362460.3843844
train: epoch 15, iter 3600, loss: 3.383770, top_1: 0.465742, top_k: 0.713750, samples/s: 2245.982 1612362471.7825828
train: epoch 15, iter 3700, loss: 3.316500, top_1: 0.466211, top_k: 0.706719, samples/s: 2250.975 1612362483.1553836
train: epoch 15, iter 3800, loss: 3.292101, top_1: 0.457969, top_k: 0.706797, samples/s: 2252.237 1612362494.521836
train: epoch 15, iter 3900, loss: 3.248171, top_1: 0.471172, top_k: 0.716484, samples/s: 2236.973 1612362505.965926
train: epoch 15, iter 4000, loss: 3.188556, top_1: 0.460859, top_k: 0.709453, samples/s: 2229.394 1612362517.448842
train: epoch 15, iter 4100, loss: 3.191637, top_1: 0.463398, top_k: 0.712734, samples/s: 2244.438 1612362528.8547697
train: epoch 15, iter 4200, loss: 3.305446, top_1: 0.469961, top_k: 0.715352, samples/s: 2239.592 1612362540.2854676
train: epoch 15, iter 4300, loss: 2.951506, top_1: 0.467305, top_k: 0.714766, samples/s: 2246.050 1612362551.68323
train: epoch 15, iter 4400, loss: 3.027627, top_1: 0.463867, top_k: 0.707812, samples/s: 2245.816 1612362563.082202
train: epoch 15, iter 4500, loss: 3.115878, top_1: 0.470977, top_k: 0.715195, samples/s: 2244.317 1612362574.4888332
train: epoch 15, iter 4600, loss: 3.116016, top_1: 0.462109, top_k: 0.709648, samples/s: 2238.087 1612362585.9271996
train: epoch 15, iter 4700, loss: 2.958124, top_1: 0.468438, top_k: 0.715586, samples/s: 2215.695 1612362597.481076
train: epoch 15, iter 4800, loss: 3.234621, top_1: 0.467187, top_k: 0.713242, samples/s: 2251.638 1612362608.850592
train: epoch 15, iter 4900, loss: 3.484507, top_1: 0.463398, top_k: 0.712227, samples/s: 2229.163 1612362620.3347194
train: epoch 15, iter 5000, loss: 3.350259, top_1: 0.467969, top_k: 0.712305, samples/s: 2244.810 1612362631.7388644
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_15.
validation: epoch 15, iter 195, top_1: 0.506210, top_k: 0.758594, samples/s: 2832.597 1612362649.6149144
train: epoch 16, iter 100, loss: 3.174008, top_1: 0.487344, top_k: 0.730117, samples/s: 2222.526 1612362676.8780875
train: epoch 16, iter 200, loss: 3.159405, top_1: 0.483828, top_k: 0.724141, samples/s: 2262.023 1612362688.1953855
train: epoch 16, iter 300, loss: 3.110018, top_1: 0.480938, top_k: 0.720234, samples/s: 2260.643 1612362699.5195508
train: epoch 16, iter 400, loss: 3.224056, top_1: 0.476289, top_k: 0.719375, samples/s: 2228.466 1612362711.0072737
train: epoch 16, iter 500, loss: 2.972253, top_1: 0.468477, top_k: 0.717891, samples/s: 2247.577 1612362722.3974977
train: epoch 16, iter 600, loss: 3.281240, top_1: 0.469258, top_k: 0.722383, samples/s: 2267.426 1612362733.687664
train: epoch 16, iter 700, loss: 3.170602, top_1: 0.474492, top_k: 0.713516, samples/s: 2249.050 1612362745.0702362
train: epoch 16, iter 800, loss: 3.150290, top_1: 0.471172, top_k: 0.716094, samples/s: 2248.060 1612362756.4578223
train: epoch 16, iter 900, loss: 3.077208, top_1: 0.481211, top_k: 0.722852, samples/s: 2239.401 1612362767.889609
train: epoch 16, iter 1000, loss: 3.043818, top_1: 0.473594, top_k: 0.718789, samples/s: 2245.256 1612362779.291268
train: epoch 16, iter 1100, loss: 3.269633, top_1: 0.478711, top_k: 0.723672, samples/s: 2229.035 1612362790.7760615
train: epoch 16, iter 1200, loss: 3.343867, top_1: 0.481758, top_k: 0.722812, samples/s: 2224.378 1612362802.2849522
train: epoch 16, iter 1300, loss: 3.156231, top_1: 0.472617, top_k: 0.715313, samples/s: 2231.219 1612362813.758525
train: epoch 16, iter 1400, loss: 3.306799, top_1: 0.471016, top_k: 0.716602, samples/s: 2217.150 1612362825.3048139
train: epoch 16, iter 1500, loss: 3.151694, top_1: 0.472383, top_k: 0.716367, samples/s: 2230.138 1612362836.7839308
train: epoch 16, iter 1600, loss: 3.276245, top_1: 0.473594, top_k: 0.720703, samples/s: 2224.706 1612362848.2911177
train: epoch 16, iter 1700, loss: 3.272137, top_1: 0.467500, top_k: 0.716602, samples/s: 2218.486 1612362859.8305838
train: epoch 16, iter 1800, loss: 3.274500, top_1: 0.465508, top_k: 0.710859, samples/s: 2206.830 1612362871.430805
train: epoch 16, iter 1900, loss: 3.219440, top_1: 0.470977, top_k: 0.715273, samples/s: 2222.873 1612362882.9474356
train: epoch 16, iter 2000, loss: 3.250645, top_1: 0.472070, top_k: 0.716133, samples/s: 2231.694 1612362894.4185853
train: epoch 16, iter 2100, loss: 3.266821, top_1: 0.468047, top_k: 0.718242, samples/s: 2216.245 1612362905.9696484
train: epoch 16, iter 2200, loss: 3.207355, top_1: 0.477383, top_k: 0.715000, samples/s: 2233.066 1612362917.4337003
train: epoch 16, iter 2300, loss: 3.291447, top_1: 0.472539, top_k: 0.716367, samples/s: 2207.887 1612362929.0284746
train: epoch 16, iter 2400, loss: 3.210864, top_1: 0.472383, top_k: 0.718203, samples/s: 2216.314 1612362940.579217
train: epoch 16, iter 2500, loss: 3.056112, top_1: 0.474336, top_k: 0.719492, samples/s: 2225.045 1612362952.0846043
train: epoch 16, iter 2600, loss: 3.171955, top_1: 0.473320, top_k: 0.718672, samples/s: 2224.881 1612362963.5908
train: epoch 16, iter 2700, loss: 3.091512, top_1: 0.476992, top_k: 0.714258, samples/s: 2224.418 1612362975.0995026
train: epoch 16, iter 2800, loss: 3.304303, top_1: 0.469180, top_k: 0.713047, samples/s: 2237.100 1612362986.5429223
train: epoch 16, iter 2900, loss: 3.195368, top_1: 0.471289, top_k: 0.715313, samples/s: 2229.780 1612362998.0237658
train: epoch 16, iter 3000, loss: 3.286174, top_1: 0.477891, top_k: 0.719297, samples/s: 2217.958 1612363009.56592
train: epoch 16, iter 3100, loss: 3.268936, top_1: 0.476914, top_k: 0.716211, samples/s: 2225.748 1612363021.0676997
train: epoch 16, iter 3200, loss: 3.106609, top_1: 0.477812, top_k: 0.715898, samples/s: 2235.614 1612363032.5186727
train: epoch 16, iter 3300, loss: 3.290310, top_1: 0.473242, top_k: 0.715625, samples/s: 2233.900 1612363043.9784417
train: epoch 16, iter 3400, loss: 3.436201, top_1: 0.469570, top_k: 0.716641, samples/s: 2187.564 1612363055.6810343
train: epoch 16, iter 3500, loss: 3.103257, top_1: 0.477891, top_k: 0.721133, samples/s: 2208.674 1612363067.2716246
train: epoch 16, iter 3600, loss: 3.409190, top_1: 0.466953, top_k: 0.711055, samples/s: 2218.628 1612363078.8102896
train: epoch 16, iter 3700, loss: 3.154845, top_1: 0.469453, top_k: 0.710195, samples/s: 2206.028 1612363090.4149902
train: epoch 16, iter 3800, loss: 3.241050, top_1: 0.471836, top_k: 0.718750, samples/s: 2233.749 1612363101.8754454
train: epoch 16, iter 3900, loss: 3.221429, top_1: 0.468438, top_k: 0.715391, samples/s: 2214.639 1612363113.4349651
train: epoch 16, iter 4000, loss: 2.946883, top_1: 0.470508, top_k: 0.719102, samples/s: 2232.240 1612363124.903269
train: epoch 16, iter 4100, loss: 2.998880, top_1: 0.470508, top_k: 0.715781, samples/s: 2234.118 1612363136.3618348
train: epoch 16, iter 4200, loss: 3.310008, top_1: 0.472578, top_k: 0.717031, samples/s: 2221.195 1612363147.887209
train: epoch 16, iter 4300, loss: 3.113882, top_1: 0.466836, top_k: 0.714375, samples/s: 2205.292 1612363159.4955983
train: epoch 16, iter 4400, loss: 3.268243, top_1: 0.470586, top_k: 0.711133, samples/s: 2234.215 1612363170.9538171
train: epoch 16, iter 4500, loss: 3.353981, top_1: 0.471211, top_k: 0.716445, samples/s: 2217.302 1612363182.4993246
train: epoch 16, iter 4600, loss: 3.096217, top_1: 0.470234, top_k: 0.713984, samples/s: 2217.639 1612363194.0431643
train: epoch 16, iter 4700, loss: 3.300333, top_1: 0.474570, top_k: 0.717617, samples/s: 2220.507 1612363205.572011
train: epoch 16, iter 4800, loss: 3.121041, top_1: 0.469766, top_k: 0.720391, samples/s: 2211.462 1612363217.1481755
train: epoch 16, iter 4900, loss: 3.073505, top_1: 0.474453, top_k: 0.718789, samples/s: 2239.246 1612363228.5805175
train: epoch 16, iter 5000, loss: 3.144072, top_1: 0.470625, top_k: 0.720625, samples/s: 2220.680 1612363240.1085784
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_16.
validation: epoch 16, iter 195, top_1: 0.521274, top_k: 0.772356, samples/s: 2807.207 1612363258.2164497
train: epoch 17, iter 100, loss: 3.095481, top_1: 0.481016, top_k: 0.726719, samples/s: 2242.094 1612363286.012521
train: epoch 17, iter 200, loss: 3.174472, top_1: 0.485859, top_k: 0.728711, samples/s: 2255.010 1612363297.3653932
train: epoch 17, iter 300, loss: 3.256304, top_1: 0.473164, top_k: 0.721094, samples/s: 2265.125 1612363308.6668599
train: epoch 17, iter 400, loss: 3.237344, top_1: 0.476445, top_k: 0.721719, samples/s: 2260.991 1612363319.9893048
train: epoch 17, iter 500, loss: 3.143893, top_1: 0.481445, top_k: 0.721641, samples/s: 2247.668 1612363331.3789191
train: epoch 17, iter 600, loss: 3.001519, top_1: 0.478320, top_k: 0.719648, samples/s: 2247.270 1612363342.7704558
train: epoch 17, iter 700, loss: 3.255756, top_1: 0.474922, top_k: 0.716875, samples/s: 2248.479 1612363354.1559837
train: epoch 17, iter 800, loss: 3.376162, top_1: 0.477227, top_k: 0.722109, samples/s: 2235.293 1612363365.6087053
train: epoch 17, iter 900, loss: 3.321031, top_1: 0.478008, top_k: 0.723906, samples/s: 2240.135 1612363377.0364523
train: epoch 17, iter 1000, loss: 3.073406, top_1: 0.478477, top_k: 0.722227, samples/s: 2244.111 1612363388.4441013
train: epoch 17, iter 1100, loss: 3.180461, top_1: 0.476641, top_k: 0.716641, samples/s: 2203.665 1612363400.0611007
train: epoch 17, iter 1200, loss: 3.218200, top_1: 0.472461, top_k: 0.721484, samples/s: 2217.132 1612363411.6075697
train: epoch 17, iter 1300, loss: 3.282250, top_1: 0.476719, top_k: 0.722930, samples/s: 2229.008 1612363423.0924852
train: epoch 17, iter 1400, loss: 3.231879, top_1: 0.474961, top_k: 0.721680, samples/s: 2227.226 1612363434.5866334
train: epoch 17, iter 1500, loss: 3.183621, top_1: 0.469062, top_k: 0.714727, samples/s: 2221.853 1612363446.1085114
train: epoch 17, iter 1600, loss: 3.349429, top_1: 0.473984, top_k: 0.720156, samples/s: 2230.271 1612363457.5869365
train: epoch 17, iter 1700, loss: 3.217503, top_1: 0.472539, top_k: 0.717500, samples/s: 2222.787 1612363469.1041367
train: epoch 17, iter 1800, loss: 3.119745, top_1: 0.478008, top_k: 0.719727, samples/s: 2222.422 1612363480.6229796
train: epoch 17, iter 1900, loss: 3.271137, top_1: 0.474883, top_k: 0.721211, samples/s: 2227.240 1612363492.117038
train: epoch 17, iter 2000, loss: 3.462561, top_1: 0.477500, top_k: 0.721484, samples/s: 2224.442 1612363503.6255538
train: epoch 17, iter 2100, loss: 3.407802, top_1: 0.475742, top_k: 0.719844, samples/s: 2215.020 1612363515.1829906
train: epoch 17, iter 2200, loss: 3.222049, top_1: 0.480586, top_k: 0.720547, samples/s: 2201.420 1612363526.8118973
train: epoch 17, iter 2300, loss: 3.316668, top_1: 0.479766, top_k: 0.722695, samples/s: 2229.604 1612363538.2937183
train: epoch 17, iter 2400, loss: 3.276579, top_1: 0.478906, top_k: 0.720078, samples/s: 2212.845 1612363549.8625185
train: epoch 17, iter 2500, loss: 3.075709, top_1: 0.473281, top_k: 0.720352, samples/s: 2226.376 1612363561.3610656
train: epoch 17, iter 2600, loss: 3.253411, top_1: 0.477539, top_k: 0.720664, samples/s: 2229.541 1612363572.8432078
train: epoch 17, iter 2700, loss: 3.176627, top_1: 0.469375, top_k: 0.715117, samples/s: 2210.866 1612363584.4223778
train: epoch 17, iter 2800, loss: 3.264812, top_1: 0.476133, top_k: 0.720859, samples/s: 2213.573 1612363595.9874456
train: epoch 17, iter 2900, loss: 3.020681, top_1: 0.474687, top_k: 0.716758, samples/s: 2221.838 1612363607.5093796
train: epoch 17, iter 3000, loss: 3.248381, top_1: 0.479648, top_k: 0.720938, samples/s: 2222.929 1612363619.025715
train: epoch 17, iter 3100, loss: 3.397651, top_1: 0.471992, top_k: 0.716172, samples/s: 2220.824 1612363630.553013
train: epoch 17, iter 3200, loss: 3.219453, top_1: 0.473828, top_k: 0.717656, samples/s: 2220.985 1612363642.0794177
train: epoch 17, iter 3300, loss: 3.056047, top_1: 0.471914, top_k: 0.717930, samples/s: 2238.356 1612363653.5164793
train: epoch 17, iter 3400, loss: 3.227473, top_1: 0.480195, top_k: 0.723789, samples/s: 2225.597 1612363665.0189548
train: epoch 17, iter 3500, loss: 2.952152, top_1: 0.474023, top_k: 0.719688, samples/s: 2207.804 1612363676.6141293
train: epoch 17, iter 3600, loss: 3.295621, top_1: 0.469609, top_k: 0.718633, samples/s: 2216.882 1612363688.1619754
train: epoch 17, iter 3700, loss: 3.049341, top_1: 0.480859, top_k: 0.719844, samples/s: 2227.173 1612363699.6563447
train: epoch 17, iter 3800, loss: 3.196882, top_1: 0.471445, top_k: 0.715820, samples/s: 2225.606 1612363711.1587431
train: epoch 17, iter 3900, loss: 3.546091, top_1: 0.477539, top_k: 0.721289, samples/s: 2222.643 1612363722.6767056
train: epoch 17, iter 4000, loss: 3.173389, top_1: 0.473672, top_k: 0.717812, samples/s: 2224.153 1612363734.1865659
train: epoch 17, iter 4100, loss: 3.129810, top_1: 0.479180, top_k: 0.721602, samples/s: 2213.838 1612363745.7502317
train: epoch 17, iter 4200, loss: 3.132874, top_1: 0.474805, top_k: 0.717852, samples/s: 2218.414 1612363757.2899797
train: epoch 17, iter 4300, loss: 3.329711, top_1: 0.479727, top_k: 0.720430, samples/s: 2227.861 1612363768.7809494
train: epoch 17, iter 4400, loss: 3.121405, top_1: 0.473945, top_k: 0.717227, samples/s: 2226.834 1612363780.2769833
train: epoch 17, iter 4500, loss: 3.170335, top_1: 0.476328, top_k: 0.719375, samples/s: 2209.046 1612363791.8656702
train: epoch 17, iter 4600, loss: 3.195879, top_1: 0.475234, top_k: 0.718633, samples/s: 2231.856 1612363803.3359609
train: epoch 17, iter 4700, loss: 3.284866, top_1: 0.479570, top_k: 0.718359, samples/s: 2193.800 1612363815.0052986
train: epoch 17, iter 4800, loss: 3.028496, top_1: 0.477266, top_k: 0.722422, samples/s: 2236.899 1612363826.4496026
train: epoch 17, iter 4900, loss: 3.120604, top_1: 0.476094, top_k: 0.719570, samples/s: 2215.349 1612363838.005352
train: epoch 17, iter 5000, loss: 3.063855, top_1: 0.475313, top_k: 0.719883, samples/s: 2226.018 1612363849.5057008
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_17.
validation: epoch 17, iter 195, top_1: 0.504868, top_k: 0.761478, samples/s: 2894.560 1612363867.0682187
train: epoch 18, iter 100, loss: 3.056882, top_1: 0.484648, top_k: 0.726484, samples/s: 2259.509 1612363894.3597002
train: epoch 18, iter 200, loss: 3.300868, top_1: 0.483086, top_k: 0.726484, samples/s: 2247.903 1612363905.7480297
train: epoch 18, iter 300, loss: 3.269075, top_1: 0.480273, top_k: 0.724570, samples/s: 2257.252 1612363917.0893626
train: epoch 18, iter 400, loss: 3.177020, top_1: 0.483008, top_k: 0.723672, samples/s: 2257.715 1612363928.4282694
train: epoch 18, iter 500, loss: 3.321242, top_1: 0.486367, top_k: 0.723203, samples/s: 2252.060 1612363939.7955651
train: epoch 18, iter 600, loss: 3.408514, top_1: 0.482383, top_k: 0.729609, samples/s: 2257.423 1612363951.135934
train: epoch 18, iter 700, loss: 3.063655, top_1: 0.480625, top_k: 0.726523, samples/s: 2242.329 1612363962.5527208
train: epoch 18, iter 800, loss: 3.239136, top_1: 0.479102, top_k: 0.724375, samples/s: 2247.437 1612363973.9433877
train: epoch 18, iter 900, loss: 3.159980, top_1: 0.474492, top_k: 0.716172, samples/s: 2243.881 1612363985.3522172
train: epoch 18, iter 1000, loss: 3.204582, top_1: 0.485820, top_k: 0.728281, samples/s: 2206.249 1612363996.9556043
train: epoch 18, iter 1100, loss: 3.318428, top_1: 0.486836, top_k: 0.727344, samples/s: 2227.736 1612364008.4470885
train: epoch 18, iter 1200, loss: 3.276602, top_1: 0.477969, top_k: 0.721094, samples/s: 2201.930 1612364020.0732756
train: epoch 18, iter 1300, loss: 3.176071, top_1: 0.474609, top_k: 0.721289, samples/s: 2213.821 1612364031.6369686
train: epoch 18, iter 1400, loss: 3.180506, top_1: 0.481367, top_k: 0.723750, samples/s: 2212.822 1612364043.2059245
train: epoch 18, iter 1500, loss: 3.290271, top_1: 0.475547, top_k: 0.721797, samples/s: 2228.067 1612364054.695689
train: epoch 18, iter 1600, loss: 3.209586, top_1: 0.481445, top_k: 0.722734, samples/s: 2205.931 1612364066.3007789
train: epoch 18, iter 1700, loss: 3.319039, top_1: 0.479570, top_k: 0.719102, samples/s: 2231.825 1612364077.7713027
train: epoch 18, iter 1800, loss: 3.240846, top_1: 0.476016, top_k: 0.723672, samples/s: 2213.860 1612364089.334716
train: epoch 18, iter 1900, loss: 3.007714, top_1: 0.477695, top_k: 0.718867, samples/s: 2217.337 1612364100.8801234
train: epoch 18, iter 2000, loss: 3.267048, top_1: 0.479961, top_k: 0.722227, samples/s: 2209.463 1612364112.4666648
train: epoch 18, iter 2100, loss: 3.169724, top_1: 0.479063, top_k: 0.722383, samples/s: 2232.468 1612364123.9337604
train: epoch 18, iter 2200, loss: 3.021843, top_1: 0.475039, top_k: 0.719766, samples/s: 2224.466 1612364135.4421635
train: epoch 18, iter 2300, loss: 3.134272, top_1: 0.476680, top_k: 0.719570, samples/s: 2232.847 1612364146.9073777
train: epoch 18, iter 2400, loss: 3.042788, top_1: 0.474297, top_k: 0.717187, samples/s: 2215.528 1612364158.4621887
train: epoch 18, iter 2500, loss: 3.129475, top_1: 0.479492, top_k: 0.726367, samples/s: 2203.347 1612364170.080869
train: epoch 18, iter 2600, loss: 3.194832, top_1: 0.478672, top_k: 0.717227, samples/s: 2218.542 1612364181.6199753
train: epoch 18, iter 2700, loss: 3.185164, top_1: 0.482266, top_k: 0.720859, samples/s: 2210.921 1612364193.1988008
train: epoch 18, iter 2800, loss: 3.132486, top_1: 0.478125, top_k: 0.723164, samples/s: 2217.193 1612364204.7449708
train: epoch 18, iter 2900, loss: 3.301263, top_1: 0.478477, top_k: 0.719180, samples/s: 2227.355 1612364216.2384374
train: epoch 18, iter 3000, loss: 3.353541, top_1: 0.478711, top_k: 0.718633, samples/s: 2212.602 1612364227.8086548
train: epoch 18, iter 3100, loss: 3.112627, top_1: 0.479375, top_k: 0.721758, samples/s: 2221.912 1612364239.330088
train: epoch 18, iter 3200, loss: 3.083913, top_1: 0.480898, top_k: 0.720313, samples/s: 2207.150 1612364250.9287844
train: epoch 18, iter 3300, loss: 3.196919, top_1: 0.478789, top_k: 0.715820, samples/s: 2219.414 1612364262.4633386
train: epoch 18, iter 3400, loss: 3.195235, top_1: 0.479531, top_k: 0.722578, samples/s: 2222.129 1612364273.9838183
train: epoch 18, iter 3500, loss: 3.245338, top_1: 0.475078, top_k: 0.715781, samples/s: 2230.852 1612364285.4592817
train: epoch 18, iter 3600, loss: 3.279378, top_1: 0.476797, top_k: 0.720547, samples/s: 2227.529 1612364296.9518843
train: epoch 18, iter 3700, loss: 3.208885, top_1: 0.484766, top_k: 0.722227, samples/s: 2216.184 1612364308.5032847
train: epoch 18, iter 3800, loss: 3.169142, top_1: 0.477812, top_k: 0.721719, samples/s: 2230.230 1612364319.981856
train: epoch 18, iter 3900, loss: 3.041782, top_1: 0.481758, top_k: 0.722734, samples/s: 2205.068 1612364331.5914507
train: epoch 18, iter 4000, loss: 3.173482, top_1: 0.479687, top_k: 0.721523, samples/s: 2197.692 1612364343.2401228
train: epoch 18, iter 4100, loss: 3.257648, top_1: 0.475078, top_k: 0.715703, samples/s: 2220.691 1612364354.7680173
train: epoch 18, iter 4200, loss: 3.320378, top_1: 0.478633, top_k: 0.724609, samples/s: 2207.356 1612364366.3655636
train: epoch 18, iter 4300, loss: 3.370260, top_1: 0.480000, top_k: 0.716992, samples/s: 2221.096 1612364377.8914568
train: epoch 18, iter 4400, loss: 2.968238, top_1: 0.478789, top_k: 0.723711, samples/s: 2230.873 1612364389.3667357
train: epoch 18, iter 4500, loss: 3.337847, top_1: 0.480234, top_k: 0.722109, samples/s: 2231.440 1612364400.839151
train: epoch 18, iter 4600, loss: 3.258465, top_1: 0.477383, top_k: 0.719297, samples/s: 2216.328 1612364412.389788
train: epoch 18, iter 4700, loss: 3.234623, top_1: 0.480195, top_k: 0.723867, samples/s: 2223.362 1612364423.9040282
train: epoch 18, iter 4800, loss: 3.112484, top_1: 0.479766, top_k: 0.722500, samples/s: 2215.099 1612364435.460953
train: epoch 18, iter 4900, loss: 3.141073, top_1: 0.479961, top_k: 0.721406, samples/s: 2226.509 1612364446.95876
train: epoch 18, iter 5000, loss: 3.164960, top_1: 0.479141, top_k: 0.724336, samples/s: 2204.904 1612364458.5693007
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_18.
validation: epoch 18, iter 195, top_1: 0.523097, top_k: 0.774399, samples/s: 2852.371 1612364476.27297
train: epoch 19, iter 100, loss: 3.426231, top_1: 0.491250, top_k: 0.731172, samples/s: 2246.596 1612364503.635378
train: epoch 19, iter 200, loss: 3.116384, top_1: 0.484336, top_k: 0.730625, samples/s: 2260.783 1612364514.9588711
train: epoch 19, iter 300, loss: 3.153717, top_1: 0.485117, top_k: 0.728477, samples/s: 2246.822 1612364526.3527944
train: epoch 19, iter 400, loss: 3.230935, top_1: 0.483633, top_k: 0.726562, samples/s: 2253.290 1612364537.713987
train: epoch 19, iter 500, loss: 3.160830, top_1: 0.488008, top_k: 0.725625, samples/s: 2269.887 1612364548.9920774
train: epoch 19, iter 600, loss: 3.200521, top_1: 0.488203, top_k: 0.728203, samples/s: 2257.937 1612364560.3298411
train: epoch 19, iter 700, loss: 3.276101, top_1: 0.479961, top_k: 0.722187, samples/s: 2221.597 1612364571.8530667
train: epoch 19, iter 800, loss: 3.263076, top_1: 0.488984, top_k: 0.730391, samples/s: 2242.736 1612364583.2677193
train: epoch 19, iter 900, loss: 3.256255, top_1: 0.488086, top_k: 0.729766, samples/s: 2215.412 1612364594.8231406
train: epoch 19, iter 1000, loss: 2.848227, top_1: 0.483906, top_k: 0.726250, samples/s: 2211.969 1612364606.3964963
train: epoch 19, iter 1100, loss: 3.119710, top_1: 0.482187, top_k: 0.723359, samples/s: 2224.771 1612364617.903273
train: epoch 19, iter 1200, loss: 3.198148, top_1: 0.482969, top_k: 0.725352, samples/s: 2223.513 1612364629.4165936
train: epoch 19, iter 1300, loss: 3.162794, top_1: 0.485039, top_k: 0.728516, samples/s: 2220.056 1612364640.947865
train: epoch 19, iter 1400, loss: 3.166658, top_1: 0.483750, top_k: 0.724805, samples/s: 2236.762 1612364652.3930435
train: epoch 19, iter 1500, loss: 3.136958, top_1: 0.482695, top_k: 0.723320, samples/s: 2200.017 1612364664.0292053
train: epoch 19, iter 1600, loss: 3.234888, top_1: 0.478398, top_k: 0.723320, samples/s: 2207.197 1612364675.6276755
train: epoch 19, iter 1700, loss: 3.274178, top_1: 0.481133, top_k: 0.722539, samples/s: 2221.431 1612364687.1517181
train: epoch 19, iter 1800, loss: 3.198766, top_1: 0.479141, top_k: 0.721523, samples/s: 2202.094 1612364698.777002
train: epoch 19, iter 1900, loss: 3.196363, top_1: 0.481719, top_k: 0.722227, samples/s: 2224.935 1612364710.28306
train: epoch 19, iter 2000, loss: 3.179708, top_1: 0.481992, top_k: 0.721133, samples/s: 2233.017 1612364721.7473168
train: epoch 19, iter 2100, loss: 3.136195, top_1: 0.482187, top_k: 0.722461, samples/s: 2227.725 1612364733.2388403
train: epoch 19, iter 2200, loss: 3.266169, top_1: 0.481250, top_k: 0.723203, samples/s: 2208.612 1612364744.8299415
train: epoch 19, iter 2300, loss: 3.095724, top_1: 0.486797, top_k: 0.731172, samples/s: 2224.090 1612364756.3401515
train: epoch 19, iter 2400, loss: 3.165947, top_1: 0.485312, top_k: 0.725742, samples/s: 2234.514 1612364767.7968247
train: epoch 19, iter 2500, loss: 3.156696, top_1: 0.482812, top_k: 0.727461, samples/s: 2214.604 1612364779.3564076
train: epoch 19, iter 2600, loss: 3.451292, top_1: 0.479414, top_k: 0.722852, samples/s: 2211.887 1612364790.930319
train: epoch 19, iter 2700, loss: 3.219178, top_1: 0.483789, top_k: 0.721367, samples/s: 2222.655 1612364802.4479482
train: epoch 19, iter 2800, loss: 3.195893, top_1: 0.483008, top_k: 0.727734, samples/s: 2227.584 1612364813.9403238
train: epoch 19, iter 2900, loss: 3.112368, top_1: 0.478711, top_k: 0.725156, samples/s: 2225.523 1612364825.4432645
train: epoch 19, iter 3000, loss: 3.265459, top_1: 0.481563, top_k: 0.722461, samples/s: 2246.134 1612364836.8406208
train: epoch 19, iter 3100, loss: 3.364795, top_1: 0.477383, top_k: 0.725078, samples/s: 2246.995 1612364848.2336452
train: epoch 19, iter 3200, loss: 3.174559, top_1: 0.477461, top_k: 0.719023, samples/s: 2244.981 1612364859.6368263
train: epoch 19, iter 3300, loss: 3.004025, top_1: 0.477539, top_k: 0.719102, samples/s: 2242.313 1612364871.0535374
train: epoch 19, iter 3400, loss: 3.224576, top_1: 0.482187, top_k: 0.725703, samples/s: 2236.019 1612364882.5024648
train: epoch 19, iter 3500, loss: 3.258251, top_1: 0.481211, top_k: 0.726211, samples/s: 2243.300 1612364893.914218
train: epoch 19, iter 3600, loss: 3.051225, top_1: 0.486211, top_k: 0.728945, samples/s: 2235.490 1612364905.3659868
train: epoch 19, iter 3700, loss: 3.231932, top_1: 0.478867, top_k: 0.723711, samples/s: 2240.877 1612364916.7899888
train: epoch 19, iter 3800, loss: 3.171879, top_1: 0.476836, top_k: 0.719375, samples/s: 2245.143 1612364928.192377
train: epoch 19, iter 3900, loss: 3.063090, top_1: 0.477734, top_k: 0.724805, samples/s: 2230.985 1612364939.6670887
train: epoch 19, iter 4000, loss: 3.160580, top_1: 0.477344, top_k: 0.725000, samples/s: 2256.101 1612364951.0141468
train: epoch 19, iter 4100, loss: 3.162712, top_1: 0.480898, top_k: 0.722539, samples/s: 2242.435 1612364962.4302745
train: epoch 19, iter 4200, loss: 2.865944, top_1: 0.479609, top_k: 0.724844, samples/s: 2235.273 1612364973.8829877
train: epoch 19, iter 4300, loss: 3.118703, top_1: 0.478633, top_k: 0.721797, samples/s: 2239.326 1612364985.3150492
train: epoch 19, iter 4400, loss: 3.131659, top_1: 0.483164, top_k: 0.724219, samples/s: 2246.987 1612364996.7080722
train: epoch 19, iter 4500, loss: 3.135993, top_1: 0.476289, top_k: 0.724453, samples/s: 2234.401 1612365008.1653752
train: epoch 19, iter 4600, loss: 3.065136, top_1: 0.483633, top_k: 0.724414, samples/s: 2264.836 1612365019.4685245
train: epoch 19, iter 4700, loss: 3.446742, top_1: 0.486719, top_k: 0.725078, samples/s: 2237.878 1612365030.9080007
train: epoch 19, iter 4800, loss: 2.998265, top_1: 0.488086, top_k: 0.727617, samples/s: 2231.513 1612365042.379919
train: epoch 19, iter 4900, loss: 3.197271, top_1: 0.479570, top_k: 0.723477, samples/s: 2234.647 1612365053.8359034
train: epoch 19, iter 5000, loss: 3.167765, top_1: 0.483594, top_k: 0.724922, samples/s: 2251.802 1612365065.2046275
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_19.
validation: epoch 19, iter 195, top_1: 0.535557, top_k: 0.786378, samples/s: 2890.607 1612365082.8017595
train: epoch 20, iter 100, loss: 3.213959, top_1: 0.489063, top_k: 0.733359, samples/s: 2246.968 1612365110.1330342
train: epoch 20, iter 200, loss: 3.054567, top_1: 0.490586, top_k: 0.726836, samples/s: 2257.237 1612365121.4743092
train: epoch 20, iter 300, loss: 2.920139, top_1: 0.489648, top_k: 0.733437, samples/s: 2251.939 1612365132.842288
train: epoch 20, iter 400, loss: 3.036501, top_1: 0.483438, top_k: 0.721680, samples/s: 2256.989 1612365144.1849973
train: epoch 20, iter 500, loss: 3.033275, top_1: 0.496914, top_k: 0.733477, samples/s: 2260.424 1612365155.510209
train: epoch 20, iter 600, loss: 3.061579, top_1: 0.485781, top_k: 0.730313, samples/s: 2257.898 1612365166.8482096
train: epoch 20, iter 700, loss: 3.249422, top_1: 0.487539, top_k: 0.731758, samples/s: 2255.982 1612365178.1957688
train: epoch 20, iter 800, loss: 3.141525, top_1: 0.486758, top_k: 0.729453, samples/s: 2235.108 1612365189.6493518
train: epoch 20, iter 900, loss: 3.187474, top_1: 0.492070, top_k: 0.730352, samples/s: 2222.310 1612365201.168947
train: epoch 20, iter 1000, loss: 3.013028, top_1: 0.486641, top_k: 0.727578, samples/s: 2234.863 1612365212.623761
train: epoch 20, iter 1100, loss: 3.046203, top_1: 0.492227, top_k: 0.726133, samples/s: 2210.631 1612365224.2041273
train: epoch 20, iter 1200, loss: 3.045096, top_1: 0.485508, top_k: 0.725742, samples/s: 2240.519 1612365235.6300204
train: epoch 20, iter 1300, loss: 3.234297, top_1: 0.485508, top_k: 0.730078, samples/s: 2237.839 1612365247.069705
train: epoch 20, iter 1400, loss: 3.072365, top_1: 0.479180, top_k: 0.724844, samples/s: 2225.434 1612365258.5731075
train: epoch 20, iter 1500, loss: 3.026103, top_1: 0.491914, top_k: 0.732734, samples/s: 2229.042 1612365270.0577612
train: epoch 20, iter 1600, loss: 3.134187, top_1: 0.485469, top_k: 0.724375, samples/s: 2208.385 1612365281.6499445
train: epoch 20, iter 1700, loss: 3.190433, top_1: 0.484766, top_k: 0.728008, samples/s: 2241.905 1612365293.0688972
train: epoch 20, iter 1800, loss: 3.126106, top_1: 0.481406, top_k: 0.725234, samples/s: 2243.494 1612365304.4795668
train: epoch 20, iter 1900, loss: 3.109935, top_1: 0.488516, top_k: 0.726094, samples/s: 2233.195 1612365315.942968
train: epoch 20, iter 2000, loss: 3.241670, top_1: 0.485312, top_k: 0.728281, samples/s: 2218.019 1612365327.4848971
train: epoch 20, iter 2100, loss: 3.250479, top_1: 0.482422, top_k: 0.725273, samples/s: 2272.409 1612365338.7503827
train: epoch 20, iter 2200, loss: 3.252606, top_1: 0.487344, top_k: 0.727187, samples/s: 2232.688 1612365350.2163846
train: epoch 20, iter 2300, loss: 3.044738, top_1: 0.486914, top_k: 0.730234, samples/s: 2207.129 1612365361.8151603
train: epoch 20, iter 2400, loss: 3.322238, top_1: 0.485898, top_k: 0.729805, samples/s: 2249.639 1612365373.1948242
train: epoch 20, iter 2500, loss: 3.022911, top_1: 0.486172, top_k: 0.725625, samples/s: 2245.570 1612365384.5950193
train: epoch 20, iter 2600, loss: 3.289859, top_1: 0.483125, top_k: 0.726445, samples/s: 2229.241 1612365396.0787256
train: epoch 20, iter 2700, loss: 3.351775, top_1: 0.484141, top_k: 0.725938, samples/s: 2232.688 1612365407.5449035
train: epoch 20, iter 2800, loss: 3.288292, top_1: 0.483906, top_k: 0.725156, samples/s: 2239.165 1612365418.9775565
train: epoch 20, iter 2900, loss: 3.175446, top_1: 0.477617, top_k: 0.720547, samples/s: 2258.313 1612365430.31344
train: epoch 20, iter 3000, loss: 3.101119, top_1: 0.489687, top_k: 0.730547, samples/s: 2239.999 1612365441.7420182
train: epoch 20, iter 3100, loss: 3.195889, top_1: 0.484805, top_k: 0.727305, samples/s: 2229.557 1612365453.224247
train: epoch 20, iter 3200, loss: 3.055993, top_1: 0.484766, top_k: 0.725664, samples/s: 2244.309 1612365464.6307302
train: epoch 20, iter 3300, loss: 3.319877, top_1: 0.480898, top_k: 0.728359, samples/s: 2225.580 1612365476.1334774
train: epoch 20, iter 3400, loss: 3.282917, top_1: 0.479648, top_k: 0.723242, samples/s: 2238.672 1612365487.5687175
train: epoch 20, iter 3500, loss: 3.257275, top_1: 0.482383, top_k: 0.727109, samples/s: 2238.487 1612365499.0051067
train: epoch 20, iter 3600, loss: 3.099267, top_1: 0.484727, top_k: 0.728164, samples/s: 2248.827 1612365510.3887243
train: epoch 20, iter 3700, loss: 3.219288, top_1: 0.481836, top_k: 0.724141, samples/s: 2251.196 1612365521.7604878
train: epoch 20, iter 3800, loss: 3.325638, top_1: 0.483594, top_k: 0.722227, samples/s: 2242.156 1612365533.1780462
train: epoch 20, iter 3900, loss: 3.143803, top_1: 0.484648, top_k: 0.727734, samples/s: 2248.508 1612365544.5634475
train: epoch 20, iter 4000, loss: 3.168556, top_1: 0.481719, top_k: 0.723711, samples/s: 2238.503 1612365555.9997888
train: epoch 20, iter 4100, loss: 3.180405, top_1: 0.484453, top_k: 0.724688, samples/s: 2244.401 1612365567.405767
train: epoch 20, iter 4200, loss: 3.164975, top_1: 0.483359, top_k: 0.725703, samples/s: 2233.471 1612365578.867743
train: epoch 20, iter 4300, loss: 3.062046, top_1: 0.482773, top_k: 0.726133, samples/s: 2246.797 1612365590.2617564
train: epoch 20, iter 4400, loss: 3.145144, top_1: 0.480703, top_k: 0.725938, samples/s: 2239.232 1612365601.6943567
train: epoch 20, iter 4500, loss: 3.203367, top_1: 0.481992, top_k: 0.727852, samples/s: 2217.925 1612365613.2365658
train: epoch 20, iter 4600, loss: 2.987555, top_1: 0.486563, top_k: 0.724766, samples/s: 2213.719 1612365624.8007867
train: epoch 20, iter 4700, loss: 3.286656, top_1: 0.485000, top_k: 0.721641, samples/s: 2268.614 1612365636.08521
train: epoch 20, iter 4800, loss: 3.101578, top_1: 0.485781, top_k: 0.727695, samples/s: 2248.259 1612365647.471745
train: epoch 20, iter 4900, loss: 3.226164, top_1: 0.479258, top_k: 0.722383, samples/s: 2229.001 1612365658.956779
train: epoch 20, iter 5000, loss: 3.181300, top_1: 0.484180, top_k: 0.727070, samples/s: 2258.451 1612365670.2919636
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_20.
validation: epoch 20, iter 195, top_1: 0.533373, top_k: 0.785537, samples/s: 2889.629 1612365688.061934
train: epoch 21, iter 100, loss: 2.833312, top_1: 0.501523, top_k: 0.742266, samples/s: 2246.795 1612365715.2736087
train: epoch 21, iter 200, loss: 3.025796, top_1: 0.498516, top_k: 0.738398, samples/s: 2261.452 1612365726.5937626
train: epoch 21, iter 300, loss: 3.226751, top_1: 0.492188, top_k: 0.735898, samples/s: 2258.921 1612365737.926589
train: epoch 21, iter 400, loss: 2.968112, top_1: 0.492852, top_k: 0.736953, samples/s: 2251.929 1612365749.2946072
train: epoch 21, iter 500, loss: 3.137549, top_1: 0.490391, top_k: 0.729297, samples/s: 2261.750 1612365760.6132388
train: epoch 21, iter 600, loss: 3.108601, top_1: 0.495273, top_k: 0.733086, samples/s: 2257.737 1612365771.9520268
train: epoch 21, iter 700, loss: 3.291903, top_1: 0.490312, top_k: 0.729141, samples/s: 2256.007 1612365783.2995782
train: epoch 21, iter 800, loss: 3.166967, top_1: 0.485469, top_k: 0.731094, samples/s: 2239.248 1612365794.7319767
train: epoch 21, iter 900, loss: 3.157868, top_1: 0.492188, top_k: 0.735664, samples/s: 2249.828 1612365806.1105652
train: epoch 21, iter 1000, loss: 2.907766, top_1: 0.486719, top_k: 0.731680, samples/s: 2255.539 1612365817.460488
train: epoch 21, iter 1100, loss: 3.160571, top_1: 0.492539, top_k: 0.733789, samples/s: 2242.948 1612365828.8740246
train: epoch 21, iter 1200, loss: 3.167493, top_1: 0.490508, top_k: 0.733086, samples/s: 2219.787 1612365840.4066126
train: epoch 21, iter 1300, loss: 3.255683, top_1: 0.486797, top_k: 0.728125, samples/s: 2242.179 1612365851.8241243
train: epoch 21, iter 1400, loss: 2.985872, top_1: 0.485703, top_k: 0.728359, samples/s: 2233.969 1612365863.2835534
train: epoch 21, iter 1500, loss: 3.217753, top_1: 0.489727, top_k: 0.732383, samples/s: 2225.272 1612365874.787712
train: epoch 21, iter 1600, loss: 3.257150, top_1: 0.484336, top_k: 0.725352, samples/s: 2234.762 1612365886.2430577
train: epoch 21, iter 1700, loss: 3.166563, top_1: 0.489883, top_k: 0.728906, samples/s: 2225.705 1612365897.745142
train: epoch 21, iter 1800, loss: 3.208181, top_1: 0.482578, top_k: 0.728594, samples/s: 2226.792 1612365909.2414868
train: epoch 21, iter 1900, loss: 3.028379, top_1: 0.485977, top_k: 0.728789, samples/s: 2264.583 1612365920.545934
train: epoch 21, iter 2000, loss: 3.287636, top_1: 0.492188, top_k: 0.732539, samples/s: 2238.389 1612365931.9827194
train: epoch 21, iter 2100, loss: 3.293150, top_1: 0.478789, top_k: 0.725156, samples/s: 2214.558 1612365943.5426323
train: epoch 21, iter 2200, loss: 3.150903, top_1: 0.490430, top_k: 0.731445, samples/s: 2248.127 1612365954.929954
train: epoch 21, iter 2300, loss: 3.179080, top_1: 0.489219, top_k: 0.727656, samples/s: 2245.715 1612365966.329363
train: epoch 21, iter 2400, loss: 3.201680, top_1: 0.489727, top_k: 0.731094, samples/s: 2246.564 1612365977.7244825
train: epoch 21, iter 2500, loss: 3.024906, top_1: 0.488008, top_k: 0.733203, samples/s: 2246.165 1612365989.121674
train: epoch 21, iter 2600, loss: 3.254322, top_1: 0.483398, top_k: 0.724961, samples/s: 2244.573 1612366000.527041
train: epoch 21, iter 2700, loss: 3.230886, top_1: 0.488828, top_k: 0.730391, samples/s: 2227.430 1612366012.0201926
train: epoch 21, iter 2800, loss: 3.207867, top_1: 0.487734, top_k: 0.729414, samples/s: 2249.068 1612366023.402535
train: epoch 21, iter 2900, loss: 3.230896, top_1: 0.492031, top_k: 0.728359, samples/s: 2231.200 1612366034.8762302
train: epoch 21, iter 3000, loss: 3.105020, top_1: 0.485000, top_k: 0.723359, samples/s: 2253.759 1612366046.234984
train: epoch 21, iter 3100, loss: 3.175247, top_1: 0.481484, top_k: 0.723672, samples/s: 2233.574 1612366057.6966207
train: epoch 21, iter 3200, loss: 3.203680, top_1: 0.483398, top_k: 0.728398, samples/s: 2252.744 1612366069.0603566
train: epoch 21, iter 3300, loss: 3.443256, top_1: 0.480117, top_k: 0.724453, samples/s: 2246.534 1612366080.4557781
train: epoch 21, iter 3400, loss: 2.980472, top_1: 0.482969, top_k: 0.729922, samples/s: 2240.662 1612366091.8808992
train: epoch 21, iter 3500, loss: 2.983299, top_1: 0.484727, top_k: 0.725352, samples/s: 2244.345 1612366103.2873707
train: epoch 21, iter 3600, loss: 3.145248, top_1: 0.486641, top_k: 0.728633, samples/s: 2225.014 1612366114.7929292
train: epoch 21, iter 3700, loss: 3.108332, top_1: 0.487383, top_k: 0.727422, samples/s: 2269.286 1612366126.073979
train: epoch 21, iter 3800, loss: 3.200095, top_1: 0.489102, top_k: 0.727266, samples/s: 2244.468 1612366137.4798121
train: epoch 21, iter 3900, loss: 3.126985, top_1: 0.481250, top_k: 0.726172, samples/s: 2232.926 1612366148.944682
train: epoch 21, iter 4000, loss: 3.224678, top_1: 0.482773, top_k: 0.724688, samples/s: 2258.541 1612366160.2793667
train: epoch 21, iter 4100, loss: 3.202639, top_1: 0.488203, top_k: 0.728984, samples/s: 2239.143 1612366171.712239
train: epoch 21, iter 4200, loss: 3.149607, top_1: 0.482852, top_k: 0.729141, samples/s: 2229.496 1612366183.1948752
train: epoch 21, iter 4300, loss: 3.227199, top_1: 0.482305, top_k: 0.724492, samples/s: 2255.687 1612366194.5437453
train: epoch 21, iter 4400, loss: 3.121069, top_1: 0.478789, top_k: 0.726133, samples/s: 2199.743 1612366206.1814888
train: epoch 21, iter 4500, loss: 2.940692, top_1: 0.485039, top_k: 0.727070, samples/s: 2258.552 1612366217.516246
train: epoch 21, iter 4600, loss: 3.489494, top_1: 0.482266, top_k: 0.724141, samples/s: 2239.945 1612366228.9450338
train: epoch 21, iter 4700, loss: 3.095358, top_1: 0.482109, top_k: 0.724336, samples/s: 2230.216 1612366240.423727
train: epoch 21, iter 4800, loss: 3.098581, top_1: 0.483906, top_k: 0.727500, samples/s: 2228.068 1612366251.9135828
train: epoch 21, iter 4900, loss: 2.972344, top_1: 0.488164, top_k: 0.729297, samples/s: 2238.164 1612366263.351511
train: epoch 21, iter 5000, loss: 3.133290, top_1: 0.483789, top_k: 0.729844, samples/s: 2262.314 1612366274.6673036
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_21.
validation: epoch 21, iter 195, top_1: 0.523397, top_k: 0.775160, samples/s: 2879.387 1612366292.3797896
train: epoch 22, iter 100, loss: 3.242103, top_1: 0.501875, top_k: 0.741406, samples/s: 2243.983 1612366320.765946
train: epoch 22, iter 200, loss: 2.976785, top_1: 0.483008, top_k: 0.726719, samples/s: 2246.075 1612366332.1636055
train: epoch 22, iter 300, loss: 3.062388, top_1: 0.496719, top_k: 0.735977, samples/s: 2273.064 1612366343.4259648
train: epoch 22, iter 400, loss: 3.100776, top_1: 0.492578, top_k: 0.731953, samples/s: 2263.699 1612366354.7349975
train: epoch 22, iter 500, loss: 3.071569, top_1: 0.497148, top_k: 0.736445, samples/s: 2256.423 1612366366.080299
train: epoch 22, iter 600, loss: 3.102600, top_1: 0.496641, top_k: 0.737070, samples/s: 2243.500 1612366377.490981
train: epoch 22, iter 700, loss: 3.181471, top_1: 0.488789, top_k: 0.735273, samples/s: 2255.228 1612366388.8423584
train: epoch 22, iter 800, loss: 3.040843, top_1: 0.494219, top_k: 0.735195, samples/s: 2249.523 1612366400.2226362
train: epoch 22, iter 900, loss: 3.052617, top_1: 0.490469, top_k: 0.734180, samples/s: 2249.262 1612366411.6040976
train: epoch 22, iter 1000, loss: 3.164695, top_1: 0.489922, top_k: 0.729258, samples/s: 2236.316 1612366423.0515554
train: epoch 22, iter 1100, loss: 3.038494, top_1: 0.488594, top_k: 0.730039, samples/s: 2230.739 1612366434.5274978
train: epoch 22, iter 1200, loss: 3.166632, top_1: 0.491055, top_k: 0.727812, samples/s: 2225.992 1612366446.0280447
train: epoch 22, iter 1300, loss: 2.941648, top_1: 0.489453, top_k: 0.729961, samples/s: 2232.523 1612366457.4948294
train: epoch 22, iter 1400, loss: 3.122898, top_1: 0.490078, top_k: 0.732578, samples/s: 2215.669 1612366469.0489056
train: epoch 22, iter 1500, loss: 3.078998, top_1: 0.492734, top_k: 0.734180, samples/s: 2232.294 1612366480.5169199
train: epoch 22, iter 1600, loss: 3.146424, top_1: 0.486055, top_k: 0.730625, samples/s: 2243.863 1612366491.9258902
train: epoch 22, iter 1700, loss: 3.077828, top_1: 0.487891, top_k: 0.727266, samples/s: 2239.461 1612366503.3571215
train: epoch 22, iter 1800, loss: 2.996364, top_1: 0.490312, top_k: 0.732812, samples/s: 2233.865 1612366514.8172333
train: epoch 22, iter 1900, loss: 3.219109, top_1: 0.494648, top_k: 0.734727, samples/s: 2249.412 1612366526.1979377
train: epoch 22, iter 2000, loss: 3.229790, top_1: 0.484883, top_k: 0.728906, samples/s: 2239.089 1612366537.6311154
train: epoch 22, iter 2100, loss: 3.091828, top_1: 0.492109, top_k: 0.730664, samples/s: 2241.291 1612366549.0530653
train: epoch 22, iter 2200, loss: 3.168023, top_1: 0.486094, top_k: 0.727031, samples/s: 2249.461 1612366560.4336681
train: epoch 22, iter 2300, loss: 3.085908, top_1: 0.493711, top_k: 0.732070, samples/s: 2233.465 1612366571.8956606
train: epoch 22, iter 2400, loss: 3.079177, top_1: 0.494844, top_k: 0.732539, samples/s: 2232.420 1612366583.3629277
train: epoch 22, iter 2500, loss: 3.250834, top_1: 0.490312, top_k: 0.725977, samples/s: 2239.840 1612366594.7923455
train: epoch 22, iter 2600, loss: 3.243627, top_1: 0.489023, top_k: 0.730156, samples/s: 2235.790 1612366606.2425036
train: epoch 22, iter 2700, loss: 3.051808, top_1: 0.489023, top_k: 0.729062, samples/s: 2231.887 1612366617.7126334
train: epoch 22, iter 2800, loss: 3.217267, top_1: 0.490352, top_k: 0.728477, samples/s: 2232.575 1612366629.1791127
train: epoch 22, iter 2900, loss: 3.228952, top_1: 0.488750, top_k: 0.729531, samples/s: 2231.730 1612366640.6501117
train: epoch 22, iter 3000, loss: 3.108768, top_1: 0.491133, top_k: 0.726992, samples/s: 2239.599 1612366652.0806515
train: epoch 22, iter 3100, loss: 3.194527, top_1: 0.487461, top_k: 0.730039, samples/s: 2235.776 1612366663.5308816
train: epoch 22, iter 3200, loss: 3.121750, top_1: 0.492539, top_k: 0.728477, samples/s: 2216.837 1612366675.07879
train: epoch 22, iter 3300, loss: 3.140989, top_1: 0.485703, top_k: 0.728242, samples/s: 2246.658 1612366686.4735763
train: epoch 22, iter 3400, loss: 3.176485, top_1: 0.490078, top_k: 0.731836, samples/s: 2236.091 1612366697.92212
train: epoch 22, iter 3500, loss: 3.141725, top_1: 0.485469, top_k: 0.729531, samples/s: 2235.229 1612366709.3750513
train: epoch 22, iter 3600, loss: 3.029118, top_1: 0.481797, top_k: 0.725273, samples/s: 2246.813 1612366720.768926
train: epoch 22, iter 3700, loss: 2.911428, top_1: 0.488555, top_k: 0.729336, samples/s: 2238.001 1612366732.2078028
train: epoch 22, iter 3800, loss: 3.159777, top_1: 0.486953, top_k: 0.733359, samples/s: 2255.605 1612366743.5573359
train: epoch 22, iter 3900, loss: 3.101490, top_1: 0.487617, top_k: 0.730820, samples/s: 2246.278 1612366754.9538429
train: epoch 22, iter 4000, loss: 3.030816, top_1: 0.486523, top_k: 0.734375, samples/s: 2242.905 1612366766.3676736
train: epoch 22, iter 4100, loss: 3.213560, top_1: 0.482539, top_k: 0.726406, samples/s: 2245.156 1612366777.7699502
train: epoch 22, iter 4200, loss: 3.242202, top_1: 0.488047, top_k: 0.726523, samples/s: 2197.770 1612366789.418136
train: epoch 22, iter 4300, loss: 3.084842, top_1: 0.489609, top_k: 0.729727, samples/s: 2226.360 1612366800.9167836
train: epoch 22, iter 4400, loss: 3.201107, top_1: 0.487344, top_k: 0.731133, samples/s: 2252.878 1612366812.2799475
train: epoch 22, iter 4500, loss: 3.030510, top_1: 0.487266, top_k: 0.728516, samples/s: 2248.958 1612366823.663051
train: epoch 22, iter 4600, loss: 3.166359, top_1: 0.482500, top_k: 0.725313, samples/s: 2237.596 1612366835.1039138
train: epoch 22, iter 4700, loss: 3.190216, top_1: 0.484492, top_k: 0.728086, samples/s: 2236.219 1612366846.5517702
train: epoch 22, iter 4800, loss: 3.377016, top_1: 0.483906, top_k: 0.725273, samples/s: 2238.516 1612366857.987976
train: epoch 22, iter 4900, loss: 3.217748, top_1: 0.486797, top_k: 0.729453, samples/s: 2268.204 1612366869.2744362
train: epoch 22, iter 5000, loss: 3.138114, top_1: 0.487109, top_k: 0.730000, samples/s: 2243.787 1612366880.68373
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_22.
validation: epoch 22, iter 195, top_1: 0.528866, top_k: 0.781691, samples/s: 2954.207 1612366897.9224784
train: epoch 23, iter 100, loss: 3.112198, top_1: 0.499883, top_k: 0.739961, samples/s: 2250.973 1612366924.993899
train: epoch 23, iter 200, loss: 3.154468, top_1: 0.493867, top_k: 0.735742, samples/s: 2258.945 1612366936.3266153
train: epoch 23, iter 300, loss: 2.955034, top_1: 0.492617, top_k: 0.735117, samples/s: 2251.115 1612366947.6987603
train: epoch 23, iter 400, loss: 2.983039, top_1: 0.494414, top_k: 0.736211, samples/s: 2240.787 1612366959.12368
train: epoch 23, iter 500, loss: 3.273005, top_1: 0.489570, top_k: 0.728555, samples/s: 2248.982 1612366970.506248
train: epoch 23, iter 600, loss: 3.075049, top_1: 0.493398, top_k: 0.734648, samples/s: 2258.727 1612366981.8406467
train: epoch 23, iter 700, loss: 3.092203, top_1: 0.493516, top_k: 0.733711, samples/s: 2272.694 1612366993.1042569
train: epoch 23, iter 800, loss: 3.210079, top_1: 0.494766, top_k: 0.734492, samples/s: 2243.713 1612367004.5139458
train: epoch 23, iter 900, loss: 3.128985, top_1: 0.494648, top_k: 0.733086, samples/s: 2216.918 1612367016.0614338
train: epoch 23, iter 1000, loss: 3.265500, top_1: 0.493164, top_k: 0.734531, samples/s: 2227.624 1612367027.5535486
train: epoch 23, iter 1100, loss: 3.221926, top_1: 0.492148, top_k: 0.735820, samples/s: 2219.185 1612367039.0892792
train: epoch 23, iter 1200, loss: 2.980239, top_1: 0.495586, top_k: 0.737461, samples/s: 2225.092 1612367050.5944612
train: epoch 23, iter 1300, loss: 3.175730, top_1: 0.493867, top_k: 0.734258, samples/s: 2224.860 1612367062.100838
train: epoch 23, iter 1400, loss: 3.248886, top_1: 0.490625, top_k: 0.732617, samples/s: 2225.132 1612367073.6056926
train: epoch 23, iter 1500, loss: 3.325337, top_1: 0.495391, top_k: 0.735977, samples/s: 2231.703 1612367085.076749
train: epoch 23, iter 1600, loss: 3.107951, top_1: 0.491680, top_k: 0.737930, samples/s: 2214.851 1612367096.6351984
train: epoch 23, iter 1700, loss: 3.076058, top_1: 0.493516, top_k: 0.735078, samples/s: 2247.901 1612367108.0234916
train: epoch 23, iter 1800, loss: 3.200520, top_1: 0.488789, top_k: 0.731953, samples/s: 2197.626 1612367119.672427
train: epoch 23, iter 1900, loss: 3.043869, top_1: 0.488164, top_k: 0.729727, samples/s: 2220.140 1612367131.2032332
train: epoch 23, iter 2000, loss: 2.976651, top_1: 0.482344, top_k: 0.729062, samples/s: 2239.609 1612367142.6337957
train: epoch 23, iter 2100, loss: 3.256082, top_1: 0.492656, top_k: 0.731523, samples/s: 2202.779 1612367154.2555287
train: epoch 23, iter 2200, loss: 2.999099, top_1: 0.491836, top_k: 0.732461, samples/s: 2231.342 1612367165.728393
train: epoch 23, iter 2300, loss: 3.127080, top_1: 0.489258, top_k: 0.733398, samples/s: 2227.013 1612367177.223671
train: epoch 23, iter 2400, loss: 3.184661, top_1: 0.487930, top_k: 0.735156, samples/s: 2210.983 1612367188.8022652
train: epoch 23, iter 2500, loss: 3.035694, top_1: 0.497930, top_k: 0.737070, samples/s: 2202.968 1612367200.4228587
train: epoch 23, iter 2600, loss: 3.141779, top_1: 0.494766, top_k: 0.734961, samples/s: 2195.834 1612367212.081303
train: epoch 23, iter 2700, loss: 2.968749, top_1: 0.491211, top_k: 0.732734, samples/s: 2208.167 1612367223.674642
train: epoch 23, iter 2800, loss: 3.124677, top_1: 0.486914, top_k: 0.729531, samples/s: 2217.476 1612367235.2193248
train: epoch 23, iter 2900, loss: 3.034059, top_1: 0.493516, top_k: 0.731758, samples/s: 2194.709 1612367246.8837185
train: epoch 23, iter 3000, loss: 3.246660, top_1: 0.499531, top_k: 0.736094, samples/s: 2220.329 1612367258.4139633
train: epoch 23, iter 3100, loss: 3.067436, top_1: 0.494883, top_k: 0.736289, samples/s: 2213.045 1612367269.9813037
train: epoch 23, iter 3200, loss: 2.934860, top_1: 0.490430, top_k: 0.734023, samples/s: 2188.859 1612367281.6774185
train: epoch 23, iter 3300, loss: 3.103728, top_1: 0.489297, top_k: 0.731836, samples/s: 2208.876 1612367293.2665217
train: epoch 23, iter 3400, loss: 3.296586, top_1: 0.487500, top_k: 0.727969, samples/s: 2213.455 1612367304.832156
train: epoch 23, iter 3500, loss: 3.127354, top_1: 0.491406, top_k: 0.730664, samples/s: 2197.638 1612367316.481042
train: epoch 23, iter 3600, loss: 3.009593, top_1: 0.484883, top_k: 0.726445, samples/s: 2212.556 1612367328.0513802
train: epoch 23, iter 3700, loss: 3.229119, top_1: 0.491094, top_k: 0.729258, samples/s: 2210.063 1612367339.6347058
train: epoch 23, iter 3800, loss: 2.968797, top_1: 0.491289, top_k: 0.733242, samples/s: 2218.468 1612367351.1742048
train: epoch 23, iter 3900, loss: 3.048759, top_1: 0.492969, top_k: 0.730898, samples/s: 2205.603 1612367362.780998
train: epoch 23, iter 4000, loss: 3.331218, top_1: 0.490898, top_k: 0.731445, samples/s: 2232.565 1612367374.24763
train: epoch 23, iter 4100, loss: 2.995059, top_1: 0.488164, top_k: 0.731289, samples/s: 2207.396 1612367385.8450046
train: epoch 23, iter 4200, loss: 3.217922, top_1: 0.484961, top_k: 0.728906, samples/s: 2204.106 1612367397.4597511
train: epoch 23, iter 4300, loss: 2.963103, top_1: 0.491602, top_k: 0.734062, samples/s: 2229.926 1612367408.9399176
train: epoch 23, iter 4400, loss: 3.119852, top_1: 0.489414, top_k: 0.728086, samples/s: 2218.733 1612367420.4782348
train: epoch 23, iter 4500, loss: 3.265040, top_1: 0.490703, top_k: 0.732852, samples/s: 2224.932 1612367431.9840052
train: epoch 23, iter 4600, loss: 3.177271, top_1: 0.494219, top_k: 0.734492, samples/s: 2214.422 1612367443.5445812
train: epoch 23, iter 4700, loss: 3.313556, top_1: 0.488203, top_k: 0.727734, samples/s: 2210.809 1612367455.1240544
train: epoch 23, iter 4800, loss: 3.260797, top_1: 0.493945, top_k: 0.731953, samples/s: 2227.628 1612367466.6161351
train: epoch 23, iter 4900, loss: 2.911596, top_1: 0.492227, top_k: 0.736836, samples/s: 2206.436 1612367478.2186162
train: epoch 23, iter 5000, loss: 3.025463, top_1: 0.490742, top_k: 0.732773, samples/s: 2231.669 1612367489.6897385
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_23.
validation: epoch 23, iter 195, top_1: 0.524780, top_k: 0.778345, samples/s: 2890.382 1612367507.3497024
train: epoch 24, iter 100, loss: 2.891889, top_1: 0.500703, top_k: 0.736367, samples/s: 2244.921 1612367534.431328
train: epoch 24, iter 200, loss: 3.054105, top_1: 0.505898, top_k: 0.745898, samples/s: 2259.495 1612367545.7612875
train: epoch 24, iter 300, loss: 3.361186, top_1: 0.491680, top_k: 0.732578, samples/s: 2252.735 1612367557.1253397
train: epoch 24, iter 400, loss: 3.142339, top_1: 0.503047, top_k: 0.742500, samples/s: 2259.341 1612367568.4560454
train: epoch 24, iter 500, loss: 3.202012, top_1: 0.500742, top_k: 0.738242, samples/s: 2241.948 1612367579.8746784
train: epoch 24, iter 600, loss: 3.118910, top_1: 0.498672, top_k: 0.740508, samples/s: 2253.552 1612367591.2346072
train: epoch 24, iter 700, loss: 2.935674, top_1: 0.493320, top_k: 0.736641, samples/s: 2241.373 1612367602.6561277
train: epoch 24, iter 800, loss: 3.231736, top_1: 0.492695, top_k: 0.730078, samples/s: 2238.003 1612367614.0949178
train: epoch 24, iter 900, loss: 3.053991, top_1: 0.494492, top_k: 0.736992, samples/s: 2219.738 1612367625.6278117
train: epoch 24, iter 1000, loss: 3.183197, top_1: 0.495820, top_k: 0.737031, samples/s: 2210.443 1612367637.209104
train: epoch 24, iter 1100, loss: 3.025385, top_1: 0.493398, top_k: 0.732695, samples/s: 2218.296 1612367648.7495272
train: epoch 24, iter 1200, loss: 2.977889, top_1: 0.496797, top_k: 0.733789, samples/s: 2228.067 1612367660.239275
train: epoch 24, iter 1300, loss: 3.275854, top_1: 0.494961, top_k: 0.738242, samples/s: 2214.149 1612367671.8012795
train: epoch 24, iter 1400, loss: 3.257215, top_1: 0.495820, top_k: 0.736055, samples/s: 2213.511 1612367683.366673
train: epoch 24, iter 1500, loss: 3.116636, top_1: 0.491250, top_k: 0.730820, samples/s: 2215.423 1612367694.9220579
train: epoch 24, iter 1600, loss: 2.867880, top_1: 0.494883, top_k: 0.734414, samples/s: 2208.277 1612367706.5147216
train: epoch 24, iter 1700, loss: 3.182791, top_1: 0.493945, top_k: 0.736289, samples/s: 2226.566 1612367718.012262
train: epoch 24, iter 1800, loss: 2.979167, top_1: 0.494805, top_k: 0.732148, samples/s: 2207.486 1612367729.6091597
train: epoch 24, iter 1900, loss: 3.135635, top_1: 0.497773, top_k: 0.732930, samples/s: 2228.295 1612367741.0978763
train: epoch 24, iter 2000, loss: 3.000904, top_1: 0.492461, top_k: 0.734570, samples/s: 2200.625 1612367752.7309124
train: epoch 24, iter 2100, loss: 3.129277, top_1: 0.495898, top_k: 0.734727, samples/s: 2208.271 1612367764.3235893
train: epoch 24, iter 2200, loss: 3.155641, top_1: 0.499102, top_k: 0.739570, samples/s: 2218.652 1612367775.8621545
train: epoch 24, iter 2300, loss: 3.061452, top_1: 0.497188, top_k: 0.735508, samples/s: 2201.255 1612367787.491865
train: epoch 24, iter 2400, loss: 2.925419, top_1: 0.492383, top_k: 0.731211, samples/s: 2227.347 1612367798.9853504
train: epoch 24, iter 2500, loss: 3.076680, top_1: 0.496055, top_k: 0.735234, samples/s: 2224.824 1612367810.491832
train: epoch 24, iter 2600, loss: 3.332112, top_1: 0.495156, top_k: 0.735000, samples/s: 2226.332 1612367821.990617
train: epoch 24, iter 2700, loss: 3.200075, top_1: 0.492852, top_k: 0.730586, samples/s: 2203.496 1612367833.6085432
train: epoch 24, iter 2800, loss: 2.985764, top_1: 0.494570, top_k: 0.734883, samples/s: 2236.949 1612367845.0527499
train: epoch 24, iter 2900, loss: 3.189890, top_1: 0.495742, top_k: 0.733164, samples/s: 2201.659 1612367856.6803148
train: epoch 24, iter 3000, loss: 3.314055, top_1: 0.492656, top_k: 0.733516, samples/s: 2220.703 1612367868.2082472
train: epoch 24, iter 3100, loss: 2.995285, top_1: 0.490938, top_k: 0.731484, samples/s: 2225.340 1612367879.7120223
train: epoch 24, iter 3200, loss: 3.149977, top_1: 0.493125, top_k: 0.735508, samples/s: 2210.438 1612367891.2934375
train: epoch 24, iter 3300, loss: 3.030887, top_1: 0.493750, top_k: 0.733242, samples/s: 2223.342 1612367902.8076193
train: epoch 24, iter 3400, loss: 3.291188, top_1: 0.494688, top_k: 0.738945, samples/s: 2218.454 1612367914.3472059
train: epoch 24, iter 3500, loss: 3.056043, top_1: 0.484805, top_k: 0.728555, samples/s: 2218.369 1612367925.8872201
train: epoch 24, iter 3600, loss: 3.193280, top_1: 0.491914, top_k: 0.733203, samples/s: 2194.920 1612367937.5505588
train: epoch 24, iter 3700, loss: 3.172127, top_1: 0.490156, top_k: 0.731445, samples/s: 2227.384 1612367949.04385
train: epoch 24, iter 3800, loss: 3.027571, top_1: 0.489102, top_k: 0.731328, samples/s: 2234.936 1612367960.4982708
train: epoch 24, iter 3900, loss: 2.989047, top_1: 0.495703, top_k: 0.730781, samples/s: 2216.961 1612367972.045625
train: epoch 24, iter 4000, loss: 3.160533, top_1: 0.493633, top_k: 0.733828, samples/s: 2229.923 1612367983.5258188
train: epoch 24, iter 4100, loss: 3.094912, top_1: 0.491484, top_k: 0.730938, samples/s: 2212.182 1612367995.098096
train: epoch 24, iter 4200, loss: 3.122326, top_1: 0.496523, top_k: 0.735391, samples/s: 2200.374 1612368006.7325232
train: epoch 24, iter 4300, loss: 3.159478, top_1: 0.487266, top_k: 0.725039, samples/s: 2207.329 1612368018.3302193
train: epoch 24, iter 4400, loss: 3.146656, top_1: 0.489492, top_k: 0.729766, samples/s: 2243.591 1612368029.7405057
train: epoch 24, iter 4500, loss: 3.370551, top_1: 0.487070, top_k: 0.726406, samples/s: 2184.010 1612368041.4620447
train: epoch 24, iter 4600, loss: 3.088599, top_1: 0.496758, top_k: 0.735000, samples/s: 2213.240 1612368053.02881
train: epoch 24, iter 4700, loss: 3.158525, top_1: 0.495312, top_k: 0.733437, samples/s: 2230.683 1612368064.5051384
train: epoch 24, iter 4800, loss: 3.183194, top_1: 0.495312, top_k: 0.739219, samples/s: 2225.847 1612368076.0063462
train: epoch 24, iter 4900, loss: 3.168242, top_1: 0.493828, top_k: 0.734023, samples/s: 2194.779 1612368087.6705534
train: epoch 24, iter 5000, loss: 3.076118, top_1: 0.496406, top_k: 0.736563, samples/s: 2243.135 1612368099.082996
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_24.
validation: epoch 24, iter 195, top_1: 0.540264, top_k: 0.789864, samples/s: 2944.005 1612368116.3786469
train: epoch 25, iter 100, loss: 2.953984, top_1: 0.501211, top_k: 0.742891, samples/s: 2239.832 1612368143.609071
train: epoch 25, iter 200, loss: 2.969344, top_1: 0.501680, top_k: 0.744609, samples/s: 2246.298 1612368155.005498
train: epoch 25, iter 300, loss: 3.127894, top_1: 0.497305, top_k: 0.737500, samples/s: 2259.864 1612368166.3335946
train: epoch 25, iter 400, loss: 3.193620, top_1: 0.499336, top_k: 0.742266, samples/s: 2238.684 1612368177.7689924
train: epoch 25, iter 500, loss: 3.273910, top_1: 0.499766, top_k: 0.736523, samples/s: 2257.471 1612368189.1090302
train: epoch 25, iter 600, loss: 2.871543, top_1: 0.504453, top_k: 0.738711, samples/s: 2261.917 1612368200.4268484
train: epoch 25, iter 700, loss: 3.150837, top_1: 0.496055, top_k: 0.734570, samples/s: 2244.078 1612368211.834656
train: epoch 25, iter 800, loss: 3.248765, top_1: 0.503242, top_k: 0.742422, samples/s: 2202.066 1612368223.4601567
train: epoch 25, iter 900, loss: 3.099485, top_1: 0.491758, top_k: 0.736602, samples/s: 2229.300 1612368234.9439552
train: epoch 25, iter 1000, loss: 3.041353, top_1: 0.493164, top_k: 0.735000, samples/s: 2223.335 1612368246.4578106
train: epoch 25, iter 1100, loss: 3.399374, top_1: 0.499766, top_k: 0.736797, samples/s: 2224.135 1612368257.968302
train: epoch 25, iter 1200, loss: 3.349643, top_1: 0.496836, top_k: 0.738750, samples/s: 2223.816 1612368269.4795954
train: epoch 25, iter 1300, loss: 3.132249, top_1: 0.500977, top_k: 0.739570, samples/s: 2212.726 1612368281.049045
train: epoch 25, iter 1400, loss: 2.932232, top_1: 0.496875, top_k: 0.740313, samples/s: 2213.563 1612368292.6141386
train: epoch 25, iter 1500, loss: 3.169953, top_1: 0.493672, top_k: 0.734141, samples/s: 2203.455 1612368304.232216
train: epoch 25, iter 1600, loss: 3.064261, top_1: 0.493516, top_k: 0.733437, samples/s: 2246.145 1612368315.6294725
train: epoch 25, iter 1700, loss: 2.970151, top_1: 0.499180, top_k: 0.737695, samples/s: 2199.920 1612368327.2662978
train: epoch 25, iter 1800, loss: 3.173400, top_1: 0.494531, top_k: 0.739648, samples/s: 2190.629 1612368338.952501
train: epoch 25, iter 1900, loss: 3.093474, top_1: 0.492461, top_k: 0.736289, samples/s: 2220.395 1612368350.4819462
train: epoch 25, iter 2000, loss: 3.217818, top_1: 0.497422, top_k: 0.740117, samples/s: 2218.980 1612368362.018734
train: epoch 25, iter 2100, loss: 3.081537, top_1: 0.494492, top_k: 0.734219, samples/s: 2241.758 1612368373.4383636
train: epoch 25, iter 2200, loss: 2.824486, top_1: 0.492695, top_k: 0.728281, samples/s: 2213.411 1612368385.0043812
train: epoch 25, iter 2300, loss: 3.100482, top_1: 0.495195, top_k: 0.733984, samples/s: 2211.358 1612368396.580824
train: epoch 25, iter 2400, loss: 3.156398, top_1: 0.494727, top_k: 0.735508, samples/s: 2223.468 1612368408.0943606
train: epoch 25, iter 2500, loss: 3.057980, top_1: 0.494609, top_k: 0.728984, samples/s: 2192.141 1612368419.7724676
train: epoch 25, iter 2600, loss: 3.211611, top_1: 0.502305, top_k: 0.737539, samples/s: 2182.935 1612368431.4997792
train: epoch 25, iter 2700, loss: 3.105079, top_1: 0.495117, top_k: 0.734297, samples/s: 2255.383 1612368442.8503993
train: epoch 25, iter 2800, loss: 3.099839, top_1: 0.492266, top_k: 0.736641, samples/s: 2222.046 1612368454.3713179
train: epoch 25, iter 2900, loss: 2.986093, top_1: 0.495352, top_k: 0.737812, samples/s: 2227.287 1612368465.8651512
train: epoch 25, iter 3000, loss: 2.828836, top_1: 0.496680, top_k: 0.735469, samples/s: 2239.703 1612368477.2955203
train: epoch 25, iter 3100, loss: 3.141178, top_1: 0.499102, top_k: 0.737109, samples/s: 2234.083 1612368488.7541049
train: epoch 25, iter 3200, loss: 3.163669, top_1: 0.497266, top_k: 0.734492, samples/s: 2222.251 1612368500.2739348
train: epoch 25, iter 3300, loss: 3.172174, top_1: 0.495508, top_k: 0.734062, samples/s: 2216.603 1612368511.8231242
train: epoch 25, iter 3400, loss: 3.000607, top_1: 0.498555, top_k: 0.735195, samples/s: 2252.977 1612368523.1858838
train: epoch 25, iter 3500, loss: 3.102808, top_1: 0.498437, top_k: 0.733320, samples/s: 2220.513 1612368534.7147331
train: epoch 25, iter 3600, loss: 3.255783, top_1: 0.490977, top_k: 0.734219, samples/s: 2251.767 1612368546.0836015
train: epoch 25, iter 3700, loss: 3.188087, top_1: 0.489102, top_k: 0.736641, samples/s: 2229.142 1612368557.5678644
train: epoch 25, iter 3800, loss: 2.882738, top_1: 0.495156, top_k: 0.739883, samples/s: 2250.304 1612368568.9440722
train: epoch 25, iter 3900, loss: 3.127880, top_1: 0.502070, top_k: 0.739727, samples/s: 2218.754 1612368580.482087
train: epoch 25, iter 4000, loss: 3.074623, top_1: 0.496016, top_k: 0.737500, samples/s: 2229.176 1612368591.966106
train: epoch 25, iter 4100, loss: 3.045503, top_1: 0.494805, top_k: 0.733359, samples/s: 2242.223 1612368603.3833492
train: epoch 25, iter 4200, loss: 3.213957, top_1: 0.493828, top_k: 0.736875, samples/s: 2238.746 1612368614.8183591
train: epoch 25, iter 4300, loss: 3.143477, top_1: 0.494297, top_k: 0.731563, samples/s: 2242.650 1612368626.233426
train: epoch 25, iter 4400, loss: 3.116218, top_1: 0.490234, top_k: 0.731328, samples/s: 2230.594 1612368637.71018
train: epoch 25, iter 4500, loss: 3.155337, top_1: 0.492422, top_k: 0.735977, samples/s: 2233.292 1612368649.173054
train: epoch 25, iter 4600, loss: 3.219097, top_1: 0.491836, top_k: 0.734453, samples/s: 2233.695 1612368660.6338854
train: epoch 25, iter 4700, loss: 3.118766, top_1: 0.492734, top_k: 0.735742, samples/s: 2252.454 1612368671.999295
train: epoch 25, iter 4800, loss: 3.051981, top_1: 0.495273, top_k: 0.733164, samples/s: 2235.800 1612368683.4493172
train: epoch 25, iter 4900, loss: 3.270398, top_1: 0.491211, top_k: 0.731133, samples/s: 2235.552 1612368694.9006162
train: epoch 25, iter 5000, loss: 2.926901, top_1: 0.494180, top_k: 0.737148, samples/s: 2236.759 1612368706.3457654
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_25.
validation: epoch 25, iter 195, top_1: 0.538381, top_k: 0.787079, samples/s: 2981.748 1612368723.3607006
train: epoch 26, iter 100, loss: 3.367123, top_1: 0.499883, top_k: 0.742461, samples/s: 2231.629 1612368751.4811637
train: epoch 26, iter 200, loss: 3.131843, top_1: 0.506641, top_k: 0.746914, samples/s: 2274.776 1612368762.7350204
train: epoch 26, iter 300, loss: 3.319126, top_1: 0.501289, top_k: 0.741836, samples/s: 2237.953 1612368774.1740692
train: epoch 26, iter 400, loss: 2.817567, top_1: 0.505664, top_k: 0.745625, samples/s: 2238.506 1612368785.6102262
train: epoch 26, iter 500, loss: 3.039294, top_1: 0.507344, top_k: 0.747969, samples/s: 2250.995 1612368796.9830146
train: epoch 26, iter 600, loss: 2.970476, top_1: 0.497266, top_k: 0.738203, samples/s: 2242.444 1612368808.3990397
train: epoch 26, iter 700, loss: 3.071678, top_1: 0.500664, top_k: 0.737852, samples/s: 2257.695 1612368819.7380393
train: epoch 26, iter 800, loss: 3.051754, top_1: 0.498633, top_k: 0.741133, samples/s: 2229.320 1612368831.2214384
train: epoch 26, iter 900, loss: 3.154338, top_1: 0.501602, top_k: 0.739258, samples/s: 2225.842 1612368842.7226353
train: epoch 26, iter 1000, loss: 3.135267, top_1: 0.500664, top_k: 0.742070, samples/s: 2250.198 1612368854.0994062
train: epoch 26, iter 1100, loss: 3.143343, top_1: 0.501094, top_k: 0.743789, samples/s: 2227.092 1612368865.5943038
train: epoch 26, iter 1200, loss: 3.119628, top_1: 0.498086, top_k: 0.738555, samples/s: 2234.467 1612368877.0511303
train: epoch 26, iter 1300, loss: 3.148932, top_1: 0.496406, top_k: 0.739297, samples/s: 2241.734 1612368888.4708083
train: epoch 26, iter 1400, loss: 2.990674, top_1: 0.494023, top_k: 0.737344, samples/s: 2240.532 1612368899.8967135
train: epoch 26, iter 1500, loss: 2.909904, top_1: 0.495391, top_k: 0.733555, samples/s: 2240.555 1612368911.3224652
train: epoch 26, iter 1600, loss: 3.272374, top_1: 0.496992, top_k: 0.738086, samples/s: 2233.783 1612368922.7827847
train: epoch 26, iter 1700, loss: 3.019773, top_1: 0.498906, top_k: 0.736523, samples/s: 2225.347 1612368934.2866096
train: epoch 26, iter 1800, loss: 3.226356, top_1: 0.497773, top_k: 0.736953, samples/s: 2262.589 1612368945.6010883
train: epoch 26, iter 1900, loss: 3.296735, top_1: 0.500273, top_k: 0.738672, samples/s: 2245.148 1612368957.0034535
train: epoch 26, iter 2000, loss: 3.152665, top_1: 0.498789, top_k: 0.737344, samples/s: 2244.248 1612368968.4103854
train: epoch 26, iter 2100, loss: 3.153348, top_1: 0.497422, top_k: 0.736328, samples/s: 2241.109 1612368979.8333604
train: epoch 26, iter 2200, loss: 3.038351, top_1: 0.499258, top_k: 0.738594, samples/s: 2233.511 1612368991.2952492
train: epoch 26, iter 2300, loss: 3.039056, top_1: 0.494414, top_k: 0.736953, samples/s: 2235.786 1612369002.7452323
train: epoch 26, iter 2400, loss: 3.231172, top_1: 0.498047, top_k: 0.737578, samples/s: 2197.131 1612369014.3967497
train: epoch 26, iter 2500, loss: 3.139279, top_1: 0.496836, top_k: 0.739766, samples/s: 2237.810 1612369025.8365078
train: epoch 26, iter 2600, loss: 3.098836, top_1: 0.496875, top_k: 0.736211, samples/s: 2249.892 1612369037.2148788
train: epoch 26, iter 2700, loss: 3.069765, top_1: 0.500859, top_k: 0.738516, samples/s: 2241.174 1612369048.6374886
train: epoch 26, iter 2800, loss: 3.146745, top_1: 0.497070, top_k: 0.737930, samples/s: 2219.881 1612369060.1695662
train: epoch 26, iter 2900, loss: 3.101253, top_1: 0.495781, top_k: 0.734648, samples/s: 2242.638 1612369071.5847127
train: epoch 26, iter 3000, loss: 3.106359, top_1: 0.494883, top_k: 0.738008, samples/s: 2241.666 1612369083.0048125
train: epoch 26, iter 3100, loss: 3.166902, top_1: 0.495664, top_k: 0.736914, samples/s: 2233.402 1612369094.467109
train: epoch 26, iter 3200, loss: 3.157670, top_1: 0.494531, top_k: 0.733711, samples/s: 2241.040 1612369105.8903806
train: epoch 26, iter 3300, loss: 3.114422, top_1: 0.488086, top_k: 0.733086, samples/s: 2226.021 1612369117.3907714
train: epoch 26, iter 3400, loss: 3.232786, top_1: 0.498984, top_k: 0.733242, samples/s: 2250.495 1612369128.7659907
train: epoch 26, iter 3500, loss: 3.143566, top_1: 0.497891, top_k: 0.736055, samples/s: 2232.232 1612369140.2343752
train: epoch 26, iter 3600, loss: 3.241326, top_1: 0.489336, top_k: 0.731875, samples/s: 2257.171 1612369151.5760095
train: epoch 26, iter 3700, loss: 3.281215, top_1: 0.500508, top_k: 0.738711, samples/s: 2175.616 1612369163.3428288
train: epoch 26, iter 3800, loss: 2.977693, top_1: 0.500547, top_k: 0.736836, samples/s: 2261.945 1612369174.6604605
train: epoch 26, iter 3900, loss: 3.024276, top_1: 0.500000, top_k: 0.734492, samples/s: 2235.611 1612369186.1114664
train: epoch 26, iter 4000, loss: 3.392558, top_1: 0.498320, top_k: 0.732266, samples/s: 2235.327 1612369197.5639381
train: epoch 26, iter 4100, loss: 3.233325, top_1: 0.496211, top_k: 0.734023, samples/s: 2227.975 1612369209.0542135
train: epoch 26, iter 4200, loss: 3.210716, top_1: 0.495781, top_k: 0.734922, samples/s: 2253.084 1612369220.4164143
train: epoch 26, iter 4300, loss: 2.857265, top_1: 0.495469, top_k: 0.736602, samples/s: 2237.452 1612369231.8579607
train: epoch 26, iter 4400, loss: 2.955477, top_1: 0.499258, top_k: 0.740313, samples/s: 2249.233 1612369243.2396355
train: epoch 26, iter 4500, loss: 3.302292, top_1: 0.491914, top_k: 0.733125, samples/s: 2246.110 1612369254.6371038
train: epoch 26, iter 4600, loss: 3.238361, top_1: 0.495859, top_k: 0.734766, samples/s: 2237.661 1612369266.0776975
train: epoch 26, iter 4700, loss: 3.260419, top_1: 0.488633, top_k: 0.730156, samples/s: 2214.065 1612369277.6401246
train: epoch 26, iter 4800, loss: 3.109311, top_1: 0.492461, top_k: 0.736016, samples/s: 2246.296 1612369289.0365975
train: epoch 26, iter 4900, loss: 3.236982, top_1: 0.496953, top_k: 0.734805, samples/s: 2241.197 1612369300.4591076
train: epoch 26, iter 5000, loss: 3.062156, top_1: 0.496641, top_k: 0.737656, samples/s: 2244.021 1612369311.8672035
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_26.
validation: epoch 26, iter 195, top_1: 0.544231, top_k: 0.793570, samples/s: 2894.099 1612369329.4584002
train: epoch 27, iter 100, loss: 2.952907, top_1: 0.510195, top_k: 0.750469, samples/s: 2236.677 1612369357.191717
train: epoch 27, iter 200, loss: 3.095274, top_1: 0.500742, top_k: 0.741016, samples/s: 2256.916 1612369368.53479
train: epoch 27, iter 300, loss: 2.967876, top_1: 0.501406, top_k: 0.741563, samples/s: 2246.069 1612369379.9322968
train: epoch 27, iter 400, loss: 3.212242, top_1: 0.500781, top_k: 0.740234, samples/s: 2248.410 1612369391.3181586
train: epoch 27, iter 500, loss: 3.055718, top_1: 0.504180, top_k: 0.745469, samples/s: 2248.695 1612369402.7024996
train: epoch 27, iter 600, loss: 2.860030, top_1: 0.502617, top_k: 0.743672, samples/s: 2254.501 1612369414.057649
train: epoch 27, iter 700, loss: 2.780078, top_1: 0.499141, top_k: 0.740156, samples/s: 2248.717 1612369425.4418697
train: epoch 27, iter 800, loss: 3.045444, top_1: 0.503789, top_k: 0.736406, samples/s: 2239.970 1612369436.8706021
train: epoch 27, iter 900, loss: 3.050894, top_1: 0.502148, top_k: 0.737422, samples/s: 2237.176 1612369448.3135912
train: epoch 27, iter 1000, loss: 3.062548, top_1: 0.502383, top_k: 0.741094, samples/s: 2241.597 1612369459.7339838
train: epoch 27, iter 1100, loss: 3.249141, top_1: 0.499766, top_k: 0.737539, samples/s: 2231.241 1612369471.2074313
train: epoch 27, iter 1200, loss: 2.969332, top_1: 0.503242, top_k: 0.737891, samples/s: 2218.109 1612369482.7487726
train: epoch 27, iter 1300, loss: 3.126765, top_1: 0.499336, top_k: 0.737109, samples/s: 2223.854 1612369494.2603424
train: epoch 27, iter 1400, loss: 2.941660, top_1: 0.500977, top_k: 0.743555, samples/s: 2226.248 1612369505.7594907
train: epoch 27, iter 1500, loss: 3.205846, top_1: 0.498594, top_k: 0.738281, samples/s: 2202.091 1612369517.384801
train: epoch 27, iter 1600, loss: 3.049667, top_1: 0.493633, top_k: 0.731836, samples/s: 2231.821 1612369528.8552592
train: epoch 27, iter 1700, loss: 2.905625, top_1: 0.495312, top_k: 0.738359, samples/s: 2231.154 1612369540.32914
train: epoch 27, iter 1800, loss: 3.185663, top_1: 0.500117, top_k: 0.738672, samples/s: 2229.047 1612369551.8138697
train: epoch 27, iter 1900, loss: 2.898798, top_1: 0.499531, top_k: 0.739805, samples/s: 2211.337 1612369563.3906236
train: epoch 27, iter 2000, loss: 3.072943, top_1: 0.499375, top_k: 0.740234, samples/s: 2199.563 1612369575.0294273
train: epoch 27, iter 2100, loss: 3.088638, top_1: 0.496563, top_k: 0.731133, samples/s: 2233.530 1612369586.4909658
train: epoch 27, iter 2200, loss: 2.993749, top_1: 0.498242, top_k: 0.738477, samples/s: 2199.702 1612369598.1289146
train: epoch 27, iter 2300, loss: 3.230796, top_1: 0.498437, top_k: 0.738437, samples/s: 2187.335 1612369609.832645
train: epoch 27, iter 2400, loss: 3.020716, top_1: 0.492656, top_k: 0.735391, samples/s: 2228.400 1612369621.320678
train: epoch 27, iter 2500, loss: 3.096304, top_1: 0.500117, top_k: 0.741758, samples/s: 2231.863 1612369632.7909346
train: epoch 27, iter 2600, loss: 3.341186, top_1: 0.497070, top_k: 0.739375, samples/s: 2219.637 1612369644.324355
train: epoch 27, iter 2700, loss: 3.190881, top_1: 0.500469, top_k: 0.739414, samples/s: 2230.606 1612369655.8010733
train: epoch 27, iter 2800, loss: 3.013273, top_1: 0.500977, top_k: 0.740586, samples/s: 2214.617 1612369667.3606071
train: epoch 27, iter 2900, loss: 3.187040, top_1: 0.502422, top_k: 0.737422, samples/s: 2216.227 1612369678.9118266
train: epoch 27, iter 3000, loss: 3.257861, top_1: 0.499805, top_k: 0.739375, samples/s: 2195.641 1612369690.571245
train: epoch 27, iter 3100, loss: 3.102674, top_1: 0.504961, top_k: 0.738789, samples/s: 2242.446 1612369701.9876106
train: epoch 27, iter 3200, loss: 3.229045, top_1: 0.493555, top_k: 0.743789, samples/s: 2216.759 1612369713.535727
train: epoch 27, iter 3300, loss: 3.248247, top_1: 0.495742, top_k: 0.738242, samples/s: 2217.404 1612369725.0807135
train: epoch 27, iter 3400, loss: 3.347552, top_1: 0.504023, top_k: 0.743516, samples/s: 2198.342 1612369736.7263055
train: epoch 27, iter 3500, loss: 3.096234, top_1: 0.504219, top_k: 0.743828, samples/s: 2237.240 1612369748.1685665
train: epoch 27, iter 3600, loss: 3.030867, top_1: 0.499102, top_k: 0.737227, samples/s: 2236.704 1612369759.6139998
train: epoch 27, iter 3700, loss: 3.217444, top_1: 0.494063, top_k: 0.732383, samples/s: 2208.476 1612369771.2056801
train: epoch 27, iter 3800, loss: 3.166117, top_1: 0.496680, top_k: 0.734922, samples/s: 2257.724 1612369782.5445626
train: epoch 27, iter 3900, loss: 2.900942, top_1: 0.499375, top_k: 0.738398, samples/s: 2234.859 1612369793.9993925
train: epoch 27, iter 4000, loss: 3.163594, top_1: 0.502461, top_k: 0.739648, samples/s: 2217.946 1612369805.5416229
train: epoch 27, iter 4100, loss: 2.990360, top_1: 0.494063, top_k: 0.737109, samples/s: 2244.115 1612369816.9492261
train: epoch 27, iter 4200, loss: 3.068022, top_1: 0.496875, top_k: 0.736563, samples/s: 2237.401 1612369828.391106
train: epoch 27, iter 4300, loss: 3.197163, top_1: 0.498594, top_k: 0.735547, samples/s: 2235.256 1612369839.8439221
train: epoch 27, iter 4400, loss: 2.995964, top_1: 0.505078, top_k: 0.744453, samples/s: 2237.395 1612369851.2857742
train: epoch 27, iter 4500, loss: 3.219215, top_1: 0.494375, top_k: 0.730977, samples/s: 2239.160 1612369862.718682
train: epoch 27, iter 4600, loss: 3.193217, top_1: 0.497344, top_k: 0.739219, samples/s: 2229.644 1612369874.200291
train: epoch 27, iter 4700, loss: 3.187008, top_1: 0.503984, top_k: 0.742773, samples/s: 2244.644 1612369885.6052995
train: epoch 27, iter 4800, loss: 3.237329, top_1: 0.501602, top_k: 0.735977, samples/s: 2240.683 1612369897.0302904
train: epoch 27, iter 4900, loss: 2.948894, top_1: 0.498672, top_k: 0.738398, samples/s: 2240.466 1612369908.456558
train: epoch 27, iter 5000, loss: 3.065770, top_1: 0.501367, top_k: 0.741094, samples/s: 2247.880 1612369919.844995
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_27.
validation: epoch 27, iter 195, top_1: 0.537380, top_k: 0.784255, samples/s: 2820.546 1612369937.9458506
train: epoch 28, iter 100, loss: 3.147252, top_1: 0.513789, top_k: 0.750938, samples/s: 2244.381 1612369965.6087134
train: epoch 28, iter 200, loss: 3.109880, top_1: 0.510664, top_k: 0.747500, samples/s: 2245.707 1612369977.0082757
train: epoch 28, iter 300, loss: 3.062089, top_1: 0.506055, top_k: 0.748437, samples/s: 2189.703 1612369988.6993136
train: epoch 28, iter 400, loss: 3.184934, top_1: 0.505586, top_k: 0.747109, samples/s: 2281.619 1612369999.9198542
train: epoch 28, iter 500, loss: 3.176200, top_1: 0.502070, top_k: 0.740273, samples/s: 2258.992 1612370011.2518861
train: epoch 28, iter 600, loss: 3.123159, top_1: 0.497188, top_k: 0.739219, samples/s: 2236.183 1612370022.6999593
train: epoch 28, iter 700, loss: 3.137132, top_1: 0.500313, top_k: 0.741680, samples/s: 2243.740 1612370034.1094744
train: epoch 28, iter 800, loss: 3.120137, top_1: 0.507695, top_k: 0.746172, samples/s: 2257.345 1612370045.4502544
train: epoch 28, iter 900, loss: 2.917389, top_1: 0.507148, top_k: 0.741172, samples/s: 2222.606 1612370056.9681957
train: epoch 28, iter 1000, loss: 2.915793, top_1: 0.501055, top_k: 0.743437, samples/s: 2227.377 1612370068.4619386
train: epoch 28, iter 1100, loss: 3.097265, top_1: 0.504297, top_k: 0.746367, samples/s: 2224.432 1612370079.9701443
train: epoch 28, iter 1200, loss: 3.109131, top_1: 0.500391, top_k: 0.737852, samples/s: 2210.682 1612370091.550259
train: epoch 28, iter 1300, loss: 3.043560, top_1: 0.499414, top_k: 0.743242, samples/s: 2228.194 1612370103.0394056
train: epoch 28, iter 1400, loss: 3.061468, top_1: 0.506445, top_k: 0.746602, samples/s: 2226.422 1612370114.5376668
train: epoch 28, iter 1500, loss: 3.055564, top_1: 0.493242, top_k: 0.735938, samples/s: 2219.705 1612370126.0707192
train: epoch 28, iter 1600, loss: 3.343136, top_1: 0.500977, top_k: 0.740781, samples/s: 2210.451 1612370137.6520798
train: epoch 28, iter 1700, loss: 3.020810, top_1: 0.500508, top_k: 0.741875, samples/s: 2237.907 1612370149.0913122
train: epoch 28, iter 1800, loss: 3.153559, top_1: 0.502266, top_k: 0.740195, samples/s: 2214.409 1612370160.651972
train: epoch 28, iter 1900, loss: 3.128132, top_1: 0.503281, top_k: 0.742734, samples/s: 2214.921 1612370172.2103982
train: epoch 28, iter 2000, loss: 3.075170, top_1: 0.501406, top_k: 0.739727, samples/s: 2221.743 1612370183.7324362
train: epoch 28, iter 2100, loss: 3.113955, top_1: 0.493711, top_k: 0.735469, samples/s: 2218.187 1612370195.2733853
train: epoch 28, iter 2200, loss: 2.994569, top_1: 0.504961, top_k: 0.742031, samples/s: 2237.607 1612370206.7141767
train: epoch 28, iter 2300, loss: 3.118763, top_1: 0.501758, top_k: 0.743555, samples/s: 2222.731 1612370218.2323225
train: epoch 28, iter 2400, loss: 3.073157, top_1: 0.502656, top_k: 0.740078, samples/s: 2228.939 1612370229.716822
train: epoch 28, iter 2500, loss: 3.152643, top_1: 0.501172, top_k: 0.737734, samples/s: 2240.941 1612370241.140606
train: epoch 28, iter 2600, loss: 3.135987, top_1: 0.490547, top_k: 0.738125, samples/s: 2246.028 1612370252.5393932
train: epoch 28, iter 2700, loss: 3.121677, top_1: 0.499492, top_k: 0.739766, samples/s: 2229.630 1612370264.0202322
train: epoch 28, iter 2800, loss: 3.360015, top_1: 0.501211, top_k: 0.737500, samples/s: 2254.265 1612370275.376492
train: epoch 28, iter 2900, loss: 3.149739, top_1: 0.493320, top_k: 0.735156, samples/s: 2228.836 1612370286.8626118
train: epoch 28, iter 3000, loss: 3.232367, top_1: 0.500313, top_k: 0.743281, samples/s: 2236.614 1612370298.3082502
train: epoch 28, iter 3100, loss: 2.974834, top_1: 0.498477, top_k: 0.736484, samples/s: 2243.703 1612370309.7178726
train: epoch 28, iter 3200, loss: 3.131092, top_1: 0.500898, top_k: 0.740117, samples/s: 2241.351 1612370321.1395462
train: epoch 28, iter 3300, loss: 3.102409, top_1: 0.498555, top_k: 0.741719, samples/s: 2202.077 1612370332.7649305
train: epoch 28, iter 3400, loss: 3.149806, top_1: 0.504844, top_k: 0.738281, samples/s: 2244.417 1612370344.1710973
train: epoch 28, iter 3500, loss: 3.223488, top_1: 0.508867, top_k: 0.743555, samples/s: 2234.659 1612370355.626922
train: epoch 28, iter 3600, loss: 3.297811, top_1: 0.502109, top_k: 0.742188, samples/s: 2226.331 1612370367.1257603
train: epoch 28, iter 3700, loss: 2.985505, top_1: 0.502891, top_k: 0.739453, samples/s: 2246.907 1612370378.5190673
train: epoch 28, iter 3800, loss: 2.847205, top_1: 0.498125, top_k: 0.737266, samples/s: 2229.767 1612370390.0000877
train: epoch 28, iter 3900, loss: 3.190639, top_1: 0.499141, top_k: 0.736914, samples/s: 2245.224 1612370401.4020712
train: epoch 28, iter 4000, loss: 2.758681, top_1: 0.501367, top_k: 0.739805, samples/s: 2245.560 1612370412.8023674
train: epoch 28, iter 4100, loss: 3.207906, top_1: 0.497070, top_k: 0.738945, samples/s: 2226.873 1612370424.2986484
train: epoch 28, iter 4200, loss: 3.145644, top_1: 0.496328, top_k: 0.741289, samples/s: 2234.084 1612370435.7571225
train: epoch 28, iter 4300, loss: 3.106799, top_1: 0.495703, top_k: 0.734219, samples/s: 2241.745 1612370447.177068
train: epoch 28, iter 4400, loss: 3.078412, top_1: 0.500625, top_k: 0.738984, samples/s: 2231.097 1612370458.6510506
train: epoch 28, iter 4500, loss: 3.197849, top_1: 0.495547, top_k: 0.735117, samples/s: 2230.704 1612370470.1271918
train: epoch 28, iter 4600, loss: 3.012757, top_1: 0.495547, top_k: 0.736563, samples/s: 2258.678 1612370481.4613128
train: epoch 28, iter 4700, loss: 3.142865, top_1: 0.504102, top_k: 0.735820, samples/s: 2230.175 1612370492.9402313
train: epoch 28, iter 4800, loss: 3.203236, top_1: 0.498945, top_k: 0.741016, samples/s: 2207.931 1612370504.5347579
train: epoch 28, iter 4900, loss: 3.197165, top_1: 0.500859, top_k: 0.740234, samples/s: 2246.237 1612370515.932016
train: epoch 28, iter 5000, loss: 3.075752, top_1: 0.503398, top_k: 0.739961, samples/s: 2239.281 1612370527.3638694
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_28.
validation: epoch 28, iter 195, top_1: 0.548838, top_k: 0.793490, samples/s: 2881.159 1612370545.0308297
train: epoch 29, iter 100, loss: 3.023274, top_1: 0.507852, top_k: 0.745703, samples/s: 2217.716 1612370572.9621925
train: epoch 29, iter 200, loss: 3.014580, top_1: 0.513437, top_k: 0.749258, samples/s: 2236.814 1612370584.4070652
train: epoch 29, iter 300, loss: 2.988975, top_1: 0.512578, top_k: 0.744062, samples/s: 2253.879 1612370595.7653534
train: epoch 29, iter 400, loss: 3.188722, top_1: 0.508242, top_k: 0.749805, samples/s: 2253.646 1612370607.124607
train: epoch 29, iter 500, loss: 3.186321, top_1: 0.498320, top_k: 0.738320, samples/s: 2241.472 1612370618.5456493
train: epoch 29, iter 600, loss: 3.163554, top_1: 0.507500, top_k: 0.746797, samples/s: 2264.223 1612370629.8523057
train: epoch 29, iter 700, loss: 3.155215, top_1: 0.505234, top_k: 0.743789, samples/s: 2247.086 1612370641.2445037
train: epoch 29, iter 800, loss: 3.282143, top_1: 0.508555, top_k: 0.747031, samples/s: 2238.354 1612370652.681445
train: epoch 29, iter 900, loss: 3.008179, top_1: 0.508008, top_k: 0.748750, samples/s: 2239.668 1612370664.1117182
train: epoch 29, iter 1000, loss: 3.008434, top_1: 0.504219, top_k: 0.745195, samples/s: 2196.107 1612370675.7687068
train: epoch 29, iter 1100, loss: 3.150052, top_1: 0.506797, top_k: 0.746328, samples/s: 2231.450 1612370687.2410936
train: epoch 29, iter 1200, loss: 3.175795, top_1: 0.496367, top_k: 0.741602, samples/s: 2220.444 1612370698.7703576
train: epoch 29, iter 1300, loss: 3.012078, top_1: 0.507188, top_k: 0.743242, samples/s: 2222.675 1612370710.2879915
train: epoch 29, iter 1400, loss: 3.042953, top_1: 0.501094, top_k: 0.742227, samples/s: 2218.248 1612370721.8286438
train: epoch 29, iter 1500, loss: 3.143937, top_1: 0.497617, top_k: 0.738320, samples/s: 2235.539 1612370733.279969
train: epoch 29, iter 1600, loss: 3.235371, top_1: 0.501836, top_k: 0.745000, samples/s: 2210.451 1612370744.861321
train: epoch 29, iter 1700, loss: 3.075258, top_1: 0.503711, top_k: 0.741328, samples/s: 2235.754 1612370756.311774
train: epoch 29, iter 1800, loss: 3.091943, top_1: 0.502578, top_k: 0.739414, samples/s: 2233.041 1612370767.7758427
train: epoch 29, iter 1900, loss: 3.014355, top_1: 0.512461, top_k: 0.747578, samples/s: 2222.413 1612370779.294806
train: epoch 29, iter 2000, loss: 3.260350, top_1: 0.509141, top_k: 0.742031, samples/s: 2216.122 1612370790.8465338
train: epoch 29, iter 2100, loss: 3.129301, top_1: 0.503125, top_k: 0.741406, samples/s: 2218.345 1612370802.386636
train: epoch 29, iter 2200, loss: 3.147455, top_1: 0.504414, top_k: 0.741914, samples/s: 2214.244 1612370813.94819
train: epoch 29, iter 2300, loss: 3.075251, top_1: 0.507461, top_k: 0.745898, samples/s: 2209.274 1612370825.5356708
train: epoch 29, iter 2400, loss: 3.068781, top_1: 0.505469, top_k: 0.744180, samples/s: 2203.176 1612370837.1552634
train: epoch 29, iter 2500, loss: 3.120689, top_1: 0.503359, top_k: 0.741367, samples/s: 2250.035 1612370848.5328667
train: epoch 29, iter 2600, loss: 3.135511, top_1: 0.501836, top_k: 0.741719, samples/s: 2210.315 1612370860.114932
train: epoch 29, iter 2700, loss: 2.958570, top_1: 0.499531, top_k: 0.738398, samples/s: 2241.141 1612370871.5376952
train: epoch 29, iter 2800, loss: 3.037381, top_1: 0.502656, top_k: 0.741094, samples/s: 2215.680 1612370883.0916808
train: epoch 29, iter 2900, loss: 3.047695, top_1: 0.499766, top_k: 0.738789, samples/s: 2241.754 1612370894.5113525
train: epoch 29, iter 3000, loss: 3.125776, top_1: 0.498672, top_k: 0.741719, samples/s: 2245.754 1612370905.9106984
train: epoch 29, iter 3100, loss: 3.226017, top_1: 0.508711, top_k: 0.746211, samples/s: 2238.227 1612370917.3482828
train: epoch 29, iter 3200, loss: 3.008701, top_1: 0.501250, top_k: 0.738594, samples/s: 2241.221 1612370928.7706325
train: epoch 29, iter 3300, loss: 3.004695, top_1: 0.504922, top_k: 0.737695, samples/s: 2213.217 1612370940.337446
train: epoch 29, iter 3400, loss: 3.410412, top_1: 0.506445, top_k: 0.741836, samples/s: 2248.192 1612370951.7243793
train: epoch 29, iter 3500, loss: 3.010989, top_1: 0.499102, top_k: 0.739570, samples/s: 2232.262 1612370963.1926186
train: epoch 29, iter 3600, loss: 3.078268, top_1: 0.501445, top_k: 0.745664, samples/s: 2244.969 1612370974.595833
train: epoch 29, iter 3700, loss: 3.076835, top_1: 0.497305, top_k: 0.738828, samples/s: 2241.363 1612370986.0174685
train: epoch 29, iter 3800, loss: 3.165313, top_1: 0.496914, top_k: 0.740859, samples/s: 2232.504 1612370997.4844081
train: epoch 29, iter 3900, loss: 3.198272, top_1: 0.502695, top_k: 0.741914, samples/s: 2257.500 1612371008.8243783
train: epoch 29, iter 4000, loss: 3.262297, top_1: 0.503555, top_k: 0.741250, samples/s: 2241.568 1612371020.2449574
train: epoch 29, iter 4100, loss: 2.987165, top_1: 0.494609, top_k: 0.737109, samples/s: 2243.886 1612371031.6537352
train: epoch 29, iter 4200, loss: 3.112933, top_1: 0.501914, top_k: 0.740625, samples/s: 2245.526 1612371043.054199
train: epoch 29, iter 4300, loss: 3.057564, top_1: 0.502617, top_k: 0.742070, samples/s: 2227.871 1612371054.5450518
train: epoch 29, iter 4400, loss: 3.038764, top_1: 0.500430, top_k: 0.740938, samples/s: 2241.681 1612371065.9651349
train: epoch 29, iter 4500, loss: 3.066182, top_1: 0.497930, top_k: 0.742422, samples/s: 2244.046 1612371077.3733203
train: epoch 29, iter 4600, loss: 3.098520, top_1: 0.504023, top_k: 0.740938, samples/s: 2237.784 1612371088.813011
train: epoch 29, iter 4700, loss: 3.068214, top_1: 0.497344, top_k: 0.740508, samples/s: 2205.143 1612371100.4220617
train: epoch 29, iter 4800, loss: 3.269272, top_1: 0.501172, top_k: 0.739414, samples/s: 2247.184 1612371111.8141024
train: epoch 29, iter 4900, loss: 3.066536, top_1: 0.495937, top_k: 0.738398, samples/s: 2209.198 1612371123.4020274
train: epoch 29, iter 5000, loss: 3.061125, top_1: 0.499297, top_k: 0.741094, samples/s: 2247.713 1612371134.7916677
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_29.
validation: epoch 29, iter 195, top_1: 0.552224, top_k: 0.800962, samples/s: 2930.165 1612371152.1209161
train: epoch 30, iter 100, loss: 3.028112, top_1: 0.511172, top_k: 0.748516, samples/s: 2205.840 1612371186.7514553
train: epoch 30, iter 200, loss: 3.027470, top_1: 0.509609, top_k: 0.746211, samples/s: 2258.556 1612371198.086145
train: epoch 30, iter 300, loss: 3.319044, top_1: 0.514727, top_k: 0.750859, samples/s: 2254.885 1612371209.439258
train: epoch 30, iter 400, loss: 2.865624, top_1: 0.509766, top_k: 0.748633, samples/s: 2237.354 1612371220.8816576
train: epoch 30, iter 500, loss: 3.127918, top_1: 0.505703, top_k: 0.745273, samples/s: 2254.896 1612371232.2344234
train: epoch 30, iter 600, loss: 3.248245, top_1: 0.507656, top_k: 0.746758, samples/s: 2233.093 1612371243.698329
train: epoch 30, iter 700, loss: 3.131165, top_1: 0.508867, top_k: 0.749180, samples/s: 2256.531 1612371255.043248
train: epoch 30, iter 800, loss: 2.980957, top_1: 0.503828, top_k: 0.747500, samples/s: 2244.876 1612371266.4469817
train: epoch 30, iter 900, loss: 3.201194, top_1: 0.504844, top_k: 0.746797, samples/s: 2235.470 1612371277.8986592
train: epoch 30, iter 1000, loss: 2.967917, top_1: 0.509727, top_k: 0.748789, samples/s: 2245.049 1612371289.3015642
train: epoch 30, iter 1100, loss: 3.007757, top_1: 0.507031, top_k: 0.743203, samples/s: 2200.429 1612371300.935663
train: epoch 30, iter 1200, loss: 3.177666, top_1: 0.507344, top_k: 0.745000, samples/s: 2265.501 1612371312.2355716
train: epoch 30, iter 1300, loss: 3.097849, top_1: 0.503555, top_k: 0.743984, samples/s: 2206.831 1612371323.8359475
train: epoch 30, iter 1400, loss: 2.954325, top_1: 0.505664, top_k: 0.742617, samples/s: 2214.844 1612371335.394333
train: epoch 30, iter 1500, loss: 2.992449, top_1: 0.504922, top_k: 0.744414, samples/s: 2247.971 1612371346.7823489
train: epoch 30, iter 1600, loss: 3.026625, top_1: 0.503711, top_k: 0.742539, samples/s: 2224.971 1612371358.2881393
train: epoch 30, iter 1700, loss: 3.065188, top_1: 0.503477, top_k: 0.743281, samples/s: 2217.336 1612371369.8334916
train: epoch 30, iter 1800, loss: 3.146554, top_1: 0.504883, top_k: 0.743945, samples/s: 2238.056 1612371381.2719698
train: epoch 30, iter 1900, loss: 3.068454, top_1: 0.502812, top_k: 0.743242, samples/s: 2218.298 1612371392.8123593
train: epoch 30, iter 2000, loss: 3.102934, top_1: 0.502734, top_k: 0.739609, samples/s: 2243.570 1612371404.2227721
train: epoch 30, iter 2100, loss: 2.869619, top_1: 0.509570, top_k: 0.749453, samples/s: 2206.441 1612371415.8251371
train: epoch 30, iter 2200, loss: 3.008676, top_1: 0.513320, top_k: 0.744883, samples/s: 2214.003 1612371427.3880055
train: epoch 30, iter 2300, loss: 3.156662, top_1: 0.509336, top_k: 0.743633, samples/s: 2227.166 1612371438.8824146
train: epoch 30, iter 2400, loss: 3.068645, top_1: 0.502461, top_k: 0.743828, samples/s: 2230.121 1612371450.3615866
train: epoch 30, iter 2500, loss: 2.929408, top_1: 0.504141, top_k: 0.742539, samples/s: 2193.661 1612371462.0315297
train: epoch 30, iter 2600, loss: 3.187345, top_1: 0.499922, top_k: 0.738672, samples/s: 2226.304 1612371473.5303926
train: epoch 30, iter 2700, loss: 3.173168, top_1: 0.497734, top_k: 0.738555, samples/s: 2234.450 1612371484.9874146
train: epoch 30, iter 2800, loss: 3.082489, top_1: 0.498711, top_k: 0.739062, samples/s: 2220.894 1612371496.514313
train: epoch 30, iter 2900, loss: 3.088539, top_1: 0.501953, top_k: 0.741758, samples/s: 2216.956 1612371508.0616057
train: epoch 30, iter 3000, loss: 3.072279, top_1: 0.500898, top_k: 0.741055, samples/s: 2233.313 1612371519.5243945
train: epoch 30, iter 3100, loss: 3.086936, top_1: 0.505938, top_k: 0.745313, samples/s: 2214.921 1612371531.082378
train: epoch 30, iter 3200, loss: 3.098186, top_1: 0.502500, top_k: 0.743477, samples/s: 2220.987 1612371542.608827
train: epoch 30, iter 3300, loss: 3.337246, top_1: 0.498125, top_k: 0.737109, samples/s: 2221.093 1612371554.134657
train: epoch 30, iter 3400, loss: 2.932671, top_1: 0.504727, top_k: 0.740898, samples/s: 2206.691 1612371565.7357202
train: epoch 30, iter 3500, loss: 2.968603, top_1: 0.501875, top_k: 0.741133, samples/s: 2193.735 1612371577.405414
train: epoch 30, iter 3600, loss: 3.192347, top_1: 0.501758, top_k: 0.737969, samples/s: 2216.199 1612371588.9566293
train: epoch 30, iter 3700, loss: 2.973361, top_1: 0.504961, top_k: 0.742617, samples/s: 2236.627 1612371600.4024549
train: epoch 30, iter 3800, loss: 3.240164, top_1: 0.503359, top_k: 0.737773, samples/s: 2238.172 1612371611.8403525
train: epoch 30, iter 3900, loss: 3.044439, top_1: 0.509219, top_k: 0.750273, samples/s: 2234.090 1612371623.299143
train: epoch 30, iter 4000, loss: 3.112965, top_1: 0.506250, top_k: 0.741172, samples/s: 2211.263 1612371634.876349
train: epoch 30, iter 4100, loss: 3.084287, top_1: 0.500000, top_k: 0.739805, samples/s: 2227.080 1612371646.3711264
train: epoch 30, iter 4200, loss: 3.428216, top_1: 0.502695, top_k: 0.742188, samples/s: 2232.066 1612371657.840311
train: epoch 30, iter 4300, loss: 3.055264, top_1: 0.497344, top_k: 0.739141, samples/s: 2219.783 1612371669.3729672
train: epoch 30, iter 4400, loss: 3.244624, top_1: 0.506992, top_k: 0.741289, samples/s: 2226.167 1612371680.872643
train: epoch 30, iter 4500, loss: 2.891787, top_1: 0.500352, top_k: 0.737852, samples/s: 2219.449 1612371692.4069986
train: epoch 30, iter 4600, loss: 3.084706, top_1: 0.503555, top_k: 0.736133, samples/s: 2228.608 1612371703.8940153
train: epoch 30, iter 4700, loss: 3.019748, top_1: 0.501875, top_k: 0.740117, samples/s: 2230.055 1612371715.3734777
train: epoch 30, iter 4800, loss: 3.060028, top_1: 0.499922, top_k: 0.743047, samples/s: 2223.925 1612371726.884658
train: epoch 30, iter 4900, loss: 3.077473, top_1: 0.501172, top_k: 0.738633, samples/s: 2220.107 1612371738.4156482
train: epoch 30, iter 5000, loss: 3.015714, top_1: 0.504570, top_k: 0.742109, samples/s: 2211.819 1612371749.9898193
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_30.
validation: epoch 30, iter 195, top_1: 0.549439, top_k: 0.796615, samples/s: 2899.844 1612371767.4635448
train: epoch 31, iter 100, loss: 3.142287, top_1: 0.507891, top_k: 0.750859, samples/s: 2229.927 1612371794.995761
train: epoch 31, iter 200, loss: 2.873433, top_1: 0.513672, top_k: 0.751250, samples/s: 2262.084 1612371806.3127449
train: epoch 31, iter 300, loss: 3.105302, top_1: 0.506992, top_k: 0.750352, samples/s: 2251.237 1612371817.6843
train: epoch 31, iter 400, loss: 2.982388, top_1: 0.504844, top_k: 0.748008, samples/s: 2251.722 1612371829.0533621
train: epoch 31, iter 500, loss: 3.031813, top_1: 0.513047, top_k: 0.751445, samples/s: 2268.226 1612371840.3398845
train: epoch 31, iter 600, loss: 2.857789, top_1: 0.508555, top_k: 0.747070, samples/s: 2240.120 1612371851.767658
train: epoch 31, iter 700, loss: 3.028617, top_1: 0.500898, top_k: 0.742969, samples/s: 2255.611 1612371863.1172004
train: epoch 31, iter 800, loss: 3.128876, top_1: 0.511758, top_k: 0.749531, samples/s: 2237.703 1612371874.5574367
train: epoch 31, iter 900, loss: 3.086105, top_1: 0.506523, top_k: 0.749062, samples/s: 2237.838 1612371886.0022519
train: epoch 31, iter 1000, loss: 3.078291, top_1: 0.511992, top_k: 0.750469, samples/s: 2215.917 1612371897.5498302
train: epoch 31, iter 1100, loss: 3.110374, top_1: 0.507812, top_k: 0.744336, samples/s: 2197.969 1612371909.196949
train: epoch 31, iter 1200, loss: 2.969883, top_1: 0.503945, top_k: 0.746250, samples/s: 2236.115 1612371920.645393
train: epoch 31, iter 1300, loss: 3.123637, top_1: 0.504531, top_k: 0.741914, samples/s: 2229.976 1612371932.1253629
train: epoch 31, iter 1400, loss: 2.924036, top_1: 0.505781, top_k: 0.745000, samples/s: 2200.666 1612371943.7581568
train: epoch 31, iter 1500, loss: 2.901801, top_1: 0.498594, top_k: 0.741094, samples/s: 2216.719 1612371955.3068142
train: epoch 31, iter 1600, loss: 3.112828, top_1: 0.506523, top_k: 0.742852, samples/s: 2218.691 1612371966.845577
train: epoch 31, iter 1700, loss: 2.874894, top_1: 0.501445, top_k: 0.746992, samples/s: 2230.812 1612371978.3207448
train: epoch 31, iter 1800, loss: 2.929693, top_1: 0.508125, top_k: 0.743398, samples/s: 2209.734 1612371989.9059427
train: epoch 31, iter 1900, loss: 3.126243, top_1: 0.501914, top_k: 0.741172, samples/s: 2161.547 1612372001.7492416
train: epoch 31, iter 2000, loss: 3.084982, top_1: 0.504062, top_k: 0.742227, samples/s: 2212.113 1612372013.3218749
train: epoch 31, iter 2100, loss: 2.951472, top_1: 0.503359, top_k: 0.740508, samples/s: 2240.466 1612372024.7481227
train: epoch 31, iter 2200, loss: 3.024878, top_1: 0.502344, top_k: 0.738867, samples/s: 2232.883 1612372036.2130573
train: epoch 31, iter 2300, loss: 3.045988, top_1: 0.504102, top_k: 0.745156, samples/s: 2183.392 1612372047.938354
train: epoch 31, iter 2400, loss: 2.985624, top_1: 0.507109, top_k: 0.743164, samples/s: 2271.495 1612372059.2080345
train: epoch 31, iter 2500, loss: 2.908646, top_1: 0.506602, top_k: 0.746992, samples/s: 2221.727 1612372070.7306046
train: epoch 31, iter 2600, loss: 2.906905, top_1: 0.510039, top_k: 0.748555, samples/s: 2246.458 1612372082.1263187
train: epoch 31, iter 2700, loss: 3.278306, top_1: 0.503477, top_k: 0.745742, samples/s: 2233.947 1612372093.5858927
train: epoch 31, iter 2800, loss: 3.055018, top_1: 0.505859, top_k: 0.748672, samples/s: 2249.664 1612372104.965334
train: epoch 31, iter 2900, loss: 3.117336, top_1: 0.503203, top_k: 0.742773, samples/s: 2234.233 1612372116.42341
train: epoch 31, iter 3000, loss: 3.016954, top_1: 0.506016, top_k: 0.744219, samples/s: 2212.580 1612372127.9936464
train: epoch 31, iter 3100, loss: 3.173268, top_1: 0.506836, top_k: 0.745352, samples/s: 2263.314 1612372139.3044646
train: epoch 31, iter 3200, loss: 3.354190, top_1: 0.504766, top_k: 0.743164, samples/s: 2236.950 1612372150.748619
train: epoch 31, iter 3300, loss: 3.099646, top_1: 0.499492, top_k: 0.740781, samples/s: 2235.661 1612372162.1993718
train: epoch 31, iter 3400, loss: 2.954823, top_1: 0.509453, top_k: 0.743594, samples/s: 2239.510 1612372173.6304505
train: epoch 31, iter 3500, loss: 3.040874, top_1: 0.502031, top_k: 0.740039, samples/s: 2239.903 1612372185.0595229
train: epoch 31, iter 3600, loss: 3.063558, top_1: 0.509805, top_k: 0.745313, samples/s: 2242.341 1612372196.4761722
train: epoch 31, iter 3700, loss: 3.114796, top_1: 0.507305, top_k: 0.744102, samples/s: 2239.236 1612372207.9086478
train: epoch 31, iter 3800, loss: 3.200027, top_1: 0.501367, top_k: 0.737930, samples/s: 2203.855 1612372219.52467
train: epoch 31, iter 3900, loss: 2.992282, top_1: 0.504648, top_k: 0.741250, samples/s: 2242.853 1612372230.9386766
train: epoch 31, iter 4000, loss: 3.092692, top_1: 0.508203, top_k: 0.743555, samples/s: 2222.066 1612372242.4595466
train: epoch 31, iter 4100, loss: 3.131497, top_1: 0.501523, top_k: 0.748164, samples/s: 2241.111 1612372253.8824964
train: epoch 31, iter 4200, loss: 3.094816, top_1: 0.498398, top_k: 0.738086, samples/s: 2242.467 1612372265.2984827
train: epoch 31, iter 4300, loss: 2.946342, top_1: 0.507344, top_k: 0.741563, samples/s: 2228.026 1612372276.7884605
train: epoch 31, iter 4400, loss: 3.045977, top_1: 0.500234, top_k: 0.738789, samples/s: 2268.475 1612372288.073492
train: epoch 31, iter 4500, loss: 3.055310, top_1: 0.501875, top_k: 0.744023, samples/s: 2244.430 1612372299.4795246
train: epoch 31, iter 4600, loss: 3.000326, top_1: 0.510000, top_k: 0.748516, samples/s: 2234.056 1612372310.9384549
train: epoch 31, iter 4700, loss: 3.170039, top_1: 0.500469, top_k: 0.739062, samples/s: 2243.352 1612372322.3503451
train: epoch 31, iter 4800, loss: 2.860751, top_1: 0.513867, top_k: 0.743398, samples/s: 2244.480 1612372333.7557552
train: epoch 31, iter 4900, loss: 3.086627, top_1: 0.504219, top_k: 0.744062, samples/s: 2238.149 1612372345.1937864
train: epoch 31, iter 5000, loss: 3.027706, top_1: 0.507930, top_k: 0.744492, samples/s: 2248.255 1612372356.5807376
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_31.
validation: epoch 31, iter 195, top_1: 0.550601, top_k: 0.796675, samples/s: 2958.460 1612372373.7925508
train: epoch 32, iter 100, loss: 2.933966, top_1: 0.518359, top_k: 0.753437, samples/s: 2249.707 1612372401.4771383
train: epoch 32, iter 200, loss: 2.955608, top_1: 0.509023, top_k: 0.747305, samples/s: 2246.203 1612372412.8742619
train: epoch 32, iter 300, loss: 3.028701, top_1: 0.520234, top_k: 0.755078, samples/s: 2257.737 1612372424.2129378
train: epoch 32, iter 400, loss: 3.221015, top_1: 0.516172, top_k: 0.751211, samples/s: 2253.758 1612372435.5717885
train: epoch 32, iter 500, loss: 2.961263, top_1: 0.513555, top_k: 0.748242, samples/s: 2249.167 1612372446.95372
train: epoch 32, iter 600, loss: 2.847356, top_1: 0.508711, top_k: 0.745664, samples/s: 2252.636 1612372458.3182003
train: epoch 32, iter 700, loss: 2.977590, top_1: 0.515469, top_k: 0.744297, samples/s: 2251.856 1612372469.6867008
train: epoch 32, iter 800, loss: 3.175313, top_1: 0.508945, top_k: 0.751719, samples/s: 2243.242 1612372481.0987308
train: epoch 32, iter 900, loss: 3.000710, top_1: 0.506172, top_k: 0.744258, samples/s: 2219.299 1612372492.6338487
train: epoch 32, iter 1000, loss: 3.097230, top_1: 0.508359, top_k: 0.746914, samples/s: 2234.330 1612372504.0914145
train: epoch 32, iter 1100, loss: 3.034046, top_1: 0.506016, top_k: 0.745039, samples/s: 2233.262 1612372515.5544405
train: epoch 32, iter 1200, loss: 3.178463, top_1: 0.509961, top_k: 0.749687, samples/s: 2220.801 1612372527.0818253
train: epoch 32, iter 1300, loss: 2.966712, top_1: 0.514648, top_k: 0.749062, samples/s: 2237.380 1612372538.5243623
train: epoch 32, iter 1400, loss: 3.004211, top_1: 0.500156, top_k: 0.743711, samples/s: 2217.900 1612372550.0662396
train: epoch 32, iter 1500, loss: 3.187295, top_1: 0.510898, top_k: 0.744961, samples/s: 2243.107 1612372561.478955
train: epoch 32, iter 1600, loss: 3.075846, top_1: 0.512500, top_k: 0.746367, samples/s: 2201.102 1612372573.1099737
train: epoch 32, iter 1700, loss: 2.935638, top_1: 0.509219, top_k: 0.745391, samples/s: 2233.578 1612372584.5709517
train: epoch 32, iter 1800, loss: 3.058619, top_1: 0.511094, top_k: 0.746367, samples/s: 2209.631 1612372596.1566792
train: epoch 32, iter 1900, loss: 3.119712, top_1: 0.508477, top_k: 0.741289, samples/s: 2145.078 1612372608.0908673
train: epoch 32, iter 2000, loss: 3.223297, top_1: 0.507305, top_k: 0.746719, samples/s: 2233.587 1612372619.5522568
train: epoch 32, iter 2100, loss: 3.140880, top_1: 0.510352, top_k: 0.744023, samples/s: 2219.464 1612372631.0866008
train: epoch 32, iter 2200, loss: 2.966603, top_1: 0.507461, top_k: 0.742852, samples/s: 2227.253 1612372642.5805776
train: epoch 32, iter 2300, loss: 3.089975, top_1: 0.508711, top_k: 0.746602, samples/s: 2227.223 1612372654.0747197
train: epoch 32, iter 2400, loss: 3.018075, top_1: 0.504180, top_k: 0.746953, samples/s: 2235.731 1612372665.5251303
train: epoch 32, iter 2500, loss: 2.979262, top_1: 0.505781, top_k: 0.743086, samples/s: 2225.781 1612372677.026692
train: epoch 32, iter 2600, loss: 3.088223, top_1: 0.504648, top_k: 0.745078, samples/s: 2215.576 1612372688.5812771
train: epoch 32, iter 2700, loss: 3.081921, top_1: 0.505781, top_k: 0.747539, samples/s: 2223.183 1612372700.0962832
train: epoch 32, iter 2800, loss: 2.998348, top_1: 0.503398, top_k: 0.746680, samples/s: 2223.582 1612372711.6092112
train: epoch 32, iter 2900, loss: 2.980183, top_1: 0.505664, top_k: 0.743750, samples/s: 2226.152 1612372723.1089199
train: epoch 32, iter 3000, loss: 3.077129, top_1: 0.505430, top_k: 0.747812, samples/s: 2217.023 1612372734.6559143
train: epoch 32, iter 3100, loss: 3.165332, top_1: 0.505234, top_k: 0.746094, samples/s: 2227.518 1612372746.1484993
train: epoch 32, iter 3200, loss: 3.189490, top_1: 0.504531, top_k: 0.745156, samples/s: 2236.176 1612372757.5966039
train: epoch 32, iter 3300, loss: 3.056209, top_1: 0.503437, top_k: 0.743320, samples/s: 2214.985 1612372769.1543086
train: epoch 32, iter 3400, loss: 3.161804, top_1: 0.502461, top_k: 0.743867, samples/s: 2214.834 1612372780.7126777
train: epoch 32, iter 3500, loss: 3.192039, top_1: 0.508008, top_k: 0.745586, samples/s: 2215.929 1612372792.265423
train: epoch 32, iter 3600, loss: 3.080180, top_1: 0.507344, top_k: 0.747500, samples/s: 2224.887 1612372803.7716436
train: epoch 32, iter 3700, loss: 3.118269, top_1: 0.508594, top_k: 0.750039, samples/s: 2220.608 1612372815.2999673
train: epoch 32, iter 3800, loss: 2.795462, top_1: 0.508047, top_k: 0.745820, samples/s: 2216.242 1612372826.8510532
train: epoch 32, iter 3900, loss: 3.047357, top_1: 0.504961, top_k: 0.738086, samples/s: 2234.168 1612372838.3094716
train: epoch 32, iter 4000, loss: 3.106676, top_1: 0.512773, top_k: 0.748594, samples/s: 2231.224 1612372849.782974
train: epoch 32, iter 4100, loss: 3.175146, top_1: 0.498594, top_k: 0.738008, samples/s: 2212.299 1612372861.3546877
train: epoch 32, iter 4200, loss: 3.009274, top_1: 0.512539, top_k: 0.747344, samples/s: 2202.107 1612372872.9798965
train: epoch 32, iter 4300, loss: 3.089549, top_1: 0.507383, top_k: 0.744727, samples/s: 2188.402 1612372884.6779084
train: epoch 32, iter 4400, loss: 3.079072, top_1: 0.503906, top_k: 0.741758, samples/s: 2236.886 1612372896.1223495
train: epoch 32, iter 4500, loss: 3.176095, top_1: 0.508477, top_k: 0.746875, samples/s: 2217.680 1612372907.6660135
train: epoch 32, iter 4600, loss: 3.065725, top_1: 0.505117, top_k: 0.742344, samples/s: 2214.050 1612372919.228556
train: epoch 32, iter 4700, loss: 2.835585, top_1: 0.499609, top_k: 0.741484, samples/s: 2232.239 1612372930.6968346
train: epoch 32, iter 4800, loss: 3.023216, top_1: 0.506914, top_k: 0.748789, samples/s: 2238.717 1612372942.1319835
train: epoch 32, iter 4900, loss: 3.232894, top_1: 0.500039, top_k: 0.738398, samples/s: 2220.966 1612372953.658443
train: epoch 32, iter 5000, loss: 3.018493, top_1: 0.502930, top_k: 0.743242, samples/s: 2222.978 1612372965.1745322
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_32.
validation: epoch 32, iter 195, top_1: 0.559535, top_k: 0.803285, samples/s: 2902.377 1612372982.7280202
train: epoch 33, iter 100, loss: 3.000591, top_1: 0.513437, top_k: 0.754570, samples/s: 2230.194 1612373010.6069345
train: epoch 33, iter 200, loss: 2.949242, top_1: 0.515039, top_k: 0.752305, samples/s: 2265.055 1612373021.9091272
train: epoch 33, iter 300, loss: 3.013793, top_1: 0.509687, top_k: 0.745352, samples/s: 2246.042 1612373033.3069575
train: epoch 33, iter 400, loss: 2.879994, top_1: 0.518828, top_k: 0.753086, samples/s: 2205.621 1612373044.913539
train: epoch 33, iter 500, loss: 3.110608, top_1: 0.513516, top_k: 0.753203, samples/s: 2261.706 1612373056.2324762
train: epoch 33, iter 600, loss: 3.058087, top_1: 0.514062, top_k: 0.748359, samples/s: 2255.938 1612373067.580322
train: epoch 33, iter 700, loss: 3.136818, top_1: 0.508203, top_k: 0.745156, samples/s: 2246.989 1612373078.9737039
train: epoch 33, iter 800, loss: 3.110864, top_1: 0.515430, top_k: 0.748125, samples/s: 2233.572 1612373090.4348645
train: epoch 33, iter 900, loss: 2.997447, top_1: 0.508945, top_k: 0.744023, samples/s: 2242.708 1612373101.8495824
train: epoch 33, iter 1000, loss: 3.137848, top_1: 0.510820, top_k: 0.748242, samples/s: 2231.617 1612373113.32106
train: epoch 33, iter 1100, loss: 2.999004, top_1: 0.515039, top_k: 0.752773, samples/s: 2223.808 1612373124.8328521
train: epoch 33, iter 1200, loss: 3.094087, top_1: 0.510898, top_k: 0.744219, samples/s: 2221.314 1612373136.357561
train: epoch 33, iter 1300, loss: 3.076355, top_1: 0.508867, top_k: 0.747773, samples/s: 2231.853 1612373147.8278458
train: epoch 33, iter 1400, loss: 3.056909, top_1: 0.508906, top_k: 0.743672, samples/s: 2208.461 1612373159.4199839
train: epoch 33, iter 1500, loss: 2.945168, top_1: 0.507852, top_k: 0.748828, samples/s: 2223.194 1612373170.9345863
train: epoch 33, iter 1600, loss: 3.003497, top_1: 0.504453, top_k: 0.746367, samples/s: 2224.902 1612373182.4407709
train: epoch 33, iter 1700, loss: 2.973974, top_1: 0.512109, top_k: 0.749844, samples/s: 2231.602 1612373193.9123876
train: epoch 33, iter 1800, loss: 3.206150, top_1: 0.505000, top_k: 0.746133, samples/s: 2226.032 1612373205.4130871
train: epoch 33, iter 1900, loss: 3.057252, top_1: 0.510508, top_k: 0.747852, samples/s: 2218.963 1612373216.9495347
train: epoch 33, iter 2000, loss: 2.819912, top_1: 0.507383, top_k: 0.745898, samples/s: 2220.427 1612373228.4790134
train: epoch 33, iter 2100, loss: 3.068789, top_1: 0.502266, top_k: 0.741758, samples/s: 2225.036 1612373239.984295
train: epoch 33, iter 2200, loss: 2.931588, top_1: 0.508945, top_k: 0.745938, samples/s: 2234.277 1612373251.4421854
train: epoch 33, iter 2300, loss: 2.821507, top_1: 0.510117, top_k: 0.747930, samples/s: 2219.738 1612373262.9749923
train: epoch 33, iter 2400, loss: 3.157316, top_1: 0.504062, top_k: 0.741250, samples/s: 2221.768 1612373274.4973583
train: epoch 33, iter 2500, loss: 2.918410, top_1: 0.509687, top_k: 0.746211, samples/s: 2212.547 1612373286.0677283
train: epoch 33, iter 2600, loss: 3.171566, top_1: 0.505547, top_k: 0.746328, samples/s: 2219.323 1612373297.6028423
train: epoch 33, iter 2700, loss: 3.057066, top_1: 0.511250, top_k: 0.751523, samples/s: 2225.578 1612373309.10541
train: epoch 33, iter 2800, loss: 3.152857, top_1: 0.510078, top_k: 0.744961, samples/s: 2242.134 1612373320.523231
train: epoch 33, iter 2900, loss: 2.835847, top_1: 0.505703, top_k: 0.744453, samples/s: 2241.759 1612373331.9427824
train: epoch 33, iter 3000, loss: 3.167548, top_1: 0.502891, top_k: 0.745273, samples/s: 2224.359 1612373343.451781
train: epoch 33, iter 3100, loss: 2.959018, top_1: 0.513125, top_k: 0.747148, samples/s: 2243.083 1612373354.864508
train: epoch 33, iter 3200, loss: 2.953274, top_1: 0.509844, top_k: 0.744258, samples/s: 2241.913 1612373366.283388
train: epoch 33, iter 3300, loss: 3.227007, top_1: 0.507852, top_k: 0.748945, samples/s: 2249.810 1612373377.6621115
train: epoch 33, iter 3400, loss: 3.028945, top_1: 0.514531, top_k: 0.747305, samples/s: 2226.029 1612373389.1623785
train: epoch 33, iter 3500, loss: 3.067374, top_1: 0.507500, top_k: 0.744258, samples/s: 2237.382 1612373400.6044884
train: epoch 33, iter 3600, loss: 2.983450, top_1: 0.503750, top_k: 0.744023, samples/s: 2240.689 1612373412.0294046
train: epoch 33, iter 3700, loss: 3.151692, top_1: 0.511367, top_k: 0.746914, samples/s: 2239.211 1612373423.4619818
train: epoch 33, iter 3800, loss: 2.984644, top_1: 0.505664, top_k: 0.746797, samples/s: 2244.074 1612373434.8698266
train: epoch 33, iter 3900, loss: 3.375709, top_1: 0.514375, top_k: 0.746094, samples/s: 2240.787 1612373446.2944236
train: epoch 33, iter 4000, loss: 3.220491, top_1: 0.514687, top_k: 0.751914, samples/s: 2213.399 1612373457.8602793
train: epoch 33, iter 4100, loss: 2.840465, top_1: 0.513047, top_k: 0.746445, samples/s: 2265.015 1612373469.1626365
train: epoch 33, iter 4200, loss: 2.995354, top_1: 0.508516, top_k: 0.744297, samples/s: 2234.404 1612373480.6199267
train: epoch 33, iter 4300, loss: 3.163824, top_1: 0.505898, top_k: 0.741133, samples/s: 2244.230 1612373492.0268476
train: epoch 33, iter 4400, loss: 3.141395, top_1: 0.513164, top_k: 0.749414, samples/s: 2247.085 1612373503.4194584
train: epoch 33, iter 4500, loss: 3.234566, top_1: 0.508477, top_k: 0.746406, samples/s: 2238.523 1612373514.8555014
train: epoch 33, iter 4600, loss: 3.186035, top_1: 0.498555, top_k: 0.743672, samples/s: 2238.228 1612373526.293232
train: epoch 33, iter 4700, loss: 2.991637, top_1: 0.511328, top_k: 0.745391, samples/s: 2245.829 1612373537.6920583
train: epoch 33, iter 4800, loss: 2.939128, top_1: 0.510156, top_k: 0.745078, samples/s: 2245.363 1612373549.093372
train: epoch 33, iter 4900, loss: 3.194981, top_1: 0.509844, top_k: 0.748906, samples/s: 2241.991 1612373560.5118055
train: epoch 33, iter 5000, loss: 2.872787, top_1: 0.510312, top_k: 0.742773, samples/s: 2241.152 1612373571.9344263
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_33.
validation: epoch 33, iter 195, top_1: 0.554868, top_k: 0.798317, samples/s: 2914.290 1612373589.4161353
train: epoch 34, iter 100, loss: 3.226756, top_1: 0.514805, top_k: 0.753633, samples/s: 2246.690 1612373617.0485058
train: epoch 34, iter 200, loss: 2.861491, top_1: 0.517344, top_k: 0.753086, samples/s: 2249.601 1612373628.428618
train: epoch 34, iter 300, loss: 3.092660, top_1: 0.518555, top_k: 0.753008, samples/s: 2241.022 1612373639.8516772
train: epoch 34, iter 400, loss: 3.080267, top_1: 0.515547, top_k: 0.752148, samples/s: 2261.284 1612373651.172647
train: epoch 34, iter 500, loss: 3.245827, top_1: 0.509687, top_k: 0.749531, samples/s: 2253.169 1612373662.5344365
train: epoch 34, iter 600, loss: 3.108619, top_1: 0.510938, top_k: 0.749961, samples/s: 2249.074 1612373673.9169402
train: epoch 34, iter 700, loss: 2.850645, top_1: 0.515391, top_k: 0.753984, samples/s: 2246.461 1612373685.3126278
train: epoch 34, iter 800, loss: 3.142296, top_1: 0.522578, top_k: 0.758086, samples/s: 2251.674 1612373696.6819181
train: epoch 34, iter 900, loss: 3.073806, top_1: 0.516875, top_k: 0.753750, samples/s: 2240.622 1612373708.1072989
train: epoch 34, iter 1000, loss: 3.010318, top_1: 0.513359, top_k: 0.749883, samples/s: 2205.524 1612373719.7146356
train: epoch 34, iter 1100, loss: 3.172472, top_1: 0.516211, top_k: 0.751094, samples/s: 2234.339 1612373731.1720374
train: epoch 34, iter 1200, loss: 3.082263, top_1: 0.514062, top_k: 0.748828, samples/s: 2159.827 1612373743.0249114
train: epoch 34, iter 1300, loss: 2.997383, top_1: 0.516133, top_k: 0.751328, samples/s: 2264.279 1612373754.3308723
train: epoch 34, iter 1400, loss: 2.930673, top_1: 0.506797, top_k: 0.748164, samples/s: 2199.795 1612373765.9683213
train: epoch 34, iter 1500, loss: 3.157205, top_1: 0.514297, top_k: 0.751484, samples/s: 2225.557 1612373777.4710572
train: epoch 34, iter 1600, loss: 3.071406, top_1: 0.509531, top_k: 0.748125, samples/s: 2217.051 1612373789.0179312
train: epoch 34, iter 1700, loss: 3.008581, top_1: 0.507617, top_k: 0.744922, samples/s: 2230.195 1612373800.4967794
train: epoch 34, iter 1800, loss: 3.134403, top_1: 0.514453, top_k: 0.750313, samples/s: 2231.896 1612373811.9668171
train: epoch 34, iter 1900, loss: 3.102217, top_1: 0.511992, top_k: 0.747422, samples/s: 2196.397 1612373823.6222935
train: epoch 34, iter 2000, loss: 3.022852, top_1: 0.506016, top_k: 0.746172, samples/s: 2225.511 1612373835.1253736
train: epoch 34, iter 2100, loss: 3.155815, top_1: 0.509336, top_k: 0.747578, samples/s: 2204.501 1612373846.7378917
train: epoch 34, iter 2200, loss: 2.947031, top_1: 0.510273, top_k: 0.746289, samples/s: 2234.150 1612373858.1964495
train: epoch 34, iter 2300, loss: 3.117791, top_1: 0.508398, top_k: 0.746328, samples/s: 2223.883 1612373869.7078097
train: epoch 34, iter 2400, loss: 3.043336, top_1: 0.512031, top_k: 0.753047, samples/s: 2232.310 1612373881.175692
train: epoch 34, iter 2500, loss: 3.103021, top_1: 0.510898, top_k: 0.749805, samples/s: 2230.219 1612373892.6543803
train: epoch 34, iter 2600, loss: 3.149594, top_1: 0.505898, top_k: 0.744766, samples/s: 2219.413 1612373904.1890197
train: epoch 34, iter 2700, loss: 3.160407, top_1: 0.508047, top_k: 0.745547, samples/s: 2231.649 1612373915.6603158
train: epoch 34, iter 2800, loss: 3.148511, top_1: 0.511055, top_k: 0.750781, samples/s: 2217.177 1612373927.2077067
train: epoch 34, iter 2900, loss: 2.859398, top_1: 0.502266, top_k: 0.742930, samples/s: 2229.366 1612373938.6896842
train: epoch 34, iter 3000, loss: 3.096465, top_1: 0.505508, top_k: 0.745117, samples/s: 2221.018 1612373950.2162027
train: epoch 34, iter 3100, loss: 3.062244, top_1: 0.509023, top_k: 0.747773, samples/s: 2210.835 1612373961.7953038
train: epoch 34, iter 3200, loss: 3.015234, top_1: 0.513750, top_k: 0.747656, samples/s: 2211.016 1612373973.3735778
train: epoch 34, iter 3300, loss: 3.205563, top_1: 0.511875, top_k: 0.747734, samples/s: 2227.606 1612373984.8657374
train: epoch 34, iter 3400, loss: 3.103993, top_1: 0.510156, top_k: 0.746406, samples/s: 2206.914 1612373996.4657164
train: epoch 34, iter 3500, loss: 2.849577, top_1: 0.506680, top_k: 0.745078, samples/s: 2228.925 1612374007.9510083
train: epoch 34, iter 3600, loss: 2.836687, top_1: 0.509062, top_k: 0.743008, samples/s: 2217.708 1612374019.4944613
train: epoch 34, iter 3700, loss: 3.049221, top_1: 0.507617, top_k: 0.748281, samples/s: 2232.151 1612374030.9632823
train: epoch 34, iter 3800, loss: 3.028350, top_1: 0.506875, top_k: 0.746836, samples/s: 2211.361 1612374042.5398352
train: epoch 34, iter 3900, loss: 3.253709, top_1: 0.507656, top_k: 0.744375, samples/s: 2235.168 1612374053.9933612
train: epoch 34, iter 4000, loss: 2.973364, top_1: 0.503828, top_k: 0.739180, samples/s: 2248.458 1612374065.3786275
train: epoch 34, iter 4100, loss: 3.016423, top_1: 0.511289, top_k: 0.752031, samples/s: 2235.873 1612374076.8282669
train: epoch 34, iter 4200, loss: 3.034473, top_1: 0.508203, top_k: 0.743164, samples/s: 2246.704 1612374088.2227676
train: epoch 34, iter 4300, loss: 3.043683, top_1: 0.506680, top_k: 0.744844, samples/s: 2220.717 1612374099.750586
train: epoch 34, iter 4400, loss: 3.516509, top_1: 0.502227, top_k: 0.741719, samples/s: 2243.385 1612374111.1619058
train: epoch 34, iter 4500, loss: 3.108680, top_1: 0.510234, top_k: 0.750234, samples/s: 2198.744 1612374122.8050642
train: epoch 34, iter 4600, loss: 3.213094, top_1: 0.506016, top_k: 0.746094, samples/s: 2241.760 1612374134.224523
train: epoch 34, iter 4700, loss: 3.069038, top_1: 0.509180, top_k: 0.746602, samples/s: 2238.703 1612374145.6596754
train: epoch 34, iter 4800, loss: 3.292447, top_1: 0.507891, top_k: 0.749102, samples/s: 2237.050 1612374157.1033556
train: epoch 34, iter 4900, loss: 2.884160, top_1: 0.508516, top_k: 0.747578, samples/s: 2221.501 1612374168.627184
train: epoch 34, iter 5000, loss: 3.203228, top_1: 0.510117, top_k: 0.745078, samples/s: 2256.682 1612374179.9712245
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_34.
validation: epoch 34, iter 195, top_1: 0.558033, top_k: 0.802424, samples/s: 2915.249 1612374197.4234412
train: epoch 35, iter 100, loss: 3.077970, top_1: 0.526289, top_k: 0.762266, samples/s: 2232.676 1612374224.9162734
train: epoch 35, iter 200, loss: 3.065887, top_1: 0.521250, top_k: 0.752930, samples/s: 2230.084 1612374236.3955896
train: epoch 35, iter 300, loss: 3.166015, top_1: 0.515508, top_k: 0.755352, samples/s: 2266.701 1612374247.6895416
train: epoch 35, iter 400, loss: 3.140010, top_1: 0.513789, top_k: 0.753672, samples/s: 2256.456 1612374259.034762
train: epoch 35, iter 500, loss: 3.305609, top_1: 0.517305, top_k: 0.751406, samples/s: 2240.182 1612374270.4624448
train: epoch 35, iter 600, loss: 2.949576, top_1: 0.514883, top_k: 0.749258, samples/s: 2250.813 1612374281.8360782
train: epoch 35, iter 700, loss: 2.956359, top_1: 0.512734, top_k: 0.750469, samples/s: 2234.948 1612374293.2904832
train: epoch 35, iter 800, loss: 3.097294, top_1: 0.514648, top_k: 0.747461, samples/s: 2253.270 1612374304.6517394
train: epoch 35, iter 900, loss: 3.116189, top_1: 0.513906, top_k: 0.750313, samples/s: 2241.689 1612374316.0717256
train: epoch 35, iter 1000, loss: 3.210995, top_1: 0.513125, top_k: 0.753633, samples/s: 2232.637 1612374327.5379632
train: epoch 35, iter 1100, loss: 2.945964, top_1: 0.517031, top_k: 0.758750, samples/s: 2221.381 1612374339.062385
train: epoch 35, iter 1200, loss: 3.040752, top_1: 0.513047, top_k: 0.750859, samples/s: 2208.241 1612374350.6552699
train: epoch 35, iter 1300, loss: 3.000042, top_1: 0.519648, top_k: 0.748711, samples/s: 2241.981 1612374362.0737407
train: epoch 35, iter 1400, loss: 3.012066, top_1: 0.512148, top_k: 0.749258, samples/s: 2213.539 1612374373.6389258
train: epoch 35, iter 1500, loss: 3.112134, top_1: 0.520352, top_k: 0.754141, samples/s: 2224.497 1612374385.1471574
train: epoch 35, iter 1600, loss: 2.938696, top_1: 0.513984, top_k: 0.754062, samples/s: 2230.233 1612374396.6258276
train: epoch 35, iter 1700, loss: 3.040106, top_1: 0.512383, top_k: 0.748789, samples/s: 2224.351 1612374408.1347933
train: epoch 35, iter 1800, loss: 3.143300, top_1: 0.512109, top_k: 0.749648, samples/s: 2217.206 1612374419.6808674
train: epoch 35, iter 1900, loss: 3.030816, top_1: 0.505117, top_k: 0.744570, samples/s: 2231.354 1612374431.1536937
train: epoch 35, iter 2000, loss: 3.130692, top_1: 0.509102, top_k: 0.747070, samples/s: 2229.661 1612374442.63524
train: epoch 35, iter 2100, loss: 2.995296, top_1: 0.514570, top_k: 0.752891, samples/s: 2216.042 1612374454.1873696
train: epoch 35, iter 2200, loss: 2.954806, top_1: 0.510039, top_k: 0.746992, samples/s: 2200.721 1612374465.819931
train: epoch 35, iter 2300, loss: 3.068308, top_1: 0.510234, top_k: 0.744687, samples/s: 2190.743 1612374477.5055559
train: epoch 35, iter 2400, loss: 2.962981, top_1: 0.511055, top_k: 0.748242, samples/s: 2212.865 1612374489.0741534
train: epoch 35, iter 2500, loss: 3.043124, top_1: 0.514844, top_k: 0.748555, samples/s: 2231.329 1612374500.547135
train: epoch 35, iter 2600, loss: 3.027315, top_1: 0.514414, top_k: 0.749687, samples/s: 2220.436 1612374512.0764012
train: epoch 35, iter 2700, loss: 2.953836, top_1: 0.518711, top_k: 0.753750, samples/s: 2212.929 1612374523.6448228
train: epoch 35, iter 2800, loss: 3.145894, top_1: 0.508320, top_k: 0.746719, samples/s: 2211.076 1612374535.2228596
train: epoch 35, iter 2900, loss: 3.041266, top_1: 0.508203, top_k: 0.748750, samples/s: 2242.976 1612374546.6362796
train: epoch 35, iter 3000, loss: 3.138874, top_1: 0.511289, top_k: 0.751016, samples/s: 2214.000 1612374558.1990502
train: epoch 35, iter 3100, loss: 3.371883, top_1: 0.510273, top_k: 0.744102, samples/s: 2216.396 1612374569.749334
train: epoch 35, iter 3200, loss: 3.136001, top_1: 0.506172, top_k: 0.745313, samples/s: 2221.381 1612374581.2736857
train: epoch 35, iter 3300, loss: 3.204733, top_1: 0.510977, top_k: 0.751641, samples/s: 2235.385 1612374592.7258966
train: epoch 35, iter 3400, loss: 2.814321, top_1: 0.515039, top_k: 0.751016, samples/s: 2220.443 1612374604.255089
train: epoch 35, iter 3500, loss: 3.015488, top_1: 0.508047, top_k: 0.745078, samples/s: 2212.756 1612374615.8244257
train: epoch 35, iter 3600, loss: 3.257934, top_1: 0.507305, top_k: 0.748477, samples/s: 2226.977 1612374627.3197699
train: epoch 35, iter 3700, loss: 3.014216, top_1: 0.509648, top_k: 0.752109, samples/s: 2220.935 1612374638.8464634
train: epoch 35, iter 3800, loss: 3.218925, top_1: 0.506602, top_k: 0.743125, samples/s: 2226.229 1612374650.345761
train: epoch 35, iter 3900, loss: 3.354869, top_1: 0.517148, top_k: 0.753750, samples/s: 2207.885 1612374661.9405162
train: epoch 35, iter 4000, loss: 2.898951, top_1: 0.508750, top_k: 0.747812, samples/s: 2238.240 1612374673.3780828
train: epoch 35, iter 4100, loss: 2.945457, top_1: 0.508477, top_k: 0.752383, samples/s: 2210.515 1612374684.9590921
train: epoch 35, iter 4200, loss: 3.046440, top_1: 0.507188, top_k: 0.744922, samples/s: 2223.976 1612374696.4700067
train: epoch 35, iter 4300, loss: 3.102659, top_1: 0.507852, top_k: 0.750430, samples/s: 2234.495 1612374707.926739
train: epoch 35, iter 4400, loss: 3.335484, top_1: 0.506367, top_k: 0.744570, samples/s: 2241.892 1612374719.345697
train: epoch 35, iter 4500, loss: 2.870311, top_1: 0.512813, top_k: 0.749258, samples/s: 2239.922 1612374730.7746751
train: epoch 35, iter 4600, loss: 3.072616, top_1: 0.508828, top_k: 0.744609, samples/s: 2234.877 1612374742.2294335
train: epoch 35, iter 4700, loss: 3.246763, top_1: 0.510273, top_k: 0.747422, samples/s: 2233.349 1612374753.6920114
train: epoch 35, iter 4800, loss: 3.077133, top_1: 0.509180, top_k: 0.745430, samples/s: 2226.676 1612374765.1889627
train: epoch 35, iter 4900, loss: 2.929389, top_1: 0.510547, top_k: 0.751484, samples/s: 2236.554 1612374776.635177
train: epoch 35, iter 5000, loss: 3.124474, top_1: 0.517344, top_k: 0.750508, samples/s: 2228.075 1612374788.1249504
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_35.
validation: epoch 35, iter 195, top_1: 0.564463, top_k: 0.805869, samples/s: 3012.079 1612374804.9851153
train: epoch 36, iter 100, loss: 2.881301, top_1: 0.530742, top_k: 0.763555, samples/s: 2239.573 1612374832.8890173
train: epoch 36, iter 200, loss: 3.081112, top_1: 0.520781, top_k: 0.755117, samples/s: 2247.573 1612374844.2790926
train: epoch 36, iter 300, loss: 3.111575, top_1: 0.523789, top_k: 0.756484, samples/s: 2253.989 1612374855.6368587
train: epoch 36, iter 400, loss: 3.004285, top_1: 0.516172, top_k: 0.755625, samples/s: 2265.463 1612374866.936856
train: epoch 36, iter 500, loss: 3.164227, top_1: 0.517500, top_k: 0.754336, samples/s: 2254.382 1612374878.2925148
train: epoch 36, iter 600, loss: 3.204545, top_1: 0.512344, top_k: 0.750938, samples/s: 2235.554 1612374889.7438123
train: epoch 36, iter 700, loss: 2.843709, top_1: 0.516250, top_k: 0.756172, samples/s: 2263.111 1612374901.0556796
train: epoch 36, iter 800, loss: 3.093442, top_1: 0.516523, top_k: 0.754219, samples/s: 2247.726 1612374912.4450586
train: epoch 36, iter 900, loss: 3.082381, top_1: 0.517305, top_k: 0.750859, samples/s: 2241.717 1612374923.8647933
train: epoch 36, iter 1000, loss: 2.938069, top_1: 0.514336, top_k: 0.750625, samples/s: 2237.201 1612374935.307789
train: epoch 36, iter 1100, loss: 2.925352, top_1: 0.515117, top_k: 0.751367, samples/s: 2234.864 1612374946.762489
train: epoch 36, iter 1200, loss: 3.146854, top_1: 0.511797, top_k: 0.748047, samples/s: 2219.234 1612374958.2980804
train: epoch 36, iter 1300, loss: 3.207107, top_1: 0.516758, top_k: 0.753281, samples/s: 2217.238 1612374969.843933
train: epoch 36, iter 1400, loss: 2.983316, top_1: 0.513633, top_k: 0.751953, samples/s: 2212.524 1612374981.4144263
train: epoch 36, iter 1500, loss: 3.062990, top_1: 0.514492, top_k: 0.749844, samples/s: 2237.033 1612374992.8581855
train: epoch 36, iter 1600, loss: 3.061646, top_1: 0.514062, top_k: 0.751484, samples/s: 2232.368 1612375004.3258162
train: epoch 36, iter 1700, loss: 3.128137, top_1: 0.518672, top_k: 0.752383, samples/s: 2235.277 1612375015.7784905
train: epoch 36, iter 1800, loss: 3.002597, top_1: 0.511992, top_k: 0.751211, samples/s: 2228.208 1612375027.2675884
train: epoch 36, iter 1900, loss: 2.885288, top_1: 0.514961, top_k: 0.750508, samples/s: 2219.469 1612375038.8018892
train: epoch 36, iter 2000, loss: 3.053542, top_1: 0.515000, top_k: 0.751055, samples/s: 2201.988 1612375050.427724
train: epoch 36, iter 2100, loss: 3.059145, top_1: 0.511641, top_k: 0.746445, samples/s: 2234.006 1612375061.8869345
train: epoch 36, iter 2200, loss: 3.035420, top_1: 0.511914, top_k: 0.750977, samples/s: 2197.751 1612375073.5352402
train: epoch 36, iter 2300, loss: 2.937051, top_1: 0.512461, top_k: 0.752617, samples/s: 2250.643 1612375084.9097145
train: epoch 36, iter 2400, loss: 3.044404, top_1: 0.518906, top_k: 0.746797, samples/s: 2220.417 1612375096.4390788
train: epoch 36, iter 2500, loss: 2.955553, top_1: 0.512344, top_k: 0.748086, samples/s: 2223.594 1612375107.9520292
train: epoch 36, iter 2600, loss: 3.057147, top_1: 0.515078, top_k: 0.751484, samples/s: 2223.866 1612375119.46348
train: epoch 36, iter 2700, loss: 2.825383, top_1: 0.515977, top_k: 0.753984, samples/s: 2209.209 1612375131.0513065
train: epoch 36, iter 2800, loss: 3.215766, top_1: 0.510156, top_k: 0.748320, samples/s: 2225.841 1612375142.5525832
train: epoch 36, iter 2900, loss: 3.068763, top_1: 0.508086, top_k: 0.748008, samples/s: 2218.851 1612375154.090088
train: epoch 36, iter 3000, loss: 2.933202, top_1: 0.508633, top_k: 0.743555, samples/s: 2222.348 1612375165.6095057
train: epoch 36, iter 3100, loss: 3.168519, top_1: 0.511211, top_k: 0.746758, samples/s: 2209.371 1612375177.1964467
train: epoch 36, iter 3200, loss: 2.931229, top_1: 0.511133, top_k: 0.748789, samples/s: 2195.829 1612375188.8549118
train: epoch 36, iter 3300, loss: 2.986845, top_1: 0.514375, top_k: 0.748047, samples/s: 2202.700 1612375200.47701
train: epoch 36, iter 3400, loss: 3.042407, top_1: 0.512813, top_k: 0.752188, samples/s: 2232.966 1612375211.9416182
train: epoch 36, iter 3500, loss: 2.883198, top_1: 0.508750, top_k: 0.747305, samples/s: 2217.181 1612375223.4877934
train: epoch 36, iter 3600, loss: 2.948743, top_1: 0.507539, top_k: 0.748633, samples/s: 2249.569 1612375234.867733
train: epoch 36, iter 3700, loss: 2.936122, top_1: 0.512578, top_k: 0.750469, samples/s: 2229.939 1612375246.3478818
train: epoch 36, iter 3800, loss: 3.009317, top_1: 0.514102, top_k: 0.749687, samples/s: 2239.375 1612375257.7797163
train: epoch 36, iter 3900, loss: 3.041058, top_1: 0.514414, top_k: 0.752148, samples/s: 2246.170 1612375269.1768477
train: epoch 36, iter 4000, loss: 3.085444, top_1: 0.511133, top_k: 0.743750, samples/s: 2228.389 1612375280.6648939
train: epoch 36, iter 4100, loss: 2.948947, top_1: 0.511758, top_k: 0.746680, samples/s: 2256.701 1612375292.0089612
train: epoch 36, iter 4200, loss: 3.200936, top_1: 0.509687, top_k: 0.745859, samples/s: 2236.563 1612375303.4550903
train: epoch 36, iter 4300, loss: 3.150618, top_1: 0.510703, top_k: 0.743242, samples/s: 2228.286 1612375314.9437945
train: epoch 36, iter 4400, loss: 3.022752, top_1: 0.513086, top_k: 0.749180, samples/s: 2249.467 1612375326.3241847
train: epoch 36, iter 4500, loss: 2.779615, top_1: 0.511563, top_k: 0.751523, samples/s: 2247.482 1612375337.7147093
train: epoch 36, iter 4600, loss: 3.051735, top_1: 0.507812, top_k: 0.746836, samples/s: 2234.950 1612375349.1691346
train: epoch 36, iter 4700, loss: 2.927014, top_1: 0.506445, top_k: 0.744883, samples/s: 2232.553 1612375360.6359801
train: epoch 36, iter 4800, loss: 3.251816, top_1: 0.508945, top_k: 0.746094, samples/s: 2237.093 1612375372.0792372
train: epoch 36, iter 4900, loss: 3.220483, top_1: 0.519961, top_k: 0.750039, samples/s: 2224.243 1612375383.5887487
train: epoch 36, iter 5000, loss: 3.004594, top_1: 0.512500, top_k: 0.752656, samples/s: 2211.024 1612375395.1671038
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_36.
validation: epoch 36, iter 195, top_1: 0.563522, top_k: 0.806831, samples/s: 2889.547 1612375412.7441611
train: epoch 37, iter 100, loss: 3.104989, top_1: 0.522500, top_k: 0.758359, samples/s: 2229.894 1612375440.18143
train: epoch 37, iter 200, loss: 3.141889, top_1: 0.523320, top_k: 0.755625, samples/s: 2256.630 1612375451.5257843
train: epoch 37, iter 300, loss: 3.050613, top_1: 0.526719, top_k: 0.758164, samples/s: 2255.496 1612375462.8758373
train: epoch 37, iter 400, loss: 2.972034, top_1: 0.526172, top_k: 0.760547, samples/s: 2259.578 1612375474.205516
train: epoch 37, iter 500, loss: 3.138355, top_1: 0.525195, top_k: 0.759492, samples/s: 2244.507 1612375485.6110203
train: epoch 37, iter 600, loss: 3.065953, top_1: 0.522734, top_k: 0.753320, samples/s: 2264.598 1612375496.9154477
train: epoch 37, iter 700, loss: 3.104042, top_1: 0.520391, top_k: 0.755078, samples/s: 2260.473 1612375508.2405612
train: epoch 37, iter 800, loss: 3.186454, top_1: 0.517773, top_k: 0.755820, samples/s: 2247.603 1612375519.630902
train: epoch 37, iter 900, loss: 2.717807, top_1: 0.515117, top_k: 0.751563, samples/s: 2256.277 1612375530.976646
train: epoch 37, iter 1000, loss: 3.073922, top_1: 0.512930, top_k: 0.754727, samples/s: 2218.444 1612375542.5165107
train: epoch 37, iter 1100, loss: 3.151412, top_1: 0.522109, top_k: 0.754648, samples/s: 2223.755 1612375554.028231
train: epoch 37, iter 1200, loss: 2.906988, top_1: 0.519453, top_k: 0.756172, samples/s: 2232.574 1612375565.4948525
train: epoch 37, iter 1300, loss: 3.174846, top_1: 0.519258, top_k: 0.757305, samples/s: 2239.304 1612375576.9269295
train: epoch 37, iter 1400, loss: 3.243132, top_1: 0.509727, top_k: 0.749883, samples/s: 2234.872 1612375588.3817868
train: epoch 37, iter 1500, loss: 3.110699, top_1: 0.514961, top_k: 0.752695, samples/s: 2197.948 1612375600.0289493
train: epoch 37, iter 1600, loss: 2.931082, top_1: 0.514023, top_k: 0.750117, samples/s: 2223.744 1612375611.5411015
train: epoch 37, iter 1700, loss: 3.046011, top_1: 0.517813, top_k: 0.752031, samples/s: 2221.762 1612375623.063517
train: epoch 37, iter 1800, loss: 3.021418, top_1: 0.516680, top_k: 0.752461, samples/s: 2217.556 1612375634.607699
train: epoch 37, iter 1900, loss: 2.997429, top_1: 0.509766, top_k: 0.751484, samples/s: 2237.600 1612375646.048561
train: epoch 37, iter 2000, loss: 2.983372, top_1: 0.510820, top_k: 0.747539, samples/s: 2227.900 1612375657.5395265
train: epoch 37, iter 2100, loss: 3.040554, top_1: 0.515742, top_k: 0.754297, samples/s: 2215.111 1612375669.0961487
train: epoch 37, iter 2200, loss: 3.109241, top_1: 0.513281, top_k: 0.747070, samples/s: 2200.944 1612375680.7277746
train: epoch 37, iter 2300, loss: 2.999223, top_1: 0.515625, top_k: 0.749844, samples/s: 2232.532 1612375692.1944158
train: epoch 37, iter 2400, loss: 3.216491, top_1: 0.519023, top_k: 0.754492, samples/s: 2229.763 1612375703.6753638
train: epoch 37, iter 2500, loss: 3.079672, top_1: 0.513516, top_k: 0.750547, samples/s: 2221.091 1612375715.2013514
train: epoch 37, iter 2600, loss: 2.987044, top_1: 0.505586, top_k: 0.748437, samples/s: 2214.341 1612375726.7623427
train: epoch 37, iter 2700, loss: 3.126139, top_1: 0.513047, top_k: 0.751641, samples/s: 2242.901 1612375738.1762218
train: epoch 37, iter 2800, loss: 3.100728, top_1: 0.515859, top_k: 0.750664, samples/s: 2230.695 1612375749.6522694
train: epoch 37, iter 2900, loss: 3.037791, top_1: 0.514258, top_k: 0.754766, samples/s: 2212.521 1612375761.222785
train: epoch 37, iter 3000, loss: 3.113373, top_1: 0.511250, top_k: 0.747539, samples/s: 2234.106 1612375772.6814947
train: epoch 37, iter 3100, loss: 2.913359, top_1: 0.507617, top_k: 0.747500, samples/s: 2234.913 1612375784.1361067
train: epoch 37, iter 3200, loss: 3.080345, top_1: 0.512539, top_k: 0.751133, samples/s: 2234.899 1612375795.5907953
train: epoch 37, iter 3300, loss: 3.047424, top_1: 0.514922, top_k: 0.750156, samples/s: 2229.193 1612375807.0747082
train: epoch 37, iter 3400, loss: 2.800640, top_1: 0.515117, top_k: 0.753047, samples/s: 2240.289 1612375818.5018296
train: epoch 37, iter 3500, loss: 3.030346, top_1: 0.515586, top_k: 0.751719, samples/s: 2230.385 1612375829.9796453
train: epoch 37, iter 3600, loss: 2.959282, top_1: 0.510703, top_k: 0.744102, samples/s: 2215.807 1612375841.5330513
train: epoch 37, iter 3700, loss: 3.004788, top_1: 0.507969, top_k: 0.751328, samples/s: 2232.498 1612375853.0000794
train: epoch 37, iter 3800, loss: 2.894419, top_1: 0.512539, top_k: 0.752969, samples/s: 2231.474 1612375864.4722264
train: epoch 37, iter 3900, loss: 3.051416, top_1: 0.512695, top_k: 0.748477, samples/s: 2223.676 1612375875.984696
train: epoch 37, iter 4000, loss: 3.095661, top_1: 0.511758, top_k: 0.750430, samples/s: 2229.294 1612375887.468138
train: epoch 37, iter 4100, loss: 3.050922, top_1: 0.512852, top_k: 0.750938, samples/s: 2250.308 1612375898.8443706
train: epoch 37, iter 4200, loss: 2.896091, top_1: 0.511719, top_k: 0.750742, samples/s: 2239.060 1612375910.2778199
train: epoch 37, iter 4300, loss: 3.125090, top_1: 0.513672, top_k: 0.755391, samples/s: 2243.953 1612375921.6862614
train: epoch 37, iter 4400, loss: 3.080352, top_1: 0.512695, top_k: 0.753320, samples/s: 2240.775 1612375933.1107802
train: epoch 37, iter 4500, loss: 3.163354, top_1: 0.506641, top_k: 0.746992, samples/s: 2251.042 1612375944.4833288
train: epoch 37, iter 4600, loss: 3.016565, top_1: 0.508164, top_k: 0.749258, samples/s: 2246.956 1612375955.876678
train: epoch 37, iter 4700, loss: 2.990336, top_1: 0.518164, top_k: 0.751992, samples/s: 2229.952 1612375967.3566244
train: epoch 37, iter 4800, loss: 2.923335, top_1: 0.510156, top_k: 0.745859, samples/s: 2244.399 1612375978.7627625
train: epoch 37, iter 4900, loss: 3.288352, top_1: 0.512617, top_k: 0.750117, samples/s: 2245.497 1612375990.1634037
train: epoch 37, iter 5000, loss: 3.114694, top_1: 0.511172, top_k: 0.750859, samples/s: 2218.322 1612376001.7035773
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_37.
validation: epoch 37, iter 195, top_1: 0.559275, top_k: 0.801262, samples/s: 2809.700 1612376019.755775
train: epoch 38, iter 100, loss: 2.851216, top_1: 0.522773, top_k: 0.761055, samples/s: 2211.943 1612376047.48515
train: epoch 38, iter 200, loss: 2.902754, top_1: 0.522695, top_k: 0.761016, samples/s: 2232.609 1612376058.951564
train: epoch 38, iter 300, loss: 3.097663, top_1: 0.524883, top_k: 0.759219, samples/s: 2268.050 1612376070.2387803
train: epoch 38, iter 400, loss: 2.947387, top_1: 0.520117, top_k: 0.756914, samples/s: 2262.872 1612376081.5519083
train: epoch 38, iter 500, loss: 3.095144, top_1: 0.521094, top_k: 0.756406, samples/s: 2250.241 1612376092.9284267
train: epoch 38, iter 600, loss: 2.913603, top_1: 0.512148, top_k: 0.753633, samples/s: 2244.437 1612376104.3344004
train: epoch 38, iter 700, loss: 3.105225, top_1: 0.512891, top_k: 0.752812, samples/s: 2257.091 1612376115.6764946
train: epoch 38, iter 800, loss: 2.941669, top_1: 0.515742, top_k: 0.754648, samples/s: 2232.029 1612376127.1458197
train: epoch 38, iter 900, loss: 2.982773, top_1: 0.520469, top_k: 0.755586, samples/s: 2238.482 1612376138.5821137
train: epoch 38, iter 1000, loss: 3.096456, top_1: 0.518437, top_k: 0.754609, samples/s: 2235.133 1612376150.035583
train: epoch 38, iter 1100, loss: 3.040140, top_1: 0.508672, top_k: 0.750703, samples/s: 2228.179 1612376161.5248573
train: epoch 38, iter 1200, loss: 3.100652, top_1: 0.508867, top_k: 0.752148, samples/s: 2210.697 1612376173.1052768
train: epoch 38, iter 1300, loss: 3.064846, top_1: 0.515859, top_k: 0.752539, samples/s: 2230.161 1612376184.5839274
train: epoch 38, iter 1400, loss: 3.115942, top_1: 0.515508, top_k: 0.753984, samples/s: 2216.869 1612376196.1317363
train: epoch 38, iter 1500, loss: 3.024843, top_1: 0.523672, top_k: 0.758594, samples/s: 2212.421 1612376207.7026846
train: epoch 38, iter 1600, loss: 3.005762, top_1: 0.519297, top_k: 0.754258, samples/s: 2193.109 1612376219.375665
train: epoch 38, iter 1700, loss: 2.903475, top_1: 0.515625, top_k: 0.752461, samples/s: 2230.389 1612376230.8538444
train: epoch 38, iter 1800, loss: 2.980947, top_1: 0.520859, top_k: 0.756563, samples/s: 2213.215 1612376242.42036
train: epoch 38, iter 1900, loss: 3.014753, top_1: 0.517188, top_k: 0.753828, samples/s: 2211.021 1612376253.998671
train: epoch 38, iter 2000, loss: 3.056038, top_1: 0.520742, top_k: 0.754453, samples/s: 2221.251 1612376265.5237257
train: epoch 38, iter 2100, loss: 2.958361, top_1: 0.515703, top_k: 0.753320, samples/s: 2231.141 1612376276.9976563
train: epoch 38, iter 2200, loss: 3.071293, top_1: 0.521367, top_k: 0.754922, samples/s: 2230.321 1612376288.4758377
train: epoch 38, iter 2300, loss: 3.035322, top_1: 0.515000, top_k: 0.751992, samples/s: 2186.849 1612376300.1825454
train: epoch 38, iter 2400, loss: 3.054548, top_1: 0.516563, top_k: 0.751680, samples/s: 2268.378 1612376311.4677615
train: epoch 38, iter 2500, loss: 3.049082, top_1: 0.513867, top_k: 0.750078, samples/s: 2230.541 1612376322.9451263
train: epoch 38, iter 2600, loss: 2.802088, top_1: 0.512656, top_k: 0.748984, samples/s: 2238.653 1612376334.38031
train: epoch 38, iter 2700, loss: 3.125155, top_1: 0.514023, top_k: 0.752188, samples/s: 2242.367 1612376345.7967727
train: epoch 38, iter 2800, loss: 3.086897, top_1: 0.519141, top_k: 0.753281, samples/s: 2230.204 1612376357.2755623
train: epoch 38, iter 2900, loss: 2.966238, top_1: 0.514414, top_k: 0.751211, samples/s: 2243.296 1612376368.6873746
train: epoch 38, iter 3000, loss: 3.143641, top_1: 0.506641, top_k: 0.749922, samples/s: 2241.113 1612376380.1102052
train: epoch 38, iter 3100, loss: 2.975903, top_1: 0.516367, top_k: 0.748437, samples/s: 2229.037 1612376391.5949755
train: epoch 38, iter 3200, loss: 3.224587, top_1: 0.515664, top_k: 0.753281, samples/s: 2233.401 1612376403.0573676
train: epoch 38, iter 3300, loss: 3.249754, top_1: 0.515547, top_k: 0.753984, samples/s: 2241.448 1612376414.478567
train: epoch 38, iter 3400, loss: 3.012655, top_1: 0.511680, top_k: 0.755195, samples/s: 2241.031 1612376425.9017842
train: epoch 38, iter 3500, loss: 3.039221, top_1: 0.511289, top_k: 0.749961, samples/s: 2235.995 1612376437.3509505
train: epoch 38, iter 3600, loss: 2.963515, top_1: 0.518008, top_k: 0.753672, samples/s: 2241.412 1612376448.7723074
train: epoch 38, iter 3700, loss: 3.128907, top_1: 0.515039, top_k: 0.750156, samples/s: 2242.873 1612376460.1861815
train: epoch 38, iter 3800, loss: 3.075894, top_1: 0.514648, top_k: 0.752148, samples/s: 2240.836 1612376471.610465
train: epoch 38, iter 3900, loss: 3.180278, top_1: 0.512461, top_k: 0.747188, samples/s: 2241.632 1612376483.0307243
train: epoch 38, iter 4000, loss: 3.060395, top_1: 0.516680, top_k: 0.753281, samples/s: 2233.739 1612376494.4913232
train: epoch 38, iter 4100, loss: 2.981704, top_1: 0.513281, top_k: 0.753086, samples/s: 2231.607 1612376505.9629529
train: epoch 38, iter 4200, loss: 3.167109, top_1: 0.514180, top_k: 0.747344, samples/s: 2238.439 1612376517.399776
train: epoch 38, iter 4300, loss: 3.020545, top_1: 0.516406, top_k: 0.752383, samples/s: 2239.561 1612376528.8302567
train: epoch 38, iter 4400, loss: 2.938358, top_1: 0.510312, top_k: 0.750195, samples/s: 2247.621 1612376540.220424
train: epoch 38, iter 4500, loss: 3.150861, top_1: 0.515469, top_k: 0.753281, samples/s: 2248.282 1612376551.6065197
train: epoch 38, iter 4600, loss: 2.942067, top_1: 0.510742, top_k: 0.748711, samples/s: 2248.238 1612376562.9932752
train: epoch 38, iter 4700, loss: 3.219778, top_1: 0.510820, top_k: 0.746094, samples/s: 2251.087 1612376574.365497
train: epoch 38, iter 4800, loss: 2.900023, top_1: 0.512695, top_k: 0.749219, samples/s: 2233.049 1612376585.8296564
train: epoch 38, iter 4900, loss: 2.917790, top_1: 0.514727, top_k: 0.751875, samples/s: 2240.857 1612376597.2539737
train: epoch 38, iter 5000, loss: 2.986166, top_1: 0.517070, top_k: 0.753789, samples/s: 2250.871 1612376608.627245
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_38.
validation: epoch 38, iter 195, top_1: 0.567348, top_k: 0.810837, samples/s: 2818.077 1612376626.6710515
train: epoch 39, iter 100, loss: 3.059836, top_1: 0.528438, top_k: 0.765195, samples/s: 2235.227 1612376653.9724302
train: epoch 39, iter 200, loss: 3.176400, top_1: 0.524727, top_k: 0.757930, samples/s: 2252.681 1612376665.336341
train: epoch 39, iter 300, loss: 3.113971, top_1: 0.523242, top_k: 0.757461, samples/s: 2262.126 1612376676.6535366
train: epoch 39, iter 400, loss: 2.838652, top_1: 0.524922, top_k: 0.760820, samples/s: 2249.342 1612376688.034246
train: epoch 39, iter 500, loss: 3.226830, top_1: 0.524922, top_k: 0.759961, samples/s: 2250.028 1612376699.4118698
train: epoch 39, iter 600, loss: 3.090921, top_1: 0.525195, top_k: 0.758242, samples/s: 2259.377 1612376710.7424386
train: epoch 39, iter 700, loss: 3.067319, top_1: 0.515039, top_k: 0.754141, samples/s: 2235.861 1612376722.192171
train: epoch 39, iter 800, loss: 2.989454, top_1: 0.516250, top_k: 0.757305, samples/s: 2265.283 1612376733.4931588
train: epoch 39, iter 900, loss: 3.274830, top_1: 0.515742, top_k: 0.757266, samples/s: 2249.195 1612376744.8750362
train: epoch 39, iter 1000, loss: 2.902582, top_1: 0.519102, top_k: 0.757930, samples/s: 2238.703 1612376756.3102744
train: epoch 39, iter 1100, loss: 3.027496, top_1: 0.520312, top_k: 0.756289, samples/s: 2220.243 1612376767.84048
train: epoch 39, iter 1200, loss: 3.002354, top_1: 0.519570, top_k: 0.750625, samples/s: 2207.588 1612376779.4368525
train: epoch 39, iter 1300, loss: 3.115256, top_1: 0.518203, top_k: 0.753242, samples/s: 2251.127 1612376790.8089256
train: epoch 39, iter 1400, loss: 2.970353, top_1: 0.523086, top_k: 0.755469, samples/s: 2230.769 1612376802.2848125
train: epoch 39, iter 1500, loss: 3.087309, top_1: 0.520820, top_k: 0.757422, samples/s: 2221.736 1612376813.8073857
train: epoch 39, iter 1600, loss: 3.087556, top_1: 0.518125, top_k: 0.755391, samples/s: 2238.533 1612376825.2434134
train: epoch 39, iter 1700, loss: 3.175756, top_1: 0.518203, top_k: 0.751836, samples/s: 2217.805 1612376836.7863219
train: epoch 39, iter 1800, loss: 2.959771, top_1: 0.518008, top_k: 0.757500, samples/s: 2230.215 1612376848.2650719
train: epoch 39, iter 1900, loss: 3.278531, top_1: 0.515312, top_k: 0.748437, samples/s: 2226.880 1612376859.7609365
train: epoch 39, iter 2000, loss: 3.205277, top_1: 0.510703, top_k: 0.751211, samples/s: 2214.994 1612376871.3185701
train: epoch 39, iter 2100, loss: 3.385846, top_1: 0.516563, top_k: 0.753398, samples/s: 2170.629 1612376883.1123824
train: epoch 39, iter 2200, loss: 2.991168, top_1: 0.516328, top_k: 0.758242, samples/s: 2264.184 1612376894.4188461
train: epoch 39, iter 2300, loss: 2.845263, top_1: 0.516836, top_k: 0.751602, samples/s: 2213.429 1612376905.9846323
train: epoch 39, iter 2400, loss: 3.227555, top_1: 0.513906, top_k: 0.748945, samples/s: 2213.735 1612376917.5487797
train: epoch 39, iter 2500, loss: 2.967213, top_1: 0.518086, top_k: 0.754727, samples/s: 2230.773 1612376929.0247605
train: epoch 39, iter 2600, loss: 2.924112, top_1: 0.511758, top_k: 0.749883, samples/s: 2231.813 1612376940.4951088
train: epoch 39, iter 2700, loss: 3.115348, top_1: 0.519648, top_k: 0.754141, samples/s: 2238.205 1612376951.9329443
train: epoch 39, iter 2800, loss: 3.022299, top_1: 0.516250, top_k: 0.750977, samples/s: 2220.740 1612376963.4606726
train: epoch 39, iter 2900, loss: 2.969774, top_1: 0.519727, top_k: 0.752148, samples/s: 2255.970 1612376974.8082073
train: epoch 39, iter 3000, loss: 3.025573, top_1: 0.521641, top_k: 0.757656, samples/s: 2217.966 1612376986.3503387
train: epoch 39, iter 3100, loss: 2.827211, top_1: 0.514961, top_k: 0.754023, samples/s: 2266.653 1612376997.6444976
train: epoch 39, iter 3200, loss: 3.171679, top_1: 0.514805, top_k: 0.753555, samples/s: 2233.291 1612377009.1074095
train: epoch 39, iter 3300, loss: 2.930055, top_1: 0.515469, top_k: 0.754258, samples/s: 2207.693 1612377020.703262
train: epoch 39, iter 3400, loss: 2.918510, top_1: 0.516914, top_k: 0.751953, samples/s: 2240.974 1612377032.1268451
train: epoch 39, iter 3500, loss: 2.938297, top_1: 0.515312, top_k: 0.755938, samples/s: 2248.701 1612377043.5112317
train: epoch 39, iter 3600, loss: 3.006720, top_1: 0.518437, top_k: 0.755039, samples/s: 2237.478 1612377054.9526231
train: epoch 39, iter 3700, loss: 3.086516, top_1: 0.516719, top_k: 0.751641, samples/s: 2218.481 1612377066.4920676
train: epoch 39, iter 3800, loss: 3.143715, top_1: 0.512305, top_k: 0.749883, samples/s: 2237.587 1612377077.9329479
train: epoch 39, iter 3900, loss: 3.173702, top_1: 0.520234, top_k: 0.757383, samples/s: 2234.578 1612377089.3892772
train: epoch 39, iter 4000, loss: 3.069010, top_1: 0.509375, top_k: 0.751953, samples/s: 2249.923 1612377100.7674692
train: epoch 39, iter 4100, loss: 3.061165, top_1: 0.519570, top_k: 0.753359, samples/s: 2250.274 1612377112.1438272
train: epoch 39, iter 4200, loss: 3.019061, top_1: 0.519492, top_k: 0.747812, samples/s: 2238.947 1612377123.5777879
train: epoch 39, iter 4300, loss: 2.828171, top_1: 0.514336, top_k: 0.749922, samples/s: 2241.160 1612377135.0004108
train: epoch 39, iter 4400, loss: 2.921642, top_1: 0.517930, top_k: 0.749766, samples/s: 2226.798 1612377146.496756
train: epoch 39, iter 4500, loss: 2.926167, top_1: 0.513281, top_k: 0.751211, samples/s: 2224.632 1612377158.0042958
train: epoch 39, iter 4600, loss: 3.017126, top_1: 0.514883, top_k: 0.752930, samples/s: 2255.602 1612377169.3538098
train: epoch 39, iter 4700, loss: 3.022155, top_1: 0.513867, top_k: 0.750156, samples/s: 2251.869 1612377180.7221558
train: epoch 39, iter 4800, loss: 2.869639, top_1: 0.516016, top_k: 0.753086, samples/s: 2235.935 1612377192.1715443
train: epoch 39, iter 4900, loss: 2.754662, top_1: 0.519727, top_k: 0.756250, samples/s: 2246.971 1612377203.5645754
train: epoch 39, iter 5000, loss: 2.897675, top_1: 0.518164, top_k: 0.755313, samples/s: 2234.841 1612377215.019583
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_39.
validation: epoch 39, iter 195, top_1: 0.554708, top_k: 0.799499, samples/s: 2864.514 1612377232.6952934
train: epoch 40, iter 100, loss: 3.003702, top_1: 0.524180, top_k: 0.757773, samples/s: 2230.014 1612377261.0664773
train: epoch 40, iter 200, loss: 3.230721, top_1: 0.523594, top_k: 0.756641, samples/s: 2243.021 1612377272.4796395
train: epoch 40, iter 300, loss: 3.031090, top_1: 0.517266, top_k: 0.758828, samples/s: 2253.145 1612377283.8415375
train: epoch 40, iter 400, loss: 3.013370, top_1: 0.525156, top_k: 0.757109, samples/s: 2252.059 1612377295.2089598
train: epoch 40, iter 500, loss: 3.073552, top_1: 0.521133, top_k: 0.757656, samples/s: 2255.182 1612377306.5605562
train: epoch 40, iter 600, loss: 3.145037, top_1: 0.527070, top_k: 0.756406, samples/s: 2253.809 1612377317.9191487
train: epoch 40, iter 700, loss: 3.335649, top_1: 0.520977, top_k: 0.757773, samples/s: 2258.762 1612377329.2527657
train: epoch 40, iter 800, loss: 3.037360, top_1: 0.520000, top_k: 0.755156, samples/s: 2211.481 1612377340.829208
train: epoch 40, iter 900, loss: 3.057228, top_1: 0.520898, top_k: 0.757578, samples/s: 2242.231 1612377352.245892
train: epoch 40, iter 1000, loss: 3.110754, top_1: 0.523477, top_k: 0.757305, samples/s: 2240.363 1612377363.6726205
train: epoch 40, iter 1100, loss: 2.826850, top_1: 0.520352, top_k: 0.757305, samples/s: 2245.703 1612377375.0721736
train: epoch 40, iter 1200, loss: 3.032824, top_1: 0.515391, top_k: 0.755078, samples/s: 2215.819 1612377386.6266508
train: epoch 40, iter 1300, loss: 3.161617, top_1: 0.515625, top_k: 0.755117, samples/s: 2236.515 1612377398.0718343
train: epoch 40, iter 1400, loss: 2.968576, top_1: 0.515664, top_k: 0.753086, samples/s: 2197.397 1612377409.722503
train: epoch 40, iter 1500, loss: 3.096485, top_1: 0.515742, top_k: 0.754414, samples/s: 2226.227 1612377421.2214396
train: epoch 40, iter 1600, loss: 3.028770, top_1: 0.522500, top_k: 0.757422, samples/s: 2227.365 1612377432.7147322
train: epoch 40, iter 1700, loss: 3.063951, top_1: 0.519258, top_k: 0.756602, samples/s: 2232.127 1612377444.1835315
train: epoch 40, iter 1800, loss: 3.069902, top_1: 0.525352, top_k: 0.758789, samples/s: 2219.918 1612377455.7157638
train: epoch 40, iter 1900, loss: 3.134011, top_1: 0.517773, top_k: 0.754961, samples/s: 2240.340 1612377467.1423745
train: epoch 40, iter 2000, loss: 2.865435, top_1: 0.523867, top_k: 0.760391, samples/s: 2233.744 1612377478.6029222
train: epoch 40, iter 2100, loss: 2.970249, top_1: 0.515586, top_k: 0.754531, samples/s: 2230.126 1612377490.0820768
train: epoch 40, iter 2200, loss: 3.059045, top_1: 0.517109, top_k: 0.754805, samples/s: 2198.851 1612377501.7246106
train: epoch 40, iter 2300, loss: 2.925226, top_1: 0.513437, top_k: 0.752617, samples/s: 2216.426 1612377513.2746942
train: epoch 40, iter 2400, loss: 3.158497, top_1: 0.513164, top_k: 0.753906, samples/s: 2219.228 1612377524.8102257
train: epoch 40, iter 2500, loss: 2.992883, top_1: 0.523984, top_k: 0.757227, samples/s: 2223.726 1612377536.3230426
train: epoch 40, iter 2600, loss: 2.956104, top_1: 0.524141, top_k: 0.757539, samples/s: 2234.961 1612377547.77674
train: epoch 40, iter 2700, loss: 3.145409, top_1: 0.526016, top_k: 0.758203, samples/s: 2223.626 1612377559.2894592
train: epoch 40, iter 2800, loss: 2.847524, top_1: 0.517891, top_k: 0.758125, samples/s: 2228.988 1612377570.7745223
train: epoch 40, iter 2900, loss: 3.031027, top_1: 0.523047, top_k: 0.760820, samples/s: 2220.041 1612377582.30584
train: epoch 40, iter 3000, loss: 3.030195, top_1: 0.513281, top_k: 0.747461, samples/s: 2228.669 1612377593.792845
train: epoch 40, iter 3100, loss: 2.939004, top_1: 0.520664, top_k: 0.753555, samples/s: 2205.844 1612377605.3980496
train: epoch 40, iter 3200, loss: 3.086195, top_1: 0.521836, top_k: 0.755664, samples/s: 2232.534 1612377616.864822
train: epoch 40, iter 3300, loss: 3.087245, top_1: 0.520664, top_k: 0.757344, samples/s: 2184.073 1612377628.5860536
train: epoch 40, iter 3400, loss: 3.185279, top_1: 0.515352, top_k: 0.750117, samples/s: 2229.719 1612377640.0673084
train: epoch 40, iter 3500, loss: 3.075564, top_1: 0.513789, top_k: 0.755547, samples/s: 2220.268 1612377651.5974593
train: epoch 40, iter 3600, loss: 2.720779, top_1: 0.515586, top_k: 0.754297, samples/s: 2226.982 1612377663.092829
train: epoch 40, iter 3700, loss: 3.025082, top_1: 0.518633, top_k: 0.756406, samples/s: 2243.718 1612377674.5024505
train: epoch 40, iter 3800, loss: 3.002589, top_1: 0.516055, top_k: 0.755742, samples/s: 2236.408 1612377685.949385
train: epoch 40, iter 3900, loss: 3.194410, top_1: 0.519531, top_k: 0.756055, samples/s: 2237.982 1612377697.3886461
train: epoch 40, iter 4000, loss: 3.305392, top_1: 0.516094, top_k: 0.752930, samples/s: 2240.552 1612377708.8140094
train: epoch 40, iter 4100, loss: 3.145996, top_1: 0.518867, top_k: 0.754648, samples/s: 2235.107 1612377720.2679727
train: epoch 40, iter 4200, loss: 3.215248, top_1: 0.512031, top_k: 0.749102, samples/s: 2229.263 1612377731.7512553
train: epoch 40, iter 4300, loss: 3.076068, top_1: 0.513516, top_k: 0.749609, samples/s: 2223.932 1612377743.262371
train: epoch 40, iter 4400, loss: 3.134128, top_1: 0.509961, top_k: 0.750859, samples/s: 2238.076 1612377754.7007668
train: epoch 40, iter 4500, loss: 2.941079, top_1: 0.513633, top_k: 0.752070, samples/s: 2232.847 1612377766.1659317
train: epoch 40, iter 4600, loss: 3.188985, top_1: 0.518633, top_k: 0.750469, samples/s: 2242.245 1612377777.5830588
train: epoch 40, iter 4700, loss: 3.016788, top_1: 0.517383, top_k: 0.753398, samples/s: 2236.201 1612377789.0310905
train: epoch 40, iter 4800, loss: 2.997843, top_1: 0.517422, top_k: 0.755391, samples/s: 2242.462 1612377800.4470956
train: epoch 40, iter 4900, loss: 3.064333, top_1: 0.513359, top_k: 0.752539, samples/s: 2237.918 1612377811.886303
train: epoch 40, iter 5000, loss: 2.980627, top_1: 0.520938, top_k: 0.754922, samples/s: 2241.613 1612377823.3066306
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_40.
validation: epoch 40, iter 195, top_1: 0.555689, top_k: 0.799519, samples/s: 2787.995 1612377841.5725822
train: epoch 41, iter 100, loss: 3.129074, top_1: 0.523281, top_k: 0.757656, samples/s: 2242.664 1612377868.7686236
train: epoch 41, iter 200, loss: 2.826939, top_1: 0.524609, top_k: 0.759961, samples/s: 2241.565 1612377880.1892898
train: epoch 41, iter 300, loss: 2.893479, top_1: 0.525352, top_k: 0.759141, samples/s: 2263.797 1612377891.4976027
train: epoch 41, iter 400, loss: 2.996797, top_1: 0.518516, top_k: 0.754023, samples/s: 2243.975 1612377902.9059594
train: epoch 41, iter 500, loss: 2.880270, top_1: 0.527266, top_k: 0.762148, samples/s: 2265.722 1612377914.2047634
train: epoch 41, iter 600, loss: 3.067358, top_1: 0.521406, top_k: 0.755469, samples/s: 2252.206 1612377925.5714295
train: epoch 41, iter 700, loss: 2.893380, top_1: 0.521914, top_k: 0.758281, samples/s: 2254.872 1612377936.9245956
train: epoch 41, iter 800, loss: 2.913226, top_1: 0.521836, top_k: 0.760781, samples/s: 2241.794 1612377948.3440113
train: epoch 41, iter 900, loss: 2.884580, top_1: 0.524062, top_k: 0.754219, samples/s: 2219.430 1612377959.8785114
train: epoch 41, iter 1000, loss: 3.130218, top_1: 0.519219, top_k: 0.757422, samples/s: 2227.228 1612377971.3726976
train: epoch 41, iter 1100, loss: 3.046205, top_1: 0.526172, top_k: 0.759570, samples/s: 2213.565 1612377982.9376855
train: epoch 41, iter 1200, loss: 2.965365, top_1: 0.524844, top_k: 0.760430, samples/s: 2239.841 1612377994.3670948
train: epoch 41, iter 1300, loss: 3.018194, top_1: 0.520586, top_k: 0.753906, samples/s: 2239.855 1612378005.7964017
train: epoch 41, iter 1400, loss: 3.124918, top_1: 0.523125, top_k: 0.758594, samples/s: 2231.762 1612378017.2671244
train: epoch 41, iter 1500, loss: 2.966310, top_1: 0.523945, top_k: 0.758828, samples/s: 2224.440 1612378028.7756743
train: epoch 41, iter 1600, loss: 3.143245, top_1: 0.520391, top_k: 0.756094, samples/s: 2213.369 1612378040.341738
train: epoch 41, iter 1700, loss: 3.040018, top_1: 0.525586, top_k: 0.759727, samples/s: 2214.271 1612378051.903072
train: epoch 41, iter 1800, loss: 2.969860, top_1: 0.522383, top_k: 0.757031, samples/s: 2231.578 1612378063.374807
train: epoch 41, iter 1900, loss: 3.197357, top_1: 0.523242, top_k: 0.755117, samples/s: 2225.773 1612378074.8763974
train: epoch 41, iter 2000, loss: 2.931914, top_1: 0.522070, top_k: 0.757148, samples/s: 2239.276 1612378086.3087242
train: epoch 41, iter 2100, loss: 2.772585, top_1: 0.521211, top_k: 0.754023, samples/s: 2211.507 1612378097.8846278
train: epoch 41, iter 2200, loss: 2.862300, top_1: 0.520586, top_k: 0.753125, samples/s: 2223.835 1612378109.396135
train: epoch 41, iter 2300, loss: 2.763549, top_1: 0.520156, top_k: 0.754687, samples/s: 2230.495 1612378120.8734076
train: epoch 41, iter 2400, loss: 3.060152, top_1: 0.515859, top_k: 0.751523, samples/s: 2215.689 1612378132.4273815
train: epoch 41, iter 2500, loss: 3.170083, top_1: 0.515352, top_k: 0.753828, samples/s: 2235.568 1612378143.8786488
train: epoch 41, iter 2600, loss: 3.150223, top_1: 0.525156, top_k: 0.757461, samples/s: 2223.481 1612378155.3920782
train: epoch 41, iter 2700, loss: 2.952448, top_1: 0.519648, top_k: 0.753437, samples/s: 2208.915 1612378166.981497
train: epoch 41, iter 2800, loss: 2.977471, top_1: 0.519141, top_k: 0.757891, samples/s: 2223.672 1612378178.4940357
train: epoch 41, iter 2900, loss: 2.633235, top_1: 0.517578, top_k: 0.754805, samples/s: 2229.637 1612378189.9757674
train: epoch 41, iter 3000, loss: 3.177450, top_1: 0.520977, top_k: 0.759375, samples/s: 2230.543 1612378201.4526823
train: epoch 41, iter 3100, loss: 3.208242, top_1: 0.520977, top_k: 0.757109, samples/s: 2219.541 1612378212.986608
train: epoch 41, iter 3200, loss: 2.945152, top_1: 0.513711, top_k: 0.754062, samples/s: 2228.449 1612378224.474408
train: epoch 41, iter 3300, loss: 2.969912, top_1: 0.522148, top_k: 0.760352, samples/s: 2211.873 1612378236.0483267
train: epoch 41, iter 3400, loss: 3.052403, top_1: 0.523281, top_k: 0.757852, samples/s: 2244.889 1612378247.4519987
train: epoch 41, iter 3500, loss: 3.284004, top_1: 0.519336, top_k: 0.758437, samples/s: 2238.601 1612378258.8877444
train: epoch 41, iter 3600, loss: 2.883152, top_1: 0.518125, top_k: 0.753242, samples/s: 2238.829 1612378270.322263
train: epoch 41, iter 3700, loss: 2.872495, top_1: 0.519492, top_k: 0.753945, samples/s: 2228.004 1612378281.812413
train: epoch 41, iter 3800, loss: 3.153746, top_1: 0.513398, top_k: 0.751289, samples/s: 2240.452 1612378293.2390175
train: epoch 41, iter 3900, loss: 2.974195, top_1: 0.516602, top_k: 0.755898, samples/s: 2223.493 1612378304.7520912
train: epoch 41, iter 4000, loss: 2.777402, top_1: 0.518086, top_k: 0.753711, samples/s: 2239.450 1612378316.1837053
train: epoch 41, iter 4100, loss: 3.078379, top_1: 0.521172, top_k: 0.752812, samples/s: 2247.864 1612378327.5720115
train: epoch 41, iter 4200, loss: 3.096755, top_1: 0.515938, top_k: 0.753047, samples/s: 2253.191 1612378338.9337187
train: epoch 41, iter 4300, loss: 2.932711, top_1: 0.518086, top_k: 0.751055, samples/s: 2216.498 1612378350.483435
train: epoch 41, iter 4400, loss: 2.821903, top_1: 0.523633, top_k: 0.756484, samples/s: 2232.615 1612378361.9498
train: epoch 41, iter 4500, loss: 2.976071, top_1: 0.515547, top_k: 0.751992, samples/s: 2237.419 1612378373.3915615
train: epoch 41, iter 4600, loss: 3.177536, top_1: 0.516914, top_k: 0.753516, samples/s: 2238.248 1612378384.8291197
train: epoch 41, iter 4700, loss: 2.971621, top_1: 0.520273, top_k: 0.753672, samples/s: 2251.633 1612378396.198646
train: epoch 41, iter 4800, loss: 2.862300, top_1: 0.517813, top_k: 0.753398, samples/s: 2242.653 1612378407.6136527
train: epoch 41, iter 4900, loss: 2.879848, top_1: 0.517500, top_k: 0.755156, samples/s: 2212.227 1612378419.1857545
train: epoch 41, iter 5000, loss: 2.979082, top_1: 0.523359, top_k: 0.755859, samples/s: 2254.691 1612378430.539847
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_41.
validation: epoch 41, iter 195, top_1: 0.558393, top_k: 0.802945, samples/s: 2925.108 1612378448.0555189
train: epoch 42, iter 100, loss: 3.046605, top_1: 0.527422, top_k: 0.762813, samples/s: 2246.078 1612378474.986011
train: epoch 42, iter 200, loss: 3.144156, top_1: 0.527266, top_k: 0.758672, samples/s: 2258.899 1612378486.318903
train: epoch 42, iter 300, loss: 3.116120, top_1: 0.526094, top_k: 0.764375, samples/s: 2255.231 1612378497.6702867
train: epoch 42, iter 400, loss: 3.095843, top_1: 0.520898, top_k: 0.762305, samples/s: 2247.438 1612378509.0610347
train: epoch 42, iter 500, loss: 3.074451, top_1: 0.530820, top_k: 0.763867, samples/s: 2246.802 1612378520.4550023
train: epoch 42, iter 600, loss: 2.975123, top_1: 0.522617, top_k: 0.757266, samples/s: 2247.577 1612378531.845102
train: epoch 42, iter 700, loss: 2.943604, top_1: 0.525156, top_k: 0.759180, samples/s: 2235.791 1612378543.2951565
train: epoch 42, iter 800, loss: 2.983164, top_1: 0.523711, top_k: 0.757812, samples/s: 2256.105 1612378554.6421337
train: epoch 42, iter 900, loss: 2.949148, top_1: 0.519844, top_k: 0.755781, samples/s: 2227.396 1612378566.1353703
train: epoch 42, iter 1000, loss: 3.014128, top_1: 0.526641, top_k: 0.763359, samples/s: 2249.963 1612378577.5133173
train: epoch 42, iter 1100, loss: 3.017098, top_1: 0.518047, top_k: 0.757695, samples/s: 2247.914 1612378588.9016879
train: epoch 42, iter 1200, loss: 3.076128, top_1: 0.521758, top_k: 0.752695, samples/s: 2219.067 1612378600.4381022
train: epoch 42, iter 1300, loss: 2.903245, top_1: 0.520977, top_k: 0.755508, samples/s: 2226.305 1612378611.93696
train: epoch 42, iter 1400, loss: 3.226918, top_1: 0.520430, top_k: 0.757578, samples/s: 2230.395 1612378623.4147253
train: epoch 42, iter 1500, loss: 2.848291, top_1: 0.520742, top_k: 0.755078, samples/s: 2235.862 1612378634.864437
train: epoch 42, iter 1600, loss: 2.896625, top_1: 0.520078, top_k: 0.758125, samples/s: 2207.074 1612378646.4634984
train: epoch 42, iter 1700, loss: 2.886266, top_1: 0.516523, top_k: 0.759492, samples/s: 2222.104 1612378657.984188
train: epoch 42, iter 1800, loss: 2.900720, top_1: 0.524492, top_k: 0.754961, samples/s: 2232.096 1612378669.453159
train: epoch 42, iter 1900, loss: 3.025613, top_1: 0.526875, top_k: 0.758281, samples/s: 2221.360 1612378680.9776843
train: epoch 42, iter 2000, loss: 2.874433, top_1: 0.517383, top_k: 0.758320, samples/s: 2240.444 1612378692.4039395
train: epoch 42, iter 2100, loss: 3.075716, top_1: 0.518672, top_k: 0.758750, samples/s: 2210.053 1612378703.9874184
train: epoch 42, iter 2200, loss: 3.040070, top_1: 0.522344, top_k: 0.753906, samples/s: 2216.856 1612378715.535354
train: epoch 42, iter 2300, loss: 2.912428, top_1: 0.523438, top_k: 0.756289, samples/s: 2224.621 1612378727.042881
train: epoch 42, iter 2400, loss: 2.719324, top_1: 0.518047, top_k: 0.757383, samples/s: 2227.148 1612378738.5373676
train: epoch 42, iter 2500, loss: 3.006500, top_1: 0.520039, top_k: 0.758750, samples/s: 2228.236 1612378750.0263417
train: epoch 42, iter 2600, loss: 3.024797, top_1: 0.526797, top_k: 0.757969, samples/s: 2221.247 1612378761.5513155
train: epoch 42, iter 2700, loss: 2.953796, top_1: 0.515977, top_k: 0.755859, samples/s: 2226.738 1612378773.0479808
train: epoch 42, iter 2800, loss: 3.136195, top_1: 0.525742, top_k: 0.757266, samples/s: 2232.219 1612378784.5164025
train: epoch 42, iter 2900, loss: 3.125316, top_1: 0.521680, top_k: 0.759297, samples/s: 2220.391 1612378796.0458972
train: epoch 42, iter 3000, loss: 3.121014, top_1: 0.521719, top_k: 0.755469, samples/s: 2234.643 1612378807.501854
train: epoch 42, iter 3100, loss: 3.073702, top_1: 0.519102, top_k: 0.755195, samples/s: 2233.162 1612378818.9653907
train: epoch 42, iter 3200, loss: 2.889328, top_1: 0.524023, top_k: 0.759453, samples/s: 2234.538 1612378830.4218802
train: epoch 42, iter 3300, loss: 2.768923, top_1: 0.521289, top_k: 0.760234, samples/s: 2240.562 1612378841.8476117
train: epoch 42, iter 3400, loss: 2.892506, top_1: 0.523047, top_k: 0.757695, samples/s: 2246.555 1612378853.2428281
train: epoch 42, iter 3500, loss: 2.949404, top_1: 0.518516, top_k: 0.754844, samples/s: 2244.788 1612378864.6470885
train: epoch 42, iter 3600, loss: 2.993072, top_1: 0.514180, top_k: 0.750234, samples/s: 2221.000 1612378876.1733682
train: epoch 42, iter 3700, loss: 2.873487, top_1: 0.512188, top_k: 0.754961, samples/s: 2239.354 1612378887.6052368
train: epoch 42, iter 3800, loss: 3.027553, top_1: 0.521211, top_k: 0.756758, samples/s: 2234.337 1612378899.0628896
train: epoch 42, iter 3900, loss: 2.927442, top_1: 0.515312, top_k: 0.751406, samples/s: 2226.322 1612378910.561576
train: epoch 42, iter 4000, loss: 3.104894, top_1: 0.518398, top_k: 0.754180, samples/s: 2243.481 1612378921.9723954
train: epoch 42, iter 4100, loss: 3.121906, top_1: 0.520234, top_k: 0.758437, samples/s: 2243.926 1612378933.38097
train: epoch 42, iter 4200, loss: 2.994036, top_1: 0.516914, top_k: 0.753281, samples/s: 2239.534 1612378944.8119776
train: epoch 42, iter 4300, loss: 2.872225, top_1: 0.523516, top_k: 0.759297, samples/s: 2248.800 1612378956.1957645
train: epoch 42, iter 4400, loss: 3.192299, top_1: 0.518281, top_k: 0.750469, samples/s: 2241.416 1612378967.6171389
train: epoch 42, iter 4500, loss: 3.118713, top_1: 0.523398, top_k: 0.762617, samples/s: 2235.196 1612378979.0703382
train: epoch 42, iter 4600, loss: 2.837609, top_1: 0.519062, top_k: 0.753320, samples/s: 2245.901 1612378990.4688413
train: epoch 42, iter 4700, loss: 3.165440, top_1: 0.524687, top_k: 0.759844, samples/s: 2213.456 1612379002.034536
train: epoch 42, iter 4800, loss: 3.086781, top_1: 0.520547, top_k: 0.752305, samples/s: 2211.740 1612379013.6091058
train: epoch 42, iter 4900, loss: 3.096499, top_1: 0.527070, top_k: 0.762773, samples/s: 2212.346 1612379025.1804602
train: epoch 42, iter 5000, loss: 2.896332, top_1: 0.520977, top_k: 0.754531, samples/s: 2212.930 1612379036.7488306
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_42.
validation: epoch 42, iter 195, top_1: 0.565825, top_k: 0.805509, samples/s: 2827.987 1612379054.6624982
train: epoch 43, iter 100, loss: 2.875587, top_1: 0.524883, top_k: 0.758828, samples/s: 2233.391 1612379082.5487747
train: epoch 43, iter 200, loss: 2.952805, top_1: 0.536133, top_k: 0.767656, samples/s: 2253.797 1612379093.9073515
train: epoch 43, iter 300, loss: 3.069430, top_1: 0.533438, top_k: 0.767930, samples/s: 2257.692 1612379105.2463806
train: epoch 43, iter 400, loss: 2.845364, top_1: 0.528242, top_k: 0.758711, samples/s: 2255.954 1612379116.5941284
train: epoch 43, iter 500, loss: 2.832612, top_1: 0.524766, top_k: 0.762188, samples/s: 2245.208 1612379127.9961452
train: epoch 43, iter 600, loss: 3.374114, top_1: 0.526172, top_k: 0.756797, samples/s: 2246.974 1612379139.3892713
train: epoch 43, iter 700, loss: 2.695586, top_1: 0.529453, top_k: 0.766367, samples/s: 2249.273 1612379150.77072
train: epoch 43, iter 800, loss: 2.925044, top_1: 0.526797, top_k: 0.763711, samples/s: 2246.033 1612379162.1686027
train: epoch 43, iter 900, loss: 2.956979, top_1: 0.525352, top_k: 0.766328, samples/s: 2246.837 1612379173.562897
train: epoch 43, iter 1000, loss: 2.970336, top_1: 0.528125, top_k: 0.759570, samples/s: 2240.145 1612379184.9902558
train: epoch 43, iter 1100, loss: 3.008240, top_1: 0.523203, top_k: 0.752734, samples/s: 2222.844 1612379196.5070512
train: epoch 43, iter 1200, loss: 2.893074, top_1: 0.522773, top_k: 0.755742, samples/s: 2229.195 1612379207.9913647
train: epoch 43, iter 1300, loss: 3.238207, top_1: 0.521719, top_k: 0.760508, samples/s: 2202.097 1612379219.6163323
train: epoch 43, iter 1400, loss: 2.868325, top_1: 0.521992, top_k: 0.757188, samples/s: 2236.343 1612379231.0635517
train: epoch 43, iter 1500, loss: 2.910472, top_1: 0.523984, top_k: 0.759141, samples/s: 2216.551 1612379242.612981
train: epoch 43, iter 1600, loss: 3.089685, top_1: 0.521484, top_k: 0.760586, samples/s: 2230.813 1612379254.088796
train: epoch 43, iter 1700, loss: 3.100977, top_1: 0.522930, top_k: 0.758203, samples/s: 2208.358 1612379265.680941
train: epoch 43, iter 1800, loss: 3.045708, top_1: 0.521016, top_k: 0.758867, samples/s: 2228.661 1612379277.1676607
train: epoch 43, iter 1900, loss: 3.163319, top_1: 0.521602, top_k: 0.759687, samples/s: 2240.140 1612379288.5955215
train: epoch 43, iter 2000, loss: 2.862974, top_1: 0.528555, top_k: 0.762344, samples/s: 2215.111 1612379300.152513
train: epoch 43, iter 2100, loss: 2.887627, top_1: 0.528047, top_k: 0.761484, samples/s: 2233.757 1612379311.613022
train: epoch 43, iter 2200, loss: 2.991567, top_1: 0.521328, top_k: 0.755508, samples/s: 2217.447 1612379323.157826
train: epoch 43, iter 2300, loss: 2.816985, top_1: 0.526055, top_k: 0.757188, samples/s: 2190.071 1612379334.8469546
train: epoch 43, iter 2400, loss: 2.959080, top_1: 0.517734, top_k: 0.757812, samples/s: 2220.588 1612379346.3754551
train: epoch 43, iter 2500, loss: 2.875813, top_1: 0.519492, top_k: 0.759141, samples/s: 2223.302 1612379357.8898182
train: epoch 43, iter 2600, loss: 2.949818, top_1: 0.524102, top_k: 0.764102, samples/s: 2214.644 1612379369.4492593
train: epoch 43, iter 2700, loss: 2.995507, top_1: 0.516719, top_k: 0.755195, samples/s: 2207.756 1612379381.0447423
train: epoch 43, iter 2800, loss: 2.964600, top_1: 0.524922, top_k: 0.760898, samples/s: 2237.643 1612379392.4853292
train: epoch 43, iter 2900, loss: 3.020531, top_1: 0.522188, top_k: 0.758359, samples/s: 2206.732 1612379404.0862164
train: epoch 43, iter 3000, loss: 3.128229, top_1: 0.520742, top_k: 0.757109, samples/s: 2218.709 1612379415.62475
train: epoch 43, iter 3100, loss: 3.057981, top_1: 0.517344, top_k: 0.756367, samples/s: 2244.008 1612379427.0325918
train: epoch 43, iter 3200, loss: 2.843075, top_1: 0.518906, top_k: 0.752070, samples/s: 2220.440 1612379438.561848
train: epoch 43, iter 3300, loss: 2.874192, top_1: 0.520195, top_k: 0.755391, samples/s: 2209.854 1612379450.1463106
train: epoch 43, iter 3400, loss: 3.122620, top_1: 0.524492, top_k: 0.756133, samples/s: 2220.144 1612379461.6774592
train: epoch 43, iter 3500, loss: 2.814655, top_1: 0.517617, top_k: 0.751836, samples/s: 2215.201 1612379473.2336547
train: epoch 43, iter 3600, loss: 2.999807, top_1: 0.518594, top_k: 0.752852, samples/s: 2217.695 1612379484.7771833
train: epoch 43, iter 3700, loss: 2.894644, top_1: 0.515078, top_k: 0.757422, samples/s: 2213.813 1612379496.3408825
train: epoch 43, iter 3800, loss: 2.918416, top_1: 0.522695, top_k: 0.755469, samples/s: 2222.999 1612379507.8568976
train: epoch 43, iter 3900, loss: 2.878132, top_1: 0.515859, top_k: 0.755586, samples/s: 2220.869 1612379519.383867
train: epoch 43, iter 4000, loss: 3.166205, top_1: 0.520234, top_k: 0.757539, samples/s: 2217.302 1612379530.9295065
train: epoch 43, iter 4100, loss: 3.036036, top_1: 0.519023, top_k: 0.754922, samples/s: 2218.952 1612379542.4664679
train: epoch 43, iter 4200, loss: 3.055713, top_1: 0.523867, top_k: 0.760234, samples/s: 2227.499 1612379553.9591472
train: epoch 43, iter 4300, loss: 2.832633, top_1: 0.523477, top_k: 0.754336, samples/s: 2238.659 1612379565.3945472
train: epoch 43, iter 4400, loss: 2.898756, top_1: 0.525234, top_k: 0.759961, samples/s: 2223.743 1612379576.9066758
train: epoch 43, iter 4500, loss: 2.924968, top_1: 0.520508, top_k: 0.756484, samples/s: 2224.732 1612379588.4137423
train: epoch 43, iter 4600, loss: 2.898546, top_1: 0.522539, top_k: 0.755352, samples/s: 2216.424 1612379599.9638042
train: epoch 43, iter 4700, loss: 2.828286, top_1: 0.525391, top_k: 0.757930, samples/s: 2217.795 1612379611.5068734
train: epoch 43, iter 4800, loss: 3.129304, top_1: 0.521523, top_k: 0.753711, samples/s: 2221.550 1612379623.0303059
train: epoch 43, iter 4900, loss: 3.038328, top_1: 0.516523, top_k: 0.750977, samples/s: 2223.554 1612379634.543445
train: epoch 43, iter 5000, loss: 3.005205, top_1: 0.515938, top_k: 0.753789, samples/s: 2235.933 1612379645.9928038
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_43.
validation: epoch 43, iter 195, top_1: 0.573077, top_k: 0.812861, samples/s: 2892.663 1612379663.6027596
train: epoch 44, iter 100, loss: 2.893385, top_1: 0.528672, top_k: 0.761250, samples/s: 2230.637 1612379691.50429
train: epoch 44, iter 200, loss: 3.036780, top_1: 0.530664, top_k: 0.766563, samples/s: 2262.166 1612379702.8207843
train: epoch 44, iter 300, loss: 3.012789, top_1: 0.528008, top_k: 0.763437, samples/s: 2234.504 1612379714.2774525
train: epoch 44, iter 400, loss: 2.871237, top_1: 0.527852, top_k: 0.761680, samples/s: 2253.060 1612379725.6397848
train: epoch 44, iter 500, loss: 2.950510, top_1: 0.528398, top_k: 0.760977, samples/s: 2242.098 1612379737.0576594
train: epoch 44, iter 600, loss: 2.869308, top_1: 0.518437, top_k: 0.759414, samples/s: 2237.873 1612379748.497132
train: epoch 44, iter 700, loss: 3.111860, top_1: 0.522969, top_k: 0.759961, samples/s: 2253.546 1612379759.856965
train: epoch 44, iter 800, loss: 2.856099, top_1: 0.526367, top_k: 0.761055, samples/s: 2248.756 1612379771.2410386
train: epoch 44, iter 900, loss: 2.919719, top_1: 0.529375, top_k: 0.762617, samples/s: 2222.202 1612379782.761214
train: epoch 44, iter 1000, loss: 2.900702, top_1: 0.524453, top_k: 0.760508, samples/s: 2216.354 1612379794.3116548
train: epoch 44, iter 1100, loss: 3.103411, top_1: 0.526836, top_k: 0.759102, samples/s: 2211.075 1612379805.8897672
train: epoch 44, iter 1200, loss: 2.924940, top_1: 0.526406, top_k: 0.759727, samples/s: 2217.588 1612379817.4338365
train: epoch 44, iter 1300, loss: 3.121125, top_1: 0.525508, top_k: 0.762227, samples/s: 2224.878 1612379828.940046
train: epoch 44, iter 1400, loss: 2.980877, top_1: 0.521250, top_k: 0.758359, samples/s: 2230.778 1612379840.4158657
train: epoch 44, iter 1500, loss: 3.150959, top_1: 0.526094, top_k: 0.766758, samples/s: 2222.028 1612379851.936867
train: epoch 44, iter 1600, loss: 3.183681, top_1: 0.530703, top_k: 0.765430, samples/s: 2230.449 1612379863.4143968
train: epoch 44, iter 1700, loss: 2.935168, top_1: 0.527461, top_k: 0.764453, samples/s: 2229.863 1612379874.8949037
train: epoch 44, iter 1800, loss: 3.104374, top_1: 0.525937, top_k: 0.758164, samples/s: 2216.350 1612379886.4454334
train: epoch 44, iter 1900, loss: 2.913602, top_1: 0.519648, top_k: 0.758633, samples/s: 2229.180 1612379897.9294853
train: epoch 44, iter 2000, loss: 3.082592, top_1: 0.519727, top_k: 0.754453, samples/s: 2214.192 1612379909.4912932
train: epoch 44, iter 2100, loss: 3.039416, top_1: 0.525156, top_k: 0.761563, samples/s: 2213.160 1612379921.058443
train: epoch 44, iter 2200, loss: 3.090536, top_1: 0.522500, top_k: 0.759336, samples/s: 2247.700 1612379932.4479058
train: epoch 44, iter 2300, loss: 3.297950, top_1: 0.522617, top_k: 0.758711, samples/s: 2240.680 1612379943.872967
train: epoch 44, iter 2400, loss: 3.057639, top_1: 0.515820, top_k: 0.755313, samples/s: 2221.386 1612379955.397336
train: epoch 44, iter 2500, loss: 2.828327, top_1: 0.523242, top_k: 0.760312, samples/s: 2221.710 1612379966.9200542
train: epoch 44, iter 2600, loss: 3.049367, top_1: 0.527383, top_k: 0.756719, samples/s: 2226.449 1612379978.4181068
train: epoch 44, iter 2700, loss: 3.239021, top_1: 0.525273, top_k: 0.760234, samples/s: 2220.402 1612379989.947547
train: epoch 44, iter 2800, loss: 3.129333, top_1: 0.534297, top_k: 0.766055, samples/s: 2228.135 1612380001.4369783
train: epoch 44, iter 2900, loss: 2.955500, top_1: 0.523555, top_k: 0.757344, samples/s: 2242.299 1612380012.8538368
train: epoch 44, iter 3000, loss: 3.037396, top_1: 0.523633, top_k: 0.759766, samples/s: 2235.693 1612380024.3043945
train: epoch 44, iter 3100, loss: 2.995354, top_1: 0.524883, top_k: 0.762031, samples/s: 2231.031 1612380035.7789288
train: epoch 44, iter 3200, loss: 3.054258, top_1: 0.525508, top_k: 0.757188, samples/s: 2237.733 1612380047.219123
train: epoch 44, iter 3300, loss: 3.111852, top_1: 0.525781, top_k: 0.762617, samples/s: 2229.615 1612380058.7009754
train: epoch 44, iter 3400, loss: 2.891508, top_1: 0.519844, top_k: 0.756367, samples/s: 2241.716 1612380070.120726
train: epoch 44, iter 3500, loss: 2.981764, top_1: 0.519023, top_k: 0.757969, samples/s: 2247.635 1612380081.5104446
train: epoch 44, iter 3600, loss: 3.158230, top_1: 0.523320, top_k: 0.763867, samples/s: 2239.821 1612380092.9399636
train: epoch 44, iter 3700, loss: 3.063497, top_1: 0.519922, top_k: 0.756680, samples/s: 2248.906 1612380104.3232927
train: epoch 44, iter 3800, loss: 3.072310, top_1: 0.522656, top_k: 0.757383, samples/s: 2227.995 1612380115.8134205
train: epoch 44, iter 3900, loss: 3.090959, top_1: 0.516602, top_k: 0.755508, samples/s: 2247.857 1612380127.2020495
train: epoch 44, iter 4000, loss: 2.860456, top_1: 0.523633, top_k: 0.756484, samples/s: 2242.059 1612380138.6200986
train: epoch 44, iter 4100, loss: 2.872989, top_1: 0.521758, top_k: 0.759141, samples/s: 2239.119 1612380150.053217
train: epoch 44, iter 4200, loss: 2.879588, top_1: 0.519687, top_k: 0.757930, samples/s: 2241.828 1612380161.4724035
train: epoch 44, iter 4300, loss: 3.012086, top_1: 0.521992, top_k: 0.758906, samples/s: 2235.209 1612380172.9254518
train: epoch 44, iter 4400, loss: 2.995914, top_1: 0.523086, top_k: 0.760391, samples/s: 2209.172 1612380184.513557
train: epoch 44, iter 4500, loss: 2.945541, top_1: 0.531211, top_k: 0.763984, samples/s: 2253.532 1612380195.873479
train: epoch 44, iter 4600, loss: 3.126784, top_1: 0.516953, top_k: 0.750273, samples/s: 2250.278 1612380207.2498922
train: epoch 44, iter 4700, loss: 3.049564, top_1: 0.518594, top_k: 0.752930, samples/s: 2233.143 1612380218.7135396
train: epoch 44, iter 4800, loss: 2.976202, top_1: 0.523516, top_k: 0.756367, samples/s: 2203.086 1612380230.333641
train: epoch 44, iter 4900, loss: 2.970672, top_1: 0.526914, top_k: 0.760977, samples/s: 2239.117 1612380241.766644
train: epoch 44, iter 5000, loss: 2.917778, top_1: 0.523359, top_k: 0.761523, samples/s: 2215.623 1612380253.3209493
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_44.
validation: epoch 44, iter 195, top_1: 0.569551, top_k: 0.811018, samples/s: 2935.063 1612380270.7042775
train: epoch 45, iter 100, loss: 3.040656, top_1: 0.534727, top_k: 0.767969, samples/s: 2240.081 1612380298.2181387
train: epoch 45, iter 200, loss: 3.060976, top_1: 0.536445, top_k: 0.769961, samples/s: 2240.011 1612380309.6465707
train: epoch 45, iter 300, loss: 3.054564, top_1: 0.531836, top_k: 0.761914, samples/s: 2266.223 1612380320.9428918
train: epoch 45, iter 400, loss: 2.840275, top_1: 0.527344, top_k: 0.762500, samples/s: 2253.129 1612380332.3049548
train: epoch 45, iter 500, loss: 2.922527, top_1: 0.532227, top_k: 0.767148, samples/s: 2254.033 1612380343.6623356
train: epoch 45, iter 600, loss: 2.954363, top_1: 0.530898, top_k: 0.762227, samples/s: 2256.840 1612380355.0055923
train: epoch 45, iter 700, loss: 2.969370, top_1: 0.532578, top_k: 0.763867, samples/s: 2248.054 1612380366.3932612
train: epoch 45, iter 800, loss: 3.082253, top_1: 0.522188, top_k: 0.759062, samples/s: 2210.082 1612380377.9764988
train: epoch 45, iter 900, loss: 2.718663, top_1: 0.529609, top_k: 0.766445, samples/s: 2257.462 1612380389.3166823
train: epoch 45, iter 1000, loss: 3.094165, top_1: 0.525977, top_k: 0.761172, samples/s: 2226.065 1612380400.8174021
train: epoch 45, iter 1100, loss: 2.937204, top_1: 0.528516, top_k: 0.765703, samples/s: 2244.518 1612380412.222358
train: epoch 45, iter 1200, loss: 2.861480, top_1: 0.524062, top_k: 0.760781, samples/s: 2213.555 1612380423.7880526
train: epoch 45, iter 1300, loss: 2.816808, top_1: 0.522031, top_k: 0.756445, samples/s: 2226.231 1612380435.2867346
train: epoch 45, iter 1400, loss: 2.987514, top_1: 0.529727, top_k: 0.761953, samples/s: 2221.945 1612380446.8081782
train: epoch 45, iter 1500, loss: 2.994778, top_1: 0.531094, top_k: 0.765664, samples/s: 2223.560 1612380458.3212361
train: epoch 45, iter 1600, loss: 2.965445, top_1: 0.524102, top_k: 0.756641, samples/s: 2223.750 1612380469.8333364
train: epoch 45, iter 1700, loss: 3.149159, top_1: 0.529648, top_k: 0.759102, samples/s: 2229.393 1612380481.3162796
train: epoch 45, iter 1800, loss: 3.011741, top_1: 0.523672, top_k: 0.758047, samples/s: 2224.095 1612380492.8265631
train: epoch 45, iter 1900, loss: 2.944327, top_1: 0.524570, top_k: 0.759805, samples/s: 2227.958 1612380504.3169603
train: epoch 45, iter 2000, loss: 2.977174, top_1: 0.525312, top_k: 0.756992, samples/s: 2221.594 1612380515.8402143
train: epoch 45, iter 2100, loss: 3.007601, top_1: 0.522969, top_k: 0.758633, samples/s: 2225.901 1612380527.3411386
train: epoch 45, iter 2200, loss: 3.036216, top_1: 0.531406, top_k: 0.761367, samples/s: 2220.590 1612380538.8696012
train: epoch 45, iter 2300, loss: 3.115284, top_1: 0.523555, top_k: 0.758633, samples/s: 2207.581 1612380550.466071
train: epoch 45, iter 2400, loss: 2.942962, top_1: 0.519766, top_k: 0.760742, samples/s: 2222.646 1612380561.98381
train: epoch 45, iter 2500, loss: 2.926275, top_1: 0.521094, top_k: 0.759062, samples/s: 2205.516 1612380573.5910614
train: epoch 45, iter 2600, loss: 2.944263, top_1: 0.519883, top_k: 0.755117, samples/s: 2213.374 1612380585.1571426
train: epoch 45, iter 2700, loss: 2.894526, top_1: 0.520391, top_k: 0.757656, samples/s: 2212.131 1612380596.7296815
train: epoch 45, iter 2800, loss: 2.993240, top_1: 0.523047, top_k: 0.758086, samples/s: 2230.981 1612380608.2044396
train: epoch 45, iter 2900, loss: 2.949561, top_1: 0.525430, top_k: 0.761250, samples/s: 2210.048 1612380619.7879038
train: epoch 45, iter 3000, loss: 2.787533, top_1: 0.532031, top_k: 0.763750, samples/s: 2217.114 1612380631.3344417
train: epoch 45, iter 3100, loss: 2.718846, top_1: 0.526914, top_k: 0.759570, samples/s: 2235.297 1612380642.7871034
train: epoch 45, iter 3200, loss: 3.165908, top_1: 0.524531, top_k: 0.760664, samples/s: 2230.110 1612380654.2663114
train: epoch 45, iter 3300, loss: 3.272506, top_1: 0.522148, top_k: 0.754766, samples/s: 2224.643 1612380665.7738495
train: epoch 45, iter 3400, loss: 3.102592, top_1: 0.524062, top_k: 0.755820, samples/s: 2238.147 1612380677.211909
train: epoch 45, iter 3500, loss: 2.923505, top_1: 0.525586, top_k: 0.766367, samples/s: 2231.441 1612380688.68429
train: epoch 45, iter 3600, loss: 2.895391, top_1: 0.522070, top_k: 0.755820, samples/s: 2238.074 1612380700.1226275
train: epoch 45, iter 3700, loss: 3.168238, top_1: 0.519453, top_k: 0.753164, samples/s: 2230.182 1612380711.6015115
train: epoch 45, iter 3800, loss: 3.083232, top_1: 0.526445, top_k: 0.760469, samples/s: 2238.820 1612380723.0361063
train: epoch 45, iter 3900, loss: 2.917972, top_1: 0.530156, top_k: 0.758477, samples/s: 2241.123 1612380734.4589486
train: epoch 45, iter 4000, loss: 2.985939, top_1: 0.528711, top_k: 0.762695, samples/s: 2238.803 1612380745.8936489
train: epoch 45, iter 4100, loss: 3.200071, top_1: 0.520234, top_k: 0.758047, samples/s: 2237.433 1612380757.3353152
train: epoch 45, iter 4200, loss: 3.117102, top_1: 0.521016, top_k: 0.754180, samples/s: 2241.629 1612380768.755595
train: epoch 45, iter 4300, loss: 2.991857, top_1: 0.516133, top_k: 0.755195, samples/s: 2246.055 1612380780.1533449
train: epoch 45, iter 4400, loss: 2.928466, top_1: 0.525312, top_k: 0.761641, samples/s: 2249.612 1612380791.533121
train: epoch 45, iter 4500, loss: 3.080624, top_1: 0.521094, top_k: 0.757617, samples/s: 2223.901 1612380803.0444038
train: epoch 45, iter 4600, loss: 2.986405, top_1: 0.519062, top_k: 0.756914, samples/s: 2239.288 1612380814.476623
train: epoch 45, iter 4700, loss: 3.157443, top_1: 0.521953, top_k: 0.752344, samples/s: 2229.303 1612380825.960005
train: epoch 45, iter 4800, loss: 2.824171, top_1: 0.521875, top_k: 0.758828, samples/s: 2253.476 1612380837.3203175
train: epoch 45, iter 4900, loss: 2.877493, top_1: 0.524648, top_k: 0.757578, samples/s: 2252.626 1612380848.684805
train: epoch 45, iter 5000, loss: 2.997925, top_1: 0.530664, top_k: 0.765312, samples/s: 2233.105 1612380860.148604
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_45.
validation: epoch 45, iter 195, top_1: 0.560056, top_k: 0.805749, samples/s: 2898.154 1612380877.7072358
train: epoch 46, iter 100, loss: 3.016429, top_1: 0.541680, top_k: 0.768828, samples/s: 2218.085 1612380911.3438563
train: epoch 46, iter 200, loss: 2.886484, top_1: 0.531211, top_k: 0.762109, samples/s: 2264.957 1612380922.6466315
train: epoch 46, iter 300, loss: 2.932941, top_1: 0.537617, top_k: 0.771328, samples/s: 2239.237 1612380934.0789385
train: epoch 46, iter 400, loss: 2.666097, top_1: 0.530664, top_k: 0.767031, samples/s: 2278.120 1612380945.3163013
train: epoch 46, iter 500, loss: 3.027760, top_1: 0.535586, top_k: 0.767266, samples/s: 2252.426 1612380956.681799
train: epoch 46, iter 600, loss: 2.932021, top_1: 0.528555, top_k: 0.767148, samples/s: 2257.613 1612380968.0212314
train: epoch 46, iter 700, loss: 2.901789, top_1: 0.533164, top_k: 0.763867, samples/s: 2260.540 1612380979.346004
train: epoch 46, iter 800, loss: 2.971091, top_1: 0.525664, top_k: 0.765156, samples/s: 2231.357 1612380990.8188882
train: epoch 46, iter 900, loss: 2.791332, top_1: 0.538359, top_k: 0.768828, samples/s: 2234.659 1612381002.274675
train: epoch 46, iter 1000, loss: 3.135375, top_1: 0.530898, top_k: 0.764180, samples/s: 2239.096 1612381013.708205
train: epoch 46, iter 1100, loss: 2.968956, top_1: 0.523984, top_k: 0.761172, samples/s: 2246.543 1612381025.1031706
train: epoch 46, iter 1200, loss: 3.011117, top_1: 0.534922, top_k: 0.766250, samples/s: 2230.512 1612381036.5803869
train: epoch 46, iter 1300, loss: 2.984468, top_1: 0.532383, top_k: 0.763984, samples/s: 2206.279 1612381048.183663
train: epoch 46, iter 1400, loss: 3.140315, top_1: 0.537656, top_k: 0.770039, samples/s: 2239.307 1612381059.6156962
train: epoch 46, iter 1500, loss: 3.016103, top_1: 0.527031, top_k: 0.759922, samples/s: 2212.736 1612381071.1850648
train: epoch 46, iter 1600, loss: 2.861261, top_1: 0.531758, top_k: 0.764844, samples/s: 2205.023 1612381082.7949307
train: epoch 46, iter 1700, loss: 2.811981, top_1: 0.527578, top_k: 0.761758, samples/s: 2220.148 1612381094.3261106
train: epoch 46, iter 1800, loss: 2.828746, top_1: 0.526406, top_k: 0.758750, samples/s: 2232.975 1612381105.7902713
train: epoch 46, iter 1900, loss: 2.739964, top_1: 0.528945, top_k: 0.762773, samples/s: 2227.909 1612381117.2807915
train: epoch 46, iter 2000, loss: 3.058183, top_1: 0.533203, top_k: 0.763359, samples/s: 2210.382 1612381128.8625214
train: epoch 46, iter 2100, loss: 3.145992, top_1: 0.522383, top_k: 0.761563, samples/s: 2221.246 1612381140.3875635
train: epoch 46, iter 2200, loss: 2.847538, top_1: 0.533008, top_k: 0.764687, samples/s: 2235.791 1612381151.837654
train: epoch 46, iter 2300, loss: 2.965279, top_1: 0.522617, top_k: 0.755664, samples/s: 2213.567 1612381163.4027088
train: epoch 46, iter 2400, loss: 2.893509, top_1: 0.529492, top_k: 0.762852, samples/s: 2198.828 1612381175.0453246
train: epoch 46, iter 2500, loss: 2.818664, top_1: 0.528945, top_k: 0.763828, samples/s: 2228.715 1612381186.531699
train: epoch 46, iter 2600, loss: 3.161609, top_1: 0.525430, top_k: 0.760625, samples/s: 2208.897 1612381198.1212084
train: epoch 46, iter 2700, loss: 3.159435, top_1: 0.523984, top_k: 0.762969, samples/s: 2211.843 1612381209.6952906
train: epoch 46, iter 2800, loss: 2.999143, top_1: 0.521523, top_k: 0.754414, samples/s: 2219.179 1612381221.2310605
train: epoch 46, iter 2900, loss: 2.976133, top_1: 0.526406, top_k: 0.758242, samples/s: 2239.757 1612381232.660862
train: epoch 46, iter 3000, loss: 2.875648, top_1: 0.527188, top_k: 0.755781, samples/s: 2213.427 1612381244.2267494
train: epoch 46, iter 3100, loss: 2.879143, top_1: 0.521953, top_k: 0.754492, samples/s: 2229.634 1612381255.7083404
train: epoch 46, iter 3200, loss: 2.924343, top_1: 0.521953, top_k: 0.757266, samples/s: 2199.931 1612381267.3452349
train: epoch 46, iter 3300, loss: 3.029158, top_1: 0.526328, top_k: 0.758633, samples/s: 2251.681 1612381278.7143571
train: epoch 46, iter 3400, loss: 2.908181, top_1: 0.528789, top_k: 0.761523, samples/s: 2200.826 1612381290.3464215
train: epoch 46, iter 3500, loss: 3.063332, top_1: 0.522969, top_k: 0.758437, samples/s: 2216.330 1612381301.8969905
train: epoch 46, iter 3600, loss: 2.863315, top_1: 0.527031, top_k: 0.758984, samples/s: 2216.194 1612381313.448815
train: epoch 46, iter 3700, loss: 2.925663, top_1: 0.524531, top_k: 0.757656, samples/s: 2242.206 1612381324.8657017
train: epoch 46, iter 3800, loss: 2.922055, top_1: 0.525781, top_k: 0.759844, samples/s: 2215.124 1612381336.422921
train: epoch 46, iter 3900, loss: 2.889522, top_1: 0.520938, top_k: 0.759570, samples/s: 2217.315 1612381347.9681063
train: epoch 46, iter 4000, loss: 2.831703, top_1: 0.527344, top_k: 0.760117, samples/s: 2219.384 1612381359.5027847
train: epoch 46, iter 4100, loss: 3.172850, top_1: 0.523047, top_k: 0.759531, samples/s: 2208.034 1612381371.0968242
train: epoch 46, iter 4200, loss: 3.053516, top_1: 0.525664, top_k: 0.759336, samples/s: 2216.600 1612381382.6460466
train: epoch 46, iter 4300, loss: 2.845753, top_1: 0.528359, top_k: 0.760391, samples/s: 2227.051 1612381394.1410534
train: epoch 46, iter 4400, loss: 3.095140, top_1: 0.521797, top_k: 0.759531, samples/s: 2212.801 1612381405.7101374
train: epoch 46, iter 4500, loss: 3.013981, top_1: 0.525430, top_k: 0.757344, samples/s: 2217.656 1612381417.253878
train: epoch 46, iter 4600, loss: 2.830903, top_1: 0.523984, top_k: 0.759062, samples/s: 2227.124 1612381428.7485757
train: epoch 46, iter 4700, loss: 3.050445, top_1: 0.529219, top_k: 0.762539, samples/s: 2220.652 1612381440.2767081
train: epoch 46, iter 4800, loss: 2.887070, top_1: 0.523125, top_k: 0.760742, samples/s: 2211.041 1612381451.8549168
train: epoch 46, iter 4900, loss: 3.103727, top_1: 0.523359, top_k: 0.761172, samples/s: 2221.457 1612381463.3788917
train: epoch 46, iter 5000, loss: 3.061929, top_1: 0.527969, top_k: 0.759531, samples/s: 2220.818 1612381474.9061177
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_46.
validation: epoch 46, iter 195, top_1: 0.580929, top_k: 0.817588, samples/s: 2877.690 1612381492.603975
train: epoch 47, iter 100, loss: 3.070387, top_1: 0.537813, top_k: 0.768906, samples/s: 2225.949 1612381519.938088
train: epoch 47, iter 200, loss: 2.810699, top_1: 0.535781, top_k: 0.770742, samples/s: 2251.566 1612381531.3079169
train: epoch 47, iter 300, loss: 3.004748, top_1: 0.533086, top_k: 0.771406, samples/s: 2256.963 1612381542.6505837
train: epoch 47, iter 400, loss: 2.925408, top_1: 0.531133, top_k: 0.764648, samples/s: 2258.320 1612381553.9864357
train: epoch 47, iter 500, loss: 2.799209, top_1: 0.530703, top_k: 0.767930, samples/s: 2222.662 1612381565.5043328
train: epoch 47, iter 600, loss: 2.733481, top_1: 0.532188, top_k: 0.762500, samples/s: 2235.739 1612381576.9545116
train: epoch 47, iter 700, loss: 3.052636, top_1: 0.530898, top_k: 0.767813, samples/s: 2230.482 1612381588.4318671
train: epoch 47, iter 800, loss: 2.965624, top_1: 0.535469, top_k: 0.764375, samples/s: 2222.506 1612381599.9503834
train: epoch 47, iter 900, loss: 2.862804, top_1: 0.526016, top_k: 0.764687, samples/s: 2232.174 1612381611.4190893
train: epoch 47, iter 1000, loss: 3.004832, top_1: 0.527422, top_k: 0.765859, samples/s: 2215.781 1612381622.972504
train: epoch 47, iter 1100, loss: 2.955705, top_1: 0.534961, top_k: 0.763984, samples/s: 2223.650 1612381634.4851823
train: epoch 47, iter 1200, loss: 3.161803, top_1: 0.526523, top_k: 0.759961, samples/s: 2215.618 1612381646.0395358
train: epoch 47, iter 1300, loss: 3.004813, top_1: 0.535508, top_k: 0.771602, samples/s: 2196.053 1612381657.6967623
train: epoch 47, iter 1400, loss: 2.983205, top_1: 0.527773, top_k: 0.762188, samples/s: 2211.007 1612381669.275239
train: epoch 47, iter 1500, loss: 3.112879, top_1: 0.527461, top_k: 0.763828, samples/s: 2225.460 1612381680.7784224
train: epoch 47, iter 1600, loss: 2.994174, top_1: 0.527031, top_k: 0.763242, samples/s: 2179.188 1612381692.52589
train: epoch 47, iter 1700, loss: 2.917809, top_1: 0.523398, top_k: 0.759883, samples/s: 2219.990 1612381704.0575104
train: epoch 47, iter 1800, loss: 2.880418, top_1: 0.523867, top_k: 0.758906, samples/s: 2218.386 1612381715.597409
train: epoch 47, iter 1900, loss: 2.811410, top_1: 0.525937, top_k: 0.760195, samples/s: 2216.285 1612381727.1482804
train: epoch 47, iter 2000, loss: 2.941476, top_1: 0.526328, top_k: 0.762969, samples/s: 2220.869 1612381738.6756454
train: epoch 47, iter 2100, loss: 2.949569, top_1: 0.531719, top_k: 0.763945, samples/s: 2227.156 1612381750.1697583
train: epoch 47, iter 2200, loss: 2.810538, top_1: 0.525977, top_k: 0.763008, samples/s: 2223.082 1612381761.6853514
train: epoch 47, iter 2300, loss: 2.841403, top_1: 0.526289, top_k: 0.758242, samples/s: 2218.042 1612381773.2271307
train: epoch 47, iter 2400, loss: 2.832818, top_1: 0.523984, top_k: 0.756289, samples/s: 2223.898 1612381784.7386775
train: epoch 47, iter 2500, loss: 3.042417, top_1: 0.522227, top_k: 0.757695, samples/s: 2210.508 1612381796.3194363
train: epoch 47, iter 2600, loss: 3.000207, top_1: 0.526016, top_k: 0.766445, samples/s: 2234.504 1612381807.7760682
train: epoch 47, iter 2700, loss: 2.796751, top_1: 0.523906, top_k: 0.762500, samples/s: 2216.785 1612381819.3243284
train: epoch 47, iter 2800, loss: 2.762192, top_1: 0.523047, top_k: 0.764297, samples/s: 2190.943 1612381831.0093417
train: epoch 47, iter 2900, loss: 2.996126, top_1: 0.527656, top_k: 0.761602, samples/s: 2229.009 1612381842.493767
train: epoch 47, iter 3000, loss: 2.930973, top_1: 0.524180, top_k: 0.760508, samples/s: 2225.413 1612381853.997601
train: epoch 47, iter 3100, loss: 2.842842, top_1: 0.530547, top_k: 0.761328, samples/s: 2216.466 1612381865.5471885
train: epoch 47, iter 3200, loss: 2.910896, top_1: 0.524414, top_k: 0.761797, samples/s: 2208.473 1612381877.1388505
train: epoch 47, iter 3300, loss: 3.120266, top_1: 0.527031, top_k: 0.764180, samples/s: 2236.637 1612381888.5845664
train: epoch 47, iter 3400, loss: 2.899330, top_1: 0.523672, top_k: 0.758555, samples/s: 2217.879 1612381900.127268
train: epoch 47, iter 3500, loss: 2.955276, top_1: 0.525156, top_k: 0.758516, samples/s: 2214.875 1612381911.6854174
train: epoch 47, iter 3600, loss: 2.890216, top_1: 0.522734, top_k: 0.759883, samples/s: 2221.032 1612381923.2116215
train: epoch 47, iter 3700, loss: 2.876036, top_1: 0.528398, top_k: 0.763086, samples/s: 2231.265 1612381934.6849968
train: epoch 47, iter 3800, loss: 3.056949, top_1: 0.527266, top_k: 0.758789, samples/s: 2205.131 1612381946.2941294
train: epoch 47, iter 3900, loss: 3.006032, top_1: 0.529766, top_k: 0.764180, samples/s: 2229.073 1612381957.7787642
train: epoch 47, iter 4000, loss: 3.237529, top_1: 0.525977, top_k: 0.757070, samples/s: 2222.661 1612381969.29678
train: epoch 47, iter 4100, loss: 3.088228, top_1: 0.524844, top_k: 0.758906, samples/s: 2211.829 1612381980.8705952
train: epoch 47, iter 4200, loss: 2.905328, top_1: 0.524766, top_k: 0.758672, samples/s: 2207.674 1612381992.4665134
train: epoch 47, iter 4300, loss: 2.956301, top_1: 0.534922, top_k: 0.766133, samples/s: 2237.485 1612382003.9079351
train: epoch 47, iter 4400, loss: 2.773558, top_1: 0.528438, top_k: 0.759414, samples/s: 2218.240 1612382015.4487495
train: epoch 47, iter 4500, loss: 3.021110, top_1: 0.527734, top_k: 0.761328, samples/s: 2212.894 1612382027.0172317
train: epoch 47, iter 4600, loss: 2.828712, top_1: 0.528906, top_k: 0.761641, samples/s: 2228.576 1612382038.5043352
train: epoch 47, iter 4700, loss: 3.094618, top_1: 0.525156, top_k: 0.759414, samples/s: 2222.202 1612382050.0245032
train: epoch 47, iter 4800, loss: 2.828016, top_1: 0.523203, top_k: 0.762266, samples/s: 2223.451 1612382061.538114
train: epoch 47, iter 4900, loss: 2.958543, top_1: 0.527813, top_k: 0.763555, samples/s: 2199.751 1612382073.1759021
train: epoch 47, iter 5000, loss: 3.113023, top_1: 0.526406, top_k: 0.763555, samples/s: 2227.823 1612382084.6667743
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_47.
validation: epoch 47, iter 195, top_1: 0.584175, top_k: 0.820994, samples/s: 2923.281 1612382102.1115556
train: epoch 48, iter 100, loss: 2.832426, top_1: 0.535234, top_k: 0.769961, samples/s: 2244.358 1612382129.785449
train: epoch 48, iter 200, loss: 2.926368, top_1: 0.538164, top_k: 0.770078, samples/s: 2256.297 1612382141.1313052
train: epoch 48, iter 300, loss: 2.922509, top_1: 0.532188, top_k: 0.769141, samples/s: 2258.597 1612382152.465729
train: epoch 48, iter 400, loss: 2.992531, top_1: 0.536016, top_k: 0.767070, samples/s: 2237.651 1612382163.90641
train: epoch 48, iter 500, loss: 3.036957, top_1: 0.533398, top_k: 0.762500, samples/s: 2261.520 1612382175.2262056
train: epoch 48, iter 600, loss: 2.932029, top_1: 0.533477, top_k: 0.767422, samples/s: 2238.675 1612382186.6614864
train: epoch 48, iter 700, loss: 2.871792, top_1: 0.528750, top_k: 0.762266, samples/s: 2259.484 1612382197.9915087
train: epoch 48, iter 800, loss: 2.958425, top_1: 0.525937, top_k: 0.761680, samples/s: 2242.662 1612382209.4065917
train: epoch 48, iter 900, loss: 2.756291, top_1: 0.533945, top_k: 0.764180, samples/s: 2219.449 1612382220.9409056
train: epoch 48, iter 1000, loss: 2.788852, top_1: 0.526523, top_k: 0.763984, samples/s: 2212.907 1612382232.5094366
train: epoch 48, iter 1100, loss: 2.935566, top_1: 0.533906, top_k: 0.766367, samples/s: 2230.621 1612382243.9860406
train: epoch 48, iter 1200, loss: 2.798490, top_1: 0.531094, top_k: 0.764062, samples/s: 2224.182 1612382255.4958863
train: epoch 48, iter 1300, loss: 3.001562, top_1: 0.524531, top_k: 0.760391, samples/s: 2215.572 1612382267.0505579
train: epoch 48, iter 1400, loss: 2.961180, top_1: 0.534414, top_k: 0.763437, samples/s: 2232.908 1612382278.5153344
train: epoch 48, iter 1500, loss: 2.818401, top_1: 0.532422, top_k: 0.770000, samples/s: 2209.647 1612382290.1009676
train: epoch 48, iter 1600, loss: 2.873253, top_1: 0.523477, top_k: 0.759648, samples/s: 2219.730 1612382301.6338234
train: epoch 48, iter 1700, loss: 2.879252, top_1: 0.532070, top_k: 0.763203, samples/s: 2224.478 1612382313.1421485
train: epoch 48, iter 1800, loss: 2.962890, top_1: 0.530234, top_k: 0.763164, samples/s: 2222.623 1612382324.6600986
train: epoch 48, iter 1900, loss: 2.917015, top_1: 0.526055, top_k: 0.761797, samples/s: 2198.326 1612382336.305336
train: epoch 48, iter 2000, loss: 2.745077, top_1: 0.531836, top_k: 0.765977, samples/s: 2230.498 1612382347.782541
train: epoch 48, iter 2100, loss: 2.916963, top_1: 0.533359, top_k: 0.761836, samples/s: 2235.005 1612382359.2366557
train: epoch 48, iter 2200, loss: 2.930305, top_1: 0.531172, top_k: 0.763477, samples/s: 2249.536 1612382370.616788
train: epoch 48, iter 2300, loss: 2.982318, top_1: 0.535703, top_k: 0.766250, samples/s: 2230.691 1612382382.0930836
train: epoch 48, iter 2400, loss: 3.054477, top_1: 0.530039, top_k: 0.763359, samples/s: 2247.741 1612382393.4823103
train: epoch 48, iter 2500, loss: 3.119235, top_1: 0.524531, top_k: 0.760664, samples/s: 2233.898 1612382404.9420538
train: epoch 48, iter 2600, loss: 2.992507, top_1: 0.527578, top_k: 0.759258, samples/s: 2233.400 1612382416.4044127
train: epoch 48, iter 2700, loss: 3.058964, top_1: 0.530859, top_k: 0.766445, samples/s: 2242.502 1612382427.8202221
train: epoch 48, iter 2800, loss: 2.937309, top_1: 0.523477, top_k: 0.761953, samples/s: 2203.558 1612382439.4378614
train: epoch 48, iter 2900, loss: 2.941765, top_1: 0.526133, top_k: 0.756914, samples/s: 2253.837 1612382450.79626
train: epoch 48, iter 3000, loss: 3.028769, top_1: 0.530977, top_k: 0.763242, samples/s: 2221.925 1612382462.3177423
train: epoch 48, iter 3100, loss: 3.222946, top_1: 0.529805, top_k: 0.758555, samples/s: 2216.027 1612382473.8699028
train: epoch 48, iter 3200, loss: 2.901221, top_1: 0.531094, top_k: 0.763437, samples/s: 2245.100 1612382485.2725656
train: epoch 48, iter 3300, loss: 2.929742, top_1: 0.532891, top_k: 0.766758, samples/s: 2243.152 1612382496.6850693
train: epoch 48, iter 3400, loss: 2.848097, top_1: 0.525312, top_k: 0.760469, samples/s: 2257.255 1612382508.026281
train: epoch 48, iter 3500, loss: 3.148653, top_1: 0.526992, top_k: 0.762031, samples/s: 2252.624 1612382519.3909066
train: epoch 48, iter 3600, loss: 2.870294, top_1: 0.526602, top_k: 0.761758, samples/s: 2238.364 1612382530.8277504
train: epoch 48, iter 3700, loss: 2.785207, top_1: 0.530820, top_k: 0.766172, samples/s: 2230.354 1612382542.3057694
train: epoch 48, iter 3800, loss: 2.980181, top_1: 0.531875, top_k: 0.763203, samples/s: 2243.485 1612382553.7165492
train: epoch 48, iter 3900, loss: 2.941693, top_1: 0.533242, top_k: 0.768164, samples/s: 2246.029 1612382565.114434
train: epoch 48, iter 4000, loss: 2.914444, top_1: 0.527578, top_k: 0.762148, samples/s: 2252.005 1612382576.4820774
train: epoch 48, iter 4100, loss: 2.964453, top_1: 0.523867, top_k: 0.763789, samples/s: 2235.386 1612382587.934331
train: epoch 48, iter 4200, loss: 2.884975, top_1: 0.524687, top_k: 0.763555, samples/s: 2257.164 1612382599.275964
train: epoch 48, iter 4300, loss: 3.036964, top_1: 0.528711, top_k: 0.763008, samples/s: 2230.889 1612382610.7512205
train: epoch 48, iter 4400, loss: 2.952837, top_1: 0.533516, top_k: 0.765938, samples/s: 2248.667 1612382622.1357162
train: epoch 48, iter 4500, loss: 2.933632, top_1: 0.531055, top_k: 0.765039, samples/s: 2236.377 1612382633.5828602
train: epoch 48, iter 4600, loss: 3.189331, top_1: 0.522969, top_k: 0.756680, samples/s: 2253.862 1612382644.941059
train: epoch 48, iter 4700, loss: 2.798251, top_1: 0.528398, top_k: 0.761914, samples/s: 2216.713 1612382656.4898212
train: epoch 48, iter 4800, loss: 2.909827, top_1: 0.527930, top_k: 0.761016, samples/s: 2229.985 1612382667.969577
train: epoch 48, iter 4900, loss: 2.844561, top_1: 0.527031, top_k: 0.766719, samples/s: 2221.457 1612382679.4935534
train: epoch 48, iter 5000, loss: 3.191902, top_1: 0.533477, top_k: 0.766563, samples/s: 2263.606 1612382690.8029401
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_48.
validation: epoch 48, iter 195, top_1: 0.574038, top_k: 0.811879, samples/s: 2871.013 1612382708.5285628
train: epoch 49, iter 100, loss: 2.806610, top_1: 0.542305, top_k: 0.776094, samples/s: 2228.560 1612382736.5988066
train: epoch 49, iter 200, loss: 3.021420, top_1: 0.538672, top_k: 0.770820, samples/s: 2244.549 1612382748.004635
train: epoch 49, iter 300, loss: 2.894408, top_1: 0.536367, top_k: 0.769102, samples/s: 2244.045 1612382759.412243
train: epoch 49, iter 400, loss: 3.058903, top_1: 0.537031, top_k: 0.775508, samples/s: 2223.273 1612382770.927106
train: epoch 49, iter 500, loss: 2.873553, top_1: 0.537578, top_k: 0.766914, samples/s: 2274.175 1612382782.1835706
train: epoch 49, iter 600, loss: 2.982092, top_1: 0.540000, top_k: 0.770703, samples/s: 2249.243 1612382793.5652077
train: epoch 49, iter 700, loss: 2.888234, top_1: 0.533711, top_k: 0.769648, samples/s: 2253.231 1612382804.9266531
train: epoch 49, iter 800, loss: 3.065996, top_1: 0.532656, top_k: 0.766563, samples/s: 2245.537 1612382816.3270652
train: epoch 49, iter 900, loss: 2.955327, top_1: 0.538320, top_k: 0.768555, samples/s: 2238.093 1612382827.7653372
train: epoch 49, iter 1000, loss: 2.968336, top_1: 0.536172, top_k: 0.769687, samples/s: 2245.034 1612382839.1682737
train: epoch 49, iter 1100, loss: 2.949794, top_1: 0.535391, top_k: 0.765078, samples/s: 2220.809 1612382850.6956081
train: epoch 49, iter 1200, loss: 3.067640, top_1: 0.537422, top_k: 0.766563, samples/s: 2236.719 1612382862.1409533
train: epoch 49, iter 1300, loss: 3.081459, top_1: 0.538594, top_k: 0.769961, samples/s: 2223.212 1612382873.65585
train: epoch 49, iter 1400, loss: 2.948116, top_1: 0.539023, top_k: 0.769922, samples/s: 2231.532 1612382885.1280372
train: epoch 49, iter 1500, loss: 2.861980, top_1: 0.528906, top_k: 0.760586, samples/s: 2229.826 1612382896.6084983
train: epoch 49, iter 1600, loss: 2.813123, top_1: 0.532109, top_k: 0.769570, samples/s: 2197.848 1612382908.2566142
train: epoch 49, iter 1700, loss: 2.822184, top_1: 0.524297, top_k: 0.762031, samples/s: 2233.071 1612382919.7202318
train: epoch 49, iter 1800, loss: 2.943559, top_1: 0.532969, top_k: 0.765742, samples/s: 2226.145 1612382931.2199912
train: epoch 49, iter 1900, loss: 3.081307, top_1: 0.525898, top_k: 0.763203, samples/s: 2231.990 1612382942.6895447
train: epoch 49, iter 2000, loss: 3.116848, top_1: 0.527422, top_k: 0.764570, samples/s: 2219.515 1612382954.2235854
train: epoch 49, iter 2100, loss: 2.921751, top_1: 0.534102, top_k: 0.769062, samples/s: 2227.983 1612382965.7138371
train: epoch 49, iter 2200, loss: 2.914922, top_1: 0.529844, top_k: 0.762969, samples/s: 2211.686 1612382977.289023
train: epoch 49, iter 2300, loss: 3.010959, top_1: 0.533672, top_k: 0.766172, samples/s: 2200.761 1612382988.9210336
train: epoch 49, iter 2400, loss: 2.986576, top_1: 0.534297, top_k: 0.768047, samples/s: 2206.332 1612383000.5245113
train: epoch 49, iter 2500, loss: 2.862121, top_1: 0.528555, top_k: 0.759062, samples/s: 2245.624 1612383011.924056
train: epoch 49, iter 2600, loss: 3.018580, top_1: 0.523789, top_k: 0.757930, samples/s: 2224.154 1612383023.4342763
train: epoch 49, iter 2700, loss: 2.781059, top_1: 0.531680, top_k: 0.766641, samples/s: 2217.315 1612383034.9794524
train: epoch 49, iter 2800, loss: 2.945433, top_1: 0.530742, top_k: 0.765195, samples/s: 2228.821 1612383046.4653313
train: epoch 49, iter 2900, loss: 3.007777, top_1: 0.529648, top_k: 0.762930, samples/s: 2210.225 1612383058.04793
train: epoch 49, iter 3000, loss: 2.928239, top_1: 0.531484, top_k: 0.761680, samples/s: 2246.342 1612383069.4441826
train: epoch 49, iter 3100, loss: 2.800833, top_1: 0.525117, top_k: 0.759609, samples/s: 2216.094 1612383080.9960423
train: epoch 49, iter 3200, loss: 2.978877, top_1: 0.525859, top_k: 0.760547, samples/s: 2219.364 1612383092.53087
train: epoch 49, iter 3300, loss: 3.229006, top_1: 0.530156, top_k: 0.762773, samples/s: 2190.504 1612383104.2176783
train: epoch 49, iter 3400, loss: 3.011461, top_1: 0.528281, top_k: 0.763984, samples/s: 2216.900 1612383115.7653844
train: epoch 49, iter 3500, loss: 2.953201, top_1: 0.520312, top_k: 0.760000, samples/s: 2195.884 1612383127.423541
train: epoch 49, iter 3600, loss: 3.073876, top_1: 0.532500, top_k: 0.758594, samples/s: 2223.743 1612383138.9357228
train: epoch 49, iter 3700, loss: 3.008127, top_1: 0.535430, top_k: 0.763398, samples/s: 2230.074 1612383150.4150743
train: epoch 49, iter 3800, loss: 3.008981, top_1: 0.526523, top_k: 0.760977, samples/s: 2201.103 1612383162.0456188
train: epoch 49, iter 3900, loss: 3.004242, top_1: 0.531563, top_k: 0.761094, samples/s: 2242.189 1612383173.463063
train: epoch 49, iter 4000, loss: 2.994812, top_1: 0.524375, top_k: 0.760039, samples/s: 2220.362 1612383184.9926887
train: epoch 49, iter 4100, loss: 2.880509, top_1: 0.528672, top_k: 0.759922, samples/s: 2224.517 1612383196.500817
train: epoch 49, iter 4200, loss: 2.897550, top_1: 0.528359, top_k: 0.764687, samples/s: 2226.938 1612383207.9964714
train: epoch 49, iter 4300, loss: 2.966197, top_1: 0.532305, top_k: 0.762734, samples/s: 2229.043 1612383219.4811332
train: epoch 49, iter 4400, loss: 3.028145, top_1: 0.530195, top_k: 0.762930, samples/s: 2224.470 1612383230.989492
train: epoch 49, iter 4500, loss: 2.895557, top_1: 0.531445, top_k: 0.766641, samples/s: 2218.193 1612383242.5304291
train: epoch 49, iter 4600, loss: 2.979519, top_1: 0.532422, top_k: 0.763086, samples/s: 2214.776 1612383254.0891538
train: epoch 49, iter 4700, loss: 2.947777, top_1: 0.534180, top_k: 0.762539, samples/s: 2255.615 1612383265.4386058
train: epoch 49, iter 4800, loss: 2.926060, top_1: 0.526563, top_k: 0.762461, samples/s: 2230.925 1612383276.9137118
train: epoch 49, iter 4900, loss: 2.916711, top_1: 0.527617, top_k: 0.761680, samples/s: 2245.953 1612383288.3119812
train: epoch 49, iter 5000, loss: 2.772555, top_1: 0.530859, top_k: 0.766602, samples/s: 2215.145 1612383299.868831
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_49.
validation: epoch 49, iter 195, top_1: 0.574359, top_k: 0.812139, samples/s: 2954.834 1612383317.020097
train: epoch 50, iter 100, loss: 2.912594, top_1: 0.545430, top_k: 0.776367, samples/s: 2242.278 1612383345.5161283
train: epoch 50, iter 200, loss: 3.089373, top_1: 0.541562, top_k: 0.772070, samples/s: 2251.179 1612383356.8879292
train: epoch 50, iter 300, loss: 2.984671, top_1: 0.541445, top_k: 0.771563, samples/s: 2242.717 1612383368.30272
train: epoch 50, iter 400, loss: 3.050752, top_1: 0.537734, top_k: 0.773281, samples/s: 2274.712 1612383379.557016
train: epoch 50, iter 500, loss: 3.002000, top_1: 0.536484, top_k: 0.770273, samples/s: 2244.552 1612383390.9623559
train: epoch 50, iter 600, loss: 2.956783, top_1: 0.534258, top_k: 0.765977, samples/s: 2251.488 1612383402.3325129
train: epoch 50, iter 700, loss: 3.141844, top_1: 0.532578, top_k: 0.768906, samples/s: 2259.249 1612383413.6636906
train: epoch 50, iter 800, loss: 2.974560, top_1: 0.533203, top_k: 0.765508, samples/s: 2218.734 1612383425.2018898
train: epoch 50, iter 900, loss: 2.939325, top_1: 0.533906, top_k: 0.762070, samples/s: 2269.829 1612383436.480211
train: epoch 50, iter 1000, loss: 2.708494, top_1: 0.536289, top_k: 0.772773, samples/s: 2245.465 1612383447.8809416
train: epoch 50, iter 1100, loss: 2.977570, top_1: 0.535000, top_k: 0.769766, samples/s: 2209.011 1612383459.4698236
train: epoch 50, iter 1200, loss: 3.065335, top_1: 0.534922, top_k: 0.770156, samples/s: 2206.146 1612383471.07377
train: epoch 50, iter 1300, loss: 2.853855, top_1: 0.532734, top_k: 0.769727, samples/s: 2224.703 1612383482.5809343
train: epoch 50, iter 1400, loss: 2.858322, top_1: 0.533125, top_k: 0.767305, samples/s: 2221.484 1612383494.1047554
train: epoch 50, iter 1500, loss: 3.048479, top_1: 0.532617, top_k: 0.766641, samples/s: 2220.366 1612383505.6345685
train: epoch 50, iter 1600, loss: 2.845392, top_1: 0.532500, top_k: 0.765430, samples/s: 2217.570 1612383517.1785638
train: epoch 50, iter 1700, loss: 3.095840, top_1: 0.531211, top_k: 0.763828, samples/s: 2236.057 1612383528.627481
train: epoch 50, iter 1800, loss: 3.246348, top_1: 0.535703, top_k: 0.763555, samples/s: 2219.714 1612383540.1603765
train: epoch 50, iter 1900, loss: 2.878042, top_1: 0.534805, top_k: 0.765586, samples/s: 2243.084 1612383551.5731604
train: epoch 50, iter 2000, loss: 2.798007, top_1: 0.531953, top_k: 0.764062, samples/s: 2224.680 1612383563.0805027
train: epoch 50, iter 2100, loss: 3.035531, top_1: 0.531602, top_k: 0.765469, samples/s: 2218.105 1612383574.621827
train: epoch 50, iter 2200, loss: 2.985264, top_1: 0.529531, top_k: 0.764258, samples/s: 2220.412 1612383586.151304
train: epoch 50, iter 2300, loss: 2.934968, top_1: 0.532266, top_k: 0.761211, samples/s: 2219.866 1612383597.6834369
train: epoch 50, iter 2400, loss: 2.900621, top_1: 0.535156, top_k: 0.766484, samples/s: 2194.112 1612383609.351017
train: epoch 50, iter 2500, loss: 2.897936, top_1: 0.528008, top_k: 0.763203, samples/s: 2238.253 1612383620.788513
train: epoch 50, iter 2600, loss: 2.899909, top_1: 0.536680, top_k: 0.770078, samples/s: 2228.484 1612383632.276146
train: epoch 50, iter 2700, loss: 2.907505, top_1: 0.530234, top_k: 0.766406, samples/s: 2224.742 1612383643.7831006
train: epoch 50, iter 2800, loss: 2.893410, top_1: 0.528594, top_k: 0.763594, samples/s: 2223.507 1612383655.296444
train: epoch 50, iter 2900, loss: 2.950598, top_1: 0.533438, top_k: 0.764531, samples/s: 2243.090 1612383666.7092729
train: epoch 50, iter 3000, loss: 3.126630, top_1: 0.527422, top_k: 0.763398, samples/s: 2231.576 1612383678.1809933
train: epoch 50, iter 3100, loss: 2.998821, top_1: 0.528984, top_k: 0.766641, samples/s: 2230.518 1612383689.658132
train: epoch 50, iter 3200, loss: 2.973228, top_1: 0.536563, top_k: 0.765508, samples/s: 2253.308 1612383701.01924
train: epoch 50, iter 3300, loss: 3.056422, top_1: 0.534648, top_k: 0.766875, samples/s: 2200.315 1612383712.6539512
train: epoch 50, iter 3400, loss: 3.089144, top_1: 0.530039, top_k: 0.764336, samples/s: 2233.868 1612383724.1138535
train: epoch 50, iter 3500, loss: 2.847936, top_1: 0.522617, top_k: 0.760352, samples/s: 2193.429 1612383735.7851436
train: epoch 50, iter 3600, loss: 2.953217, top_1: 0.527266, top_k: 0.763711, samples/s: 2238.303 1612383747.2223077
train: epoch 50, iter 3700, loss: 3.085736, top_1: 0.529687, top_k: 0.762617, samples/s: 2234.693 1612383758.6780477
train: epoch 50, iter 3800, loss: 3.016215, top_1: 0.526328, top_k: 0.762656, samples/s: 2221.307 1612383770.2027688
train: epoch 50, iter 3900, loss: 2.904943, top_1: 0.531172, top_k: 0.767695, samples/s: 2209.497 1612383781.7891216
train: epoch 50, iter 4000, loss: 2.871031, top_1: 0.529805, top_k: 0.764180, samples/s: 2229.398 1612383793.2720299
train: epoch 50, iter 4100, loss: 3.058539, top_1: 0.527266, top_k: 0.761172, samples/s: 2254.997 1612383804.6245916
train: epoch 50, iter 4200, loss: 2.951256, top_1: 0.528555, top_k: 0.764844, samples/s: 2233.016 1612383816.0889301
train: epoch 50, iter 4300, loss: 2.915894, top_1: 0.528203, top_k: 0.762656, samples/s: 2229.129 1612383827.5733755
train: epoch 50, iter 4400, loss: 3.014802, top_1: 0.530469, top_k: 0.766602, samples/s: 2241.343 1612383838.994936
train: epoch 50, iter 4500, loss: 2.941387, top_1: 0.526484, top_k: 0.759648, samples/s: 2235.512 1612383850.4465814
train: epoch 50, iter 4600, loss: 2.914253, top_1: 0.528984, top_k: 0.764180, samples/s: 2250.924 1612383861.8195715
train: epoch 50, iter 4700, loss: 2.886459, top_1: 0.533594, top_k: 0.764102, samples/s: 2239.303 1612383873.2516983
train: epoch 50, iter 4800, loss: 2.874894, top_1: 0.536445, top_k: 0.769492, samples/s: 2245.874 1612383884.6503932
train: epoch 50, iter 4900, loss: 2.868173, top_1: 0.529414, top_k: 0.764375, samples/s: 2235.165 1612383896.1036758
train: epoch 50, iter 5000, loss: 2.875842, top_1: 0.535469, top_k: 0.766797, samples/s: 2233.265 1612383907.5667188
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_50.
validation: epoch 50, iter 195, top_1: 0.578746, top_k: 0.818369, samples/s: 2937.738 1612383924.8476717
train: epoch 51, iter 100, loss: 3.143237, top_1: 0.544648, top_k: 0.766914, samples/s: 2242.904 1612383952.6841931
train: epoch 51, iter 200, loss: 2.835886, top_1: 0.535977, top_k: 0.767969, samples/s: 2255.672 1612383964.033553
train: epoch 51, iter 300, loss: 2.819016, top_1: 0.531680, top_k: 0.762383, samples/s: 2244.097 1612383975.4410715
train: epoch 51, iter 400, loss: 2.944072, top_1: 0.537813, top_k: 0.770820, samples/s: 2257.905 1612383986.7789736
train: epoch 51, iter 500, loss: 2.887677, top_1: 0.541250, top_k: 0.774922, samples/s: 2251.679 1612383998.1482706
train: epoch 51, iter 600, loss: 2.959111, top_1: 0.536367, top_k: 0.768398, samples/s: 2225.215 1612384009.6528866
train: epoch 51, iter 700, loss: 2.833558, top_1: 0.540000, top_k: 0.771680, samples/s: 2263.717 1612384020.9616344
train: epoch 51, iter 800, loss: 2.995206, top_1: 0.538320, top_k: 0.770156, samples/s: 2225.705 1612384032.4635956
train: epoch 51, iter 900, loss: 2.972141, top_1: 0.537148, top_k: 0.769102, samples/s: 2241.509 1612384043.884472
train: epoch 51, iter 1000, loss: 3.127005, top_1: 0.539492, top_k: 0.771328, samples/s: 2240.620 1612384055.3099449
train: epoch 51, iter 1100, loss: 2.824904, top_1: 0.532422, top_k: 0.765195, samples/s: 2225.888 1612384066.8108969
train: epoch 51, iter 1200, loss: 2.923412, top_1: 0.540547, top_k: 0.769453, samples/s: 2219.750 1612384078.3437967
train: epoch 51, iter 1300, loss: 2.827435, top_1: 0.534922, top_k: 0.765352, samples/s: 2214.563 1612384089.9035687
train: epoch 51, iter 1400, loss: 2.898925, top_1: 0.533008, top_k: 0.764219, samples/s: 2237.131 1612384101.3467922
train: epoch 51, iter 1500, loss: 2.944165, top_1: 0.537383, top_k: 0.766211, samples/s: 2234.035 1612384112.8059509
train: epoch 51, iter 1600, loss: 3.106750, top_1: 0.526563, top_k: 0.763242, samples/s: 2212.751 1612384124.3752093
train: epoch 51, iter 1700, loss: 2.896858, top_1: 0.533672, top_k: 0.763125, samples/s: 2222.573 1612384135.8934112
train: epoch 51, iter 1800, loss: 3.025743, top_1: 0.534141, top_k: 0.768320, samples/s: 2233.987 1612384147.3527548
train: epoch 51, iter 1900, loss: 3.095556, top_1: 0.530664, top_k: 0.764453, samples/s: 2209.594 1612384158.9386055
train: epoch 51, iter 2000, loss: 2.881447, top_1: 0.532031, top_k: 0.764492, samples/s: 2246.228 1612384170.3355155
train: epoch 51, iter 2100, loss: 2.889675, top_1: 0.534570, top_k: 0.766172, samples/s: 2223.321 1612384181.849747
train: epoch 51, iter 2200, loss: 2.993558, top_1: 0.534023, top_k: 0.768750, samples/s: 2209.366 1612384193.4367824
train: epoch 51, iter 2300, loss: 2.996514, top_1: 0.539336, top_k: 0.768945, samples/s: 2227.370 1612384204.930216
train: epoch 51, iter 2400, loss: 2.939167, top_1: 0.536680, top_k: 0.765781, samples/s: 2221.734 1612384216.452708
train: epoch 51, iter 2500, loss: 3.030744, top_1: 0.535391, top_k: 0.766367, samples/s: 2223.114 1612384227.9680638
train: epoch 51, iter 2600, loss: 2.957278, top_1: 0.535273, top_k: 0.769609, samples/s: 2213.412 1612384239.533911
train: epoch 51, iter 2700, loss: 3.075169, top_1: 0.533438, top_k: 0.763242, samples/s: 2226.693 1612384251.0308561
train: epoch 51, iter 2800, loss: 2.920320, top_1: 0.523789, top_k: 0.761836, samples/s: 2227.622 1612384262.5228605
train: epoch 51, iter 2900, loss: 3.124252, top_1: 0.535156, top_k: 0.767188, samples/s: 2213.105 1612384274.0903754
train: epoch 51, iter 3000, loss: 2.974657, top_1: 0.523867, top_k: 0.757422, samples/s: 2232.281 1612384285.5584044
train: epoch 51, iter 3100, loss: 3.045248, top_1: 0.531992, top_k: 0.765703, samples/s: 2215.798 1612384297.1118128
train: epoch 51, iter 3200, loss: 2.962137, top_1: 0.529922, top_k: 0.766523, samples/s: 2243.796 1612384308.521032
train: epoch 51, iter 3300, loss: 2.878603, top_1: 0.530391, top_k: 0.763867, samples/s: 2227.966 1612384320.0113297
train: epoch 51, iter 3400, loss: 2.957919, top_1: 0.530898, top_k: 0.765039, samples/s: 2240.051 1612384331.4397802
train: epoch 51, iter 3500, loss: 2.888638, top_1: 0.537461, top_k: 0.765312, samples/s: 2237.340 1612384342.881811
train: epoch 51, iter 3600, loss: 2.859353, top_1: 0.536172, top_k: 0.768633, samples/s: 2212.846 1612384354.450628
train: epoch 51, iter 3700, loss: 3.053119, top_1: 0.534180, top_k: 0.764375, samples/s: 2248.854 1612384365.8342936
train: epoch 51, iter 3800, loss: 2.909614, top_1: 0.523516, top_k: 0.761094, samples/s: 2251.255 1612384377.205716
train: epoch 51, iter 3900, loss: 2.973631, top_1: 0.531016, top_k: 0.765703, samples/s: 2217.988 1612384388.747639
train: epoch 51, iter 4000, loss: 2.936132, top_1: 0.535781, top_k: 0.770312, samples/s: 2252.681 1612384400.111923
train: epoch 51, iter 4100, loss: 2.984102, top_1: 0.531328, top_k: 0.764258, samples/s: 2244.066 1612384411.5197458
train: epoch 51, iter 4200, loss: 2.849741, top_1: 0.528555, top_k: 0.761563, samples/s: 2248.287 1612384422.906148
train: epoch 51, iter 4300, loss: 3.110940, top_1: 0.531484, top_k: 0.760547, samples/s: 2238.178 1612384434.3441877
train: epoch 51, iter 4400, loss: 3.007891, top_1: 0.525391, top_k: 0.762773, samples/s: 2249.225 1612384445.7257993
train: epoch 51, iter 4500, loss: 2.917131, top_1: 0.534414, top_k: 0.767461, samples/s: 2247.572 1612384457.115823
train: epoch 51, iter 4600, loss: 2.770436, top_1: 0.536328, top_k: 0.766367, samples/s: 2231.835 1612384468.5862613
train: epoch 51, iter 4700, loss: 3.030741, top_1: 0.531563, top_k: 0.761992, samples/s: 2230.673 1612384480.0625677
train: epoch 51, iter 4800, loss: 2.936587, top_1: 0.537383, top_k: 0.769492, samples/s: 2245.418 1612384491.4636085
train: epoch 51, iter 4900, loss: 3.135149, top_1: 0.532852, top_k: 0.761367, samples/s: 2240.121 1612384502.8915298
train: epoch 51, iter 5000, loss: 2.909781, top_1: 0.533789, top_k: 0.767500, samples/s: 2255.640 1612384514.2409005
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_51.
validation: epoch 51, iter 195, top_1: 0.580168, top_k: 0.819952, samples/s: 2932.670 1612384531.6077776
train: epoch 52, iter 100, loss: 2.933183, top_1: 0.539453, top_k: 0.773164, samples/s: 2226.351 1612384558.8930752
train: epoch 52, iter 200, loss: 2.999791, top_1: 0.538125, top_k: 0.772305, samples/s: 2248.740 1612384570.2772434
train: epoch 52, iter 300, loss: 2.890429, top_1: 0.542266, top_k: 0.776953, samples/s: 2242.728 1612384581.691909
train: epoch 52, iter 400, loss: 3.059719, top_1: 0.540547, top_k: 0.774453, samples/s: 2253.498 1612384593.0521188
train: epoch 52, iter 500, loss: 2.777522, top_1: 0.535117, top_k: 0.767227, samples/s: 2263.688 1612384604.361338
train: epoch 52, iter 600, loss: 2.945745, top_1: 0.536836, top_k: 0.771172, samples/s: 2228.575 1612384615.8482323
train: epoch 52, iter 700, loss: 2.826949, top_1: 0.537070, top_k: 0.774297, samples/s: 2272.635 1612384627.1126683
train: epoch 52, iter 800, loss: 3.021120, top_1: 0.541172, top_k: 0.769492, samples/s: 2241.066 1612384638.53613
train: epoch 52, iter 900, loss: 2.916142, top_1: 0.536289, top_k: 0.771719, samples/s: 2242.165 1612384649.9532995
train: epoch 52, iter 1000, loss: 3.003260, top_1: 0.531602, top_k: 0.766133, samples/s: 2249.889 1612384661.3316379
train: epoch 52, iter 1100, loss: 2.807821, top_1: 0.536445, top_k: 0.770547, samples/s: 2191.458 1612384673.0134292
train: epoch 52, iter 1200, loss: 3.071860, top_1: 0.536602, top_k: 0.770312, samples/s: 2234.246 1612384684.471358
train: epoch 52, iter 1300, loss: 3.122675, top_1: 0.539023, top_k: 0.770039, samples/s: 2229.218 1612384695.9552853
train: epoch 52, iter 1400, loss: 2.935797, top_1: 0.542773, top_k: 0.771602, samples/s: 2227.103 1612384707.4499946
train: epoch 52, iter 1500, loss: 2.982139, top_1: 0.530312, top_k: 0.767188, samples/s: 2230.360 1612384718.928058
train: epoch 52, iter 1600, loss: 2.861567, top_1: 0.537539, top_k: 0.767734, samples/s: 2239.425 1612384730.3594835
train: epoch 52, iter 1700, loss: 3.059232, top_1: 0.532227, top_k: 0.761289, samples/s: 2241.980 1612384741.7779727
train: epoch 52, iter 1800, loss: 2.872954, top_1: 0.536875, top_k: 0.772539, samples/s: 2237.448 1612384753.2195587
train: epoch 52, iter 1900, loss: 2.844793, top_1: 0.538086, top_k: 0.768555, samples/s: 2226.036 1612384764.7198896
train: epoch 52, iter 2000, loss: 3.141021, top_1: 0.533984, top_k: 0.767695, samples/s: 2255.318 1612384776.070775
train: epoch 52, iter 2100, loss: 2.795389, top_1: 0.533867, top_k: 0.768984, samples/s: 2236.595 1612384787.516769
train: epoch 52, iter 2200, loss: 2.951816, top_1: 0.536250, top_k: 0.768008, samples/s: 2221.130 1612384799.042364
train: epoch 52, iter 2300, loss: 2.928146, top_1: 0.530234, top_k: 0.767500, samples/s: 2231.434 1612384810.5148056
train: epoch 52, iter 2400, loss: 2.963551, top_1: 0.531641, top_k: 0.764297, samples/s: 2245.023 1612384821.9178119
train: epoch 52, iter 2500, loss: 2.769682, top_1: 0.534648, top_k: 0.765625, samples/s: 2202.329 1612384833.54187
train: epoch 52, iter 2600, loss: 2.880598, top_1: 0.538828, top_k: 0.769219, samples/s: 2256.049 1612384844.8891904
train: epoch 52, iter 2700, loss: 2.924881, top_1: 0.530937, top_k: 0.769727, samples/s: 2241.050 1612384856.3123527
train: epoch 52, iter 2800, loss: 2.869278, top_1: 0.533477, top_k: 0.766797, samples/s: 2233.939 1612384867.77197
train: epoch 52, iter 2900, loss: 2.864025, top_1: 0.532031, top_k: 0.768047, samples/s: 2232.912 1612384879.2368264
train: epoch 52, iter 3000, loss: 2.776731, top_1: 0.535664, top_k: 0.762266, samples/s: 2235.745 1612384890.6870968
train: epoch 52, iter 3100, loss: 2.868035, top_1: 0.531992, top_k: 0.762969, samples/s: 2237.845 1612384902.126767
train: epoch 52, iter 3200, loss: 2.881526, top_1: 0.534453, top_k: 0.767148, samples/s: 2239.240 1612384913.559237
train: epoch 52, iter 3300, loss: 2.991306, top_1: 0.533789, top_k: 0.766445, samples/s: 2236.965 1612384925.0033665
train: epoch 52, iter 3400, loss: 2.831491, top_1: 0.531367, top_k: 0.765234, samples/s: 2222.333 1612384936.522732
train: epoch 52, iter 3500, loss: 2.872143, top_1: 0.535430, top_k: 0.767539, samples/s: 2246.704 1612384947.9171042
train: epoch 52, iter 3600, loss: 3.031736, top_1: 0.538750, top_k: 0.767969, samples/s: 2251.508 1612384959.2872841
train: epoch 52, iter 3700, loss: 3.004903, top_1: 0.533945, top_k: 0.764062, samples/s: 2241.477 1612384970.7083087
train: epoch 52, iter 3800, loss: 2.973434, top_1: 0.536367, top_k: 0.767969, samples/s: 2232.327 1612384982.176158
train: epoch 52, iter 3900, loss: 2.849387, top_1: 0.535508, top_k: 0.771758, samples/s: 2243.324 1612384993.587787
train: epoch 52, iter 4000, loss: 2.784829, top_1: 0.541562, top_k: 0.769492, samples/s: 2243.362 1612385004.99923
train: epoch 52, iter 4100, loss: 2.842908, top_1: 0.530156, top_k: 0.767305, samples/s: 2236.182 1612385016.447313
train: epoch 52, iter 4200, loss: 2.921490, top_1: 0.528438, top_k: 0.767656, samples/s: 2222.196 1612385027.9674823
train: epoch 52, iter 4300, loss: 3.082590, top_1: 0.527734, top_k: 0.761758, samples/s: 2258.817 1612385039.3008142
train: epoch 52, iter 4400, loss: 2.935915, top_1: 0.535898, top_k: 0.765156, samples/s: 2231.089 1612385050.775271
train: epoch 52, iter 4500, loss: 2.875473, top_1: 0.534414, top_k: 0.764687, samples/s: 2226.780 1612385062.2714813
train: epoch 52, iter 4600, loss: 3.023271, top_1: 0.535820, top_k: 0.766289, samples/s: 2238.092 1612385073.7097652
train: epoch 52, iter 4700, loss: 2.809309, top_1: 0.534687, top_k: 0.764336, samples/s: 2250.326 1612385085.0859041
train: epoch 52, iter 4800, loss: 2.866367, top_1: 0.529297, top_k: 0.765156, samples/s: 2247.988 1612385096.4738524
train: epoch 52, iter 4900, loss: 2.853705, top_1: 0.530625, top_k: 0.766680, samples/s: 2254.261 1612385107.83027
train: epoch 52, iter 5000, loss: 2.994625, top_1: 0.537813, top_k: 0.773945, samples/s: 2235.111 1612385119.2837057
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_52.
validation: epoch 52, iter 195, top_1: 0.572516, top_k: 0.812179, samples/s: 2919.324 1612385136.7237332
train: epoch 53, iter 100, loss: 2.992731, top_1: 0.541016, top_k: 0.776367, samples/s: 2222.962 1612385164.0998678
train: epoch 53, iter 200, loss: 2.720177, top_1: 0.542305, top_k: 0.781133, samples/s: 2263.349 1612385175.4104254
train: epoch 53, iter 300, loss: 2.804233, top_1: 0.545352, top_k: 0.775469, samples/s: 2259.150 1612385186.742152
train: epoch 53, iter 400, loss: 2.884728, top_1: 0.538516, top_k: 0.767578, samples/s: 2259.603 1612385198.071546
train: epoch 53, iter 500, loss: 3.024185, top_1: 0.538203, top_k: 0.772422, samples/s: 2242.642 1612385209.4867082
train: epoch 53, iter 600, loss: 3.125436, top_1: 0.536914, top_k: 0.769414, samples/s: 2267.823 1612385220.7750516
train: epoch 53, iter 700, loss: 2.956963, top_1: 0.543594, top_k: 0.776328, samples/s: 2251.095 1612385232.1472607
train: epoch 53, iter 800, loss: 2.884502, top_1: 0.539687, top_k: 0.766445, samples/s: 2240.023 1612385243.5757208
train: epoch 53, iter 900, loss: 2.987965, top_1: 0.541445, top_k: 0.774883, samples/s: 2250.966 1612385254.948617
train: epoch 53, iter 1000, loss: 3.126191, top_1: 0.542813, top_k: 0.774492, samples/s: 2220.391 1612385266.47816
train: epoch 53, iter 1100, loss: 2.919996, top_1: 0.540781, top_k: 0.769062, samples/s: 2228.997 1612385277.9630945
train: epoch 53, iter 1200, loss: 3.062874, top_1: 0.541016, top_k: 0.770352, samples/s: 2233.389 1612385289.4254937
train: epoch 53, iter 1300, loss: 2.776234, top_1: 0.541641, top_k: 0.770703, samples/s: 2215.772 1612385300.9790993
train: epoch 53, iter 1400, loss: 3.029660, top_1: 0.529258, top_k: 0.767930, samples/s: 2226.304 1612385312.4779038
train: epoch 53, iter 1500, loss: 2.747057, top_1: 0.536484, top_k: 0.768398, samples/s: 2217.123 1612385324.0244434
train: epoch 53, iter 1600, loss: 3.077878, top_1: 0.540039, top_k: 0.770625, samples/s: 2231.678 1612385335.4956217
train: epoch 53, iter 1700, loss: 2.918152, top_1: 0.541875, top_k: 0.770977, samples/s: 2225.958 1612385346.9963229
train: epoch 53, iter 1800, loss: 2.863990, top_1: 0.538945, top_k: 0.765938, samples/s: 2220.585 1612385358.5247452
train: epoch 53, iter 1900, loss: 2.934396, top_1: 0.539531, top_k: 0.766523, samples/s: 2204.646 1612385370.1366515
train: epoch 53, iter 2000, loss: 2.717712, top_1: 0.532656, top_k: 0.767031, samples/s: 2244.367 1612385381.542916
train: epoch 53, iter 2100, loss: 3.006722, top_1: 0.536445, top_k: 0.766445, samples/s: 2236.982 1612385392.986929
train: epoch 53, iter 2200, loss: 2.748475, top_1: 0.536523, top_k: 0.765547, samples/s: 2221.613 1612385404.5100877
train: epoch 53, iter 2300, loss: 2.847155, top_1: 0.537734, top_k: 0.771328, samples/s: 2213.424 1612385416.0759382
train: epoch 53, iter 2400, loss: 2.843358, top_1: 0.539844, top_k: 0.773281, samples/s: 2225.835 1612385427.5771568
train: epoch 53, iter 2500, loss: 2.836724, top_1: 0.536016, top_k: 0.765547, samples/s: 2230.946 1612385439.0521305
train: epoch 53, iter 2600, loss: 3.253292, top_1: 0.532891, top_k: 0.763711, samples/s: 2176.034 1612385450.81688
train: epoch 53, iter 2700, loss: 2.863766, top_1: 0.537969, top_k: 0.770664, samples/s: 2233.405 1612385462.2789736
train: epoch 53, iter 2800, loss: 2.777012, top_1: 0.539297, top_k: 0.767539, samples/s: 2221.657 1612385473.8018768
train: epoch 53, iter 2900, loss: 2.966516, top_1: 0.535586, top_k: 0.769453, samples/s: 2225.805 1612385485.303363
train: epoch 53, iter 3000, loss: 2.869566, top_1: 0.537891, top_k: 0.770312, samples/s: 2217.865 1612385496.8460426
train: epoch 53, iter 3100, loss: 3.072591, top_1: 0.530977, top_k: 0.767695, samples/s: 2197.990 1612385508.4930763
train: epoch 53, iter 3200, loss: 3.010131, top_1: 0.539961, top_k: 0.770039, samples/s: 2228.323 1612385519.981611
train: epoch 53, iter 3300, loss: 2.905870, top_1: 0.538164, top_k: 0.769375, samples/s: 2213.149 1612385531.5486636
train: epoch 53, iter 3400, loss: 2.834920, top_1: 0.536250, top_k: 0.768516, samples/s: 2228.452 1612385543.0364583
train: epoch 53, iter 3500, loss: 2.925373, top_1: 0.532031, top_k: 0.766602, samples/s: 2243.301 1612385554.4481997
train: epoch 53, iter 3600, loss: 2.880588, top_1: 0.532422, top_k: 0.764922, samples/s: 2217.560 1612385565.992434
train: epoch 53, iter 3700, loss: 3.044042, top_1: 0.533984, top_k: 0.764687, samples/s: 2184.048 1612385577.7137914
train: epoch 53, iter 3800, loss: 3.033437, top_1: 0.534492, top_k: 0.768750, samples/s: 2225.708 1612385589.215811
train: epoch 53, iter 3900, loss: 2.666932, top_1: 0.533672, top_k: 0.764219, samples/s: 2216.226 1612385600.7669106
train: epoch 53, iter 4000, loss: 2.915073, top_1: 0.536563, top_k: 0.766484, samples/s: 2209.880 1612385612.3513188
train: epoch 53, iter 4100, loss: 2.754405, top_1: 0.531523, top_k: 0.767031, samples/s: 2198.718 1612385623.9943967
train: epoch 53, iter 4200, loss: 2.981662, top_1: 0.533750, top_k: 0.766875, samples/s: 2271.501 1612385635.264564
train: epoch 53, iter 4300, loss: 2.918893, top_1: 0.533477, top_k: 0.767148, samples/s: 2221.545 1612385646.7879872
train: epoch 53, iter 4400, loss: 2.982893, top_1: 0.535781, top_k: 0.767734, samples/s: 2235.660 1612385658.2387724
train: epoch 53, iter 4500, loss: 3.045843, top_1: 0.531523, top_k: 0.768437, samples/s: 2227.077 1612385669.7336445
train: epoch 53, iter 4600, loss: 2.745655, top_1: 0.535469, top_k: 0.768594, samples/s: 2243.031 1612385681.1467633
train: epoch 53, iter 4700, loss: 3.019735, top_1: 0.537305, top_k: 0.763047, samples/s: 2242.481 1612385692.5627544
train: epoch 53, iter 4800, loss: 2.921794, top_1: 0.533906, top_k: 0.768281, samples/s: 2248.659 1612385703.947263
train: epoch 53, iter 4900, loss: 2.914448, top_1: 0.535820, top_k: 0.766133, samples/s: 2229.064 1612385715.4319663
train: epoch 53, iter 5000, loss: 2.786917, top_1: 0.533945, top_k: 0.766484, samples/s: 2236.693 1612385726.8774374
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_53.
validation: epoch 53, iter 195, top_1: 0.582212, top_k: 0.818550, samples/s: 2910.025 1612385744.3795907
train: epoch 54, iter 100, loss: 2.836047, top_1: 0.555195, top_k: 0.781484, samples/s: 2241.363 1612385771.5473044
train: epoch 54, iter 200, loss: 2.779648, top_1: 0.549453, top_k: 0.781133, samples/s: 2237.679 1612385782.9877264
train: epoch 54, iter 300, loss: 2.809201, top_1: 0.538438, top_k: 0.771250, samples/s: 2261.446 1612385794.3079593
train: epoch 54, iter 400, loss: 2.802207, top_1: 0.543320, top_k: 0.771875, samples/s: 2255.474 1612385805.6580806
train: epoch 54, iter 500, loss: 2.705343, top_1: 0.538711, top_k: 0.771055, samples/s: 2238.265 1612385817.095906
train: epoch 54, iter 600, loss: 2.834516, top_1: 0.541680, top_k: 0.775820, samples/s: 2256.123 1612385828.4424145
train: epoch 54, iter 700, loss: 3.021887, top_1: 0.543008, top_k: 0.771641, samples/s: 2253.867 1612385839.8007834
train: epoch 54, iter 800, loss: 2.940123, top_1: 0.539844, top_k: 0.768398, samples/s: 2238.766 1612385851.2355561
train: epoch 54, iter 900, loss: 2.872261, top_1: 0.535195, top_k: 0.773398, samples/s: 2237.473 1612385862.677563
train: epoch 54, iter 1000, loss: 2.982668, top_1: 0.535078, top_k: 0.768828, samples/s: 2234.627 1612385874.1330557
train: epoch 54, iter 1100, loss: 2.927831, top_1: 0.543672, top_k: 0.769922, samples/s: 2230.928 1612385885.6081882
train: epoch 54, iter 1200, loss: 2.827390, top_1: 0.542148, top_k: 0.772188, samples/s: 2225.189 1612385897.1127985
train: epoch 54, iter 1300, loss: 2.986902, top_1: 0.538398, top_k: 0.769609, samples/s: 2226.368 1612385908.611295
train: epoch 54, iter 1400, loss: 2.932295, top_1: 0.541562, top_k: 0.773164, samples/s: 2222.414 1612385920.1303685
train: epoch 54, iter 1500, loss: 3.027370, top_1: 0.533086, top_k: 0.768125, samples/s: 2221.366 1612385931.6547384
train: epoch 54, iter 1600, loss: 2.983121, top_1: 0.539336, top_k: 0.770234, samples/s: 2223.048 1612385943.1704645
train: epoch 54, iter 1700, loss: 2.974645, top_1: 0.538672, top_k: 0.773320, samples/s: 2227.201 1612385954.6647532
train: epoch 54, iter 1800, loss: 3.097693, top_1: 0.530625, top_k: 0.769336, samples/s: 2230.719 1612385966.140869
train: epoch 54, iter 1900, loss: 2.833426, top_1: 0.540117, top_k: 0.770898, samples/s: 2220.372 1612385977.6707616
train: epoch 54, iter 2000, loss: 2.791493, top_1: 0.542461, top_k: 0.771133, samples/s: 2238.006 1612385989.109478
train: epoch 54, iter 2100, loss: 2.787612, top_1: 0.544844, top_k: 0.773359, samples/s: 2231.592 1612386000.5808558
train: epoch 54, iter 2200, loss: 2.865631, top_1: 0.534844, top_k: 0.763594, samples/s: 2225.696 1612386012.083319
train: epoch 54, iter 2300, loss: 2.846914, top_1: 0.540937, top_k: 0.770039, samples/s: 2219.842 1612386023.6152585
train: epoch 54, iter 2400, loss: 3.021672, top_1: 0.537695, top_k: 0.771133, samples/s: 2253.052 1612386034.9778945
train: epoch 54, iter 2500, loss: 2.801131, top_1: 0.539023, top_k: 0.771914, samples/s: 2233.719 1612386046.4382675
train: epoch 54, iter 2600, loss: 3.023646, top_1: 0.534727, top_k: 0.768594, samples/s: 2233.105 1612386057.9021182
train: epoch 54, iter 2700, loss: 2.844798, top_1: 0.538047, top_k: 0.768984, samples/s: 2239.856 1612386069.3314667
train: epoch 54, iter 2800, loss: 2.833223, top_1: 0.536055, top_k: 0.772266, samples/s: 2220.766 1612386080.8589857
train: epoch 54, iter 2900, loss: 3.102606, top_1: 0.534141, top_k: 0.764062, samples/s: 2209.776 1612386092.4439049
train: epoch 54, iter 3000, loss: 2.997773, top_1: 0.531836, top_k: 0.764219, samples/s: 2255.435 1612386103.794231
train: epoch 54, iter 3100, loss: 3.051752, top_1: 0.534922, top_k: 0.769258, samples/s: 2237.554 1612386115.2357557
train: epoch 54, iter 3200, loss: 2.967731, top_1: 0.535859, top_k: 0.767266, samples/s: 2230.868 1612386126.710838
train: epoch 54, iter 3300, loss: 3.030710, top_1: 0.538828, top_k: 0.769141, samples/s: 2244.067 1612386138.1185615
train: epoch 54, iter 3400, loss: 2.863648, top_1: 0.536875, top_k: 0.768203, samples/s: 2228.659 1612386149.605242
train: epoch 54, iter 3500, loss: 2.779162, top_1: 0.537695, top_k: 0.767227, samples/s: 2238.617 1612386161.0408983
train: epoch 54, iter 3600, loss: 3.023992, top_1: 0.535156, top_k: 0.767148, samples/s: 2251.344 1612386172.4118376
train: epoch 54, iter 3700, loss: 3.049620, top_1: 0.531289, top_k: 0.766328, samples/s: 2243.782 1612386183.8212004
train: epoch 54, iter 3800, loss: 3.106766, top_1: 0.538594, top_k: 0.772109, samples/s: 2231.047 1612386195.295577
train: epoch 54, iter 3900, loss: 2.863183, top_1: 0.532813, top_k: 0.769805, samples/s: 2223.895 1612386206.8069944
train: epoch 54, iter 4000, loss: 2.798262, top_1: 0.536953, top_k: 0.766758, samples/s: 2238.626 1612386218.242549
train: epoch 54, iter 4100, loss: 2.975317, top_1: 0.540469, top_k: 0.768789, samples/s: 2247.514 1612386229.632873
train: epoch 54, iter 4200, loss: 3.006928, top_1: 0.532539, top_k: 0.768437, samples/s: 2237.811 1612386241.0727036
train: epoch 54, iter 4300, loss: 2.974718, top_1: 0.534648, top_k: 0.770195, samples/s: 2209.973 1612386252.6564746
train: epoch 54, iter 4400, loss: 3.062903, top_1: 0.533828, top_k: 0.764102, samples/s: 2225.117 1612386264.161507
train: epoch 54, iter 4500, loss: 3.000948, top_1: 0.534727, top_k: 0.770703, samples/s: 2250.366 1612386275.537441
train: epoch 54, iter 4600, loss: 3.041739, top_1: 0.533516, top_k: 0.766602, samples/s: 2243.311 1612386286.9491162
train: epoch 54, iter 4700, loss: 3.032628, top_1: 0.532305, top_k: 0.769687, samples/s: 2247.509 1612386298.3396
train: epoch 54, iter 4800, loss: 3.101353, top_1: 0.537578, top_k: 0.768164, samples/s: 2221.435 1612386309.8635895
train: epoch 54, iter 4900, loss: 2.867398, top_1: 0.536836, top_k: 0.767656, samples/s: 2242.547 1612386321.2791975
train: epoch 54, iter 5000, loss: 3.057072, top_1: 0.538555, top_k: 0.769922, samples/s: 2231.508 1612386332.7513475
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_54.
validation: epoch 54, iter 195, top_1: 0.581510, top_k: 0.819271, samples/s: 2911.288 1612386350.2635083
train: epoch 55, iter 100, loss: 2.842766, top_1: 0.545586, top_k: 0.775156, samples/s: 2243.273 1612386377.7034411
train: epoch 55, iter 200, loss: 2.887647, top_1: 0.547383, top_k: 0.776055, samples/s: 2240.241 1612386389.1307673
train: epoch 55, iter 300, loss: 2.697490, top_1: 0.541211, top_k: 0.767930, samples/s: 2259.048 1612386400.4630024
train: epoch 55, iter 400, loss: 2.810312, top_1: 0.543281, top_k: 0.777500, samples/s: 2251.956 1612386411.8309016
train: epoch 55, iter 500, loss: 2.831521, top_1: 0.553320, top_k: 0.776289, samples/s: 2250.991 1612386423.2036397
train: epoch 55, iter 600, loss: 2.865842, top_1: 0.547734, top_k: 0.774922, samples/s: 2254.875 1612386434.5568163
train: epoch 55, iter 700, loss: 2.779129, top_1: 0.549648, top_k: 0.776523, samples/s: 2230.051 1612386446.0364518
train: epoch 55, iter 800, loss: 2.833704, top_1: 0.535820, top_k: 0.768711, samples/s: 2226.562 1612386457.5339298
train: epoch 55, iter 900, loss: 2.911928, top_1: 0.540508, top_k: 0.774297, samples/s: 2226.667 1612386469.0309255
train: epoch 55, iter 1000, loss: 2.721232, top_1: 0.544648, top_k: 0.778789, samples/s: 2257.199 1612386480.3724153
train: epoch 55, iter 1100, loss: 2.830153, top_1: 0.533945, top_k: 0.770781, samples/s: 2222.834 1612386491.8892615
train: epoch 55, iter 1200, loss: 2.931245, top_1: 0.541289, top_k: 0.769062, samples/s: 2226.485 1612386503.3872247
train: epoch 55, iter 1300, loss: 2.764084, top_1: 0.542266, top_k: 0.772969, samples/s: 2222.243 1612386514.9071348
train: epoch 55, iter 1400, loss: 2.785110, top_1: 0.539141, top_k: 0.768906, samples/s: 2201.404 1612386526.5361369
train: epoch 55, iter 1500, loss: 2.948600, top_1: 0.541016, top_k: 0.773203, samples/s: 2206.458 1612386538.1383288
train: epoch 55, iter 1600, loss: 2.866952, top_1: 0.538125, top_k: 0.771133, samples/s: 2243.505 1612386549.5490465
train: epoch 55, iter 1700, loss: 2.886928, top_1: 0.541211, top_k: 0.771563, samples/s: 2215.802 1612386561.1024857
train: epoch 55, iter 1800, loss: 2.987534, top_1: 0.537695, top_k: 0.766055, samples/s: 2239.211 1612386572.5350535
train: epoch 55, iter 1900, loss: 2.832022, top_1: 0.539844, top_k: 0.775117, samples/s: 2197.804 1612386584.1830494
train: epoch 55, iter 2000, loss: 3.109952, top_1: 0.538711, top_k: 0.768945, samples/s: 2210.039 1612386595.7666202
train: epoch 55, iter 2100, loss: 2.695000, top_1: 0.540469, top_k: 0.769453, samples/s: 2219.035 1612386607.3030913
train: epoch 55, iter 2200, loss: 3.032941, top_1: 0.540703, top_k: 0.772695, samples/s: 2223.320 1612386618.817462
train: epoch 55, iter 2300, loss: 2.902023, top_1: 0.539766, top_k: 0.773203, samples/s: 2245.429 1612386630.2183194
train: epoch 55, iter 2400, loss: 3.111467, top_1: 0.540937, top_k: 0.770000, samples/s: 2222.806 1612386641.7353
train: epoch 55, iter 2500, loss: 2.994676, top_1: 0.541953, top_k: 0.773750, samples/s: 2218.967 1612386653.2722225
train: epoch 55, iter 2600, loss: 2.960948, top_1: 0.537227, top_k: 0.771914, samples/s: 2243.198 1612386664.6844876
train: epoch 55, iter 2700, loss: 2.834937, top_1: 0.534844, top_k: 0.766016, samples/s: 2229.781 1612386676.1655216
train: epoch 55, iter 2800, loss: 2.745532, top_1: 0.537930, top_k: 0.765352, samples/s: 2251.514 1612386687.5355523
train: epoch 55, iter 2900, loss: 3.011786, top_1: 0.535547, top_k: 0.769336, samples/s: 2212.197 1612386699.1077616
train: epoch 55, iter 3000, loss: 3.005826, top_1: 0.536797, top_k: 0.770312, samples/s: 2255.907 1612386710.4557633
train: epoch 55, iter 3100, loss: 3.044424, top_1: 0.533945, top_k: 0.765312, samples/s: 2230.177 1612386721.9346836
train: epoch 55, iter 3200, loss: 2.993948, top_1: 0.536055, top_k: 0.766914, samples/s: 2249.928 1612386733.3128178
train: epoch 55, iter 3300, loss: 2.946708, top_1: 0.536406, top_k: 0.768398, samples/s: 2254.326 1612386744.6687417
train: epoch 55, iter 3400, loss: 2.894958, top_1: 0.532813, top_k: 0.765586, samples/s: 2230.749 1612386756.1447308
train: epoch 55, iter 3500, loss: 2.788481, top_1: 0.539766, top_k: 0.771406, samples/s: 2231.880 1612386767.6148593
train: epoch 55, iter 3600, loss: 2.861925, top_1: 0.539180, top_k: 0.769805, samples/s: 2245.261 1612386779.01672
train: epoch 55, iter 3700, loss: 2.937613, top_1: 0.537383, top_k: 0.766563, samples/s: 2224.428 1612386790.525305
train: epoch 55, iter 3800, loss: 2.858148, top_1: 0.538828, top_k: 0.770977, samples/s: 2238.989 1612386801.959052
train: epoch 55, iter 3900, loss: 2.942433, top_1: 0.535352, top_k: 0.768047, samples/s: 2245.891 1612386813.3575454
train: epoch 55, iter 4000, loss: 2.889972, top_1: 0.537617, top_k: 0.767344, samples/s: 2216.008 1612386824.9099731
train: epoch 55, iter 4100, loss: 3.112984, top_1: 0.534648, top_k: 0.769687, samples/s: 2235.084 1612386836.3635519
train: epoch 55, iter 4200, loss: 2.872811, top_1: 0.540000, top_k: 0.768672, samples/s: 2251.110 1612386847.735722
train: epoch 55, iter 4300, loss: 3.009376, top_1: 0.534414, top_k: 0.767695, samples/s: 2241.132 1612386859.1585293
train: epoch 55, iter 4400, loss: 3.029767, top_1: 0.538594, top_k: 0.769141, samples/s: 2240.621 1612386870.5839198
train: epoch 55, iter 4500, loss: 3.026732, top_1: 0.539414, top_k: 0.767656, samples/s: 2232.680 1612386882.0500264
train: epoch 55, iter 4600, loss: 3.129144, top_1: 0.535469, top_k: 0.766836, samples/s: 2252.764 1612386893.413811
train: epoch 55, iter 4700, loss: 2.948982, top_1: 0.537500, top_k: 0.772305, samples/s: 2240.505 1612386904.8397799
train: epoch 55, iter 4800, loss: 3.032818, top_1: 0.530391, top_k: 0.765859, samples/s: 2209.828 1612386916.4244096
train: epoch 55, iter 4900, loss: 2.920969, top_1: 0.534023, top_k: 0.772148, samples/s: 2247.687 1612386927.8138807
train: epoch 55, iter 5000, loss: 2.899400, top_1: 0.538633, top_k: 0.773750, samples/s: 2240.521 1612386939.2397938
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_55.
validation: epoch 55, iter 195, top_1: 0.586278, top_k: 0.823798, samples/s: 2937.293 1612386956.5769355
train: epoch 56, iter 100, loss: 2.865425, top_1: 0.552148, top_k: 0.780547, samples/s: 2214.835 1612386983.980958
train: epoch 56, iter 200, loss: 2.704022, top_1: 0.553906, top_k: 0.781289, samples/s: 2217.009 1612386995.5280097
train: epoch 56, iter 300, loss: 3.024428, top_1: 0.544570, top_k: 0.773867, samples/s: 2260.017 1612387006.8553162
train: epoch 56, iter 400, loss: 2.820155, top_1: 0.545586, top_k: 0.780195, samples/s: 2256.261 1612387018.201538
train: epoch 56, iter 500, loss: 2.960735, top_1: 0.545469, top_k: 0.777539, samples/s: 2229.553 1612387029.6835968
train: epoch 56, iter 600, loss: 2.786117, top_1: 0.549766, top_k: 0.776094, samples/s: 2273.252 1612387040.9450002
train: epoch 56, iter 700, loss: 3.025354, top_1: 0.543438, top_k: 0.775508, samples/s: 2258.271 1612387052.281072
train: epoch 56, iter 800, loss: 2.883034, top_1: 0.537305, top_k: 0.773242, samples/s: 2243.059 1612387063.6941907
train: epoch 56, iter 900, loss: 2.872335, top_1: 0.541328, top_k: 0.770859, samples/s: 2225.551 1612387075.196861
train: epoch 56, iter 1000, loss: 3.004173, top_1: 0.539102, top_k: 0.767734, samples/s: 2198.037 1612387086.8436346
train: epoch 56, iter 1100, loss: 3.050856, top_1: 0.543203, top_k: 0.776094, samples/s: 2227.691 1612387098.335443
train: epoch 56, iter 1200, loss: 2.870874, top_1: 0.538359, top_k: 0.768945, samples/s: 2236.067 1612387109.7840426
train: epoch 56, iter 1300, loss: 2.709651, top_1: 0.543438, top_k: 0.776406, samples/s: 2213.395 1612387121.3499653
train: epoch 56, iter 1400, loss: 2.848918, top_1: 0.540039, top_k: 0.771289, samples/s: 2218.848 1612387132.887506
train: epoch 56, iter 1500, loss: 2.918758, top_1: 0.538047, top_k: 0.772344, samples/s: 2216.424 1612387144.437704
train: epoch 56, iter 1600, loss: 2.884252, top_1: 0.542734, top_k: 0.770508, samples/s: 2231.751 1612387155.9085047
train: epoch 56, iter 1700, loss: 2.761569, top_1: 0.542734, top_k: 0.771094, samples/s: 2239.337 1612387167.3403788
train: epoch 56, iter 1800, loss: 2.683069, top_1: 0.536992, top_k: 0.767422, samples/s: 2172.460 1612387179.1242623
train: epoch 56, iter 1900, loss: 2.953991, top_1: 0.536680, top_k: 0.769609, samples/s: 2224.949 1612387190.630213
train: epoch 56, iter 2000, loss: 2.743739, top_1: 0.539531, top_k: 0.769844, samples/s: 2238.027 1612387202.0687797
train: epoch 56, iter 2100, loss: 3.079239, top_1: 0.536758, top_k: 0.770352, samples/s: 2239.716 1612387213.4988167
train: epoch 56, iter 2200, loss: 2.911913, top_1: 0.536445, top_k: 0.770469, samples/s: 2235.402 1612387224.9508781
train: epoch 56, iter 2300, loss: 2.736167, top_1: 0.539844, top_k: 0.772188, samples/s: 2241.034 1612387236.3742676
train: epoch 56, iter 2400, loss: 2.986835, top_1: 0.538164, top_k: 0.770039, samples/s: 2237.542 1612387247.8153234
train: epoch 56, iter 2500, loss: 2.890571, top_1: 0.541992, top_k: 0.770352, samples/s: 2236.512 1612387259.26171
train: epoch 56, iter 2600, loss: 3.050994, top_1: 0.540469, top_k: 0.770938, samples/s: 2239.865 1612387270.691508
train: epoch 56, iter 2700, loss: 2.810624, top_1: 0.544687, top_k: 0.773633, samples/s: 2231.698 1612387282.1620924
train: epoch 56, iter 2800, loss: 2.760936, top_1: 0.535391, top_k: 0.771484, samples/s: 2241.752 1612387293.5817683
train: epoch 56, iter 2900, loss: 2.656896, top_1: 0.541133, top_k: 0.771289, samples/s: 2240.752 1612387305.006722
train: epoch 56, iter 3000, loss: 3.045269, top_1: 0.537500, top_k: 0.768242, samples/s: 2245.006 1612387316.4095058
train: epoch 56, iter 3100, loss: 2.828257, top_1: 0.539727, top_k: 0.773672, samples/s: 2225.845 1612387327.910766
train: epoch 56, iter 3200, loss: 3.065558, top_1: 0.537813, top_k: 0.769609, samples/s: 2234.172 1612387339.3691487
train: epoch 56, iter 3300, loss: 2.764216, top_1: 0.539727, top_k: 0.769922, samples/s: 2219.831 1612387350.901563
train: epoch 56, iter 3400, loss: 2.951839, top_1: 0.539219, top_k: 0.768828, samples/s: 2257.683 1612387362.2406278
train: epoch 56, iter 3500, loss: 2.646393, top_1: 0.541016, top_k: 0.772500, samples/s: 2244.209 1612387373.6477888
train: epoch 56, iter 3600, loss: 2.976314, top_1: 0.538906, top_k: 0.769375, samples/s: 2246.715 1612387385.0421717
train: epoch 56, iter 3700, loss: 3.080839, top_1: 0.537852, top_k: 0.768555, samples/s: 2261.623 1612387396.3615327
train: epoch 56, iter 3800, loss: 3.012623, top_1: 0.535977, top_k: 0.768867, samples/s: 2215.119 1612387407.918456
train: epoch 56, iter 3900, loss: 2.840533, top_1: 0.535547, top_k: 0.771953, samples/s: 2231.491 1612387419.3905547
train: epoch 56, iter 4000, loss: 2.764783, top_1: 0.536289, top_k: 0.769258, samples/s: 2244.617 1612387430.795705
train: epoch 56, iter 4100, loss: 2.927923, top_1: 0.535156, top_k: 0.771016, samples/s: 2232.041 1612387442.2649794
train: epoch 56, iter 4200, loss: 3.155185, top_1: 0.541484, top_k: 0.771367, samples/s: 2249.875 1612387453.6433628
train: epoch 56, iter 4300, loss: 2.810257, top_1: 0.541680, top_k: 0.773594, samples/s: 2208.750 1612387465.2336333
train: epoch 56, iter 4400, loss: 2.919866, top_1: 0.537344, top_k: 0.771094, samples/s: 2241.912 1612387476.6524491
train: epoch 56, iter 4500, loss: 2.791421, top_1: 0.538281, top_k: 0.769453, samples/s: 2242.548 1612387488.0681067
train: epoch 56, iter 4600, loss: 3.047530, top_1: 0.539922, top_k: 0.770312, samples/s: 2251.523 1612387499.4381595
train: epoch 56, iter 4700, loss: 3.031407, top_1: 0.538828, top_k: 0.768672, samples/s: 2229.267 1612387510.92222
train: epoch 56, iter 4800, loss: 2.922180, top_1: 0.532227, top_k: 0.767344, samples/s: 2226.634 1612387522.4189417
train: epoch 56, iter 4900, loss: 3.092025, top_1: 0.536484, top_k: 0.770859, samples/s: 2237.736 1612387533.8593335
train: epoch 56, iter 5000, loss: 2.840251, top_1: 0.537305, top_k: 0.767305, samples/s: 2228.649 1612387545.345858
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_56.
validation: epoch 56, iter 195, top_1: 0.581050, top_k: 0.817548, samples/s: 2893.452 1612387562.940798
train: epoch 57, iter 100, loss: 2.955137, top_1: 0.548438, top_k: 0.776914, samples/s: 2235.474 1612387590.4264688
train: epoch 57, iter 200, loss: 2.687799, top_1: 0.544727, top_k: 0.773398, samples/s: 2248.958 1612387601.809577
train: epoch 57, iter 300, loss: 3.013999, top_1: 0.549687, top_k: 0.777891, samples/s: 2260.852 1612387613.1326737
train: epoch 57, iter 400, loss: 2.715337, top_1: 0.548711, top_k: 0.780312, samples/s: 2254.783 1612387624.4863183
train: epoch 57, iter 500, loss: 2.945853, top_1: 0.544805, top_k: 0.774375, samples/s: 2245.556 1612387635.8867106
train: epoch 57, iter 600, loss: 3.105885, top_1: 0.545781, top_k: 0.777031, samples/s: 2258.744 1612387647.2203453
train: epoch 57, iter 700, loss: 2.946445, top_1: 0.547109, top_k: 0.777383, samples/s: 2241.720 1612387658.640154
train: epoch 57, iter 800, loss: 2.841366, top_1: 0.545742, top_k: 0.777070, samples/s: 2247.967 1612387670.0282702
train: epoch 57, iter 900, loss: 2.959654, top_1: 0.540352, top_k: 0.771211, samples/s: 2214.254 1612387681.589695
train: epoch 57, iter 1000, loss: 2.934431, top_1: 0.546992, top_k: 0.777070, samples/s: 2248.309 1612387692.9760227
train: epoch 57, iter 1100, loss: 2.890450, top_1: 0.540547, top_k: 0.773984, samples/s: 2223.763 1612387704.4880602
train: epoch 57, iter 1200, loss: 2.933349, top_1: 0.539180, top_k: 0.771289, samples/s: 2218.200 1612387716.0289452
train: epoch 57, iter 1300, loss: 3.068953, top_1: 0.538711, top_k: 0.771055, samples/s: 2231.274 1612387727.5022135
train: epoch 57, iter 1400, loss: 2.838000, top_1: 0.542930, top_k: 0.771875, samples/s: 2205.258 1612387739.1107924
train: epoch 57, iter 1500, loss: 2.820282, top_1: 0.544805, top_k: 0.776523, samples/s: 2215.973 1612387750.6635919
train: epoch 57, iter 1600, loss: 2.964978, top_1: 0.550273, top_k: 0.779883, samples/s: 2211.617 1612387762.2385476
train: epoch 57, iter 1700, loss: 2.884301, top_1: 0.543906, top_k: 0.772695, samples/s: 2236.086 1612387773.6874948
train: epoch 57, iter 1800, loss: 3.039670, top_1: 0.542578, top_k: 0.773242, samples/s: 2216.082 1612387785.2392273
train: epoch 57, iter 1900, loss: 2.937866, top_1: 0.542773, top_k: 0.774727, samples/s: 2210.880 1612387796.81812
train: epoch 57, iter 2000, loss: 2.995979, top_1: 0.541133, top_k: 0.772969, samples/s: 2220.441 1612387808.3474343
train: epoch 57, iter 2100, loss: 2.825832, top_1: 0.539609, top_k: 0.771680, samples/s: 2212.593 1612387819.917488
train: epoch 57, iter 2200, loss: 2.845717, top_1: 0.540273, top_k: 0.770273, samples/s: 2203.066 1612387831.537653
train: epoch 57, iter 2300, loss: 2.888481, top_1: 0.539805, top_k: 0.769414, samples/s: 2233.495 1612387842.9995124
train: epoch 57, iter 2400, loss: 2.800699, top_1: 0.543711, top_k: 0.774141, samples/s: 2225.769 1612387854.5011764
train: epoch 57, iter 2500, loss: 2.710147, top_1: 0.542656, top_k: 0.770781, samples/s: 2230.698 1612387865.9774475
train: epoch 57, iter 2600, loss: 2.959905, top_1: 0.541250, top_k: 0.771719, samples/s: 2230.087 1612387877.456756
train: epoch 57, iter 2700, loss: 2.777172, top_1: 0.542422, top_k: 0.775234, samples/s: 2237.280 1612387888.8992448
train: epoch 57, iter 2800, loss: 2.991410, top_1: 0.538633, top_k: 0.775430, samples/s: 2240.438 1612387900.3255653
train: epoch 57, iter 2900, loss: 2.837891, top_1: 0.543359, top_k: 0.774102, samples/s: 2258.818 1612387911.6589377
train: epoch 57, iter 3000, loss: 3.015550, top_1: 0.543555, top_k: 0.769805, samples/s: 2199.894 1612387923.2958632
train: epoch 57, iter 3100, loss: 2.947316, top_1: 0.538359, top_k: 0.773516, samples/s: 2246.682 1612387934.6905098
train: epoch 57, iter 3200, loss: 3.077834, top_1: 0.539258, top_k: 0.767461, samples/s: 2210.589 1612387946.2710838
train: epoch 57, iter 3300, loss: 3.019025, top_1: 0.534141, top_k: 0.765391, samples/s: 2224.580 1612387957.7788568
train: epoch 57, iter 3400, loss: 2.874710, top_1: 0.538008, top_k: 0.772773, samples/s: 2242.935 1612387969.192473
train: epoch 57, iter 3500, loss: 2.809117, top_1: 0.540039, top_k: 0.776094, samples/s: 2231.320 1612387980.6654866
train: epoch 57, iter 3600, loss: 2.977104, top_1: 0.536953, top_k: 0.770391, samples/s: 2238.716 1612387992.1006155
train: epoch 57, iter 3700, loss: 2.996320, top_1: 0.535508, top_k: 0.771133, samples/s: 2243.819 1612388003.5098047
train: epoch 57, iter 3800, loss: 3.159935, top_1: 0.540469, top_k: 0.771602, samples/s: 2224.338 1612388015.0188477
train: epoch 57, iter 3900, loss: 2.944598, top_1: 0.533477, top_k: 0.771094, samples/s: 2224.186 1612388026.5286195
train: epoch 57, iter 4000, loss: 2.971389, top_1: 0.541211, top_k: 0.770898, samples/s: 2246.833 1612388037.922438
train: epoch 57, iter 4100, loss: 2.853358, top_1: 0.537891, top_k: 0.771406, samples/s: 2227.570 1612388049.4148226
train: epoch 57, iter 4200, loss: 2.990788, top_1: 0.537188, top_k: 0.769961, samples/s: 2215.223 1612388060.9711788
train: epoch 57, iter 4300, loss: 2.881205, top_1: 0.537109, top_k: 0.769766, samples/s: 2248.525 1612388072.3564968
train: epoch 57, iter 4400, loss: 2.864819, top_1: 0.546055, top_k: 0.772813, samples/s: 2237.685 1612388083.7968755
train: epoch 57, iter 4500, loss: 2.930816, top_1: 0.535703, top_k: 0.771094, samples/s: 2243.004 1612388095.2101889
train: epoch 57, iter 4600, loss: 2.811350, top_1: 0.543867, top_k: 0.775625, samples/s: 2249.306 1612388106.591375
train: epoch 57, iter 4700, loss: 2.911365, top_1: 0.535898, top_k: 0.769219, samples/s: 2220.222 1612388118.1217139
train: epoch 57, iter 4800, loss: 3.009120, top_1: 0.538594, top_k: 0.768906, samples/s: 2238.510 1612388129.5579443
train: epoch 57, iter 4900, loss: 2.832801, top_1: 0.540000, top_k: 0.771328, samples/s: 2235.434 1612388141.0099034
train: epoch 57, iter 5000, loss: 2.692159, top_1: 0.546133, top_k: 0.775312, samples/s: 2244.750 1612388152.4142249
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_57.
validation: epoch 57, iter 195, top_1: 0.586719, top_k: 0.822296, samples/s: 2916.219 1612388169.9044027
train: epoch 58, iter 100, loss: 2.813317, top_1: 0.562617, top_k: 0.785664, samples/s: 2231.794 1612388197.285583
train: epoch 58, iter 200, loss: 2.774251, top_1: 0.550586, top_k: 0.778945, samples/s: 2257.621 1612388208.6249475
train: epoch 58, iter 300, loss: 2.939133, top_1: 0.550000, top_k: 0.781680, samples/s: 2259.429 1612388219.9552922
train: epoch 58, iter 400, loss: 3.002553, top_1: 0.550781, top_k: 0.778633, samples/s: 2246.660 1612388231.3499246
train: epoch 58, iter 500, loss: 2.971682, top_1: 0.544609, top_k: 0.777617, samples/s: 2256.937 1612388242.6927803
train: epoch 58, iter 600, loss: 2.678039, top_1: 0.545430, top_k: 0.776133, samples/s: 2222.633 1612388254.210661
train: epoch 58, iter 700, loss: 2.958391, top_1: 0.544063, top_k: 0.774766, samples/s: 2254.727 1612388265.5645454
train: epoch 58, iter 800, loss: 2.834266, top_1: 0.549609, top_k: 0.782656, samples/s: 2233.757 1612388277.0250483
train: epoch 58, iter 900, loss: 2.861089, top_1: 0.542734, top_k: 0.774687, samples/s: 2226.322 1612388288.5238314
train: epoch 58, iter 1000, loss: 2.946889, top_1: 0.546797, top_k: 0.776055, samples/s: 2232.284 1612388299.9919493
train: epoch 58, iter 1100, loss: 3.020662, top_1: 0.549766, top_k: 0.777148, samples/s: 2226.770 1612388311.4883814
train: epoch 58, iter 1200, loss: 2.905139, top_1: 0.541289, top_k: 0.774609, samples/s: 2207.217 1612388323.0867603
train: epoch 58, iter 1300, loss: 3.011440, top_1: 0.542656, top_k: 0.773438, samples/s: 2237.708 1612388334.5269887
train: epoch 58, iter 1400, loss: 2.857414, top_1: 0.548047, top_k: 0.781211, samples/s: 2213.241 1612388346.0937736
train: epoch 58, iter 1500, loss: 2.994044, top_1: 0.545586, top_k: 0.774297, samples/s: 2226.233 1612388357.592959
train: epoch 58, iter 1600, loss: 2.711596, top_1: 0.540547, top_k: 0.773867, samples/s: 2206.803 1612388369.193512
train: epoch 58, iter 1700, loss: 2.847383, top_1: 0.540820, top_k: 0.769961, samples/s: 2214.102 1612388380.7557833
train: epoch 58, iter 1800, loss: 2.933390, top_1: 0.540977, top_k: 0.778281, samples/s: 2228.763 1612388392.2420187
train: epoch 58, iter 1900, loss: 2.936539, top_1: 0.543164, top_k: 0.777734, samples/s: 2219.968 1612388403.7736218
train: epoch 58, iter 2000, loss: 2.996215, top_1: 0.545664, top_k: 0.777383, samples/s: 2224.622 1612388415.281172
train: epoch 58, iter 2100, loss: 2.812244, top_1: 0.543867, top_k: 0.775195, samples/s: 2220.275 1612388426.811327
train: epoch 58, iter 2200, loss: 3.056745, top_1: 0.548516, top_k: 0.777227, samples/s: 2211.557 1612388438.3868277
train: epoch 58, iter 2300, loss: 2.960844, top_1: 0.542383, top_k: 0.774922, samples/s: 2221.835 1612388449.9088352
train: epoch 58, iter 2400, loss: 2.871754, top_1: 0.545156, top_k: 0.772227, samples/s: 2217.902 1612388461.4512722
train: epoch 58, iter 2500, loss: 2.818811, top_1: 0.538281, top_k: 0.770273, samples/s: 2206.667 1612388473.0525312
train: epoch 58, iter 2600, loss: 3.065451, top_1: 0.537031, top_k: 0.766211, samples/s: 2243.891 1612388484.4613936
train: epoch 58, iter 2700, loss: 3.232059, top_1: 0.541797, top_k: 0.773828, samples/s: 2226.194 1612388495.960715
train: epoch 58, iter 2800, loss: 2.908122, top_1: 0.543086, top_k: 0.772813, samples/s: 2229.318 1612388507.4441285
train: epoch 58, iter 2900, loss: 2.892164, top_1: 0.545352, top_k: 0.774844, samples/s: 2242.486 1612388518.8599524
train: epoch 58, iter 3000, loss: 2.817850, top_1: 0.541523, top_k: 0.770898, samples/s: 2218.016 1612388530.4017377
train: epoch 58, iter 3100, loss: 2.903353, top_1: 0.544961, top_k: 0.773320, samples/s: 2249.196 1612388541.7836154
train: epoch 58, iter 3200, loss: 3.077160, top_1: 0.539805, top_k: 0.771992, samples/s: 2242.503 1612388553.199458
train: epoch 58, iter 3300, loss: 2.949891, top_1: 0.539531, top_k: 0.772617, samples/s: 2245.192 1612388564.6016395
train: epoch 58, iter 3400, loss: 3.017417, top_1: 0.542031, top_k: 0.774414, samples/s: 2235.398 1612388576.0537014
train: epoch 58, iter 3500, loss: 2.956104, top_1: 0.544141, top_k: 0.774102, samples/s: 2222.042 1612388587.574564
train: epoch 58, iter 3600, loss: 2.805398, top_1: 0.544727, top_k: 0.775664, samples/s: 2212.023 1612388599.147713
train: epoch 58, iter 3700, loss: 3.085906, top_1: 0.546250, top_k: 0.773555, samples/s: 2183.206 1612388610.8737803
train: epoch 58, iter 3800, loss: 2.822104, top_1: 0.542695, top_k: 0.771602, samples/s: 2253.493 1612388622.2337315
train: epoch 58, iter 3900, loss: 2.919088, top_1: 0.544063, top_k: 0.775000, samples/s: 2215.277 1612388633.7898922
train: epoch 58, iter 4000, loss: 3.098710, top_1: 0.541953, top_k: 0.772031, samples/s: 2239.102 1612388645.2231843
train: epoch 58, iter 4100, loss: 2.910213, top_1: 0.545508, top_k: 0.774922, samples/s: 2223.452 1612388656.7366922
train: epoch 58, iter 4200, loss: 2.872716, top_1: 0.543867, top_k: 0.771797, samples/s: 2249.775 1612388668.115622
train: epoch 58, iter 4300, loss: 2.731059, top_1: 0.538906, top_k: 0.768555, samples/s: 2216.094 1612388679.6673927
train: epoch 58, iter 4400, loss: 2.724121, top_1: 0.537852, top_k: 0.769180, samples/s: 2244.977 1612388691.0706513
train: epoch 58, iter 4500, loss: 2.956319, top_1: 0.536445, top_k: 0.770781, samples/s: 2221.048 1612388702.596792
train: epoch 58, iter 4600, loss: 2.817802, top_1: 0.541094, top_k: 0.769414, samples/s: 2242.924 1612388714.0104067
train: epoch 58, iter 4700, loss: 2.815919, top_1: 0.538906, top_k: 0.771758, samples/s: 2206.949 1612388725.610122
train: epoch 58, iter 4800, loss: 2.860500, top_1: 0.543047, top_k: 0.774492, samples/s: 2262.851 1612388736.9233186
train: epoch 58, iter 4900, loss: 2.925836, top_1: 0.537734, top_k: 0.770664, samples/s: 2248.598 1612388748.3081524
train: epoch 58, iter 5000, loss: 2.791718, top_1: 0.548672, top_k: 0.775586, samples/s: 2249.256 1612388759.6896968
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_58.
validation: epoch 58, iter 195, top_1: 0.585697, top_k: 0.820393, samples/s: 2912.718 1612388777.16685
train: epoch 59, iter 100, loss: 3.027061, top_1: 0.552695, top_k: 0.781563, samples/s: 2213.490 1612388804.4829535
train: epoch 59, iter 200, loss: 2.919495, top_1: 0.547031, top_k: 0.777070, samples/s: 2254.581 1612388815.8375745
train: epoch 59, iter 300, loss: 2.975367, top_1: 0.548047, top_k: 0.784375, samples/s: 2256.679 1612388827.1817534
train: epoch 59, iter 400, loss: 2.750407, top_1: 0.555352, top_k: 0.782383, samples/s: 2252.919 1612388838.5447202
train: epoch 59, iter 500, loss: 2.722671, top_1: 0.550156, top_k: 0.780820, samples/s: 2256.422 1612388849.8903623
train: epoch 59, iter 600, loss: 2.869200, top_1: 0.550312, top_k: 0.777617, samples/s: 2211.125 1612388861.467931
train: epoch 59, iter 700, loss: 2.820996, top_1: 0.541523, top_k: 0.774961, samples/s: 2284.860 1612388872.6721194
train: epoch 59, iter 800, loss: 2.891590, top_1: 0.541523, top_k: 0.775977, samples/s: 2233.813 1612388884.132357
train: epoch 59, iter 900, loss: 3.047169, top_1: 0.540937, top_k: 0.776836, samples/s: 2242.009 1612388895.5508077
train: epoch 59, iter 1000, loss: 2.771952, top_1: 0.540000, top_k: 0.776523, samples/s: 2213.348 1612388907.1168542
train: epoch 59, iter 1100, loss: 2.776326, top_1: 0.543828, top_k: 0.778516, samples/s: 2220.786 1612388918.6443782
train: epoch 59, iter 1200, loss: 2.766836, top_1: 0.544648, top_k: 0.778633, samples/s: 2213.684 1612388930.2087512
train: epoch 59, iter 1300, loss: 2.850664, top_1: 0.551133, top_k: 0.778867, samples/s: 2223.308 1612388941.7231236
train: epoch 59, iter 1400, loss: 2.867583, top_1: 0.550117, top_k: 0.779258, samples/s: 2224.827 1612388953.2296364
train: epoch 59, iter 1500, loss: 2.819226, top_1: 0.548086, top_k: 0.779570, samples/s: 2235.760 1612388964.6799076
train: epoch 59, iter 1600, loss: 2.688659, top_1: 0.549531, top_k: 0.780586, samples/s: 2219.178 1612388976.215704
train: epoch 59, iter 1700, loss: 2.741223, top_1: 0.549805, top_k: 0.779922, samples/s: 2227.836 1612388987.70668
train: epoch 59, iter 1800, loss: 2.990142, top_1: 0.544922, top_k: 0.777109, samples/s: 2224.705 1612388999.2137947
train: epoch 59, iter 1900, loss: 2.833443, top_1: 0.545391, top_k: 0.775000, samples/s: 2239.981 1612389010.6424253
train: epoch 59, iter 2000, loss: 3.016112, top_1: 0.542500, top_k: 0.772656, samples/s: 2227.938 1612389022.132938
train: epoch 59, iter 2100, loss: 2.815692, top_1: 0.539336, top_k: 0.775078, samples/s: 2232.445 1612389033.6001592
train: epoch 59, iter 2200, loss: 3.034869, top_1: 0.542773, top_k: 0.774805, samples/s: 2227.758 1612389045.0915685
train: epoch 59, iter 2300, loss: 2.879594, top_1: 0.540273, top_k: 0.774453, samples/s: 2242.507 1612389056.5073888
train: epoch 59, iter 2400, loss: 2.984754, top_1: 0.539609, top_k: 0.769961, samples/s: 2238.587 1612389067.9431143
train: epoch 59, iter 2500, loss: 2.897570, top_1: 0.545273, top_k: 0.772266, samples/s: 2240.040 1612389079.371527
train: epoch 59, iter 2600, loss: 3.152881, top_1: 0.539648, top_k: 0.768437, samples/s: 2221.258 1612389090.8965394
train: epoch 59, iter 2700, loss: 2.897408, top_1: 0.546016, top_k: 0.772813, samples/s: 2224.680 1612389102.4038208
train: epoch 59, iter 2800, loss: 2.955099, top_1: 0.543320, top_k: 0.771758, samples/s: 2239.503 1612389113.8348505
train: epoch 59, iter 2900, loss: 2.999978, top_1: 0.545273, top_k: 0.777109, samples/s: 2243.216 1612389125.2470489
train: epoch 59, iter 3000, loss: 2.856511, top_1: 0.546094, top_k: 0.777227, samples/s: 2223.650 1612389136.7598479
train: epoch 59, iter 3100, loss: 2.861182, top_1: 0.540977, top_k: 0.774141, samples/s: 2251.577 1612389148.1295476
train: epoch 59, iter 3200, loss: 2.948351, top_1: 0.542891, top_k: 0.772031, samples/s: 2228.855 1612389159.615188
train: epoch 59, iter 3300, loss: 3.132177, top_1: 0.541992, top_k: 0.770664, samples/s: 2229.726 1612389171.0964096
train: epoch 59, iter 3400, loss: 2.941704, top_1: 0.541836, top_k: 0.772305, samples/s: 2231.179 1612389182.5702124
train: epoch 59, iter 3500, loss: 2.987032, top_1: 0.541055, top_k: 0.767031, samples/s: 2227.414 1612389194.0633075
train: epoch 59, iter 3600, loss: 2.953494, top_1: 0.545742, top_k: 0.776250, samples/s: 2233.321 1612389205.526095
train: epoch 59, iter 3700, loss: 2.971822, top_1: 0.540664, top_k: 0.773672, samples/s: 2239.020 1612389216.9596386
train: epoch 59, iter 3800, loss: 2.917757, top_1: 0.541836, top_k: 0.772188, samples/s: 2237.246 1612389228.4023511
train: epoch 59, iter 3900, loss: 2.897410, top_1: 0.549492, top_k: 0.774414, samples/s: 2220.718 1612389239.9300675
train: epoch 59, iter 4000, loss: 2.947906, top_1: 0.545547, top_k: 0.779687, samples/s: 2233.287 1612389251.3930657
train: epoch 59, iter 4100, loss: 3.140460, top_1: 0.541367, top_k: 0.772031, samples/s: 2236.356 1612389262.8401754
train: epoch 59, iter 4200, loss: 3.013656, top_1: 0.544609, top_k: 0.772539, samples/s: 2231.388 1612389274.3128266
train: epoch 59, iter 4300, loss: 2.802986, top_1: 0.544844, top_k: 0.778477, samples/s: 2226.388 1612389285.8113003
train: epoch 59, iter 4400, loss: 2.815578, top_1: 0.544063, top_k: 0.772930, samples/s: 2247.947 1612389297.19949
train: epoch 59, iter 4500, loss: 3.020294, top_1: 0.539570, top_k: 0.769609, samples/s: 2237.833 1612389308.6392057
train: epoch 59, iter 4600, loss: 2.772038, top_1: 0.543555, top_k: 0.774414, samples/s: 2233.289 1612389320.1020272
train: epoch 59, iter 4700, loss: 2.779144, top_1: 0.542734, top_k: 0.769453, samples/s: 2221.944 1612389331.6235518
train: epoch 59, iter 4800, loss: 2.871685, top_1: 0.534219, top_k: 0.767461, samples/s: 2239.832 1612389343.0529823
train: epoch 59, iter 4900, loss: 2.980036, top_1: 0.541680, top_k: 0.771445, samples/s: 2252.809 1612389354.4165037
train: epoch 59, iter 5000, loss: 3.012966, top_1: 0.542656, top_k: 0.774609, samples/s: 2242.924 1612389365.830245
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_59.
validation: epoch 59, iter 195, top_1: 0.592508, top_k: 0.825901, samples/s: 2970.805 1612389382.9726567
train: epoch 60, iter 100, loss: 2.908475, top_1: 0.551953, top_k: 0.783516, samples/s: 2238.551 1612389410.0928125
train: epoch 60, iter 200, loss: 2.755994, top_1: 0.552227, top_k: 0.780312, samples/s: 2248.964 1612389421.4758852
train: epoch 60, iter 300, loss: 2.675112, top_1: 0.550977, top_k: 0.784297, samples/s: 2250.015 1612389432.8535337
train: epoch 60, iter 400, loss: 2.710103, top_1: 0.552227, top_k: 0.782266, samples/s: 2239.498 1612389444.284659
train: epoch 60, iter 500, loss: 2.761184, top_1: 0.554844, top_k: 0.781094, samples/s: 2263.526 1612389455.5944817
train: epoch 60, iter 600, loss: 2.960664, top_1: 0.548828, top_k: 0.781484, samples/s: 2249.755 1612389466.9734943
train: epoch 60, iter 700, loss: 2.985287, top_1: 0.551250, top_k: 0.778164, samples/s: 2255.638 1612389478.3228087
train: epoch 60, iter 800, loss: 2.798039, top_1: 0.550898, top_k: 0.777305, samples/s: 2232.382 1612389489.7903755
train: epoch 60, iter 900, loss: 2.963019, top_1: 0.548867, top_k: 0.779062, samples/s: 2228.779 1612389501.2765288
train: epoch 60, iter 1000, loss: 2.847801, top_1: 0.541172, top_k: 0.775352, samples/s: 2215.349 1612389512.8323154
train: epoch 60, iter 1100, loss: 2.872414, top_1: 0.552773, top_k: 0.779219, samples/s: 2215.619 1612389524.386593
train: epoch 60, iter 1200, loss: 2.825358, top_1: 0.548984, top_k: 0.780234, samples/s: 2226.891 1612389535.8825245
train: epoch 60, iter 1300, loss: 3.067559, top_1: 0.550586, top_k: 0.777734, samples/s: 2206.673 1612389547.483618
train: epoch 60, iter 1400, loss: 2.916812, top_1: 0.549922, top_k: 0.781055, samples/s: 2202.035 1612389559.1091957
train: epoch 60, iter 1500, loss: 2.868572, top_1: 0.553242, top_k: 0.780898, samples/s: 2229.885 1612389570.5896695
train: epoch 60, iter 1600, loss: 2.748448, top_1: 0.546562, top_k: 0.777969, samples/s: 2205.213 1612389582.1984692
train: epoch 60, iter 1700, loss: 3.066464, top_1: 0.547891, top_k: 0.780273, samples/s: 2218.998 1612389593.7352505
train: epoch 60, iter 1800, loss: 2.805758, top_1: 0.547852, top_k: 0.773906, samples/s: 2227.114 1612389605.2298934
train: epoch 60, iter 1900, loss: 2.897092, top_1: 0.545469, top_k: 0.777461, samples/s: 2231.195 1612389616.703576
train: epoch 60, iter 2000, loss: 2.732686, top_1: 0.547852, top_k: 0.780273, samples/s: 2230.636 1612389628.1801107
train: epoch 60, iter 2100, loss: 2.916168, top_1: 0.547344, top_k: 0.776719, samples/s: 2218.595 1612389639.7189488
train: epoch 60, iter 2200, loss: 2.924432, top_1: 0.547188, top_k: 0.774961, samples/s: 2233.637 1612389651.1801972
train: epoch 60, iter 2300, loss: 2.776110, top_1: 0.542695, top_k: 0.776758, samples/s: 2244.070 1612389662.587922
train: epoch 60, iter 2400, loss: 2.886176, top_1: 0.551328, top_k: 0.779922, samples/s: 2235.080 1612389674.0416496
train: epoch 60, iter 2500, loss: 3.102908, top_1: 0.544375, top_k: 0.771328, samples/s: 2235.859 1612389685.4914217
train: epoch 60, iter 2600, loss: 2.840713, top_1: 0.545547, top_k: 0.775977, samples/s: 2230.205 1612389696.9702263
train: epoch 60, iter 2700, loss: 2.757411, top_1: 0.547266, top_k: 0.777109, samples/s: 2228.117 1612389708.4597182
train: epoch 60, iter 2800, loss: 2.901936, top_1: 0.541641, top_k: 0.770820, samples/s: 2227.330 1612389719.9533324
train: epoch 60, iter 2900, loss: 2.796496, top_1: 0.541328, top_k: 0.773555, samples/s: 2232.624 1612389731.419783
train: epoch 60, iter 3000, loss: 2.919848, top_1: 0.543242, top_k: 0.774570, samples/s: 2237.404 1612389742.8614187
train: epoch 60, iter 3100, loss: 2.846889, top_1: 0.547852, top_k: 0.779258, samples/s: 2230.435 1612389754.3389988
train: epoch 60, iter 3200, loss: 2.791340, top_1: 0.547617, top_k: 0.772383, samples/s: 2252.382 1612389765.7047417
train: epoch 60, iter 3300, loss: 3.375347, top_1: 0.539414, top_k: 0.771797, samples/s: 2229.152 1612389777.1889591
train: epoch 60, iter 3400, loss: 2.796855, top_1: 0.550117, top_k: 0.778672, samples/s: 2238.891 1612389788.6232455
train: epoch 60, iter 3500, loss: 2.794125, top_1: 0.544102, top_k: 0.774453, samples/s: 2227.079 1612389800.1181414
train: epoch 60, iter 3600, loss: 2.715049, top_1: 0.547578, top_k: 0.780898, samples/s: 2221.518 1612389811.6416972
train: epoch 60, iter 3700, loss: 3.038686, top_1: 0.537227, top_k: 0.771172, samples/s: 2239.236 1612389823.0742652
train: epoch 60, iter 3800, loss: 3.024936, top_1: 0.540000, top_k: 0.769453, samples/s: 2252.717 1612389834.4382899
train: epoch 60, iter 3900, loss: 2.817844, top_1: 0.544531, top_k: 0.774102, samples/s: 2237.278 1612389845.8807685
train: epoch 60, iter 4000, loss: 2.989886, top_1: 0.539570, top_k: 0.770000, samples/s: 2200.650 1612389857.51365
train: epoch 60, iter 4100, loss: 2.828070, top_1: 0.543711, top_k: 0.773594, samples/s: 2217.964 1612389869.055803
train: epoch 60, iter 4200, loss: 2.872976, top_1: 0.544766, top_k: 0.776289, samples/s: 2255.399 1612389880.406288
train: epoch 60, iter 4300, loss: 2.935236, top_1: 0.545039, top_k: 0.773047, samples/s: 2250.339 1612389891.7824035
train: epoch 60, iter 4400, loss: 2.788433, top_1: 0.545547, top_k: 0.775859, samples/s: 2237.280 1612389903.2248118
train: epoch 60, iter 4500, loss: 3.024559, top_1: 0.543398, top_k: 0.776289, samples/s: 2215.788 1612389914.778392
train: epoch 60, iter 4600, loss: 3.062862, top_1: 0.547266, top_k: 0.777852, samples/s: 2235.841 1612389926.2281008
train: epoch 60, iter 4700, loss: 2.812529, top_1: 0.543984, top_k: 0.774336, samples/s: 2240.447 1612389937.6544337
train: epoch 60, iter 4800, loss: 3.078040, top_1: 0.542500, top_k: 0.769023, samples/s: 2242.756 1612389949.0689259
train: epoch 60, iter 4900, loss: 2.832864, top_1: 0.542539, top_k: 0.774531, samples/s: 2243.781 1612389960.478234
train: epoch 60, iter 5000, loss: 2.858327, top_1: 0.554492, top_k: 0.782461, samples/s: 2243.527 1612389971.8891168
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_60.
validation: epoch 60, iter 195, top_1: 0.597516, top_k: 0.830869, samples/s: 2927.096 1612389989.3060532
train: epoch 61, iter 100, loss: 2.920063, top_1: 0.548906, top_k: 0.780352, samples/s: 2243.405 1612390016.6767178
train: epoch 61, iter 200, loss: 2.887237, top_1: 0.557187, top_k: 0.784258, samples/s: 2236.535 1612390028.123225
train: epoch 61, iter 300, loss: 2.755624, top_1: 0.551914, top_k: 0.786016, samples/s: 2269.784 1612390039.4016745
train: epoch 61, iter 400, loss: 2.969829, top_1: 0.550742, top_k: 0.777695, samples/s: 2241.786 1612390050.8210464
train: epoch 61, iter 500, loss: 2.767575, top_1: 0.551953, top_k: 0.784219, samples/s: 2249.964 1612390062.1990504
train: epoch 61, iter 600, loss: 2.838758, top_1: 0.554609, top_k: 0.783086, samples/s: 2248.520 1612390073.5843084
train: epoch 61, iter 700, loss: 2.786548, top_1: 0.553398, top_k: 0.781445, samples/s: 2240.723 1612390085.009171
train: epoch 61, iter 800, loss: 2.854244, top_1: 0.547500, top_k: 0.780430, samples/s: 2226.827 1612390096.5053241
train: epoch 61, iter 900, loss: 2.704328, top_1: 0.554570, top_k: 0.783555, samples/s: 2228.895 1612390107.990899
train: epoch 61, iter 1000, loss: 2.709774, top_1: 0.549219, top_k: 0.777266, samples/s: 2231.270 1612390119.46412
train: epoch 61, iter 1100, loss: 2.878681, top_1: 0.546562, top_k: 0.777031, samples/s: 2209.593 1612390131.0500448
train: epoch 61, iter 1200, loss: 2.855821, top_1: 0.544766, top_k: 0.774961, samples/s: 2237.405 1612390142.4918056
train: epoch 61, iter 1300, loss: 2.818088, top_1: 0.554063, top_k: 0.782617, samples/s: 2219.444 1612390154.0262258
train: epoch 61, iter 1400, loss: 2.929300, top_1: 0.551289, top_k: 0.779141, samples/s: 2224.283 1612390165.5355406
train: epoch 61, iter 1500, loss: 2.989167, top_1: 0.543633, top_k: 0.777148, samples/s: 2211.555 1612390177.1111133
train: epoch 61, iter 1600, loss: 2.881514, top_1: 0.548789, top_k: 0.779258, samples/s: 2215.283 1612390188.6671553
train: epoch 61, iter 1700, loss: 2.836499, top_1: 0.550742, top_k: 0.777656, samples/s: 2203.400 1612390200.2857158
train: epoch 61, iter 1800, loss: 3.011647, top_1: 0.553203, top_k: 0.779297, samples/s: 2218.846 1612390211.8230917
train: epoch 61, iter 1900, loss: 2.819469, top_1: 0.550937, top_k: 0.783047, samples/s: 2218.949 1612390223.3601613
train: epoch 61, iter 2000, loss: 2.984894, top_1: 0.549063, top_k: 0.778125, samples/s: 2227.292 1612390234.8539124
train: epoch 61, iter 2100, loss: 2.929012, top_1: 0.543242, top_k: 0.775898, samples/s: 2241.565 1612390246.2745295
train: epoch 61, iter 2200, loss: 2.763442, top_1: 0.550977, top_k: 0.776523, samples/s: 2237.177 1612390257.7174947
train: epoch 61, iter 2300, loss: 3.046885, top_1: 0.546875, top_k: 0.773242, samples/s: 2231.191 1612390269.1912112
train: epoch 61, iter 2400, loss: 2.879345, top_1: 0.543086, top_k: 0.772617, samples/s: 2244.705 1612390280.5958061
train: epoch 61, iter 2500, loss: 2.978861, top_1: 0.543867, top_k: 0.775859, samples/s: 2238.962 1612390292.029696
train: epoch 61, iter 2600, loss: 3.037553, top_1: 0.542109, top_k: 0.772695, samples/s: 2190.211 1612390303.718043
train: epoch 61, iter 2700, loss: 3.027127, top_1: 0.541328, top_k: 0.774531, samples/s: 2239.302 1612390315.15023
train: epoch 61, iter 2800, loss: 2.940476, top_1: 0.546602, top_k: 0.778867, samples/s: 2247.795 1612390326.539112
train: epoch 61, iter 2900, loss: 2.798217, top_1: 0.542500, top_k: 0.779102, samples/s: 2225.248 1612390338.0434978
train: epoch 61, iter 3000, loss: 2.748118, top_1: 0.548516, top_k: 0.776328, samples/s: 2245.592 1612390349.4435773
train: epoch 61, iter 3100, loss: 2.772750, top_1: 0.547969, top_k: 0.775898, samples/s: 2240.107 1612390360.8715775
train: epoch 61, iter 3200, loss: 2.880223, top_1: 0.544922, top_k: 0.776523, samples/s: 2219.940 1612390372.403484
train: epoch 61, iter 3300, loss: 2.807610, top_1: 0.540820, top_k: 0.774961, samples/s: 2229.977 1612390383.8833745
train: epoch 61, iter 3400, loss: 2.812722, top_1: 0.550937, top_k: 0.782266, samples/s: 2223.343 1612390395.3976526
train: epoch 61, iter 3500, loss: 2.869488, top_1: 0.543438, top_k: 0.773320, samples/s: 2202.402 1612390407.021313
train: epoch 61, iter 3600, loss: 2.737860, top_1: 0.543750, top_k: 0.775937, samples/s: 2239.232 1612390418.453761
train: epoch 61, iter 3700, loss: 2.971544, top_1: 0.547773, top_k: 0.775430, samples/s: 2227.831 1612390429.945094
train: epoch 61, iter 3800, loss: 2.976766, top_1: 0.549922, top_k: 0.777188, samples/s: 2241.853 1612390441.3638573
train: epoch 61, iter 3900, loss: 2.746858, top_1: 0.547383, top_k: 0.774102, samples/s: 2247.476 1612390452.7548668
train: epoch 61, iter 4000, loss: 3.030890, top_1: 0.544180, top_k: 0.775312, samples/s: 2217.068 1612390464.3012288
train: epoch 61, iter 4100, loss: 2.952554, top_1: 0.549297, top_k: 0.778281, samples/s: 2241.327 1612390475.7230134
train: epoch 61, iter 4200, loss: 2.788411, top_1: 0.545742, top_k: 0.777305, samples/s: 2229.494 1612390487.205463
train: epoch 61, iter 4300, loss: 2.790178, top_1: 0.545703, top_k: 0.776484, samples/s: 2239.295 1612390498.6375892
train: epoch 61, iter 4400, loss: 2.856359, top_1: 0.547539, top_k: 0.775234, samples/s: 2243.599 1612390510.0478342
train: epoch 61, iter 4500, loss: 2.804975, top_1: 0.547500, top_k: 0.775781, samples/s: 2218.658 1612390521.5863419
train: epoch 61, iter 4600, loss: 2.785210, top_1: 0.542930, top_k: 0.773477, samples/s: 2250.932 1612390532.9594343
train: epoch 61, iter 4700, loss: 2.844896, top_1: 0.537266, top_k: 0.768711, samples/s: 2242.734 1612390544.374024
train: epoch 61, iter 4800, loss: 2.958707, top_1: 0.547695, top_k: 0.773516, samples/s: 2236.235 1612390555.8218932
train: epoch 61, iter 4900, loss: 2.780622, top_1: 0.546133, top_k: 0.772617, samples/s: 2232.582 1612390567.288449
train: epoch 61, iter 5000, loss: 2.952989, top_1: 0.545547, top_k: 0.779141, samples/s: 2234.127 1612390578.7471411
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_61.
validation: epoch 61, iter 195, top_1: 0.595333, top_k: 0.828466, samples/s: 2851.116 1612390596.5959945
train: epoch 62, iter 100, loss: 3.023813, top_1: 0.553672, top_k: 0.782773, samples/s: 2244.597 1612390629.08731
train: epoch 62, iter 200, loss: 2.667428, top_1: 0.563164, top_k: 0.788008, samples/s: 2254.843 1612390640.4407156
train: epoch 62, iter 300, loss: 2.863335, top_1: 0.551797, top_k: 0.780391, samples/s: 2247.428 1612390651.8315327
train: epoch 62, iter 400, loss: 2.732483, top_1: 0.550703, top_k: 0.779687, samples/s: 2261.838 1612390663.149707
train: epoch 62, iter 500, loss: 2.700466, top_1: 0.549727, top_k: 0.782188, samples/s: 2258.542 1612390674.4844425
train: epoch 62, iter 600, loss: 2.922448, top_1: 0.552148, top_k: 0.780625, samples/s: 2234.458 1612390685.9413753
train: epoch 62, iter 700, loss: 3.064710, top_1: 0.550312, top_k: 0.780117, samples/s: 2247.871 1612390697.3299024
train: epoch 62, iter 800, loss: 2.928843, top_1: 0.547930, top_k: 0.782891, samples/s: 2248.193 1612390708.7168894
train: epoch 62, iter 900, loss: 3.090867, top_1: 0.549102, top_k: 0.780117, samples/s: 2237.480 1612390720.1583433
train: epoch 62, iter 1000, loss: 2.777652, top_1: 0.543633, top_k: 0.775703, samples/s: 2224.599 1612390731.6659725
train: epoch 62, iter 1100, loss: 2.771518, top_1: 0.549453, top_k: 0.780078, samples/s: 2211.877 1612390743.23991
train: epoch 62, iter 1200, loss: 2.935103, top_1: 0.552500, top_k: 0.780195, samples/s: 2220.912 1612390754.7666426
train: epoch 62, iter 1300, loss: 2.538611, top_1: 0.550000, top_k: 0.780039, samples/s: 2222.291 1612390766.286321
train: epoch 62, iter 1400, loss: 2.865294, top_1: 0.551250, top_k: 0.776563, samples/s: 2222.948 1612390777.802519
train: epoch 62, iter 1500, loss: 2.932897, top_1: 0.550234, top_k: 0.780820, samples/s: 2221.157 1612390789.3282197
train: epoch 62, iter 1600, loss: 2.746742, top_1: 0.557266, top_k: 0.783203, samples/s: 2215.833 1612390800.8812695
train: epoch 62, iter 1700, loss: 2.766927, top_1: 0.552188, top_k: 0.780586, samples/s: 2235.142 1612390812.334774
train: epoch 62, iter 1800, loss: 2.925279, top_1: 0.551562, top_k: 0.777266, samples/s: 2228.798 1612390823.8206875
train: epoch 62, iter 1900, loss: 2.865798, top_1: 0.548438, top_k: 0.778086, samples/s: 2236.604 1612390835.2671347
train: epoch 62, iter 2000, loss: 2.688362, top_1: 0.551289, top_k: 0.777695, samples/s: 2208.455 1612390846.8584375
train: epoch 62, iter 2100, loss: 2.797945, top_1: 0.554688, top_k: 0.782930, samples/s: 2235.542 1612390858.3101273
train: epoch 62, iter 2200, loss: 2.620814, top_1: 0.550469, top_k: 0.782891, samples/s: 2211.460 1612390869.8859847
train: epoch 62, iter 2300, loss: 2.883768, top_1: 0.548828, top_k: 0.778047, samples/s: 2245.405 1612390881.2869093
train: epoch 62, iter 2400, loss: 2.762918, top_1: 0.553555, top_k: 0.778281, samples/s: 2234.739 1612390892.7423804
train: epoch 62, iter 2500, loss: 2.803608, top_1: 0.549844, top_k: 0.778828, samples/s: 2236.728 1612390904.187695
train: epoch 62, iter 2600, loss: 2.961310, top_1: 0.548672, top_k: 0.775352, samples/s: 2235.654 1612390915.638465
train: epoch 62, iter 2700, loss: 2.921644, top_1: 0.548281, top_k: 0.776445, samples/s: 2209.365 1612390927.2254944
train: epoch 62, iter 2800, loss: 2.809354, top_1: 0.551211, top_k: 0.778945, samples/s: 2239.374 1612390938.6575913
train: epoch 62, iter 2900, loss: 3.064319, top_1: 0.546523, top_k: 0.776055, samples/s: 2246.072 1612390950.054983
train: epoch 62, iter 3000, loss: 2.835298, top_1: 0.547969, top_k: 0.776484, samples/s: 2221.554 1612390961.5784018
train: epoch 62, iter 3100, loss: 2.879087, top_1: 0.545625, top_k: 0.777695, samples/s: 2232.484 1612390973.0454876
train: epoch 62, iter 3200, loss: 2.743621, top_1: 0.550586, top_k: 0.777656, samples/s: 2238.506 1612390984.4816418
train: epoch 62, iter 3300, loss: 2.884244, top_1: 0.549414, top_k: 0.775312, samples/s: 2237.298 1612390995.9240272
train: epoch 62, iter 3400, loss: 2.674967, top_1: 0.547930, top_k: 0.777656, samples/s: 2233.281 1612391007.3873432
train: epoch 62, iter 3500, loss: 2.993708, top_1: 0.546641, top_k: 0.771133, samples/s: 2216.038 1612391018.9391236
train: epoch 62, iter 3600, loss: 2.893579, top_1: 0.550586, top_k: 0.776211, samples/s: 2225.956 1612391030.4398549
train: epoch 62, iter 3700, loss: 2.962166, top_1: 0.549375, top_k: 0.776055, samples/s: 2244.454 1612391041.8456979
train: epoch 62, iter 3800, loss: 2.813481, top_1: 0.542383, top_k: 0.774531, samples/s: 2243.777 1612391053.2550783
train: epoch 62, iter 3900, loss: 3.069511, top_1: 0.547070, top_k: 0.780469, samples/s: 2233.617 1612391064.7162428
train: epoch 62, iter 4000, loss: 2.840522, top_1: 0.545273, top_k: 0.776758, samples/s: 2236.109 1612391076.1647956
train: epoch 62, iter 4100, loss: 2.850921, top_1: 0.545469, top_k: 0.771055, samples/s: 2233.683 1612391087.6256163
train: epoch 62, iter 4200, loss: 2.895471, top_1: 0.547227, top_k: 0.773086, samples/s: 2236.307 1612391099.0730112
train: epoch 62, iter 4300, loss: 2.809549, top_1: 0.547227, top_k: 0.775937, samples/s: 2253.016 1612391110.4356525
train: epoch 62, iter 4400, loss: 2.953352, top_1: 0.545352, top_k: 0.773203, samples/s: 2235.511 1612391121.8871424
train: epoch 62, iter 4500, loss: 2.883618, top_1: 0.544805, top_k: 0.776602, samples/s: 2215.889 1612391133.4400516
train: epoch 62, iter 4600, loss: 2.874652, top_1: 0.545352, top_k: 0.776680, samples/s: 2223.524 1612391144.953311
train: epoch 62, iter 4700, loss: 2.858578, top_1: 0.548711, top_k: 0.778203, samples/s: 2252.061 1612391156.3206758
train: epoch 62, iter 4800, loss: 2.836186, top_1: 0.544141, top_k: 0.777852, samples/s: 2232.088 1612391167.789794
train: epoch 62, iter 4900, loss: 3.074702, top_1: 0.549102, top_k: 0.776211, samples/s: 2248.314 1612391179.1760964
train: epoch 62, iter 5000, loss: 2.901447, top_1: 0.542109, top_k: 0.779023, samples/s: 2227.598 1612391190.6683555
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_62.
validation: epoch 62, iter 195, top_1: 0.594091, top_k: 0.829788, samples/s: 2866.977 1612391208.3962693
train: epoch 63, iter 100, loss: 2.811318, top_1: 0.558359, top_k: 0.783359, samples/s: 2214.804 1612391235.613678
train: epoch 63, iter 200, loss: 2.854001, top_1: 0.561406, top_k: 0.786641, samples/s: 2244.322 1612391247.020252
train: epoch 63, iter 300, loss: 2.811425, top_1: 0.553828, top_k: 0.784336, samples/s: 2250.079 1612391258.39768
train: epoch 63, iter 400, loss: 2.726140, top_1: 0.554648, top_k: 0.784727, samples/s: 2258.932 1612391269.7304094
train: epoch 63, iter 500, loss: 3.231628, top_1: 0.552539, top_k: 0.778906, samples/s: 2255.772 1612391281.0790775
train: epoch 63, iter 600, loss: 2.657283, top_1: 0.556719, top_k: 0.783633, samples/s: 2237.775 1612391292.5190232
train: epoch 63, iter 700, loss: 2.903536, top_1: 0.554023, top_k: 0.785000, samples/s: 2242.302 1612391303.9358552
train: epoch 63, iter 800, loss: 2.789419, top_1: 0.554453, top_k: 0.781719, samples/s: 2255.712 1612391315.2849257
train: epoch 63, iter 900, loss: 2.820217, top_1: 0.556172, top_k: 0.779336, samples/s: 2229.070 1612391326.76969
train: epoch 63, iter 1000, loss: 2.659526, top_1: 0.552383, top_k: 0.781055, samples/s: 2224.898 1612391338.2755759
train: epoch 63, iter 1100, loss: 3.071194, top_1: 0.550625, top_k: 0.779219, samples/s: 2202.791 1612391349.8972
train: epoch 63, iter 1200, loss: 2.817187, top_1: 0.546836, top_k: 0.779648, samples/s: 2236.561 1612391361.3433628
train: epoch 63, iter 1300, loss: 2.815410, top_1: 0.548594, top_k: 0.779453, samples/s: 2218.486 1612391372.8827507
train: epoch 63, iter 1400, loss: 2.772265, top_1: 0.559688, top_k: 0.785195, samples/s: 2217.884 1612391384.4252696
train: epoch 63, iter 1500, loss: 2.807785, top_1: 0.548516, top_k: 0.779531, samples/s: 2215.131 1612391395.9821582
train: epoch 63, iter 1600, loss: 2.887799, top_1: 0.554688, top_k: 0.781875, samples/s: 2225.911 1612391407.4830792
train: epoch 63, iter 1700, loss: 2.834534, top_1: 0.548750, top_k: 0.778594, samples/s: 2233.334 1612391418.9457355
train: epoch 63, iter 1800, loss: 2.873167, top_1: 0.549805, top_k: 0.778047, samples/s: 2243.249 1612391430.3577561
train: epoch 63, iter 1900, loss: 2.968253, top_1: 0.547227, top_k: 0.775898, samples/s: 2216.322 1612391441.9084353
train: epoch 63, iter 2000, loss: 2.748892, top_1: 0.553789, top_k: 0.780039, samples/s: 2244.535 1612391453.3139055
train: epoch 63, iter 2100, loss: 2.952410, top_1: 0.546641, top_k: 0.779258, samples/s: 2225.869 1612391464.815027
train: epoch 63, iter 2200, loss: 2.903501, top_1: 0.545156, top_k: 0.778125, samples/s: 2240.699 1612391476.240074
train: epoch 63, iter 2300, loss: 2.959855, top_1: 0.550352, top_k: 0.778203, samples/s: 2229.404 1612391487.7230232
train: epoch 63, iter 2400, loss: 2.671195, top_1: 0.556289, top_k: 0.780898, samples/s: 2235.835 1612391499.1727872
train: epoch 63, iter 2500, loss: 2.876794, top_1: 0.549844, top_k: 0.778633, samples/s: 2197.087 1612391510.824586
train: epoch 63, iter 2600, loss: 2.847735, top_1: 0.551211, top_k: 0.780312, samples/s: 2258.504 1612391522.1595533
train: epoch 63, iter 2700, loss: 2.999833, top_1: 0.549258, top_k: 0.779844, samples/s: 2228.653 1612391533.646316
train: epoch 63, iter 2800, loss: 2.835138, top_1: 0.552109, top_k: 0.776680, samples/s: 2233.256 1612391545.1093602
train: epoch 63, iter 2900, loss: 2.849309, top_1: 0.546562, top_k: 0.774062, samples/s: 2246.777 1612391556.5034604
train: epoch 63, iter 3000, loss: 2.965442, top_1: 0.548750, top_k: 0.776719, samples/s: 2234.451 1612391567.9604073
train: epoch 63, iter 3100, loss: 2.766551, top_1: 0.552695, top_k: 0.781914, samples/s: 2228.445 1612391579.448302
train: epoch 63, iter 3200, loss: 2.765689, top_1: 0.551250, top_k: 0.776133, samples/s: 2213.027 1612391591.0161223
train: epoch 63, iter 3300, loss: 2.804279, top_1: 0.546328, top_k: 0.777656, samples/s: 2256.411 1612391602.3615508
train: epoch 63, iter 3400, loss: 2.629757, top_1: 0.549336, top_k: 0.780039, samples/s: 2232.867 1612391613.8266394
train: epoch 63, iter 3500, loss: 2.744096, top_1: 0.552305, top_k: 0.781016, samples/s: 2225.213 1612391625.331157
train: epoch 63, iter 3600, loss: 2.885730, top_1: 0.553281, top_k: 0.779922, samples/s: 2230.792 1612391636.8068888
train: epoch 63, iter 3700, loss: 2.932055, top_1: 0.547500, top_k: 0.778281, samples/s: 2248.300 1612391648.1933165
train: epoch 63, iter 3800, loss: 3.130329, top_1: 0.554023, top_k: 0.781523, samples/s: 2198.862 1612391659.8357248
train: epoch 63, iter 3900, loss: 2.870358, top_1: 0.544609, top_k: 0.778086, samples/s: 2245.662 1612391671.235414
train: epoch 63, iter 4000, loss: 3.119637, top_1: 0.549336, top_k: 0.778359, samples/s: 2203.939 1612391682.850992
train: epoch 63, iter 4100, loss: 2.671731, top_1: 0.547383, top_k: 0.777109, samples/s: 2246.743 1612391694.2453032
train: epoch 63, iter 4200, loss: 2.662085, top_1: 0.552383, top_k: 0.779570, samples/s: 2208.314 1612391705.8378325
train: epoch 63, iter 4300, loss: 2.926829, top_1: 0.550703, top_k: 0.775664, samples/s: 2237.048 1612391717.2814734
train: epoch 63, iter 4400, loss: 2.744561, top_1: 0.546406, top_k: 0.774258, samples/s: 2221.121 1612391728.807199
train: epoch 63, iter 4500, loss: 2.992418, top_1: 0.553711, top_k: 0.779219, samples/s: 2235.861 1612391740.2569182
train: epoch 63, iter 4600, loss: 2.810881, top_1: 0.548828, top_k: 0.776211, samples/s: 2244.600 1612391751.6620538
train: epoch 63, iter 4700, loss: 3.171022, top_1: 0.551602, top_k: 0.779844, samples/s: 2244.497 1612391763.067781
train: epoch 63, iter 4800, loss: 2.958958, top_1: 0.542539, top_k: 0.775156, samples/s: 2245.801 1612391774.4667835
train: epoch 63, iter 4900, loss: 2.961960, top_1: 0.544492, top_k: 0.778867, samples/s: 2205.960 1612391786.0717113
train: epoch 63, iter 5000, loss: 2.783983, top_1: 0.551055, top_k: 0.784297, samples/s: 2228.995 1612391797.5566974
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_63.
validation: epoch 63, iter 195, top_1: 0.587600, top_k: 0.826342, samples/s: 2959.892 1612391814.6693006
train: epoch 64, iter 100, loss: 2.803653, top_1: 0.565742, top_k: 0.793672, samples/s: 2216.045 1612391841.8020813
train: epoch 64, iter 200, loss: 2.882601, top_1: 0.559492, top_k: 0.786055, samples/s: 2247.049 1612391853.194812
train: epoch 64, iter 300, loss: 2.761750, top_1: 0.559141, top_k: 0.784258, samples/s: 2243.106 1612391864.6075585
train: epoch 64, iter 400, loss: 2.859463, top_1: 0.559961, top_k: 0.787773, samples/s: 2260.551 1612391875.9322264
train: epoch 64, iter 500, loss: 2.771561, top_1: 0.546602, top_k: 0.778320, samples/s: 2252.494 1612391887.2976174
train: epoch 64, iter 600, loss: 2.886827, top_1: 0.559883, top_k: 0.786641, samples/s: 2244.351 1612391898.7038233
train: epoch 64, iter 700, loss: 2.751680, top_1: 0.553906, top_k: 0.782109, samples/s: 2239.324 1612391910.1358812
train: epoch 64, iter 800, loss: 2.849180, top_1: 0.553750, top_k: 0.783594, samples/s: 2238.897 1612391921.5700865
train: epoch 64, iter 900, loss: 2.847305, top_1: 0.554727, top_k: 0.782383, samples/s: 2217.285 1612391933.1158972
train: epoch 64, iter 1000, loss: 2.947875, top_1: 0.560156, top_k: 0.785898, samples/s: 2232.729 1612391944.5815587
train: epoch 64, iter 1100, loss: 2.891951, top_1: 0.556719, top_k: 0.781055, samples/s: 2211.261 1612391956.1586707
train: epoch 64, iter 1200, loss: 2.743293, top_1: 0.552188, top_k: 0.781992, samples/s: 2225.142 1612391967.6634727
train: epoch 64, iter 1300, loss: 2.758567, top_1: 0.551992, top_k: 0.780039, samples/s: 2199.875 1612391979.3004937
train: epoch 64, iter 1400, loss: 2.943088, top_1: 0.552188, top_k: 0.780156, samples/s: 2229.725 1612391990.7817423
train: epoch 64, iter 1500, loss: 3.007610, top_1: 0.553047, top_k: 0.778086, samples/s: 2228.951 1612392002.2670608
train: epoch 64, iter 1600, loss: 2.865883, top_1: 0.556289, top_k: 0.782383, samples/s: 2207.197 1612392013.8654397
train: epoch 64, iter 1700, loss: 2.720850, top_1: 0.551758, top_k: 0.779297, samples/s: 2214.955 1612392025.423229
train: epoch 64, iter 1800, loss: 2.814866, top_1: 0.554258, top_k: 0.780234, samples/s: 2209.095 1612392037.0116353
train: epoch 64, iter 1900, loss: 2.974011, top_1: 0.550703, top_k: 0.780234, samples/s: 2224.737 1612392048.5186014
train: epoch 64, iter 2000, loss: 2.823732, top_1: 0.552188, top_k: 0.782891, samples/s: 2225.618 1612392060.0210242
train: epoch 64, iter 2100, loss: 2.769866, top_1: 0.554805, top_k: 0.781133, samples/s: 2220.140 1612392071.551869
train: epoch 64, iter 2200, loss: 2.936182, top_1: 0.554141, top_k: 0.786016, samples/s: 2220.525 1612392083.0806928
train: epoch 64, iter 2300, loss: 2.796808, top_1: 0.555859, top_k: 0.782422, samples/s: 2248.329 1612392094.4668918
train: epoch 64, iter 2400, loss: 2.827610, top_1: 0.549219, top_k: 0.781445, samples/s: 2223.051 1612392105.9825757
train: epoch 64, iter 2500, loss: 2.824625, top_1: 0.553398, top_k: 0.782148, samples/s: 2245.011 1612392117.3856492
train: epoch 64, iter 2600, loss: 2.867140, top_1: 0.553164, top_k: 0.780273, samples/s: 2246.337 1612392128.7820046
train: epoch 64, iter 2700, loss: 2.928340, top_1: 0.550117, top_k: 0.779844, samples/s: 2232.514 1612392140.2488542
train: epoch 64, iter 2800, loss: 2.864744, top_1: 0.551875, top_k: 0.780469, samples/s: 2226.731 1612392151.745545
train: epoch 64, iter 2900, loss: 2.729688, top_1: 0.552813, top_k: 0.779961, samples/s: 2231.816 1612392163.2160807
train: epoch 64, iter 3000, loss: 3.078547, top_1: 0.552227, top_k: 0.781875, samples/s: 2254.268 1612392174.5722733
train: epoch 64, iter 3100, loss: 2.946056, top_1: 0.549922, top_k: 0.780937, samples/s: 2224.595 1612392186.07996
train: epoch 64, iter 3200, loss: 2.765437, top_1: 0.553555, top_k: 0.779336, samples/s: 2224.763 1612392197.5867972
train: epoch 64, iter 3300, loss: 2.833193, top_1: 0.549023, top_k: 0.779727, samples/s: 2247.184 1612392208.978851
train: epoch 64, iter 3400, loss: 3.065477, top_1: 0.540195, top_k: 0.774883, samples/s: 2230.812 1612392220.4544628
train: epoch 64, iter 3500, loss: 2.829136, top_1: 0.551719, top_k: 0.782031, samples/s: 2240.186 1612392231.8821352
train: epoch 64, iter 3600, loss: 2.808838, top_1: 0.545977, top_k: 0.776484, samples/s: 2229.146 1612392243.366387
train: epoch 64, iter 3700, loss: 2.807784, top_1: 0.548711, top_k: 0.779297, samples/s: 2239.443 1612392254.7978039
train: epoch 64, iter 3800, loss: 2.888865, top_1: 0.557109, top_k: 0.784297, samples/s: 2228.628 1612392266.2846928
train: epoch 64, iter 3900, loss: 2.729031, top_1: 0.549805, top_k: 0.778242, samples/s: 2245.217 1612392277.6866617
train: epoch 64, iter 4000, loss: 2.927277, top_1: 0.557930, top_k: 0.783945, samples/s: 2246.636 1612392289.0815926
train: epoch 64, iter 4100, loss: 2.797535, top_1: 0.548828, top_k: 0.776641, samples/s: 2232.142 1612392300.5502636
train: epoch 64, iter 4200, loss: 2.704984, top_1: 0.551992, top_k: 0.776289, samples/s: 2227.650 1612392312.042266
train: epoch 64, iter 4300, loss: 3.068353, top_1: 0.548750, top_k: 0.778672, samples/s: 2230.478 1612392323.5197313
train: epoch 64, iter 4400, loss: 2.646866, top_1: 0.553047, top_k: 0.778398, samples/s: 2225.857 1612392335.0207624
train: epoch 64, iter 4500, loss: 2.865220, top_1: 0.541602, top_k: 0.776680, samples/s: 2247.295 1612392346.4122186
train: epoch 64, iter 4600, loss: 2.786676, top_1: 0.547031, top_k: 0.776953, samples/s: 2246.311 1612392357.8090343
train: epoch 64, iter 4700, loss: 2.718006, top_1: 0.549844, top_k: 0.779453, samples/s: 2204.672 1612392369.4203758
train: epoch 64, iter 4800, loss: 2.877142, top_1: 0.546133, top_k: 0.775547, samples/s: 2258.998 1612392380.752834
train: epoch 64, iter 4900, loss: 2.677107, top_1: 0.550195, top_k: 0.777969, samples/s: 2220.845 1612392392.280309
train: epoch 64, iter 5000, loss: 2.923614, top_1: 0.553320, top_k: 0.779922, samples/s: 2245.186 1612392403.6822248
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_64.
validation: epoch 64, iter 195, top_1: 0.598057, top_k: 0.832652, samples/s: 2922.624 1612392421.147456
train: epoch 65, iter 100, loss: 2.929095, top_1: 0.564375, top_k: 0.787891, samples/s: 2243.411 1612392448.3963401
train: epoch 65, iter 200, loss: 2.793877, top_1: 0.559336, top_k: 0.785781, samples/s: 2261.077 1612392459.7183647
train: epoch 65, iter 300, loss: 2.872500, top_1: 0.561875, top_k: 0.792656, samples/s: 2261.635 1612392471.0377553
train: epoch 65, iter 400, loss: 3.056692, top_1: 0.559531, top_k: 0.786875, samples/s: 2260.608 1612392482.3621194
train: epoch 65, iter 500, loss: 2.906468, top_1: 0.554727, top_k: 0.784258, samples/s: 2250.097 1612392493.7393105
train: epoch 65, iter 600, loss: 2.860799, top_1: 0.560547, top_k: 0.786875, samples/s: 2161.768 1612392505.5813982
train: epoch 65, iter 700, loss: 2.871857, top_1: 0.557383, top_k: 0.786953, samples/s: 2242.848 1612392516.995661
train: epoch 65, iter 800, loss: 2.771819, top_1: 0.559219, top_k: 0.785391, samples/s: 2242.365 1612392528.412025
train: epoch 65, iter 900, loss: 2.764419, top_1: 0.554336, top_k: 0.777461, samples/s: 2220.789 1612392539.9394703
train: epoch 65, iter 1000, loss: 2.879363, top_1: 0.561172, top_k: 0.784727, samples/s: 2199.628 1612392551.5778763
train: epoch 65, iter 1100, loss: 2.917980, top_1: 0.554805, top_k: 0.783945, samples/s: 2225.585 1612392563.080359
train: epoch 65, iter 1200, loss: 2.880778, top_1: 0.557539, top_k: 0.787227, samples/s: 2243.268 1612392574.4922898
train: epoch 65, iter 1300, loss: 2.902452, top_1: 0.554141, top_k: 0.781484, samples/s: 2234.503 1612392585.9489639
train: epoch 65, iter 1400, loss: 2.784425, top_1: 0.559766, top_k: 0.783203, samples/s: 2200.825 1612392597.5810628
train: epoch 65, iter 1500, loss: 2.883305, top_1: 0.554492, top_k: 0.780977, samples/s: 2218.211 1612392609.1218028
train: epoch 65, iter 1600, loss: 2.848213, top_1: 0.552773, top_k: 0.775391, samples/s: 2218.792 1612392620.659689
train: epoch 65, iter 1700, loss: 2.909072, top_1: 0.553789, top_k: 0.778672, samples/s: 2221.068 1612392632.1856122
train: epoch 65, iter 1800, loss: 2.875232, top_1: 0.556641, top_k: 0.782852, samples/s: 2238.236 1612392643.6232421
train: epoch 65, iter 1900, loss: 2.713355, top_1: 0.556992, top_k: 0.784453, samples/s: 2228.222 1612392655.1121519
train: epoch 65, iter 2000, loss: 2.884593, top_1: 0.559375, top_k: 0.785352, samples/s: 2201.831 1612392666.738901
train: epoch 65, iter 2100, loss: 2.957950, top_1: 0.559922, top_k: 0.785078, samples/s: 2240.177 1612392678.166586
train: epoch 65, iter 2200, loss: 2.931584, top_1: 0.553477, top_k: 0.780195, samples/s: 2223.671 1612392689.679047
train: epoch 65, iter 2300, loss: 2.855975, top_1: 0.546484, top_k: 0.775469, samples/s: 2217.757 1612392701.222312
train: epoch 65, iter 2400, loss: 2.665469, top_1: 0.551289, top_k: 0.783281, samples/s: 2245.972 1612392712.620385
train: epoch 65, iter 2500, loss: 2.915755, top_1: 0.548945, top_k: 0.776875, samples/s: 2241.761 1612392724.0400007
train: epoch 65, iter 2600, loss: 2.884873, top_1: 0.552422, top_k: 0.781133, samples/s: 2224.816 1612392735.5465481
train: epoch 65, iter 2700, loss: 2.810550, top_1: 0.557656, top_k: 0.784141, samples/s: 2228.401 1612392747.0346656
train: epoch 65, iter 2800, loss: 2.958775, top_1: 0.552070, top_k: 0.782188, samples/s: 2227.075 1612392758.5295856
train: epoch 65, iter 2900, loss: 2.766890, top_1: 0.556250, top_k: 0.783320, samples/s: 2238.843 1612392769.9640083
train: epoch 65, iter 3000, loss: 2.772654, top_1: 0.550859, top_k: 0.782266, samples/s: 2211.566 1612392781.5395358
train: epoch 65, iter 3100, loss: 2.956875, top_1: 0.547227, top_k: 0.780234, samples/s: 2254.497 1612392792.8945699
train: epoch 65, iter 3200, loss: 2.729756, top_1: 0.554531, top_k: 0.778555, samples/s: 2225.863 1612392804.3957326
train: epoch 65, iter 3300, loss: 3.066580, top_1: 0.552852, top_k: 0.778594, samples/s: 2254.412 1612392815.7513313
train: epoch 65, iter 3400, loss: 2.744040, top_1: 0.552461, top_k: 0.779375, samples/s: 2232.315 1612392827.219177
train: epoch 65, iter 3500, loss: 2.894411, top_1: 0.552813, top_k: 0.779375, samples/s: 2249.326 1612392838.6003833
train: epoch 65, iter 3600, loss: 2.835413, top_1: 0.551055, top_k: 0.779922, samples/s: 2214.730 1612392850.1593208
train: epoch 65, iter 3700, loss: 2.897738, top_1: 0.556836, top_k: 0.782773, samples/s: 2242.615 1612392861.574574
train: epoch 65, iter 3800, loss: 2.732174, top_1: 0.547500, top_k: 0.776836, samples/s: 2213.887 1612392873.137935
train: epoch 65, iter 3900, loss: 2.824582, top_1: 0.550156, top_k: 0.779687, samples/s: 2232.210 1612392884.6063874
train: epoch 65, iter 4000, loss: 2.813599, top_1: 0.547031, top_k: 0.778516, samples/s: 2236.950 1612392896.0505502
train: epoch 65, iter 4100, loss: 3.057810, top_1: 0.544687, top_k: 0.775625, samples/s: 2242.961 1612392907.4641187
train: epoch 65, iter 4200, loss: 2.943335, top_1: 0.549727, top_k: 0.779961, samples/s: 2235.361 1612392918.9163663
train: epoch 65, iter 4300, loss: 2.886481, top_1: 0.551719, top_k: 0.778438, samples/s: 2233.815 1612392930.3766174
train: epoch 65, iter 4400, loss: 2.887808, top_1: 0.552656, top_k: 0.780820, samples/s: 2235.650 1612392941.827393
train: epoch 65, iter 4500, loss: 2.858847, top_1: 0.547148, top_k: 0.776602, samples/s: 2228.632 1612392953.3142889
train: epoch 65, iter 4600, loss: 2.976181, top_1: 0.557578, top_k: 0.780703, samples/s: 2246.976 1612392964.7073076
train: epoch 65, iter 4700, loss: 2.920671, top_1: 0.552266, top_k: 0.781445, samples/s: 2240.521 1612392976.1332572
train: epoch 65, iter 4800, loss: 2.849638, top_1: 0.552383, top_k: 0.783281, samples/s: 2234.143 1612392987.591762
train: epoch 65, iter 4900, loss: 2.762153, top_1: 0.551133, top_k: 0.780508, samples/s: 2238.150 1612392999.0298083
train: epoch 65, iter 5000, loss: 2.901538, top_1: 0.550430, top_k: 0.778789, samples/s: 2209.202 1612393010.6176674
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_65.
validation: epoch 65, iter 195, top_1: 0.599880, top_k: 0.832332, samples/s: 2807.232 1612393028.7621891
train: epoch 66, iter 100, loss: 2.697896, top_1: 0.561953, top_k: 0.785586, samples/s: 2223.393 1612393055.9745016
train: epoch 66, iter 200, loss: 2.822810, top_1: 0.560312, top_k: 0.787578, samples/s: 2246.693 1612393067.3690345
train: epoch 66, iter 300, loss: 2.783423, top_1: 0.556016, top_k: 0.785312, samples/s: 2262.762 1612393078.6826413
train: epoch 66, iter 400, loss: 3.039854, top_1: 0.558516, top_k: 0.783281, samples/s: 2251.829 1612393090.0511882
train: epoch 66, iter 500, loss: 2.721937, top_1: 0.550195, top_k: 0.780898, samples/s: 2255.115 1612393101.4031825
train: epoch 66, iter 600, loss: 2.756502, top_1: 0.560586, top_k: 0.788750, samples/s: 2252.133 1612393112.7703314
train: epoch 66, iter 700, loss: 2.890754, top_1: 0.562500, top_k: 0.788438, samples/s: 2243.838 1612393124.1792018
train: epoch 66, iter 800, loss: 2.795862, top_1: 0.565312, top_k: 0.792539, samples/s: 2239.199 1612393135.6118286
train: epoch 66, iter 900, loss: 2.932636, top_1: 0.564180, top_k: 0.786094, samples/s: 2235.025 1612393147.0658324
train: epoch 66, iter 1000, loss: 2.886537, top_1: 0.551328, top_k: 0.783789, samples/s: 2213.285 1612393158.6323502
train: epoch 66, iter 1100, loss: 2.826678, top_1: 0.558984, top_k: 0.784375, samples/s: 2196.937 1612393170.284945
train: epoch 66, iter 1200, loss: 2.853906, top_1: 0.557461, top_k: 0.784570, samples/s: 2228.244 1612393181.7738607
train: epoch 66, iter 1300, loss: 2.790773, top_1: 0.558555, top_k: 0.785312, samples/s: 2221.785 1612393193.2960765
train: epoch 66, iter 1400, loss: 2.935898, top_1: 0.555391, top_k: 0.783125, samples/s: 2218.003 1612393204.8379877
train: epoch 66, iter 1500, loss: 2.687442, top_1: 0.554180, top_k: 0.779961, samples/s: 2207.049 1612393216.4371915
train: epoch 66, iter 1600, loss: 3.002992, top_1: 0.553828, top_k: 0.782500, samples/s: 2217.720 1612393227.9806046
train: epoch 66, iter 1700, loss: 2.748762, top_1: 0.556992, top_k: 0.783438, samples/s: 2207.001 1612393239.5800483
train: epoch 66, iter 1800, loss: 2.787007, top_1: 0.550781, top_k: 0.784609, samples/s: 2214.109 1612393251.1423962
train: epoch 66, iter 1900, loss: 2.945478, top_1: 0.558438, top_k: 0.780977, samples/s: 2210.903 1612393262.7212892
train: epoch 66, iter 2000, loss: 2.746387, top_1: 0.555156, top_k: 0.782305, samples/s: 2218.547 1612393274.2604973
train: epoch 66, iter 2100, loss: 2.882892, top_1: 0.555000, top_k: 0.785117, samples/s: 2231.730 1612393285.7312393
train: epoch 66, iter 2200, loss: 2.836497, top_1: 0.558086, top_k: 0.787031, samples/s: 2206.414 1612393297.3338044
train: epoch 66, iter 2300, loss: 2.781427, top_1: 0.555078, top_k: 0.784766, samples/s: 2224.349 1612393308.8427367
train: epoch 66, iter 2400, loss: 2.712874, top_1: 0.552695, top_k: 0.782227, samples/s: 2195.477 1612393320.5031912
train: epoch 66, iter 2500, loss: 2.822561, top_1: 0.558281, top_k: 0.783711, samples/s: 2224.542 1612393332.0110996
train: epoch 66, iter 2600, loss: 2.800329, top_1: 0.560664, top_k: 0.784648, samples/s: 2214.754 1612393343.5699518
train: epoch 66, iter 2700, loss: 2.986603, top_1: 0.549180, top_k: 0.784609, samples/s: 2242.791 1612393354.9847248
train: epoch 66, iter 2800, loss: 2.898189, top_1: 0.558555, top_k: 0.783164, samples/s: 2240.115 1612393366.412258
train: epoch 66, iter 2900, loss: 2.675431, top_1: 0.549687, top_k: 0.778984, samples/s: 2223.978 1612393377.9236636
train: epoch 66, iter 3000, loss: 2.926497, top_1: 0.556641, top_k: 0.781719, samples/s: 2228.306 1612393389.411727
train: epoch 66, iter 3100, loss: 2.961656, top_1: 0.548867, top_k: 0.782266, samples/s: 2226.448 1612393400.9099474
train: epoch 66, iter 3200, loss: 3.120797, top_1: 0.551641, top_k: 0.779648, samples/s: 2232.554 1612393412.3766148
train: epoch 66, iter 3300, loss: 2.709883, top_1: 0.555937, top_k: 0.785000, samples/s: 2242.098 1612393423.79447
train: epoch 66, iter 3400, loss: 2.712467, top_1: 0.555234, top_k: 0.788867, samples/s: 2224.184 1612393435.3042707
train: epoch 66, iter 3500, loss: 2.955134, top_1: 0.554570, top_k: 0.782695, samples/s: 2238.074 1612393446.7426412
train: epoch 66, iter 3600, loss: 2.877635, top_1: 0.551172, top_k: 0.780234, samples/s: 2228.725 1612393458.2290537
train: epoch 66, iter 3700, loss: 2.687217, top_1: 0.554258, top_k: 0.777500, samples/s: 2229.876 1612393469.709504
train: epoch 66, iter 3800, loss: 3.157552, top_1: 0.552969, top_k: 0.781367, samples/s: 2233.625 1612393481.1707215
train: epoch 66, iter 3900, loss: 2.698123, top_1: 0.552734, top_k: 0.782383, samples/s: 2216.326 1612393492.721331
train: epoch 66, iter 4000, loss: 2.821313, top_1: 0.546445, top_k: 0.776406, samples/s: 2219.599 1612393504.2549353
train: epoch 66, iter 4100, loss: 2.884035, top_1: 0.551836, top_k: 0.781016, samples/s: 2233.055 1612393515.7190506
train: epoch 66, iter 4200, loss: 2.790784, top_1: 0.551445, top_k: 0.780547, samples/s: 2237.171 1612393527.162146
train: epoch 66, iter 4300, loss: 2.828102, top_1: 0.546562, top_k: 0.774180, samples/s: 2236.790 1612393538.607436
train: epoch 66, iter 4400, loss: 2.896794, top_1: 0.548555, top_k: 0.777695, samples/s: 2221.778 1612393550.129355
train: epoch 66, iter 4500, loss: 2.822344, top_1: 0.548320, top_k: 0.780195, samples/s: 2247.713 1612393561.5191135
train: epoch 66, iter 4600, loss: 2.712232, top_1: 0.550156, top_k: 0.778750, samples/s: 2230.608 1612393572.9955208
train: epoch 66, iter 4700, loss: 3.011949, top_1: 0.550859, top_k: 0.783984, samples/s: 2237.792 1612393584.4352572
train: epoch 66, iter 4800, loss: 2.840187, top_1: 0.552500, top_k: 0.783672, samples/s: 2239.930 1612393595.8642585
train: epoch 66, iter 4900, loss: 2.922882, top_1: 0.548320, top_k: 0.778555, samples/s: 2216.251 1612393607.415215
train: epoch 66, iter 5000, loss: 2.719412, top_1: 0.555195, top_k: 0.785391, samples/s: 2264.145 1612393618.7218971
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_66.
validation: epoch 66, iter 195, top_1: 0.601743, top_k: 0.835397, samples/s: 2824.103 1612393636.7546756
train: epoch 67, iter 100, loss: 2.798144, top_1: 0.573867, top_k: 0.796016, samples/s: 2232.568 1612393664.2431211
train: epoch 67, iter 200, loss: 2.808709, top_1: 0.559961, top_k: 0.790742, samples/s: 2257.676 1612393675.5822496
train: epoch 67, iter 300, loss: 2.900647, top_1: 0.555234, top_k: 0.782852, samples/s: 2251.585 1612393686.952013
train: epoch 67, iter 400, loss: 2.906048, top_1: 0.554688, top_k: 0.782969, samples/s: 2253.190 1612393698.313653
train: epoch 67, iter 500, loss: 2.816059, top_1: 0.558242, top_k: 0.785664, samples/s: 2256.094 1612393709.6606963
train: epoch 67, iter 600, loss: 2.977308, top_1: 0.556836, top_k: 0.789766, samples/s: 2242.131 1612393721.0783956
train: epoch 67, iter 700, loss: 2.937992, top_1: 0.558242, top_k: 0.783320, samples/s: 2253.164 1612393732.4402063
train: epoch 67, iter 800, loss: 2.828534, top_1: 0.562461, top_k: 0.792734, samples/s: 2235.584 1612393743.8913476
train: epoch 67, iter 900, loss: 2.735623, top_1: 0.558398, top_k: 0.787578, samples/s: 2232.552 1612393755.3582625
train: epoch 67, iter 1000, loss: 2.837165, top_1: 0.559102, top_k: 0.790391, samples/s: 2227.858 1612393766.8489
train: epoch 67, iter 1100, loss: 2.624775, top_1: 0.559180, top_k: 0.789219, samples/s: 2216.441 1612393778.3989577
train: epoch 67, iter 1200, loss: 2.844184, top_1: 0.564219, top_k: 0.789023, samples/s: 2218.618 1612393789.9378493
train: epoch 67, iter 1300, loss: 3.002373, top_1: 0.562695, top_k: 0.787344, samples/s: 2218.004 1612393801.4795718
train: epoch 67, iter 1400, loss: 2.799806, top_1: 0.555312, top_k: 0.779766, samples/s: 2213.385 1612393813.0455718
train: epoch 67, iter 1500, loss: 3.069314, top_1: 0.562070, top_k: 0.787891, samples/s: 2228.678 1612393824.532207
train: epoch 67, iter 1600, loss: 2.939335, top_1: 0.551602, top_k: 0.782852, samples/s: 2243.388 1612393835.9435625
train: epoch 67, iter 1700, loss: 2.873467, top_1: 0.556914, top_k: 0.787344, samples/s: 2227.049 1612393847.4385555
train: epoch 67, iter 1800, loss: 2.830044, top_1: 0.549023, top_k: 0.780000, samples/s: 2235.892 1612393858.8882325
train: epoch 67, iter 1900, loss: 2.876959, top_1: 0.560312, top_k: 0.785000, samples/s: 2244.759 1612393870.2924592
train: epoch 67, iter 2000, loss: 2.744808, top_1: 0.559375, top_k: 0.787227, samples/s: 2235.410 1612393881.7445662
train: epoch 67, iter 2100, loss: 2.941581, top_1: 0.556758, top_k: 0.786563, samples/s: 2222.047 1612393893.265401
train: epoch 67, iter 2200, loss: 2.745634, top_1: 0.551211, top_k: 0.780977, samples/s: 2214.570 1612393904.8252842
train: epoch 67, iter 2300, loss: 2.827127, top_1: 0.561211, top_k: 0.786914, samples/s: 2246.814 1612393916.2191184
train: epoch 67, iter 2400, loss: 2.721390, top_1: 0.549219, top_k: 0.783594, samples/s: 2211.282 1612393927.7961085
train: epoch 67, iter 2500, loss: 2.750581, top_1: 0.554102, top_k: 0.784570, samples/s: 2232.452 1612393939.2633207
train: epoch 67, iter 2600, loss: 2.897589, top_1: 0.553633, top_k: 0.782500, samples/s: 2233.288 1612393950.726305
train: epoch 67, iter 2700, loss: 2.853046, top_1: 0.554414, top_k: 0.783789, samples/s: 2241.143 1612393962.1489801
train: epoch 67, iter 2800, loss: 3.165436, top_1: 0.554180, top_k: 0.781953, samples/s: 2200.129 1612393973.7847583
train: epoch 67, iter 2900, loss: 3.009041, top_1: 0.554688, top_k: 0.784766, samples/s: 2243.909 1612393985.1933253
train: epoch 67, iter 3000, loss: 2.975294, top_1: 0.556055, top_k: 0.785781, samples/s: 2240.462 1612393996.6195385
train: epoch 67, iter 3100, loss: 3.024012, top_1: 0.561523, top_k: 0.787734, samples/s: 2232.731 1612394008.0853143
train: epoch 67, iter 3200, loss: 2.904252, top_1: 0.562539, top_k: 0.785469, samples/s: 2232.792 1612394019.550796
train: epoch 67, iter 3300, loss: 2.614850, top_1: 0.559023, top_k: 0.783906, samples/s: 2226.173 1612394031.0504115
train: epoch 67, iter 3400, loss: 2.919955, top_1: 0.551406, top_k: 0.782891, samples/s: 2227.550 1612394042.5429175
train: epoch 67, iter 3500, loss: 2.762850, top_1: 0.558516, top_k: 0.782539, samples/s: 2230.120 1612394054.0220003
train: epoch 67, iter 3600, loss: 2.857656, top_1: 0.553281, top_k: 0.784961, samples/s: 2235.365 1612394065.4742835
train: epoch 67, iter 3700, loss: 2.880501, top_1: 0.551250, top_k: 0.782070, samples/s: 2237.665 1612394076.9148114
train: epoch 67, iter 3800, loss: 2.786694, top_1: 0.553203, top_k: 0.783320, samples/s: 2216.885 1612394088.4625363
train: epoch 67, iter 3900, loss: 2.836346, top_1: 0.551445, top_k: 0.779492, samples/s: 2246.495 1612394099.8580496
train: epoch 67, iter 4000, loss: 2.945486, top_1: 0.552773, top_k: 0.782305, samples/s: 2239.275 1612394111.2902935
train: epoch 67, iter 4100, loss: 2.885934, top_1: 0.552188, top_k: 0.779570, samples/s: 2212.171 1612394122.8628266
train: epoch 67, iter 4200, loss: 3.079470, top_1: 0.550352, top_k: 0.781133, samples/s: 2246.276 1612394134.2594583
train: epoch 67, iter 4300, loss: 2.903595, top_1: 0.554844, top_k: 0.785352, samples/s: 2242.476 1612394145.6752286
train: epoch 67, iter 4400, loss: 2.805962, top_1: 0.555234, top_k: 0.787539, samples/s: 2226.016 1612394157.1755893
train: epoch 67, iter 4500, loss: 2.730036, top_1: 0.555195, top_k: 0.782891, samples/s: 2243.168 1612394168.5880227
train: epoch 67, iter 4600, loss: 2.902664, top_1: 0.552813, top_k: 0.778945, samples/s: 2236.302 1612394180.03549
train: epoch 67, iter 4700, loss: 2.854489, top_1: 0.555937, top_k: 0.781172, samples/s: 2225.276 1612394191.539719
train: epoch 67, iter 4800, loss: 2.954615, top_1: 0.552813, top_k: 0.784219, samples/s: 2237.090 1612394202.9833455
train: epoch 67, iter 4900, loss: 2.937528, top_1: 0.549414, top_k: 0.783398, samples/s: 2242.721 1612394214.3978546
train: epoch 67, iter 5000, loss: 2.822302, top_1: 0.557734, top_k: 0.782891, samples/s: 2224.784 1612394225.9045637
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_67.
validation: epoch 67, iter 195, top_1: 0.604046, top_k: 0.835196, samples/s: 2794.846 1612394244.2105591
train: epoch 68, iter 100, loss: 2.909321, top_1: 0.560469, top_k: 0.788086, samples/s: 2238.027 1612394271.3242993
train: epoch 68, iter 200, loss: 2.862087, top_1: 0.558125, top_k: 0.791328, samples/s: 2241.446 1612394282.745413
train: epoch 68, iter 300, loss: 2.902519, top_1: 0.568125, top_k: 0.790859, samples/s: 2259.623 1612394294.0747714
train: epoch 68, iter 400, loss: 2.663169, top_1: 0.565312, top_k: 0.792188, samples/s: 2256.718 1612394305.4186568
train: epoch 68, iter 500, loss: 2.820661, top_1: 0.564609, top_k: 0.794414, samples/s: 2266.784 1612394316.7122192
train: epoch 68, iter 600, loss: 2.801392, top_1: 0.567344, top_k: 0.792070, samples/s: 2240.206 1612394328.139717
train: epoch 68, iter 700, loss: 2.959377, top_1: 0.559219, top_k: 0.787656, samples/s: 2235.189 1612394339.5929124
train: epoch 68, iter 800, loss: 2.870814, top_1: 0.558125, top_k: 0.786172, samples/s: 2225.280 1612394351.0970554
train: epoch 68, iter 900, loss: 2.621355, top_1: 0.564414, top_k: 0.791875, samples/s: 2237.045 1612394362.5407348
train: epoch 68, iter 1000, loss: 2.853070, top_1: 0.560625, top_k: 0.784922, samples/s: 2227.002 1612394374.0359962
train: epoch 68, iter 1100, loss: 2.961997, top_1: 0.557891, top_k: 0.786953, samples/s: 2226.001 1612394385.5364516
train: epoch 68, iter 1200, loss: 2.882346, top_1: 0.556602, top_k: 0.787656, samples/s: 2223.311 1612394397.050859
train: epoch 68, iter 1300, loss: 2.908185, top_1: 0.562109, top_k: 0.785664, samples/s: 2208.043 1612394408.6447773
train: epoch 68, iter 1400, loss: 2.706421, top_1: 0.560039, top_k: 0.787070, samples/s: 2207.765 1612394420.240217
train: epoch 68, iter 1500, loss: 2.909378, top_1: 0.560000, top_k: 0.786992, samples/s: 2234.314 1612394431.6978557
train: epoch 68, iter 1600, loss: 2.968268, top_1: 0.563203, top_k: 0.785195, samples/s: 2250.523 1612394443.0730984
train: epoch 68, iter 1700, loss: 2.703073, top_1: 0.559570, top_k: 0.786914, samples/s: 2242.217 1612394454.4903603
train: epoch 68, iter 1800, loss: 2.810383, top_1: 0.560195, top_k: 0.787031, samples/s: 2235.947 1612394465.9395707
train: epoch 68, iter 1900, loss: 2.803514, top_1: 0.555117, top_k: 0.788398, samples/s: 2211.296 1612394477.5165396
train: epoch 68, iter 2000, loss: 2.872663, top_1: 0.556992, top_k: 0.781484, samples/s: 2225.475 1612394489.0196476
train: epoch 68, iter 2100, loss: 2.911201, top_1: 0.554336, top_k: 0.784336, samples/s: 2235.488 1612394500.4713557
train: epoch 68, iter 2200, loss: 2.777575, top_1: 0.554883, top_k: 0.782891, samples/s: 2238.664 1612394511.906759
train: epoch 68, iter 2300, loss: 2.975065, top_1: 0.562969, top_k: 0.788438, samples/s: 2245.535 1612394523.3070798
train: epoch 68, iter 2400, loss: 2.853143, top_1: 0.551914, top_k: 0.782617, samples/s: 2232.669 1612394534.7732046
train: epoch 68, iter 2500, loss: 2.854708, top_1: 0.558828, top_k: 0.788164, samples/s: 2229.120 1612394546.2575226
train: epoch 68, iter 2600, loss: 3.028156, top_1: 0.563047, top_k: 0.789219, samples/s: 2236.430 1612394557.7044559
train: epoch 68, iter 2700, loss: 2.780506, top_1: 0.553516, top_k: 0.779883, samples/s: 2214.065 1612394569.2668433
train: epoch 68, iter 2800, loss: 2.812963, top_1: 0.560977, top_k: 0.787188, samples/s: 2235.338 1612394580.7192376
train: epoch 68, iter 2900, loss: 2.823331, top_1: 0.558516, top_k: 0.784258, samples/s: 2246.038 1612394592.117159
train: epoch 68, iter 3000, loss: 2.896372, top_1: 0.555781, top_k: 0.786797, samples/s: 2234.123 1612394603.5756662
train: epoch 68, iter 3100, loss: 3.028899, top_1: 0.554180, top_k: 0.780625, samples/s: 2231.165 1612394615.0495071
train: epoch 68, iter 3200, loss: 2.726395, top_1: 0.561953, top_k: 0.790156, samples/s: 2240.715 1612394626.474513
train: epoch 68, iter 3300, loss: 2.669638, top_1: 0.557305, top_k: 0.786406, samples/s: 2218.765 1612394638.012343
train: epoch 68, iter 3400, loss: 3.142860, top_1: 0.554297, top_k: 0.783203, samples/s: 2251.497 1612394649.3825972
train: epoch 68, iter 3500, loss: 2.765252, top_1: 0.558672, top_k: 0.784375, samples/s: 2212.916 1612394660.951057
train: epoch 68, iter 3600, loss: 2.712192, top_1: 0.558242, top_k: 0.784844, samples/s: 2232.317 1612394672.4189928
train: epoch 68, iter 3700, loss: 2.794751, top_1: 0.562305, top_k: 0.786211, samples/s: 2230.494 1612394683.8962352
train: epoch 68, iter 3800, loss: 2.662782, top_1: 0.559102, top_k: 0.786875, samples/s: 2252.541 1612394695.2612119
train: epoch 68, iter 3900, loss: 2.900391, top_1: 0.558086, top_k: 0.785234, samples/s: 2223.506 1612394706.7745097
train: epoch 68, iter 4000, loss: 2.841677, top_1: 0.555156, top_k: 0.782422, samples/s: 2258.368 1612394718.1101823
train: epoch 68, iter 4100, loss: 3.111158, top_1: 0.555937, top_k: 0.781328, samples/s: 2240.068 1612394729.5384562
train: epoch 68, iter 4200, loss: 2.741929, top_1: 0.553516, top_k: 0.782305, samples/s: 2243.284 1612394740.9502113
train: epoch 68, iter 4300, loss: 2.879109, top_1: 0.553008, top_k: 0.785234, samples/s: 2219.210 1612394752.4858327
train: epoch 68, iter 4400, loss: 2.993318, top_1: 0.549727, top_k: 0.778438, samples/s: 2226.569 1612394763.9833488
train: epoch 68, iter 4500, loss: 2.784606, top_1: 0.560547, top_k: 0.785195, samples/s: 2208.383 1612394775.575534
train: epoch 68, iter 4600, loss: 2.976630, top_1: 0.556914, top_k: 0.780742, samples/s: 2236.057 1612394787.024266
train: epoch 68, iter 4700, loss: 2.845721, top_1: 0.559414, top_k: 0.783867, samples/s: 2236.725 1612394798.469571
train: epoch 68, iter 4800, loss: 2.790288, top_1: 0.555547, top_k: 0.780469, samples/s: 2200.177 1612394810.1050668
train: epoch 68, iter 4900, loss: 2.768268, top_1: 0.554766, top_k: 0.781211, samples/s: 2264.215 1612394821.4113717
train: epoch 68, iter 5000, loss: 2.897366, top_1: 0.563203, top_k: 0.786133, samples/s: 2227.915 1612394832.9019463
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_68.
validation: epoch 68, iter 195, top_1: 0.604327, top_k: 0.835877, samples/s: 2933.086 1612394850.2395618
train: epoch 69, iter 100, loss: 2.791150, top_1: 0.573984, top_k: 0.796484, samples/s: 2240.358 1612394877.2563896
train: epoch 69, iter 200, loss: 2.806533, top_1: 0.573516, top_k: 0.797266, samples/s: 2253.245 1612394888.6181962
train: epoch 69, iter 300, loss: 2.792166, top_1: 0.562305, top_k: 0.788594, samples/s: 2246.551 1612394900.0130222
train: epoch 69, iter 400, loss: 2.927949, top_1: 0.560586, top_k: 0.791289, samples/s: 2252.678 1612394911.377624
train: epoch 69, iter 500, loss: 2.791573, top_1: 0.564141, top_k: 0.788984, samples/s: 2248.101 1612394922.7646642
train: epoch 69, iter 600, loss: 2.851729, top_1: 0.564961, top_k: 0.791914, samples/s: 2254.341 1612394934.1205335
train: epoch 69, iter 700, loss: 2.804741, top_1: 0.558125, top_k: 0.790117, samples/s: 2241.083 1612394945.5435712
train: epoch 69, iter 800, loss: 2.669527, top_1: 0.560117, top_k: 0.787109, samples/s: 2236.044 1612394956.992361
train: epoch 69, iter 900, loss: 2.790401, top_1: 0.554766, top_k: 0.785508, samples/s: 2246.011 1612394968.3903449
train: epoch 69, iter 1000, loss: 2.859271, top_1: 0.560039, top_k: 0.786758, samples/s: 2209.058 1612394979.9790018
train: epoch 69, iter 1100, loss: 2.774187, top_1: 0.557461, top_k: 0.784375, samples/s: 2207.561 1612394991.5755053
train: epoch 69, iter 1200, loss: 2.866743, top_1: 0.560000, top_k: 0.785977, samples/s: 2217.125 1612395003.1219878
train: epoch 69, iter 1300, loss: 2.726542, top_1: 0.564258, top_k: 0.787813, samples/s: 2211.329 1612395014.6988318
train: epoch 69, iter 1400, loss: 2.812470, top_1: 0.558438, top_k: 0.784102, samples/s: 2231.006 1612395026.173434
train: epoch 69, iter 1500, loss: 2.799074, top_1: 0.560117, top_k: 0.789258, samples/s: 2216.285 1612395037.724367
train: epoch 69, iter 1600, loss: 2.926223, top_1: 0.557773, top_k: 0.784687, samples/s: 2226.922 1612395049.219977
train: epoch 69, iter 1700, loss: 3.036904, top_1: 0.564453, top_k: 0.791133, samples/s: 2233.651 1612395060.680976
train: epoch 69, iter 1800, loss: 2.838949, top_1: 0.559414, top_k: 0.785820, samples/s: 2215.245 1612395072.2373693
train: epoch 69, iter 1900, loss: 2.864823, top_1: 0.554531, top_k: 0.784297, samples/s: 2255.952 1612395083.5850377
train: epoch 69, iter 2000, loss: 2.853298, top_1: 0.560859, top_k: 0.787852, samples/s: 2222.140 1612395095.1054578
train: epoch 69, iter 2100, loss: 2.697619, top_1: 0.555703, top_k: 0.784727, samples/s: 2217.558 1612395106.6497731
train: epoch 69, iter 2200, loss: 2.905531, top_1: 0.555820, top_k: 0.785625, samples/s: 2229.808 1612395118.1305296
train: epoch 69, iter 2300, loss: 2.803722, top_1: 0.558945, top_k: 0.783906, samples/s: 2230.385 1612395129.6086524
train: epoch 69, iter 2400, loss: 3.016834, top_1: 0.559336, top_k: 0.787813, samples/s: 2226.987 1612395141.103752
train: epoch 69, iter 2500, loss: 2.736892, top_1: 0.560781, top_k: 0.784961, samples/s: 2231.783 1612395152.5745482
train: epoch 69, iter 2600, loss: 2.725403, top_1: 0.564453, top_k: 0.790898, samples/s: 2242.271 1612395163.9915347
train: epoch 69, iter 2700, loss: 2.806448, top_1: 0.559453, top_k: 0.788438, samples/s: 2219.277 1612395175.5266175
train: epoch 69, iter 2800, loss: 2.989503, top_1: 0.556836, top_k: 0.782344, samples/s: 2228.977 1612395187.0117083
train: epoch 69, iter 2900, loss: 2.963043, top_1: 0.556797, top_k: 0.787070, samples/s: 2217.410 1612395198.5567572
train: epoch 69, iter 3000, loss: 2.936015, top_1: 0.554141, top_k: 0.785859, samples/s: 2231.592 1612395210.028382
train: epoch 69, iter 3100, loss: 3.028519, top_1: 0.558164, top_k: 0.783867, samples/s: 2242.924 1612395221.4420667
train: epoch 69, iter 3200, loss: 2.889816, top_1: 0.556797, top_k: 0.782422, samples/s: 2201.731 1612395233.0693536
train: epoch 69, iter 3300, loss: 2.970325, top_1: 0.551523, top_k: 0.781328, samples/s: 2259.135 1612395244.4010088
train: epoch 69, iter 3400, loss: 2.849053, top_1: 0.557813, top_k: 0.785742, samples/s: 2239.566 1612395255.8317955
train: epoch 69, iter 3500, loss: 2.798888, top_1: 0.560312, top_k: 0.787422, samples/s: 2242.134 1612395267.2495525
train: epoch 69, iter 3600, loss: 3.041236, top_1: 0.557930, top_k: 0.789023, samples/s: 2235.138 1612395278.7028933
train: epoch 69, iter 3700, loss: 2.929005, top_1: 0.551992, top_k: 0.781406, samples/s: 2232.173 1612395290.171596
train: epoch 69, iter 3800, loss: 2.716352, top_1: 0.564258, top_k: 0.787148, samples/s: 2222.768 1612395301.6886714
train: epoch 69, iter 3900, loss: 2.961668, top_1: 0.557344, top_k: 0.782305, samples/s: 2244.226 1612395313.0958035
train: epoch 69, iter 4000, loss: 2.892009, top_1: 0.559336, top_k: 0.786953, samples/s: 2242.846 1612395324.5098455
train: epoch 69, iter 4100, loss: 2.954324, top_1: 0.562500, top_k: 0.786445, samples/s: 2201.848 1612395336.1364427
train: epoch 69, iter 4200, loss: 2.595056, top_1: 0.555234, top_k: 0.783555, samples/s: 2240.687 1612395347.5615103
train: epoch 69, iter 4300, loss: 2.757303, top_1: 0.562773, top_k: 0.784531, samples/s: 2217.434 1612395359.10648
train: epoch 69, iter 4400, loss: 2.926118, top_1: 0.559844, top_k: 0.781172, samples/s: 2235.212 1612395370.559551
train: epoch 69, iter 4500, loss: 2.893529, top_1: 0.557930, top_k: 0.786836, samples/s: 2225.877 1612395382.0605512
train: epoch 69, iter 4600, loss: 2.900642, top_1: 0.554375, top_k: 0.783984, samples/s: 2237.229 1612395393.5032468
train: epoch 69, iter 4700, loss: 2.612129, top_1: 0.556758, top_k: 0.780703, samples/s: 2232.603 1612395404.9698002
train: epoch 69, iter 4800, loss: 3.039437, top_1: 0.550508, top_k: 0.779062, samples/s: 2247.914 1612395416.3580163
train: epoch 69, iter 4900, loss: 2.786157, top_1: 0.557891, top_k: 0.783125, samples/s: 2233.542 1612395427.8196268
train: epoch 69, iter 5000, loss: 2.834744, top_1: 0.557578, top_k: 0.788516, samples/s: 2236.992 1612395439.263572
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_69.
validation: epoch 69, iter 195, top_1: 0.603425, top_k: 0.835677, samples/s: 2893.561 1612395456.8731253
train: epoch 70, iter 100, loss: 3.021826, top_1: 0.568242, top_k: 0.797695, samples/s: 2250.805 1612395483.9918249
train: epoch 70, iter 200, loss: 2.772319, top_1: 0.566523, top_k: 0.791250, samples/s: 2244.886 1612395495.3954976
train: epoch 70, iter 300, loss: 2.865330, top_1: 0.572500, top_k: 0.795937, samples/s: 2255.895 1612395506.7436182
train: epoch 70, iter 400, loss: 2.868471, top_1: 0.566992, top_k: 0.793906, samples/s: 2264.009 1612395518.0509398
train: epoch 70, iter 500, loss: 2.770757, top_1: 0.560547, top_k: 0.788125, samples/s: 2251.777 1612395529.4197392
train: epoch 70, iter 600, loss: 2.713601, top_1: 0.568633, top_k: 0.789453, samples/s: 2238.432 1612395540.8563128
train: epoch 70, iter 700, loss: 2.648733, top_1: 0.565312, top_k: 0.790195, samples/s: 2259.551 1612395552.1860702
train: epoch 70, iter 800, loss: 2.731098, top_1: 0.566406, top_k: 0.790352, samples/s: 2215.600 1612395563.7405062
train: epoch 70, iter 900, loss: 2.826777, top_1: 0.558906, top_k: 0.787656, samples/s: 2227.086 1612395575.2352738
train: epoch 70, iter 1000, loss: 2.962682, top_1: 0.564102, top_k: 0.791562, samples/s: 2227.520 1612395586.7278717
train: epoch 70, iter 1100, loss: 2.978720, top_1: 0.566328, top_k: 0.793750, samples/s: 2215.710 1612395598.281774
train: epoch 70, iter 1200, loss: 2.846364, top_1: 0.566758, top_k: 0.790703, samples/s: 2215.172 1612395609.8385324
train: epoch 70, iter 1300, loss: 3.017807, top_1: 0.565156, top_k: 0.791328, samples/s: 2229.798 1612395621.3192482
train: epoch 70, iter 1400, loss: 2.780431, top_1: 0.559141, top_k: 0.788320, samples/s: 2228.030 1612395632.8092272
train: epoch 70, iter 1500, loss: 2.711144, top_1: 0.556875, top_k: 0.786602, samples/s: 2212.216 1612395644.3813345
train: epoch 70, iter 1600, loss: 2.951889, top_1: 0.557539, top_k: 0.782734, samples/s: 2237.857 1612395655.820844
train: epoch 70, iter 1700, loss: 2.779050, top_1: 0.563828, top_k: 0.794219, samples/s: 2228.670 1612395667.3075252
train: epoch 70, iter 1800, loss: 2.932358, top_1: 0.565156, top_k: 0.791797, samples/s: 2203.107 1612395678.9275143
train: epoch 70, iter 1900, loss: 3.071287, top_1: 0.553438, top_k: 0.784180, samples/s: 2245.620 1612395690.3274992
train: epoch 70, iter 2000, loss: 2.947132, top_1: 0.559922, top_k: 0.784453, samples/s: 2226.011 1612395701.828004
train: epoch 70, iter 2100, loss: 2.794718, top_1: 0.562031, top_k: 0.787539, samples/s: 2252.707 1612395713.1920056
train: epoch 70, iter 2200, loss: 2.697313, top_1: 0.561211, top_k: 0.788555, samples/s: 2224.007 1612395724.702698
train: epoch 70, iter 2300, loss: 2.870544, top_1: 0.565430, top_k: 0.788984, samples/s: 2172.291 1612395736.4875343
train: epoch 70, iter 2400, loss: 2.954481, top_1: 0.563242, top_k: 0.787109, samples/s: 2268.799 1612395747.7709885
train: epoch 70, iter 2500, loss: 2.676211, top_1: 0.560273, top_k: 0.787813, samples/s: 2172.069 1612395759.557016
train: epoch 70, iter 2600, loss: 2.807448, top_1: 0.568086, top_k: 0.790469, samples/s: 2235.628 1612395771.0079834
train: epoch 70, iter 2700, loss: 2.962914, top_1: 0.557617, top_k: 0.786953, samples/s: 2226.413 1612395782.5064619
train: epoch 70, iter 2800, loss: 2.829501, top_1: 0.563398, top_k: 0.788125, samples/s: 2247.849 1612395793.894877
train: epoch 70, iter 2900, loss: 2.598915, top_1: 0.555234, top_k: 0.783516, samples/s: 2226.706 1612395805.391755
train: epoch 70, iter 3000, loss: 2.822639, top_1: 0.552539, top_k: 0.781484, samples/s: 2235.331 1612395816.8441794
train: epoch 70, iter 3100, loss: 2.797166, top_1: 0.559922, top_k: 0.789805, samples/s: 2214.186 1612395828.4059541
train: epoch 70, iter 3200, loss: 3.068098, top_1: 0.555859, top_k: 0.785078, samples/s: 2244.546 1612395839.8114297
train: epoch 70, iter 3300, loss: 2.805650, top_1: 0.559453, top_k: 0.784766, samples/s: 2220.123 1612395851.3422713
train: epoch 70, iter 3400, loss: 2.754366, top_1: 0.556250, top_k: 0.782148, samples/s: 2237.260 1612395862.7848282
train: epoch 70, iter 3500, loss: 2.819514, top_1: 0.551211, top_k: 0.787109, samples/s: 2224.756 1612395874.29171
train: epoch 70, iter 3600, loss: 2.902542, top_1: 0.558672, top_k: 0.789844, samples/s: 2252.963 1612395885.6545925
train: epoch 70, iter 3700, loss: 2.850467, top_1: 0.556523, top_k: 0.785977, samples/s: 2234.772 1612395897.10989
train: epoch 70, iter 3800, loss: 2.818343, top_1: 0.556055, top_k: 0.783359, samples/s: 2213.299 1612395908.6762788
train: epoch 70, iter 3900, loss: 2.693388, top_1: 0.557344, top_k: 0.787148, samples/s: 2248.732 1612395920.0604692
train: epoch 70, iter 4000, loss: 2.851453, top_1: 0.561680, top_k: 0.787695, samples/s: 2207.325 1612395931.6583338
train: epoch 70, iter 4100, loss: 2.794822, top_1: 0.561641, top_k: 0.787539, samples/s: 2247.458 1612395943.0488632
train: epoch 70, iter 4200, loss: 2.882714, top_1: 0.557852, top_k: 0.784766, samples/s: 2235.531 1612395954.500324
train: epoch 70, iter 4300, loss: 3.040296, top_1: 0.557109, top_k: 0.785039, samples/s: 2224.733 1612395966.0073056
train: epoch 70, iter 4400, loss: 2.779305, top_1: 0.551875, top_k: 0.781367, samples/s: 2220.093 1612395977.5384352
train: epoch 70, iter 4500, loss: 2.924988, top_1: 0.557734, top_k: 0.785977, samples/s: 2248.816 1612395988.922227
train: epoch 70, iter 4600, loss: 2.823958, top_1: 0.561172, top_k: 0.788242, samples/s: 2231.368 1612396000.3948748
train: epoch 70, iter 4700, loss: 2.742872, top_1: 0.554922, top_k: 0.782852, samples/s: 2235.604 1612396011.845957
train: epoch 70, iter 4800, loss: 2.865482, top_1: 0.555977, top_k: 0.787344, samples/s: 2246.167 1612396023.243118
train: epoch 70, iter 4900, loss: 2.876007, top_1: 0.558672, top_k: 0.785391, samples/s: 2229.505 1612396034.7254822
train: epoch 70, iter 5000, loss: 2.926901, top_1: 0.562852, top_k: 0.786328, samples/s: 2249.154 1612396046.1075375
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_70.
validation: epoch 70, iter 195, top_1: 0.596775, top_k: 0.829627, samples/s: 2810.983 1612396064.2021313
train: epoch 71, iter 100, loss: 2.748561, top_1: 0.572852, top_k: 0.797695, samples/s: 2246.656 1612396091.3183167
train: epoch 71, iter 200, loss: 2.582959, top_1: 0.564922, top_k: 0.792852, samples/s: 2246.548 1612396102.7135584
train: epoch 71, iter 300, loss: 2.937684, top_1: 0.566875, top_k: 0.792734, samples/s: 2256.849 1612396114.0568
train: epoch 71, iter 400, loss: 3.038144, top_1: 0.569531, top_k: 0.799180, samples/s: 2239.817 1612396125.4863508
train: epoch 71, iter 500, loss: 2.731279, top_1: 0.569023, top_k: 0.795781, samples/s: 2267.726 1612396136.775119
train: epoch 71, iter 600, loss: 2.791041, top_1: 0.566836, top_k: 0.786367, samples/s: 2265.237 1612396148.0763474
train: epoch 71, iter 700, loss: 2.643777, top_1: 0.566719, top_k: 0.792500, samples/s: 2227.309 1612396159.5701013
train: epoch 71, iter 800, loss: 2.683144, top_1: 0.565352, top_k: 0.790625, samples/s: 2226.637 1612396171.067265
train: epoch 71, iter 900, loss: 2.778438, top_1: 0.566484, top_k: 0.791406, samples/s: 2239.800 1612396182.4968266
train: epoch 71, iter 1000, loss: 2.706543, top_1: 0.562266, top_k: 0.791055, samples/s: 2226.670 1612396193.993781
train: epoch 71, iter 1100, loss: 2.729108, top_1: 0.567305, top_k: 0.793984, samples/s: 2233.484 1612396205.4556866
train: epoch 71, iter 1200, loss: 2.800620, top_1: 0.571016, top_k: 0.793828, samples/s: 2236.724 1612396216.900997
train: epoch 71, iter 1300, loss: 2.834535, top_1: 0.566680, top_k: 0.789805, samples/s: 2236.120 1612396228.3494005
train: epoch 71, iter 1400, loss: 2.793720, top_1: 0.564766, top_k: 0.792969, samples/s: 2239.082 1612396239.7827272
train: epoch 71, iter 1500, loss: 2.777441, top_1: 0.562344, top_k: 0.788125, samples/s: 2228.396 1612396251.2707481
train: epoch 71, iter 1600, loss: 2.884197, top_1: 0.557891, top_k: 0.786758, samples/s: 2198.181 1612396262.9167366
train: epoch 71, iter 1700, loss: 2.678155, top_1: 0.566211, top_k: 0.789922, samples/s: 2259.971 1612396274.2443419
train: epoch 71, iter 1800, loss: 2.778552, top_1: 0.564883, top_k: 0.796289, samples/s: 2221.204 1612396285.7696555
train: epoch 71, iter 1900, loss: 2.829928, top_1: 0.562031, top_k: 0.791328, samples/s: 2228.633 1612396297.2564547
train: epoch 71, iter 2000, loss: 2.800434, top_1: 0.560156, top_k: 0.788398, samples/s: 2219.158 1612396308.7923841
train: epoch 71, iter 2100, loss: 2.857803, top_1: 0.563633, top_k: 0.786172, samples/s: 2222.592 1612396320.310455
train: epoch 71, iter 2200, loss: 2.926358, top_1: 0.561328, top_k: 0.790625, samples/s: 2208.371 1612396331.9027143
train: epoch 71, iter 2300, loss: 2.743290, top_1: 0.568867, top_k: 0.791016, samples/s: 2219.085 1612396343.4389994
train: epoch 71, iter 2400, loss: 2.696664, top_1: 0.559883, top_k: 0.785391, samples/s: 2240.064 1612396354.8672483
train: epoch 71, iter 2500, loss: 2.719715, top_1: 0.562031, top_k: 0.786836, samples/s: 2233.029 1612396366.331542
train: epoch 71, iter 2600, loss: 2.743829, top_1: 0.560586, top_k: 0.790508, samples/s: 2198.657 1612396377.9749591
train: epoch 71, iter 2700, loss: 3.074721, top_1: 0.558867, top_k: 0.788047, samples/s: 2247.505 1612396389.3653822
train: epoch 71, iter 2800, loss: 2.815871, top_1: 0.562773, top_k: 0.788828, samples/s: 2231.947 1612396400.83518
train: epoch 71, iter 2900, loss: 2.995489, top_1: 0.559648, top_k: 0.789414, samples/s: 2241.317 1612396412.2570653
train: epoch 71, iter 3000, loss: 2.996416, top_1: 0.563594, top_k: 0.788359, samples/s: 2234.028 1612396423.7162178
train: epoch 71, iter 3100, loss: 2.817873, top_1: 0.561016, top_k: 0.786016, samples/s: 2215.960 1612396435.268768
train: epoch 71, iter 3200, loss: 2.654178, top_1: 0.559609, top_k: 0.785234, samples/s: 2240.877 1612396446.6929133
train: epoch 71, iter 3300, loss: 2.904290, top_1: 0.556875, top_k: 0.785430, samples/s: 2243.125 1612396458.1054573
train: epoch 71, iter 3400, loss: 2.901400, top_1: 0.556211, top_k: 0.783828, samples/s: 2223.821 1612396469.6171844
train: epoch 71, iter 3500, loss: 2.932149, top_1: 0.559297, top_k: 0.783477, samples/s: 2247.364 1612396481.0083103
train: epoch 71, iter 3600, loss: 2.951152, top_1: 0.560156, top_k: 0.785820, samples/s: 2239.125 1612396492.4413471
train: epoch 71, iter 3700, loss: 2.747178, top_1: 0.559219, top_k: 0.788945, samples/s: 2229.470 1612396503.9239385
train: epoch 71, iter 3800, loss: 2.736206, top_1: 0.558164, top_k: 0.787383, samples/s: 2238.989 1612396515.3576548
train: epoch 71, iter 3900, loss: 3.076687, top_1: 0.562773, top_k: 0.786836, samples/s: 2245.457 1612396526.7584145
train: epoch 71, iter 4000, loss: 2.768157, top_1: 0.563164, top_k: 0.790156, samples/s: 2235.574 1612396538.2096088
train: epoch 71, iter 4100, loss: 2.837451, top_1: 0.561914, top_k: 0.791016, samples/s: 2238.237 1612396549.6472073
train: epoch 71, iter 4200, loss: 2.737002, top_1: 0.557578, top_k: 0.785195, samples/s: 2241.966 1612396561.0657752
train: epoch 71, iter 4300, loss: 2.879096, top_1: 0.562500, top_k: 0.788242, samples/s: 2242.419 1612396572.4819849
train: epoch 71, iter 4400, loss: 2.695811, top_1: 0.557383, top_k: 0.785430, samples/s: 2231.365 1612396583.9547753
train: epoch 71, iter 4500, loss: 2.822605, top_1: 0.558242, top_k: 0.785937, samples/s: 2218.264 1612396595.495334
train: epoch 71, iter 4600, loss: 2.659062, top_1: 0.560781, top_k: 0.786328, samples/s: 2250.065 1612396606.8727732
train: epoch 71, iter 4700, loss: 2.795038, top_1: 0.559492, top_k: 0.786055, samples/s: 2232.868 1612396618.3378322
train: epoch 71, iter 4800, loss: 2.954130, top_1: 0.562148, top_k: 0.784492, samples/s: 2250.682 1612396629.7121933
train: epoch 71, iter 4900, loss: 2.815927, top_1: 0.559102, top_k: 0.783477, samples/s: 2210.092 1612396641.2954605
train: epoch 71, iter 5000, loss: 2.720263, top_1: 0.561367, top_k: 0.785781, samples/s: 2230.442 1612396652.7730489
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_71.
validation: epoch 71, iter 195, top_1: 0.601643, top_k: 0.833794, samples/s: 2908.536 1612396670.309313
train: epoch 72, iter 100, loss: 2.840535, top_1: 0.565312, top_k: 0.790352, samples/s: 2251.287 1612396697.0586526
train: epoch 72, iter 200, loss: 2.681641, top_1: 0.572227, top_k: 0.796523, samples/s: 2241.202 1612396708.4810894
train: epoch 72, iter 300, loss: 2.841782, top_1: 0.571914, top_k: 0.797500, samples/s: 2249.350 1612396719.8622334
train: epoch 72, iter 400, loss: 2.830191, top_1: 0.568672, top_k: 0.791992, samples/s: 2257.587 1612396731.2017126
train: epoch 72, iter 500, loss: 2.853597, top_1: 0.562969, top_k: 0.789023, samples/s: 2250.858 1612396742.5751843
train: epoch 72, iter 600, loss: 2.723050, top_1: 0.572422, top_k: 0.794687, samples/s: 2263.709 1612396753.8840206
train: epoch 72, iter 700, loss: 2.650033, top_1: 0.569453, top_k: 0.792266, samples/s: 2253.594 1612396765.24372
train: epoch 72, iter 800, loss: 2.611057, top_1: 0.565273, top_k: 0.791680, samples/s: 2209.431 1612396776.83044
train: epoch 72, iter 900, loss: 2.883902, top_1: 0.566953, top_k: 0.791016, samples/s: 2229.529 1612396788.3125875
train: epoch 72, iter 1000, loss: 2.802601, top_1: 0.568164, top_k: 0.790156, samples/s: 2215.353 1612396799.868349
train: epoch 72, iter 1100, loss: 2.738628, top_1: 0.562617, top_k: 0.791445, samples/s: 2224.466 1612396811.3766901
train: epoch 72, iter 1200, loss: 2.803922, top_1: 0.566172, top_k: 0.790273, samples/s: 2226.923 1612396822.8724241
train: epoch 72, iter 1300, loss: 2.867308, top_1: 0.569414, top_k: 0.794961, samples/s: 2206.872 1612396834.4725301
train: epoch 72, iter 1400, loss: 2.759565, top_1: 0.569023, top_k: 0.791719, samples/s: 2212.236 1612396846.0444992
train: epoch 72, iter 1500, loss: 2.878626, top_1: 0.565586, top_k: 0.788945, samples/s: 2224.951 1612396857.5503795
train: epoch 72, iter 1600, loss: 2.776309, top_1: 0.571602, top_k: 0.797578, samples/s: 2241.032 1612396868.9740534
train: epoch 72, iter 1700, loss: 2.747264, top_1: 0.563203, top_k: 0.790078, samples/s: 2207.853 1612396880.5686665
train: epoch 72, iter 1800, loss: 3.140114, top_1: 0.565117, top_k: 0.792148, samples/s: 2226.784 1612396892.0650597
train: epoch 72, iter 1900, loss: 2.784242, top_1: 0.561133, top_k: 0.790469, samples/s: 2249.805 1612396903.443876
train: epoch 72, iter 2000, loss: 2.765004, top_1: 0.565898, top_k: 0.791133, samples/s: 2228.410 1612396914.9318323
train: epoch 72, iter 2100, loss: 3.040478, top_1: 0.561406, top_k: 0.786016, samples/s: 2213.118 1612396926.4992223
train: epoch 72, iter 2200, loss: 2.827239, top_1: 0.567734, top_k: 0.789141, samples/s: 2218.237 1612396938.039947
train: epoch 72, iter 2300, loss: 2.907195, top_1: 0.564297, top_k: 0.792461, samples/s: 2224.556 1612396949.5478418
train: epoch 72, iter 2400, loss: 2.933024, top_1: 0.563555, top_k: 0.788438, samples/s: 2219.705 1612396961.0813107
train: epoch 72, iter 2500, loss: 2.729395, top_1: 0.560586, top_k: 0.789336, samples/s: 2231.224 1612396972.5544295
train: epoch 72, iter 2600, loss: 3.113043, top_1: 0.560703, top_k: 0.785469, samples/s: 2229.331 1612396984.037696
train: epoch 72, iter 2700, loss: 2.996250, top_1: 0.566016, top_k: 0.790078, samples/s: 2219.331 1612396995.5726936
train: epoch 72, iter 2800, loss: 2.739745, top_1: 0.566953, top_k: 0.791758, samples/s: 2243.348 1612397006.9842272
train: epoch 72, iter 2900, loss: 2.706806, top_1: 0.565273, top_k: 0.788750, samples/s: 2233.813 1612397018.4444425
train: epoch 72, iter 3000, loss: 2.892324, top_1: 0.566445, top_k: 0.794883, samples/s: 2228.446 1612397029.9322734
train: epoch 72, iter 3100, loss: 2.862553, top_1: 0.558477, top_k: 0.786992, samples/s: 2225.898 1612397041.433288
train: epoch 72, iter 3200, loss: 2.904109, top_1: 0.560547, top_k: 0.784219, samples/s: 2227.815 1612397052.924355
train: epoch 72, iter 3300, loss: 2.938097, top_1: 0.564023, top_k: 0.789102, samples/s: 2245.255 1612397064.326141
train: epoch 72, iter 3400, loss: 2.867046, top_1: 0.559453, top_k: 0.784023, samples/s: 2234.608 1612397075.7823849
train: epoch 72, iter 3500, loss: 2.968899, top_1: 0.560000, top_k: 0.784727, samples/s: 2226.677 1612397087.279278
train: epoch 72, iter 3600, loss: 2.822798, top_1: 0.562930, top_k: 0.789023, samples/s: 2233.218 1612397098.7424886
train: epoch 72, iter 3700, loss: 2.855492, top_1: 0.566445, top_k: 0.793203, samples/s: 2241.810 1612397110.1618624
train: epoch 72, iter 3800, loss: 2.841988, top_1: 0.563711, top_k: 0.794023, samples/s: 2239.489 1612397121.5931134
train: epoch 72, iter 3900, loss: 2.588987, top_1: 0.561367, top_k: 0.791797, samples/s: 2236.246 1612397133.0408125
train: epoch 72, iter 4000, loss: 2.957755, top_1: 0.563438, top_k: 0.788984, samples/s: 2219.391 1612397144.5754983
train: epoch 72, iter 4100, loss: 2.678697, top_1: 0.557734, top_k: 0.785391, samples/s: 2228.150 1612397156.06486
train: epoch 72, iter 4200, loss: 2.996122, top_1: 0.566719, top_k: 0.790312, samples/s: 2219.892 1612397167.5969615
train: epoch 72, iter 4300, loss: 2.723074, top_1: 0.564297, top_k: 0.788164, samples/s: 2237.221 1612397179.039707
train: epoch 72, iter 4400, loss: 2.762257, top_1: 0.567148, top_k: 0.793828, samples/s: 2255.914 1612397190.387672
train: epoch 72, iter 4500, loss: 2.668968, top_1: 0.563750, top_k: 0.787188, samples/s: 2212.556 1612397201.958094
train: epoch 72, iter 4600, loss: 2.824316, top_1: 0.559297, top_k: 0.786719, samples/s: 2260.575 1612397213.2825577
train: epoch 72, iter 4700, loss: 2.672987, top_1: 0.558867, top_k: 0.786211, samples/s: 2238.704 1612397224.7177253
train: epoch 72, iter 4800, loss: 2.794120, top_1: 0.557109, top_k: 0.787500, samples/s: 2220.681 1612397236.245754
train: epoch 72, iter 4900, loss: 2.777656, top_1: 0.557148, top_k: 0.782266, samples/s: 2248.452 1612397247.6313837
train: epoch 72, iter 5000, loss: 2.858639, top_1: 0.568086, top_k: 0.796445, samples/s: 2223.857 1612397259.1429305
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_72.
validation: epoch 72, iter 195, top_1: 0.604768, top_k: 0.834515, samples/s: 2944.079 1612397276.4643526
train: epoch 73, iter 100, loss: 2.658515, top_1: 0.575937, top_k: 0.800195, samples/s: 2219.348 1612397303.6736524
train: epoch 73, iter 200, loss: 2.901339, top_1: 0.566914, top_k: 0.794023, samples/s: 2256.252 1612397315.0199256
train: epoch 73, iter 300, loss: 2.852990, top_1: 0.573828, top_k: 0.796523, samples/s: 2252.375 1612397326.3857229
train: epoch 73, iter 400, loss: 2.916905, top_1: 0.564961, top_k: 0.791680, samples/s: 2247.060 1612397337.778368
train: epoch 73, iter 500, loss: 2.831986, top_1: 0.572461, top_k: 0.796680, samples/s: 2241.590 1612397349.1988814
train: epoch 73, iter 600, loss: 2.841505, top_1: 0.571250, top_k: 0.796523, samples/s: 2250.697 1612397360.5730684
train: epoch 73, iter 700, loss: 2.885827, top_1: 0.573867, top_k: 0.795781, samples/s: 2248.776 1612397371.957058
train: epoch 73, iter 800, loss: 2.769463, top_1: 0.568398, top_k: 0.795703, samples/s: 2238.696 1612397383.3922777
train: epoch 73, iter 900, loss: 2.772866, top_1: 0.573516, top_k: 0.799180, samples/s: 2230.316 1612397394.8704712
train: epoch 73, iter 1000, loss: 2.578057, top_1: 0.562734, top_k: 0.788906, samples/s: 2228.689 1612397406.357118
train: epoch 73, iter 1100, loss: 2.909345, top_1: 0.565352, top_k: 0.793633, samples/s: 2217.511 1612397417.901503
train: epoch 73, iter 1200, loss: 2.650682, top_1: 0.567461, top_k: 0.793867, samples/s: 2214.968 1612397429.4594624
train: epoch 73, iter 1300, loss: 3.003744, top_1: 0.570430, top_k: 0.793906, samples/s: 2213.861 1612397441.0227942
train: epoch 73, iter 1400, loss: 2.623277, top_1: 0.568750, top_k: 0.793008, samples/s: 2222.638 1612397452.5406098
train: epoch 73, iter 1500, loss: 2.806862, top_1: 0.567461, top_k: 0.791484, samples/s: 2233.599 1612397464.0019512
train: epoch 73, iter 1600, loss: 2.954055, top_1: 0.567930, top_k: 0.791719, samples/s: 2228.143 1612397475.491385
train: epoch 73, iter 1700, loss: 2.923251, top_1: 0.566133, top_k: 0.795703, samples/s: 2211.675 1612397487.0662518
train: epoch 73, iter 1800, loss: 2.711805, top_1: 0.566211, top_k: 0.789609, samples/s: 2190.742 1612397498.751787
train: epoch 73, iter 1900, loss: 2.800516, top_1: 0.565156, top_k: 0.790547, samples/s: 2213.461 1612397510.3173814
train: epoch 73, iter 2000, loss: 2.840066, top_1: 0.567539, top_k: 0.792266, samples/s: 2262.166 1612397521.6339796
train: epoch 73, iter 2100, loss: 2.833333, top_1: 0.564336, top_k: 0.792891, samples/s: 2216.896 1612397533.181597
train: epoch 73, iter 2200, loss: 2.945099, top_1: 0.566133, top_k: 0.789961, samples/s: 2228.594 1612397544.6688185
train: epoch 73, iter 2300, loss: 2.733984, top_1: 0.570312, top_k: 0.796992, samples/s: 2229.583 1612397556.1506906
train: epoch 73, iter 2400, loss: 2.875909, top_1: 0.567148, top_k: 0.791797, samples/s: 2247.385 1612397567.541694
train: epoch 73, iter 2500, loss: 2.814666, top_1: 0.559453, top_k: 0.788984, samples/s: 2212.286 1612397579.1134357
train: epoch 73, iter 2600, loss: 2.882325, top_1: 0.567969, top_k: 0.792266, samples/s: 2241.213 1612397590.5358872
train: epoch 73, iter 2700, loss: 2.790846, top_1: 0.562031, top_k: 0.792070, samples/s: 2222.130 1612397602.0562992
train: epoch 73, iter 2800, loss: 2.801837, top_1: 0.565156, top_k: 0.791250, samples/s: 2218.710 1612397613.594577
train: epoch 73, iter 2900, loss: 2.770175, top_1: 0.560664, top_k: 0.786641, samples/s: 2229.574 1612397625.0765052
train: epoch 73, iter 3000, loss: 2.700164, top_1: 0.564492, top_k: 0.792422, samples/s: 2220.675 1612397636.6045778
train: epoch 73, iter 3100, loss: 2.666550, top_1: 0.565000, top_k: 0.791328, samples/s: 2243.297 1612397648.0164044
train: epoch 73, iter 3200, loss: 2.971380, top_1: 0.560000, top_k: 0.788125, samples/s: 2219.561 1612397659.5501647
train: epoch 73, iter 3300, loss: 2.879742, top_1: 0.560195, top_k: 0.786328, samples/s: 2234.013 1612397671.0093675
train: epoch 73, iter 3400, loss: 2.675472, top_1: 0.567344, top_k: 0.791172, samples/s: 2222.490 1612397682.5279777
train: epoch 73, iter 3500, loss: 2.872601, top_1: 0.561367, top_k: 0.789961, samples/s: 2247.123 1612397693.9203339
train: epoch 73, iter 3600, loss: 2.845849, top_1: 0.568945, top_k: 0.789180, samples/s: 2242.935 1612397705.3339906
train: epoch 73, iter 3700, loss: 2.672369, top_1: 0.565703, top_k: 0.793359, samples/s: 2220.780 1612397716.861426
train: epoch 73, iter 3800, loss: 2.857103, top_1: 0.563594, top_k: 0.789766, samples/s: 2243.571 1612397728.27183
train: epoch 73, iter 3900, loss: 3.020721, top_1: 0.561602, top_k: 0.789609, samples/s: 2239.824 1612397739.7012775
train: epoch 73, iter 4000, loss: 2.853478, top_1: 0.563984, top_k: 0.787773, samples/s: 2232.884 1612397751.166275
train: epoch 73, iter 4100, loss: 2.856861, top_1: 0.556953, top_k: 0.784570, samples/s: 2247.057 1612397762.5589604
train: epoch 73, iter 4200, loss: 2.972488, top_1: 0.559766, top_k: 0.783828, samples/s: 2232.683 1612397774.0250344
train: epoch 73, iter 4300, loss: 2.848828, top_1: 0.556133, top_k: 0.789531, samples/s: 2221.467 1612397785.5488892
train: epoch 73, iter 4400, loss: 2.617479, top_1: 0.563594, top_k: 0.788086, samples/s: 2254.684 1612397796.903966
train: epoch 73, iter 4500, loss: 2.663063, top_1: 0.560352, top_k: 0.788828, samples/s: 2204.868 1612397808.513795
train: epoch 73, iter 4600, loss: 2.851791, top_1: 0.565352, top_k: 0.789648, samples/s: 2230.912 1612397819.9888191
train: epoch 73, iter 4700, loss: 2.715185, top_1: 0.565156, top_k: 0.794063, samples/s: 2240.183 1612397831.4167686
train: epoch 73, iter 4800, loss: 2.841864, top_1: 0.560781, top_k: 0.784297, samples/s: 2234.300 1612397842.8743806
train: epoch 73, iter 4900, loss: 2.846095, top_1: 0.565859, top_k: 0.793125, samples/s: 2248.648 1612397854.2588246
train: epoch 73, iter 5000, loss: 2.864159, top_1: 0.562422, top_k: 0.787070, samples/s: 2213.671 1612397865.823313
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_73.
validation: epoch 73, iter 195, top_1: 0.608974, top_k: 0.837780, samples/s: 2844.751 1612397883.6439056
train: epoch 74, iter 100, loss: 2.613111, top_1: 0.566953, top_k: 0.793438, samples/s: 2227.136 1612397911.2392194
train: epoch 74, iter 200, loss: 2.806427, top_1: 0.574531, top_k: 0.798008, samples/s: 2252.928 1612397922.6023037
train: epoch 74, iter 300, loss: 2.628010, top_1: 0.578477, top_k: 0.797656, samples/s: 2268.139 1612397933.888986
train: epoch 74, iter 400, loss: 2.801436, top_1: 0.572148, top_k: 0.795117, samples/s: 2265.637 1612397945.188282
train: epoch 74, iter 500, loss: 2.645906, top_1: 0.570664, top_k: 0.792461, samples/s: 2248.414 1612397956.5740402
train: epoch 74, iter 600, loss: 2.658617, top_1: 0.576328, top_k: 0.798945, samples/s: 2249.457 1612397967.9546373
train: epoch 74, iter 700, loss: 2.688835, top_1: 0.571797, top_k: 0.798008, samples/s: 2247.675 1612397979.3441033
train: epoch 74, iter 800, loss: 3.006538, top_1: 0.571953, top_k: 0.795859, samples/s: 2237.523 1612397990.7853253
train: epoch 74, iter 900, loss: 2.940249, top_1: 0.573672, top_k: 0.797344, samples/s: 2251.063 1612398002.1578035
train: epoch 74, iter 1000, loss: 2.825541, top_1: 0.571055, top_k: 0.796602, samples/s: 2226.724 1612398013.6544669
train: epoch 74, iter 1100, loss: 2.884205, top_1: 0.566406, top_k: 0.795078, samples/s: 2221.100 1612398025.1802697
train: epoch 74, iter 1200, loss: 2.894011, top_1: 0.566055, top_k: 0.791406, samples/s: 2218.035 1612398036.7221012
train: epoch 74, iter 1300, loss: 2.795085, top_1: 0.569180, top_k: 0.793594, samples/s: 2205.073 1612398048.3315976
train: epoch 74, iter 1400, loss: 2.761812, top_1: 0.567109, top_k: 0.791094, samples/s: 2214.040 1612398059.894198
train: epoch 74, iter 1500, loss: 2.755292, top_1: 0.565234, top_k: 0.790781, samples/s: 2207.318 1612398071.4919586
train: epoch 74, iter 1600, loss: 2.922412, top_1: 0.567500, top_k: 0.791289, samples/s: 2215.848 1612398083.0451205
train: epoch 74, iter 1700, loss: 2.674563, top_1: 0.567070, top_k: 0.794805, samples/s: 2216.160 1612398094.5966845
train: epoch 74, iter 1800, loss: 3.005191, top_1: 0.568984, top_k: 0.790117, samples/s: 2208.687 1612398106.187322
train: epoch 74, iter 1900, loss: 2.782827, top_1: 0.568438, top_k: 0.791562, samples/s: 2219.151 1612398117.7232037
train: epoch 74, iter 2000, loss: 2.849652, top_1: 0.562891, top_k: 0.788086, samples/s: 2215.144 1612398129.2799594
train: epoch 74, iter 2100, loss: 2.667822, top_1: 0.566953, top_k: 0.789258, samples/s: 2199.751 1612398140.9177368
train: epoch 74, iter 2200, loss: 2.742880, top_1: 0.572734, top_k: 0.794375, samples/s: 2224.400 1612398152.4263687
train: epoch 74, iter 2300, loss: 2.684595, top_1: 0.571602, top_k: 0.793906, samples/s: 2229.031 1612398163.911571
train: epoch 74, iter 2400, loss: 2.720918, top_1: 0.570078, top_k: 0.789141, samples/s: 2233.108 1612398175.3750925
train: epoch 74, iter 2500, loss: 2.762167, top_1: 0.566133, top_k: 0.793047, samples/s: 2205.073 1612398186.984617
train: epoch 74, iter 2600, loss: 2.839116, top_1: 0.569570, top_k: 0.789414, samples/s: 2228.515 1612398198.4721534
train: epoch 74, iter 2700, loss: 2.659072, top_1: 0.569609, top_k: 0.794883, samples/s: 2204.841 1612398210.0833418
train: epoch 74, iter 2800, loss: 2.815893, top_1: 0.572187, top_k: 0.795977, samples/s: 2237.207 1612398221.5257382
train: epoch 74, iter 2900, loss: 2.896519, top_1: 0.561836, top_k: 0.789180, samples/s: 2220.260 1612398233.0560079
train: epoch 74, iter 3000, loss: 2.898889, top_1: 0.568555, top_k: 0.786797, samples/s: 2250.127 1612398244.4330766
train: epoch 74, iter 3100, loss: 2.789858, top_1: 0.569102, top_k: 0.793711, samples/s: 2217.918 1612398255.9754555
train: epoch 74, iter 3200, loss: 2.818741, top_1: 0.563359, top_k: 0.785234, samples/s: 2223.958 1612398267.486371
train: epoch 74, iter 3300, loss: 2.948992, top_1: 0.569844, top_k: 0.793008, samples/s: 2211.671 1612398279.0614178
train: epoch 74, iter 3400, loss: 2.878312, top_1: 0.563828, top_k: 0.788711, samples/s: 2201.562 1612398290.6898005
train: epoch 74, iter 3500, loss: 2.778495, top_1: 0.567383, top_k: 0.792500, samples/s: 2244.640 1612398302.0944314
train: epoch 74, iter 3600, loss: 2.708456, top_1: 0.562617, top_k: 0.792070, samples/s: 2230.147 1612398313.575136
train: epoch 74, iter 3700, loss: 2.903144, top_1: 0.564961, top_k: 0.787734, samples/s: 2220.376 1612398325.1031284
train: epoch 74, iter 3800, loss: 2.825648, top_1: 0.568828, top_k: 0.793555, samples/s: 2229.322 1612398336.5863984
train: epoch 74, iter 3900, loss: 2.816382, top_1: 0.567578, top_k: 0.793516, samples/s: 2236.279 1612398348.034008
train: epoch 74, iter 4000, loss: 2.702292, top_1: 0.565234, top_k: 0.788516, samples/s: 2230.449 1612398359.511494
train: epoch 74, iter 4100, loss: 2.592875, top_1: 0.563633, top_k: 0.789258, samples/s: 2245.173 1612398370.913721
train: epoch 74, iter 4200, loss: 2.858869, top_1: 0.563555, top_k: 0.794453, samples/s: 2228.313 1612398382.4022646
train: epoch 74, iter 4300, loss: 2.731488, top_1: 0.563203, top_k: 0.787031, samples/s: 2224.950 1612398393.9081187
train: epoch 74, iter 4400, loss: 2.895241, top_1: 0.572344, top_k: 0.791406, samples/s: 2248.582 1612398405.293057
train: epoch 74, iter 4500, loss: 2.818658, top_1: 0.569492, top_k: 0.796719, samples/s: 2242.087 1612398416.711046
train: epoch 74, iter 4600, loss: 2.968912, top_1: 0.562734, top_k: 0.787266, samples/s: 2222.126 1612398428.2315187
train: epoch 74, iter 4700, loss: 2.597272, top_1: 0.565937, top_k: 0.793047, samples/s: 2233.819 1612398439.6916854
train: epoch 74, iter 4800, loss: 2.873035, top_1: 0.564141, top_k: 0.792422, samples/s: 2248.139 1612398451.0790823
train: epoch 74, iter 4900, loss: 2.939029, top_1: 0.566484, top_k: 0.792383, samples/s: 2208.526 1612398462.670321
train: epoch 74, iter 5000, loss: 2.796103, top_1: 0.570781, top_k: 0.793047, samples/s: 2235.384 1612398474.1225405
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_74.
validation: epoch 74, iter 195, top_1: 0.614724, top_k: 0.843690, samples/s: 2783.407 1612398492.3534906
train: epoch 75, iter 100, loss: 2.837923, top_1: 0.574102, top_k: 0.797930, samples/s: 2240.466 1612398519.3407655
train: epoch 75, iter 200, loss: 2.847580, top_1: 0.575117, top_k: 0.799219, samples/s: 2252.555 1612398530.7056894
train: epoch 75, iter 300, loss: 3.012335, top_1: 0.567695, top_k: 0.795664, samples/s: 2261.667 1612398542.025318
train: epoch 75, iter 400, loss: 2.747747, top_1: 0.578750, top_k: 0.801953, samples/s: 2248.354 1612398553.4108284
train: epoch 75, iter 500, loss: 2.870764, top_1: 0.572578, top_k: 0.792422, samples/s: 2222.981 1612398564.9268687
train: epoch 75, iter 600, loss: 2.655765, top_1: 0.570078, top_k: 0.797695, samples/s: 2271.202 1612398576.1988032
train: epoch 75, iter 700, loss: 2.501390, top_1: 0.571953, top_k: 0.795508, samples/s: 2252.894 1612398587.5616822
train: epoch 75, iter 800, loss: 2.551198, top_1: 0.571094, top_k: 0.799336, samples/s: 2241.141 1612398598.984763
train: epoch 75, iter 900, loss: 2.519727, top_1: 0.573164, top_k: 0.800937, samples/s: 2227.474 1612398610.4773042
train: epoch 75, iter 1000, loss: 2.831716, top_1: 0.568906, top_k: 0.796875, samples/s: 2213.363 1612398622.0433636
train: epoch 75, iter 1100, loss: 2.786386, top_1: 0.566680, top_k: 0.793750, samples/s: 2197.016 1612398633.6954906
train: epoch 75, iter 1200, loss: 2.868365, top_1: 0.568984, top_k: 0.796992, samples/s: 2215.555 1612398645.2501452
train: epoch 75, iter 1300, loss: 2.732061, top_1: 0.569805, top_k: 0.791406, samples/s: 2214.027 1612398656.812821
train: epoch 75, iter 1400, loss: 2.729858, top_1: 0.570273, top_k: 0.795508, samples/s: 2217.237 1612398668.3587472
train: epoch 75, iter 1500, loss: 2.970490, top_1: 0.571484, top_k: 0.793984, samples/s: 2204.006 1612398679.9739668
train: epoch 75, iter 1600, loss: 2.674262, top_1: 0.570039, top_k: 0.794883, samples/s: 2223.656 1612398691.4864829
train: epoch 75, iter 1700, loss: 2.915852, top_1: 0.573477, top_k: 0.792188, samples/s: 2219.462 1612398703.0210288
train: epoch 75, iter 1800, loss: 2.751480, top_1: 0.573281, top_k: 0.797383, samples/s: 2238.388 1612398714.4576256
train: epoch 75, iter 1900, loss: 2.811791, top_1: 0.571172, top_k: 0.791328, samples/s: 2224.320 1612398725.966788
train: epoch 75, iter 2000, loss: 2.712463, top_1: 0.569727, top_k: 0.791406, samples/s: 2235.609 1612398737.4177692
train: epoch 75, iter 2100, loss: 2.850537, top_1: 0.566094, top_k: 0.789844, samples/s: 2213.686 1612398748.9823222
train: epoch 75, iter 2200, loss: 2.861124, top_1: 0.568242, top_k: 0.790898, samples/s: 2256.224 1612398760.3285844
train: epoch 75, iter 2300, loss: 2.786879, top_1: 0.572422, top_k: 0.796914, samples/s: 2234.189 1612398771.7869663
train: epoch 75, iter 2400, loss: 2.677302, top_1: 0.569141, top_k: 0.792266, samples/s: 2196.973 1612398783.4393213
train: epoch 75, iter 2500, loss: 2.845846, top_1: 0.574063, top_k: 0.791172, samples/s: 2238.227 1612398794.8769119
train: epoch 75, iter 2600, loss: 2.755955, top_1: 0.571719, top_k: 0.795664, samples/s: 2219.277 1612398806.4122105
train: epoch 75, iter 2700, loss: 2.782213, top_1: 0.568789, top_k: 0.794258, samples/s: 2237.522 1612398817.8535016
train: epoch 75, iter 2800, loss: 2.771079, top_1: 0.570859, top_k: 0.794102, samples/s: 2242.855 1612398829.2674997
train: epoch 75, iter 2900, loss: 2.716819, top_1: 0.561172, top_k: 0.790273, samples/s: 2225.864 1612398840.768613
train: epoch 75, iter 3000, loss: 2.744616, top_1: 0.563047, top_k: 0.789648, samples/s: 2230.435 1612398852.2462907
train: epoch 75, iter 3100, loss: 2.826877, top_1: 0.570078, top_k: 0.796914, samples/s: 2243.539 1612398863.6567395
train: epoch 75, iter 3200, loss: 2.921535, top_1: 0.563359, top_k: 0.791836, samples/s: 2238.567 1612398875.092676
train: epoch 75, iter 3300, loss: 2.792102, top_1: 0.566211, top_k: 0.793711, samples/s: 2244.423 1612398886.4986525
train: epoch 75, iter 3400, loss: 2.780944, top_1: 0.560664, top_k: 0.791289, samples/s: 2236.456 1612398897.9453912
train: epoch 75, iter 3500, loss: 2.850923, top_1: 0.565898, top_k: 0.794219, samples/s: 2231.902 1612398909.4154146
train: epoch 75, iter 3600, loss: 2.805122, top_1: 0.561875, top_k: 0.788711, samples/s: 2248.080 1612398920.8029208
train: epoch 75, iter 3700, loss: 2.758623, top_1: 0.574414, top_k: 0.791719, samples/s: 2220.536 1612398932.3316228
train: epoch 75, iter 3800, loss: 2.698376, top_1: 0.567930, top_k: 0.791133, samples/s: 2228.767 1612398943.817844
train: epoch 75, iter 3900, loss: 2.654656, top_1: 0.563477, top_k: 0.789531, samples/s: 2233.121 1612398955.2815795
train: epoch 75, iter 4000, loss: 2.749014, top_1: 0.566953, top_k: 0.796172, samples/s: 2237.834 1612398966.7212055
train: epoch 75, iter 4100, loss: 2.966022, top_1: 0.568672, top_k: 0.791094, samples/s: 2230.753 1612398978.1971457
train: epoch 75, iter 4200, loss: 2.806694, top_1: 0.563359, top_k: 0.787578, samples/s: 2239.446 1612398989.6286023
train: epoch 75, iter 4300, loss: 2.790994, top_1: 0.565078, top_k: 0.789336, samples/s: 2236.205 1612399001.0765524
train: epoch 75, iter 4400, loss: 2.937367, top_1: 0.566406, top_k: 0.790430, samples/s: 2223.374 1612399012.5906394
train: epoch 75, iter 4500, loss: 2.691192, top_1: 0.571016, top_k: 0.793438, samples/s: 2239.234 1612399024.0230956
train: epoch 75, iter 4600, loss: 2.725101, top_1: 0.563242, top_k: 0.788633, samples/s: 2238.115 1612399035.461293
train: epoch 75, iter 4700, loss: 2.737544, top_1: 0.566602, top_k: 0.793633, samples/s: 2226.369 1612399046.959758
train: epoch 75, iter 4800, loss: 2.593682, top_1: 0.572461, top_k: 0.794727, samples/s: 2238.827 1612399058.3943415
train: epoch 75, iter 4900, loss: 2.646258, top_1: 0.564023, top_k: 0.792539, samples/s: 2213.455 1612399069.9599888
train: epoch 75, iter 5000, loss: 2.891832, top_1: 0.566602, top_k: 0.792031, samples/s: 2262.143 1612399081.2766595
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_75.
validation: epoch 75, iter 195, top_1: 0.610717, top_k: 0.840565, samples/s: 2833.165 1612399099.2053714
train: epoch 76, iter 100, loss: 2.657786, top_1: 0.575547, top_k: 0.800469, samples/s: 2240.995 1612399126.2878954
train: epoch 76, iter 200, loss: 2.805933, top_1: 0.577773, top_k: 0.798945, samples/s: 2248.426 1612399137.6736457
train: epoch 76, iter 300, loss: 2.922021, top_1: 0.577227, top_k: 0.797734, samples/s: 2250.854 1612399149.0470982
train: epoch 76, iter 400, loss: 2.738674, top_1: 0.578008, top_k: 0.800156, samples/s: 2242.339 1612399160.4636986
train: epoch 76, iter 500, loss: 2.626399, top_1: 0.576719, top_k: 0.796953, samples/s: 2250.005 1612399171.8414764
train: epoch 76, iter 600, loss: 2.715858, top_1: 0.575352, top_k: 0.798906, samples/s: 2253.414 1612399183.2019858
train: epoch 76, iter 700, loss: 2.634910, top_1: 0.573047, top_k: 0.795820, samples/s: 2216.397 1612399194.7522695
train: epoch 76, iter 800, loss: 2.751726, top_1: 0.576953, top_k: 0.797500, samples/s: 2241.975 1612399206.1707933
train: epoch 76, iter 900, loss: 2.804229, top_1: 0.571289, top_k: 0.794883, samples/s: 2202.020 1612399217.796616
train: epoch 76, iter 1000, loss: 2.780828, top_1: 0.568438, top_k: 0.795078, samples/s: 2245.603 1612399229.1966357
train: epoch 76, iter 1100, loss: 2.867983, top_1: 0.572812, top_k: 0.800117, samples/s: 2232.670 1612399240.6626577
train: epoch 76, iter 1200, loss: 2.585352, top_1: 0.579766, top_k: 0.797891, samples/s: 2206.552 1612399252.2644184
train: epoch 76, iter 1300, loss: 2.786024, top_1: 0.568047, top_k: 0.793047, samples/s: 2208.728 1612399263.8548026
train: epoch 76, iter 1400, loss: 2.677499, top_1: 0.569414, top_k: 0.796055, samples/s: 2206.354 1612399275.4577506
train: epoch 76, iter 1500, loss: 2.772065, top_1: 0.570391, top_k: 0.793008, samples/s: 2232.015 1612399286.9271955
train: epoch 76, iter 1600, loss: 2.690266, top_1: 0.573203, top_k: 0.798438, samples/s: 2226.478 1612399298.4250824
train: epoch 76, iter 1700, loss: 2.755636, top_1: 0.575234, top_k: 0.800742, samples/s: 2205.010 1612399310.035098
train: epoch 76, iter 1800, loss: 2.821568, top_1: 0.572383, top_k: 0.794961, samples/s: 2218.766 1612399321.5729513
train: epoch 76, iter 1900, loss: 2.789665, top_1: 0.572578, top_k: 0.795586, samples/s: 2216.142 1612399333.124568
train: epoch 76, iter 2000, loss: 2.606898, top_1: 0.572656, top_k: 0.794141, samples/s: 2228.929 1612399344.609962
train: epoch 76, iter 2100, loss: 2.933591, top_1: 0.573125, top_k: 0.797070, samples/s: 2228.080 1612399356.099602
train: epoch 76, iter 2200, loss: 2.808467, top_1: 0.564961, top_k: 0.792617, samples/s: 2207.796 1612399367.6949003
train: epoch 76, iter 2300, loss: 2.793614, top_1: 0.565547, top_k: 0.789570, samples/s: 2239.338 1612399379.1268291
train: epoch 76, iter 2400, loss: 2.935170, top_1: 0.568750, top_k: 0.796367, samples/s: 2210.082 1612399390.7101076
train: epoch 76, iter 2500, loss: 2.576994, top_1: 0.571367, top_k: 0.797422, samples/s: 2235.940 1612399402.1594317
train: epoch 76, iter 2600, loss: 2.714066, top_1: 0.567578, top_k: 0.793477, samples/s: 2210.507 1612399413.7404885
train: epoch 76, iter 2700, loss: 2.714499, top_1: 0.571836, top_k: 0.797578, samples/s: 2249.769 1612399425.1194437
train: epoch 76, iter 2800, loss: 2.771079, top_1: 0.571523, top_k: 0.797344, samples/s: 2241.783 1612399436.5388806
train: epoch 76, iter 2900, loss: 2.748880, top_1: 0.572812, top_k: 0.795898, samples/s: 2238.225 1612399447.9766212
train: epoch 76, iter 3000, loss: 2.801564, top_1: 0.576250, top_k: 0.798008, samples/s: 2229.638 1612399459.4582899
train: epoch 76, iter 3100, loss: 2.791275, top_1: 0.567695, top_k: 0.791523, samples/s: 2223.584 1612399470.971248
train: epoch 76, iter 3200, loss: 3.216172, top_1: 0.567109, top_k: 0.791055, samples/s: 2232.267 1612399482.4393375
train: epoch 76, iter 3300, loss: 2.699920, top_1: 0.566094, top_k: 0.791406, samples/s: 2243.813 1612399493.8485224
train: epoch 76, iter 3400, loss: 2.635330, top_1: 0.566914, top_k: 0.791836, samples/s: 2246.512 1612399505.2439876
train: epoch 76, iter 3500, loss: 2.728497, top_1: 0.567852, top_k: 0.792500, samples/s: 2224.913 1612399516.7500443
train: epoch 76, iter 3600, loss: 2.832729, top_1: 0.567461, top_k: 0.793008, samples/s: 2233.211 1612399528.213324
train: epoch 76, iter 3700, loss: 2.622979, top_1: 0.570352, top_k: 0.794531, samples/s: 2235.365 1612399539.6655867
train: epoch 76, iter 3800, loss: 3.084709, top_1: 0.572266, top_k: 0.796836, samples/s: 2243.329 1612399551.0772085
train: epoch 76, iter 3900, loss: 2.864916, top_1: 0.566953, top_k: 0.794492, samples/s: 2225.530 1612399562.5800712
train: epoch 76, iter 4000, loss: 2.814404, top_1: 0.568203, top_k: 0.794805, samples/s: 2239.666 1612399574.010346
train: epoch 76, iter 4100, loss: 2.687263, top_1: 0.567031, top_k: 0.794258, samples/s: 2228.307 1612399585.498976
train: epoch 76, iter 4200, loss: 2.798601, top_1: 0.570156, top_k: 0.792930, samples/s: 2259.243 1612399596.83014
train: epoch 76, iter 4300, loss: 2.863323, top_1: 0.567969, top_k: 0.793711, samples/s: 2234.355 1612399608.2875643
train: epoch 76, iter 4400, loss: 2.801320, top_1: 0.562695, top_k: 0.790391, samples/s: 2223.846 1612399619.7991776
train: epoch 76, iter 4500, loss: 2.766406, top_1: 0.565742, top_k: 0.791719, samples/s: 2233.502 1612399631.2610652
train: epoch 76, iter 4600, loss: 2.929709, top_1: 0.568789, top_k: 0.791797, samples/s: 2245.635 1612399642.6608982
train: epoch 76, iter 4700, loss: 2.799952, top_1: 0.562969, top_k: 0.786836, samples/s: 2239.012 1612399654.0944982
train: epoch 76, iter 4800, loss: 2.866133, top_1: 0.577070, top_k: 0.797070, samples/s: 2242.212 1612399665.5117786
train: epoch 76, iter 4900, loss: 2.823525, top_1: 0.568594, top_k: 0.788906, samples/s: 2227.952 1612399677.002197
train: epoch 76, iter 5000, loss: 2.788628, top_1: 0.570664, top_k: 0.793750, samples/s: 2229.993 1612399688.4820104
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_76.
validation: epoch 76, iter 195, top_1: 0.616987, top_k: 0.847756, samples/s: 2957.257 1612399705.703567
train: epoch 77, iter 100, loss: 2.605368, top_1: 0.580937, top_k: 0.802383, samples/s: 2242.545 1612399732.7852767
train: epoch 77, iter 200, loss: 2.869487, top_1: 0.580625, top_k: 0.805898, samples/s: 2250.741 1612399744.1593168
train: epoch 77, iter 300, loss: 2.751449, top_1: 0.570703, top_k: 0.799180, samples/s: 2201.221 1612399755.7891932
train: epoch 77, iter 400, loss: 2.753191, top_1: 0.570664, top_k: 0.797852, samples/s: 2261.149 1612399767.1108985
train: epoch 77, iter 500, loss: 2.755677, top_1: 0.572539, top_k: 0.800078, samples/s: 2251.222 1612399778.482578
train: epoch 77, iter 600, loss: 2.955729, top_1: 0.578320, top_k: 0.798008, samples/s: 2253.036 1612399789.8450778
train: epoch 77, iter 700, loss: 2.906470, top_1: 0.576250, top_k: 0.800039, samples/s: 2242.350 1612399801.2615824
train: epoch 77, iter 800, loss: 2.886652, top_1: 0.576523, top_k: 0.800625, samples/s: 2234.134 1612399812.7202513
train: epoch 77, iter 900, loss: 2.844539, top_1: 0.571211, top_k: 0.796875, samples/s: 2238.539 1612399824.1561637
train: epoch 77, iter 1000, loss: 2.842335, top_1: 0.571094, top_k: 0.798711, samples/s: 2236.862 1612399835.6008694
train: epoch 77, iter 1100, loss: 2.620768, top_1: 0.576719, top_k: 0.799648, samples/s: 2214.507 1612399847.16092
train: epoch 77, iter 1200, loss: 2.740789, top_1: 0.573555, top_k: 0.798750, samples/s: 2215.106 1612399858.7178872
train: epoch 77, iter 1300, loss: 2.756394, top_1: 0.575078, top_k: 0.798672, samples/s: 2234.077 1612399870.176763
train: epoch 77, iter 1400, loss: 2.806234, top_1: 0.573008, top_k: 0.793164, samples/s: 2222.995 1612399881.692771
train: epoch 77, iter 1500, loss: 3.026318, top_1: 0.574336, top_k: 0.794727, samples/s: 2217.161 1612399893.2390702
train: epoch 77, iter 1600, loss: 2.827045, top_1: 0.570156, top_k: 0.797422, samples/s: 2226.076 1612399904.7391217
train: epoch 77, iter 1700, loss: 2.758383, top_1: 0.569063, top_k: 0.793281, samples/s: 2221.082 1612399916.2650867
train: epoch 77, iter 1800, loss: 2.627111, top_1: 0.576133, top_k: 0.800273, samples/s: 2234.179 1612399927.7234383
train: epoch 77, iter 1900, loss: 2.831828, top_1: 0.567500, top_k: 0.791211, samples/s: 2235.102 1612399939.1770024
train: epoch 77, iter 2000, loss: 2.640227, top_1: 0.565312, top_k: 0.793320, samples/s: 2218.962 1612399950.7140234
train: epoch 77, iter 2100, loss: 2.654716, top_1: 0.570039, top_k: 0.795977, samples/s: 2250.195 1612399962.09072
train: epoch 77, iter 2200, loss: 2.782611, top_1: 0.565664, top_k: 0.791992, samples/s: 2238.068 1612399973.5291889
train: epoch 77, iter 2300, loss: 2.955790, top_1: 0.573516, top_k: 0.796250, samples/s: 2227.447 1612399985.0221324
train: epoch 77, iter 2400, loss: 2.828585, top_1: 0.572852, top_k: 0.798672, samples/s: 2209.748 1612399996.607321
train: epoch 77, iter 2500, loss: 2.847190, top_1: 0.572773, top_k: 0.797188, samples/s: 2208.988 1612400008.1962743
train: epoch 77, iter 2600, loss: 2.649573, top_1: 0.572969, top_k: 0.795117, samples/s: 2250.788 1612400019.5699694
train: epoch 77, iter 2700, loss: 2.714954, top_1: 0.569727, top_k: 0.793203, samples/s: 2237.133 1612400031.0132453
train: epoch 77, iter 2800, loss: 2.768364, top_1: 0.565508, top_k: 0.792344, samples/s: 2233.479 1612400042.475147
train: epoch 77, iter 2900, loss: 2.793426, top_1: 0.572695, top_k: 0.799687, samples/s: 2246.402 1612400053.871182
train: epoch 77, iter 3000, loss: 2.524078, top_1: 0.576875, top_k: 0.800703, samples/s: 2228.927 1612400065.356506
train: epoch 77, iter 3100, loss: 2.761417, top_1: 0.567344, top_k: 0.794570, samples/s: 2238.097 1612400076.794813
train: epoch 77, iter 3200, loss: 2.791962, top_1: 0.574570, top_k: 0.794648, samples/s: 2220.428 1612400088.3244708
train: epoch 77, iter 3300, loss: 2.839897, top_1: 0.563828, top_k: 0.792461, samples/s: 2236.726 1612400099.7693763
train: epoch 77, iter 3400, loss: 2.755779, top_1: 0.569141, top_k: 0.794727, samples/s: 2237.800 1612400111.209674
train: epoch 77, iter 3500, loss: 2.764173, top_1: 0.572617, top_k: 0.796133, samples/s: 2221.397 1612400122.7334564
train: epoch 77, iter 3600, loss: 2.804774, top_1: 0.572461, top_k: 0.795039, samples/s: 2232.324 1612400134.2013726
train: epoch 77, iter 3700, loss: 2.910306, top_1: 0.569922, top_k: 0.796992, samples/s: 2260.573 1612400145.5258937
train: epoch 77, iter 3800, loss: 2.900713, top_1: 0.568438, top_k: 0.791328, samples/s: 2204.708 1612400157.1374123
train: epoch 77, iter 3900, loss: 2.842261, top_1: 0.568633, top_k: 0.791680, samples/s: 2231.718 1612400168.6084187
train: epoch 77, iter 4000, loss: 2.883836, top_1: 0.573945, top_k: 0.795664, samples/s: 2235.328 1612400180.0608525
train: epoch 77, iter 4100, loss: 2.916020, top_1: 0.569102, top_k: 0.796523, samples/s: 2215.730 1612400191.614705
train: epoch 77, iter 4200, loss: 2.846275, top_1: 0.572305, top_k: 0.798242, samples/s: 2236.328 1612400203.0620048
train: epoch 77, iter 4300, loss: 2.813695, top_1: 0.572695, top_k: 0.794023, samples/s: 2231.309 1612400214.535035
train: epoch 77, iter 4400, loss: 2.913345, top_1: 0.572109, top_k: 0.792070, samples/s: 2242.036 1612400225.9533205
train: epoch 77, iter 4500, loss: 2.746460, top_1: 0.569766, top_k: 0.793672, samples/s: 2242.582 1612400237.3686302
train: epoch 77, iter 4600, loss: 3.057069, top_1: 0.568789, top_k: 0.790195, samples/s: 2240.630 1612400248.7940364
train: epoch 77, iter 4700, loss: 2.769708, top_1: 0.567656, top_k: 0.791641, samples/s: 2247.258 1612400260.1856534
train: epoch 77, iter 4800, loss: 2.795334, top_1: 0.573242, top_k: 0.798086, samples/s: 2243.294 1612400271.5974457
train: epoch 77, iter 4900, loss: 2.749281, top_1: 0.568359, top_k: 0.795977, samples/s: 2221.219 1612400283.1226795
train: epoch 77, iter 5000, loss: 2.507324, top_1: 0.574961, top_k: 0.801289, samples/s: 2262.993 1612400294.435097
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_77.
validation: epoch 77, iter 195, top_1: 0.613241, top_k: 0.839984, samples/s: 2905.042 1612400311.943813
train: epoch 78, iter 100, loss: 2.747144, top_1: 0.582148, top_k: 0.802227, samples/s: 2232.011 1612400344.5925725
train: epoch 78, iter 200, loss: 2.552908, top_1: 0.584141, top_k: 0.805703, samples/s: 2249.384 1612400355.9735262
train: epoch 78, iter 300, loss: 2.665713, top_1: 0.584102, top_k: 0.805859, samples/s: 2258.714 1612400367.3073575
train: epoch 78, iter 400, loss: 2.833324, top_1: 0.579492, top_k: 0.805508, samples/s: 2248.272 1612400378.6941378
train: epoch 78, iter 500, loss: 2.828549, top_1: 0.578633, top_k: 0.801172, samples/s: 2256.447 1612400390.039129
train: epoch 78, iter 600, loss: 2.763225, top_1: 0.573867, top_k: 0.797539, samples/s: 2247.240 1612400401.430986
train: epoch 78, iter 700, loss: 2.669842, top_1: 0.572695, top_k: 0.793008, samples/s: 2271.232 1612400412.702298
train: epoch 78, iter 800, loss: 2.969777, top_1: 0.582187, top_k: 0.800117, samples/s: 2246.527 1612400424.097668
train: epoch 78, iter 900, loss: 2.751092, top_1: 0.576758, top_k: 0.801016, samples/s: 2224.599 1612400435.6053565
train: epoch 78, iter 1000, loss: 2.622923, top_1: 0.581250, top_k: 0.801758, samples/s: 2230.585 1612400447.0854876
train: epoch 78, iter 1100, loss: 2.759196, top_1: 0.576797, top_k: 0.798398, samples/s: 2216.511 1612400458.6318443
train: epoch 78, iter 1200, loss: 2.753381, top_1: 0.568516, top_k: 0.792461, samples/s: 2225.636 1612400470.1341898
train: epoch 78, iter 1300, loss: 2.826704, top_1: 0.571133, top_k: 0.798516, samples/s: 2219.115 1612400481.6703782
train: epoch 78, iter 1400, loss: 2.549591, top_1: 0.573828, top_k: 0.795195, samples/s: 2206.339 1612400493.2732449
train: epoch 78, iter 1500, loss: 2.847581, top_1: 0.573516, top_k: 0.794883, samples/s: 2216.578 1612400504.8225772
train: epoch 78, iter 1600, loss: 2.608384, top_1: 0.574648, top_k: 0.801797, samples/s: 2236.999 1612400516.2665527
train: epoch 78, iter 1700, loss: 2.811939, top_1: 0.576680, top_k: 0.794687, samples/s: 2220.255 1612400527.7967553
train: epoch 78, iter 1800, loss: 2.941054, top_1: 0.572070, top_k: 0.800039, samples/s: 2194.581 1612400539.4618673
train: epoch 78, iter 1900, loss: 2.648540, top_1: 0.576133, top_k: 0.796797, samples/s: 2224.333 1612400550.970911
train: epoch 78, iter 2000, loss: 2.545097, top_1: 0.570859, top_k: 0.796836, samples/s: 2205.968 1612400562.5757313
train: epoch 78, iter 2100, loss: 2.773832, top_1: 0.573672, top_k: 0.798320, samples/s: 2227.834 1612400574.066709
train: epoch 78, iter 2200, loss: 2.687939, top_1: 0.566367, top_k: 0.794727, samples/s: 2232.443 1612400585.533972
train: epoch 78, iter 2300, loss: 2.841120, top_1: 0.569922, top_k: 0.798047, samples/s: 2219.766 1612400597.0667164
train: epoch 78, iter 2400, loss: 2.799542, top_1: 0.572305, top_k: 0.794687, samples/s: 2229.264 1612400608.550399
train: epoch 78, iter 2500, loss: 2.920921, top_1: 0.565937, top_k: 0.794570, samples/s: 2237.101 1612400619.9937146
train: epoch 78, iter 2600, loss: 2.683646, top_1: 0.572539, top_k: 0.795977, samples/s: 2223.030 1612400631.5095298
train: epoch 78, iter 2700, loss: 2.852236, top_1: 0.573203, top_k: 0.796016, samples/s: 2237.519 1612400642.9507694
train: epoch 78, iter 2800, loss: 2.791083, top_1: 0.575859, top_k: 0.798086, samples/s: 2220.265 1612400654.480925
train: epoch 78, iter 2900, loss: 2.716451, top_1: 0.570469, top_k: 0.794922, samples/s: 2253.943 1612400665.8388073
train: epoch 78, iter 3000, loss: 2.753517, top_1: 0.574648, top_k: 0.795781, samples/s: 2223.749 1612400677.3508945
train: epoch 78, iter 3100, loss: 2.974176, top_1: 0.575937, top_k: 0.794961, samples/s: 2228.840 1612400688.8366935
train: epoch 78, iter 3200, loss: 2.697789, top_1: 0.576523, top_k: 0.799453, samples/s: 2250.185 1612400700.2135746
train: epoch 78, iter 3300, loss: 2.598939, top_1: 0.572930, top_k: 0.793867, samples/s: 2236.702 1612400711.6590173
train: epoch 78, iter 3400, loss: 2.580933, top_1: 0.571992, top_k: 0.793984, samples/s: 2226.774 1612400723.155415
train: epoch 78, iter 3500, loss: 2.762860, top_1: 0.572773, top_k: 0.799414, samples/s: 2238.392 1612400734.5922017
train: epoch 78, iter 3600, loss: 2.518905, top_1: 0.569336, top_k: 0.795352, samples/s: 2221.835 1612400746.1142075
train: epoch 78, iter 3700, loss: 2.805466, top_1: 0.574531, top_k: 0.797031, samples/s: 2252.832 1612400757.4777727
train: epoch 78, iter 3800, loss: 2.666660, top_1: 0.573789, top_k: 0.795117, samples/s: 2229.737 1612400768.9588506
train: epoch 78, iter 3900, loss: 2.674986, top_1: 0.573008, top_k: 0.797773, samples/s: 2217.479 1612400780.5034845
train: epoch 78, iter 4000, loss: 2.822454, top_1: 0.567461, top_k: 0.795547, samples/s: 2217.545 1612400792.0479217
train: epoch 78, iter 4100, loss: 2.675411, top_1: 0.574766, top_k: 0.797070, samples/s: 2243.390 1612400803.4594097
train: epoch 78, iter 4200, loss: 2.842623, top_1: 0.567852, top_k: 0.791953, samples/s: 2241.309 1612400814.8810065
train: epoch 78, iter 4300, loss: 2.602341, top_1: 0.575742, top_k: 0.798438, samples/s: 2232.839 1612400826.346538
train: epoch 78, iter 4400, loss: 2.780620, top_1: 0.568594, top_k: 0.795430, samples/s: 2238.336 1612400837.783324
train: epoch 78, iter 4500, loss: 2.808940, top_1: 0.572344, top_k: 0.798828, samples/s: 2188.225 1612400849.482306
train: epoch 78, iter 4600, loss: 2.944777, top_1: 0.577812, top_k: 0.799766, samples/s: 2258.038 1612400860.8195956
train: epoch 78, iter 4700, loss: 2.913196, top_1: 0.573672, top_k: 0.798281, samples/s: 2230.606 1612400872.2962906
train: epoch 78, iter 4800, loss: 2.661329, top_1: 0.573633, top_k: 0.793477, samples/s: 2249.224 1612400883.6779408
train: epoch 78, iter 4900, loss: 2.855712, top_1: 0.571367, top_k: 0.796367, samples/s: 2215.183 1612400895.2346497
train: epoch 78, iter 5000, loss: 2.792642, top_1: 0.577109, top_k: 0.800547, samples/s: 2259.162 1612400906.566243
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_78.
validation: epoch 78, iter 195, top_1: 0.621635, top_k: 0.846875, samples/s: 2843.831 1612400924.4630375
train: epoch 79, iter 100, loss: 2.653083, top_1: 0.584531, top_k: 0.802656, samples/s: 2216.526 1612400952.2246943
train: epoch 79, iter 200, loss: 2.781674, top_1: 0.580078, top_k: 0.803477, samples/s: 2260.542 1612400963.549678
train: epoch 79, iter 300, loss: 2.808818, top_1: 0.580313, top_k: 0.804180, samples/s: 2256.410 1612400974.8948023
train: epoch 79, iter 400, loss: 2.765884, top_1: 0.584688, top_k: 0.806484, samples/s: 2258.567 1612400986.2294328
train: epoch 79, iter 500, loss: 2.798498, top_1: 0.576523, top_k: 0.802578, samples/s: 2252.288 1612400997.5956438
train: epoch 79, iter 600, loss: 2.640337, top_1: 0.578516, top_k: 0.797891, samples/s: 2258.169 1612401008.9322746
train: epoch 79, iter 700, loss: 3.105348, top_1: 0.581484, top_k: 0.804766, samples/s: 2250.611 1612401020.306946
train: epoch 79, iter 800, loss: 2.837927, top_1: 0.580664, top_k: 0.803320, samples/s: 2230.764 1612401031.78284
train: epoch 79, iter 900, loss: 2.602502, top_1: 0.579648, top_k: 0.799492, samples/s: 2248.243 1612401043.1695466
train: epoch 79, iter 1000, loss: 2.888329, top_1: 0.583398, top_k: 0.803672, samples/s: 2224.472 1612401054.6778555
train: epoch 79, iter 1100, loss: 2.794502, top_1: 0.576602, top_k: 0.801172, samples/s: 2220.474 1612401066.2069879
train: epoch 79, iter 1200, loss: 2.625406, top_1: 0.577734, top_k: 0.803203, samples/s: 2229.947 1612401077.6871362
train: epoch 79, iter 1300, loss: 2.744970, top_1: 0.575039, top_k: 0.797578, samples/s: 2213.058 1612401089.2550395
train: epoch 79, iter 1400, loss: 2.905481, top_1: 0.580664, top_k: 0.802227, samples/s: 2219.782 1612401100.7873964
train: epoch 79, iter 1500, loss: 2.571187, top_1: 0.581562, top_k: 0.800195, samples/s: 2218.928 1612401112.3250418
train: epoch 79, iter 1600, loss: 2.940020, top_1: 0.577266, top_k: 0.798789, samples/s: 2214.920 1612401123.8824692
train: epoch 79, iter 1700, loss: 2.928008, top_1: 0.578906, top_k: 0.797891, samples/s: 2219.707 1612401135.415527
train: epoch 79, iter 1800, loss: 2.921920, top_1: 0.573750, top_k: 0.793164, samples/s: 2229.380 1612401146.8985388
train: epoch 79, iter 1900, loss: 2.735327, top_1: 0.578984, top_k: 0.799844, samples/s: 2226.793 1612401158.3948843
train: epoch 79, iter 2000, loss: 2.704909, top_1: 0.581758, top_k: 0.803555, samples/s: 2222.644 1612401169.9127295
train: epoch 79, iter 2100, loss: 2.864258, top_1: 0.579141, top_k: 0.799492, samples/s: 2221.688 1612401181.4355302
train: epoch 79, iter 2200, loss: 2.760915, top_1: 0.573516, top_k: 0.797188, samples/s: 2210.131 1612401193.0184941
train: epoch 79, iter 2300, loss: 2.720027, top_1: 0.572578, top_k: 0.796602, samples/s: 2253.274 1612401204.3798082
train: epoch 79, iter 2400, loss: 2.752073, top_1: 0.572187, top_k: 0.796836, samples/s: 2224.909 1612401215.8858778
train: epoch 79, iter 2500, loss: 2.649201, top_1: 0.578555, top_k: 0.799375, samples/s: 2220.363 1612401227.415475
train: epoch 79, iter 2600, loss: 2.792586, top_1: 0.574063, top_k: 0.802227, samples/s: 2249.116 1612401238.7977276
train: epoch 79, iter 2700, loss: 2.972078, top_1: 0.573281, top_k: 0.796523, samples/s: 2233.881 1612401250.2576041
train: epoch 79, iter 2800, loss: 2.822149, top_1: 0.579570, top_k: 0.799844, samples/s: 2219.538 1612401261.7915418
train: epoch 79, iter 2900, loss: 2.615454, top_1: 0.578203, top_k: 0.797109, samples/s: 2235.903 1612401273.241056
train: epoch 79, iter 3000, loss: 2.857347, top_1: 0.577891, top_k: 0.799023, samples/s: 2221.487 1612401284.7649293
train: epoch 79, iter 3100, loss: 2.628813, top_1: 0.571797, top_k: 0.797344, samples/s: 2209.679 1612401296.3502734
train: epoch 79, iter 3200, loss: 2.632684, top_1: 0.577656, top_k: 0.799219, samples/s: 2203.577 1612401307.9677484
train: epoch 79, iter 3300, loss: 2.848999, top_1: 0.575234, top_k: 0.800547, samples/s: 2253.246 1612401319.3291543
train: epoch 79, iter 3400, loss: 2.680708, top_1: 0.575625, top_k: 0.799570, samples/s: 2221.853 1612401330.851086
train: epoch 79, iter 3500, loss: 2.562669, top_1: 0.569375, top_k: 0.793164, samples/s: 2241.067 1612401342.2741776
train: epoch 79, iter 3600, loss: 2.848454, top_1: 0.577734, top_k: 0.798867, samples/s: 2231.626 1612401353.7456234
train: epoch 79, iter 3700, loss: 2.830192, top_1: 0.573828, top_k: 0.796094, samples/s: 2230.638 1612401365.2222264
train: epoch 79, iter 3800, loss: 2.886803, top_1: 0.575430, top_k: 0.792070, samples/s: 2224.408 1612401376.7309067
train: epoch 79, iter 3900, loss: 2.599442, top_1: 0.571367, top_k: 0.791641, samples/s: 2246.294 1612401388.127385
train: epoch 79, iter 4000, loss: 2.606197, top_1: 0.573203, top_k: 0.794648, samples/s: 2215.343 1612401399.6832643
train: epoch 79, iter 4100, loss: 2.819264, top_1: 0.574805, top_k: 0.797109, samples/s: 2234.685 1612401411.1389418
train: epoch 79, iter 4200, loss: 2.727786, top_1: 0.575430, top_k: 0.799297, samples/s: 2241.605 1612401422.5593915
train: epoch 79, iter 4300, loss: 2.827108, top_1: 0.572969, top_k: 0.796484, samples/s: 2231.634 1612401434.03075
train: epoch 79, iter 4400, loss: 2.724123, top_1: 0.573906, top_k: 0.796875, samples/s: 2232.927 1612401445.4954896
train: epoch 79, iter 4500, loss: 2.710110, top_1: 0.570508, top_k: 0.794766, samples/s: 2233.428 1612401456.957703
train: epoch 79, iter 4600, loss: 2.899043, top_1: 0.573047, top_k: 0.796445, samples/s: 2251.449 1612401468.328237
train: epoch 79, iter 4700, loss: 2.791963, top_1: 0.572930, top_k: 0.796094, samples/s: 2241.061 1612401479.751378
train: epoch 79, iter 4800, loss: 2.824307, top_1: 0.567578, top_k: 0.788828, samples/s: 2225.124 1612401491.2563605
train: epoch 79, iter 4900, loss: 2.661145, top_1: 0.579180, top_k: 0.797031, samples/s: 2229.863 1612401502.7368083
train: epoch 79, iter 5000, loss: 2.798854, top_1: 0.575273, top_k: 0.799883, samples/s: 2250.117 1612401514.1140294
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_79.
validation: epoch 79, iter 195, top_1: 0.613301, top_k: 0.840925, samples/s: 2918.970 1612401531.5551775
train: epoch 80, iter 100, loss: 2.749500, top_1: 0.582266, top_k: 0.806055, samples/s: 2220.993 1612401559.7213361
train: epoch 80, iter 200, loss: 2.580004, top_1: 0.580977, top_k: 0.804297, samples/s: 2260.333 1612401571.047251
train: epoch 80, iter 300, loss: 2.888855, top_1: 0.580234, top_k: 0.800820, samples/s: 2259.061 1612401582.3792393
train: epoch 80, iter 400, loss: 2.702934, top_1: 0.585195, top_k: 0.802617, samples/s: 2257.944 1612401593.7169933
train: epoch 80, iter 500, loss: 2.666880, top_1: 0.580977, top_k: 0.805430, samples/s: 2259.995 1612401605.0444884
train: epoch 80, iter 600, loss: 2.569187, top_1: 0.588125, top_k: 0.802109, samples/s: 2247.005 1612401616.437377
train: epoch 80, iter 700, loss: 2.729034, top_1: 0.579648, top_k: 0.802930, samples/s: 2258.286 1612401627.7737017
train: epoch 80, iter 800, loss: 2.815543, top_1: 0.583164, top_k: 0.805156, samples/s: 2221.483 1612401639.2973683
train: epoch 80, iter 900, loss: 2.771711, top_1: 0.582539, top_k: 0.800703, samples/s: 2256.398 1612401650.6432254
train: epoch 80, iter 1000, loss: 2.683717, top_1: 0.580781, top_k: 0.807148, samples/s: 2213.361 1612401662.2089274
train: epoch 80, iter 1100, loss: 2.682709, top_1: 0.575547, top_k: 0.801758, samples/s: 2217.549 1612401673.753226
train: epoch 80, iter 1200, loss: 2.797173, top_1: 0.576094, top_k: 0.797031, samples/s: 2216.169 1612401685.3046575
train: epoch 80, iter 1300, loss: 2.797535, top_1: 0.578711, top_k: 0.802148, samples/s: 2212.530 1612401696.8752282
train: epoch 80, iter 1400, loss: 2.808079, top_1: 0.583047, top_k: 0.801719, samples/s: 2225.525 1612401708.3779898
train: epoch 80, iter 1500, loss: 2.636320, top_1: 0.576562, top_k: 0.798828, samples/s: 2224.750 1612401719.8849034
train: epoch 80, iter 1600, loss: 2.547812, top_1: 0.582617, top_k: 0.802578, samples/s: 2182.861 1612401731.6126773
train: epoch 80, iter 1700, loss: 2.819345, top_1: 0.575742, top_k: 0.797266, samples/s: 2215.205 1612401743.1691859
train: epoch 80, iter 1800, loss: 2.696292, top_1: 0.583203, top_k: 0.804609, samples/s: 2238.222 1612401754.6067777
train: epoch 80, iter 1900, loss: 2.667191, top_1: 0.577227, top_k: 0.802109, samples/s: 2226.699 1612401766.1036499
train: epoch 80, iter 2000, loss: 2.865914, top_1: 0.581797, top_k: 0.804141, samples/s: 2210.908 1612401777.682571
train: epoch 80, iter 2100, loss: 2.802140, top_1: 0.580273, top_k: 0.802578, samples/s: 2220.951 1612401789.209159
train: epoch 80, iter 2200, loss: 2.816530, top_1: 0.576602, top_k: 0.799258, samples/s: 2230.762 1612401800.6852062
train: epoch 80, iter 2300, loss: 2.670180, top_1: 0.575000, top_k: 0.797500, samples/s: 2217.487 1612401812.2296681
train: epoch 80, iter 2400, loss: 2.851664, top_1: 0.576094, top_k: 0.797305, samples/s: 2236.595 1612401823.6756318
train: epoch 80, iter 2500, loss: 2.927719, top_1: 0.578477, top_k: 0.801719, samples/s: 2201.387 1612401835.3047545
train: epoch 80, iter 2600, loss: 2.608637, top_1: 0.578047, top_k: 0.798086, samples/s: 2223.023 1612401846.8205593
train: epoch 80, iter 2700, loss: 2.761170, top_1: 0.576875, top_k: 0.797109, samples/s: 2212.394 1612401858.391703
train: epoch 80, iter 2800, loss: 2.797905, top_1: 0.565781, top_k: 0.793711, samples/s: 2250.156 1612401869.7686844
train: epoch 80, iter 2900, loss: 2.788310, top_1: 0.578945, top_k: 0.800664, samples/s: 2229.538 1612401881.25099
train: epoch 80, iter 3000, loss: 2.621522, top_1: 0.581562, top_k: 0.801289, samples/s: 2229.629 1612401892.732614
train: epoch 80, iter 3100, loss: 2.463011, top_1: 0.575273, top_k: 0.793945, samples/s: 2231.021 1612401904.207184
train: epoch 80, iter 3200, loss: 2.827094, top_1: 0.571719, top_k: 0.794023, samples/s: 2238.374 1612401915.644053
train: epoch 80, iter 3300, loss: 2.763479, top_1: 0.575391, top_k: 0.796953, samples/s: 2201.373 1612401927.2731912
train: epoch 80, iter 3400, loss: 2.877292, top_1: 0.579336, top_k: 0.802031, samples/s: 2248.717 1612401938.6574373
train: epoch 80, iter 3500, loss: 2.790373, top_1: 0.576484, top_k: 0.797383, samples/s: 2215.702 1612401950.2113998
train: epoch 80, iter 3600, loss: 2.588705, top_1: 0.578477, top_k: 0.797266, samples/s: 2231.135 1612401961.6853092
train: epoch 80, iter 3700, loss: 3.032486, top_1: 0.575156, top_k: 0.796914, samples/s: 2227.288 1612401973.1791346
train: epoch 80, iter 3800, loss: 2.739881, top_1: 0.572383, top_k: 0.795117, samples/s: 2251.615 1612401984.5488088
train: epoch 80, iter 3900, loss: 2.687150, top_1: 0.572695, top_k: 0.794297, samples/s: 2222.050 1612401996.069634
train: epoch 80, iter 4000, loss: 2.751296, top_1: 0.583203, top_k: 0.797578, samples/s: 2230.679 1612402007.5459454
train: epoch 80, iter 4100, loss: 3.009700, top_1: 0.572344, top_k: 0.794883, samples/s: 2225.560 1612402019.0486548
train: epoch 80, iter 4200, loss: 2.964042, top_1: 0.575508, top_k: 0.799297, samples/s: 2224.720 1612402030.555765
train: epoch 80, iter 4300, loss: 2.859506, top_1: 0.570508, top_k: 0.793047, samples/s: 2234.021 1612402042.0148876
train: epoch 80, iter 4400, loss: 2.776649, top_1: 0.575859, top_k: 0.800391, samples/s: 2235.948 1612402053.4642415
train: epoch 80, iter 4500, loss: 2.752090, top_1: 0.572344, top_k: 0.796836, samples/s: 2227.168 1612402064.9586923
train: epoch 80, iter 4600, loss: 3.004615, top_1: 0.574492, top_k: 0.798359, samples/s: 2233.985 1612402076.4179404
train: epoch 80, iter 4700, loss: 2.645651, top_1: 0.574414, top_k: 0.796250, samples/s: 2229.409 1612402087.9008496
train: epoch 80, iter 4800, loss: 2.719853, top_1: 0.577266, top_k: 0.799297, samples/s: 2243.236 1612402099.3128936
train: epoch 80, iter 4900, loss: 2.739477, top_1: 0.567383, top_k: 0.792461, samples/s: 2215.698 1612402110.8668053
train: epoch 80, iter 5000, loss: 2.640079, top_1: 0.574570, top_k: 0.798164, samples/s: 2234.699 1612402122.322495
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_80.
validation: epoch 80, iter 195, top_1: 0.616186, top_k: 0.842147, samples/s: 2898.678 1612402139.884853
train: epoch 81, iter 100, loss: 2.786649, top_1: 0.589453, top_k: 0.807539, samples/s: 2241.810 1612402167.3985388
train: epoch 81, iter 200, loss: 2.617886, top_1: 0.587227, top_k: 0.806953, samples/s: 2229.907 1612402178.8789184
train: epoch 81, iter 300, loss: 2.560086, top_1: 0.582539, top_k: 0.806289, samples/s: 2263.358 1612402190.1894739
train: epoch 81, iter 400, loss: 2.926928, top_1: 0.584648, top_k: 0.804414, samples/s: 2250.222 1612402201.5661137
train: epoch 81, iter 500, loss: 2.837916, top_1: 0.588906, top_k: 0.808672, samples/s: 2260.965 1612402212.8887088
train: epoch 81, iter 600, loss: 2.630507, top_1: 0.584922, top_k: 0.805937, samples/s: 2257.842 1612402224.2269864
train: epoch 81, iter 700, loss: 2.695604, top_1: 0.585469, top_k: 0.802773, samples/s: 2249.944 1612402235.605077
train: epoch 81, iter 800, loss: 2.794088, top_1: 0.581797, top_k: 0.805703, samples/s: 2232.240 1612402247.0733445
train: epoch 81, iter 900, loss: 2.921860, top_1: 0.581328, top_k: 0.803164, samples/s: 2220.735 1612402258.6010563
train: epoch 81, iter 1000, loss: 2.638382, top_1: 0.579570, top_k: 0.802109, samples/s: 2241.222 1612402270.0235422
train: epoch 81, iter 1100, loss: 2.735302, top_1: 0.579688, top_k: 0.801133, samples/s: 2220.757 1612402281.5509953
train: epoch 81, iter 1200, loss: 2.746896, top_1: 0.578594, top_k: 0.802070, samples/s: 2229.194 1612402293.0349658
train: epoch 81, iter 1300, loss: 2.892738, top_1: 0.579961, top_k: 0.801094, samples/s: 2227.089 1612402304.5298107
train: epoch 81, iter 1400, loss: 2.808864, top_1: 0.583945, top_k: 0.800312, samples/s: 2221.312 1612402316.0545328
train: epoch 81, iter 1500, loss: 2.716403, top_1: 0.577969, top_k: 0.803867, samples/s: 2232.948 1612402327.5193229
train: epoch 81, iter 1600, loss: 2.785909, top_1: 0.581797, top_k: 0.805195, samples/s: 2210.990 1612402339.0977042
train: epoch 81, iter 1700, loss: 2.686853, top_1: 0.580117, top_k: 0.800977, samples/s: 2220.335 1612402350.6274967
train: epoch 81, iter 1800, loss: 2.716944, top_1: 0.580547, top_k: 0.800586, samples/s: 2216.754 1612402362.1764607
train: epoch 81, iter 1900, loss: 2.694747, top_1: 0.577734, top_k: 0.799492, samples/s: 2224.729 1612402373.6829495
train: epoch 81, iter 2000, loss: 2.656736, top_1: 0.583867, top_k: 0.805586, samples/s: 2209.485 1612402385.2696862
train: epoch 81, iter 2100, loss: 2.845786, top_1: 0.578477, top_k: 0.800195, samples/s: 2228.029 1612402396.7593477
train: epoch 81, iter 2200, loss: 2.823641, top_1: 0.572344, top_k: 0.794219, samples/s: 2241.426 1612402408.1807256
train: epoch 81, iter 2300, loss: 2.699833, top_1: 0.577617, top_k: 0.801602, samples/s: 2232.298 1612402419.648635
train: epoch 81, iter 2400, loss: 2.739858, top_1: 0.575000, top_k: 0.800312, samples/s: 2223.561 1612402431.1616886
train: epoch 81, iter 2500, loss: 2.824399, top_1: 0.573906, top_k: 0.801602, samples/s: 2242.357 1612402442.5782635
train: epoch 81, iter 2600, loss: 2.693278, top_1: 0.578711, top_k: 0.799414, samples/s: 2224.994 1612402454.0839567
train: epoch 81, iter 2700, loss: 2.707570, top_1: 0.578945, top_k: 0.796953, samples/s: 2239.649 1612402465.5143857
train: epoch 81, iter 2800, loss: 2.817416, top_1: 0.580937, top_k: 0.803047, samples/s: 2252.350 1612402476.880225
train: epoch 81, iter 2900, loss: 2.750406, top_1: 0.578516, top_k: 0.804141, samples/s: 2232.351 1612402488.3478565
train: epoch 81, iter 3000, loss: 2.817091, top_1: 0.578203, top_k: 0.798672, samples/s: 2233.520 1612402499.8096333
train: epoch 81, iter 3100, loss: 2.578533, top_1: 0.576758, top_k: 0.799609, samples/s: 2212.635 1612402511.3799105
train: epoch 81, iter 3200, loss: 2.857977, top_1: 0.580469, top_k: 0.797891, samples/s: 2241.589 1612402522.8000307
train: epoch 81, iter 3300, loss: 2.805751, top_1: 0.584102, top_k: 0.805937, samples/s: 2246.257 1612402534.197096
train: epoch 81, iter 3400, loss: 2.803277, top_1: 0.572852, top_k: 0.797344, samples/s: 2213.012 1612402545.7647822
train: epoch 81, iter 3500, loss: 2.642147, top_1: 0.575273, top_k: 0.794219, samples/s: 2238.086 1612402557.2030756
train: epoch 81, iter 3600, loss: 2.848298, top_1: 0.577266, top_k: 0.802969, samples/s: 2235.925 1612402568.6524444
train: epoch 81, iter 3700, loss: 2.863091, top_1: 0.579727, top_k: 0.798672, samples/s: 2235.147 1612402580.1059282
train: epoch 81, iter 3800, loss: 2.900533, top_1: 0.577617, top_k: 0.795039, samples/s: 2229.648 1612402591.5874634
train: epoch 81, iter 3900, loss: 2.868454, top_1: 0.580156, top_k: 0.797930, samples/s: 2226.184 1612402603.0869603
train: epoch 81, iter 4000, loss: 2.718445, top_1: 0.573320, top_k: 0.796836, samples/s: 2248.071 1612402614.4745584
train: epoch 81, iter 4100, loss: 2.684075, top_1: 0.577656, top_k: 0.801094, samples/s: 2217.506 1612402626.019137
train: epoch 81, iter 4200, loss: 2.763865, top_1: 0.575000, top_k: 0.798789, samples/s: 2246.448 1612402637.4147942
train: epoch 81, iter 4300, loss: 2.825340, top_1: 0.582187, top_k: 0.801562, samples/s: 2227.403 1612402648.9079747
train: epoch 81, iter 4400, loss: 2.626698, top_1: 0.576797, top_k: 0.797148, samples/s: 2231.381 1612402660.3808415
train: epoch 81, iter 4500, loss: 2.592689, top_1: 0.571914, top_k: 0.796914, samples/s: 2238.235 1612402671.8182821
train: epoch 81, iter 4600, loss: 2.699629, top_1: 0.576953, top_k: 0.796484, samples/s: 2241.292 1612402683.2402704
train: epoch 81, iter 4700, loss: 2.765249, top_1: 0.571953, top_k: 0.793281, samples/s: 2204.502 1612402694.8530393
train: epoch 81, iter 4800, loss: 2.891098, top_1: 0.573398, top_k: 0.798281, samples/s: 2232.417 1612402706.3202677
train: epoch 81, iter 4900, loss: 2.809073, top_1: 0.576523, top_k: 0.795898, samples/s: 2238.589 1612402717.7561097
train: epoch 81, iter 5000, loss: 2.676052, top_1: 0.584375, top_k: 0.805312, samples/s: 2249.635 1612402729.1356769
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_81.
validation: epoch 81, iter 195, top_1: 0.622436, top_k: 0.848778, samples/s: 2949.650 1612402746.3977392
train: epoch 82, iter 100, loss: 2.877133, top_1: 0.581289, top_k: 0.803164, samples/s: 2248.356 1612402773.7976062
train: epoch 82, iter 200, loss: 2.657575, top_1: 0.583867, top_k: 0.804414, samples/s: 2238.121 1612402785.2358334
train: epoch 82, iter 300, loss: 2.764614, top_1: 0.583477, top_k: 0.806523, samples/s: 2263.490 1612402796.545743
train: epoch 82, iter 400, loss: 2.594072, top_1: 0.590195, top_k: 0.807930, samples/s: 2254.992 1612402807.898351
train: epoch 82, iter 500, loss: 2.846309, top_1: 0.586406, top_k: 0.806484, samples/s: 2250.860 1612402819.2717512
train: epoch 82, iter 600, loss: 2.708199, top_1: 0.583008, top_k: 0.801836, samples/s: 2238.713 1612402830.7069032
train: epoch 82, iter 700, loss: 2.811314, top_1: 0.581758, top_k: 0.805469, samples/s: 2235.395 1612402842.15912
train: epoch 82, iter 800, loss: 2.887129, top_1: 0.578867, top_k: 0.804688, samples/s: 2236.198 1612402853.6070414
train: epoch 82, iter 900, loss: 2.876057, top_1: 0.585391, top_k: 0.809063, samples/s: 2228.479 1612402865.0947733
train: epoch 82, iter 1000, loss: 2.716852, top_1: 0.578633, top_k: 0.801797, samples/s: 2239.832 1612402876.5241418
train: epoch 82, iter 1100, loss: 2.875818, top_1: 0.582695, top_k: 0.801406, samples/s: 2219.275 1612402888.0593925
train: epoch 82, iter 1200, loss: 2.706870, top_1: 0.581992, top_k: 0.808242, samples/s: 2225.663 1612402899.561663
train: epoch 82, iter 1300, loss: 2.923016, top_1: 0.583828, top_k: 0.801992, samples/s: 2230.606 1612402911.038298
train: epoch 82, iter 1400, loss: 2.906165, top_1: 0.585820, top_k: 0.805117, samples/s: 2223.858 1612402922.5498075
train: epoch 82, iter 1500, loss: 2.724123, top_1: 0.580313, top_k: 0.801836, samples/s: 2207.019 1612402934.1491945
train: epoch 82, iter 1600, loss: 2.693168, top_1: 0.581875, top_k: 0.803047, samples/s: 2219.789 1612402945.6818638
train: epoch 82, iter 1700, loss: 2.733813, top_1: 0.581250, top_k: 0.803242, samples/s: 2232.837 1612402957.147032
train: epoch 82, iter 1800, loss: 2.706504, top_1: 0.580781, top_k: 0.802500, samples/s: 2229.101 1612402968.6315029
train: epoch 82, iter 1900, loss: 2.858643, top_1: 0.579844, top_k: 0.802930, samples/s: 2232.794 1612402980.096965
train: epoch 82, iter 2000, loss: 2.877270, top_1: 0.576602, top_k: 0.797500, samples/s: 2238.093 1612402991.5353043
train: epoch 82, iter 2100, loss: 2.862829, top_1: 0.586055, top_k: 0.803555, samples/s: 2236.454 1612403002.9819376
train: epoch 82, iter 2200, loss: 2.811620, top_1: 0.583086, top_k: 0.801445, samples/s: 2243.375 1612403014.3933382
train: epoch 82, iter 2300, loss: 2.726510, top_1: 0.583320, top_k: 0.806484, samples/s: 2243.824 1612403025.8026285
train: epoch 82, iter 2400, loss: 2.677462, top_1: 0.582539, top_k: 0.804219, samples/s: 2219.924 1612403037.334382
train: epoch 82, iter 2500, loss: 2.858705, top_1: 0.580391, top_k: 0.801133, samples/s: 2238.475 1612403048.7707937
train: epoch 82, iter 2600, loss: 2.836683, top_1: 0.583320, top_k: 0.801484, samples/s: 2228.167 1612403060.2601097
train: epoch 82, iter 2700, loss: 2.709558, top_1: 0.581406, top_k: 0.800391, samples/s: 2225.342 1612403071.7638156
train: epoch 82, iter 2800, loss: 2.759272, top_1: 0.580898, top_k: 0.802266, samples/s: 2241.253 1612403083.186033
train: epoch 82, iter 2900, loss: 2.768726, top_1: 0.581836, top_k: 0.804414, samples/s: 2233.900 1612403094.645855
train: epoch 82, iter 3000, loss: 2.826903, top_1: 0.572617, top_k: 0.800156, samples/s: 2215.079 1612403106.2030299
train: epoch 82, iter 3100, loss: 2.705012, top_1: 0.581680, top_k: 0.801836, samples/s: 2245.279 1612403117.6046166
train: epoch 82, iter 3200, loss: 2.854849, top_1: 0.581172, top_k: 0.797813, samples/s: 2237.733 1612403129.0448644
train: epoch 82, iter 3300, loss: 2.673951, top_1: 0.583203, top_k: 0.801133, samples/s: 2235.881 1612403140.4945233
train: epoch 82, iter 3400, loss: 2.799732, top_1: 0.578789, top_k: 0.801367, samples/s: 2244.622 1612403151.8994374
train: epoch 82, iter 3500, loss: 2.813105, top_1: 0.583906, top_k: 0.803008, samples/s: 2234.802 1612403163.354631
train: epoch 82, iter 3600, loss: 2.893204, top_1: 0.575977, top_k: 0.798125, samples/s: 2253.506 1612403174.7147484
train: epoch 82, iter 3700, loss: 2.792696, top_1: 0.575586, top_k: 0.801211, samples/s: 2217.751 1612403186.2579358
train: epoch 82, iter 3800, loss: 2.910713, top_1: 0.581914, top_k: 0.802734, samples/s: 2217.040 1612403197.8047714
train: epoch 82, iter 3900, loss: 2.935680, top_1: 0.574492, top_k: 0.801953, samples/s: 2242.114 1612403209.222654
train: epoch 82, iter 4000, loss: 2.623443, top_1: 0.582344, top_k: 0.801914, samples/s: 2245.135 1612403220.6251044
train: epoch 82, iter 4100, loss: 2.883446, top_1: 0.576289, top_k: 0.798359, samples/s: 2235.689 1612403232.0756571
train: epoch 82, iter 4200, loss: 2.744365, top_1: 0.583828, top_k: 0.802344, samples/s: 2245.045 1612403243.4786355
train: epoch 82, iter 4300, loss: 2.649351, top_1: 0.575273, top_k: 0.799219, samples/s: 2229.826 1612403254.9592621
train: epoch 82, iter 4400, loss: 2.619457, top_1: 0.575508, top_k: 0.797305, samples/s: 2245.626 1612403266.3592057
train: epoch 82, iter 4500, loss: 2.698088, top_1: 0.579883, top_k: 0.801797, samples/s: 2206.868 1612403277.9594347
train: epoch 82, iter 4600, loss: 2.616000, top_1: 0.574414, top_k: 0.798359, samples/s: 2264.314 1612403289.2652004
train: epoch 82, iter 4700, loss: 2.821693, top_1: 0.579492, top_k: 0.799609, samples/s: 2224.670 1612403300.7725856
train: epoch 82, iter 4800, loss: 2.821908, top_1: 0.574219, top_k: 0.794922, samples/s: 2216.948 1612403312.3200095
train: epoch 82, iter 4900, loss: 2.764671, top_1: 0.578008, top_k: 0.796719, samples/s: 2243.384 1612403323.7312748
train: epoch 82, iter 5000, loss: 2.767254, top_1: 0.581758, top_k: 0.802891, samples/s: 2226.487 1612403335.2293596
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_82.
validation: epoch 82, iter 195, top_1: 0.622216, top_k: 0.847015, samples/s: 2928.177 1612403352.63873
train: epoch 83, iter 100, loss: 2.588006, top_1: 0.589336, top_k: 0.807383, samples/s: 2236.738 1612403380.0345802
train: epoch 83, iter 200, loss: 2.621458, top_1: 0.588398, top_k: 0.812070, samples/s: 2263.157 1612403391.3462083
train: epoch 83, iter 300, loss: 2.713058, top_1: 0.584922, top_k: 0.807031, samples/s: 2216.910 1612403402.8938692
train: epoch 83, iter 400, loss: 2.683249, top_1: 0.586484, top_k: 0.807695, samples/s: 2273.376 1612403414.1546311
train: epoch 83, iter 500, loss: 2.877276, top_1: 0.587305, top_k: 0.806484, samples/s: 2261.475 1612403425.474657
train: epoch 83, iter 600, loss: 2.613075, top_1: 0.586914, top_k: 0.811289, samples/s: 2241.777 1612403436.8942316
train: epoch 83, iter 700, loss: 2.480538, top_1: 0.593555, top_k: 0.808086, samples/s: 2256.188 1612403448.240716
train: epoch 83, iter 800, loss: 2.643806, top_1: 0.585469, top_k: 0.804336, samples/s: 2236.534 1612403459.687
train: epoch 83, iter 900, loss: 2.680048, top_1: 0.580352, top_k: 0.803047, samples/s: 2251.936 1612403471.054999
train: epoch 83, iter 1000, loss: 2.662712, top_1: 0.586445, top_k: 0.807969, samples/s: 2224.384 1612403482.5638015
train: epoch 83, iter 1100, loss: 2.685667, top_1: 0.587422, top_k: 0.806250, samples/s: 2213.840 1612403494.1274288
train: epoch 83, iter 1200, loss: 2.736714, top_1: 0.583594, top_k: 0.805781, samples/s: 2216.616 1612403505.6765661
train: epoch 83, iter 1300, loss: 2.538078, top_1: 0.581211, top_k: 0.799023, samples/s: 2199.902 1612403517.3134785
train: epoch 83, iter 1400, loss: 2.736225, top_1: 0.577656, top_k: 0.796484, samples/s: 2225.994 1612403528.8139384
train: epoch 83, iter 1500, loss: 2.767109, top_1: 0.577930, top_k: 0.799883, samples/s: 2224.431 1612403540.3224843
train: epoch 83, iter 1600, loss: 2.772423, top_1: 0.581836, top_k: 0.806367, samples/s: 2230.305 1612403551.8007362
train: epoch 83, iter 1700, loss: 2.771035, top_1: 0.591641, top_k: 0.807539, samples/s: 2217.660 1612403563.3444767
train: epoch 83, iter 1800, loss: 2.720225, top_1: 0.582227, top_k: 0.802070, samples/s: 2224.862 1612403574.8507526
train: epoch 83, iter 1900, loss: 2.595121, top_1: 0.579844, top_k: 0.802461, samples/s: 2211.903 1612403586.4245095
train: epoch 83, iter 2000, loss: 2.610914, top_1: 0.580000, top_k: 0.804688, samples/s: 2228.412 1612403597.9125113
train: epoch 83, iter 2100, loss: 2.555403, top_1: 0.584141, top_k: 0.806016, samples/s: 2216.986 1612403609.459767
train: epoch 83, iter 2200, loss: 2.826090, top_1: 0.578281, top_k: 0.799102, samples/s: 2202.236 1612403621.0842783
train: epoch 83, iter 2300, loss: 2.742375, top_1: 0.581055, top_k: 0.803359, samples/s: 2223.383 1612403632.5983078
train: epoch 83, iter 2400, loss: 2.998264, top_1: 0.582539, top_k: 0.804375, samples/s: 2247.714 1612403643.9877927
train: epoch 83, iter 2500, loss: 2.717515, top_1: 0.585234, top_k: 0.805898, samples/s: 2229.271 1612403655.4713068
train: epoch 83, iter 2600, loss: 2.838101, top_1: 0.578281, top_k: 0.801250, samples/s: 2181.928 1612403667.2038693
train: epoch 83, iter 2700, loss: 2.653789, top_1: 0.585039, top_k: 0.802891, samples/s: 2257.839 1612403678.542244
train: epoch 83, iter 2800, loss: 2.619480, top_1: 0.582656, top_k: 0.801836, samples/s: 2241.452 1612403689.9633985
train: epoch 83, iter 2900, loss: 2.605815, top_1: 0.579219, top_k: 0.798477, samples/s: 2225.696 1612403701.4655
train: epoch 83, iter 3000, loss: 2.871948, top_1: 0.581250, top_k: 0.802422, samples/s: 2236.502 1612403712.9118388
train: epoch 83, iter 3100, loss: 2.718113, top_1: 0.583633, top_k: 0.804609, samples/s: 2224.152 1612403724.4218965
train: epoch 83, iter 3200, loss: 2.712211, top_1: 0.578516, top_k: 0.800430, samples/s: 2248.857 1612403735.805402
train: epoch 83, iter 3300, loss: 2.661846, top_1: 0.580547, top_k: 0.797969, samples/s: 2236.060 1612403747.2541535
train: epoch 83, iter 3400, loss: 2.720121, top_1: 0.587227, top_k: 0.803125, samples/s: 2235.717 1612403758.7046356
train: epoch 83, iter 3500, loss: 2.775239, top_1: 0.587617, top_k: 0.802383, samples/s: 2203.329 1612403770.323358
train: epoch 83, iter 3600, loss: 2.810740, top_1: 0.579727, top_k: 0.798750, samples/s: 2249.939 1612403781.701444
train: epoch 83, iter 3700, loss: 2.780241, top_1: 0.573555, top_k: 0.796680, samples/s: 2236.658 1612403793.1470895
train: epoch 83, iter 3800, loss: 2.710795, top_1: 0.577461, top_k: 0.806211, samples/s: 2243.072 1612403804.560019
train: epoch 83, iter 3900, loss: 2.711908, top_1: 0.577695, top_k: 0.801406, samples/s: 2241.793 1612403815.979444
train: epoch 83, iter 4000, loss: 2.666954, top_1: 0.585859, top_k: 0.802930, samples/s: 2223.844 1612403827.491103
train: epoch 83, iter 4100, loss: 2.707222, top_1: 0.582617, top_k: 0.803945, samples/s: 2221.392 1612403839.0154316
train: epoch 83, iter 4200, loss: 2.674076, top_1: 0.577109, top_k: 0.800625, samples/s: 2246.623 1612403850.4103055
train: epoch 83, iter 4300, loss: 2.626195, top_1: 0.582344, top_k: 0.804219, samples/s: 2224.216 1612403861.9199872
train: epoch 83, iter 4400, loss: 2.681104, top_1: 0.573477, top_k: 0.798984, samples/s: 2238.255 1612403873.3574333
train: epoch 83, iter 4500, loss: 2.685715, top_1: 0.578984, top_k: 0.802461, samples/s: 2234.685 1612403884.8131866
train: epoch 83, iter 4600, loss: 2.649143, top_1: 0.580078, top_k: 0.799336, samples/s: 2229.814 1612403896.29391
train: epoch 83, iter 4700, loss: 2.698014, top_1: 0.585781, top_k: 0.806758, samples/s: 2236.808 1612403907.738824
train: epoch 83, iter 4800, loss: 2.791318, top_1: 0.578789, top_k: 0.798711, samples/s: 2247.714 1612403919.1282005
train: epoch 83, iter 4900, loss: 2.661154, top_1: 0.576914, top_k: 0.799375, samples/s: 2229.767 1612403930.6091945
train: epoch 83, iter 5000, loss: 2.699311, top_1: 0.584297, top_k: 0.806328, samples/s: 2236.515 1612403942.055601
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_83.
validation: epoch 83, iter 195, top_1: 0.625621, top_k: 0.848357, samples/s: 2941.812 1612403959.344491
train: epoch 84, iter 100, loss: 2.594491, top_1: 0.598281, top_k: 0.814570, samples/s: 2236.392 1612403986.6038496
train: epoch 84, iter 200, loss: 2.685649, top_1: 0.591797, top_k: 0.811562, samples/s: 2240.113 1612403998.0318353
train: epoch 84, iter 300, loss: 2.837128, top_1: 0.588672, top_k: 0.806641, samples/s: 2255.304 1612404009.3828692
train: epoch 84, iter 400, loss: 2.763246, top_1: 0.586719, top_k: 0.807813, samples/s: 2205.286 1612404020.9913623
train: epoch 84, iter 500, loss: 2.646594, top_1: 0.592227, top_k: 0.809961, samples/s: 2240.570 1612404032.4170532
train: epoch 84, iter 600, loss: 2.654115, top_1: 0.587930, top_k: 0.807813, samples/s: 2244.851 1612404043.8208718
train: epoch 84, iter 700, loss: 2.616633, top_1: 0.590352, top_k: 0.807734, samples/s: 2233.728 1612404055.2815368
train: epoch 84, iter 800, loss: 2.800149, top_1: 0.584961, top_k: 0.806523, samples/s: 2259.632 1612404066.610807
train: epoch 84, iter 900, loss: 2.731788, top_1: 0.578984, top_k: 0.802188, samples/s: 2243.271 1612404078.0227678
train: epoch 84, iter 1000, loss: 2.576050, top_1: 0.585078, top_k: 0.805859, samples/s: 2228.675 1612404089.509426
train: epoch 84, iter 1100, loss: 2.827691, top_1: 0.594688, top_k: 0.814492, samples/s: 2212.396 1612404101.0806282
train: epoch 84, iter 1200, loss: 2.742895, top_1: 0.593086, top_k: 0.811445, samples/s: 2237.319 1612404112.5227826
train: epoch 84, iter 1300, loss: 2.691548, top_1: 0.588672, top_k: 0.805469, samples/s: 2228.346 1612404124.0111747
train: epoch 84, iter 1400, loss: 2.634473, top_1: 0.591797, top_k: 0.809844, samples/s: 2211.639 1612404135.5863833
train: epoch 84, iter 1500, loss: 2.782897, top_1: 0.591641, top_k: 0.807383, samples/s: 2240.022 1612404147.0147147
train: epoch 84, iter 1600, loss: 2.672570, top_1: 0.587852, top_k: 0.803789, samples/s: 2212.406 1612404158.5859249
train: epoch 84, iter 1700, loss: 2.811627, top_1: 0.583125, top_k: 0.804023, samples/s: 2208.404 1612404170.177911
train: epoch 84, iter 1800, loss: 2.660778, top_1: 0.587812, top_k: 0.806289, samples/s: 2230.192 1612404181.6567352
train: epoch 84, iter 1900, loss: 2.695164, top_1: 0.585117, top_k: 0.805312, samples/s: 2190.194 1612404193.3452551
train: epoch 84, iter 2000, loss: 2.611983, top_1: 0.585742, top_k: 0.807891, samples/s: 2224.470 1612404204.853618
train: epoch 84, iter 2100, loss: 2.665010, top_1: 0.583125, top_k: 0.805352, samples/s: 2223.624 1612404216.36632
train: epoch 84, iter 2200, loss: 2.718705, top_1: 0.580195, top_k: 0.800742, samples/s: 2217.501 1612404227.910923
train: epoch 84, iter 2300, loss: 2.743727, top_1: 0.585977, top_k: 0.805664, samples/s: 2236.675 1612404239.3563824
train: epoch 84, iter 2400, loss: 2.682830, top_1: 0.581250, top_k: 0.802891, samples/s: 2230.265 1612404250.834845
train: epoch 84, iter 2500, loss: 2.768244, top_1: 0.579492, top_k: 0.805312, samples/s: 2237.426 1612404262.2765675
train: epoch 84, iter 2600, loss: 2.742541, top_1: 0.581758, top_k: 0.806133, samples/s: 2236.919 1612404273.7208767
train: epoch 84, iter 2700, loss: 2.748997, top_1: 0.581016, top_k: 0.801523, samples/s: 2219.805 1612404285.2534215
train: epoch 84, iter 2800, loss: 2.768565, top_1: 0.587578, top_k: 0.805664, samples/s: 2237.290 1612404296.6958454
train: epoch 84, iter 2900, loss: 2.675550, top_1: 0.587773, top_k: 0.806602, samples/s: 2236.603 1612404308.1417994
train: epoch 84, iter 3000, loss: 2.867874, top_1: 0.581641, top_k: 0.804141, samples/s: 2231.364 1612404319.6146047
train: epoch 84, iter 3100, loss: 2.886897, top_1: 0.583008, top_k: 0.800469, samples/s: 2229.676 1612404331.096054
train: epoch 84, iter 3200, loss: 2.780277, top_1: 0.578164, top_k: 0.801953, samples/s: 2233.957 1612404342.5555427
train: epoch 84, iter 3300, loss: 2.598417, top_1: 0.585547, top_k: 0.804766, samples/s: 2233.372 1612404354.018052
train: epoch 84, iter 3400, loss: 2.859878, top_1: 0.574336, top_k: 0.799687, samples/s: 2232.616 1612404365.4844418
train: epoch 84, iter 3500, loss: 2.707625, top_1: 0.588906, top_k: 0.802773, samples/s: 2243.027 1612404376.897547
train: epoch 84, iter 3600, loss: 2.616436, top_1: 0.572891, top_k: 0.797656, samples/s: 2227.361 1612404388.3909838
train: epoch 84, iter 3700, loss: 2.773893, top_1: 0.583164, top_k: 0.805000, samples/s: 2235.836 1612404399.840906
train: epoch 84, iter 3800, loss: 2.821892, top_1: 0.584336, top_k: 0.801875, samples/s: 2204.178 1612404411.4551451
train: epoch 84, iter 3900, loss: 2.991263, top_1: 0.578320, top_k: 0.803281, samples/s: 2236.405 1612404422.90208
train: epoch 84, iter 4000, loss: 2.867992, top_1: 0.587500, top_k: 0.806406, samples/s: 2219.270 1612404434.4374342
train: epoch 84, iter 4100, loss: 2.863132, top_1: 0.577930, top_k: 0.801953, samples/s: 2249.195 1612404445.8192575
train: epoch 84, iter 4200, loss: 2.788956, top_1: 0.580273, top_k: 0.800430, samples/s: 2228.267 1612404457.3080616
train: epoch 84, iter 4300, loss: 2.707588, top_1: 0.579180, top_k: 0.802656, samples/s: 2197.658 1612404468.9567666
train: epoch 84, iter 4400, loss: 2.808046, top_1: 0.585156, top_k: 0.804883, samples/s: 2275.453 1612404480.2073224
train: epoch 84, iter 4500, loss: 2.580291, top_1: 0.585938, top_k: 0.801992, samples/s: 2244.848 1612404491.6111865
train: epoch 84, iter 4600, loss: 2.944053, top_1: 0.577930, top_k: 0.798867, samples/s: 2216.218 1612404503.1624794
train: epoch 84, iter 4700, loss: 2.761950, top_1: 0.576289, top_k: 0.802500, samples/s: 2230.619 1612404514.6390607
train: epoch 84, iter 4800, loss: 2.590942, top_1: 0.581992, top_k: 0.802852, samples/s: 2252.402 1612404526.004735
train: epoch 84, iter 4900, loss: 2.749629, top_1: 0.575391, top_k: 0.799687, samples/s: 2228.300 1612404537.4933171
train: epoch 84, iter 5000, loss: 2.834629, top_1: 0.586641, top_k: 0.808750, samples/s: 2258.532 1612404548.8280392
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_84.
validation: epoch 84, iter 195, top_1: 0.635136, top_k: 0.853846, samples/s: 2975.506 1612404565.9771597
train: epoch 85, iter 100, loss: 2.602622, top_1: 0.596445, top_k: 0.811602, samples/s: 2197.240 1612404593.3208003
train: epoch 85, iter 200, loss: 2.629603, top_1: 0.589609, top_k: 0.810547, samples/s: 2241.395 1612404604.7423954
train: epoch 85, iter 300, loss: 2.800441, top_1: 0.593242, top_k: 0.807852, samples/s: 2262.310 1612404616.0581234
train: epoch 85, iter 400, loss: 2.581886, top_1: 0.591992, top_k: 0.809023, samples/s: 2223.723 1612404627.570363
train: epoch 85, iter 500, loss: 2.587898, top_1: 0.589102, top_k: 0.811953, samples/s: 2263.516 1612404638.8802402
train: epoch 85, iter 600, loss: 2.678790, top_1: 0.587656, top_k: 0.807656, samples/s: 2248.647 1612404650.2648125
train: epoch 85, iter 700, loss: 2.612158, top_1: 0.596172, top_k: 0.812578, samples/s: 2242.429 1612404661.6810138
train: epoch 85, iter 800, loss: 2.936033, top_1: 0.589609, top_k: 0.807578, samples/s: 2242.720 1612404673.0957532
train: epoch 85, iter 900, loss: 2.726685, top_1: 0.586914, top_k: 0.806172, samples/s: 2234.411 1612404684.5528743
train: epoch 85, iter 1000, loss: 2.792257, top_1: 0.594453, top_k: 0.813281, samples/s: 2234.470 1612404696.0097198
train: epoch 85, iter 1100, loss: 2.667235, top_1: 0.591250, top_k: 0.808359, samples/s: 2217.030 1612404707.556701
train: epoch 85, iter 1200, loss: 2.840280, top_1: 0.588125, top_k: 0.809922, samples/s: 2225.928 1612404719.0575457
train: epoch 85, iter 1300, loss: 2.710373, top_1: 0.583438, top_k: 0.807070, samples/s: 2235.823 1612404730.5075095
train: epoch 85, iter 1400, loss: 2.744033, top_1: 0.586602, top_k: 0.808008, samples/s: 2221.694 1612404742.0301788
train: epoch 85, iter 1500, loss: 2.612291, top_1: 0.584922, top_k: 0.810195, samples/s: 2227.099 1612404753.5249512
train: epoch 85, iter 1600, loss: 2.761240, top_1: 0.581914, top_k: 0.808398, samples/s: 2205.472 1612404765.132643
train: epoch 85, iter 1700, loss: 2.705716, top_1: 0.586445, top_k: 0.807891, samples/s: 2212.518 1612404776.7029781
train: epoch 85, iter 1800, loss: 2.720118, top_1: 0.583320, top_k: 0.804258, samples/s: 2212.181 1612404788.2753723
train: epoch 85, iter 1900, loss: 2.810152, top_1: 0.582187, top_k: 0.803320, samples/s: 2233.256 1612404799.7383687
train: epoch 85, iter 2000, loss: 2.607596, top_1: 0.585234, top_k: 0.810977, samples/s: 2224.941 1612404811.2442853
train: epoch 85, iter 2100, loss: 2.765637, top_1: 0.591172, top_k: 0.809609, samples/s: 2232.178 1612404822.7128942
train: epoch 85, iter 2200, loss: 2.562290, top_1: 0.591094, top_k: 0.807344, samples/s: 2220.140 1612404834.2436996
train: epoch 85, iter 2300, loss: 2.602840, top_1: 0.587773, top_k: 0.806211, samples/s: 2203.780 1612404845.8602471
train: epoch 85, iter 2400, loss: 2.859243, top_1: 0.578867, top_k: 0.796914, samples/s: 2243.980 1612404857.2684371
train: epoch 85, iter 2500, loss: 2.802754, top_1: 0.581562, top_k: 0.800781, samples/s: 2211.007 1612404868.8469467
train: epoch 85, iter 2600, loss: 2.744283, top_1: 0.579531, top_k: 0.804688, samples/s: 2220.152 1612404880.3775897
train: epoch 85, iter 2700, loss: 2.700336, top_1: 0.583633, top_k: 0.805547, samples/s: 2256.106 1612404891.7247002
train: epoch 85, iter 2800, loss: 2.564897, top_1: 0.582891, top_k: 0.800898, samples/s: 2232.962 1612404903.1891732
train: epoch 85, iter 2900, loss: 2.614172, top_1: 0.584727, top_k: 0.805195, samples/s: 2225.823 1612404914.6905277
train: epoch 85, iter 3000, loss: 2.652865, top_1: 0.587305, top_k: 0.806250, samples/s: 2240.477 1612404926.1167736
train: epoch 85, iter 3100, loss: 2.646702, top_1: 0.584609, top_k: 0.805859, samples/s: 2243.557 1612404937.527128
train: epoch 85, iter 3200, loss: 2.595648, top_1: 0.583203, top_k: 0.807344, samples/s: 2238.877 1612404948.9614584
train: epoch 85, iter 3300, loss: 2.804040, top_1: 0.588789, top_k: 0.806641, samples/s: 2224.659 1612404960.4688957
train: epoch 85, iter 3400, loss: 2.588163, top_1: 0.589180, top_k: 0.801172, samples/s: 2232.456 1612404971.936004
train: epoch 85, iter 3500, loss: 2.789538, top_1: 0.577578, top_k: 0.801094, samples/s: 2237.054 1612404983.3796306
train: epoch 85, iter 3600, loss: 2.755752, top_1: 0.578086, top_k: 0.803438, samples/s: 2221.847 1612404994.9015708
train: epoch 85, iter 3700, loss: 2.751889, top_1: 0.581523, top_k: 0.803789, samples/s: 2247.784 1612405006.2906258
train: epoch 85, iter 3800, loss: 2.848113, top_1: 0.589805, top_k: 0.808438, samples/s: 2213.776 1612405017.8545098
train: epoch 85, iter 3900, loss: 2.670295, top_1: 0.580508, top_k: 0.805547, samples/s: 2245.595 1612405029.2546036
train: epoch 85, iter 4000, loss: 2.676948, top_1: 0.582969, top_k: 0.804766, samples/s: 2235.496 1612405040.706221
train: epoch 85, iter 4100, loss: 2.759289, top_1: 0.587109, top_k: 0.805078, samples/s: 2232.337 1612405052.1740549
train: epoch 85, iter 4200, loss: 2.792561, top_1: 0.587500, top_k: 0.801875, samples/s: 2233.131 1612405063.6377442
train: epoch 85, iter 4300, loss: 2.727725, top_1: 0.581992, top_k: 0.801484, samples/s: 2231.985 1612405075.107372
train: epoch 85, iter 4400, loss: 2.740123, top_1: 0.584063, top_k: 0.802500, samples/s: 2240.648 1612405086.5326576
train: epoch 85, iter 4500, loss: 2.557717, top_1: 0.581328, top_k: 0.800352, samples/s: 2234.150 1612405097.9911048
train: epoch 85, iter 4600, loss: 2.817934, top_1: 0.580391, top_k: 0.801562, samples/s: 2243.456 1612405109.4020805
train: epoch 85, iter 4700, loss: 2.581192, top_1: 0.583398, top_k: 0.803945, samples/s: 2246.134 1612405120.7994337
train: epoch 85, iter 4800, loss: 2.785524, top_1: 0.577070, top_k: 0.804023, samples/s: 2243.315 1612405132.21111
train: epoch 85, iter 4900, loss: 2.597115, top_1: 0.585781, top_k: 0.808242, samples/s: 2237.785 1612405143.6510017
train: epoch 85, iter 5000, loss: 2.790918, top_1: 0.586172, top_k: 0.809414, samples/s: 2240.702 1612405155.0759938
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_85.
validation: epoch 85, iter 195, top_1: 0.628305, top_k: 0.852744, samples/s: 2907.464 1612405172.5881255
train: epoch 86, iter 100, loss: 2.661223, top_1: 0.588281, top_k: 0.807383, samples/s: 2225.878 1612405199.5439107
train: epoch 86, iter 200, loss: 2.811896, top_1: 0.589336, top_k: 0.806172, samples/s: 2260.469 1612405210.8689475
train: epoch 86, iter 300, loss: 2.705250, top_1: 0.593906, top_k: 0.815742, samples/s: 2247.984 1612405222.256948
train: epoch 86, iter 400, loss: 2.678089, top_1: 0.597656, top_k: 0.815156, samples/s: 2258.081 1612405233.5939763
train: epoch 86, iter 500, loss: 2.680132, top_1: 0.590352, top_k: 0.811016, samples/s: 2244.911 1612405244.997563
train: epoch 86, iter 600, loss: 2.767294, top_1: 0.587891, top_k: 0.808086, samples/s: 2257.765 1612405256.336194
train: epoch 86, iter 700, loss: 2.740642, top_1: 0.588672, top_k: 0.809805, samples/s: 2234.291 1612405267.79397
train: epoch 86, iter 800, loss: 2.965270, top_1: 0.588555, top_k: 0.810391, samples/s: 2238.756 1612405279.228891
train: epoch 86, iter 900, loss: 2.594003, top_1: 0.591328, top_k: 0.808125, samples/s: 2237.689 1612405290.669348
train: epoch 86, iter 1000, loss: 2.749828, top_1: 0.588437, top_k: 0.811484, samples/s: 2229.306 1612405302.1527202
train: epoch 86, iter 1100, loss: 2.479393, top_1: 0.597812, top_k: 0.814414, samples/s: 2216.846 1612405313.7005997
train: epoch 86, iter 1200, loss: 2.548162, top_1: 0.587852, top_k: 0.809180, samples/s: 2231.796 1612405325.1711857
train: epoch 86, iter 1300, loss: 2.843976, top_1: 0.590117, top_k: 0.810078, samples/s: 2223.889 1612405336.6825535
train: epoch 86, iter 1400, loss: 2.740463, top_1: 0.591641, top_k: 0.807578, samples/s: 2209.612 1612405348.268291
train: epoch 86, iter 1500, loss: 2.562481, top_1: 0.585195, top_k: 0.805117, samples/s: 2226.959 1612405359.7638183
train: epoch 86, iter 1600, loss: 2.613804, top_1: 0.593242, top_k: 0.811641, samples/s: 2223.126 1612405371.2791505
train: epoch 86, iter 1700, loss: 2.770755, top_1: 0.591211, top_k: 0.810273, samples/s: 2218.013 1612405382.8209736
train: epoch 86, iter 1800, loss: 2.608682, top_1: 0.593555, top_k: 0.807148, samples/s: 2217.001 1612405394.3680954
train: epoch 86, iter 1900, loss: 2.724408, top_1: 0.592344, top_k: 0.811836, samples/s: 2213.820 1612405405.931836
train: epoch 86, iter 2000, loss: 2.693056, top_1: 0.589258, top_k: 0.804961, samples/s: 2219.597 1612405417.4654508
train: epoch 86, iter 2100, loss: 2.824196, top_1: 0.589922, top_k: 0.808047, samples/s: 2208.152 1612405429.0588787
train: epoch 86, iter 2200, loss: 2.632269, top_1: 0.586758, top_k: 0.805820, samples/s: 2199.240 1612405440.6993403
train: epoch 86, iter 2300, loss: 2.662569, top_1: 0.586055, top_k: 0.808320, samples/s: 2210.065 1612405452.2826474
train: epoch 86, iter 2400, loss: 2.652386, top_1: 0.587969, top_k: 0.805117, samples/s: 2222.144 1612405463.8030105
train: epoch 86, iter 2500, loss: 2.605287, top_1: 0.589844, top_k: 0.809102, samples/s: 2210.617 1612405475.38356
train: epoch 86, iter 2600, loss: 2.655614, top_1: 0.582148, top_k: 0.807031, samples/s: 2232.132 1612405486.8523507
train: epoch 86, iter 2700, loss: 2.898153, top_1: 0.580273, top_k: 0.807461, samples/s: 2224.421 1612405498.3609707
train: epoch 86, iter 2800, loss: 2.711800, top_1: 0.587852, top_k: 0.802578, samples/s: 2237.416 1612405509.802735
train: epoch 86, iter 2900, loss: 2.966786, top_1: 0.584922, top_k: 0.802734, samples/s: 2214.256 1612405521.3642976
train: epoch 86, iter 3000, loss: 2.782990, top_1: 0.584297, top_k: 0.807109, samples/s: 2236.624 1612405532.8100042
train: epoch 86, iter 3100, loss: 2.712929, top_1: 0.587383, top_k: 0.805234, samples/s: 2233.677 1612405544.2709203
train: epoch 86, iter 3200, loss: 2.927133, top_1: 0.580859, top_k: 0.803555, samples/s: 2222.887 1612405555.7875016
train: epoch 86, iter 3300, loss: 2.613619, top_1: 0.588984, top_k: 0.807383, samples/s: 2245.654 1612405567.1872745
train: epoch 86, iter 3400, loss: 2.729594, top_1: 0.583203, top_k: 0.805273, samples/s: 2225.608 1612405578.6897354
train: epoch 86, iter 3500, loss: 2.665870, top_1: 0.590859, top_k: 0.810664, samples/s: 2228.570 1612405590.1769433
train: epoch 86, iter 3600, loss: 2.753040, top_1: 0.585430, top_k: 0.806914, samples/s: 2220.195 1612405601.7075644
train: epoch 86, iter 3700, loss: 2.711488, top_1: 0.584141, top_k: 0.803281, samples/s: 2249.759 1612405613.086457
train: epoch 86, iter 3800, loss: 2.573080, top_1: 0.585000, top_k: 0.807305, samples/s: 2230.685 1612405624.562832
train: epoch 86, iter 3900, loss: 2.617245, top_1: 0.586875, top_k: 0.810078, samples/s: 2224.270 1612405636.0721374
train: epoch 86, iter 4000, loss: 2.787575, top_1: 0.584883, top_k: 0.806719, samples/s: 2224.538 1612405647.5801413
train: epoch 86, iter 4100, loss: 2.629951, top_1: 0.578047, top_k: 0.805117, samples/s: 2230.885 1612405659.0554104
train: epoch 86, iter 4200, loss: 2.698535, top_1: 0.581172, top_k: 0.805508, samples/s: 2242.597 1612405670.4707527
train: epoch 86, iter 4300, loss: 2.864055, top_1: 0.580313, top_k: 0.800859, samples/s: 2234.528 1612405681.9273098
train: epoch 86, iter 4400, loss: 2.670089, top_1: 0.580156, top_k: 0.804141, samples/s: 2214.785 1612405693.4859996
train: epoch 86, iter 4500, loss: 2.657876, top_1: 0.585508, top_k: 0.809023, samples/s: 2217.998 1612405705.0279367
train: epoch 86, iter 4600, loss: 2.576957, top_1: 0.585703, top_k: 0.804609, samples/s: 2229.842 1612405716.5086374
train: epoch 86, iter 4700, loss: 2.705495, top_1: 0.582109, top_k: 0.806992, samples/s: 2242.027 1612405727.926805
train: epoch 86, iter 4800, loss: 2.656751, top_1: 0.583633, top_k: 0.804063, samples/s: 2224.243 1612405739.4363613
train: epoch 86, iter 4900, loss: 2.539874, top_1: 0.579805, top_k: 0.800430, samples/s: 2240.772 1612405750.860997
train: epoch 86, iter 5000, loss: 2.661815, top_1: 0.590703, top_k: 0.810781, samples/s: 2222.194 1612405762.381125
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_86.
validation: epoch 86, iter 195, top_1: 0.628546, top_k: 0.852123, samples/s: 2933.079 1612405779.7698963
train: epoch 87, iter 100, loss: 2.758441, top_1: 0.605859, top_k: 0.819414, samples/s: 2238.325 1612405806.8694777
train: epoch 87, iter 200, loss: 2.666556, top_1: 0.596445, top_k: 0.813945, samples/s: 2254.411 1612405818.2249966
train: epoch 87, iter 300, loss: 2.601470, top_1: 0.597148, top_k: 0.810625, samples/s: 2249.575 1612405829.604921
train: epoch 87, iter 400, loss: 2.643523, top_1: 0.593398, top_k: 0.812305, samples/s: 2244.308 1612405841.01167
train: epoch 87, iter 500, loss: 2.585217, top_1: 0.594414, top_k: 0.813711, samples/s: 2259.847 1612405852.3397639
train: epoch 87, iter 600, loss: 2.681576, top_1: 0.592773, top_k: 0.813281, samples/s: 2242.325 1612405863.756481
train: epoch 87, iter 700, loss: 2.418491, top_1: 0.594414, top_k: 0.813242, samples/s: 2263.677 1612405875.0655217
train: epoch 87, iter 800, loss: 2.766764, top_1: 0.593086, top_k: 0.809883, samples/s: 2242.547 1612405886.48111
train: epoch 87, iter 900, loss: 2.575346, top_1: 0.595938, top_k: 0.813281, samples/s: 2236.457 1612405897.9278479
train: epoch 87, iter 1000, loss: 2.585489, top_1: 0.587930, top_k: 0.809258, samples/s: 2225.419 1612405909.4312992
train: epoch 87, iter 1100, loss: 2.831955, top_1: 0.585820, top_k: 0.807813, samples/s: 2210.758 1612405921.010985
train: epoch 87, iter 1200, loss: 2.742670, top_1: 0.592773, top_k: 0.807383, samples/s: 2207.557 1612405932.6076348
train: epoch 87, iter 1300, loss: 2.645956, top_1: 0.589297, top_k: 0.810664, samples/s: 2216.387 1612405944.1578407
train: epoch 87, iter 1400, loss: 2.735026, top_1: 0.590977, top_k: 0.809727, samples/s: 2205.253 1612405955.7664676
train: epoch 87, iter 1500, loss: 2.710392, top_1: 0.588984, top_k: 0.809766, samples/s: 2222.043 1612405967.2874289
train: epoch 87, iter 1600, loss: 2.564410, top_1: 0.593008, top_k: 0.811016, samples/s: 2226.304 1612405978.7863376
train: epoch 87, iter 1700, loss: 2.774004, top_1: 0.593984, top_k: 0.815117, samples/s: 2249.977 1612405990.1642215
train: epoch 87, iter 1800, loss: 2.816798, top_1: 0.589844, top_k: 0.808125, samples/s: 2228.934 1612406001.6494865
train: epoch 87, iter 1900, loss: 2.794771, top_1: 0.592422, top_k: 0.807813, samples/s: 2222.301 1612406013.169082
train: epoch 87, iter 2000, loss: 2.812762, top_1: 0.596211, top_k: 0.809414, samples/s: 2249.552 1612406024.5491292
train: epoch 87, iter 2100, loss: 2.805097, top_1: 0.587070, top_k: 0.804688, samples/s: 2222.380 1612406036.0683107
train: epoch 87, iter 2200, loss: 2.693302, top_1: 0.592227, top_k: 0.808281, samples/s: 2237.203 1612406047.5111885
train: epoch 87, iter 2300, loss: 2.783208, top_1: 0.587969, top_k: 0.809453, samples/s: 2245.404 1612406058.9122427
train: epoch 87, iter 2400, loss: 2.544062, top_1: 0.590703, top_k: 0.808477, samples/s: 2240.765 1612406070.3369396
train: epoch 87, iter 2500, loss: 2.804814, top_1: 0.587148, top_k: 0.806484, samples/s: 2227.634 1612406081.8289127
train: epoch 87, iter 2600, loss: 2.759658, top_1: 0.588711, top_k: 0.805156, samples/s: 2219.480 1612406093.3631477
train: epoch 87, iter 2700, loss: 2.689717, top_1: 0.596641, top_k: 0.812852, samples/s: 2228.748 1612406104.8494182
train: epoch 87, iter 2800, loss: 2.707107, top_1: 0.586562, top_k: 0.804141, samples/s: 2240.042 1612406116.2778997
train: epoch 87, iter 2900, loss: 2.600775, top_1: 0.590195, top_k: 0.809922, samples/s: 2232.495 1612406127.7447526
train: epoch 87, iter 3000, loss: 2.616451, top_1: 0.586562, top_k: 0.808516, samples/s: 2223.566 1612406139.2578535
train: epoch 87, iter 3100, loss: 2.589398, top_1: 0.587891, top_k: 0.810273, samples/s: 2233.696 1612406150.718628
train: epoch 87, iter 3200, loss: 2.949147, top_1: 0.584727, top_k: 0.806680, samples/s: 2239.165 1612406162.1514564
train: epoch 87, iter 3300, loss: 2.707486, top_1: 0.590508, top_k: 0.810312, samples/s: 2212.761 1612406173.7207193
train: epoch 87, iter 3400, loss: 2.712275, top_1: 0.589102, top_k: 0.807578, samples/s: 2244.751 1612406185.1251318
train: epoch 87, iter 3500, loss: 2.858914, top_1: 0.587109, top_k: 0.806250, samples/s: 2243.160 1612406196.5376377
train: epoch 87, iter 3600, loss: 2.821085, top_1: 0.587305, top_k: 0.806328, samples/s: 2223.625 1612406208.0503907
train: epoch 87, iter 3700, loss: 2.751856, top_1: 0.591016, top_k: 0.808633, samples/s: 2248.465 1612406219.43591
train: epoch 87, iter 3800, loss: 2.677913, top_1: 0.588008, top_k: 0.806016, samples/s: 2224.676 1612406230.9432287
train: epoch 87, iter 3900, loss: 2.566681, top_1: 0.586250, top_k: 0.809570, samples/s: 2208.177 1612406242.5364103
train: epoch 87, iter 4000, loss: 2.731942, top_1: 0.590352, top_k: 0.810312, samples/s: 2235.882 1612406253.9860334
train: epoch 87, iter 4100, loss: 2.574790, top_1: 0.591328, top_k: 0.808594, samples/s: 2197.324 1612406265.6365771
train: epoch 87, iter 4200, loss: 2.809176, top_1: 0.588398, top_k: 0.808398, samples/s: 2247.715 1612406277.0259392
train: epoch 87, iter 4300, loss: 2.621272, top_1: 0.581133, top_k: 0.802070, samples/s: 2220.803 1612406288.5532892
train: epoch 87, iter 4400, loss: 2.502655, top_1: 0.586562, top_k: 0.807891, samples/s: 2253.754 1612406299.9120986
train: epoch 87, iter 4500, loss: 2.761886, top_1: 0.585469, top_k: 0.807695, samples/s: 2225.161 1612406311.4169474
train: epoch 87, iter 4600, loss: 2.683911, top_1: 0.596289, top_k: 0.808633, samples/s: 2226.611 1612406322.9141762
train: epoch 87, iter 4700, loss: 2.715385, top_1: 0.589961, top_k: 0.804844, samples/s: 2260.191 1612406334.240813
train: epoch 87, iter 4800, loss: 2.820553, top_1: 0.582812, top_k: 0.803672, samples/s: 2244.943 1612406345.6440663
train: epoch 87, iter 4900, loss: 2.594839, top_1: 0.588320, top_k: 0.807656, samples/s: 2227.805 1612406357.1352446
train: epoch 87, iter 5000, loss: 2.588728, top_1: 0.592461, top_k: 0.810352, samples/s: 2239.729 1612406368.565182
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_87.
validation: epoch 87, iter 195, top_1: 0.639103, top_k: 0.856130, samples/s: 2956.187 1612406385.8463073
train: epoch 88, iter 100, loss: 2.691847, top_1: 0.599805, top_k: 0.819492, samples/s: 2236.482 1612406413.016335
train: epoch 88, iter 200, loss: 2.742662, top_1: 0.596758, top_k: 0.814336, samples/s: 2256.077 1612406424.363394
train: epoch 88, iter 300, loss: 2.581483, top_1: 0.598906, top_k: 0.815195, samples/s: 2254.235 1612406435.7197707
train: epoch 88, iter 400, loss: 2.611956, top_1: 0.595273, top_k: 0.812305, samples/s: 2240.099 1612406447.1478868
train: epoch 88, iter 500, loss: 2.525123, top_1: 0.595547, top_k: 0.812070, samples/s: 2258.782 1612406458.4813287
train: epoch 88, iter 600, loss: 2.616117, top_1: 0.596133, top_k: 0.815859, samples/s: 2258.916 1612406469.8142493
train: epoch 88, iter 700, loss: 2.590747, top_1: 0.593867, top_k: 0.813477, samples/s: 2243.442 1612406481.2254148
train: epoch 88, iter 800, loss: 2.655561, top_1: 0.595430, top_k: 0.811875, samples/s: 2244.686 1612406492.6300027
train: epoch 88, iter 900, loss: 2.923712, top_1: 0.595156, top_k: 0.810820, samples/s: 2201.417 1612406504.2588782
train: epoch 88, iter 1000, loss: 2.697353, top_1: 0.599883, top_k: 0.811992, samples/s: 2228.990 1612406515.7438893
train: epoch 88, iter 1100, loss: 2.599101, top_1: 0.596836, top_k: 0.814531, samples/s: 2209.422 1612406527.3306265
train: epoch 88, iter 1200, loss: 2.672851, top_1: 0.598008, top_k: 0.812891, samples/s: 2229.721 1612406538.8118832
train: epoch 88, iter 1300, loss: 2.608018, top_1: 0.596836, top_k: 0.810898, samples/s: 2241.458 1612406550.2330601
train: epoch 88, iter 1400, loss: 2.775189, top_1: 0.595508, top_k: 0.810117, samples/s: 2224.536 1612406561.7411132
train: epoch 88, iter 1500, loss: 2.658113, top_1: 0.594102, top_k: 0.808086, samples/s: 2238.234 1612406573.1787045
train: epoch 88, iter 1600, loss: 2.472747, top_1: 0.593594, top_k: 0.811094, samples/s: 2225.762 1612406584.6803284
train: epoch 88, iter 1700, loss: 2.613148, top_1: 0.591094, top_k: 0.811250, samples/s: 2220.636 1612406596.2085505
train: epoch 88, iter 1800, loss: 2.573184, top_1: 0.594063, top_k: 0.809492, samples/s: 2233.264 1612406607.671585
train: epoch 88, iter 1900, loss: 2.646056, top_1: 0.590156, top_k: 0.811484, samples/s: 2227.541 1612406619.1641107
train: epoch 88, iter 2000, loss: 2.450159, top_1: 0.597461, top_k: 0.813398, samples/s: 2233.061 1612406630.6282806
train: epoch 88, iter 2100, loss: 2.718458, top_1: 0.594375, top_k: 0.812031, samples/s: 2247.566 1612406642.0182712
train: epoch 88, iter 2200, loss: 2.667150, top_1: 0.586367, top_k: 0.807422, samples/s: 2233.477 1612406653.4802198
train: epoch 88, iter 2300, loss: 2.707458, top_1: 0.593008, top_k: 0.813555, samples/s: 2237.422 1612406664.92195
train: epoch 88, iter 2400, loss: 2.701956, top_1: 0.587930, top_k: 0.804922, samples/s: 2216.439 1612406676.4720283
train: epoch 88, iter 2500, loss: 2.909901, top_1: 0.595313, top_k: 0.810156, samples/s: 2223.440 1612406687.9857001
train: epoch 88, iter 2600, loss: 2.983157, top_1: 0.592930, top_k: 0.809492, samples/s: 2222.955 1612406699.5019114
train: epoch 88, iter 2700, loss: 2.562209, top_1: 0.587109, top_k: 0.807070, samples/s: 2229.026 1612406710.9867454
train: epoch 88, iter 2800, loss: 2.788514, top_1: 0.592852, top_k: 0.809609, samples/s: 2241.340 1612406722.4084916
train: epoch 88, iter 2900, loss: 2.696910, top_1: 0.592461, top_k: 0.810117, samples/s: 2238.998 1612406733.8421726
train: epoch 88, iter 3000, loss: 2.794496, top_1: 0.591445, top_k: 0.807969, samples/s: 2228.244 1612406745.3310676
train: epoch 88, iter 3100, loss: 2.885925, top_1: 0.588555, top_k: 0.809063, samples/s: 2236.388 1612406756.778067
train: epoch 88, iter 3200, loss: 2.585267, top_1: 0.590703, top_k: 0.808047, samples/s: 2247.216 1612406768.1699376
train: epoch 88, iter 3300, loss: 2.667635, top_1: 0.588437, top_k: 0.808555, samples/s: 2226.174 1612406779.669554
train: epoch 88, iter 3400, loss: 2.666094, top_1: 0.586211, top_k: 0.808516, samples/s: 2244.539 1612406791.0750117
train: epoch 88, iter 3500, loss: 2.711841, top_1: 0.585000, top_k: 0.806250, samples/s: 2229.404 1612406802.5578353
train: epoch 88, iter 3600, loss: 2.870881, top_1: 0.587070, top_k: 0.809570, samples/s: 2206.590 1612406814.1594453
train: epoch 88, iter 3700, loss: 2.557293, top_1: 0.594922, top_k: 0.810625, samples/s: 2233.744 1612406825.6200438
train: epoch 88, iter 3800, loss: 2.627066, top_1: 0.585625, top_k: 0.807656, samples/s: 2234.365 1612406837.0774257
train: epoch 88, iter 3900, loss: 2.631358, top_1: 0.586328, top_k: 0.809023, samples/s: 2237.297 1612406848.5197978
train: epoch 88, iter 4000, loss: 2.659177, top_1: 0.585898, top_k: 0.805664, samples/s: 2242.595 1612406859.9351408
train: epoch 88, iter 4100, loss: 2.670755, top_1: 0.592969, top_k: 0.815508, samples/s: 2236.826 1612406871.3799527
train: epoch 88, iter 4200, loss: 2.821513, top_1: 0.590977, top_k: 0.807031, samples/s: 2242.400 1612406882.7962859
train: epoch 88, iter 4300, loss: 2.751562, top_1: 0.589336, top_k: 0.807969, samples/s: 2236.888 1612406894.2408423
train: epoch 88, iter 4400, loss: 2.625782, top_1: 0.591328, top_k: 0.809922, samples/s: 2234.239 1612406905.698795
train: epoch 88, iter 4500, loss: 2.664134, top_1: 0.589063, top_k: 0.806406, samples/s: 2233.645 1612406917.1598902
train: epoch 88, iter 4600, loss: 2.738835, top_1: 0.591133, top_k: 0.809531, samples/s: 2237.652 1612406928.6004813
train: epoch 88, iter 4700, loss: 2.784074, top_1: 0.593359, top_k: 0.811055, samples/s: 2224.813 1612406940.107032
train: epoch 88, iter 4800, loss: 2.770975, top_1: 0.588633, top_k: 0.802422, samples/s: 2223.735 1612406951.6192665
train: epoch 88, iter 4900, loss: 2.504252, top_1: 0.593008, top_k: 0.809922, samples/s: 2262.724 1612406962.932995
train: epoch 88, iter 5000, loss: 2.575933, top_1: 0.596250, top_k: 0.811680, samples/s: 2233.859 1612406974.3930902
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_88.
validation: epoch 88, iter 195, top_1: 0.634375, top_k: 0.854187, samples/s: 2867.100 1612406992.123294
train: epoch 89, iter 100, loss: 2.564766, top_1: 0.600078, top_k: 0.814102, samples/s: 2251.256 1612407019.3940961
train: epoch 89, iter 200, loss: 2.639904, top_1: 0.594688, top_k: 0.813359, samples/s: 2255.752 1612407030.7429526
train: epoch 89, iter 300, loss: 2.724934, top_1: 0.596445, top_k: 0.815859, samples/s: 2250.796 1612407042.1167278
train: epoch 89, iter 400, loss: 2.635600, top_1: 0.600742, top_k: 0.815195, samples/s: 2251.911 1612407053.48474
train: epoch 89, iter 500, loss: 2.576582, top_1: 0.590117, top_k: 0.809727, samples/s: 2255.170 1612407064.8364215
train: epoch 89, iter 600, loss: 2.630232, top_1: 0.602695, top_k: 0.817422, samples/s: 2246.548 1612407076.231678
train: epoch 89, iter 700, loss: 2.796534, top_1: 0.592773, top_k: 0.813438, samples/s: 2226.599 1612407087.7290673
train: epoch 89, iter 800, loss: 2.658344, top_1: 0.594727, top_k: 0.813594, samples/s: 2213.887 1612407099.2926006
train: epoch 89, iter 900, loss: 2.450026, top_1: 0.597383, top_k: 0.814922, samples/s: 2250.737 1612407110.666484
train: epoch 89, iter 1000, loss: 2.529453, top_1: 0.601953, top_k: 0.816758, samples/s: 2218.718 1612407122.2046592
train: epoch 89, iter 1100, loss: 2.539867, top_1: 0.592266, top_k: 0.810000, samples/s: 2203.695 1612407133.8215141
train: epoch 89, iter 1200, loss: 2.728533, top_1: 0.596367, top_k: 0.813594, samples/s: 2232.784 1612407145.287048
train: epoch 89, iter 1300, loss: 2.493011, top_1: 0.597266, top_k: 0.819258, samples/s: 2228.911 1612407156.7724388
train: epoch 89, iter 1400, loss: 2.564585, top_1: 0.595273, top_k: 0.809609, samples/s: 2203.064 1612407168.392628
train: epoch 89, iter 1500, loss: 2.623196, top_1: 0.593594, top_k: 0.811055, samples/s: 2221.639 1612407179.9156547
train: epoch 89, iter 1600, loss: 2.635879, top_1: 0.598203, top_k: 0.817305, samples/s: 2209.748 1612407191.5006764
train: epoch 89, iter 1700, loss: 2.773744, top_1: 0.595391, top_k: 0.811445, samples/s: 2218.258 1612407203.0413244
train: epoch 89, iter 1800, loss: 2.668542, top_1: 0.591133, top_k: 0.806562, samples/s: 2233.213 1612407214.5045664
train: epoch 89, iter 1900, loss: 2.579228, top_1: 0.599727, top_k: 0.814258, samples/s: 2222.246 1612407226.0245588
train: epoch 89, iter 2000, loss: 2.942054, top_1: 0.598750, top_k: 0.814023, samples/s: 2234.739 1612407237.4799337
train: epoch 89, iter 2100, loss: 2.942760, top_1: 0.594102, top_k: 0.811797, samples/s: 2225.873 1612407248.9810238
train: epoch 89, iter 2200, loss: 2.601601, top_1: 0.597930, top_k: 0.816836, samples/s: 2231.799 1612407260.4516425
train: epoch 89, iter 2300, loss: 2.714552, top_1: 0.596094, top_k: 0.813750, samples/s: 2225.834 1612407271.9529057
train: epoch 89, iter 2400, loss: 2.782242, top_1: 0.594063, top_k: 0.811992, samples/s: 2223.326 1612407283.4672625
train: epoch 89, iter 2500, loss: 2.431188, top_1: 0.592500, top_k: 0.809492, samples/s: 2206.935 1612407295.0669794
train: epoch 89, iter 2600, loss: 2.628665, top_1: 0.590898, top_k: 0.811406, samples/s: 2235.681 1612407306.5176919
train: epoch 89, iter 2700, loss: 2.678826, top_1: 0.591328, top_k: 0.805156, samples/s: 2229.641 1612407317.9992933
train: epoch 89, iter 2800, loss: 2.771681, top_1: 0.593125, top_k: 0.809180, samples/s: 2193.028 1612407329.6726754
train: epoch 89, iter 2900, loss: 2.479324, top_1: 0.595352, top_k: 0.811797, samples/s: 2252.596 1612407341.0373735
train: epoch 89, iter 3000, loss: 2.746312, top_1: 0.591992, top_k: 0.811250, samples/s: 2219.900 1612407352.569512
train: epoch 89, iter 3100, loss: 2.618083, top_1: 0.589141, top_k: 0.810586, samples/s: 2234.916 1612407364.0239742
train: epoch 89, iter 3200, loss: 2.693931, top_1: 0.589297, top_k: 0.808711, samples/s: 2225.183 1612407375.528617
train: epoch 89, iter 3300, loss: 2.523077, top_1: 0.591367, top_k: 0.810625, samples/s: 2239.121 1612407386.9617343
train: epoch 89, iter 3400, loss: 2.731258, top_1: 0.591992, top_k: 0.813242, samples/s: 2235.054 1612407398.4160101
train: epoch 89, iter 3500, loss: 2.748963, top_1: 0.594258, top_k: 0.812227, samples/s: 2232.866 1612407409.8806517
train: epoch 89, iter 3600, loss: 2.718314, top_1: 0.587500, top_k: 0.801875, samples/s: 2242.131 1612407421.2989378
train: epoch 89, iter 3700, loss: 2.681760, top_1: 0.595859, top_k: 0.811289, samples/s: 2227.309 1612407432.7921178
train: epoch 89, iter 3800, loss: 2.608068, top_1: 0.594063, top_k: 0.811602, samples/s: 2208.020 1612407444.38613
train: epoch 89, iter 3900, loss: 2.563592, top_1: 0.587773, top_k: 0.805469, samples/s: 2245.473 1612407455.7868762
train: epoch 89, iter 4000, loss: 2.762706, top_1: 0.591367, top_k: 0.810078, samples/s: 2231.069 1612407467.2611613
train: epoch 89, iter 4100, loss: 2.542155, top_1: 0.595039, top_k: 0.813047, samples/s: 2220.903 1612407478.7880561
train: epoch 89, iter 4200, loss: 2.711029, top_1: 0.593711, top_k: 0.810469, samples/s: 2243.633 1612407490.1980948
train: epoch 89, iter 4300, loss: 2.865523, top_1: 0.592617, top_k: 0.809531, samples/s: 2245.051 1612407501.6009305
train: epoch 89, iter 4400, loss: 2.715098, top_1: 0.588633, top_k: 0.805391, samples/s: 2222.621 1612407513.1188688
train: epoch 89, iter 4500, loss: 2.644910, top_1: 0.591289, top_k: 0.812617, samples/s: 2232.015 1612407524.5884206
train: epoch 89, iter 4600, loss: 2.736989, top_1: 0.591445, top_k: 0.805000, samples/s: 2238.220 1612407536.026003
train: epoch 89, iter 4700, loss: 2.868368, top_1: 0.587734, top_k: 0.803711, samples/s: 2234.700 1612407547.481716
train: epoch 89, iter 4800, loss: 2.560587, top_1: 0.590430, top_k: 0.809922, samples/s: 2236.897 1612407558.9260905
train: epoch 89, iter 4900, loss: 2.597120, top_1: 0.593437, top_k: 0.809570, samples/s: 2238.905 1612407570.360404
train: epoch 89, iter 5000, loss: 2.461012, top_1: 0.596836, top_k: 0.814727, samples/s: 2249.421 1612407581.741029
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_89.
validation: epoch 89, iter 195, top_1: 0.639443, top_k: 0.857492, samples/s: 2863.088 1612407599.5343306
train: epoch 90, iter 100, loss: 2.672662, top_1: 0.599336, top_k: 0.816953, samples/s: 2216.215 1612407626.692072
train: epoch 90, iter 200, loss: 2.575943, top_1: 0.597852, top_k: 0.815859, samples/s: 2250.886 1612407638.0654886
train: epoch 90, iter 300, loss: 2.516999, top_1: 0.600703, top_k: 0.814180, samples/s: 2245.067 1612407649.4680984
train: epoch 90, iter 400, loss: 2.580964, top_1: 0.595469, top_k: 0.813438, samples/s: 2251.853 1612407660.8365157
train: epoch 90, iter 500, loss: 2.810564, top_1: 0.601016, top_k: 0.817891, samples/s: 2255.569 1612407672.1862383
train: epoch 90, iter 600, loss: 2.821058, top_1: 0.597852, top_k: 0.813047, samples/s: 2258.069 1612407683.5232983
train: epoch 90, iter 700, loss: 2.656424, top_1: 0.593398, top_k: 0.814570, samples/s: 2251.310 1612407694.895373
train: epoch 90, iter 800, loss: 2.657555, top_1: 0.597695, top_k: 0.815937, samples/s: 2237.217 1612407706.3372598
train: epoch 90, iter 900, loss: 2.588882, top_1: 0.596797, top_k: 0.812734, samples/s: 2236.508 1612407717.7840204
train: epoch 90, iter 1000, loss: 2.798843, top_1: 0.602070, top_k: 0.814297, samples/s: 2215.756 1612407729.3373334
train: epoch 90, iter 1100, loss: 2.769890, top_1: 0.600117, top_k: 0.814297, samples/s: 2215.760 1612407740.8908772
train: epoch 90, iter 1200, loss: 2.647831, top_1: 0.594414, top_k: 0.813945, samples/s: 2220.883 1612407752.417828
train: epoch 90, iter 1300, loss: 2.566570, top_1: 0.597305, top_k: 0.813438, samples/s: 2221.263 1612407763.9428005
train: epoch 90, iter 1400, loss: 2.705367, top_1: 0.595508, top_k: 0.811797, samples/s: 2233.950 1612407775.4023476
train: epoch 90, iter 1500, loss: 2.648429, top_1: 0.603047, top_k: 0.819141, samples/s: 2220.216 1612407786.9328144
train: epoch 90, iter 1600, loss: 2.563101, top_1: 0.597617, top_k: 0.814258, samples/s: 2213.669 1612407798.4972484
train: epoch 90, iter 1700, loss: 2.702920, top_1: 0.600547, top_k: 0.817031, samples/s: 2202.411 1612407810.1209173
train: epoch 90, iter 1800, loss: 2.741060, top_1: 0.594297, top_k: 0.814648, samples/s: 2213.423 1612407821.6867874
train: epoch 90, iter 1900, loss: 2.649779, top_1: 0.594766, top_k: 0.810703, samples/s: 2225.211 1612407833.1912684
train: epoch 90, iter 2000, loss: 2.562469, top_1: 0.593125, top_k: 0.812383, samples/s: 2248.278 1612407844.5776806
train: epoch 90, iter 2100, loss: 2.602740, top_1: 0.592383, top_k: 0.808398, samples/s: 2189.714 1612407856.2686965
train: epoch 90, iter 2200, loss: 2.574748, top_1: 0.595195, top_k: 0.812305, samples/s: 2236.028 1612407867.7176228
train: epoch 90, iter 2300, loss: 2.689969, top_1: 0.595273, top_k: 0.809844, samples/s: 2228.747 1612407879.203925
train: epoch 90, iter 2400, loss: 2.645769, top_1: 0.593945, top_k: 0.812227, samples/s: 2230.831 1612407890.67939
train: epoch 90, iter 2500, loss: 2.370437, top_1: 0.590977, top_k: 0.807773, samples/s: 2221.086 1612407902.205389
train: epoch 90, iter 2600, loss: 2.597769, top_1: 0.602266, top_k: 0.813477, samples/s: 2250.774 1612407913.5791526
train: epoch 90, iter 2700, loss: 2.582489, top_1: 0.589805, top_k: 0.809492, samples/s: 2234.812 1612407925.0343418
train: epoch 90, iter 2800, loss: 2.761680, top_1: 0.598555, top_k: 0.811484, samples/s: 2225.541 1612407936.5370774
train: epoch 90, iter 2900, loss: 2.727892, top_1: 0.590391, top_k: 0.808281, samples/s: 2234.931 1612407947.9915853
train: epoch 90, iter 3000, loss: 2.802126, top_1: 0.593867, top_k: 0.813633, samples/s: 2243.809 1612407959.4007478
train: epoch 90, iter 3100, loss: 2.803946, top_1: 0.595859, top_k: 0.815195, samples/s: 2227.289 1612407970.8946161
train: epoch 90, iter 3200, loss: 2.551159, top_1: 0.590625, top_k: 0.808359, samples/s: 2230.061 1612407982.3740394
train: epoch 90, iter 3300, loss: 2.689778, top_1: 0.591680, top_k: 0.811484, samples/s: 2230.579 1612407993.8508794
train: epoch 90, iter 3400, loss: 2.647555, top_1: 0.594336, top_k: 0.808906, samples/s: 2223.012 1612408005.366859
train: epoch 90, iter 3500, loss: 2.564994, top_1: 0.593984, top_k: 0.813555, samples/s: 2231.937 1612408016.836645
train: epoch 90, iter 3600, loss: 2.704013, top_1: 0.594023, top_k: 0.811211, samples/s: 2237.341 1612408028.278852
train: epoch 90, iter 3700, loss: 2.559581, top_1: 0.593242, top_k: 0.810898, samples/s: 2235.849 1612408039.7285879
train: epoch 90, iter 3800, loss: 2.664998, top_1: 0.593945, top_k: 0.814648, samples/s: 2236.084 1612408051.1772304
train: epoch 90, iter 3900, loss: 2.642580, top_1: 0.595234, top_k: 0.812813, samples/s: 2244.661 1612408062.5820134
train: epoch 90, iter 4000, loss: 2.665864, top_1: 0.591445, top_k: 0.811016, samples/s: 2211.821 1612408074.1562471
train: epoch 90, iter 4100, loss: 2.687373, top_1: 0.589414, top_k: 0.806641, samples/s: 2236.363 1612408085.603344
train: epoch 90, iter 4200, loss: 2.802223, top_1: 0.592031, top_k: 0.811797, samples/s: 2234.922 1612408097.0578837
train: epoch 90, iter 4300, loss: 2.748379, top_1: 0.590273, top_k: 0.807383, samples/s: 2230.491 1612408108.5351918
train: epoch 90, iter 4400, loss: 2.668773, top_1: 0.593945, top_k: 0.811211, samples/s: 2245.962 1612408119.9334352
train: epoch 90, iter 4500, loss: 2.716064, top_1: 0.593203, top_k: 0.808828, samples/s: 2234.135 1612408131.392009
train: epoch 90, iter 4600, loss: 2.784499, top_1: 0.595469, top_k: 0.811719, samples/s: 2229.000 1612408142.8769617
train: epoch 90, iter 4700, loss: 2.591686, top_1: 0.592695, top_k: 0.812852, samples/s: 2245.492 1612408154.277594
train: epoch 90, iter 4800, loss: 2.788483, top_1: 0.598906, top_k: 0.815586, samples/s: 2230.212 1612408165.7563057
train: epoch 90, iter 4900, loss: 2.739792, top_1: 0.590352, top_k: 0.809102, samples/s: 2176.550 1612408177.518041
train: epoch 90, iter 5000, loss: 2.916086, top_1: 0.594375, top_k: 0.808359, samples/s: 2269.097 1612408188.8001244
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_90.
validation: epoch 90, iter 195, top_1: 0.637520, top_k: 0.855609, samples/s: 2988.209 1612408205.8319263
train: epoch 91, iter 100, loss: 2.707841, top_1: 0.603086, top_k: 0.817773, samples/s: 2244.946 1612408232.7643998
train: epoch 91, iter 200, loss: 2.732385, top_1: 0.602305, top_k: 0.816172, samples/s: 2252.448 1612408244.1297917
train: epoch 91, iter 300, loss: 2.724831, top_1: 0.609531, top_k: 0.821055, samples/s: 2261.977 1612408255.4473548
train: epoch 91, iter 400, loss: 2.507856, top_1: 0.600898, top_k: 0.819102, samples/s: 2258.256 1612408266.7834966
train: epoch 91, iter 500, loss: 2.714083, top_1: 0.601133, top_k: 0.814883, samples/s: 2258.441 1612408278.1187654
train: epoch 91, iter 600, loss: 2.549813, top_1: 0.601250, top_k: 0.821211, samples/s: 2252.317 1612408289.4852479
train: epoch 91, iter 700, loss: 2.554080, top_1: 0.606250, top_k: 0.821523, samples/s: 2235.976 1612408300.9339652
train: epoch 91, iter 800, loss: 2.628184, top_1: 0.606367, top_k: 0.820547, samples/s: 2238.666 1612408312.3697038
train: epoch 91, iter 900, loss: 2.602672, top_1: 0.595742, top_k: 0.814883, samples/s: 2244.397 1612408323.7755284
train: epoch 91, iter 1000, loss: 2.691510, top_1: 0.596250, top_k: 0.813359, samples/s: 2219.936 1612408335.3073883
train: epoch 91, iter 1100, loss: 2.707530, top_1: 0.601953, top_k: 0.812930, samples/s: 2182.196 1612408347.0387292
train: epoch 91, iter 1200, loss: 2.757218, top_1: 0.599063, top_k: 0.813789, samples/s: 2241.517 1612408358.4595408
train: epoch 91, iter 1300, loss: 2.666901, top_1: 0.598750, top_k: 0.813945, samples/s: 2209.964 1612408370.043428
train: epoch 91, iter 1400, loss: 2.591712, top_1: 0.600195, top_k: 0.812773, samples/s: 2229.993 1612408381.523351
train: epoch 91, iter 1500, loss: 2.556883, top_1: 0.597930, top_k: 0.817695, samples/s: 2209.864 1612408393.1077383
train: epoch 91, iter 1600, loss: 2.639477, top_1: 0.599219, top_k: 0.815391, samples/s: 2205.511 1612408404.7150717
train: epoch 91, iter 1700, loss: 2.632233, top_1: 0.592266, top_k: 0.813203, samples/s: 2206.160 1612408416.3188736
train: epoch 91, iter 1800, loss: 2.866828, top_1: 0.596445, top_k: 0.811094, samples/s: 2227.596 1612408427.8111277
train: epoch 91, iter 1900, loss: 2.475858, top_1: 0.595508, top_k: 0.809883, samples/s: 2163.012 1612408439.6464581
train: epoch 91, iter 2000, loss: 2.800245, top_1: 0.594844, top_k: 0.811250, samples/s: 2236.336 1612408451.0937667
train: epoch 91, iter 2100, loss: 2.469989, top_1: 0.604688, top_k: 0.817578, samples/s: 2212.235 1612408462.6657326
train: epoch 91, iter 2200, loss: 2.655897, top_1: 0.599609, top_k: 0.811445, samples/s: 2211.296 1612408474.242663
train: epoch 91, iter 2300, loss: 2.581309, top_1: 0.600313, top_k: 0.817305, samples/s: 2229.354 1612408485.725852
train: epoch 91, iter 2400, loss: 2.727409, top_1: 0.599180, top_k: 0.815352, samples/s: 2214.756 1612408497.2846448
train: epoch 91, iter 2500, loss: 2.698328, top_1: 0.596016, top_k: 0.810039, samples/s: 2206.461 1612408508.8869846
train: epoch 91, iter 2600, loss: 2.589579, top_1: 0.599258, top_k: 0.815742, samples/s: 2215.682 1612408520.440927
train: epoch 91, iter 2700, loss: 2.928753, top_1: 0.598164, top_k: 0.816719, samples/s: 2219.845 1612408531.9732752
train: epoch 91, iter 2800, loss: 2.783847, top_1: 0.594727, top_k: 0.812617, samples/s: 2208.014 1612408543.5675259
train: epoch 91, iter 2900, loss: 2.624965, top_1: 0.602266, top_k: 0.817305, samples/s: 2186.037 1612408555.2780867
train: epoch 91, iter 3000, loss: 2.768502, top_1: 0.599102, top_k: 0.811016, samples/s: 2229.398 1612408566.7610044
train: epoch 91, iter 3100, loss: 2.435093, top_1: 0.600625, top_k: 0.814375, samples/s: 2209.998 1612408578.3447225
train: epoch 91, iter 3200, loss: 2.792686, top_1: 0.596523, top_k: 0.810430, samples/s: 2194.636 1612408590.0095325
train: epoch 91, iter 3300, loss: 2.645787, top_1: 0.597344, top_k: 0.814844, samples/s: 2189.289 1612408601.7029107
train: epoch 91, iter 3400, loss: 2.666656, top_1: 0.592070, top_k: 0.813516, samples/s: 2204.870 1612408613.313496
train: epoch 91, iter 3500, loss: 2.724485, top_1: 0.592500, top_k: 0.811797, samples/s: 2227.425 1612408624.8066258
train: epoch 91, iter 3600, loss: 2.886193, top_1: 0.595820, top_k: 0.813086, samples/s: 2203.627 1612408636.4239576
train: epoch 91, iter 3700, loss: 2.623734, top_1: 0.593828, top_k: 0.812266, samples/s: 2207.950 1612408648.018336
train: epoch 91, iter 3800, loss: 2.546150, top_1: 0.599414, top_k: 0.817695, samples/s: 2226.113 1612408659.5181193
train: epoch 91, iter 3900, loss: 2.767475, top_1: 0.590000, top_k: 0.810117, samples/s: 2211.520 1612408671.0938685
train: epoch 91, iter 4000, loss: 2.652675, top_1: 0.595000, top_k: 0.810273, samples/s: 2225.095 1612408682.5990336
train: epoch 91, iter 4100, loss: 2.612686, top_1: 0.590625, top_k: 0.810312, samples/s: 2231.224 1612408694.0725152
train: epoch 91, iter 4200, loss: 2.782104, top_1: 0.595273, top_k: 0.810156, samples/s: 2223.506 1612408705.5858648
train: epoch 91, iter 4300, loss: 2.684690, top_1: 0.591914, top_k: 0.811445, samples/s: 2240.113 1612408717.013878
train: epoch 91, iter 4400, loss: 2.576630, top_1: 0.596055, top_k: 0.813047, samples/s: 2221.017 1612408728.540203
train: epoch 91, iter 4500, loss: 2.640830, top_1: 0.595664, top_k: 0.814727, samples/s: 2242.985 1612408739.9535582
train: epoch 91, iter 4600, loss: 2.695402, top_1: 0.594336, top_k: 0.811445, samples/s: 2212.813 1612408751.52246
train: epoch 91, iter 4700, loss: 2.654578, top_1: 0.597578, top_k: 0.813047, samples/s: 2243.479 1612408762.9333177
train: epoch 91, iter 4800, loss: 2.734805, top_1: 0.596602, top_k: 0.811953, samples/s: 2235.543 1612408774.384665
train: epoch 91, iter 4900, loss: 2.624887, top_1: 0.589141, top_k: 0.805781, samples/s: 2236.492 1612408785.831195
train: epoch 91, iter 5000, loss: 2.701935, top_1: 0.598945, top_k: 0.815508, samples/s: 2225.403 1612408797.3347142
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_91.
validation: epoch 91, iter 195, top_1: 0.637981, top_k: 0.855629, samples/s: 2812.475 1612408815.439726
train: epoch 92, iter 100, loss: 2.695444, top_1: 0.603828, top_k: 0.819258, samples/s: 2241.257 1612408842.4564133
train: epoch 92, iter 200, loss: 2.824329, top_1: 0.599961, top_k: 0.816758, samples/s: 2254.446 1612408853.8117273
train: epoch 92, iter 300, loss: 2.636622, top_1: 0.609727, top_k: 0.822422, samples/s: 2252.580 1612408865.1765065
train: epoch 92, iter 400, loss: 2.695252, top_1: 0.606602, top_k: 0.818867, samples/s: 2265.050 1612408876.4787023
train: epoch 92, iter 500, loss: 2.678943, top_1: 0.608750, top_k: 0.817227, samples/s: 2254.830 1612408887.8321128
train: epoch 92, iter 600, loss: 2.832787, top_1: 0.603398, top_k: 0.814141, samples/s: 2231.145 1612408899.3060663
train: epoch 92, iter 700, loss: 2.726980, top_1: 0.603828, top_k: 0.817305, samples/s: 2259.399 1612408910.6365695
train: epoch 92, iter 800, loss: 2.679657, top_1: 0.605781, top_k: 0.820742, samples/s: 2242.797 1612408922.0508044
train: epoch 92, iter 900, loss: 2.694535, top_1: 0.595664, top_k: 0.814180, samples/s: 2235.781 1612408933.500987
train: epoch 92, iter 1000, loss: 2.719443, top_1: 0.603320, top_k: 0.816992, samples/s: 2210.099 1612408945.084067
train: epoch 92, iter 1100, loss: 2.754823, top_1: 0.599258, top_k: 0.816953, samples/s: 2204.754 1612408956.6954112
train: epoch 92, iter 1200, loss: 2.590649, top_1: 0.604219, top_k: 0.820430, samples/s: 2206.939 1612408968.29523
train: epoch 92, iter 1300, loss: 2.598009, top_1: 0.599258, top_k: 0.816094, samples/s: 2213.766 1612408979.8591201
train: epoch 92, iter 1400, loss: 2.785759, top_1: 0.604414, top_k: 0.817422, samples/s: 2218.731 1612408991.397262
train: epoch 92, iter 1500, loss: 2.787261, top_1: 0.600742, top_k: 0.815430, samples/s: 2215.167 1612409002.9540095
train: epoch 92, iter 1600, loss: 2.587064, top_1: 0.602031, top_k: 0.817109, samples/s: 2207.663 1612409014.5499127
train: epoch 92, iter 1700, loss: 2.645062, top_1: 0.598164, top_k: 0.816094, samples/s: 2223.014 1612409026.0658596
train: epoch 92, iter 1800, loss: 2.822162, top_1: 0.592109, top_k: 0.810312, samples/s: 2225.349 1612409037.5696347
train: epoch 92, iter 1900, loss: 2.880359, top_1: 0.602812, top_k: 0.818711, samples/s: 2226.257 1612409049.0687501
train: epoch 92, iter 2000, loss: 2.742044, top_1: 0.601953, top_k: 0.816523, samples/s: 2230.591 1612409060.5454938
train: epoch 92, iter 2100, loss: 2.590416, top_1: 0.598359, top_k: 0.815977, samples/s: 2234.674 1612409072.0013194
train: epoch 92, iter 2200, loss: 2.719743, top_1: 0.604023, top_k: 0.816211, samples/s: 2206.693 1612409083.6024032
train: epoch 92, iter 2300, loss: 2.579712, top_1: 0.598086, top_k: 0.810078, samples/s: 2235.840 1612409095.0522351
train: epoch 92, iter 2400, loss: 2.621351, top_1: 0.598008, top_k: 0.815352, samples/s: 2236.856 1612409106.496866
train: epoch 92, iter 2500, loss: 2.689335, top_1: 0.600781, top_k: 0.813555, samples/s: 2229.775 1612409117.9778862
train: epoch 92, iter 2600, loss: 2.793283, top_1: 0.596211, top_k: 0.816875, samples/s: 2224.160 1612409129.4878078
train: epoch 92, iter 2700, loss: 2.598006, top_1: 0.599727, top_k: 0.815117, samples/s: 2224.423 1612409140.9965522
train: epoch 92, iter 2800, loss: 2.744107, top_1: 0.594375, top_k: 0.814102, samples/s: 2238.976 1612409152.4302726
train: epoch 92, iter 2900, loss: 2.786890, top_1: 0.599727, top_k: 0.819023, samples/s: 2232.572 1612409163.8968086
train: epoch 92, iter 3000, loss: 2.771496, top_1: 0.600664, top_k: 0.813633, samples/s: 2233.989 1612409175.356137
train: epoch 92, iter 3100, loss: 2.724919, top_1: 0.597148, top_k: 0.812305, samples/s: 2233.229 1612409186.8193486
train: epoch 92, iter 3200, loss: 2.711699, top_1: 0.595273, top_k: 0.813398, samples/s: 2219.150 1612409198.3552988
train: epoch 92, iter 3300, loss: 2.874793, top_1: 0.593320, top_k: 0.811680, samples/s: 2249.824 1612409209.73399
train: epoch 92, iter 3400, loss: 2.728518, top_1: 0.598633, top_k: 0.815039, samples/s: 2233.152 1612409221.1975808
train: epoch 92, iter 3500, loss: 2.528173, top_1: 0.597383, top_k: 0.817695, samples/s: 2221.777 1612409232.7198887
train: epoch 92, iter 3600, loss: 2.681495, top_1: 0.595820, top_k: 0.810703, samples/s: 2230.479 1612409244.197296
train: epoch 92, iter 3700, loss: 2.653128, top_1: 0.599844, top_k: 0.812813, samples/s: 2237.144 1612409255.6404092
train: epoch 92, iter 3800, loss: 2.703187, top_1: 0.596875, top_k: 0.813750, samples/s: 2240.847 1612409267.064666
train: epoch 92, iter 3900, loss: 2.682239, top_1: 0.594023, top_k: 0.810078, samples/s: 2230.537 1612409278.5418165
train: epoch 92, iter 4000, loss: 2.745388, top_1: 0.601133, top_k: 0.815586, samples/s: 2242.705 1612409289.95658
train: epoch 92, iter 4100, loss: 2.748448, top_1: 0.591602, top_k: 0.812461, samples/s: 2222.500 1612409301.4750564
train: epoch 92, iter 4200, loss: 2.723943, top_1: 0.591641, top_k: 0.812109, samples/s: 2252.863 1612409312.8383784
train: epoch 92, iter 4300, loss: 2.877521, top_1: 0.595078, top_k: 0.811719, samples/s: 2214.848 1612409324.39669
train: epoch 92, iter 4400, loss: 2.660466, top_1: 0.591875, top_k: 0.811016, samples/s: 2217.584 1612409335.9408476
train: epoch 92, iter 4500, loss: 2.683413, top_1: 0.594141, top_k: 0.812578, samples/s: 2249.530 1612409347.321001
train: epoch 92, iter 4600, loss: 2.641278, top_1: 0.592461, top_k: 0.809648, samples/s: 2210.749 1612409358.9008038
train: epoch 92, iter 4700, loss: 2.606418, top_1: 0.597812, top_k: 0.814844, samples/s: 2250.577 1612409370.2756615
train: epoch 92, iter 4800, loss: 2.791053, top_1: 0.603594, top_k: 0.814844, samples/s: 2236.979 1612409381.7197154
train: epoch 92, iter 4900, loss: 2.816483, top_1: 0.593984, top_k: 0.812656, samples/s: 2233.193 1612409393.183056
train: epoch 92, iter 5000, loss: 2.696247, top_1: 0.602305, top_k: 0.815039, samples/s: 2224.065 1612409404.6935296
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_92.
validation: epoch 92, iter 195, top_1: 0.637660, top_k: 0.857111, samples/s: 2897.460 1612409422.237159
train: epoch 93, iter 100, loss: 2.716323, top_1: 0.609180, top_k: 0.819727, samples/s: 2229.920 1612409455.0423834
train: epoch 93, iter 200, loss: 2.782111, top_1: 0.609883, top_k: 0.825000, samples/s: 2256.566 1612409466.3870142
train: epoch 93, iter 300, loss: 2.609058, top_1: 0.607656, top_k: 0.823633, samples/s: 2260.973 1612409477.7095401
train: epoch 93, iter 400, loss: 2.519091, top_1: 0.603945, top_k: 0.821211, samples/s: 2253.116 1612409489.0716624
train: epoch 93, iter 500, loss: 2.690543, top_1: 0.605039, top_k: 0.820000, samples/s: 2244.445 1612409500.4775596
train: epoch 93, iter 600, loss: 2.645021, top_1: 0.603867, top_k: 0.819023, samples/s: 2221.285 1612409512.0024126
train: epoch 93, iter 700, loss: 2.682777, top_1: 0.601719, top_k: 0.820508, samples/s: 2245.529 1612409523.4028397
train: epoch 93, iter 800, loss: 2.602829, top_1: 0.604023, top_k: 0.818711, samples/s: 2245.951 1612409534.8012664
train: epoch 93, iter 900, loss: 2.490458, top_1: 0.602539, top_k: 0.817813, samples/s: 2223.156 1612409546.3163548
train: epoch 93, iter 1000, loss: 2.750936, top_1: 0.610039, top_k: 0.822539, samples/s: 2226.685 1612409557.8132534
train: epoch 93, iter 1100, loss: 2.689168, top_1: 0.602539, top_k: 0.814609, samples/s: 2200.085 1612409569.4490938
train: epoch 93, iter 1200, loss: 2.726524, top_1: 0.604648, top_k: 0.818086, samples/s: 2222.792 1612409580.966229
train: epoch 93, iter 1300, loss: 2.660526, top_1: 0.597500, top_k: 0.814180, samples/s: 2236.715 1612409592.4115245
train: epoch 93, iter 1400, loss: 2.736637, top_1: 0.603633, top_k: 0.817695, samples/s: 2206.255 1612409604.0149424
train: epoch 93, iter 1500, loss: 2.648023, top_1: 0.605664, top_k: 0.821836, samples/s: 2226.608 1612409615.5122056
train: epoch 93, iter 1600, loss: 2.530277, top_1: 0.604023, top_k: 0.816953, samples/s: 2234.160 1612409626.9707
train: epoch 93, iter 1700, loss: 2.908136, top_1: 0.595859, top_k: 0.813203, samples/s: 2214.017 1612409638.5333514
train: epoch 93, iter 1800, loss: 2.654249, top_1: 0.603008, top_k: 0.816758, samples/s: 2247.573 1612409649.9234834
train: epoch 93, iter 1900, loss: 2.697893, top_1: 0.601680, top_k: 0.814180, samples/s: 2207.162 1612409661.5220134
train: epoch 93, iter 2000, loss: 2.778661, top_1: 0.599219, top_k: 0.815234, samples/s: 2224.243 1612409673.031562
train: epoch 93, iter 2100, loss: 2.832137, top_1: 0.599219, top_k: 0.814531, samples/s: 2231.018 1612409684.506141
train: epoch 93, iter 2200, loss: 2.628981, top_1: 0.601211, top_k: 0.820156, samples/s: 2251.412 1612409695.876779
train: epoch 93, iter 2300, loss: 2.466554, top_1: 0.596328, top_k: 0.815156, samples/s: 2241.166 1612409707.2994738
train: epoch 93, iter 2400, loss: 2.739248, top_1: 0.602031, top_k: 0.815703, samples/s: 2209.855 1612409718.8838792
train: epoch 93, iter 2500, loss: 2.490423, top_1: 0.603477, top_k: 0.818594, samples/s: 2228.028 1612409730.374007
train: epoch 93, iter 2600, loss: 2.653797, top_1: 0.602148, top_k: 0.813711, samples/s: 2230.548 1612409741.8508658
train: epoch 93, iter 2700, loss: 2.695179, top_1: 0.601562, top_k: 0.816445, samples/s: 2237.985 1612409753.2897332
train: epoch 93, iter 2800, loss: 2.626342, top_1: 0.599375, top_k: 0.817305, samples/s: 2231.645 1612409764.7612112
train: epoch 93, iter 2900, loss: 2.712079, top_1: 0.600430, top_k: 0.814727, samples/s: 2242.576 1612409776.1765273
train: epoch 93, iter 3000, loss: 2.475137, top_1: 0.602539, top_k: 0.819141, samples/s: 2228.910 1612409787.661961
train: epoch 93, iter 3100, loss: 2.810567, top_1: 0.603164, top_k: 0.819180, samples/s: 2217.503 1612409799.2064998
train: epoch 93, iter 3200, loss: 2.734647, top_1: 0.600430, top_k: 0.815937, samples/s: 2235.834 1612409810.6563606
train: epoch 93, iter 3300, loss: 2.600803, top_1: 0.603086, top_k: 0.817617, samples/s: 2177.101 1612409822.4151123
train: epoch 93, iter 3400, loss: 2.548449, top_1: 0.598320, top_k: 0.813555, samples/s: 2273.754 1612409833.6740189
train: epoch 93, iter 3500, loss: 2.667652, top_1: 0.596406, top_k: 0.817617, samples/s: 2206.105 1612409845.2781594
train: epoch 93, iter 3600, loss: 2.693082, top_1: 0.596992, top_k: 0.814570, samples/s: 2229.074 1612409856.762764
train: epoch 93, iter 3700, loss: 2.602447, top_1: 0.604023, top_k: 0.815039, samples/s: 2242.651 1612409868.1779056
train: epoch 93, iter 3800, loss: 2.794837, top_1: 0.600820, top_k: 0.813828, samples/s: 2211.165 1612409879.7554421
train: epoch 93, iter 3900, loss: 2.704391, top_1: 0.598086, top_k: 0.812969, samples/s: 2242.176 1612409891.1729228
train: epoch 93, iter 4000, loss: 2.800462, top_1: 0.599414, top_k: 0.815000, samples/s: 2250.574 1612409902.5477939
train: epoch 93, iter 4100, loss: 2.746978, top_1: 0.597500, top_k: 0.813438, samples/s: 2216.790 1612409914.096033
train: epoch 93, iter 4200, loss: 2.576116, top_1: 0.601914, top_k: 0.815937, samples/s: 2236.922 1612409925.540303
train: epoch 93, iter 4300, loss: 2.605618, top_1: 0.599297, top_k: 0.814141, samples/s: 2220.619 1612409937.0687408
train: epoch 93, iter 4400, loss: 2.601302, top_1: 0.599805, top_k: 0.817617, samples/s: 2216.436 1612409948.6187987
train: epoch 93, iter 4500, loss: 2.577971, top_1: 0.596914, top_k: 0.815234, samples/s: 2244.590 1612409960.0240192
train: epoch 93, iter 4600, loss: 2.529905, top_1: 0.602656, top_k: 0.816719, samples/s: 2236.818 1612409971.468866
train: epoch 93, iter 4700, loss: 2.544532, top_1: 0.598086, top_k: 0.813711, samples/s: 2235.941 1612409982.9180706
train: epoch 93, iter 4800, loss: 2.507028, top_1: 0.598437, top_k: 0.817031, samples/s: 2218.527 1612409994.4572752
train: epoch 93, iter 4900, loss: 2.714710, top_1: 0.596289, top_k: 0.813047, samples/s: 2220.733 1612410005.9849946
train: epoch 93, iter 5000, loss: 2.761386, top_1: 0.606563, top_k: 0.820664, samples/s: 2250.262 1612410017.3614402
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_93.
validation: epoch 93, iter 195, top_1: 0.641266, top_k: 0.859195, samples/s: 2920.858 1612410034.8006527
train: epoch 94, iter 100, loss: 2.771284, top_1: 0.605781, top_k: 0.821094, samples/s: 2238.664 1612410061.9720662
train: epoch 94, iter 200, loss: 2.703494, top_1: 0.610508, top_k: 0.820312, samples/s: 2252.265 1612410073.3383305
train: epoch 94, iter 300, loss: 2.705960, top_1: 0.607070, top_k: 0.818320, samples/s: 2219.367 1612410084.8731527
train: epoch 94, iter 400, loss: 2.547712, top_1: 0.612266, top_k: 0.821719, samples/s: 2278.099 1612410096.110635
train: epoch 94, iter 500, loss: 2.883375, top_1: 0.604883, top_k: 0.821094, samples/s: 2251.635 1612410107.480105
train: epoch 94, iter 600, loss: 2.587351, top_1: 0.611953, top_k: 0.826562, samples/s: 2243.474 1612410118.8909862
train: epoch 94, iter 700, loss: 2.744273, top_1: 0.610195, top_k: 0.821328, samples/s: 2263.841 1612410130.199205
train: epoch 94, iter 800, loss: 2.710899, top_1: 0.608086, top_k: 0.821172, samples/s: 2229.974 1612410141.6791544
train: epoch 94, iter 900, loss: 2.496401, top_1: 0.612734, top_k: 0.822617, samples/s: 2226.738 1612410153.1757402
train: epoch 94, iter 1000, loss: 2.568627, top_1: 0.615352, top_k: 0.824727, samples/s: 2231.567 1612410164.6475642
train: epoch 94, iter 1100, loss: 2.721505, top_1: 0.604961, top_k: 0.820586, samples/s: 2219.890 1612410176.1796622
train: epoch 94, iter 1200, loss: 2.743021, top_1: 0.604531, top_k: 0.820547, samples/s: 2246.942 1612410187.5729084
train: epoch 94, iter 1300, loss: 2.675111, top_1: 0.599531, top_k: 0.812070, samples/s: 2234.589 1612410199.0292335
train: epoch 94, iter 1400, loss: 2.682881, top_1: 0.604727, top_k: 0.818633, samples/s: 2214.797 1612410210.5877721
train: epoch 94, iter 1500, loss: 2.764057, top_1: 0.610977, top_k: 0.823008, samples/s: 2243.225 1612410221.999939
train: epoch 94, iter 1600, loss: 2.729732, top_1: 0.602734, top_k: 0.821133, samples/s: 2235.993 1612410233.4489753
train: epoch 94, iter 1700, loss: 2.813491, top_1: 0.599922, top_k: 0.813945, samples/s: 2210.063 1612410245.0323718
train: epoch 94, iter 1800, loss: 2.639573, top_1: 0.607148, top_k: 0.819766, samples/s: 2223.075 1612410256.547962
train: epoch 94, iter 1900, loss: 2.593129, top_1: 0.601055, top_k: 0.816445, samples/s: 2223.547 1612410268.061071
train: epoch 94, iter 2000, loss: 2.563224, top_1: 0.603984, top_k: 0.817813, samples/s: 2227.535 1612410279.5536273
train: epoch 94, iter 2100, loss: 2.647209, top_1: 0.596719, top_k: 0.816211, samples/s: 2243.611 1612410290.9637825
train: epoch 94, iter 2200, loss: 2.506890, top_1: 0.599414, top_k: 0.817539, samples/s: 2224.607 1612410302.471458
train: epoch 94, iter 2300, loss: 2.638461, top_1: 0.601367, top_k: 0.821602, samples/s: 2212.545 1612410314.0418663
train: epoch 94, iter 2400, loss: 2.628612, top_1: 0.609102, top_k: 0.823008, samples/s: 2243.148 1612410325.4548056
train: epoch 94, iter 2500, loss: 2.650947, top_1: 0.607812, top_k: 0.819258, samples/s: 2233.382 1612410336.9167876
train: epoch 94, iter 2600, loss: 2.548756, top_1: 0.604023, top_k: 0.814688, samples/s: 2239.300 1612410348.3489656
train: epoch 94, iter 2700, loss: 2.594983, top_1: 0.603594, top_k: 0.821133, samples/s: 2230.310 1612410359.8271558
train: epoch 94, iter 2800, loss: 2.568006, top_1: 0.604805, top_k: 0.813086, samples/s: 2214.640 1612410371.3869479
train: epoch 94, iter 2900, loss: 2.744616, top_1: 0.603437, top_k: 0.817461, samples/s: 2236.409 1612410382.8335767
train: epoch 94, iter 3000, loss: 2.647227, top_1: 0.600664, top_k: 0.814609, samples/s: 2224.414 1612410394.3421545
train: epoch 94, iter 3100, loss: 2.786777, top_1: 0.595430, top_k: 0.812617, samples/s: 2242.600 1612410405.7575243
train: epoch 94, iter 3200, loss: 2.574433, top_1: 0.600898, top_k: 0.816250, samples/s: 2230.013 1612410417.2372458
train: epoch 94, iter 3300, loss: 2.610511, top_1: 0.601172, top_k: 0.815469, samples/s: 2220.950 1612410428.7639306
train: epoch 94, iter 3400, loss: 2.800671, top_1: 0.602695, top_k: 0.814688, samples/s: 2218.662 1612410440.3023224
train: epoch 94, iter 3500, loss: 2.467517, top_1: 0.601406, top_k: 0.816797, samples/s: 2207.502 1612410451.8991272
train: epoch 94, iter 3600, loss: 2.598819, top_1: 0.602266, top_k: 0.815234, samples/s: 2207.969 1612410463.4935553
train: epoch 94, iter 3700, loss: 2.682045, top_1: 0.595039, top_k: 0.815273, samples/s: 2239.102 1612410474.926657
train: epoch 94, iter 3800, loss: 2.646981, top_1: 0.600000, top_k: 0.811641, samples/s: 2222.167 1612410486.4469445
train: epoch 94, iter 3900, loss: 2.720799, top_1: 0.603359, top_k: 0.816133, samples/s: 2235.788 1612410497.8970923
train: epoch 94, iter 4000, loss: 2.671999, top_1: 0.596836, top_k: 0.813164, samples/s: 2233.693 1612410509.3579452
train: epoch 94, iter 4100, loss: 2.627550, top_1: 0.601445, top_k: 0.817148, samples/s: 2228.872 1612410520.843516
train: epoch 94, iter 4200, loss: 2.764666, top_1: 0.604531, top_k: 0.816758, samples/s: 2218.528 1612410532.382691
train: epoch 94, iter 4300, loss: 2.578546, top_1: 0.602266, top_k: 0.815898, samples/s: 2213.503 1612410543.948236
train: epoch 94, iter 4400, loss: 2.728087, top_1: 0.598359, top_k: 0.815977, samples/s: 2268.237 1612410555.2343786
train: epoch 94, iter 4500, loss: 2.547392, top_1: 0.602773, top_k: 0.813164, samples/s: 2217.558 1612410566.7786088
train: epoch 94, iter 4600, loss: 2.556996, top_1: 0.599219, top_k: 0.816914, samples/s: 2235.827 1612410578.228502
train: epoch 94, iter 4700, loss: 2.717574, top_1: 0.600078, top_k: 0.818164, samples/s: 2233.226 1612410589.6917603
train: epoch 94, iter 4800, loss: 2.630799, top_1: 0.601250, top_k: 0.814453, samples/s: 2230.109 1612410601.1709588
train: epoch 94, iter 4900, loss: 2.724461, top_1: 0.598867, top_k: 0.817891, samples/s: 2227.051 1612410612.6660197
train: epoch 94, iter 5000, loss: 2.586093, top_1: 0.608281, top_k: 0.818359, samples/s: 2225.400 1612410624.16957
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_94.
validation: epoch 94, iter 195, top_1: 0.642047, top_k: 0.861418, samples/s: 2879.412 1612410641.85242
train: epoch 95, iter 100, loss: 2.689984, top_1: 0.617422, top_k: 0.829453, samples/s: 2244.003 1612410669.0456192
train: epoch 95, iter 200, loss: 2.868724, top_1: 0.610039, top_k: 0.824922, samples/s: 2250.091 1612410680.423053
train: epoch 95, iter 300, loss: 2.662848, top_1: 0.614141, top_k: 0.827031, samples/s: 2261.207 1612410691.7443695
train: epoch 95, iter 400, loss: 2.758240, top_1: 0.610664, top_k: 0.822031, samples/s: 2255.290 1612410703.095413
train: epoch 95, iter 500, loss: 2.499230, top_1: 0.614023, top_k: 0.823477, samples/s: 2246.262 1612410714.4921646
train: epoch 95, iter 600, loss: 2.552553, top_1: 0.611367, top_k: 0.820391, samples/s: 2245.496 1612410725.8927338
train: epoch 95, iter 700, loss: 2.531850, top_1: 0.611953, top_k: 0.823359, samples/s: 2247.152 1612410737.28492
train: epoch 95, iter 800, loss: 2.567650, top_1: 0.606055, top_k: 0.822305, samples/s: 2221.695 1612410748.8076398
train: epoch 95, iter 900, loss: 2.751326, top_1: 0.606484, top_k: 0.820508, samples/s: 2227.951 1612410760.2980413
train: epoch 95, iter 1000, loss: 2.636887, top_1: 0.607695, top_k: 0.823203, samples/s: 2208.679 1612410771.888663
train: epoch 95, iter 1100, loss: 2.671942, top_1: 0.605156, top_k: 0.820195, samples/s: 2228.386 1612410783.3768592
train: epoch 95, iter 1200, loss: 2.808283, top_1: 0.610898, top_k: 0.820195, samples/s: 2220.901 1612410794.9036617
train: epoch 95, iter 1300, loss: 2.839045, top_1: 0.607187, top_k: 0.819414, samples/s: 2243.569 1612410806.3141913
train: epoch 95, iter 1400, loss: 2.736100, top_1: 0.602891, top_k: 0.823086, samples/s: 2233.985 1612410817.7734604
train: epoch 95, iter 1500, loss: 2.595484, top_1: 0.604336, top_k: 0.817969, samples/s: 2231.646 1612410829.2447617
train: epoch 95, iter 1600, loss: 2.707151, top_1: 0.603828, top_k: 0.816836, samples/s: 2223.728 1612410840.7569408
train: epoch 95, iter 1700, loss: 2.671619, top_1: 0.604805, top_k: 0.820000, samples/s: 2225.702 1612410852.2589881
train: epoch 95, iter 1800, loss: 2.874459, top_1: 0.608086, top_k: 0.819922, samples/s: 2213.765 1612410863.822955
train: epoch 95, iter 1900, loss: 2.516526, top_1: 0.608008, top_k: 0.823672, samples/s: 2220.730 1612410875.3506753
train: epoch 95, iter 2000, loss: 2.637133, top_1: 0.598477, top_k: 0.817539, samples/s: 2195.274 1612410887.0122483
train: epoch 95, iter 2100, loss: 2.559166, top_1: 0.611211, top_k: 0.821992, samples/s: 2221.429 1612410898.536213
train: epoch 95, iter 2200, loss: 2.618497, top_1: 0.611367, top_k: 0.824063, samples/s: 2229.852 1612410910.0168412
train: epoch 95, iter 2300, loss: 2.526120, top_1: 0.608203, top_k: 0.821250, samples/s: 2240.769 1612410921.441469
train: epoch 95, iter 2400, loss: 2.581237, top_1: 0.607891, top_k: 0.823008, samples/s: 2234.271 1612410932.8993444
train: epoch 95, iter 2500, loss: 2.838332, top_1: 0.603320, top_k: 0.820430, samples/s: 2218.805 1612410944.4370654
train: epoch 95, iter 2600, loss: 2.690215, top_1: 0.602500, top_k: 0.818633, samples/s: 2221.240 1612410955.9623678
train: epoch 95, iter 2700, loss: 2.750131, top_1: 0.605586, top_k: 0.816406, samples/s: 2233.762 1612410967.4226618
train: epoch 95, iter 2800, loss: 2.728676, top_1: 0.602617, top_k: 0.821094, samples/s: 2233.567 1612410978.8841827
train: epoch 95, iter 2900, loss: 2.748299, top_1: 0.603867, top_k: 0.814844, samples/s: 2235.771 1612410990.3343203
train: epoch 95, iter 3000, loss: 2.716039, top_1: 0.600742, top_k: 0.816914, samples/s: 2212.214 1612411001.9064353
train: epoch 95, iter 3100, loss: 2.586865, top_1: 0.609844, top_k: 0.821172, samples/s: 2245.784 1612411013.305632
train: epoch 95, iter 3200, loss: 2.528538, top_1: 0.608477, top_k: 0.816758, samples/s: 2228.844 1612411024.791359
train: epoch 95, iter 3300, loss: 2.595661, top_1: 0.602891, top_k: 0.818164, samples/s: 2236.539 1612411036.237642
train: epoch 95, iter 3400, loss: 2.732453, top_1: 0.599883, top_k: 0.814180, samples/s: 2239.545 1612411047.6686323
train: epoch 95, iter 3500, loss: 2.590219, top_1: 0.604141, top_k: 0.819727, samples/s: 2224.930 1612411059.1745603
train: epoch 95, iter 3600, loss: 2.694832, top_1: 0.604180, top_k: 0.816328, samples/s: 2223.715 1612411070.6867516
train: epoch 95, iter 3700, loss: 2.833584, top_1: 0.597656, top_k: 0.816484, samples/s: 2239.908 1612411082.1158075
train: epoch 95, iter 3800, loss: 2.696039, top_1: 0.601328, top_k: 0.819688, samples/s: 2236.304 1612411093.563244
train: epoch 95, iter 3900, loss: 2.608974, top_1: 0.600820, top_k: 0.819805, samples/s: 2221.245 1612411105.0883965
train: epoch 95, iter 4000, loss: 2.816075, top_1: 0.596094, top_k: 0.816055, samples/s: 2225.213 1612411116.592898
train: epoch 95, iter 4100, loss: 2.727751, top_1: 0.603789, top_k: 0.818789, samples/s: 2240.215 1612411128.0203712
train: epoch 95, iter 4200, loss: 2.556037, top_1: 0.606719, top_k: 0.820469, samples/s: 2220.464 1612411139.5494194
train: epoch 95, iter 4300, loss: 2.666914, top_1: 0.604609, top_k: 0.819297, samples/s: 2221.318 1612411151.0741193
train: epoch 95, iter 4400, loss: 2.740301, top_1: 0.603125, top_k: 0.818828, samples/s: 2254.388 1612411162.4297984
train: epoch 95, iter 4500, loss: 2.639588, top_1: 0.594727, top_k: 0.814922, samples/s: 2215.728 1612411173.9835887
train: epoch 95, iter 4600, loss: 2.747753, top_1: 0.604727, top_k: 0.818164, samples/s: 2202.334 1612411185.6075382
train: epoch 95, iter 4700, loss: 2.685844, top_1: 0.602461, top_k: 0.818008, samples/s: 2247.892 1612411196.9960139
train: epoch 95, iter 4800, loss: 2.613373, top_1: 0.605039, top_k: 0.822852, samples/s: 2249.908 1612411208.3742309
train: epoch 95, iter 4900, loss: 2.757028, top_1: 0.602461, top_k: 0.816836, samples/s: 2222.196 1612411219.8944144
train: epoch 95, iter 5000, loss: 2.538764, top_1: 0.604062, top_k: 0.821758, samples/s: 2211.766 1612411231.4688265
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_95.
validation: epoch 95, iter 195, top_1: 0.647175, top_k: 0.863642, samples/s: 2966.246 1612411248.5951083
train: epoch 96, iter 100, loss: 2.450546, top_1: 0.611953, top_k: 0.829180, samples/s: 2248.040 1612411275.720175
train: epoch 96, iter 200, loss: 2.714433, top_1: 0.615469, top_k: 0.827891, samples/s: 2254.850 1612411287.0734005
train: epoch 96, iter 300, loss: 2.720345, top_1: 0.616055, top_k: 0.826406, samples/s: 2245.837 1612411298.472271
train: epoch 96, iter 400, loss: 2.709281, top_1: 0.609492, top_k: 0.820234, samples/s: 2238.602 1612411309.9079804
train: epoch 96, iter 500, loss: 2.636803, top_1: 0.612656, top_k: 0.824336, samples/s: 2267.395 1612411321.1985638
train: epoch 96, iter 600, loss: 2.599627, top_1: 0.605352, top_k: 0.819844, samples/s: 2236.733 1612411332.6437385
train: epoch 96, iter 700, loss: 2.771241, top_1: 0.609492, top_k: 0.821680, samples/s: 2250.347 1612411344.0198622
train: epoch 96, iter 800, loss: 2.637400, top_1: 0.610703, top_k: 0.823594, samples/s: 2245.325 1612411355.4212918
train: epoch 96, iter 900, loss: 2.630966, top_1: 0.609414, top_k: 0.823320, samples/s: 2218.888 1612411366.9585366
train: epoch 96, iter 1000, loss: 2.760419, top_1: 0.604609, top_k: 0.820625, samples/s: 2194.347 1612411378.6249146
train: epoch 96, iter 1100, loss: 2.583566, top_1: 0.607383, top_k: 0.820273, samples/s: 2192.118 1612411390.3030846
train: epoch 96, iter 1200, loss: 2.651459, top_1: 0.605664, top_k: 0.821836, samples/s: 2236.344 1612411401.7504022
train: epoch 96, iter 1300, loss: 2.704074, top_1: 0.618984, top_k: 0.830352, samples/s: 2225.649 1612411413.2526083
train: epoch 96, iter 1400, loss: 2.488421, top_1: 0.608711, top_k: 0.824023, samples/s: 2217.415 1612411424.7978954
train: epoch 96, iter 1500, loss: 2.595901, top_1: 0.606875, top_k: 0.824063, samples/s: 2211.396 1612411436.3740926
train: epoch 96, iter 1600, loss: 2.760190, top_1: 0.608477, top_k: 0.820820, samples/s: 2240.829 1612411447.7987332
train: epoch 96, iter 1700, loss: 2.637578, top_1: 0.610039, top_k: 0.824180, samples/s: 2215.081 1612411459.3555152
train: epoch 96, iter 1800, loss: 2.520519, top_1: 0.608789, top_k: 0.824258, samples/s: 2204.915 1612411470.965947
train: epoch 96, iter 1900, loss: 2.728826, top_1: 0.605859, top_k: 0.818164, samples/s: 2244.162 1612411482.3733194
train: epoch 96, iter 2000, loss: 2.695979, top_1: 0.603125, top_k: 0.817695, samples/s: 2239.701 1612411493.8033595
train: epoch 96, iter 2100, loss: 2.786136, top_1: 0.606563, top_k: 0.818555, samples/s: 2215.652 1612411505.3575325
train: epoch 96, iter 2200, loss: 2.814982, top_1: 0.612305, top_k: 0.821602, samples/s: 2230.314 1612411516.8357196
train: epoch 96, iter 2300, loss: 2.566916, top_1: 0.607812, top_k: 0.824336, samples/s: 2231.197 1612411528.3094494
train: epoch 96, iter 2400, loss: 2.700188, top_1: 0.605938, top_k: 0.818086, samples/s: 2221.568 1612411539.8327706
train: epoch 96, iter 2500, loss: 2.652950, top_1: 0.604023, top_k: 0.819688, samples/s: 2225.027 1612411551.3383374
train: epoch 96, iter 2600, loss: 2.626386, top_1: 0.606953, top_k: 0.820937, samples/s: 2213.164 1612411562.9054022
train: epoch 96, iter 2700, loss: 2.758532, top_1: 0.603047, top_k: 0.822070, samples/s: 2234.561 1612411574.3618062
train: epoch 96, iter 2800, loss: 2.591486, top_1: 0.607578, top_k: 0.824961, samples/s: 2233.194 1612411585.8252616
train: epoch 96, iter 2900, loss: 2.691092, top_1: 0.601211, top_k: 0.816562, samples/s: 2233.602 1612411597.2868648
train: epoch 96, iter 3000, loss: 2.568601, top_1: 0.605625, top_k: 0.816367, samples/s: 2213.889 1612411608.8498712
train: epoch 96, iter 3100, loss: 2.537866, top_1: 0.605586, top_k: 0.821406, samples/s: 2238.305 1612411620.2874591
train: epoch 96, iter 3200, loss: 2.770152, top_1: 0.606094, top_k: 0.819297, samples/s: 2224.217 1612411631.7967522
train: epoch 96, iter 3300, loss: 2.598356, top_1: 0.606055, top_k: 0.819922, samples/s: 2239.510 1612411643.227825
train: epoch 96, iter 3400, loss: 2.516586, top_1: 0.611719, top_k: 0.823398, samples/s: 2231.257 1612411654.7011907
train: epoch 96, iter 3500, loss: 2.537180, top_1: 0.607500, top_k: 0.822187, samples/s: 2220.445 1612411666.2304535
train: epoch 96, iter 3600, loss: 2.602109, top_1: 0.604688, top_k: 0.816602, samples/s: 2238.823 1612411677.6649835
train: epoch 96, iter 3700, loss: 2.640592, top_1: 0.605547, top_k: 0.817305, samples/s: 2216.683 1612411689.2137747
train: epoch 96, iter 3800, loss: 2.502445, top_1: 0.611055, top_k: 0.822891, samples/s: 2225.528 1612411700.7166615
train: epoch 96, iter 3900, loss: 2.675871, top_1: 0.601016, top_k: 0.818320, samples/s: 2222.729 1612411712.2340403
train: epoch 96, iter 4000, loss: 2.638941, top_1: 0.601250, top_k: 0.820234, samples/s: 2235.278 1612411723.6867607
train: epoch 96, iter 4100, loss: 2.628159, top_1: 0.611211, top_k: 0.820820, samples/s: 2236.290 1612411735.134303
train: epoch 96, iter 4200, loss: 2.724772, top_1: 0.598477, top_k: 0.817344, samples/s: 2225.477 1612411746.6375084
train: epoch 96, iter 4300, loss: 2.515319, top_1: 0.603008, top_k: 0.816562, samples/s: 2226.916 1612411758.133155
train: epoch 96, iter 4400, loss: 2.579241, top_1: 0.605469, top_k: 0.819336, samples/s: 2238.353 1612411769.570142
train: epoch 96, iter 4500, loss: 2.562946, top_1: 0.609375, top_k: 0.821289, samples/s: 2228.810 1612411781.0560896
train: epoch 96, iter 4600, loss: 2.710206, top_1: 0.600859, top_k: 0.820352, samples/s: 2240.902 1612411792.4800582
train: epoch 96, iter 4700, loss: 2.522778, top_1: 0.597305, top_k: 0.816016, samples/s: 2208.652 1612411804.0708244
train: epoch 96, iter 4800, loss: 2.754613, top_1: 0.604023, top_k: 0.818828, samples/s: 2249.193 1612411815.452736
train: epoch 96, iter 4900, loss: 2.749092, top_1: 0.601445, top_k: 0.816758, samples/s: 2235.703 1612411826.903238
train: epoch 96, iter 5000, loss: 2.547465, top_1: 0.615195, top_k: 0.824219, samples/s: 2230.655 1612411838.379678
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_96.
validation: epoch 96, iter 195, top_1: 0.652925, top_k: 0.866286, samples/s: 2903.046 1612411855.9965284
train: epoch 97, iter 100, loss: 2.285772, top_1: 0.613594, top_k: 0.829336, samples/s: 2236.687 1612411882.974461
train: epoch 97, iter 200, loss: 2.593482, top_1: 0.609219, top_k: 0.822539, samples/s: 2259.881 1612411894.302531
train: epoch 97, iter 300, loss: 2.454311, top_1: 0.609570, top_k: 0.821680, samples/s: 2256.449 1612411905.647696
train: epoch 97, iter 400, loss: 2.501891, top_1: 0.614531, top_k: 0.824805, samples/s: 2252.143 1612411917.0147161
train: epoch 97, iter 500, loss: 2.372037, top_1: 0.620703, top_k: 0.830391, samples/s: 2259.251 1612411928.345999
train: epoch 97, iter 600, loss: 2.586602, top_1: 0.611836, top_k: 0.827773, samples/s: 2249.472 1612411939.7263422
train: epoch 97, iter 700, loss: 2.477512, top_1: 0.617578, top_k: 0.825820, samples/s: 2202.808 1612411951.3478756
train: epoch 97, iter 800, loss: 2.797884, top_1: 0.611367, top_k: 0.826250, samples/s: 2231.587 1612411962.8195708
train: epoch 97, iter 900, loss: 2.504365, top_1: 0.616875, top_k: 0.825977, samples/s: 2226.153 1612411974.3191872
train: epoch 97, iter 1000, loss: 2.790580, top_1: 0.609297, top_k: 0.822969, samples/s: 2210.823 1612411985.898651
train: epoch 97, iter 1100, loss: 2.753098, top_1: 0.617344, top_k: 0.825703, samples/s: 2214.689 1612411997.457799
train: epoch 97, iter 1200, loss: 2.685578, top_1: 0.613555, top_k: 0.822969, samples/s: 2228.837 1612412008.9435856
train: epoch 97, iter 1300, loss: 2.620176, top_1: 0.611992, top_k: 0.827383, samples/s: 2215.373 1612412020.499199
train: epoch 97, iter 1400, loss: 2.809534, top_1: 0.610039, top_k: 0.822539, samples/s: 2225.984 1612412031.9997303
train: epoch 97, iter 1500, loss: 2.454860, top_1: 0.614961, top_k: 0.823242, samples/s: 2174.642 1612412043.7717838
train: epoch 97, iter 1600, loss: 2.530525, top_1: 0.609414, top_k: 0.821719, samples/s: 2197.773 1612412055.4199295
train: epoch 97, iter 1700, loss: 2.583371, top_1: 0.616211, top_k: 0.827422, samples/s: 2225.121 1612412066.9249752
train: epoch 97, iter 1800, loss: 2.542298, top_1: 0.618242, top_k: 0.826172, samples/s: 2216.010 1612412078.4772701
train: epoch 97, iter 1900, loss: 2.731806, top_1: 0.610703, top_k: 0.824063, samples/s: 2240.193 1612412089.9048085
train: epoch 97, iter 2000, loss: 2.704540, top_1: 0.614023, top_k: 0.824063, samples/s: 2221.092 1612412101.4306757
train: epoch 97, iter 2100, loss: 2.633248, top_1: 0.613203, top_k: 0.824414, samples/s: 2210.944 1612412113.0094318
train: epoch 97, iter 2200, loss: 2.801028, top_1: 0.614805, top_k: 0.826836, samples/s: 2225.472 1612412124.5126045
train: epoch 97, iter 2300, loss: 2.681742, top_1: 0.607773, top_k: 0.820234, samples/s: 2234.592 1612412135.968833
train: epoch 97, iter 2400, loss: 2.699297, top_1: 0.608555, top_k: 0.822109, samples/s: 2226.623 1612412147.4661043
train: epoch 97, iter 2500, loss: 2.740305, top_1: 0.613594, top_k: 0.824805, samples/s: 2237.402 1612412158.9079123
train: epoch 97, iter 2600, loss: 2.754884, top_1: 0.611094, top_k: 0.821367, samples/s: 2207.402 1612412170.5052578
train: epoch 97, iter 2700, loss: 2.746042, top_1: 0.616914, top_k: 0.824961, samples/s: 2227.748 1612412181.996723
train: epoch 97, iter 2800, loss: 2.422490, top_1: 0.606328, top_k: 0.817578, samples/s: 2224.080 1612412193.507096
train: epoch 97, iter 2900, loss: 2.614409, top_1: 0.610117, top_k: 0.821484, samples/s: 2222.630 1612412205.024947
train: epoch 97, iter 3000, loss: 2.859117, top_1: 0.607656, top_k: 0.822148, samples/s: 2223.106 1612412216.5404046
train: epoch 97, iter 3100, loss: 2.527404, top_1: 0.607852, top_k: 0.822461, samples/s: 2230.124 1612412228.0195446
train: epoch 97, iter 3200, loss: 2.560505, top_1: 0.601289, top_k: 0.822578, samples/s: 2230.169 1612412239.4984949
train: epoch 97, iter 3300, loss: 2.796917, top_1: 0.609805, top_k: 0.821289, samples/s: 2193.958 1612412251.1669052
train: epoch 97, iter 3400, loss: 2.753101, top_1: 0.604727, top_k: 0.820312, samples/s: 2246.666 1612412262.5615728
train: epoch 97, iter 3500, loss: 2.469314, top_1: 0.603008, top_k: 0.818945, samples/s: 2219.339 1612412274.0965822
train: epoch 97, iter 3600, loss: 2.526360, top_1: 0.608867, top_k: 0.814766, samples/s: 2223.927 1612412285.6077867
train: epoch 97, iter 3700, loss: 2.683069, top_1: 0.609023, top_k: 0.823594, samples/s: 2246.093 1612412297.0053437
train: epoch 97, iter 3800, loss: 2.618587, top_1: 0.607148, top_k: 0.822109, samples/s: 2231.783 1612412308.475927
train: epoch 97, iter 3900, loss: 2.650590, top_1: 0.610547, top_k: 0.824531, samples/s: 2216.448 1612412320.0259333
train: epoch 97, iter 4000, loss: 2.462123, top_1: 0.602539, top_k: 0.813516, samples/s: 2226.322 1612412331.5247233
train: epoch 97, iter 4100, loss: 2.777767, top_1: 0.602969, top_k: 0.818320, samples/s: 2238.316 1612412342.961916
train: epoch 97, iter 4200, loss: 2.545696, top_1: 0.604727, top_k: 0.820469, samples/s: 2227.198 1612412354.45629
train: epoch 97, iter 4300, loss: 2.818921, top_1: 0.604961, top_k: 0.821211, samples/s: 2241.258 1612412365.878364
train: epoch 97, iter 4400, loss: 2.594823, top_1: 0.610039, top_k: 0.821055, samples/s: 2230.966 1612412377.3531618
train: epoch 97, iter 4500, loss: 2.518117, top_1: 0.603242, top_k: 0.819727, samples/s: 2232.699 1612412388.8191366
train: epoch 97, iter 4600, loss: 2.845355, top_1: 0.608477, top_k: 0.822070, samples/s: 2228.938 1612412400.3044317
train: epoch 97, iter 4700, loss: 2.702127, top_1: 0.602812, top_k: 0.819609, samples/s: 2225.539 1612412411.807345
train: epoch 97, iter 4800, loss: 2.575276, top_1: 0.606641, top_k: 0.820898, samples/s: 2219.811 1612412423.339757
train: epoch 97, iter 4900, loss: 2.744923, top_1: 0.602031, top_k: 0.817539, samples/s: 2230.612 1612412434.8165972
train: epoch 97, iter 5000, loss: 2.538016, top_1: 0.608047, top_k: 0.823945, samples/s: 2237.823 1612412446.256089
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_97.
validation: epoch 97, iter 195, top_1: 0.651823, top_k: 0.866546, samples/s: 2895.065 1612412463.867599
train: epoch 98, iter 100, loss: 2.724145, top_1: 0.615078, top_k: 0.833672, samples/s: 2232.830 1612412490.9452326
train: epoch 98, iter 200, loss: 2.755801, top_1: 0.612539, top_k: 0.829063, samples/s: 2250.333 1612412502.3212883
train: epoch 98, iter 300, loss: 2.444020, top_1: 0.609727, top_k: 0.825000, samples/s: 2243.527 1612412513.7318869
train: epoch 98, iter 400, loss: 2.663841, top_1: 0.617656, top_k: 0.831289, samples/s: 2255.951 1612412525.079865
train: epoch 98, iter 500, loss: 2.589897, top_1: 0.611406, top_k: 0.824688, samples/s: 2232.131 1612412536.548621
train: epoch 98, iter 600, loss: 2.672044, top_1: 0.615430, top_k: 0.827305, samples/s: 2257.817 1612412547.8869412
train: epoch 98, iter 700, loss: 2.691609, top_1: 0.612969, top_k: 0.825078, samples/s: 2239.465 1612412559.318218
train: epoch 98, iter 800, loss: 2.617694, top_1: 0.613750, top_k: 0.824453, samples/s: 2243.955 1612412570.7267365
train: epoch 98, iter 900, loss: 2.664621, top_1: 0.615547, top_k: 0.827891, samples/s: 2233.300 1612412582.189501
train: epoch 98, iter 1000, loss: 2.468936, top_1: 0.609961, top_k: 0.824102, samples/s: 2222.293 1612412593.7091217
train: epoch 98, iter 1100, loss: 2.412834, top_1: 0.609102, top_k: 0.822187, samples/s: 2208.218 1612412605.3021865
train: epoch 98, iter 1200, loss: 2.697948, top_1: 0.611992, top_k: 0.826328, samples/s: 2216.740 1612412616.8506749
train: epoch 98, iter 1300, loss: 2.620463, top_1: 0.618164, top_k: 0.829531, samples/s: 2223.775 1612412628.3627403
train: epoch 98, iter 1400, loss: 2.717335, top_1: 0.618281, top_k: 0.825234, samples/s: 2231.424 1612412639.8351624
train: epoch 98, iter 1500, loss: 2.547400, top_1: 0.613086, top_k: 0.824648, samples/s: 2222.066 1612412651.3559778
train: epoch 98, iter 1600, loss: 2.658404, top_1: 0.612187, top_k: 0.822070, samples/s: 2224.605 1612412662.86365
train: epoch 98, iter 1700, loss: 2.493033, top_1: 0.611133, top_k: 0.824570, samples/s: 2239.488 1612412674.2948315
train: epoch 98, iter 1800, loss: 2.427872, top_1: 0.610781, top_k: 0.822695, samples/s: 2237.025 1612412685.7385523
train: epoch 98, iter 1900, loss: 2.606622, top_1: 0.618477, top_k: 0.825937, samples/s: 2232.174 1612412697.2072444
train: epoch 98, iter 2000, loss: 2.616897, top_1: 0.607266, top_k: 0.817773, samples/s: 2233.626 1612412708.668444
train: epoch 98, iter 2100, loss: 2.459023, top_1: 0.611172, top_k: 0.825430, samples/s: 2247.409 1612412720.0593617
train: epoch 98, iter 2200, loss: 2.562854, top_1: 0.613086, top_k: 0.822852, samples/s: 2245.221 1612412731.4612918
train: epoch 98, iter 2300, loss: 2.787588, top_1: 0.610273, top_k: 0.822539, samples/s: 2232.498 1612412742.9282494
train: epoch 98, iter 2400, loss: 2.679977, top_1: 0.612695, top_k: 0.823945, samples/s: 2247.592 1612412754.3182173
train: epoch 98, iter 2500, loss: 2.549962, top_1: 0.608398, top_k: 0.821914, samples/s: 2218.855 1612412765.855729
train: epoch 98, iter 2600, loss: 2.545979, top_1: 0.612461, top_k: 0.823984, samples/s: 2235.600 1612412777.3067477
train: epoch 98, iter 2700, loss: 2.624073, top_1: 0.610430, top_k: 0.822461, samples/s: 2261.409 1612412788.6271253
train: epoch 98, iter 2800, loss: 2.664112, top_1: 0.616016, top_k: 0.823398, samples/s: 2246.038 1612412800.02505
train: epoch 98, iter 2900, loss: 2.754470, top_1: 0.610430, top_k: 0.820898, samples/s: 2238.125 1612412811.4632127
train: epoch 98, iter 3000, loss: 2.640632, top_1: 0.605938, top_k: 0.819297, samples/s: 2241.317 1612412822.8850448
train: epoch 98, iter 3100, loss: 2.550777, top_1: 0.610508, top_k: 0.823711, samples/s: 2246.267 1612412834.2816622
train: epoch 98, iter 3200, loss: 2.679417, top_1: 0.607461, top_k: 0.825547, samples/s: 2237.758 1612412845.721734
train: epoch 98, iter 3300, loss: 2.455849, top_1: 0.613711, top_k: 0.824609, samples/s: 2235.462 1612412857.173503
train: epoch 98, iter 3400, loss: 2.568875, top_1: 0.613984, top_k: 0.826523, samples/s: 2246.678 1612412868.568133
train: epoch 98, iter 3500, loss: 2.560552, top_1: 0.608711, top_k: 0.818164, samples/s: 2241.752 1612412879.987651
train: epoch 98, iter 3600, loss: 2.781129, top_1: 0.606797, top_k: 0.819805, samples/s: 2223.210 1612412891.502685
train: epoch 98, iter 3700, loss: 2.600895, top_1: 0.606797, top_k: 0.824609, samples/s: 2259.286 1612412902.8335896
train: epoch 98, iter 3800, loss: 2.550715, top_1: 0.607031, top_k: 0.821914, samples/s: 2247.549 1612412914.2237766
train: epoch 98, iter 3900, loss: 2.686397, top_1: 0.610391, top_k: 0.822969, samples/s: 2248.586 1612412925.6087284
train: epoch 98, iter 4000, loss: 2.497995, top_1: 0.605508, top_k: 0.822656, samples/s: 2241.760 1612412937.0283847
train: epoch 98, iter 4100, loss: 2.602869, top_1: 0.608672, top_k: 0.819297, samples/s: 2235.166 1612412948.4816358
train: epoch 98, iter 4200, loss: 2.582530, top_1: 0.607344, top_k: 0.822344, samples/s: 2256.664 1612412959.8258495
train: epoch 98, iter 4300, loss: 2.715995, top_1: 0.611484, top_k: 0.824414, samples/s: 2252.320 1612412971.1918507
train: epoch 98, iter 4400, loss: 2.892472, top_1: 0.607148, top_k: 0.817227, samples/s: 2241.054 1612412982.6151366
train: epoch 98, iter 4500, loss: 2.566231, top_1: 0.610820, top_k: 0.827539, samples/s: 2236.256 1612412994.062734
train: epoch 98, iter 4600, loss: 2.603014, top_1: 0.608164, top_k: 0.819844, samples/s: 2230.878 1612413005.5380394
train: epoch 98, iter 4700, loss: 2.750082, top_1: 0.603437, top_k: 0.818438, samples/s: 2239.765 1612413016.9678664
train: epoch 98, iter 4800, loss: 2.568866, top_1: 0.612891, top_k: 0.822344, samples/s: 2172.296 1612413028.75288
train: epoch 98, iter 4900, loss: 2.829259, top_1: 0.605781, top_k: 0.818945, samples/s: 2267.279 1612413040.043669
train: epoch 98, iter 5000, loss: 2.461448, top_1: 0.616133, top_k: 0.826367, samples/s: 2248.640 1612413051.428336
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_98.
validation: epoch 98, iter 195, top_1: 0.652784, top_k: 0.866667, samples/s: 2900.127 1612413068.9970434
train: epoch 99, iter 100, loss: 2.482427, top_1: 0.623086, top_k: 0.830937, samples/s: 2241.436 1612413096.9552643
train: epoch 99, iter 200, loss: 2.558484, top_1: 0.623125, top_k: 0.832148, samples/s: 2249.468 1612413108.335688
train: epoch 99, iter 300, loss: 2.557333, top_1: 0.624180, top_k: 0.831602, samples/s: 2181.348 1612413120.0715604
train: epoch 99, iter 400, loss: 2.543836, top_1: 0.616758, top_k: 0.827031, samples/s: 2264.685 1612413131.375451
train: epoch 99, iter 500, loss: 2.505875, top_1: 0.612031, top_k: 0.823242, samples/s: 2253.167 1612413142.7372522
train: epoch 99, iter 600, loss: 2.576361, top_1: 0.617227, top_k: 0.827422, samples/s: 2233.606 1612413154.1984832
train: epoch 99, iter 700, loss: 2.501806, top_1: 0.621289, top_k: 0.829688, samples/s: 2258.402 1612413165.5340836
train: epoch 99, iter 800, loss: 2.566764, top_1: 0.611719, top_k: 0.826133, samples/s: 2227.697 1612413177.0256224
train: epoch 99, iter 900, loss: 2.680602, top_1: 0.617891, top_k: 0.832578, samples/s: 2246.084 1612413188.4232423
train: epoch 99, iter 1000, loss: 2.572303, top_1: 0.618164, top_k: 0.830313, samples/s: 2222.869 1612413199.9399202
train: epoch 99, iter 1100, loss: 2.494871, top_1: 0.619961, top_k: 0.829922, samples/s: 2213.601 1612413211.5047898
train: epoch 99, iter 1200, loss: 2.732155, top_1: 0.617461, top_k: 0.825195, samples/s: 2218.514 1612413223.0440054
train: epoch 99, iter 1300, loss: 2.503805, top_1: 0.611953, top_k: 0.823633, samples/s: 2204.808 1612413234.655242
train: epoch 99, iter 1400, loss: 2.448644, top_1: 0.623164, top_k: 0.831719, samples/s: 2224.914 1612413246.161108
train: epoch 99, iter 1500, loss: 2.569799, top_1: 0.613086, top_k: 0.824570, samples/s: 2247.076 1612413257.5537012
train: epoch 99, iter 1600, loss: 2.741119, top_1: 0.610625, top_k: 0.824805, samples/s: 2222.836 1612413269.0704522
train: epoch 99, iter 1700, loss: 2.640476, top_1: 0.611914, top_k: 0.823672, samples/s: 2233.005 1612413280.534917
train: epoch 99, iter 1800, loss: 2.852305, top_1: 0.610469, top_k: 0.825977, samples/s: 2226.146 1612413292.034537
train: epoch 99, iter 1900, loss: 2.503350, top_1: 0.611953, top_k: 0.826523, samples/s: 2239.812 1612413303.4641566
train: epoch 99, iter 2000, loss: 2.622811, top_1: 0.611250, top_k: 0.827109, samples/s: 2235.543 1612413314.9153688
train: epoch 99, iter 2100, loss: 2.489003, top_1: 0.614453, top_k: 0.823398, samples/s: 2212.621 1612413326.4854684
train: epoch 99, iter 2200, loss: 2.664789, top_1: 0.615313, top_k: 0.825156, samples/s: 2244.572 1612413337.8907542
train: epoch 99, iter 2300, loss: 2.548566, top_1: 0.617734, top_k: 0.824648, samples/s: 2217.189 1612413349.4368336
train: epoch 99, iter 2400, loss: 2.534591, top_1: 0.614922, top_k: 0.827148, samples/s: 2206.781 1612413361.0374906
train: epoch 99, iter 2500, loss: 2.527081, top_1: 0.615313, top_k: 0.826641, samples/s: 2238.150 1612413372.4754725
train: epoch 99, iter 2600, loss: 2.576534, top_1: 0.612695, top_k: 0.824414, samples/s: 2233.528 1612413383.9372907
train: epoch 99, iter 2700, loss: 2.656836, top_1: 0.610469, top_k: 0.824297, samples/s: 2226.161 1612413395.436823
train: epoch 99, iter 2800, loss: 2.645962, top_1: 0.615117, top_k: 0.824766, samples/s: 2227.878 1612413406.9275517
train: epoch 99, iter 2900, loss: 2.434416, top_1: 0.616211, top_k: 0.823711, samples/s: 2232.663 1612413418.3937392
train: epoch 99, iter 3000, loss: 2.547779, top_1: 0.608789, top_k: 0.822422, samples/s: 2223.908 1612413429.9049125
train: epoch 99, iter 3100, loss: 2.551480, top_1: 0.605664, top_k: 0.820234, samples/s: 2234.067 1612413441.3638713
train: epoch 99, iter 3200, loss: 2.729510, top_1: 0.607227, top_k: 0.824688, samples/s: 2226.829 1612413452.8600056
train: epoch 99, iter 3300, loss: 2.722609, top_1: 0.610508, top_k: 0.820820, samples/s: 2199.527 1612413464.498868
train: epoch 99, iter 3400, loss: 2.658422, top_1: 0.615820, top_k: 0.826250, samples/s: 2246.286 1612413475.895508
train: epoch 99, iter 3500, loss: 2.614807, top_1: 0.603711, top_k: 0.819258, samples/s: 2225.523 1612413487.3983686
train: epoch 99, iter 3600, loss: 2.726866, top_1: 0.610859, top_k: 0.824414, samples/s: 2227.655 1612413498.8902988
train: epoch 99, iter 3700, loss: 2.676768, top_1: 0.610625, top_k: 0.823516, samples/s: 2238.568 1612413510.3262355
train: epoch 99, iter 3800, loss: 2.628784, top_1: 0.613086, top_k: 0.825234, samples/s: 2241.667 1612413521.7462394
train: epoch 99, iter 3900, loss: 2.536797, top_1: 0.608281, top_k: 0.822461, samples/s: 2201.291 1612413533.375765
train: epoch 99, iter 4000, loss: 2.644504, top_1: 0.609141, top_k: 0.820703, samples/s: 2252.033 1612413544.7434936
train: epoch 99, iter 4100, loss: 2.551396, top_1: 0.610039, top_k: 0.823594, samples/s: 2224.991 1612413556.2489433
train: epoch 99, iter 4200, loss: 2.502726, top_1: 0.614844, top_k: 0.822500, samples/s: 2246.630 1612413567.6438076
train: epoch 99, iter 4300, loss: 2.598868, top_1: 0.613281, top_k: 0.819883, samples/s: 2228.242 1612413579.132668
train: epoch 99, iter 4400, loss: 2.665384, top_1: 0.611602, top_k: 0.823125, samples/s: 2247.239 1612413590.524423
train: epoch 99, iter 4500, loss: 2.705999, top_1: 0.613398, top_k: 0.827187, samples/s: 2240.100 1612413601.9524786
train: epoch 99, iter 4600, loss: 2.694122, top_1: 0.611563, top_k: 0.821523, samples/s: 2240.701 1612413613.3774824
train: epoch 99, iter 4700, loss: 2.441974, top_1: 0.615391, top_k: 0.826289, samples/s: 2225.550 1612413624.8802605
train: epoch 99, iter 4800, loss: 2.599039, top_1: 0.610820, top_k: 0.823984, samples/s: 2210.167 1612413636.4630861
train: epoch 99, iter 4900, loss: 2.622270, top_1: 0.611289, top_k: 0.823711, samples/s: 2238.614 1612413647.8995988
train: epoch 99, iter 5000, loss: 2.460809, top_1: 0.617969, top_k: 0.828164, samples/s: 2223.699 1612413659.411221
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_99.
validation: epoch 99, iter 195, top_1: 0.655709, top_k: 0.867468, samples/s: 2850.624 1612413677.2587507
train: epoch 100, iter 100, loss: 2.465020, top_1: 0.614414, top_k: 0.826484, samples/s: 2166.297 1612413705.1330962
train: epoch 100, iter 200, loss: 2.660100, top_1: 0.620000, top_k: 0.833828, samples/s: 2246.758 1612413716.5271866
train: epoch 100, iter 300, loss: 2.671031, top_1: 0.622266, top_k: 0.833906, samples/s: 2248.107 1612413727.9145274
train: epoch 100, iter 400, loss: 2.547683, top_1: 0.620898, top_k: 0.828047, samples/s: 2251.210 1612413739.2862034
train: epoch 100, iter 500, loss: 2.590386, top_1: 0.619648, top_k: 0.830391, samples/s: 2246.461 1612413750.6818986
train: epoch 100, iter 600, loss: 2.483980, top_1: 0.618516, top_k: 0.829258, samples/s: 2256.464 1612413762.0271626
train: epoch 100, iter 700, loss: 2.512587, top_1: 0.623320, top_k: 0.832617, samples/s: 2223.149 1612413773.542257
train: epoch 100, iter 800, loss: 2.498332, top_1: 0.619180, top_k: 0.830078, samples/s: 2234.246 1612413785.000236
train: epoch 100, iter 900, loss: 2.684690, top_1: 0.619180, top_k: 0.827187, samples/s: 2221.721 1612413796.5228355
train: epoch 100, iter 1000, loss: 2.652575, top_1: 0.622422, top_k: 0.832109, samples/s: 2218.540 1612413808.0619726
train: epoch 100, iter 1100, loss: 2.572916, top_1: 0.618086, top_k: 0.827930, samples/s: 2208.539 1612413819.65333
train: epoch 100, iter 1200, loss: 2.703889, top_1: 0.614844, top_k: 0.824805, samples/s: 2209.872 1612413831.2377303
train: epoch 100, iter 1300, loss: 2.482595, top_1: 0.617344, top_k: 0.828086, samples/s: 2218.136 1612413842.7789335
train: epoch 100, iter 1400, loss: 2.436388, top_1: 0.616875, top_k: 0.829609, samples/s: 2210.801 1612413854.3584478
train: epoch 100, iter 1500, loss: 2.728321, top_1: 0.616484, top_k: 0.828359, samples/s: 2211.991 1612413865.9318492
train: epoch 100, iter 1600, loss: 2.643665, top_1: 0.621602, top_k: 0.829844, samples/s: 2211.742 1612413877.506401
train: epoch 100, iter 1700, loss: 2.586434, top_1: 0.614297, top_k: 0.831680, samples/s: 2232.030 1612413888.9756925
train: epoch 100, iter 1800, loss: 2.532739, top_1: 0.621445, top_k: 0.830898, samples/s: 2232.161 1612413900.4443936
train: epoch 100, iter 1900, loss: 2.581160, top_1: 0.619727, top_k: 0.825078, samples/s: 2209.021 1612413912.033309
train: epoch 100, iter 2000, loss: 2.705818, top_1: 0.616680, top_k: 0.830586, samples/s: 2213.120 1612413923.6006508
train: epoch 100, iter 2100, loss: 2.889013, top_1: 0.615898, top_k: 0.825078, samples/s: 2226.217 1612413935.0999525
train: epoch 100, iter 2200, loss: 2.451643, top_1: 0.613867, top_k: 0.829063, samples/s: 2235.481 1612413946.5517116
train: epoch 100, iter 2300, loss: 2.651614, top_1: 0.615234, top_k: 0.826328, samples/s: 2230.189 1612413958.0305905
train: epoch 100, iter 2400, loss: 2.422222, top_1: 0.621563, top_k: 0.829805, samples/s: 2209.456 1612413969.6170814
train: epoch 100, iter 2500, loss: 2.619046, top_1: 0.617773, top_k: 0.827969, samples/s: 2233.242 1612413981.080273
train: epoch 100, iter 2600, loss: 2.463497, top_1: 0.617500, top_k: 0.827461, samples/s: 2222.693 1612413992.597773
train: epoch 100, iter 2700, loss: 2.694973, top_1: 0.617656, top_k: 0.828086, samples/s: 2215.427 1612414004.1532018
train: epoch 100, iter 2800, loss: 2.703545, top_1: 0.611836, top_k: 0.823086, samples/s: 2234.111 1612414015.611785
train: epoch 100, iter 2900, loss: 2.726860, top_1: 0.608320, top_k: 0.822422, samples/s: 2216.867 1612414027.1596901
train: epoch 100, iter 3000, loss: 2.927186, top_1: 0.617422, top_k: 0.826758, samples/s: 2230.621 1612414038.6362386
train: epoch 100, iter 3100, loss: 2.513223, top_1: 0.609180, top_k: 0.825430, samples/s: 2222.921 1612414050.1527107
train: epoch 100, iter 3200, loss: 2.325426, top_1: 0.616758, top_k: 0.828867, samples/s: 2242.930 1612414061.5663083
train: epoch 100, iter 3300, loss: 2.741651, top_1: 0.612578, top_k: 0.826406, samples/s: 2239.452 1612414072.9976258
train: epoch 100, iter 3400, loss: 2.708098, top_1: 0.619375, top_k: 0.828984, samples/s: 2228.601 1612414084.4846776
train: epoch 100, iter 3500, loss: 2.597752, top_1: 0.619336, top_k: 0.824414, samples/s: 2222.752 1612414096.001909
train: epoch 100, iter 3600, loss: 2.468537, top_1: 0.618281, top_k: 0.826133, samples/s: 2234.857 1612414107.4568064
train: epoch 100, iter 3700, loss: 2.777548, top_1: 0.614023, top_k: 0.827734, samples/s: 2242.013 1612414118.8751001
train: epoch 100, iter 3800, loss: 2.431265, top_1: 0.614844, top_k: 0.825156, samples/s: 2216.172 1612414130.4265523
train: epoch 100, iter 3900, loss: 2.712641, top_1: 0.612539, top_k: 0.824219, samples/s: 2217.888 1612414141.9690576
train: epoch 100, iter 4000, loss: 2.705595, top_1: 0.616523, top_k: 0.827891, samples/s: 2227.192 1612414153.4633613
train: epoch 100, iter 4100, loss: 2.631162, top_1: 0.611758, top_k: 0.825273, samples/s: 2232.770 1612414164.929015
train: epoch 100, iter 4200, loss: 2.665538, top_1: 0.608750, top_k: 0.821133, samples/s: 2226.387 1612414176.4273927
train: epoch 100, iter 4300, loss: 2.610434, top_1: 0.612734, top_k: 0.823320, samples/s: 2224.042 1612414187.9379728
train: epoch 100, iter 4400, loss: 2.510922, top_1: 0.613789, top_k: 0.824141, samples/s: 2239.570 1612414199.3687565
train: epoch 100, iter 4500, loss: 2.383865, top_1: 0.610820, top_k: 0.824961, samples/s: 2228.500 1612414210.8562837
train: epoch 100, iter 4600, loss: 2.434484, top_1: 0.608789, top_k: 0.822500, samples/s: 2220.650 1612414222.3844147
train: epoch 100, iter 4700, loss: 2.730949, top_1: 0.610352, top_k: 0.824609, samples/s: 2223.667 1612414233.8969314
train: epoch 100, iter 4800, loss: 2.781786, top_1: 0.613516, top_k: 0.822852, samples/s: 2237.202 1612414245.3397949
train: epoch 100, iter 4900, loss: 2.742036, top_1: 0.618633, top_k: 0.825391, samples/s: 2232.635 1612414256.8060794
train: epoch 100, iter 5000, loss: 2.506925, top_1: 0.618750, top_k: 0.828750, samples/s: 2227.714 1612414268.2977705
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_100.
validation: epoch 100, iter 195, top_1: 0.655248, top_k: 0.868209, samples/s: 3008.757 1612414285.2426083
train: epoch 101, iter 100, loss: 2.676451, top_1: 0.625898, top_k: 0.837187, samples/s: 2243.088 1612414312.2579505
train: epoch 101, iter 200, loss: 2.431135, top_1: 0.626563, top_k: 0.833359, samples/s: 2244.914 1612414323.661486
train: epoch 101, iter 300, loss: 2.449454, top_1: 0.627031, top_k: 0.835938, samples/s: 2257.004 1612414335.003932
train: epoch 101, iter 400, loss: 2.639688, top_1: 0.622188, top_k: 0.833945, samples/s: 2245.834 1612414346.4028025
train: epoch 101, iter 500, loss: 2.507074, top_1: 0.619219, top_k: 0.829219, samples/s: 2247.967 1612414357.7909157
train: epoch 101, iter 600, loss: 2.562754, top_1: 0.626523, top_k: 0.836016, samples/s: 2254.294 1612414369.1470456
train: epoch 101, iter 700, loss: 2.584605, top_1: 0.622070, top_k: 0.830234, samples/s: 2232.593 1612414380.613471
train: epoch 101, iter 800, loss: 2.653417, top_1: 0.613906, top_k: 0.826055, samples/s: 2211.921 1612414392.187266
train: epoch 101, iter 900, loss: 2.410617, top_1: 0.619297, top_k: 0.828516, samples/s: 2230.663 1612414403.663558
train: epoch 101, iter 1000, loss: 2.632730, top_1: 0.618867, top_k: 0.828555, samples/s: 2227.839 1612414415.154507
train: epoch 101, iter 1100, loss: 2.609148, top_1: 0.620898, top_k: 0.829180, samples/s: 2222.082 1612414426.675258
train: epoch 101, iter 1200, loss: 2.457494, top_1: 0.612109, top_k: 0.826836, samples/s: 2231.680 1612414438.1464248
train: epoch 101, iter 1300, loss: 2.636287, top_1: 0.614844, top_k: 0.825977, samples/s: 2233.406 1612414449.6087737
train: epoch 101, iter 1400, loss: 2.525201, top_1: 0.620625, top_k: 0.831719, samples/s: 2186.087 1612414461.319124
train: epoch 101, iter 1500, loss: 2.566487, top_1: 0.621914, top_k: 0.827422, samples/s: 2211.305 1612414472.896009
train: epoch 101, iter 1600, loss: 2.513468, top_1: 0.618828, top_k: 0.830391, samples/s: 2227.698 1612414484.3878121
train: epoch 101, iter 1700, loss: 2.506454, top_1: 0.618555, top_k: 0.829258, samples/s: 2210.582 1612414495.9683576
train: epoch 101, iter 1800, loss: 2.472681, top_1: 0.615977, top_k: 0.831094, samples/s: 2226.648 1612414507.4654903
train: epoch 101, iter 1900, loss: 2.445049, top_1: 0.615664, top_k: 0.826094, samples/s: 2229.544 1612414518.9477692
train: epoch 101, iter 2000, loss: 2.552469, top_1: 0.627852, top_k: 0.835508, samples/s: 2197.681 1612414530.5964532
train: epoch 101, iter 2100, loss: 2.748769, top_1: 0.617031, top_k: 0.826367, samples/s: 2237.734 1612414542.0363986
train: epoch 101, iter 2200, loss: 2.497300, top_1: 0.617383, top_k: 0.831172, samples/s: 2220.412 1612414553.5658336
train: epoch 101, iter 2300, loss: 2.463764, top_1: 0.619883, top_k: 0.827227, samples/s: 2220.751 1612414565.093437
train: epoch 101, iter 2400, loss: 2.431176, top_1: 0.618437, top_k: 0.829336, samples/s: 2216.817 1612414576.6415346
train: epoch 101, iter 2500, loss: 2.822770, top_1: 0.614961, top_k: 0.825156, samples/s: 2214.920 1612414588.1994972
train: epoch 101, iter 2600, loss: 2.545778, top_1: 0.616133, top_k: 0.830469, samples/s: 2222.147 1612414599.7198794
train: epoch 101, iter 2700, loss: 2.582224, top_1: 0.611992, top_k: 0.823672, samples/s: 2205.664 1612414611.3264775
train: epoch 101, iter 2800, loss: 2.651355, top_1: 0.620234, top_k: 0.829102, samples/s: 2240.274 1612414622.7536125
train: epoch 101, iter 2900, loss: 2.583027, top_1: 0.618086, top_k: 0.832422, samples/s: 2260.278 1612414634.0795844
train: epoch 101, iter 3000, loss: 2.432245, top_1: 0.615391, top_k: 0.826328, samples/s: 2229.950 1612414645.559659
train: epoch 101, iter 3100, loss: 2.610214, top_1: 0.615039, top_k: 0.827969, samples/s: 2233.064 1612414657.023734
train: epoch 101, iter 3200, loss: 2.786029, top_1: 0.616016, top_k: 0.826289, samples/s: 2207.499 1612414668.620628
train: epoch 101, iter 3300, loss: 2.580671, top_1: 0.619297, top_k: 0.827578, samples/s: 2204.037 1612414680.235626
train: epoch 101, iter 3400, loss: 2.707943, top_1: 0.615273, top_k: 0.827969, samples/s: 2237.412 1612414691.6774244
train: epoch 101, iter 3500, loss: 2.859694, top_1: 0.619258, top_k: 0.829102, samples/s: 2219.151 1612414703.2134223
train: epoch 101, iter 3600, loss: 2.606765, top_1: 0.615977, top_k: 0.826914, samples/s: 2239.117 1612414714.6464372
train: epoch 101, iter 3700, loss: 2.666317, top_1: 0.617891, top_k: 0.828555, samples/s: 2221.625 1612414726.169532
train: epoch 101, iter 3800, loss: 2.683735, top_1: 0.616172, top_k: 0.827344, samples/s: 2216.050 1612414737.721612
train: epoch 101, iter 3900, loss: 2.749946, top_1: 0.616641, top_k: 0.826992, samples/s: 2234.966 1612414749.1759367
train: epoch 101, iter 4000, loss: 2.576538, top_1: 0.620820, top_k: 0.828086, samples/s: 2245.109 1612414760.5784895
train: epoch 101, iter 4100, loss: 2.541944, top_1: 0.618398, top_k: 0.830078, samples/s: 2225.011 1612414772.0840464
train: epoch 101, iter 4200, loss: 2.657114, top_1: 0.613281, top_k: 0.826289, samples/s: 2229.275 1612414783.567662
train: epoch 101, iter 4300, loss: 2.513285, top_1: 0.619766, top_k: 0.830820, samples/s: 2219.134 1612414795.1036506
train: epoch 101, iter 4400, loss: 2.410292, top_1: 0.616250, top_k: 0.825547, samples/s: 2240.194 1612414806.5312572
train: epoch 101, iter 4500, loss: 2.718545, top_1: 0.615352, top_k: 0.824570, samples/s: 2232.100 1612414818.0002506
train: epoch 101, iter 4600, loss: 2.670606, top_1: 0.615977, top_k: 0.826797, samples/s: 2228.813 1612414829.4865427
train: epoch 101, iter 4700, loss: 2.563704, top_1: 0.619453, top_k: 0.829063, samples/s: 2227.672 1612414840.9780045
train: epoch 101, iter 4800, loss: 2.588433, top_1: 0.613789, top_k: 0.822773, samples/s: 2229.235 1612414852.4621017
train: epoch 101, iter 4900, loss: 2.741214, top_1: 0.616953, top_k: 0.828555, samples/s: 2229.164 1612414863.9458723
train: epoch 101, iter 5000, loss: 2.679968, top_1: 0.621328, top_k: 0.828320, samples/s: 2236.375 1612414875.3930097
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_101.
validation: epoch 101, iter 195, top_1: 0.661659, top_k: 0.872656, samples/s: 2952.420 1612414892.6181946
train: epoch 102, iter 100, loss: 2.575022, top_1: 0.624258, top_k: 0.831836, samples/s: 2248.520 1612414919.5132263
train: epoch 102, iter 200, loss: 2.534825, top_1: 0.626680, top_k: 0.833750, samples/s: 2248.990 1612414930.896121
train: epoch 102, iter 300, loss: 2.482307, top_1: 0.625977, top_k: 0.837695, samples/s: 2246.508 1612414942.2915707
train: epoch 102, iter 400, loss: 2.485833, top_1: 0.628086, top_k: 0.833359, samples/s: 2246.983 1612414953.6846313
train: epoch 102, iter 500, loss: 2.676809, top_1: 0.620039, top_k: 0.832266, samples/s: 2244.863 1612414965.0885394
train: epoch 102, iter 600, loss: 2.406538, top_1: 0.623203, top_k: 0.830273, samples/s: 2247.341 1612414976.479687
train: epoch 102, iter 700, loss: 2.614432, top_1: 0.630820, top_k: 0.838008, samples/s: 2248.721 1612414987.8639417
train: epoch 102, iter 800, loss: 2.506462, top_1: 0.624297, top_k: 0.831367, samples/s: 2244.806 1612414999.2680323
train: epoch 102, iter 900, loss: 2.490873, top_1: 0.625391, top_k: 0.836055, samples/s: 2244.460 1612415010.673893
train: epoch 102, iter 1000, loss: 2.573575, top_1: 0.622617, top_k: 0.828281, samples/s: 2245.785 1612415022.073064
train: epoch 102, iter 1100, loss: 2.523657, top_1: 0.619180, top_k: 0.827227, samples/s: 2231.216 1612415033.5465927
train: epoch 102, iter 1200, loss: 2.646936, top_1: 0.620078, top_k: 0.831016, samples/s: 2221.436 1612415045.0706635
train: epoch 102, iter 1300, loss: 2.477194, top_1: 0.622500, top_k: 0.833008, samples/s: 2215.482 1612415056.6257124
train: epoch 102, iter 1400, loss: 2.422153, top_1: 0.622695, top_k: 0.831523, samples/s: 2231.868 1612415068.0959804
train: epoch 102, iter 1500, loss: 2.785991, top_1: 0.620117, top_k: 0.829414, samples/s: 2234.192 1612415079.554493
train: epoch 102, iter 1600, loss: 2.722980, top_1: 0.625703, top_k: 0.833320, samples/s: 2232.948 1612415091.018881
train: epoch 102, iter 1700, loss: 2.678587, top_1: 0.622148, top_k: 0.830781, samples/s: 2174.864 1612415102.7897284
train: epoch 102, iter 1800, loss: 2.660068, top_1: 0.615898, top_k: 0.826172, samples/s: 2240.611 1612415114.2152936
train: epoch 102, iter 1900, loss: 2.626698, top_1: 0.620898, top_k: 0.832969, samples/s: 2238.595 1612415125.651307
train: epoch 102, iter 2000, loss: 2.531081, top_1: 0.622891, top_k: 0.830430, samples/s: 2238.454 1612415137.0874414
train: epoch 102, iter 2100, loss: 2.454847, top_1: 0.616836, top_k: 0.828164, samples/s: 2231.287 1612415148.5606167
train: epoch 102, iter 2200, loss: 2.461795, top_1: 0.624219, top_k: 0.830820, samples/s: 2218.821 1612415160.0982735
train: epoch 102, iter 2300, loss: 2.510176, top_1: 0.617539, top_k: 0.828398, samples/s: 2246.131 1612415171.495658
train: epoch 102, iter 2400, loss: 2.627226, top_1: 0.617188, top_k: 0.829648, samples/s: 2213.972 1612415183.0586743
train: epoch 102, iter 2500, loss: 2.520067, top_1: 0.622656, top_k: 0.832422, samples/s: 2226.572 1612415194.5562716
train: epoch 102, iter 2600, loss: 2.458967, top_1: 0.614727, top_k: 0.823945, samples/s: 2227.721 1612415206.0476274
train: epoch 102, iter 2700, loss: 2.661955, top_1: 0.624375, top_k: 0.830977, samples/s: 2232.238 1612415217.515946
train: epoch 102, iter 2800, loss: 2.581648, top_1: 0.618906, top_k: 0.832031, samples/s: 2223.139 1612415229.0311806
train: epoch 102, iter 2900, loss: 2.634650, top_1: 0.619141, top_k: 0.825937, samples/s: 2224.385 1612415240.5400085
train: epoch 102, iter 3000, loss: 2.639267, top_1: 0.614570, top_k: 0.824609, samples/s: 2232.791 1612415252.005446
train: epoch 102, iter 3100, loss: 2.393034, top_1: 0.616016, top_k: 0.826758, samples/s: 2230.128 1612415263.4846082
train: epoch 102, iter 3200, loss: 2.536487, top_1: 0.612227, top_k: 0.826523, samples/s: 2226.560 1612415274.9821692
train: epoch 102, iter 3300, loss: 2.484102, top_1: 0.624102, top_k: 0.831953, samples/s: 2226.321 1612415286.4810145
train: epoch 102, iter 3400, loss: 2.545721, top_1: 0.619141, top_k: 0.825937, samples/s: 2233.289 1612415297.9439294
train: epoch 102, iter 3500, loss: 2.503560, top_1: 0.619922, top_k: 0.831914, samples/s: 2222.892 1612415309.4604032
train: epoch 102, iter 3600, loss: 2.586935, top_1: 0.621992, top_k: 0.831562, samples/s: 2240.356 1612415320.8871944
train: epoch 102, iter 3700, loss: 2.483705, top_1: 0.618906, top_k: 0.830898, samples/s: 2217.093 1612415332.4338157
train: epoch 102, iter 3800, loss: 2.792848, top_1: 0.617227, top_k: 0.825313, samples/s: 2227.613 1612415343.9260042
train: epoch 102, iter 3900, loss: 2.557381, top_1: 0.610234, top_k: 0.828516, samples/s: 2219.025 1612415355.4625201
train: epoch 102, iter 4000, loss: 2.438404, top_1: 0.616484, top_k: 0.827266, samples/s: 2238.241 1612415366.9000869
train: epoch 102, iter 4100, loss: 2.631281, top_1: 0.613984, top_k: 0.825078, samples/s: 2232.324 1612415378.3679557
train: epoch 102, iter 4200, loss: 2.553602, top_1: 0.618047, top_k: 0.829180, samples/s: 2231.345 1612415389.8409674
train: epoch 102, iter 4300, loss: 2.874730, top_1: 0.612383, top_k: 0.826094, samples/s: 2245.288 1612415401.2425241
train: epoch 102, iter 4400, loss: 2.692678, top_1: 0.620234, top_k: 0.827852, samples/s: 2227.576 1612415412.73489
train: epoch 102, iter 4500, loss: 2.601400, top_1: 0.614688, top_k: 0.825430, samples/s: 2228.788 1612415424.2210016
train: epoch 102, iter 4600, loss: 2.581295, top_1: 0.617969, top_k: 0.826406, samples/s: 2237.413 1612415435.662675
train: epoch 102, iter 4700, loss: 2.637589, top_1: 0.614766, top_k: 0.823906, samples/s: 2231.067 1612415447.1370714
train: epoch 102, iter 4800, loss: 2.558730, top_1: 0.623086, top_k: 0.831484, samples/s: 2209.076 1612415458.7256517
train: epoch 102, iter 4900, loss: 2.503770, top_1: 0.612734, top_k: 0.827148, samples/s: 2230.767 1612415470.2014925
train: epoch 102, iter 5000, loss: 2.522753, top_1: 0.628203, top_k: 0.833789, samples/s: 2242.901 1612415481.6152442
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_102.
validation: epoch 102, iter 195, top_1: 0.660657, top_k: 0.871354, samples/s: 2900.733 1612415499.184573
train: epoch 103, iter 100, loss: 2.626928, top_1: 0.623984, top_k: 0.829688, samples/s: 2232.813 1612415526.2527027
train: epoch 103, iter 200, loss: 2.594538, top_1: 0.624297, top_k: 0.830742, samples/s: 2244.982 1612415537.655864
train: epoch 103, iter 300, loss: 2.540094, top_1: 0.624531, top_k: 0.836367, samples/s: 2233.284 1612415549.1188343
train: epoch 103, iter 400, loss: 2.472252, top_1: 0.635781, top_k: 0.839375, samples/s: 2250.327 1612415560.4950404
train: epoch 103, iter 500, loss: 2.735240, top_1: 0.632852, top_k: 0.835977, samples/s: 2245.386 1612415571.8961353
train: epoch 103, iter 600, loss: 2.466627, top_1: 0.629805, top_k: 0.833203, samples/s: 2243.722 1612415583.3057888
train: epoch 103, iter 700, loss: 2.573220, top_1: 0.622109, top_k: 0.834922, samples/s: 2262.078 1612415594.6228204
train: epoch 103, iter 800, loss: 2.693573, top_1: 0.627773, top_k: 0.835273, samples/s: 2243.760 1612415606.0321817
train: epoch 103, iter 900, loss: 2.674305, top_1: 0.624805, top_k: 0.833672, samples/s: 2225.444 1612415617.535554
train: epoch 103, iter 1000, loss: 2.400123, top_1: 0.623008, top_k: 0.828984, samples/s: 2246.574 1612415628.9306614
train: epoch 103, iter 1100, loss: 2.400222, top_1: 0.627148, top_k: 0.835391, samples/s: 2226.964 1612415640.4262772
train: epoch 103, iter 1200, loss: 2.522284, top_1: 0.621680, top_k: 0.832305, samples/s: 2234.539 1612415651.882616
train: epoch 103, iter 1300, loss: 2.739243, top_1: 0.619336, top_k: 0.830586, samples/s: 2232.003 1612415663.3521378
train: epoch 103, iter 1400, loss: 2.471957, top_1: 0.625742, top_k: 0.831719, samples/s: 2237.425 1612415674.793854
train: epoch 103, iter 1500, loss: 2.361300, top_1: 0.631328, top_k: 0.836328, samples/s: 2220.196 1612415686.3244252
train: epoch 103, iter 1600, loss: 2.659813, top_1: 0.622266, top_k: 0.832031, samples/s: 2230.575 1612415697.8012745
train: epoch 103, iter 1700, loss: 2.429431, top_1: 0.623555, top_k: 0.829648, samples/s: 2231.675 1612415709.2724233
train: epoch 103, iter 1800, loss: 2.613063, top_1: 0.623867, top_k: 0.830430, samples/s: 2216.601 1612415720.8216386
train: epoch 103, iter 1900, loss: 2.540269, top_1: 0.618164, top_k: 0.828086, samples/s: 2240.508 1612415732.2476606
train: epoch 103, iter 2000, loss: 2.506925, top_1: 0.619844, top_k: 0.829453, samples/s: 2216.186 1612415743.7990782
train: epoch 103, iter 2100, loss: 2.428442, top_1: 0.621211, top_k: 0.830352, samples/s: 2220.382 1612415755.3285396
train: epoch 103, iter 2200, loss: 2.437450, top_1: 0.620547, top_k: 0.831406, samples/s: 2242.829 1612415766.7427647
train: epoch 103, iter 2300, loss: 2.492768, top_1: 0.627227, top_k: 0.835508, samples/s: 2212.355 1612415778.3140762
train: epoch 103, iter 2400, loss: 2.538796, top_1: 0.623320, top_k: 0.832891, samples/s: 2230.559 1612415789.7911804
train: epoch 103, iter 2500, loss: 2.487589, top_1: 0.621523, top_k: 0.831133, samples/s: 2230.457 1612415801.2684882
train: epoch 103, iter 2600, loss: 2.394749, top_1: 0.620273, top_k: 0.829180, samples/s: 2214.064 1612415812.8309314
train: epoch 103, iter 2700, loss: 2.669132, top_1: 0.623516, top_k: 0.832969, samples/s: 2234.986 1612415824.2851472
train: epoch 103, iter 2800, loss: 2.648185, top_1: 0.626250, top_k: 0.833984, samples/s: 2210.013 1612415835.868881
train: epoch 103, iter 2900, loss: 2.406986, top_1: 0.620781, top_k: 0.832969, samples/s: 2249.716 1612415847.248021
train: epoch 103, iter 3000, loss: 2.580677, top_1: 0.615781, top_k: 0.827617, samples/s: 2245.867 1612415858.647195
train: epoch 103, iter 3100, loss: 2.484061, top_1: 0.625977, top_k: 0.830195, samples/s: 2214.607 1612415870.2063477
train: epoch 103, iter 3200, loss: 2.590896, top_1: 0.624180, top_k: 0.829375, samples/s: 2229.309 1612415881.6897285
train: epoch 103, iter 3300, loss: 2.318667, top_1: 0.626523, top_k: 0.832539, samples/s: 2224.731 1612415893.1970358
train: epoch 103, iter 3400, loss: 2.523797, top_1: 0.626172, top_k: 0.835430, samples/s: 2229.346 1612415904.6799595
train: epoch 103, iter 3500, loss: 2.543032, top_1: 0.621172, top_k: 0.835039, samples/s: 2220.100 1612415916.2109294
train: epoch 103, iter 3600, loss: 2.683537, top_1: 0.619687, top_k: 0.828711, samples/s: 2216.573 1612415927.760317
train: epoch 103, iter 3700, loss: 2.467171, top_1: 0.615664, top_k: 0.823789, samples/s: 2216.953 1612415939.307673
train: epoch 103, iter 3800, loss: 2.787242, top_1: 0.621875, top_k: 0.829531, samples/s: 2217.395 1612415950.8527727
train: epoch 103, iter 3900, loss: 2.643421, top_1: 0.617266, top_k: 0.828633, samples/s: 2226.228 1612415962.3520913
train: epoch 103, iter 4000, loss: 2.722619, top_1: 0.610664, top_k: 0.824258, samples/s: 2233.083 1612415973.8160062
train: epoch 103, iter 4100, loss: 2.639347, top_1: 0.616133, top_k: 0.825977, samples/s: 2234.738 1612415985.2714796
train: epoch 103, iter 4200, loss: 2.503720, top_1: 0.625195, top_k: 0.834219, samples/s: 2224.829 1612415996.7780092
train: epoch 103, iter 4300, loss: 2.563282, top_1: 0.615820, top_k: 0.828398, samples/s: 2232.699 1612416008.2439878
train: epoch 103, iter 4400, loss: 2.506721, top_1: 0.617344, top_k: 0.831016, samples/s: 2228.689 1612416019.7305806
train: epoch 103, iter 4500, loss: 2.627377, top_1: 0.619766, top_k: 0.830469, samples/s: 2230.262 1612416031.208981
train: epoch 103, iter 4600, loss: 2.636660, top_1: 0.618047, top_k: 0.831367, samples/s: 2231.627 1612416042.6804771
train: epoch 103, iter 4700, loss: 2.502971, top_1: 0.616367, top_k: 0.829961, samples/s: 2220.826 1612416054.2076929
train: epoch 103, iter 4800, loss: 2.528844, top_1: 0.619570, top_k: 0.829609, samples/s: 2227.852 1612416065.698622
train: epoch 103, iter 4900, loss: 2.508967, top_1: 0.615430, top_k: 0.828320, samples/s: 2235.534 1612416077.1499398
train: epoch 103, iter 5000, loss: 2.520252, top_1: 0.622695, top_k: 0.830977, samples/s: 2237.636 1612416088.5906534
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_103.
validation: epoch 103, iter 195, top_1: 0.660276, top_k: 0.869812, samples/s: 2844.404 1612416106.4850547
train: epoch 104, iter 100, loss: 2.674509, top_1: 0.637031, top_k: 0.841055, samples/s: 2236.065 1612416133.5342352
train: epoch 104, iter 200, loss: 2.636953, top_1: 0.627383, top_k: 0.834063, samples/s: 2252.343 1612416144.9001708
train: epoch 104, iter 300, loss: 2.727704, top_1: 0.631953, top_k: 0.840859, samples/s: 2248.293 1612416156.2865736
train: epoch 104, iter 400, loss: 2.612554, top_1: 0.629570, top_k: 0.834531, samples/s: 2243.368 1612416167.6980357
train: epoch 104, iter 500, loss: 2.543860, top_1: 0.630625, top_k: 0.834023, samples/s: 2257.282 1612416179.0391405
train: epoch 104, iter 600, loss: 2.388428, top_1: 0.624258, top_k: 0.834805, samples/s: 2247.204 1612416190.4310012
train: epoch 104, iter 700, loss: 2.458961, top_1: 0.623242, top_k: 0.835156, samples/s: 2262.247 1612416201.7472067
train: epoch 104, iter 800, loss: 2.359384, top_1: 0.624180, top_k: 0.833867, samples/s: 2229.138 1612416213.2314496
train: epoch 104, iter 900, loss: 2.570521, top_1: 0.625938, top_k: 0.836016, samples/s: 2217.903 1612416224.773904
train: epoch 104, iter 1000, loss: 2.435026, top_1: 0.627109, top_k: 0.835273, samples/s: 2210.643 1612416236.3542218
train: epoch 104, iter 1100, loss: 2.461740, top_1: 0.636172, top_k: 0.838828, samples/s: 2215.139 1612416247.911137
train: epoch 104, iter 1200, loss: 2.584324, top_1: 0.627852, top_k: 0.834531, samples/s: 2207.916 1612416259.5057988
train: epoch 104, iter 1300, loss: 2.509216, top_1: 0.623437, top_k: 0.834336, samples/s: 2209.814 1612416271.0904531
train: epoch 104, iter 1400, loss: 2.479511, top_1: 0.627891, top_k: 0.832031, samples/s: 2200.312 1612416282.725202
train: epoch 104, iter 1500, loss: 2.487988, top_1: 0.631094, top_k: 0.834453, samples/s: 2237.512 1612416294.1664274
train: epoch 104, iter 1600, loss: 2.495319, top_1: 0.631797, top_k: 0.834766, samples/s: 2189.370 1612416305.8593426
train: epoch 104, iter 1700, loss: 2.619488, top_1: 0.629180, top_k: 0.837187, samples/s: 2247.279 1612416317.2508087
train: epoch 104, iter 1800, loss: 2.375720, top_1: 0.627578, top_k: 0.838398, samples/s: 2177.878 1612416329.0054066
train: epoch 104, iter 1900, loss: 2.459143, top_1: 0.622734, top_k: 0.831328, samples/s: 2233.246 1612416340.4685636
train: epoch 104, iter 2000, loss: 2.517483, top_1: 0.618945, top_k: 0.831133, samples/s: 2223.781 1612416351.9805017
train: epoch 104, iter 2100, loss: 2.421825, top_1: 0.627227, top_k: 0.835391, samples/s: 2226.942 1612416363.4760256
train: epoch 104, iter 2200, loss: 2.493247, top_1: 0.629297, top_k: 0.835234, samples/s: 2223.918 1612416374.9873068
train: epoch 104, iter 2300, loss: 2.564586, top_1: 0.627188, top_k: 0.837500, samples/s: 2209.674 1612416386.5726879
train: epoch 104, iter 2400, loss: 2.577811, top_1: 0.623398, top_k: 0.832187, samples/s: 2232.121 1612416398.0415385
train: epoch 104, iter 2500, loss: 2.484292, top_1: 0.628828, top_k: 0.833164, samples/s: 2210.211 1612416409.6242003
train: epoch 104, iter 2600, loss: 2.814635, top_1: 0.623398, top_k: 0.831445, samples/s: 2233.594 1612416421.085489
train: epoch 104, iter 2700, loss: 2.567214, top_1: 0.624062, top_k: 0.831055, samples/s: 2219.576 1612416432.6192622
train: epoch 104, iter 2800, loss: 2.583076, top_1: 0.620625, top_k: 0.828672, samples/s: 2241.563 1612416444.0398672
train: epoch 104, iter 2900, loss: 2.461151, top_1: 0.621797, top_k: 0.827773, samples/s: 2192.715 1612416455.7150626
train: epoch 104, iter 3000, loss: 2.592161, top_1: 0.618281, top_k: 0.827969, samples/s: 2233.781 1612416467.1753302
train: epoch 104, iter 3100, loss: 2.613713, top_1: 0.624336, top_k: 0.833945, samples/s: 2229.655 1612416478.6568139
train: epoch 104, iter 3200, loss: 2.521626, top_1: 0.626133, top_k: 0.833867, samples/s: 2220.599 1612416490.1854277
train: epoch 104, iter 3300, loss: 2.658280, top_1: 0.623906, top_k: 0.834102, samples/s: 2240.258 1612416501.6125271
train: epoch 104, iter 3400, loss: 2.591772, top_1: 0.622539, top_k: 0.832187, samples/s: 2229.851 1612416513.0934737
train: epoch 104, iter 3500, loss: 2.481979, top_1: 0.628047, top_k: 0.836016, samples/s: 2233.637 1612416524.5542405
train: epoch 104, iter 3600, loss: 2.492266, top_1: 0.620547, top_k: 0.828867, samples/s: 2235.708 1612416536.004815
train: epoch 104, iter 3700, loss: 2.715535, top_1: 0.623906, top_k: 0.831367, samples/s: 2216.538 1612416547.5542834
train: epoch 104, iter 3800, loss: 2.386569, top_1: 0.622617, top_k: 0.833711, samples/s: 2214.533 1612416559.1143584
train: epoch 104, iter 3900, loss: 2.595833, top_1: 0.623945, top_k: 0.832617, samples/s: 2246.629 1612416570.509172
train: epoch 104, iter 4000, loss: 2.594244, top_1: 0.620234, top_k: 0.827812, samples/s: 2216.028 1612416582.0614994
train: epoch 104, iter 4100, loss: 2.637995, top_1: 0.623242, top_k: 0.832773, samples/s: 2249.338 1612416593.4424703
train: epoch 104, iter 4200, loss: 2.544639, top_1: 0.622422, top_k: 0.832930, samples/s: 2231.637 1612416604.9139235
train: epoch 104, iter 4300, loss: 2.594040, top_1: 0.620664, top_k: 0.833555, samples/s: 2217.357 1612416616.459202
train: epoch 104, iter 4400, loss: 2.511768, top_1: 0.621836, top_k: 0.829180, samples/s: 2216.337 1612416628.0097375
train: epoch 104, iter 4500, loss: 2.495702, top_1: 0.634727, top_k: 0.836875, samples/s: 2228.426 1612416639.4977548
train: epoch 104, iter 4600, loss: 2.598285, top_1: 0.618320, top_k: 0.827500, samples/s: 2231.637 1612416650.9690444
train: epoch 104, iter 4700, loss: 2.372859, top_1: 0.618711, top_k: 0.828242, samples/s: 2234.801 1612416662.4243517
train: epoch 104, iter 4800, loss: 2.558934, top_1: 0.621133, top_k: 0.826211, samples/s: 2213.320 1612416673.9906187
train: epoch 104, iter 4900, loss: 2.541469, top_1: 0.622852, top_k: 0.831641, samples/s: 2223.939 1612416685.501651
train: epoch 104, iter 5000, loss: 2.558875, top_1: 0.628984, top_k: 0.834922, samples/s: 2228.053 1612416696.9915538
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_104.
validation: epoch 104, iter 195, top_1: 0.663822, top_k: 0.873818, samples/s: 2904.141 1612416714.5644114
train: epoch 105, iter 100, loss: 2.496947, top_1: 0.628359, top_k: 0.832812, samples/s: 2212.895 1612416741.814435
train: epoch 105, iter 200, loss: 2.583046, top_1: 0.639219, top_k: 0.841367, samples/s: 2250.446 1612416753.1899529
train: epoch 105, iter 300, loss: 2.530896, top_1: 0.629844, top_k: 0.839766, samples/s: 2254.461 1612416764.5452592
train: epoch 105, iter 400, loss: 2.419581, top_1: 0.631328, top_k: 0.838789, samples/s: 2246.902 1612416775.9386642
train: epoch 105, iter 500, loss: 2.589987, top_1: 0.639414, top_k: 0.839961, samples/s: 2249.840 1612416787.3171735
train: epoch 105, iter 600, loss: 2.581277, top_1: 0.632148, top_k: 0.840234, samples/s: 2255.312 1612416798.668218
train: epoch 105, iter 700, loss: 2.562720, top_1: 0.631523, top_k: 0.838398, samples/s: 2238.113 1612416810.106353
train: epoch 105, iter 800, loss: 2.504755, top_1: 0.629219, top_k: 0.836875, samples/s: 2234.752 1612416821.5618608
train: epoch 105, iter 900, loss: 2.436586, top_1: 0.633047, top_k: 0.840625, samples/s: 2226.647 1612416833.058922
train: epoch 105, iter 1000, loss: 2.468197, top_1: 0.632148, top_k: 0.840391, samples/s: 2213.874 1612416844.622406
train: epoch 105, iter 1100, loss: 2.426708, top_1: 0.623984, top_k: 0.833867, samples/s: 2222.248 1612416856.1422284
train: epoch 105, iter 1200, loss: 2.598043, top_1: 0.630352, top_k: 0.836211, samples/s: 2210.198 1612416867.7249622
train: epoch 105, iter 1300, loss: 2.713763, top_1: 0.629062, top_k: 0.835000, samples/s: 2223.350 1612416879.2390475
train: epoch 105, iter 1400, loss: 2.499085, top_1: 0.630273, top_k: 0.835352, samples/s: 2222.966 1612416890.7552779
train: epoch 105, iter 1500, loss: 2.543234, top_1: 0.625430, top_k: 0.834023, samples/s: 2221.541 1612416902.278714
train: epoch 105, iter 1600, loss: 2.641040, top_1: 0.630898, top_k: 0.837383, samples/s: 2200.980 1612416913.910036
train: epoch 105, iter 1700, loss: 2.561994, top_1: 0.629727, top_k: 0.837031, samples/s: 2217.800 1612416925.4529476
train: epoch 105, iter 1800, loss: 2.541610, top_1: 0.627383, top_k: 0.832070, samples/s: 2242.951 1612416936.8663793
train: epoch 105, iter 1900, loss: 2.558429, top_1: 0.625938, top_k: 0.837148, samples/s: 2210.326 1612416948.4484782
train: epoch 105, iter 2000, loss: 2.494836, top_1: 0.624609, top_k: 0.832070, samples/s: 2220.642 1612416959.9766169
train: epoch 105, iter 2100, loss: 2.568637, top_1: 0.628906, top_k: 0.833750, samples/s: 2236.879 1612416971.4211373
train: epoch 105, iter 2200, loss: 2.736029, top_1: 0.624570, top_k: 0.832734, samples/s: 2220.752 1612416982.949125
train: epoch 105, iter 2300, loss: 2.646291, top_1: 0.630273, top_k: 0.837500, samples/s: 2215.603 1612416994.503312
train: epoch 105, iter 2400, loss: 2.449873, top_1: 0.623516, top_k: 0.833008, samples/s: 2211.817 1612417006.077404
train: epoch 105, iter 2500, loss: 2.658160, top_1: 0.623828, top_k: 0.833633, samples/s: 2230.443 1612417017.5549173
train: epoch 105, iter 2600, loss: 2.415939, top_1: 0.628008, top_k: 0.835586, samples/s: 2219.101 1612417029.0915127
train: epoch 105, iter 2700, loss: 2.551778, top_1: 0.622578, top_k: 0.831797, samples/s: 2227.988 1612417040.581366
train: epoch 105, iter 2800, loss: 2.488442, top_1: 0.630625, top_k: 0.835430, samples/s: 2221.931 1612417052.1028535
train: epoch 105, iter 2900, loss: 2.528021, top_1: 0.622617, top_k: 0.835234, samples/s: 2215.626 1612417063.657115
train: epoch 105, iter 3000, loss: 2.420671, top_1: 0.626328, top_k: 0.830391, samples/s: 2234.304 1612417075.1148522
train: epoch 105, iter 3100, loss: 2.517354, top_1: 0.624453, top_k: 0.830742, samples/s: 2198.974 1612417086.7566566
train: epoch 105, iter 3200, loss: 2.530596, top_1: 0.624805, top_k: 0.835039, samples/s: 2215.682 1612417098.310741
train: epoch 105, iter 3300, loss: 2.582447, top_1: 0.623281, top_k: 0.834141, samples/s: 2238.285 1612417109.7480776
train: epoch 105, iter 3400, loss: 2.530148, top_1: 0.625195, top_k: 0.831914, samples/s: 2206.880 1612417121.3480947
train: epoch 105, iter 3500, loss: 2.726756, top_1: 0.630391, top_k: 0.832070, samples/s: 2235.632 1612417132.7990422
train: epoch 105, iter 3600, loss: 2.617571, top_1: 0.622188, top_k: 0.829063, samples/s: 2225.834 1612417144.3002522
train: epoch 105, iter 3700, loss: 2.620130, top_1: 0.627188, top_k: 0.832148, samples/s: 2238.025 1612417155.7389052
train: epoch 105, iter 3800, loss: 2.624363, top_1: 0.624062, top_k: 0.833477, samples/s: 2213.380 1612417167.304926
train: epoch 105, iter 3900, loss: 2.634655, top_1: 0.623750, top_k: 0.835273, samples/s: 2216.062 1612417178.856932
train: epoch 105, iter 4000, loss: 2.708751, top_1: 0.623242, top_k: 0.832422, samples/s: 2232.405 1612417190.32455
train: epoch 105, iter 4100, loss: 2.651321, top_1: 0.624375, top_k: 0.832617, samples/s: 2220.022 1612417201.855853
train: epoch 105, iter 4200, loss: 2.478861, top_1: 0.627070, top_k: 0.835820, samples/s: 2231.072 1612417213.3302202
train: epoch 105, iter 4300, loss: 2.648729, top_1: 0.619727, top_k: 0.829102, samples/s: 2226.514 1612417224.8279757
train: epoch 105, iter 4400, loss: 2.583417, top_1: 0.619453, top_k: 0.832461, samples/s: 2207.182 1612417236.4264448
train: epoch 105, iter 4500, loss: 2.663779, top_1: 0.622617, top_k: 0.834180, samples/s: 2238.520 1612417247.8626208
train: epoch 105, iter 4600, loss: 2.606795, top_1: 0.632031, top_k: 0.838320, samples/s: 2221.846 1612417259.3845623
train: epoch 105, iter 4700, loss: 2.556503, top_1: 0.625352, top_k: 0.833672, samples/s: 2235.382 1612417270.8366668
train: epoch 105, iter 4800, loss: 2.533905, top_1: 0.625391, top_k: 0.830391, samples/s: 2228.648 1612417282.3234468
train: epoch 105, iter 4900, loss: 2.521749, top_1: 0.628594, top_k: 0.835859, samples/s: 2235.574 1612417293.7747068
train: epoch 105, iter 5000, loss: 2.510970, top_1: 0.632578, top_k: 0.836836, samples/s: 2206.477 1612417305.3768485
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_105.
validation: epoch 105, iter 195, top_1: 0.658373, top_k: 0.870333, samples/s: 2985.228 1612417322.6610477
train: epoch 106, iter 100, loss: 2.375527, top_1: 0.634883, top_k: 0.838828, samples/s: 2233.904 1612417349.663013
train: epoch 106, iter 200, loss: 2.431345, top_1: 0.633125, top_k: 0.836523, samples/s: 2255.207 1612417361.0145147
train: epoch 106, iter 300, loss: 2.476678, top_1: 0.635469, top_k: 0.837617, samples/s: 2255.837 1612417372.3628664
train: epoch 106, iter 400, loss: 2.519018, top_1: 0.635547, top_k: 0.840664, samples/s: 2238.064 1612417383.8014379
train: epoch 106, iter 500, loss: 2.580878, top_1: 0.635977, top_k: 0.839297, samples/s: 2257.148 1612417395.1430535
train: epoch 106, iter 600, loss: 2.518910, top_1: 0.632500, top_k: 0.834922, samples/s: 2250.455 1612417406.518565
train: epoch 106, iter 700, loss: 2.321768, top_1: 0.636367, top_k: 0.837617, samples/s: 2234.386 1612417417.9758253
train: epoch 106, iter 800, loss: 2.592222, top_1: 0.629023, top_k: 0.837266, samples/s: 2243.718 1612417429.3854952
train: epoch 106, iter 900, loss: 2.545166, top_1: 0.631172, top_k: 0.838789, samples/s: 2250.302 1612417440.7617102
train: epoch 106, iter 1000, loss: 2.509169, top_1: 0.638281, top_k: 0.838477, samples/s: 2211.264 1612417452.3388467
train: epoch 106, iter 1100, loss: 2.356006, top_1: 0.629844, top_k: 0.834063, samples/s: 2222.571 1612417463.8570032
train: epoch 106, iter 1200, loss: 2.400258, top_1: 0.630469, top_k: 0.838945, samples/s: 2213.780 1612417475.4209177
train: epoch 106, iter 1300, loss: 2.578919, top_1: 0.630977, top_k: 0.838125, samples/s: 2248.808 1612417486.8047512
train: epoch 106, iter 1400, loss: 2.661005, top_1: 0.630469, top_k: 0.837734, samples/s: 2223.900 1612417498.316093
train: epoch 106, iter 1500, loss: 2.620443, top_1: 0.628828, top_k: 0.834180, samples/s: 2234.698 1612417509.771725
train: epoch 106, iter 1600, loss: 2.538188, top_1: 0.632969, top_k: 0.837031, samples/s: 2221.323 1612417521.2963886
train: epoch 106, iter 1700, loss: 2.566731, top_1: 0.633984, top_k: 0.838281, samples/s: 2232.680 1612417532.7625506
train: epoch 106, iter 1800, loss: 2.639158, top_1: 0.628828, top_k: 0.833945, samples/s: 2221.408 1612417544.2867072
train: epoch 106, iter 1900, loss: 2.464248, top_1: 0.632305, top_k: 0.839648, samples/s: 2234.317 1612417555.7443027
train: epoch 106, iter 2000, loss: 2.502034, top_1: 0.623320, top_k: 0.832500, samples/s: 2209.943 1612417567.3283134
train: epoch 106, iter 2100, loss: 2.643471, top_1: 0.633555, top_k: 0.834492, samples/s: 2229.839 1612417578.808969
train: epoch 106, iter 2200, loss: 2.510623, top_1: 0.623867, top_k: 0.835898, samples/s: 2228.175 1612417590.2982845
train: epoch 106, iter 2300, loss: 2.433208, top_1: 0.626016, top_k: 0.833047, samples/s: 2229.686 1612417601.779588
train: epoch 106, iter 2400, loss: 2.577391, top_1: 0.623203, top_k: 0.834414, samples/s: 2215.513 1612417613.3345523
train: epoch 106, iter 2500, loss: 2.576377, top_1: 0.630820, top_k: 0.835898, samples/s: 2244.438 1612417624.7404778
train: epoch 106, iter 2600, loss: 2.441106, top_1: 0.635195, top_k: 0.842305, samples/s: 2224.255 1612417636.2499633
train: epoch 106, iter 2700, loss: 2.702538, top_1: 0.628008, top_k: 0.832734, samples/s: 2240.968 1612417647.6735313
train: epoch 106, iter 2800, loss: 2.307800, top_1: 0.623750, top_k: 0.834102, samples/s: 2232.723 1612417659.139394
train: epoch 106, iter 2900, loss: 2.540992, top_1: 0.628594, top_k: 0.833945, samples/s: 2230.187 1612417670.618358
train: epoch 106, iter 3000, loss: 2.679442, top_1: 0.625742, top_k: 0.834766, samples/s: 2231.327 1612417682.091324
train: epoch 106, iter 3100, loss: 2.716298, top_1: 0.626367, top_k: 0.833789, samples/s: 2233.732 1612417693.5519066
train: epoch 106, iter 3200, loss: 2.380500, top_1: 0.624023, top_k: 0.834453, samples/s: 2241.210 1612417704.9742928
train: epoch 106, iter 3300, loss: 2.388981, top_1: 0.631289, top_k: 0.838789, samples/s: 2232.925 1612417716.4391065
train: epoch 106, iter 3400, loss: 2.480731, top_1: 0.631445, top_k: 0.836641, samples/s: 2220.404 1612417727.9684992
train: epoch 106, iter 3500, loss: 2.644740, top_1: 0.628320, top_k: 0.835547, samples/s: 2213.332 1612417739.5347745
train: epoch 106, iter 3600, loss: 2.347997, top_1: 0.624414, top_k: 0.836055, samples/s: 2233.157 1612417750.9984264
train: epoch 106, iter 3700, loss: 2.641041, top_1: 0.624922, top_k: 0.835586, samples/s: 2230.765 1612417762.4742699
train: epoch 106, iter 3800, loss: 2.475751, top_1: 0.628711, top_k: 0.833633, samples/s: 2215.336 1612417774.0301263
train: epoch 106, iter 3900, loss: 2.622099, top_1: 0.626680, top_k: 0.835703, samples/s: 2249.697 1612417785.409367
train: epoch 106, iter 4000, loss: 2.458836, top_1: 0.628711, top_k: 0.836562, samples/s: 2218.609 1612417796.9481506
train: epoch 106, iter 4100, loss: 2.546433, top_1: 0.631172, top_k: 0.834805, samples/s: 2243.406 1612417808.3598063
train: epoch 106, iter 4200, loss: 2.504459, top_1: 0.631250, top_k: 0.836562, samples/s: 2235.578 1612417819.8105378
train: epoch 106, iter 4300, loss: 2.527708, top_1: 0.626992, top_k: 0.835078, samples/s: 2230.437 1612417831.2885504
train: epoch 106, iter 4400, loss: 2.538021, top_1: 0.629883, top_k: 0.839531, samples/s: 2197.503 1612417842.9377153
train: epoch 106, iter 4500, loss: 2.580094, top_1: 0.621719, top_k: 0.830703, samples/s: 2232.996 1612417854.4021027
train: epoch 106, iter 4600, loss: 2.556386, top_1: 0.627930, top_k: 0.833750, samples/s: 2220.888 1612417865.929017
train: epoch 106, iter 4700, loss: 2.463552, top_1: 0.625156, top_k: 0.832187, samples/s: 2233.073 1612417877.393107
train: epoch 106, iter 4800, loss: 2.505187, top_1: 0.625195, top_k: 0.836445, samples/s: 2231.801 1612417888.8636096
train: epoch 106, iter 4900, loss: 2.508169, top_1: 0.632461, top_k: 0.833984, samples/s: 2229.591 1612417900.3455343
train: epoch 106, iter 5000, loss: 2.593152, top_1: 0.626953, top_k: 0.836328, samples/s: 2229.634 1612417911.827314
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_106.
validation: epoch 106, iter 195, top_1: 0.665805, top_k: 0.875040, samples/s: 2843.436 1612417929.7863715
train: epoch 107, iter 100, loss: 2.479084, top_1: 0.642461, top_k: 0.845000, samples/s: 2225.412 1612417957.0577593
train: epoch 107, iter 200, loss: 2.548303, top_1: 0.637031, top_k: 0.842578, samples/s: 2260.526 1612417968.3825524
train: epoch 107, iter 300, loss: 2.551501, top_1: 0.637578, top_k: 0.842187, samples/s: 2265.065 1612417979.6847248
train: epoch 107, iter 400, loss: 2.589321, top_1: 0.641875, top_k: 0.844609, samples/s: 2228.766 1612417991.1708622
train: epoch 107, iter 500, loss: 2.587291, top_1: 0.636172, top_k: 0.839805, samples/s: 2267.427 1612418002.4611576
train: epoch 107, iter 600, loss: 2.464600, top_1: 0.642266, top_k: 0.839102, samples/s: 2240.721 1612418013.8860526
train: epoch 107, iter 700, loss: 2.502666, top_1: 0.632344, top_k: 0.836445, samples/s: 2240.775 1612418025.3107274
train: epoch 107, iter 800, loss: 2.641315, top_1: 0.637852, top_k: 0.841523, samples/s: 2219.694 1612418036.843797
train: epoch 107, iter 900, loss: 2.614757, top_1: 0.633281, top_k: 0.838594, samples/s: 2249.123 1612418048.2260065
train: epoch 107, iter 1000, loss: 2.675558, top_1: 0.635586, top_k: 0.840469, samples/s: 2218.549 1612418059.7652702
train: epoch 107, iter 1100, loss: 2.578244, top_1: 0.637930, top_k: 0.841992, samples/s: 2223.223 1612418071.279893
train: epoch 107, iter 1200, loss: 2.674860, top_1: 0.632539, top_k: 0.837891, samples/s: 2219.559 1612418082.8137133
train: epoch 107, iter 1300, loss: 2.283748, top_1: 0.638047, top_k: 0.840469, samples/s: 2189.148 1612418094.507822
train: epoch 107, iter 1400, loss: 2.546080, top_1: 0.637109, top_k: 0.837734, samples/s: 2228.664 1612418105.9944592
train: epoch 107, iter 1500, loss: 2.575771, top_1: 0.629883, top_k: 0.832070, samples/s: 2212.687 1612418117.564163
train: epoch 107, iter 1600, loss: 2.523641, top_1: 0.631094, top_k: 0.837187, samples/s: 2203.618 1612418129.1813629
train: epoch 107, iter 1700, loss: 2.700113, top_1: 0.630625, top_k: 0.841055, samples/s: 2225.049 1612418140.686843
train: epoch 107, iter 1800, loss: 2.707338, top_1: 0.630586, top_k: 0.834414, samples/s: 2228.711 1612418152.1731958
train: epoch 107, iter 1900, loss: 2.737867, top_1: 0.634258, top_k: 0.837969, samples/s: 2224.130 1612418163.68338
train: epoch 107, iter 2000, loss: 2.534642, top_1: 0.634922, top_k: 0.839922, samples/s: 2236.325 1612418175.1307948
train: epoch 107, iter 2100, loss: 2.475400, top_1: 0.631797, top_k: 0.838828, samples/s: 2228.453 1612418186.6185179
train: epoch 107, iter 2200, loss: 2.640575, top_1: 0.628750, top_k: 0.837148, samples/s: 2233.356 1612418198.081106
train: epoch 107, iter 2300, loss: 2.536438, top_1: 0.623984, top_k: 0.834141, samples/s: 2223.064 1612418209.596769
train: epoch 107, iter 2400, loss: 2.581626, top_1: 0.636367, top_k: 0.837734, samples/s: 2226.486 1612418221.0946856
train: epoch 107, iter 2500, loss: 2.671496, top_1: 0.628320, top_k: 0.835039, samples/s: 2229.719 1612418232.5758622
train: epoch 107, iter 2600, loss: 2.296112, top_1: 0.631992, top_k: 0.835664, samples/s: 2233.857 1612418244.0359128
train: epoch 107, iter 2700, loss: 2.579669, top_1: 0.629922, top_k: 0.831758, samples/s: 2237.135 1612418255.4791033
train: epoch 107, iter 2800, loss: 2.521163, top_1: 0.627109, top_k: 0.835391, samples/s: 2235.135 1612418266.932532
train: epoch 107, iter 2900, loss: 2.521735, top_1: 0.634414, top_k: 0.838594, samples/s: 2238.427 1612418278.37065
train: epoch 107, iter 3000, loss: 2.525848, top_1: 0.631211, top_k: 0.835859, samples/s: 2220.069 1612418289.9003272
train: epoch 107, iter 3100, loss: 2.495588, top_1: 0.633047, top_k: 0.839727, samples/s: 2241.430 1612418301.321594
train: epoch 107, iter 3200, loss: 2.736372, top_1: 0.631172, top_k: 0.838086, samples/s: 2225.456 1612418312.825261
train: epoch 107, iter 3300, loss: 2.603014, top_1: 0.627930, top_k: 0.837930, samples/s: 2229.785 1612418324.305811
train: epoch 107, iter 3400, loss: 2.643242, top_1: 0.631953, top_k: 0.837930, samples/s: 2238.552 1612418335.742177
train: epoch 107, iter 3500, loss: 2.497049, top_1: 0.632305, top_k: 0.837891, samples/s: 2217.955 1612418347.2839792
train: epoch 107, iter 3600, loss: 2.418252, top_1: 0.632344, top_k: 0.833047, samples/s: 2233.753 1612418358.7447476
train: epoch 107, iter 3700, loss: 2.490371, top_1: 0.628672, top_k: 0.834297, samples/s: 2223.280 1612418370.2590446
train: epoch 107, iter 3800, loss: 2.430025, top_1: 0.626836, top_k: 0.833008, samples/s: 2237.000 1612418381.7028964
train: epoch 107, iter 3900, loss: 2.708917, top_1: 0.633320, top_k: 0.838594, samples/s: 2228.349 1612418393.1912498
train: epoch 107, iter 4000, loss: 2.617546, top_1: 0.631523, top_k: 0.834297, samples/s: 2239.259 1612418404.6235116
train: epoch 107, iter 4100, loss: 2.444043, top_1: 0.628516, top_k: 0.835313, samples/s: 2222.397 1612418416.1426766
train: epoch 107, iter 4200, loss: 2.552252, top_1: 0.632969, top_k: 0.836719, samples/s: 2241.366 1612418427.5642092
train: epoch 107, iter 4300, loss: 2.541021, top_1: 0.629180, top_k: 0.835117, samples/s: 2224.960 1612418439.0700357
train: epoch 107, iter 4400, loss: 2.326866, top_1: 0.630625, top_k: 0.835781, samples/s: 2211.586 1612418450.6454651
train: epoch 107, iter 4500, loss: 2.572816, top_1: 0.625234, top_k: 0.833125, samples/s: 2228.380 1612418462.1337004
train: epoch 107, iter 4600, loss: 2.518601, top_1: 0.630391, top_k: 0.835898, samples/s: 2234.859 1612418473.588481
train: epoch 107, iter 4700, loss: 2.681920, top_1: 0.626602, top_k: 0.837500, samples/s: 2213.376 1612418485.1545193
train: epoch 107, iter 4800, loss: 2.626663, top_1: 0.629180, top_k: 0.835742, samples/s: 2226.957 1612418496.6500134
train: epoch 107, iter 4900, loss: 2.466581, top_1: 0.630625, top_k: 0.838086, samples/s: 2238.143 1612418508.088063
train: epoch 107, iter 5000, loss: 2.404214, top_1: 0.642383, top_k: 0.844102, samples/s: 2219.330 1612418519.62308
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_107.
validation: epoch 107, iter 195, top_1: 0.671735, top_k: 0.880128, samples/s: 2938.015 1612418536.9547794
train: epoch 108, iter 100, loss: 2.429053, top_1: 0.643672, top_k: 0.841875, samples/s: 2245.266 1612418564.3585591
train: epoch 108, iter 200, loss: 2.486701, top_1: 0.640625, top_k: 0.847109, samples/s: 2225.729 1612418575.8603802
train: epoch 108, iter 300, loss: 2.443275, top_1: 0.640117, top_k: 0.842695, samples/s: 2235.440 1612418587.312275
train: epoch 108, iter 400, loss: 2.469619, top_1: 0.635430, top_k: 0.840820, samples/s: 2267.829 1612418598.6006544
train: epoch 108, iter 500, loss: 2.612870, top_1: 0.642070, top_k: 0.845625, samples/s: 2252.758 1612418609.964483
train: epoch 108, iter 600, loss: 2.458247, top_1: 0.634375, top_k: 0.837148, samples/s: 2256.272 1612418621.3107023
train: epoch 108, iter 700, loss: 2.654407, top_1: 0.637266, top_k: 0.843594, samples/s: 2238.533 1612418632.7466893
train: epoch 108, iter 800, loss: 2.671554, top_1: 0.639805, top_k: 0.842891, samples/s: 2224.019 1612418644.257343
train: epoch 108, iter 900, loss: 2.376972, top_1: 0.637695, top_k: 0.842656, samples/s: 2207.247 1612418655.8555624
train: epoch 108, iter 1000, loss: 2.487080, top_1: 0.632344, top_k: 0.841328, samples/s: 2205.817 1612418667.4612465
train: epoch 108, iter 1100, loss: 2.327865, top_1: 0.640195, top_k: 0.839688, samples/s: 2203.363 1612418679.079787
train: epoch 108, iter 1200, loss: 2.452506, top_1: 0.640273, top_k: 0.841719, samples/s: 2209.125 1612418690.6680884
train: epoch 108, iter 1300, loss: 2.643153, top_1: 0.632422, top_k: 0.839258, samples/s: 2204.323 1612418702.2821972
train: epoch 108, iter 1400, loss: 2.490096, top_1: 0.639414, top_k: 0.845234, samples/s: 2223.857 1612418713.7931628
train: epoch 108, iter 1500, loss: 2.429306, top_1: 0.635781, top_k: 0.839219, samples/s: 2227.524 1612418725.2857504
train: epoch 108, iter 1600, loss: 2.568340, top_1: 0.629336, top_k: 0.835703, samples/s: 2231.866 1612418736.7560098
train: epoch 108, iter 1700, loss: 2.395164, top_1: 0.637305, top_k: 0.839375, samples/s: 2211.843 1612418748.3303585
train: epoch 108, iter 1800, loss: 2.476880, top_1: 0.628516, top_k: 0.835352, samples/s: 2239.286 1612418759.7622375
train: epoch 108, iter 1900, loss: 2.684646, top_1: 0.640547, top_k: 0.840273, samples/s: 2229.277 1612418771.2458386
train: epoch 108, iter 2000, loss: 2.639953, top_1: 0.629141, top_k: 0.836562, samples/s: 2221.479 1612418782.7696292
train: epoch 108, iter 2100, loss: 2.439538, top_1: 0.632734, top_k: 0.838750, samples/s: 2236.622 1612418794.2155068
train: epoch 108, iter 2200, loss: 2.573534, top_1: 0.630195, top_k: 0.838398, samples/s: 2220.634 1612418805.7437599
train: epoch 108, iter 2300, loss: 2.717634, top_1: 0.634687, top_k: 0.839883, samples/s: 2248.400 1612418817.1296074
train: epoch 108, iter 2400, loss: 2.399961, top_1: 0.632383, top_k: 0.838906, samples/s: 2237.421 1612418828.571292
train: epoch 108, iter 2500, loss: 2.541605, top_1: 0.630469, top_k: 0.835781, samples/s: 2213.000 1612418840.1393373
train: epoch 108, iter 2600, loss: 2.713044, top_1: 0.633125, top_k: 0.835078, samples/s: 2223.995 1612418851.6501584
train: epoch 108, iter 2700, loss: 2.401983, top_1: 0.639141, top_k: 0.838047, samples/s: 2243.839 1612418863.0592263
train: epoch 108, iter 2800, loss: 2.613413, top_1: 0.632617, top_k: 0.837148, samples/s: 2213.002 1612418874.627161
train: epoch 108, iter 2900, loss: 2.514535, top_1: 0.633164, top_k: 0.836562, samples/s: 2220.195 1612418886.157675
train: epoch 108, iter 3000, loss: 2.746714, top_1: 0.635117, top_k: 0.840664, samples/s: 2236.476 1612418897.6043491
train: epoch 108, iter 3100, loss: 2.479896, top_1: 0.630703, top_k: 0.834375, samples/s: 2245.150 1612418909.0067523
train: epoch 108, iter 3200, loss: 2.462044, top_1: 0.637344, top_k: 0.839414, samples/s: 2216.110 1612418920.5584104
train: epoch 108, iter 3300, loss: 2.462780, top_1: 0.634375, top_k: 0.839609, samples/s: 2244.117 1612418931.9659996
train: epoch 108, iter 3400, loss: 2.377348, top_1: 0.634844, top_k: 0.838398, samples/s: 2217.754 1612418943.509241
train: epoch 108, iter 3500, loss: 2.458298, top_1: 0.633477, top_k: 0.838711, samples/s: 2254.001 1612418954.8667655
train: epoch 108, iter 3600, loss: 2.663229, top_1: 0.632500, top_k: 0.838125, samples/s: 2197.964 1612418966.5140123
train: epoch 108, iter 3700, loss: 2.568080, top_1: 0.632695, top_k: 0.836836, samples/s: 2229.595 1612418977.9958556
train: epoch 108, iter 3800, loss: 2.398724, top_1: 0.629219, top_k: 0.835977, samples/s: 2218.209 1612418989.5367324
train: epoch 108, iter 3900, loss: 2.733795, top_1: 0.631445, top_k: 0.840820, samples/s: 2229.027 1612419001.0215828
train: epoch 108, iter 4000, loss: 2.279012, top_1: 0.633633, top_k: 0.839609, samples/s: 2235.925 1612419012.4709752
train: epoch 108, iter 4100, loss: 2.628686, top_1: 0.634570, top_k: 0.838398, samples/s: 2228.555 1612419023.9581947
train: epoch 108, iter 4200, loss: 2.632374, top_1: 0.633125, top_k: 0.836016, samples/s: 2229.296 1612419035.4416795
train: epoch 108, iter 4300, loss: 2.503891, top_1: 0.634648, top_k: 0.840195, samples/s: 2237.486 1612419046.8830488
train: epoch 108, iter 4400, loss: 2.383003, top_1: 0.631016, top_k: 0.834609, samples/s: 2247.459 1612419058.2738364
train: epoch 108, iter 4500, loss: 2.555882, top_1: 0.638633, top_k: 0.840820, samples/s: 2230.183 1612419069.7525673
train: epoch 108, iter 4600, loss: 2.580961, top_1: 0.632227, top_k: 0.834336, samples/s: 2231.727 1612419081.2234948
train: epoch 108, iter 4700, loss: 2.394182, top_1: 0.632734, top_k: 0.838437, samples/s: 2239.427 1612419092.6550648
train: epoch 108, iter 4800, loss: 2.469192, top_1: 0.631992, top_k: 0.838398, samples/s: 2233.845 1612419104.1150422
train: epoch 108, iter 4900, loss: 2.577949, top_1: 0.627500, top_k: 0.833438, samples/s: 2219.915 1612419115.6470172
train: epoch 108, iter 5000, loss: 2.549220, top_1: 0.633242, top_k: 0.840977, samples/s: 2241.174 1612419127.0695596
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_108.
validation: epoch 108, iter 195, top_1: 0.673377, top_k: 0.878946, samples/s: 2929.122 1612419144.4522808
train: epoch 109, iter 100, loss: 2.433331, top_1: 0.640234, top_k: 0.842930, samples/s: 2244.501 1612419176.6084769
train: epoch 109, iter 200, loss: 2.426710, top_1: 0.644102, top_k: 0.845469, samples/s: 2258.023 1612419187.9458077
train: epoch 109, iter 300, loss: 2.513158, top_1: 0.641406, top_k: 0.840039, samples/s: 2243.003 1612419199.3590832
train: epoch 109, iter 400, loss: 2.402659, top_1: 0.643789, top_k: 0.843633, samples/s: 2224.189 1612419210.868949
train: epoch 109, iter 500, loss: 2.488295, top_1: 0.641602, top_k: 0.843633, samples/s: 2254.897 1612419222.221963
train: epoch 109, iter 600, loss: 2.389066, top_1: 0.642852, top_k: 0.844023, samples/s: 2256.991 1612419233.5646017
train: epoch 109, iter 700, loss: 2.570100, top_1: 0.633164, top_k: 0.839492, samples/s: 2241.767 1612419244.9841077
train: epoch 109, iter 800, loss: 2.650829, top_1: 0.634453, top_k: 0.840430, samples/s: 2222.720 1612419256.5015464
train: epoch 109, iter 900, loss: 2.547489, top_1: 0.636523, top_k: 0.845000, samples/s: 2234.249 1612419267.9594915
train: epoch 109, iter 1000, loss: 2.707991, top_1: 0.636875, top_k: 0.840273, samples/s: 2210.484 1612419279.5406513
train: epoch 109, iter 1100, loss: 2.437473, top_1: 0.639336, top_k: 0.845273, samples/s: 2215.445 1612419291.0959504
train: epoch 109, iter 1200, loss: 2.492046, top_1: 0.641602, top_k: 0.844531, samples/s: 2217.736 1612419302.639195
train: epoch 109, iter 1300, loss: 2.447143, top_1: 0.638398, top_k: 0.846172, samples/s: 2207.174 1612419314.237738
train: epoch 109, iter 1400, loss: 2.696946, top_1: 0.641758, top_k: 0.842422, samples/s: 2220.183 1612419325.768313
train: epoch 109, iter 1500, loss: 2.459887, top_1: 0.639687, top_k: 0.841016, samples/s: 2203.554 1612419337.3859406
train: epoch 109, iter 1600, loss: 2.470106, top_1: 0.637539, top_k: 0.839297, samples/s: 2232.672 1612419348.8519864
train: epoch 109, iter 1700, loss: 2.431999, top_1: 0.633906, top_k: 0.840586, samples/s: 2230.522 1612419360.329192
train: epoch 109, iter 1800, loss: 2.530070, top_1: 0.639258, top_k: 0.844023, samples/s: 2230.313 1612419371.8073409
train: epoch 109, iter 1900, loss: 2.534835, top_1: 0.646406, top_k: 0.846367, samples/s: 2216.137 1612419383.3589582
train: epoch 109, iter 2000, loss: 2.412762, top_1: 0.635625, top_k: 0.838828, samples/s: 2213.472 1612419394.9245493
train: epoch 109, iter 2100, loss: 2.509253, top_1: 0.642227, top_k: 0.844727, samples/s: 2230.544 1612419406.4015226
train: epoch 109, iter 2200, loss: 2.577646, top_1: 0.632227, top_k: 0.840547, samples/s: 2227.323 1612419417.8951485
train: epoch 109, iter 2300, loss: 2.712794, top_1: 0.636680, top_k: 0.839258, samples/s: 2224.542 1612419429.4031565
train: epoch 109, iter 2400, loss: 2.568132, top_1: 0.636602, top_k: 0.838828, samples/s: 2230.681 1612419440.8794458
train: epoch 109, iter 2500, loss: 2.504347, top_1: 0.634297, top_k: 0.837930, samples/s: 2201.625 1612419452.5072286
train: epoch 109, iter 2600, loss: 2.530741, top_1: 0.633633, top_k: 0.839805, samples/s: 2230.733 1612419463.983281
train: epoch 109, iter 2700, loss: 2.563246, top_1: 0.637656, top_k: 0.837227, samples/s: 2238.075 1612419475.4216635
train: epoch 109, iter 2800, loss: 2.555445, top_1: 0.636445, top_k: 0.841016, samples/s: 2226.464 1612419486.9197924
train: epoch 109, iter 2900, loss: 2.571053, top_1: 0.637695, top_k: 0.844336, samples/s: 2238.471 1612419498.3561008
train: epoch 109, iter 3000, loss: 2.459319, top_1: 0.632109, top_k: 0.842109, samples/s: 2225.386 1612419509.8597894
train: epoch 109, iter 3100, loss: 2.441667, top_1: 0.631992, top_k: 0.837930, samples/s: 2227.434 1612419521.3527777
train: epoch 109, iter 3200, loss: 2.425567, top_1: 0.634375, top_k: 0.840078, samples/s: 2225.990 1612419532.8532746
train: epoch 109, iter 3300, loss: 2.603753, top_1: 0.636680, top_k: 0.839688, samples/s: 2229.684 1612419544.3347244
train: epoch 109, iter 3400, loss: 2.419751, top_1: 0.636680, top_k: 0.838359, samples/s: 2230.954 1612419555.8096282
train: epoch 109, iter 3500, loss: 2.442587, top_1: 0.636211, top_k: 0.840859, samples/s: 2217.129 1612419567.3561344
train: epoch 109, iter 3600, loss: 2.446033, top_1: 0.637891, top_k: 0.842578, samples/s: 2215.634 1612419578.9103503
train: epoch 109, iter 3700, loss: 2.555371, top_1: 0.641250, top_k: 0.840313, samples/s: 2222.445 1612419590.4292593
train: epoch 109, iter 3800, loss: 2.472112, top_1: 0.632617, top_k: 0.841914, samples/s: 2228.752 1612419601.9154532
train: epoch 109, iter 3900, loss: 2.468471, top_1: 0.629414, top_k: 0.835273, samples/s: 2232.066 1612419613.3847027
train: epoch 109, iter 4000, loss: 2.446866, top_1: 0.637813, top_k: 0.836641, samples/s: 2237.803 1612419624.8245187
train: epoch 109, iter 4100, loss: 2.537226, top_1: 0.634961, top_k: 0.839766, samples/s: 2227.974 1612419636.314695
train: epoch 109, iter 4200, loss: 2.522238, top_1: 0.629961, top_k: 0.839727, samples/s: 2231.979 1612419647.7843375
train: epoch 109, iter 4300, loss: 2.568157, top_1: 0.631914, top_k: 0.836484, samples/s: 2239.462 1612419659.215668
train: epoch 109, iter 4400, loss: 2.366066, top_1: 0.637266, top_k: 0.841445, samples/s: 2225.666 1612419670.7178032
train: epoch 109, iter 4500, loss: 2.704337, top_1: 0.637305, top_k: 0.836992, samples/s: 2221.082 1612419682.2437267
train: epoch 109, iter 4600, loss: 2.752059, top_1: 0.629023, top_k: 0.837344, samples/s: 2223.795 1612419693.7555518
train: epoch 109, iter 4700, loss: 2.518564, top_1: 0.632969, top_k: 0.838320, samples/s: 2229.019 1612419705.2405143
train: epoch 109, iter 4800, loss: 2.233897, top_1: 0.634727, top_k: 0.839023, samples/s: 2252.634 1612419716.6050754
train: epoch 109, iter 4900, loss: 2.433997, top_1: 0.632930, top_k: 0.841328, samples/s: 2221.195 1612419728.1303256
train: epoch 109, iter 5000, loss: 2.481505, top_1: 0.635820, top_k: 0.841719, samples/s: 2225.321 1612419739.6342702
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_109.
validation: epoch 109, iter 195, top_1: 0.677404, top_k: 0.882051, samples/s: 2923.165 1612419757.0397866
train: epoch 110, iter 100, loss: 2.411841, top_1: 0.646016, top_k: 0.847500, samples/s: 2217.757 1612419784.2626586
train: epoch 110, iter 200, loss: 2.397580, top_1: 0.651875, top_k: 0.853086, samples/s: 2251.641 1612419795.6321266
train: epoch 110, iter 300, loss: 2.557638, top_1: 0.644648, top_k: 0.847656, samples/s: 2220.488 1612419807.1610732
train: epoch 110, iter 400, loss: 2.409076, top_1: 0.647266, top_k: 0.846406, samples/s: 2243.782 1612419818.570364
train: epoch 110, iter 500, loss: 2.534735, top_1: 0.640898, top_k: 0.845586, samples/s: 2266.235 1612419829.866688
train: epoch 110, iter 600, loss: 2.488472, top_1: 0.644141, top_k: 0.846602, samples/s: 2245.629 1612419841.2665532
train: epoch 110, iter 700, loss: 2.478255, top_1: 0.645781, top_k: 0.846289, samples/s: 2253.120 1612419852.6285827
train: epoch 110, iter 800, loss: 2.611084, top_1: 0.640078, top_k: 0.844336, samples/s: 2211.366 1612419864.2051451
train: epoch 110, iter 900, loss: 2.396298, top_1: 0.646094, top_k: 0.845195, samples/s: 2220.469 1612419875.7342482
train: epoch 110, iter 1000, loss: 2.370594, top_1: 0.642148, top_k: 0.845117, samples/s: 2217.390 1612419887.2793603
train: epoch 110, iter 1100, loss: 2.398490, top_1: 0.642891, top_k: 0.847578, samples/s: 2200.917 1612419898.910847
train: epoch 110, iter 1200, loss: 2.476083, top_1: 0.642930, top_k: 0.845195, samples/s: 2197.867 1612419910.5585191
train: epoch 110, iter 1300, loss: 2.568907, top_1: 0.640859, top_k: 0.843086, samples/s: 2226.614 1612419922.0558324
train: epoch 110, iter 1400, loss: 2.348128, top_1: 0.641641, top_k: 0.842109, samples/s: 2207.010 1612419933.6552017
train: epoch 110, iter 1500, loss: 2.496521, top_1: 0.640430, top_k: 0.843906, samples/s: 2215.522 1612419945.210076
train: epoch 110, iter 1600, loss: 2.441633, top_1: 0.636797, top_k: 0.843320, samples/s: 2235.891 1612419956.6596029
train: epoch 110, iter 1700, loss: 2.257761, top_1: 0.639453, top_k: 0.840820, samples/s: 2195.224 1612419968.3212912
train: epoch 110, iter 1800, loss: 2.592526, top_1: 0.637578, top_k: 0.841953, samples/s: 2217.902 1612419979.8637736
train: epoch 110, iter 1900, loss: 2.316508, top_1: 0.638359, top_k: 0.843633, samples/s: 2230.420 1612419991.3414328
train: epoch 110, iter 2000, loss: 2.494505, top_1: 0.640430, top_k: 0.842773, samples/s: 2231.418 1612420002.8139129
train: epoch 110, iter 2100, loss: 2.573308, top_1: 0.634961, top_k: 0.839492, samples/s: 2227.060 1612420014.3089683
train: epoch 110, iter 2200, loss: 2.610522, top_1: 0.638047, top_k: 0.840391, samples/s: 2228.878 1612420025.794519
train: epoch 110, iter 2300, loss: 2.594231, top_1: 0.634766, top_k: 0.844727, samples/s: 2222.636 1612420037.3123448
train: epoch 110, iter 2400, loss: 2.481162, top_1: 0.637227, top_k: 0.841445, samples/s: 2206.325 1612420048.9154737
train: epoch 110, iter 2500, loss: 2.647570, top_1: 0.638633, top_k: 0.843320, samples/s: 2237.590 1612420060.35625
train: epoch 110, iter 2600, loss: 2.429652, top_1: 0.639180, top_k: 0.843516, samples/s: 2242.369 1612420071.7727342
train: epoch 110, iter 2700, loss: 2.537641, top_1: 0.638437, top_k: 0.839766, samples/s: 2220.596 1612420083.3012502
train: epoch 110, iter 2800, loss: 2.607112, top_1: 0.639141, top_k: 0.844453, samples/s: 2216.409 1612420094.851376
train: epoch 110, iter 2900, loss: 2.391884, top_1: 0.636094, top_k: 0.840117, samples/s: 2216.169 1612420106.402852
train: epoch 110, iter 3000, loss: 2.646733, top_1: 0.635586, top_k: 0.839258, samples/s: 2238.613 1612420117.8384945
train: epoch 110, iter 3100, loss: 2.386854, top_1: 0.634922, top_k: 0.843203, samples/s: 2228.846 1612420129.3242488
train: epoch 110, iter 3200, loss: 2.529243, top_1: 0.637852, top_k: 0.841562, samples/s: 2235.923 1612420140.7738197
train: epoch 110, iter 3300, loss: 2.504156, top_1: 0.629961, top_k: 0.838437, samples/s: 2226.720 1612420152.2704923
train: epoch 110, iter 3400, loss: 2.583717, top_1: 0.644336, top_k: 0.843125, samples/s: 2228.737 1612420163.7567744
train: epoch 110, iter 3500, loss: 2.785499, top_1: 0.634883, top_k: 0.842227, samples/s: 2222.989 1612420175.2728212
train: epoch 110, iter 3600, loss: 2.539854, top_1: 0.636211, top_k: 0.841562, samples/s: 2224.796 1612420186.7794895
train: epoch 110, iter 3700, loss: 2.560379, top_1: 0.634492, top_k: 0.838789, samples/s: 2217.534 1612420198.323791
train: epoch 110, iter 3800, loss: 2.397770, top_1: 0.633359, top_k: 0.841914, samples/s: 2232.299 1612420209.7924826
train: epoch 110, iter 3900, loss: 2.441922, top_1: 0.634805, top_k: 0.841562, samples/s: 2227.995 1612420221.2819812
train: epoch 110, iter 4000, loss: 2.566476, top_1: 0.634687, top_k: 0.837227, samples/s: 2239.162 1612420232.7151487
train: epoch 110, iter 4100, loss: 2.618668, top_1: 0.638477, top_k: 0.840625, samples/s: 2238.970 1612420244.148657
train: epoch 110, iter 4200, loss: 2.766083, top_1: 0.635000, top_k: 0.842461, samples/s: 2228.426 1612420255.636541
train: epoch 110, iter 4300, loss: 2.511320, top_1: 0.642422, top_k: 0.845391, samples/s: 2209.895 1612420267.2208633
train: epoch 110, iter 4400, loss: 2.633363, top_1: 0.633750, top_k: 0.837891, samples/s: 2237.154 1612420278.663902
train: epoch 110, iter 4500, loss: 2.512060, top_1: 0.634609, top_k: 0.838828, samples/s: 2228.551 1612420290.1511993
train: epoch 110, iter 4600, loss: 2.498234, top_1: 0.642383, top_k: 0.843555, samples/s: 2228.056 1612420301.6411932
train: epoch 110, iter 4700, loss: 2.513758, top_1: 0.634062, top_k: 0.840313, samples/s: 2229.091 1612420313.125583
train: epoch 110, iter 4800, loss: 2.521296, top_1: 0.636016, top_k: 0.841680, samples/s: 2195.771 1612420324.7846675
train: epoch 110, iter 4900, loss: 2.508667, top_1: 0.633633, top_k: 0.837422, samples/s: 2236.776 1612420336.2293417
train: epoch 110, iter 5000, loss: 2.547996, top_1: 0.644883, top_k: 0.844141, samples/s: 2218.174 1612420347.7703848
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_110.
validation: epoch 110, iter 195, top_1: 0.674960, top_k: 0.881871, samples/s: 2910.673 1612420365.2762158
train: epoch 111, iter 100, loss: 2.347349, top_1: 0.647422, top_k: 0.844961, samples/s: 2233.739 1612420392.9086008
train: epoch 111, iter 200, loss: 2.456185, top_1: 0.647031, top_k: 0.846719, samples/s: 2256.522 1612420404.2538385
train: epoch 111, iter 300, loss: 2.519105, top_1: 0.646016, top_k: 0.846484, samples/s: 2247.793 1612420415.642413
train: epoch 111, iter 400, loss: 2.322017, top_1: 0.649023, top_k: 0.847266, samples/s: 2254.601 1612420426.9970212
train: epoch 111, iter 500, loss: 2.419054, top_1: 0.655859, top_k: 0.854297, samples/s: 2251.183 1612420438.3687932
train: epoch 111, iter 600, loss: 2.353184, top_1: 0.646758, top_k: 0.842031, samples/s: 2242.577 1612420449.7842352
train: epoch 111, iter 700, loss: 2.650447, top_1: 0.641406, top_k: 0.845352, samples/s: 2249.340 1612420461.165343
train: epoch 111, iter 800, loss: 2.358503, top_1: 0.642227, top_k: 0.845469, samples/s: 2229.534 1612420472.6475842
train: epoch 111, iter 900, loss: 2.613052, top_1: 0.646484, top_k: 0.850313, samples/s: 2230.295 1612420484.1266804
train: epoch 111, iter 1000, loss: 2.515558, top_1: 0.646719, top_k: 0.845664, samples/s: 2225.253 1612420495.630334
train: epoch 111, iter 1100, loss: 2.507035, top_1: 0.646953, top_k: 0.844727, samples/s: 2232.185 1612420507.098735
train: epoch 111, iter 1200, loss: 2.736042, top_1: 0.649102, top_k: 0.849023, samples/s: 2250.387 1612420518.4745538
train: epoch 111, iter 1300, loss: 2.348986, top_1: 0.644180, top_k: 0.846602, samples/s: 2216.663 1612420530.0234883
train: epoch 111, iter 1400, loss: 2.612971, top_1: 0.641563, top_k: 0.844336, samples/s: 2219.034 1612420541.5600035
train: epoch 111, iter 1500, loss: 2.490766, top_1: 0.644922, top_k: 0.843711, samples/s: 2218.912 1612420553.0972095
train: epoch 111, iter 1600, loss: 2.430534, top_1: 0.640625, top_k: 0.842578, samples/s: 2220.866 1612420564.6242359
train: epoch 111, iter 1700, loss: 2.492102, top_1: 0.640352, top_k: 0.843594, samples/s: 2240.698 1612420576.0492318
train: epoch 111, iter 1800, loss: 2.357724, top_1: 0.640000, top_k: 0.841953, samples/s: 2224.950 1612420587.5551543
train: epoch 111, iter 1900, loss: 2.415436, top_1: 0.647773, top_k: 0.847969, samples/s: 2191.207 1612420599.2382207
train: epoch 111, iter 2000, loss: 2.391060, top_1: 0.645859, top_k: 0.846328, samples/s: 2224.994 1612420610.7438197
train: epoch 111, iter 2100, loss: 2.540997, top_1: 0.641719, top_k: 0.847187, samples/s: 2216.967 1612420622.2911363
train: epoch 111, iter 2200, loss: 2.641985, top_1: 0.638320, top_k: 0.842070, samples/s: 2233.138 1612420633.7548912
train: epoch 111, iter 2300, loss: 2.362060, top_1: 0.641641, top_k: 0.843633, samples/s: 2235.844 1612420645.2046738
train: epoch 111, iter 2400, loss: 2.664659, top_1: 0.642305, top_k: 0.842812, samples/s: 2228.976 1612420656.6897304
train: epoch 111, iter 2500, loss: 2.497053, top_1: 0.641406, top_k: 0.840391, samples/s: 2229.884 1612420668.1701875
train: epoch 111, iter 2600, loss: 2.305901, top_1: 0.638633, top_k: 0.839375, samples/s: 2188.675 1612420679.8667068
train: epoch 111, iter 2700, loss: 2.351723, top_1: 0.641055, top_k: 0.843828, samples/s: 2207.968 1612420691.4610825
train: epoch 111, iter 2800, loss: 2.319084, top_1: 0.639609, top_k: 0.843945, samples/s: 2224.350 1612420702.9700596
train: epoch 111, iter 2900, loss: 2.435216, top_1: 0.640703, top_k: 0.843086, samples/s: 2208.517 1612420714.5615551
train: epoch 111, iter 3000, loss: 2.411619, top_1: 0.640859, top_k: 0.843945, samples/s: 2222.273 1612420726.0812798
train: epoch 111, iter 3100, loss: 2.566410, top_1: 0.641406, top_k: 0.843555, samples/s: 2210.166 1612420737.6641417
train: epoch 111, iter 3200, loss: 2.475054, top_1: 0.644414, top_k: 0.847070, samples/s: 2238.362 1612420749.1010847
train: epoch 111, iter 3300, loss: 2.489904, top_1: 0.638398, top_k: 0.843437, samples/s: 2230.745 1612420760.5771046
train: epoch 111, iter 3400, loss: 2.539377, top_1: 0.638203, top_k: 0.842148, samples/s: 2229.353 1612420772.0602245
train: epoch 111, iter 3500, loss: 2.450114, top_1: 0.637383, top_k: 0.844063, samples/s: 2209.267 1612420783.647838
train: epoch 111, iter 3600, loss: 2.350667, top_1: 0.638086, top_k: 0.844102, samples/s: 2232.423 1612420795.1156096
train: epoch 111, iter 3700, loss: 2.449641, top_1: 0.639531, top_k: 0.842461, samples/s: 2219.485 1612420806.6493573
train: epoch 111, iter 3800, loss: 2.403485, top_1: 0.641328, top_k: 0.844883, samples/s: 2228.040 1612420818.1393137
train: epoch 111, iter 3900, loss: 2.444653, top_1: 0.635156, top_k: 0.841211, samples/s: 2234.748 1612420829.595066
train: epoch 111, iter 4000, loss: 2.488647, top_1: 0.643047, top_k: 0.846172, samples/s: 2223.386 1612420841.1086867
train: epoch 111, iter 4100, loss: 2.605453, top_1: 0.638984, top_k: 0.842070, samples/s: 2221.183 1612420852.634069
train: epoch 111, iter 4200, loss: 2.477901, top_1: 0.635039, top_k: 0.838164, samples/s: 2219.677 1612420864.1678138
train: epoch 111, iter 4300, loss: 2.637692, top_1: 0.640352, top_k: 0.840977, samples/s: 2228.782 1612420875.653354
train: epoch 111, iter 4400, loss: 2.465253, top_1: 0.640547, top_k: 0.843477, samples/s: 2219.112 1612420887.18953
train: epoch 111, iter 4500, loss: 2.551290, top_1: 0.642500, top_k: 0.842734, samples/s: 2214.881 1612420898.7477105
train: epoch 111, iter 4600, loss: 2.444754, top_1: 0.639023, top_k: 0.841406, samples/s: 2240.542 1612420910.1738594
train: epoch 111, iter 4700, loss: 2.344293, top_1: 0.636680, top_k: 0.841992, samples/s: 2216.625 1612420921.7226174
train: epoch 111, iter 4800, loss: 2.413867, top_1: 0.637109, top_k: 0.839219, samples/s: 2231.055 1612420933.1970472
train: epoch 111, iter 4900, loss: 2.391539, top_1: 0.640625, top_k: 0.845625, samples/s: 2240.239 1612420944.6243224
train: epoch 111, iter 5000, loss: 2.397778, top_1: 0.639727, top_k: 0.842539, samples/s: 2218.165 1612420956.1653953
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_111.
validation: epoch 111, iter 195, top_1: 0.676462, top_k: 0.881350, samples/s: 3003.238 1612420973.0817637
train: epoch 112, iter 100, loss: 2.434209, top_1: 0.644297, top_k: 0.843789, samples/s: 2205.846 1612421001.053779
train: epoch 112, iter 200, loss: 2.436212, top_1: 0.638281, top_k: 0.846016, samples/s: 2246.099 1612421012.4513342
train: epoch 112, iter 300, loss: 2.497819, top_1: 0.648555, top_k: 0.850625, samples/s: 2248.471 1612421023.8368127
train: epoch 112, iter 400, loss: 2.528043, top_1: 0.649844, top_k: 0.849648, samples/s: 2249.560 1612421035.2168324
train: epoch 112, iter 500, loss: 2.559322, top_1: 0.652070, top_k: 0.852187, samples/s: 2250.791 1612421046.5905995
train: epoch 112, iter 600, loss: 2.555615, top_1: 0.650586, top_k: 0.850078, samples/s: 2242.733 1612421058.0052495
train: epoch 112, iter 700, loss: 2.483857, top_1: 0.646484, top_k: 0.845820, samples/s: 2234.126 1612421069.4638617
train: epoch 112, iter 800, loss: 2.515940, top_1: 0.649687, top_k: 0.850156, samples/s: 2214.756 1612421081.0226967
train: epoch 112, iter 900, loss: 2.409704, top_1: 0.648086, top_k: 0.849688, samples/s: 2201.440 1612421092.6514478
train: epoch 112, iter 1000, loss: 2.540168, top_1: 0.644883, top_k: 0.846016, samples/s: 2186.180 1612421104.3613732
train: epoch 112, iter 1100, loss: 2.609248, top_1: 0.647109, top_k: 0.846562, samples/s: 2229.827 1612421115.842095
train: epoch 112, iter 1200, loss: 2.536385, top_1: 0.647891, top_k: 0.846094, samples/s: 2198.797 1612421127.4848135
train: epoch 112, iter 1300, loss: 2.346531, top_1: 0.646211, top_k: 0.848320, samples/s: 2239.718 1612421138.914825
train: epoch 112, iter 1400, loss: 2.555841, top_1: 0.649531, top_k: 0.846211, samples/s: 2237.958 1612421150.3538337
train: epoch 112, iter 1500, loss: 2.483708, top_1: 0.646797, top_k: 0.850586, samples/s: 2233.863 1612421161.8137932
train: epoch 112, iter 1600, loss: 2.515534, top_1: 0.645039, top_k: 0.845313, samples/s: 2212.451 1612421173.3847122
train: epoch 112, iter 1700, loss: 2.529941, top_1: 0.643672, top_k: 0.842148, samples/s: 2204.947 1612421184.99494
train: epoch 112, iter 1800, loss: 2.601711, top_1: 0.644336, top_k: 0.846641, samples/s: 2236.135 1612421196.4432793
train: epoch 112, iter 1900, loss: 2.424347, top_1: 0.645273, top_k: 0.848711, samples/s: 2222.553 1612421207.9615836
train: epoch 112, iter 2000, loss: 2.609612, top_1: 0.646445, top_k: 0.847578, samples/s: 2190.571 1612421219.648084
train: epoch 112, iter 2100, loss: 2.540960, top_1: 0.642813, top_k: 0.843672, samples/s: 2258.221 1612421230.9843817
train: epoch 112, iter 2200, loss: 2.481249, top_1: 0.642852, top_k: 0.847383, samples/s: 2234.481 1612421242.4411538
train: epoch 112, iter 2300, loss: 2.481991, top_1: 0.644961, top_k: 0.848437, samples/s: 2170.515 1612421254.2357626
train: epoch 112, iter 2400, loss: 2.628020, top_1: 0.636016, top_k: 0.845859, samples/s: 2248.353 1612421265.6216981
train: epoch 112, iter 2500, loss: 2.451242, top_1: 0.643945, top_k: 0.845586, samples/s: 2219.115 1612421277.1578157
train: epoch 112, iter 2600, loss: 2.677406, top_1: 0.642773, top_k: 0.843555, samples/s: 2237.808 1612421288.597588
train: epoch 112, iter 2700, loss: 2.564577, top_1: 0.641445, top_k: 0.844297, samples/s: 2215.066 1612421300.1548126
train: epoch 112, iter 2800, loss: 2.270719, top_1: 0.646016, top_k: 0.845156, samples/s: 2221.546 1612421311.6783204
train: epoch 112, iter 2900, loss: 2.556422, top_1: 0.646094, top_k: 0.848359, samples/s: 2244.174 1612421323.0856357
train: epoch 112, iter 3000, loss: 2.302782, top_1: 0.643477, top_k: 0.840938, samples/s: 2225.963 1612421334.5862758
train: epoch 112, iter 3100, loss: 2.542993, top_1: 0.643047, top_k: 0.844453, samples/s: 2222.814 1612421346.1033013
train: epoch 112, iter 3200, loss: 2.547664, top_1: 0.639141, top_k: 0.842344, samples/s: 2238.127 1612421357.5413928
train: epoch 112, iter 3300, loss: 2.472034, top_1: 0.645586, top_k: 0.845977, samples/s: 2203.379 1612421369.159863
train: epoch 112, iter 3400, loss: 2.380550, top_1: 0.640508, top_k: 0.843008, samples/s: 2241.691 1612421380.5798419
train: epoch 112, iter 3500, loss: 2.434489, top_1: 0.649648, top_k: 0.845625, samples/s: 2232.005 1612421392.049331
train: epoch 112, iter 3600, loss: 2.576669, top_1: 0.639648, top_k: 0.844023, samples/s: 2225.623 1612421403.5517166
train: epoch 112, iter 3700, loss: 2.500579, top_1: 0.639922, top_k: 0.845469, samples/s: 2233.721 1612421415.012442
train: epoch 112, iter 3800, loss: 2.391602, top_1: 0.642148, top_k: 0.844492, samples/s: 2225.824 1612421426.5138178
train: epoch 112, iter 3900, loss: 2.855511, top_1: 0.635898, top_k: 0.841016, samples/s: 2229.831 1612421437.9944782
train: epoch 112, iter 4000, loss: 2.454283, top_1: 0.647344, top_k: 0.847773, samples/s: 2227.930 1612421449.4849417
train: epoch 112, iter 4100, loss: 2.484885, top_1: 0.641367, top_k: 0.845078, samples/s: 2230.367 1612421460.9629388
train: epoch 112, iter 4200, loss: 2.441134, top_1: 0.641016, top_k: 0.840469, samples/s: 2232.481 1612421472.429891
train: epoch 112, iter 4300, loss: 2.451678, top_1: 0.642344, top_k: 0.843242, samples/s: 2227.733 1612421483.9215486
train: epoch 112, iter 4400, loss: 2.301716, top_1: 0.641641, top_k: 0.842773, samples/s: 2212.746 1612421495.490829
train: epoch 112, iter 4500, loss: 2.454912, top_1: 0.642891, top_k: 0.845117, samples/s: 2244.111 1612421506.8984482
train: epoch 112, iter 4600, loss: 2.540614, top_1: 0.641445, top_k: 0.844023, samples/s: 2216.200 1612421518.4497628
train: epoch 112, iter 4700, loss: 2.608390, top_1: 0.639766, top_k: 0.846953, samples/s: 2219.142 1612421529.985708
train: epoch 112, iter 4800, loss: 2.582635, top_1: 0.642188, top_k: 0.843437, samples/s: 2233.424 1612421541.4479299
train: epoch 112, iter 4900, loss: 2.485231, top_1: 0.637031, top_k: 0.840703, samples/s: 2243.849 1612421552.8569856
train: epoch 112, iter 5000, loss: 2.497680, top_1: 0.642500, top_k: 0.846016, samples/s: 2237.969 1612421564.2958858
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_112.
validation: epoch 112, iter 195, top_1: 0.680208, top_k: 0.883213, samples/s: 2949.839 1612421581.568942
train: epoch 113, iter 100, loss: 2.545646, top_1: 0.656367, top_k: 0.851719, samples/s: 2244.674 1612421608.7307596
train: epoch 113, iter 200, loss: 2.198716, top_1: 0.659258, top_k: 0.854219, samples/s: 2250.753 1612421620.1047056
train: epoch 113, iter 300, loss: 2.467565, top_1: 0.658047, top_k: 0.853047, samples/s: 2250.219 1612421631.4814198
train: epoch 113, iter 400, loss: 2.377855, top_1: 0.651250, top_k: 0.852227, samples/s: 2269.259 1612421642.7626617
train: epoch 113, iter 500, loss: 2.316547, top_1: 0.652891, top_k: 0.853633, samples/s: 2255.053 1612421654.1150174
train: epoch 113, iter 600, loss: 2.402181, top_1: 0.649141, top_k: 0.848594, samples/s: 2252.727 1612421665.4788647
train: epoch 113, iter 700, loss: 2.519708, top_1: 0.650547, top_k: 0.849336, samples/s: 2243.210 1612421676.891144
train: epoch 113, iter 800, loss: 2.440582, top_1: 0.643203, top_k: 0.844180, samples/s: 2237.442 1612421688.3327656
train: epoch 113, iter 900, loss: 2.429621, top_1: 0.650898, top_k: 0.850313, samples/s: 2222.126 1612421699.8532472
train: epoch 113, iter 1000, loss: 2.437664, top_1: 0.651445, top_k: 0.853008, samples/s: 2184.190 1612421711.573838
train: epoch 113, iter 1100, loss: 2.401624, top_1: 0.645117, top_k: 0.848711, samples/s: 2201.979 1612421723.1997619
train: epoch 113, iter 1200, loss: 2.406928, top_1: 0.643945, top_k: 0.846836, samples/s: 2215.541 1612421734.7544668
train: epoch 113, iter 1300, loss: 2.476542, top_1: 0.650508, top_k: 0.850469, samples/s: 2213.231 1612421746.3212686
train: epoch 113, iter 1400, loss: 2.506185, top_1: 0.647734, top_k: 0.846953, samples/s: 2237.946 1612421757.760348
train: epoch 113, iter 1500, loss: 2.571761, top_1: 0.638867, top_k: 0.845664, samples/s: 2203.670 1612421769.3773699
train: epoch 113, iter 1600, loss: 2.326669, top_1: 0.648203, top_k: 0.850234, samples/s: 2243.441 1612421780.788404
train: epoch 113, iter 1700, loss: 2.614150, top_1: 0.648438, top_k: 0.846523, samples/s: 2219.050 1612421792.3248222
train: epoch 113, iter 1800, loss: 2.354637, top_1: 0.652070, top_k: 0.848789, samples/s: 2224.732 1612421803.8318274
train: epoch 113, iter 1900, loss: 2.503966, top_1: 0.644648, top_k: 0.843828, samples/s: 2227.375 1612421815.3251777
train: epoch 113, iter 2000, loss: 2.548663, top_1: 0.652188, top_k: 0.849922, samples/s: 2216.621 1612421826.8743062
train: epoch 113, iter 2100, loss: 2.569359, top_1: 0.643906, top_k: 0.845703, samples/s: 2234.346 1612421838.3321857
train: epoch 113, iter 2200, loss: 2.550831, top_1: 0.646094, top_k: 0.846523, samples/s: 2219.759 1612421849.8645592
train: epoch 113, iter 2300, loss: 2.531543, top_1: 0.645078, top_k: 0.851211, samples/s: 2241.958 1612421861.28321
train: epoch 113, iter 2400, loss: 2.742498, top_1: 0.646953, top_k: 0.846406, samples/s: 2232.294 1612421872.751536
train: epoch 113, iter 2500, loss: 2.511134, top_1: 0.644922, top_k: 0.845156, samples/s: 2219.623 1612421884.2846656
train: epoch 113, iter 2600, loss: 2.634702, top_1: 0.645898, top_k: 0.843516, samples/s: 2224.009 1612421895.7954226
train: epoch 113, iter 2700, loss: 2.560487, top_1: 0.647383, top_k: 0.845391, samples/s: 2229.120 1612421907.2797575
train: epoch 113, iter 2800, loss: 2.239972, top_1: 0.648242, top_k: 0.847148, samples/s: 2218.925 1612421918.8168776
train: epoch 113, iter 2900, loss: 2.464609, top_1: 0.645625, top_k: 0.845977, samples/s: 2222.504 1612421930.3354306
train: epoch 113, iter 3000, loss: 2.563261, top_1: 0.638359, top_k: 0.843320, samples/s: 2208.379 1612421941.9276338
train: epoch 113, iter 3100, loss: 2.430140, top_1: 0.644336, top_k: 0.846523, samples/s: 2223.852 1612421953.4391994
train: epoch 113, iter 3200, loss: 2.540370, top_1: 0.641563, top_k: 0.842695, samples/s: 2229.419 1612421964.9219997
train: epoch 113, iter 3300, loss: 2.503416, top_1: 0.645078, top_k: 0.845547, samples/s: 2221.001 1612421976.4483876
train: epoch 113, iter 3400, loss: 2.560410, top_1: 0.643398, top_k: 0.843555, samples/s: 2214.442 1612421988.008876
train: epoch 113, iter 3500, loss: 2.476578, top_1: 0.643203, top_k: 0.849414, samples/s: 2220.024 1612421999.5403378
train: epoch 113, iter 3600, loss: 2.437208, top_1: 0.644062, top_k: 0.845938, samples/s: 2228.050 1612422011.0301273
train: epoch 113, iter 3700, loss: 2.436515, top_1: 0.646719, top_k: 0.847930, samples/s: 2252.154 1612422022.397039
train: epoch 113, iter 3800, loss: 2.493756, top_1: 0.644805, top_k: 0.845938, samples/s: 2217.389 1612422033.9421275
train: epoch 113, iter 3900, loss: 2.470602, top_1: 0.647578, top_k: 0.848125, samples/s: 2260.481 1612422045.267171
train: epoch 113, iter 4000, loss: 2.527766, top_1: 0.643633, top_k: 0.844883, samples/s: 2220.809 1612422056.7944057
train: epoch 113, iter 4100, loss: 2.614878, top_1: 0.644570, top_k: 0.845039, samples/s: 2238.814 1612422068.2291048
train: epoch 113, iter 4200, loss: 2.453059, top_1: 0.648203, top_k: 0.848125, samples/s: 2221.083 1612422079.7549915
train: epoch 113, iter 4300, loss: 2.535777, top_1: 0.642734, top_k: 0.845898, samples/s: 2226.276 1612422091.2540944
train: epoch 113, iter 4400, loss: 2.469826, top_1: 0.643359, top_k: 0.846758, samples/s: 2249.857 1612422102.632564
train: epoch 113, iter 4500, loss: 2.451551, top_1: 0.643125, top_k: 0.844023, samples/s: 2233.900 1612422114.0922961
train: epoch 113, iter 4600, loss: 2.565641, top_1: 0.644570, top_k: 0.846680, samples/s: 2222.040 1612422125.6134355
train: epoch 113, iter 4700, loss: 2.557291, top_1: 0.642148, top_k: 0.844570, samples/s: 2243.772 1612422137.0226533
train: epoch 113, iter 4800, loss: 2.407810, top_1: 0.643359, top_k: 0.848906, samples/s: 2219.167 1612422148.5586152
train: epoch 113, iter 4900, loss: 2.316686, top_1: 0.642188, top_k: 0.847305, samples/s: 2243.405 1612422159.9696796
train: epoch 113, iter 5000, loss: 2.394973, top_1: 0.649414, top_k: 0.847578, samples/s: 2198.002 1612422171.61661
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_113.
validation: epoch 113, iter 195, top_1: 0.682973, top_k: 0.884115, samples/s: 2828.167 1612422189.5324295
train: epoch 114, iter 100, loss: 2.348688, top_1: 0.655430, top_k: 0.853984, samples/s: 2238.427 1612422217.488441
train: epoch 114, iter 200, loss: 2.449172, top_1: 0.658672, top_k: 0.853437, samples/s: 2257.860 1612422228.8266478
train: epoch 114, iter 300, loss: 2.417854, top_1: 0.655195, top_k: 0.852461, samples/s: 2248.158 1612422240.2137125
train: epoch 114, iter 400, loss: 2.480751, top_1: 0.652891, top_k: 0.850313, samples/s: 2258.757 1612422251.5473983
train: epoch 114, iter 500, loss: 2.453990, top_1: 0.652930, top_k: 0.850195, samples/s: 2247.786 1612422262.9363992
train: epoch 114, iter 600, loss: 2.554699, top_1: 0.647539, top_k: 0.847852, samples/s: 2249.236 1612422274.3180163
train: epoch 114, iter 700, loss: 2.517718, top_1: 0.648711, top_k: 0.849219, samples/s: 2254.029 1612422285.6754494
train: epoch 114, iter 800, loss: 2.267524, top_1: 0.651953, top_k: 0.852500, samples/s: 2220.400 1612422297.2049417
train: epoch 114, iter 900, loss: 2.558634, top_1: 0.654766, top_k: 0.850859, samples/s: 2230.128 1612422308.684092
train: epoch 114, iter 1000, loss: 2.366956, top_1: 0.656914, top_k: 0.851719, samples/s: 2200.463 1612422320.3179932
train: epoch 114, iter 1100, loss: 2.417332, top_1: 0.652188, top_k: 0.850000, samples/s: 2228.609 1612422331.8050208
train: epoch 114, iter 1200, loss: 2.540318, top_1: 0.647852, top_k: 0.848828, samples/s: 2192.603 1612422343.480629
train: epoch 114, iter 1300, loss: 2.489082, top_1: 0.649297, top_k: 0.851758, samples/s: 2232.612 1612422354.9470632
train: epoch 114, iter 1400, loss: 2.466865, top_1: 0.649297, top_k: 0.848828, samples/s: 2233.561 1612422366.4085214
train: epoch 114, iter 1500, loss: 2.494461, top_1: 0.647266, top_k: 0.847227, samples/s: 2239.420 1612422377.8400211
train: epoch 114, iter 1600, loss: 2.437840, top_1: 0.649531, top_k: 0.850703, samples/s: 2236.884 1612422389.28455
train: epoch 114, iter 1700, loss: 2.575754, top_1: 0.649336, top_k: 0.846562, samples/s: 2242.040 1612422400.702705
train: epoch 114, iter 1800, loss: 2.597299, top_1: 0.644062, top_k: 0.846992, samples/s: 2225.443 1612422412.2060134
train: epoch 114, iter 1900, loss: 2.522463, top_1: 0.646719, top_k: 0.846328, samples/s: 2212.406 1612422423.7771218
train: epoch 114, iter 2000, loss: 2.563732, top_1: 0.647539, top_k: 0.846562, samples/s: 2251.051 1612422435.1497486
train: epoch 114, iter 2100, loss: 2.329497, top_1: 0.647930, top_k: 0.847070, samples/s: 2223.608 1612422446.662408
train: epoch 114, iter 2200, loss: 2.548576, top_1: 0.655117, top_k: 0.851406, samples/s: 2211.697 1612422458.237265
train: epoch 114, iter 2300, loss: 2.554095, top_1: 0.645195, top_k: 0.845586, samples/s: 2217.618 1612422469.7812142
train: epoch 114, iter 2400, loss: 2.570683, top_1: 0.653750, top_k: 0.848984, samples/s: 2228.422 1612422481.2691085
train: epoch 114, iter 2500, loss: 2.351576, top_1: 0.654766, top_k: 0.852852, samples/s: 2230.947 1612422492.744076
train: epoch 114, iter 2600, loss: 2.450681, top_1: 0.646563, top_k: 0.845469, samples/s: 2232.387 1612422504.2115939
train: epoch 114, iter 2700, loss: 2.506077, top_1: 0.641250, top_k: 0.844688, samples/s: 2235.861 1612422515.6613612
train: epoch 114, iter 2800, loss: 2.471842, top_1: 0.645352, top_k: 0.848281, samples/s: 2223.886 1612422527.1727383
train: epoch 114, iter 2900, loss: 2.761071, top_1: 0.647773, top_k: 0.842148, samples/s: 2238.355 1612422538.6096747
train: epoch 114, iter 3000, loss: 2.424442, top_1: 0.649687, top_k: 0.850195, samples/s: 2244.180 1612422550.016956
train: epoch 114, iter 3100, loss: 2.183399, top_1: 0.651992, top_k: 0.853047, samples/s: 2233.551 1612422561.478545
train: epoch 114, iter 3200, loss: 2.362337, top_1: 0.648633, top_k: 0.847891, samples/s: 2229.680 1612422572.959994
train: epoch 114, iter 3300, loss: 2.581941, top_1: 0.639727, top_k: 0.843828, samples/s: 2230.391 1612422584.4378047
train: epoch 114, iter 3400, loss: 2.608483, top_1: 0.652148, top_k: 0.850781, samples/s: 2223.438 1612422595.9515312
train: epoch 114, iter 3500, loss: 2.349793, top_1: 0.651875, top_k: 0.852461, samples/s: 2243.155 1612422607.3640206
train: epoch 114, iter 3600, loss: 2.499819, top_1: 0.645977, top_k: 0.845625, samples/s: 2219.172 1612422618.8998358
train: epoch 114, iter 3700, loss: 2.282260, top_1: 0.642305, top_k: 0.847031, samples/s: 2243.485 1612422630.3106773
train: epoch 114, iter 3800, loss: 2.456488, top_1: 0.648281, top_k: 0.848672, samples/s: 2242.118 1612422641.7284348
train: epoch 114, iter 3900, loss: 2.573710, top_1: 0.645273, top_k: 0.847695, samples/s: 2229.404 1612422653.2113452
train: epoch 114, iter 4000, loss: 2.541604, top_1: 0.647891, top_k: 0.848398, samples/s: 2223.442 1612422664.72502
train: epoch 114, iter 4100, loss: 2.438001, top_1: 0.641719, top_k: 0.845469, samples/s: 2242.460 1612422676.1410358
train: epoch 114, iter 4200, loss: 2.649907, top_1: 0.643711, top_k: 0.846602, samples/s: 2235.146 1612422687.5944383
train: epoch 114, iter 4300, loss: 2.455243, top_1: 0.644883, top_k: 0.846484, samples/s: 2234.764 1612422699.0497751
train: epoch 114, iter 4400, loss: 2.495219, top_1: 0.652188, top_k: 0.850820, samples/s: 2217.720 1612422710.593301
train: epoch 114, iter 4500, loss: 2.409987, top_1: 0.644453, top_k: 0.843633, samples/s: 2229.358 1612422722.076282
train: epoch 114, iter 4600, loss: 2.375840, top_1: 0.646211, top_k: 0.844883, samples/s: 2232.771 1612422733.5418668
train: epoch 114, iter 4700, loss: 2.435703, top_1: 0.651445, top_k: 0.849844, samples/s: 2222.503 1612422745.060402
train: epoch 114, iter 4800, loss: 2.326949, top_1: 0.649141, top_k: 0.848047, samples/s: 2228.157 1612422756.549716
train: epoch 114, iter 4900, loss: 2.445722, top_1: 0.647930, top_k: 0.847500, samples/s: 2241.553 1612422767.9703634
train: epoch 114, iter 5000, loss: 2.352962, top_1: 0.650586, top_k: 0.853164, samples/s: 2229.886 1612422779.4508598
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_114.
validation: epoch 114, iter 195, top_1: 0.686458, top_k: 0.887039, samples/s: 2829.919 1612422797.3639276
train: epoch 115, iter 100, loss: 2.326817, top_1: 0.655078, top_k: 0.850430, samples/s: 2239.150 1612422824.7964945
train: epoch 115, iter 200, loss: 2.474567, top_1: 0.662461, top_k: 0.856563, samples/s: 2266.525 1612422836.0912929
train: epoch 115, iter 300, loss: 2.392920, top_1: 0.659219, top_k: 0.856016, samples/s: 2257.073 1612422847.4334157
train: epoch 115, iter 400, loss: 2.495606, top_1: 0.659609, top_k: 0.854375, samples/s: 2246.219 1612422858.8303504
train: epoch 115, iter 500, loss: 2.355318, top_1: 0.658672, top_k: 0.854570, samples/s: 2220.663 1612422870.3584628
train: epoch 115, iter 600, loss: 2.421942, top_1: 0.652969, top_k: 0.852031, samples/s: 2256.195 1612422881.7050192
train: epoch 115, iter 700, loss: 2.451731, top_1: 0.652852, top_k: 0.848516, samples/s: 2250.230 1612422893.081558
train: epoch 115, iter 800, loss: 2.459899, top_1: 0.655664, top_k: 0.855313, samples/s: 2217.531 1612422904.6260805
train: epoch 115, iter 900, loss: 2.368322, top_1: 0.658281, top_k: 0.853125, samples/s: 2229.708 1612422916.1073198
train: epoch 115, iter 1000, loss: 2.387272, top_1: 0.651055, top_k: 0.849844, samples/s: 2222.071 1612422927.6280746
train: epoch 115, iter 1100, loss: 2.314021, top_1: 0.653477, top_k: 0.850313, samples/s: 2209.848 1612422939.2125702
train: epoch 115, iter 1200, loss: 2.515021, top_1: 0.649609, top_k: 0.849844, samples/s: 2217.214 1612422950.758589
train: epoch 115, iter 1300, loss: 2.498395, top_1: 0.654219, top_k: 0.852891, samples/s: 2207.072 1612422962.357645
train: epoch 115, iter 1400, loss: 2.315174, top_1: 0.659453, top_k: 0.856406, samples/s: 2225.643 1612422973.8599713
train: epoch 115, iter 1500, loss: 2.461552, top_1: 0.646406, top_k: 0.845508, samples/s: 2218.861 1612422985.3973958
train: epoch 115, iter 1600, loss: 2.510325, top_1: 0.655312, top_k: 0.851758, samples/s: 2207.388 1612422996.99486
train: epoch 115, iter 1700, loss: 2.505311, top_1: 0.648398, top_k: 0.850469, samples/s: 2224.742 1612423008.5022056
train: epoch 115, iter 1800, loss: 2.554156, top_1: 0.652344, top_k: 0.851133, samples/s: 2213.977 1612423020.0646837
train: epoch 115, iter 1900, loss: 2.323034, top_1: 0.650898, top_k: 0.849883, samples/s: 2190.093 1612423031.7540927
train: epoch 115, iter 2000, loss: 2.325514, top_1: 0.651172, top_k: 0.849141, samples/s: 2223.822 1612423043.2654195
train: epoch 115, iter 2100, loss: 2.420209, top_1: 0.654062, top_k: 0.848242, samples/s: 2226.423 1612423054.7637205
train: epoch 115, iter 2200, loss: 2.348744, top_1: 0.653711, top_k: 0.850781, samples/s: 2222.767 1612423066.280834
train: epoch 115, iter 2300, loss: 2.529202, top_1: 0.654258, top_k: 0.849844, samples/s: 2208.124 1612423077.8743694
train: epoch 115, iter 2400, loss: 2.518488, top_1: 0.650195, top_k: 0.851836, samples/s: 2200.918 1612423089.505882
train: epoch 115, iter 2500, loss: 2.543427, top_1: 0.655234, top_k: 0.855156, samples/s: 2233.931 1612423100.965558
train: epoch 115, iter 2600, loss: 2.446412, top_1: 0.652813, top_k: 0.850273, samples/s: 2220.952 1612423112.4921114
train: epoch 115, iter 2700, loss: 2.587420, top_1: 0.650664, top_k: 0.849297, samples/s: 2206.725 1612423124.092966
train: epoch 115, iter 2800, loss: 2.468147, top_1: 0.650703, top_k: 0.848008, samples/s: 2219.481 1612423135.627306
train: epoch 115, iter 2900, loss: 2.465413, top_1: 0.655234, top_k: 0.855469, samples/s: 2223.267 1612423147.1418245
train: epoch 115, iter 3000, loss: 2.502020, top_1: 0.653203, top_k: 0.849180, samples/s: 2241.812 1612423158.5612295
train: epoch 115, iter 3100, loss: 2.349567, top_1: 0.650898, top_k: 0.852187, samples/s: 2238.144 1612423169.9992404
train: epoch 115, iter 3200, loss: 2.568666, top_1: 0.648398, top_k: 0.849688, samples/s: 2218.645 1612423181.5378153
train: epoch 115, iter 3300, loss: 2.375690, top_1: 0.651016, top_k: 0.849180, samples/s: 2241.717 1612423192.9576678
train: epoch 115, iter 3400, loss: 2.279475, top_1: 0.655547, top_k: 0.850859, samples/s: 2232.717 1612423204.4234755
train: epoch 115, iter 3500, loss: 2.398199, top_1: 0.648828, top_k: 0.848906, samples/s: 2237.161 1612423215.866571
train: epoch 115, iter 3600, loss: 2.362565, top_1: 0.648203, top_k: 0.850586, samples/s: 2233.349 1612423227.3291082
train: epoch 115, iter 3700, loss: 2.495166, top_1: 0.647109, top_k: 0.848750, samples/s: 2218.543 1612423238.8682652
train: epoch 115, iter 3800, loss: 2.540752, top_1: 0.649062, top_k: 0.847383, samples/s: 2218.786 1612423250.4060628
train: epoch 115, iter 3900, loss: 2.490010, top_1: 0.651016, top_k: 0.848789, samples/s: 2232.439 1612423261.8733382
train: epoch 115, iter 4000, loss: 2.335716, top_1: 0.645391, top_k: 0.848828, samples/s: 2228.944 1612423273.3586173
train: epoch 115, iter 4100, loss: 2.297791, top_1: 0.650625, top_k: 0.850430, samples/s: 2229.921 1612423284.8388498
train: epoch 115, iter 4200, loss: 2.432993, top_1: 0.652734, top_k: 0.851094, samples/s: 2239.993 1612423296.267429
train: epoch 115, iter 4300, loss: 2.482018, top_1: 0.640742, top_k: 0.846367, samples/s: 2219.684 1612423307.8006253
train: epoch 115, iter 4400, loss: 2.450348, top_1: 0.651367, top_k: 0.849336, samples/s: 2238.647 1612423319.236095
train: epoch 115, iter 4500, loss: 2.566231, top_1: 0.650352, top_k: 0.850117, samples/s: 2225.394 1612423330.7397132
train: epoch 115, iter 4600, loss: 2.377272, top_1: 0.647539, top_k: 0.847539, samples/s: 2249.411 1612423342.1204352
train: epoch 115, iter 4700, loss: 2.295041, top_1: 0.649922, top_k: 0.848203, samples/s: 2228.169 1612423353.6097643
train: epoch 115, iter 4800, loss: 2.478503, top_1: 0.650937, top_k: 0.851211, samples/s: 2239.131 1612423365.042687
train: epoch 115, iter 4900, loss: 2.645599, top_1: 0.645000, top_k: 0.848398, samples/s: 2239.358 1612423376.4745352
train: epoch 115, iter 5000, loss: 2.382480, top_1: 0.659375, top_k: 0.855703, samples/s: 2225.534 1612423387.9773884
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_115.
validation: epoch 115, iter 195, top_1: 0.687560, top_k: 0.886318, samples/s: 2884.485 1612423405.636849
train: epoch 116, iter 100, loss: 2.444769, top_1: 0.663945, top_k: 0.859023, samples/s: 2235.839 1612423433.9718482
train: epoch 116, iter 200, loss: 2.445534, top_1: 0.663867, top_k: 0.857187, samples/s: 2249.982 1612423445.3496995
train: epoch 116, iter 300, loss: 2.454675, top_1: 0.660000, top_k: 0.855078, samples/s: 2264.473 1612423456.654814
train: epoch 116, iter 400, loss: 2.432186, top_1: 0.656367, top_k: 0.852461, samples/s: 2257.745 1612423467.9936426
train: epoch 116, iter 500, loss: 2.301672, top_1: 0.660117, top_k: 0.852930, samples/s: 2255.022 1612423479.3459547
train: epoch 116, iter 600, loss: 2.263006, top_1: 0.651602, top_k: 0.853164, samples/s: 2250.493 1612423490.7212627
train: epoch 116, iter 700, loss: 2.334383, top_1: 0.658750, top_k: 0.856914, samples/s: 2255.975 1612423502.0688877
train: epoch 116, iter 800, loss: 2.518595, top_1: 0.650469, top_k: 0.851836, samples/s: 2221.922 1612423513.590441
train: epoch 116, iter 900, loss: 2.347444, top_1: 0.657383, top_k: 0.854844, samples/s: 2229.350 1612423525.0736842
train: epoch 116, iter 1000, loss: 2.243735, top_1: 0.658594, top_k: 0.855469, samples/s: 2239.842 1612423536.5029826
train: epoch 116, iter 1100, loss: 2.402561, top_1: 0.656367, top_k: 0.853945, samples/s: 2219.782 1612423548.0356941
train: epoch 116, iter 1200, loss: 2.521036, top_1: 0.659102, top_k: 0.853828, samples/s: 2225.195 1612423559.5402808
train: epoch 116, iter 1300, loss: 2.663511, top_1: 0.657227, top_k: 0.857383, samples/s: 2216.044 1612423571.0923746
train: epoch 116, iter 1400, loss: 2.489666, top_1: 0.657656, top_k: 0.857070, samples/s: 2224.523 1612423582.6005328
train: epoch 116, iter 1500, loss: 2.329650, top_1: 0.653516, top_k: 0.854023, samples/s: 2199.486 1612423594.239595
train: epoch 116, iter 1600, loss: 2.444525, top_1: 0.654180, top_k: 0.852578, samples/s: 2210.720 1612423605.819481
train: epoch 116, iter 1700, loss: 2.370313, top_1: 0.650898, top_k: 0.850781, samples/s: 2233.111 1612423617.2833428
train: epoch 116, iter 1800, loss: 2.220358, top_1: 0.654648, top_k: 0.851914, samples/s: 2203.528 1612423628.9010456
train: epoch 116, iter 1900, loss: 2.506001, top_1: 0.654453, top_k: 0.852812, samples/s: 2195.799 1612423640.5597832
train: epoch 116, iter 2000, loss: 2.480994, top_1: 0.661797, top_k: 0.854336, samples/s: 2234.555 1612423652.0161152
train: epoch 116, iter 2100, loss: 2.565650, top_1: 0.653203, top_k: 0.853359, samples/s: 2208.669 1612423663.6067889
train: epoch 116, iter 2200, loss: 2.431995, top_1: 0.652227, top_k: 0.849883, samples/s: 2211.913 1612423675.1804876
train: epoch 116, iter 2300, loss: 2.438506, top_1: 0.653906, top_k: 0.850586, samples/s: 2226.992 1612423686.6758552
train: epoch 116, iter 2400, loss: 2.527758, top_1: 0.656836, top_k: 0.852930, samples/s: 2218.072 1612423698.2173467
train: epoch 116, iter 2500, loss: 2.333742, top_1: 0.652422, top_k: 0.850586, samples/s: 2229.569 1612423709.699453
train: epoch 116, iter 2600, loss: 2.427527, top_1: 0.657031, top_k: 0.849766, samples/s: 2230.728 1612423721.1754818
train: epoch 116, iter 2700, loss: 2.463424, top_1: 0.657383, top_k: 0.853086, samples/s: 2228.341 1612423732.664152
train: epoch 116, iter 2800, loss: 2.274964, top_1: 0.654687, top_k: 0.853203, samples/s: 2239.343 1612423744.095829
train: epoch 116, iter 2900, loss: 2.545940, top_1: 0.655586, top_k: 0.853867, samples/s: 2227.207 1612423755.590393
train: epoch 116, iter 3000, loss: 2.376682, top_1: 0.649961, top_k: 0.846719, samples/s: 2238.038 1612423767.0285575
train: epoch 116, iter 3100, loss: 2.585574, top_1: 0.644922, top_k: 0.848750, samples/s: 2228.167 1612423778.5178227
train: epoch 116, iter 3200, loss: 2.456466, top_1: 0.661992, top_k: 0.855469, samples/s: 2218.359 1612423790.0578897
train: epoch 116, iter 3300, loss: 2.578374, top_1: 0.653867, top_k: 0.850313, samples/s: 2225.362 1612423801.5616558
train: epoch 116, iter 3400, loss: 2.326753, top_1: 0.651875, top_k: 0.850156, samples/s: 2219.919 1612423813.0936203
train: epoch 116, iter 3500, loss: 2.366482, top_1: 0.658984, top_k: 0.857187, samples/s: 2246.078 1612423824.491289
train: epoch 116, iter 3600, loss: 2.399540, top_1: 0.654336, top_k: 0.850938, samples/s: 2231.060 1612423835.9656732
train: epoch 116, iter 3700, loss: 2.457344, top_1: 0.653242, top_k: 0.850000, samples/s: 2221.799 1612423847.4878147
train: epoch 116, iter 3800, loss: 2.451804, top_1: 0.653008, top_k: 0.851250, samples/s: 2220.203 1612423859.0182838
train: epoch 116, iter 3900, loss: 2.370373, top_1: 0.655937, top_k: 0.853828, samples/s: 2237.151 1612423870.4615896
train: epoch 116, iter 4000, loss: 2.366362, top_1: 0.650742, top_k: 0.852617, samples/s: 2246.238 1612423881.8582327
train: epoch 116, iter 4100, loss: 2.464663, top_1: 0.651914, top_k: 0.850195, samples/s: 2240.299 1612423893.2853258
train: epoch 116, iter 4200, loss: 2.424454, top_1: 0.651836, top_k: 0.850234, samples/s: 2222.860 1612423904.8023953
train: epoch 116, iter 4300, loss: 2.534230, top_1: 0.651719, top_k: 0.853281, samples/s: 2234.101 1612423916.2607265
train: epoch 116, iter 4400, loss: 2.505775, top_1: 0.648320, top_k: 0.849844, samples/s: 2225.365 1612423927.7648454
train: epoch 116, iter 4500, loss: 2.372345, top_1: 0.647813, top_k: 0.848711, samples/s: 2244.739 1612423939.168898
train: epoch 116, iter 4600, loss: 2.359061, top_1: 0.651094, top_k: 0.851953, samples/s: 2235.649 1612423950.6197088
train: epoch 116, iter 4700, loss: 2.397940, top_1: 0.649219, top_k: 0.848242, samples/s: 2227.399 1612423962.1129363
train: epoch 116, iter 4800, loss: 2.445172, top_1: 0.662188, top_k: 0.852969, samples/s: 2222.178 1612423973.6332612
train: epoch 116, iter 4900, loss: 2.481461, top_1: 0.649844, top_k: 0.849766, samples/s: 2233.258 1612423985.0962527
train: epoch 116, iter 5000, loss: 2.320250, top_1: 0.663164, top_k: 0.862656, samples/s: 2227.769 1612423996.5875628
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_116.
validation: epoch 116, iter 195, top_1: 0.690044, top_k: 0.886699, samples/s: 3024.936 1612424013.4286203
train: epoch 117, iter 100, loss: 2.440991, top_1: 0.664141, top_k: 0.858555, samples/s: 2233.304 1612424041.3927052
train: epoch 117, iter 200, loss: 2.418698, top_1: 0.664648, top_k: 0.855938, samples/s: 2241.159 1612424052.815316
train: epoch 117, iter 300, loss: 2.392411, top_1: 0.664375, top_k: 0.859688, samples/s: 2250.531 1612424064.1904113
train: epoch 117, iter 400, loss: 2.344817, top_1: 0.658672, top_k: 0.856172, samples/s: 2240.217 1612424075.6178646
train: epoch 117, iter 500, loss: 2.533836, top_1: 0.662227, top_k: 0.860078, samples/s: 2255.426 1612424086.968288
train: epoch 117, iter 600, loss: 2.252493, top_1: 0.657422, top_k: 0.854609, samples/s: 2255.839 1612424098.3165944
train: epoch 117, iter 700, loss: 2.331275, top_1: 0.660391, top_k: 0.855664, samples/s: 2248.157 1612424109.7037435
train: epoch 117, iter 800, loss: 2.546059, top_1: 0.662500, top_k: 0.851953, samples/s: 2232.067 1612424121.1731215
train: epoch 117, iter 900, loss: 2.464815, top_1: 0.655469, top_k: 0.851016, samples/s: 2193.738 1612424132.8424711
train: epoch 117, iter 1000, loss: 2.398502, top_1: 0.655547, top_k: 0.856758, samples/s: 2197.961 1612424144.4896646
train: epoch 117, iter 1100, loss: 2.398359, top_1: 0.653945, top_k: 0.852539, samples/s: 2218.365 1612424156.0296626
train: epoch 117, iter 1200, loss: 2.469544, top_1: 0.659570, top_k: 0.855664, samples/s: 2242.263 1612424167.4466987
train: epoch 117, iter 1300, loss: 2.597725, top_1: 0.660156, top_k: 0.856172, samples/s: 2216.113 1612424178.9984705
train: epoch 117, iter 1400, loss: 2.319221, top_1: 0.662461, top_k: 0.856563, samples/s: 2222.321 1612424190.5180173
train: epoch 117, iter 1500, loss: 2.501163, top_1: 0.658359, top_k: 0.858086, samples/s: 2234.458 1612424201.9749017
train: epoch 117, iter 1600, loss: 2.415285, top_1: 0.661484, top_k: 0.857500, samples/s: 2242.373 1612424213.3913748
train: epoch 117, iter 1700, loss: 2.426920, top_1: 0.659805, top_k: 0.858086, samples/s: 2232.492 1612424224.8583663
train: epoch 117, iter 1800, loss: 2.522255, top_1: 0.657188, top_k: 0.855430, samples/s: 2228.094 1612424236.347983
train: epoch 117, iter 1900, loss: 2.338267, top_1: 0.657578, top_k: 0.857383, samples/s: 2243.283 1612424247.7599456
train: epoch 117, iter 2000, loss: 2.297034, top_1: 0.655703, top_k: 0.851523, samples/s: 2223.814 1612424259.271588
train: epoch 117, iter 2100, loss: 2.281660, top_1: 0.662930, top_k: 0.857422, samples/s: 2258.403 1612424270.6070285
train: epoch 117, iter 2200, loss: 2.312505, top_1: 0.657344, top_k: 0.856992, samples/s: 2232.393 1612424282.074924
train: epoch 117, iter 2300, loss: 2.486025, top_1: 0.653906, top_k: 0.853008, samples/s: 2235.093 1612424293.5281982
train: epoch 117, iter 2400, loss: 2.306304, top_1: 0.656914, top_k: 0.851914, samples/s: 2232.025 1612424304.9976103
train: epoch 117, iter 2500, loss: 2.470021, top_1: 0.657695, top_k: 0.852891, samples/s: 2203.994 1612424316.6129532
train: epoch 117, iter 2600, loss: 2.480916, top_1: 0.655703, top_k: 0.855820, samples/s: 2265.441 1612424327.9135222
train: epoch 117, iter 2700, loss: 2.286011, top_1: 0.656445, top_k: 0.854453, samples/s: 2220.649 1612424339.4412923
train: epoch 117, iter 2800, loss: 2.530883, top_1: 0.655195, top_k: 0.854102, samples/s: 2219.049 1612424350.9783459
train: epoch 117, iter 2900, loss: 2.484057, top_1: 0.657148, top_k: 0.855156, samples/s: 2226.594 1612424362.4751253
train: epoch 117, iter 3000, loss: 2.383839, top_1: 0.655508, top_k: 0.853477, samples/s: 2232.747 1612424373.940878
train: epoch 117, iter 3100, loss: 2.419527, top_1: 0.658438, top_k: 0.855703, samples/s: 2253.477 1612424385.301417
train: epoch 117, iter 3200, loss: 2.394337, top_1: 0.658906, top_k: 0.855625, samples/s: 2236.273 1612424396.7486618
train: epoch 117, iter 3300, loss: 2.293383, top_1: 0.656875, top_k: 0.852109, samples/s: 2220.737 1612424408.27652
train: epoch 117, iter 3400, loss: 2.685445, top_1: 0.655195, top_k: 0.853359, samples/s: 2237.713 1612424419.7166314
train: epoch 117, iter 3500, loss: 2.452854, top_1: 0.651758, top_k: 0.853984, samples/s: 2226.473 1612424431.214731
train: epoch 117, iter 3600, loss: 2.432562, top_1: 0.649141, top_k: 0.850898, samples/s: 2263.570 1612424442.5242867
train: epoch 117, iter 3700, loss: 2.189119, top_1: 0.653008, top_k: 0.853672, samples/s: 2227.202 1612424454.0184574
train: epoch 117, iter 3800, loss: 2.425364, top_1: 0.659180, top_k: 0.857305, samples/s: 2240.859 1612424465.4427164
train: epoch 117, iter 3900, loss: 2.284696, top_1: 0.656289, top_k: 0.855859, samples/s: 2226.490 1612424476.9405577
train: epoch 117, iter 4000, loss: 2.309160, top_1: 0.658320, top_k: 0.856094, samples/s: 2220.912 1612424488.4674096
train: epoch 117, iter 4100, loss: 2.475721, top_1: 0.658984, top_k: 0.852734, samples/s: 2236.946 1612424499.9115698
train: epoch 117, iter 4200, loss: 2.316344, top_1: 0.651055, top_k: 0.851836, samples/s: 2216.138 1612424511.4632213
train: epoch 117, iter 4300, loss: 2.379599, top_1: 0.653867, top_k: 0.853242, samples/s: 2227.548 1612424522.9559288
train: epoch 117, iter 4400, loss: 2.434282, top_1: 0.654062, top_k: 0.853867, samples/s: 2237.182 1612424534.3985984
train: epoch 117, iter 4500, loss: 2.479336, top_1: 0.659414, top_k: 0.851719, samples/s: 2232.092 1612424545.8682702
train: epoch 117, iter 4600, loss: 2.407652, top_1: 0.652852, top_k: 0.852812, samples/s: 2231.774 1612424557.3384256
train: epoch 117, iter 4700, loss: 2.530002, top_1: 0.656133, top_k: 0.852187, samples/s: 2239.461 1612424568.7699196
train: epoch 117, iter 4800, loss: 2.368378, top_1: 0.652813, top_k: 0.849609, samples/s: 2237.458 1612424580.211286
train: epoch 117, iter 4900, loss: 2.684320, top_1: 0.652070, top_k: 0.852187, samples/s: 2233.048 1612424591.67537
train: epoch 117, iter 5000, loss: 2.495831, top_1: 0.659844, top_k: 0.856719, samples/s: 2230.566 1612424603.1523001
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_117.
validation: epoch 117, iter 195, top_1: 0.689443, top_k: 0.887540, samples/s: 2932.099 1612424620.495221
train: epoch 118, iter 100, loss: 2.445833, top_1: 0.672031, top_k: 0.861875, samples/s: 2195.455 1612424648.3364234
train: epoch 118, iter 200, loss: 2.402923, top_1: 0.668984, top_k: 0.860391, samples/s: 2239.522 1612424659.7674072
train: epoch 118, iter 300, loss: 2.360044, top_1: 0.664766, top_k: 0.855508, samples/s: 2258.101 1612424671.1043255
train: epoch 118, iter 400, loss: 2.445304, top_1: 0.666953, top_k: 0.863437, samples/s: 2240.739 1612424682.5291648
train: epoch 118, iter 500, loss: 2.331069, top_1: 0.658398, top_k: 0.856602, samples/s: 2251.749 1612424693.898098
train: epoch 118, iter 600, loss: 2.366207, top_1: 0.662773, top_k: 0.856875, samples/s: 2248.740 1612424705.2822719
train: epoch 118, iter 700, loss: 2.294248, top_1: 0.664453, top_k: 0.855430, samples/s: 2243.438 1612424716.6932867
train: epoch 118, iter 800, loss: 2.534357, top_1: 0.665117, top_k: 0.856445, samples/s: 2213.034 1612424728.2612073
train: epoch 118, iter 900, loss: 2.318028, top_1: 0.666133, top_k: 0.859297, samples/s: 2247.115 1612424739.653523
train: epoch 118, iter 1000, loss: 2.409153, top_1: 0.661602, top_k: 0.859375, samples/s: 2216.547 1612424751.2029817
train: epoch 118, iter 1100, loss: 2.513958, top_1: 0.659297, top_k: 0.858164, samples/s: 2213.472 1612424762.76871
train: epoch 118, iter 1200, loss: 2.509875, top_1: 0.659648, top_k: 0.855156, samples/s: 2226.801 1612424774.2649176
train: epoch 118, iter 1300, loss: 2.381587, top_1: 0.665859, top_k: 0.858398, samples/s: 2218.259 1612424785.8054194
train: epoch 118, iter 1400, loss: 2.480341, top_1: 0.665039, top_k: 0.859766, samples/s: 2219.128 1612424797.3414717
train: epoch 118, iter 1500, loss: 2.462693, top_1: 0.659531, top_k: 0.856055, samples/s: 2217.871 1612424808.8840885
train: epoch 118, iter 1600, loss: 2.413626, top_1: 0.660273, top_k: 0.858906, samples/s: 2212.534 1612424820.4545686
train: epoch 118, iter 1700, loss: 2.298401, top_1: 0.658906, top_k: 0.856289, samples/s: 2210.157 1612424832.0374548
train: epoch 118, iter 1800, loss: 2.360539, top_1: 0.660273, top_k: 0.858320, samples/s: 2217.938 1612424843.5796998
train: epoch 118, iter 1900, loss: 2.432655, top_1: 0.661836, top_k: 0.858359, samples/s: 2232.436 1612424855.047228
train: epoch 118, iter 2000, loss: 2.424791, top_1: 0.660742, top_k: 0.855195, samples/s: 2228.049 1612424866.5368576
train: epoch 118, iter 2100, loss: 2.317990, top_1: 0.657109, top_k: 0.852852, samples/s: 2225.064 1612424878.0421283
train: epoch 118, iter 2200, loss: 2.445372, top_1: 0.659258, top_k: 0.857187, samples/s: 2238.745 1612424889.477105
train: epoch 118, iter 2300, loss: 2.399978, top_1: 0.656445, top_k: 0.855273, samples/s: 2213.083 1612424901.0446796
train: epoch 118, iter 2400, loss: 2.221892, top_1: 0.663867, top_k: 0.857578, samples/s: 2236.502 1612424912.4911609
train: epoch 118, iter 2500, loss: 2.396379, top_1: 0.663906, top_k: 0.856563, samples/s: 2228.681 1612424923.9777408
train: epoch 118, iter 2600, loss: 2.467444, top_1: 0.660469, top_k: 0.855781, samples/s: 2207.856 1612424935.5726976
train: epoch 118, iter 2700, loss: 2.436982, top_1: 0.658125, top_k: 0.853555, samples/s: 2225.045 1612424947.0780554
train: epoch 118, iter 2800, loss: 2.387415, top_1: 0.659727, top_k: 0.854922, samples/s: 2218.629 1612424958.6167457
train: epoch 118, iter 2900, loss: 2.389072, top_1: 0.657070, top_k: 0.852773, samples/s: 2253.812 1612424969.9753625
train: epoch 118, iter 3000, loss: 2.448981, top_1: 0.662656, top_k: 0.859258, samples/s: 2225.591 1612424981.4778986
train: epoch 118, iter 3100, loss: 2.384952, top_1: 0.656445, top_k: 0.852695, samples/s: 2242.049 1612424992.8960092
train: epoch 118, iter 3200, loss: 2.355818, top_1: 0.657227, top_k: 0.856289, samples/s: 2209.391 1612425004.4832857
train: epoch 118, iter 3300, loss: 2.349527, top_1: 0.657656, top_k: 0.853125, samples/s: 2246.343 1612425015.879176
train: epoch 118, iter 3400, loss: 2.380702, top_1: 0.659180, top_k: 0.854648, samples/s: 2233.262 1612425027.3426187
train: epoch 118, iter 3500, loss: 2.338688, top_1: 0.661602, top_k: 0.854688, samples/s: 2228.367 1612425038.8305418
train: epoch 118, iter 3600, loss: 2.353563, top_1: 0.664727, top_k: 0.859766, samples/s: 2231.531 1612425050.3024387
train: epoch 118, iter 3700, loss: 2.481956, top_1: 0.655781, top_k: 0.859141, samples/s: 2227.944 1612425061.7928236
train: epoch 118, iter 3800, loss: 2.451924, top_1: 0.661133, top_k: 0.855703, samples/s: 2239.739 1612425073.2227056
train: epoch 118, iter 3900, loss: 2.313214, top_1: 0.653555, top_k: 0.853711, samples/s: 2233.365 1612425084.6856122
train: epoch 118, iter 4000, loss: 2.485038, top_1: 0.656758, top_k: 0.856680, samples/s: 2234.487 1612425096.1419919
train: epoch 118, iter 4100, loss: 2.583443, top_1: 0.654219, top_k: 0.854648, samples/s: 2227.958 1612425107.632365
train: epoch 118, iter 4200, loss: 2.340533, top_1: 0.661914, top_k: 0.856445, samples/s: 2232.738 1612425119.0984592
train: epoch 118, iter 4300, loss: 2.495866, top_1: 0.657109, top_k: 0.853906, samples/s: 2231.068 1612425130.5724156
train: epoch 118, iter 4400, loss: 2.381616, top_1: 0.652109, top_k: 0.852266, samples/s: 2229.200 1612425142.0564134
train: epoch 118, iter 4500, loss: 2.373569, top_1: 0.664375, top_k: 0.857305, samples/s: 2243.583 1612425153.466753
train: epoch 118, iter 4600, loss: 2.544964, top_1: 0.657188, top_k: 0.853047, samples/s: 2239.386 1612425164.8984802
train: epoch 118, iter 4700, loss: 2.575340, top_1: 0.659805, top_k: 0.858555, samples/s: 2226.010 1612425176.3988242
train: epoch 118, iter 4800, loss: 2.253183, top_1: 0.666328, top_k: 0.858945, samples/s: 2244.302 1612425187.805626
train: epoch 118, iter 4900, loss: 2.436755, top_1: 0.658203, top_k: 0.854219, samples/s: 2218.062 1612425199.347177
train: epoch 118, iter 5000, loss: 2.418513, top_1: 0.661680, top_k: 0.859414, samples/s: 2239.093 1612425210.7802713
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_118.
validation: epoch 118, iter 195, top_1: 0.692027, top_k: 0.889223, samples/s: 2855.381 1612425228.642936
train: epoch 119, iter 100, loss: 2.355982, top_1: 0.664648, top_k: 0.857344, samples/s: 2246.323 1612425255.8800824
train: epoch 119, iter 200, loss: 2.422655, top_1: 0.670039, top_k: 0.862969, samples/s: 2254.866 1612425267.2333107
train: epoch 119, iter 300, loss: 2.577142, top_1: 0.669258, top_k: 0.862500, samples/s: 2256.933 1612425278.5760994
train: epoch 119, iter 400, loss: 2.452820, top_1: 0.666328, top_k: 0.859336, samples/s: 2258.817 1612425289.9094975
train: epoch 119, iter 500, loss: 2.391708, top_1: 0.660117, top_k: 0.857695, samples/s: 2250.251 1612425301.286053
train: epoch 119, iter 600, loss: 2.329458, top_1: 0.666992, top_k: 0.858984, samples/s: 2257.399 1612425312.6265464
train: epoch 119, iter 700, loss: 2.400166, top_1: 0.666914, top_k: 0.859844, samples/s: 2248.933 1612425324.0097027
train: epoch 119, iter 800, loss: 2.396760, top_1: 0.661367, top_k: 0.861875, samples/s: 2235.955 1612425335.458925
train: epoch 119, iter 900, loss: 2.475490, top_1: 0.667969, top_k: 0.859180, samples/s: 2250.196 1612425346.835815
train: epoch 119, iter 1000, loss: 2.389318, top_1: 0.666719, top_k: 0.860195, samples/s: 2201.761 1612425358.4627597
train: epoch 119, iter 1100, loss: 2.331601, top_1: 0.662773, top_k: 0.859727, samples/s: 2215.555 1612425370.017548
train: epoch 119, iter 1200, loss: 2.285199, top_1: 0.669141, top_k: 0.858203, samples/s: 2219.449 1612425381.5518203
train: epoch 119, iter 1300, loss: 2.499276, top_1: 0.670625, top_k: 0.863906, samples/s: 2196.183 1612425393.2084556
train: epoch 119, iter 1400, loss: 2.407994, top_1: 0.667969, top_k: 0.855195, samples/s: 2228.336 1612425404.6967924
train: epoch 119, iter 1500, loss: 2.252310, top_1: 0.659531, top_k: 0.856563, samples/s: 2217.568 1612425416.2409728
train: epoch 119, iter 1600, loss: 2.277739, top_1: 0.669492, top_k: 0.862578, samples/s: 2220.538 1612425427.7699232
train: epoch 119, iter 1700, loss: 2.571490, top_1: 0.660977, top_k: 0.858242, samples/s: 2222.508 1612425439.2882366
train: epoch 119, iter 1800, loss: 2.348874, top_1: 0.666562, top_k: 0.861172, samples/s: 2205.212 1612425450.8971632
train: epoch 119, iter 1900, loss: 2.272707, top_1: 0.665078, top_k: 0.858359, samples/s: 2212.156 1612425462.4695342
train: epoch 119, iter 2000, loss: 2.631376, top_1: 0.661602, top_k: 0.859648, samples/s: 2240.984 1612425473.8930829
train: epoch 119, iter 2100, loss: 2.275673, top_1: 0.666406, top_k: 0.858203, samples/s: 2217.244 1612425485.4389372
train: epoch 119, iter 2200, loss: 2.403402, top_1: 0.664453, top_k: 0.858789, samples/s: 2207.673 1612425497.0349233
train: epoch 119, iter 2300, loss: 2.588978, top_1: 0.663633, top_k: 0.859453, samples/s: 2221.264 1612425508.5598397
train: epoch 119, iter 2400, loss: 2.544836, top_1: 0.664570, top_k: 0.856172, samples/s: 2221.131 1612425520.0854976
train: epoch 119, iter 2500, loss: 2.378433, top_1: 0.660312, top_k: 0.855313, samples/s: 2227.253 1612425531.5794725
train: epoch 119, iter 2600, loss: 2.368934, top_1: 0.663477, top_k: 0.857695, samples/s: 2214.470 1612425543.139828
train: epoch 119, iter 2700, loss: 2.430180, top_1: 0.664180, top_k: 0.858281, samples/s: 2242.703 1612425554.5545917
train: epoch 119, iter 2800, loss: 2.394099, top_1: 0.665234, top_k: 0.858477, samples/s: 2238.258 1612425565.9920738
train: epoch 119, iter 2900, loss: 2.273195, top_1: 0.666914, top_k: 0.859531, samples/s: 2209.164 1612425577.5802689
train: epoch 119, iter 3000, loss: 2.392312, top_1: 0.658398, top_k: 0.853828, samples/s: 2219.520 1612425589.1141846
train: epoch 119, iter 3100, loss: 2.172395, top_1: 0.665391, top_k: 0.859375, samples/s: 2212.764 1612425600.6834772
train: epoch 119, iter 3200, loss: 2.500522, top_1: 0.658789, top_k: 0.856953, samples/s: 2249.567 1612425612.063403
train: epoch 119, iter 3300, loss: 2.521547, top_1: 0.665117, top_k: 0.856133, samples/s: 2224.474 1612425623.5717247
train: epoch 119, iter 3400, loss: 2.544630, top_1: 0.656797, top_k: 0.853125, samples/s: 2238.096 1612425635.0100508
train: epoch 119, iter 3500, loss: 2.262807, top_1: 0.662813, top_k: 0.858242, samples/s: 2216.001 1612425646.5624738
train: epoch 119, iter 3600, loss: 2.447437, top_1: 0.660430, top_k: 0.855859, samples/s: 2244.920 1612425657.9658854
train: epoch 119, iter 3700, loss: 2.499196, top_1: 0.661680, top_k: 0.854922, samples/s: 2224.748 1612425669.4728222
train: epoch 119, iter 3800, loss: 2.186790, top_1: 0.661016, top_k: 0.855977, samples/s: 2238.122 1612425680.9109619
train: epoch 119, iter 3900, loss: 2.431516, top_1: 0.664219, top_k: 0.857930, samples/s: 2219.454 1612425692.445641
train: epoch 119, iter 4000, loss: 2.444967, top_1: 0.663047, top_k: 0.857344, samples/s: 2247.938 1612425703.833567
train: epoch 119, iter 4100, loss: 2.321341, top_1: 0.665430, top_k: 0.857500, samples/s: 2219.116 1612425715.3697143
train: epoch 119, iter 4200, loss: 2.377156, top_1: 0.660820, top_k: 0.856367, samples/s: 2199.115 1612425727.0107338
train: epoch 119, iter 4300, loss: 2.332233, top_1: 0.657188, top_k: 0.853477, samples/s: 2198.991 1612425738.6524506
train: epoch 119, iter 4400, loss: 2.463124, top_1: 0.657500, top_k: 0.852930, samples/s: 2276.174 1612425749.899397
train: epoch 119, iter 4500, loss: 2.404564, top_1: 0.664336, top_k: 0.858711, samples/s: 2230.307 1612425761.3776865
train: epoch 119, iter 4600, loss: 2.241728, top_1: 0.662227, top_k: 0.855000, samples/s: 2245.778 1612425772.7769625
train: epoch 119, iter 4700, loss: 2.394111, top_1: 0.663320, top_k: 0.856953, samples/s: 2244.812 1612425784.1810539
train: epoch 119, iter 4800, loss: 2.371075, top_1: 0.655547, top_k: 0.852227, samples/s: 2233.340 1612425795.6436076
train: epoch 119, iter 4900, loss: 2.511671, top_1: 0.654570, top_k: 0.853359, samples/s: 2218.139 1612425807.184767
train: epoch 119, iter 5000, loss: 2.655742, top_1: 0.664258, top_k: 0.862031, samples/s: 2254.565 1612425818.5394607
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_119.
validation: epoch 119, iter 195, top_1: 0.695773, top_k: 0.890585, samples/s: 3008.338 1612425835.5318453
train: epoch 120, iter 100, loss: 2.391625, top_1: 0.676992, top_k: 0.864883, samples/s: 2240.926 1612425862.5386813
train: epoch 120, iter 200, loss: 2.405108, top_1: 0.675078, top_k: 0.863516, samples/s: 2258.734 1612425873.8724334
train: epoch 120, iter 300, loss: 2.416134, top_1: 0.671094, top_k: 0.860273, samples/s: 2247.792 1612425885.2614088
train: epoch 120, iter 400, loss: 2.445093, top_1: 0.668672, top_k: 0.861289, samples/s: 2244.308 1612425896.668397
train: epoch 120, iter 500, loss: 2.438757, top_1: 0.664609, top_k: 0.860313, samples/s: 2236.799 1612425908.1129937
train: epoch 120, iter 600, loss: 2.293069, top_1: 0.666914, top_k: 0.860820, samples/s: 2273.082 1612425919.375589
train: epoch 120, iter 700, loss: 2.406531, top_1: 0.665039, top_k: 0.860273, samples/s: 2228.207 1612425930.8642778
train: epoch 120, iter 800, loss: 2.308828, top_1: 0.668203, top_k: 0.862773, samples/s: 2255.169 1612425942.2160127
train: epoch 120, iter 900, loss: 2.408361, top_1: 0.669453, top_k: 0.861680, samples/s: 2236.325 1612425953.6633341
train: epoch 120, iter 1000, loss: 2.481665, top_1: 0.668320, top_k: 0.858750, samples/s: 2228.245 1612425965.1522124
train: epoch 120, iter 1100, loss: 2.444800, top_1: 0.666250, top_k: 0.862148, samples/s: 2219.232 1612425976.687733
train: epoch 120, iter 1200, loss: 2.362655, top_1: 0.667188, top_k: 0.861758, samples/s: 2223.251 1612425988.2024484
train: epoch 120, iter 1300, loss: 2.306144, top_1: 0.667305, top_k: 0.860547, samples/s: 2203.832 1612425999.818511
train: epoch 120, iter 1400, loss: 2.428070, top_1: 0.665117, top_k: 0.863320, samples/s: 2238.679 1612426011.2538915
train: epoch 120, iter 1500, loss: 2.355055, top_1: 0.667734, top_k: 0.861680, samples/s: 2217.387 1612426022.799238
train: epoch 120, iter 1600, loss: 2.251825, top_1: 0.668828, top_k: 0.861016, samples/s: 2216.787 1612426034.3472102
train: epoch 120, iter 1700, loss: 2.363212, top_1: 0.661758, top_k: 0.859258, samples/s: 2236.226 1612426045.795403
train: epoch 120, iter 1800, loss: 2.424875, top_1: 0.661719, top_k: 0.857344, samples/s: 2187.277 1612426057.4990916
train: epoch 120, iter 1900, loss: 2.295581, top_1: 0.666328, top_k: 0.860625, samples/s: 2232.872 1612426068.9641488
train: epoch 120, iter 2000, loss: 2.223034, top_1: 0.664453, top_k: 0.861484, samples/s: 2235.866 1612426080.4143066
train: epoch 120, iter 2100, loss: 2.321042, top_1: 0.663789, top_k: 0.858750, samples/s: 2227.762 1612426091.9052134
train: epoch 120, iter 2200, loss: 2.288240, top_1: 0.666133, top_k: 0.860156, samples/s: 2211.719 1612426103.4802446
train: epoch 120, iter 2300, loss: 2.502367, top_1: 0.664414, top_k: 0.857852, samples/s: 2238.408 1612426114.9166663
train: epoch 120, iter 2400, loss: 2.383703, top_1: 0.662734, top_k: 0.856406, samples/s: 2228.615 1612426126.4035716
train: epoch 120, iter 2500, loss: 2.525051, top_1: 0.665078, top_k: 0.858789, samples/s: 2228.618 1612426137.8905444
train: epoch 120, iter 2600, loss: 2.358734, top_1: 0.665937, top_k: 0.860820, samples/s: 2246.229 1612426149.2874503
train: epoch 120, iter 2700, loss: 2.331495, top_1: 0.662227, top_k: 0.859180, samples/s: 2228.386 1612426160.7754865
train: epoch 120, iter 2800, loss: 2.423191, top_1: 0.662383, top_k: 0.861758, samples/s: 2235.415 1612426172.2275522
train: epoch 120, iter 2900, loss: 2.423619, top_1: 0.671523, top_k: 0.859219, samples/s: 2216.027 1612426183.7797353
train: epoch 120, iter 3000, loss: 2.461766, top_1: 0.663945, top_k: 0.858398, samples/s: 2233.469 1612426195.2417495
train: epoch 120, iter 3100, loss: 2.354196, top_1: 0.666094, top_k: 0.858047, samples/s: 2241.348 1612426206.6634235
train: epoch 120, iter 3200, loss: 2.529198, top_1: 0.662422, top_k: 0.859180, samples/s: 2238.433 1612426218.10004
train: epoch 120, iter 3300, loss: 2.254835, top_1: 0.666992, top_k: 0.858047, samples/s: 2224.814 1612426229.6065865
train: epoch 120, iter 3400, loss: 2.384296, top_1: 0.662813, top_k: 0.858164, samples/s: 2246.354 1612426241.0028389
train: epoch 120, iter 3500, loss: 2.362911, top_1: 0.660469, top_k: 0.859844, samples/s: 2237.526 1612426252.4441159
train: epoch 120, iter 3600, loss: 2.330674, top_1: 0.658125, top_k: 0.855898, samples/s: 2239.142 1612426263.8770049
train: epoch 120, iter 3700, loss: 2.419333, top_1: 0.667773, top_k: 0.858984, samples/s: 2241.953 1612426275.2956212
train: epoch 120, iter 3800, loss: 2.442809, top_1: 0.665703, top_k: 0.861484, samples/s: 2238.784 1612426286.7303874
train: epoch 120, iter 3900, loss: 2.464383, top_1: 0.664805, top_k: 0.859883, samples/s: 2234.616 1612426298.18659
train: epoch 120, iter 4000, loss: 2.396801, top_1: 0.663438, top_k: 0.856758, samples/s: 2233.718 1612426309.6472118
train: epoch 120, iter 4100, loss: 2.524303, top_1: 0.664727, top_k: 0.860117, samples/s: 2233.043 1612426321.1114378
train: epoch 120, iter 4200, loss: 2.435040, top_1: 0.665508, top_k: 0.858867, samples/s: 2229.246 1612426332.595094
train: epoch 120, iter 4300, loss: 2.403371, top_1: 0.660977, top_k: 0.858711, samples/s: 2249.037 1612426343.9777493
train: epoch 120, iter 4400, loss: 2.472686, top_1: 0.662188, top_k: 0.857656, samples/s: 2252.344 1612426355.3436832
train: epoch 120, iter 4500, loss: 2.301560, top_1: 0.660156, top_k: 0.855742, samples/s: 2222.625 1612426366.8616683
train: epoch 120, iter 4600, loss: 2.493545, top_1: 0.669531, top_k: 0.861406, samples/s: 2248.058 1612426378.2492175
train: epoch 120, iter 4700, loss: 2.392122, top_1: 0.663320, top_k: 0.858516, samples/s: 2234.952 1612426389.7036312
train: epoch 120, iter 4800, loss: 2.533904, top_1: 0.658516, top_k: 0.854688, samples/s: 2239.330 1612426401.135612
train: epoch 120, iter 4900, loss: 2.427923, top_1: 0.664766, top_k: 0.858750, samples/s: 2226.841 1612426412.6316795
train: epoch 120, iter 5000, loss: 2.267330, top_1: 0.669687, top_k: 0.860391, samples/s: 2232.104 1612426424.1008391
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_120.
validation: epoch 120, iter 195, top_1: 0.697236, top_k: 0.893790, samples/s: 2874.998 1612426441.7902882
train: epoch 121, iter 100, loss: 2.466094, top_1: 0.670156, top_k: 0.867969, samples/s: 2230.772 1612426469.1353033
train: epoch 121, iter 200, loss: 2.356006, top_1: 0.674844, top_k: 0.864922, samples/s: 2238.853 1612426480.56967
train: epoch 121, iter 300, loss: 2.294213, top_1: 0.675898, top_k: 0.867227, samples/s: 2253.876 1612426491.9279544
train: epoch 121, iter 400, loss: 2.252676, top_1: 0.671211, top_k: 0.860703, samples/s: 2257.896 1612426503.2658622
train: epoch 121, iter 500, loss: 2.308037, top_1: 0.674844, top_k: 0.862656, samples/s: 2254.319 1612426514.6218479
train: epoch 121, iter 600, loss: 2.251555, top_1: 0.674102, top_k: 0.866016, samples/s: 2206.936 1612426526.22165
train: epoch 121, iter 700, loss: 2.404097, top_1: 0.674570, top_k: 0.864414, samples/s: 2273.158 1612426537.483599
train: epoch 121, iter 800, loss: 2.314375, top_1: 0.672734, top_k: 0.864062, samples/s: 2240.621 1612426548.909028
train: epoch 121, iter 900, loss: 2.489039, top_1: 0.670937, top_k: 0.862227, samples/s: 2244.309 1612426560.3156247
train: epoch 121, iter 1000, loss: 2.403186, top_1: 0.674023, top_k: 0.864141, samples/s: 2216.503 1612426571.8652751
train: epoch 121, iter 1100, loss: 2.189864, top_1: 0.667578, top_k: 0.858945, samples/s: 2205.054 1612426583.474984
train: epoch 121, iter 1200, loss: 2.208529, top_1: 0.676953, top_k: 0.867148, samples/s: 2227.217 1612426594.9691303
train: epoch 121, iter 1300, loss: 2.301509, top_1: 0.672695, top_k: 0.866719, samples/s: 2214.195 1612426606.5309427
train: epoch 121, iter 1400, loss: 2.549741, top_1: 0.668906, top_k: 0.861055, samples/s: 2214.337 1612426618.0919006
train: epoch 121, iter 1500, loss: 2.374042, top_1: 0.673672, top_k: 0.868750, samples/s: 2227.605 1612426629.584069
train: epoch 121, iter 1600, loss: 2.300514, top_1: 0.671602, top_k: 0.864141, samples/s: 2224.673 1612426641.091406
train: epoch 121, iter 1700, loss: 2.415359, top_1: 0.663984, top_k: 0.857109, samples/s: 2205.398 1612426652.6993332
train: epoch 121, iter 1800, loss: 2.207051, top_1: 0.667344, top_k: 0.861719, samples/s: 2213.866 1612426664.2628121
train: epoch 121, iter 1900, loss: 2.387968, top_1: 0.674883, top_k: 0.863594, samples/s: 2213.935 1612426675.8258567
train: epoch 121, iter 2000, loss: 2.412425, top_1: 0.667578, top_k: 0.859102, samples/s: 2211.420 1612426687.4021354
train: epoch 121, iter 2100, loss: 2.346919, top_1: 0.669258, top_k: 0.859219, samples/s: 2210.739 1612426698.9819794
train: epoch 121, iter 2200, loss: 2.440993, top_1: 0.665352, top_k: 0.860313, samples/s: 2219.401 1612426710.5167124
train: epoch 121, iter 2300, loss: 2.545763, top_1: 0.667852, top_k: 0.862500, samples/s: 2213.093 1612426722.08414
train: epoch 121, iter 2400, loss: 2.420003, top_1: 0.665078, top_k: 0.862070, samples/s: 2211.693 1612426733.6590407
train: epoch 121, iter 2500, loss: 2.393566, top_1: 0.670586, top_k: 0.862344, samples/s: 2228.442 1612426745.146826
train: epoch 121, iter 2600, loss: 2.303173, top_1: 0.669766, top_k: 0.859922, samples/s: 2222.465 1612426756.665577
train: epoch 121, iter 2700, loss: 2.402611, top_1: 0.671055, top_k: 0.861445, samples/s: 2226.609 1612426768.1629393
train: epoch 121, iter 2800, loss: 2.413370, top_1: 0.666719, top_k: 0.858164, samples/s: 2229.872 1612426779.6433885
train: epoch 121, iter 2900, loss: 2.513693, top_1: 0.665547, top_k: 0.858164, samples/s: 2218.169 1612426791.1844027
train: epoch 121, iter 3000, loss: 2.549375, top_1: 0.667695, top_k: 0.864922, samples/s: 2225.004 1612426802.6899934
train: epoch 121, iter 3100, loss: 2.457083, top_1: 0.669727, top_k: 0.863906, samples/s: 2233.756 1612426814.1505651
train: epoch 121, iter 3200, loss: 2.374076, top_1: 0.668047, top_k: 0.861563, samples/s: 2242.429 1612426825.5666707
train: epoch 121, iter 3300, loss: 2.344391, top_1: 0.659141, top_k: 0.853672, samples/s: 2232.726 1612426837.0325668
train: epoch 121, iter 3400, loss: 2.231936, top_1: 0.663281, top_k: 0.858359, samples/s: 2228.150 1612426848.521882
train: epoch 121, iter 3500, loss: 2.464320, top_1: 0.663242, top_k: 0.858047, samples/s: 2223.194 1612426860.036887
train: epoch 121, iter 3600, loss: 2.348296, top_1: 0.666250, top_k: 0.858086, samples/s: 2236.339 1612426871.4841154
train: epoch 121, iter 3700, loss: 2.279242, top_1: 0.672422, top_k: 0.862539, samples/s: 2222.823 1612426883.001075
train: epoch 121, iter 3800, loss: 2.260135, top_1: 0.667656, top_k: 0.861289, samples/s: 2238.359 1612426894.4379485
train: epoch 121, iter 3900, loss: 2.308349, top_1: 0.665430, top_k: 0.859023, samples/s: 2236.888 1612426905.8824236
train: epoch 121, iter 4000, loss: 2.288446, top_1: 0.665273, top_k: 0.862500, samples/s: 2220.094 1612426917.413486
train: epoch 121, iter 4100, loss: 2.528434, top_1: 0.667891, top_k: 0.859023, samples/s: 2256.382 1612426928.7590861
train: epoch 121, iter 4200, loss: 2.392195, top_1: 0.666406, top_k: 0.862070, samples/s: 2202.404 1612426940.3828576
train: epoch 121, iter 4300, loss: 2.399447, top_1: 0.662773, top_k: 0.858555, samples/s: 2223.969 1612426951.8936753
train: epoch 121, iter 4400, loss: 2.372587, top_1: 0.664102, top_k: 0.861641, samples/s: 2231.971 1612426963.3633938
train: epoch 121, iter 4500, loss: 2.413904, top_1: 0.668828, top_k: 0.858984, samples/s: 2241.699 1612426974.7832847
train: epoch 121, iter 4600, loss: 2.389176, top_1: 0.669141, top_k: 0.859375, samples/s: 2244.005 1612426986.1914413
train: epoch 121, iter 4700, loss: 2.363450, top_1: 0.665234, top_k: 0.860977, samples/s: 2237.944 1612426997.6305237
train: epoch 121, iter 4800, loss: 2.513197, top_1: 0.662344, top_k: 0.856953, samples/s: 2198.040 1612427009.2773826
train: epoch 121, iter 4900, loss: 2.495249, top_1: 0.665820, top_k: 0.860625, samples/s: 2247.035 1612427020.6700556
train: epoch 121, iter 5000, loss: 2.222898, top_1: 0.676289, top_k: 0.863086, samples/s: 2220.469 1612427032.1993446
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_121.
validation: epoch 121, iter 195, top_1: 0.699780, top_k: 0.894571, samples/s: 3018.562 1612427049.127475
train: epoch 122, iter 100, loss: 2.372253, top_1: 0.681367, top_k: 0.868750, samples/s: 2238.186 1612427076.2769136
train: epoch 122, iter 200, loss: 2.287589, top_1: 0.678359, top_k: 0.868359, samples/s: 2252.692 1612427087.6411552
train: epoch 122, iter 300, loss: 2.224034, top_1: 0.674844, top_k: 0.867227, samples/s: 2214.606 1612427099.200823
train: epoch 122, iter 400, loss: 2.210014, top_1: 0.678203, top_k: 0.866523, samples/s: 2248.675 1612427110.585261
train: epoch 122, iter 500, loss: 2.305893, top_1: 0.676445, top_k: 0.866367, samples/s: 2258.811 1612427121.9186502
train: epoch 122, iter 600, loss: 2.244640, top_1: 0.671016, top_k: 0.861602, samples/s: 2252.908 1612427133.2817624
train: epoch 122, iter 700, loss: 2.392789, top_1: 0.668945, top_k: 0.861641, samples/s: 2246.761 1612427144.675845
train: epoch 122, iter 800, loss: 2.576491, top_1: 0.674570, top_k: 0.863203, samples/s: 2230.087 1612427156.1552534
train: epoch 122, iter 900, loss: 2.623041, top_1: 0.668164, top_k: 0.861250, samples/s: 2248.871 1612427167.5387087
train: epoch 122, iter 1000, loss: 2.454735, top_1: 0.670352, top_k: 0.864414, samples/s: 2229.532 1612427179.021027
train: epoch 122, iter 1100, loss: 2.349458, top_1: 0.671016, top_k: 0.865195, samples/s: 2229.127 1612427190.5052617
train: epoch 122, iter 1200, loss: 2.367393, top_1: 0.671523, top_k: 0.863125, samples/s: 2208.185 1612427202.098481
train: epoch 122, iter 1300, loss: 2.388771, top_1: 0.675937, top_k: 0.865313, samples/s: 2212.315 1612427213.6700866
train: epoch 122, iter 1400, loss: 2.268190, top_1: 0.674180, top_k: 0.864961, samples/s: 2217.812 1612427225.2129946
train: epoch 122, iter 1500, loss: 2.282572, top_1: 0.673906, top_k: 0.869219, samples/s: 2222.126 1612427236.7334878
train: epoch 122, iter 1600, loss: 2.386162, top_1: 0.674687, top_k: 0.864922, samples/s: 2216.429 1612427248.2835953
train: epoch 122, iter 1700, loss: 2.394685, top_1: 0.674063, top_k: 0.864961, samples/s: 2229.337 1612427259.7668793
train: epoch 122, iter 1800, loss: 2.171561, top_1: 0.673281, top_k: 0.866133, samples/s: 2230.564 1612427271.243746
train: epoch 122, iter 1900, loss: 2.280142, top_1: 0.674375, top_k: 0.864062, samples/s: 2242.968 1612427282.6572838
train: epoch 122, iter 2000, loss: 2.446327, top_1: 0.674180, top_k: 0.865859, samples/s: 2227.211 1612427294.1514325
train: epoch 122, iter 2100, loss: 2.434306, top_1: 0.671562, top_k: 0.862656, samples/s: 2228.758 1612427305.6377132
train: epoch 122, iter 2200, loss: 2.375070, top_1: 0.675117, top_k: 0.867344, samples/s: 2240.670 1612427317.0628
train: epoch 122, iter 2300, loss: 2.422724, top_1: 0.673984, top_k: 0.864141, samples/s: 2224.794 1612427328.5695608
train: epoch 122, iter 2400, loss: 2.347949, top_1: 0.668672, top_k: 0.860430, samples/s: 2220.387 1612427340.0989895
train: epoch 122, iter 2500, loss: 2.350528, top_1: 0.668438, top_k: 0.863828, samples/s: 2232.572 1612427351.5656044
train: epoch 122, iter 2600, loss: 2.216856, top_1: 0.674023, top_k: 0.865273, samples/s: 2233.248 1612427363.0287294
train: epoch 122, iter 2700, loss: 2.331133, top_1: 0.668203, top_k: 0.861836, samples/s: 2240.689 1612427374.4537482
train: epoch 122, iter 2800, loss: 2.406090, top_1: 0.676016, top_k: 0.863555, samples/s: 2225.231 1612427385.9581838
train: epoch 122, iter 2900, loss: 2.346689, top_1: 0.670820, top_k: 0.861719, samples/s: 2232.684 1612427397.4241984
train: epoch 122, iter 3000, loss: 2.286328, top_1: 0.674805, top_k: 0.864727, samples/s: 2227.425 1612427408.9172955
train: epoch 122, iter 3100, loss: 2.447158, top_1: 0.668594, top_k: 0.861641, samples/s: 2233.067 1612427420.381489
train: epoch 122, iter 3200, loss: 2.501248, top_1: 0.668867, top_k: 0.861563, samples/s: 2234.804 1612427431.836481
train: epoch 122, iter 3300, loss: 2.372854, top_1: 0.670273, top_k: 0.863672, samples/s: 2229.390 1612427443.319447
train: epoch 122, iter 3400, loss: 2.422413, top_1: 0.670508, top_k: 0.862930, samples/s: 2245.473 1612427454.720424
train: epoch 122, iter 3500, loss: 2.224373, top_1: 0.674453, top_k: 0.864531, samples/s: 2231.406 1612427466.1927464
train: epoch 122, iter 3600, loss: 2.482915, top_1: 0.673750, top_k: 0.864219, samples/s: 2236.150 1612427477.6410365
train: epoch 122, iter 3700, loss: 2.423232, top_1: 0.664336, top_k: 0.859727, samples/s: 2240.102 1612427489.0690506
train: epoch 122, iter 3800, loss: 2.357178, top_1: 0.670430, top_k: 0.862578, samples/s: 2241.513 1612427500.4899247
train: epoch 122, iter 3900, loss: 2.370813, top_1: 0.667148, top_k: 0.861133, samples/s: 2238.352 1612427511.9269648
train: epoch 122, iter 4000, loss: 2.487811, top_1: 0.668789, top_k: 0.859375, samples/s: 2231.893 1612427523.3969438
train: epoch 122, iter 4100, loss: 2.207887, top_1: 0.666562, top_k: 0.860977, samples/s: 2216.723 1612427534.945631
train: epoch 122, iter 4200, loss: 2.465787, top_1: 0.668711, top_k: 0.861875, samples/s: 2255.367 1612427546.2966003
train: epoch 122, iter 4300, loss: 2.523705, top_1: 0.665508, top_k: 0.859180, samples/s: 2230.883 1612427557.7715533
train: epoch 122, iter 4400, loss: 2.490686, top_1: 0.673438, top_k: 0.864336, samples/s: 2236.274 1612427569.2195923
train: epoch 122, iter 4500, loss: 2.275981, top_1: 0.671680, top_k: 0.862930, samples/s: 2233.373 1612427580.681647
train: epoch 122, iter 4600, loss: 2.269039, top_1: 0.674063, top_k: 0.858984, samples/s: 2238.061 1612427592.1201615
train: epoch 122, iter 4700, loss: 2.469483, top_1: 0.671875, top_k: 0.859023, samples/s: 2233.296 1612427603.582988
train: epoch 122, iter 4800, loss: 2.222344, top_1: 0.670156, top_k: 0.869492, samples/s: 2224.898 1612427615.0892415
train: epoch 122, iter 4900, loss: 2.241239, top_1: 0.672930, top_k: 0.861328, samples/s: 2237.131 1612427626.5323648
train: epoch 122, iter 5000, loss: 2.264827, top_1: 0.675156, top_k: 0.864805, samples/s: 2242.960 1612427637.9458618
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_122.
validation: epoch 122, iter 195, top_1: 0.697496, top_k: 0.891947, samples/s: 2917.570 1612427655.403937
train: epoch 123, iter 100, loss: 2.407983, top_1: 0.677344, top_k: 0.868750, samples/s: 2223.905 1612427683.0591705
train: epoch 123, iter 200, loss: 2.385465, top_1: 0.678516, top_k: 0.866758, samples/s: 2258.314 1612427694.3950865
train: epoch 123, iter 300, loss: 2.422818, top_1: 0.676211, top_k: 0.868984, samples/s: 2254.251 1612427705.751367
train: epoch 123, iter 400, loss: 2.091641, top_1: 0.676484, top_k: 0.866484, samples/s: 2240.877 1612427717.1755824
train: epoch 123, iter 500, loss: 2.279311, top_1: 0.681758, top_k: 0.867891, samples/s: 2261.197 1612427728.4969766
train: epoch 123, iter 600, loss: 2.266376, top_1: 0.681953, top_k: 0.866445, samples/s: 2224.623 1612427740.0044816
train: epoch 123, iter 700, loss: 2.202631, top_1: 0.677773, top_k: 0.866484, samples/s: 2251.639 1612427751.3739645
train: epoch 123, iter 800, loss: 2.578333, top_1: 0.676641, top_k: 0.866289, samples/s: 2222.817 1612427762.8908808
train: epoch 123, iter 900, loss: 2.208971, top_1: 0.673633, top_k: 0.864375, samples/s: 2250.425 1612427774.2665563
train: epoch 123, iter 1000, loss: 2.267904, top_1: 0.680273, top_k: 0.870742, samples/s: 2219.186 1612427785.802271
train: epoch 123, iter 1100, loss: 2.420650, top_1: 0.680117, top_k: 0.866055, samples/s: 2236.131 1612427797.2506216
train: epoch 123, iter 1200, loss: 2.260828, top_1: 0.672734, top_k: 0.864766, samples/s: 2207.898 1612427808.8453863
train: epoch 123, iter 1300, loss: 2.309473, top_1: 0.681289, top_k: 0.869453, samples/s: 2223.489 1612427820.3587952
train: epoch 123, iter 1400, loss: 2.289042, top_1: 0.674609, top_k: 0.865938, samples/s: 2218.481 1612427831.8983064
train: epoch 123, iter 1500, loss: 2.378874, top_1: 0.674570, top_k: 0.866641, samples/s: 2221.538 1612427843.4218738
train: epoch 123, iter 1600, loss: 2.255351, top_1: 0.673281, top_k: 0.865234, samples/s: 2219.896 1612427854.9538558
train: epoch 123, iter 1700, loss: 2.304452, top_1: 0.677695, top_k: 0.865195, samples/s: 2224.367 1612427866.4627368
train: epoch 123, iter 1800, loss: 2.261262, top_1: 0.676992, top_k: 0.867812, samples/s: 2222.196 1612427877.9829235
train: epoch 123, iter 1900, loss: 2.418090, top_1: 0.677148, top_k: 0.867070, samples/s: 2208.373 1612427889.5752087
train: epoch 123, iter 2000, loss: 2.226671, top_1: 0.671133, top_k: 0.864297, samples/s: 2208.935 1612427901.1644027
train: epoch 123, iter 2100, loss: 2.349893, top_1: 0.674180, top_k: 0.866445, samples/s: 2232.729 1612427912.6303325
train: epoch 123, iter 2200, loss: 2.273160, top_1: 0.677578, top_k: 0.866641, samples/s: 2204.473 1612427924.2430649
train: epoch 123, iter 2300, loss: 2.413690, top_1: 0.678203, top_k: 0.866797, samples/s: 2247.928 1612427935.6312866
train: epoch 123, iter 2400, loss: 2.340472, top_1: 0.676406, top_k: 0.861055, samples/s: 2241.094 1612427947.05421
train: epoch 123, iter 2500, loss: 2.590375, top_1: 0.673398, top_k: 0.863203, samples/s: 2213.813 1612427958.6180632
train: epoch 123, iter 2600, loss: 2.438028, top_1: 0.671445, top_k: 0.860938, samples/s: 2233.970 1612427970.0773892
train: epoch 123, iter 2700, loss: 2.398611, top_1: 0.672305, top_k: 0.864414, samples/s: 2239.031 1612427981.5109067
train: epoch 123, iter 2800, loss: 2.317607, top_1: 0.673633, top_k: 0.861445, samples/s: 2238.392 1612427992.947744
train: epoch 123, iter 2900, loss: 2.510747, top_1: 0.674609, top_k: 0.865469, samples/s: 2245.526 1612428004.3482616
train: epoch 123, iter 3000, loss: 2.271043, top_1: 0.673398, top_k: 0.862812, samples/s: 2231.548 1612428015.8199923
train: epoch 123, iter 3100, loss: 2.379101, top_1: 0.669727, top_k: 0.860742, samples/s: 2216.013 1612428027.372315
train: epoch 123, iter 3200, loss: 2.309289, top_1: 0.674805, top_k: 0.864688, samples/s: 2230.238 1612428038.8508623
train: epoch 123, iter 3300, loss: 2.302855, top_1: 0.669258, top_k: 0.860273, samples/s: 2233.573 1612428050.312329
train: epoch 123, iter 3400, loss: 2.393541, top_1: 0.671484, top_k: 0.863555, samples/s: 2233.572 1612428061.774083
train: epoch 123, iter 3500, loss: 2.240023, top_1: 0.675625, top_k: 0.869414, samples/s: 2231.991 1612428073.243367
train: epoch 123, iter 3600, loss: 2.421066, top_1: 0.672891, top_k: 0.863711, samples/s: 2247.905 1612428084.632304
train: epoch 123, iter 3700, loss: 2.424937, top_1: 0.670820, top_k: 0.866094, samples/s: 2232.269 1612428096.0999882
train: epoch 123, iter 3800, loss: 2.326375, top_1: 0.676367, top_k: 0.865938, samples/s: 2238.794 1612428107.5346315
train: epoch 123, iter 3900, loss: 2.293862, top_1: 0.677031, top_k: 0.865859, samples/s: 2252.232 1612428118.9011376
train: epoch 123, iter 4000, loss: 2.432550, top_1: 0.674023, top_k: 0.860977, samples/s: 2237.865 1612428130.3406074
train: epoch 123, iter 4100, loss: 2.345471, top_1: 0.670625, top_k: 0.862617, samples/s: 2221.551 1612428141.8640766
train: epoch 123, iter 4200, loss: 2.348662, top_1: 0.674453, top_k: 0.864727, samples/s: 2228.738 1612428153.3504143
train: epoch 123, iter 4300, loss: 2.370781, top_1: 0.675273, top_k: 0.864531, samples/s: 2244.597 1612428164.7555861
train: epoch 123, iter 4400, loss: 2.319558, top_1: 0.674453, top_k: 0.864961, samples/s: 2237.654 1612428176.1961644
train: epoch 123, iter 4500, loss: 2.414610, top_1: 0.673164, top_k: 0.865820, samples/s: 2230.450 1612428187.6736217
train: epoch 123, iter 4600, loss: 2.278279, top_1: 0.668477, top_k: 0.861719, samples/s: 2238.593 1612428199.1093783
train: epoch 123, iter 4700, loss: 2.208393, top_1: 0.671797, top_k: 0.862891, samples/s: 2245.051 1612428210.5122676
train: epoch 123, iter 4800, loss: 2.326355, top_1: 0.674609, top_k: 0.860859, samples/s: 2237.825 1612428221.9519496
train: epoch 123, iter 4900, loss: 2.234224, top_1: 0.669687, top_k: 0.859375, samples/s: 2228.484 1612428233.4395695
train: epoch 123, iter 5000, loss: 2.209122, top_1: 0.677188, top_k: 0.867617, samples/s: 2231.869 1612428244.9097576
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_123.
validation: epoch 123, iter 195, top_1: 0.704107, top_k: 0.896655, samples/s: 2959.157 1612428262.1336021
train: epoch 124, iter 100, loss: 2.249630, top_1: 0.689844, top_k: 0.875430, samples/s: 2250.639 1612428289.1731944
train: epoch 124, iter 200, loss: 2.246132, top_1: 0.691719, top_k: 0.873555, samples/s: 2241.521 1612428300.594005
train: epoch 124, iter 300, loss: 2.186604, top_1: 0.682578, top_k: 0.871445, samples/s: 2256.717 1612428311.9379184
train: epoch 124, iter 400, loss: 2.492885, top_1: 0.686367, top_k: 0.872656, samples/s: 2227.513 1612428323.4305596
train: epoch 124, iter 500, loss: 2.164877, top_1: 0.683398, top_k: 0.871797, samples/s: 2254.494 1612428334.7856522
train: epoch 124, iter 600, loss: 2.356940, top_1: 0.675391, top_k: 0.863672, samples/s: 2257.946 1612428346.1234052
train: epoch 124, iter 700, loss: 2.370239, top_1: 0.672227, top_k: 0.861094, samples/s: 2240.950 1612428357.5471177
train: epoch 124, iter 800, loss: 2.303869, top_1: 0.678984, top_k: 0.864648, samples/s: 2258.274 1612428368.8832726
train: epoch 124, iter 900, loss: 2.351005, top_1: 0.678828, top_k: 0.866328, samples/s: 2229.651 1612428380.3648384
train: epoch 124, iter 1000, loss: 2.209593, top_1: 0.681992, top_k: 0.871016, samples/s: 2231.905 1612428391.8350685
train: epoch 124, iter 1100, loss: 2.379280, top_1: 0.681055, top_k: 0.869102, samples/s: 2220.453 1612428403.3640454
train: epoch 124, iter 1200, loss: 2.278718, top_1: 0.683945, top_k: 0.870859, samples/s: 2237.546 1612428414.805177
train: epoch 124, iter 1300, loss: 2.319297, top_1: 0.678438, top_k: 0.866680, samples/s: 2221.814 1612428426.3272846
train: epoch 124, iter 1400, loss: 2.153528, top_1: 0.677773, top_k: 0.870117, samples/s: 2209.347 1612428437.914436
train: epoch 124, iter 1500, loss: 2.461958, top_1: 0.677734, top_k: 0.868516, samples/s: 2236.384 1612428449.3614655
train: epoch 124, iter 1600, loss: 2.284715, top_1: 0.680664, top_k: 0.867656, samples/s: 2202.151 1612428460.986575
train: epoch 124, iter 1700, loss: 2.426513, top_1: 0.676055, top_k: 0.865508, samples/s: 2255.624 1612428472.3359814
train: epoch 124, iter 1800, loss: 2.226216, top_1: 0.682187, top_k: 0.869687, samples/s: 2225.056 1612428483.8411825
train: epoch 124, iter 1900, loss: 2.325845, top_1: 0.677422, top_k: 0.866953, samples/s: 2229.873 1612428495.3216507
train: epoch 124, iter 2000, loss: 2.251893, top_1: 0.675352, top_k: 0.865195, samples/s: 2233.025 1612428506.7859328
train: epoch 124, iter 2100, loss: 2.285851, top_1: 0.677656, top_k: 0.865742, samples/s: 2229.980 1612428518.26593
train: epoch 124, iter 2200, loss: 2.389709, top_1: 0.670664, top_k: 0.865078, samples/s: 2237.210 1612428529.7090569
train: epoch 124, iter 2300, loss: 2.283351, top_1: 0.675508, top_k: 0.869102, samples/s: 2223.432 1612428541.222406
train: epoch 124, iter 2400, loss: 2.296192, top_1: 0.676016, top_k: 0.863398, samples/s: 2218.556 1612428552.761435
train: epoch 124, iter 2500, loss: 2.261935, top_1: 0.681836, top_k: 0.868320, samples/s: 2236.788 1612428564.2064517
train: epoch 124, iter 2600, loss: 2.285774, top_1: 0.679805, top_k: 0.867148, samples/s: 2237.107 1612428575.6497798
train: epoch 124, iter 2700, loss: 2.285653, top_1: 0.681133, top_k: 0.868398, samples/s: 2239.607 1612428587.0807416
train: epoch 124, iter 2800, loss: 2.477540, top_1: 0.678594, top_k: 0.866523, samples/s: 2230.596 1612428598.5571136
train: epoch 124, iter 2900, loss: 2.240614, top_1: 0.677070, top_k: 0.867031, samples/s: 2219.602 1612428610.090756
train: epoch 124, iter 3000, loss: 2.243138, top_1: 0.673711, top_k: 0.864062, samples/s: 2228.586 1612428621.5778377
train: epoch 124, iter 3100, loss: 2.499631, top_1: 0.675156, top_k: 0.866563, samples/s: 2246.359 1612428632.974021
train: epoch 124, iter 3200, loss: 2.214538, top_1: 0.680117, top_k: 0.866758, samples/s: 2223.308 1612428644.4883895
train: epoch 124, iter 3300, loss: 2.568778, top_1: 0.673711, top_k: 0.866172, samples/s: 2239.463 1612428655.9197674
train: epoch 124, iter 3400, loss: 2.326373, top_1: 0.678867, top_k: 0.865508, samples/s: 2213.445 1612428667.485432
train: epoch 124, iter 3500, loss: 2.227000, top_1: 0.677852, top_k: 0.865625, samples/s: 2252.372 1612428678.851218
train: epoch 124, iter 3600, loss: 2.332827, top_1: 0.673711, top_k: 0.865977, samples/s: 2239.005 1612428690.2849097
train: epoch 124, iter 3700, loss: 2.103972, top_1: 0.671133, top_k: 0.862695, samples/s: 2214.367 1612428701.8456986
train: epoch 124, iter 3800, loss: 2.589687, top_1: 0.677031, top_k: 0.869844, samples/s: 2242.912 1612428713.2595077
train: epoch 124, iter 3900, loss: 2.475403, top_1: 0.670117, top_k: 0.860703, samples/s: 2224.229 1612428724.7691002
train: epoch 124, iter 4000, loss: 2.501726, top_1: 0.673438, top_k: 0.864688, samples/s: 2227.210 1612428736.2632456
train: epoch 124, iter 4100, loss: 2.212870, top_1: 0.679492, top_k: 0.865586, samples/s: 2245.444 1612428747.66412
train: epoch 124, iter 4200, loss: 2.362126, top_1: 0.672422, top_k: 0.863906, samples/s: 2227.292 1612428759.1578813
train: epoch 124, iter 4300, loss: 2.398767, top_1: 0.672734, top_k: 0.865156, samples/s: 2270.615 1612428770.432582
train: epoch 124, iter 4400, loss: 2.248857, top_1: 0.672891, top_k: 0.863672, samples/s: 2235.585 1612428781.8835044
train: epoch 124, iter 4500, loss: 2.307033, top_1: 0.677109, top_k: 0.867773, samples/s: 2225.432 1612428793.3870766
train: epoch 124, iter 4600, loss: 2.276576, top_1: 0.668281, top_k: 0.863984, samples/s: 2219.599 1612428804.9205291
train: epoch 124, iter 4700, loss: 2.321829, top_1: 0.679180, top_k: 0.863945, samples/s: 2236.468 1612428816.3671634
train: epoch 124, iter 4800, loss: 2.579867, top_1: 0.669492, top_k: 0.859219, samples/s: 2236.759 1612428827.8122613
train: epoch 124, iter 4900, loss: 2.242859, top_1: 0.674375, top_k: 0.861719, samples/s: 2236.875 1612428839.2569783
train: epoch 124, iter 5000, loss: 2.256412, top_1: 0.682148, top_k: 0.869766, samples/s: 2247.070 1612428850.6494298
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_124.
validation: epoch 124, iter 195, top_1: 0.703746, top_k: 0.897216, samples/s: 2862.478 1612428868.5313933
train: epoch 125, iter 100, loss: 2.334900, top_1: 0.690664, top_k: 0.873125, samples/s: 2228.196 1612428900.6816423
train: epoch 125, iter 200, loss: 2.432812, top_1: 0.695898, top_k: 0.875820, samples/s: 2244.515 1612428912.0872593
train: epoch 125, iter 300, loss: 2.249386, top_1: 0.688945, top_k: 0.871484, samples/s: 2247.104 1612428923.4796999
train: epoch 125, iter 400, loss: 2.153415, top_1: 0.682383, top_k: 0.868750, samples/s: 2255.546 1612428934.8295553
train: epoch 125, iter 500, loss: 2.216674, top_1: 0.684063, top_k: 0.870898, samples/s: 2221.438 1612428946.3535311
train: epoch 125, iter 600, loss: 2.229503, top_1: 0.676680, top_k: 0.869336, samples/s: 2272.154 1612428957.6207893
train: epoch 125, iter 700, loss: 2.177310, top_1: 0.683516, top_k: 0.872383, samples/s: 2241.947 1612428969.0390203
train: epoch 125, iter 800, loss: 2.304188, top_1: 0.685820, top_k: 0.869570, samples/s: 2234.430 1612428980.4960885
train: epoch 125, iter 900, loss: 2.286324, top_1: 0.683438, top_k: 0.870742, samples/s: 2237.315 1612428991.938759
train: epoch 125, iter 1000, loss: 2.264161, top_1: 0.683633, top_k: 0.865234, samples/s: 2237.204 1612429003.3812342
train: epoch 125, iter 1100, loss: 2.432883, top_1: 0.676406, top_k: 0.865586, samples/s: 2225.779 1612429014.882915
train: epoch 125, iter 1200, loss: 2.135685, top_1: 0.683477, top_k: 0.868555, samples/s: 2218.338 1612429026.4230442
train: epoch 125, iter 1300, loss: 2.301576, top_1: 0.680586, top_k: 0.869102, samples/s: 2222.914 1612429037.9394069
train: epoch 125, iter 1400, loss: 2.363975, top_1: 0.682422, top_k: 0.867422, samples/s: 2226.264 1612429049.4384851
train: epoch 125, iter 1500, loss: 2.121293, top_1: 0.678398, top_k: 0.865977, samples/s: 2206.387 1612429061.0412452
train: epoch 125, iter 1600, loss: 2.156607, top_1: 0.683320, top_k: 0.866680, samples/s: 2211.941 1612429072.6147456
train: epoch 125, iter 1700, loss: 2.281094, top_1: 0.684258, top_k: 0.869102, samples/s: 2220.037 1612429084.146052
train: epoch 125, iter 1800, loss: 2.334574, top_1: 0.682930, top_k: 0.869141, samples/s: 2214.488 1612429095.706441
train: epoch 125, iter 1900, loss: 2.288879, top_1: 0.682344, top_k: 0.870625, samples/s: 2189.798 1612429107.3968658
train: epoch 125, iter 2000, loss: 2.338264, top_1: 0.680234, top_k: 0.867344, samples/s: 2217.212 1612429118.9428997
train: epoch 125, iter 2100, loss: 2.421146, top_1: 0.678164, top_k: 0.866484, samples/s: 2213.770 1612429130.50694
train: epoch 125, iter 2200, loss: 2.184634, top_1: 0.676211, top_k: 0.865195, samples/s: 2206.635 1612429142.108251
train: epoch 125, iter 2300, loss: 2.313516, top_1: 0.677539, top_k: 0.870078, samples/s: 2191.602 1612429153.7893128
train: epoch 125, iter 2400, loss: 2.417655, top_1: 0.682461, top_k: 0.869102, samples/s: 2183.105 1612429165.5156162
train: epoch 125, iter 2500, loss: 2.223147, top_1: 0.678633, top_k: 0.867070, samples/s: 2218.721 1612429177.0538106
train: epoch 125, iter 2600, loss: 2.360631, top_1: 0.681211, top_k: 0.868008, samples/s: 2232.881 1612429188.5188148
train: epoch 125, iter 2700, loss: 2.318635, top_1: 0.677891, top_k: 0.867930, samples/s: 2224.154 1612429200.0287898
train: epoch 125, iter 2800, loss: 2.311726, top_1: 0.688555, top_k: 0.874141, samples/s: 2235.128 1612429211.4823055
train: epoch 125, iter 2900, loss: 2.404154, top_1: 0.679648, top_k: 0.867695, samples/s: 2200.259 1612429223.1172967
train: epoch 125, iter 3000, loss: 2.497554, top_1: 0.676367, top_k: 0.868633, samples/s: 2257.320 1612429234.4582279
train: epoch 125, iter 3100, loss: 2.370652, top_1: 0.675391, top_k: 0.868164, samples/s: 2225.423 1612429245.9617002
train: epoch 125, iter 3200, loss: 2.651941, top_1: 0.677500, top_k: 0.867617, samples/s: 2224.215 1612429257.4712791
train: epoch 125, iter 3300, loss: 2.323668, top_1: 0.681211, top_k: 0.870430, samples/s: 2228.691 1612429268.957921
train: epoch 125, iter 3400, loss: 2.391489, top_1: 0.683984, top_k: 0.868125, samples/s: 2233.926 1612429280.4174857
train: epoch 125, iter 3500, loss: 2.494810, top_1: 0.677148, top_k: 0.866172, samples/s: 2238.148 1612429291.8556163
train: epoch 125, iter 3600, loss: 2.370272, top_1: 0.678789, top_k: 0.867070, samples/s: 2229.310 1612429303.3388834
train: epoch 125, iter 3700, loss: 2.339509, top_1: 0.676797, top_k: 0.862891, samples/s: 2246.793 1612429314.732984
train: epoch 125, iter 3800, loss: 2.223831, top_1: 0.676328, top_k: 0.868047, samples/s: 2234.088 1612429326.1917214
train: epoch 125, iter 3900, loss: 2.416178, top_1: 0.679375, top_k: 0.868711, samples/s: 2235.558 1612429337.6430013
train: epoch 125, iter 4000, loss: 2.254286, top_1: 0.680000, top_k: 0.867422, samples/s: 2233.197 1612429349.1063755
train: epoch 125, iter 4100, loss: 2.223266, top_1: 0.678711, top_k: 0.865938, samples/s: 2219.896 1612429360.6385438
train: epoch 125, iter 4200, loss: 2.396683, top_1: 0.676484, top_k: 0.869453, samples/s: 2238.355 1612429372.07543
train: epoch 125, iter 4300, loss: 2.357558, top_1: 0.676836, top_k: 0.867578, samples/s: 2244.597 1612429383.4806554
train: epoch 125, iter 4400, loss: 2.369372, top_1: 0.683359, top_k: 0.870508, samples/s: 2239.164 1612429394.9134202
train: epoch 125, iter 4500, loss: 2.516722, top_1: 0.678008, top_k: 0.867539, samples/s: 2235.949 1612429406.3628743
train: epoch 125, iter 4600, loss: 2.313318, top_1: 0.680781, top_k: 0.868281, samples/s: 2233.030 1612429417.8269644
train: epoch 125, iter 4700, loss: 2.454099, top_1: 0.677031, top_k: 0.862031, samples/s: 2242.670 1612429429.2419062
train: epoch 125, iter 4800, loss: 2.473758, top_1: 0.675156, top_k: 0.865117, samples/s: 2230.456 1612429440.719387
train: epoch 125, iter 4900, loss: 2.533322, top_1: 0.678125, top_k: 0.863984, samples/s: 2233.333 1612429452.1820686
train: epoch 125, iter 5000, loss: 2.423157, top_1: 0.685664, top_k: 0.870664, samples/s: 2225.904 1612429463.68301
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_125.
validation: epoch 125, iter 195, top_1: 0.705909, top_k: 0.898518, samples/s: 2882.837 1612429481.4004564
train: epoch 126, iter 100, loss: 2.131069, top_1: 0.692734, top_k: 0.873672, samples/s: 2220.789 1612429508.5934088
train: epoch 126, iter 200, loss: 2.339004, top_1: 0.686758, top_k: 0.870547, samples/s: 2260.114 1612429519.9202695
train: epoch 126, iter 300, loss: 2.211849, top_1: 0.683203, top_k: 0.871953, samples/s: 2252.023 1612429531.2877378
train: epoch 126, iter 400, loss: 2.537082, top_1: 0.684063, top_k: 0.869062, samples/s: 2245.423 1612429542.6887808
train: epoch 126, iter 500, loss: 2.441735, top_1: 0.685898, top_k: 0.872227, samples/s: 2243.087 1612429554.1015491
train: epoch 126, iter 600, loss: 2.380496, top_1: 0.682031, top_k: 0.871094, samples/s: 2246.612 1612429565.4964786
train: epoch 126, iter 700, loss: 2.318830, top_1: 0.689844, top_k: 0.874258, samples/s: 2250.131 1612429576.8735754
train: epoch 126, iter 800, loss: 2.210028, top_1: 0.687617, top_k: 0.871563, samples/s: 2219.311 1612429588.408713
train: epoch 126, iter 900, loss: 2.321759, top_1: 0.688711, top_k: 0.872031, samples/s: 2238.892 1612429599.8430092
train: epoch 126, iter 1000, loss: 2.296113, top_1: 0.683867, top_k: 0.871016, samples/s: 2221.450 1612429611.366962
train: epoch 126, iter 1100, loss: 2.251690, top_1: 0.691055, top_k: 0.872930, samples/s: 2210.528 1612429622.9478848
train: epoch 126, iter 1200, loss: 2.447409, top_1: 0.685898, top_k: 0.866914, samples/s: 2220.298 1612429634.4778664
train: epoch 126, iter 1300, loss: 2.293625, top_1: 0.683633, top_k: 0.871094, samples/s: 2216.421 1612429646.028061
train: epoch 126, iter 1400, loss: 2.389111, top_1: 0.680859, top_k: 0.869375, samples/s: 2201.013 1612429657.6590323
train: epoch 126, iter 1500, loss: 2.328388, top_1: 0.686719, top_k: 0.872891, samples/s: 2240.897 1612429669.0830534
train: epoch 126, iter 1600, loss: 2.169017, top_1: 0.681133, top_k: 0.869961, samples/s: 2213.710 1612429680.6472871
train: epoch 126, iter 1700, loss: 2.492705, top_1: 0.685117, top_k: 0.870742, samples/s: 2219.465 1612429692.1817014
train: epoch 126, iter 1800, loss: 2.273402, top_1: 0.684961, top_k: 0.869922, samples/s: 2215.140 1612429703.738541
train: epoch 126, iter 1900, loss: 2.312360, top_1: 0.684336, top_k: 0.871211, samples/s: 2204.670 1612429715.35024
train: epoch 126, iter 2000, loss: 2.436650, top_1: 0.681562, top_k: 0.870273, samples/s: 2220.587 1612429726.8786886
train: epoch 126, iter 2100, loss: 2.241071, top_1: 0.686016, top_k: 0.868711, samples/s: 2220.984 1612429738.4051416
train: epoch 126, iter 2200, loss: 2.330941, top_1: 0.682187, top_k: 0.870078, samples/s: 2233.458 1612429749.8672137
train: epoch 126, iter 2300, loss: 2.404947, top_1: 0.682422, top_k: 0.872266, samples/s: 2241.043 1612429761.2904425
train: epoch 126, iter 2400, loss: 2.169295, top_1: 0.686484, top_k: 0.870430, samples/s: 2219.990 1612429772.82192
train: epoch 126, iter 2500, loss: 2.219997, top_1: 0.684102, top_k: 0.870430, samples/s: 2220.274 1612429784.3521943
train: epoch 126, iter 2600, loss: 2.098586, top_1: 0.676680, top_k: 0.869727, samples/s: 2238.589 1612429795.7879288
train: epoch 126, iter 2700, loss: 2.269873, top_1: 0.681719, top_k: 0.870508, samples/s: 2251.383 1612429807.158641
train: epoch 126, iter 2800, loss: 2.267176, top_1: 0.685586, top_k: 0.871133, samples/s: 2235.060 1612429818.612474
train: epoch 126, iter 2900, loss: 2.222807, top_1: 0.682266, top_k: 0.869375, samples/s: 2230.586 1612429830.0892935
train: epoch 126, iter 3000, loss: 2.230434, top_1: 0.683359, top_k: 0.867539, samples/s: 2209.770 1612429841.6742437
train: epoch 126, iter 3100, loss: 2.295240, top_1: 0.680430, top_k: 0.872031, samples/s: 2225.180 1612429853.1788871
train: epoch 126, iter 3200, loss: 2.506871, top_1: 0.685547, top_k: 0.870117, samples/s: 2229.096 1612429864.6634343
train: epoch 126, iter 3300, loss: 2.150664, top_1: 0.686133, top_k: 0.872383, samples/s: 2222.506 1612429876.1820562
train: epoch 126, iter 3400, loss: 2.262749, top_1: 0.682461, top_k: 0.869336, samples/s: 2219.191 1612429887.7176654
train: epoch 126, iter 3500, loss: 2.268306, top_1: 0.684844, top_k: 0.868125, samples/s: 2244.906 1612429899.121299
train: epoch 126, iter 3600, loss: 2.453660, top_1: 0.682539, top_k: 0.869453, samples/s: 2224.004 1612429910.6321037
train: epoch 126, iter 3700, loss: 2.156588, top_1: 0.683594, top_k: 0.868906, samples/s: 2235.562 1612429922.0832574
train: epoch 126, iter 3800, loss: 2.351141, top_1: 0.683203, top_k: 0.869687, samples/s: 2221.040 1612429933.609492
train: epoch 126, iter 3900, loss: 2.415215, top_1: 0.684766, top_k: 0.869062, samples/s: 2228.765 1612429945.09569
train: epoch 126, iter 4000, loss: 2.101267, top_1: 0.678906, top_k: 0.867930, samples/s: 2268.765 1612429956.3792398
train: epoch 126, iter 4100, loss: 2.467954, top_1: 0.680352, top_k: 0.868437, samples/s: 2233.656 1612429967.8406694
train: epoch 126, iter 4200, loss: 2.440873, top_1: 0.685234, top_k: 0.872383, samples/s: 2240.752 1612429979.2649887
train: epoch 126, iter 4300, loss: 2.318087, top_1: 0.679688, top_k: 0.870156, samples/s: 2227.284 1612429990.7588656
train: epoch 126, iter 4400, loss: 2.461189, top_1: 0.682227, top_k: 0.872422, samples/s: 2259.452 1612430002.089028
train: epoch 126, iter 4500, loss: 2.322127, top_1: 0.683672, top_k: 0.870078, samples/s: 2206.580 1612430013.6906722
train: epoch 126, iter 4600, loss: 2.297336, top_1: 0.684375, top_k: 0.873125, samples/s: 2247.761 1612430025.079822
train: epoch 126, iter 4700, loss: 2.604440, top_1: 0.688203, top_k: 0.870195, samples/s: 2231.916 1612430036.5497394
train: epoch 126, iter 4800, loss: 2.292117, top_1: 0.682266, top_k: 0.866875, samples/s: 2232.679 1612430048.0158725
train: epoch 126, iter 4900, loss: 2.392036, top_1: 0.682227, top_k: 0.868047, samples/s: 2254.467 1612430059.371036
train: epoch 126, iter 5000, loss: 2.280014, top_1: 0.687031, top_k: 0.872734, samples/s: 2235.887 1612430070.8207114
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_126.
validation: epoch 126, iter 195, top_1: 0.707833, top_k: 0.898938, samples/s: 2810.581 1612430088.886022
train: epoch 127, iter 100, loss: 2.433404, top_1: 0.693359, top_k: 0.875508, samples/s: 2241.330 1612430117.3857343
train: epoch 127, iter 200, loss: 2.313650, top_1: 0.685859, top_k: 0.871211, samples/s: 2252.820 1612430128.749278
train: epoch 127, iter 300, loss: 2.237202, top_1: 0.686133, top_k: 0.872773, samples/s: 2249.792 1612430140.1280549
train: epoch 127, iter 400, loss: 2.483756, top_1: 0.689063, top_k: 0.873320, samples/s: 2196.119 1612430151.785104
train: epoch 127, iter 500, loss: 2.079621, top_1: 0.689141, top_k: 0.871992, samples/s: 2241.999 1612430163.203439
train: epoch 127, iter 600, loss: 2.261707, top_1: 0.689492, top_k: 0.870508, samples/s: 2261.189 1612430174.5248377
train: epoch 127, iter 700, loss: 2.142276, top_1: 0.689922, top_k: 0.873437, samples/s: 2258.916 1612430185.8577652
train: epoch 127, iter 800, loss: 2.094899, top_1: 0.693164, top_k: 0.876367, samples/s: 2223.987 1612430197.3685894
train: epoch 127, iter 900, loss: 2.307495, top_1: 0.688516, top_k: 0.874180, samples/s: 2222.334 1612430208.8880374
train: epoch 127, iter 1000, loss: 2.347023, top_1: 0.689766, top_k: 0.875469, samples/s: 2233.074 1612430220.3520021
train: epoch 127, iter 1100, loss: 2.382450, top_1: 0.687969, top_k: 0.873555, samples/s: 2224.952 1612430231.858021
train: epoch 127, iter 1200, loss: 2.307249, top_1: 0.689727, top_k: 0.876250, samples/s: 2215.185 1612430243.4144702
train: epoch 127, iter 1300, loss: 2.184707, top_1: 0.685039, top_k: 0.870430, samples/s: 2225.271 1612430254.9186866
train: epoch 127, iter 1400, loss: 2.297114, top_1: 0.687266, top_k: 0.873008, samples/s: 2213.953 1612430266.4817166
train: epoch 127, iter 1500, loss: 2.169034, top_1: 0.681055, top_k: 0.870703, samples/s: 2246.004 1612430277.8798776
train: epoch 127, iter 1600, loss: 2.386355, top_1: 0.690430, top_k: 0.875430, samples/s: 2205.735 1612430289.4858491
train: epoch 127, iter 1700, loss: 2.387392, top_1: 0.684961, top_k: 0.873281, samples/s: 2216.043 1612430301.037968
train: epoch 127, iter 1800, loss: 2.172980, top_1: 0.689063, top_k: 0.872734, samples/s: 2222.732 1612430312.5553236
train: epoch 127, iter 1900, loss: 2.267628, top_1: 0.689609, top_k: 0.870352, samples/s: 2222.476 1612430324.0740764
train: epoch 127, iter 2000, loss: 2.364614, top_1: 0.689844, top_k: 0.874375, samples/s: 2213.107 1612430335.6417093
train: epoch 127, iter 2100, loss: 2.263497, top_1: 0.688359, top_k: 0.873437, samples/s: 2235.568 1612430347.092689
train: epoch 127, iter 2200, loss: 2.450541, top_1: 0.679961, top_k: 0.869727, samples/s: 2204.982 1612430358.7028086
train: epoch 127, iter 2300, loss: 2.371911, top_1: 0.686094, top_k: 0.872461, samples/s: 2222.204 1612430370.2228515
train: epoch 127, iter 2400, loss: 2.259001, top_1: 0.686992, top_k: 0.872266, samples/s: 2206.199 1612430381.826534
train: epoch 127, iter 2500, loss: 2.145795, top_1: 0.686914, top_k: 0.873359, samples/s: 2244.642 1612430393.231547
train: epoch 127, iter 2600, loss: 2.262134, top_1: 0.687852, top_k: 0.869648, samples/s: 2192.138 1612430404.9095616
train: epoch 127, iter 2700, loss: 2.315909, top_1: 0.685234, top_k: 0.869961, samples/s: 2207.881 1612430416.5044167
train: epoch 127, iter 2800, loss: 2.475950, top_1: 0.681289, top_k: 0.870742, samples/s: 2204.614 1612430428.116398
train: epoch 127, iter 2900, loss: 2.338039, top_1: 0.687305, top_k: 0.871680, samples/s: 2226.511 1612430439.6142845
train: epoch 127, iter 3000, loss: 2.225020, top_1: 0.682148, top_k: 0.872461, samples/s: 2207.864 1612430451.2092378
train: epoch 127, iter 3100, loss: 2.314738, top_1: 0.683359, top_k: 0.869102, samples/s: 2239.180 1612430462.6418736
train: epoch 127, iter 3200, loss: 2.245566, top_1: 0.689453, top_k: 0.873555, samples/s: 2224.148 1612430474.1519225
train: epoch 127, iter 3300, loss: 2.176998, top_1: 0.687500, top_k: 0.874180, samples/s: 2240.272 1612430485.5790915
train: epoch 127, iter 3400, loss: 2.298607, top_1: 0.680078, top_k: 0.870820, samples/s: 2235.516 1612430497.0306478
train: epoch 127, iter 3500, loss: 2.292668, top_1: 0.691367, top_k: 0.875977, samples/s: 2230.739 1612430508.506638
train: epoch 127, iter 3600, loss: 2.265650, top_1: 0.680312, top_k: 0.869531, samples/s: 2230.742 1612430519.982629
train: epoch 127, iter 3700, loss: 2.237865, top_1: 0.686055, top_k: 0.870859, samples/s: 2231.381 1612430531.4553218
train: epoch 127, iter 3800, loss: 2.293703, top_1: 0.681641, top_k: 0.871563, samples/s: 2242.499 1612430542.871182
train: epoch 127, iter 3900, loss: 2.164534, top_1: 0.685000, top_k: 0.869336, samples/s: 2218.476 1612430554.4106057
train: epoch 127, iter 4000, loss: 2.219532, top_1: 0.685039, top_k: 0.871094, samples/s: 2226.871 1612430565.9065566
train: epoch 127, iter 4100, loss: 2.230546, top_1: 0.685430, top_k: 0.871523, samples/s: 2207.342 1612430577.5042229
train: epoch 127, iter 4200, loss: 2.285578, top_1: 0.690000, top_k: 0.875000, samples/s: 2243.863 1612430588.9131062
train: epoch 127, iter 4300, loss: 2.201081, top_1: 0.684414, top_k: 0.873711, samples/s: 2234.302 1612430600.370861
train: epoch 127, iter 4400, loss: 2.396585, top_1: 0.685508, top_k: 0.872773, samples/s: 2220.359 1612430611.9005075
train: epoch 127, iter 4500, loss: 2.523273, top_1: 0.689375, top_k: 0.874609, samples/s: 2249.686 1612430623.279861
train: epoch 127, iter 4600, loss: 2.398857, top_1: 0.686484, top_k: 0.872031, samples/s: 2242.693 1612430634.694705
train: epoch 127, iter 4700, loss: 2.436631, top_1: 0.679609, top_k: 0.866797, samples/s: 2225.678 1612430646.1968284
train: epoch 127, iter 4800, loss: 2.204515, top_1: 0.684531, top_k: 0.869531, samples/s: 2230.674 1612430657.673221
train: epoch 127, iter 4900, loss: 2.219076, top_1: 0.681289, top_k: 0.871289, samples/s: 2254.730 1612430669.0271058
train: epoch 127, iter 5000, loss: 2.250501, top_1: 0.689922, top_k: 0.876406, samples/s: 2246.708 1612430680.421531
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_127.
validation: epoch 127, iter 195, top_1: 0.711538, top_k: 0.901482, samples/s: 2851.570 1612430698.2709317
train: epoch 128, iter 100, loss: 2.270277, top_1: 0.695234, top_k: 0.876172, samples/s: 2248.315 1612430726.5494745
train: epoch 128, iter 200, loss: 2.362561, top_1: 0.696289, top_k: 0.878242, samples/s: 2247.530 1612430737.9397514
train: epoch 128, iter 300, loss: 2.303819, top_1: 0.697500, top_k: 0.878828, samples/s: 2248.748 1612430749.323932
train: epoch 128, iter 400, loss: 2.324982, top_1: 0.694258, top_k: 0.877773, samples/s: 2262.540 1612430760.6385758
train: epoch 128, iter 500, loss: 2.302372, top_1: 0.692187, top_k: 0.874844, samples/s: 2253.420 1612430771.999064
train: epoch 128, iter 600, loss: 2.263745, top_1: 0.696055, top_k: 0.873594, samples/s: 2233.183 1612430783.4626248
train: epoch 128, iter 700, loss: 2.131666, top_1: 0.688945, top_k: 0.872852, samples/s: 2266.253 1612430794.7587214
train: epoch 128, iter 800, loss: 2.361172, top_1: 0.695195, top_k: 0.875391, samples/s: 2243.018 1612430806.1718993
train: epoch 128, iter 900, loss: 2.103562, top_1: 0.689297, top_k: 0.876445, samples/s: 2229.341 1612430817.6552017
train: epoch 128, iter 1000, loss: 2.191623, top_1: 0.695195, top_k: 0.880195, samples/s: 2227.371 1612430829.1484742
train: epoch 128, iter 1100, loss: 2.283260, top_1: 0.689023, top_k: 0.875234, samples/s: 2226.675 1612430840.645494
train: epoch 128, iter 1200, loss: 2.196618, top_1: 0.691875, top_k: 0.875625, samples/s: 2212.633 1612430852.215816
train: epoch 128, iter 1300, loss: 2.299292, top_1: 0.688125, top_k: 0.872734, samples/s: 2211.285 1612430863.7924874
train: epoch 128, iter 1400, loss: 2.467226, top_1: 0.689375, top_k: 0.874258, samples/s: 2224.405 1612430875.3010461
train: epoch 128, iter 1500, loss: 2.328156, top_1: 0.695859, top_k: 0.878984, samples/s: 2222.095 1612430886.8225636
train: epoch 128, iter 1600, loss: 2.188422, top_1: 0.686953, top_k: 0.869961, samples/s: 2205.012 1612430898.431613
train: epoch 128, iter 1700, loss: 2.359905, top_1: 0.691367, top_k: 0.875742, samples/s: 2218.742 1612430909.9696875
train: epoch 128, iter 1800, loss: 2.282040, top_1: 0.690352, top_k: 0.874336, samples/s: 2216.677 1612430921.5185173
train: epoch 128, iter 1900, loss: 2.216484, top_1: 0.692148, top_k: 0.876445, samples/s: 2233.156 1612430932.982141
train: epoch 128, iter 2000, loss: 2.153353, top_1: 0.686172, top_k: 0.871211, samples/s: 2210.937 1612430944.5609117
train: epoch 128, iter 2100, loss: 2.278916, top_1: 0.690898, top_k: 0.872734, samples/s: 2234.253 1612430956.0188346
train: epoch 128, iter 2200, loss: 2.268426, top_1: 0.689414, top_k: 0.875430, samples/s: 2205.454 1612430967.6264834
train: epoch 128, iter 2300, loss: 2.441150, top_1: 0.690430, top_k: 0.876875, samples/s: 2222.164 1612430979.1467595
train: epoch 128, iter 2400, loss: 2.302508, top_1: 0.695273, top_k: 0.873867, samples/s: 2207.694 1612430990.7425938
train: epoch 128, iter 2500, loss: 2.456196, top_1: 0.691055, top_k: 0.872227, samples/s: 2210.079 1612431002.3258662
train: epoch 128, iter 2600, loss: 2.365746, top_1: 0.683242, top_k: 0.869258, samples/s: 2184.629 1612431014.044107
train: epoch 128, iter 2700, loss: 2.180231, top_1: 0.692227, top_k: 0.874805, samples/s: 2212.694 1612431025.6137202
train: epoch 128, iter 2800, loss: 2.440448, top_1: 0.684766, top_k: 0.872031, samples/s: 2255.588 1612431036.9633386
train: epoch 128, iter 2900, loss: 2.258421, top_1: 0.686719, top_k: 0.872227, samples/s: 2215.306 1612431048.519287
train: epoch 128, iter 3000, loss: 2.224589, top_1: 0.684023, top_k: 0.871406, samples/s: 2237.501 1612431059.9606051
train: epoch 128, iter 3100, loss: 2.267080, top_1: 0.687187, top_k: 0.878555, samples/s: 2242.017 1612431071.3789003
train: epoch 128, iter 3200, loss: 2.486011, top_1: 0.686719, top_k: 0.871055, samples/s: 2238.728 1612431082.8139977
train: epoch 128, iter 3300, loss: 2.293553, top_1: 0.688242, top_k: 0.875000, samples/s: 2227.847 1612431094.3050735
train: epoch 128, iter 3400, loss: 2.365620, top_1: 0.687344, top_k: 0.870898, samples/s: 2247.612 1612431105.6947496
train: epoch 128, iter 3500, loss: 2.476576, top_1: 0.687266, top_k: 0.873555, samples/s: 2234.964 1612431117.1490705
train: epoch 128, iter 3600, loss: 2.437049, top_1: 0.690039, top_k: 0.869766, samples/s: 2240.849 1612431128.5732672
train: epoch 128, iter 3700, loss: 2.365303, top_1: 0.689336, top_k: 0.872539, samples/s: 2220.522 1612431140.102148
train: epoch 128, iter 3800, loss: 2.334285, top_1: 0.690742, top_k: 0.875469, samples/s: 2255.428 1612431151.4525673
train: epoch 128, iter 3900, loss: 2.281116, top_1: 0.686797, top_k: 0.873398, samples/s: 2235.445 1612431162.9044163
train: epoch 128, iter 4000, loss: 2.334883, top_1: 0.692227, top_k: 0.872227, samples/s: 2226.498 1612431174.4022825
train: epoch 128, iter 4100, loss: 2.262213, top_1: 0.690859, top_k: 0.873672, samples/s: 2233.308 1612431185.8650892
train: epoch 128, iter 4200, loss: 2.487498, top_1: 0.685430, top_k: 0.872969, samples/s: 2243.097 1612431197.2778852
train: epoch 128, iter 4300, loss: 2.450905, top_1: 0.688867, top_k: 0.874102, samples/s: 2244.495 1612431208.683587
train: epoch 128, iter 4400, loss: 2.179305, top_1: 0.686250, top_k: 0.869219, samples/s: 2237.652 1612431220.124201
train: epoch 128, iter 4500, loss: 2.400445, top_1: 0.690078, top_k: 0.873086, samples/s: 2230.739 1612431231.6001554
train: epoch 128, iter 4600, loss: 2.211660, top_1: 0.687383, top_k: 0.876211, samples/s: 2241.558 1612431243.0208323
train: epoch 128, iter 4700, loss: 2.384047, top_1: 0.686094, top_k: 0.870430, samples/s: 2245.229 1612431254.4231246
train: epoch 128, iter 4800, loss: 2.454428, top_1: 0.686562, top_k: 0.872891, samples/s: 2211.323 1612431265.999515
train: epoch 128, iter 4900, loss: 2.294096, top_1: 0.690586, top_k: 0.870977, samples/s: 2229.634 1612431277.4812298
train: epoch 128, iter 5000, loss: 2.296539, top_1: 0.694570, top_k: 0.875195, samples/s: 2232.489 1612431288.9483125
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_128.
validation: epoch 128, iter 195, top_1: 0.712179, top_k: 0.901683, samples/s: 2844.577 1612431306.8287969
train: epoch 129, iter 100, loss: 2.354836, top_1: 0.698594, top_k: 0.878281, samples/s: 2226.987 1612431334.4663022
train: epoch 129, iter 200, loss: 2.208555, top_1: 0.695625, top_k: 0.877031, samples/s: 2248.380 1612431345.8521247
train: epoch 129, iter 300, loss: 2.376607, top_1: 0.697617, top_k: 0.879766, samples/s: 2262.291 1612431357.1681862
train: epoch 129, iter 400, loss: 2.207595, top_1: 0.700273, top_k: 0.881367, samples/s: 2248.260 1612431368.554739
train: epoch 129, iter 500, loss: 2.364346, top_1: 0.694805, top_k: 0.876680, samples/s: 2254.904 1612431379.9078012
train: epoch 129, iter 600, loss: 2.212115, top_1: 0.697031, top_k: 0.877891, samples/s: 2252.836 1612431391.2711797
train: epoch 129, iter 700, loss: 2.359685, top_1: 0.691680, top_k: 0.876758, samples/s: 2259.242 1612431402.6028068
train: epoch 129, iter 800, loss: 2.222683, top_1: 0.693477, top_k: 0.875781, samples/s: 2255.325 1612431413.9533148
train: epoch 129, iter 900, loss: 2.280183, top_1: 0.697773, top_k: 0.878867, samples/s: 2248.222 1612431425.34021
train: epoch 129, iter 1000, loss: 2.309235, top_1: 0.695312, top_k: 0.878906, samples/s: 2221.901 1612431436.8617437
train: epoch 129, iter 1100, loss: 2.248671, top_1: 0.697539, top_k: 0.879180, samples/s: 2210.276 1612431448.444673
train: epoch 129, iter 1200, loss: 2.127538, top_1: 0.694453, top_k: 0.877500, samples/s: 2226.241 1612431459.9435
train: epoch 129, iter 1300, loss: 2.319358, top_1: 0.692070, top_k: 0.875156, samples/s: 2203.356 1612431471.5618896
train: epoch 129, iter 1400, loss: 2.170218, top_1: 0.700234, top_k: 0.878437, samples/s: 2248.951 1612431482.9449806
train: epoch 129, iter 1500, loss: 2.189488, top_1: 0.696719, top_k: 0.874258, samples/s: 2229.058 1612431494.4296083
train: epoch 129, iter 1600, loss: 2.326312, top_1: 0.694570, top_k: 0.877305, samples/s: 2229.790 1612431505.9105062
train: epoch 129, iter 1700, loss: 2.080060, top_1: 0.693672, top_k: 0.877227, samples/s: 2228.088 1612431517.4002151
train: epoch 129, iter 1800, loss: 2.262938, top_1: 0.694219, top_k: 0.876094, samples/s: 2221.598 1612431528.9234922
train: epoch 129, iter 1900, loss: 2.407778, top_1: 0.694648, top_k: 0.875000, samples/s: 2198.283 1612431540.568913
train: epoch 129, iter 2000, loss: 2.323663, top_1: 0.692109, top_k: 0.875781, samples/s: 2218.203 1612431552.10974
train: epoch 129, iter 2100, loss: 2.337629, top_1: 0.693242, top_k: 0.877188, samples/s: 2213.106 1612431563.6771953
train: epoch 129, iter 2200, loss: 2.371683, top_1: 0.689531, top_k: 0.874531, samples/s: 2222.950 1612431575.1934316
train: epoch 129, iter 2300, loss: 2.138738, top_1: 0.693711, top_k: 0.872227, samples/s: 2218.204 1612431586.7342992
train: epoch 129, iter 2400, loss: 2.271323, top_1: 0.698086, top_k: 0.876133, samples/s: 2209.366 1612431598.3213613
train: epoch 129, iter 2500, loss: 2.173733, top_1: 0.694336, top_k: 0.875664, samples/s: 2229.771 1612431609.8024209
train: epoch 129, iter 2600, loss: 2.290966, top_1: 0.699258, top_k: 0.879336, samples/s: 2225.475 1612431621.3054981
train: epoch 129, iter 2700, loss: 2.253649, top_1: 0.688477, top_k: 0.875195, samples/s: 2247.269 1612431632.6973703
train: epoch 129, iter 2800, loss: 2.176152, top_1: 0.694492, top_k: 0.877422, samples/s: 2210.899 1612431644.2761116
train: epoch 129, iter 2900, loss: 2.170528, top_1: 0.695352, top_k: 0.878516, samples/s: 2236.077 1612431655.7250578
train: epoch 129, iter 3000, loss: 2.295138, top_1: 0.696602, top_k: 0.877266, samples/s: 2228.590 1612431667.2117937
train: epoch 129, iter 3100, loss: 2.130423, top_1: 0.687148, top_k: 0.873711, samples/s: 2248.659 1612431678.5964265
train: epoch 129, iter 3200, loss: 2.175519, top_1: 0.692344, top_k: 0.876992, samples/s: 2237.031 1612431690.040102
train: epoch 129, iter 3300, loss: 2.413104, top_1: 0.690742, top_k: 0.875000, samples/s: 2230.563 1612431701.517103
train: epoch 129, iter 3400, loss: 2.185239, top_1: 0.690234, top_k: 0.873555, samples/s: 2233.549 1612431712.9785953
train: epoch 129, iter 3500, loss: 2.288326, top_1: 0.691523, top_k: 0.876094, samples/s: 2237.787 1612431724.4184554
train: epoch 129, iter 3600, loss: 2.461004, top_1: 0.689180, top_k: 0.875820, samples/s: 2222.281 1612431735.9381645
train: epoch 129, iter 3700, loss: 2.375339, top_1: 0.689063, top_k: 0.873164, samples/s: 2225.333 1612431747.44209
train: epoch 129, iter 3800, loss: 2.292527, top_1: 0.696172, top_k: 0.878281, samples/s: 2231.978 1612431758.9117436
train: epoch 129, iter 3900, loss: 2.225226, top_1: 0.688594, top_k: 0.872266, samples/s: 2229.166 1612431770.3959317
train: epoch 129, iter 4000, loss: 2.108263, top_1: 0.692344, top_k: 0.874336, samples/s: 2239.785 1612431781.8255298
train: epoch 129, iter 4100, loss: 2.379681, top_1: 0.689570, top_k: 0.873906, samples/s: 2261.170 1612431793.1470456
train: epoch 129, iter 4200, loss: 2.213264, top_1: 0.692852, top_k: 0.875859, samples/s: 2230.600 1612431804.6237805
train: epoch 129, iter 4300, loss: 2.388548, top_1: 0.683867, top_k: 0.874609, samples/s: 2234.814 1612431816.0788755
train: epoch 129, iter 4400, loss: 2.284276, top_1: 0.695078, top_k: 0.875195, samples/s: 2246.506 1612431827.474365
train: epoch 129, iter 4500, loss: 2.309182, top_1: 0.688633, top_k: 0.874297, samples/s: 2246.114 1612431838.871829
train: epoch 129, iter 4600, loss: 2.258886, top_1: 0.692461, top_k: 0.875391, samples/s: 2247.884 1612431850.2603168
train: epoch 129, iter 4700, loss: 2.149393, top_1: 0.690234, top_k: 0.873398, samples/s: 2247.332 1612431861.6516464
train: epoch 129, iter 4800, loss: 2.173120, top_1: 0.692695, top_k: 0.876094, samples/s: 2235.429 1612431873.1036053
train: epoch 129, iter 4900, loss: 2.314999, top_1: 0.691836, top_k: 0.873555, samples/s: 2244.782 1612431884.5077841
train: epoch 129, iter 5000, loss: 2.547594, top_1: 0.695078, top_k: 0.878164, samples/s: 2190.089 1612431896.196789
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_129.
validation: epoch 129, iter 195, top_1: 0.716026, top_k: 0.903085, samples/s: 2943.508 1612431913.4920955
train: epoch 130, iter 100, loss: 2.304737, top_1: 0.695547, top_k: 0.877227, samples/s: 2205.729 1612431941.3221889
train: epoch 130, iter 200, loss: 2.249694, top_1: 0.698477, top_k: 0.878594, samples/s: 2242.609 1612431952.737541
train: epoch 130, iter 300, loss: 2.278005, top_1: 0.697422, top_k: 0.881211, samples/s: 2252.943 1612431964.100342
train: epoch 130, iter 400, loss: 2.308254, top_1: 0.698477, top_k: 0.877461, samples/s: 2226.695 1612431975.5972173
train: epoch 130, iter 500, loss: 2.303163, top_1: 0.700273, top_k: 0.881602, samples/s: 2252.056 1612431986.9646273
train: epoch 130, iter 600, loss: 2.275974, top_1: 0.692695, top_k: 0.878125, samples/s: 2251.958 1612431998.3325279
train: epoch 130, iter 700, loss: 2.230294, top_1: 0.699414, top_k: 0.879492, samples/s: 2243.735 1612432009.7420366
train: epoch 130, iter 800, loss: 2.259844, top_1: 0.700391, top_k: 0.880156, samples/s: 2253.616 1612432021.1015403
train: epoch 130, iter 900, loss: 2.373665, top_1: 0.702031, top_k: 0.880391, samples/s: 2235.215 1612432032.5546277
train: epoch 130, iter 1000, loss: 2.450650, top_1: 0.699102, top_k: 0.883281, samples/s: 2216.087 1612432044.1064482
train: epoch 130, iter 1100, loss: 2.254092, top_1: 0.700156, top_k: 0.875977, samples/s: 2203.845 1612432055.7225637
train: epoch 130, iter 1200, loss: 2.112627, top_1: 0.691836, top_k: 0.873242, samples/s: 2228.190 1612432067.211772
train: epoch 130, iter 1300, loss: 2.306949, top_1: 0.695391, top_k: 0.880586, samples/s: 2232.878 1612432078.6767397
train: epoch 130, iter 1400, loss: 2.294005, top_1: 0.697031, top_k: 0.881523, samples/s: 2227.634 1612432090.1687245
train: epoch 130, iter 1500, loss: 2.199657, top_1: 0.699375, top_k: 0.878711, samples/s: 2213.335 1612432101.734972
train: epoch 130, iter 1600, loss: 2.283976, top_1: 0.698086, top_k: 0.874961, samples/s: 2212.767 1612432113.3042126
train: epoch 130, iter 1700, loss: 2.251715, top_1: 0.698398, top_k: 0.881523, samples/s: 2212.139 1612432124.8767633
train: epoch 130, iter 1800, loss: 2.360027, top_1: 0.696406, top_k: 0.877773, samples/s: 2222.095 1612432136.397343
train: epoch 130, iter 1900, loss: 2.160204, top_1: 0.702383, top_k: 0.881758, samples/s: 2220.045 1612432147.9287083
train: epoch 130, iter 2000, loss: 2.355306, top_1: 0.698633, top_k: 0.880977, samples/s: 2223.934 1612432159.4397674
train: epoch 130, iter 2100, loss: 2.280166, top_1: 0.697930, top_k: 0.879805, samples/s: 2235.450 1612432170.8916326
train: epoch 130, iter 2200, loss: 2.284296, top_1: 0.691797, top_k: 0.876484, samples/s: 2205.778 1612432182.4975545
train: epoch 130, iter 2300, loss: 2.192170, top_1: 0.694727, top_k: 0.878906, samples/s: 2214.877 1612432194.0557234
train: epoch 130, iter 2400, loss: 2.390548, top_1: 0.692383, top_k: 0.877266, samples/s: 2245.049 1612432205.4585783
train: epoch 130, iter 2500, loss: 2.151093, top_1: 0.697031, top_k: 0.876641, samples/s: 2225.570 1612432216.9612796
train: epoch 130, iter 2600, loss: 2.458655, top_1: 0.693984, top_k: 0.875117, samples/s: 2226.222 1612432228.4605746
train: epoch 130, iter 2700, loss: 2.158056, top_1: 0.691250, top_k: 0.874961, samples/s: 2211.795 1612432240.0349631
train: epoch 130, iter 2800, loss: 2.241943, top_1: 0.696914, top_k: 0.876602, samples/s: 2220.075 1612432251.5666344
train: epoch 130, iter 2900, loss: 2.171187, top_1: 0.700000, top_k: 0.880000, samples/s: 2219.453 1612432263.1003363
train: epoch 130, iter 3000, loss: 2.122128, top_1: 0.699453, top_k: 0.876406, samples/s: 2223.663 1612432274.6129198
train: epoch 130, iter 3100, loss: 2.334203, top_1: 0.695664, top_k: 0.878594, samples/s: 2208.524 1612432286.2046392
train: epoch 130, iter 3200, loss: 2.321590, top_1: 0.701992, top_k: 0.881523, samples/s: 2225.912 1612432297.7052672
train: epoch 130, iter 3300, loss: 2.188352, top_1: 0.694375, top_k: 0.878281, samples/s: 2230.692 1612432309.1816945
train: epoch 130, iter 3400, loss: 2.276245, top_1: 0.694922, top_k: 0.874414, samples/s: 2213.802 1612432320.7457025
train: epoch 130, iter 3500, loss: 2.075240, top_1: 0.698359, top_k: 0.878164, samples/s: 2224.939 1612432332.251358
train: epoch 130, iter 3600, loss: 2.321571, top_1: 0.694180, top_k: 0.876797, samples/s: 2220.835 1612432343.7784753
train: epoch 130, iter 3700, loss: 2.420535, top_1: 0.689805, top_k: 0.876016, samples/s: 2235.597 1612432355.2299755
train: epoch 130, iter 3800, loss: 2.254022, top_1: 0.686953, top_k: 0.873203, samples/s: 2213.691 1612432366.7939441
train: epoch 130, iter 3900, loss: 2.453772, top_1: 0.700742, top_k: 0.882227, samples/s: 2221.718 1612432378.3166232
train: epoch 130, iter 4000, loss: 2.385762, top_1: 0.697461, top_k: 0.880039, samples/s: 2232.498 1612432389.7835393
train: epoch 130, iter 4100, loss: 2.280883, top_1: 0.695664, top_k: 0.876016, samples/s: 2235.304 1612432401.2361355
train: epoch 130, iter 4200, loss: 2.379389, top_1: 0.689688, top_k: 0.874297, samples/s: 2249.711 1612432412.6154225
train: epoch 130, iter 4300, loss: 2.070899, top_1: 0.698750, top_k: 0.879961, samples/s: 2238.229 1612432424.0529783
train: epoch 130, iter 4400, loss: 2.277561, top_1: 0.702187, top_k: 0.882188, samples/s: 2230.466 1612432435.5304852
train: epoch 130, iter 4500, loss: 2.168769, top_1: 0.693125, top_k: 0.876914, samples/s: 2227.170 1612432447.0248065
train: epoch 130, iter 4600, loss: 2.163907, top_1: 0.694258, top_k: 0.877422, samples/s: 2223.005 1612432458.5408046
train: epoch 130, iter 4700, loss: 2.384763, top_1: 0.694648, top_k: 0.877852, samples/s: 2236.325 1612432469.9881203
train: epoch 130, iter 4800, loss: 2.285079, top_1: 0.692500, top_k: 0.876758, samples/s: 2227.285 1612432481.4819407
train: epoch 130, iter 4900, loss: 2.287006, top_1: 0.695195, top_k: 0.877734, samples/s: 2250.481 1612432492.8575375
train: epoch 130, iter 5000, loss: 2.141731, top_1: 0.699766, top_k: 0.879727, samples/s: 2226.496 1612432504.3552043
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_130.
validation: epoch 130, iter 195, top_1: 0.717548, top_k: 0.903606, samples/s: 2854.237 1612432522.1006866
train: epoch 131, iter 100, loss: 2.182368, top_1: 0.706602, top_k: 0.884531, samples/s: 2246.069 1612432550.3248973
train: epoch 131, iter 200, loss: 2.239536, top_1: 0.706875, top_k: 0.882305, samples/s: 2228.963 1612432561.8099406
train: epoch 131, iter 300, loss: 2.146583, top_1: 0.697266, top_k: 0.879805, samples/s: 2259.783 1612432573.138619
train: epoch 131, iter 400, loss: 2.359184, top_1: 0.696719, top_k: 0.877930, samples/s: 2240.227 1612432584.565929
train: epoch 131, iter 500, loss: 2.233392, top_1: 0.698164, top_k: 0.878398, samples/s: 2231.158 1612432596.0397015
train: epoch 131, iter 600, loss: 2.303515, top_1: 0.700195, top_k: 0.882109, samples/s: 2260.085 1612432607.3667548
train: epoch 131, iter 700, loss: 2.256350, top_1: 0.706211, top_k: 0.883242, samples/s: 2239.353 1612432618.7985892
train: epoch 131, iter 800, loss: 2.037390, top_1: 0.703438, top_k: 0.881602, samples/s: 2233.238 1612432630.2622032
train: epoch 131, iter 900, loss: 2.224984, top_1: 0.701953, top_k: 0.879414, samples/s: 2219.378 1612432641.7965262
train: epoch 131, iter 1000, loss: 2.413719, top_1: 0.699883, top_k: 0.879453, samples/s: 2236.420 1612432653.2438123
train: epoch 131, iter 1100, loss: 2.220117, top_1: 0.699063, top_k: 0.879727, samples/s: 2220.867 1612432664.770416
train: epoch 131, iter 1200, loss: 2.208935, top_1: 0.707266, top_k: 0.885312, samples/s: 2236.711 1612432676.2158544
train: epoch 131, iter 1300, loss: 2.138961, top_1: 0.704648, top_k: 0.880586, samples/s: 2190.196 1612432687.9042513
train: epoch 131, iter 1400, loss: 2.402061, top_1: 0.702109, top_k: 0.881133, samples/s: 2234.141 1612432699.3627784
train: epoch 131, iter 1500, loss: 2.215129, top_1: 0.696406, top_k: 0.879102, samples/s: 2224.182 1612432710.8726535
train: epoch 131, iter 1600, loss: 2.154084, top_1: 0.701055, top_k: 0.881602, samples/s: 2207.751 1612432722.4682043
train: epoch 131, iter 1700, loss: 2.344050, top_1: 0.697969, top_k: 0.878477, samples/s: 2240.588 1612432733.8937573
train: epoch 131, iter 1800, loss: 2.105133, top_1: 0.702227, top_k: 0.881680, samples/s: 2208.020 1612432745.4878113
train: epoch 131, iter 1900, loss: 2.107109, top_1: 0.698984, top_k: 0.880625, samples/s: 2229.956 1612432756.9678638
train: epoch 131, iter 2000, loss: 2.257506, top_1: 0.696953, top_k: 0.878711, samples/s: 2214.975 1612432768.5255578
train: epoch 131, iter 2100, loss: 2.037338, top_1: 0.697812, top_k: 0.879687, samples/s: 2229.428 1612432780.008368
train: epoch 131, iter 2200, loss: 2.381085, top_1: 0.696133, top_k: 0.879414, samples/s: 2226.862 1612432791.5043159
train: epoch 131, iter 2300, loss: 2.350426, top_1: 0.699766, top_k: 0.878945, samples/s: 2198.190 1612432803.1502635
train: epoch 131, iter 2400, loss: 2.129035, top_1: 0.696172, top_k: 0.877930, samples/s: 2229.058 1612432814.6350021
train: epoch 131, iter 2500, loss: 2.146048, top_1: 0.700352, top_k: 0.883203, samples/s: 2220.547 1612432826.1636276
train: epoch 131, iter 2600, loss: 2.300477, top_1: 0.700664, top_k: 0.879219, samples/s: 2221.912 1612432837.6852334
train: epoch 131, iter 2700, loss: 2.184208, top_1: 0.697187, top_k: 0.878320, samples/s: 2232.142 1612432849.1540332
train: epoch 131, iter 2800, loss: 2.144355, top_1: 0.698633, top_k: 0.879648, samples/s: 2220.189 1612432860.6845837
train: epoch 131, iter 2900, loss: 2.301337, top_1: 0.695586, top_k: 0.877656, samples/s: 2233.996 1612432872.1438746
train: epoch 131, iter 3000, loss: 2.108666, top_1: 0.699023, top_k: 0.881484, samples/s: 2216.432 1612432883.6939647
train: epoch 131, iter 3100, loss: 2.299187, top_1: 0.698789, top_k: 0.879062, samples/s: 2261.859 1612432895.0120986
train: epoch 131, iter 3200, loss: 2.294519, top_1: 0.703945, top_k: 0.882773, samples/s: 2244.828 1612432906.416083
train: epoch 131, iter 3300, loss: 2.313207, top_1: 0.696367, top_k: 0.876367, samples/s: 2223.057 1612432917.9318383
train: epoch 131, iter 3400, loss: 2.239912, top_1: 0.697734, top_k: 0.878437, samples/s: 2240.997 1612432929.3553047
train: epoch 131, iter 3500, loss: 2.216825, top_1: 0.693828, top_k: 0.877773, samples/s: 2241.746 1612432940.7749634
train: epoch 131, iter 3600, loss: 2.140179, top_1: 0.695469, top_k: 0.877305, samples/s: 2222.836 1612432952.291925
train: epoch 131, iter 3700, loss: 2.286015, top_1: 0.696406, top_k: 0.880586, samples/s: 2240.099 1612432963.7197995
train: epoch 131, iter 3800, loss: 2.167400, top_1: 0.692813, top_k: 0.874844, samples/s: 2239.165 1612432975.1527095
train: epoch 131, iter 3900, loss: 2.129919, top_1: 0.697148, top_k: 0.880313, samples/s: 2243.052 1612432986.5656557
train: epoch 131, iter 4000, loss: 2.059822, top_1: 0.698320, top_k: 0.879687, samples/s: 2252.274 1612432997.9319222
train: epoch 131, iter 4100, loss: 2.227704, top_1: 0.700273, top_k: 0.879805, samples/s: 2245.901 1612433009.3305166
train: epoch 131, iter 4200, loss: 2.173521, top_1: 0.699336, top_k: 0.878164, samples/s: 2246.732 1612433020.7248132
train: epoch 131, iter 4300, loss: 2.317935, top_1: 0.695078, top_k: 0.879375, samples/s: 2227.757 1612433032.2162142
train: epoch 131, iter 4400, loss: 2.181044, top_1: 0.695703, top_k: 0.875977, samples/s: 2236.399 1612433043.6631923
train: epoch 131, iter 4500, loss: 2.338408, top_1: 0.698398, top_k: 0.878672, samples/s: 2242.416 1612433055.079507
train: epoch 131, iter 4600, loss: 2.375485, top_1: 0.700430, top_k: 0.877734, samples/s: 2243.755 1612433066.4888773
train: epoch 131, iter 4700, loss: 2.236035, top_1: 0.704219, top_k: 0.880352, samples/s: 2230.820 1612433077.9645073
train: epoch 131, iter 4800, loss: 2.401561, top_1: 0.700195, top_k: 0.878555, samples/s: 2246.395 1612433089.360563
train: epoch 131, iter 4900, loss: 2.394697, top_1: 0.696680, top_k: 0.879141, samples/s: 2244.434 1612433100.766498
train: epoch 131, iter 5000, loss: 2.284540, top_1: 0.705664, top_k: 0.886445, samples/s: 2241.672 1612433112.186581
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_131.
validation: epoch 131, iter 195, top_1: 0.720773, top_k: 0.905529, samples/s: 2913.129 1612433129.6814141
train: epoch 132, iter 100, loss: 2.323009, top_1: 0.705703, top_k: 0.883633, samples/s: 2236.201 1612433157.1851466
train: epoch 132, iter 200, loss: 2.174690, top_1: 0.705039, top_k: 0.882930, samples/s: 2267.764 1612433168.4737697
train: epoch 132, iter 300, loss: 2.250970, top_1: 0.705195, top_k: 0.883125, samples/s: 2247.515 1612433179.8640597
train: epoch 132, iter 400, loss: 2.256505, top_1: 0.703281, top_k: 0.880352, samples/s: 2245.336 1612433191.2654674
train: epoch 132, iter 500, loss: 2.196115, top_1: 0.703359, top_k: 0.884805, samples/s: 2252.927 1612433202.6285608
train: epoch 132, iter 600, loss: 2.311908, top_1: 0.706641, top_k: 0.884062, samples/s: 2256.396 1612433213.973998
train: epoch 132, iter 700, loss: 2.378802, top_1: 0.703672, top_k: 0.880898, samples/s: 2255.049 1612433225.3262963
train: epoch 132, iter 800, loss: 2.116463, top_1: 0.701992, top_k: 0.878906, samples/s: 2252.058 1612433236.6936743
train: epoch 132, iter 900, loss: 2.176622, top_1: 0.703359, top_k: 0.881641, samples/s: 2214.506 1612433248.253962
train: epoch 132, iter 1000, loss: 2.223113, top_1: 0.700508, top_k: 0.878555, samples/s: 2211.668 1612433259.8287935
train: epoch 132, iter 1100, loss: 2.103530, top_1: 0.704180, top_k: 0.878867, samples/s: 2230.925 1612433271.3039083
train: epoch 132, iter 1200, loss: 2.274112, top_1: 0.703320, top_k: 0.882422, samples/s: 2246.129 1612433282.7012773
train: epoch 132, iter 1300, loss: 2.257077, top_1: 0.705937, top_k: 0.883047, samples/s: 2234.886 1612433294.1559653
train: epoch 132, iter 1400, loss: 2.301777, top_1: 0.701094, top_k: 0.877734, samples/s: 2234.581 1612433305.612288
train: epoch 132, iter 1500, loss: 2.269102, top_1: 0.706367, top_k: 0.882188, samples/s: 2212.829 1612433317.1811955
train: epoch 132, iter 1600, loss: 2.151695, top_1: 0.703750, top_k: 0.881016, samples/s: 2212.506 1612433328.7517524
train: epoch 132, iter 1700, loss: 2.339403, top_1: 0.703945, top_k: 0.882305, samples/s: 2229.544 1612433340.2339797
train: epoch 132, iter 1800, loss: 2.274681, top_1: 0.704883, top_k: 0.882188, samples/s: 2241.126 1612433351.6568027
train: epoch 132, iter 1900, loss: 2.221793, top_1: 0.704453, top_k: 0.886523, samples/s: 2157.344 1612433363.5232089
train: epoch 132, iter 2000, loss: 2.278476, top_1: 0.706094, top_k: 0.883594, samples/s: 2231.651 1612433374.9945397
train: epoch 132, iter 2100, loss: 2.322115, top_1: 0.704141, top_k: 0.880000, samples/s: 2226.979 1612433386.4899228
train: epoch 132, iter 2200, loss: 2.193823, top_1: 0.698398, top_k: 0.880039, samples/s: 2192.961 1612433398.1636903
train: epoch 132, iter 2300, loss: 2.269895, top_1: 0.702266, top_k: 0.880195, samples/s: 2242.751 1612433409.578228
train: epoch 132, iter 2400, loss: 2.312917, top_1: 0.702656, top_k: 0.881523, samples/s: 2228.749 1612433421.0645056
train: epoch 132, iter 2500, loss: 2.279585, top_1: 0.697500, top_k: 0.876133, samples/s: 2238.563 1612433432.5004117
train: epoch 132, iter 2600, loss: 2.256981, top_1: 0.701250, top_k: 0.882188, samples/s: 2183.438 1612433444.2250926
train: epoch 132, iter 2700, loss: 2.305443, top_1: 0.699336, top_k: 0.879687, samples/s: 2215.631 1612433455.7792528
train: epoch 132, iter 2800, loss: 2.050575, top_1: 0.702734, top_k: 0.879375, samples/s: 2222.087 1612433467.2999988
train: epoch 132, iter 2900, loss: 2.291727, top_1: 0.699453, top_k: 0.878906, samples/s: 2234.133 1612433478.7585342
train: epoch 132, iter 3000, loss: 2.274364, top_1: 0.698516, top_k: 0.876016, samples/s: 2230.805 1612433490.2342129
train: epoch 132, iter 3100, loss: 2.387237, top_1: 0.700664, top_k: 0.879414, samples/s: 2222.711 1612433501.7516818
train: epoch 132, iter 3200, loss: 2.229947, top_1: 0.701719, top_k: 0.877500, samples/s: 2220.589 1612433513.2802143
train: epoch 132, iter 3300, loss: 2.338330, top_1: 0.702344, top_k: 0.880703, samples/s: 2237.935 1612433524.7192817
train: epoch 132, iter 3400, loss: 2.256802, top_1: 0.701680, top_k: 0.878359, samples/s: 2202.357 1612433536.3431783
train: epoch 132, iter 3500, loss: 2.341432, top_1: 0.699102, top_k: 0.879414, samples/s: 2228.927 1612433547.8285325
train: epoch 132, iter 3600, loss: 2.444651, top_1: 0.700195, top_k: 0.879922, samples/s: 2217.351 1612433559.3738606
train: epoch 132, iter 3700, loss: 2.147727, top_1: 0.697227, top_k: 0.878555, samples/s: 2215.530 1612433570.9286406
train: epoch 132, iter 3800, loss: 2.196998, top_1: 0.699297, top_k: 0.878203, samples/s: 2222.107 1612433582.4492793
train: epoch 132, iter 3900, loss: 2.174926, top_1: 0.702734, top_k: 0.880977, samples/s: 2226.364 1612433593.9478052
train: epoch 132, iter 4000, loss: 2.252465, top_1: 0.704688, top_k: 0.884180, samples/s: 2231.659 1612433605.4194953
train: epoch 132, iter 4100, loss: 2.167003, top_1: 0.703711, top_k: 0.883125, samples/s: 2234.478 1612433616.8759496
train: epoch 132, iter 4200, loss: 2.084227, top_1: 0.704453, top_k: 0.880234, samples/s: 2213.348 1612433628.4422326
train: epoch 132, iter 4300, loss: 2.347121, top_1: 0.699219, top_k: 0.882734, samples/s: 2258.480 1612433639.7771556
train: epoch 132, iter 4400, loss: 2.168924, top_1: 0.702031, top_k: 0.878945, samples/s: 2203.394 1612433651.3959424
train: epoch 132, iter 4500, loss: 2.251571, top_1: 0.700000, top_k: 0.880938, samples/s: 2204.873 1612433663.0063503
train: epoch 132, iter 4600, loss: 2.306064, top_1: 0.703359, top_k: 0.880234, samples/s: 2226.052 1612433674.50641
train: epoch 132, iter 4700, loss: 2.122100, top_1: 0.704258, top_k: 0.882734, samples/s: 2211.170 1612433686.0839927
train: epoch 132, iter 4800, loss: 2.175093, top_1: 0.708438, top_k: 0.883477, samples/s: 2233.063 1612433697.548067
train: epoch 132, iter 4900, loss: 2.282078, top_1: 0.701719, top_k: 0.879023, samples/s: 2230.947 1612433709.023035
train: epoch 132, iter 5000, loss: 2.303415, top_1: 0.704141, top_k: 0.884609, samples/s: 2229.257 1612433720.5066795
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_132.
validation: epoch 132, iter 195, top_1: 0.720933, top_k: 0.906791, samples/s: 2967.602 1612433737.7080235
train: epoch 133, iter 100, loss: 2.190988, top_1: 0.717383, top_k: 0.889961, samples/s: 2246.116 1612433765.1961064
train: epoch 133, iter 200, loss: 2.088840, top_1: 0.709258, top_k: 0.884062, samples/s: 2253.646 1612433776.5554407
train: epoch 133, iter 300, loss: 2.113781, top_1: 0.713711, top_k: 0.885547, samples/s: 2251.042 1612433787.9279437
train: epoch 133, iter 400, loss: 2.371632, top_1: 0.708359, top_k: 0.886133, samples/s: 2240.038 1612433799.3563082
train: epoch 133, iter 500, loss: 2.170089, top_1: 0.706914, top_k: 0.884453, samples/s: 2256.097 1612433810.7034779
train: epoch 133, iter 600, loss: 2.255298, top_1: 0.710156, top_k: 0.884297, samples/s: 2251.164 1612433822.0753431
train: epoch 133, iter 700, loss: 2.313642, top_1: 0.707031, top_k: 0.886133, samples/s: 2246.849 1612433833.4689705
train: epoch 133, iter 800, loss: 2.296288, top_1: 0.710625, top_k: 0.881836, samples/s: 2244.260 1612433844.8758643
train: epoch 133, iter 900, loss: 2.266565, top_1: 0.707344, top_k: 0.883867, samples/s: 2247.766 1612433856.26497
train: epoch 133, iter 1000, loss: 2.375475, top_1: 0.704336, top_k: 0.884062, samples/s: 2223.334 1612433867.7792032
train: epoch 133, iter 1100, loss: 2.323211, top_1: 0.703398, top_k: 0.884961, samples/s: 2200.206 1612433879.4145794
train: epoch 133, iter 1200, loss: 2.184328, top_1: 0.704688, top_k: 0.882500, samples/s: 2213.227 1612433890.9814305
train: epoch 133, iter 1300, loss: 2.131353, top_1: 0.711133, top_k: 0.884297, samples/s: 2228.043 1612433902.4711752
train: epoch 133, iter 1400, loss: 2.104708, top_1: 0.701211, top_k: 0.881445, samples/s: 2214.311 1612433914.0323296
train: epoch 133, iter 1500, loss: 2.277077, top_1: 0.708555, top_k: 0.884023, samples/s: 2226.453 1612433925.5304587
train: epoch 133, iter 1600, loss: 2.196751, top_1: 0.709688, top_k: 0.883281, samples/s: 2210.473 1612433937.1116784
train: epoch 133, iter 1700, loss: 2.357756, top_1: 0.708203, top_k: 0.887578, samples/s: 2223.107 1612433948.6270735
train: epoch 133, iter 1800, loss: 2.330345, top_1: 0.704258, top_k: 0.884961, samples/s: 2212.940 1612433960.1954045
train: epoch 133, iter 1900, loss: 2.232910, top_1: 0.700273, top_k: 0.880391, samples/s: 2211.891 1612433971.7692635
train: epoch 133, iter 2000, loss: 2.464829, top_1: 0.706367, top_k: 0.882773, samples/s: 2227.658 1612433983.2611375
train: epoch 133, iter 2100, loss: 2.342084, top_1: 0.707734, top_k: 0.886836, samples/s: 2221.202 1612433994.7864366
train: epoch 133, iter 2200, loss: 2.257749, top_1: 0.706641, top_k: 0.881641, samples/s: 2222.034 1612434006.3073683
train: epoch 133, iter 2300, loss: 2.204586, top_1: 0.702227, top_k: 0.884648, samples/s: 2210.671 1612434017.8875906
train: epoch 133, iter 2400, loss: 2.252835, top_1: 0.710625, top_k: 0.885977, samples/s: 2202.290 1612434029.5118282
train: epoch 133, iter 2500, loss: 2.247201, top_1: 0.703906, top_k: 0.883867, samples/s: 2224.030 1612434041.0224812
train: epoch 133, iter 2600, loss: 2.162141, top_1: 0.704453, top_k: 0.881680, samples/s: 2215.514 1612434052.577624
train: epoch 133, iter 2700, loss: 2.264862, top_1: 0.708047, top_k: 0.886797, samples/s: 2223.993 1612434064.0881743
train: epoch 133, iter 2800, loss: 2.288992, top_1: 0.708945, top_k: 0.885664, samples/s: 2201.035 1612434075.7190766
train: epoch 133, iter 2900, loss: 2.160438, top_1: 0.705547, top_k: 0.884570, samples/s: 2203.186 1612434087.3386424
train: epoch 133, iter 3000, loss: 2.367163, top_1: 0.699375, top_k: 0.880820, samples/s: 2233.383 1612434098.8010368
train: epoch 133, iter 3100, loss: 2.185865, top_1: 0.697891, top_k: 0.877734, samples/s: 2218.992 1612434110.3378074
train: epoch 133, iter 3200, loss: 2.140682, top_1: 0.705586, top_k: 0.881758, samples/s: 2213.232 1612434121.9046052
train: epoch 133, iter 3300, loss: 2.206085, top_1: 0.707578, top_k: 0.882969, samples/s: 2200.052 1612434133.5406988
train: epoch 133, iter 3400, loss: 2.075840, top_1: 0.701758, top_k: 0.880664, samples/s: 2241.877 1612434144.9597137
train: epoch 133, iter 3500, loss: 2.243014, top_1: 0.704648, top_k: 0.884531, samples/s: 2230.762 1612434156.435599
train: epoch 133, iter 3600, loss: 2.067733, top_1: 0.701016, top_k: 0.880234, samples/s: 2234.547 1612434167.8920982
train: epoch 133, iter 3700, loss: 2.338117, top_1: 0.701953, top_k: 0.884102, samples/s: 2223.355 1612434179.4061892
train: epoch 133, iter 3800, loss: 2.143224, top_1: 0.706836, top_k: 0.885586, samples/s: 2230.273 1612434190.8846152
train: epoch 133, iter 3900, loss: 2.222430, top_1: 0.706172, top_k: 0.882031, samples/s: 2204.622 1612434202.4969604
train: epoch 133, iter 4000, loss: 2.159497, top_1: 0.703867, top_k: 0.881836, samples/s: 2230.138 1612434213.975764
train: epoch 133, iter 4100, loss: 2.194259, top_1: 0.698789, top_k: 0.879102, samples/s: 2229.426 1612434225.4584665
train: epoch 133, iter 4200, loss: 2.060002, top_1: 0.706406, top_k: 0.882188, samples/s: 2228.993 1612434236.943985
train: epoch 133, iter 4300, loss: 2.189286, top_1: 0.710898, top_k: 0.883320, samples/s: 2220.363 1612434248.473139
train: epoch 133, iter 4400, loss: 2.375313, top_1: 0.702969, top_k: 0.882305, samples/s: 2218.285 1612434260.0136325
train: epoch 133, iter 4500, loss: 2.055210, top_1: 0.707187, top_k: 0.882305, samples/s: 2223.107 1612434271.5289822
train: epoch 133, iter 4600, loss: 2.203336, top_1: 0.704531, top_k: 0.882656, samples/s: 2222.422 1612434283.0481708
train: epoch 133, iter 4700, loss: 2.161222, top_1: 0.711016, top_k: 0.883164, samples/s: 2225.148 1612434294.552789
train: epoch 133, iter 4800, loss: 2.316980, top_1: 0.706562, top_k: 0.887305, samples/s: 2206.569 1612434306.1545348
train: epoch 133, iter 4900, loss: 2.337777, top_1: 0.705039, top_k: 0.881367, samples/s: 2211.559 1612434317.730121
train: epoch 133, iter 5000, loss: 2.168993, top_1: 0.709414, top_k: 0.884492, samples/s: 2227.433 1612434329.2231138
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_133.
validation: epoch 133, iter 195, top_1: 0.724539, top_k: 0.909535, samples/s: 2962.415 1612434346.4323378
train: epoch 134, iter 100, loss: 2.217161, top_1: 0.713711, top_k: 0.885234, samples/s: 2249.588 1612434374.21642
train: epoch 134, iter 200, loss: 2.141893, top_1: 0.709648, top_k: 0.884727, samples/s: 2235.774 1612434385.6668928
train: epoch 134, iter 300, loss: 2.163725, top_1: 0.709063, top_k: 0.886445, samples/s: 2254.047 1612434397.023886
train: epoch 134, iter 400, loss: 2.255166, top_1: 0.709688, top_k: 0.888906, samples/s: 2248.965 1612434408.4073174
train: epoch 134, iter 500, loss: 2.062973, top_1: 0.708008, top_k: 0.883203, samples/s: 2253.422 1612434419.7673736
train: epoch 134, iter 600, loss: 2.199344, top_1: 0.713203, top_k: 0.886758, samples/s: 2270.709 1612434431.0414133
train: epoch 134, iter 700, loss: 2.258632, top_1: 0.716016, top_k: 0.889648, samples/s: 2240.116 1612434442.4693797
train: epoch 134, iter 800, loss: 2.384725, top_1: 0.710586, top_k: 0.887344, samples/s: 2241.341 1612434453.8911855
train: epoch 134, iter 900, loss: 2.074909, top_1: 0.712734, top_k: 0.886172, samples/s: 2232.857 1612434465.356249
train: epoch 134, iter 1000, loss: 2.266281, top_1: 0.715430, top_k: 0.886875, samples/s: 2241.593 1612434476.7767117
train: epoch 134, iter 1100, loss: 2.232860, top_1: 0.712734, top_k: 0.887383, samples/s: 2217.757 1612434488.3199003
train: epoch 134, iter 1200, loss: 2.308128, top_1: 0.710508, top_k: 0.880898, samples/s: 2213.670 1612434499.884373
train: epoch 134, iter 1300, loss: 2.273541, top_1: 0.709727, top_k: 0.884375, samples/s: 2193.782 1612434511.5537338
train: epoch 134, iter 1400, loss: 2.196433, top_1: 0.710000, top_k: 0.880859, samples/s: 2235.233 1612434523.0066833
train: epoch 134, iter 1500, loss: 2.237889, top_1: 0.712930, top_k: 0.887461, samples/s: 2222.097 1612434534.5273132
train: epoch 134, iter 1600, loss: 2.075416, top_1: 0.705039, top_k: 0.887773, samples/s: 2225.788 1612434546.028887
train: epoch 134, iter 1700, loss: 2.195956, top_1: 0.711719, top_k: 0.883984, samples/s: 2205.403 1612434557.6367164
train: epoch 134, iter 1800, loss: 2.207150, top_1: 0.710586, top_k: 0.885781, samples/s: 2235.773 1612434569.0868957
train: epoch 134, iter 1900, loss: 2.243071, top_1: 0.705313, top_k: 0.883711, samples/s: 2196.992 1612434580.739226
train: epoch 134, iter 2000, loss: 2.357314, top_1: 0.707617, top_k: 0.885234, samples/s: 2243.232 1612434592.1513517
train: epoch 134, iter 2100, loss: 2.236181, top_1: 0.708633, top_k: 0.884766, samples/s: 2228.200 1612434603.6404443
train: epoch 134, iter 2200, loss: 2.298006, top_1: 0.711641, top_k: 0.885742, samples/s: 2221.997 1612434615.1615565
train: epoch 134, iter 2300, loss: 2.329761, top_1: 0.705703, top_k: 0.883086, samples/s: 2221.815 1612434626.6837275
train: epoch 134, iter 2400, loss: 2.203838, top_1: 0.710117, top_k: 0.883945, samples/s: 2222.155 1612434638.204077
train: epoch 134, iter 2500, loss: 2.155524, top_1: 0.709648, top_k: 0.885273, samples/s: 2215.249 1612434649.7603202
train: epoch 134, iter 2600, loss: 2.311386, top_1: 0.705313, top_k: 0.883672, samples/s: 2222.551 1612434661.2786002
train: epoch 134, iter 2700, loss: 2.363830, top_1: 0.706836, top_k: 0.880820, samples/s: 2200.742 1612434672.9110773
train: epoch 134, iter 2800, loss: 2.333870, top_1: 0.706562, top_k: 0.885781, samples/s: 2231.871 1612434684.381245
train: epoch 134, iter 2900, loss: 2.072563, top_1: 0.709844, top_k: 0.885000, samples/s: 2214.624 1612434695.9407609
train: epoch 134, iter 3000, loss: 2.210114, top_1: 0.710859, top_k: 0.884453, samples/s: 2239.755 1612434707.370609
train: epoch 134, iter 3100, loss: 2.359839, top_1: 0.704258, top_k: 0.883125, samples/s: 2222.440 1612434718.8894517
train: epoch 134, iter 3200, loss: 2.003047, top_1: 0.710352, top_k: 0.882500, samples/s: 2232.076 1612434730.3585835
train: epoch 134, iter 3300, loss: 2.138122, top_1: 0.710938, top_k: 0.886094, samples/s: 2211.499 1612434741.934439
train: epoch 134, iter 3400, loss: 2.176632, top_1: 0.706992, top_k: 0.884141, samples/s: 2230.341 1612434753.4125068
train: epoch 134, iter 3500, loss: 2.186193, top_1: 0.706562, top_k: 0.883242, samples/s: 2200.423 1612434765.0466847
train: epoch 134, iter 3600, loss: 2.169700, top_1: 0.708125, top_k: 0.885352, samples/s: 2220.155 1612434776.5773869
train: epoch 134, iter 3700, loss: 2.351037, top_1: 0.705898, top_k: 0.883398, samples/s: 2226.050 1612434788.0775468
train: epoch 134, iter 3800, loss: 2.253490, top_1: 0.707500, top_k: 0.883867, samples/s: 2234.859 1612434799.532401
train: epoch 134, iter 3900, loss: 2.255784, top_1: 0.707773, top_k: 0.884844, samples/s: 2222.385 1612434811.0515919
train: epoch 134, iter 4000, loss: 2.182737, top_1: 0.708320, top_k: 0.886797, samples/s: 2208.583 1612434822.642701
train: epoch 134, iter 4100, loss: 2.073825, top_1: 0.702266, top_k: 0.882891, samples/s: 2228.021 1612434834.1327815
train: epoch 134, iter 4200, loss: 2.150068, top_1: 0.705273, top_k: 0.883945, samples/s: 2211.787 1612434845.7070842
train: epoch 134, iter 4300, loss: 2.150976, top_1: 0.707461, top_k: 0.883477, samples/s: 2214.914 1612434857.2654371
train: epoch 134, iter 4400, loss: 2.147297, top_1: 0.703789, top_k: 0.882891, samples/s: 2233.097 1612434868.7289908
train: epoch 134, iter 4500, loss: 2.209219, top_1: 0.711328, top_k: 0.886250, samples/s: 2225.478 1612434880.2326071
train: epoch 134, iter 4600, loss: 2.143158, top_1: 0.707305, top_k: 0.883672, samples/s: 2215.696 1612434891.7861094
train: epoch 134, iter 4700, loss: 2.233546, top_1: 0.707930, top_k: 0.885586, samples/s: 2211.233 1612434903.3633075
train: epoch 134, iter 4800, loss: 2.349483, top_1: 0.705820, top_k: 0.886367, samples/s: 2230.692 1612434914.8396268
train: epoch 134, iter 4900, loss: 2.256841, top_1: 0.710938, top_k: 0.884609, samples/s: 2230.694 1612434926.3158205
train: epoch 134, iter 5000, loss: 2.143827, top_1: 0.711719, top_k: 0.886797, samples/s: 2219.112 1612434937.8519936
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_134.
validation: epoch 134, iter 195, top_1: 0.724639, top_k: 0.908173, samples/s: 2909.665 1612434955.3467765
train: epoch 135, iter 100, loss: 2.270562, top_1: 0.718906, top_k: 0.889062, samples/s: 2237.640 1612434983.1014407
train: epoch 135, iter 200, loss: 2.126235, top_1: 0.719336, top_k: 0.892188, samples/s: 2213.934 1612434994.6645727
train: epoch 135, iter 300, loss: 2.208372, top_1: 0.714414, top_k: 0.892852, samples/s: 2245.976 1612435006.0629683
train: epoch 135, iter 400, loss: 2.133058, top_1: 0.714766, top_k: 0.888086, samples/s: 2228.361 1612435017.551019
train: epoch 135, iter 500, loss: 2.305192, top_1: 0.713711, top_k: 0.887070, samples/s: 2251.937 1612435028.9190226
train: epoch 135, iter 600, loss: 2.157471, top_1: 0.715313, top_k: 0.890352, samples/s: 2244.963 1612435040.322362
train: epoch 135, iter 700, loss: 2.217004, top_1: 0.712031, top_k: 0.888203, samples/s: 2262.820 1612435051.6356838
train: epoch 135, iter 800, loss: 2.165805, top_1: 0.713789, top_k: 0.888555, samples/s: 2235.586 1612435063.0867927
train: epoch 135, iter 900, loss: 2.137574, top_1: 0.717500, top_k: 0.889727, samples/s: 2242.208 1612435074.5040588
train: epoch 135, iter 1000, loss: 2.321399, top_1: 0.714375, top_k: 0.888555, samples/s: 2215.783 1612435086.0575376
train: epoch 135, iter 1100, loss: 2.089955, top_1: 0.716602, top_k: 0.892070, samples/s: 2244.613 1612435097.4627323
train: epoch 135, iter 1200, loss: 2.143560, top_1: 0.714805, top_k: 0.887656, samples/s: 2227.271 1612435108.9565053
train: epoch 135, iter 1300, loss: 2.367404, top_1: 0.708516, top_k: 0.887656, samples/s: 2198.831 1612435120.5991247
train: epoch 135, iter 1400, loss: 2.122740, top_1: 0.717383, top_k: 0.887930, samples/s: 2227.315 1612435132.0928204
train: epoch 135, iter 1500, loss: 2.250407, top_1: 0.714727, top_k: 0.886094, samples/s: 2185.767 1612435143.8048437
train: epoch 135, iter 1600, loss: 2.228712, top_1: 0.708398, top_k: 0.885586, samples/s: 2218.904 1612435155.342077
train: epoch 135, iter 1700, loss: 2.324241, top_1: 0.716797, top_k: 0.888672, samples/s: 2213.038 1612435166.9098988
train: epoch 135, iter 1800, loss: 2.107157, top_1: 0.716953, top_k: 0.889062, samples/s: 2206.466 1612435178.5121598
train: epoch 135, iter 1900, loss: 2.120810, top_1: 0.710352, top_k: 0.891211, samples/s: 2210.341 1612435190.0941246
train: epoch 135, iter 2000, loss: 2.254468, top_1: 0.709297, top_k: 0.883516, samples/s: 2214.808 1612435201.6527653
train: epoch 135, iter 2100, loss: 2.052479, top_1: 0.713242, top_k: 0.889336, samples/s: 2221.724 1612435213.1752722
train: epoch 135, iter 2200, loss: 2.405828, top_1: 0.712734, top_k: 0.886641, samples/s: 2208.266 1612435224.7681231
train: epoch 135, iter 2300, loss: 2.137358, top_1: 0.718008, top_k: 0.888516, samples/s: 2224.085 1612435236.2784858
train: epoch 135, iter 2400, loss: 2.260308, top_1: 0.712734, top_k: 0.886797, samples/s: 2226.595 1612435247.775807
train: epoch 135, iter 2500, loss: 2.119259, top_1: 0.710938, top_k: 0.884062, samples/s: 2226.162 1612435259.275426
train: epoch 135, iter 2600, loss: 2.301763, top_1: 0.708477, top_k: 0.884727, samples/s: 2226.064 1612435270.775479
train: epoch 135, iter 2700, loss: 2.244805, top_1: 0.703438, top_k: 0.882148, samples/s: 2232.936 1612435282.240239
train: epoch 135, iter 2800, loss: 2.226913, top_1: 0.712109, top_k: 0.885312, samples/s: 2211.650 1612435293.815475
train: epoch 135, iter 2900, loss: 2.111473, top_1: 0.709922, top_k: 0.888711, samples/s: 2213.055 1612435305.383061
train: epoch 135, iter 3000, loss: 2.109312, top_1: 0.712930, top_k: 0.884609, samples/s: 2203.323 1612435317.0018148
train: epoch 135, iter 3100, loss: 2.123326, top_1: 0.711523, top_k: 0.886406, samples/s: 2212.923 1612435328.5702205
train: epoch 135, iter 3200, loss: 2.288170, top_1: 0.709805, top_k: 0.885391, samples/s: 2245.138 1612435339.9726512
train: epoch 135, iter 3300, loss: 2.073903, top_1: 0.708086, top_k: 0.885430, samples/s: 2211.386 1612435351.5490751
train: epoch 135, iter 3400, loss: 2.197789, top_1: 0.711953, top_k: 0.885820, samples/s: 2225.788 1612435363.0506282
train: epoch 135, iter 3500, loss: 2.231223, top_1: 0.712031, top_k: 0.885898, samples/s: 2194.811 1612435374.7145474
train: epoch 135, iter 3600, loss: 2.358144, top_1: 0.709648, top_k: 0.884883, samples/s: 2237.767 1612435386.1544828
train: epoch 135, iter 3700, loss: 2.382624, top_1: 0.713594, top_k: 0.887070, samples/s: 2238.434 1612435397.5910873
train: epoch 135, iter 3800, loss: 2.098673, top_1: 0.702969, top_k: 0.880547, samples/s: 2231.601 1612435409.0626302
train: epoch 135, iter 3900, loss: 2.091145, top_1: 0.707500, top_k: 0.888047, samples/s: 2216.599 1612435420.611813
train: epoch 135, iter 4000, loss: 2.222378, top_1: 0.715703, top_k: 0.889336, samples/s: 2206.582 1612435432.2136154
train: epoch 135, iter 4100, loss: 2.252731, top_1: 0.714727, top_k: 0.886406, samples/s: 2228.550 1612435443.7009416
train: epoch 135, iter 4200, loss: 2.210976, top_1: 0.705625, top_k: 0.883008, samples/s: 2207.710 1612435455.2966096
train: epoch 135, iter 4300, loss: 2.106962, top_1: 0.712656, top_k: 0.887500, samples/s: 2236.714 1612435466.7419326
train: epoch 135, iter 4400, loss: 2.188675, top_1: 0.710430, top_k: 0.884375, samples/s: 2221.687 1612435478.2646608
train: epoch 135, iter 4500, loss: 2.292626, top_1: 0.712031, top_k: 0.886484, samples/s: 2230.831 1612435489.740208
train: epoch 135, iter 4600, loss: 2.104367, top_1: 0.707383, top_k: 0.886016, samples/s: 2239.604 1612435501.1708105
train: epoch 135, iter 4700, loss: 2.103431, top_1: 0.714492, top_k: 0.888164, samples/s: 2231.360 1612435512.6436238
train: epoch 135, iter 4800, loss: 2.399379, top_1: 0.711719, top_k: 0.886875, samples/s: 2212.448 1612435524.2145236
train: epoch 135, iter 4900, loss: 2.092299, top_1: 0.711953, top_k: 0.887656, samples/s: 2227.370 1612435535.7079597
train: epoch 135, iter 5000, loss: 2.175751, top_1: 0.724648, top_k: 0.891914, samples/s: 2222.414 1612435547.2269082
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_135.
validation: epoch 135, iter 195, top_1: 0.726963, top_k: 0.908894, samples/s: 2927.057 1612435564.5896327
train: epoch 136, iter 100, loss: 2.196408, top_1: 0.720898, top_k: 0.889375, samples/s: 2229.527 1612435591.9026358
train: epoch 136, iter 200, loss: 2.237398, top_1: 0.718672, top_k: 0.889297, samples/s: 2285.285 1612435603.104702
train: epoch 136, iter 300, loss: 2.216531, top_1: 0.718203, top_k: 0.890273, samples/s: 2252.558 1612435614.4695458
train: epoch 136, iter 400, loss: 2.265456, top_1: 0.715977, top_k: 0.886914, samples/s: 2228.960 1612435625.954825
train: epoch 136, iter 500, loss: 2.309951, top_1: 0.719531, top_k: 0.889687, samples/s: 2263.409 1612435637.2650986
train: epoch 136, iter 600, loss: 2.125345, top_1: 0.720078, top_k: 0.890625, samples/s: 2263.653 1612435648.5743191
train: epoch 136, iter 700, loss: 2.081556, top_1: 0.716836, top_k: 0.887461, samples/s: 2248.365 1612435659.9603071
train: epoch 136, iter 800, loss: 2.309016, top_1: 0.717539, top_k: 0.889023, samples/s: 2243.534 1612435671.3709364
train: epoch 136, iter 900, loss: 2.092974, top_1: 0.721836, top_k: 0.891992, samples/s: 2233.812 1612435682.8311586
train: epoch 136, iter 1000, loss: 2.203220, top_1: 0.715195, top_k: 0.890156, samples/s: 2199.785 1612435694.468601
train: epoch 136, iter 1100, loss: 2.161037, top_1: 0.713477, top_k: 0.888555, samples/s: 2219.719 1612435706.001617
train: epoch 136, iter 1200, loss: 2.100508, top_1: 0.712539, top_k: 0.886680, samples/s: 2217.072 1612435717.5484033
train: epoch 136, iter 1300, loss: 2.101676, top_1: 0.713164, top_k: 0.888594, samples/s: 2209.580 1612435729.1342769
train: epoch 136, iter 1400, loss: 2.012904, top_1: 0.717656, top_k: 0.888516, samples/s: 2206.073 1612435740.738605
train: epoch 136, iter 1500, loss: 2.384776, top_1: 0.712891, top_k: 0.886719, samples/s: 2234.246 1612435752.1965845
train: epoch 136, iter 1600, loss: 2.084327, top_1: 0.714531, top_k: 0.889570, samples/s: 2230.412 1612435763.6743002
train: epoch 136, iter 1700, loss: 2.265005, top_1: 0.712383, top_k: 0.885547, samples/s: 2206.464 1612435775.2767246
train: epoch 136, iter 1800, loss: 2.221193, top_1: 0.720781, top_k: 0.888984, samples/s: 2225.584 1612435786.779267
train: epoch 136, iter 1900, loss: 1.992440, top_1: 0.718672, top_k: 0.888672, samples/s: 2204.585 1612435798.391404
train: epoch 136, iter 2000, loss: 2.173102, top_1: 0.713672, top_k: 0.888086, samples/s: 2240.071 1612435809.8195965
train: epoch 136, iter 2100, loss: 2.212394, top_1: 0.709063, top_k: 0.886445, samples/s: 2230.197 1612435821.298403
train: epoch 136, iter 2200, loss: 2.219792, top_1: 0.718203, top_k: 0.890547, samples/s: 2212.114 1612435832.871045
train: epoch 136, iter 2300, loss: 2.172268, top_1: 0.716016, top_k: 0.886875, samples/s: 2234.616 1612435844.327257
train: epoch 136, iter 2400, loss: 2.192209, top_1: 0.715977, top_k: 0.887266, samples/s: 2224.748 1612435855.8340166
train: epoch 136, iter 2500, loss: 2.290414, top_1: 0.712891, top_k: 0.885977, samples/s: 2227.540 1612435867.3265207
train: epoch 136, iter 2600, loss: 2.198816, top_1: 0.711484, top_k: 0.889375, samples/s: 2216.348 1612435878.8771183
train: epoch 136, iter 2700, loss: 2.132818, top_1: 0.716914, top_k: 0.889023, samples/s: 2216.370 1612435890.4274902
train: epoch 136, iter 2800, loss: 2.281290, top_1: 0.713984, top_k: 0.888672, samples/s: 2222.185 1612435901.94772
train: epoch 136, iter 2900, loss: 2.381195, top_1: 0.713164, top_k: 0.885312, samples/s: 2234.431 1612435913.4051456
train: epoch 136, iter 3000, loss: 2.199269, top_1: 0.713984, top_k: 0.886523, samples/s: 2215.545 1612435924.9595597
train: epoch 136, iter 3100, loss: 2.174166, top_1: 0.713633, top_k: 0.886016, samples/s: 2227.299 1612435936.4535847
train: epoch 136, iter 3200, loss: 2.183773, top_1: 0.714805, top_k: 0.889062, samples/s: 2222.162 1612435947.9735224
train: epoch 136, iter 3300, loss: 2.113595, top_1: 0.713945, top_k: 0.887734, samples/s: 2212.138 1612435959.5460258
train: epoch 136, iter 3400, loss: 2.319322, top_1: 0.709023, top_k: 0.886016, samples/s: 2219.617 1612435971.0795293
train: epoch 136, iter 3500, loss: 2.234195, top_1: 0.709570, top_k: 0.886328, samples/s: 2247.700 1612435982.4690344
train: epoch 136, iter 3600, loss: 2.051029, top_1: 0.715391, top_k: 0.889297, samples/s: 2211.162 1612435994.0465856
train: epoch 136, iter 3700, loss: 2.352361, top_1: 0.716094, top_k: 0.887656, samples/s: 2208.113 1612436005.640262
train: epoch 136, iter 3800, loss: 2.199437, top_1: 0.713086, top_k: 0.886328, samples/s: 2229.713 1612436017.121483
train: epoch 136, iter 3900, loss: 2.221530, top_1: 0.712734, top_k: 0.888633, samples/s: 2222.193 1612436028.6418319
train: epoch 136, iter 4000, loss: 2.106679, top_1: 0.715195, top_k: 0.889219, samples/s: 2228.531 1612436040.129059
train: epoch 136, iter 4100, loss: 2.102332, top_1: 0.716172, top_k: 0.889180, samples/s: 2213.764 1612436051.6930633
train: epoch 136, iter 4200, loss: 2.208092, top_1: 0.719063, top_k: 0.890000, samples/s: 2226.022 1612436063.1934106
train: epoch 136, iter 4300, loss: 2.101880, top_1: 0.718945, top_k: 0.889727, samples/s: 2216.199 1612436074.7446947
train: epoch 136, iter 4400, loss: 2.267426, top_1: 0.713594, top_k: 0.885352, samples/s: 2220.191 1612436086.2753053
train: epoch 136, iter 4500, loss: 2.205358, top_1: 0.715430, top_k: 0.888945, samples/s: 2228.040 1612436097.7653353
train: epoch 136, iter 4600, loss: 2.181693, top_1: 0.715977, top_k: 0.888242, samples/s: 2210.159 1612436109.348096
train: epoch 136, iter 4700, loss: 2.217989, top_1: 0.713008, top_k: 0.888125, samples/s: 2223.437 1612436120.8617105
train: epoch 136, iter 4800, loss: 2.249017, top_1: 0.714336, top_k: 0.886758, samples/s: 2239.281 1612436132.2939887
train: epoch 136, iter 4900, loss: 2.347108, top_1: 0.714922, top_k: 0.887578, samples/s: 2223.028 1612436143.8098304
train: epoch 136, iter 5000, loss: 2.222605, top_1: 0.720156, top_k: 0.890195, samples/s: 2227.094 1612436155.3045886
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_136.
validation: epoch 136, iter 195, top_1: 0.728446, top_k: 0.909615, samples/s: 2928.957 1612436172.6721323
train: epoch 137, iter 100, loss: 2.168800, top_1: 0.723125, top_k: 0.891914, samples/s: 2232.610 1612436200.029466
train: epoch 137, iter 200, loss: 2.108788, top_1: 0.721367, top_k: 0.890781, samples/s: 2240.656 1612436211.4547517
train: epoch 137, iter 300, loss: 2.222669, top_1: 0.724297, top_k: 0.893047, samples/s: 2270.690 1612436222.7288094
train: epoch 137, iter 400, loss: 2.135668, top_1: 0.717422, top_k: 0.889180, samples/s: 2259.323 1612436234.0597177
train: epoch 137, iter 500, loss: 2.063327, top_1: 0.720273, top_k: 0.892695, samples/s: 2265.328 1612436245.360415
train: epoch 137, iter 600, loss: 2.024328, top_1: 0.721602, top_k: 0.891406, samples/s: 2257.300 1612436256.7014275
train: epoch 137, iter 700, loss: 2.138527, top_1: 0.721953, top_k: 0.891719, samples/s: 2240.354 1612436268.1282368
train: epoch 137, iter 800, loss: 2.126974, top_1: 0.719922, top_k: 0.889414, samples/s: 2252.962 1612436279.490991
train: epoch 137, iter 900, loss: 2.467729, top_1: 0.722187, top_k: 0.891289, samples/s: 2217.575 1612436291.0351183
train: epoch 137, iter 1000, loss: 2.228994, top_1: 0.718594, top_k: 0.889961, samples/s: 2214.574 1612436302.5949059
train: epoch 137, iter 1100, loss: 2.121017, top_1: 0.720273, top_k: 0.891289, samples/s: 2214.462 1612436314.155294
train: epoch 137, iter 1200, loss: 2.134131, top_1: 0.717539, top_k: 0.889492, samples/s: 2199.159 1612436325.7961063
train: epoch 137, iter 1300, loss: 2.407769, top_1: 0.718867, top_k: 0.892852, samples/s: 2226.510 1612436337.2939217
train: epoch 137, iter 1400, loss: 2.189189, top_1: 0.718828, top_k: 0.890430, samples/s: 2221.705 1612436348.8165803
train: epoch 137, iter 1500, loss: 2.379867, top_1: 0.717617, top_k: 0.891211, samples/s: 2232.996 1612436360.2809913
train: epoch 137, iter 1600, loss: 2.250410, top_1: 0.716484, top_k: 0.888398, samples/s: 2209.676 1612436371.8664925
train: epoch 137, iter 1700, loss: 2.240129, top_1: 0.724375, top_k: 0.893437, samples/s: 2224.832 1612436383.3728914
train: epoch 137, iter 1800, loss: 2.359422, top_1: 0.714727, top_k: 0.887227, samples/s: 2222.737 1612436394.890272
train: epoch 137, iter 1900, loss: 2.250954, top_1: 0.720195, top_k: 0.890508, samples/s: 2204.237 1612436406.5042715
train: epoch 137, iter 2000, loss: 2.345969, top_1: 0.720352, top_k: 0.892383, samples/s: 2199.082 1612436418.1454728
train: epoch 137, iter 2100, loss: 2.182520, top_1: 0.723672, top_k: 0.889453, samples/s: 2200.138 1612436429.7811315
train: epoch 137, iter 2200, loss: 2.144011, top_1: 0.718594, top_k: 0.892305, samples/s: 2217.464 1612436441.32581
train: epoch 137, iter 2300, loss: 2.304363, top_1: 0.717422, top_k: 0.890273, samples/s: 2224.121 1612436452.8360162
train: epoch 137, iter 2400, loss: 2.191034, top_1: 0.721836, top_k: 0.893867, samples/s: 2204.304 1612436464.449613
train: epoch 137, iter 2500, loss: 2.299474, top_1: 0.713750, top_k: 0.890039, samples/s: 2240.036 1612436475.8779936
train: epoch 137, iter 2600, loss: 2.208334, top_1: 0.720391, top_k: 0.888359, samples/s: 2208.521 1612436487.4695182
train: epoch 137, iter 2700, loss: 2.153222, top_1: 0.718359, top_k: 0.889375, samples/s: 2221.433 1612436498.9936564
train: epoch 137, iter 2800, loss: 2.140504, top_1: 0.720195, top_k: 0.891094, samples/s: 2212.758 1612436510.5628457
train: epoch 137, iter 2900, loss: 2.088943, top_1: 0.721250, top_k: 0.889844, samples/s: 2206.512 1612436522.1648922
train: epoch 137, iter 3000, loss: 2.117767, top_1: 0.719531, top_k: 0.890664, samples/s: 2217.751 1612436533.70809
train: epoch 137, iter 3100, loss: 2.101264, top_1: 0.718984, top_k: 0.892422, samples/s: 2232.927 1612436545.1728816
train: epoch 137, iter 3200, loss: 2.147696, top_1: 0.716914, top_k: 0.887305, samples/s: 2198.032 1612436556.819656
train: epoch 137, iter 3300, loss: 2.204194, top_1: 0.720000, top_k: 0.892734, samples/s: 2233.032 1612436568.2838674
train: epoch 137, iter 3400, loss: 2.175139, top_1: 0.720469, top_k: 0.891211, samples/s: 2220.318 1612436579.8137195
train: epoch 137, iter 3500, loss: 2.181522, top_1: 0.719453, top_k: 0.893281, samples/s: 2234.438 1612436591.270757
train: epoch 137, iter 3600, loss: 2.350222, top_1: 0.717109, top_k: 0.891523, samples/s: 2216.668 1612436602.8196647
train: epoch 137, iter 3700, loss: 2.238405, top_1: 0.714766, top_k: 0.889258, samples/s: 2186.225 1612436614.5293717
train: epoch 137, iter 3800, loss: 2.249804, top_1: 0.716250, top_k: 0.887266, samples/s: 2208.941 1612436626.118573
train: epoch 137, iter 3900, loss: 2.370139, top_1: 0.717031, top_k: 0.890781, samples/s: 2247.729 1612436637.5078409
train: epoch 137, iter 4000, loss: 2.040434, top_1: 0.719375, top_k: 0.891211, samples/s: 2219.028 1612436649.0444157
train: epoch 137, iter 4100, loss: 2.169380, top_1: 0.719258, top_k: 0.888477, samples/s: 2227.977 1612436660.534666
train: epoch 137, iter 4200, loss: 2.260073, top_1: 0.715313, top_k: 0.887344, samples/s: 2226.688 1612436672.031564
train: epoch 137, iter 4300, loss: 2.170301, top_1: 0.717539, top_k: 0.888398, samples/s: 2214.546 1612436683.5915492
train: epoch 137, iter 4400, loss: 2.281677, top_1: 0.722266, top_k: 0.890742, samples/s: 2208.777 1612436695.1816137
train: epoch 137, iter 4500, loss: 2.198497, top_1: 0.716992, top_k: 0.889883, samples/s: 2230.426 1612436706.6592615
train: epoch 137, iter 4600, loss: 2.175364, top_1: 0.714336, top_k: 0.884727, samples/s: 2229.496 1612436718.1416712
train: epoch 137, iter 4700, loss: 2.187372, top_1: 0.718672, top_k: 0.888164, samples/s: 2216.986 1612436729.6888785
train: epoch 137, iter 4800, loss: 2.095357, top_1: 0.714258, top_k: 0.888125, samples/s: 2218.110 1612436741.230234
train: epoch 137, iter 4900, loss: 2.242198, top_1: 0.715859, top_k: 0.891602, samples/s: 2222.102 1612436752.7508442
train: epoch 137, iter 5000, loss: 2.102293, top_1: 0.724531, top_k: 0.896445, samples/s: 2192.482 1612436764.42712
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_137.
validation: epoch 137, iter 195, top_1: 0.731751, top_k: 0.911258, samples/s: 2867.187 1612436782.1808343
train: epoch 138, iter 100, loss: 2.428491, top_1: 0.727500, top_k: 0.895195, samples/s: 2209.482 1612436809.5485241
train: epoch 138, iter 200, loss: 2.072199, top_1: 0.726211, top_k: 0.892891, samples/s: 2247.026 1612436820.9412892
train: epoch 138, iter 300, loss: 2.147783, top_1: 0.720313, top_k: 0.891992, samples/s: 2261.414 1612436832.261726
train: epoch 138, iter 400, loss: 2.179720, top_1: 0.722852, top_k: 0.891836, samples/s: 2235.507 1612436843.713202
train: epoch 138, iter 500, loss: 1.994640, top_1: 0.726094, top_k: 0.892578, samples/s: 2255.952 1612436855.0609336
train: epoch 138, iter 600, loss: 2.224833, top_1: 0.722148, top_k: 0.892148, samples/s: 2254.661 1612436866.41526
train: epoch 138, iter 700, loss: 2.072955, top_1: 0.722734, top_k: 0.891367, samples/s: 2259.385 1612436877.7457273
train: epoch 138, iter 800, loss: 2.161416, top_1: 0.722305, top_k: 0.893047, samples/s: 2247.750 1612436889.1349316
train: epoch 138, iter 900, loss: 2.190593, top_1: 0.720469, top_k: 0.892383, samples/s: 2215.303 1612436900.690849
train: epoch 138, iter 1000, loss: 2.091809, top_1: 0.725000, top_k: 0.895508, samples/s: 2241.391 1612436912.1123755
train: epoch 138, iter 1100, loss: 2.180215, top_1: 0.724219, top_k: 0.890938, samples/s: 2211.250 1612436923.6895058
train: epoch 138, iter 1200, loss: 2.077624, top_1: 0.718984, top_k: 0.892266, samples/s: 2227.956 1612436935.179974
train: epoch 138, iter 1300, loss: 2.238064, top_1: 0.727422, top_k: 0.895703, samples/s: 2232.642 1612436946.6461818
train: epoch 138, iter 1400, loss: 2.071221, top_1: 0.719883, top_k: 0.890664, samples/s: 2215.808 1612436958.199424
train: epoch 138, iter 1500, loss: 2.153916, top_1: 0.724922, top_k: 0.892422, samples/s: 2235.332 1612436969.651866
train: epoch 138, iter 1600, loss: 2.270114, top_1: 0.724609, top_k: 0.891875, samples/s: 2222.056 1612436981.1727324
train: epoch 138, iter 1700, loss: 2.209805, top_1: 0.726250, top_k: 0.895625, samples/s: 2215.090 1612436992.729836
train: epoch 138, iter 1800, loss: 2.119762, top_1: 0.726445, top_k: 0.893242, samples/s: 2219.089 1612437004.2661052
train: epoch 138, iter 1900, loss: 2.185912, top_1: 0.722344, top_k: 0.894375, samples/s: 2212.171 1612437015.838432
train: epoch 138, iter 2000, loss: 2.234220, top_1: 0.721328, top_k: 0.892109, samples/s: 2206.670 1612437027.4396768
train: epoch 138, iter 2100, loss: 2.184375, top_1: 0.721875, top_k: 0.889609, samples/s: 2207.525 1612437039.0363445
train: epoch 138, iter 2200, loss: 2.040807, top_1: 0.726875, top_k: 0.892383, samples/s: 2247.740 1612437050.4255927
train: epoch 138, iter 2300, loss: 2.266652, top_1: 0.717227, top_k: 0.890781, samples/s: 2219.684 1612437061.9587045
train: epoch 138, iter 2400, loss: 2.130111, top_1: 0.721094, top_k: 0.893750, samples/s: 2228.068 1612437073.4485846
train: epoch 138, iter 2500, loss: 2.086148, top_1: 0.719609, top_k: 0.891055, samples/s: 2202.436 1612437085.0722976
train: epoch 138, iter 2600, loss: 2.227337, top_1: 0.718125, top_k: 0.891289, samples/s: 2216.423 1612437096.6221426
train: epoch 138, iter 2700, loss: 2.270725, top_1: 0.719961, top_k: 0.892109, samples/s: 2215.178 1612437108.1794555
train: epoch 138, iter 2800, loss: 2.128097, top_1: 0.720547, top_k: 0.891758, samples/s: 2232.109 1612437119.6477666
train: epoch 138, iter 2900, loss: 2.357724, top_1: 0.722734, top_k: 0.892891, samples/s: 2221.102 1612437131.1735156
train: epoch 138, iter 3000, loss: 2.243062, top_1: 0.715742, top_k: 0.889297, samples/s: 2228.523 1612437142.6610072
train: epoch 138, iter 3100, loss: 2.317410, top_1: 0.720742, top_k: 0.893008, samples/s: 2228.398 1612437154.149083
train: epoch 138, iter 3200, loss: 2.137668, top_1: 0.719961, top_k: 0.889648, samples/s: 2224.388 1612437165.6578467
train: epoch 138, iter 3300, loss: 2.101405, top_1: 0.717812, top_k: 0.891172, samples/s: 2220.647 1612437177.186002
train: epoch 138, iter 3400, loss: 2.260454, top_1: 0.717773, top_k: 0.890938, samples/s: 2218.812 1612437188.72373
train: epoch 138, iter 3500, loss: 2.097260, top_1: 0.726484, top_k: 0.892031, samples/s: 2230.546 1612437200.2007208
train: epoch 138, iter 3600, loss: 2.261608, top_1: 0.721172, top_k: 0.892305, samples/s: 2226.131 1612437211.7004776
train: epoch 138, iter 3700, loss: 2.186357, top_1: 0.724688, top_k: 0.891953, samples/s: 2207.272 1612437223.2986605
train: epoch 138, iter 3800, loss: 2.109618, top_1: 0.725820, top_k: 0.892578, samples/s: 2194.740 1612437234.963252
train: epoch 138, iter 3900, loss: 2.089228, top_1: 0.721680, top_k: 0.889102, samples/s: 2208.396 1612437246.5548937
train: epoch 138, iter 4000, loss: 2.231836, top_1: 0.726094, top_k: 0.893633, samples/s: 2221.666 1612437258.0781279
train: epoch 138, iter 4100, loss: 2.109234, top_1: 0.722891, top_k: 0.897344, samples/s: 2214.031 1612437269.6404092
train: epoch 138, iter 4200, loss: 2.187001, top_1: 0.719609, top_k: 0.892383, samples/s: 2214.704 1612437281.1995022
train: epoch 138, iter 4300, loss: 2.111461, top_1: 0.719023, top_k: 0.889258, samples/s: 2227.377 1612437292.6928444
train: epoch 138, iter 4400, loss: 2.251917, top_1: 0.721719, top_k: 0.895508, samples/s: 2213.572 1612437304.2579293
train: epoch 138, iter 4500, loss: 2.059274, top_1: 0.722266, top_k: 0.890625, samples/s: 2216.210 1612437315.8095233
train: epoch 138, iter 4600, loss: 2.081554, top_1: 0.719219, top_k: 0.890078, samples/s: 2226.777 1612437327.305554
train: epoch 138, iter 4700, loss: 2.132423, top_1: 0.721602, top_k: 0.894062, samples/s: 2224.699 1612437338.8131602
train: epoch 138, iter 4800, loss: 2.144783, top_1: 0.719570, top_k: 0.887578, samples/s: 2231.421 1612437350.2853312
train: epoch 138, iter 4900, loss: 2.246495, top_1: 0.716328, top_k: 0.888477, samples/s: 2227.408 1612437361.778445
train: epoch 138, iter 5000, loss: 2.040013, top_1: 0.727187, top_k: 0.895703, samples/s: 2228.387 1612437373.2665467
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_138.
validation: epoch 138, iter 195, top_1: 0.732853, top_k: 0.911579, samples/s: 2955.139 1612437390.5035284
train: epoch 139, iter 100, loss: 2.112586, top_1: 0.731055, top_k: 0.899141, samples/s: 2244.438 1612437417.999252
train: epoch 139, iter 200, loss: 2.217710, top_1: 0.727148, top_k: 0.896719, samples/s: 2252.331 1612437429.3652325
train: epoch 139, iter 300, loss: 2.222625, top_1: 0.723516, top_k: 0.894609, samples/s: 2253.454 1612437440.725496
train: epoch 139, iter 400, loss: 2.308641, top_1: 0.726523, top_k: 0.895000, samples/s: 2264.379 1612437452.031022
train: epoch 139, iter 500, loss: 2.098478, top_1: 0.724961, top_k: 0.890938, samples/s: 2254.846 1612437463.384372
train: epoch 139, iter 600, loss: 2.151427, top_1: 0.721211, top_k: 0.894258, samples/s: 2237.759 1612437474.8243616
train: epoch 139, iter 700, loss: 2.138502, top_1: 0.727852, top_k: 0.893789, samples/s: 2243.955 1612437486.2327943
train: epoch 139, iter 800, loss: 2.133977, top_1: 0.724648, top_k: 0.892734, samples/s: 2247.397 1612437497.623808
train: epoch 139, iter 900, loss: 2.225225, top_1: 0.726484, top_k: 0.894219, samples/s: 2220.600 1612437509.152188
train: epoch 139, iter 1000, loss: 2.137939, top_1: 0.727695, top_k: 0.894492, samples/s: 2249.199 1612437520.5343444
train: epoch 139, iter 1100, loss: 2.196171, top_1: 0.723203, top_k: 0.891719, samples/s: 2217.814 1612437532.0769439
train: epoch 139, iter 1200, loss: 2.160547, top_1: 0.724219, top_k: 0.894805, samples/s: 2227.500 1612437543.5699394
train: epoch 139, iter 1300, loss: 2.241348, top_1: 0.726367, top_k: 0.893945, samples/s: 2227.455 1612437555.0628152
train: epoch 139, iter 1400, loss: 2.050918, top_1: 0.719844, top_k: 0.891641, samples/s: 2217.505 1612437566.6070378
train: epoch 139, iter 1500, loss: 1.957394, top_1: 0.723477, top_k: 0.892031, samples/s: 2226.945 1612437578.1026602
train: epoch 139, iter 1600, loss: 2.294776, top_1: 0.724727, top_k: 0.893320, samples/s: 2205.232 1612437589.7114222
train: epoch 139, iter 1700, loss: 2.098407, top_1: 0.723984, top_k: 0.894023, samples/s: 2218.667 1612437601.2498348
train: epoch 139, iter 1800, loss: 2.261263, top_1: 0.725000, top_k: 0.892852, samples/s: 2217.673 1612437612.7934778
train: epoch 139, iter 1900, loss: 2.222356, top_1: 0.727891, top_k: 0.893164, samples/s: 2223.884 1612437624.3048997
train: epoch 139, iter 2000, loss: 2.197283, top_1: 0.723437, top_k: 0.891523, samples/s: 2219.436 1612437635.839312
train: epoch 139, iter 2100, loss: 2.321142, top_1: 0.716602, top_k: 0.888477, samples/s: 2224.708 1612437647.346562
train: epoch 139, iter 2200, loss: 2.104815, top_1: 0.724023, top_k: 0.893359, samples/s: 2229.878 1612437658.8269188
train: epoch 139, iter 2300, loss: 2.018440, top_1: 0.723437, top_k: 0.892070, samples/s: 2204.870 1612437670.4375494
train: epoch 139, iter 2400, loss: 2.042688, top_1: 0.727383, top_k: 0.894414, samples/s: 2224.827 1612437681.944182
train: epoch 139, iter 2500, loss: 2.243768, top_1: 0.729414, top_k: 0.894102, samples/s: 2211.838 1612437693.518211
train: epoch 139, iter 2600, loss: 2.197709, top_1: 0.719336, top_k: 0.891016, samples/s: 2238.376 1612437704.9550583
train: epoch 139, iter 2700, loss: 2.143949, top_1: 0.721172, top_k: 0.890078, samples/s: 2215.941 1612437716.5077171
train: epoch 139, iter 2800, loss: 2.194887, top_1: 0.726953, top_k: 0.893906, samples/s: 2223.502 1612437728.0210543
train: epoch 139, iter 2900, loss: 2.190861, top_1: 0.728906, top_k: 0.895703, samples/s: 2205.987 1612437739.6258495
train: epoch 139, iter 3000, loss: 2.108811, top_1: 0.721055, top_k: 0.891172, samples/s: 2210.961 1612437751.2045496
train: epoch 139, iter 3100, loss: 2.106929, top_1: 0.726523, top_k: 0.895156, samples/s: 2229.411 1612437762.687356
train: epoch 139, iter 3200, loss: 2.073427, top_1: 0.724883, top_k: 0.893164, samples/s: 2218.007 1612437774.2295368
train: epoch 139, iter 3300, loss: 2.210764, top_1: 0.725781, top_k: 0.893828, samples/s: 2237.264 1612437785.6717978
train: epoch 139, iter 3400, loss: 2.103886, top_1: 0.724727, top_k: 0.896211, samples/s: 2217.182 1612437797.2180068
train: epoch 139, iter 3500, loss: 2.108986, top_1: 0.719844, top_k: 0.890625, samples/s: 2242.763 1612437808.6324449
train: epoch 139, iter 3600, loss: 2.170999, top_1: 0.724063, top_k: 0.891836, samples/s: 2212.169 1612437820.2048318
train: epoch 139, iter 3700, loss: 2.013143, top_1: 0.725352, top_k: 0.892188, samples/s: 2207.879 1612437831.7996821
train: epoch 139, iter 3800, loss: 2.191324, top_1: 0.722305, top_k: 0.892852, samples/s: 2239.841 1612437843.229083
train: epoch 139, iter 3900, loss: 2.108925, top_1: 0.724102, top_k: 0.895391, samples/s: 2241.479 1612437854.6500998
train: epoch 139, iter 4000, loss: 2.146636, top_1: 0.728164, top_k: 0.900078, samples/s: 2211.137 1612437866.2278974
train: epoch 139, iter 4100, loss: 2.206325, top_1: 0.728516, top_k: 0.892578, samples/s: 2224.363 1612437877.736805
train: epoch 139, iter 4200, loss: 2.068702, top_1: 0.721484, top_k: 0.894141, samples/s: 2196.846 1612437889.3898935
train: epoch 139, iter 4300, loss: 2.216409, top_1: 0.720273, top_k: 0.889609, samples/s: 2216.521 1612437900.939439
train: epoch 139, iter 4400, loss: 2.178166, top_1: 0.723437, top_k: 0.893164, samples/s: 2245.070 1612437912.3422182
train: epoch 139, iter 4500, loss: 2.088906, top_1: 0.726484, top_k: 0.895195, samples/s: 2231.205 1612437923.8158853
train: epoch 139, iter 4600, loss: 2.176626, top_1: 0.725547, top_k: 0.893555, samples/s: 2215.293 1612437935.3718567
train: epoch 139, iter 4700, loss: 2.099857, top_1: 0.722305, top_k: 0.892734, samples/s: 2208.131 1612437946.9660263
train: epoch 139, iter 4800, loss: 2.151421, top_1: 0.722695, top_k: 0.892734, samples/s: 2235.202 1612437958.4184887
train: epoch 139, iter 4900, loss: 2.109193, top_1: 0.732578, top_k: 0.895859, samples/s: 2226.387 1612437969.9169679
train: epoch 139, iter 5000, loss: 2.061573, top_1: 0.729727, top_k: 0.895312, samples/s: 2221.353 1612437981.4414604
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_139.
validation: epoch 139, iter 195, top_1: 0.733253, top_k: 0.912440, samples/s: 2966.180 1612437998.6264586
train: epoch 140, iter 100, loss: 2.059846, top_1: 0.729727, top_k: 0.896445, samples/s: 2238.184 1612438027.0438445
train: epoch 140, iter 200, loss: 2.150571, top_1: 0.732930, top_k: 0.899922, samples/s: 2255.614 1612438038.393025
train: epoch 140, iter 300, loss: 2.028469, top_1: 0.723906, top_k: 0.892930, samples/s: 2234.283 1612438049.850923
train: epoch 140, iter 400, loss: 2.232876, top_1: 0.731328, top_k: 0.898555, samples/s: 2273.380 1612438061.1117737
train: epoch 140, iter 500, loss: 2.085938, top_1: 0.728164, top_k: 0.894531, samples/s: 2249.087 1612438072.4939806
train: epoch 140, iter 600, loss: 2.157434, top_1: 0.728867, top_k: 0.897578, samples/s: 2241.108 1612438083.916892
train: epoch 140, iter 700, loss: 2.259811, top_1: 0.734062, top_k: 0.899961, samples/s: 2249.848 1612438095.2954447
train: epoch 140, iter 800, loss: 2.008569, top_1: 0.729141, top_k: 0.895664, samples/s: 2245.084 1612438106.698131
train: epoch 140, iter 900, loss: 2.247669, top_1: 0.728203, top_k: 0.892578, samples/s: 2241.073 1612438118.1212516
train: epoch 140, iter 1000, loss: 2.031933, top_1: 0.726641, top_k: 0.894805, samples/s: 2229.023 1612438129.606097
train: epoch 140, iter 1100, loss: 2.264628, top_1: 0.721914, top_k: 0.889492, samples/s: 2219.270 1612438141.1414118
train: epoch 140, iter 1200, loss: 1.994473, top_1: 0.730117, top_k: 0.895977, samples/s: 2222.256 1612438152.661247
train: epoch 140, iter 1300, loss: 2.111532, top_1: 0.732422, top_k: 0.896523, samples/s: 2217.163 1612438164.207554
train: epoch 140, iter 1400, loss: 2.133591, top_1: 0.729414, top_k: 0.897305, samples/s: 2217.408 1612438175.7525563
train: epoch 140, iter 1500, loss: 1.971075, top_1: 0.729922, top_k: 0.893711, samples/s: 2253.161 1612438187.114418
train: epoch 140, iter 1600, loss: 2.079235, top_1: 0.727070, top_k: 0.895312, samples/s: 2218.995 1612438198.6511178
train: epoch 140, iter 1700, loss: 2.271716, top_1: 0.726953, top_k: 0.896797, samples/s: 2221.919 1612438210.172783
train: epoch 140, iter 1800, loss: 2.046291, top_1: 0.726914, top_k: 0.895352, samples/s: 2225.607 1612438221.675245
train: epoch 140, iter 1900, loss: 2.146176, top_1: 0.725352, top_k: 0.893437, samples/s: 2232.986 1612438233.1396246
train: epoch 140, iter 2000, loss: 2.177955, top_1: 0.728437, top_k: 0.898750, samples/s: 2221.221 1612438244.6651633
train: epoch 140, iter 2100, loss: 2.116604, top_1: 0.730078, top_k: 0.897344, samples/s: 2213.410 1612438256.2306993
train: epoch 140, iter 2200, loss: 2.186893, top_1: 0.729805, top_k: 0.897461, samples/s: 2231.246 1612438267.7040553
train: epoch 140, iter 2300, loss: 2.205306, top_1: 0.722734, top_k: 0.892930, samples/s: 2161.558 1612438279.547733
train: epoch 140, iter 2400, loss: 2.243290, top_1: 0.725625, top_k: 0.895938, samples/s: 2223.953 1612438291.0584936
train: epoch 140, iter 2500, loss: 2.131199, top_1: 0.724063, top_k: 0.893125, samples/s: 2227.920 1612438302.5492694
train: epoch 140, iter 2600, loss: 2.088136, top_1: 0.730156, top_k: 0.897383, samples/s: 2211.197 1612438314.1263802
train: epoch 140, iter 2700, loss: 2.305794, top_1: 0.731836, top_k: 0.895000, samples/s: 2213.661 1612438325.6909847
train: epoch 140, iter 2800, loss: 2.134352, top_1: 0.727109, top_k: 0.894297, samples/s: 2230.109 1612438337.1707
train: epoch 140, iter 2900, loss: 2.383972, top_1: 0.725664, top_k: 0.893359, samples/s: 2246.059 1612438348.5680182
train: epoch 140, iter 3000, loss: 2.147095, top_1: 0.721758, top_k: 0.893828, samples/s: 2235.145 1612438360.021414
train: epoch 140, iter 3100, loss: 2.146771, top_1: 0.724727, top_k: 0.892422, samples/s: 2232.544 1612438371.4881318
train: epoch 140, iter 3200, loss: 2.190869, top_1: 0.726289, top_k: 0.895352, samples/s: 2181.843 1612438383.2213204
train: epoch 140, iter 3300, loss: 2.077208, top_1: 0.727773, top_k: 0.890234, samples/s: 2231.842 1612438394.6917005
train: epoch 140, iter 3400, loss: 2.206880, top_1: 0.727500, top_k: 0.894453, samples/s: 2217.707 1612438406.2354772
train: epoch 140, iter 3500, loss: 2.021604, top_1: 0.724531, top_k: 0.893164, samples/s: 2220.760 1612438417.7627003
train: epoch 140, iter 3600, loss: 2.035054, top_1: 0.724336, top_k: 0.896055, samples/s: 2216.677 1612438429.3115072
train: epoch 140, iter 3700, loss: 2.373898, top_1: 0.725313, top_k: 0.893516, samples/s: 2228.569 1612438440.7987146
train: epoch 140, iter 3800, loss: 2.099086, top_1: 0.726992, top_k: 0.892266, samples/s: 2198.677 1612438452.4421074
train: epoch 140, iter 3900, loss: 2.059422, top_1: 0.728125, top_k: 0.894883, samples/s: 2199.694 1612438464.0801055
train: epoch 140, iter 4000, loss: 2.097263, top_1: 0.730742, top_k: 0.893477, samples/s: 2243.565 1612438475.4904728
train: epoch 140, iter 4100, loss: 2.126284, top_1: 0.731563, top_k: 0.896133, samples/s: 2219.632 1612438487.0239167
train: epoch 140, iter 4200, loss: 2.082835, top_1: 0.726836, top_k: 0.894297, samples/s: 2228.696 1612438498.5104663
train: epoch 140, iter 4300, loss: 2.125227, top_1: 0.723086, top_k: 0.893008, samples/s: 2213.601 1612438510.0756774
train: epoch 140, iter 4400, loss: 2.250711, top_1: 0.727461, top_k: 0.897930, samples/s: 2228.849 1612438521.561063
train: epoch 140, iter 4500, loss: 2.282947, top_1: 0.726797, top_k: 0.895117, samples/s: 2245.199 1612438532.9632323
train: epoch 140, iter 4600, loss: 2.395230, top_1: 0.724766, top_k: 0.891797, samples/s: 2205.445 1612438544.5707998
train: epoch 140, iter 4700, loss: 2.103478, top_1: 0.730508, top_k: 0.894141, samples/s: 2230.653 1612438556.047257
train: epoch 140, iter 4800, loss: 2.239383, top_1: 0.730156, top_k: 0.894727, samples/s: 2228.512 1612438567.5347872
train: epoch 140, iter 4900, loss: 2.129375, top_1: 0.730703, top_k: 0.895078, samples/s: 2212.307 1612438579.1064065
train: epoch 140, iter 5000, loss: 2.073889, top_1: 0.730547, top_k: 0.896992, samples/s: 2229.232 1612438590.5902183
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_140.
validation: epoch 140, iter 195, top_1: 0.736659, top_k: 0.914543, samples/s: 2985.974 1612438607.686782
train: epoch 141, iter 100, loss: 2.112799, top_1: 0.737695, top_k: 0.898984, samples/s: 2234.149 1612438641.8627436
train: epoch 141, iter 200, loss: 2.186273, top_1: 0.737109, top_k: 0.899414, samples/s: 2247.544 1612438653.2528422
train: epoch 141, iter 300, loss: 2.234936, top_1: 0.730898, top_k: 0.896055, samples/s: 2247.820 1612438664.6417155
train: epoch 141, iter 400, loss: 2.094171, top_1: 0.731602, top_k: 0.898789, samples/s: 2237.733 1612438676.0818875
train: epoch 141, iter 500, loss: 1.952592, top_1: 0.731133, top_k: 0.899805, samples/s: 2261.981 1612438687.3993173
train: epoch 141, iter 600, loss: 2.066168, top_1: 0.740039, top_k: 0.903008, samples/s: 2248.188 1612438698.7864301
train: epoch 141, iter 700, loss: 2.129861, top_1: 0.731680, top_k: 0.895352, samples/s: 2255.736 1612438710.1351087
train: epoch 141, iter 800, loss: 2.187909, top_1: 0.730078, top_k: 0.896484, samples/s: 2225.185 1612438721.6397712
train: epoch 141, iter 900, loss: 2.175075, top_1: 0.723906, top_k: 0.895273, samples/s: 2250.824 1612438733.0133798
train: epoch 141, iter 1000, loss: 2.180340, top_1: 0.734727, top_k: 0.898672, samples/s: 2212.653 1612438744.5832148
train: epoch 141, iter 1100, loss: 2.096251, top_1: 0.730508, top_k: 0.895430, samples/s: 2214.438 1612438756.1437523
train: epoch 141, iter 1200, loss: 2.181498, top_1: 0.731563, top_k: 0.895977, samples/s: 2227.129 1612438767.6383626
train: epoch 141, iter 1300, loss: 2.298150, top_1: 0.729453, top_k: 0.893242, samples/s: 2236.065 1612438779.086992
train: epoch 141, iter 1400, loss: 2.247041, top_1: 0.732500, top_k: 0.898438, samples/s: 2213.699 1612438790.6517737
train: epoch 141, iter 1500, loss: 2.141121, top_1: 0.731875, top_k: 0.896641, samples/s: 2228.738 1612438802.1376896
train: epoch 141, iter 1600, loss: 2.144447, top_1: 0.729219, top_k: 0.895508, samples/s: 2212.445 1612438813.708621
train: epoch 141, iter 1700, loss: 2.181057, top_1: 0.737500, top_k: 0.900469, samples/s: 2216.835 1612438825.2573404
train: epoch 141, iter 1800, loss: 2.131932, top_1: 0.731211, top_k: 0.897539, samples/s: 2235.558 1612438836.7079368
train: epoch 141, iter 1900, loss: 2.111845, top_1: 0.735156, top_k: 0.899844, samples/s: 2219.372 1612438848.2427042
train: epoch 141, iter 2000, loss: 2.213333, top_1: 0.734219, top_k: 0.898008, samples/s: 2217.278 1612438859.7883465
train: epoch 141, iter 2100, loss: 2.118231, top_1: 0.731172, top_k: 0.895703, samples/s: 2223.351 1612438871.3025763
train: epoch 141, iter 2200, loss: 2.092907, top_1: 0.729180, top_k: 0.897383, samples/s: 2225.021 1612438882.8083127
train: epoch 141, iter 2300, loss: 2.117115, top_1: 0.731680, top_k: 0.897461, samples/s: 2237.152 1612438894.2512062
train: epoch 141, iter 2400, loss: 2.080393, top_1: 0.734961, top_k: 0.900547, samples/s: 2231.622 1612438905.7231119
train: epoch 141, iter 2500, loss: 2.111457, top_1: 0.731406, top_k: 0.896445, samples/s: 2223.042 1612438917.2384334
train: epoch 141, iter 2600, loss: 2.238060, top_1: 0.730703, top_k: 0.895312, samples/s: 2229.402 1612438928.7213478
train: epoch 141, iter 2700, loss: 2.102036, top_1: 0.737500, top_k: 0.900547, samples/s: 2228.979 1612438940.206406
train: epoch 141, iter 2800, loss: 2.090189, top_1: 0.728320, top_k: 0.896797, samples/s: 2207.509 1612438951.80311
train: epoch 141, iter 2900, loss: 2.084906, top_1: 0.724766, top_k: 0.893711, samples/s: 2229.155 1612438963.2872906
train: epoch 141, iter 3000, loss: 2.191033, top_1: 0.730000, top_k: 0.894805, samples/s: 2224.259 1612438974.7972267
train: epoch 141, iter 3100, loss: 2.124776, top_1: 0.730820, top_k: 0.897031, samples/s: 2233.503 1612438986.2585788
train: epoch 141, iter 3200, loss: 2.095655, top_1: 0.731797, top_k: 0.897813, samples/s: 2224.063 1612438997.7690077
train: epoch 141, iter 3300, loss: 2.110974, top_1: 0.731211, top_k: 0.897305, samples/s: 2232.965 1612439009.23362
train: epoch 141, iter 3400, loss: 2.131236, top_1: 0.726914, top_k: 0.896406, samples/s: 2216.744 1612439020.7820845
train: epoch 141, iter 3500, loss: 2.106306, top_1: 0.726484, top_k: 0.896055, samples/s: 2216.352 1612439032.3325617
train: epoch 141, iter 3600, loss: 2.194294, top_1: 0.732461, top_k: 0.899297, samples/s: 2229.867 1612439043.8130665
train: epoch 141, iter 3700, loss: 2.113458, top_1: 0.727773, top_k: 0.892891, samples/s: 2223.112 1612439055.3285291
train: epoch 141, iter 3800, loss: 2.019423, top_1: 0.730313, top_k: 0.898398, samples/s: 2237.934 1612439066.7675824
train: epoch 141, iter 3900, loss: 2.142116, top_1: 0.727969, top_k: 0.893398, samples/s: 2244.045 1612439078.17556
train: epoch 141, iter 4000, loss: 2.137325, top_1: 0.731484, top_k: 0.894805, samples/s: 2236.659 1612439089.6212554
train: epoch 141, iter 4100, loss: 2.233993, top_1: 0.725078, top_k: 0.893477, samples/s: 2237.304 1612439101.0635316
train: epoch 141, iter 4200, loss: 2.242617, top_1: 0.734180, top_k: 0.899687, samples/s: 2234.141 1612439112.5220783
train: epoch 141, iter 4300, loss: 2.275137, top_1: 0.734258, top_k: 0.892813, samples/s: 2214.932 1612439124.0800865
train: epoch 141, iter 4400, loss: 2.072570, top_1: 0.730234, top_k: 0.896836, samples/s: 2248.517 1612439135.4653368
train: epoch 141, iter 4500, loss: 2.172746, top_1: 0.730977, top_k: 0.896992, samples/s: 2219.257 1612439147.000667
train: epoch 141, iter 4600, loss: 2.167552, top_1: 0.727344, top_k: 0.897070, samples/s: 2237.499 1612439158.4420552
train: epoch 141, iter 4700, loss: 2.098697, top_1: 0.731445, top_k: 0.898789, samples/s: 2241.531 1612439169.8627748
train: epoch 141, iter 4800, loss: 2.198876, top_1: 0.730938, top_k: 0.899062, samples/s: 2223.946 1612439181.3738706
train: epoch 141, iter 4900, loss: 2.059647, top_1: 0.730391, top_k: 0.898242, samples/s: 2263.444 1612439192.6840408
train: epoch 141, iter 5000, loss: 2.176519, top_1: 0.732031, top_k: 0.896445, samples/s: 2240.736 1612439204.108854
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_141.
validation: epoch 141, iter 195, top_1: 0.737079, top_k: 0.915445, samples/s: 2949.097 1612439221.4196377
train: epoch 142, iter 100, loss: 2.124618, top_1: 0.737461, top_k: 0.901641, samples/s: 2231.962 1612439248.3746495
train: epoch 142, iter 200, loss: 2.152244, top_1: 0.732656, top_k: 0.897813, samples/s: 2231.379 1612439259.8474836
train: epoch 142, iter 300, loss: 2.168865, top_1: 0.732969, top_k: 0.899492, samples/s: 2227.085 1612439271.3422525
train: epoch 142, iter 400, loss: 2.051170, top_1: 0.740742, top_k: 0.904375, samples/s: 2247.101 1612439282.7347069
train: epoch 142, iter 500, loss: 2.175570, top_1: 0.733086, top_k: 0.898867, samples/s: 2250.554 1612439294.109651
train: epoch 142, iter 600, loss: 2.176564, top_1: 0.734570, top_k: 0.897695, samples/s: 2252.558 1612439305.4745526
train: epoch 142, iter 700, loss: 2.162971, top_1: 0.733047, top_k: 0.897578, samples/s: 2253.793 1612439316.8331494
train: epoch 142, iter 800, loss: 2.031168, top_1: 0.735195, top_k: 0.899766, samples/s: 2239.993 1612439328.2617445
train: epoch 142, iter 900, loss: 2.133279, top_1: 0.732969, top_k: 0.896055, samples/s: 2249.642 1612439339.6413934
train: epoch 142, iter 1000, loss: 2.102194, top_1: 0.737070, top_k: 0.900156, samples/s: 2213.731 1612439351.2056375
train: epoch 142, iter 1100, loss: 2.053353, top_1: 0.731055, top_k: 0.897344, samples/s: 2219.047 1612439362.7420914
train: epoch 142, iter 1200, loss: 2.107625, top_1: 0.732461, top_k: 0.899414, samples/s: 2233.387 1612439374.2044642
train: epoch 142, iter 1300, loss: 2.117474, top_1: 0.732891, top_k: 0.899453, samples/s: 2213.127 1612439385.7717607
train: epoch 142, iter 1400, loss: 1.974747, top_1: 0.733516, top_k: 0.899609, samples/s: 2217.373 1612439397.316982
train: epoch 142, iter 1500, loss: 2.044364, top_1: 0.730000, top_k: 0.896406, samples/s: 2221.160 1612439408.8424678
train: epoch 142, iter 1600, loss: 2.103845, top_1: 0.735508, top_k: 0.898711, samples/s: 2220.685 1612439420.3705044
train: epoch 142, iter 1700, loss: 2.186051, top_1: 0.738477, top_k: 0.902070, samples/s: 2219.224 1612439431.9060497
train: epoch 142, iter 1800, loss: 2.322474, top_1: 0.732266, top_k: 0.898125, samples/s: 2222.205 1612439443.426123
train: epoch 142, iter 1900, loss: 2.170742, top_1: 0.731758, top_k: 0.896406, samples/s: 2209.460 1612439455.0126815
train: epoch 142, iter 2000, loss: 2.100696, top_1: 0.736445, top_k: 0.900742, samples/s: 2214.271 1612439466.5740533
train: epoch 142, iter 2100, loss: 2.059818, top_1: 0.741523, top_k: 0.902813, samples/s: 2231.415 1612439478.0465426
train: epoch 142, iter 2200, loss: 2.107643, top_1: 0.731992, top_k: 0.897031, samples/s: 2215.803 1612439489.5999215
train: epoch 142, iter 2300, loss: 1.989839, top_1: 0.734414, top_k: 0.898477, samples/s: 2220.498 1612439501.1288488
train: epoch 142, iter 2400, loss: 2.286902, top_1: 0.737031, top_k: 0.897930, samples/s: 2201.270 1612439512.7586093
train: epoch 142, iter 2500, loss: 2.215236, top_1: 0.729883, top_k: 0.895781, samples/s: 2231.454 1612439524.2308576
train: epoch 142, iter 2600, loss: 2.028336, top_1: 0.730820, top_k: 0.895312, samples/s: 2223.629 1612439535.7435503
train: epoch 142, iter 2700, loss: 2.119566, top_1: 0.736016, top_k: 0.897773, samples/s: 2204.026 1612439547.3587277
train: epoch 142, iter 2800, loss: 2.105433, top_1: 0.732539, top_k: 0.896133, samples/s: 2237.916 1612439558.7978847
train: epoch 142, iter 2900, loss: 2.195256, top_1: 0.735859, top_k: 0.900391, samples/s: 2223.127 1612439570.3132238
train: epoch 142, iter 3000, loss: 2.053056, top_1: 0.730703, top_k: 0.898242, samples/s: 2198.396 1612439581.958119
train: epoch 142, iter 3100, loss: 2.324533, top_1: 0.735078, top_k: 0.899180, samples/s: 2222.795 1612439593.4750836
train: epoch 142, iter 3200, loss: 2.069229, top_1: 0.733828, top_k: 0.895820, samples/s: 2216.144 1612439605.026735
train: epoch 142, iter 3300, loss: 2.098574, top_1: 0.728086, top_k: 0.897852, samples/s: 2243.340 1612439616.4382334
train: epoch 142, iter 3400, loss: 1.983244, top_1: 0.733125, top_k: 0.898867, samples/s: 2240.146 1612439627.8660603
train: epoch 142, iter 3500, loss: 2.222341, top_1: 0.730352, top_k: 0.897305, samples/s: 2236.906 1612439639.3104565
train: epoch 142, iter 3600, loss: 2.107146, top_1: 0.729609, top_k: 0.894687, samples/s: 2235.927 1612439650.7598317
train: epoch 142, iter 3700, loss: 2.048642, top_1: 0.736211, top_k: 0.899219, samples/s: 2244.135 1612439662.1673524
train: epoch 142, iter 3800, loss: 2.014858, top_1: 0.737617, top_k: 0.898945, samples/s: 2224.863 1612439673.6736767
train: epoch 142, iter 3900, loss: 1.988100, top_1: 0.735781, top_k: 0.899844, samples/s: 2230.880 1612439685.1489758
train: epoch 142, iter 4000, loss: 2.062876, top_1: 0.734531, top_k: 0.899336, samples/s: 2240.328 1612439696.5758812
train: epoch 142, iter 4100, loss: 2.346933, top_1: 0.730430, top_k: 0.898242, samples/s: 2241.553 1612439707.996575
train: epoch 142, iter 4200, loss: 2.151596, top_1: 0.730117, top_k: 0.897578, samples/s: 2232.194 1612439719.4650989
train: epoch 142, iter 4300, loss: 1.962294, top_1: 0.730898, top_k: 0.898242, samples/s: 2236.980 1612439730.9091005
train: epoch 142, iter 4400, loss: 2.095856, top_1: 0.730664, top_k: 0.897852, samples/s: 2234.813 1612439742.3641515
train: epoch 142, iter 4500, loss: 1.942879, top_1: 0.734258, top_k: 0.899609, samples/s: 2235.105 1612439753.8177612
train: epoch 142, iter 4600, loss: 2.286850, top_1: 0.736445, top_k: 0.897227, samples/s: 2235.286 1612439765.2704213
train: epoch 142, iter 4700, loss: 2.262980, top_1: 0.734922, top_k: 0.897500, samples/s: 2242.606 1612439776.6857188
train: epoch 142, iter 4800, loss: 2.061841, top_1: 0.735586, top_k: 0.897969, samples/s: 2246.337 1612439788.082045
train: epoch 142, iter 4900, loss: 1.963120, top_1: 0.738398, top_k: 0.897617, samples/s: 2244.192 1612439799.4892757
train: epoch 142, iter 5000, loss: 2.045773, top_1: 0.734844, top_k: 0.896641, samples/s: 2220.205 1612439811.0197372
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_142.
validation: epoch 142, iter 195, top_1: 0.740365, top_k: 0.914784, samples/s: 2880.969 1612439828.6601722
train: epoch 143, iter 100, loss: 2.272533, top_1: 0.733437, top_k: 0.898711, samples/s: 2238.254 1612439856.2145722
train: epoch 143, iter 200, loss: 2.164187, top_1: 0.741992, top_k: 0.900937, samples/s: 2247.486 1612439867.605089
train: epoch 143, iter 300, loss: 2.040749, top_1: 0.739180, top_k: 0.902500, samples/s: 2260.524 1612439878.9298959
train: epoch 143, iter 400, loss: 2.128619, top_1: 0.733359, top_k: 0.897695, samples/s: 2254.634 1612439890.2842844
train: epoch 143, iter 500, loss: 2.193313, top_1: 0.736680, top_k: 0.900195, samples/s: 2253.191 1612439901.645937
train: epoch 143, iter 600, loss: 2.037335, top_1: 0.736914, top_k: 0.900117, samples/s: 2233.524 1612439913.1076236
train: epoch 143, iter 700, loss: 2.200999, top_1: 0.736914, top_k: 0.900664, samples/s: 2228.078 1612439924.5973856
train: epoch 143, iter 800, loss: 2.107663, top_1: 0.738242, top_k: 0.901133, samples/s: 2246.727 1612439935.991751
train: epoch 143, iter 900, loss: 2.175177, top_1: 0.738516, top_k: 0.900977, samples/s: 2205.929 1612439947.5968263
train: epoch 143, iter 1000, loss: 2.223172, top_1: 0.734297, top_k: 0.900000, samples/s: 2251.068 1612439958.9692483
train: epoch 143, iter 1100, loss: 1.996462, top_1: 0.733164, top_k: 0.900664, samples/s: 2223.116 1612439970.4846299
train: epoch 143, iter 1200, loss: 2.246158, top_1: 0.739531, top_k: 0.899297, samples/s: 2232.161 1612439981.953297
train: epoch 143, iter 1300, loss: 2.049403, top_1: 0.736484, top_k: 0.900781, samples/s: 2232.496 1612439993.4202647
train: epoch 143, iter 1400, loss: 2.212045, top_1: 0.733320, top_k: 0.900820, samples/s: 2218.828 1612440004.9578974
train: epoch 143, iter 1500, loss: 2.033883, top_1: 0.739219, top_k: 0.900586, samples/s: 2206.110 1612440016.562015
train: epoch 143, iter 1600, loss: 2.071985, top_1: 0.734727, top_k: 0.897852, samples/s: 2213.105 1612440028.1294777
train: epoch 143, iter 1700, loss: 2.122152, top_1: 0.741211, top_k: 0.901289, samples/s: 2205.363 1612440039.7376091
train: epoch 143, iter 1800, loss: 2.183177, top_1: 0.734141, top_k: 0.898125, samples/s: 2228.889 1612440051.223086
train: epoch 143, iter 1900, loss: 2.220774, top_1: 0.735039, top_k: 0.899922, samples/s: 2209.363 1612440062.810134
train: epoch 143, iter 2000, loss: 2.114448, top_1: 0.731445, top_k: 0.897891, samples/s: 2231.464 1612440074.2824163
train: epoch 143, iter 2100, loss: 2.381383, top_1: 0.734219, top_k: 0.899492, samples/s: 2216.824 1612440085.830536
train: epoch 143, iter 2200, loss: 2.108602, top_1: 0.737344, top_k: 0.898945, samples/s: 2219.106 1612440097.3666704
train: epoch 143, iter 2300, loss: 2.044677, top_1: 0.734688, top_k: 0.898203, samples/s: 2242.859 1612440108.7807918
train: epoch 143, iter 2400, loss: 2.101070, top_1: 0.731914, top_k: 0.898945, samples/s: 2238.972 1612440120.2145593
train: epoch 143, iter 2500, loss: 2.253386, top_1: 0.737852, top_k: 0.901172, samples/s: 2229.190 1612440131.698549
train: epoch 143, iter 2600, loss: 2.039561, top_1: 0.736602, top_k: 0.900273, samples/s: 2229.463 1612440143.1810563
train: epoch 143, iter 2700, loss: 2.097170, top_1: 0.735039, top_k: 0.897930, samples/s: 2221.442 1612440154.705104
train: epoch 143, iter 2800, loss: 2.132388, top_1: 0.739609, top_k: 0.902461, samples/s: 2226.340 1612440166.2038076
train: epoch 143, iter 2900, loss: 2.145523, top_1: 0.734141, top_k: 0.896484, samples/s: 2249.788 1612440177.5826466
train: epoch 143, iter 3000, loss: 2.059601, top_1: 0.731875, top_k: 0.897148, samples/s: 2236.287 1612440189.0301988
train: epoch 143, iter 3100, loss: 2.193108, top_1: 0.740859, top_k: 0.901445, samples/s: 2230.628 1612440200.506781
train: epoch 143, iter 3200, loss: 2.131576, top_1: 0.739688, top_k: 0.900508, samples/s: 2223.760 1612440212.0187874
train: epoch 143, iter 3300, loss: 2.015985, top_1: 0.736133, top_k: 0.900273, samples/s: 2249.847 1612440223.3974175
train: epoch 143, iter 3400, loss: 1.992523, top_1: 0.731523, top_k: 0.899687, samples/s: 2228.647 1612440234.884176
train: epoch 143, iter 3500, loss: 2.042605, top_1: 0.741367, top_k: 0.904727, samples/s: 2241.584 1612440246.3049674
train: epoch 143, iter 3600, loss: 2.083163, top_1: 0.732852, top_k: 0.898477, samples/s: 2221.236 1612440257.829782
train: epoch 143, iter 3700, loss: 2.008505, top_1: 0.735156, top_k: 0.900234, samples/s: 2243.612 1612440269.2404327
train: epoch 143, iter 3800, loss: 2.056715, top_1: 0.737305, top_k: 0.902109, samples/s: 2238.655 1612440280.6754317
train: epoch 143, iter 3900, loss: 2.091800, top_1: 0.733789, top_k: 0.897773, samples/s: 2238.823 1612440292.1099503
train: epoch 143, iter 4000, loss: 2.118062, top_1: 0.731797, top_k: 0.895859, samples/s: 2212.954 1612440303.6782103
train: epoch 143, iter 4100, loss: 2.194283, top_1: 0.736484, top_k: 0.901563, samples/s: 2224.752 1612440315.185155
train: epoch 143, iter 4200, loss: 2.145704, top_1: 0.735586, top_k: 0.898789, samples/s: 2213.397 1612440326.751111
train: epoch 143, iter 4300, loss: 2.032405, top_1: 0.734961, top_k: 0.902422, samples/s: 2195.510 1612440338.4116492
train: epoch 143, iter 4400, loss: 2.055220, top_1: 0.736367, top_k: 0.900000, samples/s: 2249.524 1612440349.7913976
train: epoch 143, iter 4500, loss: 2.027974, top_1: 0.736445, top_k: 0.898555, samples/s: 2235.403 1612440361.2435043
train: epoch 143, iter 4600, loss: 2.010235, top_1: 0.732812, top_k: 0.898711, samples/s: 2236.884 1612440372.687998
train: epoch 143, iter 4700, loss: 2.138754, top_1: 0.735078, top_k: 0.899492, samples/s: 2175.139 1612440384.4575675
train: epoch 143, iter 4800, loss: 2.189839, top_1: 0.738477, top_k: 0.899609, samples/s: 2263.410 1612440395.7676437
train: epoch 143, iter 4900, loss: 1.994058, top_1: 0.740742, top_k: 0.900000, samples/s: 2220.111 1612440407.2987838
train: epoch 143, iter 5000, loss: 1.992491, top_1: 0.740352, top_k: 0.901836, samples/s: 2235.996 1612440418.747677
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_143.
validation: epoch 143, iter 195, top_1: 0.740625, top_k: 0.916386, samples/s: 2894.151 1612440436.335899
train: epoch 144, iter 100, loss: 2.049186, top_1: 0.742422, top_k: 0.903789, samples/s: 2232.327 1612440463.8244724
train: epoch 144, iter 200, loss: 2.134754, top_1: 0.739102, top_k: 0.901445, samples/s: 2255.654 1612440475.1737328
train: epoch 144, iter 300, loss: 2.118040, top_1: 0.740156, top_k: 0.900273, samples/s: 2245.006 1612440486.5768008
train: epoch 144, iter 400, loss: 2.066216, top_1: 0.743633, top_k: 0.902148, samples/s: 2249.165 1612440497.9588747
train: epoch 144, iter 500, loss: 2.083097, top_1: 0.738320, top_k: 0.897852, samples/s: 2265.738 1612440509.2576694
train: epoch 144, iter 600, loss: 1.990354, top_1: 0.735859, top_k: 0.896992, samples/s: 2240.282 1612440520.6846852
train: epoch 144, iter 700, loss: 1.972124, top_1: 0.743008, top_k: 0.900586, samples/s: 2259.081 1612440532.0168831
train: epoch 144, iter 800, loss: 1.953014, top_1: 0.736953, top_k: 0.901602, samples/s: 2243.788 1612440543.4262013
train: epoch 144, iter 900, loss: 2.185953, top_1: 0.739688, top_k: 0.900273, samples/s: 2226.436 1612440554.9242325
train: epoch 144, iter 1000, loss: 2.134800, top_1: 0.739609, top_k: 0.901328, samples/s: 2217.698 1612440566.467696
train: epoch 144, iter 1100, loss: 2.005147, top_1: 0.740664, top_k: 0.902344, samples/s: 2219.257 1612440578.003085
train: epoch 144, iter 1200, loss: 1.871483, top_1: 0.741367, top_k: 0.901211, samples/s: 2225.253 1612440589.5073972
train: epoch 144, iter 1300, loss: 2.221004, top_1: 0.738242, top_k: 0.900352, samples/s: 2207.363 1612440601.104952
train: epoch 144, iter 1400, loss: 2.025425, top_1: 0.738320, top_k: 0.900898, samples/s: 2213.794 1612440612.668886
train: epoch 144, iter 1500, loss: 2.139986, top_1: 0.740078, top_k: 0.900391, samples/s: 2216.689 1612440624.2175663
train: epoch 144, iter 1600, loss: 2.260475, top_1: 0.737539, top_k: 0.900273, samples/s: 2220.277 1612440635.7476974
train: epoch 144, iter 1700, loss: 2.111121, top_1: 0.738633, top_k: 0.901875, samples/s: 2226.509 1612440647.2455368
train: epoch 144, iter 1800, loss: 2.041911, top_1: 0.735898, top_k: 0.901133, samples/s: 2213.266 1612440658.8121297
train: epoch 144, iter 1900, loss: 2.160477, top_1: 0.736797, top_k: 0.900430, samples/s: 2257.864 1612440670.1503594
train: epoch 144, iter 2000, loss: 2.260277, top_1: 0.734180, top_k: 0.899023, samples/s: 2231.810 1612440681.6208067
train: epoch 144, iter 2100, loss: 2.056058, top_1: 0.738281, top_k: 0.900234, samples/s: 2217.997 1612440693.162687
train: epoch 144, iter 2200, loss: 2.054626, top_1: 0.743672, top_k: 0.901758, samples/s: 2242.704 1612440704.5774965
train: epoch 144, iter 2300, loss: 2.110049, top_1: 0.740508, top_k: 0.900391, samples/s: 2215.563 1612440716.1321106
train: epoch 144, iter 2400, loss: 2.051847, top_1: 0.739727, top_k: 0.899844, samples/s: 2247.660 1612440727.521752
train: epoch 144, iter 2500, loss: 2.148342, top_1: 0.742695, top_k: 0.901289, samples/s: 2225.866 1612440739.0228767
train: epoch 144, iter 2600, loss: 2.286394, top_1: 0.737852, top_k: 0.898711, samples/s: 2235.248 1612440750.4757385
train: epoch 144, iter 2700, loss: 2.005849, top_1: 0.733867, top_k: 0.896406, samples/s: 2236.792 1612440761.9207323
train: epoch 144, iter 2800, loss: 2.104157, top_1: 0.739648, top_k: 0.901172, samples/s: 2236.777 1612440773.3657458
train: epoch 144, iter 2900, loss: 1.981619, top_1: 0.738867, top_k: 0.903164, samples/s: 2229.854 1612440784.8464105
train: epoch 144, iter 3000, loss: 2.029766, top_1: 0.739688, top_k: 0.900117, samples/s: 2241.951 1612440796.2649047
train: epoch 144, iter 3100, loss: 2.014903, top_1: 0.734727, top_k: 0.898750, samples/s: 2219.698 1612440807.7980416
train: epoch 144, iter 3200, loss: 1.918411, top_1: 0.740156, top_k: 0.900977, samples/s: 2226.558 1612440819.295614
train: epoch 144, iter 3300, loss: 2.134094, top_1: 0.735977, top_k: 0.900273, samples/s: 2220.870 1612440830.8227153
train: epoch 144, iter 3400, loss: 2.122914, top_1: 0.738359, top_k: 0.899648, samples/s: 2255.087 1612440842.174741
train: epoch 144, iter 3500, loss: 2.046051, top_1: 0.734883, top_k: 0.899180, samples/s: 2229.589 1612440853.6566758
train: epoch 144, iter 3600, loss: 2.046443, top_1: 0.734727, top_k: 0.899766, samples/s: 2221.709 1612440865.1793628
train: epoch 144, iter 3700, loss: 2.137345, top_1: 0.739648, top_k: 0.899453, samples/s: 2234.610 1612440876.6355224
train: epoch 144, iter 3800, loss: 2.158157, top_1: 0.737617, top_k: 0.901172, samples/s: 2237.361 1612440888.0775263
train: epoch 144, iter 3900, loss: 2.221950, top_1: 0.734570, top_k: 0.899844, samples/s: 2227.078 1612440899.572447
train: epoch 144, iter 4000, loss: 2.017880, top_1: 0.739648, top_k: 0.900820, samples/s: 2233.600 1612440911.0337532
train: epoch 144, iter 4100, loss: 2.181319, top_1: 0.739102, top_k: 0.900625, samples/s: 2194.412 1612440922.6997411
train: epoch 144, iter 4200, loss: 2.127407, top_1: 0.738906, top_k: 0.901211, samples/s: 2232.521 1612440934.166648
train: epoch 144, iter 4300, loss: 2.107384, top_1: 0.740781, top_k: 0.900273, samples/s: 2220.638 1612440945.694827
train: epoch 144, iter 4400, loss: 2.059187, top_1: 0.743242, top_k: 0.903594, samples/s: 2265.993 1612440956.9922833
train: epoch 144, iter 4500, loss: 2.171933, top_1: 0.742539, top_k: 0.901758, samples/s: 2231.468 1612440968.4644933
train: epoch 144, iter 4600, loss: 2.093964, top_1: 0.737852, top_k: 0.899102, samples/s: 2256.705 1612440979.8085403
train: epoch 144, iter 4700, loss: 1.975657, top_1: 0.733086, top_k: 0.897305, samples/s: 2225.704 1612440991.310463
train: epoch 144, iter 4800, loss: 2.024742, top_1: 0.740430, top_k: 0.899375, samples/s: 2235.952 1612441002.7597597
train: epoch 144, iter 4900, loss: 2.042254, top_1: 0.742383, top_k: 0.903828, samples/s: 2229.040 1612441014.2445335
train: epoch 144, iter 5000, loss: 2.104319, top_1: 0.738672, top_k: 0.902266, samples/s: 2236.677 1612441025.690041
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_144.
validation: epoch 144, iter 195, top_1: 0.742228, top_k: 0.916587, samples/s: 2881.472 1612441043.369358
train: epoch 145, iter 100, loss: 2.062391, top_1: 0.744687, top_k: 0.903750, samples/s: 2230.581 1612441070.6024313
train: epoch 145, iter 200, loss: 1.969630, top_1: 0.747227, top_k: 0.905195, samples/s: 2255.229 1612441081.9537756
train: epoch 145, iter 300, loss: 2.127994, top_1: 0.745156, top_k: 0.901563, samples/s: 2233.227 1612441093.4170518
train: epoch 145, iter 400, loss: 2.340861, top_1: 0.739922, top_k: 0.901523, samples/s: 2269.278 1612441104.6981876
train: epoch 145, iter 500, loss: 2.162485, top_1: 0.738203, top_k: 0.902891, samples/s: 2255.491 1612441116.0482683
train: epoch 145, iter 600, loss: 2.348387, top_1: 0.740586, top_k: 0.903984, samples/s: 2235.944 1612441127.4975653
train: epoch 145, iter 700, loss: 2.211477, top_1: 0.738008, top_k: 0.901680, samples/s: 2251.047 1612441138.8700619
train: epoch 145, iter 800, loss: 2.082107, top_1: 0.745352, top_k: 0.904023, samples/s: 2230.256 1612441150.3486161
train: epoch 145, iter 900, loss: 2.191364, top_1: 0.740117, top_k: 0.899570, samples/s: 2259.977 1612441161.6761365
train: epoch 145, iter 1000, loss: 2.030113, top_1: 0.740547, top_k: 0.901836, samples/s: 2206.573 1612441173.2777977
train: epoch 145, iter 1100, loss: 2.099998, top_1: 0.738086, top_k: 0.899023, samples/s: 2206.425 1612441184.880374
train: epoch 145, iter 1200, loss: 2.181058, top_1: 0.744844, top_k: 0.903789, samples/s: 2248.887 1612441196.2636817
train: epoch 145, iter 1300, loss: 2.016627, top_1: 0.744141, top_k: 0.900430, samples/s: 2251.679 1612441207.6330035
train: epoch 145, iter 1400, loss: 2.157952, top_1: 0.742188, top_k: 0.901953, samples/s: 2209.159 1612441219.2211194
train: epoch 145, iter 1500, loss: 2.153107, top_1: 0.740195, top_k: 0.902969, samples/s: 2239.285 1612441230.6533246
train: epoch 145, iter 1600, loss: 2.141914, top_1: 0.742539, top_k: 0.903789, samples/s: 2226.531 1612441242.1510682
train: epoch 145, iter 1700, loss: 1.930522, top_1: 0.741523, top_k: 0.903984, samples/s: 2231.759 1612441253.6218188
train: epoch 145, iter 1800, loss: 2.215808, top_1: 0.741445, top_k: 0.899023, samples/s: 2231.740 1612441265.0926783
train: epoch 145, iter 1900, loss: 2.102309, top_1: 0.743437, top_k: 0.905859, samples/s: 2230.173 1612441276.5716112
train: epoch 145, iter 2000, loss: 2.025800, top_1: 0.740977, top_k: 0.901523, samples/s: 2246.128 1612441287.968991
train: epoch 145, iter 2100, loss: 2.130088, top_1: 0.742188, top_k: 0.900352, samples/s: 2222.146 1612441299.489433
train: epoch 145, iter 2200, loss: 2.136189, top_1: 0.740820, top_k: 0.903203, samples/s: 2239.864 1612441310.9186597
train: epoch 145, iter 2300, loss: 2.193154, top_1: 0.742891, top_k: 0.902891, samples/s: 2222.725 1612441322.4360785
train: epoch 145, iter 2400, loss: 2.211462, top_1: 0.737656, top_k: 0.899844, samples/s: 2245.534 1612441333.8364606
train: epoch 145, iter 2500, loss: 2.119973, top_1: 0.742500, top_k: 0.903633, samples/s: 2245.071 1612441345.2392235
train: epoch 145, iter 2600, loss: 2.126641, top_1: 0.740977, top_k: 0.899687, samples/s: 2222.704 1612441356.7568624
train: epoch 145, iter 2700, loss: 2.161959, top_1: 0.740313, top_k: 0.899922, samples/s: 2239.041 1612441368.1901796
train: epoch 145, iter 2800, loss: 2.148077, top_1: 0.743086, top_k: 0.902109, samples/s: 2217.040 1612441379.7371597
train: epoch 145, iter 2900, loss: 2.085025, top_1: 0.745352, top_k: 0.904102, samples/s: 2237.464 1612441391.178653
train: epoch 145, iter 3000, loss: 2.036620, top_1: 0.740117, top_k: 0.900156, samples/s: 2227.922 1612441402.6692042
train: epoch 145, iter 3100, loss: 2.106606, top_1: 0.742578, top_k: 0.901758, samples/s: 2237.949 1612441414.1082
train: epoch 145, iter 3200, loss: 2.279363, top_1: 0.737578, top_k: 0.901133, samples/s: 2218.766 1612441425.646269
train: epoch 145, iter 3300, loss: 2.055026, top_1: 0.735664, top_k: 0.901797, samples/s: 2233.037 1612441437.110362
train: epoch 145, iter 3400, loss: 2.063473, top_1: 0.739766, top_k: 0.902305, samples/s: 2225.600 1612441448.612865
train: epoch 145, iter 3500, loss: 2.132411, top_1: 0.741602, top_k: 0.902383, samples/s: 2217.086 1612441460.1595707
train: epoch 145, iter 3600, loss: 2.121436, top_1: 0.741211, top_k: 0.900781, samples/s: 2253.369 1612441471.5205104
train: epoch 145, iter 3700, loss: 2.224034, top_1: 0.740117, top_k: 0.903320, samples/s: 2228.370 1612441483.0085564
train: epoch 145, iter 3800, loss: 2.010461, top_1: 0.737266, top_k: 0.902969, samples/s: 2225.080 1612441494.5137832
train: epoch 145, iter 3900, loss: 2.100393, top_1: 0.736719, top_k: 0.900703, samples/s: 2232.367 1612441505.9814086
train: epoch 145, iter 4000, loss: 2.198473, top_1: 0.744883, top_k: 0.905078, samples/s: 2244.467 1612441517.3872402
train: epoch 145, iter 4100, loss: 2.047576, top_1: 0.740039, top_k: 0.903164, samples/s: 2231.370 1612441528.8600063
train: epoch 145, iter 4200, loss: 2.162322, top_1: 0.737031, top_k: 0.900664, samples/s: 2225.838 1612441540.3612862
train: epoch 145, iter 4300, loss: 2.048755, top_1: 0.743242, top_k: 0.903008, samples/s: 2240.191 1612441551.788904
train: epoch 145, iter 4400, loss: 2.018628, top_1: 0.737852, top_k: 0.899336, samples/s: 2249.818 1612441563.1675684
train: epoch 145, iter 4500, loss: 2.178935, top_1: 0.739688, top_k: 0.900898, samples/s: 2243.415 1612441574.5787408
train: epoch 145, iter 4600, loss: 1.997326, top_1: 0.743555, top_k: 0.901523, samples/s: 2232.471 1612441586.0458906
train: epoch 145, iter 4700, loss: 2.129927, top_1: 0.741172, top_k: 0.901016, samples/s: 2230.232 1612441597.5244794
train: epoch 145, iter 4800, loss: 2.066277, top_1: 0.741523, top_k: 0.901953, samples/s: 2256.468 1612441608.8696465
train: epoch 145, iter 4900, loss: 2.117035, top_1: 0.742109, top_k: 0.901328, samples/s: 2227.570 1612441620.3620517
train: epoch 145, iter 5000, loss: 2.178898, top_1: 0.742852, top_k: 0.902773, samples/s: 2230.040 1612441631.8416007
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_145.
validation: epoch 145, iter 195, top_1: 0.743490, top_k: 0.917448, samples/s: 2784.524 1612441650.125215
train: epoch 146, iter 100, loss: 2.021986, top_1: 0.739297, top_k: 0.903672, samples/s: 2204.054 1612441677.5168734
train: epoch 146, iter 200, loss: 2.089068, top_1: 0.744844, top_k: 0.905469, samples/s: 2262.494 1612441688.8317404
train: epoch 146, iter 300, loss: 1.928525, top_1: 0.743242, top_k: 0.902070, samples/s: 2244.720 1612441700.2363954
train: epoch 146, iter 400, loss: 2.140268, top_1: 0.744922, top_k: 0.904648, samples/s: 2250.929 1612441711.6093643
train: epoch 146, iter 500, loss: 1.976795, top_1: 0.745430, top_k: 0.905352, samples/s: 2261.375 1612441722.9299538
train: epoch 146, iter 600, loss: 2.320272, top_1: 0.745977, top_k: 0.905000, samples/s: 2250.122 1612441734.3077223
train: epoch 146, iter 700, loss: 2.036983, top_1: 0.743398, top_k: 0.903242, samples/s: 2229.015 1612441745.791926
train: epoch 146, iter 800, loss: 2.187125, top_1: 0.747148, top_k: 0.904141, samples/s: 2225.041 1612441757.2973475
train: epoch 146, iter 900, loss: 2.039621, top_1: 0.740508, top_k: 0.901953, samples/s: 2221.951 1612441768.8187485
train: epoch 146, iter 1000, loss: 2.194462, top_1: 0.746211, top_k: 0.903750, samples/s: 2221.679 1612441780.3415148
train: epoch 146, iter 1100, loss: 2.102413, top_1: 0.743477, top_k: 0.902305, samples/s: 2217.834 1612441791.8843536
train: epoch 146, iter 1200, loss: 1.906883, top_1: 0.745273, top_k: 0.901016, samples/s: 2211.534 1612441803.460395
train: epoch 146, iter 1300, loss: 2.132130, top_1: 0.743633, top_k: 0.902070, samples/s: 2234.120 1612441814.9186876
train: epoch 146, iter 1400, loss: 2.166896, top_1: 0.744219, top_k: 0.903477, samples/s: 2215.931 1612441826.471408
train: epoch 146, iter 1500, loss: 1.960602, top_1: 0.745859, top_k: 0.903164, samples/s: 2219.956 1612441838.003238
train: epoch 146, iter 1600, loss: 2.159722, top_1: 0.743398, top_k: 0.903789, samples/s: 2223.117 1612441849.5185072
train: epoch 146, iter 1700, loss: 2.178587, top_1: 0.747500, top_k: 0.902695, samples/s: 2226.049 1612441861.0187008
train: epoch 146, iter 1800, loss: 1.998868, top_1: 0.741719, top_k: 0.903320, samples/s: 2214.969 1612441872.576421
train: epoch 146, iter 1900, loss: 2.103407, top_1: 0.741406, top_k: 0.901250, samples/s: 2207.732 1612441884.1720114
train: epoch 146, iter 2000, loss: 2.048828, top_1: 0.744766, top_k: 0.903945, samples/s: 2207.655 1612441895.7680523
train: epoch 146, iter 2100, loss: 1.955230, top_1: 0.738789, top_k: 0.900547, samples/s: 2210.298 1612441907.3502002
train: epoch 146, iter 2200, loss: 2.101999, top_1: 0.741563, top_k: 0.902695, samples/s: 2224.824 1612441918.8567379
train: epoch 146, iter 2300, loss: 1.956595, top_1: 0.748711, top_k: 0.907266, samples/s: 2151.716 1612441930.7543037
train: epoch 146, iter 2400, loss: 2.046166, top_1: 0.742539, top_k: 0.900586, samples/s: 2221.405 1612441942.2790806
train: epoch 146, iter 2500, loss: 2.189814, top_1: 0.740273, top_k: 0.902383, samples/s: 2234.713 1612441953.7340653
train: epoch 146, iter 2600, loss: 2.110004, top_1: 0.740195, top_k: 0.902656, samples/s: 2245.143 1612441965.1365185
train: epoch 146, iter 2700, loss: 2.147308, top_1: 0.741719, top_k: 0.906250, samples/s: 2227.023 1612441976.6316292
train: epoch 146, iter 2800, loss: 2.089235, top_1: 0.741289, top_k: 0.901563, samples/s: 2218.986 1612441988.1687708
train: epoch 146, iter 2900, loss: 2.166962, top_1: 0.747031, top_k: 0.905625, samples/s: 2223.708 1612441999.6807888
train: epoch 146, iter 3000, loss: 1.975847, top_1: 0.742852, top_k: 0.901719, samples/s: 2246.485 1612442011.076326
train: epoch 146, iter 3100, loss: 2.107556, top_1: 0.748437, top_k: 0.903555, samples/s: 2237.809 1612442022.5161474
train: epoch 146, iter 3200, loss: 1.964207, top_1: 0.739805, top_k: 0.903828, samples/s: 2204.851 1612442034.1268759
train: epoch 146, iter 3300, loss: 1.984967, top_1: 0.739492, top_k: 0.901914, samples/s: 2227.969 1612442045.6171901
train: epoch 146, iter 3400, loss: 1.925393, top_1: 0.744219, top_k: 0.903633, samples/s: 2250.944 1612442056.9901233
train: epoch 146, iter 3500, loss: 2.140170, top_1: 0.744961, top_k: 0.902969, samples/s: 2225.023 1612442068.4956408
train: epoch 146, iter 3600, loss: 2.174224, top_1: 0.742930, top_k: 0.903164, samples/s: 2242.024 1612442079.913936
train: epoch 146, iter 3700, loss: 1.994567, top_1: 0.739492, top_k: 0.903789, samples/s: 2214.422 1612442091.4744527
train: epoch 146, iter 3800, loss: 2.233677, top_1: 0.740664, top_k: 0.903672, samples/s: 2233.469 1612442102.9364836
train: epoch 146, iter 3900, loss: 2.410844, top_1: 0.742852, top_k: 0.900898, samples/s: 2227.005 1612442114.4318492
train: epoch 146, iter 4000, loss: 2.164787, top_1: 0.741875, top_k: 0.903203, samples/s: 2228.172 1612442125.9209843
train: epoch 146, iter 4100, loss: 2.136081, top_1: 0.748359, top_k: 0.905469, samples/s: 2241.082 1612442137.3440886
train: epoch 146, iter 4200, loss: 2.079931, top_1: 0.742656, top_k: 0.902578, samples/s: 2222.957 1612442148.860223
train: epoch 146, iter 4300, loss: 2.263696, top_1: 0.744961, top_k: 0.902188, samples/s: 2245.416 1612442160.2612371
train: epoch 146, iter 4400, loss: 2.075224, top_1: 0.739531, top_k: 0.902188, samples/s: 2231.117 1612442171.7352717
train: epoch 146, iter 4500, loss: 2.072435, top_1: 0.741914, top_k: 0.899961, samples/s: 2244.234 1612442183.1422784
train: epoch 146, iter 4600, loss: 2.081995, top_1: 0.745352, top_k: 0.904648, samples/s: 2227.782 1612442194.633525
train: epoch 146, iter 4700, loss: 2.251911, top_1: 0.742656, top_k: 0.900391, samples/s: 2218.565 1612442206.1725295
train: epoch 146, iter 4800, loss: 2.052982, top_1: 0.748242, top_k: 0.906094, samples/s: 2226.991 1612442217.667856
train: epoch 146, iter 4900, loss: 2.127382, top_1: 0.743984, top_k: 0.905781, samples/s: 2245.339 1612442229.069258
train: epoch 146, iter 5000, loss: 2.028243, top_1: 0.743984, top_k: 0.901602, samples/s: 2242.940 1612442240.4828396
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_146.
validation: epoch 146, iter 195, top_1: 0.742768, top_k: 0.916166, samples/s: 2869.899 1612442258.175797
train: epoch 147, iter 100, loss: 2.048701, top_1: 0.745078, top_k: 0.904062, samples/s: 2236.730 1612442285.687416
train: epoch 147, iter 200, loss: 2.060826, top_1: 0.744727, top_k: 0.905234, samples/s: 2241.339 1612442297.1091604
train: epoch 147, iter 300, loss: 2.028905, top_1: 0.748164, top_k: 0.907539, samples/s: 2246.439 1612442308.5049844
train: epoch 147, iter 400, loss: 2.156402, top_1: 0.745664, top_k: 0.907422, samples/s: 2234.663 1612442319.9608452
train: epoch 147, iter 500, loss: 2.068558, top_1: 0.748555, top_k: 0.903945, samples/s: 2263.322 1612442331.2717063
train: epoch 147, iter 600, loss: 2.073632, top_1: 0.740781, top_k: 0.901016, samples/s: 2259.686 1612442342.600716
train: epoch 147, iter 700, loss: 2.023787, top_1: 0.743242, top_k: 0.901914, samples/s: 2229.028 1612442354.0855272
train: epoch 147, iter 800, loss: 2.080978, top_1: 0.748672, top_k: 0.906914, samples/s: 2232.005 1612442365.5550687
train: epoch 147, iter 900, loss: 2.340949, top_1: 0.745508, top_k: 0.904727, samples/s: 2241.146 1612442376.9777377
train: epoch 147, iter 1000, loss: 2.112135, top_1: 0.748047, top_k: 0.904180, samples/s: 2217.597 1612442388.5217533
train: epoch 147, iter 1100, loss: 2.049614, top_1: 0.743711, top_k: 0.905742, samples/s: 2209.825 1612442400.1063795
train: epoch 147, iter 1200, loss: 2.188497, top_1: 0.746367, top_k: 0.903750, samples/s: 2224.666 1612442411.6137292
train: epoch 147, iter 1300, loss: 2.170521, top_1: 0.746953, top_k: 0.904531, samples/s: 2185.714 1612442423.326243
train: epoch 147, iter 1400, loss: 2.106613, top_1: 0.743945, top_k: 0.903086, samples/s: 2239.742 1612442434.7560453
train: epoch 147, iter 1500, loss: 2.124693, top_1: 0.745039, top_k: 0.904844, samples/s: 2220.029 1612442446.2874718
train: epoch 147, iter 1600, loss: 2.156539, top_1: 0.743203, top_k: 0.903477, samples/s: 2223.867 1612442457.7989037
train: epoch 147, iter 1700, loss: 2.019105, top_1: 0.741523, top_k: 0.903516, samples/s: 2209.818 1612442469.3835742
train: epoch 147, iter 1800, loss: 1.946996, top_1: 0.743242, top_k: 0.902969, samples/s: 2245.832 1612442480.7824624
train: epoch 147, iter 1900, loss: 2.098254, top_1: 0.742148, top_k: 0.904258, samples/s: 2208.250 1612442492.3753505
train: epoch 147, iter 2000, loss: 2.088583, top_1: 0.747930, top_k: 0.902734, samples/s: 2214.983 1612442503.9330442
train: epoch 147, iter 2100, loss: 2.065525, top_1: 0.745586, top_k: 0.900352, samples/s: 2221.612 1612442515.4561841
train: epoch 147, iter 2200, loss: 2.060777, top_1: 0.740586, top_k: 0.900977, samples/s: 2226.354 1612442526.9548535
train: epoch 147, iter 2300, loss: 2.012617, top_1: 0.748008, top_k: 0.904141, samples/s: 2228.488 1612442538.442433
train: epoch 147, iter 2400, loss: 2.092656, top_1: 0.747656, top_k: 0.905937, samples/s: 2228.894 1612442549.9280992
train: epoch 147, iter 2500, loss: 2.056575, top_1: 0.744375, top_k: 0.904492, samples/s: 2229.971 1612442561.4078784
train: epoch 147, iter 2600, loss: 1.895082, top_1: 0.750781, top_k: 0.905273, samples/s: 2247.673 1612442572.797437
train: epoch 147, iter 2700, loss: 1.892325, top_1: 0.745859, top_k: 0.904648, samples/s: 2231.826 1612442584.2678993
train: epoch 147, iter 2800, loss: 1.924275, top_1: 0.748047, top_k: 0.907539, samples/s: 2182.740 1612442595.9962695
train: epoch 147, iter 2900, loss: 1.963651, top_1: 0.743125, top_k: 0.903750, samples/s: 2244.224 1612442607.4033072
train: epoch 147, iter 3000, loss: 2.043688, top_1: 0.740508, top_k: 0.901016, samples/s: 2222.744 1612442618.9205947
train: epoch 147, iter 3100, loss: 1.997778, top_1: 0.744922, top_k: 0.902461, samples/s: 2227.227 1612442630.4148047
train: epoch 147, iter 3200, loss: 1.937728, top_1: 0.745781, top_k: 0.905664, samples/s: 2246.422 1612442641.8106077
train: epoch 147, iter 3300, loss: 2.254079, top_1: 0.742695, top_k: 0.902773, samples/s: 2225.240 1612442653.3150547
train: epoch 147, iter 3400, loss: 2.077302, top_1: 0.743984, top_k: 0.907422, samples/s: 2221.724 1612442664.8377454
train: epoch 147, iter 3500, loss: 2.134581, top_1: 0.747383, top_k: 0.902695, samples/s: 2245.905 1612442676.2360904
train: epoch 147, iter 3600, loss: 2.043336, top_1: 0.742305, top_k: 0.902109, samples/s: 2239.156 1612442687.6690042
train: epoch 147, iter 3700, loss: 2.007057, top_1: 0.740625, top_k: 0.904922, samples/s: 2236.396 1612442699.1159942
train: epoch 147, iter 3800, loss: 2.104654, top_1: 0.742148, top_k: 0.903125, samples/s: 2249.226 1612442710.4976509
train: epoch 147, iter 3900, loss: 2.175220, top_1: 0.744570, top_k: 0.903945, samples/s: 2227.607 1612442721.989836
train: epoch 147, iter 4000, loss: 2.076143, top_1: 0.743437, top_k: 0.903398, samples/s: 2220.407 1612442733.519318
train: epoch 147, iter 4100, loss: 2.089729, top_1: 0.745391, top_k: 0.906016, samples/s: 2235.924 1612442744.9686372
train: epoch 147, iter 4200, loss: 2.097808, top_1: 0.747422, top_k: 0.904062, samples/s: 2224.892 1612442756.4748144
train: epoch 147, iter 4300, loss: 2.103699, top_1: 0.741836, top_k: 0.905547, samples/s: 2232.539 1612442767.9415772
train: epoch 147, iter 4400, loss: 2.192059, top_1: 0.746484, top_k: 0.902891, samples/s: 2230.060 1612442779.4211073
train: epoch 147, iter 4500, loss: 2.224689, top_1: 0.744922, top_k: 0.901797, samples/s: 2208.225 1612442791.0144348
train: epoch 147, iter 4600, loss: 2.064859, top_1: 0.743672, top_k: 0.904219, samples/s: 2252.870 1612442802.3774045
train: epoch 147, iter 4700, loss: 1.953295, top_1: 0.744375, top_k: 0.904844, samples/s: 2236.278 1612442813.824947
train: epoch 147, iter 4800, loss: 1.932606, top_1: 0.746406, top_k: 0.903242, samples/s: 2228.002 1612442825.315134
train: epoch 147, iter 4900, loss: 2.070638, top_1: 0.744531, top_k: 0.901445, samples/s: 2238.127 1612442836.7532928
train: epoch 147, iter 5000, loss: 1.916315, top_1: 0.746563, top_k: 0.907734, samples/s: 2219.341 1612442848.2883372
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_147.
validation: epoch 147, iter 195, top_1: 0.746655, top_k: 0.918830, samples/s: 2853.317 1612442866.036727
train: epoch 148, iter 100, loss: 2.200694, top_1: 0.747266, top_k: 0.905312, samples/s: 2243.135 1612442893.3181486
train: epoch 148, iter 200, loss: 2.047668, top_1: 0.748867, top_k: 0.906602, samples/s: 2245.162 1612442904.720843
train: epoch 148, iter 300, loss: 1.985733, top_1: 0.740195, top_k: 0.902500, samples/s: 2245.667 1612442916.1201708
train: epoch 148, iter 400, loss: 2.074741, top_1: 0.748945, top_k: 0.906016, samples/s: 2247.799 1612442927.5094645
train: epoch 148, iter 500, loss: 2.046960, top_1: 0.748437, top_k: 0.905430, samples/s: 2250.596 1612442938.883853
train: epoch 148, iter 600, loss: 2.240090, top_1: 0.746914, top_k: 0.905352, samples/s: 2251.679 1612442950.2531614
train: epoch 148, iter 700, loss: 1.966301, top_1: 0.749219, top_k: 0.906016, samples/s: 2242.499 1612442961.6689713
train: epoch 148, iter 800, loss: 2.006881, top_1: 0.744180, top_k: 0.905352, samples/s: 2244.575 1612442973.0742693
train: epoch 148, iter 900, loss: 2.179916, top_1: 0.746289, top_k: 0.903984, samples/s: 2235.639 1612442984.525128
train: epoch 148, iter 1000, loss: 2.047114, top_1: 0.746406, top_k: 0.905234, samples/s: 2228.250 1612442996.0139544
train: epoch 148, iter 1100, loss: 2.034292, top_1: 0.745000, top_k: 0.903359, samples/s: 2216.030 1612443007.5662704
train: epoch 148, iter 1200, loss: 2.117946, top_1: 0.745078, top_k: 0.905625, samples/s: 2226.724 1612443019.0628502
train: epoch 148, iter 1300, loss: 1.962209, top_1: 0.746094, top_k: 0.902148, samples/s: 2216.313 1612443030.6138978
train: epoch 148, iter 1400, loss: 2.108413, top_1: 0.750273, top_k: 0.907383, samples/s: 2182.626 1612443042.342637
train: epoch 148, iter 1500, loss: 2.116485, top_1: 0.745977, top_k: 0.906875, samples/s: 2243.399 1612443053.7541642
train: epoch 148, iter 1600, loss: 2.204881, top_1: 0.739062, top_k: 0.904687, samples/s: 2225.290 1612443065.2579327
train: epoch 148, iter 1700, loss: 2.151967, top_1: 0.744141, top_k: 0.902734, samples/s: 2209.813 1612443076.8426282
train: epoch 148, iter 1800, loss: 1.982300, top_1: 0.747578, top_k: 0.907070, samples/s: 2212.750 1612443088.41196
train: epoch 148, iter 1900, loss: 2.263899, top_1: 0.747344, top_k: 0.905547, samples/s: 2221.896 1612443099.9336457
train: epoch 148, iter 2000, loss: 2.238037, top_1: 0.747109, top_k: 0.902656, samples/s: 2234.366 1612443111.3911092
train: epoch 148, iter 2100, loss: 2.064977, top_1: 0.747852, top_k: 0.908008, samples/s: 2239.900 1612443122.821139
train: epoch 148, iter 2200, loss: 2.105697, top_1: 0.747109, top_k: 0.905508, samples/s: 2239.416 1612443134.251651
train: epoch 148, iter 2300, loss: 1.812955, top_1: 0.746055, top_k: 0.904922, samples/s: 2238.985 1612443145.6854644
train: epoch 148, iter 2400, loss: 2.196573, top_1: 0.743242, top_k: 0.900078, samples/s: 2178.263 1612443157.437949
train: epoch 148, iter 2500, loss: 2.236099, top_1: 0.749180, top_k: 0.908438, samples/s: 2251.273 1612443168.8092127
train: epoch 148, iter 2600, loss: 2.246833, top_1: 0.745117, top_k: 0.902969, samples/s: 2234.966 1612443180.2635527
train: epoch 148, iter 2700, loss: 2.139160, top_1: 0.747188, top_k: 0.904180, samples/s: 2227.868 1612443191.7543585
train: epoch 148, iter 2800, loss: 2.040888, top_1: 0.749609, top_k: 0.905508, samples/s: 2223.774 1612443203.266332
train: epoch 148, iter 2900, loss: 2.097873, top_1: 0.747109, top_k: 0.904844, samples/s: 2249.712 1612443214.645559
train: epoch 148, iter 3000, loss: 1.996616, top_1: 0.744609, top_k: 0.904180, samples/s: 2179.019 1612443226.3940594
train: epoch 148, iter 3100, loss: 2.068073, top_1: 0.746992, top_k: 0.904922, samples/s: 2245.223 1612443237.795984
train: epoch 148, iter 3200, loss: 1.988781, top_1: 0.746953, top_k: 0.903750, samples/s: 2216.661 1612443249.3448577
train: epoch 148, iter 3300, loss: 1.933729, top_1: 0.748398, top_k: 0.905312, samples/s: 2233.936 1612443260.8044426
train: epoch 148, iter 3400, loss: 1.990134, top_1: 0.745664, top_k: 0.904297, samples/s: 2227.337 1612443272.2979808
train: epoch 148, iter 3500, loss: 1.904928, top_1: 0.743594, top_k: 0.903555, samples/s: 2219.260 1612443283.8333557
train: epoch 148, iter 3600, loss: 1.957725, top_1: 0.748437, top_k: 0.908008, samples/s: 2244.233 1612443295.2404065
train: epoch 148, iter 3700, loss: 2.078433, top_1: 0.747109, top_k: 0.905781, samples/s: 2241.099 1612443306.663336
train: epoch 148, iter 3800, loss: 2.019075, top_1: 0.751914, top_k: 0.907656, samples/s: 2225.974 1612443318.1639323
train: epoch 148, iter 3900, loss: 1.984789, top_1: 0.746602, top_k: 0.901992, samples/s: 2227.300 1612443329.657659
train: epoch 148, iter 4000, loss: 1.967104, top_1: 0.746523, top_k: 0.904727, samples/s: 2234.680 1612443341.1135042
train: epoch 148, iter 4100, loss: 2.078736, top_1: 0.745156, top_k: 0.902539, samples/s: 2245.108 1612443352.5160513
train: epoch 148, iter 4200, loss: 2.048116, top_1: 0.743242, top_k: 0.903047, samples/s: 2210.061 1612443364.0994902
train: epoch 148, iter 4300, loss: 2.092859, top_1: 0.747812, top_k: 0.903633, samples/s: 2255.887 1612443375.4474797
train: epoch 148, iter 4400, loss: 2.022056, top_1: 0.750117, top_k: 0.904961, samples/s: 2225.574 1612443386.9501398
train: epoch 148, iter 4500, loss: 2.022805, top_1: 0.745000, top_k: 0.905117, samples/s: 2237.423 1612443398.3919053
train: epoch 148, iter 4600, loss: 2.167068, top_1: 0.747188, top_k: 0.905977, samples/s: 2228.939 1612443409.8771806
train: epoch 148, iter 4700, loss: 2.097384, top_1: 0.744531, top_k: 0.901563, samples/s: 2257.658 1612443421.2163603
train: epoch 148, iter 4800, loss: 2.104945, top_1: 0.749727, top_k: 0.907539, samples/s: 2237.098 1612443432.659781
train: epoch 148, iter 4900, loss: 1.961194, top_1: 0.746133, top_k: 0.904570, samples/s: 2249.973 1612443444.0376518
train: epoch 148, iter 5000, loss: 2.090659, top_1: 0.751680, top_k: 0.905078, samples/s: 2206.733 1612443455.638511
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_148.
validation: epoch 148, iter 195, top_1: 0.747336, top_k: 0.919211, samples/s: 2861.883 1612443473.397489
train: epoch 149, iter 100, loss: 2.046522, top_1: 0.745117, top_k: 0.905586, samples/s: 2232.123 1612443500.9821575
train: epoch 149, iter 200, loss: 2.078046, top_1: 0.748437, top_k: 0.904961, samples/s: 2264.767 1612443512.2858098
train: epoch 149, iter 300, loss: 2.107031, top_1: 0.741055, top_k: 0.902500, samples/s: 2240.271 1612443523.7129579
train: epoch 149, iter 400, loss: 2.385453, top_1: 0.746836, top_k: 0.907422, samples/s: 2257.847 1612443535.0511801
train: epoch 149, iter 500, loss: 2.056629, top_1: 0.749687, top_k: 0.903555, samples/s: 2248.060 1612443546.4387848
train: epoch 149, iter 600, loss: 2.040497, top_1: 0.745938, top_k: 0.905156, samples/s: 2244.629 1612443557.8437746
train: epoch 149, iter 700, loss: 2.053401, top_1: 0.747578, top_k: 0.907422, samples/s: 2262.439 1612443569.159018
train: epoch 149, iter 800, loss: 1.958272, top_1: 0.749648, top_k: 0.903633, samples/s: 2233.278 1612443580.6220038
train: epoch 149, iter 900, loss: 1.984742, top_1: 0.749492, top_k: 0.906563, samples/s: 2230.829 1612443592.0975616
train: epoch 149, iter 1000, loss: 1.927395, top_1: 0.745234, top_k: 0.905117, samples/s: 2224.017 1612443603.608772
train: epoch 149, iter 1100, loss: 2.028915, top_1: 0.748945, top_k: 0.907813, samples/s: 2210.949 1612443615.186978
train: epoch 149, iter 1200, loss: 2.074153, top_1: 0.741445, top_k: 0.900781, samples/s: 2236.129 1612443626.636331
train: epoch 149, iter 1300, loss: 2.087313, top_1: 0.746719, top_k: 0.906211, samples/s: 2212.191 1612443638.2076147
train: epoch 149, iter 1400, loss: 2.041641, top_1: 0.746758, top_k: 0.902813, samples/s: 2225.786 1612443649.7091851
train: epoch 149, iter 1500, loss: 2.171679, top_1: 0.748945, top_k: 0.906484, samples/s: 2231.424 1612443661.1816638
train: epoch 149, iter 1600, loss: 2.106164, top_1: 0.750859, top_k: 0.907578, samples/s: 2237.658 1612443672.6221876
train: epoch 149, iter 1700, loss: 2.018009, top_1: 0.747109, top_k: 0.908477, samples/s: 2230.851 1612443684.0975847
train: epoch 149, iter 1800, loss: 2.127331, top_1: 0.748516, top_k: 0.903359, samples/s: 2228.114 1612443695.5871162
train: epoch 149, iter 1900, loss: 2.179592, top_1: 0.751719, top_k: 0.906211, samples/s: 2237.675 1612443707.027569
train: epoch 149, iter 2000, loss: 1.981192, top_1: 0.749492, top_k: 0.905781, samples/s: 2212.325 1612443718.5991786
train: epoch 149, iter 2100, loss: 2.065172, top_1: 0.743984, top_k: 0.904453, samples/s: 2231.979 1612443730.0687392
train: epoch 149, iter 2200, loss: 2.172598, top_1: 0.745273, top_k: 0.902617, samples/s: 2210.296 1612443741.6509812
train: epoch 149, iter 2300, loss: 2.046558, top_1: 0.748164, top_k: 0.908164, samples/s: 2230.807 1612443753.1266255
train: epoch 149, iter 2400, loss: 1.893759, top_1: 0.749531, top_k: 0.908086, samples/s: 2224.904 1612443764.6326845
train: epoch 149, iter 2500, loss: 2.093771, top_1: 0.751680, top_k: 0.906250, samples/s: 2214.923 1612443776.190676
train: epoch 149, iter 2600, loss: 2.015162, top_1: 0.746797, top_k: 0.906641, samples/s: 2223.567 1612443787.70368
train: epoch 149, iter 2700, loss: 2.101102, top_1: 0.750352, top_k: 0.910195, samples/s: 2232.554 1612443799.170413
train: epoch 149, iter 2800, loss: 1.961318, top_1: 0.750820, top_k: 0.903125, samples/s: 2235.843 1612443810.6201994
train: epoch 149, iter 2900, loss: 2.000254, top_1: 0.750898, top_k: 0.906992, samples/s: 2209.650 1612443822.2057397
train: epoch 149, iter 3000, loss: 2.191982, top_1: 0.747266, top_k: 0.904102, samples/s: 2223.203 1612443833.7206566
train: epoch 149, iter 3100, loss: 2.050842, top_1: 0.751680, top_k: 0.908828, samples/s: 2212.243 1612443845.292645
train: epoch 149, iter 3200, loss: 2.125722, top_1: 0.748945, top_k: 0.903906, samples/s: 2232.778 1612443856.7581527
train: epoch 149, iter 3300, loss: 2.064841, top_1: 0.752852, top_k: 0.908750, samples/s: 2238.895 1612443868.192362
train: epoch 149, iter 3400, loss: 2.113361, top_1: 0.748477, top_k: 0.903750, samples/s: 2250.160 1612443879.5694265
train: epoch 149, iter 3500, loss: 1.947308, top_1: 0.750117, top_k: 0.903828, samples/s: 2222.608 1612443891.0874145
train: epoch 149, iter 3600, loss: 2.148237, top_1: 0.744180, top_k: 0.905937, samples/s: 2237.416 1612443902.5291414
train: epoch 149, iter 3700, loss: 2.318964, top_1: 0.748867, top_k: 0.903750, samples/s: 2223.261 1612443914.0437908
train: epoch 149, iter 3800, loss: 2.041526, top_1: 0.749531, top_k: 0.903633, samples/s: 2238.193 1612443925.4815266
train: epoch 149, iter 3900, loss: 2.024450, top_1: 0.751094, top_k: 0.909336, samples/s: 2226.727 1612443936.9782295
train: epoch 149, iter 4000, loss: 2.209960, top_1: 0.751250, top_k: 0.904766, samples/s: 2248.439 1612443948.3640096
train: epoch 149, iter 4100, loss: 1.985341, top_1: 0.747031, top_k: 0.905820, samples/s: 2226.852 1612443959.859976
train: epoch 149, iter 4200, loss: 2.148424, top_1: 0.747070, top_k: 0.904961, samples/s: 2244.770 1612443971.2643044
train: epoch 149, iter 4300, loss: 1.942192, top_1: 0.753125, top_k: 0.910469, samples/s: 2226.783 1612443982.7606356
train: epoch 149, iter 4400, loss: 2.047787, top_1: 0.751523, top_k: 0.905703, samples/s: 2248.097 1612443994.1480663
train: epoch 149, iter 4500, loss: 2.116570, top_1: 0.747969, top_k: 0.906992, samples/s: 2241.712 1612444005.567919
train: epoch 149, iter 4600, loss: 1.981484, top_1: 0.749805, top_k: 0.907070, samples/s: 2237.106 1612444017.0112529
train: epoch 149, iter 4700, loss: 2.087956, top_1: 0.749922, top_k: 0.904141, samples/s: 2217.341 1612444028.5566044
train: epoch 149, iter 4800, loss: 2.068664, top_1: 0.747852, top_k: 0.906367, samples/s: 2235.558 1612444040.0078855
train: epoch 149, iter 4900, loss: 2.074685, top_1: 0.754023, top_k: 0.910508, samples/s: 2235.195 1612444051.461069
train: epoch 149, iter 5000, loss: 2.070446, top_1: 0.751992, top_k: 0.907617, samples/s: 2239.495 1612444062.8922393
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_149.
validation: epoch 149, iter 195, top_1: 0.742087, top_k: 0.917027, samples/s: 2888.985 1612444080.5113175
train: epoch 150, iter 100, loss: 1.894758, top_1: 0.752227, top_k: 0.908516, samples/s: 2218.366 1612444107.5867248
train: epoch 150, iter 200, loss: 1.996470, top_1: 0.747617, top_k: 0.902852, samples/s: 2261.112 1612444118.9085968
train: epoch 150, iter 300, loss: 2.078850, top_1: 0.751055, top_k: 0.905703, samples/s: 2252.311 1612444130.2746348
train: epoch 150, iter 400, loss: 1.871225, top_1: 0.748086, top_k: 0.906406, samples/s: 2257.240 1612444141.6159136
train: epoch 150, iter 500, loss: 1.850531, top_1: 0.751875, top_k: 0.908398, samples/s: 2236.482 1612444153.0624645
train: epoch 150, iter 600, loss: 1.949992, top_1: 0.746328, top_k: 0.905508, samples/s: 2232.154 1612444164.531221
train: epoch 150, iter 700, loss: 2.055145, top_1: 0.748867, top_k: 0.907148, samples/s: 2223.787 1612444176.0431614
train: epoch 150, iter 800, loss: 2.124967, top_1: 0.754844, top_k: 0.907773, samples/s: 2241.413 1612444187.4644678
train: epoch 150, iter 900, loss: 1.926025, top_1: 0.751250, top_k: 0.907422, samples/s: 2243.660 1612444198.8743885
train: epoch 150, iter 1000, loss: 2.140010, top_1: 0.747031, top_k: 0.906328, samples/s: 2230.702 1612444210.3506064
train: epoch 150, iter 1100, loss: 2.029248, top_1: 0.750195, top_k: 0.906484, samples/s: 2259.947 1612444221.6782548
train: epoch 150, iter 1200, loss: 2.154895, top_1: 0.750313, top_k: 0.906953, samples/s: 2221.700 1612444233.2010467
train: epoch 150, iter 1300, loss: 1.966251, top_1: 0.747539, top_k: 0.906406, samples/s: 2239.028 1612444244.6346009
train: epoch 150, iter 1400, loss: 2.078360, top_1: 0.749883, top_k: 0.904844, samples/s: 2241.255 1612444256.0567057
train: epoch 150, iter 1500, loss: 1.976017, top_1: 0.752305, top_k: 0.906445, samples/s: 2239.915 1612444267.4857123
train: epoch 150, iter 1600, loss: 2.102024, top_1: 0.749453, top_k: 0.905430, samples/s: 2217.552 1612444279.0299764
train: epoch 150, iter 1700, loss: 2.019652, top_1: 0.747227, top_k: 0.905781, samples/s: 2223.254 1612444290.5446641
train: epoch 150, iter 1800, loss: 2.002058, top_1: 0.744766, top_k: 0.905117, samples/s: 2242.515 1612444301.960514
train: epoch 150, iter 1900, loss: 1.933323, top_1: 0.747539, top_k: 0.905898, samples/s: 2226.042 1612444313.4606304
train: epoch 150, iter 2000, loss: 1.977039, top_1: 0.751055, top_k: 0.907695, samples/s: 2238.184 1612444324.8984776
train: epoch 150, iter 2100, loss: 1.884727, top_1: 0.754609, top_k: 0.907344, samples/s: 2223.243 1612444336.4131808
train: epoch 150, iter 2200, loss: 2.143981, top_1: 0.749922, top_k: 0.907266, samples/s: 2240.825 1612444347.8375325
train: epoch 150, iter 2300, loss: 2.238218, top_1: 0.749648, top_k: 0.905039, samples/s: 2232.955 1612444359.3021948
train: epoch 150, iter 2400, loss: 2.129597, top_1: 0.749180, top_k: 0.907852, samples/s: 2209.644 1612444370.887758
train: epoch 150, iter 2500, loss: 2.049380, top_1: 0.747344, top_k: 0.905273, samples/s: 2235.249 1612444382.3406796
train: epoch 150, iter 2600, loss: 2.036018, top_1: 0.748477, top_k: 0.907734, samples/s: 2224.432 1612444393.8491547
train: epoch 150, iter 2700, loss: 2.043426, top_1: 0.749648, top_k: 0.904766, samples/s: 2243.813 1612444405.2583349
train: epoch 150, iter 2800, loss: 2.027532, top_1: 0.752695, top_k: 0.909648, samples/s: 2231.105 1612444416.7324557
train: epoch 150, iter 2900, loss: 2.012042, top_1: 0.747344, top_k: 0.904687, samples/s: 2243.211 1612444428.1446903
train: epoch 150, iter 3000, loss: 2.100584, top_1: 0.744805, top_k: 0.902422, samples/s: 2224.754 1612444439.6515877
train: epoch 150, iter 3100, loss: 2.026616, top_1: 0.751172, top_k: 0.908711, samples/s: 2250.655 1612444451.0260377
train: epoch 150, iter 3200, loss: 2.047420, top_1: 0.748633, top_k: 0.903984, samples/s: 2243.362 1612444462.437801
train: epoch 150, iter 3300, loss: 2.088701, top_1: 0.751484, top_k: 0.906406, samples/s: 2243.851 1612444473.8464348
train: epoch 150, iter 3400, loss: 2.036825, top_1: 0.748828, top_k: 0.908125, samples/s: 2234.166 1612444485.305185
train: epoch 150, iter 3500, loss: 2.122211, top_1: 0.754922, top_k: 0.908672, samples/s: 2220.760 1612444496.8325129
train: epoch 150, iter 3600, loss: 2.037542, top_1: 0.748516, top_k: 0.903789, samples/s: 2237.583 1612444508.2733665
train: epoch 150, iter 3700, loss: 2.093562, top_1: 0.749805, top_k: 0.905781, samples/s: 2225.389 1612444519.7769473
train: epoch 150, iter 3800, loss: 1.956609, top_1: 0.750820, top_k: 0.907383, samples/s: 2232.603 1612444531.2433863
train: epoch 150, iter 3900, loss: 2.023190, top_1: 0.747305, top_k: 0.904375, samples/s: 2229.901 1612444542.7237525
train: epoch 150, iter 4000, loss: 2.061220, top_1: 0.746367, top_k: 0.905117, samples/s: 2270.010 1612444554.001277
train: epoch 150, iter 4100, loss: 2.044318, top_1: 0.742148, top_k: 0.905547, samples/s: 2227.148 1612444565.495724
train: epoch 150, iter 4200, loss: 2.020361, top_1: 0.754961, top_k: 0.909922, samples/s: 2232.654 1612444576.9619308
train: epoch 150, iter 4300, loss: 1.986396, top_1: 0.749414, top_k: 0.907578, samples/s: 2238.896 1612444588.3960931
train: epoch 150, iter 4400, loss: 2.022384, top_1: 0.746797, top_k: 0.905273, samples/s: 2221.166 1612444599.9216914
train: epoch 150, iter 4500, loss: 2.143530, top_1: 0.748164, top_k: 0.906523, samples/s: 2238.850 1612444611.3560612
train: epoch 150, iter 4600, loss: 2.091448, top_1: 0.748828, top_k: 0.905742, samples/s: 2236.134 1612444622.8043556
train: epoch 150, iter 4700, loss: 2.069735, top_1: 0.745664, top_k: 0.906133, samples/s: 2225.572 1612444634.3070133
train: epoch 150, iter 4800, loss: 1.967150, top_1: 0.751211, top_k: 0.906289, samples/s: 2246.034 1612444645.7048912
train: epoch 150, iter 4900, loss: 1.997625, top_1: 0.753086, top_k: 0.907891, samples/s: 2237.642 1612444657.1455443
train: epoch 150, iter 5000, loss: 2.005187, top_1: 0.752773, top_k: 0.908516, samples/s: 2229.280 1612444668.6290202
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_150.
validation: epoch 150, iter 195, top_1: 0.741867, top_k: 0.916627, samples/s: 2913.203 1612444686.0681376
train: epoch 151, iter 100, loss: 2.018411, top_1: 0.752500, top_k: 0.909648, samples/s: 2246.557 1612444713.1758034
train: epoch 151, iter 200, loss: 2.163570, top_1: 0.753203, top_k: 0.905547, samples/s: 2257.911 1612444724.513706
train: epoch 151, iter 300, loss: 2.001249, top_1: 0.747930, top_k: 0.903750, samples/s: 2247.969 1612444735.9017704
train: epoch 151, iter 400, loss: 1.890987, top_1: 0.754023, top_k: 0.908164, samples/s: 2233.820 1612444747.3619726
train: epoch 151, iter 500, loss: 2.266974, top_1: 0.752578, top_k: 0.907852, samples/s: 2280.258 1612444758.588737
train: epoch 151, iter 600, loss: 2.093381, top_1: 0.746602, top_k: 0.905312, samples/s: 2253.662 1612444769.9480495
train: epoch 151, iter 700, loss: 1.963959, top_1: 0.752773, top_k: 0.908555, samples/s: 2220.853 1612444781.4751563
train: epoch 151, iter 800, loss: 1.910884, top_1: 0.749023, top_k: 0.907344, samples/s: 2239.561 1612444792.9060214
train: epoch 151, iter 900, loss: 2.113729, top_1: 0.743242, top_k: 0.903945, samples/s: 2232.036 1612444804.375459
train: epoch 151, iter 1000, loss: 2.143837, top_1: 0.745938, top_k: 0.907305, samples/s: 2235.356 1612444815.8279922
train: epoch 151, iter 1100, loss: 2.329669, top_1: 0.750039, top_k: 0.908750, samples/s: 2222.863 1612444827.344322
train: epoch 151, iter 1200, loss: 1.941369, top_1: 0.750039, top_k: 0.905234, samples/s: 2213.932 1612444838.9078014
train: epoch 151, iter 1300, loss: 2.186407, top_1: 0.747422, top_k: 0.904609, samples/s: 2233.408 1612444850.3697433
train: epoch 151, iter 1400, loss: 2.081509, top_1: 0.749961, top_k: 0.904336, samples/s: 2212.697 1612444861.93934
train: epoch 151, iter 1500, loss: 2.040028, top_1: 0.747227, top_k: 0.906641, samples/s: 2228.483 1612444873.426949
train: epoch 151, iter 1600, loss: 1.951604, top_1: 0.749766, top_k: 0.904766, samples/s: 2217.029 1612444884.9739573
train: epoch 151, iter 1700, loss: 2.198803, top_1: 0.744648, top_k: 0.902422, samples/s: 2243.708 1612444896.3836539
train: epoch 151, iter 1800, loss: 2.091964, top_1: 0.747891, top_k: 0.904961, samples/s: 2234.287 1612444907.8414528
train: epoch 151, iter 1900, loss: 2.085423, top_1: 0.751211, top_k: 0.906953, samples/s: 2221.321 1612444919.366532
train: epoch 151, iter 2000, loss: 2.047348, top_1: 0.745391, top_k: 0.906484, samples/s: 2234.792 1612444930.8213382
train: epoch 151, iter 2100, loss: 2.138722, top_1: 0.749609, top_k: 0.906719, samples/s: 2233.302 1612444942.2844906
train: epoch 151, iter 2200, loss: 1.971875, top_1: 0.752188, top_k: 0.909687, samples/s: 2242.826 1612444953.6983259
train: epoch 151, iter 2300, loss: 1.988587, top_1: 0.757617, top_k: 0.911836, samples/s: 2219.733 1612444965.2312684
train: epoch 151, iter 2400, loss: 2.263468, top_1: 0.750469, top_k: 0.905469, samples/s: 2177.741 1612444976.9869263
train: epoch 151, iter 2500, loss: 1.941446, top_1: 0.755156, top_k: 0.910859, samples/s: 2236.351 1612444988.4337385
train: epoch 151, iter 2600, loss: 2.142977, top_1: 0.748828, top_k: 0.905000, samples/s: 2237.072 1612444999.8773525
train: epoch 151, iter 2700, loss: 2.135728, top_1: 0.748320, top_k: 0.905391, samples/s: 2230.902 1612445011.3525453
train: epoch 151, iter 2800, loss: 1.976967, top_1: 0.748359, top_k: 0.905352, samples/s: 2234.684 1612445022.8088279
train: epoch 151, iter 2900, loss: 1.970370, top_1: 0.753125, top_k: 0.906523, samples/s: 2236.650 1612445034.2539284
train: epoch 151, iter 3000, loss: 2.061637, top_1: 0.747578, top_k: 0.905352, samples/s: 2238.790 1612445045.688705
train: epoch 151, iter 3100, loss: 2.034754, top_1: 0.749219, top_k: 0.908945, samples/s: 2228.316 1612445057.1772478
train: epoch 151, iter 3200, loss: 1.950365, top_1: 0.744844, top_k: 0.905391, samples/s: 2224.231 1612445068.6867576
train: epoch 151, iter 3300, loss: 2.078348, top_1: 0.755000, top_k: 0.903750, samples/s: 2234.874 1612445080.1415384
train: epoch 151, iter 3400, loss: 2.160031, top_1: 0.749727, top_k: 0.905859, samples/s: 2240.575 1612445091.567172
train: epoch 151, iter 3500, loss: 2.127905, top_1: 0.749961, top_k: 0.906484, samples/s: 2238.582 1612445103.0030265
train: epoch 151, iter 3600, loss: 2.153378, top_1: 0.748945, top_k: 0.908047, samples/s: 2236.515 1612445114.4493656
train: epoch 151, iter 3700, loss: 2.074547, top_1: 0.750781, top_k: 0.906211, samples/s: 2220.115 1612445125.980307
train: epoch 151, iter 3800, loss: 2.035514, top_1: 0.749375, top_k: 0.902539, samples/s: 2251.592 1612445137.3500686
train: epoch 151, iter 3900, loss: 2.006404, top_1: 0.743086, top_k: 0.903711, samples/s: 2225.622 1612445148.8524365
train: epoch 151, iter 4000, loss: 1.916949, top_1: 0.751680, top_k: 0.906055, samples/s: 2220.697 1612445160.3803766
train: epoch 151, iter 4100, loss: 2.058651, top_1: 0.748984, top_k: 0.906445, samples/s: 2239.003 1612445171.814013
train: epoch 151, iter 4200, loss: 2.081031, top_1: 0.747930, top_k: 0.903906, samples/s: 2229.043 1612445183.2987573
train: epoch 151, iter 4300, loss: 2.131371, top_1: 0.751055, top_k: 0.906367, samples/s: 2236.476 1612445194.7453375
train: epoch 151, iter 4400, loss: 2.032851, top_1: 0.750859, top_k: 0.904961, samples/s: 2230.728 1612445206.2214265
train: epoch 151, iter 4500, loss: 2.102307, top_1: 0.753281, top_k: 0.907813, samples/s: 2238.948 1612445217.6554272
train: epoch 151, iter 4600, loss: 2.048124, top_1: 0.747383, top_k: 0.905430, samples/s: 2239.470 1612445229.0866272
train: epoch 151, iter 4700, loss: 1.987139, top_1: 0.748164, top_k: 0.904805, samples/s: 2224.114 1612445240.5968328
train: epoch 151, iter 4800, loss: 2.047956, top_1: 0.750508, top_k: 0.905625, samples/s: 2244.298 1612445252.0035338
train: epoch 151, iter 4900, loss: 2.108069, top_1: 0.753242, top_k: 0.909766, samples/s: 2226.499 1612445263.5014024
train: epoch 151, iter 5000, loss: 2.053988, top_1: 0.752500, top_k: 0.906250, samples/s: 2227.698 1612445274.9930832
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_151.
validation: epoch 151, iter 195, top_1: 0.747075, top_k: 0.920192, samples/s: 2907.799 1612445292.4414964
train: epoch 152, iter 100, loss: 2.042912, top_1: 0.748867, top_k: 0.902227, samples/s: 2231.598 1612445320.1019561
train: epoch 152, iter 200, loss: 1.955822, top_1: 0.757773, top_k: 0.910234, samples/s: 2257.484 1612445331.4420083
train: epoch 152, iter 300, loss: 2.060759, top_1: 0.750469, top_k: 0.907383, samples/s: 2251.598 1612445342.8117163
train: epoch 152, iter 400, loss: 2.137162, top_1: 0.748281, top_k: 0.904336, samples/s: 2210.331 1612445354.39374
train: epoch 152, iter 500, loss: 2.065879, top_1: 0.750234, top_k: 0.906406, samples/s: 2271.859 1612445365.6619906
train: epoch 152, iter 600, loss: 2.025659, top_1: 0.748437, top_k: 0.908477, samples/s: 2225.217 1612445377.1665144
train: epoch 152, iter 700, loss: 1.992149, top_1: 0.750781, top_k: 0.905234, samples/s: 2232.982 1612445388.6311066
train: epoch 152, iter 800, loss: 1.933439, top_1: 0.750195, top_k: 0.907969, samples/s: 2235.017 1612445400.0850492
train: epoch 152, iter 900, loss: 2.052930, top_1: 0.754922, top_k: 0.909062, samples/s: 2235.912 1612445411.5345416
train: epoch 152, iter 1000, loss: 1.847267, top_1: 0.756211, top_k: 0.910312, samples/s: 2219.635 1612445423.0679307
train: epoch 152, iter 1100, loss: 2.098238, top_1: 0.751211, top_k: 0.909492, samples/s: 2203.291 1612445434.6869464
train: epoch 152, iter 1200, loss: 2.018287, top_1: 0.751914, top_k: 0.907734, samples/s: 2199.954 1612445446.3235943
train: epoch 152, iter 1300, loss: 1.957384, top_1: 0.747109, top_k: 0.905195, samples/s: 2235.891 1612445457.7730892
train: epoch 152, iter 1400, loss: 2.010418, top_1: 0.748516, top_k: 0.906836, samples/s: 2227.546 1612445469.2656121
train: epoch 152, iter 1500, loss: 2.057777, top_1: 0.751563, top_k: 0.906133, samples/s: 2229.459 1612445480.7481647
train: epoch 152, iter 1600, loss: 2.163421, top_1: 0.753281, top_k: 0.910156, samples/s: 2238.992 1612445492.1818905
train: epoch 152, iter 1700, loss: 1.884685, top_1: 0.751289, top_k: 0.907930, samples/s: 2240.430 1612445503.6082785
train: epoch 152, iter 1800, loss: 2.014695, top_1: 0.750859, top_k: 0.909023, samples/s: 2212.194 1612445515.1805143
train: epoch 152, iter 1900, loss: 1.965003, top_1: 0.749531, top_k: 0.906680, samples/s: 2247.466 1612445526.5710971
train: epoch 152, iter 2000, loss: 1.969031, top_1: 0.752891, top_k: 0.907891, samples/s: 2234.877 1612445538.0258567
train: epoch 152, iter 2100, loss: 2.067918, top_1: 0.756641, top_k: 0.909102, samples/s: 2228.262 1612445549.5146737
train: epoch 152, iter 2200, loss: 2.068878, top_1: 0.752891, top_k: 0.909258, samples/s: 2226.750 1612445561.0120945
train: epoch 152, iter 2300, loss: 1.948751, top_1: 0.754766, top_k: 0.909297, samples/s: 2240.318 1612445572.4381642
train: epoch 152, iter 2400, loss: 1.952514, top_1: 0.752305, top_k: 0.909297, samples/s: 2236.580 1612445583.884675
train: epoch 152, iter 2500, loss: 2.174277, top_1: 0.748906, top_k: 0.903672, samples/s: 2218.925 1612445595.421311
train: epoch 152, iter 2600, loss: 2.210078, top_1: 0.748789, top_k: 0.905547, samples/s: 2225.516 1612445606.9244037
train: epoch 152, iter 2700, loss: 2.027272, top_1: 0.750703, top_k: 0.907617, samples/s: 2220.400 1612445618.4537385
train: epoch 152, iter 2800, loss: 2.114694, top_1: 0.751406, top_k: 0.905859, samples/s: 2235.354 1612445629.9060483
train: epoch 152, iter 2900, loss: 2.061967, top_1: 0.750000, top_k: 0.904336, samples/s: 2223.520 1612445641.41938
train: epoch 152, iter 3000, loss: 2.092053, top_1: 0.750625, top_k: 0.908320, samples/s: 2257.762 1612445652.7579834
train: epoch 152, iter 3100, loss: 2.058806, top_1: 0.751055, top_k: 0.907383, samples/s: 2231.373 1612445664.2308366
train: epoch 152, iter 3200, loss: 1.973552, top_1: 0.750313, top_k: 0.905898, samples/s: 2221.034 1612445675.756906
train: epoch 152, iter 3300, loss: 2.108623, top_1: 0.747656, top_k: 0.906055, samples/s: 2235.981 1612445687.2061539
train: epoch 152, iter 3400, loss: 1.983297, top_1: 0.745742, top_k: 0.905430, samples/s: 2235.774 1612445698.6561925
train: epoch 152, iter 3500, loss: 2.009749, top_1: 0.750977, top_k: 0.907695, samples/s: 2220.056 1612445710.1875057
train: epoch 152, iter 3600, loss: 2.108148, top_1: 0.749883, top_k: 0.905625, samples/s: 2215.626 1612445721.7417464
train: epoch 152, iter 3700, loss: 1.997258, top_1: 0.750469, top_k: 0.907461, samples/s: 2250.974 1612445733.1145916
train: epoch 152, iter 3800, loss: 2.076675, top_1: 0.747500, top_k: 0.907773, samples/s: 2210.063 1612445744.6979675
train: epoch 152, iter 3900, loss: 1.987920, top_1: 0.752461, top_k: 0.905156, samples/s: 2231.767 1612445756.1687365
train: epoch 152, iter 4000, loss: 2.198632, top_1: 0.747109, top_k: 0.906328, samples/s: 2241.062 1612445767.5918453
train: epoch 152, iter 4100, loss: 2.071285, top_1: 0.753203, top_k: 0.907734, samples/s: 2236.061 1612445779.040565
train: epoch 152, iter 4200, loss: 1.966236, top_1: 0.746250, top_k: 0.906563, samples/s: 2215.635 1612445790.594854
train: epoch 152, iter 4300, loss: 2.037946, top_1: 0.747070, top_k: 0.905625, samples/s: 2242.366 1612445802.011313
train: epoch 152, iter 4400, loss: 2.079517, top_1: 0.750078, top_k: 0.906172, samples/s: 2247.395 1612445813.4022899
train: epoch 152, iter 4500, loss: 2.083771, top_1: 0.754102, top_k: 0.906094, samples/s: 2234.714 1612445824.8578806
train: epoch 152, iter 4600, loss: 2.026102, top_1: 0.747578, top_k: 0.905000, samples/s: 2207.253 1612445836.4560113
train: epoch 152, iter 4700, loss: 1.999749, top_1: 0.752461, top_k: 0.907422, samples/s: 2247.411 1612445847.8468907
train: epoch 152, iter 4800, loss: 2.054070, top_1: 0.748906, top_k: 0.905508, samples/s: 2231.686 1612445859.3181083
train: epoch 152, iter 4900, loss: 2.182844, top_1: 0.753555, top_k: 0.908672, samples/s: 2212.477 1612445870.888792
train: epoch 152, iter 5000, loss: 2.006893, top_1: 0.751641, top_k: 0.908672, samples/s: 2243.254 1612445882.3008149
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_152.
validation: epoch 152, iter 195, top_1: 0.740485, top_k: 0.915064, samples/s: 2904.673 1612445899.7836418
train: epoch 153, iter 100, loss: 2.041831, top_1: 0.750078, top_k: 0.907656, samples/s: 2245.424 1612445927.2351892
train: epoch 153, iter 200, loss: 2.114826, top_1: 0.753750, top_k: 0.907500, samples/s: 2241.424 1612445938.6566093
train: epoch 153, iter 300, loss: 1.945261, top_1: 0.753555, top_k: 0.908359, samples/s: 2257.968 1612445949.994117
train: epoch 153, iter 400, loss: 2.019414, top_1: 0.753242, top_k: 0.909297, samples/s: 2218.236 1612445961.534863
train: epoch 153, iter 500, loss: 1.963043, top_1: 0.754414, top_k: 0.911094, samples/s: 2269.361 1612445972.8155756
train: epoch 153, iter 600, loss: 2.209125, top_1: 0.752070, top_k: 0.906406, samples/s: 2264.625 1612445984.1198719
train: epoch 153, iter 700, loss: 2.162614, top_1: 0.751406, top_k: 0.907539, samples/s: 2250.516 1612445995.495033
train: epoch 153, iter 800, loss: 1.929067, top_1: 0.749141, top_k: 0.907539, samples/s: 2216.285 1612446007.0459907
train: epoch 153, iter 900, loss: 2.000742, top_1: 0.748750, top_k: 0.905742, samples/s: 2226.845 1612446018.5420203
train: epoch 153, iter 1000, loss: 1.978813, top_1: 0.754180, top_k: 0.909648, samples/s: 2195.113 1612446030.204229
train: epoch 153, iter 1100, loss: 1.976662, top_1: 0.752148, top_k: 0.908984, samples/s: 2211.441 1612446041.7804458
train: epoch 153, iter 1200, loss: 2.055524, top_1: 0.747070, top_k: 0.907031, samples/s: 2225.046 1612446053.2857547
train: epoch 153, iter 1300, loss: 2.074985, top_1: 0.750352, top_k: 0.909219, samples/s: 2225.616 1612446064.7881944
train: epoch 153, iter 1400, loss: 2.147814, top_1: 0.746445, top_k: 0.904648, samples/s: 2233.850 1612446076.2482293
train: epoch 153, iter 1500, loss: 2.168766, top_1: 0.754414, top_k: 0.905469, samples/s: 2227.843 1612446087.7391827
train: epoch 153, iter 1600, loss: 1.983959, top_1: 0.748242, top_k: 0.905703, samples/s: 2229.023 1612446099.2240572
train: epoch 153, iter 1700, loss: 2.136662, top_1: 0.751953, top_k: 0.906133, samples/s: 2229.364 1612446110.707136
train: epoch 153, iter 1800, loss: 2.004852, top_1: 0.750703, top_k: 0.906367, samples/s: 2233.167 1612446122.1706445
train: epoch 153, iter 1900, loss: 2.078201, top_1: 0.748516, top_k: 0.905156, samples/s: 2190.638 1612446133.8567953
train: epoch 153, iter 2000, loss: 2.055705, top_1: 0.752539, top_k: 0.909805, samples/s: 2247.770 1612446145.245865
train: epoch 153, iter 2100, loss: 2.164885, top_1: 0.749609, top_k: 0.904531, samples/s: 2222.884 1612446156.7625415
train: epoch 153, iter 2200, loss: 2.214135, top_1: 0.749336, top_k: 0.907852, samples/s: 2232.342 1612446168.2305257
train: epoch 153, iter 2300, loss: 2.098143, top_1: 0.748516, top_k: 0.905273, samples/s: 2208.210 1612446179.8233852
train: epoch 153, iter 2400, loss: 1.917307, top_1: 0.751953, top_k: 0.906953, samples/s: 2249.009 1612446191.2060895
train: epoch 153, iter 2500, loss: 1.915776, top_1: 0.750547, top_k: 0.909922, samples/s: 2216.505 1612446202.7561736
train: epoch 153, iter 2600, loss: 2.016694, top_1: 0.751836, top_k: 0.908594, samples/s: 2235.717 1612446214.2062392
train: epoch 153, iter 2700, loss: 2.119955, top_1: 0.748906, top_k: 0.906836, samples/s: 2243.843 1612446225.6152494
train: epoch 153, iter 2800, loss: 2.128229, top_1: 0.745391, top_k: 0.902500, samples/s: 2240.157 1612446237.0430336
train: epoch 153, iter 2900, loss: 2.064357, top_1: 0.751602, top_k: 0.907344, samples/s: 2236.824 1612446248.487828
train: epoch 153, iter 3000, loss: 2.106132, top_1: 0.752500, top_k: 0.908789, samples/s: 2207.915 1612446260.0824435
train: epoch 153, iter 3100, loss: 2.034293, top_1: 0.749883, top_k: 0.906523, samples/s: 2251.729 1612446271.4514937
train: epoch 153, iter 3200, loss: 2.025985, top_1: 0.754648, top_k: 0.906992, samples/s: 2237.913 1612446282.890722
train: epoch 153, iter 3300, loss: 2.000321, top_1: 0.747383, top_k: 0.906563, samples/s: 2236.414 1612446294.337647
train: epoch 153, iter 3400, loss: 2.023806, top_1: 0.752109, top_k: 0.909336, samples/s: 2238.599 1612446305.7733576
train: epoch 153, iter 3500, loss: 2.051448, top_1: 0.756094, top_k: 0.909727, samples/s: 2240.984 1612446317.1970394
train: epoch 153, iter 3600, loss: 2.193337, top_1: 0.751250, top_k: 0.904883, samples/s: 2226.666 1612446328.6943223
train: epoch 153, iter 3700, loss: 2.333255, top_1: 0.753594, top_k: 0.908086, samples/s: 2236.339 1612446340.1411965
train: epoch 153, iter 3800, loss: 1.937233, top_1: 0.750391, top_k: 0.907266, samples/s: 2234.282 1612446351.5993366
train: epoch 153, iter 3900, loss: 1.962137, top_1: 0.749336, top_k: 0.906445, samples/s: 2234.024 1612446363.0581448
train: epoch 153, iter 4000, loss: 1.922895, top_1: 0.747188, top_k: 0.908320, samples/s: 2219.339 1612446374.5931225
train: epoch 153, iter 4100, loss: 1.979774, top_1: 0.748359, top_k: 0.907422, samples/s: 2255.988 1612446385.9406958
train: epoch 153, iter 4200, loss: 2.079939, top_1: 0.751328, top_k: 0.906445, samples/s: 2243.673 1612446397.3505526
train: epoch 153, iter 4300, loss: 1.919382, top_1: 0.751406, top_k: 0.906719, samples/s: 2236.539 1612446408.7968311
train: epoch 153, iter 4400, loss: 1.896798, top_1: 0.752188, top_k: 0.905078, samples/s: 2221.318 1612446420.3215258
train: epoch 153, iter 4500, loss: 2.237005, top_1: 0.751563, top_k: 0.908242, samples/s: 2228.799 1612446431.8075104
train: epoch 153, iter 4600, loss: 2.057718, top_1: 0.749141, top_k: 0.908477, samples/s: 2239.011 1612446443.2411218
train: epoch 153, iter 4700, loss: 2.173487, top_1: 0.756094, top_k: 0.910430, samples/s: 2237.032 1612446454.6848361
train: epoch 153, iter 4800, loss: 1.999742, top_1: 0.752266, top_k: 0.905781, samples/s: 2238.491 1612446466.1211445
train: epoch 153, iter 4900, loss: 2.061978, top_1: 0.753398, top_k: 0.908594, samples/s: 2228.801 1612446477.6071296
train: epoch 153, iter 5000, loss: 2.102736, top_1: 0.749141, top_k: 0.907969, samples/s: 2230.424 1612446489.0848236
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_153.
validation: epoch 153, iter 195, top_1: 0.747196, top_k: 0.919792, samples/s: 2834.284 1612446507.0317192
train: epoch 154, iter 100, loss: 2.155422, top_1: 0.752344, top_k: 0.908555, samples/s: 2227.269 1612446534.8063047
train: epoch 154, iter 200, loss: 1.982517, top_1: 0.751406, top_k: 0.905273, samples/s: 2249.803 1612446546.1849375
train: epoch 154, iter 300, loss: 2.049840, top_1: 0.749531, top_k: 0.905977, samples/s: 2198.311 1612446557.8304627
train: epoch 154, iter 400, loss: 1.965121, top_1: 0.753867, top_k: 0.908320, samples/s: 2235.382 1612446569.2825794
train: epoch 154, iter 500, loss: 2.161636, top_1: 0.747500, top_k: 0.904961, samples/s: 2271.995 1612446580.5505428
train: epoch 154, iter 600, loss: 2.101482, top_1: 0.754531, top_k: 0.907266, samples/s: 2254.760 1612446591.9037898
train: epoch 154, iter 700, loss: 2.006696, top_1: 0.753281, top_k: 0.908047, samples/s: 2211.188 1612446603.4812663
train: epoch 154, iter 800, loss: 2.001677, top_1: 0.753320, top_k: 0.910469, samples/s: 2229.708 1612446614.9630127
train: epoch 154, iter 900, loss: 1.990126, top_1: 0.751523, top_k: 0.909492, samples/s: 2214.468 1612446626.5229714
train: epoch 154, iter 1000, loss: 1.959936, top_1: 0.750859, top_k: 0.908594, samples/s: 2222.989 1612446638.0390139
train: epoch 154, iter 1100, loss: 2.184340, top_1: 0.749531, top_k: 0.908438, samples/s: 2226.233 1612446649.538192
train: epoch 154, iter 1200, loss: 1.955947, top_1: 0.751094, top_k: 0.906680, samples/s: 2216.707 1612446661.0868776
train: epoch 154, iter 1300, loss: 2.106061, top_1: 0.755234, top_k: 0.909648, samples/s: 2230.894 1612446672.5620677
train: epoch 154, iter 1400, loss: 2.035325, top_1: 0.751055, top_k: 0.908555, samples/s: 2227.021 1612446684.0572596
train: epoch 154, iter 1500, loss: 2.051976, top_1: 0.751133, top_k: 0.907461, samples/s: 2230.881 1612446695.532543
train: epoch 154, iter 1600, loss: 2.042421, top_1: 0.750703, top_k: 0.905312, samples/s: 2223.690 1612446707.0449717
train: epoch 154, iter 1700, loss: 2.065433, top_1: 0.753281, top_k: 0.908984, samples/s: 2203.148 1612446718.6646633
train: epoch 154, iter 1800, loss: 2.055955, top_1: 0.753789, top_k: 0.904844, samples/s: 2262.839 1612446729.9779599
train: epoch 154, iter 1900, loss: 1.929262, top_1: 0.755781, top_k: 0.909180, samples/s: 2212.989 1612446741.5460541
train: epoch 154, iter 2000, loss: 2.213786, top_1: 0.752617, top_k: 0.907031, samples/s: 2253.934 1612446752.9039297
train: epoch 154, iter 2100, loss: 2.073615, top_1: 0.755625, top_k: 0.906289, samples/s: 2244.640 1612446764.3088663
train: epoch 154, iter 2200, loss: 2.010805, top_1: 0.748906, top_k: 0.906406, samples/s: 2233.813 1612446775.7690737
train: epoch 154, iter 2300, loss: 2.181054, top_1: 0.751797, top_k: 0.906367, samples/s: 2238.499 1612446787.2053468
train: epoch 154, iter 2400, loss: 2.018694, top_1: 0.755703, top_k: 0.907148, samples/s: 2205.879 1612446798.810629
train: epoch 154, iter 2500, loss: 2.038658, top_1: 0.752031, top_k: 0.906797, samples/s: 2251.548 1612446810.1805768
train: epoch 154, iter 2600, loss: 2.081805, top_1: 0.756641, top_k: 0.907930, samples/s: 2229.990 1612446821.660457
train: epoch 154, iter 2700, loss: 1.915398, top_1: 0.755938, top_k: 0.906641, samples/s: 2230.064 1612446833.140052
train: epoch 154, iter 2800, loss: 2.146982, top_1: 0.751563, top_k: 0.907344, samples/s: 2249.323 1612446844.5211563
train: epoch 154, iter 2900, loss: 2.102820, top_1: 0.753086, top_k: 0.907695, samples/s: 2227.503 1612446856.0138323
train: epoch 154, iter 3000, loss: 2.157678, top_1: 0.754922, top_k: 0.910234, samples/s: 2213.037 1612446867.581652
train: epoch 154, iter 3100, loss: 2.098405, top_1: 0.751094, top_k: 0.905937, samples/s: 2236.231 1612446879.0295174
train: epoch 154, iter 3200, loss: 1.954032, top_1: 0.746719, top_k: 0.906641, samples/s: 2241.537 1612446890.4502604
train: epoch 154, iter 3300, loss: 2.104289, top_1: 0.752969, top_k: 0.909570, samples/s: 2237.850 1612446901.8899603
train: epoch 154, iter 3400, loss: 2.010836, top_1: 0.751875, top_k: 0.907539, samples/s: 2233.317 1612446913.3526273
train: epoch 154, iter 3500, loss: 1.953947, top_1: 0.752656, top_k: 0.909375, samples/s: 2228.513 1612446924.8400183
train: epoch 154, iter 3600, loss: 2.083915, top_1: 0.747891, top_k: 0.902969, samples/s: 2230.315 1612446936.318223
train: epoch 154, iter 3700, loss: 2.070422, top_1: 0.748945, top_k: 0.908242, samples/s: 2236.524 1612446947.764628
train: epoch 154, iter 3800, loss: 2.152789, top_1: 0.750703, top_k: 0.905859, samples/s: 2227.790 1612446959.2557585
train: epoch 154, iter 3900, loss: 2.028411, top_1: 0.750234, top_k: 0.905781, samples/s: 2245.956 1612446970.6540244
train: epoch 154, iter 4000, loss: 2.105874, top_1: 0.755195, top_k: 0.909609, samples/s: 2227.165 1612446982.1484544
train: epoch 154, iter 4100, loss: 1.942421, top_1: 0.749844, top_k: 0.907734, samples/s: 2235.181 1612446993.6016626
train: epoch 154, iter 4200, loss: 2.028225, top_1: 0.750234, top_k: 0.910312, samples/s: 2234.083 1612447005.0605125
train: epoch 154, iter 4300, loss: 2.174246, top_1: 0.749180, top_k: 0.907031, samples/s: 2219.324 1612447016.595553
train: epoch 154, iter 4400, loss: 2.011093, top_1: 0.755234, top_k: 0.908086, samples/s: 2242.313 1612447028.012346
train: epoch 154, iter 4500, loss: 2.050198, top_1: 0.751133, top_k: 0.907227, samples/s: 2233.619 1612447039.4735725
train: epoch 154, iter 4600, loss: 2.091481, top_1: 0.752305, top_k: 0.906563, samples/s: 2220.816 1612447051.0008996
train: epoch 154, iter 4700, loss: 2.015328, top_1: 0.750117, top_k: 0.907070, samples/s: 2219.515 1612447062.5349627
train: epoch 154, iter 4800, loss: 1.874115, top_1: 0.747734, top_k: 0.906719, samples/s: 2225.243 1612447074.0392945
train: epoch 154, iter 4900, loss: 2.116374, top_1: 0.753437, top_k: 0.907109, samples/s: 2233.738 1612447085.4998798
train: epoch 154, iter 5000, loss: 1.974791, top_1: 0.755391, top_k: 0.908398, samples/s: 2245.443 1612447096.900763
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_154.
validation: epoch 154, iter 195, top_1: 0.749379, top_k: 0.920513, samples/s: 2910.842 1612447114.4301968
train: epoch 155, iter 100, loss: 1.976851, top_1: 0.755234, top_k: 0.909453, samples/s: 2245.067 1612447141.8420355
train: epoch 155, iter 200, loss: 2.028022, top_1: 0.754414, top_k: 0.907734, samples/s: 2248.952 1612447153.2250893
train: epoch 155, iter 300, loss: 2.171327, top_1: 0.753672, top_k: 0.909414, samples/s: 2253.887 1612447164.5832038
train: epoch 155, iter 400, loss: 1.920276, top_1: 0.750273, top_k: 0.905391, samples/s: 2248.915 1612447175.9665508
train: epoch 155, iter 500, loss: 2.073768, top_1: 0.752969, top_k: 0.909414, samples/s: 2258.674 1612447187.3006372
train: epoch 155, iter 600, loss: 2.093185, top_1: 0.750430, top_k: 0.906602, samples/s: 2228.368 1612447198.7888858
train: epoch 155, iter 700, loss: 2.026150, top_1: 0.751484, top_k: 0.906758, samples/s: 2259.617 1612447210.1182299
train: epoch 155, iter 800, loss: 2.098963, top_1: 0.752578, top_k: 0.908281, samples/s: 2248.467 1612447221.503759
train: epoch 155, iter 900, loss: 2.048209, top_1: 0.750195, top_k: 0.905469, samples/s: 2221.123 1612447233.0294135
train: epoch 155, iter 1000, loss: 2.082778, top_1: 0.752969, top_k: 0.908516, samples/s: 2200.241 1612447244.664549
train: epoch 155, iter 1100, loss: 1.970429, top_1: 0.750039, top_k: 0.908086, samples/s: 2213.906 1612447256.2278302
train: epoch 155, iter 1200, loss: 1.899517, top_1: 0.751445, top_k: 0.906523, samples/s: 2215.830 1612447267.7810156
train: epoch 155, iter 1300, loss: 1.948628, top_1: 0.744883, top_k: 0.903242, samples/s: 2214.758 1612447279.3399518
train: epoch 155, iter 1400, loss: 2.113938, top_1: 0.755859, top_k: 0.910820, samples/s: 2246.870 1612447290.7334602
train: epoch 155, iter 1500, loss: 2.058343, top_1: 0.749375, top_k: 0.906719, samples/s: 2186.147 1612447302.4435718
train: epoch 155, iter 1600, loss: 2.056433, top_1: 0.755156, top_k: 0.910156, samples/s: 2211.531 1612447314.0192506
train: epoch 155, iter 1700, loss: 2.129738, top_1: 0.749687, top_k: 0.905312, samples/s: 2184.442 1612447325.7384884
train: epoch 155, iter 1800, loss: 2.039795, top_1: 0.757188, top_k: 0.907227, samples/s: 2226.694 1612447337.2353532
train: epoch 155, iter 1900, loss: 1.980524, top_1: 0.748867, top_k: 0.904844, samples/s: 2208.550 1612447348.8267221
train: epoch 155, iter 2000, loss: 1.983049, top_1: 0.753359, top_k: 0.904844, samples/s: 2214.289 1612447360.3879986
train: epoch 155, iter 2100, loss: 2.268175, top_1: 0.751563, top_k: 0.907656, samples/s: 2209.467 1612447371.9744499
train: epoch 155, iter 2200, loss: 2.063603, top_1: 0.756523, top_k: 0.912188, samples/s: 2211.531 1612447383.5501523
train: epoch 155, iter 2300, loss: 2.085468, top_1: 0.754883, top_k: 0.906836, samples/s: 2212.612 1612447395.1202998
train: epoch 155, iter 2400, loss: 2.219374, top_1: 0.752734, top_k: 0.907266, samples/s: 2221.170 1612447406.6456969
train: epoch 155, iter 2500, loss: 1.939948, top_1: 0.756289, top_k: 0.910352, samples/s: 2205.290 1612447418.2541924
train: epoch 155, iter 2600, loss: 2.025846, top_1: 0.754805, top_k: 0.908945, samples/s: 2233.618 1612447429.7153542
train: epoch 155, iter 2700, loss: 2.009650, top_1: 0.753437, top_k: 0.908281, samples/s: 2232.953 1612447441.1799598
train: epoch 155, iter 2800, loss: 2.007232, top_1: 0.750586, top_k: 0.908203, samples/s: 2210.109 1612447452.7630792
train: epoch 155, iter 2900, loss: 2.146837, top_1: 0.754844, top_k: 0.907383, samples/s: 2259.693 1612447464.0920656
train: epoch 155, iter 3000, loss: 1.980897, top_1: 0.752695, top_k: 0.905820, samples/s: 2226.552 1612447475.5896533
train: epoch 155, iter 3100, loss: 2.066891, top_1: 0.753008, top_k: 0.907813, samples/s: 2227.706 1612447487.0813124
train: epoch 155, iter 3200, loss: 2.168143, top_1: 0.749570, top_k: 0.905586, samples/s: 2161.055 1612447498.9273713
train: epoch 155, iter 3300, loss: 2.174890, top_1: 0.752578, top_k: 0.906953, samples/s: 2220.424 1612447510.456743
train: epoch 155, iter 3400, loss: 2.155888, top_1: 0.753867, top_k: 0.906250, samples/s: 2241.776 1612447521.8762543
train: epoch 155, iter 3500, loss: 2.087547, top_1: 0.749141, top_k: 0.905156, samples/s: 2221.154 1612447533.4017506
train: epoch 155, iter 3600, loss: 2.027042, top_1: 0.752344, top_k: 0.907695, samples/s: 2236.131 1612447544.8501174
train: epoch 155, iter 3700, loss: 2.051464, top_1: 0.752148, top_k: 0.909219, samples/s: 2231.052 1612447556.3245163
train: epoch 155, iter 3800, loss: 2.130688, top_1: 0.751563, top_k: 0.908828, samples/s: 2218.681 1612447567.8629112
train: epoch 155, iter 3900, loss: 1.986808, top_1: 0.751289, top_k: 0.904180, samples/s: 2240.486 1612447579.288987
train: epoch 155, iter 4000, loss: 2.034986, top_1: 0.746563, top_k: 0.902891, samples/s: 2210.946 1612447590.867792
train: epoch 155, iter 4100, loss: 1.971212, top_1: 0.752266, top_k: 0.908672, samples/s: 2233.321 1612447602.330502
train: epoch 155, iter 4200, loss: 2.029468, top_1: 0.754219, top_k: 0.910234, samples/s: 2230.677 1612447613.806907
train: epoch 155, iter 4300, loss: 2.092482, top_1: 0.752344, top_k: 0.907891, samples/s: 2231.412 1612447625.2793932
train: epoch 155, iter 4400, loss: 1.978395, top_1: 0.751367, top_k: 0.907227, samples/s: 2224.912 1612447636.7858593
train: epoch 155, iter 4500, loss: 2.143649, top_1: 0.751992, top_k: 0.906289, samples/s: 2227.406 1612447648.2786703
train: epoch 155, iter 4600, loss: 2.192950, top_1: 0.755703, top_k: 0.908516, samples/s: 2232.767 1612447659.7442732
train: epoch 155, iter 4700, loss: 2.024242, top_1: 0.750430, top_k: 0.908008, samples/s: 2222.851 1612447671.261046
train: epoch 155, iter 4800, loss: 1.965720, top_1: 0.754062, top_k: 0.906992, samples/s: 2232.308 1612447682.7290208
train: epoch 155, iter 4900, loss: 1.947364, top_1: 0.749531, top_k: 0.905547, samples/s: 2225.789 1612447694.2305436
train: epoch 155, iter 5000, loss: 1.980741, top_1: 0.746172, top_k: 0.908555, samples/s: 2229.632 1612447705.7124772
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_155.
validation: epoch 155, iter 195, top_1: 0.748858, top_k: 0.920733, samples/s: 2894.422 1612447723.2503848
train: epoch 156, iter 100, loss: 2.048501, top_1: 0.756563, top_k: 0.909609, samples/s: 2222.375 1612447751.071502
train: epoch 156, iter 200, loss: 2.082417, top_1: 0.754727, top_k: 0.910234, samples/s: 2256.895 1612447762.4145205
train: epoch 156, iter 300, loss: 2.158628, top_1: 0.753242, top_k: 0.908086, samples/s: 2247.097 1612447773.807004
train: epoch 156, iter 400, loss: 2.098597, top_1: 0.752266, top_k: 0.908320, samples/s: 2235.421 1612447785.2590315
train: epoch 156, iter 500, loss: 1.913667, top_1: 0.756641, top_k: 0.907656, samples/s: 2257.093 1612447796.6010005
train: epoch 156, iter 600, loss: 1.897854, top_1: 0.751875, top_k: 0.907383, samples/s: 2248.310 1612447807.9873354
train: epoch 156, iter 700, loss: 2.158357, top_1: 0.754727, top_k: 0.907148, samples/s: 2240.966 1612447819.4109776
train: epoch 156, iter 800, loss: 2.168043, top_1: 0.754922, top_k: 0.911602, samples/s: 2219.106 1612447830.947193
train: epoch 156, iter 900, loss: 1.966199, top_1: 0.746836, top_k: 0.906406, samples/s: 2228.900 1612447842.4326415
train: epoch 156, iter 1000, loss: 2.049886, top_1: 0.752188, top_k: 0.908164, samples/s: 2220.337 1612447853.9624264
train: epoch 156, iter 1100, loss: 2.155768, top_1: 0.752852, top_k: 0.908906, samples/s: 2222.762 1612447865.4796355
train: epoch 156, iter 1200, loss: 2.086497, top_1: 0.754336, top_k: 0.907109, samples/s: 2220.090 1612447877.0107553
train: epoch 156, iter 1300, loss: 1.942675, top_1: 0.761133, top_k: 0.912266, samples/s: 2227.296 1612447888.5044446
train: epoch 156, iter 1400, loss: 2.059112, top_1: 0.758398, top_k: 0.911094, samples/s: 2226.673 1612447900.0014846
train: epoch 156, iter 1500, loss: 1.929056, top_1: 0.751367, top_k: 0.907422, samples/s: 2227.622 1612447911.4934902
train: epoch 156, iter 1600, loss: 2.251771, top_1: 0.754375, top_k: 0.908242, samples/s: 2230.561 1612447922.970439
train: epoch 156, iter 1700, loss: 2.075163, top_1: 0.750703, top_k: 0.907148, samples/s: 2226.531 1612447934.4681332
train: epoch 156, iter 1800, loss: 1.995960, top_1: 0.748203, top_k: 0.906055, samples/s: 2233.641 1612447945.929279
train: epoch 156, iter 1900, loss: 2.066857, top_1: 0.754844, top_k: 0.906563, samples/s: 2225.731 1612447957.4311285
train: epoch 156, iter 2000, loss: 1.872703, top_1: 0.753711, top_k: 0.907461, samples/s: 2234.537 1612447968.887603
train: epoch 156, iter 2100, loss: 1.895788, top_1: 0.747578, top_k: 0.905312, samples/s: 2219.508 1612447980.4216802
train: epoch 156, iter 2200, loss: 2.171520, top_1: 0.750430, top_k: 0.907461, samples/s: 2247.604 1612447991.8116057
train: epoch 156, iter 2300, loss: 2.172820, top_1: 0.747578, top_k: 0.904844, samples/s: 2240.803 1612448003.236089
train: epoch 156, iter 2400, loss: 2.155570, top_1: 0.751914, top_k: 0.905820, samples/s: 2221.424 1612448014.7602556
train: epoch 156, iter 2500, loss: 1.951364, top_1: 0.752969, top_k: 0.909687, samples/s: 2229.649 1612448026.2418954
train: epoch 156, iter 2600, loss: 2.126958, top_1: 0.751563, top_k: 0.908672, samples/s: 2238.344 1612448037.6788838
train: epoch 156, iter 2700, loss: 2.088380, top_1: 0.750430, top_k: 0.906484, samples/s: 2211.947 1612448049.252349
train: epoch 156, iter 2800, loss: 2.033411, top_1: 0.754727, top_k: 0.908828, samples/s: 2222.905 1612448060.7688704
train: epoch 156, iter 2900, loss: 2.188210, top_1: 0.746758, top_k: 0.906797, samples/s: 2230.313 1612448072.2474291
train: epoch 156, iter 3000, loss: 2.071610, top_1: 0.754844, top_k: 0.908438, samples/s: 2224.643 1612448083.7545416
train: epoch 156, iter 3100, loss: 2.164739, top_1: 0.753789, top_k: 0.909258, samples/s: 2259.588 1612448095.0844595
train: epoch 156, iter 3200, loss: 2.204347, top_1: 0.746875, top_k: 0.907305, samples/s: 2225.756 1612448106.5858128
train: epoch 156, iter 3300, loss: 2.151790, top_1: 0.752969, top_k: 0.909805, samples/s: 2222.585 1612448118.1042273
train: epoch 156, iter 3400, loss: 2.021005, top_1: 0.755664, top_k: 0.908320, samples/s: 2239.515 1612448129.5348952
train: epoch 156, iter 3500, loss: 1.955008, top_1: 0.751289, top_k: 0.908125, samples/s: 2216.761 1612448141.0836318
train: epoch 156, iter 3600, loss: 2.107352, top_1: 0.754609, top_k: 0.911211, samples/s: 2254.919 1612448152.4363573
train: epoch 156, iter 3700, loss: 2.104556, top_1: 0.753008, top_k: 0.908359, samples/s: 2238.172 1612448163.87415
train: epoch 156, iter 3800, loss: 2.072544, top_1: 0.753828, top_k: 0.906797, samples/s: 2236.273 1612448175.3218296
train: epoch 156, iter 3900, loss: 1.891936, top_1: 0.749961, top_k: 0.906016, samples/s: 2229.833 1612448186.8024523
train: epoch 156, iter 4000, loss: 2.132462, top_1: 0.754609, top_k: 0.907383, samples/s: 2236.489 1612448198.2489474
train: epoch 156, iter 4100, loss: 2.005544, top_1: 0.754102, top_k: 0.907344, samples/s: 2233.951 1612448209.7085361
train: epoch 156, iter 4200, loss: 1.964139, top_1: 0.754531, top_k: 0.910508, samples/s: 2223.107 1612448221.2245088
train: epoch 156, iter 4300, loss: 2.004711, top_1: 0.754648, top_k: 0.907227, samples/s: 2210.644 1612448232.8042343
train: epoch 156, iter 4400, loss: 2.018833, top_1: 0.751602, top_k: 0.905273, samples/s: 2226.371 1612448244.303077
train: epoch 156, iter 4500, loss: 2.047122, top_1: 0.748672, top_k: 0.907656, samples/s: 2256.025 1612448255.6501396
train: epoch 156, iter 4600, loss: 2.075874, top_1: 0.753828, top_k: 0.906406, samples/s: 2225.281 1612448267.1543698
train: epoch 156, iter 4700, loss: 2.010924, top_1: 0.752500, top_k: 0.907969, samples/s: 2231.730 1612448278.6253293
train: epoch 156, iter 4800, loss: 1.984918, top_1: 0.750938, top_k: 0.905156, samples/s: 2244.340 1612448290.0317304
train: epoch 156, iter 4900, loss: 2.250337, top_1: 0.745508, top_k: 0.901719, samples/s: 2217.932 1612448301.5740533
train: epoch 156, iter 5000, loss: 2.085210, top_1: 0.750625, top_k: 0.905937, samples/s: 2229.143 1612448313.0582497
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_156.
validation: epoch 156, iter 195, top_1: 0.747877, top_k: 0.920593, samples/s: 2868.800 1612448330.7669578
train: epoch 157, iter 100, loss: 2.135860, top_1: 0.752812, top_k: 0.906484, samples/s: 2248.258 1612448364.9318278
train: epoch 157, iter 200, loss: 2.069971, top_1: 0.747070, top_k: 0.902969, samples/s: 2251.860 1612448376.3003666
train: epoch 157, iter 300, loss: 2.062590, top_1: 0.755039, top_k: 0.909570, samples/s: 2243.990 1612448387.708501
train: epoch 157, iter 400, loss: 2.188828, top_1: 0.751484, top_k: 0.906680, samples/s: 2252.819 1612448399.0720441
train: epoch 157, iter 500, loss: 2.089958, top_1: 0.756992, top_k: 0.910078, samples/s: 2236.652 1612448410.5176804
train: epoch 157, iter 600, loss: 2.110337, top_1: 0.745156, top_k: 0.903281, samples/s: 2218.660 1612448422.056179
train: epoch 157, iter 700, loss: 2.049039, top_1: 0.756992, top_k: 0.911172, samples/s: 2252.850 1612448433.4195492
train: epoch 157, iter 800, loss: 2.151891, top_1: 0.751367, top_k: 0.906641, samples/s: 2245.554 1612448444.8198926
train: epoch 157, iter 900, loss: 2.168911, top_1: 0.746719, top_k: 0.905742, samples/s: 2224.073 1612448456.331229
train: epoch 157, iter 1000, loss: 2.137698, top_1: 0.752539, top_k: 0.907422, samples/s: 2228.989 1612448467.815361
train: epoch 157, iter 1100, loss: 2.138568, top_1: 0.751484, top_k: 0.908984, samples/s: 2237.642 1612448479.2559094
train: epoch 157, iter 1200, loss: 2.033867, top_1: 0.753164, top_k: 0.909219, samples/s: 2220.386 1612448490.7857354
train: epoch 157, iter 1300, loss: 2.028313, top_1: 0.752031, top_k: 0.907344, samples/s: 2227.984 1612448502.2757194
train: epoch 157, iter 1400, loss: 2.059729, top_1: 0.754297, top_k: 0.905625, samples/s: 2196.653 1612448513.929739
train: epoch 157, iter 1500, loss: 2.010873, top_1: 0.749258, top_k: 0.906484, samples/s: 2219.828 1612448525.4621868
train: epoch 157, iter 1600, loss: 1.980772, top_1: 0.754727, top_k: 0.907070, samples/s: 2211.720 1612448537.0368967
train: epoch 157, iter 1700, loss: 1.988645, top_1: 0.751094, top_k: 0.908594, samples/s: 2220.860 1612448548.5639775
train: epoch 157, iter 1800, loss: 1.992501, top_1: 0.755078, top_k: 0.907383, samples/s: 2222.441 1612448560.082859
train: epoch 157, iter 1900, loss: 2.181639, top_1: 0.752695, top_k: 0.907227, samples/s: 2216.713 1612448571.6314228
train: epoch 157, iter 2000, loss: 2.155694, top_1: 0.748594, top_k: 0.907070, samples/s: 2200.716 1612448583.264217
train: epoch 157, iter 2100, loss: 2.137722, top_1: 0.755898, top_k: 0.911992, samples/s: 2219.930 1612448594.7958972
train: epoch 157, iter 2200, loss: 1.893801, top_1: 0.755039, top_k: 0.908945, samples/s: 2214.214 1612448606.3575592
train: epoch 157, iter 2300, loss: 2.002140, top_1: 0.752188, top_k: 0.903867, samples/s: 2215.852 1612448617.9106865
train: epoch 157, iter 2400, loss: 2.155744, top_1: 0.750039, top_k: 0.907148, samples/s: 2212.657 1612448629.4804816
train: epoch 157, iter 2500, loss: 2.121577, top_1: 0.751328, top_k: 0.910391, samples/s: 2226.614 1612448640.9778147
train: epoch 157, iter 2600, loss: 1.889247, top_1: 0.757266, top_k: 0.909687, samples/s: 2214.312 1612448652.5389638
train: epoch 157, iter 2700, loss: 1.966948, top_1: 0.755898, top_k: 0.910156, samples/s: 2218.964 1612448664.0758307
train: epoch 157, iter 2800, loss: 2.250306, top_1: 0.752227, top_k: 0.910195, samples/s: 2225.374 1612448675.5795202
train: epoch 157, iter 2900, loss: 2.101057, top_1: 0.749609, top_k: 0.904883, samples/s: 2235.103 1612448687.0331624
train: epoch 157, iter 3000, loss: 1.964894, top_1: 0.754727, top_k: 0.908398, samples/s: 2229.683 1612448698.5145364
train: epoch 157, iter 3100, loss: 2.183372, top_1: 0.757734, top_k: 0.909727, samples/s: 2227.649 1612448710.0065186
train: epoch 157, iter 3200, loss: 1.998499, top_1: 0.754297, top_k: 0.906992, samples/s: 2224.307 1612448721.5157132
train: epoch 157, iter 3300, loss: 1.980061, top_1: 0.751445, top_k: 0.907188, samples/s: 2233.755 1612448732.9762504
train: epoch 157, iter 3400, loss: 1.985880, top_1: 0.754805, top_k: 0.909219, samples/s: 2217.537 1612448744.5205781
train: epoch 157, iter 3500, loss: 2.013599, top_1: 0.750898, top_k: 0.907500, samples/s: 2230.988 1612448755.9953535
train: epoch 157, iter 3600, loss: 2.002224, top_1: 0.757734, top_k: 0.908008, samples/s: 2220.930 1612448767.5220196
train: epoch 157, iter 3700, loss: 2.099259, top_1: 0.752344, top_k: 0.909766, samples/s: 2236.198 1612448778.9700222
train: epoch 157, iter 3800, loss: 2.094320, top_1: 0.747852, top_k: 0.904570, samples/s: 2234.103 1612448790.4287534
train: epoch 157, iter 3900, loss: 2.072265, top_1: 0.751797, top_k: 0.908633, samples/s: 2248.313 1612448801.8151097
train: epoch 157, iter 4000, loss: 2.156529, top_1: 0.751836, top_k: 0.909023, samples/s: 2233.079 1612448813.279091
train: epoch 157, iter 4100, loss: 1.961834, top_1: 0.753828, top_k: 0.909062, samples/s: 2228.590 1612448824.766177
train: epoch 157, iter 4200, loss: 2.126997, top_1: 0.753789, top_k: 0.910469, samples/s: 2232.576 1612448836.2328274
train: epoch 157, iter 4300, loss: 1.999417, top_1: 0.753281, top_k: 0.907578, samples/s: 2249.150 1612448847.6148229
train: epoch 157, iter 4400, loss: 2.122570, top_1: 0.755625, top_k: 0.909492, samples/s: 2213.060 1612448859.1825204
train: epoch 157, iter 4500, loss: 1.963275, top_1: 0.754336, top_k: 0.909297, samples/s: 2241.954 1612448870.601144
train: epoch 157, iter 4600, loss: 2.257890, top_1: 0.751094, top_k: 0.907109, samples/s: 2223.430 1612448882.114846
train: epoch 157, iter 4700, loss: 2.053761, top_1: 0.751875, top_k: 0.907344, samples/s: 2219.541 1612448893.6488228
train: epoch 157, iter 4800, loss: 1.963422, top_1: 0.752852, top_k: 0.912617, samples/s: 2238.206 1612448905.0864952
train: epoch 157, iter 4900, loss: 2.173771, top_1: 0.752461, top_k: 0.908711, samples/s: 2214.868 1612448916.6447883
train: epoch 157, iter 5000, loss: 2.034732, top_1: 0.753711, top_k: 0.905781, samples/s: 2237.089 1612448928.0882077
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_157.
validation: epoch 157, iter 195, top_1: 0.748718, top_k: 0.920673, samples/s: 2936.795 1612448945.6055036
train: epoch 158, iter 100, loss: 1.972546, top_1: 0.754648, top_k: 0.908945, samples/s: 2231.241 1612448972.8788836
train: epoch 158, iter 200, loss: 2.000062, top_1: 0.751133, top_k: 0.906289, samples/s: 2236.043 1612448984.3275905
train: epoch 158, iter 300, loss: 2.117329, top_1: 0.757148, top_k: 0.909844, samples/s: 2263.747 1612448995.6362872
train: epoch 158, iter 400, loss: 1.999651, top_1: 0.751992, top_k: 0.908281, samples/s: 2240.543 1612449007.0620036
train: epoch 158, iter 500, loss: 2.075247, top_1: 0.756016, top_k: 0.906797, samples/s: 2253.734 1612449018.4214542
train: epoch 158, iter 600, loss: 2.063635, top_1: 0.752344, top_k: 0.911563, samples/s: 2270.527 1612449029.695954
train: epoch 158, iter 700, loss: 1.987050, top_1: 0.746641, top_k: 0.905469, samples/s: 2233.246 1612449041.1589751
train: epoch 158, iter 800, loss: 2.098891, top_1: 0.747773, top_k: 0.906367, samples/s: 2239.407 1612449052.5906003
train: epoch 158, iter 900, loss: 2.004778, top_1: 0.755391, top_k: 0.908086, samples/s: 2234.420 1612449064.0476987
train: epoch 158, iter 1000, loss: 2.024935, top_1: 0.747891, top_k: 0.906563, samples/s: 2238.015 1612449075.4864044
train: epoch 158, iter 1100, loss: 2.222122, top_1: 0.748164, top_k: 0.909375, samples/s: 2206.515 1612449087.0884411
train: epoch 158, iter 1200, loss: 2.062293, top_1: 0.750859, top_k: 0.909141, samples/s: 2216.445 1612449098.6384656
train: epoch 158, iter 1300, loss: 2.046213, top_1: 0.752305, top_k: 0.908516, samples/s: 2217.751 1612449110.181646
train: epoch 158, iter 1400, loss: 2.081623, top_1: 0.755273, top_k: 0.909961, samples/s: 2215.801 1612449121.735053
train: epoch 158, iter 1500, loss: 1.921649, top_1: 0.755313, top_k: 0.911602, samples/s: 2226.461 1612449133.2331238
train: epoch 158, iter 1600, loss: 2.051915, top_1: 0.751992, top_k: 0.908555, samples/s: 2206.953 1612449144.8328428
train: epoch 158, iter 1700, loss: 2.070661, top_1: 0.743828, top_k: 0.905000, samples/s: 2223.544 1612449156.3459666
train: epoch 158, iter 1800, loss: 1.826657, top_1: 0.752070, top_k: 0.908398, samples/s: 2236.409 1612449167.7929404
train: epoch 158, iter 1900, loss: 2.012370, top_1: 0.751641, top_k: 0.907383, samples/s: 2240.643 1612449179.218237
train: epoch 158, iter 2000, loss: 2.183203, top_1: 0.751406, top_k: 0.907734, samples/s: 2224.620 1612449190.7262776
train: epoch 158, iter 2100, loss: 2.024832, top_1: 0.748867, top_k: 0.905195, samples/s: 2225.724 1612449202.2276294
train: epoch 158, iter 2200, loss: 2.003963, top_1: 0.754414, top_k: 0.907148, samples/s: 2194.809 1612449213.8915336
train: epoch 158, iter 2300, loss: 1.949244, top_1: 0.750391, top_k: 0.907891, samples/s: 2220.930 1612449225.4182725
train: epoch 158, iter 2400, loss: 1.966590, top_1: 0.755781, top_k: 0.911172, samples/s: 2239.360 1612449236.8503685
train: epoch 158, iter 2500, loss: 2.081825, top_1: 0.751406, top_k: 0.908477, samples/s: 2231.728 1612449248.320978
train: epoch 158, iter 2600, loss: 2.096686, top_1: 0.753398, top_k: 0.908477, samples/s: 2231.761 1612449259.7918134
train: epoch 158, iter 2700, loss: 2.122515, top_1: 0.750234, top_k: 0.905430, samples/s: 2231.617 1612449271.263293
train: epoch 158, iter 2800, loss: 2.105433, top_1: 0.754492, top_k: 0.909258, samples/s: 2219.540 1612449282.7971704
train: epoch 158, iter 2900, loss: 2.001504, top_1: 0.751406, top_k: 0.906953, samples/s: 2239.120 1612449294.2302804
train: epoch 158, iter 3000, loss: 1.935661, top_1: 0.753711, top_k: 0.910039, samples/s: 2232.642 1612449305.6964655
train: epoch 158, iter 3100, loss: 2.106926, top_1: 0.749062, top_k: 0.907891, samples/s: 2236.057 1612449317.1452389
train: epoch 158, iter 3200, loss: 2.156049, top_1: 0.750781, top_k: 0.908203, samples/s: 2239.995 1612449328.5738
train: epoch 158, iter 3300, loss: 2.039928, top_1: 0.752188, top_k: 0.908164, samples/s: 2226.531 1612449340.0715013
train: epoch 158, iter 3400, loss: 1.990609, top_1: 0.755781, top_k: 0.909219, samples/s: 2229.690 1612449351.5530307
train: epoch 158, iter 3500, loss: 2.124474, top_1: 0.755195, top_k: 0.906445, samples/s: 2223.458 1612449363.0665193
train: epoch 158, iter 3600, loss: 1.940118, top_1: 0.752344, top_k: 0.908203, samples/s: 2252.788 1612449374.4302204
train: epoch 158, iter 3700, loss: 1.943451, top_1: 0.749922, top_k: 0.905586, samples/s: 2233.024 1612449385.8945618
train: epoch 158, iter 3800, loss: 1.901254, top_1: 0.751328, top_k: 0.905469, samples/s: 2234.284 1612449397.3522952
train: epoch 158, iter 3900, loss: 2.138821, top_1: 0.752852, top_k: 0.906133, samples/s: 2231.711 1612449408.823317
train: epoch 158, iter 4000, loss: 1.962555, top_1: 0.748477, top_k: 0.908086, samples/s: 2237.013 1612449420.2671432
train: epoch 158, iter 4100, loss: 2.086013, top_1: 0.752734, top_k: 0.907422, samples/s: 2235.076 1612449431.7208872
train: epoch 158, iter 4200, loss: 2.092045, top_1: 0.750000, top_k: 0.908359, samples/s: 2232.784 1612449443.1863966
train: epoch 158, iter 4300, loss: 2.107483, top_1: 0.757227, top_k: 0.913281, samples/s: 2245.252 1612449454.5882404
train: epoch 158, iter 4400, loss: 2.027201, top_1: 0.751953, top_k: 0.905039, samples/s: 2227.681 1612449466.0800035
train: epoch 158, iter 4500, loss: 1.929461, top_1: 0.754883, top_k: 0.906055, samples/s: 2246.679 1612449477.4746017
train: epoch 158, iter 4600, loss: 2.042254, top_1: 0.755273, top_k: 0.908984, samples/s: 2237.984 1612449488.913479
train: epoch 158, iter 4700, loss: 2.020141, top_1: 0.755508, top_k: 0.907266, samples/s: 2233.211 1612449500.3768153
train: epoch 158, iter 4800, loss: 2.137040, top_1: 0.750039, top_k: 0.904687, samples/s: 2241.111 1612449511.7997506
train: epoch 158, iter 4900, loss: 2.078911, top_1: 0.754180, top_k: 0.910117, samples/s: 2239.644 1612449523.2300706
train: epoch 158, iter 5000, loss: 2.047350, top_1: 0.750586, top_k: 0.907617, samples/s: 2222.191 1612449534.750246
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_158.
validation: epoch 158, iter 195, top_1: 0.748838, top_k: 0.920633, samples/s: 2883.594 1612449552.3499115
train: epoch 159, iter 100, loss: 2.216678, top_1: 0.746719, top_k: 0.906250, samples/s: 2180.139 1612449579.7459266
train: epoch 159, iter 200, loss: 1.978883, top_1: 0.753320, top_k: 0.908438, samples/s: 2233.837 1612449591.206027
train: epoch 159, iter 300, loss: 2.009946, top_1: 0.754219, top_k: 0.906250, samples/s: 2265.148 1612449602.5077136
train: epoch 159, iter 400, loss: 2.056779, top_1: 0.753125, top_k: 0.910156, samples/s: 2240.776 1612449613.9324725
train: epoch 159, iter 500, loss: 2.153604, top_1: 0.750742, top_k: 0.909687, samples/s: 2249.140 1612449625.314448
train: epoch 159, iter 600, loss: 2.039352, top_1: 0.748477, top_k: 0.907070, samples/s: 2253.966 1612449636.672211
train: epoch 159, iter 700, loss: 2.045604, top_1: 0.754141, top_k: 0.908984, samples/s: 2231.960 1612449648.1419692
train: epoch 159, iter 800, loss: 2.182649, top_1: 0.753086, top_k: 0.908125, samples/s: 2228.236 1612449659.6308866
train: epoch 159, iter 900, loss: 1.892977, top_1: 0.750859, top_k: 0.907930, samples/s: 2243.847 1612449671.0398273
train: epoch 159, iter 1000, loss: 1.986494, top_1: 0.754648, top_k: 0.907539, samples/s: 2223.986 1612449682.5507321
train: epoch 159, iter 1100, loss: 1.899733, top_1: 0.751992, top_k: 0.906992, samples/s: 2201.793 1612449694.1776445
train: epoch 159, iter 1200, loss: 1.952137, top_1: 0.754180, top_k: 0.906680, samples/s: 2228.641 1612449705.6644363
train: epoch 159, iter 1300, loss: 2.096144, top_1: 0.749062, top_k: 0.907734, samples/s: 2242.054 1612449717.0825045
train: epoch 159, iter 1400, loss: 2.022259, top_1: 0.750313, top_k: 0.907578, samples/s: 2232.846 1612449728.5476964
train: epoch 159, iter 1500, loss: 1.954993, top_1: 0.756172, top_k: 0.909297, samples/s: 2239.067 1612449739.9810379
train: epoch 159, iter 1600, loss: 2.036330, top_1: 0.755430, top_k: 0.909844, samples/s: 2226.451 1612449751.4791646
train: epoch 159, iter 1700, loss: 1.960927, top_1: 0.751992, top_k: 0.906680, samples/s: 2224.252 1612449762.9886043
train: epoch 159, iter 1800, loss: 2.076302, top_1: 0.750781, top_k: 0.905039, samples/s: 2241.057 1612449774.4118285
train: epoch 159, iter 1900, loss: 2.001144, top_1: 0.755195, top_k: 0.910898, samples/s: 2221.418 1612449785.9360228
train: epoch 159, iter 2000, loss: 2.118887, top_1: 0.750039, top_k: 0.907695, samples/s: 2243.905 1612449797.3451018
train: epoch 159, iter 2100, loss: 1.978339, top_1: 0.752930, top_k: 0.911094, samples/s: 2223.073 1612449808.8602905
train: epoch 159, iter 2200, loss: 2.200945, top_1: 0.756719, top_k: 0.911133, samples/s: 2257.029 1612449820.2031355
train: epoch 159, iter 2300, loss: 2.012431, top_1: 0.751953, top_k: 0.905742, samples/s: 2222.618 1612449831.720619
train: epoch 159, iter 2400, loss: 2.173315, top_1: 0.750977, top_k: 0.906484, samples/s: 2230.583 1612449843.1973946
train: epoch 159, iter 2500, loss: 2.048246, top_1: 0.755039, top_k: 0.910430, samples/s: 2232.804 1612449854.6632364
train: epoch 159, iter 2600, loss: 1.856112, top_1: 0.753203, top_k: 0.907383, samples/s: 2225.567 1612449866.1655533
train: epoch 159, iter 2700, loss: 2.145406, top_1: 0.747617, top_k: 0.904180, samples/s: 2227.679 1612449877.6575775
train: epoch 159, iter 2800, loss: 2.246966, top_1: 0.751914, top_k: 0.908242, samples/s: 2242.084 1612449889.0751836
train: epoch 159, iter 2900, loss: 2.014005, top_1: 0.752344, top_k: 0.909102, samples/s: 2211.312 1612449900.65205
train: epoch 159, iter 3000, loss: 2.029220, top_1: 0.754258, top_k: 0.907969, samples/s: 2230.329 1612449912.1301615
train: epoch 159, iter 3100, loss: 2.116244, top_1: 0.751992, top_k: 0.907695, samples/s: 2225.174 1612449923.63488
train: epoch 159, iter 3200, loss: 2.118887, top_1: 0.754570, top_k: 0.909727, samples/s: 2253.951 1612449934.992745
train: epoch 159, iter 3300, loss: 2.121661, top_1: 0.753984, top_k: 0.909375, samples/s: 2220.756 1612449946.5203419
train: epoch 159, iter 3400, loss: 2.062918, top_1: 0.755859, top_k: 0.909297, samples/s: 2212.319 1612449958.0918906
train: epoch 159, iter 3500, loss: 2.223045, top_1: 0.755664, top_k: 0.906563, samples/s: 2223.722 1612449969.604193
train: epoch 159, iter 3600, loss: 2.092235, top_1: 0.751875, top_k: 0.907656, samples/s: 2239.353 1612449981.036021
train: epoch 159, iter 3700, loss: 1.977540, top_1: 0.753789, top_k: 0.907500, samples/s: 2223.053 1612449992.5517464
train: epoch 159, iter 3800, loss: 2.188422, top_1: 0.747305, top_k: 0.905937, samples/s: 2221.254 1612450004.0767436
train: epoch 159, iter 3900, loss: 2.154414, top_1: 0.757227, top_k: 0.909766, samples/s: 2212.383 1612450015.6479638
train: epoch 159, iter 4000, loss: 2.057541, top_1: 0.754453, top_k: 0.909961, samples/s: 2244.743 1612450027.052723
train: epoch 159, iter 4100, loss: 2.109549, top_1: 0.757500, top_k: 0.909492, samples/s: 2231.104 1612450038.5265212
train: epoch 159, iter 4200, loss: 2.068611, top_1: 0.749414, top_k: 0.906328, samples/s: 2227.525 1612450050.0194092
train: epoch 159, iter 4300, loss: 2.123502, top_1: 0.750234, top_k: 0.906758, samples/s: 2238.540 1612450061.4551113
train: epoch 159, iter 4400, loss: 2.005155, top_1: 0.750156, top_k: 0.908984, samples/s: 2236.775 1612450072.900179
train: epoch 159, iter 4500, loss: 2.066873, top_1: 0.750898, top_k: 0.903125, samples/s: 2224.200 1612450084.410002
train: epoch 159, iter 4600, loss: 2.019511, top_1: 0.750430, top_k: 0.904648, samples/s: 2242.854 1612450095.8240426
train: epoch 159, iter 4700, loss: 1.990598, top_1: 0.750391, top_k: 0.905781, samples/s: 2225.594 1612450107.3265326
train: epoch 159, iter 4800, loss: 2.156884, top_1: 0.748789, top_k: 0.907656, samples/s: 2237.179 1612450118.7694688
train: epoch 159, iter 4900, loss: 1.923803, top_1: 0.753398, top_k: 0.910781, samples/s: 2231.980 1612450130.2391784
train: epoch 159, iter 5000, loss: 2.111699, top_1: 0.751758, top_k: 0.902266, samples/s: 2235.290 1612450141.6918056
Saving model to ./repvggA1/snapshots/model_save/snapshot_epoch_159.
validation: epoch 159, iter 195, top_1: 0.748778, top_k: 0.920012, samples/s: 2880.683 1612450159.3515074
