==================================================================
Running repvggB1g4: num_gpu_per_node = 4, num_nodes = 1.
==================================================================
dtype = float32
gpu_num_per_node = 4
num_nodes = 1
node_ips = ['192.168.1.13', '192.168.1.14']
ctrl_port = 50051
model = repvggB1g4
mixup = False
use_fp16 = None
use_xla = None
channel_last = False
pad_output = None
num_epochs = 160
model_load_dir = None
batch_size_per_device = 64
val_batch_size_per_device = 64
nccl_fusion_threshold_mb = 16
nccl_fusion_max_ops = 24
fuse_bn_relu = True
fuse_bn_add_relu = True
gpu_image_decoder = True
image_path = test_img/tiger.jpg
num_classes = 1000
num_examples = 1281167
num_val_examples = 50000
rgb_mean = [123.68, 116.779, 103.939]
rgb_std = [58.393, 57.12, 57.375]
image_shape = [3, 224, 224]
label_smoothing = 0.1
model_save_dir = ./repvggB1g4/snapshots/model_save/
log_dir = ./output
loss_print_every_n_iter = 100
image_size = 224
resize_shorter = 256
train_data_dir = /DATA/disk1/ImageNet/ofrecord/train
train_data_part_num = 256
val_data_dir = /DATA/disk1/ImageNet/ofrecord/validation
val_data_part_num = 256
optimizer = sgd
learning_rate = 0.1
wd = 3.0517578125e-05
momentum = 0.9
lr_decay = cosine
lr_decay_rate = 0.94
lr_decay_epochs = 2
warmup_epochs = 5
decay_rate = 0.9
epsilon = 1.0
gradient_clipping = 0.0
------------------------------------------------------------------
Time stamp: 2021-02-10-21:32:23
!!!!!===!!!! ./repvggB1g4/snapshots/model_save/
[1mWARNING: 'flow.train.CheckPoint' is deprecated. Please use the new API:[0m
flow.train.CheckPoint().save(path) => [1m[92mflow.checkpoint.save(path)[0m
flow.train.CheckPoint().load(path) => [1m[92mflow.load_variables(flow.checkpoint.get(path))[0m
flow.train.CheckPoint().init() is not needed any more.

Loading data from /DATA/disk1/ImageNet/ofrecord/train
No MixUp
loss.shape (1,)
predictions:  (256, 1000)
Optimizer:  SGD
Loading data from /DATA/disk1/ImageNet/ofrecord/validation
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_initial_model.
Init model on demand.
train: epoch 0, iter 100, loss: 6.880165, top_1: 0.002344, top_k: 0.009570, samples/s: 861.132 1612964130.6314938
train: epoch 0, iter 200, loss: 6.765061, top_1: 0.003477, top_k: 0.015703, samples/s: 866.885 1612964160.1626186
train: epoch 0, iter 300, loss: 6.673030, top_1: 0.007148, top_k: 0.026055, samples/s: 866.331 1612964189.7122138
train: epoch 0, iter 400, loss: 6.566583, top_1: 0.008320, top_k: 0.033711, samples/s: 866.900 1612964219.2426605
train: epoch 0, iter 500, loss: 6.498016, top_1: 0.010703, top_k: 0.041719, samples/s: 867.089 1612964248.7668483
train: epoch 0, iter 600, loss: 6.522723, top_1: 0.013125, top_k: 0.048555, samples/s: 867.071 1612964278.2915065
train: epoch 0, iter 700, loss: 6.247834, top_1: 0.013945, top_k: 0.055898, samples/s: 867.234 1612964307.810587
train: epoch 0, iter 800, loss: 6.167317, top_1: 0.019414, top_k: 0.063672, samples/s: 864.366 1612964337.4277432
train: epoch 0, iter 900, loss: 6.253841, top_1: 0.023164, top_k: 0.076406, samples/s: 862.279 1612964367.116449
train: epoch 0, iter 1000, loss: 6.138456, top_1: 0.024570, top_k: 0.087734, samples/s: 857.960 1612964396.9546757
train: epoch 0, iter 1100, loss: 5.996501, top_1: 0.030117, top_k: 0.097227, samples/s: 858.058 1612964426.789458
train: epoch 0, iter 1200, loss: 6.073841, top_1: 0.033633, top_k: 0.108867, samples/s: 857.275 1612964456.6516073
train: epoch 0, iter 1300, loss: 5.913519, top_1: 0.035664, top_k: 0.112773, samples/s: 852.582 1612964486.6779468
train: epoch 0, iter 1400, loss: 5.836931, top_1: 0.041211, top_k: 0.128164, samples/s: 852.090 1612964516.7218046
train: epoch 0, iter 1500, loss: 5.836384, top_1: 0.042578, top_k: 0.136406, samples/s: 854.329 1612964546.6868293
train: epoch 0, iter 1600, loss: 5.838831, top_1: 0.048281, top_k: 0.147500, samples/s: 851.284 1612964576.7590487
train: epoch 0, iter 1700, loss: 5.781207, top_1: 0.052695, top_k: 0.154453, samples/s: 851.126 1612964606.8369207
train: epoch 0, iter 1800, loss: 5.646959, top_1: 0.057969, top_k: 0.170586, samples/s: 853.134 1612964636.8438594
train: epoch 0, iter 1900, loss: 5.597132, top_1: 0.059922, top_k: 0.177266, samples/s: 850.025 1612964666.9606683
train: epoch 0, iter 2000, loss: 5.578331, top_1: 0.066016, top_k: 0.184922, samples/s: 850.970 1612964697.0440211
train: epoch 0, iter 2100, loss: 5.711000, top_1: 0.068789, top_k: 0.195586, samples/s: 850.926 1612964727.128835
train: epoch 0, iter 2200, loss: 5.460015, top_1: 0.071953, top_k: 0.204063, samples/s: 848.454 1612964757.3013368
train: epoch 0, iter 2300, loss: 5.289889, top_1: 0.081875, top_k: 0.216875, samples/s: 849.932 1612964787.4214075
train: epoch 0, iter 2400, loss: 5.483397, top_1: 0.082383, top_k: 0.220352, samples/s: 847.907 1612964817.613501
train: epoch 0, iter 2500, loss: 5.451489, top_1: 0.088281, top_k: 0.226680, samples/s: 848.112 1612964847.7980971
train: epoch 0, iter 2600, loss: 5.225628, top_1: 0.090313, top_k: 0.238516, samples/s: 849.321 1612964877.939808
train: epoch 0, iter 2700, loss: 5.416083, top_1: 0.094375, top_k: 0.240078, samples/s: 846.168 1612964908.1939204
train: epoch 0, iter 2800, loss: 5.043221, top_1: 0.104414, top_k: 0.260664, samples/s: 848.244 1612964938.3738585
train: epoch 0, iter 2900, loss: 5.314973, top_1: 0.106055, top_k: 0.268711, samples/s: 845.898 1612964968.6375728
train: epoch 0, iter 3000, loss: 5.160428, top_1: 0.112578, top_k: 0.278906, samples/s: 849.031 1612964998.789667
train: epoch 0, iter 3100, loss: 5.237869, top_1: 0.113359, top_k: 0.285313, samples/s: 848.904 1612965028.9462035
train: epoch 0, iter 3200, loss: 5.194224, top_1: 0.118438, top_k: 0.292422, samples/s: 848.853 1612965059.104535
train: epoch 0, iter 3300, loss: 5.027333, top_1: 0.122852, top_k: 0.300820, samples/s: 844.713 1612965089.4106944
train: epoch 0, iter 3400, loss: 4.977611, top_1: 0.126562, top_k: 0.303438, samples/s: 850.162 1612965119.5226152
train: epoch 0, iter 3500, loss: 5.118303, top_1: 0.132344, top_k: 0.312109, samples/s: 845.017 1612965149.8178391
train: epoch 0, iter 3600, loss: 5.105807, top_1: 0.135508, top_k: 0.316445, samples/s: 845.961 1612965180.0792794
train: epoch 0, iter 3700, loss: 4.933883, top_1: 0.139961, top_k: 0.329609, samples/s: 846.672 1612965210.3153944
train: epoch 0, iter 3800, loss: 5.038251, top_1: 0.148633, top_k: 0.335000, samples/s: 848.946 1612965240.4704173
train: epoch 0, iter 3900, loss: 4.960436, top_1: 0.149531, top_k: 0.344102, samples/s: 846.297 1612965270.719886
train: epoch 0, iter 4000, loss: 4.629749, top_1: 0.158906, top_k: 0.351797, samples/s: 845.109 1612965301.011766
train: epoch 0, iter 4100, loss: 4.910262, top_1: 0.161992, top_k: 0.359258, samples/s: 845.615 1612965331.2855256
train: epoch 0, iter 4200, loss: 4.739016, top_1: 0.160664, top_k: 0.362852, samples/s: 847.932 1612965361.4766681
train: epoch 0, iter 4300, loss: 4.776517, top_1: 0.164922, top_k: 0.365938, samples/s: 847.482 1612965391.6838167
train: epoch 0, iter 4400, loss: 4.637058, top_1: 0.172187, top_k: 0.375977, samples/s: 846.736 1612965421.9175813
train: epoch 0, iter 4500, loss: 4.658894, top_1: 0.177305, top_k: 0.386016, samples/s: 848.109 1612965452.1023676
train: epoch 0, iter 4600, loss: 4.821558, top_1: 0.177891, top_k: 0.386172, samples/s: 845.111 1612965482.3942945
train: epoch 0, iter 4700, loss: 4.705637, top_1: 0.181250, top_k: 0.394922, samples/s: 850.482 1612965512.4948218
train: epoch 0, iter 4800, loss: 4.728687, top_1: 0.184414, top_k: 0.398359, samples/s: 843.583 1612965542.8416364
train: epoch 0, iter 4900, loss: 4.707671, top_1: 0.187461, top_k: 0.400625, samples/s: 847.626 1612965573.043642
train: epoch 0, iter 5000, loss: 4.682152, top_1: 0.189805, top_k: 0.407891, samples/s: 847.559 1612965603.2480304
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_0.
validation: epoch 0, iter 195, top_1: 0.197095, top_k: 0.420393, samples/s: 2379.924 1612965625.080378
train: epoch 1, iter 100, loss: 4.898324, top_1: 0.198828, top_k: 0.417969, samples/s: 869.342 1612965676.0132751
train: epoch 1, iter 200, loss: 4.696212, top_1: 0.202813, top_k: 0.421602, samples/s: 866.650 1612965705.5524604
train: epoch 1, iter 300, loss: 4.679070, top_1: 0.207266, top_k: 0.429102, samples/s: 849.118 1612965735.7012076
train: epoch 1, iter 400, loss: 4.547192, top_1: 0.204922, top_k: 0.428008, samples/s: 847.598 1612965765.904113
train: epoch 1, iter 500, loss: 4.612097, top_1: 0.212305, top_k: 0.439844, samples/s: 846.545 1612965796.14473
train: epoch 1, iter 600, loss: 4.613148, top_1: 0.217344, top_k: 0.442227, samples/s: 843.264 1612965826.502933
train: epoch 1, iter 700, loss: 4.706192, top_1: 0.217617, top_k: 0.445352, samples/s: 844.042 1612965856.8331459
train: epoch 1, iter 800, loss: 4.515697, top_1: 0.220312, top_k: 0.450508, samples/s: 847.726 1612965887.031561
train: epoch 1, iter 900, loss: 4.776153, top_1: 0.224688, top_k: 0.449648, samples/s: 844.513 1612965917.344938
train: epoch 1, iter 1000, loss: 4.326984, top_1: 0.224805, top_k: 0.449297, samples/s: 847.104 1612965947.565573
train: epoch 1, iter 1100, loss: 4.274946, top_1: 0.231875, top_k: 0.461992, samples/s: 845.791 1612965977.833118
train: epoch 1, iter 1200, loss: 4.266800, top_1: 0.233867, top_k: 0.469492, samples/s: 847.108 1612966008.053585
train: epoch 1, iter 1300, loss: 4.387126, top_1: 0.238008, top_k: 0.470313, samples/s: 844.310 1612966038.3741949
train: epoch 1, iter 1400, loss: 4.268156, top_1: 0.238633, top_k: 0.472734, samples/s: 846.995 1612966068.5986722
train: epoch 1, iter 1500, loss: 4.237043, top_1: 0.236523, top_k: 0.471406, samples/s: 848.977 1612966098.7525263
train: epoch 1, iter 1600, loss: 4.345658, top_1: 0.238789, top_k: 0.478438, samples/s: 845.373 1612966129.0350711
train: epoch 1, iter 1700, loss: 4.123727, top_1: 0.251797, top_k: 0.485938, samples/s: 846.990 1612966159.2597709
train: epoch 1, iter 1800, loss: 4.253742, top_1: 0.249141, top_k: 0.488672, samples/s: 850.210 1612966189.3699076
train: epoch 1, iter 1900, loss: 4.340397, top_1: 0.250039, top_k: 0.485586, samples/s: 845.115 1612966219.6617072
train: epoch 1, iter 2000, loss: 4.312154, top_1: 0.255430, top_k: 0.496836, samples/s: 849.735 1612966249.7887537
train: epoch 1, iter 2100, loss: 4.413537, top_1: 0.259648, top_k: 0.494922, samples/s: 846.270 1612966280.039136
train: epoch 1, iter 2200, loss: 4.078600, top_1: 0.258320, top_k: 0.497227, samples/s: 847.580 1612966310.242691
train: epoch 1, iter 2300, loss: 4.382809, top_1: 0.262969, top_k: 0.504766, samples/s: 848.343 1612966340.4191878
train: epoch 1, iter 2400, loss: 4.017831, top_1: 0.268437, top_k: 0.505664, samples/s: 847.723 1612966370.617814
train: epoch 1, iter 2500, loss: 4.246523, top_1: 0.266406, top_k: 0.505898, samples/s: 847.735 1612966400.815911
train: epoch 1, iter 2600, loss: 4.153298, top_1: 0.270703, top_k: 0.509414, samples/s: 850.370 1612966430.9204774
train: epoch 1, iter 2700, loss: 4.133526, top_1: 0.271445, top_k: 0.512383, samples/s: 848.167 1612966461.1031494
train: epoch 1, iter 2800, loss: 4.245261, top_1: 0.272734, top_k: 0.514609, samples/s: 849.672 1612966491.2325017
train: epoch 1, iter 2900, loss: 4.304380, top_1: 0.281484, top_k: 0.525469, samples/s: 847.505 1612966521.438763
train: epoch 1, iter 3000, loss: 4.035750, top_1: 0.278008, top_k: 0.519531, samples/s: 848.414 1612966551.6126971
train: epoch 1, iter 3100, loss: 4.085039, top_1: 0.276406, top_k: 0.526367, samples/s: 847.932 1612966581.80382
train: epoch 1, iter 3200, loss: 4.182959, top_1: 0.280547, top_k: 0.518828, samples/s: 846.472 1612966612.0470707
train: epoch 1, iter 3300, loss: 4.031182, top_1: 0.277031, top_k: 0.518984, samples/s: 850.106 1612966642.160972
train: epoch 1, iter 3400, loss: 4.004403, top_1: 0.287422, top_k: 0.534375, samples/s: 848.498 1612966672.331864
train: epoch 1, iter 3500, loss: 4.235664, top_1: 0.288906, top_k: 0.532227, samples/s: 847.013 1612966702.555723
train: epoch 1, iter 3600, loss: 3.986027, top_1: 0.287813, top_k: 0.535781, samples/s: 848.818 1612966732.715344
train: epoch 1, iter 3700, loss: 4.216042, top_1: 0.296445, top_k: 0.540078, samples/s: 847.466 1612966762.9230974
train: epoch 1, iter 3800, loss: 4.104692, top_1: 0.292969, top_k: 0.538828, samples/s: 847.828 1612966793.1179025
train: epoch 1, iter 3900, loss: 4.195293, top_1: 0.292305, top_k: 0.539492, samples/s: 846.218 1612966823.3701293
train: epoch 1, iter 4000, loss: 3.957393, top_1: 0.296289, top_k: 0.541328, samples/s: 851.560 1612966853.4325309
train: epoch 1, iter 4100, loss: 4.014125, top_1: 0.303906, top_k: 0.542734, samples/s: 847.835 1612966883.6270583
train: epoch 1, iter 4200, loss: 4.204134, top_1: 0.300391, top_k: 0.549492, samples/s: 849.167 1612966913.7742968
train: epoch 1, iter 4300, loss: 4.049384, top_1: 0.302734, top_k: 0.554531, samples/s: 844.553 1612966944.0861616
train: epoch 1, iter 4400, loss: 4.236565, top_1: 0.302422, top_k: 0.552578, samples/s: 848.104 1612966974.271242
train: epoch 1, iter 4500, loss: 3.895059, top_1: 0.307266, top_k: 0.557422, samples/s: 848.654 1612967004.4366336
train: epoch 1, iter 4600, loss: 4.016649, top_1: 0.314453, top_k: 0.558711, samples/s: 846.686 1612967034.6720715
train: epoch 1, iter 4700, loss: 4.267764, top_1: 0.307227, top_k: 0.558008, samples/s: 847.763 1612967064.8691902
train: epoch 1, iter 4800, loss: 3.688608, top_1: 0.310859, top_k: 0.561953, samples/s: 850.091 1612967094.9836621
train: epoch 1, iter 4900, loss: 3.915005, top_1: 0.312969, top_k: 0.559492, samples/s: 845.311 1612967125.2684639
train: epoch 1, iter 5000, loss: 3.912407, top_1: 0.313789, top_k: 0.560430, samples/s: 845.508 1612967155.546063
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_1.
validation: epoch 1, iter 195, top_1: 0.338702, top_k: 0.601182, samples/s: 2428.161 1612967177.0016394
train: epoch 2, iter 100, loss: 3.873596, top_1: 0.331289, top_k: 0.576953, samples/s: 870.125 1612967227.6093345
train: epoch 2, iter 200, loss: 3.763393, top_1: 0.327422, top_k: 0.571172, samples/s: 865.908 1612967257.1736612
train: epoch 2, iter 300, loss: 4.053629, top_1: 0.326406, top_k: 0.574063, samples/s: 853.936 1612967287.1527355
train: epoch 2, iter 400, loss: 3.922016, top_1: 0.326445, top_k: 0.578750, samples/s: 849.323 1612967317.2941003
train: epoch 2, iter 500, loss: 3.839607, top_1: 0.329258, top_k: 0.579336, samples/s: 844.000 1612967347.6258016
train: epoch 2, iter 600, loss: 4.038680, top_1: 0.324414, top_k: 0.577930, samples/s: 845.710 1612967377.8962548
train: epoch 2, iter 700, loss: 3.869038, top_1: 0.329727, top_k: 0.578867, samples/s: 847.723 1612967408.0947864
train: epoch 2, iter 800, loss: 3.849363, top_1: 0.332031, top_k: 0.585234, samples/s: 848.016 1612967438.282849
train: epoch 2, iter 900, loss: 3.958553, top_1: 0.333047, top_k: 0.580586, samples/s: 845.999 1612967468.5429235
train: epoch 2, iter 1000, loss: 3.714143, top_1: 0.330273, top_k: 0.585703, samples/s: 846.988 1612967498.7677715
train: epoch 2, iter 1100, loss: 4.029010, top_1: 0.333008, top_k: 0.586523, samples/s: 843.206 1612967529.128085
train: epoch 2, iter 1200, loss: 3.859862, top_1: 0.337031, top_k: 0.588516, samples/s: 846.999 1612967559.3524094
train: epoch 2, iter 1300, loss: 3.979413, top_1: 0.340391, top_k: 0.595938, samples/s: 848.843 1612967589.5110617
train: epoch 2, iter 1400, loss: 3.816372, top_1: 0.338711, top_k: 0.590039, samples/s: 846.324 1612967619.7595649
train: epoch 2, iter 1500, loss: 3.870953, top_1: 0.339492, top_k: 0.593320, samples/s: 844.795 1612967650.0627265
train: epoch 2, iter 1600, loss: 3.806868, top_1: 0.337930, top_k: 0.589023, samples/s: 844.419 1612967680.3794215
train: epoch 2, iter 1700, loss: 3.820354, top_1: 0.341133, top_k: 0.591367, samples/s: 849.389 1612967710.5188115
train: epoch 2, iter 1800, loss: 3.793849, top_1: 0.340313, top_k: 0.591562, samples/s: 844.895 1612967740.8183305
train: epoch 2, iter 1900, loss: 3.740659, top_1: 0.341797, top_k: 0.591875, samples/s: 850.795 1612967770.9078567
train: epoch 2, iter 2000, loss: 3.928919, top_1: 0.349844, top_k: 0.598437, samples/s: 844.952 1612967801.205417
train: epoch 2, iter 2100, loss: 3.671258, top_1: 0.344531, top_k: 0.593867, samples/s: 847.087 1612967831.426616
train: epoch 2, iter 2200, loss: 3.821405, top_1: 0.342930, top_k: 0.600820, samples/s: 845.482 1612967861.7052257
train: epoch 2, iter 2300, loss: 3.686855, top_1: 0.356289, top_k: 0.609102, samples/s: 849.170 1612967891.8522856
train: epoch 2, iter 2400, loss: 3.626109, top_1: 0.351406, top_k: 0.604609, samples/s: 850.497 1612967921.9524536
train: epoch 2, iter 2500, loss: 3.765878, top_1: 0.351484, top_k: 0.603359, samples/s: 847.944 1612967952.1430132
train: epoch 2, iter 2600, loss: 3.907708, top_1: 0.348945, top_k: 0.599414, samples/s: 846.975 1612967982.368289
train: epoch 2, iter 2700, loss: 3.738143, top_1: 0.350117, top_k: 0.599414, samples/s: 847.070 1612968012.590033
train: epoch 2, iter 2800, loss: 3.612167, top_1: 0.357773, top_k: 0.613047, samples/s: 848.408 1612968042.7642117
train: epoch 2, iter 2900, loss: 3.733360, top_1: 0.353359, top_k: 0.605078, samples/s: 844.976 1612968073.060896
train: epoch 2, iter 3000, loss: 3.865556, top_1: 0.359570, top_k: 0.606758, samples/s: 846.887 1612968103.2893105
train: epoch 2, iter 3100, loss: 3.844265, top_1: 0.361094, top_k: 0.609844, samples/s: 849.472 1612968133.4257271
train: epoch 2, iter 3200, loss: 3.571945, top_1: 0.361016, top_k: 0.613633, samples/s: 845.573 1612968163.7010593
train: epoch 2, iter 3300, loss: 3.571218, top_1: 0.361250, top_k: 0.612461, samples/s: 847.360 1612968193.9124477
train: epoch 2, iter 3400, loss: 3.703815, top_1: 0.364648, top_k: 0.618750, samples/s: 846.537 1612968224.153298
train: epoch 2, iter 3500, loss: 3.878870, top_1: 0.359609, top_k: 0.613945, samples/s: 847.194 1612968254.3707867
train: epoch 2, iter 3600, loss: 3.815247, top_1: 0.364102, top_k: 0.613398, samples/s: 847.040 1612968284.5935574
train: epoch 2, iter 3700, loss: 3.994126, top_1: 0.363047, top_k: 0.617109, samples/s: 845.818 1612968314.8601546
train: epoch 2, iter 3800, loss: 3.751967, top_1: 0.369141, top_k: 0.619219, samples/s: 846.532 1612968345.1012812
train: epoch 2, iter 3900, loss: 3.732550, top_1: 0.365000, top_k: 0.612109, samples/s: 850.147 1612968375.213653
train: epoch 2, iter 4000, loss: 3.647348, top_1: 0.365977, top_k: 0.619492, samples/s: 843.416 1612968405.5663636
train: epoch 2, iter 4100, loss: 3.568852, top_1: 0.367422, top_k: 0.621680, samples/s: 847.071 1612968435.788219
train: epoch 2, iter 4200, loss: 3.485779, top_1: 0.359609, top_k: 0.620430, samples/s: 847.905 1612968465.9802237
train: epoch 2, iter 4300, loss: 3.948905, top_1: 0.367305, top_k: 0.619961, samples/s: 844.663 1612968496.28827
train: epoch 2, iter 4400, loss: 3.705040, top_1: 0.368555, top_k: 0.621289, samples/s: 849.629 1612968526.4189963
train: epoch 2, iter 4500, loss: 3.556418, top_1: 0.365781, top_k: 0.621328, samples/s: 845.232 1612968556.706643
train: epoch 2, iter 4600, loss: 3.748893, top_1: 0.375078, top_k: 0.626367, samples/s: 849.027 1612968586.8587499
train: epoch 2, iter 4700, loss: 3.656556, top_1: 0.368008, top_k: 0.624766, samples/s: 847.129 1612968617.078476
train: epoch 2, iter 4800, loss: 3.858540, top_1: 0.372617, top_k: 0.626328, samples/s: 846.892 1612968647.3065958
train: epoch 2, iter 4900, loss: 3.588952, top_1: 0.371172, top_k: 0.624531, samples/s: 849.289 1612968677.4494374
train: epoch 2, iter 5000, loss: 3.389262, top_1: 0.383516, top_k: 0.633594, samples/s: 848.916 1612968707.6056373
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_2.
validation: epoch 2, iter 195, top_1: 0.411839, top_k: 0.676202, samples/s: 2482.803 1612968728.6180174
train: epoch 3, iter 100, loss: 3.515600, top_1: 0.393477, top_k: 0.644922, samples/s: 869.382 1612968779.501142
train: epoch 3, iter 200, loss: 3.600475, top_1: 0.382070, top_k: 0.629570, samples/s: 867.207 1612968809.0213118
train: epoch 3, iter 300, loss: 3.587334, top_1: 0.388672, top_k: 0.637656, samples/s: 852.769 1612968839.0410907
train: epoch 3, iter 400, loss: 3.417150, top_1: 0.388945, top_k: 0.641875, samples/s: 843.460 1612968869.3923335
train: epoch 3, iter 500, loss: 3.457627, top_1: 0.388750, top_k: 0.639570, samples/s: 845.453 1612968899.6719198
train: epoch 3, iter 600, loss: 3.528497, top_1: 0.375859, top_k: 0.633281, samples/s: 847.979 1612968929.8614228
train: epoch 3, iter 700, loss: 3.736057, top_1: 0.386367, top_k: 0.638477, samples/s: 843.925 1612968960.1958134
train: epoch 3, iter 800, loss: 3.554585, top_1: 0.386992, top_k: 0.640547, samples/s: 846.356 1612968990.4430788
train: epoch 3, iter 900, loss: 3.769093, top_1: 0.382812, top_k: 0.639648, samples/s: 843.668 1612969020.786805
train: epoch 3, iter 1000, loss: 3.573697, top_1: 0.386680, top_k: 0.637109, samples/s: 849.838 1612969050.910514
train: epoch 3, iter 1100, loss: 3.735346, top_1: 0.384453, top_k: 0.637383, samples/s: 846.366 1612969081.1571898
train: epoch 3, iter 1200, loss: 3.504227, top_1: 0.386758, top_k: 0.637539, samples/s: 846.504 1612969111.3992584
train: epoch 3, iter 1300, loss: 3.647135, top_1: 0.387891, top_k: 0.640977, samples/s: 848.967 1612969141.5535014
train: epoch 3, iter 1400, loss: 3.566234, top_1: 0.392734, top_k: 0.643359, samples/s: 846.644 1612969171.790863
train: epoch 3, iter 1500, loss: 3.604009, top_1: 0.385898, top_k: 0.636328, samples/s: 845.496 1612969202.068547
train: epoch 3, iter 1600, loss: 3.702335, top_1: 0.390234, top_k: 0.643125, samples/s: 850.381 1612969232.1728024
train: epoch 3, iter 1700, loss: 3.783998, top_1: 0.388203, top_k: 0.641875, samples/s: 846.336 1612969262.420764
train: epoch 3, iter 1800, loss: 3.705585, top_1: 0.389648, top_k: 0.644609, samples/s: 845.012 1612969292.7162125
train: epoch 3, iter 1900, loss: 3.516783, top_1: 0.391836, top_k: 0.643320, samples/s: 850.182 1612969322.8274581
train: epoch 3, iter 2000, loss: 3.635067, top_1: 0.394766, top_k: 0.646758, samples/s: 846.075 1612969353.0847754
train: epoch 3, iter 2100, loss: 4.019113, top_1: 0.395508, top_k: 0.649062, samples/s: 850.574 1612969383.182126
train: epoch 3, iter 2200, loss: 3.679967, top_1: 0.396055, top_k: 0.647109, samples/s: 845.242 1612969413.469302
train: epoch 3, iter 2300, loss: 3.653845, top_1: 0.393828, top_k: 0.653438, samples/s: 847.905 1612969443.6613166
train: epoch 3, iter 2400, loss: 3.791720, top_1: 0.394297, top_k: 0.648047, samples/s: 850.592 1612969473.757998
train: epoch 3, iter 2500, loss: 3.608760, top_1: 0.400234, top_k: 0.653320, samples/s: 843.627 1612969504.103139
train: epoch 3, iter 2600, loss: 3.931042, top_1: 0.393164, top_k: 0.648594, samples/s: 846.063 1612969534.3610046
train: epoch 3, iter 2700, loss: 3.680201, top_1: 0.400313, top_k: 0.651289, samples/s: 848.905 1612969564.517461
train: epoch 3, iter 2800, loss: 3.426353, top_1: 0.400586, top_k: 0.649531, samples/s: 846.017 1612969594.7769618
train: epoch 3, iter 2900, loss: 3.513295, top_1: 0.402500, top_k: 0.654727, samples/s: 846.860 1612969625.0062943
train: epoch 3, iter 3000, loss: 3.548817, top_1: 0.400742, top_k: 0.651719, samples/s: 847.290 1612969655.220233
train: epoch 3, iter 3100, loss: 3.534446, top_1: 0.400664, top_k: 0.652461, samples/s: 847.099 1612969685.4410262
train: epoch 3, iter 3200, loss: 3.512063, top_1: 0.406211, top_k: 0.653203, samples/s: 847.329 1612969715.6535275
train: epoch 3, iter 3300, loss: 3.421563, top_1: 0.399570, top_k: 0.650820, samples/s: 848.038 1612969745.8409162
train: epoch 3, iter 3400, loss: 3.686722, top_1: 0.398086, top_k: 0.649766, samples/s: 849.171 1612969775.9878898
train: epoch 3, iter 3500, loss: 3.508437, top_1: 0.399727, top_k: 0.653789, samples/s: 848.966 1612969806.1422074
train: epoch 3, iter 3600, loss: 3.627937, top_1: 0.399727, top_k: 0.651641, samples/s: 847.158 1612969836.3609006
train: epoch 3, iter 3700, loss: 3.619327, top_1: 0.402461, top_k: 0.654180, samples/s: 846.690 1612969866.5962749
train: epoch 3, iter 3800, loss: 3.667777, top_1: 0.401992, top_k: 0.655703, samples/s: 848.476 1612969896.767984
train: epoch 3, iter 3900, loss: 3.719981, top_1: 0.400313, top_k: 0.651406, samples/s: 847.093 1612969926.9891002
train: epoch 3, iter 4000, loss: 3.423582, top_1: 0.399961, top_k: 0.652344, samples/s: 848.293 1612969957.1672716
train: epoch 3, iter 4100, loss: 3.600774, top_1: 0.399531, top_k: 0.650703, samples/s: 846.237 1612969987.4188032
train: epoch 3, iter 4200, loss: 3.621309, top_1: 0.398945, top_k: 0.652969, samples/s: 848.695 1612970017.5827742
train: epoch 3, iter 4300, loss: 3.575824, top_1: 0.406562, top_k: 0.657852, samples/s: 847.582 1612970047.7863886
train: epoch 3, iter 4400, loss: 3.706871, top_1: 0.406953, top_k: 0.656836, samples/s: 849.007 1612970077.9391875
train: epoch 3, iter 4500, loss: 3.491667, top_1: 0.407227, top_k: 0.659922, samples/s: 848.211 1612970108.1204228
train: epoch 3, iter 4600, loss: 3.471385, top_1: 0.403867, top_k: 0.655039, samples/s: 848.735 1612970138.2829483
train: epoch 3, iter 4700, loss: 3.491720, top_1: 0.406328, top_k: 0.658047, samples/s: 850.225 1612970168.3926094
train: epoch 3, iter 4800, loss: 3.516761, top_1: 0.406211, top_k: 0.663125, samples/s: 843.424 1612970198.7450945
train: epoch 3, iter 4900, loss: 3.474205, top_1: 0.409844, top_k: 0.663008, samples/s: 847.789 1612970228.9413095
train: epoch 3, iter 5000, loss: 3.503668, top_1: 0.410977, top_k: 0.669922, samples/s: 846.560 1612970259.1813762
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_3.
validation: epoch 3, iter 195, top_1: 0.440525, top_k: 0.704227, samples/s: 2417.959 1612970280.7351146
train: epoch 4, iter 100, loss: 3.664677, top_1: 0.417891, top_k: 0.670156, samples/s: 870.690 1612970331.1154735
train: epoch 4, iter 200, loss: 3.388109, top_1: 0.415859, top_k: 0.666680, samples/s: 866.603 1612970360.6560917
train: epoch 4, iter 300, loss: 3.368385, top_1: 0.411875, top_k: 0.662773, samples/s: 852.025 1612970390.702146
train: epoch 4, iter 400, loss: 3.527341, top_1: 0.415391, top_k: 0.667109, samples/s: 848.291 1612970420.8805604
train: epoch 4, iter 500, loss: 3.491831, top_1: 0.420312, top_k: 0.674375, samples/s: 846.458 1612970451.124287
train: epoch 4, iter 600, loss: 3.631482, top_1: 0.420312, top_k: 0.669648, samples/s: 844.586 1612970481.434946
train: epoch 4, iter 700, loss: 3.573123, top_1: 0.416992, top_k: 0.670117, samples/s: 845.895 1612970511.6987655
train: epoch 4, iter 800, loss: 3.633073, top_1: 0.415312, top_k: 0.662969, samples/s: 848.191 1612970541.8806322
train: epoch 4, iter 900, loss: 3.636484, top_1: 0.419922, top_k: 0.669414, samples/s: 845.861 1612970572.14561
train: epoch 4, iter 1000, loss: 3.365204, top_1: 0.413516, top_k: 0.668945, samples/s: 849.803 1612970602.2703319
train: epoch 4, iter 1100, loss: 3.415737, top_1: 0.418242, top_k: 0.668516, samples/s: 846.026 1612970632.5293567
train: epoch 4, iter 1200, loss: 3.546117, top_1: 0.418438, top_k: 0.666719, samples/s: 849.146 1612970662.6773646
train: epoch 4, iter 1300, loss: 3.488936, top_1: 0.416953, top_k: 0.666641, samples/s: 843.334 1612970693.0330224
train: epoch 4, iter 1400, loss: 3.371663, top_1: 0.420312, top_k: 0.670625, samples/s: 846.070 1612970723.2906528
train: epoch 4, iter 1500, loss: 3.346165, top_1: 0.421055, top_k: 0.667617, samples/s: 847.533 1612970753.4959562
train: epoch 4, iter 1600, loss: 3.222817, top_1: 0.417461, top_k: 0.669570, samples/s: 848.262 1612970783.6753411
train: epoch 4, iter 1700, loss: 3.352768, top_1: 0.419023, top_k: 0.669258, samples/s: 846.891 1612970813.9035249
train: epoch 4, iter 1800, loss: 3.390882, top_1: 0.412695, top_k: 0.668516, samples/s: 846.178 1612970844.1571612
train: epoch 4, iter 1900, loss: 3.577609, top_1: 0.420273, top_k: 0.672109, samples/s: 848.215 1612970874.3381846
train: epoch 4, iter 2000, loss: 3.432351, top_1: 0.418516, top_k: 0.671328, samples/s: 848.336 1612970904.51493
train: epoch 4, iter 2100, loss: 3.399482, top_1: 0.418281, top_k: 0.669766, samples/s: 847.255 1612970934.7300916
train: epoch 4, iter 2200, loss: 3.519071, top_1: 0.411836, top_k: 0.667305, samples/s: 845.294 1612970965.0154111
train: epoch 4, iter 2300, loss: 3.429524, top_1: 0.424375, top_k: 0.675977, samples/s: 845.877 1612970995.279952
train: epoch 4, iter 2400, loss: 3.663718, top_1: 0.416641, top_k: 0.670898, samples/s: 848.370 1612971025.4554422
train: epoch 4, iter 2500, loss: 3.442115, top_1: 0.420078, top_k: 0.671523, samples/s: 844.583 1612971055.7662137
train: epoch 4, iter 2600, loss: 3.168462, top_1: 0.424648, top_k: 0.670234, samples/s: 847.918 1612971085.9578526
train: epoch 4, iter 2700, loss: 3.630906, top_1: 0.422266, top_k: 0.673086, samples/s: 849.310 1612971116.099943
train: epoch 4, iter 2800, loss: 3.562709, top_1: 0.423945, top_k: 0.676016, samples/s: 848.187 1612971146.282016
train: epoch 4, iter 2900, loss: 3.348206, top_1: 0.419102, top_k: 0.674375, samples/s: 845.054 1612971176.575861
train: epoch 4, iter 3000, loss: 3.442611, top_1: 0.428125, top_k: 0.674922, samples/s: 848.429 1612971206.7492805
train: epoch 4, iter 3100, loss: 3.219350, top_1: 0.426836, top_k: 0.677422, samples/s: 847.558 1612971236.9537463
train: epoch 4, iter 3200, loss: 3.334826, top_1: 0.424531, top_k: 0.677891, samples/s: 845.907 1612971267.2170887
train: epoch 4, iter 3300, loss: 3.418231, top_1: 0.426523, top_k: 0.676055, samples/s: 849.054 1612971297.3683698
train: epoch 4, iter 3400, loss: 3.650072, top_1: 0.421367, top_k: 0.670977, samples/s: 846.110 1612971327.6244953
train: epoch 4, iter 3500, loss: 3.600476, top_1: 0.419844, top_k: 0.677383, samples/s: 847.687 1612971357.8242736
train: epoch 4, iter 3600, loss: 3.502101, top_1: 0.426016, top_k: 0.673828, samples/s: 850.361 1612971387.9291525
train: epoch 4, iter 3700, loss: 3.495779, top_1: 0.425820, top_k: 0.676289, samples/s: 847.296 1612971418.1429014
train: epoch 4, iter 3800, loss: 3.238723, top_1: 0.425820, top_k: 0.683086, samples/s: 846.960 1612971448.3687515
train: epoch 4, iter 3900, loss: 3.545779, top_1: 0.424336, top_k: 0.675508, samples/s: 850.642 1612971478.4635754
train: epoch 4, iter 4000, loss: 3.426047, top_1: 0.423633, top_k: 0.673867, samples/s: 844.904 1612971508.7629695
train: epoch 4, iter 4100, loss: 3.593257, top_1: 0.423086, top_k: 0.676836, samples/s: 848.651 1612971538.9283786
train: epoch 4, iter 4200, loss: 3.207508, top_1: 0.428555, top_k: 0.677031, samples/s: 849.017 1612971569.080934
train: epoch 4, iter 4300, loss: 3.400055, top_1: 0.428125, top_k: 0.676445, samples/s: 847.472 1612971599.2885048
train: epoch 4, iter 4400, loss: 3.289691, top_1: 0.429688, top_k: 0.678164, samples/s: 845.906 1612971629.5518746
train: epoch 4, iter 4500, loss: 3.476666, top_1: 0.425664, top_k: 0.676133, samples/s: 847.392 1612971659.7622309
train: epoch 4, iter 4600, loss: 3.488558, top_1: 0.422148, top_k: 0.673711, samples/s: 850.156 1612971689.8742695
train: epoch 4, iter 4700, loss: 3.466981, top_1: 0.428086, top_k: 0.677031, samples/s: 845.514 1612971720.151778
train: epoch 4, iter 4800, loss: 3.458607, top_1: 0.427617, top_k: 0.679531, samples/s: 848.367 1612971750.3273525
train: epoch 4, iter 4900, loss: 3.323932, top_1: 0.433359, top_k: 0.678203, samples/s: 849.819 1612971780.4514453
train: epoch 4, iter 5000, loss: 3.373603, top_1: 0.428281, top_k: 0.681641, samples/s: 844.116 1612971810.7789965
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_4.
validation: epoch 4, iter 195, top_1: 0.474519, top_k: 0.733233, samples/s: 2465.832 1612971831.9218445
train: epoch 5, iter 100, loss: 3.221488, top_1: 0.434570, top_k: 0.686367, samples/s: 867.640 1612971882.428657
train: epoch 5, iter 200, loss: 3.429881, top_1: 0.433594, top_k: 0.687539, samples/s: 866.398 1612971911.9763644
train: epoch 5, iter 300, loss: 3.452861, top_1: 0.431836, top_k: 0.685312, samples/s: 855.107 1612971941.914023
train: epoch 5, iter 400, loss: 3.289488, top_1: 0.430859, top_k: 0.686094, samples/s: 844.909 1612971972.2132025
train: epoch 5, iter 500, loss: 3.312493, top_1: 0.440430, top_k: 0.689102, samples/s: 844.310 1612972002.5338652
train: epoch 5, iter 600, loss: 3.686701, top_1: 0.435977, top_k: 0.683828, samples/s: 849.092 1612972032.683683
train: epoch 5, iter 700, loss: 3.237609, top_1: 0.438633, top_k: 0.688203, samples/s: 844.870 1612972062.9842572
train: epoch 5, iter 800, loss: 3.462386, top_1: 0.436797, top_k: 0.687422, samples/s: 849.862 1612972093.1066997
train: epoch 5, iter 900, loss: 3.457872, top_1: 0.437812, top_k: 0.688125, samples/s: 841.362 1612972123.5336258
train: epoch 5, iter 1000, loss: 3.540186, top_1: 0.436563, top_k: 0.683594, samples/s: 847.718 1612972153.7322767
train: epoch 5, iter 1100, loss: 3.349632, top_1: 0.436289, top_k: 0.689492, samples/s: 848.611 1612972183.8993037
train: epoch 5, iter 1200, loss: 3.372858, top_1: 0.438633, top_k: 0.691484, samples/s: 845.175 1612972214.1888266
train: epoch 5, iter 1300, loss: 3.524204, top_1: 0.441367, top_k: 0.693789, samples/s: 846.222 1612972244.440979
train: epoch 5, iter 1400, loss: 3.672734, top_1: 0.441250, top_k: 0.691523, samples/s: 843.897 1612972274.776468
train: epoch 5, iter 1500, loss: 3.386313, top_1: 0.436445, top_k: 0.690195, samples/s: 849.043 1612972304.9280078
train: epoch 5, iter 1600, loss: 3.406887, top_1: 0.430859, top_k: 0.683594, samples/s: 843.776 1612972335.2678397
train: epoch 5, iter 1700, loss: 3.133359, top_1: 0.442266, top_k: 0.690625, samples/s: 849.302 1612972365.4102738
train: epoch 5, iter 1800, loss: 3.444194, top_1: 0.444063, top_k: 0.693828, samples/s: 846.736 1612972395.6438892
train: epoch 5, iter 1900, loss: 3.192075, top_1: 0.438945, top_k: 0.691250, samples/s: 848.176 1612972425.826298
train: epoch 5, iter 2000, loss: 3.255718, top_1: 0.441523, top_k: 0.691562, samples/s: 849.535 1612972455.960446
train: epoch 5, iter 2100, loss: 3.599179, top_1: 0.437539, top_k: 0.683008, samples/s: 842.721 1612972486.338255
train: epoch 5, iter 2200, loss: 3.397434, top_1: 0.443516, top_k: 0.692422, samples/s: 849.217 1612972516.4837048
train: epoch 5, iter 2300, loss: 3.457502, top_1: 0.438633, top_k: 0.688633, samples/s: 845.898 1612972546.7474556
train: epoch 5, iter 2400, loss: 3.533602, top_1: 0.443047, top_k: 0.692891, samples/s: 849.968 1612972576.8662417
train: epoch 5, iter 2500, loss: 3.242339, top_1: 0.441484, top_k: 0.694492, samples/s: 848.392 1612972607.0408442
train: epoch 5, iter 2600, loss: 3.264372, top_1: 0.444219, top_k: 0.692578, samples/s: 848.193 1612972637.2227118
train: epoch 5, iter 2700, loss: 3.369222, top_1: 0.440391, top_k: 0.689219, samples/s: 847.124 1612972667.4426172
train: epoch 5, iter 2800, loss: 3.355444, top_1: 0.440937, top_k: 0.694375, samples/s: 849.556 1612972697.575993
train: epoch 5, iter 2900, loss: 3.238288, top_1: 0.443516, top_k: 0.692148, samples/s: 846.414 1612972727.8212447
train: epoch 5, iter 3000, loss: 3.195745, top_1: 0.452383, top_k: 0.697930, samples/s: 848.066 1612972758.0075824
train: epoch 5, iter 3100, loss: 3.271631, top_1: 0.447383, top_k: 0.695391, samples/s: 849.298 1612972788.1501987
train: epoch 5, iter 3200, loss: 3.333455, top_1: 0.439688, top_k: 0.686953, samples/s: 849.173 1612972818.2970488
train: epoch 5, iter 3300, loss: 3.094083, top_1: 0.442891, top_k: 0.693125, samples/s: 848.135 1612972848.4810047
train: epoch 5, iter 3400, loss: 3.087001, top_1: 0.450859, top_k: 0.697578, samples/s: 847.440 1612972878.6896393
train: epoch 5, iter 3500, loss: 3.325646, top_1: 0.443828, top_k: 0.698516, samples/s: 849.428 1612972908.8275552
train: epoch 5, iter 3600, loss: 3.376042, top_1: 0.449727, top_k: 0.698711, samples/s: 844.719 1612972939.1334047
train: epoch 5, iter 3700, loss: 3.489078, top_1: 0.453047, top_k: 0.701328, samples/s: 850.028 1612972969.2501106
train: epoch 5, iter 3800, loss: 3.232329, top_1: 0.448164, top_k: 0.693164, samples/s: 847.774 1612972999.4468858
train: epoch 5, iter 3900, loss: 3.103780, top_1: 0.446992, top_k: 0.692070, samples/s: 845.924 1612973029.7096267
train: epoch 5, iter 4000, loss: 3.303028, top_1: 0.446953, top_k: 0.697070, samples/s: 850.092 1612973059.8239512
train: epoch 5, iter 4100, loss: 3.501011, top_1: 0.445781, top_k: 0.693711, samples/s: 846.752 1612973090.0572126
train: epoch 5, iter 4200, loss: 3.166970, top_1: 0.449570, top_k: 0.697852, samples/s: 849.971 1612973120.1758673
train: epoch 5, iter 4300, loss: 3.326529, top_1: 0.443594, top_k: 0.693867, samples/s: 848.804 1612973150.3359025
train: epoch 5, iter 4400, loss: 3.427874, top_1: 0.443867, top_k: 0.696562, samples/s: 848.335 1612973180.5126688
train: epoch 5, iter 4500, loss: 3.193627, top_1: 0.448906, top_k: 0.694727, samples/s: 845.136 1612973210.8036585
train: epoch 5, iter 4600, loss: 3.382574, top_1: 0.454688, top_k: 0.701914, samples/s: 847.817 1612973240.9987824
train: epoch 5, iter 4700, loss: 3.145779, top_1: 0.454844, top_k: 0.701484, samples/s: 851.045 1612973271.0794504
train: epoch 5, iter 4800, loss: 3.347753, top_1: 0.452617, top_k: 0.703945, samples/s: 844.703 1612973301.3860276
train: epoch 5, iter 4900, loss: 3.373597, top_1: 0.448867, top_k: 0.700937, samples/s: 847.267 1612973331.6008458
train: epoch 5, iter 5000, loss: 3.269347, top_1: 0.454219, top_k: 0.701367, samples/s: 849.665 1612973361.7303486
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_5.
validation: epoch 5, iter 195, top_1: 0.502304, top_k: 0.761799, samples/s: 2458.870 1612973382.941459
train: epoch 6, iter 100, loss: 3.273502, top_1: 0.459297, top_k: 0.709531, samples/s: 866.292 1612973433.582365
train: epoch 6, iter 200, loss: 3.169486, top_1: 0.459531, top_k: 0.701680, samples/s: 866.621 1612973463.1224802
train: epoch 6, iter 300, loss: 3.335385, top_1: 0.455898, top_k: 0.702383, samples/s: 853.978 1612973493.0995443
train: epoch 6, iter 400, loss: 3.101495, top_1: 0.453867, top_k: 0.701641, samples/s: 845.508 1612973523.377251
train: epoch 6, iter 500, loss: 3.203513, top_1: 0.455977, top_k: 0.705703, samples/s: 844.665 1612973553.6851647
train: epoch 6, iter 600, loss: 3.343853, top_1: 0.457266, top_k: 0.704609, samples/s: 848.053 1612973583.8719306
train: epoch 6, iter 700, loss: 3.383947, top_1: 0.459922, top_k: 0.706250, samples/s: 846.051 1612973614.1301255
train: epoch 6, iter 800, loss: 3.193448, top_1: 0.452617, top_k: 0.699258, samples/s: 848.794 1612973644.2906115
train: epoch 6, iter 900, loss: 3.207242, top_1: 0.453984, top_k: 0.704492, samples/s: 845.804 1612973674.557709
train: epoch 6, iter 1000, loss: 3.328602, top_1: 0.466445, top_k: 0.713555, samples/s: 845.298 1612973704.84281
train: epoch 6, iter 1100, loss: 3.285234, top_1: 0.459648, top_k: 0.706250, samples/s: 846.788 1612973735.0747643
train: epoch 6, iter 1200, loss: 2.997281, top_1: 0.465156, top_k: 0.711797, samples/s: 849.104 1612973765.2241914
train: epoch 6, iter 1300, loss: 3.366705, top_1: 0.465195, top_k: 0.704844, samples/s: 845.073 1612973795.5174532
train: epoch 6, iter 1400, loss: 3.173624, top_1: 0.465430, top_k: 0.716133, samples/s: 847.621 1612973825.7195253
train: epoch 6, iter 1500, loss: 3.200366, top_1: 0.463203, top_k: 0.706953, samples/s: 846.458 1612973855.9632912
train: epoch 6, iter 1600, loss: 3.346202, top_1: 0.456094, top_k: 0.706055, samples/s: 847.911 1612973886.1550567
train: epoch 6, iter 1700, loss: 3.385720, top_1: 0.460977, top_k: 0.706758, samples/s: 846.438 1612973916.3994246
train: epoch 6, iter 1800, loss: 3.269919, top_1: 0.463555, top_k: 0.707422, samples/s: 849.157 1612973946.5470192
train: epoch 6, iter 1900, loss: 3.102030, top_1: 0.463125, top_k: 0.707187, samples/s: 847.422 1612973976.7563963
train: epoch 6, iter 2000, loss: 3.439729, top_1: 0.462187, top_k: 0.711680, samples/s: 845.706 1612974007.0268831
train: epoch 6, iter 2100, loss: 3.292830, top_1: 0.461641, top_k: 0.708047, samples/s: 845.305 1612974037.3118083
train: epoch 6, iter 2200, loss: 3.524705, top_1: 0.465117, top_k: 0.709219, samples/s: 848.185 1612974067.4937994
train: epoch 6, iter 2300, loss: 3.422969, top_1: 0.457852, top_k: 0.704492, samples/s: 851.053 1612974097.5742986
train: epoch 6, iter 2400, loss: 3.324605, top_1: 0.453672, top_k: 0.703672, samples/s: 845.541 1612974127.850752
train: epoch 6, iter 2500, loss: 3.463533, top_1: 0.461875, top_k: 0.706797, samples/s: 848.806 1612974158.0107477
train: epoch 6, iter 2600, loss: 3.212265, top_1: 0.465273, top_k: 0.708438, samples/s: 847.679 1612974188.2108657
train: epoch 6, iter 2700, loss: 3.255142, top_1: 0.463867, top_k: 0.708555, samples/s: 850.043 1612974218.3269129
train: epoch 6, iter 2800, loss: 3.378447, top_1: 0.460430, top_k: 0.706641, samples/s: 845.689 1612974248.5980546
train: epoch 6, iter 2900, loss: 3.382193, top_1: 0.465117, top_k: 0.708125, samples/s: 848.976 1612974278.752103
train: epoch 6, iter 3000, loss: 3.192850, top_1: 0.466172, top_k: 0.711094, samples/s: 848.627 1612974308.9183946
train: epoch 6, iter 3100, loss: 3.281098, top_1: 0.467109, top_k: 0.713242, samples/s: 849.486 1612974339.0543623
train: epoch 6, iter 3200, loss: 3.128090, top_1: 0.463789, top_k: 0.711641, samples/s: 849.049 1612974369.2056503
train: epoch 6, iter 3300, loss: 3.242543, top_1: 0.461250, top_k: 0.708516, samples/s: 845.242 1612974399.492903
train: epoch 6, iter 3400, loss: 3.297589, top_1: 0.465938, top_k: 0.712187, samples/s: 848.217 1612974429.6737628
train: epoch 6, iter 3500, loss: 3.252282, top_1: 0.466250, top_k: 0.712930, samples/s: 850.363 1612974459.778583
train: epoch 6, iter 3600, loss: 3.147652, top_1: 0.467617, top_k: 0.715781, samples/s: 847.437 1612974489.987399
train: epoch 6, iter 3700, loss: 3.197185, top_1: 0.460781, top_k: 0.708555, samples/s: 849.819 1612974520.11144
train: epoch 6, iter 3800, loss: 3.312834, top_1: 0.462187, top_k: 0.710703, samples/s: 846.636 1612974550.348731
train: epoch 6, iter 3900, loss: 3.208398, top_1: 0.468984, top_k: 0.712578, samples/s: 847.081 1612974580.5701337
train: epoch 6, iter 4000, loss: 3.327976, top_1: 0.467969, top_k: 0.710273, samples/s: 846.654 1612974610.8068893
train: epoch 6, iter 4100, loss: 3.402122, top_1: 0.465430, top_k: 0.711445, samples/s: 848.027 1612974640.9944806
train: epoch 6, iter 4200, loss: 3.136555, top_1: 0.464375, top_k: 0.710859, samples/s: 850.050 1612974671.1103988
train: epoch 6, iter 4300, loss: 3.285102, top_1: 0.468125, top_k: 0.713047, samples/s: 845.891 1612974701.3743217
train: epoch 6, iter 4400, loss: 3.239586, top_1: 0.463672, top_k: 0.706758, samples/s: 845.634 1612974731.6475344
train: epoch 6, iter 4500, loss: 3.046096, top_1: 0.466484, top_k: 0.714844, samples/s: 848.312 1612974761.8250754
train: epoch 6, iter 4600, loss: 3.164760, top_1: 0.466367, top_k: 0.711406, samples/s: 849.924 1612974791.9454892
train: epoch 6, iter 4700, loss: 3.201100, top_1: 0.464258, top_k: 0.716680, samples/s: 847.597 1612974822.148469
train: epoch 6, iter 4800, loss: 3.163795, top_1: 0.462383, top_k: 0.710039, samples/s: 845.367 1612974852.4311962
train: epoch 6, iter 4900, loss: 3.396595, top_1: 0.466133, top_k: 0.708164, samples/s: 851.874 1612974882.4825459
train: epoch 6, iter 5000, loss: 3.457117, top_1: 0.468828, top_k: 0.715195, samples/s: 846.566 1612974912.7224255
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_6.
validation: epoch 6, iter 195, top_1: 0.512881, top_k: 0.771014, samples/s: 2460.189 1612974933.9154277
train: epoch 7, iter 100, loss: 3.246852, top_1: 0.468438, top_k: 0.721406, samples/s: 870.265 1612974984.8252258
train: epoch 7, iter 200, loss: 3.200130, top_1: 0.476094, top_k: 0.721953, samples/s: 867.744 1612975014.3272176
train: epoch 7, iter 300, loss: 3.224061, top_1: 0.477109, top_k: 0.722227, samples/s: 855.754 1612975044.2421317
train: epoch 7, iter 400, loss: 3.366626, top_1: 0.475820, top_k: 0.721406, samples/s: 843.852 1612975074.579306
train: epoch 7, iter 500, loss: 3.220522, top_1: 0.483320, top_k: 0.725938, samples/s: 846.964 1612975104.8048608
train: epoch 7, iter 600, loss: 3.059176, top_1: 0.478438, top_k: 0.720352, samples/s: 846.706 1612975135.0397263
train: epoch 7, iter 700, loss: 3.171320, top_1: 0.471016, top_k: 0.718711, samples/s: 849.235 1612975165.184514
train: epoch 7, iter 800, loss: 3.347910, top_1: 0.471016, top_k: 0.720000, samples/s: 845.321 1612975195.4688537
train: epoch 7, iter 900, loss: 3.002845, top_1: 0.477930, top_k: 0.719023, samples/s: 849.259 1612975225.6127114
train: epoch 7, iter 1000, loss: 3.291705, top_1: 0.476992, top_k: 0.720469, samples/s: 843.966 1612975255.945721
train: epoch 7, iter 1100, loss: 3.177987, top_1: 0.474687, top_k: 0.719961, samples/s: 850.609 1612975286.0418124
train: epoch 7, iter 1200, loss: 3.092061, top_1: 0.473789, top_k: 0.721523, samples/s: 843.407 1612975316.3948808
train: epoch 7, iter 1300, loss: 3.262995, top_1: 0.480977, top_k: 0.726367, samples/s: 848.019 1612975346.582921
train: epoch 7, iter 1400, loss: 3.370476, top_1: 0.471797, top_k: 0.722500, samples/s: 845.458 1612975376.8623621
train: epoch 7, iter 1500, loss: 3.254032, top_1: 0.470234, top_k: 0.716094, samples/s: 847.130 1612975407.0819807
train: epoch 7, iter 1600, loss: 3.184409, top_1: 0.473516, top_k: 0.720898, samples/s: 848.991 1612975437.2354615
train: epoch 7, iter 1700, loss: 3.267097, top_1: 0.477305, top_k: 0.721875, samples/s: 845.742 1612975467.5047257
train: epoch 7, iter 1800, loss: 3.293462, top_1: 0.471367, top_k: 0.713867, samples/s: 848.743 1612975497.6669676
train: epoch 7, iter 1900, loss: 3.223756, top_1: 0.478008, top_k: 0.722852, samples/s: 846.210 1612975527.9194481
train: epoch 7, iter 2000, loss: 3.003077, top_1: 0.478359, top_k: 0.726328, samples/s: 850.652 1612975558.0140264
train: epoch 7, iter 2100, loss: 3.225980, top_1: 0.467344, top_k: 0.716562, samples/s: 848.679 1612975588.1786032
train: epoch 7, iter 2200, loss: 3.050708, top_1: 0.475313, top_k: 0.719180, samples/s: 848.360 1612975618.3544798
train: epoch 7, iter 2300, loss: 3.105908, top_1: 0.478906, top_k: 0.725313, samples/s: 849.656 1612975648.4843318
train: epoch 7, iter 2400, loss: 3.435817, top_1: 0.472617, top_k: 0.719023, samples/s: 848.539 1612975678.653894
train: epoch 7, iter 2500, loss: 3.244691, top_1: 0.471719, top_k: 0.718125, samples/s: 844.998 1612975708.9498074
train: epoch 7, iter 2600, loss: 3.390658, top_1: 0.476641, top_k: 0.724844, samples/s: 846.735 1612975739.1835308
train: epoch 7, iter 2700, loss: 3.188793, top_1: 0.474414, top_k: 0.721016, samples/s: 847.873 1612975769.3768091
train: epoch 7, iter 2800, loss: 3.160438, top_1: 0.474102, top_k: 0.719336, samples/s: 847.386 1612975799.5873103
train: epoch 7, iter 2900, loss: 3.158642, top_1: 0.474180, top_k: 0.720820, samples/s: 847.819 1612975829.782422
train: epoch 7, iter 3000, loss: 3.323576, top_1: 0.472266, top_k: 0.716875, samples/s: 846.530 1612975860.0235205
train: epoch 7, iter 3100, loss: 3.259674, top_1: 0.468281, top_k: 0.719922, samples/s: 848.687 1612975890.187774
train: epoch 7, iter 3200, loss: 3.187840, top_1: 0.477812, top_k: 0.723281, samples/s: 847.037 1612975920.4106753
train: epoch 7, iter 3300, loss: 3.260823, top_1: 0.480078, top_k: 0.722891, samples/s: 846.127 1612975950.6662543
train: epoch 7, iter 3400, loss: 3.465120, top_1: 0.477187, top_k: 0.722578, samples/s: 850.781 1612975980.7562497
train: epoch 7, iter 3500, loss: 3.263878, top_1: 0.482344, top_k: 0.723828, samples/s: 847.894 1612976010.9487216
train: epoch 7, iter 3600, loss: 3.292084, top_1: 0.478281, top_k: 0.725664, samples/s: 848.598 1612976041.1161146
train: epoch 7, iter 3700, loss: 3.264875, top_1: 0.475742, top_k: 0.722656, samples/s: 848.825 1612976071.2754297
train: epoch 7, iter 3800, loss: 3.265840, top_1: 0.475938, top_k: 0.720000, samples/s: 850.701 1612976101.3682816
train: epoch 7, iter 3900, loss: 3.199425, top_1: 0.480742, top_k: 0.722266, samples/s: 849.501 1612976131.5036106
train: epoch 7, iter 4000, loss: 3.204583, top_1: 0.481250, top_k: 0.721953, samples/s: 846.784 1612976161.7355814
train: epoch 7, iter 4100, loss: 3.377516, top_1: 0.479063, top_k: 0.725430, samples/s: 849.016 1612976191.8882015
train: epoch 7, iter 4200, loss: 3.203307, top_1: 0.475938, top_k: 0.714922, samples/s: 848.212 1612976222.0693665
train: epoch 7, iter 4300, loss: 3.216662, top_1: 0.476875, top_k: 0.727578, samples/s: 850.033 1612976252.185846
train: epoch 7, iter 4400, loss: 3.082015, top_1: 0.477695, top_k: 0.722578, samples/s: 847.681 1612976282.3857796
train: epoch 7, iter 4500, loss: 3.202641, top_1: 0.479883, top_k: 0.724609, samples/s: 843.879 1612976312.7218778
train: epoch 7, iter 4600, loss: 3.166658, top_1: 0.480273, top_k: 0.725039, samples/s: 849.348 1612976342.8626914
train: epoch 7, iter 4700, loss: 3.105323, top_1: 0.481836, top_k: 0.724102, samples/s: 849.640 1612976372.9930868
train: epoch 7, iter 4800, loss: 3.146981, top_1: 0.480781, top_k: 0.723398, samples/s: 847.159 1612976403.2118495
train: epoch 7, iter 4900, loss: 3.155827, top_1: 0.486406, top_k: 0.730625, samples/s: 846.729 1612976433.4457707
train: epoch 7, iter 5000, loss: 2.967364, top_1: 0.476211, top_k: 0.723008, samples/s: 851.849 1612976463.4980168
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_7.
validation: epoch 7, iter 195, top_1: 0.525240, top_k: 0.777444, samples/s: 2457.343 1612976484.7584033
train: epoch 8, iter 100, loss: 3.023603, top_1: 0.490781, top_k: 0.735352, samples/s: 869.527 1612976535.2237582
train: epoch 8, iter 200, loss: 3.073107, top_1: 0.493320, top_k: 0.735547, samples/s: 868.874 1612976564.6871543
train: epoch 8, iter 300, loss: 3.323308, top_1: 0.480977, top_k: 0.729883, samples/s: 850.881 1612976594.7735922
train: epoch 8, iter 400, loss: 2.947883, top_1: 0.485859, top_k: 0.727070, samples/s: 848.191 1612976624.955448
train: epoch 8, iter 500, loss: 2.931087, top_1: 0.472539, top_k: 0.718086, samples/s: 847.652 1612976655.156508
train: epoch 8, iter 600, loss: 3.206584, top_1: 0.477773, top_k: 0.720781, samples/s: 846.916 1612976685.3839211
train: epoch 8, iter 700, loss: 3.140411, top_1: 0.483438, top_k: 0.726602, samples/s: 850.044 1612976715.499926
train: epoch 8, iter 800, loss: 3.088151, top_1: 0.483906, top_k: 0.726719, samples/s: 845.448 1612976745.7798266
train: epoch 8, iter 900, loss: 3.356008, top_1: 0.484219, top_k: 0.732344, samples/s: 847.009 1612976776.0037158
train: epoch 8, iter 1000, loss: 3.194115, top_1: 0.480156, top_k: 0.727734, samples/s: 847.841 1612976806.1980307
train: epoch 8, iter 1100, loss: 3.170242, top_1: 0.479609, top_k: 0.725625, samples/s: 850.403 1612976836.3013973
train: epoch 8, iter 1200, loss: 3.177942, top_1: 0.483789, top_k: 0.731758, samples/s: 846.253 1612976866.5524926
train: epoch 8, iter 1300, loss: 3.111498, top_1: 0.477187, top_k: 0.721953, samples/s: 846.285 1612976896.8023562
train: epoch 8, iter 1400, loss: 3.236100, top_1: 0.487812, top_k: 0.730664, samples/s: 849.741 1612976926.929096
train: epoch 8, iter 1500, loss: 3.092992, top_1: 0.483672, top_k: 0.727891, samples/s: 847.630 1612976957.1309676
train: epoch 8, iter 1600, loss: 3.118671, top_1: 0.486680, top_k: 0.731484, samples/s: 849.361 1612976987.2712991
train: epoch 8, iter 1700, loss: 3.162556, top_1: 0.485977, top_k: 0.728750, samples/s: 848.719 1612977017.4343865
train: epoch 8, iter 1800, loss: 3.088494, top_1: 0.482891, top_k: 0.729141, samples/s: 849.858 1612977047.557142
train: epoch 8, iter 1900, loss: 3.168384, top_1: 0.484609, top_k: 0.727930, samples/s: 849.229 1612977077.7020347
train: epoch 8, iter 2000, loss: 2.956800, top_1: 0.490703, top_k: 0.733437, samples/s: 848.266 1612977107.8812387
train: epoch 8, iter 2100, loss: 3.426425, top_1: 0.486445, top_k: 0.731719, samples/s: 848.260 1612977138.0607548
train: epoch 8, iter 2200, loss: 3.252045, top_1: 0.487148, top_k: 0.732031, samples/s: 850.203 1612977168.1711404
train: epoch 8, iter 2300, loss: 3.221094, top_1: 0.482148, top_k: 0.722773, samples/s: 846.434 1612977198.4157114
train: epoch 8, iter 2400, loss: 3.195701, top_1: 0.481953, top_k: 0.728672, samples/s: 847.563 1612977228.6198857
train: epoch 8, iter 2500, loss: 3.228778, top_1: 0.481445, top_k: 0.726953, samples/s: 848.788 1612977258.780606
train: epoch 8, iter 2600, loss: 3.088309, top_1: 0.483477, top_k: 0.729570, samples/s: 848.490 1612977288.9518633
train: epoch 8, iter 2700, loss: 3.208046, top_1: 0.486172, top_k: 0.732734, samples/s: 846.890 1612977319.180122
train: epoch 8, iter 2800, loss: 3.098304, top_1: 0.485000, top_k: 0.730820, samples/s: 848.802 1612977349.3403435
train: epoch 8, iter 2900, loss: 3.254854, top_1: 0.489961, top_k: 0.733359, samples/s: 848.677 1612977379.5049162
train: epoch 8, iter 3000, loss: 3.004811, top_1: 0.485469, top_k: 0.728555, samples/s: 848.083 1612977409.6905894
train: epoch 8, iter 3100, loss: 3.151154, top_1: 0.484141, top_k: 0.726875, samples/s: 852.221 1612977439.7297704
train: epoch 8, iter 3200, loss: 3.153641, top_1: 0.490625, top_k: 0.731563, samples/s: 845.784 1612977469.9975657
train: epoch 8, iter 3300, loss: 3.168226, top_1: 0.485352, top_k: 0.728125, samples/s: 847.136 1612977500.2170413
train: epoch 8, iter 3400, loss: 3.152001, top_1: 0.482930, top_k: 0.725430, samples/s: 848.256 1612977530.3965623
train: epoch 8, iter 3500, loss: 3.045393, top_1: 0.488477, top_k: 0.726758, samples/s: 848.780 1612977560.5575378
train: epoch 8, iter 3600, loss: 3.155573, top_1: 0.481328, top_k: 0.726289, samples/s: 849.191 1612977590.7038
train: epoch 8, iter 3700, loss: 3.165778, top_1: 0.489375, top_k: 0.735664, samples/s: 846.124 1612977620.9594934
train: epoch 8, iter 3800, loss: 3.108212, top_1: 0.486602, top_k: 0.730898, samples/s: 848.656 1612977651.1247256
train: epoch 8, iter 3900, loss: 3.288903, top_1: 0.486328, top_k: 0.730586, samples/s: 847.623 1612977681.3268533
train: epoch 8, iter 4000, loss: 3.143296, top_1: 0.485625, top_k: 0.728789, samples/s: 849.522 1612977711.461418
train: epoch 8, iter 4100, loss: 3.320066, top_1: 0.487070, top_k: 0.729414, samples/s: 848.259 1612977741.64088
train: epoch 8, iter 4200, loss: 3.109633, top_1: 0.485977, top_k: 0.732773, samples/s: 849.874 1612977771.7630882
train: epoch 8, iter 4300, loss: 3.221752, top_1: 0.484570, top_k: 0.733711, samples/s: 848.259 1612977801.9425535
train: epoch 8, iter 4400, loss: 3.190297, top_1: 0.482227, top_k: 0.728203, samples/s: 849.079 1612977832.0928144
train: epoch 8, iter 4500, loss: 2.996672, top_1: 0.487852, top_k: 0.730820, samples/s: 850.393 1612977862.1965947
train: epoch 8, iter 4600, loss: 3.193816, top_1: 0.486563, top_k: 0.734141, samples/s: 851.001 1612977892.2787976
train: epoch 8, iter 4700, loss: 3.190575, top_1: 0.493984, top_k: 0.735586, samples/s: 849.470 1612977922.4151554
train: epoch 8, iter 4800, loss: 3.191874, top_1: 0.486953, top_k: 0.733203, samples/s: 846.525 1612977952.6564553
train: epoch 8, iter 4900, loss: 2.987862, top_1: 0.489922, top_k: 0.731172, samples/s: 848.935 1612977982.8118813
train: epoch 8, iter 5000, loss: 3.224277, top_1: 0.492852, top_k: 0.736523, samples/s: 850.822 1612978012.900446
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_8.
validation: epoch 8, iter 195, top_1: 0.541827, top_k: 0.792909, samples/s: 2465.611 1612978034.038662
train: epoch 9, iter 100, loss: 3.064179, top_1: 0.500820, top_k: 0.742891, samples/s: 870.109 1612978084.199919
train: epoch 9, iter 200, loss: 2.960635, top_1: 0.501602, top_k: 0.743711, samples/s: 866.637 1612978113.7393968
train: epoch 9, iter 300, loss: 3.371713, top_1: 0.498555, top_k: 0.741406, samples/s: 853.322 1612978143.7397583
train: epoch 9, iter 400, loss: 3.014345, top_1: 0.498828, top_k: 0.743320, samples/s: 846.375 1612978173.9864178
train: epoch 9, iter 500, loss: 3.289480, top_1: 0.490820, top_k: 0.741250, samples/s: 848.037 1612978204.1737363
train: epoch 9, iter 600, loss: 3.174099, top_1: 0.492656, top_k: 0.732344, samples/s: 845.508 1612978234.4514644
train: epoch 9, iter 700, loss: 3.075457, top_1: 0.494414, top_k: 0.738437, samples/s: 848.173 1612978264.633913
train: epoch 9, iter 800, loss: 2.908674, top_1: 0.500117, top_k: 0.742148, samples/s: 845.651 1612978294.906471
train: epoch 9, iter 900, loss: 3.077247, top_1: 0.492969, top_k: 0.732930, samples/s: 847.536 1612978325.1117465
train: epoch 9, iter 1000, loss: 2.967908, top_1: 0.491953, top_k: 0.738594, samples/s: 852.873 1612978355.127887
train: epoch 9, iter 1100, loss: 3.105505, top_1: 0.494141, top_k: 0.736484, samples/s: 843.738 1612978385.4690187
train: epoch 9, iter 1200, loss: 3.366433, top_1: 0.489063, top_k: 0.735195, samples/s: 849.698 1612978415.5973444
train: epoch 9, iter 1300, loss: 3.033962, top_1: 0.493047, top_k: 0.734258, samples/s: 848.066 1612978445.7836676
train: epoch 9, iter 1400, loss: 2.917742, top_1: 0.497148, top_k: 0.736758, samples/s: 849.632 1612978475.914349
train: epoch 9, iter 1500, loss: 3.204334, top_1: 0.492812, top_k: 0.736797, samples/s: 847.618 1612978506.1166956
train: epoch 9, iter 1600, loss: 3.176651, top_1: 0.489180, top_k: 0.734609, samples/s: 849.055 1612978536.2679145
train: epoch 9, iter 1700, loss: 3.153161, top_1: 0.489727, top_k: 0.734336, samples/s: 845.737 1612978566.537336
train: epoch 9, iter 1800, loss: 3.194684, top_1: 0.495039, top_k: 0.731563, samples/s: 849.785 1612978596.6625783
train: epoch 9, iter 1900, loss: 2.985550, top_1: 0.494375, top_k: 0.738242, samples/s: 849.862 1612978626.785077
train: epoch 9, iter 2000, loss: 2.948109, top_1: 0.496094, top_k: 0.735977, samples/s: 848.318 1612978656.9623785
train: epoch 9, iter 2100, loss: 3.115561, top_1: 0.498477, top_k: 0.738867, samples/s: 844.854 1612978687.2635176
train: epoch 9, iter 2200, loss: 2.945168, top_1: 0.496094, top_k: 0.735313, samples/s: 848.221 1612978717.444337
train: epoch 9, iter 2300, loss: 3.122796, top_1: 0.497344, top_k: 0.737578, samples/s: 846.460 1612978747.6879745
train: epoch 9, iter 2400, loss: 3.068218, top_1: 0.499531, top_k: 0.737812, samples/s: 846.350 1612978777.935438
train: epoch 9, iter 2500, loss: 3.073914, top_1: 0.498008, top_k: 0.738320, samples/s: 846.913 1612978808.1629694
train: epoch 9, iter 2600, loss: 3.136939, top_1: 0.501016, top_k: 0.739805, samples/s: 852.221 1612978838.2021031
train: epoch 9, iter 2700, loss: 3.227869, top_1: 0.492734, top_k: 0.738359, samples/s: 846.109 1612978868.4581437
train: epoch 9, iter 2800, loss: 2.743031, top_1: 0.494219, top_k: 0.737187, samples/s: 846.697 1612978898.6933548
train: epoch 9, iter 2900, loss: 3.085979, top_1: 0.496719, top_k: 0.738164, samples/s: 849.716 1612978928.8211124
train: epoch 9, iter 3000, loss: 3.180750, top_1: 0.490898, top_k: 0.735313, samples/s: 845.870 1612978959.0857413
train: epoch 9, iter 3100, loss: 3.350950, top_1: 0.495781, top_k: 0.735352, samples/s: 848.937 1612978989.2411427
train: epoch 9, iter 3200, loss: 2.990695, top_1: 0.491055, top_k: 0.735000, samples/s: 850.599 1612979019.337478
train: epoch 9, iter 3300, loss: 3.037402, top_1: 0.490820, top_k: 0.733867, samples/s: 846.573 1612979049.5771022
train: epoch 9, iter 3400, loss: 3.084457, top_1: 0.492109, top_k: 0.738437, samples/s: 850.075 1612979079.6920507
train: epoch 9, iter 3500, loss: 3.202819, top_1: 0.488867, top_k: 0.734961, samples/s: 848.112 1612979109.8768182
train: epoch 9, iter 3600, loss: 3.184128, top_1: 0.497188, top_k: 0.740430, samples/s: 849.264 1612979140.020559
train: epoch 9, iter 3700, loss: 3.036881, top_1: 0.503633, top_k: 0.741445, samples/s: 847.004 1612979170.2447166
train: epoch 9, iter 3800, loss: 3.158438, top_1: 0.494492, top_k: 0.734570, samples/s: 849.958 1612979200.3637931
train: epoch 9, iter 3900, loss: 3.274269, top_1: 0.500664, top_k: 0.742383, samples/s: 846.902 1612979230.5916574
train: epoch 9, iter 4000, loss: 2.993263, top_1: 0.494766, top_k: 0.738437, samples/s: 849.779 1612979260.717129
train: epoch 9, iter 4100, loss: 3.121373, top_1: 0.494805, top_k: 0.739062, samples/s: 849.095 1612979290.8668895
train: epoch 9, iter 4200, loss: 3.201864, top_1: 0.498437, top_k: 0.738906, samples/s: 847.952 1612979321.0572953
train: epoch 9, iter 4300, loss: 3.325528, top_1: 0.493984, top_k: 0.736016, samples/s: 852.398 1612979351.0902214
train: epoch 9, iter 4400, loss: 3.276300, top_1: 0.491523, top_k: 0.733945, samples/s: 849.593 1612979381.2223902
train: epoch 9, iter 4500, loss: 3.216045, top_1: 0.496445, top_k: 0.741094, samples/s: 846.474 1612979411.4653952
train: epoch 9, iter 4600, loss: 3.182813, top_1: 0.495859, top_k: 0.734648, samples/s: 851.163 1612979441.541849
train: epoch 9, iter 4700, loss: 3.132404, top_1: 0.494688, top_k: 0.734375, samples/s: 848.753 1612979471.703798
train: epoch 9, iter 4800, loss: 2.999751, top_1: 0.498516, top_k: 0.739922, samples/s: 846.254 1612979501.954679
train: epoch 9, iter 4900, loss: 3.119663, top_1: 0.495547, top_k: 0.739883, samples/s: 847.208 1612979532.1716533
train: epoch 9, iter 5000, loss: 3.036813, top_1: 0.501016, top_k: 0.742070, samples/s: 848.782 1612979562.3324652
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_9.
validation: epoch 9, iter 195, top_1: 0.530228, top_k: 0.785978, samples/s: 2449.213 1612979583.6277049
train: epoch 10, iter 100, loss: 3.056004, top_1: 0.510352, top_k: 0.750938, samples/s: 870.350 1612979639.653199
train: epoch 10, iter 200, loss: 2.860634, top_1: 0.503594, top_k: 0.748516, samples/s: 869.258 1612979669.1035259
train: epoch 10, iter 300, loss: 2.997411, top_1: 0.500508, top_k: 0.742070, samples/s: 858.682 1612979698.9166858
train: epoch 10, iter 400, loss: 2.938912, top_1: 0.500742, top_k: 0.743125, samples/s: 848.139 1612979729.1004164
train: epoch 10, iter 500, loss: 3.096196, top_1: 0.501797, top_k: 0.745586, samples/s: 845.870 1612979759.3651094
train: epoch 10, iter 600, loss: 3.022258, top_1: 0.503125, top_k: 0.745586, samples/s: 848.261 1612979789.54455
train: epoch 10, iter 700, loss: 2.932156, top_1: 0.495820, top_k: 0.739688, samples/s: 850.377 1612979819.6488616
train: epoch 10, iter 800, loss: 3.097553, top_1: 0.511992, top_k: 0.746992, samples/s: 846.736 1612979849.882533
train: epoch 10, iter 900, loss: 3.190441, top_1: 0.505000, top_k: 0.747422, samples/s: 847.780 1612979880.0791235
train: epoch 10, iter 1000, loss: 3.022881, top_1: 0.499648, top_k: 0.743359, samples/s: 845.346 1612979910.3625784
train: epoch 10, iter 1100, loss: 3.065388, top_1: 0.504180, top_k: 0.743984, samples/s: 846.707 1612979940.5972853
train: epoch 10, iter 1200, loss: 3.034868, top_1: 0.503047, top_k: 0.747734, samples/s: 851.726 1612979970.6539783
train: epoch 10, iter 1300, loss: 3.126780, top_1: 0.503633, top_k: 0.742812, samples/s: 848.312 1612980000.8315587
train: epoch 10, iter 1400, loss: 2.989837, top_1: 0.507852, top_k: 0.748516, samples/s: 847.786 1612980031.0277436
train: epoch 10, iter 1500, loss: 3.288306, top_1: 0.508359, top_k: 0.746719, samples/s: 851.346 1612980061.097811
train: epoch 10, iter 1600, loss: 3.253478, top_1: 0.497695, top_k: 0.737656, samples/s: 847.128 1612980091.3176553
train: epoch 10, iter 1700, loss: 3.182426, top_1: 0.504922, top_k: 0.747109, samples/s: 847.578 1612980121.521257
train: epoch 10, iter 1800, loss: 3.096182, top_1: 0.502266, top_k: 0.745391, samples/s: 850.583 1612980151.618309
train: epoch 10, iter 1900, loss: 3.148530, top_1: 0.497695, top_k: 0.740508, samples/s: 847.290 1612980181.832284
train: epoch 10, iter 2000, loss: 2.956342, top_1: 0.499023, top_k: 0.739922, samples/s: 850.184 1612980211.9434903
train: epoch 10, iter 2100, loss: 3.075821, top_1: 0.505234, top_k: 0.746172, samples/s: 847.332 1612980242.1559088
train: epoch 10, iter 2200, loss: 2.963518, top_1: 0.502148, top_k: 0.745273, samples/s: 848.322 1612980272.3331602
train: epoch 10, iter 2300, loss: 3.113076, top_1: 0.502930, top_k: 0.740781, samples/s: 849.040 1612980302.4848468
train: epoch 10, iter 2400, loss: 3.181103, top_1: 0.498633, top_k: 0.740859, samples/s: 847.204 1612980332.701922
train: epoch 10, iter 2500, loss: 3.046999, top_1: 0.500977, top_k: 0.742695, samples/s: 849.575 1612980362.8345795
train: epoch 10, iter 2600, loss: 3.036894, top_1: 0.497344, top_k: 0.740039, samples/s: 849.528 1612980392.968972
train: epoch 10, iter 2700, loss: 3.075576, top_1: 0.501367, top_k: 0.742539, samples/s: 849.962 1612980423.0879076
train: epoch 10, iter 2800, loss: 3.239453, top_1: 0.503594, top_k: 0.742188, samples/s: 848.615 1612980453.2547796
train: epoch 10, iter 2900, loss: 2.930869, top_1: 0.501836, top_k: 0.746016, samples/s: 849.442 1612980483.3922184
train: epoch 10, iter 3000, loss: 3.175163, top_1: 0.502227, top_k: 0.747148, samples/s: 846.015 1612980513.6517117
train: epoch 10, iter 3100, loss: 3.055146, top_1: 0.495430, top_k: 0.738164, samples/s: 848.401 1612980543.8261578
train: epoch 10, iter 3200, loss: 3.093957, top_1: 0.502852, top_k: 0.743125, samples/s: 849.073 1612980573.9765906
train: epoch 10, iter 3300, loss: 3.144301, top_1: 0.501563, top_k: 0.741953, samples/s: 847.481 1612980604.183773
train: epoch 10, iter 3400, loss: 3.038096, top_1: 0.502656, top_k: 0.744414, samples/s: 849.193 1612980634.3300295
train: epoch 10, iter 3500, loss: 3.188945, top_1: 0.505078, top_k: 0.742148, samples/s: 846.904 1612980664.5577803
train: epoch 10, iter 3600, loss: 3.148984, top_1: 0.500625, top_k: 0.742070, samples/s: 848.787 1612980694.7185671
train: epoch 10, iter 3700, loss: 3.150127, top_1: 0.500898, top_k: 0.743125, samples/s: 845.407 1612980724.9998333
train: epoch 10, iter 3800, loss: 2.982589, top_1: 0.500508, top_k: 0.740469, samples/s: 851.077 1612980755.079314
train: epoch 10, iter 3900, loss: 3.026434, top_1: 0.500898, top_k: 0.744375, samples/s: 849.062 1612980785.2302966
train: epoch 10, iter 4000, loss: 3.136493, top_1: 0.504258, top_k: 0.744570, samples/s: 848.893 1612980815.3872375
train: epoch 10, iter 4100, loss: 3.211922, top_1: 0.494883, top_k: 0.740234, samples/s: 849.215 1612980845.5327263
train: epoch 10, iter 4200, loss: 3.070945, top_1: 0.498125, top_k: 0.740625, samples/s: 847.371 1612980875.7437792
train: epoch 10, iter 4300, loss: 3.150987, top_1: 0.503125, top_k: 0.742578, samples/s: 849.003 1612980905.8967957
train: epoch 10, iter 4400, loss: 3.196839, top_1: 0.504141, top_k: 0.744492, samples/s: 849.046 1612980936.0482488
train: epoch 10, iter 4500, loss: 3.020534, top_1: 0.501953, top_k: 0.743594, samples/s: 848.616 1612980966.2149951
train: epoch 10, iter 4600, loss: 3.150769, top_1: 0.503164, top_k: 0.742344, samples/s: 850.540 1612980996.3135056
train: epoch 10, iter 4700, loss: 3.035571, top_1: 0.500586, top_k: 0.742266, samples/s: 848.269 1612981026.4926784
train: epoch 10, iter 4800, loss: 3.062229, top_1: 0.500938, top_k: 0.741914, samples/s: 850.086 1612981056.6071844
train: epoch 10, iter 4900, loss: 2.875463, top_1: 0.505664, top_k: 0.747305, samples/s: 850.179 1612981086.7185354
train: epoch 10, iter 5000, loss: 3.002474, top_1: 0.505664, top_k: 0.750508, samples/s: 847.325 1612981116.9312756
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_10.
validation: epoch 10, iter 195, top_1: 0.561338, top_k: 0.807893, samples/s: 2415.510 1612981138.4861982
train: epoch 11, iter 100, loss: 3.219363, top_1: 0.508867, top_k: 0.750273, samples/s: 869.615 1612981190.3343408
train: epoch 11, iter 200, loss: 3.160792, top_1: 0.507227, top_k: 0.748359, samples/s: 866.295 1612981219.8854837
train: epoch 11, iter 300, loss: 2.848716, top_1: 0.509766, top_k: 0.749961, samples/s: 856.217 1612981249.7844234
train: epoch 11, iter 400, loss: 3.019497, top_1: 0.510391, top_k: 0.749687, samples/s: 845.712 1612981280.0548012
train: epoch 11, iter 500, loss: 3.195625, top_1: 0.512461, top_k: 0.753984, samples/s: 847.169 1612981310.2729976
train: epoch 11, iter 600, loss: 3.112154, top_1: 0.507031, top_k: 0.747812, samples/s: 847.460 1612981340.4810283
train: epoch 11, iter 700, loss: 3.073296, top_1: 0.508281, top_k: 0.750703, samples/s: 850.300 1612981370.5879822
train: epoch 11, iter 800, loss: 2.976599, top_1: 0.506914, top_k: 0.750938, samples/s: 845.900 1612981400.8515944
train: epoch 11, iter 900, loss: 2.951471, top_1: 0.502305, top_k: 0.743984, samples/s: 846.898 1612981431.0795462
train: epoch 11, iter 1000, loss: 2.957908, top_1: 0.507773, top_k: 0.747383, samples/s: 849.609 1612981461.2111313
train: epoch 11, iter 1100, loss: 3.033464, top_1: 0.508242, top_k: 0.747461, samples/s: 844.713 1612981491.5172293
train: epoch 11, iter 1200, loss: 2.885171, top_1: 0.510117, top_k: 0.748633, samples/s: 847.266 1612981521.7321374
train: epoch 11, iter 1300, loss: 2.929690, top_1: 0.510391, top_k: 0.750195, samples/s: 851.438 1612981551.7988632
train: epoch 11, iter 1400, loss: 3.036945, top_1: 0.506680, top_k: 0.747656, samples/s: 845.742 1612981582.0681624
train: epoch 11, iter 1500, loss: 2.856180, top_1: 0.512227, top_k: 0.749883, samples/s: 849.825 1612981612.1920037
train: epoch 11, iter 1600, loss: 3.046128, top_1: 0.513984, top_k: 0.753750, samples/s: 846.067 1612981642.4495595
train: epoch 11, iter 1700, loss: 3.291821, top_1: 0.502812, top_k: 0.745586, samples/s: 848.407 1612981672.6238093
train: epoch 11, iter 1800, loss: 3.233068, top_1: 0.510469, top_k: 0.744805, samples/s: 847.783 1612981702.8202224
train: epoch 11, iter 1900, loss: 3.192420, top_1: 0.506016, top_k: 0.745391, samples/s: 850.927 1612981732.9051497
train: epoch 11, iter 2000, loss: 2.902225, top_1: 0.503945, top_k: 0.744219, samples/s: 847.565 1612981763.109203
train: epoch 11, iter 2100, loss: 3.107124, top_1: 0.502539, top_k: 0.745234, samples/s: 847.565 1612981793.313387
train: epoch 11, iter 2200, loss: 3.231080, top_1: 0.509414, top_k: 0.747539, samples/s: 848.079 1612981823.4993021
train: epoch 11, iter 2300, loss: 3.178960, top_1: 0.505156, top_k: 0.746758, samples/s: 848.979 1612981853.6531756
train: epoch 11, iter 2400, loss: 2.958123, top_1: 0.506953, top_k: 0.750469, samples/s: 848.252 1612981883.8328192
train: epoch 11, iter 2500, loss: 3.111251, top_1: 0.509609, top_k: 0.751016, samples/s: 847.968 1612981914.0226798
train: epoch 11, iter 2600, loss: 3.070243, top_1: 0.506641, top_k: 0.747109, samples/s: 848.421 1612981944.1963496
train: epoch 11, iter 2700, loss: 3.136527, top_1: 0.512109, top_k: 0.749336, samples/s: 851.128 1612981974.274152
train: epoch 11, iter 2800, loss: 3.115507, top_1: 0.519062, top_k: 0.755430, samples/s: 847.865 1612982004.4676297
train: epoch 11, iter 2900, loss: 3.144629, top_1: 0.506680, top_k: 0.748086, samples/s: 846.769 1612982034.7002006
train: epoch 11, iter 3000, loss: 3.165040, top_1: 0.504492, top_k: 0.747305, samples/s: 850.523 1612982064.7992873
train: epoch 11, iter 3100, loss: 3.187654, top_1: 0.510625, top_k: 0.750039, samples/s: 847.976 1612982094.988839
train: epoch 11, iter 3200, loss: 2.951965, top_1: 0.506641, top_k: 0.746797, samples/s: 847.475 1612982125.1961453
train: epoch 11, iter 3300, loss: 3.153854, top_1: 0.511172, top_k: 0.747070, samples/s: 850.955 1612982155.2800872
train: epoch 11, iter 3400, loss: 2.999669, top_1: 0.506719, top_k: 0.742148, samples/s: 848.274 1612982185.458928
train: epoch 11, iter 3500, loss: 2.842027, top_1: 0.507109, top_k: 0.745430, samples/s: 848.398 1612982215.6334968
train: epoch 11, iter 3600, loss: 3.176547, top_1: 0.507930, top_k: 0.747461, samples/s: 848.821 1612982245.792935
train: epoch 11, iter 3700, loss: 3.016263, top_1: 0.515859, top_k: 0.750898, samples/s: 847.727 1612982275.9913306
train: epoch 11, iter 3800, loss: 3.050169, top_1: 0.505430, top_k: 0.748672, samples/s: 850.711 1612982306.0838456
train: epoch 11, iter 3900, loss: 3.033093, top_1: 0.505391, top_k: 0.749492, samples/s: 847.172 1612982336.3021
train: epoch 11, iter 4000, loss: 2.872981, top_1: 0.507969, top_k: 0.748789, samples/s: 850.043 1612982366.4181263
train: epoch 11, iter 4100, loss: 3.106966, top_1: 0.505352, top_k: 0.751328, samples/s: 850.496 1612982396.5183141
train: epoch 11, iter 4200, loss: 3.102754, top_1: 0.501484, top_k: 0.745156, samples/s: 846.158 1612982426.7726402
train: epoch 11, iter 4300, loss: 2.872871, top_1: 0.512070, top_k: 0.748906, samples/s: 850.122 1612982456.8859317
train: epoch 11, iter 4400, loss: 3.183396, top_1: 0.503164, top_k: 0.739258, samples/s: 845.869 1612982487.15071
train: epoch 11, iter 4500, loss: 3.108569, top_1: 0.510273, top_k: 0.750234, samples/s: 851.492 1612982517.2156124
train: epoch 11, iter 4600, loss: 2.948714, top_1: 0.506094, top_k: 0.745664, samples/s: 847.988 1612982547.4047294
train: epoch 11, iter 4700, loss: 2.983984, top_1: 0.508047, top_k: 0.744375, samples/s: 848.376 1612982577.5799587
train: epoch 11, iter 4800, loss: 3.165220, top_1: 0.504453, top_k: 0.745273, samples/s: 853.693 1612982607.567325
train: epoch 11, iter 4900, loss: 3.144027, top_1: 0.504375, top_k: 0.746016, samples/s: 848.541 1612982637.7368178
train: epoch 11, iter 5000, loss: 2.964720, top_1: 0.506758, top_k: 0.749570, samples/s: 849.175 1612982667.8837347
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_11.
validation: epoch 11, iter 195, top_1: 0.558854, top_k: 0.805990, samples/s: 2406.509 1612982689.5336237
train: epoch 12, iter 100, loss: 3.021359, top_1: 0.515664, top_k: 0.753750, samples/s: 871.325 1612982739.5841477
train: epoch 12, iter 200, loss: 3.028728, top_1: 0.525156, top_k: 0.762031, samples/s: 865.937 1612982769.1475356
train: epoch 12, iter 300, loss: 2.915360, top_1: 0.516953, top_k: 0.756992, samples/s: 854.495 1612982799.10674
train: epoch 12, iter 400, loss: 3.037369, top_1: 0.524258, top_k: 0.760508, samples/s: 849.438 1612982829.244307
train: epoch 12, iter 500, loss: 3.141823, top_1: 0.515156, top_k: 0.755508, samples/s: 849.322 1612982859.3859603
train: epoch 12, iter 600, loss: 2.993682, top_1: 0.520898, top_k: 0.759219, samples/s: 844.751 1612982889.690773
train: epoch 12, iter 700, loss: 2.975120, top_1: 0.520781, top_k: 0.759375, samples/s: 847.413 1612982919.9004037
train: epoch 12, iter 800, loss: 3.238740, top_1: 0.516563, top_k: 0.754805, samples/s: 848.025 1612982950.0881453
train: epoch 12, iter 900, loss: 3.010522, top_1: 0.513711, top_k: 0.755234, samples/s: 849.609 1612982980.2197201
train: epoch 12, iter 1000, loss: 2.770410, top_1: 0.522773, top_k: 0.759648, samples/s: 845.687 1612983010.490976
train: epoch 12, iter 1100, loss: 2.981025, top_1: 0.515039, top_k: 0.748711, samples/s: 849.495 1612983040.6264627
train: epoch 12, iter 1200, loss: 2.925246, top_1: 0.516055, top_k: 0.750313, samples/s: 850.903 1612983070.7122073
train: epoch 12, iter 1300, loss: 2.964458, top_1: 0.508242, top_k: 0.750078, samples/s: 849.827 1612983100.8359756
train: epoch 12, iter 1400, loss: 2.980005, top_1: 0.516016, top_k: 0.751914, samples/s: 847.838 1612983131.0304062
train: epoch 12, iter 1500, loss: 3.086128, top_1: 0.512969, top_k: 0.751211, samples/s: 850.676 1612983161.1241543
train: epoch 12, iter 1600, loss: 2.937304, top_1: 0.513555, top_k: 0.750469, samples/s: 851.173 1612983191.2003276
train: epoch 12, iter 1700, loss: 3.321245, top_1: 0.513945, top_k: 0.751133, samples/s: 848.753 1612983221.3621335
train: epoch 12, iter 1800, loss: 3.092494, top_1: 0.519492, top_k: 0.754258, samples/s: 850.584 1612983251.459105
train: epoch 12, iter 1900, loss: 2.981320, top_1: 0.510234, top_k: 0.749609, samples/s: 847.925 1612983281.650553
train: epoch 12, iter 2000, loss: 3.007304, top_1: 0.510156, top_k: 0.753164, samples/s: 849.013 1612983311.803097
train: epoch 12, iter 2100, loss: 2.776134, top_1: 0.512578, top_k: 0.750313, samples/s: 850.050 1612983341.9190114
train: epoch 12, iter 2200, loss: 3.120160, top_1: 0.515977, top_k: 0.752305, samples/s: 851.738 1612983371.9752724
train: epoch 12, iter 2300, loss: 3.104188, top_1: 0.514492, top_k: 0.752070, samples/s: 849.313 1612983402.1172037
train: epoch 12, iter 2400, loss: 3.088984, top_1: 0.515039, top_k: 0.751797, samples/s: 850.789 1612983432.2069812
train: epoch 12, iter 2500, loss: 3.053673, top_1: 0.512188, top_k: 0.749414, samples/s: 849.595 1612983462.3389792
train: epoch 12, iter 2600, loss: 3.075085, top_1: 0.517305, top_k: 0.752422, samples/s: 851.002 1612983492.421122
train: epoch 12, iter 2700, loss: 2.895035, top_1: 0.506953, top_k: 0.752852, samples/s: 852.244 1612983522.4594862
train: epoch 12, iter 2800, loss: 2.946753, top_1: 0.511641, top_k: 0.751172, samples/s: 851.079 1612983552.539005
train: epoch 12, iter 2900, loss: 2.980622, top_1: 0.516953, top_k: 0.751016, samples/s: 852.544 1612983582.5666585
train: epoch 12, iter 3000, loss: 3.184779, top_1: 0.512070, top_k: 0.753398, samples/s: 849.785 1612983612.6920602
train: epoch 12, iter 3100, loss: 3.107277, top_1: 0.515000, top_k: 0.752383, samples/s: 850.866 1612983642.7790375
train: epoch 12, iter 3200, loss: 3.038974, top_1: 0.512070, top_k: 0.750859, samples/s: 850.136 1612983672.8918788
train: epoch 12, iter 3300, loss: 2.982011, top_1: 0.520234, top_k: 0.756992, samples/s: 850.581 1612983702.9889662
train: epoch 12, iter 3400, loss: 3.181780, top_1: 0.513711, top_k: 0.751172, samples/s: 851.047 1612983733.0695832
train: epoch 12, iter 3500, loss: 2.747929, top_1: 0.511680, top_k: 0.751328, samples/s: 850.805 1612983763.1587548
train: epoch 12, iter 3600, loss: 3.073135, top_1: 0.513555, top_k: 0.751016, samples/s: 850.197 1612983793.2694342
train: epoch 12, iter 3700, loss: 3.040464, top_1: 0.511836, top_k: 0.750977, samples/s: 853.629 1612983823.2589676
train: epoch 12, iter 3800, loss: 3.156955, top_1: 0.511836, top_k: 0.747500, samples/s: 850.597 1612983853.3555713
train: epoch 12, iter 3900, loss: 3.211812, top_1: 0.513516, top_k: 0.749609, samples/s: 852.221 1612983883.3945997
train: epoch 12, iter 4000, loss: 3.205871, top_1: 0.515586, top_k: 0.751602, samples/s: 849.540 1612983913.5285368
train: epoch 12, iter 4100, loss: 3.071605, top_1: 0.515312, top_k: 0.751016, samples/s: 853.220 1612983943.5325186
train: epoch 12, iter 4200, loss: 3.021060, top_1: 0.510547, top_k: 0.750703, samples/s: 850.310 1612983973.6392944
train: epoch 12, iter 4300, loss: 2.989095, top_1: 0.514062, top_k: 0.752227, samples/s: 850.020 1612984003.7562525
train: epoch 12, iter 4400, loss: 2.773045, top_1: 0.514883, top_k: 0.751563, samples/s: 852.909 1612984033.7710931
train: epoch 12, iter 4500, loss: 3.064322, top_1: 0.519727, top_k: 0.755039, samples/s: 850.496 1612984063.8711498
train: epoch 12, iter 4600, loss: 2.972585, top_1: 0.515977, top_k: 0.755625, samples/s: 851.784 1612984093.9257984
train: epoch 12, iter 4700, loss: 3.079782, top_1: 0.510117, top_k: 0.750820, samples/s: 851.991 1612984123.9730875
train: epoch 12, iter 4800, loss: 3.202069, top_1: 0.506641, top_k: 0.750000, samples/s: 850.230 1612984154.0825334
train: epoch 12, iter 4900, loss: 2.866526, top_1: 0.518711, top_k: 0.756172, samples/s: 850.043 1612984184.1987302
train: epoch 12, iter 5000, loss: 2.942052, top_1: 0.511563, top_k: 0.749609, samples/s: 849.178 1612984214.3455033
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_12.
validation: epoch 12, iter 195, top_1: 0.560296, top_k: 0.806631, samples/s: 2471.343 1612984235.4492989
train: epoch 13, iter 100, loss: 3.160011, top_1: 0.523828, top_k: 0.758359, samples/s: 868.157 1612984285.0886161
train: epoch 13, iter 200, loss: 2.994369, top_1: 0.518594, top_k: 0.757188, samples/s: 868.250 1612984314.57322
train: epoch 13, iter 300, loss: 2.974080, top_1: 0.521055, top_k: 0.756133, samples/s: 853.631 1612984344.5627694
train: epoch 13, iter 400, loss: 2.930118, top_1: 0.517656, top_k: 0.760625, samples/s: 848.727 1612984374.7256095
train: epoch 13, iter 500, loss: 3.182241, top_1: 0.521992, top_k: 0.764844, samples/s: 848.123 1612984404.9099865
train: epoch 13, iter 600, loss: 3.003501, top_1: 0.521289, top_k: 0.762266, samples/s: 846.616 1612984435.1479108
train: epoch 13, iter 700, loss: 2.896704, top_1: 0.519375, top_k: 0.756563, samples/s: 849.454 1612984465.2850397
train: epoch 13, iter 800, loss: 3.073982, top_1: 0.517148, top_k: 0.761680, samples/s: 844.753 1612984495.589631
train: epoch 13, iter 900, loss: 2.980419, top_1: 0.520703, top_k: 0.761055, samples/s: 850.824 1612984525.678193
train: epoch 13, iter 1000, loss: 3.012895, top_1: 0.519375, top_k: 0.760312, samples/s: 849.754 1612984555.804504
train: epoch 13, iter 1100, loss: 3.200749, top_1: 0.512305, top_k: 0.752969, samples/s: 846.533 1612984586.04544
train: epoch 13, iter 1200, loss: 2.990671, top_1: 0.516641, top_k: 0.756172, samples/s: 850.496 1612984616.1455567
train: epoch 13, iter 1300, loss: 2.966539, top_1: 0.523594, top_k: 0.762539, samples/s: 844.287 1612984646.467028
train: epoch 13, iter 1400, loss: 3.116687, top_1: 0.516680, top_k: 0.755703, samples/s: 848.756 1612984676.6288157
train: epoch 13, iter 1500, loss: 2.874847, top_1: 0.518086, top_k: 0.753906, samples/s: 846.724 1612984706.8629122
train: epoch 13, iter 1600, loss: 3.296424, top_1: 0.516680, top_k: 0.754609, samples/s: 847.660 1612984737.0637906
train: epoch 13, iter 1700, loss: 3.014635, top_1: 0.523945, top_k: 0.756563, samples/s: 849.985 1612984767.181927
train: epoch 13, iter 1800, loss: 3.267927, top_1: 0.515547, top_k: 0.751328, samples/s: 844.907 1612984797.4811356
train: epoch 13, iter 1900, loss: 3.013977, top_1: 0.513789, top_k: 0.753633, samples/s: 849.182 1612984827.6278067
train: epoch 13, iter 2000, loss: 2.974145, top_1: 0.515508, top_k: 0.755313, samples/s: 843.723 1612984857.9695528
train: epoch 13, iter 2100, loss: 3.004328, top_1: 0.517109, top_k: 0.756758, samples/s: 848.023 1612984888.15732
train: epoch 13, iter 2200, loss: 3.122966, top_1: 0.520117, top_k: 0.757109, samples/s: 850.137 1612984918.2701483
train: epoch 13, iter 2300, loss: 2.866007, top_1: 0.520898, top_k: 0.758594, samples/s: 847.327 1612984948.4828343
train: epoch 13, iter 2400, loss: 3.099381, top_1: 0.518164, top_k: 0.759102, samples/s: 850.621 1612984978.5785244
train: epoch 13, iter 2500, loss: 2.896597, top_1: 0.520508, top_k: 0.757695, samples/s: 846.125 1612985008.8340268
train: epoch 13, iter 2600, loss: 3.155262, top_1: 0.515938, top_k: 0.759492, samples/s: 847.528 1612985039.0394883
train: epoch 13, iter 2700, loss: 2.934158, top_1: 0.523477, top_k: 0.762500, samples/s: 847.978 1612985069.2289405
train: epoch 13, iter 2800, loss: 3.169548, top_1: 0.523906, top_k: 0.758008, samples/s: 848.563 1612985099.3975997
train: epoch 13, iter 2900, loss: 3.083698, top_1: 0.517070, top_k: 0.750195, samples/s: 847.038 1612985129.6207192
train: epoch 13, iter 3000, loss: 2.952509, top_1: 0.514609, top_k: 0.754883, samples/s: 848.187 1612985159.8026319
train: epoch 13, iter 3100, loss: 3.098557, top_1: 0.517070, top_k: 0.754492, samples/s: 844.729 1612985190.108243
train: epoch 13, iter 3200, loss: 2.990809, top_1: 0.520117, top_k: 0.753320, samples/s: 847.833 1612985220.3028347
train: epoch 13, iter 3300, loss: 2.896037, top_1: 0.519805, top_k: 0.755703, samples/s: 848.299 1612985250.4809217
train: epoch 13, iter 3400, loss: 2.940433, top_1: 0.520664, top_k: 0.762344, samples/s: 849.365 1612985280.6209762
train: epoch 13, iter 3500, loss: 3.162729, top_1: 0.517422, top_k: 0.753867, samples/s: 845.635 1612985310.8940814
train: epoch 13, iter 3600, loss: 3.078171, top_1: 0.519453, top_k: 0.759414, samples/s: 846.088 1612985341.1510122
train: epoch 13, iter 3700, loss: 3.080989, top_1: 0.511914, top_k: 0.752891, samples/s: 848.606 1612985371.3181138
train: epoch 13, iter 3800, loss: 3.134060, top_1: 0.510820, top_k: 0.754453, samples/s: 848.439 1612985401.491248
train: epoch 13, iter 3900, loss: 3.137371, top_1: 0.515000, top_k: 0.754062, samples/s: 847.707 1612985431.6902652
train: epoch 13, iter 4000, loss: 2.874774, top_1: 0.518789, top_k: 0.756523, samples/s: 847.919 1612985461.881906
train: epoch 13, iter 4100, loss: 3.001156, top_1: 0.515742, top_k: 0.749297, samples/s: 848.873 1612985492.0394795
train: epoch 13, iter 4200, loss: 3.056300, top_1: 0.518984, top_k: 0.757266, samples/s: 847.784 1612985522.2358649
train: epoch 13, iter 4300, loss: 3.154799, top_1: 0.518945, top_k: 0.755742, samples/s: 847.370 1612985552.4470332
train: epoch 13, iter 4400, loss: 3.137505, top_1: 0.518672, top_k: 0.758594, samples/s: 849.043 1612985582.5985265
train: epoch 13, iter 4500, loss: 3.108570, top_1: 0.520273, top_k: 0.755117, samples/s: 846.156 1612985612.8530853
train: epoch 13, iter 4600, loss: 3.061577, top_1: 0.509141, top_k: 0.753750, samples/s: 846.631 1612985643.0905588
train: epoch 13, iter 4700, loss: 3.088620, top_1: 0.517852, top_k: 0.758242, samples/s: 850.681 1612985673.1840973
train: epoch 13, iter 4800, loss: 3.000782, top_1: 0.514258, top_k: 0.751992, samples/s: 846.865 1612985703.4131584
train: epoch 13, iter 4900, loss: 2.880465, top_1: 0.519375, top_k: 0.758750, samples/s: 847.878 1612985733.60624
train: epoch 13, iter 5000, loss: 2.976375, top_1: 0.519375, top_k: 0.758047, samples/s: 847.088 1612985763.8274035
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_13.
validation: epoch 13, iter 195, top_1: 0.569772, top_k: 0.814944, samples/s: 2466.112 1612985784.9717655
train: epoch 14, iter 100, loss: 3.050163, top_1: 0.534648, top_k: 0.768437, samples/s: 867.975 1612985835.5310616
train: epoch 14, iter 200, loss: 2.741967, top_1: 0.526719, top_k: 0.760039, samples/s: 866.862 1612985865.0630867
train: epoch 14, iter 300, loss: 2.919806, top_1: 0.524453, top_k: 0.760977, samples/s: 852.336 1612985895.0979736
train: epoch 14, iter 400, loss: 2.799511, top_1: 0.525586, top_k: 0.762656, samples/s: 848.633 1612985925.2641401
train: epoch 14, iter 500, loss: 2.894453, top_1: 0.532109, top_k: 0.763750, samples/s: 845.530 1612985955.5409527
train: epoch 14, iter 600, loss: 3.023778, top_1: 0.528164, top_k: 0.765273, samples/s: 848.803 1612985985.7012064
train: epoch 14, iter 700, loss: 3.180612, top_1: 0.522852, top_k: 0.756602, samples/s: 845.561 1612986015.9768877
train: epoch 14, iter 800, loss: 2.750921, top_1: 0.528125, top_k: 0.764336, samples/s: 846.805 1612986046.2081785
train: epoch 14, iter 900, loss: 2.861134, top_1: 0.526523, top_k: 0.766289, samples/s: 847.589 1612986076.4114752
train: epoch 14, iter 1000, loss: 3.011383, top_1: 0.524258, top_k: 0.763242, samples/s: 845.460 1612986106.690802
train: epoch 14, iter 1100, loss: 2.854241, top_1: 0.524570, top_k: 0.760312, samples/s: 849.561 1612986136.82401
train: epoch 14, iter 1200, loss: 3.208507, top_1: 0.526016, top_k: 0.764219, samples/s: 845.895 1612986167.0878155
train: epoch 14, iter 1300, loss: 3.074073, top_1: 0.523008, top_k: 0.758320, samples/s: 844.898 1612986197.3874483
train: epoch 14, iter 1400, loss: 2.840852, top_1: 0.520000, top_k: 0.757266, samples/s: 842.875 1612986227.7595894
train: epoch 14, iter 1500, loss: 2.833598, top_1: 0.520977, top_k: 0.763516, samples/s: 851.486 1612986257.8247292
train: epoch 14, iter 1600, loss: 3.152560, top_1: 0.525039, top_k: 0.761406, samples/s: 845.351 1612986288.1079488
train: epoch 14, iter 1700, loss: 3.034717, top_1: 0.531406, top_k: 0.764258, samples/s: 849.021 1612986318.2604132
train: epoch 14, iter 1800, loss: 2.820956, top_1: 0.520273, top_k: 0.759570, samples/s: 843.405 1612986348.613496
train: epoch 14, iter 1900, loss: 3.169419, top_1: 0.519180, top_k: 0.754922, samples/s: 847.512 1612986378.8195467
train: epoch 14, iter 2000, loss: 2.931011, top_1: 0.524727, top_k: 0.766992, samples/s: 847.057 1612986409.0418339
train: epoch 14, iter 2100, loss: 2.888466, top_1: 0.524453, top_k: 0.758906, samples/s: 848.398 1612986439.2163582
train: epoch 14, iter 2200, loss: 3.065474, top_1: 0.524570, top_k: 0.760273, samples/s: 845.939 1612986469.4786386
train: epoch 14, iter 2300, loss: 3.202583, top_1: 0.519570, top_k: 0.757695, samples/s: 849.706 1612986499.6066806
train: epoch 14, iter 2400, loss: 3.079336, top_1: 0.525703, top_k: 0.762813, samples/s: 845.781 1612986529.8745651
train: epoch 14, iter 2500, loss: 3.020536, top_1: 0.524414, top_k: 0.761406, samples/s: 850.913 1612986559.959908
train: epoch 14, iter 2600, loss: 3.001975, top_1: 0.521016, top_k: 0.759648, samples/s: 848.633 1612986590.1261208
train: epoch 14, iter 2700, loss: 2.885407, top_1: 0.525156, top_k: 0.758711, samples/s: 846.605 1612986620.3644643
train: epoch 14, iter 2800, loss: 3.021883, top_1: 0.525820, top_k: 0.763945, samples/s: 848.892 1612986650.5215437
train: epoch 14, iter 2900, loss: 3.152997, top_1: 0.524492, top_k: 0.761211, samples/s: 847.025 1612986680.7448878
train: epoch 14, iter 3000, loss: 2.990773, top_1: 0.509453, top_k: 0.754141, samples/s: 845.672 1612986711.0167375
train: epoch 14, iter 3100, loss: 2.866436, top_1: 0.523359, top_k: 0.756680, samples/s: 848.491 1612986741.1878517
train: epoch 14, iter 3200, loss: 2.801868, top_1: 0.526133, top_k: 0.760977, samples/s: 847.909 1612986771.3798802
train: epoch 14, iter 3300, loss: 3.055206, top_1: 0.519687, top_k: 0.759180, samples/s: 846.325 1612986801.6282146
train: epoch 14, iter 3400, loss: 3.024259, top_1: 0.528242, top_k: 0.760547, samples/s: 848.003 1612986831.8167908
train: epoch 14, iter 3500, loss: 2.938349, top_1: 0.520312, top_k: 0.762695, samples/s: 846.314 1612986862.0656955
train: epoch 14, iter 3600, loss: 3.092491, top_1: 0.522617, top_k: 0.755938, samples/s: 846.560 1612986892.3056226
train: epoch 14, iter 3700, loss: 2.872260, top_1: 0.523398, top_k: 0.759883, samples/s: 845.351 1612986922.588915
train: epoch 14, iter 3800, loss: 3.009517, top_1: 0.525742, top_k: 0.762656, samples/s: 847.449 1612986952.7972715
train: epoch 14, iter 3900, loss: 3.061667, top_1: 0.514219, top_k: 0.752891, samples/s: 845.395 1612986983.0788937
train: epoch 14, iter 4000, loss: 3.128545, top_1: 0.519375, top_k: 0.758750, samples/s: 847.816 1612987013.2741075
train: epoch 14, iter 4100, loss: 2.820901, top_1: 0.519297, top_k: 0.759531, samples/s: 848.542 1612987043.4435387
train: epoch 14, iter 4200, loss: 2.894246, top_1: 0.518945, top_k: 0.756719, samples/s: 845.224 1612987073.731419
train: epoch 14, iter 4300, loss: 2.893366, top_1: 0.525078, top_k: 0.760273, samples/s: 848.232 1612987103.9117637
train: epoch 14, iter 4400, loss: 2.854019, top_1: 0.520625, top_k: 0.762070, samples/s: 847.453 1612987134.120012
train: epoch 14, iter 4500, loss: 2.928938, top_1: 0.521289, top_k: 0.758320, samples/s: 843.088 1612987164.4846132
train: epoch 14, iter 4600, loss: 2.928112, top_1: 0.518789, top_k: 0.756602, samples/s: 848.178 1612987194.6668067
train: epoch 14, iter 4700, loss: 3.069222, top_1: 0.522109, top_k: 0.753398, samples/s: 846.668 1612987224.9030418
train: epoch 14, iter 4800, loss: 2.974674, top_1: 0.525352, top_k: 0.762539, samples/s: 846.454 1612987255.146915
train: epoch 14, iter 4900, loss: 2.862895, top_1: 0.523242, top_k: 0.759805, samples/s: 848.650 1612987285.3123817
train: epoch 14, iter 5000, loss: 2.943759, top_1: 0.526250, top_k: 0.760352, samples/s: 844.245 1612987315.6353357
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_14.
validation: epoch 14, iter 195, top_1: 0.571154, top_k: 0.816747, samples/s: 2454.270 1612987336.8893967
train: epoch 15, iter 100, loss: 2.715208, top_1: 0.535937, top_k: 0.772070, samples/s: 869.909 1612987387.8440382
train: epoch 15, iter 200, loss: 3.022679, top_1: 0.528008, top_k: 0.767617, samples/s: 867.702 1612987417.3472774
train: epoch 15, iter 300, loss: 3.019654, top_1: 0.532891, top_k: 0.765352, samples/s: 851.490 1612987447.4122658
train: epoch 15, iter 400, loss: 2.986243, top_1: 0.531758, top_k: 0.767500, samples/s: 848.888 1612987477.5692985
train: epoch 15, iter 500, loss: 3.024611, top_1: 0.535781, top_k: 0.765977, samples/s: 844.011 1612987507.9007297
train: epoch 15, iter 600, loss: 2.907461, top_1: 0.530469, top_k: 0.766953, samples/s: 845.879 1612987538.16503
train: epoch 15, iter 700, loss: 3.117927, top_1: 0.531406, top_k: 0.766836, samples/s: 846.408 1612987568.4104931
train: epoch 15, iter 800, loss: 2.946761, top_1: 0.523203, top_k: 0.762227, samples/s: 846.628 1612987598.6480868
train: epoch 15, iter 900, loss: 2.830194, top_1: 0.529961, top_k: 0.769922, samples/s: 847.822 1612987628.8430552
train: epoch 15, iter 1000, loss: 2.853126, top_1: 0.531680, top_k: 0.766172, samples/s: 845.468 1612987659.1222613
train: epoch 15, iter 1100, loss: 3.169718, top_1: 0.532266, top_k: 0.766016, samples/s: 847.319 1612987689.335127
train: epoch 15, iter 1200, loss: 2.958034, top_1: 0.524570, top_k: 0.763594, samples/s: 847.202 1612987719.5522969
train: epoch 15, iter 1300, loss: 2.893930, top_1: 0.530273, top_k: 0.769297, samples/s: 849.398 1612987749.6912038
train: epoch 15, iter 1400, loss: 2.846375, top_1: 0.533398, top_k: 0.767930, samples/s: 846.035 1612987779.950064
train: epoch 15, iter 1500, loss: 3.020755, top_1: 0.531328, top_k: 0.768164, samples/s: 850.516 1612987810.0493965
train: epoch 15, iter 1600, loss: 2.993512, top_1: 0.526641, top_k: 0.761602, samples/s: 846.492 1612987840.2918315
train: epoch 15, iter 1700, loss: 2.871653, top_1: 0.525937, top_k: 0.768125, samples/s: 848.965 1612987870.4462311
train: epoch 15, iter 1800, loss: 2.938350, top_1: 0.526719, top_k: 0.760195, samples/s: 847.939 1612987900.6370494
train: epoch 15, iter 1900, loss: 2.882025, top_1: 0.527188, top_k: 0.761523, samples/s: 848.596 1612987930.8045676
train: epoch 15, iter 2000, loss: 3.059289, top_1: 0.527734, top_k: 0.762461, samples/s: 848.422 1612987960.9783108
train: epoch 15, iter 2100, loss: 2.900813, top_1: 0.525820, top_k: 0.759648, samples/s: 847.347 1612987991.190137
train: epoch 15, iter 2200, loss: 2.992378, top_1: 0.521836, top_k: 0.764492, samples/s: 849.240 1612988021.3347788
train: epoch 15, iter 2300, loss: 2.935139, top_1: 0.527852, top_k: 0.760703, samples/s: 845.765 1612988051.6032982
train: epoch 15, iter 2400, loss: 2.839625, top_1: 0.520195, top_k: 0.758359, samples/s: 849.283 1612988081.7463732
train: epoch 15, iter 2500, loss: 2.848601, top_1: 0.525352, top_k: 0.761367, samples/s: 848.438 1612988111.9194174
train: epoch 15, iter 2600, loss: 2.849660, top_1: 0.528906, top_k: 0.767969, samples/s: 847.025 1612988142.1428263
train: epoch 15, iter 2700, loss: 3.022882, top_1: 0.526172, top_k: 0.764023, samples/s: 845.782 1612988172.410667
train: epoch 15, iter 2800, loss: 2.970264, top_1: 0.526367, top_k: 0.763203, samples/s: 850.074 1612988202.5256848
train: epoch 15, iter 2900, loss: 2.965310, top_1: 0.528438, top_k: 0.761836, samples/s: 848.340 1612988232.7023513
train: epoch 15, iter 3000, loss: 2.742917, top_1: 0.523750, top_k: 0.768203, samples/s: 845.035 1612988262.996937
train: epoch 15, iter 3100, loss: 2.828099, top_1: 0.530039, top_k: 0.768086, samples/s: 846.350 1612988293.2443988
train: epoch 15, iter 3200, loss: 2.751157, top_1: 0.530625, top_k: 0.769531, samples/s: 849.907 1612988323.3654003
train: epoch 15, iter 3300, loss: 3.110275, top_1: 0.530039, top_k: 0.766016, samples/s: 846.420 1612988353.610366
train: epoch 15, iter 3400, loss: 2.887156, top_1: 0.528398, top_k: 0.763516, samples/s: 847.819 1612988383.8055859
train: epoch 15, iter 3500, loss: 2.956757, top_1: 0.521680, top_k: 0.758242, samples/s: 847.981 1612988413.994893
train: epoch 15, iter 3600, loss: 3.008553, top_1: 0.530117, top_k: 0.766133, samples/s: 848.532 1612988444.164679
train: epoch 15, iter 3700, loss: 3.052263, top_1: 0.523750, top_k: 0.758828, samples/s: 846.854 1612988474.394119
train: epoch 15, iter 3800, loss: 2.981250, top_1: 0.526094, top_k: 0.759766, samples/s: 843.862 1612988504.7308729
train: epoch 15, iter 3900, loss: 2.961020, top_1: 0.525664, top_k: 0.762500, samples/s: 852.970 1612988534.7436771
train: epoch 15, iter 4000, loss: 2.706555, top_1: 0.519258, top_k: 0.759922, samples/s: 847.894 1612988564.936117
train: epoch 15, iter 4100, loss: 3.024821, top_1: 0.523555, top_k: 0.759336, samples/s: 849.268 1612988595.0797029
train: epoch 15, iter 4200, loss: 3.001996, top_1: 0.526094, top_k: 0.763516, samples/s: 849.155 1612988625.227377
train: epoch 15, iter 4300, loss: 3.052547, top_1: 0.525703, top_k: 0.763437, samples/s: 850.787 1612988655.317041
train: epoch 15, iter 4400, loss: 3.029233, top_1: 0.521367, top_k: 0.760273, samples/s: 846.657 1612988685.5537047
train: epoch 15, iter 4500, loss: 2.898413, top_1: 0.527656, top_k: 0.760898, samples/s: 847.905 1612988715.7457058
train: epoch 15, iter 4600, loss: 2.977906, top_1: 0.529336, top_k: 0.765312, samples/s: 846.685 1612988745.981259
train: epoch 15, iter 4700, loss: 3.017393, top_1: 0.527539, top_k: 0.764336, samples/s: 847.905 1612988776.1733153
train: epoch 15, iter 4800, loss: 3.105390, top_1: 0.525977, top_k: 0.760664, samples/s: 850.182 1612988806.2846036
train: epoch 15, iter 4900, loss: 3.210200, top_1: 0.515039, top_k: 0.760469, samples/s: 849.901 1612988836.405778
train: epoch 15, iter 5000, loss: 2.824423, top_1: 0.521563, top_k: 0.762461, samples/s: 847.134 1612988866.6253006
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_15.
validation: epoch 15, iter 195, top_1: 0.580689, top_k: 0.820753, samples/s: 2417.450 1612988888.177504
train: epoch 16, iter 100, loss: 3.104970, top_1: 0.543398, top_k: 0.773633, samples/s: 871.723 1612988938.1778286
train: epoch 16, iter 200, loss: 2.871808, top_1: 0.537930, top_k: 0.772617, samples/s: 868.067 1612988967.6686356
train: epoch 16, iter 300, loss: 2.898605, top_1: 0.543594, top_k: 0.773555, samples/s: 852.801 1612988997.687313
train: epoch 16, iter 400, loss: 2.804806, top_1: 0.538438, top_k: 0.770156, samples/s: 849.556 1612989027.820801
train: epoch 16, iter 500, loss: 2.770680, top_1: 0.530977, top_k: 0.767500, samples/s: 845.978 1612989058.0815792
train: epoch 16, iter 600, loss: 3.017676, top_1: 0.529219, top_k: 0.768437, samples/s: 851.510 1612989088.1458066
train: epoch 16, iter 700, loss: 2.907657, top_1: 0.528359, top_k: 0.762461, samples/s: 847.571 1612989118.3497167
train: epoch 16, iter 800, loss: 2.990203, top_1: 0.529180, top_k: 0.767148, samples/s: 849.638 1612989148.4802637
train: epoch 16, iter 900, loss: 2.816801, top_1: 0.540781, top_k: 0.777891, samples/s: 845.730 1612989178.7499819
train: epoch 16, iter 1000, loss: 2.759474, top_1: 0.538594, top_k: 0.768320, samples/s: 849.649 1612989208.8800707
train: epoch 16, iter 1100, loss: 2.882050, top_1: 0.537383, top_k: 0.769922, samples/s: 847.661 1612989239.0808113
train: epoch 16, iter 1200, loss: 2.937195, top_1: 0.537383, top_k: 0.776328, samples/s: 848.848 1612989269.2393322
train: epoch 16, iter 1300, loss: 2.943652, top_1: 0.530312, top_k: 0.768633, samples/s: 847.541 1612989299.4445
train: epoch 16, iter 1400, loss: 2.972414, top_1: 0.527578, top_k: 0.763125, samples/s: 849.123 1612989329.59319
train: epoch 16, iter 1500, loss: 2.872331, top_1: 0.530430, top_k: 0.764062, samples/s: 850.709 1612989359.685678
train: epoch 16, iter 1600, loss: 2.994474, top_1: 0.529180, top_k: 0.768477, samples/s: 851.101 1612989389.7644086
train: epoch 16, iter 1700, loss: 2.888415, top_1: 0.529531, top_k: 0.766875, samples/s: 848.795 1612989419.9247642
train: epoch 16, iter 1800, loss: 2.943671, top_1: 0.527305, top_k: 0.763008, samples/s: 849.775 1612989450.0504458
train: epoch 16, iter 1900, loss: 2.782373, top_1: 0.523750, top_k: 0.760508, samples/s: 851.622 1612989480.1106453
train: epoch 16, iter 2000, loss: 2.953201, top_1: 0.534102, top_k: 0.769297, samples/s: 849.391 1612989510.2499573
train: epoch 16, iter 2100, loss: 3.009764, top_1: 0.527969, top_k: 0.764023, samples/s: 851.585 1612989540.3115394
train: epoch 16, iter 2200, loss: 2.910091, top_1: 0.529062, top_k: 0.761914, samples/s: 849.954 1612989570.4307547
train: epoch 16, iter 2300, loss: 2.931528, top_1: 0.529883, top_k: 0.763867, samples/s: 852.752 1612989600.4512582
train: epoch 16, iter 2400, loss: 2.972013, top_1: 0.530781, top_k: 0.764766, samples/s: 847.987 1612989630.640337
train: epoch 16, iter 2500, loss: 2.866032, top_1: 0.529727, top_k: 0.765430, samples/s: 853.669 1612989660.6285336
train: epoch 16, iter 2600, loss: 3.025980, top_1: 0.531602, top_k: 0.769492, samples/s: 849.174 1612989690.7754233
train: epoch 16, iter 2700, loss: 3.271279, top_1: 0.529648, top_k: 0.765039, samples/s: 852.980 1612989720.787936
train: epoch 16, iter 2800, loss: 2.885466, top_1: 0.527305, top_k: 0.765586, samples/s: 848.023 1612989750.975745
train: epoch 16, iter 2900, loss: 2.984492, top_1: 0.526094, top_k: 0.763437, samples/s: 848.219 1612989781.1566432
train: epoch 16, iter 3000, loss: 2.995493, top_1: 0.535352, top_k: 0.765469, samples/s: 854.482 1612989811.116353
train: epoch 16, iter 3100, loss: 2.959842, top_1: 0.529062, top_k: 0.766172, samples/s: 851.699 1612989841.1738307
train: epoch 16, iter 3200, loss: 3.184386, top_1: 0.534492, top_k: 0.766836, samples/s: 849.543 1612989871.3077211
train: epoch 16, iter 3300, loss: 3.061280, top_1: 0.527617, top_k: 0.763008, samples/s: 849.931 1612989901.4278858
train: epoch 16, iter 3400, loss: 2.976348, top_1: 0.532422, top_k: 0.768867, samples/s: 851.605 1612989931.4887657
train: epoch 16, iter 3500, loss: 2.954869, top_1: 0.531445, top_k: 0.764922, samples/s: 851.425 1612989961.5559833
train: epoch 16, iter 3600, loss: 2.898502, top_1: 0.533906, top_k: 0.765000, samples/s: 844.635 1612989991.864956
train: epoch 16, iter 3700, loss: 2.960091, top_1: 0.529141, top_k: 0.765586, samples/s: 852.622 1612990021.8898635
train: epoch 16, iter 3800, loss: 2.915212, top_1: 0.528516, top_k: 0.762617, samples/s: 850.207 1612990052.000179
train: epoch 16, iter 3900, loss: 3.068675, top_1: 0.530742, top_k: 0.767969, samples/s: 851.682 1612990082.0583937
train: epoch 16, iter 4000, loss: 3.075051, top_1: 0.529336, top_k: 0.769570, samples/s: 852.393 1612990112.0914676
train: epoch 16, iter 4100, loss: 2.926777, top_1: 0.523594, top_k: 0.760430, samples/s: 851.954 1612990142.1399877
train: epoch 16, iter 4200, loss: 2.870368, top_1: 0.531680, top_k: 0.765273, samples/s: 849.130 1612990172.2885911
train: epoch 16, iter 4300, loss: 3.110170, top_1: 0.531016, top_k: 0.766367, samples/s: 848.416 1612990202.4624252
train: epoch 16, iter 4400, loss: 2.938659, top_1: 0.531641, top_k: 0.764141, samples/s: 853.920 1612990232.4418204
train: epoch 16, iter 4500, loss: 2.822520, top_1: 0.529453, top_k: 0.763945, samples/s: 848.717 1612990262.6050537
train: epoch 16, iter 4600, loss: 3.092673, top_1: 0.528359, top_k: 0.766523, samples/s: 852.070 1612990292.649554
train: epoch 16, iter 4700, loss: 3.071127, top_1: 0.523203, top_k: 0.761172, samples/s: 851.162 1612990322.72599
train: epoch 16, iter 4800, loss: 2.667903, top_1: 0.528359, top_k: 0.764023, samples/s: 851.960 1612990352.7743585
train: epoch 16, iter 4900, loss: 2.937071, top_1: 0.529727, top_k: 0.767461, samples/s: 853.825 1612990382.7570775
train: epoch 16, iter 5000, loss: 3.048012, top_1: 0.533164, top_k: 0.766992, samples/s: 849.224 1612990412.9023123
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_16.
validation: epoch 16, iter 195, top_1: 0.582131, top_k: 0.823658, samples/s: 2429.765 1612990434.3311422
train: epoch 17, iter 100, loss: 2.953611, top_1: 0.537656, top_k: 0.773047, samples/s: 870.559 1612990484.5123723
train: epoch 17, iter 200, loss: 2.958710, top_1: 0.538242, top_k: 0.771172, samples/s: 868.205 1612990513.9984057
train: epoch 17, iter 300, loss: 2.841606, top_1: 0.538008, top_k: 0.774219, samples/s: 857.169 1612990543.864127
train: epoch 17, iter 400, loss: 2.744690, top_1: 0.539023, top_k: 0.771719, samples/s: 850.840 1612990573.952122
train: epoch 17, iter 500, loss: 2.908295, top_1: 0.538594, top_k: 0.769141, samples/s: 853.342 1612990603.9518006
train: epoch 17, iter 600, loss: 3.080300, top_1: 0.534766, top_k: 0.769258, samples/s: 848.222 1612990634.1325154
train: epoch 17, iter 700, loss: 3.092569, top_1: 0.536719, top_k: 0.770078, samples/s: 850.081 1612990664.2473598
train: epoch 17, iter 800, loss: 2.851843, top_1: 0.531563, top_k: 0.772656, samples/s: 852.682 1612990694.2702076
train: epoch 17, iter 900, loss: 2.975646, top_1: 0.538555, top_k: 0.775703, samples/s: 850.232 1612990724.3797493
train: epoch 17, iter 1000, loss: 2.827399, top_1: 0.527891, top_k: 0.768867, samples/s: 849.800 1612990754.504498
train: epoch 17, iter 1100, loss: 2.698787, top_1: 0.536914, top_k: 0.770469, samples/s: 852.732 1612990784.525541
train: epoch 17, iter 1200, loss: 2.818775, top_1: 0.536680, top_k: 0.767813, samples/s: 848.951 1612990814.6804242
train: epoch 17, iter 1300, loss: 3.176389, top_1: 0.534062, top_k: 0.771641, samples/s: 850.715 1612990844.7728689
train: epoch 17, iter 1400, loss: 3.077516, top_1: 0.538164, top_k: 0.768789, samples/s: 849.220 1612990874.9182105
train: epoch 17, iter 1500, loss: 2.910971, top_1: 0.534062, top_k: 0.767695, samples/s: 852.641 1612990904.9425397
train: epoch 17, iter 1600, loss: 2.844905, top_1: 0.529414, top_k: 0.769141, samples/s: 850.923 1612990935.0274212
train: epoch 17, iter 1700, loss: 2.884670, top_1: 0.536445, top_k: 0.771758, samples/s: 851.646 1612990965.0869582
train: epoch 17, iter 1800, loss: 2.916881, top_1: 0.538320, top_k: 0.772383, samples/s: 852.961 1612990995.0999494
train: epoch 17, iter 1900, loss: 2.855238, top_1: 0.535156, top_k: 0.768555, samples/s: 850.909 1612991025.185416
train: epoch 17, iter 2000, loss: 2.904195, top_1: 0.535898, top_k: 0.769531, samples/s: 851.706 1612991055.2427886
train: epoch 17, iter 2100, loss: 2.901914, top_1: 0.534453, top_k: 0.770859, samples/s: 854.043 1612991085.217934
train: epoch 17, iter 2200, loss: 2.883055, top_1: 0.537500, top_k: 0.770508, samples/s: 848.889 1612991115.3749914
train: epoch 17, iter 2300, loss: 3.088295, top_1: 0.534727, top_k: 0.768750, samples/s: 853.984 1612991145.3521595
train: epoch 17, iter 2400, loss: 2.738105, top_1: 0.542344, top_k: 0.772461, samples/s: 852.672 1612991175.375444
train: epoch 17, iter 2500, loss: 2.803905, top_1: 0.533633, top_k: 0.765586, samples/s: 852.258 1612991205.4132018
train: epoch 17, iter 2600, loss: 3.103831, top_1: 0.532109, top_k: 0.765859, samples/s: 853.313 1612991235.4139247
train: epoch 17, iter 2700, loss: 2.721409, top_1: 0.533594, top_k: 0.770469, samples/s: 851.535 1612991265.4772809
train: epoch 17, iter 2800, loss: 2.837399, top_1: 0.532891, top_k: 0.771758, samples/s: 854.363 1612991295.44154
train: epoch 17, iter 2900, loss: 2.942883, top_1: 0.530234, top_k: 0.765664, samples/s: 849.562 1612991325.574382
train: epoch 17, iter 3000, loss: 2.881056, top_1: 0.534687, top_k: 0.766953, samples/s: 853.437 1612991355.5706496
train: epoch 17, iter 3100, loss: 3.034022, top_1: 0.530664, top_k: 0.763125, samples/s: 854.139 1612991385.5423417
train: epoch 17, iter 3200, loss: 2.908792, top_1: 0.532461, top_k: 0.765703, samples/s: 854.784 1612991415.4914942
train: epoch 17, iter 3300, loss: 2.879515, top_1: 0.536289, top_k: 0.771641, samples/s: 851.665 1612991445.5502193
train: epoch 17, iter 3400, loss: 2.810155, top_1: 0.535625, top_k: 0.771406, samples/s: 853.369 1612991475.548994
train: epoch 17, iter 3500, loss: 3.038554, top_1: 0.536250, top_k: 0.768516, samples/s: 853.753 1612991505.5343301
train: epoch 17, iter 3600, loss: 3.049395, top_1: 0.528125, top_k: 0.769336, samples/s: 854.779 1612991535.4835818
train: epoch 17, iter 3700, loss: 2.771196, top_1: 0.537461, top_k: 0.773359, samples/s: 853.282 1612991565.4853983
train: epoch 17, iter 3800, loss: 2.930469, top_1: 0.534258, top_k: 0.771836, samples/s: 854.357 1612991595.4493818
train: epoch 17, iter 3900, loss: 2.929508, top_1: 0.533203, top_k: 0.769414, samples/s: 853.897 1612991625.4296246
train: epoch 17, iter 4000, loss: 2.883572, top_1: 0.534531, top_k: 0.768789, samples/s: 852.337 1612991655.464648
train: epoch 17, iter 4100, loss: 2.979492, top_1: 0.530586, top_k: 0.765938, samples/s: 852.385 1612991685.4980829
train: epoch 17, iter 4200, loss: 3.264067, top_1: 0.527148, top_k: 0.765938, samples/s: 853.728 1612991715.4841812
train: epoch 17, iter 4300, loss: 3.136299, top_1: 0.539453, top_k: 0.772617, samples/s: 853.596 1612991745.4749799
train: epoch 17, iter 4400, loss: 2.836199, top_1: 0.529062, top_k: 0.766211, samples/s: 852.702 1612991775.4971824
train: epoch 17, iter 4500, loss: 2.984873, top_1: 0.537148, top_k: 0.771211, samples/s: 853.203 1612991805.5016997
train: epoch 17, iter 4600, loss: 2.689682, top_1: 0.529375, top_k: 0.767070, samples/s: 852.600 1612991835.527438
train: epoch 17, iter 4700, loss: 2.731367, top_1: 0.535352, top_k: 0.764648, samples/s: 854.188 1612991865.4974484
train: epoch 17, iter 4800, loss: 2.957838, top_1: 0.533906, top_k: 0.766445, samples/s: 853.294 1612991895.4988997
train: epoch 17, iter 4900, loss: 2.768031, top_1: 0.535820, top_k: 0.770508, samples/s: 853.504 1612991925.4928844
train: epoch 17, iter 5000, loss: 2.764528, top_1: 0.535156, top_k: 0.769531, samples/s: 853.456 1612991955.4885757
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_17.
validation: epoch 17, iter 195, top_1: 0.588241, top_k: 0.825982, samples/s: 2462.604 1612991976.6521494
train: epoch 18, iter 100, loss: 2.775607, top_1: 0.546797, top_k: 0.777344, samples/s: 873.564 1612992026.6971967
train: epoch 18, iter 200, loss: 3.100013, top_1: 0.537695, top_k: 0.774375, samples/s: 869.746 1612992056.1309857
train: epoch 18, iter 300, loss: 2.766347, top_1: 0.535000, top_k: 0.774805, samples/s: 861.026 1612992085.8629193
train: epoch 18, iter 400, loss: 2.650170, top_1: 0.539687, top_k: 0.774609, samples/s: 850.833 1612992115.9511232
train: epoch 18, iter 500, loss: 2.841818, top_1: 0.544297, top_k: 0.776250, samples/s: 852.368 1612992145.985043
train: epoch 18, iter 600, loss: 2.947387, top_1: 0.544219, top_k: 0.781484, samples/s: 853.443 1612992175.9812567
train: epoch 18, iter 700, loss: 2.916096, top_1: 0.533047, top_k: 0.768398, samples/s: 850.479 1612992206.0819213
train: epoch 18, iter 800, loss: 3.123550, top_1: 0.535312, top_k: 0.775625, samples/s: 853.405 1612992236.079438
train: epoch 18, iter 900, loss: 2.912809, top_1: 0.534805, top_k: 0.768672, samples/s: 853.276 1612992266.0818026
train: epoch 18, iter 1000, loss: 3.049615, top_1: 0.539414, top_k: 0.779531, samples/s: 853.921 1612992296.0607147
train: epoch 18, iter 1100, loss: 2.912457, top_1: 0.542305, top_k: 0.779180, samples/s: 850.969 1612992326.144358
train: epoch 18, iter 1200, loss: 2.833757, top_1: 0.534844, top_k: 0.771914, samples/s: 851.566 1612992356.2063196
train: epoch 18, iter 1300, loss: 3.011481, top_1: 0.534062, top_k: 0.768281, samples/s: 851.262 1612992386.2793455
train: epoch 18, iter 1400, loss: 3.178933, top_1: 0.535273, top_k: 0.766484, samples/s: 850.872 1612992416.3661585
train: epoch 18, iter 1500, loss: 2.748273, top_1: 0.541094, top_k: 0.769062, samples/s: 854.626 1612992446.3208363
train: epoch 18, iter 1600, loss: 2.857749, top_1: 0.539766, top_k: 0.771523, samples/s: 850.225 1612992476.4305017
train: epoch 18, iter 1700, loss: 2.909959, top_1: 0.537891, top_k: 0.767617, samples/s: 852.342 1612992506.4653194
train: epoch 18, iter 1800, loss: 2.898379, top_1: 0.535820, top_k: 0.771406, samples/s: 851.575 1612992536.5272334
train: epoch 18, iter 1900, loss: 2.956164, top_1: 0.541328, top_k: 0.772891, samples/s: 854.227 1612992566.4958496
train: epoch 18, iter 2000, loss: 2.987076, top_1: 0.542422, top_k: 0.772734, samples/s: 854.208 1612992596.4651554
train: epoch 18, iter 2100, loss: 2.906159, top_1: 0.538281, top_k: 0.774219, samples/s: 853.913 1612992626.444793
train: epoch 18, iter 2200, loss: 2.768281, top_1: 0.537695, top_k: 0.770391, samples/s: 852.958 1612992656.4579608
train: epoch 18, iter 2300, loss: 2.817924, top_1: 0.535586, top_k: 0.770117, samples/s: 853.086 1612992686.4667833
train: epoch 18, iter 2400, loss: 2.735544, top_1: 0.537813, top_k: 0.772188, samples/s: 853.237 1612992716.4700847
train: epoch 18, iter 2500, loss: 2.981585, top_1: 0.535469, top_k: 0.773359, samples/s: 852.802 1612992746.4888504
train: epoch 18, iter 2600, loss: 2.918963, top_1: 0.533086, top_k: 0.766992, samples/s: 854.605 1612992776.4442506
train: epoch 18, iter 2700, loss: 2.874862, top_1: 0.540039, top_k: 0.773125, samples/s: 852.867 1612992806.4605837
train: epoch 18, iter 2800, loss: 3.032084, top_1: 0.537813, top_k: 0.771289, samples/s: 851.198 1612992836.5358486
train: epoch 18, iter 2900, loss: 3.034886, top_1: 0.537813, top_k: 0.773711, samples/s: 854.774 1612992866.4853091
train: epoch 18, iter 3000, loss: 2.911895, top_1: 0.533750, top_k: 0.768437, samples/s: 854.668 1612992896.4383686
train: epoch 18, iter 3100, loss: 3.006819, top_1: 0.536641, top_k: 0.772227, samples/s: 853.405 1612992926.4358468
train: epoch 18, iter 3200, loss: 2.886843, top_1: 0.538047, top_k: 0.771055, samples/s: 855.770 1612992956.3504448
train: epoch 18, iter 3300, loss: 2.940762, top_1: 0.536055, top_k: 0.772969, samples/s: 854.216 1612992986.319486
train: epoch 18, iter 3400, loss: 2.930667, top_1: 0.533750, top_k: 0.770664, samples/s: 853.188 1612993016.3246136
train: epoch 18, iter 3500, loss: 2.849689, top_1: 0.537734, top_k: 0.769648, samples/s: 851.179 1612993046.4006066
train: epoch 18, iter 3600, loss: 2.930396, top_1: 0.536445, top_k: 0.774492, samples/s: 852.199 1612993076.4404974
train: epoch 18, iter 3700, loss: 2.935723, top_1: 0.540703, top_k: 0.773008, samples/s: 855.774 1612993106.3548849
train: epoch 18, iter 3800, loss: 2.998357, top_1: 0.533281, top_k: 0.766094, samples/s: 854.693 1612993136.307234
train: epoch 18, iter 3900, loss: 2.960809, top_1: 0.539102, top_k: 0.772461, samples/s: 853.628 1612993166.2969003
train: epoch 18, iter 4000, loss: 2.892154, top_1: 0.537344, top_k: 0.771133, samples/s: 851.956 1612993196.34534
train: epoch 18, iter 4100, loss: 2.915689, top_1: 0.534219, top_k: 0.768164, samples/s: 852.930 1612993226.359524
train: epoch 18, iter 4200, loss: 3.089920, top_1: 0.538281, top_k: 0.767852, samples/s: 854.180 1612993256.3297718
train: epoch 18, iter 4300, loss: 2.878483, top_1: 0.533242, top_k: 0.765312, samples/s: 854.352 1612993286.2939851
train: epoch 18, iter 4400, loss: 2.919282, top_1: 0.530391, top_k: 0.767070, samples/s: 850.818 1612993316.3827457
train: epoch 18, iter 4500, loss: 3.009765, top_1: 0.531445, top_k: 0.768359, samples/s: 851.515 1612993346.446774
train: epoch 18, iter 4600, loss: 3.133947, top_1: 0.537734, top_k: 0.769023, samples/s: 853.801 1612993376.4303386
train: epoch 18, iter 4700, loss: 2.873291, top_1: 0.537227, top_k: 0.774727, samples/s: 854.406 1612993406.3927383
train: epoch 18, iter 4800, loss: 2.883965, top_1: 0.532383, top_k: 0.769609, samples/s: 853.297 1612993436.3939207
train: epoch 18, iter 4900, loss: 3.009347, top_1: 0.538789, top_k: 0.772539, samples/s: 851.745 1612993466.4498713
train: epoch 18, iter 5000, loss: 2.786009, top_1: 0.538477, top_k: 0.769922, samples/s: 852.917 1612993496.4645514
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_18.
validation: epoch 18, iter 195, top_1: 0.593510, top_k: 0.830389, samples/s: 2465.815 1612993517.5949557
train: epoch 19, iter 100, loss: 2.881770, top_1: 0.545195, top_k: 0.777461, samples/s: 869.653 1612993567.745472
train: epoch 19, iter 200, loss: 2.876708, top_1: 0.543008, top_k: 0.775742, samples/s: 868.713 1612993597.2142522
train: epoch 19, iter 300, loss: 3.122052, top_1: 0.544961, top_k: 0.774492, samples/s: 861.867 1612993626.917279
train: epoch 19, iter 400, loss: 2.826928, top_1: 0.546484, top_k: 0.780781, samples/s: 853.318 1612993656.9177437
train: epoch 19, iter 500, loss: 2.852384, top_1: 0.550039, top_k: 0.779375, samples/s: 850.407 1612993687.0209749
train: epoch 19, iter 600, loss: 2.611379, top_1: 0.551797, top_k: 0.780664, samples/s: 852.522 1612993717.0495262
train: epoch 19, iter 700, loss: 2.783540, top_1: 0.543945, top_k: 0.777617, samples/s: 853.769 1612993747.034266
train: epoch 19, iter 800, loss: 2.875791, top_1: 0.544883, top_k: 0.777070, samples/s: 853.517 1612993777.0277445
train: epoch 19, iter 900, loss: 3.204775, top_1: 0.542148, top_k: 0.772305, samples/s: 853.381 1612993807.0261471
train: epoch 19, iter 1000, loss: 3.165129, top_1: 0.541094, top_k: 0.775781, samples/s: 854.979 1612993836.968373
train: epoch 19, iter 1100, loss: 2.672763, top_1: 0.540625, top_k: 0.773555, samples/s: 852.855 1612993866.985237
train: epoch 19, iter 1200, loss: 2.717039, top_1: 0.543594, top_k: 0.777070, samples/s: 853.213 1612993896.9894595
train: epoch 19, iter 1300, loss: 2.840016, top_1: 0.542188, top_k: 0.774687, samples/s: 854.008 1612993926.9657364
train: epoch 19, iter 1400, loss: 2.880685, top_1: 0.537930, top_k: 0.772383, samples/s: 852.040 1612993957.0111716
train: epoch 19, iter 1500, loss: 2.781377, top_1: 0.540078, top_k: 0.772734, samples/s: 853.549 1612993987.0035763
train: epoch 19, iter 1600, loss: 2.883225, top_1: 0.538281, top_k: 0.772656, samples/s: 853.784 1612994016.98781
train: epoch 19, iter 1700, loss: 2.806310, top_1: 0.540625, top_k: 0.770195, samples/s: 853.673 1612994046.975841
train: epoch 19, iter 1800, loss: 2.949499, top_1: 0.534258, top_k: 0.773828, samples/s: 854.194 1612994076.9456172
train: epoch 19, iter 1900, loss: 3.092361, top_1: 0.538164, top_k: 0.774531, samples/s: 854.868 1612994106.8918512
train: epoch 19, iter 2000, loss: 2.877217, top_1: 0.537734, top_k: 0.771719, samples/s: 853.964 1612994136.8695838
train: epoch 19, iter 2100, loss: 2.944380, top_1: 0.536094, top_k: 0.773125, samples/s: 853.437 1612994166.8660305
train: epoch 19, iter 2200, loss: 2.739616, top_1: 0.541250, top_k: 0.773359, samples/s: 852.908 1612994196.8809154
train: epoch 19, iter 2300, loss: 2.773382, top_1: 0.545703, top_k: 0.780117, samples/s: 853.259 1612994226.8835704
train: epoch 19, iter 2400, loss: 2.873563, top_1: 0.542070, top_k: 0.774805, samples/s: 854.372 1612994256.8470654
train: epoch 19, iter 2500, loss: 2.933317, top_1: 0.544687, top_k: 0.775234, samples/s: 853.597 1612994286.8377483
train: epoch 19, iter 2600, loss: 2.980985, top_1: 0.536055, top_k: 0.768437, samples/s: 853.897 1612994316.8179355
train: epoch 19, iter 2700, loss: 2.859789, top_1: 0.540742, top_k: 0.772695, samples/s: 852.293 1612994346.8545823
train: epoch 19, iter 2800, loss: 2.922664, top_1: 0.539375, top_k: 0.773477, samples/s: 853.215 1612994376.8587291
train: epoch 19, iter 2900, loss: 2.831205, top_1: 0.538828, top_k: 0.772031, samples/s: 856.187 1612994406.7587106
train: epoch 19, iter 3000, loss: 2.908675, top_1: 0.533945, top_k: 0.772578, samples/s: 853.904 1612994436.738695
train: epoch 19, iter 3100, loss: 2.900178, top_1: 0.535859, top_k: 0.775625, samples/s: 854.800 1612994466.6872816
train: epoch 19, iter 3200, loss: 2.884177, top_1: 0.533906, top_k: 0.771367, samples/s: 853.342 1612994496.6869087
train: epoch 19, iter 3300, loss: 2.655882, top_1: 0.534180, top_k: 0.767578, samples/s: 850.745 1612994526.778215
train: epoch 19, iter 3400, loss: 2.969247, top_1: 0.540000, top_k: 0.772617, samples/s: 852.489 1612994556.8079545
train: epoch 19, iter 3500, loss: 2.821850, top_1: 0.538008, top_k: 0.773281, samples/s: 856.377 1612994586.7012727
train: epoch 19, iter 3600, loss: 2.836895, top_1: 0.542773, top_k: 0.775781, samples/s: 852.126 1612994616.743837
train: epoch 19, iter 3700, loss: 2.916028, top_1: 0.536094, top_k: 0.770430, samples/s: 854.303 1612994646.7097101
train: epoch 19, iter 3800, loss: 2.835974, top_1: 0.538008, top_k: 0.771055, samples/s: 854.003 1612994676.6861346
train: epoch 19, iter 3900, loss: 2.904881, top_1: 0.540859, top_k: 0.770859, samples/s: 852.201 1612994706.726094
train: epoch 19, iter 4000, loss: 3.045330, top_1: 0.538086, top_k: 0.771133, samples/s: 854.586 1612994736.6820662
train: epoch 19, iter 4100, loss: 3.001557, top_1: 0.534180, top_k: 0.769219, samples/s: 852.728 1612994766.7035
train: epoch 19, iter 4200, loss: 3.090398, top_1: 0.537500, top_k: 0.775352, samples/s: 854.212 1612994796.6725194
train: epoch 19, iter 4300, loss: 3.032190, top_1: 0.535547, top_k: 0.773047, samples/s: 853.119 1612994826.6801488
train: epoch 19, iter 4400, loss: 2.778559, top_1: 0.535586, top_k: 0.770156, samples/s: 851.217 1612994856.754694
train: epoch 19, iter 4500, loss: 2.878684, top_1: 0.534570, top_k: 0.768789, samples/s: 852.950 1612994886.7685082
train: epoch 19, iter 4600, loss: 2.996241, top_1: 0.537773, top_k: 0.768164, samples/s: 854.548 1612994916.7254765
train: epoch 19, iter 4700, loss: 2.691221, top_1: 0.542813, top_k: 0.775820, samples/s: 853.314 1612994946.7261178
train: epoch 19, iter 4800, loss: 2.893687, top_1: 0.544570, top_k: 0.773516, samples/s: 853.925 1612994976.7053456
train: epoch 19, iter 4900, loss: 2.880393, top_1: 0.539883, top_k: 0.770078, samples/s: 852.537 1612995006.733889
train: epoch 19, iter 5000, loss: 2.814582, top_1: 0.535391, top_k: 0.771992, samples/s: 853.453 1612995036.7291558
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_19.
validation: epoch 19, iter 195, top_1: 0.594551, top_k: 0.834956, samples/s: 2452.400 1612995057.992681
train: epoch 20, iter 100, loss: 2.913077, top_1: 0.547422, top_k: 0.775547, samples/s: 869.116 1612995108.303948
train: epoch 20, iter 200, loss: 2.671024, top_1: 0.542578, top_k: 0.774609, samples/s: 866.044 1612995137.8636653
train: epoch 20, iter 300, loss: 3.011202, top_1: 0.548438, top_k: 0.779766, samples/s: 856.359 1612995167.7576263
train: epoch 20, iter 400, loss: 2.949627, top_1: 0.536836, top_k: 0.775312, samples/s: 851.814 1612995197.8111894
train: epoch 20, iter 500, loss: 2.858294, top_1: 0.554141, top_k: 0.783555, samples/s: 856.888 1612995227.686653
train: epoch 20, iter 600, loss: 2.805041, top_1: 0.549961, top_k: 0.779023, samples/s: 851.670 1612995257.7453103
train: epoch 20, iter 700, loss: 2.865360, top_1: 0.545391, top_k: 0.779219, samples/s: 852.715 1612995287.7669647
train: epoch 20, iter 800, loss: 2.948042, top_1: 0.549609, top_k: 0.780391, samples/s: 851.303 1612995317.8386104
train: epoch 20, iter 900, loss: 2.729631, top_1: 0.543164, top_k: 0.780898, samples/s: 852.996 1612995347.8504624
train: epoch 20, iter 1000, loss: 2.909053, top_1: 0.542773, top_k: 0.775430, samples/s: 852.039 1612995377.8960528
train: epoch 20, iter 1100, loss: 2.829743, top_1: 0.547695, top_k: 0.782813, samples/s: 853.448 1612995407.891919
train: epoch 20, iter 1200, loss: 2.959966, top_1: 0.541680, top_k: 0.775000, samples/s: 852.911 1612995437.9067855
train: epoch 20, iter 1300, loss: 2.758470, top_1: 0.544453, top_k: 0.779414, samples/s: 854.265 1612995467.874157
train: epoch 20, iter 1400, loss: 2.885821, top_1: 0.536953, top_k: 0.773828, samples/s: 852.941 1612995497.887835
train: epoch 20, iter 1500, loss: 3.009156, top_1: 0.542578, top_k: 0.777109, samples/s: 852.690 1612995527.9105694
train: epoch 20, iter 1600, loss: 2.803596, top_1: 0.539766, top_k: 0.774219, samples/s: 853.213 1612995557.9147213
train: epoch 20, iter 1700, loss: 2.953030, top_1: 0.541719, top_k: 0.775078, samples/s: 852.291 1612995587.951402
train: epoch 20, iter 1800, loss: 3.004802, top_1: 0.542109, top_k: 0.776641, samples/s: 854.530 1612995617.9094489
train: epoch 20, iter 1900, loss: 2.872204, top_1: 0.539141, top_k: 0.771953, samples/s: 854.054 1612995647.8841934
train: epoch 20, iter 2000, loss: 2.883754, top_1: 0.549453, top_k: 0.783438, samples/s: 850.080 1612995677.9989297
train: epoch 20, iter 2100, loss: 2.769825, top_1: 0.541875, top_k: 0.775898, samples/s: 856.750 1612995707.8792503
train: epoch 20, iter 2200, loss: 2.844203, top_1: 0.543711, top_k: 0.779883, samples/s: 853.172 1612995737.8850281
train: epoch 20, iter 2300, loss: 2.989551, top_1: 0.538203, top_k: 0.771680, samples/s: 852.165 1612995767.9261422
train: epoch 20, iter 2400, loss: 2.966720, top_1: 0.543516, top_k: 0.777383, samples/s: 852.968 1612995797.939013
train: epoch 20, iter 2500, loss: 2.862904, top_1: 0.543945, top_k: 0.774102, samples/s: 853.785 1612995827.9231231
train: epoch 20, iter 2600, loss: 2.771939, top_1: 0.540273, top_k: 0.773125, samples/s: 854.537 1612995857.880832
train: epoch 20, iter 2700, loss: 2.762094, top_1: 0.544570, top_k: 0.776328, samples/s: 852.526 1612995887.909281
train: epoch 20, iter 2800, loss: 2.873003, top_1: 0.540469, top_k: 0.774531, samples/s: 853.775 1612995917.893758
train: epoch 20, iter 2900, loss: 2.805561, top_1: 0.545859, top_k: 0.778242, samples/s: 854.993 1612995947.835456
train: epoch 20, iter 3000, loss: 2.895828, top_1: 0.548438, top_k: 0.776641, samples/s: 852.452 1612995977.8665152
train: epoch 20, iter 3100, loss: 2.867099, top_1: 0.543438, top_k: 0.774687, samples/s: 856.076 1612996007.7703743
train: epoch 20, iter 3200, loss: 2.931675, top_1: 0.546836, top_k: 0.775195, samples/s: 852.868 1612996037.7867477
train: epoch 20, iter 3300, loss: 2.841730, top_1: 0.538555, top_k: 0.772461, samples/s: 852.986 1612996067.7989256
train: epoch 20, iter 3400, loss: 2.989555, top_1: 0.542227, top_k: 0.775352, samples/s: 852.385 1612996097.832312
train: epoch 20, iter 3500, loss: 2.785317, top_1: 0.538438, top_k: 0.775508, samples/s: 853.568 1612996127.8240793
train: epoch 20, iter 3600, loss: 3.005670, top_1: 0.543555, top_k: 0.777969, samples/s: 853.409 1612996157.8214705
train: epoch 20, iter 3700, loss: 2.845773, top_1: 0.535195, top_k: 0.769570, samples/s: 851.388 1612996187.8900063
train: epoch 20, iter 3800, loss: 2.683147, top_1: 0.540859, top_k: 0.767656, samples/s: 853.419 1612996217.886976
train: epoch 20, iter 3900, loss: 3.014046, top_1: 0.536328, top_k: 0.773086, samples/s: 854.096 1612996247.8601742
train: epoch 20, iter 4000, loss: 2.982357, top_1: 0.536133, top_k: 0.768242, samples/s: 854.883 1612996277.8057613
train: epoch 20, iter 4100, loss: 2.884015, top_1: 0.543359, top_k: 0.771836, samples/s: 850.913 1612996307.891176
train: epoch 20, iter 4200, loss: 2.823324, top_1: 0.541758, top_k: 0.774922, samples/s: 855.489 1612996337.8155446
train: epoch 20, iter 4300, loss: 2.952992, top_1: 0.542813, top_k: 0.774062, samples/s: 851.956 1612996367.8640625
train: epoch 20, iter 4400, loss: 2.921019, top_1: 0.540000, top_k: 0.772656, samples/s: 852.772 1612996397.883874
train: epoch 20, iter 4500, loss: 2.973063, top_1: 0.542891, top_k: 0.772852, samples/s: 851.951 1612996427.9325
train: epoch 20, iter 4600, loss: 2.836910, top_1: 0.539844, top_k: 0.771016, samples/s: 852.965 1612996457.945429
train: epoch 20, iter 4700, loss: 2.885406, top_1: 0.539023, top_k: 0.768008, samples/s: 854.526 1612996487.903668
train: epoch 20, iter 4800, loss: 2.914005, top_1: 0.538359, top_k: 0.774922, samples/s: 852.752 1612996517.924025
train: epoch 20, iter 4900, loss: 2.922963, top_1: 0.540859, top_k: 0.774141, samples/s: 853.011 1612996547.935436
train: epoch 20, iter 5000, loss: 2.796238, top_1: 0.539219, top_k: 0.776680, samples/s: 852.133 1612996577.977623
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_20.
validation: epoch 20, iter 195, top_1: 0.595333, top_k: 0.829227, samples/s: 2476.450 1612996599.0396934
train: epoch 21, iter 100, loss: 2.935132, top_1: 0.558828, top_k: 0.790000, samples/s: 870.044 1612996649.1785505
train: epoch 21, iter 200, loss: 2.855842, top_1: 0.556445, top_k: 0.788086, samples/s: 867.114 1612996678.7018166
train: epoch 21, iter 300, loss: 3.125678, top_1: 0.555820, top_k: 0.784609, samples/s: 858.370 1612996708.5257933
train: epoch 21, iter 400, loss: 2.866652, top_1: 0.554336, top_k: 0.786172, samples/s: 852.210 1612996738.5652995
train: epoch 21, iter 500, loss: 2.968809, top_1: 0.551445, top_k: 0.782578, samples/s: 852.521 1612996768.5938284
train: epoch 21, iter 600, loss: 2.927240, top_1: 0.551484, top_k: 0.781484, samples/s: 850.765 1612996798.684478
train: epoch 21, iter 700, loss: 2.845394, top_1: 0.548867, top_k: 0.777891, samples/s: 851.024 1612996828.7658854
train: epoch 21, iter 800, loss: 2.899809, top_1: 0.549102, top_k: 0.778516, samples/s: 850.546 1612996858.8641927
train: epoch 21, iter 900, loss: 2.987818, top_1: 0.546641, top_k: 0.781055, samples/s: 853.539 1612996888.8569326
train: epoch 21, iter 1000, loss: 2.973569, top_1: 0.541055, top_k: 0.775508, samples/s: 852.375 1612996918.8906727
train: epoch 21, iter 1100, loss: 2.898822, top_1: 0.544297, top_k: 0.778828, samples/s: 852.168 1612996948.9316635
train: epoch 21, iter 1200, loss: 2.857109, top_1: 0.551719, top_k: 0.784766, samples/s: 852.884 1612996978.9474814
train: epoch 21, iter 1300, loss: 2.953152, top_1: 0.548164, top_k: 0.778984, samples/s: 852.551 1612997008.975129
train: epoch 21, iter 1400, loss: 2.983943, top_1: 0.541641, top_k: 0.772188, samples/s: 853.000 1612997038.9866974
train: epoch 21, iter 1500, loss: 2.643487, top_1: 0.549336, top_k: 0.784141, samples/s: 849.775 1612997069.1123831
train: epoch 21, iter 1600, loss: 2.955997, top_1: 0.551250, top_k: 0.777891, samples/s: 853.194 1612997099.1172833
train: epoch 21, iter 1700, loss: 2.935150, top_1: 0.540820, top_k: 0.776797, samples/s: 853.064 1612997129.1267412
train: epoch 21, iter 1800, loss: 2.794832, top_1: 0.543672, top_k: 0.779102, samples/s: 847.951 1612997159.3170753
train: epoch 21, iter 1900, loss: 2.929006, top_1: 0.550977, top_k: 0.782773, samples/s: 857.208 1612997189.1815317
train: epoch 21, iter 2000, loss: 2.894980, top_1: 0.546055, top_k: 0.776445, samples/s: 851.936 1612997219.2308185
train: epoch 21, iter 2100, loss: 2.836543, top_1: 0.542891, top_k: 0.776445, samples/s: 853.124 1612997249.2381024
train: epoch 21, iter 2200, loss: 2.755515, top_1: 0.543398, top_k: 0.775664, samples/s: 850.015 1612997279.3552487
train: epoch 21, iter 2300, loss: 3.019698, top_1: 0.543281, top_k: 0.772891, samples/s: 852.755 1612997309.3755653
train: epoch 21, iter 2400, loss: 2.807497, top_1: 0.545195, top_k: 0.778789, samples/s: 852.208 1612997339.4152486
train: epoch 21, iter 2500, loss: 3.136375, top_1: 0.551133, top_k: 0.779883, samples/s: 849.663 1612997369.5448167
train: epoch 21, iter 2600, loss: 2.997512, top_1: 0.538594, top_k: 0.773438, samples/s: 853.964 1612997399.5225723
train: epoch 21, iter 2700, loss: 2.881564, top_1: 0.547188, top_k: 0.780195, samples/s: 852.944 1612997429.5363765
train: epoch 21, iter 2800, loss: 2.732341, top_1: 0.550508, top_k: 0.782344, samples/s: 851.061 1612997459.616447
train: epoch 21, iter 2900, loss: 2.930467, top_1: 0.548008, top_k: 0.782266, samples/s: 851.984 1612997489.6638567
train: epoch 21, iter 3000, loss: 2.836711, top_1: 0.540937, top_k: 0.776992, samples/s: 852.075 1612997519.7081509
train: epoch 21, iter 3100, loss: 2.753775, top_1: 0.538320, top_k: 0.770469, samples/s: 854.288 1612997549.6747007
train: epoch 21, iter 3200, loss: 3.047899, top_1: 0.541211, top_k: 0.774492, samples/s: 851.788 1612997579.7291362
train: epoch 21, iter 3300, loss: 2.996854, top_1: 0.540039, top_k: 0.772383, samples/s: 851.804 1612997609.7828975
train: epoch 21, iter 3400, loss: 2.774163, top_1: 0.546914, top_k: 0.777422, samples/s: 854.226 1612997639.7515872
train: epoch 21, iter 3500, loss: 2.863781, top_1: 0.546250, top_k: 0.774687, samples/s: 851.615 1612997669.8121052
train: epoch 21, iter 3600, loss: 2.929319, top_1: 0.545469, top_k: 0.774883, samples/s: 851.123 1612997699.890119
train: epoch 21, iter 3700, loss: 2.751429, top_1: 0.545156, top_k: 0.779297, samples/s: 846.240 1612997730.1415088
train: epoch 21, iter 3800, loss: 2.962831, top_1: 0.547422, top_k: 0.777695, samples/s: 859.170 1612997759.9377856
train: epoch 21, iter 3900, loss: 3.024967, top_1: 0.540742, top_k: 0.774570, samples/s: 852.954 1612997789.9510276
train: epoch 21, iter 4000, loss: 2.956377, top_1: 0.543242, top_k: 0.776914, samples/s: 854.151 1612997819.9224124
train: epoch 21, iter 4100, loss: 2.905157, top_1: 0.540781, top_k: 0.775781, samples/s: 853.105 1612997849.9304645
train: epoch 21, iter 4200, loss: 2.928893, top_1: 0.542617, top_k: 0.773594, samples/s: 851.359 1612997879.9999442
train: epoch 21, iter 4300, loss: 3.046480, top_1: 0.544297, top_k: 0.774844, samples/s: 851.490 1612997910.064998
train: epoch 21, iter 4400, loss: 2.949643, top_1: 0.547344, top_k: 0.777539, samples/s: 852.688 1612997940.0875738
train: epoch 21, iter 4500, loss: 2.886645, top_1: 0.538438, top_k: 0.776172, samples/s: 854.671 1612997970.0406477
train: epoch 21, iter 4600, loss: 2.908049, top_1: 0.541602, top_k: 0.773789, samples/s: 853.247 1612998000.0436404
train: epoch 21, iter 4700, loss: 2.832699, top_1: 0.537461, top_k: 0.773203, samples/s: 854.020 1612998030.0196252
train: epoch 21, iter 4800, loss: 2.833014, top_1: 0.536719, top_k: 0.770586, samples/s: 850.547 1612998060.1178443
train: epoch 21, iter 4900, loss: 2.959536, top_1: 0.540273, top_k: 0.776641, samples/s: 853.947 1612998090.0963535
train: epoch 21, iter 5000, loss: 2.826849, top_1: 0.541211, top_k: 0.777734, samples/s: 851.354 1612998120.1660194
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_21.
validation: epoch 21, iter 195, top_1: 0.597356, top_k: 0.833474, samples/s: 2451.840 1612998141.4370315
train: epoch 22, iter 100, loss: 2.846813, top_1: 0.567031, top_k: 0.791328, samples/s: 872.017 1612998191.3247979
train: epoch 22, iter 200, loss: 2.652762, top_1: 0.543047, top_k: 0.778086, samples/s: 867.056 1612998220.8500042
train: epoch 22, iter 300, loss: 2.995927, top_1: 0.550508, top_k: 0.782031, samples/s: 858.681 1612998250.6631353
train: epoch 22, iter 400, loss: 3.210728, top_1: 0.553906, top_k: 0.782773, samples/s: 849.868 1612998280.7854323
train: epoch 22, iter 500, loss: 2.912522, top_1: 0.548828, top_k: 0.781719, samples/s: 850.858 1612998310.8726764
train: epoch 22, iter 600, loss: 2.851280, top_1: 0.553516, top_k: 0.786406, samples/s: 849.064 1612998341.0234942
train: epoch 22, iter 700, loss: 2.837581, top_1: 0.544648, top_k: 0.779844, samples/s: 851.546 1612998371.0865085
train: epoch 22, iter 800, loss: 2.833985, top_1: 0.552617, top_k: 0.782305, samples/s: 849.041 1612998401.2381244
train: epoch 22, iter 900, loss: 2.845290, top_1: 0.551367, top_k: 0.780898, samples/s: 852.807 1612998431.2567086
train: epoch 22, iter 1000, loss: 2.934201, top_1: 0.551289, top_k: 0.781680, samples/s: 845.498 1612998461.5347397
train: epoch 22, iter 1100, loss: 3.002353, top_1: 0.546641, top_k: 0.777305, samples/s: 849.700 1612998491.6630454
train: epoch 22, iter 1200, loss: 2.723262, top_1: 0.544687, top_k: 0.782656, samples/s: 853.216 1612998521.6670802
train: epoch 22, iter 1300, loss: 2.648661, top_1: 0.554453, top_k: 0.780469, samples/s: 851.327 1612998551.7377918
train: epoch 22, iter 1400, loss: 3.122471, top_1: 0.549102, top_k: 0.778477, samples/s: 851.256 1612998581.8110921
train: epoch 22, iter 1500, loss: 2.866360, top_1: 0.553008, top_k: 0.780234, samples/s: 849.368 1612998611.9510944
train: epoch 22, iter 1600, loss: 2.881894, top_1: 0.547148, top_k: 0.781094, samples/s: 852.457 1612998641.9819698
train: epoch 22, iter 1700, loss: 2.571640, top_1: 0.541445, top_k: 0.777344, samples/s: 851.105 1612998672.0604603
train: epoch 22, iter 1800, loss: 2.929712, top_1: 0.549102, top_k: 0.781328, samples/s: 849.250 1612998702.204714
train: epoch 22, iter 1900, loss: 2.781659, top_1: 0.548086, top_k: 0.783398, samples/s: 852.368 1612998732.238669
train: epoch 22, iter 2000, loss: 3.098827, top_1: 0.546836, top_k: 0.777422, samples/s: 851.417 1612998762.3062334
train: epoch 22, iter 2100, loss: 3.003137, top_1: 0.546953, top_k: 0.781680, samples/s: 850.005 1612998792.4236605
train: epoch 22, iter 2200, loss: 2.925872, top_1: 0.541953, top_k: 0.777031, samples/s: 852.868 1612998822.4400418
train: epoch 22, iter 2300, loss: 2.738685, top_1: 0.539844, top_k: 0.778984, samples/s: 850.339 1612998852.5457082
train: epoch 22, iter 2400, loss: 2.748085, top_1: 0.549141, top_k: 0.778320, samples/s: 850.264 1612998882.654022
train: epoch 22, iter 2500, loss: 3.004468, top_1: 0.543594, top_k: 0.776445, samples/s: 852.137 1612998912.6961312
train: epoch 22, iter 2600, loss: 3.033731, top_1: 0.541484, top_k: 0.778125, samples/s: 851.903 1612998942.746508
train: epoch 22, iter 2700, loss: 2.733295, top_1: 0.544687, top_k: 0.779609, samples/s: 850.493 1612998972.8466775
train: epoch 22, iter 2800, loss: 2.958513, top_1: 0.546758, top_k: 0.778867, samples/s: 855.558 1612999002.768661
train: epoch 22, iter 2900, loss: 2.813519, top_1: 0.545391, top_k: 0.777695, samples/s: 853.857 1612999032.7502425
train: epoch 22, iter 3000, loss: 2.960009, top_1: 0.546758, top_k: 0.778789, samples/s: 854.269 1612999062.7173073
train: epoch 22, iter 3100, loss: 3.043211, top_1: 0.544570, top_k: 0.777852, samples/s: 851.990 1612999092.7647111
train: epoch 22, iter 3200, loss: 2.812327, top_1: 0.547734, top_k: 0.782305, samples/s: 851.562 1612999122.827095
train: epoch 22, iter 3300, loss: 2.706198, top_1: 0.546797, top_k: 0.777188, samples/s: 852.117 1612999152.869823
train: epoch 22, iter 3400, loss: 2.893111, top_1: 0.547813, top_k: 0.782383, samples/s: 852.376 1612999182.9035375
train: epoch 22, iter 3500, loss: 3.136688, top_1: 0.546094, top_k: 0.780234, samples/s: 854.177 1612999212.8738735
train: epoch 22, iter 3600, loss: 2.811846, top_1: 0.540273, top_k: 0.774375, samples/s: 851.607 1612999242.9347177
train: epoch 22, iter 3700, loss: 3.056889, top_1: 0.548281, top_k: 0.778867, samples/s: 849.750 1612999273.0612361
train: epoch 22, iter 3800, loss: 2.954259, top_1: 0.541953, top_k: 0.774219, samples/s: 853.275 1612999303.0633485
train: epoch 22, iter 3900, loss: 2.888666, top_1: 0.542773, top_k: 0.776367, samples/s: 853.416 1612999333.0604424
train: epoch 22, iter 4000, loss: 2.740844, top_1: 0.545469, top_k: 0.777656, samples/s: 851.638 1612999363.1201622
train: epoch 22, iter 4100, loss: 2.953017, top_1: 0.548164, top_k: 0.780781, samples/s: 853.395 1612999393.1179557
train: epoch 22, iter 4200, loss: 3.007859, top_1: 0.550391, top_k: 0.777695, samples/s: 850.280 1612999423.2256324
train: epoch 22, iter 4300, loss: 2.921531, top_1: 0.540742, top_k: 0.775156, samples/s: 853.262 1612999453.2281084
train: epoch 22, iter 4400, loss: 2.768590, top_1: 0.546289, top_k: 0.775547, samples/s: 852.433 1612999483.2598286
train: epoch 22, iter 4500, loss: 2.927856, top_1: 0.544844, top_k: 0.781523, samples/s: 853.498 1612999513.2541132
train: epoch 22, iter 4600, loss: 2.935656, top_1: 0.541641, top_k: 0.775820, samples/s: 855.394 1612999543.181836
train: epoch 22, iter 4700, loss: 2.881736, top_1: 0.544922, top_k: 0.776875, samples/s: 853.419 1612999573.1787603
train: epoch 22, iter 4800, loss: 2.867331, top_1: 0.542969, top_k: 0.771523, samples/s: 852.592 1612999603.204819
train: epoch 22, iter 4900, loss: 2.756885, top_1: 0.546289, top_k: 0.777813, samples/s: 853.442 1612999633.201049
train: epoch 22, iter 5000, loss: 2.868468, top_1: 0.550781, top_k: 0.783359, samples/s: 854.011 1612999663.1772852
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_22.
validation: epoch 22, iter 195, top_1: 0.598017, top_k: 0.833073, samples/s: 2449.012 1612999684.46363
train: epoch 23, iter 100, loss: 2.914620, top_1: 0.555977, top_k: 0.786875, samples/s: 867.816 1612999739.8632605
train: epoch 23, iter 200, loss: 2.834353, top_1: 0.564023, top_k: 0.788477, samples/s: 868.538 1612999769.3380554
train: epoch 23, iter 300, loss: 2.893903, top_1: 0.553164, top_k: 0.785273, samples/s: 861.457 1612999799.0552175
train: epoch 23, iter 400, loss: 3.035549, top_1: 0.556953, top_k: 0.787461, samples/s: 852.760 1612999829.075391
train: epoch 23, iter 500, loss: 2.898674, top_1: 0.552500, top_k: 0.779531, samples/s: 852.832 1612999859.0929716
train: epoch 23, iter 600, loss: 2.862158, top_1: 0.550234, top_k: 0.785234, samples/s: 850.672 1612999889.1868873
train: epoch 23, iter 700, loss: 2.663817, top_1: 0.553203, top_k: 0.782148, samples/s: 851.970 1612999919.2349112
train: epoch 23, iter 800, loss: 2.940737, top_1: 0.556562, top_k: 0.783633, samples/s: 850.306 1612999949.3416846
train: epoch 23, iter 900, loss: 2.792954, top_1: 0.550273, top_k: 0.783125, samples/s: 852.126 1612999979.3841805
train: epoch 23, iter 1000, loss: 2.781559, top_1: 0.552539, top_k: 0.786914, samples/s: 853.702 1613000009.3711984
train: epoch 23, iter 1100, loss: 2.851750, top_1: 0.551992, top_k: 0.784062, samples/s: 849.706 1613000039.4993453
train: epoch 23, iter 1200, loss: 2.825498, top_1: 0.553086, top_k: 0.779297, samples/s: 852.702 1613000069.5214648
train: epoch 23, iter 1300, loss: 3.038444, top_1: 0.547734, top_k: 0.781133, samples/s: 849.588 1613000099.653672
train: epoch 23, iter 1400, loss: 2.830851, top_1: 0.546406, top_k: 0.778359, samples/s: 852.232 1613000129.6924376
train: epoch 23, iter 1500, loss: 2.657137, top_1: 0.552891, top_k: 0.785078, samples/s: 853.832 1613000159.6749911
train: epoch 23, iter 1600, loss: 2.886568, top_1: 0.553555, top_k: 0.783633, samples/s: 852.069 1613000189.7194624
train: epoch 23, iter 1700, loss: 2.842596, top_1: 0.549805, top_k: 0.784687, samples/s: 849.162 1613000219.8668668
train: epoch 23, iter 1800, loss: 2.768878, top_1: 0.544336, top_k: 0.777148, samples/s: 851.597 1613000249.9279149
train: epoch 23, iter 1900, loss: 2.940203, top_1: 0.552852, top_k: 0.784922, samples/s: 854.113 1613000279.900535
train: epoch 23, iter 2000, loss: 2.937329, top_1: 0.545664, top_k: 0.780547, samples/s: 851.506 1613000309.9649816
train: epoch 23, iter 2100, loss: 2.627921, top_1: 0.553281, top_k: 0.783242, samples/s: 852.511 1613000339.99395
train: epoch 23, iter 2200, loss: 2.912858, top_1: 0.547773, top_k: 0.779648, samples/s: 849.269 1613000370.1375237
train: epoch 23, iter 2300, loss: 2.805073, top_1: 0.552695, top_k: 0.784570, samples/s: 852.128 1613000400.1799455
train: epoch 23, iter 2400, loss: 2.895403, top_1: 0.545586, top_k: 0.777773, samples/s: 851.244 1613000430.253519
train: epoch 23, iter 2500, loss: 2.853603, top_1: 0.551445, top_k: 0.787227, samples/s: 851.301 1613000460.3252199
train: epoch 23, iter 2600, loss: 2.792183, top_1: 0.550352, top_k: 0.783633, samples/s: 852.994 1613000490.3370233
train: epoch 23, iter 2700, loss: 2.827533, top_1: 0.552578, top_k: 0.783086, samples/s: 850.492 1613000520.4372761
train: epoch 23, iter 2800, loss: 2.887064, top_1: 0.549570, top_k: 0.785703, samples/s: 852.691 1613000550.4598262
train: epoch 23, iter 2900, loss: 2.782927, top_1: 0.553945, top_k: 0.783516, samples/s: 851.964 1613000580.5081418
train: epoch 23, iter 3000, loss: 2.915882, top_1: 0.550195, top_k: 0.778984, samples/s: 853.923 1613000610.4873638
train: epoch 23, iter 3100, loss: 2.795353, top_1: 0.551836, top_k: 0.781172, samples/s: 851.874 1613000640.5387127
train: epoch 23, iter 3200, loss: 2.942300, top_1: 0.548945, top_k: 0.779062, samples/s: 853.160 1613000670.54488
train: epoch 23, iter 3300, loss: 2.757331, top_1: 0.546172, top_k: 0.776289, samples/s: 851.604 1613000700.6057298
train: epoch 23, iter 3400, loss: 2.782703, top_1: 0.545156, top_k: 0.780352, samples/s: 853.697 1613000730.5929518
train: epoch 23, iter 3500, loss: 2.946604, top_1: 0.548672, top_k: 0.780547, samples/s: 850.870 1613000760.6798131
train: epoch 23, iter 3600, loss: 2.935137, top_1: 0.540195, top_k: 0.772422, samples/s: 854.012 1613000790.6560109
train: epoch 23, iter 3700, loss: 3.034316, top_1: 0.546836, top_k: 0.778555, samples/s: 851.252 1613000820.7293632
train: epoch 23, iter 3800, loss: 2.726961, top_1: 0.550586, top_k: 0.781992, samples/s: 851.776 1613000850.7842112
train: epoch 23, iter 3900, loss: 2.750469, top_1: 0.549180, top_k: 0.780195, samples/s: 853.128 1613000880.791424
train: epoch 23, iter 4000, loss: 2.809334, top_1: 0.549687, top_k: 0.780586, samples/s: 849.301 1613000910.9338586
train: epoch 23, iter 4100, loss: 2.923831, top_1: 0.546523, top_k: 0.781836, samples/s: 852.656 1613000940.957683
train: epoch 23, iter 4200, loss: 2.825949, top_1: 0.547344, top_k: 0.778398, samples/s: 853.259 1613000970.9603093
train: epoch 23, iter 4300, loss: 2.842783, top_1: 0.545391, top_k: 0.779961, samples/s: 852.823 1613001000.9782705
train: epoch 23, iter 4400, loss: 3.015943, top_1: 0.545508, top_k: 0.779023, samples/s: 852.478 1613001031.0083358
train: epoch 23, iter 4500, loss: 3.011070, top_1: 0.550039, top_k: 0.779336, samples/s: 848.014 1613001061.1964602
train: epoch 23, iter 4600, loss: 2.813120, top_1: 0.551953, top_k: 0.782539, samples/s: 852.950 1613001091.2099688
train: epoch 23, iter 4700, loss: 2.855664, top_1: 0.547148, top_k: 0.776563, samples/s: 851.059 1613001121.2902353
train: epoch 23, iter 4800, loss: 2.858500, top_1: 0.549727, top_k: 0.778359, samples/s: 850.454 1613001151.3918009
train: epoch 23, iter 4900, loss: 2.867876, top_1: 0.546875, top_k: 0.779883, samples/s: 853.242 1613001181.394965
train: epoch 23, iter 5000, loss: 3.091452, top_1: 0.548047, top_k: 0.777813, samples/s: 850.798 1613001211.4843183
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_23.
validation: epoch 23, iter 195, top_1: 0.595453, top_k: 0.828966, samples/s: 2471.821 1613001232.5774577
train: epoch 24, iter 100, loss: 2.667143, top_1: 0.554102, top_k: 0.788750, samples/s: 870.141 1613001282.6514242
train: epoch 24, iter 200, loss: 2.800848, top_1: 0.561484, top_k: 0.792070, samples/s: 868.604 1613001312.124024
train: epoch 24, iter 300, loss: 2.884304, top_1: 0.549883, top_k: 0.781719, samples/s: 857.162 1613001341.9900146
train: epoch 24, iter 400, loss: 2.710464, top_1: 0.560742, top_k: 0.791602, samples/s: 848.455 1613001372.1624813
train: epoch 24, iter 500, loss: 2.661894, top_1: 0.562227, top_k: 0.789336, samples/s: 851.874 1613001402.2138534
train: epoch 24, iter 600, loss: 2.819667, top_1: 0.553867, top_k: 0.784180, samples/s: 850.569 1613001432.3114305
train: epoch 24, iter 700, loss: 2.886937, top_1: 0.544297, top_k: 0.780000, samples/s: 849.628 1613001462.4423048
train: epoch 24, iter 800, loss: 2.875634, top_1: 0.553047, top_k: 0.782695, samples/s: 850.323 1613001492.5484166
train: epoch 24, iter 900, loss: 3.035195, top_1: 0.553906, top_k: 0.786055, samples/s: 851.034 1613001522.6295102
train: epoch 24, iter 1000, loss: 2.861684, top_1: 0.551836, top_k: 0.783945, samples/s: 850.121 1613001552.7427876
train: epoch 24, iter 1100, loss: 2.935305, top_1: 0.548945, top_k: 0.781016, samples/s: 851.209 1613001582.8177435
train: epoch 24, iter 1200, loss: 2.775491, top_1: 0.551211, top_k: 0.781836, samples/s: 849.496 1613001612.95329
train: epoch 24, iter 1300, loss: 2.878604, top_1: 0.553438, top_k: 0.785195, samples/s: 852.521 1613001642.9818723
train: epoch 24, iter 1400, loss: 2.721668, top_1: 0.554180, top_k: 0.781875, samples/s: 850.862 1613001673.0689476
train: epoch 24, iter 1500, loss: 2.872749, top_1: 0.548516, top_k: 0.778125, samples/s: 849.147 1613001703.2167761
train: epoch 24, iter 1600, loss: 2.946858, top_1: 0.555391, top_k: 0.787461, samples/s: 854.171 1613001733.18744
train: epoch 24, iter 1700, loss: 2.670247, top_1: 0.553555, top_k: 0.785820, samples/s: 853.998 1613001763.1640818
train: epoch 24, iter 1800, loss: 2.743206, top_1: 0.556367, top_k: 0.782109, samples/s: 853.284 1613001793.165794
train: epoch 24, iter 1900, loss: 2.965993, top_1: 0.552656, top_k: 0.782500, samples/s: 848.673 1613001823.3306022
train: epoch 24, iter 2000, loss: 2.940138, top_1: 0.554570, top_k: 0.784844, samples/s: 852.294 1613001853.3672392
train: epoch 24, iter 2100, loss: 2.851266, top_1: 0.551953, top_k: 0.783750, samples/s: 853.256 1613001883.369841
train: epoch 24, iter 2200, loss: 2.828835, top_1: 0.561445, top_k: 0.786680, samples/s: 848.255 1613001913.5494862
train: epoch 24, iter 2300, loss: 2.879496, top_1: 0.553164, top_k: 0.785625, samples/s: 852.125 1613001943.5920715
train: epoch 24, iter 2400, loss: 3.005142, top_1: 0.548438, top_k: 0.778320, samples/s: 853.850 1613001973.5739267
train: epoch 24, iter 2500, loss: 2.956083, top_1: 0.551992, top_k: 0.786367, samples/s: 851.010 1613002003.6558454
train: epoch 24, iter 2600, loss: 2.970899, top_1: 0.551523, top_k: 0.783242, samples/s: 850.441 1613002033.757858
train: epoch 24, iter 2700, loss: 2.771843, top_1: 0.550625, top_k: 0.785508, samples/s: 852.365 1613002063.7919629
train: epoch 24, iter 2800, loss: 3.040894, top_1: 0.555820, top_k: 0.784961, samples/s: 849.252 1613002093.9361446
train: epoch 24, iter 2900, loss: 2.864261, top_1: 0.554727, top_k: 0.784062, samples/s: 852.201 1613002123.9759786
train: epoch 24, iter 3000, loss: 2.837905, top_1: 0.554492, top_k: 0.781523, samples/s: 854.668 1613002153.9290524
train: epoch 24, iter 3100, loss: 2.978751, top_1: 0.546680, top_k: 0.777773, samples/s: 852.531 1613002183.9573271
train: epoch 24, iter 3200, loss: 2.908479, top_1: 0.552578, top_k: 0.776055, samples/s: 851.737 1613002214.0135553
train: epoch 24, iter 3300, loss: 2.968751, top_1: 0.547969, top_k: 0.781797, samples/s: 851.569 1613002244.0757802
train: epoch 24, iter 3400, loss: 2.690331, top_1: 0.552656, top_k: 0.785625, samples/s: 852.068 1613002274.1203098
train: epoch 24, iter 3500, loss: 2.712651, top_1: 0.546055, top_k: 0.779375, samples/s: 852.444 1613002304.1515992
train: epoch 24, iter 3600, loss: 2.806101, top_1: 0.552461, top_k: 0.781914, samples/s: 853.051 1613002334.1615822
train: epoch 24, iter 3700, loss: 2.700640, top_1: 0.542422, top_k: 0.776914, samples/s: 851.999 1613002364.2084951
train: epoch 24, iter 3800, loss: 2.846866, top_1: 0.546758, top_k: 0.780312, samples/s: 848.539 1613002394.3780777
train: epoch 24, iter 3900, loss: 2.606830, top_1: 0.552031, top_k: 0.781719, samples/s: 851.358 1613002424.4476671
train: epoch 24, iter 4000, loss: 2.780811, top_1: 0.550937, top_k: 0.784531, samples/s: 853.959 1613002454.4256759
train: epoch 24, iter 4100, loss: 2.918582, top_1: 0.550469, top_k: 0.780234, samples/s: 851.830 1613002484.4786303
train: epoch 24, iter 4200, loss: 2.951909, top_1: 0.558594, top_k: 0.782500, samples/s: 849.190 1613002514.624997
train: epoch 24, iter 4300, loss: 2.800829, top_1: 0.548125, top_k: 0.779414, samples/s: 852.271 1613002544.662405
train: epoch 24, iter 4400, loss: 2.793608, top_1: 0.547695, top_k: 0.779687, samples/s: 853.174 1613002574.668024
train: epoch 24, iter 4500, loss: 2.732352, top_1: 0.543555, top_k: 0.776680, samples/s: 852.000 1613002604.714932
train: epoch 24, iter 4600, loss: 2.857048, top_1: 0.550586, top_k: 0.784219, samples/s: 854.190 1613002634.6848824
train: epoch 24, iter 4700, loss: 2.668847, top_1: 0.546797, top_k: 0.781016, samples/s: 850.311 1613002664.7915063
train: epoch 24, iter 4800, loss: 2.846586, top_1: 0.551875, top_k: 0.783984, samples/s: 851.041 1613002694.872256
train: epoch 24, iter 4900, loss: 2.812972, top_1: 0.549141, top_k: 0.781055, samples/s: 853.429 1613002724.8688633
train: epoch 24, iter 5000, loss: 2.735229, top_1: 0.553047, top_k: 0.780742, samples/s: 851.854 1613002754.9209971
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_24.
validation: epoch 24, iter 195, top_1: 0.605028, top_k: 0.838482, samples/s: 2435.186 1613002776.3183403
train: epoch 25, iter 100, loss: 2.832487, top_1: 0.567695, top_k: 0.794609, samples/s: 867.257 1613002826.8768182
train: epoch 25, iter 200, loss: 2.897100, top_1: 0.558242, top_k: 0.788594, samples/s: 869.164 1613002856.33037
train: epoch 25, iter 300, loss: 2.878399, top_1: 0.561250, top_k: 0.789258, samples/s: 861.714 1613002886.0385907
train: epoch 25, iter 400, loss: 2.780091, top_1: 0.562852, top_k: 0.787305, samples/s: 849.716 1613002916.1663342
train: epoch 25, iter 500, loss: 2.631629, top_1: 0.561641, top_k: 0.788086, samples/s: 849.488 1613002946.302223
train: epoch 25, iter 600, loss: 2.712150, top_1: 0.563164, top_k: 0.792344, samples/s: 851.272 1613002976.3748057
train: epoch 25, iter 700, loss: 2.917567, top_1: 0.554102, top_k: 0.786445, samples/s: 850.007 1613003006.4922853
train: epoch 25, iter 800, loss: 2.900473, top_1: 0.560391, top_k: 0.788945, samples/s: 850.790 1613003036.5818512
train: epoch 25, iter 900, loss: 2.882288, top_1: 0.554844, top_k: 0.783750, samples/s: 851.384 1613003066.6505904
train: epoch 25, iter 1000, loss: 2.961953, top_1: 0.558320, top_k: 0.787109, samples/s: 846.838 1613003096.8807547
train: epoch 25, iter 1100, loss: 3.071310, top_1: 0.554375, top_k: 0.785937, samples/s: 852.323 1613003126.9163284
train: epoch 25, iter 1200, loss: 2.923688, top_1: 0.556328, top_k: 0.782656, samples/s: 850.901 1613003157.0019763
train: epoch 25, iter 1300, loss: 2.728730, top_1: 0.556055, top_k: 0.786055, samples/s: 852.704 1613003187.0241706
train: epoch 25, iter 1400, loss: 2.958678, top_1: 0.555352, top_k: 0.786563, samples/s: 846.680 1613003217.2599869
train: epoch 25, iter 1500, loss: 2.766198, top_1: 0.556289, top_k: 0.782422, samples/s: 849.211 1613003247.405619
train: epoch 25, iter 1600, loss: 2.805624, top_1: 0.555820, top_k: 0.788281, samples/s: 854.551 1613003277.3627405
train: epoch 25, iter 1700, loss: 2.876729, top_1: 0.559453, top_k: 0.787031, samples/s: 849.988 1613003307.4808552
train: epoch 25, iter 1800, loss: 2.847350, top_1: 0.558555, top_k: 0.787695, samples/s: 851.950 1613003337.5296056
train: epoch 25, iter 1900, loss: 2.922461, top_1: 0.553750, top_k: 0.784336, samples/s: 851.480 1613003367.59488
train: epoch 25, iter 2000, loss: 2.834841, top_1: 0.549297, top_k: 0.785117, samples/s: 852.374 1613003397.6286836
train: epoch 25, iter 2100, loss: 2.826809, top_1: 0.553984, top_k: 0.784609, samples/s: 850.066 1613003427.7439759
train: epoch 25, iter 2200, loss: 2.865458, top_1: 0.550195, top_k: 0.778750, samples/s: 849.465 1613003457.880591
train: epoch 25, iter 2300, loss: 2.820753, top_1: 0.554805, top_k: 0.785391, samples/s: 849.425 1613003488.01852
train: epoch 25, iter 2400, loss: 2.922968, top_1: 0.549375, top_k: 0.781445, samples/s: 853.291 1613003518.0200932
train: epoch 25, iter 2500, loss: 2.836178, top_1: 0.553633, top_k: 0.781875, samples/s: 850.338 1613003548.1256804
train: epoch 25, iter 2600, loss: 2.898199, top_1: 0.553594, top_k: 0.785156, samples/s: 852.442 1613003578.1570666
train: epoch 25, iter 2700, loss: 2.741042, top_1: 0.555078, top_k: 0.785195, samples/s: 850.613 1613003608.2530794
train: epoch 25, iter 2800, loss: 2.865334, top_1: 0.552070, top_k: 0.783477, samples/s: 852.563 1613003638.2801485
train: epoch 25, iter 2900, loss: 2.943023, top_1: 0.551250, top_k: 0.781836, samples/s: 850.435 1613003668.382442
train: epoch 25, iter 3000, loss: 2.749655, top_1: 0.557734, top_k: 0.787656, samples/s: 849.476 1613003698.5186512
train: epoch 25, iter 3100, loss: 3.043740, top_1: 0.552539, top_k: 0.783828, samples/s: 854.315 1613003728.484149
train: epoch 25, iter 3200, loss: 2.784838, top_1: 0.549883, top_k: 0.783125, samples/s: 851.063 1613003758.564219
train: epoch 25, iter 3300, loss: 2.827592, top_1: 0.554023, top_k: 0.781328, samples/s: 849.531 1613003788.6984143
train: epoch 25, iter 3400, loss: 2.829051, top_1: 0.551523, top_k: 0.782031, samples/s: 852.339 1613003818.7334595
train: epoch 25, iter 3500, loss: 2.883608, top_1: 0.549922, top_k: 0.780664, samples/s: 850.523 1613003848.832626
train: epoch 25, iter 3600, loss: 2.916961, top_1: 0.553398, top_k: 0.783672, samples/s: 848.713 1613003878.9959304
train: epoch 25, iter 3700, loss: 3.013908, top_1: 0.553203, top_k: 0.785117, samples/s: 851.907 1613003909.0460675
train: epoch 25, iter 3800, loss: 2.907300, top_1: 0.556680, top_k: 0.787227, samples/s: 848.591 1613003939.2137973
train: epoch 25, iter 3900, loss: 2.884070, top_1: 0.553438, top_k: 0.783945, samples/s: 853.069 1613003969.2231276
train: epoch 25, iter 4000, loss: 2.796046, top_1: 0.555312, top_k: 0.784141, samples/s: 851.663 1613003999.281921
train: epoch 25, iter 4100, loss: 2.872404, top_1: 0.555625, top_k: 0.784414, samples/s: 850.634 1613004029.377149
train: epoch 25, iter 4200, loss: 2.808265, top_1: 0.552813, top_k: 0.784141, samples/s: 853.049 1613004059.387154
train: epoch 25, iter 4300, loss: 2.722285, top_1: 0.550430, top_k: 0.782461, samples/s: 849.568 1613004089.520089
train: epoch 25, iter 4400, loss: 2.731037, top_1: 0.555039, top_k: 0.784219, samples/s: 853.730 1613004119.5062218
train: epoch 25, iter 4500, loss: 2.821121, top_1: 0.551133, top_k: 0.783906, samples/s: 850.303 1613004149.613222
train: epoch 25, iter 4600, loss: 2.757995, top_1: 0.551641, top_k: 0.778594, samples/s: 851.722 1613004179.6698272
train: epoch 25, iter 4700, loss: 2.793272, top_1: 0.547188, top_k: 0.776836, samples/s: 850.521 1613004209.769089
train: epoch 25, iter 4800, loss: 2.787378, top_1: 0.550977, top_k: 0.783359, samples/s: 848.738 1613004239.9314754
train: epoch 25, iter 4900, loss: 2.884513, top_1: 0.550625, top_k: 0.779102, samples/s: 851.975 1613004269.9793036
train: epoch 25, iter 5000, loss: 2.846562, top_1: 0.551641, top_k: 0.784922, samples/s: 848.331 1613004300.1562707
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_25.
validation: epoch 25, iter 195, top_1: 0.605469, top_k: 0.840044, samples/s: 2455.365 1613004321.3813002
train: epoch 26, iter 100, loss: 3.082377, top_1: 0.557578, top_k: 0.787695, samples/s: 869.145 1613004371.8733897
train: epoch 26, iter 200, loss: 2.737305, top_1: 0.561133, top_k: 0.791602, samples/s: 867.307 1613004401.3900187
train: epoch 26, iter 300, loss: 2.828465, top_1: 0.561133, top_k: 0.789883, samples/s: 857.560 1613004431.2422283
train: epoch 26, iter 400, loss: 2.650569, top_1: 0.569648, top_k: 0.795547, samples/s: 850.308 1613004461.3489122
train: epoch 26, iter 500, loss: 2.910871, top_1: 0.566523, top_k: 0.795352, samples/s: 849.341 1613004491.4899478
train: epoch 26, iter 600, loss: 2.792077, top_1: 0.557266, top_k: 0.789727, samples/s: 848.989 1613004521.6434946
train: epoch 26, iter 700, loss: 2.949465, top_1: 0.555742, top_k: 0.787852, samples/s: 852.589 1613004551.6696284
train: epoch 26, iter 800, loss: 2.705612, top_1: 0.560742, top_k: 0.793984, samples/s: 850.633 1613004581.7648363
train: epoch 26, iter 900, loss: 2.890606, top_1: 0.561641, top_k: 0.788438, samples/s: 851.323 1613004611.8357046
train: epoch 26, iter 1000, loss: 2.722974, top_1: 0.564531, top_k: 0.788633, samples/s: 850.458 1613004641.937063
train: epoch 26, iter 1100, loss: 2.983136, top_1: 0.552031, top_k: 0.785312, samples/s: 852.051 1613004671.9822316
train: epoch 26, iter 1200, loss: 2.793737, top_1: 0.558398, top_k: 0.789062, samples/s: 848.188 1613004702.164274
train: epoch 26, iter 1300, loss: 2.727483, top_1: 0.558516, top_k: 0.791016, samples/s: 851.819 1613004732.217548
train: epoch 26, iter 1400, loss: 2.789786, top_1: 0.557305, top_k: 0.784492, samples/s: 848.150 1613004762.4009316
train: epoch 26, iter 1500, loss: 2.886484, top_1: 0.559922, top_k: 0.785977, samples/s: 851.534 1613004792.4643357
train: epoch 26, iter 1600, loss: 2.855788, top_1: 0.556367, top_k: 0.784375, samples/s: 850.901 1613004822.5500512
train: epoch 26, iter 1700, loss: 2.972439, top_1: 0.556016, top_k: 0.785664, samples/s: 848.713 1613004852.7134488
train: epoch 26, iter 1800, loss: 2.742922, top_1: 0.554102, top_k: 0.783008, samples/s: 850.893 1613004882.799316
train: epoch 26, iter 1900, loss: 2.809020, top_1: 0.558555, top_k: 0.785234, samples/s: 850.624 1613004912.8949718
train: epoch 26, iter 2000, loss: 2.702569, top_1: 0.557969, top_k: 0.785742, samples/s: 850.627 1613004942.990364
train: epoch 26, iter 2100, loss: 2.866161, top_1: 0.558008, top_k: 0.786602, samples/s: 851.711 1613004973.047432
train: epoch 26, iter 2200, loss: 2.682557, top_1: 0.555469, top_k: 0.784609, samples/s: 850.597 1613005003.143934
train: epoch 26, iter 2300, loss: 2.949251, top_1: 0.554297, top_k: 0.785898, samples/s: 848.076 1613005033.3299687
train: epoch 26, iter 2400, loss: 2.697319, top_1: 0.560039, top_k: 0.787383, samples/s: 851.568 1613005063.3922286
train: epoch 26, iter 2500, loss: 2.814456, top_1: 0.553906, top_k: 0.783906, samples/s: 852.578 1613005093.4187248
train: epoch 26, iter 2600, loss: 2.885782, top_1: 0.553750, top_k: 0.785078, samples/s: 849.311 1613005123.5607626
train: epoch 26, iter 2700, loss: 2.812583, top_1: 0.556367, top_k: 0.787461, samples/s: 851.381 1613005153.629632
train: epoch 26, iter 2800, loss: 2.864214, top_1: 0.554414, top_k: 0.782930, samples/s: 852.556 1613005183.6568754
train: epoch 26, iter 2900, loss: 2.812704, top_1: 0.558672, top_k: 0.786523, samples/s: 851.101 1613005213.7356079
train: epoch 26, iter 3000, loss: 2.937535, top_1: 0.553359, top_k: 0.781992, samples/s: 849.558 1613005243.8688798
train: epoch 26, iter 3100, loss: 2.933636, top_1: 0.552305, top_k: 0.784453, samples/s: 848.895 1613005274.025762
train: epoch 26, iter 3200, loss: 2.781862, top_1: 0.552383, top_k: 0.781289, samples/s: 850.385 1613005304.1297607
train: epoch 26, iter 3300, loss: 2.783326, top_1: 0.554727, top_k: 0.780820, samples/s: 851.902 1613005334.1801946
train: epoch 26, iter 3400, loss: 2.726391, top_1: 0.553555, top_k: 0.783555, samples/s: 848.412 1613005364.3541892
train: epoch 26, iter 3500, loss: 2.685158, top_1: 0.555078, top_k: 0.786172, samples/s: 851.710 1613005394.4114358
train: epoch 26, iter 3600, loss: 2.870483, top_1: 0.549922, top_k: 0.781016, samples/s: 850.638 1613005424.5063698
train: epoch 26, iter 3700, loss: 2.833216, top_1: 0.554883, top_k: 0.782891, samples/s: 850.041 1613005454.6225932
train: epoch 26, iter 3800, loss: 2.700982, top_1: 0.554922, top_k: 0.781563, samples/s: 850.236 1613005484.7319148
train: epoch 26, iter 3900, loss: 2.945842, top_1: 0.560742, top_k: 0.790312, samples/s: 851.940 1613005514.780965
train: epoch 26, iter 4000, loss: 2.875590, top_1: 0.551484, top_k: 0.778359, samples/s: 849.919 1613005544.9015636
train: epoch 26, iter 4100, loss: 2.832357, top_1: 0.550937, top_k: 0.783789, samples/s: 849.099 1613005575.051108
train: epoch 26, iter 4200, loss: 2.949118, top_1: 0.545430, top_k: 0.780859, samples/s: 848.525 1613005605.2211502
train: epoch 26, iter 4300, loss: 2.974037, top_1: 0.550625, top_k: 0.779727, samples/s: 853.715 1613005635.2077315
train: epoch 26, iter 4400, loss: 2.669883, top_1: 0.557695, top_k: 0.784609, samples/s: 852.288 1613005665.2445095
train: epoch 26, iter 4500, loss: 2.861579, top_1: 0.552109, top_k: 0.780859, samples/s: 849.666 1613005695.3740363
train: epoch 26, iter 4600, loss: 3.021070, top_1: 0.544648, top_k: 0.780312, samples/s: 850.672 1613005725.4679022
train: epoch 26, iter 4700, loss: 2.853608, top_1: 0.551250, top_k: 0.780039, samples/s: 848.929 1613005755.623488
train: epoch 26, iter 4800, loss: 2.906492, top_1: 0.550625, top_k: 0.780234, samples/s: 849.470 1613005785.7599223
train: epoch 26, iter 4900, loss: 2.793349, top_1: 0.554727, top_k: 0.783789, samples/s: 851.667 1613005815.818588
train: epoch 26, iter 5000, loss: 2.724375, top_1: 0.556211, top_k: 0.787656, samples/s: 851.565 1613005845.8808837
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_26.
validation: epoch 26, iter 195, top_1: 0.604067, top_k: 0.838562, samples/s: 2458.666 1613005867.083347
train: epoch 27, iter 100, loss: 2.689968, top_1: 0.570742, top_k: 0.796211, samples/s: 869.125 1613005917.0829775
train: epoch 27, iter 200, loss: 2.830236, top_1: 0.561562, top_k: 0.791211, samples/s: 867.228 1613005946.6023335
train: epoch 27, iter 300, loss: 2.906587, top_1: 0.567109, top_k: 0.791914, samples/s: 856.325 1613005976.4974997
train: epoch 27, iter 400, loss: 2.662853, top_1: 0.559219, top_k: 0.790039, samples/s: 850.403 1613006006.6009264
train: epoch 27, iter 500, loss: 2.572816, top_1: 0.564805, top_k: 0.790781, samples/s: 849.471 1613006036.7373283
train: epoch 27, iter 600, loss: 2.918132, top_1: 0.556250, top_k: 0.787461, samples/s: 849.185 1613006066.8838334
train: epoch 27, iter 700, loss: 2.964788, top_1: 0.560430, top_k: 0.786328, samples/s: 850.776 1613006096.9739707
train: epoch 27, iter 800, loss: 2.756410, top_1: 0.556484, top_k: 0.786250, samples/s: 847.214 1613006127.1906722
train: epoch 27, iter 900, loss: 2.799480, top_1: 0.558789, top_k: 0.787305, samples/s: 850.550 1613006157.2888377
train: epoch 27, iter 1000, loss: 2.731833, top_1: 0.565625, top_k: 0.795625, samples/s: 850.330 1613006187.3948517
train: epoch 27, iter 1100, loss: 2.704878, top_1: 0.561680, top_k: 0.786250, samples/s: 847.914 1613006217.586538
train: epoch 27, iter 1200, loss: 2.836104, top_1: 0.557109, top_k: 0.790312, samples/s: 850.698 1613006247.6795287
train: epoch 27, iter 1300, loss: 2.668332, top_1: 0.559492, top_k: 0.782578, samples/s: 850.289 1613006277.786964
train: epoch 27, iter 1400, loss: 2.651851, top_1: 0.559336, top_k: 0.789492, samples/s: 851.601 1613006307.8479185
train: epoch 27, iter 1500, loss: 2.695731, top_1: 0.557148, top_k: 0.788242, samples/s: 851.078 1613006337.927399
train: epoch 27, iter 1600, loss: 2.905722, top_1: 0.553984, top_k: 0.782734, samples/s: 850.355 1613006368.0324652
train: epoch 27, iter 1700, loss: 2.757821, top_1: 0.556094, top_k: 0.787266, samples/s: 849.719 1613006398.160096
train: epoch 27, iter 1800, loss: 2.856268, top_1: 0.561484, top_k: 0.790977, samples/s: 851.386 1613006428.2286947
train: epoch 27, iter 1900, loss: 2.809573, top_1: 0.562695, top_k: 0.789102, samples/s: 848.692 1613006458.3928616
train: epoch 27, iter 2000, loss: 3.011509, top_1: 0.560977, top_k: 0.787266, samples/s: 851.126 1613006488.4706073
train: epoch 27, iter 2100, loss: 2.713479, top_1: 0.556602, top_k: 0.784648, samples/s: 847.611 1613006518.6732354
train: epoch 27, iter 2200, loss: 2.934746, top_1: 0.556914, top_k: 0.791211, samples/s: 849.522 1613006548.807817
train: epoch 27, iter 2300, loss: 2.775620, top_1: 0.552969, top_k: 0.787578, samples/s: 850.350 1613006578.91303
train: epoch 27, iter 2400, loss: 2.802830, top_1: 0.555859, top_k: 0.785977, samples/s: 848.884 1613006609.0703416
train: epoch 27, iter 2500, loss: 2.795853, top_1: 0.562227, top_k: 0.788164, samples/s: 848.263 1613006639.2496455
train: epoch 27, iter 2600, loss: 2.885906, top_1: 0.560703, top_k: 0.787500, samples/s: 845.913 1613006669.5127783
train: epoch 27, iter 2700, loss: 3.046714, top_1: 0.552383, top_k: 0.785273, samples/s: 852.949 1613006699.52623
train: epoch 27, iter 2800, loss: 2.902611, top_1: 0.555078, top_k: 0.784219, samples/s: 849.225 1613006729.6714225
train: epoch 27, iter 2900, loss: 2.865440, top_1: 0.558828, top_k: 0.785430, samples/s: 852.402 1613006759.7042167
train: epoch 27, iter 3000, loss: 2.750204, top_1: 0.555820, top_k: 0.787266, samples/s: 847.656 1613006789.905054
train: epoch 27, iter 3100, loss: 2.906943, top_1: 0.556602, top_k: 0.784453, samples/s: 850.640 1613006820.0000396
train: epoch 27, iter 3200, loss: 2.855011, top_1: 0.557539, top_k: 0.786719, samples/s: 852.499 1613006850.0294986
train: epoch 27, iter 3300, loss: 2.780262, top_1: 0.562187, top_k: 0.787227, samples/s: 851.550 1613006880.0923622
train: epoch 27, iter 3400, loss: 2.781887, top_1: 0.560039, top_k: 0.788281, samples/s: 849.247 1613006910.236592
train: epoch 27, iter 3500, loss: 2.800275, top_1: 0.554688, top_k: 0.783984, samples/s: 851.815 1613006940.2901092
train: epoch 27, iter 3600, loss: 2.701055, top_1: 0.551680, top_k: 0.785977, samples/s: 851.317 1613006970.3611379
train: epoch 27, iter 3700, loss: 2.708044, top_1: 0.550078, top_k: 0.779570, samples/s: 847.241 1613007000.5769668
train: epoch 27, iter 3800, loss: 2.775172, top_1: 0.552969, top_k: 0.785742, samples/s: 853.884 1613007030.55761
train: epoch 27, iter 3900, loss: 3.009466, top_1: 0.556602, top_k: 0.787773, samples/s: 849.201 1613007060.7034967
train: epoch 27, iter 4000, loss: 2.833719, top_1: 0.549648, top_k: 0.785312, samples/s: 850.998 1613007090.7858765
train: epoch 27, iter 4100, loss: 2.824511, top_1: 0.553984, top_k: 0.783516, samples/s: 852.091 1613007120.8296304
train: epoch 27, iter 4200, loss: 2.977158, top_1: 0.555234, top_k: 0.785820, samples/s: 849.705 1613007150.9577794
train: epoch 27, iter 4300, loss: 2.798938, top_1: 0.553867, top_k: 0.782695, samples/s: 849.487 1613007181.093599
train: epoch 27, iter 4400, loss: 2.830729, top_1: 0.549727, top_k: 0.785742, samples/s: 850.703 1613007211.1863558
train: epoch 27, iter 4500, loss: 3.012688, top_1: 0.556055, top_k: 0.784023, samples/s: 849.688 1613007241.3149457
train: epoch 27, iter 4600, loss: 3.175903, top_1: 0.555117, top_k: 0.785898, samples/s: 854.471 1613007271.2750566
train: epoch 27, iter 4700, loss: 2.930292, top_1: 0.555078, top_k: 0.783945, samples/s: 851.393 1613007301.3434281
train: epoch 27, iter 4800, loss: 2.871259, top_1: 0.552344, top_k: 0.786094, samples/s: 848.653 1613007331.5088482
train: epoch 27, iter 4900, loss: 2.999715, top_1: 0.553828, top_k: 0.785195, samples/s: 851.355 1613007361.5786388
train: epoch 27, iter 5000, loss: 2.884703, top_1: 0.561367, top_k: 0.788555, samples/s: 851.716 1613007391.6355436
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_27.
validation: epoch 27, iter 195, top_1: 0.596775, top_k: 0.833654, samples/s: 2425.528 1613007413.1092012
train: epoch 28, iter 100, loss: 2.827006, top_1: 0.571172, top_k: 0.801328, samples/s: 871.508 1613007463.0758724
train: epoch 28, iter 200, loss: 2.801978, top_1: 0.570195, top_k: 0.792891, samples/s: 868.047 1613007492.5674372
train: epoch 28, iter 300, loss: 2.840531, top_1: 0.562813, top_k: 0.794375, samples/s: 856.339 1613007522.462155
train: epoch 28, iter 400, loss: 2.695386, top_1: 0.568164, top_k: 0.796172, samples/s: 853.283 1613007552.463858
train: epoch 28, iter 500, loss: 2.707960, top_1: 0.559414, top_k: 0.786641, samples/s: 846.180 1613007582.7175317
train: epoch 28, iter 600, loss: 2.933205, top_1: 0.560000, top_k: 0.790156, samples/s: 848.975 1613007612.8715177
train: epoch 28, iter 700, loss: 2.812052, top_1: 0.565156, top_k: 0.792773, samples/s: 851.727 1613007642.9280515
train: epoch 28, iter 800, loss: 2.920951, top_1: 0.564336, top_k: 0.794414, samples/s: 847.709 1613007673.1271567
train: epoch 28, iter 900, loss: 3.022015, top_1: 0.563672, top_k: 0.793711, samples/s: 850.862 1613007703.2142854
train: epoch 28, iter 1000, loss: 2.919702, top_1: 0.557109, top_k: 0.790586, samples/s: 848.849 1613007733.3727782
train: epoch 28, iter 1100, loss: 2.740163, top_1: 0.560664, top_k: 0.790898, samples/s: 850.165 1613007763.4845598
train: epoch 28, iter 1200, loss: 2.823306, top_1: 0.556758, top_k: 0.783945, samples/s: 850.240 1613007793.5936825
train: epoch 28, iter 1300, loss: 2.741966, top_1: 0.562187, top_k: 0.788828, samples/s: 851.993 1613007823.6408627
train: epoch 28, iter 1400, loss: 2.845003, top_1: 0.561133, top_k: 0.790078, samples/s: 847.596 1613007853.8440065
train: epoch 28, iter 1500, loss: 2.826586, top_1: 0.556250, top_k: 0.787109, samples/s: 848.636 1613007884.010035
train: epoch 28, iter 1600, loss: 3.007527, top_1: 0.558906, top_k: 0.786797, samples/s: 850.372 1613007914.114533
train: epoch 28, iter 1700, loss: 2.827645, top_1: 0.561484, top_k: 0.789687, samples/s: 849.676 1613007944.2437181
train: epoch 28, iter 1800, loss: 2.729306, top_1: 0.561523, top_k: 0.788555, samples/s: 851.710 1613007974.3008866
train: epoch 28, iter 1900, loss: 2.714696, top_1: 0.561758, top_k: 0.789687, samples/s: 850.297 1613008004.4080355
train: epoch 28, iter 2000, loss: 2.914097, top_1: 0.564531, top_k: 0.790352, samples/s: 849.552 1613008034.5415418
train: epoch 28, iter 2100, loss: 2.804523, top_1: 0.556641, top_k: 0.785625, samples/s: 851.964 1613008064.5897079
train: epoch 28, iter 2200, loss: 2.810816, top_1: 0.561484, top_k: 0.790469, samples/s: 849.543 1613008094.723524
train: epoch 28, iter 2300, loss: 2.963215, top_1: 0.557852, top_k: 0.791133, samples/s: 850.563 1613008124.8212132
train: epoch 28, iter 2400, loss: 2.907569, top_1: 0.552539, top_k: 0.787695, samples/s: 851.457 1613008154.8874116
train: epoch 28, iter 2500, loss: 2.887596, top_1: 0.555859, top_k: 0.786211, samples/s: 849.012 1613008185.0401
train: epoch 28, iter 2600, loss: 2.822947, top_1: 0.553555, top_k: 0.783906, samples/s: 847.646 1613008215.2413714
train: epoch 28, iter 2700, loss: 3.055619, top_1: 0.557852, top_k: 0.784805, samples/s: 850.100 1613008245.3554857
train: epoch 28, iter 2800, loss: 2.806098, top_1: 0.562227, top_k: 0.787656, samples/s: 851.692 1613008275.4133067
train: epoch 28, iter 2900, loss: 2.882973, top_1: 0.556875, top_k: 0.787461, samples/s: 849.708 1613008305.5412242
train: epoch 28, iter 3000, loss: 2.897281, top_1: 0.559805, top_k: 0.785117, samples/s: 849.696 1613008335.6697552
train: epoch 28, iter 3100, loss: 2.763327, top_1: 0.556523, top_k: 0.787188, samples/s: 850.999 1613008365.7519832
train: epoch 28, iter 3200, loss: 2.888204, top_1: 0.557383, top_k: 0.787773, samples/s: 853.165 1613008395.7579114
train: epoch 28, iter 3300, loss: 2.829298, top_1: 0.557227, top_k: 0.784414, samples/s: 852.007 1613008425.8046646
train: epoch 28, iter 3400, loss: 2.652740, top_1: 0.555742, top_k: 0.784687, samples/s: 849.486 1613008455.9404795
train: epoch 28, iter 3500, loss: 2.795913, top_1: 0.563789, top_k: 0.788867, samples/s: 848.679 1613008486.104993
train: epoch 28, iter 3600, loss: 2.708417, top_1: 0.559180, top_k: 0.792773, samples/s: 852.070 1613008516.149551
train: epoch 28, iter 3700, loss: 2.866031, top_1: 0.563398, top_k: 0.791914, samples/s: 850.056 1613008546.2652307
train: epoch 28, iter 3800, loss: 2.699874, top_1: 0.554063, top_k: 0.784219, samples/s: 851.304 1613008576.3366144
train: epoch 28, iter 3900, loss: 2.813066, top_1: 0.555508, top_k: 0.786406, samples/s: 849.057 1613008606.4877048
train: epoch 28, iter 4000, loss: 2.992197, top_1: 0.553906, top_k: 0.785547, samples/s: 852.290 1613008636.5244894
train: epoch 28, iter 4100, loss: 3.040828, top_1: 0.554766, top_k: 0.787734, samples/s: 849.467 1613008666.6610296
train: epoch 28, iter 4200, loss: 3.034823, top_1: 0.558320, top_k: 0.785547, samples/s: 849.224 1613008696.8062096
train: epoch 28, iter 4300, loss: 2.858097, top_1: 0.557969, top_k: 0.787930, samples/s: 850.115 1613008726.9197817
train: epoch 28, iter 4400, loss: 2.877522, top_1: 0.556172, top_k: 0.788945, samples/s: 852.219 1613008756.9590702
train: epoch 28, iter 4500, loss: 2.866955, top_1: 0.553555, top_k: 0.784883, samples/s: 849.232 1613008787.1038651
train: epoch 28, iter 4600, loss: 2.894284, top_1: 0.554336, top_k: 0.783594, samples/s: 850.592 1613008817.2006345
train: epoch 28, iter 4700, loss: 2.677294, top_1: 0.563398, top_k: 0.784141, samples/s: 852.187 1613008847.2409678
train: epoch 28, iter 4800, loss: 2.744012, top_1: 0.557422, top_k: 0.786680, samples/s: 850.998 1613008877.323282
train: epoch 28, iter 4900, loss: 2.841294, top_1: 0.553477, top_k: 0.786133, samples/s: 850.347 1613008907.4286242
train: epoch 28, iter 5000, loss: 2.849517, top_1: 0.555000, top_k: 0.782305, samples/s: 852.188 1613008937.4689498
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_28.
validation: epoch 28, iter 195, top_1: 0.610317, top_k: 0.841166, samples/s: 2402.816 1613008959.146554
train: epoch 29, iter 100, loss: 2.785601, top_1: 0.564180, top_k: 0.793945, samples/s: 870.868 1613009009.4645069
train: epoch 29, iter 200, loss: 2.856376, top_1: 0.569414, top_k: 0.795586, samples/s: 867.646 1613009038.9697056
train: epoch 29, iter 300, loss: 2.817977, top_1: 0.559063, top_k: 0.792109, samples/s: 858.337 1613009068.794733
train: epoch 29, iter 400, loss: 3.008807, top_1: 0.564336, top_k: 0.794336, samples/s: 852.251 1613009098.8328707
train: epoch 29, iter 500, loss: 2.738837, top_1: 0.564102, top_k: 0.790312, samples/s: 846.692 1613009129.0681345
train: epoch 29, iter 600, loss: 2.797433, top_1: 0.564180, top_k: 0.795195, samples/s: 848.965 1613009159.222575
train: epoch 29, iter 700, loss: 2.876612, top_1: 0.557969, top_k: 0.790664, samples/s: 849.438 1613009189.3600771
train: epoch 29, iter 800, loss: 2.911588, top_1: 0.567422, top_k: 0.791992, samples/s: 850.765 1613009219.450611
train: epoch 29, iter 900, loss: 2.675829, top_1: 0.566758, top_k: 0.793555, samples/s: 849.152 1613009249.5984282
train: epoch 29, iter 1000, loss: 2.723413, top_1: 0.561953, top_k: 0.795508, samples/s: 850.844 1613009279.6862435
train: epoch 29, iter 1100, loss: 2.661204, top_1: 0.564727, top_k: 0.794648, samples/s: 849.060 1613009309.8372061
train: epoch 29, iter 1200, loss: 2.703000, top_1: 0.560195, top_k: 0.791719, samples/s: 850.389 1613009339.9410174
train: epoch 29, iter 1300, loss: 2.728604, top_1: 0.561992, top_k: 0.790898, samples/s: 853.204 1613009369.9455416
train: epoch 29, iter 1400, loss: 2.841079, top_1: 0.566367, top_k: 0.793789, samples/s: 849.772 1613009400.0713193
train: epoch 29, iter 1500, loss: 2.701394, top_1: 0.558633, top_k: 0.785234, samples/s: 851.500 1613009430.1359673
train: epoch 29, iter 1600, loss: 2.745218, top_1: 0.557539, top_k: 0.787969, samples/s: 851.197 1613009460.211284
train: epoch 29, iter 1700, loss: 2.736273, top_1: 0.556836, top_k: 0.786328, samples/s: 851.263 1613009490.2842982
train: epoch 29, iter 1800, loss: 2.633125, top_1: 0.562148, top_k: 0.792305, samples/s: 851.079 1613009520.3636312
train: epoch 29, iter 1900, loss: 2.929018, top_1: 0.566680, top_k: 0.795234, samples/s: 848.771 1613009550.5248885
train: epoch 29, iter 2000, loss: 2.849041, top_1: 0.566172, top_k: 0.793711, samples/s: 854.671 1613009580.4779422
train: epoch 29, iter 2100, loss: 2.909535, top_1: 0.556367, top_k: 0.789492, samples/s: 848.886 1613009610.6350703
train: epoch 29, iter 2200, loss: 2.800314, top_1: 0.562852, top_k: 0.792148, samples/s: 849.550 1613009640.7688
train: epoch 29, iter 2300, loss: 2.616316, top_1: 0.568672, top_k: 0.791797, samples/s: 851.347 1613009670.8387163
train: epoch 29, iter 2400, loss: 2.844268, top_1: 0.565156, top_k: 0.796211, samples/s: 852.979 1613009700.851156
train: epoch 29, iter 2500, loss: 2.960671, top_1: 0.563164, top_k: 0.790117, samples/s: 849.593 1613009730.9833317
train: epoch 29, iter 2600, loss: 2.771477, top_1: 0.558320, top_k: 0.788125, samples/s: 852.341 1613009761.018202
train: epoch 29, iter 2700, loss: 2.867554, top_1: 0.558438, top_k: 0.789219, samples/s: 853.065 1613009791.0276966
train: epoch 29, iter 2800, loss: 2.750413, top_1: 0.566055, top_k: 0.790469, samples/s: 851.009 1613009821.1095157
train: epoch 29, iter 2900, loss: 2.753304, top_1: 0.560000, top_k: 0.790703, samples/s: 852.092 1613009851.1533532
train: epoch 29, iter 3000, loss: 2.581306, top_1: 0.563320, top_k: 0.794648, samples/s: 850.546 1613009881.251566
train: epoch 29, iter 3100, loss: 2.847334, top_1: 0.558906, top_k: 0.786328, samples/s: 850.597 1613009911.3480473
train: epoch 29, iter 3200, loss: 2.709127, top_1: 0.558633, top_k: 0.786211, samples/s: 851.526 1613009941.4117355
train: epoch 29, iter 3300, loss: 2.701953, top_1: 0.560547, top_k: 0.787695, samples/s: 851.529 1613009971.4753342
train: epoch 29, iter 3400, loss: 2.606136, top_1: 0.559766, top_k: 0.789219, samples/s: 853.420 1613010001.4723134
train: epoch 29, iter 3500, loss: 2.693630, top_1: 0.554375, top_k: 0.783945, samples/s: 852.335 1613010031.5074015
train: epoch 29, iter 3600, loss: 2.714464, top_1: 0.555742, top_k: 0.785391, samples/s: 850.866 1613010061.5943627
train: epoch 29, iter 3700, loss: 2.786985, top_1: 0.551406, top_k: 0.782266, samples/s: 850.913 1613010091.679635
train: epoch 29, iter 3800, loss: 2.827338, top_1: 0.557695, top_k: 0.790508, samples/s: 849.155 1613010121.8272905
train: epoch 29, iter 3900, loss: 2.834939, top_1: 0.557187, top_k: 0.787773, samples/s: 852.253 1613010151.8652987
train: epoch 29, iter 4000, loss: 2.704903, top_1: 0.564141, top_k: 0.793164, samples/s: 852.013 1613010181.9117522
train: epoch 29, iter 4100, loss: 2.855181, top_1: 0.555469, top_k: 0.785000, samples/s: 850.500 1613010212.0117147
train: epoch 29, iter 4200, loss: 2.706668, top_1: 0.562539, top_k: 0.790039, samples/s: 849.780 1613010242.1372485
train: epoch 29, iter 4300, loss: 2.871727, top_1: 0.557656, top_k: 0.786797, samples/s: 850.737 1613010272.2287579
train: epoch 29, iter 4400, loss: 2.836870, top_1: 0.559922, top_k: 0.787852, samples/s: 849.816 1613010302.3528724
train: epoch 29, iter 4500, loss: 2.791627, top_1: 0.559492, top_k: 0.790820, samples/s: 851.930 1613010332.4022787
train: epoch 29, iter 4600, loss: 2.926477, top_1: 0.556094, top_k: 0.785664, samples/s: 848.881 1613010362.559608
train: epoch 29, iter 4700, loss: 2.697165, top_1: 0.551016, top_k: 0.782500, samples/s: 852.003 1613010392.606566
train: epoch 29, iter 4800, loss: 2.806592, top_1: 0.558906, top_k: 0.786367, samples/s: 851.340 1613010422.6767397
train: epoch 29, iter 4900, loss: 2.728761, top_1: 0.549805, top_k: 0.784141, samples/s: 850.770 1613010452.7671728
train: epoch 29, iter 5000, loss: 2.856554, top_1: 0.556406, top_k: 0.789453, samples/s: 851.871 1613010482.8185668
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_29.
validation: epoch 29, iter 195, top_1: 0.604728, top_k: 0.836398, samples/s: 2453.616 1613010504.060335
train: epoch 30, iter 100, loss: 2.740969, top_1: 0.567383, top_k: 0.795703, samples/s: 869.485 1613010553.8219008
train: epoch 30, iter 200, loss: 2.699504, top_1: 0.570430, top_k: 0.797461, samples/s: 867.413 1613010583.334892
train: epoch 30, iter 300, loss: 2.559352, top_1: 0.575234, top_k: 0.802422, samples/s: 857.115 1613010613.202536
train: epoch 30, iter 400, loss: 2.744214, top_1: 0.567500, top_k: 0.801406, samples/s: 847.469 1613010643.4102418
train: epoch 30, iter 500, loss: 2.835197, top_1: 0.567266, top_k: 0.789414, samples/s: 850.623 1613010673.5058458
train: epoch 30, iter 600, loss: 2.940476, top_1: 0.566055, top_k: 0.793398, samples/s: 850.526 1613010703.6047785
train: epoch 30, iter 700, loss: 2.826414, top_1: 0.563555, top_k: 0.795547, samples/s: 848.649 1613010733.7704473
train: epoch 30, iter 800, loss: 2.844563, top_1: 0.566719, top_k: 0.789492, samples/s: 847.227 1613010763.986656
train: epoch 30, iter 900, loss: 2.855821, top_1: 0.564492, top_k: 0.794063, samples/s: 852.395 1613010794.019724
train: epoch 30, iter 1000, loss: 2.705510, top_1: 0.566914, top_k: 0.792852, samples/s: 850.293 1613010824.1268709
train: epoch 30, iter 1100, loss: 2.691709, top_1: 0.566992, top_k: 0.795625, samples/s: 850.861 1613010854.2141373
train: epoch 30, iter 1200, loss: 3.015405, top_1: 0.564727, top_k: 0.791602, samples/s: 847.633 1613010884.4163551
train: epoch 30, iter 1300, loss: 2.758507, top_1: 0.562344, top_k: 0.791445, samples/s: 850.403 1613010914.5192432
train: epoch 30, iter 1400, loss: 3.079455, top_1: 0.565469, top_k: 0.791719, samples/s: 850.768 1613010944.609699
train: epoch 30, iter 1500, loss: 2.712685, top_1: 0.568516, top_k: 0.794336, samples/s: 849.669 1613010974.7390916
train: epoch 30, iter 1600, loss: 2.870072, top_1: 0.563203, top_k: 0.788438, samples/s: 850.672 1613011004.8329413
train: epoch 30, iter 1700, loss: 2.953977, top_1: 0.564063, top_k: 0.791328, samples/s: 852.005 1613011034.879615
train: epoch 30, iter 1800, loss: 2.761079, top_1: 0.557109, top_k: 0.789648, samples/s: 850.060 1613011064.995472
train: epoch 30, iter 1900, loss: 2.893393, top_1: 0.564023, top_k: 0.792188, samples/s: 853.945 1613011094.9736574
train: epoch 30, iter 2000, loss: 2.884967, top_1: 0.564258, top_k: 0.791719, samples/s: 850.848 1613011125.0613303
train: epoch 30, iter 2100, loss: 2.679224, top_1: 0.564727, top_k: 0.792852, samples/s: 849.640 1613011155.1917148
train: epoch 30, iter 2200, loss: 2.852706, top_1: 0.573516, top_k: 0.795039, samples/s: 850.258 1613011185.3002408
train: epoch 30, iter 2300, loss: 2.748660, top_1: 0.571992, top_k: 0.795273, samples/s: 850.435 1613011215.40256
train: epoch 30, iter 2400, loss: 2.701022, top_1: 0.560977, top_k: 0.788750, samples/s: 848.997 1613011245.5556831
train: epoch 30, iter 2500, loss: 2.860654, top_1: 0.561016, top_k: 0.787266, samples/s: 852.903 1613011275.570863
train: epoch 30, iter 2600, loss: 2.838078, top_1: 0.562031, top_k: 0.788242, samples/s: 847.698 1613011305.770253
train: epoch 30, iter 2700, loss: 2.765281, top_1: 0.555312, top_k: 0.786367, samples/s: 851.561 1613011335.8327928
train: epoch 30, iter 2800, loss: 2.703819, top_1: 0.561836, top_k: 0.788398, samples/s: 853.342 1613011365.832457
train: epoch 30, iter 2900, loss: 2.913184, top_1: 0.558242, top_k: 0.789609, samples/s: 847.269 1613011396.0471103
train: epoch 30, iter 3000, loss: 2.903362, top_1: 0.560508, top_k: 0.788320, samples/s: 848.156 1613011426.2302325
train: epoch 30, iter 3100, loss: 2.810829, top_1: 0.561328, top_k: 0.790469, samples/s: 850.004 1613011456.3477585
train: epoch 30, iter 3200, loss: 2.963290, top_1: 0.559258, top_k: 0.790742, samples/s: 848.717 1613011486.510908
train: epoch 30, iter 3300, loss: 2.872326, top_1: 0.556055, top_k: 0.785898, samples/s: 850.821 1613011516.5995116
train: epoch 30, iter 3400, loss: 2.720448, top_1: 0.559648, top_k: 0.790781, samples/s: 849.677 1613011546.7286465
train: epoch 30, iter 3500, loss: 2.924905, top_1: 0.564063, top_k: 0.793789, samples/s: 851.524 1613011576.7923448
train: epoch 30, iter 3600, loss: 3.017260, top_1: 0.559063, top_k: 0.784531, samples/s: 850.455 1613011606.8939755
train: epoch 30, iter 3700, loss: 2.980631, top_1: 0.562852, top_k: 0.787930, samples/s: 850.737 1613011636.985393
train: epoch 30, iter 3800, loss: 2.898744, top_1: 0.558359, top_k: 0.789062, samples/s: 850.856 1613011667.072851
train: epoch 30, iter 3900, loss: 2.793614, top_1: 0.557656, top_k: 0.792148, samples/s: 851.064 1613011697.1527376
train: epoch 30, iter 4000, loss: 2.709576, top_1: 0.562891, top_k: 0.789258, samples/s: 852.016 1613011727.1998024
train: epoch 30, iter 4100, loss: 2.809911, top_1: 0.558789, top_k: 0.791680, samples/s: 849.288 1613011757.342136
train: epoch 30, iter 4200, loss: 2.989845, top_1: 0.553555, top_k: 0.788164, samples/s: 850.722 1613011787.4341505
train: epoch 30, iter 4300, loss: 2.997250, top_1: 0.559219, top_k: 0.788867, samples/s: 852.673 1613011817.4573486
train: epoch 30, iter 4400, loss: 2.576531, top_1: 0.564492, top_k: 0.787422, samples/s: 846.645 1613011847.694606
train: epoch 30, iter 4500, loss: 2.785358, top_1: 0.557305, top_k: 0.786758, samples/s: 850.498 1613011877.7944164
train: epoch 30, iter 4600, loss: 2.683142, top_1: 0.556367, top_k: 0.786875, samples/s: 850.460 1613011907.8957067
train: epoch 30, iter 4700, loss: 2.791368, top_1: 0.560273, top_k: 0.788906, samples/s: 849.598 1613011938.0276966
train: epoch 30, iter 4800, loss: 2.939050, top_1: 0.559375, top_k: 0.790430, samples/s: 850.764 1613011968.1181612
train: epoch 30, iter 4900, loss: 2.895431, top_1: 0.562500, top_k: 0.789687, samples/s: 850.548 1613011998.2163923
train: epoch 30, iter 5000, loss: 2.652513, top_1: 0.561680, top_k: 0.787617, samples/s: 849.423 1613012028.3545582
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_30.
validation: epoch 30, iter 195, top_1: 0.608914, top_k: 0.840365, samples/s: 2431.862 1613012049.784945
train: epoch 31, iter 100, loss: 2.659595, top_1: 0.570703, top_k: 0.795703, samples/s: 867.090 1613012100.3199015
train: epoch 31, iter 200, loss: 3.039027, top_1: 0.571758, top_k: 0.798828, samples/s: 868.904 1613012129.782403
train: epoch 31, iter 300, loss: 2.575579, top_1: 0.575273, top_k: 0.802031, samples/s: 855.934 1613012159.6911347
train: epoch 31, iter 400, loss: 2.836049, top_1: 0.567930, top_k: 0.795430, samples/s: 849.475 1613012189.8274574
train: epoch 31, iter 500, loss: 2.823540, top_1: 0.569141, top_k: 0.795000, samples/s: 848.267 1613012220.0066528
train: epoch 31, iter 600, loss: 2.668102, top_1: 0.567578, top_k: 0.798008, samples/s: 850.644 1613012250.101399
train: epoch 31, iter 700, loss: 2.719445, top_1: 0.566406, top_k: 0.797344, samples/s: 849.060 1613012280.2524936
train: epoch 31, iter 800, loss: 2.785924, top_1: 0.568438, top_k: 0.794297, samples/s: 849.296 1613012310.395078
train: epoch 31, iter 900, loss: 2.802362, top_1: 0.570820, top_k: 0.796367, samples/s: 848.475 1613012340.566868
train: epoch 31, iter 1000, loss: 2.915243, top_1: 0.568320, top_k: 0.793672, samples/s: 851.427 1613012370.6339297
train: epoch 31, iter 1100, loss: 2.694416, top_1: 0.567383, top_k: 0.791836, samples/s: 848.025 1613012400.8217566
train: epoch 31, iter 1200, loss: 2.869947, top_1: 0.565703, top_k: 0.789219, samples/s: 852.944 1613012430.83548
train: epoch 31, iter 1300, loss: 2.840686, top_1: 0.562656, top_k: 0.791680, samples/s: 848.308 1613012461.0132556
train: epoch 31, iter 1400, loss: 2.981583, top_1: 0.562578, top_k: 0.788516, samples/s: 850.587 1613012491.1099927
train: epoch 31, iter 1500, loss: 2.831731, top_1: 0.565625, top_k: 0.791328, samples/s: 851.895 1613012521.1606145
train: epoch 31, iter 1600, loss: 2.865036, top_1: 0.562539, top_k: 0.789922, samples/s: 850.853 1613012551.2480876
train: epoch 31, iter 1700, loss: 2.760432, top_1: 0.567773, top_k: 0.794648, samples/s: 850.888 1613012581.334393
train: epoch 31, iter 1800, loss: 2.692311, top_1: 0.560937, top_k: 0.787695, samples/s: 849.592 1613012611.4664104
train: epoch 31, iter 1900, loss: 2.729721, top_1: 0.558672, top_k: 0.791250, samples/s: 851.846 1613012641.518809
train: epoch 31, iter 2000, loss: 2.741816, top_1: 0.565469, top_k: 0.790937, samples/s: 851.069 1613012671.5986376
train: epoch 31, iter 2100, loss: 2.947850, top_1: 0.562187, top_k: 0.789961, samples/s: 849.336 1613012701.73977
train: epoch 31, iter 2200, loss: 2.865480, top_1: 0.562695, top_k: 0.788711, samples/s: 851.831 1613012731.7927496
train: epoch 31, iter 2300, loss: 2.767497, top_1: 0.566914, top_k: 0.794063, samples/s: 848.605 1613012761.9598362
train: epoch 31, iter 2400, loss: 2.663375, top_1: 0.566992, top_k: 0.795547, samples/s: 850.899 1613012792.0456607
train: epoch 31, iter 2500, loss: 2.756238, top_1: 0.561055, top_k: 0.788164, samples/s: 852.941 1613012822.0595105
train: epoch 31, iter 2600, loss: 2.657403, top_1: 0.564688, top_k: 0.792852, samples/s: 849.966 1613012852.1783783
train: epoch 31, iter 2700, loss: 2.929728, top_1: 0.561602, top_k: 0.791445, samples/s: 851.512 1613012882.2424588
train: epoch 31, iter 2800, loss: 2.689765, top_1: 0.561289, top_k: 0.795898, samples/s: 853.118 1613012912.2500718
train: epoch 31, iter 2900, loss: 2.972106, top_1: 0.556523, top_k: 0.790273, samples/s: 848.070 1613012942.4363606
train: epoch 31, iter 3000, loss: 2.834628, top_1: 0.566055, top_k: 0.796484, samples/s: 851.755 1613012972.4919043
train: epoch 31, iter 3100, loss: 2.948955, top_1: 0.565625, top_k: 0.788789, samples/s: 850.851 1613013002.579429
train: epoch 31, iter 3200, loss: 2.876904, top_1: 0.564531, top_k: 0.788945, samples/s: 851.024 1613013032.660746
train: epoch 31, iter 3300, loss: 2.766627, top_1: 0.561445, top_k: 0.788711, samples/s: 851.005 1613013062.7429204
train: epoch 31, iter 3400, loss: 2.736753, top_1: 0.559961, top_k: 0.786680, samples/s: 850.143 1613013092.85552
train: epoch 31, iter 3500, loss: 2.678736, top_1: 0.557617, top_k: 0.788867, samples/s: 850.738 1613013122.9475102
train: epoch 31, iter 3600, loss: 2.733622, top_1: 0.567617, top_k: 0.793750, samples/s: 850.761 1613013153.0377052
train: epoch 31, iter 3700, loss: 2.751839, top_1: 0.564375, top_k: 0.793438, samples/s: 850.967 1613013183.1214945
train: epoch 31, iter 3800, loss: 2.786131, top_1: 0.561562, top_k: 0.787695, samples/s: 851.213 1613013213.1957843
train: epoch 31, iter 3900, loss: 2.785256, top_1: 0.570937, top_k: 0.794883, samples/s: 851.710 1613013243.2530782
train: epoch 31, iter 4000, loss: 2.671475, top_1: 0.569766, top_k: 0.794648, samples/s: 847.804 1613013273.4486728
train: epoch 31, iter 4100, loss: 2.799607, top_1: 0.561797, top_k: 0.790469, samples/s: 850.499 1613013303.54865
train: epoch 31, iter 4200, loss: 2.907531, top_1: 0.558984, top_k: 0.787695, samples/s: 852.537 1613013333.576623
train: epoch 31, iter 4300, loss: 2.780437, top_1: 0.562422, top_k: 0.789062, samples/s: 851.619 1613013363.6371093
train: epoch 31, iter 4400, loss: 2.833891, top_1: 0.562930, top_k: 0.788867, samples/s: 848.619 1613013393.803673
train: epoch 31, iter 4500, loss: 2.832589, top_1: 0.556562, top_k: 0.789453, samples/s: 852.112 1613013423.8467789
train: epoch 31, iter 4600, loss: 2.887520, top_1: 0.569492, top_k: 0.790234, samples/s: 851.040 1613013453.927606
train: epoch 31, iter 4700, loss: 2.866427, top_1: 0.560469, top_k: 0.788555, samples/s: 848.702 1613013484.091302
train: epoch 31, iter 4800, loss: 2.794675, top_1: 0.566719, top_k: 0.790547, samples/s: 852.418 1613013514.123559
train: epoch 31, iter 4900, loss: 2.829988, top_1: 0.562969, top_k: 0.791289, samples/s: 849.131 1613013544.2719655
train: epoch 31, iter 5000, loss: 2.736948, top_1: 0.566875, top_k: 0.789219, samples/s: 852.177 1613013574.3127284
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_31.
validation: epoch 31, iter 195, top_1: 0.602183, top_k: 0.838782, samples/s: 2432.609 1613013595.733679
train: epoch 32, iter 100, loss: 2.683554, top_1: 0.572109, top_k: 0.800742, samples/s: 871.691 1613013645.8278499
train: epoch 32, iter 200, loss: 2.736328, top_1: 0.573398, top_k: 0.795469, samples/s: 867.296 1613013675.3448203
train: epoch 32, iter 300, loss: 2.740553, top_1: 0.574570, top_k: 0.796250, samples/s: 855.502 1613013705.2687924
train: epoch 32, iter 400, loss: 2.752854, top_1: 0.578047, top_k: 0.800937, samples/s: 849.176 1613013735.4157043
train: epoch 32, iter 500, loss: 2.737475, top_1: 0.575820, top_k: 0.798789, samples/s: 849.920 1613013765.536191
train: epoch 32, iter 600, loss: 2.821933, top_1: 0.567773, top_k: 0.796914, samples/s: 848.638 1613013795.7021544
train: epoch 32, iter 700, loss: 2.849296, top_1: 0.573828, top_k: 0.795742, samples/s: 850.314 1613013825.808585
train: epoch 32, iter 800, loss: 2.787900, top_1: 0.567734, top_k: 0.798477, samples/s: 847.917 1613013856.0002823
train: epoch 32, iter 900, loss: 2.846616, top_1: 0.565547, top_k: 0.796875, samples/s: 847.256 1613013886.2154315
train: epoch 32, iter 1000, loss: 2.826823, top_1: 0.569219, top_k: 0.796562, samples/s: 851.192 1613013916.2908792
train: epoch 32, iter 1100, loss: 2.674409, top_1: 0.566445, top_k: 0.793047, samples/s: 847.988 1613013946.4800696
train: epoch 32, iter 1200, loss: 2.719040, top_1: 0.571250, top_k: 0.795117, samples/s: 850.366 1613013976.584672
train: epoch 32, iter 1300, loss: 2.846306, top_1: 0.567734, top_k: 0.796094, samples/s: 848.902 1613014006.7412565
train: epoch 32, iter 1400, loss: 2.989798, top_1: 0.560703, top_k: 0.791523, samples/s: 851.511 1613014036.8055062
train: epoch 32, iter 1500, loss: 3.021056, top_1: 0.570664, top_k: 0.797773, samples/s: 849.744 1613014066.9322135
train: epoch 32, iter 1600, loss: 2.793348, top_1: 0.568672, top_k: 0.799102, samples/s: 846.300 1613014097.1814969
train: epoch 32, iter 1700, loss: 2.812478, top_1: 0.562305, top_k: 0.791055, samples/s: 847.803 1613014127.3772154
train: epoch 32, iter 1800, loss: 2.775442, top_1: 0.570273, top_k: 0.793945, samples/s: 847.918 1613014157.5689023
train: epoch 32, iter 1900, loss: 2.904614, top_1: 0.564336, top_k: 0.792031, samples/s: 848.767 1613014187.730247
train: epoch 32, iter 2000, loss: 2.638615, top_1: 0.566094, top_k: 0.796094, samples/s: 848.332 1613014217.9071743
train: epoch 32, iter 2100, loss: 2.750827, top_1: 0.563477, top_k: 0.789414, samples/s: 846.851 1613014248.1367145
train: epoch 32, iter 2200, loss: 2.940432, top_1: 0.568398, top_k: 0.792852, samples/s: 848.106 1613014278.3216562
train: epoch 32, iter 2300, loss: 2.640879, top_1: 0.567891, top_k: 0.796992, samples/s: 850.661 1613014308.4159493
train: epoch 32, iter 2400, loss: 2.858461, top_1: 0.561641, top_k: 0.791406, samples/s: 849.232 1613014338.560821
train: epoch 32, iter 2500, loss: 2.719197, top_1: 0.569336, top_k: 0.794844, samples/s: 849.133 1613014368.7092462
train: epoch 32, iter 2600, loss: 2.834761, top_1: 0.564297, top_k: 0.790898, samples/s: 848.949 1613014398.864122
train: epoch 32, iter 2700, loss: 2.895668, top_1: 0.561758, top_k: 0.790703, samples/s: 848.332 1613014429.0409415
train: epoch 32, iter 2800, loss: 2.979194, top_1: 0.566133, top_k: 0.791953, samples/s: 849.395 1613014459.1800814
train: epoch 32, iter 2900, loss: 2.855930, top_1: 0.565508, top_k: 0.788477, samples/s: 848.496 1613014489.3510985
train: epoch 32, iter 3000, loss: 2.994458, top_1: 0.563906, top_k: 0.793164, samples/s: 849.816 1613014519.4752789
train: epoch 32, iter 3100, loss: 2.875504, top_1: 0.567734, top_k: 0.792500, samples/s: 846.970 1613014549.7006335
train: epoch 32, iter 3200, loss: 2.862298, top_1: 0.561445, top_k: 0.791641, samples/s: 847.821 1613014579.8957317
train: epoch 32, iter 3300, loss: 2.875345, top_1: 0.561328, top_k: 0.787969, samples/s: 851.094 1613014609.9746423
train: epoch 32, iter 3400, loss: 2.922751, top_1: 0.559023, top_k: 0.790117, samples/s: 847.824 1613014640.1695592
train: epoch 32, iter 3500, loss: 2.599844, top_1: 0.564414, top_k: 0.792422, samples/s: 849.806 1613014670.2941377
train: epoch 32, iter 3600, loss: 2.636143, top_1: 0.568711, top_k: 0.796289, samples/s: 851.332 1613014700.3646498
train: epoch 32, iter 3700, loss: 2.694309, top_1: 0.564688, top_k: 0.792656, samples/s: 848.033 1613014730.5522354
train: epoch 32, iter 3800, loss: 2.646827, top_1: 0.558828, top_k: 0.789297, samples/s: 847.120 1613014760.772171
train: epoch 32, iter 3900, loss: 2.885496, top_1: 0.566992, top_k: 0.793398, samples/s: 849.320 1613014790.9139638
train: epoch 32, iter 4000, loss: 2.753629, top_1: 0.567187, top_k: 0.792578, samples/s: 848.254 1613014821.0936444
train: epoch 32, iter 4100, loss: 2.717625, top_1: 0.561055, top_k: 0.787305, samples/s: 848.385 1613014851.2686398
train: epoch 32, iter 4200, loss: 2.780249, top_1: 0.566641, top_k: 0.796445, samples/s: 849.836 1613014881.3919973
train: epoch 32, iter 4300, loss: 2.686217, top_1: 0.567383, top_k: 0.795352, samples/s: 847.416 1613014911.6015103
train: epoch 32, iter 4400, loss: 2.668718, top_1: 0.558984, top_k: 0.786758, samples/s: 851.519 1613014941.665459
train: epoch 32, iter 4500, loss: 2.783731, top_1: 0.566914, top_k: 0.790742, samples/s: 846.990 1613014971.8901007
train: epoch 32, iter 4600, loss: 2.817078, top_1: 0.561602, top_k: 0.791836, samples/s: 849.012 1613015002.0428302
train: epoch 32, iter 4700, loss: 3.079770, top_1: 0.564922, top_k: 0.791914, samples/s: 847.515 1613015032.248809
train: epoch 32, iter 4800, loss: 2.885575, top_1: 0.563438, top_k: 0.793164, samples/s: 847.896 1613015062.4412255
train: epoch 32, iter 4900, loss: 2.773483, top_1: 0.561133, top_k: 0.789375, samples/s: 846.944 1613015092.6675396
train: epoch 32, iter 5000, loss: 2.789458, top_1: 0.562695, top_k: 0.790273, samples/s: 848.772 1613015122.8287568
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_32.
validation: epoch 32, iter 195, top_1: 0.618309, top_k: 0.846595, samples/s: 2448.950 1613015144.097031
train: epoch 33, iter 100, loss: 2.859215, top_1: 0.575859, top_k: 0.802773, samples/s: 872.080 1613015194.126751
train: epoch 33, iter 200, loss: 2.835929, top_1: 0.577031, top_k: 0.802617, samples/s: 867.266 1613015223.6448216
train: epoch 33, iter 300, loss: 2.849710, top_1: 0.574531, top_k: 0.800781, samples/s: 851.860 1613015253.696717
train: epoch 33, iter 400, loss: 2.858958, top_1: 0.578242, top_k: 0.803359, samples/s: 847.634 1613015283.898348
train: epoch 33, iter 500, loss: 2.866132, top_1: 0.569102, top_k: 0.801094, samples/s: 847.847 1613015314.0925546
train: epoch 33, iter 600, loss: 2.743105, top_1: 0.572578, top_k: 0.798008, samples/s: 849.645 1613015344.2227695
train: epoch 33, iter 700, loss: 2.978917, top_1: 0.563477, top_k: 0.794687, samples/s: 846.022 1613015374.4820662
train: epoch 33, iter 800, loss: 2.902362, top_1: 0.572422, top_k: 0.796875, samples/s: 844.855 1613015404.7830663
train: epoch 33, iter 900, loss: 2.744915, top_1: 0.571719, top_k: 0.797695, samples/s: 848.788 1613015434.9436693
train: epoch 33, iter 1000, loss: 2.683067, top_1: 0.573242, top_k: 0.798555, samples/s: 845.556 1613015465.2196667
train: epoch 33, iter 1100, loss: 2.777938, top_1: 0.570039, top_k: 0.796719, samples/s: 846.898 1613015495.4476728
train: epoch 33, iter 1200, loss: 2.747988, top_1: 0.567383, top_k: 0.792734, samples/s: 849.274 1613015525.5909681
train: epoch 33, iter 1300, loss: 2.733071, top_1: 0.562187, top_k: 0.791289, samples/s: 850.771 1613015555.681416
train: epoch 33, iter 1400, loss: 2.783479, top_1: 0.564961, top_k: 0.792227, samples/s: 847.628 1613015585.8832536
train: epoch 33, iter 1500, loss: 2.749472, top_1: 0.566875, top_k: 0.798086, samples/s: 847.466 1613015616.0909963
train: epoch 33, iter 1600, loss: 2.753497, top_1: 0.567266, top_k: 0.797227, samples/s: 846.765 1613015646.3236659
train: epoch 33, iter 1700, loss: 2.795789, top_1: 0.572187, top_k: 0.796094, samples/s: 849.513 1613015676.4585888
train: epoch 33, iter 1800, loss: 2.767983, top_1: 0.566289, top_k: 0.792305, samples/s: 845.640 1613015706.7315907
train: epoch 33, iter 1900, loss: 2.592369, top_1: 0.566562, top_k: 0.795273, samples/s: 846.008 1613015736.991292
train: epoch 33, iter 2000, loss: 3.059684, top_1: 0.563320, top_k: 0.794023, samples/s: 851.637 1613015767.0510972
train: epoch 33, iter 2100, loss: 3.013675, top_1: 0.567500, top_k: 0.792305, samples/s: 846.129 1613015797.3065555
train: epoch 33, iter 2200, loss: 2.810562, top_1: 0.565898, top_k: 0.793672, samples/s: 846.748 1613015827.5398695
train: epoch 33, iter 2300, loss: 2.760524, top_1: 0.565273, top_k: 0.796016, samples/s: 849.282 1613015857.6829793
train: epoch 33, iter 2400, loss: 2.637914, top_1: 0.563398, top_k: 0.790508, samples/s: 851.327 1613015887.7536898
train: epoch 33, iter 2500, loss: 2.786062, top_1: 0.560430, top_k: 0.788633, samples/s: 849.750 1613015917.8801327
train: epoch 33, iter 2600, loss: 2.693126, top_1: 0.563398, top_k: 0.793008, samples/s: 845.982 1613015948.1408055
train: epoch 33, iter 2700, loss: 2.969519, top_1: 0.563398, top_k: 0.794805, samples/s: 849.411 1613015978.2793477
train: epoch 33, iter 2800, loss: 2.802185, top_1: 0.559727, top_k: 0.789219, samples/s: 849.070 1613016008.429985
train: epoch 33, iter 2900, loss: 2.853094, top_1: 0.561953, top_k: 0.791406, samples/s: 846.300 1613016038.6792998
train: epoch 33, iter 3000, loss: 2.739192, top_1: 0.566406, top_k: 0.795000, samples/s: 850.761 1613016068.7700608
train: epoch 33, iter 3100, loss: 2.809042, top_1: 0.566328, top_k: 0.796680, samples/s: 847.237 1613016098.9859817
train: epoch 33, iter 3200, loss: 2.819706, top_1: 0.570352, top_k: 0.794844, samples/s: 847.637 1613016129.1875622
train: epoch 33, iter 3300, loss: 2.795776, top_1: 0.564258, top_k: 0.795273, samples/s: 847.806 1613016159.3830452
train: epoch 33, iter 3400, loss: 2.767718, top_1: 0.572383, top_k: 0.798438, samples/s: 849.173 1613016189.530098
train: epoch 33, iter 3500, loss: 2.810408, top_1: 0.564414, top_k: 0.794922, samples/s: 847.723 1613016219.7287078
train: epoch 33, iter 3600, loss: 2.651150, top_1: 0.562656, top_k: 0.789648, samples/s: 847.056 1613016249.950986
train: epoch 33, iter 3700, loss: 2.906631, top_1: 0.570898, top_k: 0.792734, samples/s: 848.523 1613016280.121041
train: epoch 33, iter 3800, loss: 2.931627, top_1: 0.563398, top_k: 0.793828, samples/s: 849.038 1613016310.2727575
train: epoch 33, iter 3900, loss: 2.643797, top_1: 0.574414, top_k: 0.796094, samples/s: 843.394 1613016340.6263783
train: epoch 33, iter 4000, loss: 2.930845, top_1: 0.564961, top_k: 0.794883, samples/s: 849.251 1613016370.7704952
train: epoch 33, iter 4100, loss: 2.995092, top_1: 0.571992, top_k: 0.795312, samples/s: 846.681 1613016401.0063276
train: epoch 33, iter 4200, loss: 2.873340, top_1: 0.569883, top_k: 0.795430, samples/s: 851.773 1613016431.0612893
train: epoch 33, iter 4300, loss: 2.796520, top_1: 0.561914, top_k: 0.787461, samples/s: 848.605 1613016461.228368
train: epoch 33, iter 4400, loss: 2.803201, top_1: 0.569648, top_k: 0.795156, samples/s: 846.434 1613016491.4729624
train: epoch 33, iter 4500, loss: 2.869249, top_1: 0.563555, top_k: 0.793320, samples/s: 847.825 1613016521.6678565
train: epoch 33, iter 4600, loss: 2.858961, top_1: 0.565586, top_k: 0.797266, samples/s: 850.559 1613016551.765615
train: epoch 33, iter 4700, loss: 2.922165, top_1: 0.566250, top_k: 0.794609, samples/s: 846.073 1613016582.0230417
train: epoch 33, iter 4800, loss: 2.962327, top_1: 0.563281, top_k: 0.792695, samples/s: 848.500 1613016612.193925
train: epoch 33, iter 4900, loss: 2.878282, top_1: 0.563633, top_k: 0.794648, samples/s: 848.626 1613016642.3606277
train: epoch 33, iter 5000, loss: 2.611412, top_1: 0.565703, top_k: 0.793438, samples/s: 847.428 1613016672.5694578
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_33.
validation: epoch 33, iter 195, top_1: 0.618630, top_k: 0.845753, samples/s: 2443.166 1613016693.8890934
train: epoch 34, iter 100, loss: 2.790803, top_1: 0.580820, top_k: 0.807227, samples/s: 868.809 1613016743.6517618
train: epoch 34, iter 200, loss: 2.786506, top_1: 0.575234, top_k: 0.797930, samples/s: 868.380 1613016773.1319695
train: epoch 34, iter 300, loss: 2.685688, top_1: 0.581875, top_k: 0.805117, samples/s: 850.414 1613016803.2348802
train: epoch 34, iter 400, loss: 2.766701, top_1: 0.573711, top_k: 0.802031, samples/s: 846.321 1613016833.4834595
train: epoch 34, iter 500, loss: 2.784030, top_1: 0.571406, top_k: 0.800078, samples/s: 847.438 1613016863.6921546
train: epoch 34, iter 600, loss: 2.739119, top_1: 0.566328, top_k: 0.795898, samples/s: 847.694 1613016893.8917792
train: epoch 34, iter 700, loss: 2.810919, top_1: 0.578633, top_k: 0.800859, samples/s: 846.640 1613016924.1289496
train: epoch 34, iter 800, loss: 2.813652, top_1: 0.580508, top_k: 0.807383, samples/s: 843.484 1613016954.4792445
train: epoch 34, iter 900, loss: 2.776475, top_1: 0.573672, top_k: 0.799414, samples/s: 847.876 1613016984.6723511
train: epoch 34, iter 1000, loss: 2.651001, top_1: 0.572227, top_k: 0.797422, samples/s: 847.864 1613017014.8658779
train: epoch 34, iter 1100, loss: 2.748932, top_1: 0.578047, top_k: 0.798242, samples/s: 841.268 1613017045.2962277
train: epoch 34, iter 1200, loss: 2.907873, top_1: 0.570937, top_k: 0.800898, samples/s: 849.302 1613017075.4385161
train: epoch 34, iter 1300, loss: 2.986992, top_1: 0.575352, top_k: 0.798828, samples/s: 844.170 1613017105.7642708
train: epoch 34, iter 1400, loss: 2.730600, top_1: 0.565586, top_k: 0.794570, samples/s: 846.161 1613017136.018486
train: epoch 34, iter 1500, loss: 2.806357, top_1: 0.575117, top_k: 0.799219, samples/s: 847.215 1613017166.2351205
train: epoch 34, iter 1600, loss: 2.863967, top_1: 0.572734, top_k: 0.794844, samples/s: 845.163 1613017196.5251482
train: epoch 34, iter 1700, loss: 2.913842, top_1: 0.568789, top_k: 0.793633, samples/s: 847.867 1613017226.7186644
train: epoch 34, iter 1800, loss: 2.902982, top_1: 0.572969, top_k: 0.798359, samples/s: 846.529 1613017256.959651
train: epoch 34, iter 1900, loss: 2.875361, top_1: 0.566758, top_k: 0.793828, samples/s: 847.052 1613017287.1821287
train: epoch 34, iter 2000, loss: 2.764067, top_1: 0.565937, top_k: 0.790781, samples/s: 850.601 1613017317.2784896
train: epoch 34, iter 2100, loss: 2.733009, top_1: 0.569063, top_k: 0.798750, samples/s: 848.023 1613017347.4663494
train: epoch 34, iter 2200, loss: 2.652314, top_1: 0.575039, top_k: 0.798047, samples/s: 848.755 1613017377.6282299
train: epoch 34, iter 2300, loss: 2.583370, top_1: 0.565273, top_k: 0.794883, samples/s: 847.280 1613017407.8425784
train: epoch 34, iter 2400, loss: 2.907064, top_1: 0.567891, top_k: 0.793672, samples/s: 847.132 1613017438.0621712
train: epoch 34, iter 2500, loss: 2.987721, top_1: 0.565195, top_k: 0.795078, samples/s: 850.746 1613017468.1534061
train: epoch 34, iter 2600, loss: 2.775478, top_1: 0.568789, top_k: 0.793672, samples/s: 849.734 1613017498.280451
train: epoch 34, iter 2700, loss: 2.689865, top_1: 0.575000, top_k: 0.797305, samples/s: 848.956 1613017528.4352028
train: epoch 34, iter 2800, loss: 2.830571, top_1: 0.565469, top_k: 0.790469, samples/s: 847.344 1613017558.6472523
train: epoch 34, iter 2900, loss: 3.099164, top_1: 0.568398, top_k: 0.790469, samples/s: 848.217 1613017588.8281507
train: epoch 34, iter 3000, loss: 2.849677, top_1: 0.563242, top_k: 0.793984, samples/s: 846.400 1613017619.074001
train: epoch 34, iter 3100, loss: 2.701943, top_1: 0.565820, top_k: 0.790508, samples/s: 847.311 1613017649.287195
train: epoch 34, iter 3200, loss: 2.621541, top_1: 0.570664, top_k: 0.797148, samples/s: 849.993 1613017679.4050949
train: epoch 34, iter 3300, loss: 2.881862, top_1: 0.572187, top_k: 0.792695, samples/s: 844.400 1613017709.7224472
train: epoch 34, iter 3400, loss: 2.786800, top_1: 0.565469, top_k: 0.791953, samples/s: 848.527 1613017739.8923497
train: epoch 34, iter 3500, loss: 2.769227, top_1: 0.565078, top_k: 0.791484, samples/s: 846.077 1613017770.1497498
train: epoch 34, iter 3600, loss: 2.690346, top_1: 0.563516, top_k: 0.794531, samples/s: 848.161 1613017800.3327065
train: epoch 34, iter 3700, loss: 2.721164, top_1: 0.572695, top_k: 0.798984, samples/s: 846.213 1613017830.5851574
train: epoch 34, iter 3800, loss: 2.771350, top_1: 0.569141, top_k: 0.795469, samples/s: 844.750 1613017860.8899264
train: epoch 34, iter 3900, loss: 2.798472, top_1: 0.573594, top_k: 0.797148, samples/s: 845.276 1613017891.1758425
train: epoch 34, iter 4000, loss: 2.732362, top_1: 0.565977, top_k: 0.788984, samples/s: 844.363 1613017921.4946618
train: epoch 34, iter 4100, loss: 2.985817, top_1: 0.568398, top_k: 0.794102, samples/s: 846.473 1613017951.7377334
train: epoch 34, iter 4200, loss: 2.832438, top_1: 0.566914, top_k: 0.795039, samples/s: 844.388 1613017982.0555274
train: epoch 34, iter 4300, loss: 2.725077, top_1: 0.564453, top_k: 0.791055, samples/s: 842.388 1613018012.4453735
train: epoch 34, iter 4400, loss: 2.691679, top_1: 0.564063, top_k: 0.791875, samples/s: 847.218 1613018042.661855
train: epoch 34, iter 4500, loss: 2.790149, top_1: 0.561562, top_k: 0.790430, samples/s: 843.051 1613018073.0278268
train: epoch 34, iter 4600, loss: 2.786281, top_1: 0.563711, top_k: 0.790898, samples/s: 848.584 1613018103.195707
train: epoch 34, iter 4700, loss: 2.981023, top_1: 0.564961, top_k: 0.792109, samples/s: 843.137 1613018133.5585134
train: epoch 34, iter 4800, loss: 2.795376, top_1: 0.563789, top_k: 0.795156, samples/s: 846.548 1613018163.7990136
train: epoch 34, iter 4900, loss: 2.656785, top_1: 0.569063, top_k: 0.797070, samples/s: 843.484 1613018194.1492283
train: epoch 34, iter 5000, loss: 2.732708, top_1: 0.572187, top_k: 0.796406, samples/s: 844.544 1613018224.4615247
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_34.
validation: epoch 34, iter 195, top_1: 0.620613, top_k: 0.847837, samples/s: 2429.334 1613018245.9113371
train: epoch 35, iter 100, loss: 2.703708, top_1: 0.586758, top_k: 0.808438, samples/s: 868.718 1613018301.199727
train: epoch 35, iter 200, loss: 2.681477, top_1: 0.577031, top_k: 0.801328, samples/s: 869.418 1613018330.6447346
train: epoch 35, iter 300, loss: 2.817059, top_1: 0.579297, top_k: 0.803945, samples/s: 853.329 1613018360.6448994
train: epoch 35, iter 400, loss: 2.651816, top_1: 0.575508, top_k: 0.803516, samples/s: 846.970 1613018390.870322
train: epoch 35, iter 500, loss: 2.716828, top_1: 0.576250, top_k: 0.801953, samples/s: 843.473 1613018421.2209308
train: epoch 35, iter 600, loss: 2.885988, top_1: 0.571914, top_k: 0.800117, samples/s: 846.355 1613018451.4683623
train: epoch 35, iter 700, loss: 2.744457, top_1: 0.570547, top_k: 0.797422, samples/s: 845.522 1613018481.745506
train: epoch 35, iter 800, loss: 2.883451, top_1: 0.572031, top_k: 0.797813, samples/s: 846.793 1613018511.9771929
train: epoch 35, iter 900, loss: 2.796351, top_1: 0.569805, top_k: 0.799102, samples/s: 844.189 1613018542.3021562
train: epoch 35, iter 1000, loss: 2.521953, top_1: 0.575469, top_k: 0.801641, samples/s: 845.775 1613018572.5702412
train: epoch 35, iter 1100, loss: 2.640081, top_1: 0.574336, top_k: 0.798047, samples/s: 846.817 1613018602.8011088
train: epoch 35, iter 1200, loss: 2.725760, top_1: 0.573984, top_k: 0.801133, samples/s: 844.868 1613018633.1017365
train: epoch 35, iter 1300, loss: 2.713055, top_1: 0.571172, top_k: 0.797539, samples/s: 849.014 1613018663.2544076
train: epoch 35, iter 1400, loss: 2.628618, top_1: 0.574063, top_k: 0.802070, samples/s: 846.981 1613018693.4792588
train: epoch 35, iter 1500, loss: 2.761706, top_1: 0.569727, top_k: 0.799375, samples/s: 844.670 1613018723.78701
train: epoch 35, iter 1600, loss: 2.666854, top_1: 0.574375, top_k: 0.798125, samples/s: 844.665 1613018754.0949123
train: epoch 35, iter 1700, loss: 2.783132, top_1: 0.570273, top_k: 0.797461, samples/s: 847.808 1613018784.2903998
train: epoch 35, iter 1800, loss: 2.871742, top_1: 0.571797, top_k: 0.797148, samples/s: 844.324 1613018814.6104264
train: epoch 35, iter 1900, loss: 2.715206, top_1: 0.567031, top_k: 0.791055, samples/s: 848.266 1613018844.789634
train: epoch 35, iter 2000, loss: 2.667444, top_1: 0.569258, top_k: 0.794180, samples/s: 849.048 1613018874.9410305
train: epoch 35, iter 2100, loss: 2.778228, top_1: 0.567734, top_k: 0.795664, samples/s: 845.349 1613018905.2245076
train: epoch 35, iter 2200, loss: 2.670791, top_1: 0.570625, top_k: 0.798359, samples/s: 845.087 1613018935.5171552
train: epoch 35, iter 2300, loss: 2.971013, top_1: 0.567227, top_k: 0.794336, samples/s: 846.705 1613018965.7520735
train: epoch 35, iter 2400, loss: 2.733120, top_1: 0.566641, top_k: 0.792734, samples/s: 848.861 1613018995.9101317
train: epoch 35, iter 2500, loss: 2.731857, top_1: 0.569258, top_k: 0.796094, samples/s: 848.475 1613019026.081859
train: epoch 35, iter 2600, loss: 2.747743, top_1: 0.568789, top_k: 0.795195, samples/s: 849.196 1613019056.228036
train: epoch 35, iter 2700, loss: 2.922142, top_1: 0.572891, top_k: 0.799375, samples/s: 845.877 1613019086.4924965
train: epoch 35, iter 2800, loss: 2.773877, top_1: 0.570117, top_k: 0.794727, samples/s: 847.525 1613019116.6980007
train: epoch 35, iter 2900, loss: 2.865847, top_1: 0.566914, top_k: 0.793320, samples/s: 848.526 1613019146.8680425
train: epoch 35, iter 3000, loss: 2.660488, top_1: 0.569297, top_k: 0.796914, samples/s: 846.782 1613019177.1001513
train: epoch 35, iter 3100, loss: 2.848319, top_1: 0.569492, top_k: 0.796562, samples/s: 846.947 1613019207.326346
train: epoch 35, iter 3200, loss: 2.769272, top_1: 0.568672, top_k: 0.795664, samples/s: 848.783 1613019237.4872277
train: epoch 35, iter 3300, loss: 2.754514, top_1: 0.572109, top_k: 0.800508, samples/s: 847.123 1613019267.7071059
train: epoch 35, iter 3400, loss: 2.610523, top_1: 0.566953, top_k: 0.792578, samples/s: 847.927 1613019297.8983817
train: epoch 35, iter 3500, loss: 2.719547, top_1: 0.566211, top_k: 0.793242, samples/s: 848.913 1613019328.0546134
train: epoch 35, iter 3600, loss: 2.665441, top_1: 0.565898, top_k: 0.793945, samples/s: 849.719 1613019358.1822114
train: epoch 35, iter 3700, loss: 2.772085, top_1: 0.567227, top_k: 0.797305, samples/s: 846.705 1613019388.417011
train: epoch 35, iter 3800, loss: 2.800349, top_1: 0.565664, top_k: 0.794219, samples/s: 850.339 1613019418.5227695
train: epoch 35, iter 3900, loss: 2.629359, top_1: 0.573125, top_k: 0.795586, samples/s: 846.190 1613019448.7759895
train: epoch 35, iter 4000, loss: 2.677326, top_1: 0.568438, top_k: 0.794883, samples/s: 848.238 1613019478.956184
train: epoch 35, iter 4100, loss: 2.756913, top_1: 0.570312, top_k: 0.794492, samples/s: 848.775 1613019509.1172757
train: epoch 35, iter 4200, loss: 2.795026, top_1: 0.570156, top_k: 0.793867, samples/s: 847.803 1613019539.3129115
train: epoch 35, iter 4300, loss: 2.879413, top_1: 0.566211, top_k: 0.792383, samples/s: 847.912 1613019569.504717
train: epoch 35, iter 4400, loss: 2.811391, top_1: 0.566797, top_k: 0.791602, samples/s: 848.256 1613019599.684281
train: epoch 35, iter 4500, loss: 2.915956, top_1: 0.564492, top_k: 0.793828, samples/s: 849.312 1613019629.8263848
train: epoch 35, iter 4600, loss: 2.919495, top_1: 0.566602, top_k: 0.795117, samples/s: 847.808 1613019660.02193
train: epoch 35, iter 4700, loss: 2.800246, top_1: 0.566602, top_k: 0.790430, samples/s: 850.158 1613019690.1339886
train: epoch 35, iter 4800, loss: 2.925999, top_1: 0.567344, top_k: 0.794922, samples/s: 846.207 1613019720.38661
train: epoch 35, iter 4900, loss: 2.723671, top_1: 0.564727, top_k: 0.793125, samples/s: 851.950 1613019750.43523
train: epoch 35, iter 5000, loss: 2.717314, top_1: 0.575430, top_k: 0.798203, samples/s: 847.469 1613019780.6428173
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_35.
validation: epoch 35, iter 195, top_1: 0.626583, top_k: 0.853466, samples/s: 2458.418 1613019801.8492098
train: epoch 36, iter 100, loss: 2.692268, top_1: 0.586016, top_k: 0.807070, samples/s: 871.472 1613019851.902216
train: epoch 36, iter 200, loss: 2.625871, top_1: 0.581719, top_k: 0.805195, samples/s: 866.313 1613019881.4526732
train: epoch 36, iter 300, loss: 2.935869, top_1: 0.586055, top_k: 0.808672, samples/s: 855.966 1613019911.3604167
train: epoch 36, iter 400, loss: 2.731432, top_1: 0.575781, top_k: 0.806250, samples/s: 846.646 1613019941.5973883
train: epoch 36, iter 500, loss: 2.571995, top_1: 0.579141, top_k: 0.800312, samples/s: 847.562 1613019971.8015728
train: epoch 36, iter 600, loss: 2.659862, top_1: 0.573555, top_k: 0.800312, samples/s: 845.860 1613020002.0667212
train: epoch 36, iter 700, loss: 2.865148, top_1: 0.581641, top_k: 0.807773, samples/s: 848.770 1613020032.2279875
train: epoch 36, iter 800, loss: 2.953504, top_1: 0.575898, top_k: 0.797422, samples/s: 848.110 1613020062.412734
train: epoch 36, iter 900, loss: 2.584195, top_1: 0.575469, top_k: 0.798203, samples/s: 848.351 1613020092.5889146
train: epoch 36, iter 1000, loss: 2.766050, top_1: 0.574063, top_k: 0.798555, samples/s: 848.849 1613020122.7474496
train: epoch 36, iter 1100, loss: 2.604401, top_1: 0.573828, top_k: 0.794727, samples/s: 846.400 1613020152.993085
train: epoch 36, iter 1200, loss: 3.082890, top_1: 0.575313, top_k: 0.798125, samples/s: 848.152 1613020183.1764853
train: epoch 36, iter 1300, loss: 2.687002, top_1: 0.574141, top_k: 0.801133, samples/s: 848.943 1613020213.3315752
train: epoch 36, iter 1400, loss: 2.780098, top_1: 0.578516, top_k: 0.803398, samples/s: 847.443 1613020243.540021
train: epoch 36, iter 1500, loss: 2.851111, top_1: 0.574336, top_k: 0.798203, samples/s: 847.415 1613020273.7496107
train: epoch 36, iter 1600, loss: 2.885684, top_1: 0.575820, top_k: 0.801211, samples/s: 850.195 1613020303.860346
train: epoch 36, iter 1700, loss: 2.826891, top_1: 0.575937, top_k: 0.801055, samples/s: 849.563 1613020333.9935668
train: epoch 36, iter 1800, loss: 2.972844, top_1: 0.569492, top_k: 0.795156, samples/s: 847.067 1613020364.2154343
train: epoch 36, iter 1900, loss: 2.835342, top_1: 0.577695, top_k: 0.801289, samples/s: 848.765 1613020394.376904
train: epoch 36, iter 2000, loss: 2.733733, top_1: 0.572695, top_k: 0.798359, samples/s: 848.367 1613020424.5525088
train: epoch 36, iter 2100, loss: 2.893074, top_1: 0.571055, top_k: 0.799102, samples/s: 847.219 1613020454.7690344
train: epoch 36, iter 2200, loss: 2.674438, top_1: 0.569414, top_k: 0.798242, samples/s: 848.622 1613020484.9354699
train: epoch 36, iter 2300, loss: 2.627366, top_1: 0.577891, top_k: 0.800820, samples/s: 846.359 1613020515.1826982
train: epoch 36, iter 2400, loss: 2.787009, top_1: 0.564492, top_k: 0.790781, samples/s: 850.094 1613020545.2970219
train: epoch 36, iter 2500, loss: 2.704091, top_1: 0.567148, top_k: 0.794492, samples/s: 846.066 1613020575.5547566
train: epoch 36, iter 2600, loss: 2.809199, top_1: 0.567422, top_k: 0.799883, samples/s: 849.020 1613020605.707195
train: epoch 36, iter 2700, loss: 2.768078, top_1: 0.574297, top_k: 0.800234, samples/s: 848.065 1613020635.8934786
train: epoch 36, iter 2800, loss: 2.645590, top_1: 0.573086, top_k: 0.795742, samples/s: 848.038 1613020666.0808122
train: epoch 36, iter 2900, loss: 2.698366, top_1: 0.566289, top_k: 0.796953, samples/s: 846.262 1613020696.3315523
train: epoch 36, iter 3000, loss: 2.752464, top_1: 0.564453, top_k: 0.791914, samples/s: 848.306 1613020726.5093594
train: epoch 36, iter 3100, loss: 2.907812, top_1: 0.569531, top_k: 0.795586, samples/s: 849.767 1613020756.635192
train: epoch 36, iter 3200, loss: 2.878036, top_1: 0.570469, top_k: 0.791445, samples/s: 849.178 1613020786.78195
train: epoch 36, iter 3300, loss: 2.770381, top_1: 0.572266, top_k: 0.794805, samples/s: 848.950 1613020816.9369204
train: epoch 36, iter 3400, loss: 2.687593, top_1: 0.572734, top_k: 0.799727, samples/s: 850.555 1613020847.034876
train: epoch 36, iter 3500, loss: 2.776340, top_1: 0.570781, top_k: 0.793672, samples/s: 847.714 1613020877.2338223
train: epoch 36, iter 3600, loss: 2.786871, top_1: 0.569453, top_k: 0.796797, samples/s: 847.323 1613020907.4465125
train: epoch 36, iter 3700, loss: 2.928511, top_1: 0.569063, top_k: 0.796250, samples/s: 849.075 1613020937.5969923
train: epoch 36, iter 3800, loss: 2.914536, top_1: 0.568242, top_k: 0.799297, samples/s: 847.818 1613020967.7922475
train: epoch 36, iter 3900, loss: 2.821065, top_1: 0.570391, top_k: 0.796094, samples/s: 846.776 1613020998.0245578
train: epoch 36, iter 4000, loss: 2.823230, top_1: 0.568945, top_k: 0.793398, samples/s: 847.587 1613021028.2279065
train: epoch 36, iter 4100, loss: 2.929690, top_1: 0.563672, top_k: 0.788750, samples/s: 850.488 1613021058.3283563
train: epoch 36, iter 4200, loss: 2.921072, top_1: 0.564531, top_k: 0.789570, samples/s: 847.088 1613021088.549464
train: epoch 36, iter 4300, loss: 2.871194, top_1: 0.570078, top_k: 0.793594, samples/s: 849.325 1613021118.6910396
train: epoch 36, iter 4400, loss: 2.724302, top_1: 0.571953, top_k: 0.793125, samples/s: 848.450 1613021148.8637571
train: epoch 36, iter 4500, loss: 2.918255, top_1: 0.569375, top_k: 0.797891, samples/s: 847.981 1613021179.0529907
train: epoch 36, iter 4600, loss: 2.700284, top_1: 0.564492, top_k: 0.789766, samples/s: 846.741 1613021209.286563
train: epoch 36, iter 4700, loss: 2.688289, top_1: 0.566445, top_k: 0.795664, samples/s: 850.449 1613021239.38836
train: epoch 36, iter 4800, loss: 2.793268, top_1: 0.569883, top_k: 0.791992, samples/s: 849.928 1613021269.5085468
train: epoch 36, iter 4900, loss: 2.789465, top_1: 0.572891, top_k: 0.797930, samples/s: 845.962 1613021299.7698998
train: epoch 36, iter 5000, loss: 2.790218, top_1: 0.569727, top_k: 0.796797, samples/s: 848.547 1613021329.9391525
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_36.
validation: epoch 36, iter 195, top_1: 0.622075, top_k: 0.852845, samples/s: 2418.712 1613021351.4709537
train: epoch 37, iter 100, loss: 2.843249, top_1: 0.583203, top_k: 0.801914, samples/s: 870.223 1613021401.193796
train: epoch 37, iter 200, loss: 2.776375, top_1: 0.577812, top_k: 0.804961, samples/s: 869.408 1613021430.6391554
train: epoch 37, iter 300, loss: 2.689251, top_1: 0.582539, top_k: 0.809102, samples/s: 851.670 1613021460.697644
train: epoch 37, iter 400, loss: 2.713451, top_1: 0.579102, top_k: 0.802344, samples/s: 847.527 1613021490.9031646
train: epoch 37, iter 500, loss: 2.795606, top_1: 0.583125, top_k: 0.803164, samples/s: 847.988 1613021521.0923376
train: epoch 37, iter 600, loss: 2.839887, top_1: 0.578398, top_k: 0.802461, samples/s: 846.050 1613021551.3505337
train: epoch 37, iter 700, loss: 2.856897, top_1: 0.578945, top_k: 0.804375, samples/s: 846.275 1613021581.600811
train: epoch 37, iter 800, loss: 2.738234, top_1: 0.567461, top_k: 0.792891, samples/s: 850.246 1613021611.7096386
train: epoch 37, iter 900, loss: 2.757421, top_1: 0.575820, top_k: 0.799961, samples/s: 848.888 1613021641.8668206
train: epoch 37, iter 1000, loss: 2.758825, top_1: 0.573672, top_k: 0.800977, samples/s: 843.158 1613021672.22889
train: epoch 37, iter 1100, loss: 2.529740, top_1: 0.575430, top_k: 0.800859, samples/s: 846.879 1613021702.4574938
train: epoch 37, iter 1200, loss: 2.747172, top_1: 0.577461, top_k: 0.801367, samples/s: 845.846 1613021732.7230299
train: epoch 37, iter 1300, loss: 2.669816, top_1: 0.580313, top_k: 0.807500, samples/s: 847.208 1613021762.9399292
train: epoch 37, iter 1400, loss: 2.760130, top_1: 0.569570, top_k: 0.797656, samples/s: 846.704 1613021793.1747797
train: epoch 37, iter 1500, loss: 2.668934, top_1: 0.575781, top_k: 0.797578, samples/s: 846.088 1613021823.4316664
train: epoch 37, iter 1600, loss: 2.831106, top_1: 0.574375, top_k: 0.795820, samples/s: 848.587 1613021853.5994227
train: epoch 37, iter 1700, loss: 2.712629, top_1: 0.573438, top_k: 0.797422, samples/s: 843.962 1613021883.9325438
train: epoch 37, iter 1800, loss: 2.738795, top_1: 0.573711, top_k: 0.800078, samples/s: 848.956 1613021914.0872579
train: epoch 37, iter 1900, loss: 2.763923, top_1: 0.570664, top_k: 0.799063, samples/s: 846.112 1613021944.3432896
train: epoch 37, iter 2000, loss: 2.909719, top_1: 0.573281, top_k: 0.797227, samples/s: 849.357 1613021974.4837403
train: epoch 37, iter 2100, loss: 2.946135, top_1: 0.578672, top_k: 0.797891, samples/s: 842.911 1613022004.8547022
train: epoch 37, iter 2200, loss: 2.752721, top_1: 0.570469, top_k: 0.796953, samples/s: 848.814 1613022035.0144343
train: epoch 37, iter 2300, loss: 2.773972, top_1: 0.578828, top_k: 0.798633, samples/s: 846.512 1613022065.2561605
train: epoch 37, iter 2400, loss: 2.682749, top_1: 0.572852, top_k: 0.800859, samples/s: 846.077 1613022095.5135264
train: epoch 37, iter 2500, loss: 2.743881, top_1: 0.567031, top_k: 0.796680, samples/s: 850.145 1613022125.6260455
train: epoch 37, iter 2600, loss: 2.782626, top_1: 0.568203, top_k: 0.797227, samples/s: 846.099 1613022155.8825328
train: epoch 37, iter 2700, loss: 2.820821, top_1: 0.567266, top_k: 0.791836, samples/s: 848.748 1613022186.0445755
train: epoch 37, iter 2800, loss: 2.746921, top_1: 0.571875, top_k: 0.797461, samples/s: 845.665 1613022216.316601
train: epoch 37, iter 2900, loss: 2.919462, top_1: 0.570000, top_k: 0.799766, samples/s: 845.486 1613022246.5951445
train: epoch 37, iter 3000, loss: 2.839187, top_1: 0.571289, top_k: 0.796445, samples/s: 847.339 1613022276.807256
train: epoch 37, iter 3100, loss: 2.698248, top_1: 0.570000, top_k: 0.795000, samples/s: 846.993 1613022307.0318348
train: epoch 37, iter 3200, loss: 2.895908, top_1: 0.574805, top_k: 0.799687, samples/s: 847.434 1613022337.240689
train: epoch 37, iter 3300, loss: 2.867986, top_1: 0.571094, top_k: 0.792734, samples/s: 846.634 1613022367.47824
train: epoch 37, iter 3400, loss: 2.799741, top_1: 0.571445, top_k: 0.795508, samples/s: 845.480 1613022397.7567537
train: epoch 37, iter 3500, loss: 2.934334, top_1: 0.574727, top_k: 0.798008, samples/s: 846.673 1613022427.9927657
train: epoch 37, iter 3600, loss: 2.662938, top_1: 0.571016, top_k: 0.794258, samples/s: 846.466 1613022458.2361305
train: epoch 37, iter 3700, loss: 2.804099, top_1: 0.567578, top_k: 0.791641, samples/s: 848.347 1613022488.4124596
train: epoch 37, iter 3800, loss: 2.677755, top_1: 0.574336, top_k: 0.803125, samples/s: 849.353 1613022518.5531747
train: epoch 37, iter 3900, loss: 2.869113, top_1: 0.574180, top_k: 0.799883, samples/s: 841.794 1613022548.964402
train: epoch 37, iter 4000, loss: 2.792450, top_1: 0.574063, top_k: 0.794375, samples/s: 848.023 1613022579.1522102
train: epoch 37, iter 4100, loss: 2.900084, top_1: 0.578320, top_k: 0.800898, samples/s: 847.453 1613022609.3604817
train: epoch 37, iter 4200, loss: 2.736506, top_1: 0.575000, top_k: 0.798438, samples/s: 844.748 1613022639.6653225
train: epoch 37, iter 4300, loss: 2.765992, top_1: 0.572500, top_k: 0.797344, samples/s: 848.766 1613022669.8267481
train: epoch 37, iter 4400, loss: 2.927520, top_1: 0.572891, top_k: 0.800312, samples/s: 845.043 1613022700.1210368
train: epoch 37, iter 4500, loss: 2.682728, top_1: 0.569531, top_k: 0.795508, samples/s: 848.361 1613022730.2968826
train: epoch 37, iter 4600, loss: 2.736300, top_1: 0.564375, top_k: 0.795703, samples/s: 846.416 1613022760.5420194
train: epoch 37, iter 4700, loss: 2.803521, top_1: 0.569844, top_k: 0.798125, samples/s: 848.028 1613022790.729679
train: epoch 37, iter 4800, loss: 2.746839, top_1: 0.565664, top_k: 0.789648, samples/s: 846.664 1613022820.9660127
train: epoch 37, iter 4900, loss: 2.883204, top_1: 0.569648, top_k: 0.797461, samples/s: 847.100 1613022851.1868603
train: epoch 37, iter 5000, loss: 2.668389, top_1: 0.572070, top_k: 0.800859, samples/s: 845.679 1613022881.4584198
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_37.
validation: epoch 37, iter 195, top_1: 0.624960, top_k: 0.850541, samples/s: 2450.144 1613022902.7129898
train: epoch 38, iter 100, loss: 2.521570, top_1: 0.584688, top_k: 0.809023, samples/s: 870.357 1613022952.5279162
train: epoch 38, iter 200, loss: 2.581037, top_1: 0.581719, top_k: 0.805820, samples/s: 866.515 1613022982.0715215
train: epoch 38, iter 300, loss: 2.752161, top_1: 0.588437, top_k: 0.806250, samples/s: 847.449 1613023012.2798743
train: epoch 38, iter 400, loss: 2.568546, top_1: 0.581172, top_k: 0.806953, samples/s: 845.061 1613023042.5735219
train: epoch 38, iter 500, loss: 2.706350, top_1: 0.578945, top_k: 0.805664, samples/s: 844.623 1613023072.882922
train: epoch 38, iter 600, loss: 2.841938, top_1: 0.575586, top_k: 0.801406, samples/s: 847.386 1613023103.0934381
train: epoch 38, iter 700, loss: 2.820046, top_1: 0.577500, top_k: 0.802109, samples/s: 841.385 1613023133.5195138
train: epoch 38, iter 800, loss: 2.821079, top_1: 0.576719, top_k: 0.798867, samples/s: 843.501 1613023163.869234
train: epoch 38, iter 900, loss: 2.680128, top_1: 0.580039, top_k: 0.804492, samples/s: 846.934 1613023194.0958886
train: epoch 38, iter 1000, loss: 2.963042, top_1: 0.573047, top_k: 0.801055, samples/s: 845.344 1613023224.3793256
train: epoch 38, iter 1100, loss: 2.742472, top_1: 0.577266, top_k: 0.801602, samples/s: 843.560 1613023254.726969
train: epoch 38, iter 1200, loss: 2.439300, top_1: 0.584453, top_k: 0.803789, samples/s: 845.764 1613023284.9954615
train: epoch 38, iter 1300, loss: 2.832210, top_1: 0.570352, top_k: 0.797305, samples/s: 843.299 1613023315.3523946
train: epoch 38, iter 1400, loss: 2.622421, top_1: 0.576523, top_k: 0.800625, samples/s: 848.817 1613023345.5120127
train: epoch 38, iter 1500, loss: 2.788903, top_1: 0.583086, top_k: 0.804805, samples/s: 841.904 1613023375.9193184
train: epoch 38, iter 1600, loss: 2.922670, top_1: 0.578203, top_k: 0.805273, samples/s: 844.815 1613023406.2217336
train: epoch 38, iter 1700, loss: 2.800657, top_1: 0.573008, top_k: 0.799023, samples/s: 845.670 1613023436.4936578
train: epoch 38, iter 1800, loss: 3.004313, top_1: 0.573242, top_k: 0.798008, samples/s: 845.702 1613023466.764365
train: epoch 38, iter 1900, loss: 2.666701, top_1: 0.581797, top_k: 0.804570, samples/s: 845.006 1613023497.0599759
train: epoch 38, iter 2000, loss: 2.958065, top_1: 0.573672, top_k: 0.800742, samples/s: 846.022 1613023527.3192513
train: epoch 38, iter 2100, loss: 2.675019, top_1: 0.577109, top_k: 0.799336, samples/s: 846.937 1613023557.5458314
train: epoch 38, iter 2200, loss: 2.919566, top_1: 0.574531, top_k: 0.796758, samples/s: 846.767 1613023587.7784302
train: epoch 38, iter 2300, loss: 2.918494, top_1: 0.570977, top_k: 0.798945, samples/s: 848.496 1613023617.949398
train: epoch 38, iter 2400, loss: 2.958407, top_1: 0.570078, top_k: 0.799102, samples/s: 845.102 1613023648.2416303
train: epoch 38, iter 2500, loss: 2.758812, top_1: 0.572930, top_k: 0.799805, samples/s: 847.735 1613023678.439818
train: epoch 38, iter 2600, loss: 2.701678, top_1: 0.568984, top_k: 0.796094, samples/s: 845.811 1613023708.7065942
train: epoch 38, iter 2700, loss: 2.760872, top_1: 0.573672, top_k: 0.796680, samples/s: 847.466 1613023738.9142818
train: epoch 38, iter 2800, loss: 2.826422, top_1: 0.568945, top_k: 0.796719, samples/s: 848.277 1613023769.0930495
train: epoch 38, iter 2900, loss: 2.693101, top_1: 0.575430, top_k: 0.800820, samples/s: 846.876 1613023799.3218107
train: epoch 38, iter 3000, loss: 3.006812, top_1: 0.567852, top_k: 0.795625, samples/s: 845.341 1613023829.6055152
train: epoch 38, iter 3100, loss: 2.770069, top_1: 0.575273, top_k: 0.803242, samples/s: 843.658 1613023859.9495432
train: epoch 38, iter 3200, loss: 2.737963, top_1: 0.575313, top_k: 0.799687, samples/s: 849.966 1613023890.068437
train: epoch 38, iter 3300, loss: 2.818308, top_1: 0.574102, top_k: 0.797344, samples/s: 845.434 1613023920.348789
train: epoch 38, iter 3400, loss: 2.787282, top_1: 0.572500, top_k: 0.800508, samples/s: 848.259 1613023950.528207
train: epoch 38, iter 3500, loss: 2.746530, top_1: 0.573008, top_k: 0.798594, samples/s: 846.665 1613023980.7644982
train: epoch 38, iter 3600, loss: 2.647770, top_1: 0.572773, top_k: 0.798555, samples/s: 844.211 1613024011.088713
train: epoch 38, iter 3700, loss: 2.673455, top_1: 0.575781, top_k: 0.801055, samples/s: 845.723 1613024041.358642
train: epoch 38, iter 3800, loss: 2.865402, top_1: 0.574922, top_k: 0.799492, samples/s: 845.571 1613024071.6340263
train: epoch 38, iter 3900, loss: 2.739220, top_1: 0.569063, top_k: 0.794219, samples/s: 844.841 1613024101.935568
train: epoch 38, iter 4000, loss: 2.852859, top_1: 0.571406, top_k: 0.799375, samples/s: 845.609 1613024132.2096782
train: epoch 38, iter 4100, loss: 2.760939, top_1: 0.568242, top_k: 0.797031, samples/s: 848.229 1613024162.3902032
train: epoch 38, iter 4200, loss: 3.012178, top_1: 0.570391, top_k: 0.792344, samples/s: 847.537 1613024192.5952985
train: epoch 38, iter 4300, loss: 2.717917, top_1: 0.576992, top_k: 0.798945, samples/s: 843.357 1613024222.9502094
train: epoch 38, iter 4400, loss: 2.705878, top_1: 0.570937, top_k: 0.800117, samples/s: 847.851 1613024253.1441267
train: epoch 38, iter 4500, loss: 2.651596, top_1: 0.569648, top_k: 0.797813, samples/s: 847.728 1613024283.3425994
train: epoch 38, iter 4600, loss: 2.587532, top_1: 0.565664, top_k: 0.794141, samples/s: 847.276 1613024313.5569603
train: epoch 38, iter 4700, loss: 2.780911, top_1: 0.574414, top_k: 0.795977, samples/s: 843.159 1613024343.918944
train: epoch 38, iter 4800, loss: 2.606997, top_1: 0.572617, top_k: 0.799766, samples/s: 847.473 1613024374.126509
train: epoch 38, iter 4900, loss: 2.906071, top_1: 0.571406, top_k: 0.794570, samples/s: 845.162 1613024404.4165826
train: epoch 38, iter 5000, loss: 2.540624, top_1: 0.578828, top_k: 0.797773, samples/s: 846.164 1613024434.6706576
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_38.
validation: epoch 38, iter 195, top_1: 0.620673, top_k: 0.847596, samples/s: 2440.781 1613024455.9979248
train: epoch 39, iter 100, loss: 2.967651, top_1: 0.592812, top_k: 0.813516, samples/s: 869.486 1613024505.9026287
train: epoch 39, iter 200, loss: 2.691392, top_1: 0.586055, top_k: 0.810312, samples/s: 866.994 1613024535.4298384
train: epoch 39, iter 300, loss: 2.570653, top_1: 0.581953, top_k: 0.803945, samples/s: 848.336 1613024565.6066406
train: epoch 39, iter 400, loss: 2.755912, top_1: 0.581992, top_k: 0.802227, samples/s: 841.628 1613024596.0238311
train: epoch 39, iter 500, loss: 2.858954, top_1: 0.589023, top_k: 0.811758, samples/s: 843.690 1613024626.3667738
train: epoch 39, iter 600, loss: 2.670084, top_1: 0.581758, top_k: 0.803828, samples/s: 846.836 1613024656.5968676
train: epoch 39, iter 700, loss: 2.656729, top_1: 0.581289, top_k: 0.805117, samples/s: 841.090 1613024687.0336623
train: epoch 39, iter 800, loss: 2.709581, top_1: 0.576523, top_k: 0.804336, samples/s: 842.861 1613024717.4063
train: epoch 39, iter 900, loss: 2.749846, top_1: 0.575508, top_k: 0.803047, samples/s: 845.690 1613024747.677467
train: epoch 39, iter 1000, loss: 2.637059, top_1: 0.576875, top_k: 0.802227, samples/s: 843.107 1613024778.041387
train: epoch 39, iter 1100, loss: 2.794201, top_1: 0.576875, top_k: 0.803438, samples/s: 844.627 1613024808.3506439
train: epoch 39, iter 1200, loss: 2.609953, top_1: 0.575742, top_k: 0.802500, samples/s: 842.063 1613024838.7521796
train: epoch 39, iter 1300, loss: 2.694138, top_1: 0.575937, top_k: 0.799453, samples/s: 846.300 1613024869.0014362
train: epoch 39, iter 1400, loss: 2.716006, top_1: 0.581211, top_k: 0.801055, samples/s: 843.425 1613024899.3538375
train: epoch 39, iter 1500, loss: 2.675142, top_1: 0.579063, top_k: 0.803555, samples/s: 845.566 1613024929.6294541
train: epoch 39, iter 1600, loss: 2.888288, top_1: 0.580937, top_k: 0.803750, samples/s: 845.405 1613024959.9108214
train: epoch 39, iter 1700, loss: 2.610135, top_1: 0.578789, top_k: 0.803164, samples/s: 843.105 1613024990.274723
train: epoch 39, iter 1800, loss: 2.833295, top_1: 0.571562, top_k: 0.799922, samples/s: 845.540 1613025020.5511923
train: epoch 39, iter 1900, loss: 2.667148, top_1: 0.581445, top_k: 0.802461, samples/s: 846.888 1613025050.7795768
train: epoch 39, iter 2000, loss: 2.755794, top_1: 0.570977, top_k: 0.799492, samples/s: 841.739 1613025081.1927664
train: epoch 39, iter 2100, loss: 2.718785, top_1: 0.574531, top_k: 0.801289, samples/s: 845.466 1613025111.4719663
train: epoch 39, iter 2200, loss: 2.823224, top_1: 0.576484, top_k: 0.799258, samples/s: 844.912 1613025141.7709887
train: epoch 39, iter 2300, loss: 2.864520, top_1: 0.571680, top_k: 0.796328, samples/s: 845.701 1613025172.0417035
train: epoch 39, iter 2400, loss: 2.835833, top_1: 0.570742, top_k: 0.796953, samples/s: 839.725 1613025202.5278842
train: epoch 39, iter 2500, loss: 2.704086, top_1: 0.577500, top_k: 0.802734, samples/s: 847.505 1613025232.7341642
train: epoch 39, iter 2600, loss: 2.690056, top_1: 0.568594, top_k: 0.794531, samples/s: 842.722 1613025263.1118665
train: epoch 39, iter 2700, loss: 2.687511, top_1: 0.577227, top_k: 0.803047, samples/s: 847.596 1613025293.3149498
train: epoch 39, iter 2800, loss: 2.890820, top_1: 0.576562, top_k: 0.800859, samples/s: 843.891 1613025323.6506536
train: epoch 39, iter 2900, loss: 2.658592, top_1: 0.572148, top_k: 0.799023, samples/s: 846.985 1613025353.8754845
train: epoch 39, iter 3000, loss: 2.671579, top_1: 0.577695, top_k: 0.803828, samples/s: 844.716 1613025384.1816084
train: epoch 39, iter 3100, loss: 2.827888, top_1: 0.577187, top_k: 0.798281, samples/s: 844.399 1613025414.4990594
train: epoch 39, iter 3200, loss: 2.596466, top_1: 0.575664, top_k: 0.801680, samples/s: 844.611 1613025444.8087745
train: epoch 39, iter 3300, loss: 2.715763, top_1: 0.573789, top_k: 0.797383, samples/s: 843.671 1613025475.1524532
train: epoch 39, iter 3400, loss: 2.653247, top_1: 0.569219, top_k: 0.797969, samples/s: 846.694 1613025505.3875864
train: epoch 39, iter 3500, loss: 2.688885, top_1: 0.574922, top_k: 0.798906, samples/s: 843.006 1613025535.755224
train: epoch 39, iter 3600, loss: 2.604107, top_1: 0.572031, top_k: 0.798906, samples/s: 844.850 1613025566.0564046
train: epoch 39, iter 3700, loss: 2.940573, top_1: 0.573789, top_k: 0.799727, samples/s: 846.963 1613025596.2819664
train: epoch 39, iter 3800, loss: 2.908774, top_1: 0.570352, top_k: 0.796250, samples/s: 843.565 1613025626.6294596
train: epoch 39, iter 3900, loss: 2.790861, top_1: 0.571055, top_k: 0.796797, samples/s: 845.396 1613025656.9111392
train: epoch 39, iter 4000, loss: 2.780526, top_1: 0.573438, top_k: 0.795625, samples/s: 845.491 1613025687.1894243
train: epoch 39, iter 4100, loss: 2.773515, top_1: 0.574648, top_k: 0.797969, samples/s: 842.635 1613025717.5702937
train: epoch 39, iter 4200, loss: 2.810740, top_1: 0.577930, top_k: 0.799258, samples/s: 845.610 1613025747.8443067
train: epoch 39, iter 4300, loss: 2.588455, top_1: 0.569336, top_k: 0.798945, samples/s: 846.341 1613025778.0920532
train: epoch 39, iter 4400, loss: 2.600936, top_1: 0.576328, top_k: 0.799570, samples/s: 843.656 1613025808.4361894
train: epoch 39, iter 4500, loss: 2.715131, top_1: 0.575937, top_k: 0.801406, samples/s: 843.871 1613025838.7725725
train: epoch 39, iter 4600, loss: 2.835679, top_1: 0.572031, top_k: 0.795000, samples/s: 848.314 1613025868.9500744
train: epoch 39, iter 4700, loss: 2.736679, top_1: 0.569922, top_k: 0.797227, samples/s: 841.978 1613025899.3547494
train: epoch 39, iter 4800, loss: 2.760848, top_1: 0.578242, top_k: 0.801641, samples/s: 844.062 1613025929.684296
train: epoch 39, iter 4900, loss: 2.830779, top_1: 0.574688, top_k: 0.794805, samples/s: 844.947 1613025959.9819806
train: epoch 39, iter 5000, loss: 2.811932, top_1: 0.569961, top_k: 0.801016, samples/s: 845.835 1613025990.2479002
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_39.
validation: epoch 39, iter 195, top_1: 0.631510, top_k: 0.853806, samples/s: 2448.980 1613026011.556636
train: epoch 40, iter 100, loss: 2.756053, top_1: 0.577148, top_k: 0.803789, samples/s: 872.065 1613026061.5162134
train: epoch 40, iter 200, loss: 2.704447, top_1: 0.582070, top_k: 0.802656, samples/s: 866.154 1613026091.0720928
train: epoch 40, iter 300, loss: 2.763071, top_1: 0.582734, top_k: 0.807344, samples/s: 847.988 1613026121.2612607
train: epoch 40, iter 400, loss: 2.808205, top_1: 0.584297, top_k: 0.806641, samples/s: 843.149 1613026151.6235988
train: epoch 40, iter 500, loss: 2.895141, top_1: 0.585078, top_k: 0.806875, samples/s: 842.477 1613026182.0101926
train: epoch 40, iter 600, loss: 2.514399, top_1: 0.584883, top_k: 0.802539, samples/s: 845.644 1613026212.282906
train: epoch 40, iter 700, loss: 2.732956, top_1: 0.580547, top_k: 0.804492, samples/s: 841.088 1613026242.719672
train: epoch 40, iter 800, loss: 2.633446, top_1: 0.585195, top_k: 0.806211, samples/s: 843.343 1613026273.0750513
train: epoch 40, iter 900, loss: 2.875792, top_1: 0.576406, top_k: 0.803398, samples/s: 844.934 1613026303.3732693
train: epoch 40, iter 1000, loss: 2.998363, top_1: 0.579609, top_k: 0.804688, samples/s: 842.557 1613026333.7570448
train: epoch 40, iter 1100, loss: 2.778235, top_1: 0.578320, top_k: 0.804219, samples/s: 847.652 1613026363.9581258
train: epoch 40, iter 1200, loss: 2.736644, top_1: 0.577852, top_k: 0.803164, samples/s: 842.409 1613026394.347092
train: epoch 40, iter 1300, loss: 2.761739, top_1: 0.574727, top_k: 0.799414, samples/s: 844.542 1613026424.6593268
train: epoch 40, iter 1400, loss: 2.756218, top_1: 0.579805, top_k: 0.802617, samples/s: 843.651 1613026455.0037143
train: epoch 40, iter 1500, loss: 2.763104, top_1: 0.578789, top_k: 0.802188, samples/s: 845.298 1613026485.2888012
train: epoch 40, iter 1600, loss: 2.892117, top_1: 0.579688, top_k: 0.799961, samples/s: 841.436 1613026515.7129993
train: epoch 40, iter 1700, loss: 2.496295, top_1: 0.581602, top_k: 0.807266, samples/s: 844.356 1613026546.0319815
train: epoch 40, iter 1800, loss: 2.823037, top_1: 0.584648, top_k: 0.805117, samples/s: 843.765 1613026576.3722053
train: epoch 40, iter 1900, loss: 2.826004, top_1: 0.579141, top_k: 0.801523, samples/s: 845.552 1613026606.6482878
train: epoch 40, iter 2000, loss: 2.696072, top_1: 0.577227, top_k: 0.801875, samples/s: 840.281 1613026637.114347
train: epoch 40, iter 2100, loss: 2.806660, top_1: 0.576133, top_k: 0.799922, samples/s: 847.518 1613026667.3200917
train: epoch 40, iter 2200, loss: 2.816070, top_1: 0.573203, top_k: 0.801484, samples/s: 842.446 1613026697.7082996
train: epoch 40, iter 2300, loss: 3.061235, top_1: 0.577773, top_k: 0.799648, samples/s: 845.107 1613026727.9998598
train: epoch 40, iter 2400, loss: 2.710965, top_1: 0.573945, top_k: 0.803281, samples/s: 843.253 1613026758.3588102
train: epoch 40, iter 2500, loss: 2.737577, top_1: 0.577773, top_k: 0.803086, samples/s: 841.607 1613026788.7764912
train: epoch 40, iter 2600, loss: 2.759389, top_1: 0.582500, top_k: 0.805000, samples/s: 844.643 1613026819.085242
train: epoch 40, iter 2700, loss: 2.674002, top_1: 0.580117, top_k: 0.803281, samples/s: 844.739 1613026849.3904142
train: epoch 40, iter 2800, loss: 2.752045, top_1: 0.582656, top_k: 0.803398, samples/s: 842.780 1613026879.7660022
train: epoch 40, iter 2900, loss: 2.765148, top_1: 0.580313, top_k: 0.802344, samples/s: 842.320 1613026910.1582398
train: epoch 40, iter 3000, loss: 2.648689, top_1: 0.578672, top_k: 0.802695, samples/s: 843.630 1613026940.5032947
train: epoch 40, iter 3100, loss: 2.697482, top_1: 0.572773, top_k: 0.797891, samples/s: 844.325 1613026970.8234468
train: epoch 40, iter 3200, loss: 2.679259, top_1: 0.578945, top_k: 0.802773, samples/s: 842.277 1613027001.2173002
train: epoch 40, iter 3300, loss: 2.634470, top_1: 0.579336, top_k: 0.803672, samples/s: 844.098 1613027031.5454922
train: epoch 40, iter 3400, loss: 2.867168, top_1: 0.579063, top_k: 0.803398, samples/s: 843.090 1613027061.9100175
train: epoch 40, iter 3500, loss: 2.624884, top_1: 0.572852, top_k: 0.800469, samples/s: 847.145 1613027092.129121
train: epoch 40, iter 3600, loss: 2.992998, top_1: 0.574883, top_k: 0.800898, samples/s: 839.173 1613027122.635294
train: epoch 40, iter 3700, loss: 2.964458, top_1: 0.571562, top_k: 0.799961, samples/s: 843.857 1613027152.972252
train: epoch 40, iter 3800, loss: 2.854941, top_1: 0.576289, top_k: 0.802422, samples/s: 844.394 1613027183.289822
train: epoch 40, iter 3900, loss: 2.835546, top_1: 0.575703, top_k: 0.798125, samples/s: 846.702 1613027213.5247986
train: epoch 40, iter 4000, loss: 2.614275, top_1: 0.569063, top_k: 0.797578, samples/s: 842.503 1613027243.9103878
train: epoch 40, iter 4100, loss: 2.809501, top_1: 0.574609, top_k: 0.797227, samples/s: 844.228 1613027274.233977
train: epoch 40, iter 4200, loss: 3.005715, top_1: 0.573477, top_k: 0.801289, samples/s: 844.507 1613027304.5476236
train: epoch 40, iter 4300, loss: 2.751793, top_1: 0.568789, top_k: 0.793438, samples/s: 843.970 1613027334.880449
train: epoch 40, iter 4400, loss: 2.823526, top_1: 0.571406, top_k: 0.796211, samples/s: 842.534 1613027365.264903
train: epoch 40, iter 4500, loss: 2.918202, top_1: 0.573867, top_k: 0.801016, samples/s: 846.525 1613027395.506635
train: epoch 40, iter 4600, loss: 2.668279, top_1: 0.574141, top_k: 0.802344, samples/s: 841.007 1613027425.9459383
train: epoch 40, iter 4700, loss: 2.862695, top_1: 0.574570, top_k: 0.797070, samples/s: 845.959 1613027456.2076674
train: epoch 40, iter 4800, loss: 2.828008, top_1: 0.575078, top_k: 0.801641, samples/s: 844.048 1613027486.5375047
train: epoch 40, iter 4900, loss: 2.727550, top_1: 0.575898, top_k: 0.801289, samples/s: 844.559 1613027516.8491533
train: epoch 40, iter 5000, loss: 2.650170, top_1: 0.574727, top_k: 0.797344, samples/s: 842.708 1613027547.2274163
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_40.
validation: epoch 40, iter 195, top_1: 0.620433, top_k: 0.847256, samples/s: 2415.165 1613027568.789595
train: epoch 41, iter 100, loss: 2.513469, top_1: 0.581953, top_k: 0.807773, samples/s: 872.697 1613027618.6922884
train: epoch 41, iter 200, loss: 2.673800, top_1: 0.587266, top_k: 0.808984, samples/s: 866.049 1613027648.251858
train: epoch 41, iter 300, loss: 2.700036, top_1: 0.583398, top_k: 0.808438, samples/s: 846.902 1613027678.4796154
train: epoch 41, iter 400, loss: 2.633281, top_1: 0.582773, top_k: 0.805352, samples/s: 840.728 1613027708.9295244
train: epoch 41, iter 500, loss: 2.954697, top_1: 0.580195, top_k: 0.806992, samples/s: 845.317 1613027739.2139406
train: epoch 41, iter 600, loss: 2.673697, top_1: 0.582656, top_k: 0.807930, samples/s: 837.283 1613027769.7890677
train: epoch 41, iter 700, loss: 2.704619, top_1: 0.582461, top_k: 0.807383, samples/s: 844.088 1613027800.1176646
train: epoch 41, iter 800, loss: 2.559749, top_1: 0.581055, top_k: 0.804531, samples/s: 840.569 1613027830.5732884
train: epoch 41, iter 900, loss: 2.788520, top_1: 0.580586, top_k: 0.799844, samples/s: 842.988 1613027860.9413507
train: epoch 41, iter 1000, loss: 2.658509, top_1: 0.584219, top_k: 0.808633, samples/s: 843.663 1613027891.285331
train: epoch 41, iter 1100, loss: 2.677261, top_1: 0.578867, top_k: 0.807383, samples/s: 843.738 1613027921.626469
train: epoch 41, iter 1200, loss: 2.714828, top_1: 0.585039, top_k: 0.808594, samples/s: 842.065 1613027952.0278912
train: epoch 41, iter 1300, loss: 2.637148, top_1: 0.578633, top_k: 0.800820, samples/s: 839.881 1613027982.5084171
train: epoch 41, iter 1400, loss: 2.642248, top_1: 0.580547, top_k: 0.802266, samples/s: 847.974 1613028012.698007
train: epoch 41, iter 1500, loss: 2.810604, top_1: 0.577031, top_k: 0.799219, samples/s: 841.708 1613028043.112284
train: epoch 41, iter 1600, loss: 2.622646, top_1: 0.579258, top_k: 0.803086, samples/s: 845.336 1613028073.396196
train: epoch 41, iter 1700, loss: 2.605484, top_1: 0.581445, top_k: 0.806719, samples/s: 845.355 1613028103.679216
train: epoch 41, iter 1800, loss: 2.680779, top_1: 0.582383, top_k: 0.804414, samples/s: 841.589 1613028134.097947
train: epoch 41, iter 1900, loss: 2.767323, top_1: 0.583086, top_k: 0.804922, samples/s: 844.899 1613028164.39737
train: epoch 41, iter 2000, loss: 2.819433, top_1: 0.576953, top_k: 0.800391, samples/s: 842.876 1613028194.7696056
train: epoch 41, iter 2100, loss: 2.864166, top_1: 0.580039, top_k: 0.802578, samples/s: 845.477 1613028225.0483077
train: epoch 41, iter 2200, loss: 2.671904, top_1: 0.576758, top_k: 0.800273, samples/s: 841.539 1613028255.4688778
train: epoch 41, iter 2300, loss: 2.582232, top_1: 0.581289, top_k: 0.806445, samples/s: 842.889 1613028285.840613
train: epoch 41, iter 2400, loss: 2.722779, top_1: 0.576250, top_k: 0.796758, samples/s: 844.791 1613028316.1438885
train: epoch 41, iter 2500, loss: 2.756204, top_1: 0.576484, top_k: 0.800312, samples/s: 841.960 1613028346.5491147
train: epoch 41, iter 2600, loss: 2.605691, top_1: 0.584258, top_k: 0.801172, samples/s: 847.041 1613028376.7719707
train: epoch 41, iter 2700, loss: 2.760707, top_1: 0.571289, top_k: 0.799336, samples/s: 844.223 1613028407.0958025
train: epoch 41, iter 2800, loss: 2.596640, top_1: 0.579688, top_k: 0.803789, samples/s: 842.744 1613028437.47273
train: epoch 41, iter 2900, loss: 2.653864, top_1: 0.576055, top_k: 0.798398, samples/s: 842.548 1613028467.856712
train: epoch 41, iter 3000, loss: 2.741258, top_1: 0.579258, top_k: 0.802852, samples/s: 844.707 1613028498.163147
train: epoch 41, iter 3100, loss: 2.971786, top_1: 0.576055, top_k: 0.802891, samples/s: 841.616 1613028528.5807316
train: epoch 41, iter 3200, loss: 2.669184, top_1: 0.578359, top_k: 0.801367, samples/s: 845.172 1613028558.8705428
train: epoch 41, iter 3300, loss: 2.841537, top_1: 0.580859, top_k: 0.801328, samples/s: 846.749 1613028589.1037943
train: epoch 41, iter 3400, loss: 2.685225, top_1: 0.573750, top_k: 0.807656, samples/s: 842.337 1613028619.495438
train: epoch 41, iter 3500, loss: 2.746415, top_1: 0.575273, top_k: 0.802266, samples/s: 844.029 1613028649.8260763
train: epoch 41, iter 3600, loss: 2.728750, top_1: 0.576172, top_k: 0.801289, samples/s: 846.116 1613028680.0820417
train: epoch 41, iter 3700, loss: 2.681769, top_1: 0.571719, top_k: 0.800273, samples/s: 841.660 1613028710.4980564
train: epoch 41, iter 3800, loss: 2.876691, top_1: 0.576133, top_k: 0.797695, samples/s: 849.430 1613028740.6359785
train: epoch 41, iter 3900, loss: 2.825205, top_1: 0.575781, top_k: 0.798906, samples/s: 841.623 1613028771.0533326
train: epoch 41, iter 4000, loss: 2.590409, top_1: 0.574609, top_k: 0.797148, samples/s: 845.156 1613028801.343681
train: epoch 41, iter 4100, loss: 2.867996, top_1: 0.574609, top_k: 0.801641, samples/s: 842.562 1613028831.727106
train: epoch 41, iter 4200, loss: 2.606537, top_1: 0.579766, top_k: 0.802109, samples/s: 849.366 1613028861.8672483
train: epoch 41, iter 4300, loss: 2.863793, top_1: 0.572617, top_k: 0.797422, samples/s: 841.376 1613028892.2936256
train: epoch 41, iter 4400, loss: 2.806437, top_1: 0.577266, top_k: 0.802305, samples/s: 847.017 1613028922.5173194
train: epoch 41, iter 4500, loss: 2.730170, top_1: 0.573281, top_k: 0.802500, samples/s: 843.221 1613028952.8770695
train: epoch 41, iter 4600, loss: 2.611097, top_1: 0.579180, top_k: 0.800469, samples/s: 843.123 1613028983.240377
train: epoch 41, iter 4700, loss: 2.853343, top_1: 0.574766, top_k: 0.800469, samples/s: 843.185 1613029013.6015012
train: epoch 41, iter 4800, loss: 2.666520, top_1: 0.575547, top_k: 0.800937, samples/s: 844.775 1613029043.905402
train: epoch 41, iter 4900, loss: 2.935194, top_1: 0.579961, top_k: 0.804141, samples/s: 848.227 1613029074.0861042
train: epoch 41, iter 5000, loss: 2.633831, top_1: 0.575117, top_k: 0.799258, samples/s: 840.831 1613029104.532069
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_41.
validation: epoch 41, iter 195, top_1: 0.621635, top_k: 0.850881, samples/s: 2431.509 1613029125.965413
train: epoch 42, iter 100, loss: 2.847206, top_1: 0.587812, top_k: 0.806055, samples/s: 868.762 1613029176.2896497
train: epoch 42, iter 200, loss: 2.857830, top_1: 0.584922, top_k: 0.806211, samples/s: 866.330 1613029205.8396237
train: epoch 42, iter 300, loss: 2.578196, top_1: 0.586211, top_k: 0.808516, samples/s: 848.038 1613029236.026911
train: epoch 42, iter 400, loss: 2.702822, top_1: 0.583203, top_k: 0.804258, samples/s: 842.691 1613029266.4057739
train: epoch 42, iter 500, loss: 2.789192, top_1: 0.584688, top_k: 0.803672, samples/s: 841.938 1613029296.8117335
train: epoch 42, iter 600, loss: 2.625955, top_1: 0.582852, top_k: 0.803320, samples/s: 843.238 1613029327.1709185
train: epoch 42, iter 700, loss: 2.709748, top_1: 0.588516, top_k: 0.811914, samples/s: 846.678 1613029357.406769
train: epoch 42, iter 800, loss: 2.664686, top_1: 0.583086, top_k: 0.804297, samples/s: 839.163 1613029387.91342
train: epoch 42, iter 900, loss: 2.665666, top_1: 0.578906, top_k: 0.802383, samples/s: 843.770 1613029418.2534492
train: epoch 42, iter 1000, loss: 2.514788, top_1: 0.576953, top_k: 0.801602, samples/s: 845.074 1613029448.5465803
train: epoch 42, iter 1100, loss: 2.907936, top_1: 0.578086, top_k: 0.802383, samples/s: 841.137 1613029478.9815857
train: epoch 42, iter 1200, loss: 2.628865, top_1: 0.581914, top_k: 0.805312, samples/s: 844.630 1613029509.2907
train: epoch 42, iter 1300, loss: 2.879075, top_1: 0.576484, top_k: 0.800039, samples/s: 841.827 1613029539.7008557
train: epoch 42, iter 1400, loss: 2.731651, top_1: 0.577695, top_k: 0.804258, samples/s: 844.649 1613029570.0092912
train: epoch 42, iter 1500, loss: 2.747718, top_1: 0.579102, top_k: 0.800781, samples/s: 841.581 1613029600.4281185
train: epoch 42, iter 1600, loss: 2.642703, top_1: 0.577969, top_k: 0.805977, samples/s: 845.018 1613029630.723389
train: epoch 42, iter 1700, loss: 2.844025, top_1: 0.585703, top_k: 0.811602, samples/s: 844.240 1613029661.0465126
train: epoch 42, iter 1800, loss: 2.856569, top_1: 0.576992, top_k: 0.803164, samples/s: 842.777 1613029691.4223585
train: epoch 42, iter 1900, loss: 2.806036, top_1: 0.585703, top_k: 0.806289, samples/s: 844.390 1613029721.7399712
train: epoch 42, iter 2000, loss: 2.952873, top_1: 0.583203, top_k: 0.806328, samples/s: 840.398 1613029752.2017062
train: epoch 42, iter 2100, loss: 2.688910, top_1: 0.578438, top_k: 0.805742, samples/s: 844.691 1613029782.5087078
train: epoch 42, iter 2200, loss: 2.770824, top_1: 0.577500, top_k: 0.802188, samples/s: 842.280 1613029812.9023342
train: epoch 42, iter 2300, loss: 2.792354, top_1: 0.580625, top_k: 0.804922, samples/s: 842.827 1613029843.276349
train: epoch 42, iter 2400, loss: 2.886848, top_1: 0.577422, top_k: 0.805117, samples/s: 843.754 1613029873.6169808
train: epoch 42, iter 2500, loss: 2.799538, top_1: 0.579883, top_k: 0.804766, samples/s: 842.065 1613029904.0184436
train: epoch 42, iter 2600, loss: 2.527986, top_1: 0.580508, top_k: 0.804023, samples/s: 844.882 1613029934.318487
train: epoch 42, iter 2700, loss: 2.841026, top_1: 0.579297, top_k: 0.802734, samples/s: 843.085 1613029964.6831172
train: epoch 42, iter 2800, loss: 2.713687, top_1: 0.579414, top_k: 0.804688, samples/s: 842.384 1613029995.073096
train: epoch 42, iter 2900, loss: 2.578959, top_1: 0.579766, top_k: 0.807344, samples/s: 845.004 1613030025.3687584
train: epoch 42, iter 3000, loss: 2.677536, top_1: 0.578242, top_k: 0.801602, samples/s: 840.593 1613030055.8235273
train: epoch 42, iter 3100, loss: 2.728312, top_1: 0.579922, top_k: 0.803125, samples/s: 845.023 1613030086.118549
train: epoch 42, iter 3200, loss: 2.830462, top_1: 0.583359, top_k: 0.807305, samples/s: 840.234 1613030116.586283
train: epoch 42, iter 3300, loss: 2.754421, top_1: 0.580156, top_k: 0.801484, samples/s: 844.782 1613030146.889903
train: epoch 42, iter 3400, loss: 2.636833, top_1: 0.581055, top_k: 0.802969, samples/s: 841.280 1613030177.3197482
train: epoch 42, iter 3500, loss: 2.877153, top_1: 0.580742, top_k: 0.801953, samples/s: 846.351 1613030207.567154
train: epoch 42, iter 3600, loss: 2.707583, top_1: 0.572578, top_k: 0.800430, samples/s: 842.820 1613030237.9414039
train: epoch 42, iter 3700, loss: 2.653658, top_1: 0.571914, top_k: 0.799883, samples/s: 845.168 1613030268.2312224
train: epoch 42, iter 3800, loss: 2.551867, top_1: 0.578359, top_k: 0.805547, samples/s: 843.647 1613030298.575683
train: epoch 42, iter 3900, loss: 2.752527, top_1: 0.579570, top_k: 0.803672, samples/s: 845.100 1613030328.8678944
train: epoch 42, iter 4000, loss: 2.940162, top_1: 0.578633, top_k: 0.799297, samples/s: 844.503 1613030359.1815622
train: epoch 42, iter 4100, loss: 2.649183, top_1: 0.575000, top_k: 0.802227, samples/s: 842.538 1613030389.5660248
train: epoch 42, iter 4200, loss: 2.658699, top_1: 0.578516, top_k: 0.804883, samples/s: 845.320 1613030419.8504376
train: epoch 42, iter 4300, loss: 2.673697, top_1: 0.578164, top_k: 0.801719, samples/s: 842.161 1613030450.2484162
train: epoch 42, iter 4400, loss: 2.750432, top_1: 0.578164, top_k: 0.798516, samples/s: 847.352 1613030480.4601002
train: epoch 42, iter 4500, loss: 3.007746, top_1: 0.574102, top_k: 0.801758, samples/s: 842.308 1613030510.8527987
train: epoch 42, iter 4600, loss: 2.819355, top_1: 0.572930, top_k: 0.798711, samples/s: 844.521 1613030541.165827
train: epoch 42, iter 4700, loss: 2.736446, top_1: 0.580937, top_k: 0.806758, samples/s: 844.830 1613030571.4677837
train: epoch 42, iter 4800, loss: 2.709081, top_1: 0.579258, top_k: 0.798789, samples/s: 845.398 1613030601.749358
train: epoch 42, iter 4900, loss: 2.650860, top_1: 0.581953, top_k: 0.803594, samples/s: 840.715 1613030632.1997347
train: epoch 42, iter 5000, loss: 2.789298, top_1: 0.578281, top_k: 0.801055, samples/s: 845.773 1613030662.4678679
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_42.
validation: epoch 42, iter 195, top_1: 0.629467, top_k: 0.853466, samples/s: 2451.681 1613030683.7181408
train: epoch 43, iter 100, loss: 2.831145, top_1: 0.585234, top_k: 0.809297, samples/s: 871.604 1613030733.441475
train: epoch 43, iter 200, loss: 2.684274, top_1: 0.591211, top_k: 0.809180, samples/s: 865.523 1613030763.0189533
train: epoch 43, iter 300, loss: 2.695813, top_1: 0.591641, top_k: 0.811055, samples/s: 844.580 1613030793.329825
train: epoch 43, iter 400, loss: 2.599620, top_1: 0.585703, top_k: 0.805898, samples/s: 844.425 1613030823.6463275
train: epoch 43, iter 500, loss: 2.654733, top_1: 0.582305, top_k: 0.807305, samples/s: 842.220 1613030854.0422485
train: epoch 43, iter 600, loss: 2.847174, top_1: 0.586562, top_k: 0.806797, samples/s: 840.443 1613030884.5023081
train: epoch 43, iter 700, loss: 2.668031, top_1: 0.583945, top_k: 0.807500, samples/s: 845.770 1613030914.7705538
train: epoch 43, iter 800, loss: 2.655007, top_1: 0.584336, top_k: 0.807383, samples/s: 842.683 1613030945.1497095
train: epoch 43, iter 900, loss: 2.618442, top_1: 0.584336, top_k: 0.806445, samples/s: 842.077 1613030975.5508318
train: epoch 43, iter 1000, loss: 2.669570, top_1: 0.584141, top_k: 0.809766, samples/s: 841.120 1613031005.9864395
train: epoch 43, iter 1100, loss: 2.646467, top_1: 0.578164, top_k: 0.802031, samples/s: 842.164 1613031036.3842316
train: epoch 43, iter 1200, loss: 2.745068, top_1: 0.582578, top_k: 0.806719, samples/s: 845.792 1613031066.651761
train: epoch 43, iter 1300, loss: 2.833080, top_1: 0.581484, top_k: 0.803398, samples/s: 842.210 1613031097.0479836
train: epoch 43, iter 1400, loss: 2.570219, top_1: 0.579453, top_k: 0.805195, samples/s: 846.122 1613031127.3036742
train: epoch 43, iter 1500, loss: 2.736482, top_1: 0.586250, top_k: 0.806953, samples/s: 842.732 1613031157.68111
train: epoch 43, iter 1600, loss: 2.883734, top_1: 0.580898, top_k: 0.803867, samples/s: 844.735 1613031187.986396
train: epoch 43, iter 1700, loss: 2.631631, top_1: 0.583516, top_k: 0.807422, samples/s: 838.640 1613031218.512109
train: epoch 43, iter 1800, loss: 2.815363, top_1: 0.578398, top_k: 0.803711, samples/s: 845.782 1613031248.7798533
train: epoch 43, iter 1900, loss: 2.708736, top_1: 0.582500, top_k: 0.805898, samples/s: 840.259 1613031279.2467344
train: epoch 43, iter 2000, loss: 2.832018, top_1: 0.583438, top_k: 0.805586, samples/s: 843.753 1613031309.5873883
train: epoch 43, iter 2100, loss: 2.774764, top_1: 0.578516, top_k: 0.802930, samples/s: 842.734 1613031339.9646606
train: epoch 43, iter 2200, loss: 2.622318, top_1: 0.580586, top_k: 0.807148, samples/s: 846.300 1613031370.214009
train: epoch 43, iter 2300, loss: 2.703231, top_1: 0.581562, top_k: 0.805039, samples/s: 844.220 1613031400.5377455
train: epoch 43, iter 2400, loss: 2.710281, top_1: 0.579297, top_k: 0.801055, samples/s: 841.727 1613031430.951514
train: epoch 43, iter 2500, loss: 2.691488, top_1: 0.579414, top_k: 0.804883, samples/s: 843.091 1613031461.3159547
train: epoch 43, iter 2600, loss: 2.854873, top_1: 0.582500, top_k: 0.805898, samples/s: 845.787 1613031491.5836356
train: epoch 43, iter 2700, loss: 2.857434, top_1: 0.577383, top_k: 0.801602, samples/s: 845.287 1613031521.8692017
train: epoch 43, iter 2800, loss: 2.669045, top_1: 0.585000, top_k: 0.807070, samples/s: 840.715 1613031552.319389
train: epoch 43, iter 2900, loss: 2.581012, top_1: 0.581992, top_k: 0.801328, samples/s: 844.921 1613031582.618182
train: epoch 43, iter 3000, loss: 2.856207, top_1: 0.579102, top_k: 0.803438, samples/s: 844.818 1613031612.920523
train: epoch 43, iter 3100, loss: 2.613262, top_1: 0.576406, top_k: 0.801562, samples/s: 840.976 1613031643.3613164
train: epoch 43, iter 3200, loss: 2.693888, top_1: 0.578945, top_k: 0.799531, samples/s: 847.737 1613031673.559407
train: epoch 43, iter 3300, loss: 2.826644, top_1: 0.580313, top_k: 0.802070, samples/s: 842.950 1613031703.9289489
train: epoch 43, iter 3400, loss: 2.764307, top_1: 0.584883, top_k: 0.804609, samples/s: 847.251 1613031734.1442852
train: epoch 43, iter 3500, loss: 2.872604, top_1: 0.577148, top_k: 0.799844, samples/s: 843.332 1613031764.5000658
train: epoch 43, iter 3600, loss: 2.669530, top_1: 0.576719, top_k: 0.801055, samples/s: 845.158 1613031794.7901773
train: epoch 43, iter 3700, loss: 2.609614, top_1: 0.579805, top_k: 0.799648, samples/s: 840.812 1613031825.2369735
train: epoch 43, iter 3800, loss: 2.708632, top_1: 0.579102, top_k: 0.803555, samples/s: 848.227 1613031855.4176288
train: epoch 43, iter 3900, loss: 2.760674, top_1: 0.578086, top_k: 0.806133, samples/s: 844.135 1613031885.7445855
train: epoch 43, iter 4000, loss: 2.791673, top_1: 0.574336, top_k: 0.798594, samples/s: 844.379 1613031916.0626736
train: epoch 43, iter 4100, loss: 2.677032, top_1: 0.579883, top_k: 0.804688, samples/s: 838.974 1613031946.5760548
train: epoch 43, iter 4200, loss: 2.911761, top_1: 0.580000, top_k: 0.804102, samples/s: 847.832 1613031976.7708092
train: epoch 43, iter 4300, loss: 2.884273, top_1: 0.574531, top_k: 0.800898, samples/s: 842.492 1613032007.156836
train: epoch 43, iter 4400, loss: 2.836346, top_1: 0.581836, top_k: 0.806992, samples/s: 843.291 1613032037.5140312
train: epoch 43, iter 4500, loss: 2.769002, top_1: 0.576445, top_k: 0.800195, samples/s: 844.669 1613032067.8217456
train: epoch 43, iter 4600, loss: 2.758213, top_1: 0.581914, top_k: 0.804141, samples/s: 844.811 1613032098.124436
train: epoch 43, iter 4700, loss: 2.802252, top_1: 0.577187, top_k: 0.799258, samples/s: 843.042 1613032128.4906113
train: epoch 43, iter 4800, loss: 2.798091, top_1: 0.581836, top_k: 0.801445, samples/s: 844.798 1613032158.7938173
train: epoch 43, iter 4900, loss: 2.854034, top_1: 0.576523, top_k: 0.801367, samples/s: 841.569 1613032189.213175
train: epoch 43, iter 5000, loss: 2.654028, top_1: 0.577344, top_k: 0.799258, samples/s: 845.414 1613032219.494143
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_43.
validation: epoch 43, iter 195, top_1: 0.631791, top_k: 0.854848, samples/s: 2432.531 1613032240.858468
train: epoch 44, iter 100, loss: 2.882426, top_1: 0.587930, top_k: 0.805820, samples/s: 868.572 1613032290.953555
train: epoch 44, iter 200, loss: 2.622156, top_1: 0.589492, top_k: 0.808672, samples/s: 867.107 1613032320.4769864
train: epoch 44, iter 300, loss: 2.475950, top_1: 0.588867, top_k: 0.810742, samples/s: 847.251 1613032350.6923897
train: epoch 44, iter 400, loss: 2.707306, top_1: 0.588906, top_k: 0.809414, samples/s: 842.180 1613032381.0897737
train: epoch 44, iter 500, loss: 2.666732, top_1: 0.584922, top_k: 0.808477, samples/s: 844.328 1613032411.4096508
train: epoch 44, iter 600, loss: 2.875213, top_1: 0.587109, top_k: 0.806602, samples/s: 841.466 1613032441.832754
train: epoch 44, iter 700, loss: 2.753070, top_1: 0.587187, top_k: 0.810312, samples/s: 843.132 1613032472.1958144
train: epoch 44, iter 800, loss: 2.889016, top_1: 0.586328, top_k: 0.809219, samples/s: 842.232 1613032502.5911741
train: epoch 44, iter 900, loss: 2.671008, top_1: 0.592812, top_k: 0.819531, samples/s: 842.938 1613032532.961091
train: epoch 44, iter 1000, loss: 2.478449, top_1: 0.581953, top_k: 0.801289, samples/s: 842.605 1613032563.3431268
train: epoch 44, iter 1100, loss: 2.617991, top_1: 0.587305, top_k: 0.808477, samples/s: 841.256 1613032593.7738535
train: epoch 44, iter 1200, loss: 2.510602, top_1: 0.579453, top_k: 0.806406, samples/s: 843.135 1613032624.1366298
train: epoch 44, iter 1300, loss: 2.814178, top_1: 0.589531, top_k: 0.809961, samples/s: 841.567 1613032654.556206
train: epoch 44, iter 1400, loss: 2.753321, top_1: 0.583945, top_k: 0.806719, samples/s: 842.787 1613032684.9315965
train: epoch 44, iter 1500, loss: 2.544188, top_1: 0.586211, top_k: 0.810312, samples/s: 845.378 1613032715.21383
train: epoch 44, iter 1600, loss: 2.626393, top_1: 0.588281, top_k: 0.812617, samples/s: 841.892 1613032745.6215966
train: epoch 44, iter 1700, loss: 2.606434, top_1: 0.585938, top_k: 0.807734, samples/s: 841.816 1613032776.0319483
train: epoch 44, iter 1800, loss: 2.698268, top_1: 0.581680, top_k: 0.805586, samples/s: 841.454 1613032806.4554958
train: epoch 44, iter 1900, loss: 2.851277, top_1: 0.576992, top_k: 0.800547, samples/s: 845.515 1613032836.7330685
train: epoch 44, iter 2000, loss: 2.705810, top_1: 0.581289, top_k: 0.807461, samples/s: 840.801 1613032867.1801567
train: epoch 44, iter 2100, loss: 2.580665, top_1: 0.579805, top_k: 0.805000, samples/s: 844.392 1613032897.4978056
train: epoch 44, iter 2200, loss: 2.598718, top_1: 0.581445, top_k: 0.802461, samples/s: 844.557 1613032927.8095713
train: epoch 44, iter 2300, loss: 2.859121, top_1: 0.581367, top_k: 0.803672, samples/s: 841.548 1613032958.2297037
train: epoch 44, iter 2400, loss: 2.869271, top_1: 0.582305, top_k: 0.805508, samples/s: 841.044 1613032988.6680658
train: epoch 44, iter 2500, loss: 2.823450, top_1: 0.578828, top_k: 0.805937, samples/s: 845.143 1613033018.958779
train: epoch 44, iter 2600, loss: 2.836860, top_1: 0.583164, top_k: 0.805820, samples/s: 838.746 1613033049.480446
train: epoch 44, iter 2700, loss: 2.614452, top_1: 0.586055, top_k: 0.806680, samples/s: 843.959 1613033079.813657
train: epoch 44, iter 2800, loss: 2.712721, top_1: 0.585234, top_k: 0.810234, samples/s: 847.403 1613033110.023653
train: epoch 44, iter 2900, loss: 2.751604, top_1: 0.579258, top_k: 0.804688, samples/s: 841.781 1613033140.4353201
train: epoch 44, iter 3000, loss: 2.805164, top_1: 0.583398, top_k: 0.806133, samples/s: 840.999 1613033170.8753567
train: epoch 44, iter 3100, loss: 2.867309, top_1: 0.576094, top_k: 0.803516, samples/s: 847.681 1613033201.0754673
train: epoch 44, iter 3200, loss: 2.760011, top_1: 0.580078, top_k: 0.806992, samples/s: 838.504 1613033231.60598
train: epoch 44, iter 3300, loss: 2.710076, top_1: 0.586875, top_k: 0.804922, samples/s: 843.997 1613033261.937769
train: epoch 44, iter 3400, loss: 2.933965, top_1: 0.582148, top_k: 0.801562, samples/s: 843.306 1613033292.2945943
train: epoch 44, iter 3500, loss: 2.703595, top_1: 0.582656, top_k: 0.806172, samples/s: 841.478 1613033322.717147
train: epoch 44, iter 3600, loss: 2.650904, top_1: 0.583477, top_k: 0.802578, samples/s: 843.137 1613033353.079925
train: epoch 44, iter 3700, loss: 2.423284, top_1: 0.577617, top_k: 0.798594, samples/s: 844.007 1613033383.4114637
train: epoch 44, iter 3800, loss: 2.855953, top_1: 0.581055, top_k: 0.801875, samples/s: 841.487 1613033413.8337822
train: epoch 44, iter 3900, loss: 2.721510, top_1: 0.581992, top_k: 0.802773, samples/s: 845.715 1613033444.1040277
train: epoch 44, iter 4000, loss: 2.770416, top_1: 0.584063, top_k: 0.808320, samples/s: 844.203 1613033474.4285493
train: epoch 44, iter 4100, loss: 2.644450, top_1: 0.582812, top_k: 0.807344, samples/s: 843.186 1613033504.7896092
train: epoch 44, iter 4200, loss: 2.611014, top_1: 0.581055, top_k: 0.804102, samples/s: 840.662 1613033535.2416792
train: epoch 44, iter 4300, loss: 2.855116, top_1: 0.575898, top_k: 0.800781, samples/s: 843.170 1613033565.6033835
train: epoch 44, iter 4400, loss: 2.723662, top_1: 0.580117, top_k: 0.802930, samples/s: 837.607 1613033596.1666183
train: epoch 44, iter 4500, loss: 2.796383, top_1: 0.585313, top_k: 0.807813, samples/s: 846.902 1613033626.3943627
train: epoch 44, iter 4600, loss: 2.712167, top_1: 0.575313, top_k: 0.799336, samples/s: 845.129 1613033656.685586
train: epoch 44, iter 4700, loss: 2.760242, top_1: 0.581953, top_k: 0.804219, samples/s: 843.605 1613033687.0316572
train: epoch 44, iter 4800, loss: 2.798594, top_1: 0.587031, top_k: 0.803555, samples/s: 841.314 1613033717.4601886
train: epoch 44, iter 4900, loss: 2.638837, top_1: 0.588086, top_k: 0.807070, samples/s: 840.584 1613033747.915178
train: epoch 44, iter 5000, loss: 2.603275, top_1: 0.580117, top_k: 0.802734, samples/s: 844.117 1613033778.2427127
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_44.
validation: epoch 44, iter 195, top_1: 0.630970, top_k: 0.857652, samples/s: 2482.107 1613033799.2645051
train: epoch 45, iter 100, loss: 2.618206, top_1: 0.588516, top_k: 0.812109, samples/s: 871.657 1613033849.1425574
train: epoch 45, iter 200, loss: 2.645427, top_1: 0.593984, top_k: 0.815352, samples/s: 865.079 1613033878.735229
train: epoch 45, iter 300, loss: 2.650210, top_1: 0.595898, top_k: 0.812656, samples/s: 846.337 1613033908.9832597
train: epoch 45, iter 400, loss: 2.567044, top_1: 0.585078, top_k: 0.807852, samples/s: 841.864 1613033939.3918846
train: epoch 45, iter 500, loss: 2.799087, top_1: 0.588711, top_k: 0.813750, samples/s: 840.324 1613033969.8563805
train: epoch 45, iter 600, loss: 2.647399, top_1: 0.591211, top_k: 0.811562, samples/s: 845.215 1613034000.1445682
train: epoch 45, iter 700, loss: 2.707809, top_1: 0.589688, top_k: 0.810664, samples/s: 842.361 1613034030.5353558
train: epoch 45, iter 800, loss: 2.694871, top_1: 0.591523, top_k: 0.812656, samples/s: 837.856 1613034061.0894032
train: epoch 45, iter 900, loss: 2.740227, top_1: 0.587031, top_k: 0.811211, samples/s: 843.117 1613034091.452917
train: epoch 45, iter 1000, loss: 2.831637, top_1: 0.583047, top_k: 0.809180, samples/s: 842.152 1613034121.8512633
train: epoch 45, iter 1100, loss: 2.681957, top_1: 0.586016, top_k: 0.808750, samples/s: 844.834 1613034152.1530607
train: epoch 45, iter 1200, loss: 2.736066, top_1: 0.580898, top_k: 0.807070, samples/s: 843.783 1613034182.4926426
train: epoch 45, iter 1300, loss: 2.569473, top_1: 0.578125, top_k: 0.800625, samples/s: 844.292 1613034212.8138404
train: epoch 45, iter 1400, loss: 2.638115, top_1: 0.587734, top_k: 0.807031, samples/s: 840.897 1613034243.2575352
train: epoch 45, iter 1500, loss: 2.879456, top_1: 0.587109, top_k: 0.812578, samples/s: 844.342 1613034273.576973
train: epoch 45, iter 1600, loss: 2.671271, top_1: 0.581680, top_k: 0.804922, samples/s: 843.408 1613034303.930034
train: epoch 45, iter 1700, loss: 2.849855, top_1: 0.585742, top_k: 0.809219, samples/s: 841.918 1613034334.3368578
train: epoch 45, iter 1800, loss: 2.794852, top_1: 0.582344, top_k: 0.805977, samples/s: 841.973 1613034364.741625
train: epoch 45, iter 1900, loss: 2.398777, top_1: 0.586289, top_k: 0.806562, samples/s: 844.486 1613034395.0558753
train: epoch 45, iter 2000, loss: 2.606020, top_1: 0.584336, top_k: 0.806055, samples/s: 844.912 1613034425.3548768
train: epoch 45, iter 2100, loss: 2.851544, top_1: 0.577227, top_k: 0.802188, samples/s: 840.742 1613034455.8042476
train: epoch 45, iter 2200, loss: 2.795369, top_1: 0.576406, top_k: 0.800625, samples/s: 843.690 1613034486.1472225
train: epoch 45, iter 2300, loss: 2.692241, top_1: 0.583555, top_k: 0.808125, samples/s: 843.808 1613034516.4858527
train: epoch 45, iter 2400, loss: 2.622886, top_1: 0.583945, top_k: 0.810586, samples/s: 842.951 1613034546.855242
train: epoch 45, iter 2500, loss: 2.790389, top_1: 0.581523, top_k: 0.802344, samples/s: 843.304 1613034577.2120361
train: epoch 45, iter 2600, loss: 2.897268, top_1: 0.580508, top_k: 0.802617, samples/s: 843.009 1613034607.579441
train: epoch 45, iter 2700, loss: 2.801475, top_1: 0.582852, top_k: 0.803281, samples/s: 844.650 1613034637.887958
train: epoch 45, iter 2800, loss: 2.700971, top_1: 0.591016, top_k: 0.806328, samples/s: 842.605 1613034668.2698197
train: epoch 45, iter 2900, loss: 2.722455, top_1: 0.587305, top_k: 0.808008, samples/s: 845.718 1613034698.540016
train: epoch 45, iter 3000, loss: 2.774791, top_1: 0.585703, top_k: 0.803945, samples/s: 842.073 1613034728.9410863
train: epoch 45, iter 3100, loss: 2.543495, top_1: 0.585195, top_k: 0.807266, samples/s: 843.456 1613034759.2924128
train: epoch 45, iter 3200, loss: 2.815016, top_1: 0.587031, top_k: 0.804531, samples/s: 840.683 1613034789.7439423
train: epoch 45, iter 3300, loss: 2.652294, top_1: 0.581328, top_k: 0.802969, samples/s: 845.567 1613034820.0194683
train: epoch 45, iter 3400, loss: 2.872216, top_1: 0.583789, top_k: 0.803281, samples/s: 844.455 1613034850.3347716
train: epoch 45, iter 3500, loss: 2.702277, top_1: 0.581836, top_k: 0.805430, samples/s: 843.154 1613034880.6970534
train: epoch 45, iter 3600, loss: 2.858594, top_1: 0.582734, top_k: 0.804453, samples/s: 844.153 1613034911.0233476
train: epoch 45, iter 3700, loss: 2.819474, top_1: 0.582773, top_k: 0.804648, samples/s: 842.553 1613034941.4071102
train: epoch 45, iter 3800, loss: 2.669421, top_1: 0.582031, top_k: 0.805937, samples/s: 843.755 1613034971.7477102
train: epoch 45, iter 3900, loss: 2.793416, top_1: 0.583906, top_k: 0.804492, samples/s: 845.257 1613035002.0343614
train: epoch 45, iter 4000, loss: 2.781582, top_1: 0.587070, top_k: 0.805859, samples/s: 843.446 1613035032.3859046
train: epoch 45, iter 4100, loss: 2.587076, top_1: 0.580547, top_k: 0.804180, samples/s: 842.302 1613035062.7788086
train: epoch 45, iter 4200, loss: 2.632439, top_1: 0.575469, top_k: 0.799609, samples/s: 842.930 1613035093.149181
train: epoch 45, iter 4300, loss: 2.671160, top_1: 0.579805, top_k: 0.803906, samples/s: 843.389 1613035123.502874
train: epoch 45, iter 4400, loss: 2.826992, top_1: 0.579922, top_k: 0.804375, samples/s: 842.974 1613035153.8714507
train: epoch 45, iter 4500, loss: 2.722588, top_1: 0.587891, top_k: 0.809141, samples/s: 846.639 1613035184.1086936
train: epoch 45, iter 4600, loss: 2.650479, top_1: 0.577539, top_k: 0.803555, samples/s: 839.510 1613035214.6026363
train: epoch 45, iter 4700, loss: 2.750194, top_1: 0.582187, top_k: 0.802227, samples/s: 846.910 1613035244.8303156
train: epoch 45, iter 4800, loss: 2.618674, top_1: 0.586289, top_k: 0.807148, samples/s: 844.966 1613035275.127258
train: epoch 45, iter 4900, loss: 2.767982, top_1: 0.581328, top_k: 0.802695, samples/s: 839.854 1613035305.6087544
train: epoch 45, iter 5000, loss: 2.646420, top_1: 0.589922, top_k: 0.809883, samples/s: 844.580 1613035335.9196875
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_45.
validation: epoch 45, iter 195, top_1: 0.631831, top_k: 0.855369, samples/s: 2431.211 1613035357.3564367
train: epoch 46, iter 100, loss: 2.827607, top_1: 0.599688, top_k: 0.817891, samples/s: 866.065 1613035408.0316002
train: epoch 46, iter 200, loss: 2.737476, top_1: 0.590117, top_k: 0.813125, samples/s: 865.441 1613035437.6117492
train: epoch 46, iter 300, loss: 2.751084, top_1: 0.595508, top_k: 0.816016, samples/s: 847.883 1613035467.804703
train: epoch 46, iter 400, loss: 2.873362, top_1: 0.597266, top_k: 0.815859, samples/s: 840.190 1613035498.273967
train: epoch 46, iter 500, loss: 2.507778, top_1: 0.596641, top_k: 0.812187, samples/s: 846.991 1613035528.498549
train: epoch 46, iter 600, loss: 2.706421, top_1: 0.589922, top_k: 0.810547, samples/s: 841.949 1613035558.904281
train: epoch 46, iter 700, loss: 2.763066, top_1: 0.595313, top_k: 0.812305, samples/s: 841.134 1613035589.3393936
train: epoch 46, iter 800, loss: 2.783414, top_1: 0.587969, top_k: 0.809805, samples/s: 844.203 1613035619.6638203
train: epoch 46, iter 900, loss: 2.744522, top_1: 0.593750, top_k: 0.814258, samples/s: 839.030 1613035650.1752553
train: epoch 46, iter 1000, loss: 2.722791, top_1: 0.590313, top_k: 0.810586, samples/s: 844.870 1613035680.4756706
train: epoch 46, iter 1100, loss: 2.532566, top_1: 0.585273, top_k: 0.807305, samples/s: 841.675 1613035710.891195
train: epoch 46, iter 1200, loss: 2.663321, top_1: 0.585547, top_k: 0.808086, samples/s: 844.776 1613035741.19512
train: epoch 46, iter 1300, loss: 2.852348, top_1: 0.588477, top_k: 0.811914, samples/s: 845.971 1613035771.4561863
train: epoch 46, iter 1400, loss: 2.604220, top_1: 0.594297, top_k: 0.811445, samples/s: 838.178 1613035801.9986289
train: epoch 46, iter 1500, loss: 2.762619, top_1: 0.580977, top_k: 0.804961, samples/s: 845.440 1613035832.2786992
train: epoch 46, iter 1600, loss: 2.570648, top_1: 0.595313, top_k: 0.810469, samples/s: 843.965 1613035862.6117663
train: epoch 46, iter 1700, loss: 2.629107, top_1: 0.583594, top_k: 0.809336, samples/s: 843.459 1613035892.9629004
train: epoch 46, iter 1800, loss: 2.746861, top_1: 0.589102, top_k: 0.809766, samples/s: 844.060 1613035923.292611
train: epoch 46, iter 1900, loss: 2.674550, top_1: 0.593828, top_k: 0.812031, samples/s: 844.067 1613035953.621921
train: epoch 46, iter 2000, loss: 2.784313, top_1: 0.586758, top_k: 0.808672, samples/s: 844.122 1613035983.9493287
train: epoch 46, iter 2100, loss: 2.748678, top_1: 0.580039, top_k: 0.804805, samples/s: 843.724 1613036014.2909887
train: epoch 46, iter 2200, loss: 2.914795, top_1: 0.581211, top_k: 0.808203, samples/s: 843.777 1613036044.630813
train: epoch 46, iter 2300, loss: 2.578480, top_1: 0.577734, top_k: 0.804414, samples/s: 846.158 1613036074.8850987
train: epoch 46, iter 2400, loss: 2.679902, top_1: 0.587734, top_k: 0.808555, samples/s: 841.472 1613036105.3080988
train: epoch 46, iter 2500, loss: 2.769963, top_1: 0.590117, top_k: 0.812617, samples/s: 848.012 1613036135.4963622
train: epoch 46, iter 2600, loss: 2.744571, top_1: 0.582969, top_k: 0.803164, samples/s: 842.507 1613036165.881768
train: epoch 46, iter 2700, loss: 2.785866, top_1: 0.581992, top_k: 0.807969, samples/s: 844.674 1613036196.1893942
train: epoch 46, iter 2800, loss: 2.643575, top_1: 0.579688, top_k: 0.805664, samples/s: 843.329 1613036226.5452194
train: epoch 46, iter 2900, loss: 2.765036, top_1: 0.580703, top_k: 0.801406, samples/s: 846.148 1613036256.799963
train: epoch 46, iter 3000, loss: 2.582072, top_1: 0.584727, top_k: 0.807852, samples/s: 844.173 1613036287.1254952
train: epoch 46, iter 3100, loss: 2.803165, top_1: 0.581719, top_k: 0.803281, samples/s: 843.500 1613036317.4752467
train: epoch 46, iter 3200, loss: 2.574445, top_1: 0.584180, top_k: 0.804648, samples/s: 847.942 1613036347.6660006
train: epoch 46, iter 3300, loss: 2.811419, top_1: 0.581914, top_k: 0.806172, samples/s: 842.232 1613036378.0614088
train: epoch 46, iter 3400, loss: 2.769267, top_1: 0.582969, top_k: 0.804414, samples/s: 845.306 1613036408.3463671
train: epoch 46, iter 3500, loss: 2.799489, top_1: 0.580859, top_k: 0.806484, samples/s: 842.420 1613036438.7349343
train: epoch 46, iter 3600, loss: 2.767912, top_1: 0.584453, top_k: 0.809258, samples/s: 847.310 1613036468.948215
train: epoch 46, iter 3700, loss: 2.818913, top_1: 0.581367, top_k: 0.804453, samples/s: 843.330 1613036499.3039792
train: epoch 46, iter 3800, loss: 2.802719, top_1: 0.582617, top_k: 0.805820, samples/s: 844.064 1613036529.633514
train: epoch 46, iter 3900, loss: 2.662519, top_1: 0.581562, top_k: 0.805664, samples/s: 842.510 1613036560.018921
train: epoch 46, iter 4000, loss: 2.787565, top_1: 0.577266, top_k: 0.803555, samples/s: 842.522 1613036590.4038997
train: epoch 46, iter 4100, loss: 2.983172, top_1: 0.577344, top_k: 0.802930, samples/s: 847.318 1613036620.6168244
train: epoch 46, iter 4200, loss: 2.743082, top_1: 0.580937, top_k: 0.799844, samples/s: 840.875 1613036651.061389
train: epoch 46, iter 4300, loss: 2.757400, top_1: 0.587969, top_k: 0.807578, samples/s: 844.763 1613036681.3656402
train: epoch 46, iter 4400, loss: 2.815578, top_1: 0.582969, top_k: 0.802070, samples/s: 843.685 1613036711.7087262
train: epoch 46, iter 4500, loss: 2.781668, top_1: 0.579141, top_k: 0.803008, samples/s: 842.672 1613036742.0883124
train: epoch 46, iter 4600, loss: 2.630070, top_1: 0.582812, top_k: 0.802891, samples/s: 842.626 1613036772.469544
train: epoch 46, iter 4700, loss: 2.681563, top_1: 0.579141, top_k: 0.801758, samples/s: 843.642 1613036802.8140938
train: epoch 46, iter 4800, loss: 2.702645, top_1: 0.586406, top_k: 0.808633, samples/s: 842.363 1613036833.2048445
train: epoch 46, iter 4900, loss: 2.643247, top_1: 0.579922, top_k: 0.805352, samples/s: 846.644 1613036863.4418786
train: epoch 46, iter 5000, loss: 2.920278, top_1: 0.584922, top_k: 0.804844, samples/s: 839.442 1613036893.9383807
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_46.
validation: epoch 46, iter 195, top_1: 0.630389, top_k: 0.858934, samples/s: 2447.347 1613036915.2394989
train: epoch 47, iter 100, loss: 2.697705, top_1: 0.600508, top_k: 0.818672, samples/s: 871.839 1613036971.1517637
train: epoch 47, iter 200, loss: 2.768028, top_1: 0.597031, top_k: 0.820352, samples/s: 869.284 1613037000.6012228
train: epoch 47, iter 300, loss: 2.698635, top_1: 0.593672, top_k: 0.815039, samples/s: 848.561 1613037030.7699745
train: epoch 47, iter 400, loss: 2.587173, top_1: 0.593086, top_k: 0.810703, samples/s: 845.415 1613037061.050979
train: epoch 47, iter 500, loss: 2.612042, top_1: 0.593125, top_k: 0.813555, samples/s: 843.286 1613037091.4083562
train: epoch 47, iter 600, loss: 2.590410, top_1: 0.590820, top_k: 0.807148, samples/s: 845.091 1613037121.7009006
train: epoch 47, iter 700, loss: 2.865170, top_1: 0.591055, top_k: 0.810312, samples/s: 842.749 1613037152.0777228
train: epoch 47, iter 800, loss: 2.740586, top_1: 0.588008, top_k: 0.811406, samples/s: 844.085 1613037182.4064732
train: epoch 47, iter 900, loss: 2.666593, top_1: 0.587070, top_k: 0.812031, samples/s: 843.511 1613037212.7557986
train: epoch 47, iter 1000, loss: 2.615951, top_1: 0.587227, top_k: 0.810625, samples/s: 841.334 1613037243.183678
train: epoch 47, iter 1100, loss: 2.538600, top_1: 0.593906, top_k: 0.812148, samples/s: 841.856 1613037273.5926518
train: epoch 47, iter 1200, loss: 2.626209, top_1: 0.586406, top_k: 0.806680, samples/s: 845.870 1613037303.8573942
train: epoch 47, iter 1300, loss: 2.817914, top_1: 0.591992, top_k: 0.811406, samples/s: 843.081 1613037334.2221115
train: epoch 47, iter 1400, loss: 2.702894, top_1: 0.587656, top_k: 0.811289, samples/s: 844.409 1613037364.5392356
train: epoch 47, iter 1500, loss: 2.728053, top_1: 0.592070, top_k: 0.812305, samples/s: 841.583 1613037394.9580622
train: epoch 47, iter 1600, loss: 2.687755, top_1: 0.586133, top_k: 0.808359, samples/s: 844.603 1613037425.2681646
train: epoch 47, iter 1700, loss: 2.692220, top_1: 0.585898, top_k: 0.808164, samples/s: 842.805 1613037455.6429589
train: epoch 47, iter 1800, loss: 2.643743, top_1: 0.586172, top_k: 0.808164, samples/s: 845.191 1613037485.931962
train: epoch 47, iter 1900, loss: 2.907870, top_1: 0.582617, top_k: 0.811211, samples/s: 844.686 1613037516.2390962
train: epoch 47, iter 2000, loss: 2.490871, top_1: 0.584570, top_k: 0.805820, samples/s: 842.529 1613037546.623797
train: epoch 47, iter 2100, loss: 2.705885, top_1: 0.583555, top_k: 0.807539, samples/s: 844.649 1613037576.932177
train: epoch 47, iter 2200, loss: 2.698401, top_1: 0.586172, top_k: 0.803672, samples/s: 841.738 1613037607.3454096
train: epoch 47, iter 2300, loss: 2.756127, top_1: 0.584648, top_k: 0.810508, samples/s: 845.700 1613037637.616304
train: epoch 47, iter 2400, loss: 2.729194, top_1: 0.592109, top_k: 0.808594, samples/s: 843.070 1613037667.9815154
train: epoch 47, iter 2500, loss: 2.750211, top_1: 0.578477, top_k: 0.801484, samples/s: 843.016 1613037698.34858
train: epoch 47, iter 2600, loss: 2.674303, top_1: 0.587422, top_k: 0.810937, samples/s: 843.356 1613037728.703512
train: epoch 47, iter 2700, loss: 2.738991, top_1: 0.580195, top_k: 0.808867, samples/s: 842.393 1613037759.0932107
train: epoch 47, iter 2800, loss: 2.763111, top_1: 0.586797, top_k: 0.804531, samples/s: 845.975 1613037789.3543017
train: epoch 47, iter 2900, loss: 2.790987, top_1: 0.587422, top_k: 0.812109, samples/s: 841.781 1613037819.7657816
train: epoch 47, iter 3000, loss: 2.801824, top_1: 0.584336, top_k: 0.804961, samples/s: 843.347 1613037850.1210072
train: epoch 47, iter 3100, loss: 2.711471, top_1: 0.583906, top_k: 0.807813, samples/s: 847.538 1613037880.326258
train: epoch 47, iter 3200, loss: 2.658020, top_1: 0.582305, top_k: 0.806758, samples/s: 842.917 1613037910.6968563
train: epoch 47, iter 3300, loss: 2.714611, top_1: 0.585508, top_k: 0.806289, samples/s: 841.279 1613037941.1267076
train: epoch 47, iter 3400, loss: 2.716818, top_1: 0.586445, top_k: 0.805273, samples/s: 842.882 1613037971.498737
train: epoch 47, iter 3500, loss: 2.725681, top_1: 0.578008, top_k: 0.804961, samples/s: 845.683 1613038001.770188
train: epoch 47, iter 3600, loss: 2.655193, top_1: 0.582148, top_k: 0.806133, samples/s: 844.352 1613038032.089288
train: epoch 47, iter 3700, loss: 2.651568, top_1: 0.582578, top_k: 0.805781, samples/s: 841.937 1613038062.495332
train: epoch 47, iter 3800, loss: 2.711193, top_1: 0.580469, top_k: 0.808672, samples/s: 842.830 1613038092.869148
train: epoch 47, iter 3900, loss: 2.817218, top_1: 0.586211, top_k: 0.808047, samples/s: 842.861 1613038123.2418547
train: epoch 47, iter 4000, loss: 2.737356, top_1: 0.584219, top_k: 0.805937, samples/s: 844.676 1613038153.5493255
train: epoch 47, iter 4100, loss: 2.638924, top_1: 0.587812, top_k: 0.805117, samples/s: 846.156 1613038183.8038306
train: epoch 47, iter 4200, loss: 2.752107, top_1: 0.584844, top_k: 0.803828, samples/s: 842.261 1613038214.198154
train: epoch 47, iter 4300, loss: 2.607840, top_1: 0.583281, top_k: 0.807109, samples/s: 843.008 1613038244.5656471
train: epoch 47, iter 4400, loss: 2.669082, top_1: 0.586367, top_k: 0.806406, samples/s: 843.032 1613038274.932174
train: epoch 47, iter 4500, loss: 2.826528, top_1: 0.587227, top_k: 0.805078, samples/s: 847.265 1613038305.1471326
train: epoch 47, iter 4600, loss: 2.742720, top_1: 0.586680, top_k: 0.806289, samples/s: 842.200 1613038335.5436232
train: epoch 47, iter 4700, loss: 2.541065, top_1: 0.584063, top_k: 0.807187, samples/s: 846.778 1613038365.7759385
train: epoch 47, iter 4800, loss: 2.689663, top_1: 0.576406, top_k: 0.802266, samples/s: 842.293 1613038396.1692584
train: epoch 47, iter 4900, loss: 2.741161, top_1: 0.581445, top_k: 0.807773, samples/s: 842.098 1613038426.5694191
train: epoch 47, iter 5000, loss: 2.660799, top_1: 0.579805, top_k: 0.805039, samples/s: 846.069 1613038456.8269534
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_47.
validation: epoch 47, iter 195, top_1: 0.630469, top_k: 0.857091, samples/s: 2465.459 1613038477.9732518
train: epoch 48, iter 100, loss: 2.637375, top_1: 0.594922, top_k: 0.816250, samples/s: 867.820 1613038527.917523
train: epoch 48, iter 200, loss: 2.702564, top_1: 0.594805, top_k: 0.815273, samples/s: 865.161 1613038557.507408
train: epoch 48, iter 300, loss: 2.826700, top_1: 0.591172, top_k: 0.812969, samples/s: 846.678 1613038587.7431917
train: epoch 48, iter 400, loss: 2.782499, top_1: 0.600273, top_k: 0.816523, samples/s: 842.408 1613038618.1322322
train: epoch 48, iter 500, loss: 2.635736, top_1: 0.592891, top_k: 0.811992, samples/s: 844.066 1613038648.4616272
train: epoch 48, iter 600, loss: 2.692242, top_1: 0.590078, top_k: 0.811992, samples/s: 843.247 1613038678.8204744
train: epoch 48, iter 700, loss: 2.740519, top_1: 0.592578, top_k: 0.812578, samples/s: 843.774 1613038709.1603367
train: epoch 48, iter 800, loss: 2.764463, top_1: 0.590430, top_k: 0.812187, samples/s: 843.466 1613038739.5113938
train: epoch 48, iter 900, loss: 2.655077, top_1: 0.593203, top_k: 0.815391, samples/s: 837.665 1613038770.0727046
train: epoch 48, iter 1000, loss: 2.685236, top_1: 0.590664, top_k: 0.806719, samples/s: 846.327 1613038800.3208148
train: epoch 48, iter 1100, loss: 2.647655, top_1: 0.587773, top_k: 0.805469, samples/s: 842.907 1613038830.6918786
train: epoch 48, iter 1200, loss: 2.832780, top_1: 0.591016, top_k: 0.814258, samples/s: 841.990 1613038861.0961149
train: epoch 48, iter 1300, loss: 2.768104, top_1: 0.585859, top_k: 0.809648, samples/s: 844.819 1613038891.3984337
train: epoch 48, iter 1400, loss: 2.695948, top_1: 0.593594, top_k: 0.810352, samples/s: 840.114 1613038921.8704784
train: epoch 48, iter 1500, loss: 2.636481, top_1: 0.590508, top_k: 0.812969, samples/s: 846.850 1613038952.1001387
train: epoch 48, iter 1600, loss: 2.588600, top_1: 0.590469, top_k: 0.809688, samples/s: 841.540 1613038982.5206482
train: epoch 48, iter 1700, loss: 2.771125, top_1: 0.585859, top_k: 0.809805, samples/s: 843.314 1613039012.877012
train: epoch 48, iter 1800, loss: 2.747707, top_1: 0.590625, top_k: 0.810820, samples/s: 843.959 1613039043.210311
train: epoch 48, iter 1900, loss: 2.649344, top_1: 0.583164, top_k: 0.804844, samples/s: 842.561 1613039073.5937636
train: epoch 48, iter 2000, loss: 2.629523, top_1: 0.591914, top_k: 0.813633, samples/s: 843.462 1613039103.944947
train: epoch 48, iter 2100, loss: 2.883761, top_1: 0.587617, top_k: 0.808203, samples/s: 842.616 1613039134.3264194
train: epoch 48, iter 2200, loss: 2.693553, top_1: 0.585625, top_k: 0.810312, samples/s: 844.761 1613039164.6309357
train: epoch 48, iter 2300, loss: 2.742212, top_1: 0.591680, top_k: 0.812695, samples/s: 846.174 1613039194.88471
train: epoch 48, iter 2400, loss: 2.791071, top_1: 0.586445, top_k: 0.808398, samples/s: 839.118 1613039225.3929267
train: epoch 48, iter 2500, loss: 2.694454, top_1: 0.582148, top_k: 0.806641, samples/s: 847.142 1613039255.6122496
train: epoch 48, iter 2600, loss: 2.749803, top_1: 0.581992, top_k: 0.806406, samples/s: 840.635 1613039286.0654085
train: epoch 48, iter 2700, loss: 2.530336, top_1: 0.589883, top_k: 0.812734, samples/s: 845.422 1613039316.346048
train: epoch 48, iter 2800, loss: 2.811065, top_1: 0.582695, top_k: 0.808906, samples/s: 842.687 1613039346.7251287
train: epoch 48, iter 2900, loss: 2.481633, top_1: 0.587031, top_k: 0.810391, samples/s: 844.131 1613039377.0521212
train: epoch 48, iter 3000, loss: 2.651323, top_1: 0.584531, top_k: 0.808906, samples/s: 846.326 1613039407.3005965
train: epoch 48, iter 3100, loss: 2.624143, top_1: 0.585430, top_k: 0.805195, samples/s: 841.931 1613039437.706804
train: epoch 48, iter 3200, loss: 2.509952, top_1: 0.591758, top_k: 0.810430, samples/s: 845.311 1613039467.9915478
train: epoch 48, iter 3300, loss: 2.761881, top_1: 0.589414, top_k: 0.805508, samples/s: 844.710 1613039498.297785
train: epoch 48, iter 3400, loss: 2.745699, top_1: 0.591797, top_k: 0.808633, samples/s: 847.433 1613039528.5066767
train: epoch 48, iter 3500, loss: 2.754265, top_1: 0.585703, top_k: 0.808477, samples/s: 841.140 1613039558.941519
train: epoch 48, iter 3600, loss: 2.742336, top_1: 0.579570, top_k: 0.806992, samples/s: 845.587 1613039589.216408
train: epoch 48, iter 3700, loss: 2.771562, top_1: 0.591719, top_k: 0.807578, samples/s: 846.110 1613039619.472484
train: epoch 48, iter 3800, loss: 2.748715, top_1: 0.588711, top_k: 0.807305, samples/s: 840.170 1613039649.94257
train: epoch 48, iter 3900, loss: 2.678227, top_1: 0.593125, top_k: 0.810273, samples/s: 845.754 1613039680.2113297
train: epoch 48, iter 4000, loss: 2.796911, top_1: 0.581133, top_k: 0.801758, samples/s: 845.992 1613039710.4717996
train: epoch 48, iter 4100, loss: 2.714362, top_1: 0.583086, top_k: 0.809180, samples/s: 841.270 1613039740.9019504
train: epoch 48, iter 4200, loss: 2.791798, top_1: 0.576719, top_k: 0.800703, samples/s: 845.731 1613039771.171637
train: epoch 48, iter 4300, loss: 2.737174, top_1: 0.587656, top_k: 0.807930, samples/s: 844.195 1613039801.4963098
train: epoch 48, iter 4400, loss: 2.786764, top_1: 0.587031, top_k: 0.808828, samples/s: 843.994 1613039831.8283885
train: epoch 48, iter 4500, loss: 2.640247, top_1: 0.585508, top_k: 0.807031, samples/s: 843.239 1613039862.1875157
train: epoch 48, iter 4600, loss: 2.587650, top_1: 0.582969, top_k: 0.806875, samples/s: 842.241 1613039892.5825639
train: epoch 48, iter 4700, loss: 2.707411, top_1: 0.586680, top_k: 0.809805, samples/s: 846.662 1613039922.8189394
train: epoch 48, iter 4800, loss: 2.831924, top_1: 0.585625, top_k: 0.807617, samples/s: 843.540 1613039953.16718
train: epoch 48, iter 4900, loss: 2.665157, top_1: 0.583281, top_k: 0.806445, samples/s: 845.182 1613039983.4565609
train: epoch 48, iter 5000, loss: 2.661692, top_1: 0.589102, top_k: 0.808594, samples/s: 844.592 1613040013.767011
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_48.
validation: epoch 48, iter 195, top_1: 0.642929, top_k: 0.862280, samples/s: 2516.417 1613040034.5612164
train: epoch 49, iter 100, loss: 2.794646, top_1: 0.602266, top_k: 0.819922, samples/s: 868.408 1613040084.7782369
train: epoch 49, iter 200, loss: 2.655479, top_1: 0.595898, top_k: 0.814727, samples/s: 865.291 1613040114.36349
train: epoch 49, iter 300, loss: 2.718400, top_1: 0.594883, top_k: 0.816328, samples/s: 845.822 1613040144.6299787
train: epoch 49, iter 400, loss: 2.496192, top_1: 0.601367, top_k: 0.820078, samples/s: 845.374 1613040174.9124002
train: epoch 49, iter 500, loss: 2.553414, top_1: 0.599570, top_k: 0.819336, samples/s: 841.881 1613040205.3205185
train: epoch 49, iter 600, loss: 2.663530, top_1: 0.600195, top_k: 0.814609, samples/s: 842.040 1613040235.7229571
train: epoch 49, iter 700, loss: 2.849287, top_1: 0.590977, top_k: 0.809102, samples/s: 841.293 1613040266.1523347
train: epoch 49, iter 800, loss: 2.608057, top_1: 0.596367, top_k: 0.815820, samples/s: 845.648 1613040296.4248672
train: epoch 49, iter 900, loss: 2.882916, top_1: 0.589961, top_k: 0.814609, samples/s: 842.713 1613040326.802947
train: epoch 49, iter 1000, loss: 2.658167, top_1: 0.597500, top_k: 0.816445, samples/s: 840.482 1613040357.2617497
train: epoch 49, iter 1100, loss: 2.822028, top_1: 0.592656, top_k: 0.812109, samples/s: 843.707 1613040387.6040554
train: epoch 49, iter 1200, loss: 2.657524, top_1: 0.597109, top_k: 0.812500, samples/s: 842.799 1613040417.9789248
train: epoch 49, iter 1300, loss: 2.676186, top_1: 0.597617, top_k: 0.816016, samples/s: 843.350 1613040448.334045
train: epoch 49, iter 1400, loss: 2.791426, top_1: 0.587891, top_k: 0.815273, samples/s: 844.542 1613040478.6464403
train: epoch 49, iter 1500, loss: 2.551152, top_1: 0.585508, top_k: 0.810312, samples/s: 842.694 1613040509.0251157
train: epoch 49, iter 1600, loss: 2.699533, top_1: 0.594531, top_k: 0.815000, samples/s: 845.148 1613040539.3156981
train: epoch 49, iter 1700, loss: 2.783256, top_1: 0.587891, top_k: 0.808516, samples/s: 843.629 1613040569.660807
train: epoch 49, iter 1800, loss: 2.724395, top_1: 0.587344, top_k: 0.813594, samples/s: 847.854 1613040599.8547065
train: epoch 49, iter 1900, loss: 2.921311, top_1: 0.585898, top_k: 0.806250, samples/s: 842.906 1613040630.2257643
train: epoch 49, iter 2000, loss: 2.703614, top_1: 0.589141, top_k: 0.810937, samples/s: 847.653 1613040660.4267743
train: epoch 49, iter 2100, loss: 2.554791, top_1: 0.590234, top_k: 0.812734, samples/s: 842.204 1613040690.8231988
train: epoch 49, iter 2200, loss: 2.670952, top_1: 0.586250, top_k: 0.809609, samples/s: 845.658 1613040721.095586
train: epoch 49, iter 2300, loss: 2.623312, top_1: 0.588320, top_k: 0.811562, samples/s: 842.550 1613040751.4795084
train: epoch 49, iter 2400, loss: 2.813975, top_1: 0.590000, top_k: 0.811055, samples/s: 845.716 1613040781.7496498
train: epoch 49, iter 2500, loss: 2.744074, top_1: 0.585938, top_k: 0.808984, samples/s: 842.914 1613040812.1205137
train: epoch 49, iter 2600, loss: 2.923363, top_1: 0.584805, top_k: 0.806680, samples/s: 843.955 1613040842.4539337
train: epoch 49, iter 2700, loss: 2.782940, top_1: 0.586484, top_k: 0.808711, samples/s: 844.338 1613040872.7734873
train: epoch 49, iter 2800, loss: 2.791986, top_1: 0.586992, top_k: 0.811094, samples/s: 845.686 1613040903.0447924
train: epoch 49, iter 2900, loss: 2.800057, top_1: 0.587812, top_k: 0.809219, samples/s: 841.865 1613040933.4534538
train: epoch 49, iter 3000, loss: 2.843630, top_1: 0.580547, top_k: 0.805664, samples/s: 845.360 1613040963.7363315
train: epoch 49, iter 3100, loss: 2.622158, top_1: 0.590859, top_k: 0.814375, samples/s: 844.873 1613040994.0367455
train: epoch 49, iter 3200, loss: 2.582826, top_1: 0.585430, top_k: 0.807656, samples/s: 844.674 1613041024.3443651
train: epoch 49, iter 3300, loss: 2.742548, top_1: 0.588398, top_k: 0.811523, samples/s: 840.920 1613041054.7871718
train: epoch 49, iter 3400, loss: 2.610132, top_1: 0.586875, top_k: 0.809453, samples/s: 845.708 1613041085.0576565
train: epoch 49, iter 3500, loss: 2.763910, top_1: 0.582227, top_k: 0.805078, samples/s: 846.547 1613041115.2982001
train: epoch 49, iter 3600, loss: 2.624233, top_1: 0.587148, top_k: 0.807578, samples/s: 841.569 1613041145.71753
train: epoch 49, iter 3700, loss: 2.888843, top_1: 0.586719, top_k: 0.807422, samples/s: 844.524 1613041176.030558
train: epoch 49, iter 3800, loss: 2.729453, top_1: 0.588242, top_k: 0.811953, samples/s: 846.955 1613041206.2563894
train: epoch 49, iter 3900, loss: 2.773295, top_1: 0.590820, top_k: 0.807734, samples/s: 841.048 1613041236.694652
train: epoch 49, iter 4000, loss: 2.560702, top_1: 0.589688, top_k: 0.807969, samples/s: 843.600 1613041267.0408604
train: epoch 49, iter 4100, loss: 2.683366, top_1: 0.585352, top_k: 0.808867, samples/s: 842.899 1613041297.4122477
train: epoch 49, iter 4200, loss: 2.709918, top_1: 0.585430, top_k: 0.805703, samples/s: 845.429 1613041327.6926062
train: epoch 49, iter 4300, loss: 2.596596, top_1: 0.589805, top_k: 0.806719, samples/s: 843.041 1613041358.0588446
train: epoch 49, iter 4400, loss: 2.904295, top_1: 0.587578, top_k: 0.812422, samples/s: 846.839 1613041388.288961
train: epoch 49, iter 4500, loss: 2.792858, top_1: 0.590117, top_k: 0.811211, samples/s: 845.469 1613041418.5679948
train: epoch 49, iter 4600, loss: 2.692329, top_1: 0.590117, top_k: 0.810508, samples/s: 842.293 1613041448.9612978
train: epoch 49, iter 4700, loss: 2.503890, top_1: 0.588203, top_k: 0.807266, samples/s: 842.549 1613041479.3452642
train: epoch 49, iter 4800, loss: 2.593940, top_1: 0.585273, top_k: 0.806055, samples/s: 846.140 1613041509.60023
train: epoch 49, iter 4900, loss: 2.812782, top_1: 0.581836, top_k: 0.806758, samples/s: 844.441 1613041539.9161625
train: epoch 49, iter 5000, loss: 2.614170, top_1: 0.596641, top_k: 0.810469, samples/s: 844.672 1613041570.223835
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_49.
validation: epoch 49, iter 195, top_1: 0.634776, top_k: 0.858433, samples/s: 2478.750 1613041591.2696843
train: epoch 50, iter 100, loss: 2.720357, top_1: 0.604922, top_k: 0.821211, samples/s: 870.239 1613041642.5499053
train: epoch 50, iter 200, loss: 2.674906, top_1: 0.607187, top_k: 0.818164, samples/s: 865.798 1613041672.11811
train: epoch 50, iter 300, loss: 2.613019, top_1: 0.605469, top_k: 0.820898, samples/s: 846.680 1613041702.3537574
train: epoch 50, iter 400, loss: 2.607474, top_1: 0.600938, top_k: 0.818984, samples/s: 843.659 1613041732.6976483
train: epoch 50, iter 500, loss: 2.554054, top_1: 0.596484, top_k: 0.814023, samples/s: 842.569 1613041763.0810122
train: epoch 50, iter 600, loss: 2.484988, top_1: 0.595742, top_k: 0.814063, samples/s: 844.737 1613041793.3863163
train: epoch 50, iter 700, loss: 2.798903, top_1: 0.590977, top_k: 0.815273, samples/s: 844.485 1613041823.7006357
train: epoch 50, iter 800, loss: 2.531277, top_1: 0.591055, top_k: 0.810195, samples/s: 841.154 1613041854.134958
train: epoch 50, iter 900, loss: 2.569852, top_1: 0.590273, top_k: 0.811250, samples/s: 842.687 1613041884.513948
train: epoch 50, iter 1000, loss: 2.697739, top_1: 0.592070, top_k: 0.813477, samples/s: 842.920 1613041914.8846545
train: epoch 50, iter 1100, loss: 2.591698, top_1: 0.587734, top_k: 0.812734, samples/s: 843.632 1613041945.2295415
train: epoch 50, iter 1200, loss: 2.482019, top_1: 0.596406, top_k: 0.813867, samples/s: 842.171 1613041975.62725
train: epoch 50, iter 1300, loss: 2.701303, top_1: 0.591289, top_k: 0.812070, samples/s: 844.870 1613042005.9278078
train: epoch 50, iter 1400, loss: 2.791230, top_1: 0.593359, top_k: 0.810000, samples/s: 843.418 1613042036.2804043
train: epoch 50, iter 1500, loss: 2.646462, top_1: 0.590898, top_k: 0.813906, samples/s: 844.341 1613042066.5999792
train: epoch 50, iter 1600, loss: 2.768526, top_1: 0.590469, top_k: 0.810625, samples/s: 845.883 1613042096.8640943
train: epoch 50, iter 1700, loss: 2.670420, top_1: 0.593516, top_k: 0.814023, samples/s: 840.034 1613042127.339158
train: epoch 50, iter 1800, loss: 2.635355, top_1: 0.595156, top_k: 0.812187, samples/s: 846.865 1613042157.5682173
train: epoch 50, iter 1900, loss: 2.573375, top_1: 0.589883, top_k: 0.812461, samples/s: 839.116 1613042188.0766826
train: epoch 50, iter 2000, loss: 2.732569, top_1: 0.580625, top_k: 0.806953, samples/s: 848.417 1613042218.2503643
train: epoch 50, iter 2100, loss: 2.886989, top_1: 0.586758, top_k: 0.809688, samples/s: 845.061 1613042248.5440412
train: epoch 50, iter 2200, loss: 2.618517, top_1: 0.588945, top_k: 0.807891, samples/s: 842.357 1613042278.9349432
train: epoch 50, iter 2300, loss: 2.494200, top_1: 0.590234, top_k: 0.807266, samples/s: 842.766 1613042309.3111346
train: epoch 50, iter 2400, loss: 2.960280, top_1: 0.591758, top_k: 0.810781, samples/s: 845.672 1613042339.5829344
train: epoch 50, iter 2500, loss: 2.665937, top_1: 0.589336, top_k: 0.809414, samples/s: 843.625 1613042369.9281976
train: epoch 50, iter 2600, loss: 2.722666, top_1: 0.597266, top_k: 0.815859, samples/s: 843.107 1613042400.2919972
train: epoch 50, iter 2700, loss: 2.706466, top_1: 0.581758, top_k: 0.807305, samples/s: 845.199 1613042430.5806887
train: epoch 50, iter 2800, loss: 2.528718, top_1: 0.585664, top_k: 0.813828, samples/s: 840.802 1613042461.0278406
train: epoch 50, iter 2900, loss: 2.682710, top_1: 0.591562, top_k: 0.811172, samples/s: 842.912 1613042491.398778
train: epoch 50, iter 3000, loss: 2.809108, top_1: 0.585195, top_k: 0.812266, samples/s: 845.367 1613042521.6815102
train: epoch 50, iter 3100, loss: 2.560959, top_1: 0.594141, top_k: 0.811445, samples/s: 845.353 1613042551.964663
train: epoch 50, iter 3200, loss: 2.642825, top_1: 0.595117, top_k: 0.809141, samples/s: 843.599 1613042582.310787
train: epoch 50, iter 3300, loss: 2.595055, top_1: 0.592578, top_k: 0.812305, samples/s: 844.560 1613042612.6225245
train: epoch 50, iter 3400, loss: 2.585585, top_1: 0.588672, top_k: 0.808125, samples/s: 846.565 1613042642.8622794
train: epoch 50, iter 3500, loss: 2.896866, top_1: 0.590781, top_k: 0.811797, samples/s: 845.606 1613042673.136453
train: epoch 50, iter 3600, loss: 2.717544, top_1: 0.584727, top_k: 0.809219, samples/s: 844.807 1613042703.4392352
train: epoch 50, iter 3700, loss: 2.572547, top_1: 0.590664, top_k: 0.811094, samples/s: 844.931 1613042733.7375152
train: epoch 50, iter 3800, loss: 2.783268, top_1: 0.584219, top_k: 0.809805, samples/s: 844.274 1613042764.0594182
train: epoch 50, iter 3900, loss: 2.718958, top_1: 0.590625, top_k: 0.810469, samples/s: 845.179 1613042794.3488767
train: epoch 50, iter 4000, loss: 2.807079, top_1: 0.590586, top_k: 0.808594, samples/s: 841.915 1613042824.7557132
train: epoch 50, iter 4100, loss: 2.561422, top_1: 0.582773, top_k: 0.805234, samples/s: 846.635 1613042854.993154
train: epoch 50, iter 4200, loss: 2.734421, top_1: 0.589258, top_k: 0.808867, samples/s: 847.162 1613042885.2116597
train: epoch 50, iter 4300, loss: 2.848145, top_1: 0.588398, top_k: 0.808438, samples/s: 846.124 1613042915.46732
train: epoch 50, iter 4400, loss: 2.860887, top_1: 0.589023, top_k: 0.809570, samples/s: 842.528 1613042945.8520324
train: epoch 50, iter 4500, loss: 2.723084, top_1: 0.585781, top_k: 0.810039, samples/s: 844.438 1613042976.1680894
train: epoch 50, iter 4600, loss: 2.894791, top_1: 0.583438, top_k: 0.804688, samples/s: 843.405 1613043006.5212395
train: epoch 50, iter 4700, loss: 2.773444, top_1: 0.587500, top_k: 0.806758, samples/s: 846.551 1613043036.761579
train: epoch 50, iter 4800, loss: 2.769757, top_1: 0.586445, top_k: 0.808594, samples/s: 846.729 1613043066.9956048
train: epoch 50, iter 4900, loss: 2.767277, top_1: 0.586055, top_k: 0.809766, samples/s: 845.092 1613043097.288062
train: epoch 50, iter 5000, loss: 2.800672, top_1: 0.591094, top_k: 0.808945, samples/s: 842.357 1613043127.6789937
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_50.
validation: epoch 50, iter 195, top_1: 0.628125, top_k: 0.854527, samples/s: 2457.591 1613043148.8697662
train: epoch 51, iter 100, loss: 2.888126, top_1: 0.598945, top_k: 0.816406, samples/s: 873.537 1613043199.7904732
train: epoch 51, iter 200, loss: 2.768435, top_1: 0.598750, top_k: 0.818945, samples/s: 867.197 1613043229.310611
train: epoch 51, iter 300, loss: 2.659267, top_1: 0.589609, top_k: 0.805742, samples/s: 848.713 1613043259.4739594
train: epoch 51, iter 400, loss: 2.670222, top_1: 0.600273, top_k: 0.817031, samples/s: 844.004 1613043289.8055186
train: epoch 51, iter 500, loss: 2.698044, top_1: 0.604844, top_k: 0.820352, samples/s: 843.397 1613043320.159156
train: epoch 51, iter 600, loss: 2.766639, top_1: 0.596016, top_k: 0.818906, samples/s: 841.807 1613043350.5696995
train: epoch 51, iter 700, loss: 2.869645, top_1: 0.593477, top_k: 0.815000, samples/s: 845.331 1613043380.8537881
train: epoch 51, iter 800, loss: 2.887611, top_1: 0.598516, top_k: 0.817070, samples/s: 845.000 1613043411.1495724
train: epoch 51, iter 900, loss: 2.503880, top_1: 0.591562, top_k: 0.816680, samples/s: 844.498 1613043441.4634273
train: epoch 51, iter 1000, loss: 2.455008, top_1: 0.600352, top_k: 0.818438, samples/s: 846.143 1613043471.718373
train: epoch 51, iter 1100, loss: 2.439590, top_1: 0.593359, top_k: 0.813672, samples/s: 842.156 1613043502.1166096
train: epoch 51, iter 1200, loss: 2.704051, top_1: 0.601016, top_k: 0.814688, samples/s: 844.078 1613043532.4455707
train: epoch 51, iter 1300, loss: 2.548719, top_1: 0.597070, top_k: 0.813906, samples/s: 845.202 1613043562.7341812
train: epoch 51, iter 1400, loss: 2.579142, top_1: 0.594492, top_k: 0.815508, samples/s: 841.024 1613043593.1731355
train: epoch 51, iter 1500, loss: 2.578622, top_1: 0.594766, top_k: 0.817852, samples/s: 845.531 1613043623.450063
train: epoch 51, iter 1600, loss: 2.735121, top_1: 0.588984, top_k: 0.810586, samples/s: 844.975 1613043653.7467566
train: epoch 51, iter 1700, loss: 2.860512, top_1: 0.595273, top_k: 0.811250, samples/s: 845.385 1613043684.0288494
train: epoch 51, iter 1800, loss: 2.568801, top_1: 0.587773, top_k: 0.812617, samples/s: 846.885 1613043714.2572172
train: epoch 51, iter 1900, loss: 2.701437, top_1: 0.592383, top_k: 0.814141, samples/s: 843.938 1613043744.591294
train: epoch 51, iter 2000, loss: 2.639663, top_1: 0.592109, top_k: 0.813594, samples/s: 847.024 1613043774.814676
train: epoch 51, iter 2100, loss: 2.596889, top_1: 0.594961, top_k: 0.816367, samples/s: 844.980 1613043805.1114008
train: epoch 51, iter 2200, loss: 2.635709, top_1: 0.595742, top_k: 0.812891, samples/s: 843.966 1613043835.4442492
train: epoch 51, iter 2300, loss: 2.671213, top_1: 0.596992, top_k: 0.816797, samples/s: 844.388 1613043865.7620687
train: epoch 51, iter 2400, loss: 2.644493, top_1: 0.594336, top_k: 0.814297, samples/s: 845.025 1613043896.0570939
train: epoch 51, iter 2500, loss: 2.813218, top_1: 0.590547, top_k: 0.812500, samples/s: 846.177 1613043926.3108141
train: epoch 51, iter 2600, loss: 2.830740, top_1: 0.592773, top_k: 0.811484, samples/s: 845.320 1613043956.595151
train: epoch 51, iter 2700, loss: 2.845383, top_1: 0.591836, top_k: 0.806445, samples/s: 841.458 1613043987.0186002
train: epoch 51, iter 2800, loss: 2.676150, top_1: 0.581016, top_k: 0.808672, samples/s: 847.070 1613044017.2403634
train: epoch 51, iter 2900, loss: 2.475917, top_1: 0.589023, top_k: 0.810039, samples/s: 850.460 1613044047.3416817
train: epoch 51, iter 3000, loss: 2.640622, top_1: 0.591016, top_k: 0.812148, samples/s: 842.866 1613044077.7143269
train: epoch 51, iter 3100, loss: 2.798267, top_1: 0.586328, top_k: 0.809570, samples/s: 845.356 1613044107.9974306
train: epoch 51, iter 3200, loss: 2.753415, top_1: 0.591445, top_k: 0.811953, samples/s: 844.828 1613044138.299468
train: epoch 51, iter 3300, loss: 2.601868, top_1: 0.584258, top_k: 0.808555, samples/s: 847.884 1613044168.4922283
train: epoch 51, iter 3400, loss: 2.692648, top_1: 0.594219, top_k: 0.810000, samples/s: 843.423 1613044198.8447664
train: epoch 51, iter 3500, loss: 2.723732, top_1: 0.591055, top_k: 0.810117, samples/s: 847.201 1613044229.0619218
train: epoch 51, iter 3600, loss: 3.034225, top_1: 0.594844, top_k: 0.811406, samples/s: 843.006 1613044259.429431
train: epoch 51, iter 3700, loss: 2.728427, top_1: 0.594375, top_k: 0.810469, samples/s: 845.956 1613044289.690948
train: epoch 51, iter 3800, loss: 2.525503, top_1: 0.588047, top_k: 0.810117, samples/s: 843.751 1613044320.031738
train: epoch 51, iter 3900, loss: 2.681187, top_1: 0.592969, top_k: 0.810781, samples/s: 846.423 1613044350.2766767
train: epoch 51, iter 4000, loss: 2.685497, top_1: 0.593594, top_k: 0.812539, samples/s: 843.619 1613044380.6221037
train: epoch 51, iter 4100, loss: 2.623477, top_1: 0.589297, top_k: 0.812578, samples/s: 846.307 1613044410.8712614
train: epoch 51, iter 4200, loss: 2.700744, top_1: 0.591484, top_k: 0.811055, samples/s: 843.186 1613044441.2322633
train: epoch 51, iter 4300, loss: 2.664912, top_1: 0.587812, top_k: 0.806953, samples/s: 843.932 1613044471.5663524
train: epoch 51, iter 4400, loss: 2.732358, top_1: 0.586289, top_k: 0.807031, samples/s: 845.398 1613044501.847937
train: epoch 51, iter 4500, loss: 2.638917, top_1: 0.589180, top_k: 0.814023, samples/s: 843.607 1613044532.1939275
train: epoch 51, iter 4600, loss: 2.810741, top_1: 0.591836, top_k: 0.811914, samples/s: 846.954 1613044562.419879
train: epoch 51, iter 4700, loss: 2.640822, top_1: 0.590898, top_k: 0.809375, samples/s: 843.015 1613044592.787083
train: epoch 51, iter 4800, loss: 2.733181, top_1: 0.590117, top_k: 0.808438, samples/s: 845.942 1613044623.0492163
train: epoch 51, iter 4900, loss: 2.567919, top_1: 0.585586, top_k: 0.810234, samples/s: 842.895 1613044653.42068
train: epoch 51, iter 5000, loss: 2.989165, top_1: 0.590391, top_k: 0.811133, samples/s: 843.735 1613044683.7620065
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_51.
validation: epoch 51, iter 195, top_1: 0.644611, top_k: 0.866526, samples/s: 2440.475 1613044705.119445
train: epoch 52, iter 100, loss: 2.560445, top_1: 0.598477, top_k: 0.819492, samples/s: 870.036 1613044755.2766852
train: epoch 52, iter 200, loss: 2.741159, top_1: 0.600391, top_k: 0.816836, samples/s: 866.208 1613044784.8307467
train: epoch 52, iter 300, loss: 2.638019, top_1: 0.604570, top_k: 0.822734, samples/s: 844.336 1613044815.1505008
train: epoch 52, iter 400, loss: 2.826756, top_1: 0.604062, top_k: 0.819141, samples/s: 846.648 1613044845.3873599
train: epoch 52, iter 500, loss: 2.613719, top_1: 0.596523, top_k: 0.815586, samples/s: 842.371 1613044875.777735
train: epoch 52, iter 600, loss: 2.648459, top_1: 0.598047, top_k: 0.816406, samples/s: 843.345 1613044906.133038
train: epoch 52, iter 700, loss: 2.658999, top_1: 0.601562, top_k: 0.820430, samples/s: 841.365 1613044936.5598114
train: epoch 52, iter 800, loss: 2.538048, top_1: 0.603828, top_k: 0.818633, samples/s: 845.936 1613044966.8221169
train: epoch 52, iter 900, loss: 2.741112, top_1: 0.594414, top_k: 0.815898, samples/s: 841.228 1613044997.2538128
train: epoch 52, iter 1000, loss: 2.612582, top_1: 0.592227, top_k: 0.811758, samples/s: 844.706 1613045027.5602412
train: epoch 52, iter 1100, loss: 2.580431, top_1: 0.595625, top_k: 0.814063, samples/s: 843.118 1613045057.923814
train: epoch 52, iter 1200, loss: 2.450024, top_1: 0.601758, top_k: 0.816992, samples/s: 844.043 1613045088.2540207
train: epoch 52, iter 1300, loss: 2.632408, top_1: 0.594414, top_k: 0.816602, samples/s: 843.696 1613045118.5966032
train: epoch 52, iter 1400, loss: 2.788555, top_1: 0.594688, top_k: 0.817930, samples/s: 841.777 1613045149.0085845
train: epoch 52, iter 1500, loss: 2.745724, top_1: 0.590195, top_k: 0.810430, samples/s: 842.981 1613045179.376939
train: epoch 52, iter 1600, loss: 2.584974, top_1: 0.594844, top_k: 0.816445, samples/s: 845.313 1613045209.661604
train: epoch 52, iter 1700, loss: 2.693784, top_1: 0.593516, top_k: 0.807852, samples/s: 841.870 1613045240.0700886
train: epoch 52, iter 1800, loss: 2.658583, top_1: 0.593203, top_k: 0.818359, samples/s: 846.072 1613045270.3275123
train: epoch 52, iter 1900, loss: 2.648504, top_1: 0.590625, top_k: 0.812539, samples/s: 844.120 1613045300.6549222
train: epoch 52, iter 2000, loss: 2.846248, top_1: 0.588945, top_k: 0.810859, samples/s: 843.037 1613045331.0213842
train: epoch 52, iter 2100, loss: 2.644686, top_1: 0.590977, top_k: 0.816641, samples/s: 842.479 1613045361.4078784
train: epoch 52, iter 2200, loss: 2.730698, top_1: 0.596328, top_k: 0.814609, samples/s: 847.362 1613045391.6193807
train: epoch 52, iter 2300, loss: 2.812300, top_1: 0.597266, top_k: 0.815703, samples/s: 842.773 1613045421.9953058
train: epoch 52, iter 2400, loss: 2.749392, top_1: 0.588086, top_k: 0.808281, samples/s: 841.942 1613045452.401149
train: epoch 52, iter 2500, loss: 2.630871, top_1: 0.590781, top_k: 0.808828, samples/s: 844.555 1613045482.7130344
train: epoch 52, iter 2600, loss: 2.584140, top_1: 0.600273, top_k: 0.816680, samples/s: 846.434 1613045512.9576
train: epoch 52, iter 2700, loss: 2.729845, top_1: 0.592305, top_k: 0.813633, samples/s: 841.919 1613045543.3643374
train: epoch 52, iter 2800, loss: 2.622849, top_1: 0.587266, top_k: 0.808828, samples/s: 843.196 1613045573.7249627
train: epoch 52, iter 2900, loss: 2.649396, top_1: 0.590781, top_k: 0.807578, samples/s: 846.315 1613045603.9737406
train: epoch 52, iter 3000, loss: 2.533660, top_1: 0.593477, top_k: 0.815273, samples/s: 844.957 1613045634.271111
train: epoch 52, iter 3100, loss: 2.603224, top_1: 0.587266, top_k: 0.811328, samples/s: 843.001 1613045664.6388078
train: epoch 52, iter 3200, loss: 2.759994, top_1: 0.592969, top_k: 0.812148, samples/s: 845.052 1613045694.9328575
train: epoch 52, iter 3300, loss: 2.605141, top_1: 0.593984, top_k: 0.808750, samples/s: 844.480 1613045725.2473297
train: epoch 52, iter 3400, loss: 2.592616, top_1: 0.596133, top_k: 0.813242, samples/s: 842.623 1613045755.628616
train: epoch 52, iter 3500, loss: 2.708095, top_1: 0.595820, top_k: 0.813867, samples/s: 844.665 1613045785.9365308
train: epoch 52, iter 3600, loss: 2.586097, top_1: 0.598359, top_k: 0.819922, samples/s: 843.140 1613045816.2992253
train: epoch 52, iter 3700, loss: 2.583519, top_1: 0.591250, top_k: 0.809961, samples/s: 843.949 1613045846.6327655
train: epoch 52, iter 3800, loss: 2.510426, top_1: 0.592891, top_k: 0.812891, samples/s: 847.067 1613045876.8547723
train: epoch 52, iter 3900, loss: 2.571385, top_1: 0.595508, top_k: 0.815937, samples/s: 841.955 1613045907.2602422
train: epoch 52, iter 4000, loss: 2.676441, top_1: 0.592344, top_k: 0.811133, samples/s: 845.250 1613045937.5470147
train: epoch 52, iter 4100, loss: 2.704058, top_1: 0.587812, top_k: 0.813711, samples/s: 843.566 1613045967.894382
train: epoch 52, iter 4200, loss: 2.881700, top_1: 0.587578, top_k: 0.811875, samples/s: 846.873 1613045998.123251
train: epoch 52, iter 4300, loss: 2.706564, top_1: 0.593516, top_k: 0.806953, samples/s: 841.679 1613046028.5386214
train: epoch 52, iter 4400, loss: 2.592162, top_1: 0.593437, top_k: 0.810000, samples/s: 843.472 1613046058.8894641
train: epoch 52, iter 4500, loss: 2.817095, top_1: 0.587148, top_k: 0.808203, samples/s: 847.128 1613046089.10923
train: epoch 52, iter 4600, loss: 2.882607, top_1: 0.587500, top_k: 0.808359, samples/s: 841.126 1613046119.544514
train: epoch 52, iter 4700, loss: 2.719315, top_1: 0.586602, top_k: 0.810469, samples/s: 843.656 1613046149.8887038
train: epoch 52, iter 4800, loss: 2.645749, top_1: 0.585430, top_k: 0.808672, samples/s: 844.292 1613046180.2100027
train: epoch 52, iter 4900, loss: 3.104519, top_1: 0.585938, top_k: 0.806094, samples/s: 846.374 1613046210.4565887
train: epoch 52, iter 5000, loss: 2.688403, top_1: 0.596797, top_k: 0.814141, samples/s: 843.928 1613046240.79102
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_52.
validation: epoch 52, iter 195, top_1: 0.637961, top_k: 0.858233, samples/s: 2436.507 1613046262.1734107
train: epoch 53, iter 100, loss: 2.755734, top_1: 0.596836, top_k: 0.819531, samples/s: 867.082 1613046312.464319
train: epoch 53, iter 200, loss: 2.604539, top_1: 0.602031, top_k: 0.819336, samples/s: 867.238 1613046341.9832606
train: epoch 53, iter 300, loss: 2.508658, top_1: 0.600664, top_k: 0.822930, samples/s: 848.340 1613046372.1597533
train: epoch 53, iter 400, loss: 2.467808, top_1: 0.601367, top_k: 0.819023, samples/s: 840.683 1613046402.611174
train: epoch 53, iter 500, loss: 2.595831, top_1: 0.599922, top_k: 0.816289, samples/s: 846.354 1613046432.858539
train: epoch 53, iter 600, loss: 2.586780, top_1: 0.597070, top_k: 0.814492, samples/s: 841.531 1613046463.2793674
train: epoch 53, iter 700, loss: 2.519112, top_1: 0.603125, top_k: 0.820508, samples/s: 845.192 1613046493.5683627
train: epoch 53, iter 800, loss: 2.545246, top_1: 0.599063, top_k: 0.817500, samples/s: 843.694 1613046523.9111273
train: epoch 53, iter 900, loss: 2.549375, top_1: 0.602227, top_k: 0.821016, samples/s: 842.897 1613046554.2824576
train: epoch 53, iter 1000, loss: 2.766883, top_1: 0.598867, top_k: 0.817344, samples/s: 845.481 1613046584.5612004
train: epoch 53, iter 1100, loss: 2.790098, top_1: 0.600195, top_k: 0.818711, samples/s: 841.456 1613046614.9845796
train: epoch 53, iter 1200, loss: 2.599794, top_1: 0.598789, top_k: 0.819258, samples/s: 846.092 1613046645.2413979
train: epoch 53, iter 1300, loss: 2.643178, top_1: 0.597617, top_k: 0.815703, samples/s: 843.916 1613046675.5760515
train: epoch 53, iter 1400, loss: 2.742503, top_1: 0.591094, top_k: 0.813867, samples/s: 842.223 1613046705.971835
train: epoch 53, iter 1500, loss: 2.563842, top_1: 0.594414, top_k: 0.815078, samples/s: 844.888 1613046736.2717144
train: epoch 53, iter 1600, loss: 2.852295, top_1: 0.599570, top_k: 0.819297, samples/s: 846.065 1613046766.5294325
train: epoch 53, iter 1700, loss: 2.761461, top_1: 0.599023, top_k: 0.813164, samples/s: 846.229 1613046796.7813025
train: epoch 53, iter 1800, loss: 2.788170, top_1: 0.591602, top_k: 0.812930, samples/s: 842.795 1613046827.1564653
train: epoch 53, iter 1900, loss: 2.844334, top_1: 0.598555, top_k: 0.814727, samples/s: 842.184 1613046857.5536187
train: epoch 53, iter 2000, loss: 2.824249, top_1: 0.593516, top_k: 0.813750, samples/s: 846.954 1613046887.779586
train: epoch 53, iter 2100, loss: 2.901034, top_1: 0.594648, top_k: 0.817461, samples/s: 845.010 1613046918.0750353
train: epoch 53, iter 2200, loss: 2.484582, top_1: 0.596133, top_k: 0.813438, samples/s: 845.136 1613046948.3659766
train: epoch 53, iter 2300, loss: 2.851844, top_1: 0.595938, top_k: 0.812383, samples/s: 845.627 1613046978.6393394
train: epoch 53, iter 2400, loss: 2.774202, top_1: 0.597773, top_k: 0.815391, samples/s: 845.715 1613047008.9096422
train: epoch 53, iter 2500, loss: 2.650867, top_1: 0.600195, top_k: 0.814570, samples/s: 843.479 1613047039.2601347
train: epoch 53, iter 2600, loss: 2.689780, top_1: 0.586641, top_k: 0.808477, samples/s: 843.481 1613047069.61057
train: epoch 53, iter 2700, loss: 2.736833, top_1: 0.589805, top_k: 0.816133, samples/s: 849.371 1613047099.7504754
train: epoch 53, iter 2800, loss: 2.649934, top_1: 0.594023, top_k: 0.810117, samples/s: 845.242 1613047130.0376887
train: epoch 53, iter 2900, loss: 2.574391, top_1: 0.594570, top_k: 0.810742, samples/s: 842.618 1613047160.4192479
train: epoch 53, iter 3000, loss: 2.467587, top_1: 0.590469, top_k: 0.811211, samples/s: 846.638 1613047190.656476
train: epoch 53, iter 3100, loss: 2.575791, top_1: 0.593867, top_k: 0.811680, samples/s: 844.595 1613047220.9667842
train: epoch 53, iter 3200, loss: 2.679320, top_1: 0.595352, top_k: 0.811406, samples/s: 846.475 1613047251.2098098
train: epoch 53, iter 3300, loss: 2.778569, top_1: 0.597578, top_k: 0.812227, samples/s: 845.618 1613047281.4835703
train: epoch 53, iter 3400, loss: 2.737030, top_1: 0.589883, top_k: 0.813516, samples/s: 844.491 1613047311.797704
train: epoch 53, iter 3500, loss: 2.874586, top_1: 0.588633, top_k: 0.808047, samples/s: 842.340 1613047342.1892705
train: epoch 53, iter 3600, loss: 2.804354, top_1: 0.592461, top_k: 0.814180, samples/s: 844.107 1613047372.5171182
train: epoch 53, iter 3700, loss: 2.648509, top_1: 0.587578, top_k: 0.809492, samples/s: 845.123 1613047402.808611
train: epoch 53, iter 3800, loss: 2.814598, top_1: 0.594180, top_k: 0.815430, samples/s: 846.137 1613047433.0637205
train: epoch 53, iter 3900, loss: 2.575674, top_1: 0.593828, top_k: 0.811914, samples/s: 845.227 1613047463.3515081
train: epoch 53, iter 4000, loss: 2.712743, top_1: 0.592070, top_k: 0.811562, samples/s: 847.000 1613047493.5757227
train: epoch 53, iter 4100, loss: 2.772491, top_1: 0.591641, top_k: 0.809688, samples/s: 842.549 1613047523.959706
train: epoch 53, iter 4200, loss: 2.597788, top_1: 0.594180, top_k: 0.812813, samples/s: 845.161 1613047554.2498662
train: epoch 53, iter 4300, loss: 2.706272, top_1: 0.593555, top_k: 0.813359, samples/s: 844.320 1613047584.5701776
train: epoch 53, iter 4400, loss: 2.818604, top_1: 0.592227, top_k: 0.812227, samples/s: 845.383 1613047614.8522992
train: epoch 53, iter 4500, loss: 2.614333, top_1: 0.594648, top_k: 0.812461, samples/s: 844.721 1613047645.1581
train: epoch 53, iter 4600, loss: 2.735254, top_1: 0.590508, top_k: 0.810625, samples/s: 844.177 1613047675.4835079
train: epoch 53, iter 4700, loss: 2.499806, top_1: 0.590156, top_k: 0.809258, samples/s: 841.990 1613047705.8876944
train: epoch 53, iter 4800, loss: 2.586835, top_1: 0.589727, top_k: 0.810898, samples/s: 846.874 1613047736.1164062
train: epoch 53, iter 4900, loss: 2.644613, top_1: 0.592422, top_k: 0.813789, samples/s: 842.074 1613047766.5176184
train: epoch 53, iter 5000, loss: 2.536306, top_1: 0.593711, top_k: 0.813203, samples/s: 845.807 1613047796.7845705
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_53.
validation: epoch 53, iter 195, top_1: 0.639643, top_k: 0.862780, samples/s: 2452.282 1613047818.0577931
train: epoch 54, iter 100, loss: 2.843723, top_1: 0.610234, top_k: 0.823242, samples/s: 865.496 1613047867.9729252
train: epoch 54, iter 200, loss: 2.597923, top_1: 0.606758, top_k: 0.823008, samples/s: 865.547 1613047897.5495749
train: epoch 54, iter 300, loss: 2.720238, top_1: 0.600898, top_k: 0.817109, samples/s: 847.932 1613047927.7405667
train: epoch 54, iter 400, loss: 2.649951, top_1: 0.598437, top_k: 0.816641, samples/s: 842.951 1613047958.1100574
train: epoch 54, iter 500, loss: 2.599320, top_1: 0.597734, top_k: 0.816914, samples/s: 845.766 1613047988.3785841
train: epoch 54, iter 600, loss: 2.638417, top_1: 0.604180, top_k: 0.824180, samples/s: 844.564 1613048018.6899774
train: epoch 54, iter 700, loss: 2.791198, top_1: 0.600391, top_k: 0.813047, samples/s: 842.331 1613048049.0819333
train: epoch 54, iter 800, loss: 2.462660, top_1: 0.595352, top_k: 0.817461, samples/s: 845.474 1613048079.3606963
train: epoch 54, iter 900, loss: 2.719116, top_1: 0.599648, top_k: 0.815977, samples/s: 844.548 1613048109.6728327
train: epoch 54, iter 1000, loss: 2.904113, top_1: 0.597070, top_k: 0.816719, samples/s: 844.256 1613048139.99539
train: epoch 54, iter 1100, loss: 2.610348, top_1: 0.597695, top_k: 0.816484, samples/s: 843.148 1613048170.3578293
train: epoch 54, iter 1200, loss: 2.558763, top_1: 0.598008, top_k: 0.815273, samples/s: 846.681 1613048200.5935276
train: epoch 54, iter 1300, loss: 2.456275, top_1: 0.595469, top_k: 0.815391, samples/s: 842.483 1613048230.9799235
train: epoch 54, iter 1400, loss: 2.525003, top_1: 0.593906, top_k: 0.817500, samples/s: 850.261 1613048261.0883214
train: epoch 54, iter 1500, loss: 2.681257, top_1: 0.596992, top_k: 0.814805, samples/s: 840.518 1613048291.5457275
train: epoch 54, iter 1600, loss: 2.669009, top_1: 0.597148, top_k: 0.814102, samples/s: 843.228 1613048321.9052007
train: epoch 54, iter 1700, loss: 2.635873, top_1: 0.598789, top_k: 0.819766, samples/s: 845.469 1613048352.184294
train: epoch 54, iter 1800, loss: 2.621762, top_1: 0.591641, top_k: 0.812695, samples/s: 846.248 1613048382.4354534
train: epoch 54, iter 1900, loss: 2.815927, top_1: 0.600586, top_k: 0.819766, samples/s: 847.589 1613048412.6388042
train: epoch 54, iter 2000, loss: 2.703439, top_1: 0.598320, top_k: 0.817813, samples/s: 844.081 1613048442.9676301
train: epoch 54, iter 2100, loss: 2.555187, top_1: 0.603203, top_k: 0.818789, samples/s: 843.179 1613048473.3288248
train: epoch 54, iter 2200, loss: 2.683704, top_1: 0.598320, top_k: 0.817187, samples/s: 843.050 1613048503.6948197
train: epoch 54, iter 2300, loss: 2.752259, top_1: 0.593164, top_k: 0.813438, samples/s: 848.112 1613048533.8794992
train: epoch 54, iter 2400, loss: 2.564732, top_1: 0.597617, top_k: 0.818047, samples/s: 844.459 1613048564.1947904
train: epoch 54, iter 2500, loss: 2.673933, top_1: 0.590938, top_k: 0.809688, samples/s: 845.269 1613048594.4810824
train: epoch 54, iter 2600, loss: 2.626773, top_1: 0.592539, top_k: 0.816133, samples/s: 846.705 1613048624.71591
train: epoch 54, iter 2700, loss: 2.649614, top_1: 0.594414, top_k: 0.812930, samples/s: 842.066 1613048655.1173494
train: epoch 54, iter 2800, loss: 2.760687, top_1: 0.600078, top_k: 0.816484, samples/s: 845.170 1613048685.407069
train: epoch 54, iter 2900, loss: 2.805209, top_1: 0.591094, top_k: 0.809336, samples/s: 844.662 1613048715.7150512
train: epoch 54, iter 3000, loss: 2.455433, top_1: 0.591992, top_k: 0.809727, samples/s: 846.058 1613048745.9729135
train: epoch 54, iter 3100, loss: 2.601269, top_1: 0.587031, top_k: 0.810117, samples/s: 845.572 1613048776.248266
train: epoch 54, iter 3200, loss: 2.660729, top_1: 0.592187, top_k: 0.813281, samples/s: 843.727 1613048806.5898728
train: epoch 54, iter 3300, loss: 2.474073, top_1: 0.593359, top_k: 0.812383, samples/s: 843.794 1613048836.929103
train: epoch 54, iter 3400, loss: 2.628525, top_1: 0.591914, top_k: 0.811211, samples/s: 845.846 1613048867.194572
train: epoch 54, iter 3500, loss: 2.800252, top_1: 0.597070, top_k: 0.814844, samples/s: 844.674 1613048897.5022278
train: epoch 54, iter 3600, loss: 2.384475, top_1: 0.593828, top_k: 0.813867, samples/s: 843.520 1613048927.8511715
train: epoch 54, iter 3700, loss: 2.580015, top_1: 0.595156, top_k: 0.816133, samples/s: 843.165 1613048958.2130308
train: epoch 54, iter 3800, loss: 2.476138, top_1: 0.592539, top_k: 0.814570, samples/s: 846.014 1613048988.4725468
train: epoch 54, iter 3900, loss: 2.716453, top_1: 0.595313, top_k: 0.810820, samples/s: 847.765 1613049018.669553
train: epoch 54, iter 4000, loss: 2.465848, top_1: 0.593555, top_k: 0.812148, samples/s: 844.501 1613049048.9833965
train: epoch 54, iter 4100, loss: 2.606268, top_1: 0.588711, top_k: 0.811016, samples/s: 844.777 1613049079.2871845
train: epoch 54, iter 4200, loss: 2.728399, top_1: 0.588672, top_k: 0.811445, samples/s: 846.574 1613049109.526731
train: epoch 54, iter 4300, loss: 2.875547, top_1: 0.594336, top_k: 0.814141, samples/s: 846.210 1613049139.7792385
train: epoch 54, iter 4400, loss: 2.744467, top_1: 0.590664, top_k: 0.812852, samples/s: 843.878 1613049170.115384
train: epoch 54, iter 4500, loss: 2.777992, top_1: 0.595508, top_k: 0.813594, samples/s: 845.458 1613049200.3948762
train: epoch 54, iter 4600, loss: 2.525934, top_1: 0.592734, top_k: 0.813203, samples/s: 847.160 1613049230.613476
train: epoch 54, iter 4700, loss: 2.728979, top_1: 0.588828, top_k: 0.812070, samples/s: 842.933 1613049260.9836419
train: epoch 54, iter 4800, loss: 2.744542, top_1: 0.592969, top_k: 0.812773, samples/s: 845.246 1613049291.2705963
train: epoch 54, iter 4900, loss: 2.569561, top_1: 0.586484, top_k: 0.809375, samples/s: 845.730 1613049321.5403676
train: epoch 54, iter 5000, loss: 2.821763, top_1: 0.593945, top_k: 0.811602, samples/s: 844.377 1613049351.8586087
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_54.
validation: epoch 54, iter 195, top_1: 0.641747, top_k: 0.862400, samples/s: 2464.003 1613049373.0240145
train: epoch 55, iter 100, loss: 2.469992, top_1: 0.609180, top_k: 0.823438, samples/s: 869.575 1613049422.7279878
train: epoch 55, iter 200, loss: 2.547847, top_1: 0.606914, top_k: 0.820703, samples/s: 865.823 1613049452.2952697
train: epoch 55, iter 300, loss: 2.732077, top_1: 0.599805, top_k: 0.815234, samples/s: 844.994 1613049482.5914178
train: epoch 55, iter 400, loss: 2.586041, top_1: 0.606602, top_k: 0.819570, samples/s: 844.817 1613049512.893795
train: epoch 55, iter 500, loss: 2.662070, top_1: 0.606523, top_k: 0.821875, samples/s: 845.735 1613049543.1632695
train: epoch 55, iter 600, loss: 2.451331, top_1: 0.612812, top_k: 0.827422, samples/s: 843.248 1613049573.5220814
train: epoch 55, iter 700, loss: 2.539793, top_1: 0.606875, top_k: 0.819570, samples/s: 843.011 1613049603.889435
train: epoch 55, iter 800, loss: 2.746960, top_1: 0.594023, top_k: 0.813984, samples/s: 844.336 1613049634.2090607
train: epoch 55, iter 900, loss: 2.610493, top_1: 0.597773, top_k: 0.819727, samples/s: 846.114 1613049664.4650364
train: epoch 55, iter 1000, loss: 2.571355, top_1: 0.601328, top_k: 0.824102, samples/s: 844.780 1613049694.7687378
train: epoch 55, iter 1100, loss: 2.623640, top_1: 0.601289, top_k: 0.817656, samples/s: 845.078 1613049725.0618496
train: epoch 55, iter 1200, loss: 2.543361, top_1: 0.600586, top_k: 0.815664, samples/s: 846.305 1613049755.3109972
train: epoch 55, iter 1300, loss: 2.698588, top_1: 0.599883, top_k: 0.815117, samples/s: 841.751 1613049785.7238076
train: epoch 55, iter 1400, loss: 2.686297, top_1: 0.597227, top_k: 0.820234, samples/s: 845.752 1613049815.9926782
train: epoch 55, iter 1500, loss: 2.846405, top_1: 0.597187, top_k: 0.818789, samples/s: 842.952 1613049846.3622143
train: epoch 55, iter 1600, loss: 2.662551, top_1: 0.597187, top_k: 0.817422, samples/s: 846.805 1613049876.593449
train: epoch 55, iter 1700, loss: 2.504780, top_1: 0.592383, top_k: 0.817969, samples/s: 841.517 1613049907.0147486
train: epoch 55, iter 1800, loss: 2.883455, top_1: 0.601211, top_k: 0.816289, samples/s: 843.195 1613049937.375364
train: epoch 55, iter 1900, loss: 2.563696, top_1: 0.596523, top_k: 0.818203, samples/s: 846.983 1613049967.600348
train: epoch 55, iter 2000, loss: 2.705223, top_1: 0.601055, top_k: 0.820156, samples/s: 844.422 1613049997.9168503
train: epoch 55, iter 2100, loss: 2.658885, top_1: 0.600742, top_k: 0.820078, samples/s: 841.203 1613050028.3495848
train: epoch 55, iter 2200, loss: 2.500552, top_1: 0.599961, top_k: 0.818242, samples/s: 848.560 1613050058.5182211
train: epoch 55, iter 2300, loss: 2.660689, top_1: 0.597773, top_k: 0.815586, samples/s: 841.789 1613050088.9297602
train: epoch 55, iter 2400, loss: 2.501786, top_1: 0.602578, top_k: 0.815352, samples/s: 846.099 1613050119.1861448
train: epoch 55, iter 2500, loss: 2.645434, top_1: 0.597773, top_k: 0.816719, samples/s: 843.956 1613050149.5195184
train: epoch 55, iter 2600, loss: 2.546579, top_1: 0.601797, top_k: 0.817461, samples/s: 844.002 1613050179.851182
train: epoch 55, iter 2700, loss: 2.690387, top_1: 0.597305, top_k: 0.815664, samples/s: 848.480 1613050210.0228806
train: epoch 55, iter 2800, loss: 2.604357, top_1: 0.599414, top_k: 0.813516, samples/s: 844.718 1613050240.328813
train: epoch 55, iter 2900, loss: 2.643763, top_1: 0.591875, top_k: 0.814609, samples/s: 845.318 1613050270.6133106
train: epoch 55, iter 3000, loss: 2.682229, top_1: 0.598633, top_k: 0.816094, samples/s: 845.046 1613050300.9074502
train: epoch 55, iter 3100, loss: 2.754174, top_1: 0.590117, top_k: 0.812891, samples/s: 845.544 1613050331.1838489
train: epoch 55, iter 3200, loss: 2.757050, top_1: 0.586406, top_k: 0.811250, samples/s: 844.718 1613050361.4898407
train: epoch 55, iter 3300, loss: 2.516853, top_1: 0.596992, top_k: 0.815039, samples/s: 844.101 1613050391.817888
train: epoch 55, iter 3400, loss: 2.633934, top_1: 0.596836, top_k: 0.814258, samples/s: 843.551 1613050422.1658428
train: epoch 55, iter 3500, loss: 2.591606, top_1: 0.591836, top_k: 0.811953, samples/s: 842.237 1613050452.5614345
train: epoch 55, iter 3600, loss: 2.551923, top_1: 0.596641, top_k: 0.815508, samples/s: 846.459 1613050482.8047564
train: epoch 55, iter 3700, loss: 2.607267, top_1: 0.596055, top_k: 0.816836, samples/s: 846.076 1613050513.0624444
train: epoch 55, iter 3800, loss: 2.550082, top_1: 0.592969, top_k: 0.815195, samples/s: 842.236 1613050543.4573426
train: epoch 55, iter 3900, loss: 2.597971, top_1: 0.593359, top_k: 0.810391, samples/s: 845.538 1613050573.733969
train: epoch 55, iter 4000, loss: 2.813739, top_1: 0.592031, top_k: 0.810312, samples/s: 843.625 1613050604.0792348
train: epoch 55, iter 4100, loss: 2.617358, top_1: 0.590742, top_k: 0.815156, samples/s: 848.584 1613050634.247062
train: epoch 55, iter 4200, loss: 2.825258, top_1: 0.596562, top_k: 0.814922, samples/s: 846.676 1613050664.483015
train: epoch 55, iter 4300, loss: 2.800531, top_1: 0.590469, top_k: 0.814844, samples/s: 844.305 1613050694.8037462
train: epoch 55, iter 4400, loss: 2.530678, top_1: 0.595703, top_k: 0.815664, samples/s: 844.330 1613050725.123647
train: epoch 55, iter 4500, loss: 2.786892, top_1: 0.596094, top_k: 0.813125, samples/s: 844.697 1613050755.4303813
train: epoch 55, iter 4600, loss: 2.764495, top_1: 0.594688, top_k: 0.813008, samples/s: 844.873 1613050785.731186
train: epoch 55, iter 4700, loss: 2.771367, top_1: 0.588672, top_k: 0.815078, samples/s: 843.670 1613050816.0743601
train: epoch 55, iter 4800, loss: 2.525395, top_1: 0.595664, top_k: 0.815781, samples/s: 845.773 1613050846.3425841
train: epoch 55, iter 4900, loss: 2.554223, top_1: 0.593320, top_k: 0.813477, samples/s: 846.307 1613050876.5920932
train: epoch 55, iter 5000, loss: 2.753632, top_1: 0.597695, top_k: 0.810977, samples/s: 843.815 1613050906.9300582
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_55.
validation: epoch 55, iter 195, top_1: 0.650541, top_k: 0.867748, samples/s: 2438.983 1613050928.3093503
train: epoch 56, iter 100, loss: 2.899644, top_1: 0.609648, top_k: 0.824609, samples/s: 871.285 1613050978.3683121
train: epoch 56, iter 200, loss: 2.559646, top_1: 0.611172, top_k: 0.826992, samples/s: 865.601 1613051007.9431353
train: epoch 56, iter 300, loss: 2.587730, top_1: 0.601133, top_k: 0.815039, samples/s: 846.912 1613051038.1706583
train: epoch 56, iter 400, loss: 2.645207, top_1: 0.604688, top_k: 0.820352, samples/s: 842.097 1613051068.5709481
train: epoch 56, iter 500, loss: 2.746078, top_1: 0.607266, top_k: 0.821562, samples/s: 843.384 1613051098.9248502
train: epoch 56, iter 600, loss: 2.485846, top_1: 0.611328, top_k: 0.826484, samples/s: 844.406 1613051129.2420483
train: epoch 56, iter 700, loss: 2.700969, top_1: 0.607227, top_k: 0.823750, samples/s: 842.711 1613051159.6202166
train: epoch 56, iter 800, loss: 2.562463, top_1: 0.604648, top_k: 0.819531, samples/s: 841.508 1613051190.0418007
train: epoch 56, iter 900, loss: 2.606212, top_1: 0.603437, top_k: 0.819609, samples/s: 842.811 1613051220.4162672
train: epoch 56, iter 1000, loss: 2.712282, top_1: 0.601875, top_k: 0.817344, samples/s: 841.704 1613051250.830733
train: epoch 56, iter 1100, loss: 2.847492, top_1: 0.610195, top_k: 0.823555, samples/s: 845.521 1613051281.1079488
train: epoch 56, iter 1200, loss: 2.592972, top_1: 0.603086, top_k: 0.817187, samples/s: 840.936 1613051311.5502594
train: epoch 56, iter 1300, loss: 2.554696, top_1: 0.609141, top_k: 0.819141, samples/s: 845.694 1613051341.821255
train: epoch 56, iter 1400, loss: 2.481668, top_1: 0.597422, top_k: 0.819688, samples/s: 840.623 1613051372.2748117
train: epoch 56, iter 1500, loss: 2.603526, top_1: 0.594961, top_k: 0.817734, samples/s: 848.872 1613051402.4325035
train: epoch 56, iter 1600, loss: 2.700712, top_1: 0.599922, top_k: 0.816133, samples/s: 841.009 1613051432.8721766
train: epoch 56, iter 1700, loss: 2.820213, top_1: 0.599492, top_k: 0.819414, samples/s: 844.207 1613051463.1964133
train: epoch 56, iter 1800, loss: 2.570440, top_1: 0.591914, top_k: 0.811445, samples/s: 845.880 1613051493.4607787
train: epoch 56, iter 1900, loss: 2.779537, top_1: 0.593945, top_k: 0.813555, samples/s: 840.133 1613051523.9321027
train: epoch 56, iter 2000, loss: 2.607235, top_1: 0.596367, top_k: 0.816562, samples/s: 843.662 1613051554.2761104
train: epoch 56, iter 2100, loss: 2.581325, top_1: 0.594297, top_k: 0.814063, samples/s: 844.064 1613051584.605514
train: epoch 56, iter 2200, loss: 2.397407, top_1: 0.599766, top_k: 0.820664, samples/s: 845.663 1613051614.877646
train: epoch 56, iter 2300, loss: 2.678221, top_1: 0.597500, top_k: 0.816641, samples/s: 843.200 1613051645.238192
train: epoch 56, iter 2400, loss: 2.780881, top_1: 0.595781, top_k: 0.817656, samples/s: 846.954 1613051675.464067
train: epoch 56, iter 2500, loss: 2.654836, top_1: 0.599375, top_k: 0.817383, samples/s: 844.956 1613051705.76153
train: epoch 56, iter 2600, loss: 2.539253, top_1: 0.598008, top_k: 0.818477, samples/s: 843.254 1613051736.120064
train: epoch 56, iter 2700, loss: 2.582820, top_1: 0.599453, top_k: 0.816875, samples/s: 845.766 1613051766.388539
train: epoch 56, iter 2800, loss: 2.658049, top_1: 0.599063, top_k: 0.820273, samples/s: 845.371 1613051796.6711574
train: epoch 56, iter 2900, loss: 2.902696, top_1: 0.595742, top_k: 0.814531, samples/s: 846.307 1613051826.9201415
train: epoch 56, iter 3000, loss: 2.786598, top_1: 0.598711, top_k: 0.811406, samples/s: 845.034 1613051857.2148602
train: epoch 56, iter 3100, loss: 2.927153, top_1: 0.599766, top_k: 0.816211, samples/s: 843.799 1613051887.5537543
train: epoch 56, iter 3200, loss: 2.525125, top_1: 0.596992, top_k: 0.814766, samples/s: 843.713 1613051917.895884
train: epoch 56, iter 3300, loss: 2.732977, top_1: 0.595469, top_k: 0.816016, samples/s: 846.009 1613051948.1556377
train: epoch 56, iter 3400, loss: 2.641492, top_1: 0.592852, top_k: 0.809414, samples/s: 845.337 1613051978.4394395
train: epoch 56, iter 3500, loss: 2.675224, top_1: 0.605820, top_k: 0.822617, samples/s: 841.135 1613052008.8745213
train: epoch 56, iter 3600, loss: 2.639563, top_1: 0.597109, top_k: 0.812461, samples/s: 843.617 1613052039.22001
train: epoch 56, iter 3700, loss: 2.790379, top_1: 0.597187, top_k: 0.816172, samples/s: 846.225 1613052069.472025
train: epoch 56, iter 3800, loss: 2.800552, top_1: 0.594727, top_k: 0.812695, samples/s: 844.588 1613052099.782639
train: epoch 56, iter 3900, loss: 2.637828, top_1: 0.597383, top_k: 0.817383, samples/s: 844.519 1613052130.096287
train: epoch 56, iter 4000, loss: 2.535877, top_1: 0.594727, top_k: 0.812891, samples/s: 842.704 1613052160.4741156
train: epoch 56, iter 4100, loss: 2.565509, top_1: 0.596211, top_k: 0.813789, samples/s: 846.925 1613052190.7014003
train: epoch 56, iter 4200, loss: 2.720915, top_1: 0.598555, top_k: 0.812578, samples/s: 844.786 1613052221.0046484
train: epoch 56, iter 4300, loss: 2.762522, top_1: 0.596484, top_k: 0.815000, samples/s: 846.719 1613052251.2390084
train: epoch 56, iter 4400, loss: 2.884371, top_1: 0.596680, top_k: 0.814180, samples/s: 845.669 1613052281.5110035
train: epoch 56, iter 4500, loss: 2.598325, top_1: 0.594063, top_k: 0.814453, samples/s: 842.978 1613052311.8794332
train: epoch 56, iter 4600, loss: 2.534043, top_1: 0.600586, top_k: 0.819883, samples/s: 846.608 1613052342.117846
train: epoch 56, iter 4700, loss: 2.629342, top_1: 0.597461, top_k: 0.818242, samples/s: 844.599 1613052372.427997
train: epoch 56, iter 4800, loss: 2.466222, top_1: 0.592344, top_k: 0.814805, samples/s: 844.317 1613052402.7483559
train: epoch 56, iter 4900, loss: 2.657250, top_1: 0.597539, top_k: 0.815195, samples/s: 843.371 1613052433.1028166
train: epoch 56, iter 5000, loss: 2.709222, top_1: 0.596680, top_k: 0.811602, samples/s: 846.096 1613052463.3593605
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_56.
validation: epoch 56, iter 195, top_1: 0.647216, top_k: 0.865425, samples/s: 2382.380 1613052485.215839
train: epoch 57, iter 100, loss: 2.742158, top_1: 0.606914, top_k: 0.825352, samples/s: 869.702 1613052535.2303505
train: epoch 57, iter 200, loss: 2.681711, top_1: 0.602930, top_k: 0.822695, samples/s: 865.454 1613052564.8101556
train: epoch 57, iter 300, loss: 2.585316, top_1: 0.605586, top_k: 0.820469, samples/s: 849.177 1613052594.9570124
train: epoch 57, iter 400, loss: 2.499169, top_1: 0.604219, top_k: 0.823477, samples/s: 843.166 1613052625.3187032
train: epoch 57, iter 500, loss: 2.606052, top_1: 0.604492, top_k: 0.822891, samples/s: 841.525 1613052655.739625
train: epoch 57, iter 600, loss: 2.604677, top_1: 0.607109, top_k: 0.819570, samples/s: 842.874 1613052686.1119483
train: epoch 57, iter 700, loss: 2.646582, top_1: 0.603984, top_k: 0.821836, samples/s: 848.091 1613052716.297409
train: epoch 57, iter 800, loss: 2.667051, top_1: 0.607031, top_k: 0.826602, samples/s: 844.193 1613052746.6223085
train: epoch 57, iter 900, loss: 2.607983, top_1: 0.600977, top_k: 0.817969, samples/s: 840.695 1613052777.0732625
train: epoch 57, iter 1000, loss: 2.682958, top_1: 0.611367, top_k: 0.822656, samples/s: 846.210 1613052807.325735
train: epoch 57, iter 1100, loss: 2.593718, top_1: 0.597891, top_k: 0.820312, samples/s: 841.792 1613052837.7371573
train: epoch 57, iter 1200, loss: 2.442039, top_1: 0.600352, top_k: 0.818203, samples/s: 843.132 1613052868.100139
train: epoch 57, iter 1300, loss: 2.574444, top_1: 0.599609, top_k: 0.819297, samples/s: 845.034 1613052898.3947198
train: epoch 57, iter 1400, loss: 2.526857, top_1: 0.603828, top_k: 0.817695, samples/s: 845.506 1613052928.672404
train: epoch 57, iter 1500, loss: 2.761640, top_1: 0.598125, top_k: 0.814102, samples/s: 845.528 1613052958.949403
train: epoch 57, iter 1600, loss: 2.486591, top_1: 0.608281, top_k: 0.824336, samples/s: 843.973 1613052989.2821584
train: epoch 57, iter 1700, loss: 2.643941, top_1: 0.600703, top_k: 0.819141, samples/s: 846.527 1613053019.5233316
train: epoch 57, iter 1800, loss: 2.814520, top_1: 0.599844, top_k: 0.817383, samples/s: 843.322 1613053049.8794246
train: epoch 57, iter 1900, loss: 2.642497, top_1: 0.601758, top_k: 0.816680, samples/s: 844.731 1613053080.1849363
train: epoch 57, iter 2000, loss: 2.674600, top_1: 0.599727, top_k: 0.814727, samples/s: 845.852 1613053110.450401
train: epoch 57, iter 2100, loss: 2.657329, top_1: 0.597422, top_k: 0.816367, samples/s: 846.102 1613053140.7067344
train: epoch 57, iter 2200, loss: 2.697250, top_1: 0.597148, top_k: 0.817578, samples/s: 847.013 1613053170.9306307
train: epoch 57, iter 2300, loss: 2.693580, top_1: 0.596133, top_k: 0.817500, samples/s: 842.088 1613053201.3312795
train: epoch 57, iter 2400, loss: 2.706432, top_1: 0.599453, top_k: 0.821484, samples/s: 848.599 1613053231.4986293
train: epoch 57, iter 2500, loss: 2.516042, top_1: 0.604102, top_k: 0.817187, samples/s: 846.821 1613053261.7292752
train: epoch 57, iter 2600, loss: 2.637905, top_1: 0.600234, top_k: 0.817109, samples/s: 842.775 1613053292.1052125
train: epoch 57, iter 2700, loss: 2.604878, top_1: 0.597539, top_k: 0.820820, samples/s: 844.988 1613053322.4014652
train: epoch 57, iter 2800, loss: 2.487805, top_1: 0.594961, top_k: 0.816133, samples/s: 847.650 1613053352.6026115
train: epoch 57, iter 2900, loss: 2.780906, top_1: 0.604375, top_k: 0.820469, samples/s: 843.401 1613053382.955929
train: epoch 57, iter 3000, loss: 2.750051, top_1: 0.601953, top_k: 0.819375, samples/s: 848.576 1613053413.124549
train: epoch 57, iter 3100, loss: 2.457713, top_1: 0.597227, top_k: 0.817070, samples/s: 842.900 1613053443.4954014
train: epoch 57, iter 3200, loss: 2.821203, top_1: 0.595547, top_k: 0.810039, samples/s: 846.344 1613053473.743099
train: epoch 57, iter 3300, loss: 2.876388, top_1: 0.594727, top_k: 0.812109, samples/s: 849.272 1613053503.8870769
train: epoch 57, iter 3400, loss: 2.633102, top_1: 0.599023, top_k: 0.815391, samples/s: 841.857 1613053534.2955432
train: epoch 57, iter 3500, loss: 2.597069, top_1: 0.597461, top_k: 0.816758, samples/s: 845.991 1613053564.5559402
train: epoch 57, iter 3600, loss: 2.580158, top_1: 0.596562, top_k: 0.814102, samples/s: 845.234 1613053594.843456
train: epoch 57, iter 3700, loss: 2.722835, top_1: 0.591836, top_k: 0.814102, samples/s: 846.268 1613053625.093887
train: epoch 57, iter 3800, loss: 2.689376, top_1: 0.595664, top_k: 0.814961, samples/s: 845.043 1613053655.3881602
train: epoch 57, iter 3900, loss: 2.649664, top_1: 0.598867, top_k: 0.816445, samples/s: 843.983 1613053685.7205796
train: epoch 57, iter 4000, loss: 2.731142, top_1: 0.593828, top_k: 0.815156, samples/s: 846.591 1613053715.9594476
train: epoch 57, iter 4100, loss: 2.794806, top_1: 0.596055, top_k: 0.814844, samples/s: 843.415 1613053746.3122609
train: epoch 57, iter 4200, loss: 2.714542, top_1: 0.599141, top_k: 0.815664, samples/s: 844.942 1613053776.6102595
train: epoch 57, iter 4300, loss: 2.835942, top_1: 0.597500, top_k: 0.814531, samples/s: 843.870 1613053806.9465687
train: epoch 57, iter 4400, loss: 2.656036, top_1: 0.600977, top_k: 0.818203, samples/s: 847.491 1613053837.1534064
train: epoch 57, iter 4500, loss: 2.803629, top_1: 0.604648, top_k: 0.814922, samples/s: 846.028 1613053867.4124076
train: epoch 57, iter 4600, loss: 2.706572, top_1: 0.598477, top_k: 0.817187, samples/s: 841.823 1613053897.8225844
train: epoch 57, iter 4700, loss: 2.554618, top_1: 0.596758, top_k: 0.821406, samples/s: 849.099 1613053927.9722898
train: epoch 57, iter 4800, loss: 2.598985, top_1: 0.599688, top_k: 0.817656, samples/s: 838.816 1613053958.4914436
train: epoch 57, iter 4900, loss: 2.627651, top_1: 0.592344, top_k: 0.812930, samples/s: 847.852 1613053988.6854575
train: epoch 57, iter 5000, loss: 2.804296, top_1: 0.607422, top_k: 0.823867, samples/s: 842.904 1613054019.05664
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_57.
validation: epoch 57, iter 195, top_1: 0.652584, top_k: 0.868329, samples/s: 2420.937 1613054040.5737095
train: epoch 58, iter 100, loss: 2.523352, top_1: 0.621367, top_k: 0.831445, samples/s: 870.165 1613054090.2225893
train: epoch 58, iter 200, loss: 2.574874, top_1: 0.616875, top_k: 0.826406, samples/s: 866.240 1613054119.7756302
train: epoch 58, iter 300, loss: 2.568726, top_1: 0.608047, top_k: 0.826602, samples/s: 848.541 1613054149.944999
train: epoch 58, iter 400, loss: 2.870205, top_1: 0.605508, top_k: 0.821484, samples/s: 844.000 1613054180.2766943
train: epoch 58, iter 500, loss: 2.792019, top_1: 0.612070, top_k: 0.827773, samples/s: 847.089 1613054210.4978614
train: epoch 58, iter 600, loss: 2.568688, top_1: 0.601641, top_k: 0.820859, samples/s: 841.276 1613054240.9277754
train: epoch 58, iter 700, loss: 2.650096, top_1: 0.610039, top_k: 0.823398, samples/s: 842.904 1613054271.2990105
train: epoch 58, iter 800, loss: 2.381010, top_1: 0.606875, top_k: 0.823516, samples/s: 845.169 1613054301.5887256
train: epoch 58, iter 900, loss: 2.675515, top_1: 0.600859, top_k: 0.821953, samples/s: 845.739 1613054331.8582253
train: epoch 58, iter 1000, loss: 2.664204, top_1: 0.603672, top_k: 0.822187, samples/s: 844.151 1613054362.1844528
train: epoch 58, iter 1100, loss: 2.648904, top_1: 0.609180, top_k: 0.822812, samples/s: 845.931 1613054392.447028
train: epoch 58, iter 1200, loss: 2.860312, top_1: 0.601094, top_k: 0.820820, samples/s: 844.342 1613054422.766527
train: epoch 58, iter 1300, loss: 2.792100, top_1: 0.601367, top_k: 0.815820, samples/s: 842.292 1613054453.1597924
train: epoch 58, iter 1400, loss: 2.574386, top_1: 0.605586, top_k: 0.820273, samples/s: 844.452 1613054483.4752052
train: epoch 58, iter 1500, loss: 2.562231, top_1: 0.604336, top_k: 0.820859, samples/s: 844.047 1613054513.8053098
train: epoch 58, iter 1600, loss: 2.830903, top_1: 0.595781, top_k: 0.815781, samples/s: 846.638 1613054544.0425153
train: epoch 58, iter 1700, loss: 2.702281, top_1: 0.604414, top_k: 0.818047, samples/s: 844.902 1613054574.3418953
train: epoch 58, iter 1800, loss: 2.620403, top_1: 0.598984, top_k: 0.818203, samples/s: 845.882 1613054604.6061766
train: epoch 58, iter 1900, loss: 2.665227, top_1: 0.601758, top_k: 0.824063, samples/s: 846.196 1613054634.8593254
train: epoch 58, iter 2000, loss: 2.539778, top_1: 0.602773, top_k: 0.820586, samples/s: 846.443 1613054665.1035042
train: epoch 58, iter 2100, loss: 2.543279, top_1: 0.600938, top_k: 0.817305, samples/s: 844.515 1613054695.4167612
train: epoch 58, iter 2200, loss: 2.654358, top_1: 0.603203, top_k: 0.819961, samples/s: 844.462 1613054725.731848
train: epoch 58, iter 2300, loss: 2.552048, top_1: 0.600742, top_k: 0.818906, samples/s: 843.049 1613054756.097883
train: epoch 58, iter 2400, loss: 2.702396, top_1: 0.601094, top_k: 0.824922, samples/s: 846.924 1613054786.3248878
train: epoch 58, iter 2500, loss: 2.692653, top_1: 0.596250, top_k: 0.814102, samples/s: 847.685 1613054816.5248275
train: epoch 58, iter 2600, loss: 2.635788, top_1: 0.596719, top_k: 0.815547, samples/s: 844.901 1613054846.824183
train: epoch 58, iter 2700, loss: 2.669305, top_1: 0.600313, top_k: 0.817539, samples/s: 846.794 1613054877.0559196
train: epoch 58, iter 2800, loss: 2.489986, top_1: 0.597031, top_k: 0.815937, samples/s: 845.653 1613054907.328357
train: epoch 58, iter 2900, loss: 2.905183, top_1: 0.602695, top_k: 0.820273, samples/s: 844.359 1613054937.6472049
train: epoch 58, iter 3000, loss: 2.754729, top_1: 0.596680, top_k: 0.815625, samples/s: 850.088 1613054967.761742
train: epoch 58, iter 3100, loss: 2.533530, top_1: 0.603359, top_k: 0.821172, samples/s: 844.531 1613054998.0744498
train: epoch 58, iter 3200, loss: 2.572151, top_1: 0.592812, top_k: 0.811328, samples/s: 847.780 1613055028.2708743
train: epoch 58, iter 3300, loss: 2.867378, top_1: 0.594961, top_k: 0.812969, samples/s: 847.503 1613055058.4773815
train: epoch 58, iter 3400, loss: 2.678155, top_1: 0.596992, top_k: 0.817187, samples/s: 849.109 1613055088.626558
train: epoch 58, iter 3500, loss: 2.626694, top_1: 0.599688, top_k: 0.820156, samples/s: 845.369 1613055118.909259
train: epoch 58, iter 3600, loss: 2.615671, top_1: 0.602266, top_k: 0.820664, samples/s: 847.111 1613055149.1295958
train: epoch 58, iter 3700, loss: 2.733860, top_1: 0.598906, top_k: 0.814609, samples/s: 845.841 1613055179.395227
train: epoch 58, iter 3800, loss: 2.666764, top_1: 0.598594, top_k: 0.815117, samples/s: 846.589 1613055209.6343393
train: epoch 58, iter 3900, loss: 2.743933, top_1: 0.597500, top_k: 0.812031, samples/s: 848.403 1613055239.808661
train: epoch 58, iter 4000, loss: 2.583272, top_1: 0.595977, top_k: 0.817734, samples/s: 847.367 1613055270.019786
train: epoch 58, iter 4100, loss: 2.704548, top_1: 0.603008, top_k: 0.819102, samples/s: 845.690 1613055300.2910266
train: epoch 58, iter 4200, loss: 2.828593, top_1: 0.595234, top_k: 0.816094, samples/s: 843.740 1613055330.6321037
train: epoch 58, iter 4300, loss: 2.618352, top_1: 0.593477, top_k: 0.816055, samples/s: 847.389 1613055360.8425322
train: epoch 58, iter 4400, loss: 2.622783, top_1: 0.596875, top_k: 0.816953, samples/s: 844.467 1613055391.1576133
train: epoch 58, iter 4500, loss: 2.850158, top_1: 0.595469, top_k: 0.811914, samples/s: 846.509 1613055421.399452
train: epoch 58, iter 4600, loss: 2.667493, top_1: 0.597773, top_k: 0.816406, samples/s: 844.449 1613055451.7150598
train: epoch 58, iter 4700, loss: 2.574612, top_1: 0.598320, top_k: 0.816758, samples/s: 845.366 1613055481.9977067
train: epoch 58, iter 4800, loss: 2.728838, top_1: 0.595391, top_k: 0.818945, samples/s: 846.778 1613055512.2300684
train: epoch 58, iter 4900, loss: 2.757747, top_1: 0.594375, top_k: 0.812891, samples/s: 846.523 1613055542.471349
train: epoch 58, iter 5000, loss: 2.498641, top_1: 0.604570, top_k: 0.818516, samples/s: 844.745 1613055572.7764344
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_58.
validation: epoch 58, iter 195, top_1: 0.644752, top_k: 0.864924, samples/s: 2445.141 1613055594.0946212
train: epoch 59, iter 100, loss: 2.515710, top_1: 0.615000, top_k: 0.825977, samples/s: 870.590 1613055643.9435353
train: epoch 59, iter 200, loss: 2.685624, top_1: 0.605586, top_k: 0.820508, samples/s: 865.009 1613055673.5385554
train: epoch 59, iter 300, loss: 2.528277, top_1: 0.611055, top_k: 0.826172, samples/s: 849.924 1613055703.658867
train: epoch 59, iter 400, loss: 2.552444, top_1: 0.614336, top_k: 0.828828, samples/s: 842.600 1613055734.0410812
train: epoch 59, iter 500, loss: 2.765533, top_1: 0.610039, top_k: 0.825195, samples/s: 845.512 1613055764.318544
train: epoch 59, iter 600, loss: 2.680789, top_1: 0.609180, top_k: 0.822344, samples/s: 843.648 1613055794.6630456
train: epoch 59, iter 700, loss: 2.493292, top_1: 0.609219, top_k: 0.823945, samples/s: 844.788 1613055824.9664721
train: epoch 59, iter 800, loss: 2.650782, top_1: 0.601953, top_k: 0.821250, samples/s: 845.718 1613055855.2365792
train: epoch 59, iter 900, loss: 2.850171, top_1: 0.606445, top_k: 0.822500, samples/s: 842.689 1613055885.615528
train: epoch 59, iter 1000, loss: 2.587906, top_1: 0.602734, top_k: 0.821172, samples/s: 842.773 1613055915.9914439
train: epoch 59, iter 1100, loss: 2.380109, top_1: 0.610273, top_k: 0.820820, samples/s: 848.631 1613055946.1576264
train: epoch 59, iter 1200, loss: 2.819077, top_1: 0.605781, top_k: 0.823398, samples/s: 841.328 1613055976.5857422
train: epoch 59, iter 1300, loss: 2.468320, top_1: 0.613906, top_k: 0.828320, samples/s: 845.135 1613056006.8767464
train: epoch 59, iter 1400, loss: 2.487554, top_1: 0.606914, top_k: 0.824844, samples/s: 845.653 1613056037.1492364
train: epoch 59, iter 1500, loss: 2.681025, top_1: 0.605352, top_k: 0.822539, samples/s: 846.773 1613056067.3816164
train: epoch 59, iter 1600, loss: 2.696672, top_1: 0.606016, top_k: 0.824492, samples/s: 844.103 1613056097.7096996
train: epoch 59, iter 1700, loss: 2.592318, top_1: 0.611758, top_k: 0.825234, samples/s: 849.566 1613056127.8427498
train: epoch 59, iter 1800, loss: 2.675476, top_1: 0.600977, top_k: 0.821797, samples/s: 838.840 1613056158.3610935
train: epoch 59, iter 1900, loss: 2.673673, top_1: 0.600195, top_k: 0.819883, samples/s: 846.020 1613056188.6204348
train: epoch 59, iter 2000, loss: 2.569257, top_1: 0.599922, top_k: 0.817891, samples/s: 846.227 1613056218.8724241
train: epoch 59, iter 2100, loss: 2.534235, top_1: 0.600469, top_k: 0.819727, samples/s: 843.633 1613056249.217337
train: epoch 59, iter 2200, loss: 2.795037, top_1: 0.598906, top_k: 0.819648, samples/s: 845.445 1613056279.4973145
train: epoch 59, iter 2300, loss: 2.639040, top_1: 0.597852, top_k: 0.819102, samples/s: 845.680 1613056309.7687697
train: epoch 59, iter 2400, loss: 2.570045, top_1: 0.602305, top_k: 0.820703, samples/s: 841.436 1613056340.192921
train: epoch 59, iter 2500, loss: 2.809461, top_1: 0.606914, top_k: 0.819688, samples/s: 845.951 1613056370.4546828
train: epoch 59, iter 2600, loss: 2.780248, top_1: 0.604883, top_k: 0.817344, samples/s: 848.159 1613056400.6377575
train: epoch 59, iter 2700, loss: 2.664448, top_1: 0.599023, top_k: 0.818477, samples/s: 844.097 1613056430.9659786
train: epoch 59, iter 2800, loss: 2.521050, top_1: 0.600195, top_k: 0.816836, samples/s: 846.326 1613056461.214439
train: epoch 59, iter 2900, loss: 2.627962, top_1: 0.598047, top_k: 0.818398, samples/s: 845.118 1613056491.5061026
train: epoch 59, iter 3000, loss: 2.550276, top_1: 0.603281, top_k: 0.821992, samples/s: 845.913 1613056521.7691374
train: epoch 59, iter 3100, loss: 2.402610, top_1: 0.603594, top_k: 0.821484, samples/s: 847.433 1613056551.9780807
train: epoch 59, iter 3200, loss: 2.624807, top_1: 0.599961, top_k: 0.816680, samples/s: 844.589 1613056582.288622
train: epoch 59, iter 3300, loss: 2.541770, top_1: 0.600547, top_k: 0.815898, samples/s: 847.350 1613056612.5005476
train: epoch 59, iter 3400, loss: 2.549641, top_1: 0.596055, top_k: 0.815937, samples/s: 845.615 1613056642.774311
train: epoch 59, iter 3500, loss: 2.605686, top_1: 0.601836, top_k: 0.817656, samples/s: 844.621 1613056673.0837996
train: epoch 59, iter 3600, loss: 2.644446, top_1: 0.604844, top_k: 0.822031, samples/s: 848.360 1613056703.2596707
train: epoch 59, iter 3700, loss: 2.688486, top_1: 0.605742, top_k: 0.818828, samples/s: 842.354 1613056733.6506772
train: epoch 59, iter 3800, loss: 2.754429, top_1: 0.599297, top_k: 0.818828, samples/s: 846.266 1613056763.9012392
train: epoch 59, iter 3900, loss: 2.718662, top_1: 0.603750, top_k: 0.816914, samples/s: 845.103 1613056794.1933317
train: epoch 59, iter 4000, loss: 2.623821, top_1: 0.603516, top_k: 0.823008, samples/s: 844.568 1613056824.5047362
train: epoch 59, iter 4100, loss: 2.710558, top_1: 0.598945, top_k: 0.815195, samples/s: 846.634 1613056854.7420573
train: epoch 59, iter 4200, loss: 2.290522, top_1: 0.604297, top_k: 0.820078, samples/s: 845.120 1613056885.033646
train: epoch 59, iter 4300, loss: 2.749965, top_1: 0.600195, top_k: 0.821367, samples/s: 844.393 1613056915.3512948
train: epoch 59, iter 4400, loss: 2.678768, top_1: 0.598633, top_k: 0.817852, samples/s: 844.627 1613056945.6604528
train: epoch 59, iter 4500, loss: 2.751667, top_1: 0.597656, top_k: 0.813320, samples/s: 844.131 1613056975.9876263
train: epoch 59, iter 4600, loss: 2.748355, top_1: 0.599492, top_k: 0.813086, samples/s: 844.243 1613057006.3106108
train: epoch 59, iter 4700, loss: 2.655697, top_1: 0.599766, top_k: 0.818477, samples/s: 846.499 1613057036.5527635
train: epoch 59, iter 4800, loss: 2.693344, top_1: 0.596797, top_k: 0.811484, samples/s: 845.689 1613057066.8240461
train: epoch 59, iter 4900, loss: 2.530297, top_1: 0.602891, top_k: 0.818750, samples/s: 844.380 1613057097.1421008
train: epoch 59, iter 5000, loss: 2.565120, top_1: 0.603203, top_k: 0.820312, samples/s: 845.615 1613057127.4159348
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_59.
validation: epoch 59, iter 195, top_1: 0.652564, top_k: 0.870873, samples/s: 2412.840 1613057149.0193803
train: epoch 60, iter 100, loss: 2.572493, top_1: 0.605742, top_k: 0.823398, samples/s: 869.949 1613057204.2467048
train: epoch 60, iter 200, loss: 2.396469, top_1: 0.613672, top_k: 0.823633, samples/s: 868.218 1613057233.7322412
train: epoch 60, iter 300, loss: 2.714608, top_1: 0.608750, top_k: 0.824609, samples/s: 854.811 1613057263.6804023
train: epoch 60, iter 400, loss: 2.735939, top_1: 0.611758, top_k: 0.824141, samples/s: 845.922 1613057293.94335
train: epoch 60, iter 500, loss: 2.351121, top_1: 0.606094, top_k: 0.825078, samples/s: 842.160 1613057324.3413534
train: epoch 60, iter 600, loss: 2.635914, top_1: 0.612070, top_k: 0.822617, samples/s: 845.508 1613057354.6189754
train: epoch 60, iter 700, loss: 2.510847, top_1: 0.610234, top_k: 0.826133, samples/s: 845.981 1613057384.879627
train: epoch 60, iter 800, loss: 2.598934, top_1: 0.610039, top_k: 0.823789, samples/s: 843.287 1613057415.237032
train: epoch 60, iter 900, loss: 2.610142, top_1: 0.611641, top_k: 0.823906, samples/s: 843.199 1613057445.597696
train: epoch 60, iter 1000, loss: 2.451071, top_1: 0.604453, top_k: 0.823594, samples/s: 845.925 1613057475.8603797
train: epoch 60, iter 1100, loss: 2.718591, top_1: 0.604062, top_k: 0.819727, samples/s: 844.789 1613057506.1637416
train: epoch 60, iter 1200, loss: 2.610885, top_1: 0.610469, top_k: 0.828906, samples/s: 842.189 1613057536.5608144
train: epoch 60, iter 1300, loss: 2.590501, top_1: 0.601445, top_k: 0.816875, samples/s: 845.172 1613057566.8505173
train: epoch 60, iter 1400, loss: 2.668341, top_1: 0.608633, top_k: 0.823711, samples/s: 843.904 1613057597.1856346
train: epoch 60, iter 1500, loss: 2.672893, top_1: 0.606211, top_k: 0.824492, samples/s: 842.561 1613057627.5693114
train: epoch 60, iter 1600, loss: 2.663468, top_1: 0.611563, top_k: 0.828633, samples/s: 845.368 1613057657.8518846
train: epoch 60, iter 1700, loss: 2.632480, top_1: 0.603164, top_k: 0.819688, samples/s: 842.995 1613057688.2198672
train: epoch 60, iter 1800, loss: 2.463625, top_1: 0.607266, top_k: 0.819258, samples/s: 845.991 1613057718.4802663
train: epoch 60, iter 1900, loss: 2.597641, top_1: 0.605547, top_k: 0.823203, samples/s: 840.964 1613057748.9214337
train: epoch 60, iter 2000, loss: 2.407972, top_1: 0.603984, top_k: 0.823203, samples/s: 844.268 1613057779.2436085
train: epoch 60, iter 2100, loss: 2.721155, top_1: 0.605898, top_k: 0.822422, samples/s: 848.810 1613057809.4034367
train: epoch 60, iter 2200, loss: 2.848424, top_1: 0.602617, top_k: 0.820859, samples/s: 842.882 1613057839.7753813
train: epoch 60, iter 2300, loss: 2.528518, top_1: 0.609688, top_k: 0.823125, samples/s: 845.402 1613057870.0569332
train: epoch 60, iter 2400, loss: 2.668086, top_1: 0.608594, top_k: 0.823086, samples/s: 844.474 1613057900.3720546
train: epoch 60, iter 2500, loss: 2.658465, top_1: 0.602461, top_k: 0.820078, samples/s: 844.513 1613057930.6849568
train: epoch 60, iter 2600, loss: 2.686347, top_1: 0.601328, top_k: 0.820078, samples/s: 845.739 1613057960.9544914
train: epoch 60, iter 2700, loss: 2.624052, top_1: 0.608867, top_k: 0.822109, samples/s: 845.332 1613057991.238809
train: epoch 60, iter 2800, loss: 2.742538, top_1: 0.601680, top_k: 0.820508, samples/s: 844.669 1613058021.5460954
train: epoch 60, iter 2900, loss: 2.717009, top_1: 0.602070, top_k: 0.818672, samples/s: 849.359 1613058051.6863966
train: epoch 60, iter 3000, loss: 2.607059, top_1: 0.598203, top_k: 0.817383, samples/s: 842.201 1613058082.0829911
train: epoch 60, iter 3100, loss: 2.595868, top_1: 0.606914, top_k: 0.822773, samples/s: 846.946 1613058112.3092685
train: epoch 60, iter 3200, loss: 2.666249, top_1: 0.599531, top_k: 0.817148, samples/s: 845.875 1613058142.5738165
train: epoch 60, iter 3300, loss: 2.584080, top_1: 0.607461, top_k: 0.821211, samples/s: 842.270 1613058172.9677744
train: epoch 60, iter 3400, loss: 2.529446, top_1: 0.600508, top_k: 0.820703, samples/s: 846.674 1613058203.2038276
train: epoch 60, iter 3500, loss: 2.808432, top_1: 0.600039, top_k: 0.821562, samples/s: 843.266 1613058233.5619855
train: epoch 60, iter 3600, loss: 2.572027, top_1: 0.601406, top_k: 0.819766, samples/s: 848.249 1613058263.741736
train: epoch 60, iter 3700, loss: 2.578686, top_1: 0.597578, top_k: 0.817031, samples/s: 843.528 1613058294.0905094
train: epoch 60, iter 3800, loss: 2.720410, top_1: 0.598281, top_k: 0.814648, samples/s: 845.526 1613058324.3674157
train: epoch 60, iter 3900, loss: 2.816210, top_1: 0.604805, top_k: 0.819844, samples/s: 846.310 1613058354.6164436
train: epoch 60, iter 4000, loss: 2.609368, top_1: 0.596914, top_k: 0.815117, samples/s: 843.973 1613058384.9491425
train: epoch 60, iter 4100, loss: 2.545141, top_1: 0.601367, top_k: 0.815781, samples/s: 843.039 1613058415.3154337
train: epoch 60, iter 4200, loss: 2.633485, top_1: 0.601445, top_k: 0.820547, samples/s: 845.979 1613058445.576364
train: epoch 60, iter 4300, loss: 2.639549, top_1: 0.606719, top_k: 0.820430, samples/s: 848.308 1613058475.754053
train: epoch 60, iter 4400, loss: 2.554688, top_1: 0.602852, top_k: 0.819141, samples/s: 842.392 1613058506.1436627
train: epoch 60, iter 4500, loss: 2.686215, top_1: 0.600742, top_k: 0.819414, samples/s: 845.644 1613058536.4163892
train: epoch 60, iter 4600, loss: 2.678246, top_1: 0.606172, top_k: 0.821953, samples/s: 841.825 1613058566.8266132
train: epoch 60, iter 4700, loss: 2.625559, top_1: 0.597305, top_k: 0.816055, samples/s: 847.971 1613058597.0163472
train: epoch 60, iter 4800, loss: 2.614681, top_1: 0.601523, top_k: 0.815664, samples/s: 840.394 1613058627.4781966
train: epoch 60, iter 4900, loss: 2.702955, top_1: 0.601055, top_k: 0.818047, samples/s: 849.489 1613058657.6139677
train: epoch 60, iter 5000, loss: 2.510145, top_1: 0.605859, top_k: 0.823945, samples/s: 846.046 1613058687.8724012
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_60.
validation: epoch 60, iter 195, top_1: 0.650220, top_k: 0.867007, samples/s: 2481.843 1613058708.882747
train: epoch 61, iter 100, loss: 2.637347, top_1: 0.606055, top_k: 0.824844, samples/s: 871.039 1613058758.9030676
train: epoch 61, iter 200, loss: 2.360488, top_1: 0.615039, top_k: 0.824727, samples/s: 866.230 1613058788.4563704
train: epoch 61, iter 300, loss: 2.662431, top_1: 0.611094, top_k: 0.827109, samples/s: 848.009 1613058818.6446567
train: epoch 61, iter 400, loss: 2.758132, top_1: 0.610234, top_k: 0.826406, samples/s: 842.523 1613058849.0296383
train: epoch 61, iter 500, loss: 2.643859, top_1: 0.615781, top_k: 0.827773, samples/s: 846.477 1613058879.272588
train: epoch 61, iter 600, loss: 2.629449, top_1: 0.616602, top_k: 0.830781, samples/s: 840.889 1613058909.7166271
train: epoch 61, iter 700, loss: 2.496157, top_1: 0.611914, top_k: 0.825859, samples/s: 845.572 1613058939.9920325
train: epoch 61, iter 800, loss: 2.447940, top_1: 0.611367, top_k: 0.826289, samples/s: 840.862 1613058970.4369216
train: epoch 61, iter 900, loss: 2.615920, top_1: 0.614141, top_k: 0.827773, samples/s: 844.733 1613059000.742338
train: epoch 61, iter 1000, loss: 2.541309, top_1: 0.616484, top_k: 0.830781, samples/s: 840.269 1613059031.2088096
train: epoch 61, iter 1100, loss: 2.703801, top_1: 0.604609, top_k: 0.821367, samples/s: 845.174 1613059061.4983776
train: epoch 61, iter 1200, loss: 2.492945, top_1: 0.602930, top_k: 0.822578, samples/s: 844.925 1613059091.7969677
train: epoch 61, iter 1300, loss: 2.559077, top_1: 0.605313, top_k: 0.825078, samples/s: 842.494 1613059122.1828928
train: epoch 61, iter 1400, loss: 2.579900, top_1: 0.614180, top_k: 0.830508, samples/s: 842.409 1613059152.5720246
train: epoch 61, iter 1500, loss: 2.647459, top_1: 0.607109, top_k: 0.823789, samples/s: 846.383 1613059182.8183217
train: epoch 61, iter 1600, loss: 2.633813, top_1: 0.607695, top_k: 0.822891, samples/s: 846.554 1613059213.058551
train: epoch 61, iter 1700, loss: 2.511859, top_1: 0.609453, top_k: 0.825742, samples/s: 841.798 1613059243.4696746
train: epoch 61, iter 1800, loss: 2.687201, top_1: 0.607500, top_k: 0.824102, samples/s: 845.225 1613059273.757478
train: epoch 61, iter 1900, loss: 2.590258, top_1: 0.606836, top_k: 0.825742, samples/s: 844.906 1613059304.0567532
train: epoch 61, iter 2000, loss: 2.528295, top_1: 0.614648, top_k: 0.823516, samples/s: 845.163 1613059334.346701
train: epoch 61, iter 2100, loss: 2.551131, top_1: 0.603828, top_k: 0.822031, samples/s: 844.309 1613059364.667343
train: epoch 61, iter 2200, loss: 2.727006, top_1: 0.607187, top_k: 0.819414, samples/s: 846.503 1613059394.9094968
train: epoch 61, iter 2300, loss: 2.615906, top_1: 0.598086, top_k: 0.818320, samples/s: 845.373 1613059425.1919036
train: epoch 61, iter 2400, loss: 2.613333, top_1: 0.603359, top_k: 0.816875, samples/s: 845.175 1613059455.4814534
train: epoch 61, iter 2500, loss: 2.721052, top_1: 0.602656, top_k: 0.818438, samples/s: 843.117 1613059485.8450985
train: epoch 61, iter 2600, loss: 2.688885, top_1: 0.602422, top_k: 0.820000, samples/s: 843.735 1613059516.1863725
train: epoch 61, iter 2700, loss: 2.572010, top_1: 0.605430, top_k: 0.819531, samples/s: 844.740 1613059546.4915752
train: epoch 61, iter 2800, loss: 2.695837, top_1: 0.602031, top_k: 0.825977, samples/s: 846.191 1613059576.7447808
train: epoch 61, iter 2900, loss: 2.623939, top_1: 0.599922, top_k: 0.820078, samples/s: 841.318 1613059607.1731284
train: epoch 61, iter 3000, loss: 2.542867, top_1: 0.598672, top_k: 0.815547, samples/s: 843.946 1613059637.5068424
train: epoch 61, iter 3100, loss: 2.720597, top_1: 0.609141, top_k: 0.824414, samples/s: 846.412 1613059667.7522037
train: epoch 61, iter 3200, loss: 2.804726, top_1: 0.606641, top_k: 0.820469, samples/s: 841.352 1613059698.1794724
train: epoch 61, iter 3300, loss: 2.805798, top_1: 0.604375, top_k: 0.818164, samples/s: 844.300 1613059728.5004547
train: epoch 61, iter 3400, loss: 2.656600, top_1: 0.602891, top_k: 0.820547, samples/s: 842.175 1613059758.897909
train: epoch 61, iter 3500, loss: 2.636562, top_1: 0.606602, top_k: 0.822656, samples/s: 842.198 1613059789.2945642
train: epoch 61, iter 3600, loss: 2.646828, top_1: 0.603984, top_k: 0.820859, samples/s: 845.620 1613059819.5682302
train: epoch 61, iter 3700, loss: 2.756679, top_1: 0.600781, top_k: 0.818828, samples/s: 848.698 1613059849.7320473
train: epoch 61, iter 3800, loss: 2.749294, top_1: 0.603125, top_k: 0.817266, samples/s: 840.905 1613059880.1754043
train: epoch 61, iter 3900, loss: 2.582555, top_1: 0.596445, top_k: 0.817969, samples/s: 845.226 1613059910.4631755
train: epoch 61, iter 4000, loss: 2.913014, top_1: 0.600195, top_k: 0.820820, samples/s: 846.405 1613059940.7087488
train: epoch 61, iter 4100, loss: 2.634019, top_1: 0.601367, top_k: 0.818828, samples/s: 843.123 1613059971.0721154
train: epoch 61, iter 4200, loss: 2.475893, top_1: 0.602695, top_k: 0.820977, samples/s: 844.740 1613060001.3773627
train: epoch 61, iter 4300, loss: 2.654848, top_1: 0.608047, top_k: 0.819102, samples/s: 848.098 1613060031.5624602
train: epoch 61, iter 4400, loss: 2.502698, top_1: 0.600742, top_k: 0.819063, samples/s: 842.009 1613060061.9659555
train: epoch 61, iter 4500, loss: 2.667924, top_1: 0.603828, top_k: 0.819844, samples/s: 847.329 1613060092.1785934
train: epoch 61, iter 4600, loss: 2.769142, top_1: 0.603437, top_k: 0.823516, samples/s: 844.784 1613060122.4820986
train: epoch 61, iter 4700, loss: 2.630990, top_1: 0.604219, top_k: 0.820039, samples/s: 842.348 1613060152.87332
train: epoch 61, iter 4800, loss: 2.790105, top_1: 0.596992, top_k: 0.818984, samples/s: 846.655 1613060183.1099982
train: epoch 61, iter 4900, loss: 2.539131, top_1: 0.601719, top_k: 0.820195, samples/s: 844.048 1613060213.4400516
train: epoch 61, iter 5000, loss: 2.617683, top_1: 0.599727, top_k: 0.817930, samples/s: 845.633 1613060243.7131577
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_61.
validation: epoch 61, iter 195, top_1: 0.653646, top_k: 0.869491, samples/s: 2421.993 1613060265.2262354
train: epoch 62, iter 100, loss: 2.581520, top_1: 0.615742, top_k: 0.829570, samples/s: 869.896 1613060315.3425136
train: epoch 62, iter 200, loss: 2.580695, top_1: 0.622969, top_k: 0.836328, samples/s: 865.679 1613060344.9145992
train: epoch 62, iter 300, loss: 2.673275, top_1: 0.612305, top_k: 0.829805, samples/s: 847.987 1613060375.103836
train: epoch 62, iter 400, loss: 2.745548, top_1: 0.612031, top_k: 0.828008, samples/s: 845.499 1613060405.3818412
train: epoch 62, iter 500, loss: 2.653424, top_1: 0.611641, top_k: 0.825156, samples/s: 841.294 1613060435.8110833
train: epoch 62, iter 600, loss: 2.548945, top_1: 0.615898, top_k: 0.828086, samples/s: 842.753 1613060466.1876845
train: epoch 62, iter 700, loss: 2.576063, top_1: 0.612734, top_k: 0.827656, samples/s: 841.513 1613060496.609271
train: epoch 62, iter 800, loss: 2.582802, top_1: 0.611172, top_k: 0.826250, samples/s: 844.327 1613060526.9291952
train: epoch 62, iter 900, loss: 2.600444, top_1: 0.608984, top_k: 0.826719, samples/s: 845.452 1613060557.2087858
train: epoch 62, iter 1000, loss: 2.465730, top_1: 0.610078, top_k: 0.826602, samples/s: 841.466 1613060587.6319
train: epoch 62, iter 1100, loss: 2.593607, top_1: 0.608281, top_k: 0.820156, samples/s: 847.393 1613060617.8421857
train: epoch 62, iter 1200, loss: 2.774726, top_1: 0.611172, top_k: 0.830078, samples/s: 842.318 1613060648.2345119
train: epoch 62, iter 1300, loss: 2.561843, top_1: 0.606016, top_k: 0.823359, samples/s: 846.495 1613060678.4769113
train: epoch 62, iter 1400, loss: 2.663253, top_1: 0.609297, top_k: 0.823828, samples/s: 842.427 1613060708.865262
train: epoch 62, iter 1500, loss: 2.503838, top_1: 0.615313, top_k: 0.828242, samples/s: 846.897 1613060739.0932758
train: epoch 62, iter 1600, loss: 2.455077, top_1: 0.614883, top_k: 0.826641, samples/s: 841.551 1613060769.5133893
train: epoch 62, iter 1700, loss: 2.837574, top_1: 0.607344, top_k: 0.821211, samples/s: 848.178 1613060799.695646
train: epoch 62, iter 1800, loss: 2.587615, top_1: 0.608086, top_k: 0.821250, samples/s: 841.874 1613060830.104045
train: epoch 62, iter 1900, loss: 2.577572, top_1: 0.604375, top_k: 0.819141, samples/s: 846.169 1613060860.3580036
train: epoch 62, iter 2000, loss: 2.613154, top_1: 0.610508, top_k: 0.824375, samples/s: 844.772 1613060890.6620488
train: epoch 62, iter 2100, loss: 2.677453, top_1: 0.604023, top_k: 0.821484, samples/s: 846.034 1613060920.9208674
train: epoch 62, iter 2200, loss: 2.555424, top_1: 0.607031, top_k: 0.820469, samples/s: 844.998 1613060951.2168407
train: epoch 62, iter 2300, loss: 2.591727, top_1: 0.608672, top_k: 0.823945, samples/s: 842.428 1613060981.605084
train: epoch 62, iter 2400, loss: 2.586923, top_1: 0.610586, top_k: 0.823984, samples/s: 847.337 1613061011.8174222
train: epoch 62, iter 2500, loss: 2.658498, top_1: 0.605859, top_k: 0.820977, samples/s: 844.952 1613061042.1149826
train: epoch 62, iter 2600, loss: 2.570395, top_1: 0.608828, top_k: 0.822187, samples/s: 844.205 1613061072.4393456
train: epoch 62, iter 2700, loss: 2.641135, top_1: 0.602461, top_k: 0.821367, samples/s: 843.455 1613061102.790686
train: epoch 62, iter 2800, loss: 2.465159, top_1: 0.608320, top_k: 0.823359, samples/s: 846.053 1613061133.048906
train: epoch 62, iter 2900, loss: 2.714601, top_1: 0.599688, top_k: 0.815508, samples/s: 844.606 1613061163.3589342
train: epoch 62, iter 3000, loss: 2.648830, top_1: 0.609219, top_k: 0.824688, samples/s: 844.454 1613061193.6743407
train: epoch 62, iter 3100, loss: 2.519343, top_1: 0.605859, top_k: 0.824258, samples/s: 844.073 1613061224.0035088
train: epoch 62, iter 3200, loss: 2.516134, top_1: 0.605859, top_k: 0.822187, samples/s: 844.209 1613061254.3276827
train: epoch 62, iter 3300, loss: 2.632528, top_1: 0.605078, top_k: 0.821523, samples/s: 847.080 1613061284.5492427
train: epoch 62, iter 3400, loss: 2.637996, top_1: 0.604531, top_k: 0.819063, samples/s: 842.858 1613061314.9220028
train: epoch 62, iter 3500, loss: 2.379678, top_1: 0.606016, top_k: 0.821562, samples/s: 845.963 1613061345.183411
train: epoch 62, iter 3600, loss: 2.634277, top_1: 0.601328, top_k: 0.821016, samples/s: 843.106 1613061375.5473971
train: epoch 62, iter 3700, loss: 2.683852, top_1: 0.605000, top_k: 0.820234, samples/s: 845.010 1613061405.8428152
train: epoch 62, iter 3800, loss: 2.762119, top_1: 0.606719, top_k: 0.823359, samples/s: 847.380 1613061436.0536335
train: epoch 62, iter 3900, loss: 2.451017, top_1: 0.604961, top_k: 0.823984, samples/s: 845.356 1613061466.336643
train: epoch 62, iter 4000, loss: 2.723350, top_1: 0.605000, top_k: 0.818320, samples/s: 846.624 1613061496.5744011
train: epoch 62, iter 4100, loss: 2.657249, top_1: 0.605547, top_k: 0.820391, samples/s: 846.442 1613061526.8186789
train: epoch 62, iter 4200, loss: 2.662077, top_1: 0.605430, top_k: 0.822656, samples/s: 843.733 1613061557.160059
train: epoch 62, iter 4300, loss: 2.698396, top_1: 0.603164, top_k: 0.821172, samples/s: 847.191 1613061587.3775516
train: epoch 62, iter 4400, loss: 2.604257, top_1: 0.608164, top_k: 0.818945, samples/s: 848.079 1613061617.563508
train: epoch 62, iter 4500, loss: 2.544061, top_1: 0.603125, top_k: 0.820469, samples/s: 844.098 1613061647.891672
train: epoch 62, iter 4600, loss: 2.639017, top_1: 0.598828, top_k: 0.817930, samples/s: 844.086 1613061678.22038
train: epoch 62, iter 4700, loss: 2.759724, top_1: 0.606523, top_k: 0.821875, samples/s: 845.410 1613061708.5014968
train: epoch 62, iter 4800, loss: 2.587349, top_1: 0.610234, top_k: 0.823906, samples/s: 848.766 1613061738.6629333
train: epoch 62, iter 4900, loss: 2.762249, top_1: 0.607695, top_k: 0.820391, samples/s: 846.418 1613061768.907942
train: epoch 62, iter 5000, loss: 2.593885, top_1: 0.608672, top_k: 0.823477, samples/s: 850.848 1613061798.9955783
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_62.
validation: epoch 62, iter 195, top_1: 0.644131, top_k: 0.866226, samples/s: 2499.656 1613061819.878121
train: epoch 63, iter 100, loss: 2.598837, top_1: 0.617734, top_k: 0.830117, samples/s: 870.834 1613061869.8937948
train: epoch 63, iter 200, loss: 2.673648, top_1: 0.623125, top_k: 0.837109, samples/s: 865.488 1613061899.4723566
train: epoch 63, iter 300, loss: 2.531533, top_1: 0.617891, top_k: 0.831680, samples/s: 848.071 1613061929.658589
train: epoch 63, iter 400, loss: 2.593225, top_1: 0.611797, top_k: 0.827969, samples/s: 845.553 1613061959.9345481
train: epoch 63, iter 500, loss: 2.624876, top_1: 0.616211, top_k: 0.825781, samples/s: 846.387 1613061990.180818
train: epoch 63, iter 600, loss: 2.754169, top_1: 0.616172, top_k: 0.830859, samples/s: 843.788 1613062020.5201466
train: epoch 63, iter 700, loss: 2.675456, top_1: 0.616523, top_k: 0.828398, samples/s: 844.632 1613062050.8292618
train: epoch 63, iter 800, loss: 2.531420, top_1: 0.613125, top_k: 0.828242, samples/s: 844.919 1613062081.1280053
train: epoch 63, iter 900, loss: 2.626643, top_1: 0.613789, top_k: 0.828477, samples/s: 848.473 1613062111.2998908
train: epoch 63, iter 1000, loss: 2.593190, top_1: 0.610781, top_k: 0.824766, samples/s: 842.501 1613062141.6856418
train: epoch 63, iter 1100, loss: 2.616092, top_1: 0.611563, top_k: 0.824805, samples/s: 846.526 1613062171.9269016
train: epoch 63, iter 1200, loss: 2.537399, top_1: 0.612109, top_k: 0.828594, samples/s: 845.024 1613062202.2218173
train: epoch 63, iter 1300, loss: 2.712872, top_1: 0.600078, top_k: 0.819141, samples/s: 844.352 1613062232.5410378
train: epoch 63, iter 1400, loss: 2.504673, top_1: 0.611289, top_k: 0.822734, samples/s: 846.018 1613062262.8003743
train: epoch 63, iter 1500, loss: 2.553689, top_1: 0.612773, top_k: 0.829258, samples/s: 846.891 1613062293.0286434
train: epoch 63, iter 1600, loss: 2.652740, top_1: 0.608477, top_k: 0.828867, samples/s: 844.623 1613062323.3379729
train: epoch 63, iter 1700, loss: 2.725120, top_1: 0.606172, top_k: 0.821836, samples/s: 845.350 1613062353.6213653
train: epoch 63, iter 1800, loss: 2.562409, top_1: 0.606992, top_k: 0.819961, samples/s: 847.410 1613062383.830953
train: epoch 63, iter 1900, loss: 2.739583, top_1: 0.606680, top_k: 0.824063, samples/s: 848.378 1613062414.0061495
train: epoch 63, iter 2000, loss: 2.813710, top_1: 0.612266, top_k: 0.826875, samples/s: 843.756 1613062444.3467178
train: epoch 63, iter 2100, loss: 2.581145, top_1: 0.611563, top_k: 0.824180, samples/s: 846.653 1613062474.583504
train: epoch 63, iter 2200, loss: 2.586042, top_1: 0.609375, top_k: 0.821055, samples/s: 847.615 1613062504.7858062
train: epoch 63, iter 2300, loss: 2.649041, top_1: 0.608398, top_k: 0.823359, samples/s: 847.817 1613062534.9810405
train: epoch 63, iter 2400, loss: 2.588211, top_1: 0.606172, top_k: 0.818711, samples/s: 843.903 1613062565.3162563
train: epoch 63, iter 2500, loss: 2.641796, top_1: 0.610508, top_k: 0.828633, samples/s: 845.959 1613062595.577757
train: epoch 63, iter 2600, loss: 2.731039, top_1: 0.606563, top_k: 0.824570, samples/s: 844.498 1613062625.8915918
train: epoch 63, iter 2700, loss: 2.494743, top_1: 0.606445, top_k: 0.822031, samples/s: 846.097 1613062656.148213
train: epoch 63, iter 2800, loss: 2.552617, top_1: 0.610313, top_k: 0.827422, samples/s: 846.089 1613062686.4050903
train: epoch 63, iter 2900, loss: 2.516104, top_1: 0.607422, top_k: 0.822891, samples/s: 846.319 1613062716.6537032
train: epoch 63, iter 3000, loss: 2.693467, top_1: 0.608477, top_k: 0.819648, samples/s: 847.398 1613062746.8638222
train: epoch 63, iter 3100, loss: 2.695654, top_1: 0.604375, top_k: 0.820703, samples/s: 845.716 1613062777.1340423
train: epoch 63, iter 3200, loss: 2.702146, top_1: 0.607187, top_k: 0.825000, samples/s: 847.227 1613062807.3503714
train: epoch 63, iter 3300, loss: 2.597473, top_1: 0.606367, top_k: 0.824297, samples/s: 844.862 1613062837.6510623
train: epoch 63, iter 3400, loss: 2.449643, top_1: 0.607031, top_k: 0.820937, samples/s: 849.266 1613062867.7947357
train: epoch 63, iter 3500, loss: 2.695651, top_1: 0.604336, top_k: 0.821445, samples/s: 844.637 1613062898.103728
train: epoch 63, iter 3600, loss: 2.722846, top_1: 0.608008, top_k: 0.824453, samples/s: 846.195 1613062928.3567102
train: epoch 63, iter 3700, loss: 2.565299, top_1: 0.610352, top_k: 0.822812, samples/s: 845.936 1613062958.6191118
train: epoch 63, iter 3800, loss: 2.683101, top_1: 0.606211, top_k: 0.824063, samples/s: 846.846 1613062988.8488207
train: epoch 63, iter 3900, loss: 2.584346, top_1: 0.605234, top_k: 0.822344, samples/s: 844.323 1613063019.1689672
train: epoch 63, iter 4000, loss: 2.586996, top_1: 0.606875, top_k: 0.824375, samples/s: 849.474 1613063049.3053517
train: epoch 63, iter 4100, loss: 2.587168, top_1: 0.606953, top_k: 0.821562, samples/s: 849.385 1613063079.4447618
train: epoch 63, iter 4200, loss: 2.592641, top_1: 0.602539, top_k: 0.821211, samples/s: 846.122 1613063109.7004285
train: epoch 63, iter 4300, loss: 2.735961, top_1: 0.606875, top_k: 0.822148, samples/s: 847.314 1613063139.9135916
train: epoch 63, iter 4400, loss: 2.553840, top_1: 0.600313, top_k: 0.817695, samples/s: 848.035 1613063170.1010902
train: epoch 63, iter 4500, loss: 2.709834, top_1: 0.607109, top_k: 0.821133, samples/s: 845.461 1613063200.3803327
train: epoch 63, iter 4600, loss: 2.708644, top_1: 0.606328, top_k: 0.826094, samples/s: 845.374 1613063230.6628785
train: epoch 63, iter 4700, loss: 2.705848, top_1: 0.603711, top_k: 0.819375, samples/s: 844.407 1613063260.9799426
train: epoch 63, iter 4800, loss: 2.564291, top_1: 0.599258, top_k: 0.817539, samples/s: 846.748 1613063291.2132752
train: epoch 63, iter 4900, loss: 2.746105, top_1: 0.602578, top_k: 0.818672, samples/s: 846.014 1613063321.472794
train: epoch 63, iter 5000, loss: 2.551596, top_1: 0.609688, top_k: 0.823281, samples/s: 844.718 1613063351.7787685
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_63.
validation: epoch 63, iter 195, top_1: 0.659535, top_k: 0.874058, samples/s: 2478.985 1613063372.8047373
train: epoch 64, iter 100, loss: 2.442073, top_1: 0.628398, top_k: 0.838359, samples/s: 871.433 1613063423.4876375
train: epoch 64, iter 200, loss: 2.664757, top_1: 0.622578, top_k: 0.834336, samples/s: 866.787 1613063453.022305
train: epoch 64, iter 300, loss: 2.610075, top_1: 0.615664, top_k: 0.827930, samples/s: 850.396 1613063483.1256614
train: epoch 64, iter 400, loss: 2.615555, top_1: 0.620430, top_k: 0.834063, samples/s: 844.023 1613063513.456648
train: epoch 64, iter 500, loss: 2.752540, top_1: 0.608984, top_k: 0.823750, samples/s: 845.975 1613063543.717459
train: epoch 64, iter 600, loss: 2.517712, top_1: 0.621445, top_k: 0.828555, samples/s: 844.559 1613063574.0292368
train: epoch 64, iter 700, loss: 2.757065, top_1: 0.617930, top_k: 0.827578, samples/s: 845.730 1613063604.2988894
train: epoch 64, iter 800, loss: 2.730839, top_1: 0.614531, top_k: 0.828477, samples/s: 844.078 1613063634.6278985
train: epoch 64, iter 900, loss: 2.744641, top_1: 0.613828, top_k: 0.827461, samples/s: 846.582 1613063664.8671007
train: epoch 64, iter 1000, loss: 2.470396, top_1: 0.613555, top_k: 0.826602, samples/s: 843.096 1613063695.2314644
train: epoch 64, iter 1100, loss: 2.584360, top_1: 0.608750, top_k: 0.826719, samples/s: 847.944 1613063725.4220529
train: epoch 64, iter 1200, loss: 2.541769, top_1: 0.606758, top_k: 0.826172, samples/s: 846.236 1613063755.673746
train: epoch 64, iter 1300, loss: 2.480049, top_1: 0.609492, top_k: 0.826367, samples/s: 845.296 1613063785.958889
train: epoch 64, iter 1400, loss: 2.429354, top_1: 0.611680, top_k: 0.828359, samples/s: 842.280 1613063816.352622
train: epoch 64, iter 1500, loss: 2.600785, top_1: 0.611719, top_k: 0.825391, samples/s: 844.247 1613063846.6755269
train: epoch 64, iter 1600, loss: 2.446353, top_1: 0.611602, top_k: 0.828008, samples/s: 846.583 1613063876.9146788
train: epoch 64, iter 1700, loss: 2.640655, top_1: 0.608047, top_k: 0.825195, samples/s: 848.768 1613063907.0760522
train: epoch 64, iter 1800, loss: 2.480244, top_1: 0.612500, top_k: 0.825703, samples/s: 844.474 1613063937.3908095
train: epoch 64, iter 1900, loss: 2.612325, top_1: 0.607617, top_k: 0.824414, samples/s: 843.663 1613063967.734805
train: epoch 64, iter 2000, loss: 2.721552, top_1: 0.609844, top_k: 0.825078, samples/s: 846.613 1613063997.972754
train: epoch 64, iter 2100, loss: 2.486744, top_1: 0.609570, top_k: 0.828203, samples/s: 846.977 1613064028.1980417
train: epoch 64, iter 2200, loss: 2.450070, top_1: 0.610547, top_k: 0.824375, samples/s: 845.107 1613064058.4900358
train: epoch 64, iter 2300, loss: 2.623844, top_1: 0.614609, top_k: 0.827422, samples/s: 845.271 1613064088.7760723
train: epoch 64, iter 2400, loss: 2.337240, top_1: 0.610117, top_k: 0.827539, samples/s: 846.533 1613064119.017051
train: epoch 64, iter 2500, loss: 2.757357, top_1: 0.605508, top_k: 0.821094, samples/s: 847.728 1613064149.2154157
train: epoch 64, iter 2600, loss: 2.531311, top_1: 0.615195, top_k: 0.823086, samples/s: 846.659 1613064179.4520216
train: epoch 64, iter 2700, loss: 2.746037, top_1: 0.609961, top_k: 0.823594, samples/s: 846.836 1613064209.6821008
train: epoch 64, iter 2800, loss: 2.675328, top_1: 0.611289, top_k: 0.824336, samples/s: 846.893 1613064239.9102108
train: epoch 64, iter 2900, loss: 2.782596, top_1: 0.612266, top_k: 0.827187, samples/s: 846.965 1613064270.1358771
train: epoch 64, iter 3000, loss: 2.581545, top_1: 0.606797, top_k: 0.826641, samples/s: 847.355 1613064300.3474267
train: epoch 64, iter 3100, loss: 2.512961, top_1: 0.603359, top_k: 0.820703, samples/s: 845.425 1613064330.6281571
train: epoch 64, iter 3200, loss: 2.752679, top_1: 0.612578, top_k: 0.823438, samples/s: 845.710 1613064360.8985548
train: epoch 64, iter 3300, loss: 2.556898, top_1: 0.610859, top_k: 0.825859, samples/s: 847.726 1613064391.0968978
train: epoch 64, iter 3400, loss: 2.608247, top_1: 0.607656, top_k: 0.819883, samples/s: 843.830 1613064421.4348457
train: epoch 64, iter 3500, loss: 2.541560, top_1: 0.606094, top_k: 0.820977, samples/s: 846.390 1613064451.6809645
train: epoch 64, iter 3600, loss: 2.732184, top_1: 0.606523, top_k: 0.824297, samples/s: 847.159 1613064481.8996146
train: epoch 64, iter 3700, loss: 2.669107, top_1: 0.604297, top_k: 0.818906, samples/s: 845.507 1613064512.1773093
train: epoch 64, iter 3800, loss: 2.621884, top_1: 0.611016, top_k: 0.825586, samples/s: 843.865 1613064542.5138073
train: epoch 64, iter 3900, loss: 2.723062, top_1: 0.606055, top_k: 0.823398, samples/s: 847.944 1613064572.7046254
train: epoch 64, iter 4000, loss: 2.642893, top_1: 0.605586, top_k: 0.820039, samples/s: 842.760 1613064603.0809863
train: epoch 64, iter 4100, loss: 2.564017, top_1: 0.605742, top_k: 0.818672, samples/s: 847.497 1613064633.2875328
train: epoch 64, iter 4200, loss: 2.640105, top_1: 0.613516, top_k: 0.824297, samples/s: 845.437 1613064663.5677865
train: epoch 64, iter 4300, loss: 2.728856, top_1: 0.609062, top_k: 0.825000, samples/s: 845.904 1613064693.8312013
train: epoch 64, iter 4400, loss: 2.625255, top_1: 0.607227, top_k: 0.821133, samples/s: 848.067 1613064724.0174906
train: epoch 64, iter 4500, loss: 2.620131, top_1: 0.609336, top_k: 0.823516, samples/s: 844.805 1613064754.3204415
train: epoch 64, iter 4600, loss: 2.643595, top_1: 0.605625, top_k: 0.820586, samples/s: 849.123 1613064784.4692254
train: epoch 64, iter 4700, loss: 2.588088, top_1: 0.606758, top_k: 0.821367, samples/s: 847.078 1613064814.6907306
train: epoch 64, iter 4800, loss: 2.777198, top_1: 0.603555, top_k: 0.818555, samples/s: 847.268 1613064844.905406
train: epoch 64, iter 4900, loss: 2.603979, top_1: 0.602461, top_k: 0.820742, samples/s: 845.650 1613064875.1780577
train: epoch 64, iter 5000, loss: 2.609695, top_1: 0.605938, top_k: 0.819883, samples/s: 846.366 1613064905.424969
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_64.
validation: epoch 64, iter 195, top_1: 0.644591, top_k: 0.863301, samples/s: 2506.477 1613064926.2326846
train: epoch 65, iter 100, loss: 2.677973, top_1: 0.618750, top_k: 0.835859, samples/s: 870.733 1613064977.075281
train: epoch 65, iter 200, loss: 2.546579, top_1: 0.620078, top_k: 0.832734, samples/s: 867.651 1613065006.5804617
train: epoch 65, iter 300, loss: 2.706627, top_1: 0.625938, top_k: 0.838984, samples/s: 849.021 1613065036.732588
train: epoch 65, iter 400, loss: 2.542974, top_1: 0.614414, top_k: 0.825430, samples/s: 846.205 1613065066.9852939
train: epoch 65, iter 500, loss: 2.495959, top_1: 0.615313, top_k: 0.830586, samples/s: 846.995 1613065097.209821
train: epoch 65, iter 600, loss: 2.549790, top_1: 0.619180, top_k: 0.832227, samples/s: 842.619 1613065127.5911765
train: epoch 65, iter 700, loss: 2.557992, top_1: 0.613047, top_k: 0.829688, samples/s: 843.685 1613065157.9343634
train: epoch 65, iter 800, loss: 2.469730, top_1: 0.620352, top_k: 0.829688, samples/s: 848.029 1613065188.1219776
train: epoch 65, iter 900, loss: 2.656796, top_1: 0.615313, top_k: 0.826250, samples/s: 845.703 1613065218.392607
train: epoch 65, iter 1000, loss: 2.704936, top_1: 0.618125, top_k: 0.831094, samples/s: 841.604 1613065248.8106804
train: epoch 65, iter 1100, loss: 2.498017, top_1: 0.617500, top_k: 0.832500, samples/s: 846.665 1613065279.0470812
train: epoch 65, iter 1200, loss: 2.725586, top_1: 0.617852, top_k: 0.830977, samples/s: 843.888 1613065309.382866
train: epoch 65, iter 1300, loss: 2.442770, top_1: 0.613203, top_k: 0.823750, samples/s: 849.584 1613065339.5151556
train: epoch 65, iter 1400, loss: 2.715154, top_1: 0.616055, top_k: 0.826328, samples/s: 844.259 1613065369.8376331
train: epoch 65, iter 1500, loss: 2.522273, top_1: 0.616289, top_k: 0.827930, samples/s: 847.235 1613065400.053558
train: epoch 65, iter 1600, loss: 2.614128, top_1: 0.613516, top_k: 0.824844, samples/s: 846.161 1613065430.3079288
train: epoch 65, iter 1700, loss: 2.507753, top_1: 0.611875, top_k: 0.824141, samples/s: 843.592 1613065460.6543493
train: epoch 65, iter 1800, loss: 2.517485, top_1: 0.614062, top_k: 0.828828, samples/s: 845.746 1613065490.9234138
train: epoch 65, iter 1900, loss: 2.614573, top_1: 0.613437, top_k: 0.828867, samples/s: 844.520 1613065521.236525
train: epoch 65, iter 2000, loss: 2.399553, top_1: 0.618672, top_k: 0.827500, samples/s: 849.313 1613065551.3785613
train: epoch 65, iter 2100, loss: 2.616307, top_1: 0.611328, top_k: 0.823594, samples/s: 847.468 1613065581.5861495
train: epoch 65, iter 2200, loss: 2.440895, top_1: 0.619492, top_k: 0.829922, samples/s: 845.611 1613065611.8601487
train: epoch 65, iter 2300, loss: 2.841750, top_1: 0.605586, top_k: 0.822891, samples/s: 847.955 1613065642.0504305
train: epoch 65, iter 2400, loss: 2.636936, top_1: 0.612187, top_k: 0.829414, samples/s: 847.237 1613065672.266268
train: epoch 65, iter 2500, loss: 2.667192, top_1: 0.608750, top_k: 0.822969, samples/s: 846.259 1613065702.517036
train: epoch 65, iter 2600, loss: 2.449927, top_1: 0.610117, top_k: 0.820391, samples/s: 847.114 1613065732.7373755
train: epoch 65, iter 2700, loss: 2.613257, top_1: 0.615234, top_k: 0.826445, samples/s: 847.394 1613065762.9475772
train: epoch 65, iter 2800, loss: 2.626113, top_1: 0.615078, top_k: 0.829258, samples/s: 846.857 1613065793.177014
train: epoch 65, iter 2900, loss: 2.555855, top_1: 0.611211, top_k: 0.824844, samples/s: 847.685 1613065823.3768735
train: epoch 65, iter 3000, loss: 2.622972, top_1: 0.610352, top_k: 0.826914, samples/s: 847.322 1613065853.5897713
train: epoch 65, iter 3100, loss: 2.493625, top_1: 0.607812, top_k: 0.825313, samples/s: 851.000 1613065883.671949
train: epoch 65, iter 3200, loss: 2.783664, top_1: 0.610078, top_k: 0.822930, samples/s: 846.398 1613065913.9178631
train: epoch 65, iter 3300, loss: 2.529000, top_1: 0.610625, top_k: 0.823789, samples/s: 849.107 1613065944.067193
train: epoch 65, iter 3400, loss: 2.543192, top_1: 0.610391, top_k: 0.823164, samples/s: 849.040 1613065974.2188041
train: epoch 65, iter 3500, loss: 2.552865, top_1: 0.610352, top_k: 0.823477, samples/s: 847.305 1613066004.4323294
train: epoch 65, iter 3600, loss: 2.623803, top_1: 0.607891, top_k: 0.824648, samples/s: 845.517 1613066034.7096543
train: epoch 65, iter 3700, loss: 2.746625, top_1: 0.608828, top_k: 0.820156, samples/s: 850.076 1613066064.8245163
train: epoch 65, iter 3800, loss: 2.504629, top_1: 0.612070, top_k: 0.825625, samples/s: 847.286 1613066095.0387247
train: epoch 65, iter 3900, loss: 2.617282, top_1: 0.609805, top_k: 0.821367, samples/s: 846.216 1613066125.2910264
train: epoch 65, iter 4000, loss: 2.527605, top_1: 0.612812, top_k: 0.823789, samples/s: 846.965 1613066155.5166392
train: epoch 65, iter 4100, loss: 2.510727, top_1: 0.609180, top_k: 0.824219, samples/s: 851.024 1613066185.5979617
train: epoch 65, iter 4200, loss: 2.633024, top_1: 0.607852, top_k: 0.822891, samples/s: 850.207 1613066215.708312
train: epoch 65, iter 4300, loss: 2.539003, top_1: 0.604922, top_k: 0.819375, samples/s: 844.776 1613066246.0122468
train: epoch 65, iter 4400, loss: 2.594753, top_1: 0.607266, top_k: 0.821953, samples/s: 847.178 1613066276.230171
train: epoch 65, iter 4500, loss: 2.545783, top_1: 0.611875, top_k: 0.827891, samples/s: 846.519 1613066306.4717164
train: epoch 65, iter 4600, loss: 2.621968, top_1: 0.609883, top_k: 0.822812, samples/s: 849.382 1613066336.6112537
train: epoch 65, iter 4700, loss: 2.697271, top_1: 0.612344, top_k: 0.826016, samples/s: 846.338 1613066366.8592567
train: epoch 65, iter 4800, loss: 2.739905, top_1: 0.617539, top_k: 0.827109, samples/s: 847.641 1613066397.0607362
train: epoch 65, iter 4900, loss: 2.618130, top_1: 0.607539, top_k: 0.821953, samples/s: 847.911 1613066427.2525504
train: epoch 65, iter 5000, loss: 2.670831, top_1: 0.611484, top_k: 0.824531, samples/s: 846.219 1613066457.5048432
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_65.
validation: epoch 65, iter 195, top_1: 0.656430, top_k: 0.871434, samples/s: 2393.240 1613066479.2547865
train: epoch 66, iter 100, loss: 2.487197, top_1: 0.619297, top_k: 0.837656, samples/s: 863.411 1613066530.2825046
train: epoch 66, iter 200, loss: 2.483973, top_1: 0.621914, top_k: 0.835234, samples/s: 868.250 1613066559.767348
train: epoch 66, iter 300, loss: 2.568923, top_1: 0.625781, top_k: 0.833398, samples/s: 850.693 1613066589.8601818
train: epoch 66, iter 400, loss: 2.574775, top_1: 0.615469, top_k: 0.830820, samples/s: 847.189 1613066620.077796
train: epoch 66, iter 500, loss: 2.492137, top_1: 0.619258, top_k: 0.831133, samples/s: 847.158 1613066650.2964406
train: epoch 66, iter 600, loss: 2.362518, top_1: 0.620352, top_k: 0.833828, samples/s: 848.416 1613066680.470393
train: epoch 66, iter 700, loss: 2.450724, top_1: 0.619102, top_k: 0.828516, samples/s: 844.673 1613066710.77799
train: epoch 66, iter 800, loss: 2.778890, top_1: 0.622617, top_k: 0.835234, samples/s: 844.597 1613066741.0882607
train: epoch 66, iter 900, loss: 2.610099, top_1: 0.616641, top_k: 0.829375, samples/s: 845.087 1613066771.3809845
train: epoch 66, iter 1000, loss: 2.441551, top_1: 0.616992, top_k: 0.828086, samples/s: 849.752 1613066801.507383
train: epoch 66, iter 1100, loss: 2.587358, top_1: 0.611797, top_k: 0.825625, samples/s: 845.585 1613066831.7823145
train: epoch 66, iter 1200, loss: 2.571883, top_1: 0.616055, top_k: 0.831250, samples/s: 844.597 1613066862.0925863
train: epoch 66, iter 1300, loss: 2.597322, top_1: 0.622070, top_k: 0.829180, samples/s: 847.781 1613066892.2890706
train: epoch 66, iter 1400, loss: 2.663201, top_1: 0.614688, top_k: 0.827422, samples/s: 849.440 1613066922.4266663
train: epoch 66, iter 1500, loss: 2.420309, top_1: 0.613516, top_k: 0.827227, samples/s: 845.717 1613066952.6968439
train: epoch 66, iter 1600, loss: 2.676028, top_1: 0.613984, top_k: 0.830898, samples/s: 848.549 1613066982.865974
train: epoch 66, iter 1700, loss: 2.660045, top_1: 0.612305, top_k: 0.827227, samples/s: 842.986 1613067013.234229
train: epoch 66, iter 1800, loss: 2.409561, top_1: 0.605313, top_k: 0.824727, samples/s: 846.236 1613067043.4857893
train: epoch 66, iter 1900, loss: 2.749241, top_1: 0.614844, top_k: 0.823398, samples/s: 845.284 1613067073.7714562
train: epoch 66, iter 2000, loss: 2.645700, top_1: 0.618867, top_k: 0.827852, samples/s: 847.710 1613067103.9704733
train: epoch 66, iter 2100, loss: 2.745651, top_1: 0.614180, top_k: 0.827617, samples/s: 849.329 1613067134.1119413
train: epoch 66, iter 2200, loss: 2.582704, top_1: 0.617812, top_k: 0.826523, samples/s: 845.186 1613067164.4011545
train: epoch 66, iter 2300, loss: 2.471157, top_1: 0.620313, top_k: 0.831406, samples/s: 844.897 1613067194.7006998
train: epoch 66, iter 2400, loss: 2.704814, top_1: 0.613125, top_k: 0.827031, samples/s: 847.851 1613067224.8946054
train: epoch 66, iter 2500, loss: 2.430026, top_1: 0.612617, top_k: 0.824414, samples/s: 846.397 1613067255.1404355
train: epoch 66, iter 2600, loss: 2.549402, top_1: 0.611875, top_k: 0.826289, samples/s: 846.642 1613067285.377519
train: epoch 66, iter 2700, loss: 2.571026, top_1: 0.607734, top_k: 0.826016, samples/s: 848.163 1613067315.5604146
train: epoch 66, iter 2800, loss: 2.440780, top_1: 0.617539, top_k: 0.826445, samples/s: 848.520 1613067345.7306514
train: epoch 66, iter 2900, loss: 2.349385, top_1: 0.612852, top_k: 0.830781, samples/s: 847.106 1613067375.951194
train: epoch 66, iter 3000, loss: 2.592707, top_1: 0.615586, top_k: 0.829453, samples/s: 849.158 1613067406.0986197
train: epoch 66, iter 3100, loss: 2.656091, top_1: 0.605547, top_k: 0.822187, samples/s: 842.864 1613067436.4713259
train: epoch 66, iter 3200, loss: 2.640648, top_1: 0.607930, top_k: 0.823047, samples/s: 847.809 1613067466.6668208
train: epoch 66, iter 3300, loss: 2.330941, top_1: 0.609219, top_k: 0.827266, samples/s: 848.562 1613067496.8354278
train: epoch 66, iter 3400, loss: 2.553494, top_1: 0.613281, top_k: 0.829102, samples/s: 845.487 1613067527.1139238
train: epoch 66, iter 3500, loss: 2.618444, top_1: 0.615430, top_k: 0.832305, samples/s: 846.126 1613067557.3699038
train: epoch 66, iter 3600, loss: 2.437491, top_1: 0.611680, top_k: 0.822812, samples/s: 847.981 1613067587.558759
train: epoch 66, iter 3700, loss: 2.422638, top_1: 0.609297, top_k: 0.823984, samples/s: 847.727 1613067617.7574148
train: epoch 66, iter 3800, loss: 2.604212, top_1: 0.603477, top_k: 0.825508, samples/s: 846.815 1613067647.9880831
train: epoch 66, iter 3900, loss: 2.339715, top_1: 0.612656, top_k: 0.822812, samples/s: 849.116 1613067678.1370463
train: epoch 66, iter 4000, loss: 2.483737, top_1: 0.608359, top_k: 0.822500, samples/s: 848.361 1613067708.3129597
train: epoch 66, iter 4100, loss: 2.498584, top_1: 0.607969, top_k: 0.825234, samples/s: 845.927 1613067738.5755906
train: epoch 66, iter 4200, loss: 2.746097, top_1: 0.611602, top_k: 0.828164, samples/s: 848.697 1613067768.7394009
train: epoch 66, iter 4300, loss: 2.514895, top_1: 0.607187, top_k: 0.824961, samples/s: 844.639 1613067799.0482583
train: epoch 66, iter 4400, loss: 2.652882, top_1: 0.614023, top_k: 0.824336, samples/s: 846.685 1613067829.2838228
train: epoch 66, iter 4500, loss: 2.511916, top_1: 0.605430, top_k: 0.822148, samples/s: 846.315 1613067859.5326371
train: epoch 66, iter 4600, loss: 2.506667, top_1: 0.609492, top_k: 0.825273, samples/s: 847.867 1613067889.7260191
train: epoch 66, iter 4700, loss: 2.560313, top_1: 0.610547, top_k: 0.825664, samples/s: 849.254 1613067919.8705475
train: epoch 66, iter 4800, loss: 2.573779, top_1: 0.606992, top_k: 0.821797, samples/s: 846.747 1613067950.1034336
train: epoch 66, iter 4900, loss: 2.655096, top_1: 0.609648, top_k: 0.822109, samples/s: 845.141 1613067980.394318
train: epoch 66, iter 5000, loss: 2.477347, top_1: 0.614688, top_k: 0.828008, samples/s: 845.689 1613068010.665403
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_66.
validation: epoch 66, iter 195, top_1: 0.655950, top_k: 0.872636, samples/s: 2450.656 1613068031.9509323
train: epoch 67, iter 100, loss: 2.512907, top_1: 0.630898, top_k: 0.838477, samples/s: 870.782 1613068081.4760485
train: epoch 67, iter 200, loss: 2.603728, top_1: 0.622656, top_k: 0.837383, samples/s: 868.144 1613068110.964502
train: epoch 67, iter 300, loss: 2.512475, top_1: 0.616133, top_k: 0.830898, samples/s: 850.441 1613068141.0663106
train: epoch 67, iter 400, loss: 2.716760, top_1: 0.612656, top_k: 0.828164, samples/s: 844.989 1613068171.3625262
train: epoch 67, iter 500, loss: 2.489420, top_1: 0.620625, top_k: 0.834102, samples/s: 846.806 1613068201.5937355
train: epoch 67, iter 600, loss: 2.601719, top_1: 0.615156, top_k: 0.830313, samples/s: 845.704 1613068231.8644345
train: epoch 67, iter 700, loss: 2.378875, top_1: 0.618828, top_k: 0.830430, samples/s: 846.761 1613068262.0972238
train: epoch 67, iter 800, loss: 2.551895, top_1: 0.617773, top_k: 0.830469, samples/s: 843.938 1613068292.4311693
train: epoch 67, iter 900, loss: 2.482860, top_1: 0.620391, top_k: 0.833906, samples/s: 843.243 1613068322.790158
train: epoch 67, iter 1000, loss: 2.633923, top_1: 0.618125, top_k: 0.829492, samples/s: 847.310 1613068353.0034852
train: epoch 67, iter 1100, loss: 2.497844, top_1: 0.619570, top_k: 0.834453, samples/s: 845.887 1613068383.2676232
train: epoch 67, iter 1200, loss: 2.584499, top_1: 0.618164, top_k: 0.830820, samples/s: 843.150 1613068413.6298811
train: epoch 67, iter 1300, loss: 2.543904, top_1: 0.617383, top_k: 0.826875, samples/s: 846.614 1613068443.8680108
train: epoch 67, iter 1400, loss: 2.666420, top_1: 0.614961, top_k: 0.825000, samples/s: 846.878 1613068474.0967298
train: epoch 67, iter 1500, loss: 2.570523, top_1: 0.617852, top_k: 0.831367, samples/s: 845.255 1613068504.383445
train: epoch 67, iter 1600, loss: 2.714736, top_1: 0.614570, top_k: 0.826641, samples/s: 848.786 1613068534.5441325
train: epoch 67, iter 1700, loss: 2.628764, top_1: 0.616523, top_k: 0.830547, samples/s: 844.845 1613068564.8455637
train: epoch 67, iter 1800, loss: 2.563661, top_1: 0.611406, top_k: 0.826641, samples/s: 849.826 1613068594.9694273
train: epoch 67, iter 1900, loss: 2.466966, top_1: 0.623086, top_k: 0.831484, samples/s: 845.622 1613068625.242965
train: epoch 67, iter 2000, loss: 2.595141, top_1: 0.616289, top_k: 0.830078, samples/s: 844.119 1613068655.5704591
train: epoch 67, iter 2100, loss: 2.749901, top_1: 0.616172, top_k: 0.826289, samples/s: 848.295 1613068685.7486365
train: epoch 67, iter 2200, loss: 2.654244, top_1: 0.612031, top_k: 0.828281, samples/s: 845.454 1613068716.0282357
train: epoch 67, iter 2300, loss: 2.743383, top_1: 0.617227, top_k: 0.829023, samples/s: 848.008 1613068746.2166283
train: epoch 67, iter 2400, loss: 2.566090, top_1: 0.609805, top_k: 0.828203, samples/s: 847.004 1613068776.4406872
train: epoch 67, iter 2500, loss: 2.646756, top_1: 0.614453, top_k: 0.828672, samples/s: 842.744 1613068806.8177426
train: epoch 67, iter 2600, loss: 2.500748, top_1: 0.614375, top_k: 0.825781, samples/s: 849.478 1613068836.9539042
train: epoch 67, iter 2700, loss: 2.662751, top_1: 0.611406, top_k: 0.825742, samples/s: 844.817 1613068867.2563233
train: epoch 67, iter 2800, loss: 2.692782, top_1: 0.612305, top_k: 0.829297, samples/s: 844.053 1613068897.586115
train: epoch 67, iter 2900, loss: 2.601402, top_1: 0.613086, top_k: 0.828281, samples/s: 845.815 1613068927.8527472
train: epoch 67, iter 3000, loss: 2.485785, top_1: 0.613750, top_k: 0.829141, samples/s: 846.530 1613068958.0938797
train: epoch 67, iter 3100, loss: 2.787858, top_1: 0.611680, top_k: 0.824883, samples/s: 847.010 1613068988.3178656
train: epoch 67, iter 3200, loss: 2.730397, top_1: 0.615625, top_k: 0.828516, samples/s: 846.985 1613069018.5427253
train: epoch 67, iter 3300, loss: 2.462306, top_1: 0.614219, top_k: 0.825859, samples/s: 844.020 1613069048.873783
train: epoch 67, iter 3400, loss: 2.629144, top_1: 0.610547, top_k: 0.825469, samples/s: 844.299 1613069079.1948032
train: epoch 67, iter 3500, loss: 2.599059, top_1: 0.604883, top_k: 0.821133, samples/s: 845.620 1613069109.4683561
train: epoch 67, iter 3600, loss: 2.532003, top_1: 0.618945, top_k: 0.832109, samples/s: 846.140 1613069139.7234507
train: epoch 67, iter 3700, loss: 2.764408, top_1: 0.614297, top_k: 0.827422, samples/s: 845.884 1613069169.9876578
train: epoch 67, iter 3800, loss: 2.685637, top_1: 0.610625, top_k: 0.827266, samples/s: 841.593 1613069200.4061725
train: epoch 67, iter 3900, loss: 2.664336, top_1: 0.609727, top_k: 0.822383, samples/s: 848.402 1613069230.5804906
train: epoch 67, iter 4000, loss: 2.669844, top_1: 0.612344, top_k: 0.829414, samples/s: 843.478 1613069260.9311185
train: epoch 67, iter 4100, loss: 2.498033, top_1: 0.609727, top_k: 0.824766, samples/s: 844.424 1613069291.2475815
train: epoch 67, iter 4200, loss: 2.566977, top_1: 0.612305, top_k: 0.825977, samples/s: 847.059 1613069321.469835
train: epoch 67, iter 4300, loss: 2.671754, top_1: 0.613398, top_k: 0.824063, samples/s: 845.096 1613069351.7621987
train: epoch 67, iter 4400, loss: 2.663723, top_1: 0.612422, top_k: 0.824805, samples/s: 846.592 1613069382.0011766
train: epoch 67, iter 4500, loss: 2.790393, top_1: 0.615000, top_k: 0.826328, samples/s: 843.054 1613069412.3668694
train: epoch 67, iter 4600, loss: 2.410263, top_1: 0.608555, top_k: 0.825234, samples/s: 844.849 1613069442.6681604
train: epoch 67, iter 4700, loss: 2.758785, top_1: 0.608984, top_k: 0.826094, samples/s: 845.674 1613069472.9398546
train: epoch 67, iter 4800, loss: 2.494422, top_1: 0.609023, top_k: 0.824297, samples/s: 844.239 1613069503.2630782
train: epoch 67, iter 4900, loss: 2.452086, top_1: 0.611602, top_k: 0.823555, samples/s: 845.581 1613069533.538117
train: epoch 67, iter 5000, loss: 2.539432, top_1: 0.611914, top_k: 0.826602, samples/s: 848.282 1613069563.7167711
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_67.
validation: epoch 67, iter 195, top_1: 0.660056, top_k: 0.877724, samples/s: 2412.066 1613069585.2783995
train: epoch 68, iter 100, loss: 2.548668, top_1: 0.621133, top_k: 0.832695, samples/s: 868.949 1613069635.2203472
train: epoch 68, iter 200, loss: 2.590318, top_1: 0.617656, top_k: 0.834531, samples/s: 866.004 1613069664.781397
train: epoch 68, iter 300, loss: 2.662668, top_1: 0.624219, top_k: 0.833516, samples/s: 851.253 1613069694.8546855
train: epoch 68, iter 400, loss: 2.633096, top_1: 0.619687, top_k: 0.832070, samples/s: 846.889 1613069725.083009
train: epoch 68, iter 500, loss: 2.500637, top_1: 0.628437, top_k: 0.837500, samples/s: 843.554 1613069755.4308126
train: epoch 68, iter 600, loss: 2.629110, top_1: 0.628906, top_k: 0.838203, samples/s: 846.485 1613069785.6735196
train: epoch 68, iter 700, loss: 2.596544, top_1: 0.620195, top_k: 0.833672, samples/s: 846.253 1613069815.9244828
train: epoch 68, iter 800, loss: 2.629881, top_1: 0.611641, top_k: 0.826602, samples/s: 844.243 1613069846.2475588
train: epoch 68, iter 900, loss: 2.472820, top_1: 0.625352, top_k: 0.835508, samples/s: 844.837 1613069876.5491552
train: epoch 68, iter 1000, loss: 2.590190, top_1: 0.613711, top_k: 0.832109, samples/s: 842.945 1613069906.9189434
train: epoch 68, iter 1100, loss: 2.508089, top_1: 0.621719, top_k: 0.828867, samples/s: 844.538 1613069937.2320516
train: epoch 68, iter 1200, loss: 2.644691, top_1: 0.617305, top_k: 0.828281, samples/s: 847.063 1613069967.4534323
train: epoch 68, iter 1300, loss: 2.740226, top_1: 0.617773, top_k: 0.831289, samples/s: 843.373 1613069997.808226
train: epoch 68, iter 1400, loss: 2.619340, top_1: 0.614844, top_k: 0.828438, samples/s: 844.413 1613070028.1246722
train: epoch 68, iter 1500, loss: 2.688183, top_1: 0.619180, top_k: 0.832422, samples/s: 845.186 1613070058.4139152
train: epoch 68, iter 1600, loss: 2.682942, top_1: 0.620039, top_k: 0.829609, samples/s: 843.205 1613070088.774239
train: epoch 68, iter 1700, loss: 2.461318, top_1: 0.619844, top_k: 0.832578, samples/s: 846.158 1613070119.02866
train: epoch 68, iter 1800, loss: 2.672678, top_1: 0.622188, top_k: 0.831523, samples/s: 846.301 1613070149.2778645
train: epoch 68, iter 1900, loss: 2.626316, top_1: 0.622266, top_k: 0.829844, samples/s: 847.098 1613070179.4986947
train: epoch 68, iter 2000, loss: 2.542056, top_1: 0.614609, top_k: 0.828633, samples/s: 844.682 1613070209.80597
train: epoch 68, iter 2100, loss: 2.618508, top_1: 0.614688, top_k: 0.827031, samples/s: 844.810 1613070240.1087003
train: epoch 68, iter 2200, loss: 2.501084, top_1: 0.619609, top_k: 0.831289, samples/s: 845.713 1613070270.3790195
train: epoch 68, iter 2300, loss: 2.510948, top_1: 0.617227, top_k: 0.828203, samples/s: 847.626 1613070300.5810072
train: epoch 68, iter 2400, loss: 2.627432, top_1: 0.617578, top_k: 0.829180, samples/s: 842.841 1613070330.9544275
train: epoch 68, iter 2500, loss: 2.686088, top_1: 0.613672, top_k: 0.827070, samples/s: 847.521 1613070361.1601303
train: epoch 68, iter 2600, loss: 2.626484, top_1: 0.620625, top_k: 0.832969, samples/s: 847.070 1613070391.3819818
train: epoch 68, iter 2700, loss: 2.519755, top_1: 0.610234, top_k: 0.824102, samples/s: 847.616 1613070421.5844378
train: epoch 68, iter 2800, loss: 2.687172, top_1: 0.619766, top_k: 0.830313, samples/s: 843.020 1613070451.9514258
train: epoch 68, iter 2900, loss: 2.529888, top_1: 0.615273, top_k: 0.828086, samples/s: 846.272 1613070482.2016726
train: epoch 68, iter 3000, loss: 2.593564, top_1: 0.612344, top_k: 0.827383, samples/s: 846.655 1613070512.4384139
train: epoch 68, iter 3100, loss: 2.659916, top_1: 0.609961, top_k: 0.821914, samples/s: 848.608 1613070542.605338
train: epoch 68, iter 3200, loss: 2.508174, top_1: 0.618867, top_k: 0.832461, samples/s: 844.875 1613070572.9057827
train: epoch 68, iter 3300, loss: 2.661529, top_1: 0.617070, top_k: 0.830625, samples/s: 846.205 1613070603.1583855
train: epoch 68, iter 3400, loss: 2.479393, top_1: 0.614883, top_k: 0.826641, samples/s: 846.786 1613070633.3904405
train: epoch 68, iter 3500, loss: 2.771831, top_1: 0.613555, top_k: 0.827305, samples/s: 843.370 1613070663.7447731
train: epoch 68, iter 3600, loss: 2.568524, top_1: 0.619766, top_k: 0.829297, samples/s: 845.312 1613070694.0294812
train: epoch 68, iter 3700, loss: 2.604383, top_1: 0.616914, top_k: 0.832148, samples/s: 847.198 1613070724.2466998
train: epoch 68, iter 3800, loss: 2.749236, top_1: 0.616563, top_k: 0.828945, samples/s: 846.657 1613070754.4832368
train: epoch 68, iter 3900, loss: 2.541404, top_1: 0.615977, top_k: 0.829531, samples/s: 845.141 1613070784.7740533
train: epoch 68, iter 4000, loss: 2.432676, top_1: 0.611602, top_k: 0.825703, samples/s: 843.151 1613070815.136301
train: epoch 68, iter 4100, loss: 2.675871, top_1: 0.609219, top_k: 0.823828, samples/s: 845.344 1613070845.4198973
train: epoch 68, iter 4200, loss: 2.716824, top_1: 0.613164, top_k: 0.827969, samples/s: 846.039 1613070875.678495
train: epoch 68, iter 4300, loss: 2.705894, top_1: 0.613750, top_k: 0.826445, samples/s: 845.537 1613070905.9551585
train: epoch 68, iter 4400, loss: 2.521542, top_1: 0.605117, top_k: 0.821992, samples/s: 846.231 1613070936.2069216
train: epoch 68, iter 4500, loss: 2.644351, top_1: 0.613984, top_k: 0.824805, samples/s: 847.836 1613070966.4014378
train: epoch 68, iter 4600, loss: 2.734886, top_1: 0.615273, top_k: 0.826328, samples/s: 842.956 1613070996.7707562
train: epoch 68, iter 4700, loss: 2.584118, top_1: 0.613320, top_k: 0.825547, samples/s: 847.805 1613071026.9663613
train: epoch 68, iter 4800, loss: 2.663465, top_1: 0.610625, top_k: 0.826289, samples/s: 843.874 1613071057.3027558
train: epoch 68, iter 4900, loss: 2.627540, top_1: 0.608906, top_k: 0.822852, samples/s: 846.139 1613071087.557789
train: epoch 68, iter 5000, loss: 2.561803, top_1: 0.613672, top_k: 0.832266, samples/s: 847.983 1613071117.7470932
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_68.
validation: epoch 68, iter 195, top_1: 0.660837, top_k: 0.874760, samples/s: 2427.323 1613071139.2041273
train: epoch 69, iter 100, loss: 2.683350, top_1: 0.632656, top_k: 0.841406, samples/s: 870.894 1613071189.5045986
train: epoch 69, iter 200, loss: 2.683112, top_1: 0.636055, top_k: 0.845234, samples/s: 866.661 1613071219.0432189
train: epoch 69, iter 300, loss: 2.610829, top_1: 0.621250, top_k: 0.834414, samples/s: 848.225 1613071249.2239265
train: epoch 69, iter 400, loss: 2.408468, top_1: 0.625469, top_k: 0.832187, samples/s: 846.972 1613071279.449321
train: epoch 69, iter 500, loss: 2.475495, top_1: 0.623281, top_k: 0.833750, samples/s: 844.024 1613071309.7800658
train: epoch 69, iter 600, loss: 2.456723, top_1: 0.622969, top_k: 0.834375, samples/s: 843.119 1613071340.1436079
train: epoch 69, iter 700, loss: 2.612995, top_1: 0.618477, top_k: 0.831836, samples/s: 847.643 1613071370.3449013
train: epoch 69, iter 800, loss: 2.435534, top_1: 0.620898, top_k: 0.832578, samples/s: 844.276 1613071400.6668534
train: epoch 69, iter 900, loss: 2.491717, top_1: 0.621680, top_k: 0.831211, samples/s: 843.270 1613071431.0248754
train: epoch 69, iter 1000, loss: 2.594912, top_1: 0.621836, top_k: 0.832578, samples/s: 844.073 1613071461.3538854
train: epoch 69, iter 1100, loss: 2.677546, top_1: 0.616680, top_k: 0.832383, samples/s: 844.138 1613071491.6807368
train: epoch 69, iter 1200, loss: 2.686556, top_1: 0.618555, top_k: 0.829961, samples/s: 845.952 1613071521.9425275
train: epoch 69, iter 1300, loss: 2.504197, top_1: 0.621641, top_k: 0.834258, samples/s: 842.351 1613071552.3336804
train: epoch 69, iter 1400, loss: 2.507249, top_1: 0.618359, top_k: 0.830859, samples/s: 849.061 1613071582.4845326
train: epoch 69, iter 1500, loss: 2.579447, top_1: 0.620352, top_k: 0.831602, samples/s: 839.391 1613071612.9828503
train: epoch 69, iter 1600, loss: 2.382067, top_1: 0.611172, top_k: 0.830547, samples/s: 846.599 1613071643.221518
train: epoch 69, iter 1700, loss: 2.748000, top_1: 0.621758, top_k: 0.833867, samples/s: 844.913 1613071673.5204513
train: epoch 69, iter 1800, loss: 2.659002, top_1: 0.614141, top_k: 0.825586, samples/s: 843.695 1613071703.8632033
train: epoch 69, iter 1900, loss: 2.531022, top_1: 0.615195, top_k: 0.827852, samples/s: 847.028 1613071734.0866024
train: epoch 69, iter 2000, loss: 2.756469, top_1: 0.625586, top_k: 0.832578, samples/s: 842.867 1613071764.4591198
train: epoch 69, iter 2100, loss: 2.580758, top_1: 0.620859, top_k: 0.829531, samples/s: 847.342 1613071794.671268
train: epoch 69, iter 2200, loss: 2.577095, top_1: 0.617070, top_k: 0.826953, samples/s: 846.482 1613071824.9140542
train: epoch 69, iter 2300, loss: 2.578248, top_1: 0.609062, top_k: 0.825117, samples/s: 844.507 1613071855.2275488
train: epoch 69, iter 2400, loss: 2.504929, top_1: 0.613437, top_k: 0.829297, samples/s: 846.994 1613071885.4521453
train: epoch 69, iter 2500, loss: 2.615463, top_1: 0.615586, top_k: 0.829961, samples/s: 842.638 1613071915.8329105
train: epoch 69, iter 2600, loss: 2.578504, top_1: 0.618867, top_k: 0.831016, samples/s: 847.427 1613071946.0419536
train: epoch 69, iter 2700, loss: 2.612948, top_1: 0.615508, top_k: 0.831719, samples/s: 844.974 1613071976.3387666
train: epoch 69, iter 2800, loss: 2.327039, top_1: 0.617891, top_k: 0.834023, samples/s: 848.450 1613072006.5114088
train: epoch 69, iter 2900, loss: 2.702247, top_1: 0.614492, top_k: 0.825977, samples/s: 844.061 1613072036.840994
train: epoch 69, iter 3000, loss: 2.515482, top_1: 0.607812, top_k: 0.824766, samples/s: 846.597 1613072067.0797327
train: epoch 69, iter 3100, loss: 2.607215, top_1: 0.611367, top_k: 0.825742, samples/s: 846.996 1613072097.3041818
train: epoch 69, iter 3200, loss: 2.528859, top_1: 0.613594, top_k: 0.828164, samples/s: 844.672 1613072127.611797
train: epoch 69, iter 3300, loss: 2.516265, top_1: 0.613750, top_k: 0.825820, samples/s: 845.906 1613072157.875249
train: epoch 69, iter 3400, loss: 2.725841, top_1: 0.617266, top_k: 0.833711, samples/s: 844.582 1613072188.18605
train: epoch 69, iter 3500, loss: 2.454916, top_1: 0.616250, top_k: 0.830859, samples/s: 849.219 1613072218.3313491
train: epoch 69, iter 3600, loss: 2.790657, top_1: 0.617070, top_k: 0.827266, samples/s: 844.956 1613072248.6288419
train: epoch 69, iter 3700, loss: 2.727602, top_1: 0.608945, top_k: 0.825078, samples/s: 846.106 1613072278.8850026
train: epoch 69, iter 3800, loss: 2.521671, top_1: 0.617422, top_k: 0.830039, samples/s: 844.070 1613072309.2142453
train: epoch 69, iter 3900, loss: 2.335092, top_1: 0.616602, top_k: 0.828281, samples/s: 848.187 1613072339.396356
train: epoch 69, iter 4000, loss: 2.642830, top_1: 0.617148, top_k: 0.828984, samples/s: 844.046 1613072369.72645
train: epoch 69, iter 4100, loss: 2.571654, top_1: 0.620547, top_k: 0.829375, samples/s: 848.941 1613072399.8815858
train: epoch 69, iter 4200, loss: 2.500885, top_1: 0.614297, top_k: 0.828633, samples/s: 843.371 1613072430.2360172
train: epoch 69, iter 4300, loss: 2.627521, top_1: 0.614805, top_k: 0.829141, samples/s: 847.073 1613072460.4577239
train: epoch 69, iter 4400, loss: 2.431891, top_1: 0.615938, top_k: 0.829258, samples/s: 847.832 1613072490.6524186
train: epoch 69, iter 4500, loss: 2.698788, top_1: 0.616797, top_k: 0.828320, samples/s: 844.275 1613072520.9742908
train: epoch 69, iter 4600, loss: 2.379099, top_1: 0.609570, top_k: 0.824688, samples/s: 846.236 1613072551.2259083
train: epoch 69, iter 4700, loss: 2.415271, top_1: 0.619648, top_k: 0.825078, samples/s: 844.355 1613072581.5447986
train: epoch 69, iter 4800, loss: 2.502655, top_1: 0.614453, top_k: 0.827969, samples/s: 849.063 1613072611.6957128
train: epoch 69, iter 4900, loss: 2.609964, top_1: 0.608828, top_k: 0.826836, samples/s: 846.481 1613072641.9386454
train: epoch 69, iter 5000, loss: 2.382502, top_1: 0.613125, top_k: 0.827617, samples/s: 842.265 1613072672.332868
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_69.
validation: epoch 69, iter 195, top_1: 0.649880, top_k: 0.868650, samples/s: 2455.240 1613072693.5629966
train: epoch 70, iter 100, loss: 2.613435, top_1: 0.633398, top_k: 0.841797, samples/s: 871.351 1613072743.5970786
train: epoch 70, iter 200, loss: 2.571386, top_1: 0.625781, top_k: 0.833828, samples/s: 866.946 1613072773.1259599
train: epoch 70, iter 300, loss: 2.588531, top_1: 0.631445, top_k: 0.837852, samples/s: 849.279 1613072803.269259
train: epoch 70, iter 400, loss: 2.722562, top_1: 0.622422, top_k: 0.835898, samples/s: 843.474 1613072833.6198356
train: epoch 70, iter 500, loss: 2.560335, top_1: 0.623047, top_k: 0.834492, samples/s: 844.852 1613072863.9210367
train: epoch 70, iter 600, loss: 2.795916, top_1: 0.623789, top_k: 0.834258, samples/s: 842.873 1613072894.2933643
train: epoch 70, iter 700, loss: 2.453747, top_1: 0.625742, top_k: 0.836992, samples/s: 844.649 1613072924.6017408
train: epoch 70, iter 800, loss: 2.809318, top_1: 0.624570, top_k: 0.833867, samples/s: 844.439 1613072954.9176955
train: epoch 70, iter 900, loss: 2.519269, top_1: 0.623516, top_k: 0.835391, samples/s: 843.892 1613072985.2534244
train: epoch 70, iter 1000, loss: 2.596904, top_1: 0.620078, top_k: 0.831602, samples/s: 844.709 1613073015.5596368
train: epoch 70, iter 1100, loss: 2.514871, top_1: 0.622148, top_k: 0.833867, samples/s: 844.978 1613073045.856377
train: epoch 70, iter 1200, loss: 2.688443, top_1: 0.620273, top_k: 0.835742, samples/s: 843.265 1613073076.2145488
train: epoch 70, iter 1300, loss: 2.829540, top_1: 0.620273, top_k: 0.833320, samples/s: 845.614 1613073106.4883568
train: epoch 70, iter 1400, loss: 2.631651, top_1: 0.621250, top_k: 0.833438, samples/s: 843.469 1613073136.8391807
train: epoch 70, iter 1500, loss: 2.736326, top_1: 0.615664, top_k: 0.831289, samples/s: 846.569 1613073167.07884
train: epoch 70, iter 1600, loss: 2.499162, top_1: 0.622266, top_k: 0.828711, samples/s: 845.728 1613073197.34872
train: epoch 70, iter 1700, loss: 2.588142, top_1: 0.620586, top_k: 0.833750, samples/s: 845.494 1613073227.626815
train: epoch 70, iter 1800, loss: 2.477553, top_1: 0.622344, top_k: 0.836875, samples/s: 849.777 1613073257.752416
train: epoch 70, iter 1900, loss: 2.473235, top_1: 0.612461, top_k: 0.828008, samples/s: 842.940 1613073288.1222389
train: epoch 70, iter 2000, loss: 2.655447, top_1: 0.617461, top_k: 0.826758, samples/s: 849.629 1613073318.2530787
train: epoch 70, iter 2100, loss: 2.640878, top_1: 0.621641, top_k: 0.832227, samples/s: 847.378 1613073348.4638958
train: epoch 70, iter 2200, loss: 2.654709, top_1: 0.621250, top_k: 0.831172, samples/s: 842.646 1613073378.8444586
train: epoch 70, iter 2300, loss: 2.564467, top_1: 0.617930, top_k: 0.828672, samples/s: 849.156 1613073408.9920096
train: epoch 70, iter 2400, loss: 2.738797, top_1: 0.620430, top_k: 0.833555, samples/s: 843.562 1613073439.3395486
train: epoch 70, iter 2500, loss: 2.553126, top_1: 0.617930, top_k: 0.830469, samples/s: 847.504 1613073469.5458272
train: epoch 70, iter 2600, loss: 2.434083, top_1: 0.626836, top_k: 0.834844, samples/s: 843.266 1613073499.9040344
train: epoch 70, iter 2700, loss: 2.551368, top_1: 0.621055, top_k: 0.833203, samples/s: 847.951 1613073530.0945075
train: epoch 70, iter 2800, loss: 2.666955, top_1: 0.615508, top_k: 0.827734, samples/s: 846.510 1613073560.336351
train: epoch 70, iter 2900, loss: 2.661543, top_1: 0.616680, top_k: 0.826992, samples/s: 845.005 1613073590.6320024
train: epoch 70, iter 3000, loss: 2.523474, top_1: 0.614727, top_k: 0.828359, samples/s: 845.476 1613073620.9107945
train: epoch 70, iter 3100, loss: 2.263897, top_1: 0.617422, top_k: 0.830117, samples/s: 846.895 1613073651.1388364
train: epoch 70, iter 3200, loss: 2.431631, top_1: 0.615000, top_k: 0.826914, samples/s: 844.686 1613073681.4459503
train: epoch 70, iter 3300, loss: 2.539521, top_1: 0.619687, top_k: 0.830156, samples/s: 847.002 1613073711.6702778
train: epoch 70, iter 3400, loss: 2.481013, top_1: 0.616797, top_k: 0.831289, samples/s: 847.603 1613073741.873039
train: epoch 70, iter 3500, loss: 2.675140, top_1: 0.615039, top_k: 0.829531, samples/s: 843.726 1613073772.2146964
train: epoch 70, iter 3600, loss: 2.470767, top_1: 0.617109, top_k: 0.830391, samples/s: 847.726 1613073802.413074
train: epoch 70, iter 3700, loss: 2.426136, top_1: 0.612187, top_k: 0.828906, samples/s: 846.085 1613073832.67015
train: epoch 70, iter 3800, loss: 2.537328, top_1: 0.615898, top_k: 0.829297, samples/s: 843.873 1613073863.006462
train: epoch 70, iter 3900, loss: 2.486454, top_1: 0.615703, top_k: 0.831602, samples/s: 844.090 1613073893.3349295
train: epoch 70, iter 4000, loss: 2.726944, top_1: 0.615664, top_k: 0.826953, samples/s: 847.200 1613073923.5521526
train: epoch 70, iter 4100, loss: 2.814029, top_1: 0.620430, top_k: 0.827266, samples/s: 843.584 1613073953.8988028
train: epoch 70, iter 4200, loss: 2.652859, top_1: 0.619297, top_k: 0.831406, samples/s: 845.669 1613073984.1706898
train: epoch 70, iter 4300, loss: 2.678944, top_1: 0.614023, top_k: 0.829570, samples/s: 846.742 1613074014.4043047
train: epoch 70, iter 4400, loss: 2.678920, top_1: 0.608359, top_k: 0.821250, samples/s: 845.169 1613074044.6939917
train: epoch 70, iter 4500, loss: 2.565647, top_1: 0.617344, top_k: 0.831094, samples/s: 844.619 1613074075.0036054
train: epoch 70, iter 4600, loss: 2.598281, top_1: 0.618047, top_k: 0.833828, samples/s: 846.353 1613074105.2509322
train: epoch 70, iter 4700, loss: 2.540387, top_1: 0.612031, top_k: 0.824180, samples/s: 846.950 1613074135.4770644
train: epoch 70, iter 4800, loss: 2.727041, top_1: 0.620078, top_k: 0.830508, samples/s: 844.220 1613074165.8009064
train: epoch 70, iter 4900, loss: 2.502014, top_1: 0.611406, top_k: 0.828086, samples/s: 845.675 1613074196.072671
train: epoch 70, iter 5000, loss: 2.300254, top_1: 0.618164, top_k: 0.834258, samples/s: 847.824 1613074226.2675617
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_70.
validation: epoch 70, iter 195, top_1: 0.664343, top_k: 0.876062, samples/s: 2413.871 1613074247.8350997
train: epoch 71, iter 100, loss: 2.630692, top_1: 0.631367, top_k: 0.841367, samples/s: 871.460 1613074297.7878458
train: epoch 71, iter 200, loss: 2.466548, top_1: 0.623320, top_k: 0.834492, samples/s: 868.053 1613074327.2790902
train: epoch 71, iter 300, loss: 2.436527, top_1: 0.625039, top_k: 0.835703, samples/s: 850.041 1613074357.3953524
train: epoch 71, iter 400, loss: 2.547968, top_1: 0.632344, top_k: 0.836445, samples/s: 841.827 1613074387.8053818
train: epoch 71, iter 500, loss: 2.503827, top_1: 0.631602, top_k: 0.841992, samples/s: 845.051 1613074418.0993288
train: epoch 71, iter 600, loss: 2.391684, top_1: 0.624727, top_k: 0.835195, samples/s: 840.933 1613074448.541806
train: epoch 71, iter 700, loss: 2.453503, top_1: 0.625000, top_k: 0.836523, samples/s: 847.362 1613074478.7531366
train: epoch 71, iter 800, loss: 2.513535, top_1: 0.623086, top_k: 0.833320, samples/s: 842.831 1613074509.1269877
train: epoch 71, iter 900, loss: 2.502808, top_1: 0.623437, top_k: 0.832539, samples/s: 844.354 1613074539.4460719
train: epoch 71, iter 1000, loss: 2.529127, top_1: 0.622148, top_k: 0.833672, samples/s: 844.705 1613074569.75248
train: epoch 71, iter 1100, loss: 2.568388, top_1: 0.624453, top_k: 0.835781, samples/s: 844.110 1613074600.0805876
train: epoch 71, iter 1200, loss: 2.552267, top_1: 0.634180, top_k: 0.839141, samples/s: 844.305 1613074630.4011202
train: epoch 71, iter 1300, loss: 2.658783, top_1: 0.619844, top_k: 0.833125, samples/s: 845.107 1613074660.693371
train: epoch 71, iter 1400, loss: 2.724310, top_1: 0.621172, top_k: 0.836797, samples/s: 844.272 1613074691.0150619
train: epoch 71, iter 1500, loss: 2.503302, top_1: 0.620977, top_k: 0.831836, samples/s: 844.048 1613074721.345154
train: epoch 71, iter 1600, loss: 2.648745, top_1: 0.621680, top_k: 0.832148, samples/s: 846.808 1613074751.5762196
train: epoch 71, iter 1700, loss: 2.482073, top_1: 0.622383, top_k: 0.836211, samples/s: 842.735 1613074781.9535668
train: epoch 71, iter 1800, loss: 2.653859, top_1: 0.619453, top_k: 0.831758, samples/s: 842.831 1613074812.3274362
train: epoch 71, iter 1900, loss: 2.558978, top_1: 0.622930, top_k: 0.834688, samples/s: 847.044 1613074842.5500662
train: epoch 71, iter 2000, loss: 2.752551, top_1: 0.623242, top_k: 0.838086, samples/s: 846.454 1613074872.7939403
train: epoch 71, iter 2100, loss: 2.508561, top_1: 0.623789, top_k: 0.831172, samples/s: 842.840 1613074903.1674047
train: epoch 71, iter 2200, loss: 2.622387, top_1: 0.623281, top_k: 0.831797, samples/s: 847.710 1613074933.366467
train: epoch 71, iter 2300, loss: 2.555830, top_1: 0.618633, top_k: 0.830195, samples/s: 844.103 1613074963.6944754
train: epoch 71, iter 2400, loss: 2.690028, top_1: 0.621094, top_k: 0.831680, samples/s: 843.970 1613074994.0273755
train: epoch 71, iter 2500, loss: 2.376567, top_1: 0.619219, top_k: 0.833086, samples/s: 849.007 1613075024.1801727
train: epoch 71, iter 2600, loss: 2.521687, top_1: 0.619336, top_k: 0.830156, samples/s: 845.861 1613075054.445216
train: epoch 71, iter 2700, loss: 2.590039, top_1: 0.614219, top_k: 0.828906, samples/s: 840.682 1613075084.8966537
train: epoch 71, iter 2800, loss: 2.530411, top_1: 0.621289, top_k: 0.831016, samples/s: 851.144 1613075114.9738739
train: epoch 71, iter 2900, loss: 2.500333, top_1: 0.621523, top_k: 0.833945, samples/s: 843.141 1613075145.3365502
train: epoch 71, iter 3000, loss: 2.516706, top_1: 0.621133, top_k: 0.831367, samples/s: 846.429 1613075175.5812097
train: epoch 71, iter 3100, loss: 2.622471, top_1: 0.620078, top_k: 0.834141, samples/s: 843.448 1613075205.9327977
train: epoch 71, iter 3200, loss: 2.580549, top_1: 0.616602, top_k: 0.829648, samples/s: 846.992 1613075236.1574597
train: epoch 71, iter 3300, loss: 2.691702, top_1: 0.618672, top_k: 0.832656, samples/s: 844.377 1613075266.475645
train: epoch 71, iter 3400, loss: 2.712509, top_1: 0.612422, top_k: 0.826641, samples/s: 844.540 1613075296.787963
train: epoch 71, iter 3500, loss: 2.599923, top_1: 0.610938, top_k: 0.824297, samples/s: 846.790 1613075327.019851
train: epoch 71, iter 3600, loss: 2.607561, top_1: 0.619805, top_k: 0.827969, samples/s: 843.703 1613075357.3622127
train: epoch 71, iter 3700, loss: 2.704775, top_1: 0.608867, top_k: 0.825156, samples/s: 847.090 1613075387.5833635
train: epoch 71, iter 3800, loss: 2.436908, top_1: 0.619297, top_k: 0.831211, samples/s: 845.449 1613075417.8630316
train: epoch 71, iter 3900, loss: 2.516928, top_1: 0.616328, top_k: 0.832109, samples/s: 846.295 1613075448.1125221
train: epoch 71, iter 4000, loss: 2.504746, top_1: 0.615273, top_k: 0.832695, samples/s: 847.338 1613075478.324822
train: epoch 71, iter 4100, loss: 2.582163, top_1: 0.619141, top_k: 0.833242, samples/s: 845.823 1613075508.5912662
train: epoch 71, iter 4200, loss: 2.628848, top_1: 0.617266, top_k: 0.825234, samples/s: 845.094 1613075538.883672
train: epoch 71, iter 4300, loss: 2.809534, top_1: 0.615703, top_k: 0.830430, samples/s: 849.033 1613075569.0356264
train: epoch 71, iter 4400, loss: 2.620435, top_1: 0.614805, top_k: 0.828398, samples/s: 843.356 1613075599.3905735
train: epoch 71, iter 4500, loss: 2.626303, top_1: 0.619570, top_k: 0.830234, samples/s: 843.690 1613075629.733484
train: epoch 71, iter 4600, loss: 2.462476, top_1: 0.613906, top_k: 0.827148, samples/s: 847.235 1613075659.949453
train: epoch 71, iter 4700, loss: 2.341786, top_1: 0.618164, top_k: 0.828203, samples/s: 845.675 1613075690.2210703
train: epoch 71, iter 4800, loss: 2.759262, top_1: 0.617578, top_k: 0.830547, samples/s: 846.047 1613075720.4795756
train: epoch 71, iter 4900, loss: 2.518951, top_1: 0.616992, top_k: 0.824336, samples/s: 845.939 1613075750.7417958
train: epoch 71, iter 5000, loss: 2.297264, top_1: 0.617773, top_k: 0.828906, samples/s: 846.865 1613075780.97094
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_71.
validation: epoch 71, iter 195, top_1: 0.663101, top_k: 0.876062, samples/s: 2465.996 1613075802.1036112
train: epoch 72, iter 100, loss: 2.377635, top_1: 0.628789, top_k: 0.840117, samples/s: 870.541 1613075858.0730038
train: epoch 72, iter 200, loss: 2.423256, top_1: 0.632969, top_k: 0.842031, samples/s: 868.476 1613075887.5498202
train: epoch 72, iter 300, loss: 2.476124, top_1: 0.621641, top_k: 0.839336, samples/s: 850.930 1613075917.6345134
train: epoch 72, iter 400, loss: 2.619280, top_1: 0.631445, top_k: 0.839883, samples/s: 845.151 1613075947.9251049
train: epoch 72, iter 500, loss: 2.649390, top_1: 0.626289, top_k: 0.837148, samples/s: 848.702 1613075978.0887158
train: epoch 72, iter 600, loss: 2.677027, top_1: 0.625117, top_k: 0.836992, samples/s: 843.185 1613076008.4497893
train: epoch 72, iter 700, loss: 2.442926, top_1: 0.627578, top_k: 0.836055, samples/s: 843.611 1613076038.7955258
train: epoch 72, iter 800, loss: 2.843522, top_1: 0.626211, top_k: 0.835977, samples/s: 845.690 1613076069.0666354
train: epoch 72, iter 900, loss: 2.410434, top_1: 0.630078, top_k: 0.836914, samples/s: 844.697 1613076099.3734775
train: epoch 72, iter 1000, loss: 2.603719, top_1: 0.626172, top_k: 0.837578, samples/s: 848.477 1613076129.545178
train: epoch 72, iter 1100, loss: 2.644758, top_1: 0.627734, top_k: 0.831680, samples/s: 843.462 1613076159.8961499
train: epoch 72, iter 1200, loss: 2.584428, top_1: 0.624883, top_k: 0.833594, samples/s: 850.283 1613076190.0037935
train: epoch 72, iter 1300, loss: 2.432616, top_1: 0.627773, top_k: 0.837148, samples/s: 845.889 1613076220.2677732
train: epoch 72, iter 1400, loss: 2.571635, top_1: 0.628984, top_k: 0.836758, samples/s: 847.018 1613076250.4915419
train: epoch 72, iter 1500, loss: 2.559563, top_1: 0.624961, top_k: 0.837617, samples/s: 844.412 1613076280.8084288
train: epoch 72, iter 1600, loss: 2.481423, top_1: 0.627031, top_k: 0.836445, samples/s: 846.388 1613076311.0546901
train: epoch 72, iter 1700, loss: 2.591460, top_1: 0.623750, top_k: 0.832617, samples/s: 844.413 1613076341.3716013
train: epoch 72, iter 1800, loss: 2.598055, top_1: 0.623789, top_k: 0.833984, samples/s: 842.262 1613076371.765874
train: epoch 72, iter 1900, loss: 2.448766, top_1: 0.626875, top_k: 0.836523, samples/s: 848.899 1613076401.9226623
train: epoch 72, iter 2000, loss: 2.541637, top_1: 0.625273, top_k: 0.835742, samples/s: 846.495 1613076432.1650326
train: epoch 72, iter 2100, loss: 2.523926, top_1: 0.620234, top_k: 0.832187, samples/s: 843.883 1613076462.5009692
train: epoch 72, iter 2200, loss: 2.594101, top_1: 0.623437, top_k: 0.828906, samples/s: 848.945 1613076492.6560514
train: epoch 72, iter 2300, loss: 2.546678, top_1: 0.623477, top_k: 0.835977, samples/s: 847.546 1613076522.8608902
train: epoch 72, iter 2400, loss: 2.614077, top_1: 0.620078, top_k: 0.831133, samples/s: 845.032 1613076553.1556137
train: epoch 72, iter 2500, loss: 2.685888, top_1: 0.619766, top_k: 0.832187, samples/s: 848.071 1613076583.341735
train: epoch 72, iter 2600, loss: 2.528142, top_1: 0.613672, top_k: 0.830547, samples/s: 845.347 1613076613.6251402
train: epoch 72, iter 2700, loss: 2.486302, top_1: 0.616914, top_k: 0.831445, samples/s: 845.200 1613076643.9137824
train: epoch 72, iter 2800, loss: 2.598008, top_1: 0.622930, top_k: 0.833594, samples/s: 846.825 1613076674.1443467
train: epoch 72, iter 2900, loss: 2.525195, top_1: 0.622852, top_k: 0.835039, samples/s: 845.680 1613076704.4158401
train: epoch 72, iter 3000, loss: 2.504657, top_1: 0.616992, top_k: 0.833320, samples/s: 844.692 1613076734.7227345
train: epoch 72, iter 3100, loss: 2.627338, top_1: 0.613789, top_k: 0.830898, samples/s: 847.124 1613076764.9426644
train: epoch 72, iter 3200, loss: 2.346902, top_1: 0.619648, top_k: 0.831367, samples/s: 845.825 1613076795.2089221
train: epoch 72, iter 3300, loss: 2.521523, top_1: 0.618398, top_k: 0.832852, samples/s: 844.883 1613076825.5089638
train: epoch 72, iter 3400, loss: 2.528424, top_1: 0.616250, top_k: 0.823281, samples/s: 845.972 1613076855.7700791
train: epoch 72, iter 3500, loss: 2.702336, top_1: 0.620234, top_k: 0.828867, samples/s: 843.146 1613076886.1326692
train: epoch 72, iter 3600, loss: 2.529323, top_1: 0.621016, top_k: 0.833359, samples/s: 847.808 1613076916.3280928
train: epoch 72, iter 3700, loss: 2.454557, top_1: 0.618594, top_k: 0.830586, samples/s: 845.476 1613076946.606852
train: epoch 72, iter 3800, loss: 2.534424, top_1: 0.620469, top_k: 0.832031, samples/s: 847.350 1613076976.818706
train: epoch 72, iter 3900, loss: 2.514759, top_1: 0.617188, top_k: 0.832500, samples/s: 848.665 1613077006.9837205
train: epoch 72, iter 4000, loss: 2.456931, top_1: 0.618047, top_k: 0.833438, samples/s: 842.288 1613077037.377149
train: epoch 72, iter 4100, loss: 2.744467, top_1: 0.616406, top_k: 0.825352, samples/s: 846.506 1613077067.619082
train: epoch 72, iter 4200, loss: 2.488207, top_1: 0.626406, top_k: 0.833281, samples/s: 845.175 1613077097.9087596
train: epoch 72, iter 4300, loss: 2.386317, top_1: 0.621016, top_k: 0.833789, samples/s: 848.678 1613077128.0732453
train: epoch 72, iter 4400, loss: 2.645563, top_1: 0.621250, top_k: 0.831328, samples/s: 843.225 1613077158.4330075
train: epoch 72, iter 4500, loss: 2.481319, top_1: 0.622891, top_k: 0.831641, samples/s: 843.528 1613077188.7816103
train: epoch 72, iter 4600, loss: 2.691177, top_1: 0.618828, top_k: 0.828047, samples/s: 844.910 1613077219.0807664
train: epoch 72, iter 4700, loss: 2.594695, top_1: 0.624336, top_k: 0.833086, samples/s: 848.758 1613077249.242497
train: epoch 72, iter 4800, loss: 2.691755, top_1: 0.621484, top_k: 0.832734, samples/s: 844.011 1613077279.5737648
train: epoch 72, iter 4900, loss: 2.720804, top_1: 0.617461, top_k: 0.831055, samples/s: 845.809 1613077309.8406506
train: epoch 72, iter 5000, loss: 2.655258, top_1: 0.619531, top_k: 0.832578, samples/s: 845.320 1613077340.1250656
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_72.
validation: epoch 72, iter 195, top_1: 0.666126, top_k: 0.879728, samples/s: 2472.556 1613077361.1862009
train: epoch 73, iter 100, loss: 2.644015, top_1: 0.627891, top_k: 0.836055, samples/s: 869.550 1613077410.557549
train: epoch 73, iter 200, loss: 2.345223, top_1: 0.627930, top_k: 0.838047, samples/s: 864.702 1613077440.1631184
train: epoch 73, iter 300, loss: 2.622392, top_1: 0.632383, top_k: 0.840898, samples/s: 850.589 1613077470.2599235
train: epoch 73, iter 400, loss: 2.636616, top_1: 0.624766, top_k: 0.836367, samples/s: 840.682 1613077500.7113595
train: epoch 73, iter 500, loss: 2.577222, top_1: 0.633906, top_k: 0.839609, samples/s: 847.195 1613077530.9287539
train: epoch 73, iter 600, loss: 2.447134, top_1: 0.632461, top_k: 0.839688, samples/s: 841.115 1613077561.3645635
train: epoch 73, iter 700, loss: 2.493209, top_1: 0.626406, top_k: 0.838555, samples/s: 849.765 1613077591.4904668
train: epoch 73, iter 800, loss: 2.508029, top_1: 0.630820, top_k: 0.838164, samples/s: 842.155 1613077621.8887246
train: epoch 73, iter 900, loss: 2.376471, top_1: 0.633594, top_k: 0.838008, samples/s: 849.136 1613077652.037029
train: epoch 73, iter 1000, loss: 2.529786, top_1: 0.626875, top_k: 0.837812, samples/s: 843.041 1613077682.4032612
train: epoch 73, iter 1100, loss: 2.608488, top_1: 0.627578, top_k: 0.839688, samples/s: 843.593 1613077712.7497888
train: epoch 73, iter 1200, loss: 2.442015, top_1: 0.632422, top_k: 0.840234, samples/s: 845.093 1613077743.0421202
train: epoch 73, iter 1300, loss: 2.650205, top_1: 0.631094, top_k: 0.840391, samples/s: 846.977 1613077773.2673411
train: epoch 73, iter 1400, loss: 2.404893, top_1: 0.629492, top_k: 0.838281, samples/s: 846.221 1613077803.5195005
train: epoch 73, iter 1500, loss: 2.672895, top_1: 0.629531, top_k: 0.832812, samples/s: 844.646 1613077833.8280325
train: epoch 73, iter 1600, loss: 2.757465, top_1: 0.627656, top_k: 0.835781, samples/s: 848.128 1613077864.0121891
train: epoch 73, iter 1700, loss: 2.543249, top_1: 0.626172, top_k: 0.835508, samples/s: 842.759 1613077894.3885045
train: epoch 73, iter 1800, loss: 2.374560, top_1: 0.626406, top_k: 0.836250, samples/s: 849.453 1613077924.525643
train: epoch 73, iter 1900, loss: 2.399046, top_1: 0.617109, top_k: 0.830234, samples/s: 848.318 1613077954.703015
train: epoch 73, iter 2000, loss: 2.572565, top_1: 0.625039, top_k: 0.833672, samples/s: 841.594 1613077985.1214888
train: epoch 73, iter 2100, loss: 2.562232, top_1: 0.627578, top_k: 0.834805, samples/s: 848.508 1613078015.2920258
train: epoch 73, iter 2200, loss: 2.478085, top_1: 0.622539, top_k: 0.831367, samples/s: 847.260 1613078045.507103
train: epoch 73, iter 2300, loss: 2.555914, top_1: 0.622383, top_k: 0.833086, samples/s: 844.603 1613078075.817272
train: epoch 73, iter 2400, loss: 2.457882, top_1: 0.620781, top_k: 0.834336, samples/s: 849.722 1613078105.944635
train: epoch 73, iter 2500, loss: 2.540276, top_1: 0.624297, top_k: 0.833203, samples/s: 847.311 1613078136.1579266
train: epoch 73, iter 2600, loss: 2.607880, top_1: 0.621016, top_k: 0.834805, samples/s: 847.472 1613078166.3653982
train: epoch 73, iter 2700, loss: 2.705792, top_1: 0.621953, top_k: 0.833594, samples/s: 847.499 1613078196.5719776
train: epoch 73, iter 2800, loss: 2.555536, top_1: 0.620469, top_k: 0.836953, samples/s: 843.387 1613078226.9257755
train: epoch 73, iter 2900, loss: 2.520861, top_1: 0.620547, top_k: 0.831914, samples/s: 848.438 1613078257.0988994
train: epoch 73, iter 3000, loss: 2.483894, top_1: 0.622891, top_k: 0.832500, samples/s: 849.985 1613078287.217021
train: epoch 73, iter 3100, loss: 2.528528, top_1: 0.620078, top_k: 0.830977, samples/s: 847.570 1613078317.421029
train: epoch 73, iter 3200, loss: 2.476300, top_1: 0.620313, top_k: 0.831289, samples/s: 848.280 1613078347.5997229
train: epoch 73, iter 3300, loss: 2.260967, top_1: 0.615000, top_k: 0.829375, samples/s: 847.073 1613078377.8214655
train: epoch 73, iter 3400, loss: 2.537642, top_1: 0.619531, top_k: 0.831602, samples/s: 848.724 1613078407.9844053
train: epoch 73, iter 3500, loss: 2.450290, top_1: 0.621250, top_k: 0.831953, samples/s: 844.491 1613078438.2984998
train: epoch 73, iter 3600, loss: 2.527337, top_1: 0.621328, top_k: 0.832031, samples/s: 851.306 1613078468.3700068
train: epoch 73, iter 3700, loss: 2.452416, top_1: 0.623398, top_k: 0.831250, samples/s: 847.475 1613078498.5773847
train: epoch 73, iter 3800, loss: 2.657172, top_1: 0.627227, top_k: 0.834727, samples/s: 847.601 1613078528.7801971
train: epoch 73, iter 3900, loss: 2.546041, top_1: 0.621055, top_k: 0.832695, samples/s: 846.961 1613078559.0059884
train: epoch 73, iter 4000, loss: 2.339050, top_1: 0.624102, top_k: 0.832070, samples/s: 848.112 1613078589.1906116
train: epoch 73, iter 4100, loss: 2.622646, top_1: 0.616133, top_k: 0.829219, samples/s: 847.263 1613078619.405601
train: epoch 73, iter 4200, loss: 2.559409, top_1: 0.618516, top_k: 0.828164, samples/s: 844.706 1613078649.7120755
train: epoch 73, iter 4300, loss: 2.628458, top_1: 0.622227, top_k: 0.832344, samples/s: 850.146 1613078679.824637
train: epoch 73, iter 4400, loss: 2.582863, top_1: 0.620898, top_k: 0.832617, samples/s: 846.300 1613078710.0737863
train: epoch 73, iter 4500, loss: 2.563964, top_1: 0.618594, top_k: 0.832031, samples/s: 849.567 1613078740.2068803
train: epoch 73, iter 4600, loss: 2.353099, top_1: 0.619492, top_k: 0.830977, samples/s: 844.489 1613078770.520963
train: epoch 73, iter 4700, loss: 2.751485, top_1: 0.625000, top_k: 0.835117, samples/s: 848.386 1613078800.695886
train: epoch 73, iter 4800, loss: 2.627981, top_1: 0.622070, top_k: 0.830742, samples/s: 847.244 1613078830.911542
train: epoch 73, iter 4900, loss: 2.547800, top_1: 0.612227, top_k: 0.829531, samples/s: 845.912 1613078861.174704
train: epoch 73, iter 5000, loss: 2.485009, top_1: 0.618633, top_k: 0.831133, samples/s: 849.175 1613078891.3216722
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_73.
validation: epoch 73, iter 195, top_1: 0.670893, top_k: 0.882131, samples/s: 2429.475 1613078912.8122127
train: epoch 74, iter 100, loss: 2.418983, top_1: 0.633242, top_k: 0.839609, samples/s: 870.664 1613078962.7149193
train: epoch 74, iter 200, loss: 2.400560, top_1: 0.632266, top_k: 0.841484, samples/s: 867.475 1613078992.2258658
train: epoch 74, iter 300, loss: 2.464102, top_1: 0.635625, top_k: 0.843945, samples/s: 853.043 1613079022.2359717
train: epoch 74, iter 400, loss: 2.448577, top_1: 0.627891, top_k: 0.837148, samples/s: 842.412 1613079052.6250074
train: epoch 74, iter 500, loss: 2.598125, top_1: 0.635039, top_k: 0.841719, samples/s: 844.410 1613079082.9419806
train: epoch 74, iter 600, loss: 2.455685, top_1: 0.634453, top_k: 0.843047, samples/s: 845.997 1613079113.2021458
train: epoch 74, iter 700, loss: 2.433262, top_1: 0.631953, top_k: 0.840430, samples/s: 844.351 1613079143.521369
train: epoch 74, iter 800, loss: 2.568399, top_1: 0.630859, top_k: 0.840313, samples/s: 847.586 1613079173.7247572
train: epoch 74, iter 900, loss: 2.478919, top_1: 0.627109, top_k: 0.834219, samples/s: 846.918 1613079203.9520173
train: epoch 74, iter 1000, loss: 2.429734, top_1: 0.630430, top_k: 0.843164, samples/s: 846.132 1613079234.2073371
train: epoch 74, iter 1100, loss: 2.465645, top_1: 0.629219, top_k: 0.837930, samples/s: 847.512 1613079264.4133694
train: epoch 74, iter 1200, loss: 2.474181, top_1: 0.625625, top_k: 0.835859, samples/s: 844.258 1613079294.735827
train: epoch 74, iter 1300, loss: 2.650147, top_1: 0.625977, top_k: 0.836484, samples/s: 844.688 1613079325.0428326
train: epoch 74, iter 1400, loss: 2.479760, top_1: 0.623672, top_k: 0.833125, samples/s: 845.478 1613079355.321649
train: epoch 74, iter 1500, loss: 2.572034, top_1: 0.623945, top_k: 0.834727, samples/s: 845.592 1613079385.5962534
train: epoch 74, iter 1600, loss: 2.657535, top_1: 0.624023, top_k: 0.835469, samples/s: 845.139 1613079415.8870537
train: epoch 74, iter 1700, loss: 2.516034, top_1: 0.625469, top_k: 0.832969, samples/s: 846.747 1613079446.1204417
train: epoch 74, iter 1800, loss: 2.611079, top_1: 0.620977, top_k: 0.831172, samples/s: 847.201 1613079476.3375638
train: epoch 74, iter 1900, loss: 2.527124, top_1: 0.623437, top_k: 0.832383, samples/s: 844.198 1613079506.662308
train: epoch 74, iter 2000, loss: 2.688667, top_1: 0.622734, top_k: 0.828359, samples/s: 845.718 1613079536.932332
train: epoch 74, iter 2100, loss: 2.641957, top_1: 0.624023, top_k: 0.834141, samples/s: 847.646 1613079567.1336298
train: epoch 74, iter 2200, loss: 2.632444, top_1: 0.627969, top_k: 0.837734, samples/s: 843.614 1613079597.4793239
train: epoch 74, iter 2300, loss: 2.487130, top_1: 0.629844, top_k: 0.837227, samples/s: 848.715 1613079627.6425128
train: epoch 74, iter 2400, loss: 2.582415, top_1: 0.621992, top_k: 0.832266, samples/s: 845.545 1613079657.918927
train: epoch 74, iter 2500, loss: 2.382710, top_1: 0.626836, top_k: 0.833555, samples/s: 846.040 1613079688.1774979
train: epoch 74, iter 2600, loss: 2.433663, top_1: 0.621133, top_k: 0.835273, samples/s: 847.451 1613079718.3857167
train: epoch 74, iter 2700, loss: 2.555765, top_1: 0.620195, top_k: 0.834258, samples/s: 847.679 1613079748.5858727
train: epoch 74, iter 2800, loss: 2.412676, top_1: 0.631172, top_k: 0.837578, samples/s: 850.214 1613079778.695921
train: epoch 74, iter 2900, loss: 2.599985, top_1: 0.619219, top_k: 0.832461, samples/s: 846.740 1613079808.9295266
train: epoch 74, iter 3000, loss: 2.638401, top_1: 0.622344, top_k: 0.834570, samples/s: 849.360 1613079839.0697498
train: epoch 74, iter 3100, loss: 2.632638, top_1: 0.627891, top_k: 0.835039, samples/s: 844.704 1613079869.376207
train: epoch 74, iter 3200, loss: 2.542339, top_1: 0.622695, top_k: 0.832461, samples/s: 849.724 1613079899.50362
train: epoch 74, iter 3300, loss: 2.576472, top_1: 0.621055, top_k: 0.831992, samples/s: 845.832 1613079929.7697234
train: epoch 74, iter 3400, loss: 2.659143, top_1: 0.621055, top_k: 0.832578, samples/s: 845.306 1613079960.0545719
train: epoch 74, iter 3500, loss: 2.508298, top_1: 0.623594, top_k: 0.832930, samples/s: 847.467 1613079990.2622917
train: epoch 74, iter 3600, loss: 2.589204, top_1: 0.621758, top_k: 0.829102, samples/s: 845.302 1613080020.5473065
train: epoch 74, iter 3700, loss: 2.593286, top_1: 0.620586, top_k: 0.832969, samples/s: 851.306 1613080050.6188147
train: epoch 74, iter 3800, loss: 2.678430, top_1: 0.627227, top_k: 0.832852, samples/s: 846.305 1613080080.8679473
train: epoch 74, iter 3900, loss: 2.417972, top_1: 0.630547, top_k: 0.837109, samples/s: 848.364 1613080111.043624
train: epoch 74, iter 4000, loss: 2.663980, top_1: 0.620508, top_k: 0.830586, samples/s: 849.409 1613080141.1822624
train: epoch 74, iter 4100, loss: 2.638348, top_1: 0.616250, top_k: 0.831016, samples/s: 846.728 1613080171.4161644
train: epoch 74, iter 4200, loss: 2.595903, top_1: 0.622539, top_k: 0.832383, samples/s: 849.298 1613080201.5587292
train: epoch 74, iter 4300, loss: 2.631036, top_1: 0.617070, top_k: 0.830703, samples/s: 844.417 1613080231.8755362
train: epoch 74, iter 4400, loss: 2.416313, top_1: 0.629805, top_k: 0.833750, samples/s: 850.182 1613080261.98678
train: epoch 74, iter 4500, loss: 2.528006, top_1: 0.629102, top_k: 0.835430, samples/s: 846.508 1613080292.2285912
train: epoch 74, iter 4600, loss: 2.521635, top_1: 0.619336, top_k: 0.831992, samples/s: 850.689 1613080322.3218174
train: epoch 74, iter 4700, loss: 2.644136, top_1: 0.618164, top_k: 0.830547, samples/s: 847.966 1613080352.5117815
train: epoch 74, iter 4800, loss: 2.446873, top_1: 0.627188, top_k: 0.834570, samples/s: 845.016 1613080382.8069913
train: epoch 74, iter 4900, loss: 2.606413, top_1: 0.621758, top_k: 0.831484, samples/s: 846.719 1613080413.0414279
train: epoch 74, iter 5000, loss: 2.434983, top_1: 0.633320, top_k: 0.840820, samples/s: 847.813 1613080443.2367618
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_74.
validation: epoch 74, iter 195, top_1: 0.668990, top_k: 0.882472, samples/s: 2421.766 1613080464.7461085
train: epoch 75, iter 100, loss: 2.347783, top_1: 0.636211, top_k: 0.842930, samples/s: 870.024 1613080515.1844985
train: epoch 75, iter 200, loss: 2.483012, top_1: 0.631953, top_k: 0.839336, samples/s: 867.578 1613080544.6919072
train: epoch 75, iter 300, loss: 2.536330, top_1: 0.631953, top_k: 0.840977, samples/s: 849.118 1613080574.84084
train: epoch 75, iter 400, loss: 2.472136, top_1: 0.633945, top_k: 0.839570, samples/s: 849.399 1613080604.9797711
train: epoch 75, iter 500, loss: 2.449944, top_1: 0.629766, top_k: 0.841055, samples/s: 842.039 1613080635.3821392
train: epoch 75, iter 600, loss: 2.460836, top_1: 0.628789, top_k: 0.841289, samples/s: 845.490 1613080665.66053
train: epoch 75, iter 700, loss: 2.550736, top_1: 0.631250, top_k: 0.841602, samples/s: 849.814 1613080695.784772
train: epoch 75, iter 800, loss: 2.387563, top_1: 0.633125, top_k: 0.843945, samples/s: 842.845 1613080726.157984
train: epoch 75, iter 900, loss: 2.425169, top_1: 0.633242, top_k: 0.841094, samples/s: 844.371 1613080756.47641
train: epoch 75, iter 1000, loss: 2.571493, top_1: 0.630586, top_k: 0.834375, samples/s: 846.741 1613080786.7099812
train: epoch 75, iter 1100, loss: 2.540133, top_1: 0.629375, top_k: 0.835859, samples/s: 848.920 1613080816.8659656
train: epoch 75, iter 1200, loss: 2.538258, top_1: 0.629180, top_k: 0.835547, samples/s: 844.303 1613080847.1868198
train: epoch 75, iter 1300, loss: 2.514079, top_1: 0.628008, top_k: 0.835820, samples/s: 846.269 1613080877.4373386
train: epoch 75, iter 1400, loss: 2.368969, top_1: 0.629102, top_k: 0.839297, samples/s: 849.279 1613080907.580447
train: epoch 75, iter 1500, loss: 2.257059, top_1: 0.627734, top_k: 0.835352, samples/s: 845.979 1613080937.841355
train: epoch 75, iter 1600, loss: 2.408345, top_1: 0.630156, top_k: 0.840039, samples/s: 845.924 1613080968.1040142
train: epoch 75, iter 1700, loss: 2.565444, top_1: 0.631602, top_k: 0.836758, samples/s: 845.511 1613080998.38161
train: epoch 75, iter 1800, loss: 2.646255, top_1: 0.626016, top_k: 0.837656, samples/s: 847.561 1613081028.585968
train: epoch 75, iter 1900, loss: 2.630878, top_1: 0.628086, top_k: 0.834688, samples/s: 848.331 1613081058.762781
train: epoch 75, iter 2000, loss: 2.529551, top_1: 0.627461, top_k: 0.834180, samples/s: 844.589 1613081089.0734034
train: epoch 75, iter 2100, loss: 2.531281, top_1: 0.624531, top_k: 0.831562, samples/s: 847.145 1613081119.292588
train: epoch 75, iter 2200, loss: 2.314513, top_1: 0.629336, top_k: 0.838984, samples/s: 845.379 1613081149.5749164
train: epoch 75, iter 2300, loss: 2.552188, top_1: 0.623633, top_k: 0.836562, samples/s: 846.178 1613081179.828603
train: epoch 75, iter 2400, loss: 2.489322, top_1: 0.626758, top_k: 0.834688, samples/s: 846.444 1613081210.0726986
train: epoch 75, iter 2500, loss: 2.562765, top_1: 0.629766, top_k: 0.839492, samples/s: 844.432 1613081240.3889558
train: epoch 75, iter 2600, loss: 2.519250, top_1: 0.629805, top_k: 0.834766, samples/s: 848.096 1613081270.574277
train: epoch 75, iter 2700, loss: 2.548311, top_1: 0.625430, top_k: 0.834063, samples/s: 846.710 1613081300.8089085
train: epoch 75, iter 2800, loss: 2.518829, top_1: 0.623906, top_k: 0.831836, samples/s: 845.193 1613081331.0978456
train: epoch 75, iter 2900, loss: 2.474642, top_1: 0.626055, top_k: 0.834063, samples/s: 846.512 1613081361.3395836
train: epoch 75, iter 3000, loss: 2.533292, top_1: 0.622500, top_k: 0.834922, samples/s: 846.806 1613081391.5708528
train: epoch 75, iter 3100, loss: 2.591886, top_1: 0.629922, top_k: 0.838828, samples/s: 846.977 1613081421.7960212
train: epoch 75, iter 3200, loss: 2.457233, top_1: 0.620547, top_k: 0.832539, samples/s: 846.110 1613081452.052109
train: epoch 75, iter 3300, loss: 2.502149, top_1: 0.628633, top_k: 0.837266, samples/s: 847.446 1613081482.2604704
train: epoch 75, iter 3400, loss: 2.503002, top_1: 0.621250, top_k: 0.836016, samples/s: 848.321 1613081512.4377234
train: epoch 75, iter 3500, loss: 2.389169, top_1: 0.619023, top_k: 0.836523, samples/s: 844.515 1613081542.7510357
train: epoch 75, iter 3600, loss: 2.498835, top_1: 0.625156, top_k: 0.834727, samples/s: 849.000 1613081572.9041438
train: epoch 75, iter 3700, loss: 2.407223, top_1: 0.621211, top_k: 0.831953, samples/s: 845.603 1613081603.1784177
train: epoch 75, iter 3800, loss: 2.574754, top_1: 0.626328, top_k: 0.835430, samples/s: 846.873 1613081633.4073014
train: epoch 75, iter 3900, loss: 2.479225, top_1: 0.629375, top_k: 0.834727, samples/s: 846.722 1613081663.6420856
train: epoch 75, iter 4000, loss: 2.528894, top_1: 0.624609, top_k: 0.833281, samples/s: 845.578 1613081693.9166691
train: epoch 75, iter 4100, loss: 2.626224, top_1: 0.624375, top_k: 0.832070, samples/s: 848.057 1613081724.103645
train: epoch 75, iter 4200, loss: 2.590021, top_1: 0.621680, top_k: 0.835742, samples/s: 844.303 1613081754.4242895
train: epoch 75, iter 4300, loss: 2.437927, top_1: 0.622578, top_k: 0.832539, samples/s: 849.475 1613081784.5605254
train: epoch 75, iter 4400, loss: 2.648713, top_1: 0.620703, top_k: 0.831523, samples/s: 846.186 1613081814.8138566
train: epoch 75, iter 4500, loss: 2.516581, top_1: 0.623125, top_k: 0.837930, samples/s: 845.419 1613081845.09475
train: epoch 75, iter 4600, loss: 2.526333, top_1: 0.624414, top_k: 0.832070, samples/s: 846.437 1613081875.3391838
train: epoch 75, iter 4700, loss: 2.508286, top_1: 0.624531, top_k: 0.834336, samples/s: 848.114 1613081905.5243526
train: epoch 75, iter 4800, loss: 2.491425, top_1: 0.625273, top_k: 0.831680, samples/s: 847.747 1613081935.7213864
train: epoch 75, iter 4900, loss: 2.458689, top_1: 0.621875, top_k: 0.834727, samples/s: 846.408 1613081965.9672797
train: epoch 75, iter 5000, loss: 2.467424, top_1: 0.625156, top_k: 0.832148, samples/s: 844.281 1613081996.2885282
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_75.
validation: epoch 75, iter 195, top_1: 0.669551, top_k: 0.880128, samples/s: 2389.687 1613082018.0774436
train: epoch 76, iter 100, loss: 2.222359, top_1: 0.631836, top_k: 0.841211, samples/s: 866.941 1613082068.0431926
train: epoch 76, iter 200, loss: 2.625649, top_1: 0.635234, top_k: 0.842148, samples/s: 867.154 1613082097.5650363
train: epoch 76, iter 300, loss: 2.580225, top_1: 0.636563, top_k: 0.841523, samples/s: 851.347 1613082127.6350365
train: epoch 76, iter 400, loss: 2.719940, top_1: 0.633672, top_k: 0.844492, samples/s: 845.288 1613082157.920544
train: epoch 76, iter 500, loss: 2.469770, top_1: 0.635508, top_k: 0.843750, samples/s: 846.567 1613082188.1604352
train: epoch 76, iter 600, loss: 2.697415, top_1: 0.635977, top_k: 0.843555, samples/s: 845.745 1613082218.429609
train: epoch 76, iter 700, loss: 2.298557, top_1: 0.630664, top_k: 0.837734, samples/s: 844.961 1613082248.7267597
train: epoch 76, iter 800, loss: 2.433587, top_1: 0.630586, top_k: 0.838164, samples/s: 847.091 1613082278.9478402
train: epoch 76, iter 900, loss: 2.542364, top_1: 0.633984, top_k: 0.842891, samples/s: 845.873 1613082309.2123845
train: epoch 76, iter 1000, loss: 2.657526, top_1: 0.630938, top_k: 0.840039, samples/s: 849.336 1613082339.3536773
train: epoch 76, iter 1100, loss: 2.642861, top_1: 0.634687, top_k: 0.839180, samples/s: 843.274 1613082369.71143
train: epoch 76, iter 1200, loss: 2.580100, top_1: 0.635781, top_k: 0.841992, samples/s: 848.521 1613082399.8816543
train: epoch 76, iter 1300, loss: 2.543694, top_1: 0.631914, top_k: 0.843086, samples/s: 845.272 1613082430.1677525
train: epoch 76, iter 1400, loss: 2.446751, top_1: 0.631484, top_k: 0.839141, samples/s: 846.721 1613082460.4019554
train: epoch 76, iter 1500, loss: 2.503681, top_1: 0.630703, top_k: 0.835898, samples/s: 845.170 1613082490.6916952
train: epoch 76, iter 1600, loss: 2.589215, top_1: 0.629297, top_k: 0.840742, samples/s: 851.402 1613082520.75987
train: epoch 76, iter 1700, loss: 2.503108, top_1: 0.635273, top_k: 0.840234, samples/s: 844.612 1613082551.0695949
train: epoch 76, iter 1800, loss: 2.478813, top_1: 0.634141, top_k: 0.842656, samples/s: 846.580 1613082581.3089027
train: epoch 76, iter 1900, loss: 2.466936, top_1: 0.629805, top_k: 0.837891, samples/s: 847.612 1613082611.511441
train: epoch 76, iter 2000, loss: 2.554107, top_1: 0.627930, top_k: 0.836641, samples/s: 845.099 1613082641.8037193
train: epoch 76, iter 2100, loss: 2.582537, top_1: 0.632500, top_k: 0.839922, samples/s: 848.049 1613082671.9906867
train: epoch 76, iter 2200, loss: 2.637377, top_1: 0.626289, top_k: 0.834766, samples/s: 848.648 1613082702.1562722
train: epoch 76, iter 2300, loss: 2.556051, top_1: 0.624805, top_k: 0.836641, samples/s: 848.069 1613082732.3424196
train: epoch 76, iter 2400, loss: 2.467443, top_1: 0.630547, top_k: 0.840273, samples/s: 844.225 1613082762.6661255
train: epoch 76, iter 2500, loss: 2.510427, top_1: 0.621484, top_k: 0.834258, samples/s: 847.124 1613082792.8860826
train: epoch 76, iter 2600, loss: 2.560201, top_1: 0.629531, top_k: 0.835781, samples/s: 848.202 1613082823.0675752
train: epoch 76, iter 2700, loss: 2.562236, top_1: 0.633633, top_k: 0.839258, samples/s: 847.508 1613082853.2737262
train: epoch 76, iter 2800, loss: 2.431371, top_1: 0.625273, top_k: 0.841250, samples/s: 847.296 1613082883.4875305
train: epoch 76, iter 2900, loss: 2.449654, top_1: 0.634375, top_k: 0.841289, samples/s: 846.586 1613082913.7266169
train: epoch 76, iter 3000, loss: 2.512473, top_1: 0.629258, top_k: 0.836016, samples/s: 844.162 1613082944.0524628
train: epoch 76, iter 3100, loss: 2.476291, top_1: 0.623828, top_k: 0.835391, samples/s: 847.028 1613082974.2758484
train: epoch 76, iter 3200, loss: 2.481532, top_1: 0.624023, top_k: 0.837031, samples/s: 850.514 1613083004.3753366
train: epoch 76, iter 3300, loss: 2.347701, top_1: 0.620703, top_k: 0.833828, samples/s: 844.555 1613083034.6870747
train: epoch 76, iter 3400, loss: 2.461438, top_1: 0.626055, top_k: 0.838633, samples/s: 848.035 1613083064.8745656
train: epoch 76, iter 3500, loss: 2.479191, top_1: 0.634883, top_k: 0.842344, samples/s: 845.161 1613083095.1645617
train: epoch 76, iter 3600, loss: 2.638351, top_1: 0.626875, top_k: 0.834922, samples/s: 848.524 1613083125.3346848
train: epoch 76, iter 3700, loss: 2.544534, top_1: 0.621719, top_k: 0.832422, samples/s: 846.678 1613083155.5704682
train: epoch 76, iter 3800, loss: 2.606936, top_1: 0.627656, top_k: 0.834648, samples/s: 847.406 1613083185.7802536
train: epoch 76, iter 3900, loss: 2.523834, top_1: 0.617617, top_k: 0.835117, samples/s: 845.063 1613083216.0739307
train: epoch 76, iter 4000, loss: 2.564379, top_1: 0.628359, top_k: 0.835391, samples/s: 849.738 1613083246.2007747
train: epoch 76, iter 4100, loss: 2.594352, top_1: 0.622188, top_k: 0.832695, samples/s: 846.377 1613083276.4474165
train: epoch 76, iter 4200, loss: 2.643576, top_1: 0.627578, top_k: 0.836289, samples/s: 847.093 1613083306.6684206
train: epoch 76, iter 4300, loss: 2.628502, top_1: 0.627109, top_k: 0.837187, samples/s: 846.010 1613083336.9281025
train: epoch 76, iter 4400, loss: 2.624168, top_1: 0.626328, top_k: 0.836914, samples/s: 848.582 1613083367.0960767
train: epoch 76, iter 4500, loss: 2.515716, top_1: 0.624453, top_k: 0.832266, samples/s: 850.651 1613083397.1905704
train: epoch 76, iter 4600, loss: 2.392641, top_1: 0.624375, top_k: 0.836445, samples/s: 845.280 1613083427.4764953
train: epoch 76, iter 4700, loss: 2.589435, top_1: 0.620703, top_k: 0.830430, samples/s: 848.192 1613083457.658332
train: epoch 76, iter 4800, loss: 2.743587, top_1: 0.624414, top_k: 0.831406, samples/s: 850.590 1613083487.7550342
train: epoch 76, iter 4900, loss: 2.593646, top_1: 0.622227, top_k: 0.831406, samples/s: 849.949 1613083517.8745344
train: epoch 76, iter 5000, loss: 2.626298, top_1: 0.629961, top_k: 0.837070, samples/s: 844.875 1613083548.174841
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_76.
validation: epoch 76, iter 195, top_1: 0.674038, top_k: 0.882652, samples/s: 2406.334 1613083569.81085
train: epoch 77, iter 100, loss: 2.441353, top_1: 0.641172, top_k: 0.844375, samples/s: 868.993 1613083620.9865615
train: epoch 77, iter 200, loss: 2.507291, top_1: 0.640820, top_k: 0.842070, samples/s: 868.032 1613083650.4787564
train: epoch 77, iter 300, loss: 2.423022, top_1: 0.636328, top_k: 0.842812, samples/s: 854.131 1613083680.4504647
train: epoch 77, iter 400, loss: 2.365522, top_1: 0.633828, top_k: 0.842070, samples/s: 846.803 1613083710.6818447
train: epoch 77, iter 500, loss: 2.413151, top_1: 0.635664, top_k: 0.843008, samples/s: 847.421 1613083740.891058
train: epoch 77, iter 600, loss: 2.566346, top_1: 0.634414, top_k: 0.843320, samples/s: 845.028 1613083771.185897
train: epoch 77, iter 700, loss: 2.502615, top_1: 0.635039, top_k: 0.840469, samples/s: 850.382 1613083801.290139
train: epoch 77, iter 800, loss: 2.578201, top_1: 0.636211, top_k: 0.839453, samples/s: 846.188 1613083831.5433671
train: epoch 77, iter 900, loss: 2.586944, top_1: 0.632188, top_k: 0.840469, samples/s: 848.246 1613083861.7233284
train: epoch 77, iter 1000, loss: 2.469833, top_1: 0.631953, top_k: 0.840000, samples/s: 846.523 1613083891.9647524
train: epoch 77, iter 1100, loss: 2.341446, top_1: 0.642031, top_k: 0.847422, samples/s: 846.829 1613083922.1951828
train: epoch 77, iter 1200, loss: 2.419268, top_1: 0.629180, top_k: 0.838398, samples/s: 848.144 1613083952.378727
train: epoch 77, iter 1300, loss: 2.520232, top_1: 0.633477, top_k: 0.838984, samples/s: 848.982 1613083982.5324337
train: epoch 77, iter 1400, loss: 2.454074, top_1: 0.631836, top_k: 0.835313, samples/s: 847.855 1613084012.726241
train: epoch 77, iter 1500, loss: 2.670757, top_1: 0.633437, top_k: 0.837461, samples/s: 848.088 1613084042.9117732
train: epoch 77, iter 1600, loss: 2.455862, top_1: 0.627422, top_k: 0.841172, samples/s: 847.580 1613084073.1155107
train: epoch 77, iter 1700, loss: 2.529633, top_1: 0.631797, top_k: 0.840352, samples/s: 845.499 1613084103.3934753
train: epoch 77, iter 1800, loss: 2.663945, top_1: 0.628711, top_k: 0.838672, samples/s: 848.996 1613084133.54677
train: epoch 77, iter 1900, loss: 2.629257, top_1: 0.629961, top_k: 0.837461, samples/s: 848.587 1613084163.714547
train: epoch 77, iter 2000, loss: 2.500416, top_1: 0.630117, top_k: 0.838477, samples/s: 844.777 1613084194.0183132
train: epoch 77, iter 2100, loss: 2.544885, top_1: 0.632383, top_k: 0.839414, samples/s: 850.502 1613084224.1182618
train: epoch 77, iter 2200, loss: 2.435938, top_1: 0.629297, top_k: 0.838789, samples/s: 846.926 1613084254.345097
train: epoch 77, iter 2300, loss: 2.499708, top_1: 0.627383, top_k: 0.840352, samples/s: 848.073 1613084284.5312288
train: epoch 77, iter 2400, loss: 2.389309, top_1: 0.628398, top_k: 0.837031, samples/s: 849.035 1613084314.683229
train: epoch 77, iter 2500, loss: 2.579900, top_1: 0.626914, top_k: 0.836367, samples/s: 849.186 1613084344.8296926
train: epoch 77, iter 2600, loss: 2.394410, top_1: 0.637461, top_k: 0.841602, samples/s: 846.401 1613084375.0753443
train: epoch 77, iter 2700, loss: 2.578809, top_1: 0.625898, top_k: 0.838398, samples/s: 849.082 1613084405.2255895
train: epoch 77, iter 2800, loss: 2.408370, top_1: 0.622422, top_k: 0.835508, samples/s: 849.383 1613084435.3650668
train: epoch 77, iter 2900, loss: 2.615866, top_1: 0.624805, top_k: 0.836172, samples/s: 849.679 1613084465.4940648
train: epoch 77, iter 3000, loss: 2.365028, top_1: 0.633945, top_k: 0.836211, samples/s: 848.007 1613084495.6825917
train: epoch 77, iter 3100, loss: 2.430819, top_1: 0.632188, top_k: 0.841484, samples/s: 847.921 1613084525.8740494
train: epoch 77, iter 3200, loss: 2.516387, top_1: 0.630469, top_k: 0.836953, samples/s: 848.366 1613084556.0496225
train: epoch 77, iter 3300, loss: 2.587160, top_1: 0.617383, top_k: 0.833633, samples/s: 846.767 1613084586.2823691
train: epoch 77, iter 3400, loss: 2.635179, top_1: 0.625273, top_k: 0.836797, samples/s: 849.178 1613084616.4291363
train: epoch 77, iter 3500, loss: 2.458369, top_1: 0.631172, top_k: 0.837852, samples/s: 845.261 1613084646.71568
train: epoch 77, iter 3600, loss: 2.519501, top_1: 0.627539, top_k: 0.838281, samples/s: 849.311 1613084676.8576908
train: epoch 77, iter 3700, loss: 2.591478, top_1: 0.629102, top_k: 0.837148, samples/s: 846.199 1613084707.110582
train: epoch 77, iter 3800, loss: 2.460075, top_1: 0.627422, top_k: 0.838281, samples/s: 847.864 1613084737.304163
train: epoch 77, iter 3900, loss: 2.480909, top_1: 0.624531, top_k: 0.832266, samples/s: 848.604 1613084767.4713395
train: epoch 77, iter 4000, loss: 2.440931, top_1: 0.635195, top_k: 0.841133, samples/s: 849.229 1613084797.6163177
train: epoch 77, iter 4100, loss: 2.449732, top_1: 0.628633, top_k: 0.837773, samples/s: 848.622 1613084827.7828345
train: epoch 77, iter 4200, loss: 2.624637, top_1: 0.626641, top_k: 0.839727, samples/s: 850.678 1613084857.8765512
train: epoch 77, iter 4300, loss: 2.429105, top_1: 0.624297, top_k: 0.836602, samples/s: 847.538 1613084888.081696
train: epoch 77, iter 4400, loss: 2.646775, top_1: 0.630352, top_k: 0.836055, samples/s: 848.394 1613084918.256354
train: epoch 77, iter 4500, loss: 2.606470, top_1: 0.625664, top_k: 0.837070, samples/s: 849.466 1613084948.3927956
train: epoch 77, iter 4600, loss: 2.530016, top_1: 0.630039, top_k: 0.836836, samples/s: 849.358 1613084978.5332863
train: epoch 77, iter 4700, loss: 2.542206, top_1: 0.622500, top_k: 0.834492, samples/s: 848.427 1613085008.706789
train: epoch 77, iter 4800, loss: 2.475732, top_1: 0.631484, top_k: 0.841328, samples/s: 847.488 1613085038.913649
train: epoch 77, iter 4900, loss: 2.434218, top_1: 0.627930, top_k: 0.832109, samples/s: 846.845 1613085069.1435456
train: epoch 77, iter 5000, loss: 2.434118, top_1: 0.633008, top_k: 0.841133, samples/s: 851.790 1613085099.1978889
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_77.
validation: epoch 77, iter 195, top_1: 0.675361, top_k: 0.882552, samples/s: 2475.088 1613085120.2739956
train: epoch 78, iter 100, loss: 2.366866, top_1: 0.640234, top_k: 0.846758, samples/s: 866.797 1613085171.3094828
train: epoch 78, iter 200, loss: 2.391391, top_1: 0.643984, top_k: 0.846367, samples/s: 867.086 1613085200.8338683
train: epoch 78, iter 300, loss: 2.370319, top_1: 0.645703, top_k: 0.846523, samples/s: 851.445 1613085230.9001198
train: epoch 78, iter 400, loss: 2.468183, top_1: 0.643984, top_k: 0.848984, samples/s: 848.896 1613085261.056935
train: epoch 78, iter 500, loss: 2.679053, top_1: 0.638945, top_k: 0.846445, samples/s: 845.810 1613085291.3238034
train: epoch 78, iter 600, loss: 2.489523, top_1: 0.628398, top_k: 0.839688, samples/s: 847.951 1613085321.514157
train: epoch 78, iter 700, loss: 2.588279, top_1: 0.633086, top_k: 0.837305, samples/s: 844.375 1613085351.832453
train: epoch 78, iter 800, loss: 2.552718, top_1: 0.639687, top_k: 0.842148, samples/s: 849.938 1613085381.9522936
train: epoch 78, iter 900, loss: 2.501402, top_1: 0.642695, top_k: 0.844141, samples/s: 844.569 1613085412.2636917
train: epoch 78, iter 1000, loss: 2.411843, top_1: 0.641289, top_k: 0.844297, samples/s: 846.896 1613085442.4916556
train: epoch 78, iter 1100, loss: 2.467532, top_1: 0.634258, top_k: 0.841875, samples/s: 843.478 1613085472.8422825
train: epoch 78, iter 1200, loss: 2.534695, top_1: 0.635781, top_k: 0.840039, samples/s: 850.664 1613085502.936308
train: epoch 78, iter 1300, loss: 2.523006, top_1: 0.634961, top_k: 0.840859, samples/s: 848.616 1613085533.103103
train: epoch 78, iter 1400, loss: 2.216067, top_1: 0.632500, top_k: 0.836016, samples/s: 843.421 1613085563.455669
train: epoch 78, iter 1500, loss: 2.645929, top_1: 0.624805, top_k: 0.837539, samples/s: 848.223 1613085593.636509
train: epoch 78, iter 1600, loss: 2.460975, top_1: 0.630273, top_k: 0.839844, samples/s: 845.907 1613085623.8997676
train: epoch 78, iter 1700, loss: 2.399235, top_1: 0.638008, top_k: 0.842695, samples/s: 839.524 1613085654.3933327
train: epoch 78, iter 1800, loss: 2.375822, top_1: 0.631133, top_k: 0.839844, samples/s: 852.867 1613085684.4096382
train: epoch 78, iter 1900, loss: 2.736265, top_1: 0.635664, top_k: 0.839766, samples/s: 847.244 1613085714.6253288
train: epoch 78, iter 2000, loss: 2.458325, top_1: 0.629258, top_k: 0.840586, samples/s: 849.583 1613085744.757746
train: epoch 78, iter 2100, loss: 2.412621, top_1: 0.630195, top_k: 0.837617, samples/s: 847.574 1613085774.961567
train: epoch 78, iter 2200, loss: 2.587414, top_1: 0.624062, top_k: 0.837656, samples/s: 845.545 1613085805.2379544
train: epoch 78, iter 2300, loss: 2.367018, top_1: 0.629023, top_k: 0.838711, samples/s: 846.516 1613085835.479481
train: epoch 78, iter 2400, loss: 2.565976, top_1: 0.633633, top_k: 0.839805, samples/s: 848.365 1613085865.6552236
train: epoch 78, iter 2500, loss: 2.581074, top_1: 0.622383, top_k: 0.835117, samples/s: 846.937 1613085895.8817353
train: epoch 78, iter 2600, loss: 2.364835, top_1: 0.628750, top_k: 0.838398, samples/s: 849.889 1613085926.0033822
train: epoch 78, iter 2700, loss: 2.664704, top_1: 0.628281, top_k: 0.837070, samples/s: 847.650 1613085956.2044818
train: epoch 78, iter 2800, loss: 2.644218, top_1: 0.634531, top_k: 0.837891, samples/s: 845.392 1613085986.4863997
train: epoch 78, iter 2900, loss: 2.522220, top_1: 0.636641, top_k: 0.838789, samples/s: 848.529 1613086016.6561532
train: epoch 78, iter 3000, loss: 2.540384, top_1: 0.626133, top_k: 0.840195, samples/s: 847.894 1613086046.8487103
train: epoch 78, iter 3100, loss: 2.606981, top_1: 0.631211, top_k: 0.842656, samples/s: 849.514 1613086076.9835408
train: epoch 78, iter 3200, loss: 2.501171, top_1: 0.632891, top_k: 0.842266, samples/s: 846.672 1613086107.219512
train: epoch 78, iter 3300, loss: 2.400881, top_1: 0.633047, top_k: 0.840547, samples/s: 851.938 1613086137.2687182
train: epoch 78, iter 3400, loss: 2.606706, top_1: 0.629570, top_k: 0.834180, samples/s: 844.690 1613086167.5756392
train: epoch 78, iter 3500, loss: 2.463892, top_1: 0.630469, top_k: 0.839961, samples/s: 850.233 1613086197.6850045
train: epoch 78, iter 3600, loss: 2.530078, top_1: 0.630000, top_k: 0.839688, samples/s: 846.711 1613086227.9197333
train: epoch 78, iter 3700, loss: 2.496710, top_1: 0.627070, top_k: 0.839023, samples/s: 849.720 1613086258.0472496
train: epoch 78, iter 3800, loss: 2.590290, top_1: 0.629609, top_k: 0.836250, samples/s: 848.360 1613086288.2230737
train: epoch 78, iter 3900, loss: 2.344787, top_1: 0.632539, top_k: 0.840664, samples/s: 846.712 1613086318.4577436
train: epoch 78, iter 4000, loss: 2.578080, top_1: 0.627891, top_k: 0.834805, samples/s: 847.882 1613086348.650671
train: epoch 78, iter 4100, loss: 2.501083, top_1: 0.627227, top_k: 0.835039, samples/s: 850.032 1613086378.7671285
train: epoch 78, iter 4200, loss: 2.413439, top_1: 0.627773, top_k: 0.837578, samples/s: 845.369 1613086409.0498102
train: epoch 78, iter 4300, loss: 2.594300, top_1: 0.630352, top_k: 0.837500, samples/s: 848.375 1613086439.225076
train: epoch 78, iter 4400, loss: 2.628737, top_1: 0.625156, top_k: 0.833164, samples/s: 848.678 1613086469.3896136
train: epoch 78, iter 4500, loss: 2.474291, top_1: 0.634336, top_k: 0.838945, samples/s: 848.298 1613086499.567762
train: epoch 78, iter 4600, loss: 2.678632, top_1: 0.632969, top_k: 0.839961, samples/s: 850.216 1613086529.6777425
train: epoch 78, iter 4700, loss: 2.465014, top_1: 0.632188, top_k: 0.838047, samples/s: 845.293 1613086559.963063
train: epoch 78, iter 4800, loss: 2.441737, top_1: 0.630313, top_k: 0.838203, samples/s: 848.367 1613086590.1387975
train: epoch 78, iter 4900, loss: 2.697042, top_1: 0.626797, top_k: 0.839688, samples/s: 847.112 1613086620.3591013
train: epoch 78, iter 5000, loss: 2.353939, top_1: 0.637930, top_k: 0.844766, samples/s: 847.541 1613086650.5640657
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_78.
validation: epoch 78, iter 195, top_1: 0.678486, top_k: 0.883894, samples/s: 2494.484 1613086671.3747928
train: epoch 79, iter 100, loss: 2.398997, top_1: 0.638633, top_k: 0.843789, samples/s: 868.697 1613086722.1610065
train: epoch 79, iter 200, loss: 2.483707, top_1: 0.638984, top_k: 0.845039, samples/s: 866.679 1613086751.6991367
train: epoch 79, iter 300, loss: 2.435492, top_1: 0.637383, top_k: 0.844141, samples/s: 853.706 1613086781.685977
train: epoch 79, iter 400, loss: 2.407929, top_1: 0.645000, top_k: 0.848281, samples/s: 846.801 1613086811.9173315
train: epoch 79, iter 500, loss: 2.346361, top_1: 0.639766, top_k: 0.845352, samples/s: 848.669 1613086842.0822492
train: epoch 79, iter 600, loss: 2.468131, top_1: 0.637031, top_k: 0.840898, samples/s: 845.856 1613086872.3474126
train: epoch 79, iter 700, loss: 2.586605, top_1: 0.643086, top_k: 0.848047, samples/s: 849.971 1613086902.4661765
train: epoch 79, iter 800, loss: 2.669771, top_1: 0.633906, top_k: 0.839688, samples/s: 844.130 1613086932.793199
train: epoch 79, iter 900, loss: 2.231624, top_1: 0.639766, top_k: 0.846289, samples/s: 849.591 1613086962.9253342
train: epoch 79, iter 1000, loss: 2.523470, top_1: 0.641328, top_k: 0.843203, samples/s: 846.894 1613086993.153526
train: epoch 79, iter 1100, loss: 2.634136, top_1: 0.638398, top_k: 0.845664, samples/s: 847.282 1613087023.3677526
train: epoch 79, iter 1200, loss: 2.502117, top_1: 0.633945, top_k: 0.840156, samples/s: 845.521 1613087053.6449907
train: epoch 79, iter 1300, loss: 2.704228, top_1: 0.633125, top_k: 0.840352, samples/s: 849.701 1613087083.7732537
train: epoch 79, iter 1400, loss: 2.495694, top_1: 0.641172, top_k: 0.845195, samples/s: 847.422 1613087113.9824605
train: epoch 79, iter 1500, loss: 2.326276, top_1: 0.635156, top_k: 0.841758, samples/s: 847.947 1613087144.1730053
train: epoch 79, iter 1600, loss: 2.650819, top_1: 0.634883, top_k: 0.842227, samples/s: 846.797 1613087174.4045742
train: epoch 79, iter 1700, loss: 2.800488, top_1: 0.636523, top_k: 0.845234, samples/s: 845.374 1613087204.6870515
train: epoch 79, iter 1800, loss: 2.480031, top_1: 0.632266, top_k: 0.838320, samples/s: 850.854 1613087234.7743921
train: epoch 79, iter 1900, loss: 2.458251, top_1: 0.636016, top_k: 0.838828, samples/s: 846.160 1613087265.0287166
train: epoch 79, iter 2000, loss: 2.565918, top_1: 0.638672, top_k: 0.844102, samples/s: 848.778 1613087295.1897652
train: epoch 79, iter 2100, loss: 2.602661, top_1: 0.635352, top_k: 0.844258, samples/s: 848.095 1613087325.3750324
train: epoch 79, iter 2200, loss: 2.414881, top_1: 0.634102, top_k: 0.838711, samples/s: 846.161 1613087355.6293905
train: epoch 79, iter 2300, loss: 2.366366, top_1: 0.632695, top_k: 0.841719, samples/s: 848.436 1613087385.8025165
train: epoch 79, iter 2400, loss: 2.466986, top_1: 0.632188, top_k: 0.841250, samples/s: 846.997 1613087416.0268948
train: epoch 79, iter 2500, loss: 2.415174, top_1: 0.625469, top_k: 0.838750, samples/s: 847.777 1613087446.2235305
train: epoch 79, iter 2600, loss: 2.491696, top_1: 0.636914, top_k: 0.841055, samples/s: 847.483 1613087476.4306695
train: epoch 79, iter 2700, loss: 2.723878, top_1: 0.634687, top_k: 0.840820, samples/s: 851.579 1613087506.4925253
train: epoch 79, iter 2800, loss: 2.528111, top_1: 0.633125, top_k: 0.841328, samples/s: 846.516 1613087536.7340584
train: epoch 79, iter 2900, loss: 2.446278, top_1: 0.633867, top_k: 0.838164, samples/s: 846.240 1613087566.9855883
train: epoch 79, iter 3000, loss: 2.518035, top_1: 0.631563, top_k: 0.839219, samples/s: 846.610 1613087597.2238145
train: epoch 79, iter 3100, loss: 2.654274, top_1: 0.628477, top_k: 0.837617, samples/s: 849.214 1613087627.3692887
train: epoch 79, iter 3200, loss: 2.675986, top_1: 0.632695, top_k: 0.840430, samples/s: 847.495 1613087657.57593
train: epoch 79, iter 3300, loss: 2.494810, top_1: 0.627891, top_k: 0.838125, samples/s: 849.765 1613087687.7019703
train: epoch 79, iter 3400, loss: 2.467862, top_1: 0.631719, top_k: 0.844258, samples/s: 845.873 1613087717.9666178
train: epoch 79, iter 3500, loss: 2.730085, top_1: 0.628320, top_k: 0.841094, samples/s: 847.251 1613087748.18202
train: epoch 79, iter 3600, loss: 2.448944, top_1: 0.636250, top_k: 0.838906, samples/s: 847.554 1613087778.3864686
train: epoch 79, iter 3700, loss: 2.748349, top_1: 0.627734, top_k: 0.838125, samples/s: 850.114 1613087808.5000494
train: epoch 79, iter 3800, loss: 2.390805, top_1: 0.633164, top_k: 0.839219, samples/s: 849.967 1613087838.618934
train: epoch 79, iter 3900, loss: 2.564387, top_1: 0.626445, top_k: 0.837031, samples/s: 849.366 1613087868.759084
train: epoch 79, iter 4000, loss: 2.510457, top_1: 0.630703, top_k: 0.836641, samples/s: 845.729 1613087899.0288062
train: epoch 79, iter 4100, loss: 2.460124, top_1: 0.628398, top_k: 0.838242, samples/s: 850.135 1613087929.1416833
train: epoch 79, iter 4200, loss: 2.464779, top_1: 0.629727, top_k: 0.839531, samples/s: 846.955 1613087959.367689
train: epoch 79, iter 4300, loss: 2.671873, top_1: 0.629258, top_k: 0.839961, samples/s: 850.819 1613087989.4562802
train: epoch 79, iter 4400, loss: 2.421016, top_1: 0.631055, top_k: 0.839766, samples/s: 844.003 1613088019.7878895
train: epoch 79, iter 4500, loss: 2.334116, top_1: 0.625195, top_k: 0.837422, samples/s: 848.138 1613088049.97165
train: epoch 79, iter 4600, loss: 2.513631, top_1: 0.624375, top_k: 0.834570, samples/s: 849.749 1613088080.0982106
train: epoch 79, iter 4700, loss: 2.641815, top_1: 0.627266, top_k: 0.835977, samples/s: 844.932 1613088110.396478
train: epoch 79, iter 4800, loss: 2.355442, top_1: 0.634023, top_k: 0.836445, samples/s: 847.864 1613088140.5899265
train: epoch 79, iter 4900, loss: 2.445742, top_1: 0.630195, top_k: 0.835547, samples/s: 847.056 1613088170.8123097
train: epoch 79, iter 5000, loss: 2.397268, top_1: 0.635820, top_k: 0.840000, samples/s: 847.211 1613088201.0291486
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_79.
validation: epoch 79, iter 195, top_1: 0.675040, top_k: 0.882712, samples/s: 2435.493 1613088222.4168766
train: epoch 80, iter 100, loss: 2.435495, top_1: 0.646797, top_k: 0.848594, samples/s: 871.139 1613088273.3821483
train: epoch 80, iter 200, loss: 2.420329, top_1: 0.640820, top_k: 0.848398, samples/s: 867.095 1613088302.9062357
train: epoch 80, iter 300, loss: 2.550036, top_1: 0.644492, top_k: 0.848398, samples/s: 852.368 1613088332.939957
train: epoch 80, iter 400, loss: 2.801550, top_1: 0.640703, top_k: 0.847422, samples/s: 849.098 1613088363.0895956
train: epoch 80, iter 500, loss: 2.315816, top_1: 0.639141, top_k: 0.844102, samples/s: 846.230 1613088393.341374
train: epoch 80, iter 600, loss: 2.322822, top_1: 0.641289, top_k: 0.846055, samples/s: 843.616 1613088423.6870468
train: epoch 80, iter 700, loss: 2.542349, top_1: 0.642305, top_k: 0.849531, samples/s: 849.149 1613088453.834781
train: epoch 80, iter 800, loss: 2.462327, top_1: 0.644023, top_k: 0.849609, samples/s: 844.593 1613088484.14526
train: epoch 80, iter 900, loss: 2.354681, top_1: 0.637266, top_k: 0.843281, samples/s: 846.418 1613088514.3904517
train: epoch 80, iter 1000, loss: 2.530190, top_1: 0.641406, top_k: 0.847812, samples/s: 847.302 1613088544.6039498
train: epoch 80, iter 1100, loss: 2.521441, top_1: 0.634375, top_k: 0.843125, samples/s: 848.165 1613088574.786738
train: epoch 80, iter 1200, loss: 2.574201, top_1: 0.631055, top_k: 0.840117, samples/s: 848.777 1613088604.9476926
train: epoch 80, iter 1300, loss: 2.512676, top_1: 0.641641, top_k: 0.844570, samples/s: 848.258 1613088635.1272645
train: epoch 80, iter 1400, loss: 2.379446, top_1: 0.636250, top_k: 0.842734, samples/s: 845.924 1613088665.38997
train: epoch 80, iter 1500, loss: 2.553421, top_1: 0.639297, top_k: 0.839570, samples/s: 846.983 1613088695.6149054
train: epoch 80, iter 1600, loss: 2.643976, top_1: 0.637656, top_k: 0.843203, samples/s: 849.708 1613088725.7429197
train: epoch 80, iter 1700, loss: 2.464126, top_1: 0.630195, top_k: 0.835430, samples/s: 846.853 1613088755.97249
train: epoch 80, iter 1800, loss: 2.425425, top_1: 0.634727, top_k: 0.843281, samples/s: 848.855 1613088786.1307154
train: epoch 80, iter 1900, loss: 2.433370, top_1: 0.638086, top_k: 0.845781, samples/s: 849.944 1613088816.250384
train: epoch 80, iter 2000, loss: 2.529490, top_1: 0.640898, top_k: 0.845820, samples/s: 846.128 1613088846.505883
train: epoch 80, iter 2100, loss: 2.396498, top_1: 0.637656, top_k: 0.843711, samples/s: 848.439 1613088876.678964
train: epoch 80, iter 2200, loss: 2.423040, top_1: 0.636523, top_k: 0.839922, samples/s: 846.874 1613088906.9077911
train: epoch 80, iter 2300, loss: 2.381205, top_1: 0.633320, top_k: 0.838555, samples/s: 850.512 1613088937.0073342
train: epoch 80, iter 2400, loss: 2.699025, top_1: 0.629414, top_k: 0.841328, samples/s: 846.507 1613088967.249183
train: epoch 80, iter 2500, loss: 2.414744, top_1: 0.636523, top_k: 0.839883, samples/s: 850.758 1613088997.3399684
train: epoch 80, iter 2600, loss: 2.369575, top_1: 0.636758, top_k: 0.842617, samples/s: 848.713 1613089027.5033915
train: epoch 80, iter 2700, loss: 2.581997, top_1: 0.638789, top_k: 0.842930, samples/s: 848.127 1613089057.687478
train: epoch 80, iter 2800, loss: 2.436484, top_1: 0.632617, top_k: 0.842148, samples/s: 847.361 1613089087.898963
train: epoch 80, iter 2900, loss: 2.417293, top_1: 0.630977, top_k: 0.841367, samples/s: 849.933 1613089118.0190282
train: epoch 80, iter 3000, loss: 2.519698, top_1: 0.634375, top_k: 0.841289, samples/s: 847.088 1613089148.2401853
train: epoch 80, iter 3100, loss: 2.564579, top_1: 0.627852, top_k: 0.838008, samples/s: 848.707 1613089178.403716
train: epoch 80, iter 3200, loss: 2.543073, top_1: 0.629180, top_k: 0.840039, samples/s: 849.050 1613089208.555109
train: epoch 80, iter 3300, loss: 2.349292, top_1: 0.630781, top_k: 0.843359, samples/s: 848.550 1613089238.724204
train: epoch 80, iter 3400, loss: 2.494177, top_1: 0.632617, top_k: 0.844883, samples/s: 848.253 1613089268.9039032
train: epoch 80, iter 3500, loss: 2.454195, top_1: 0.632031, top_k: 0.840195, samples/s: 844.702 1613089299.2103431
train: epoch 80, iter 3600, loss: 2.437533, top_1: 0.634062, top_k: 0.840313, samples/s: 848.270 1613089329.389478
train: epoch 80, iter 3700, loss: 2.456228, top_1: 0.637461, top_k: 0.842969, samples/s: 848.501 1613089359.5602822
train: epoch 80, iter 3800, loss: 2.473376, top_1: 0.627109, top_k: 0.839258, samples/s: 847.785 1613089389.7566442
train: epoch 80, iter 3900, loss: 2.581195, top_1: 0.626055, top_k: 0.835078, samples/s: 847.755 1613089419.9540176
train: epoch 80, iter 4000, loss: 2.584009, top_1: 0.637617, top_k: 0.844141, samples/s: 845.225 1613089450.2418952
train: epoch 80, iter 4100, loss: 2.507146, top_1: 0.631367, top_k: 0.839102, samples/s: 850.920 1613089480.326974
train: epoch 80, iter 4200, loss: 2.409146, top_1: 0.632812, top_k: 0.839609, samples/s: 849.858 1613089510.4496603
train: epoch 80, iter 4300, loss: 2.437416, top_1: 0.629414, top_k: 0.836758, samples/s: 845.067 1613089540.7430892
train: epoch 80, iter 4400, loss: 2.488639, top_1: 0.632383, top_k: 0.840938, samples/s: 847.134 1613089570.9625525
train: epoch 80, iter 4500, loss: 2.397398, top_1: 0.632188, top_k: 0.841250, samples/s: 848.657 1613089601.1279035
train: epoch 80, iter 4600, loss: 2.338456, top_1: 0.629180, top_k: 0.837656, samples/s: 846.005 1613089631.3877852
train: epoch 80, iter 4700, loss: 2.622585, top_1: 0.628398, top_k: 0.839063, samples/s: 849.275 1613089661.5311456
train: epoch 80, iter 4800, loss: 2.614946, top_1: 0.626250, top_k: 0.835977, samples/s: 846.486 1613089691.7737558
train: epoch 80, iter 4900, loss: 2.632480, top_1: 0.629453, top_k: 0.834844, samples/s: 848.328 1613089721.9508448
train: epoch 80, iter 5000, loss: 2.352029, top_1: 0.637813, top_k: 0.840352, samples/s: 846.984 1613089752.1757123
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_80.
validation: epoch 80, iter 195, top_1: 0.678225, top_k: 0.886298, samples/s: 2419.980 1613089773.6429546
train: epoch 81, iter 100, loss: 2.383740, top_1: 0.649375, top_k: 0.852500, samples/s: 870.672 1613089823.9197211
train: epoch 81, iter 200, loss: 2.369603, top_1: 0.645625, top_k: 0.850859, samples/s: 867.419 1613089853.4324956
train: epoch 81, iter 300, loss: 2.397712, top_1: 0.640352, top_k: 0.844961, samples/s: 854.244 1613089883.40053
train: epoch 81, iter 400, loss: 2.502142, top_1: 0.645898, top_k: 0.849336, samples/s: 844.512 1613089913.7139122
train: epoch 81, iter 500, loss: 2.459401, top_1: 0.650781, top_k: 0.854023, samples/s: 845.665 1613089943.985864
train: epoch 81, iter 600, loss: 2.530998, top_1: 0.648711, top_k: 0.850078, samples/s: 845.803 1613089974.2530355
train: epoch 81, iter 700, loss: 2.430361, top_1: 0.643711, top_k: 0.847148, samples/s: 846.609 1613090004.491245
train: epoch 81, iter 800, loss: 2.429601, top_1: 0.642773, top_k: 0.848086, samples/s: 846.951 1613090034.7173283
train: epoch 81, iter 900, loss: 2.628620, top_1: 0.639258, top_k: 0.844492, samples/s: 846.205 1613090064.9701118
train: epoch 81, iter 1000, loss: 2.318183, top_1: 0.638789, top_k: 0.841562, samples/s: 843.492 1613090095.3201978
train: epoch 81, iter 1100, loss: 2.436168, top_1: 0.636406, top_k: 0.843281, samples/s: 850.922 1613090125.405245
train: epoch 81, iter 1200, loss: 2.465409, top_1: 0.640273, top_k: 0.843281, samples/s: 844.347 1613090155.7244322
train: epoch 81, iter 1300, loss: 2.426609, top_1: 0.639492, top_k: 0.845430, samples/s: 850.495 1613090185.8245678
train: epoch 81, iter 1400, loss: 2.488119, top_1: 0.641680, top_k: 0.847148, samples/s: 845.043 1613090216.118838
train: epoch 81, iter 1500, loss: 2.514386, top_1: 0.638047, top_k: 0.840898, samples/s: 847.109 1613090246.3393602
train: epoch 81, iter 1600, loss: 2.481289, top_1: 0.640352, top_k: 0.845703, samples/s: 844.935 1613090276.63755
train: epoch 81, iter 1700, loss: 2.577244, top_1: 0.638437, top_k: 0.847930, samples/s: 848.620 1613090306.8041005
train: epoch 81, iter 1800, loss: 2.454115, top_1: 0.641172, top_k: 0.845859, samples/s: 845.777 1613090337.072201
train: epoch 81, iter 1900, loss: 2.386382, top_1: 0.638906, top_k: 0.842695, samples/s: 847.939 1613090367.262997
train: epoch 81, iter 2000, loss: 2.483138, top_1: 0.642695, top_k: 0.845781, samples/s: 851.012 1613090397.344829
train: epoch 81, iter 2100, loss: 2.709452, top_1: 0.635469, top_k: 0.840781, samples/s: 844.949 1613090427.6425683
train: epoch 81, iter 2200, loss: 2.586266, top_1: 0.634766, top_k: 0.843945, samples/s: 843.515 1613090457.9917297
train: epoch 81, iter 2300, loss: 2.417677, top_1: 0.632109, top_k: 0.839531, samples/s: 849.601 1613090488.1235025
train: epoch 81, iter 2400, loss: 2.457967, top_1: 0.636914, top_k: 0.844258, samples/s: 846.904 1613090518.3513496
train: epoch 81, iter 2500, loss: 2.392478, top_1: 0.633125, top_k: 0.840820, samples/s: 849.851 1613090548.4741542
train: epoch 81, iter 2600, loss: 2.383167, top_1: 0.638594, top_k: 0.843125, samples/s: 845.614 1613090578.7481444
train: epoch 81, iter 2700, loss: 2.455134, top_1: 0.637734, top_k: 0.840234, samples/s: 850.455 1613090608.8496366
train: epoch 81, iter 2800, loss: 2.423565, top_1: 0.641914, top_k: 0.845195, samples/s: 847.741 1613090639.0475922
train: epoch 81, iter 2900, loss: 2.479685, top_1: 0.634687, top_k: 0.842148, samples/s: 847.999 1613090669.2366495
train: epoch 81, iter 3000, loss: 2.463815, top_1: 0.638047, top_k: 0.843047, samples/s: 847.195 1613090699.4535413
train: epoch 81, iter 3100, loss: 2.526901, top_1: 0.635469, top_k: 0.839766, samples/s: 849.763 1613090729.579864
train: epoch 81, iter 3200, loss: 2.581549, top_1: 0.633203, top_k: 0.839805, samples/s: 844.865 1613090759.8803756
train: epoch 81, iter 3300, loss: 2.493860, top_1: 0.633750, top_k: 0.844922, samples/s: 847.163 1613090790.0989168
train: epoch 81, iter 3400, loss: 2.609438, top_1: 0.629297, top_k: 0.838594, samples/s: 849.682 1613090820.2278368
train: epoch 81, iter 3500, loss: 2.399962, top_1: 0.633164, top_k: 0.842578, samples/s: 847.195 1613090850.4451568
train: epoch 81, iter 3600, loss: 2.585824, top_1: 0.632617, top_k: 0.840078, samples/s: 846.519 1613090880.68666
train: epoch 81, iter 3700, loss: 2.554190, top_1: 0.637188, top_k: 0.840039, samples/s: 847.271 1613090910.9014077
train: epoch 81, iter 3800, loss: 2.520903, top_1: 0.633047, top_k: 0.840820, samples/s: 848.529 1613090941.0711577
train: epoch 81, iter 3900, loss: 2.493325, top_1: 0.637617, top_k: 0.844609, samples/s: 848.276 1613090971.2500422
train: epoch 81, iter 4000, loss: 2.533296, top_1: 0.635547, top_k: 0.842812, samples/s: 847.977 1613091001.4394832
train: epoch 81, iter 4100, loss: 2.681946, top_1: 0.637461, top_k: 0.840977, samples/s: 846.236 1613091031.6912162
train: epoch 81, iter 4200, loss: 2.334777, top_1: 0.635781, top_k: 0.845078, samples/s: 846.989 1613091061.9159625
train: epoch 81, iter 4300, loss: 2.506671, top_1: 0.633281, top_k: 0.840273, samples/s: 847.954 1613091092.1061373
train: epoch 81, iter 4400, loss: 2.519219, top_1: 0.636563, top_k: 0.838750, samples/s: 849.892 1613091122.2277024
train: epoch 81, iter 4500, loss: 2.541424, top_1: 0.630859, top_k: 0.841250, samples/s: 845.921 1613091152.4906151
train: epoch 81, iter 4600, loss: 2.737776, top_1: 0.630039, top_k: 0.838203, samples/s: 849.222 1613091182.63585
train: epoch 81, iter 4700, loss: 2.691702, top_1: 0.631367, top_k: 0.839453, samples/s: 849.348 1613091212.7765594
train: epoch 81, iter 4800, loss: 2.650875, top_1: 0.633945, top_k: 0.841328, samples/s: 848.020 1613091242.9645555
train: epoch 81, iter 4900, loss: 2.518285, top_1: 0.631563, top_k: 0.838320, samples/s: 846.701 1613091273.1994936
train: epoch 81, iter 5000, loss: 2.415002, top_1: 0.642539, top_k: 0.849102, samples/s: 847.058 1613091303.4217582
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_81.
validation: epoch 81, iter 195, top_1: 0.683974, top_k: 0.888682, samples/s: 2444.322 1613091324.7505398
train: epoch 82, iter 100, loss: 2.521348, top_1: 0.644492, top_k: 0.849219, samples/s: 871.861 1613091374.4815114
train: epoch 82, iter 200, loss: 2.635364, top_1: 0.643047, top_k: 0.846914, samples/s: 866.946 1613091404.0104427
train: epoch 82, iter 300, loss: 2.385390, top_1: 0.640273, top_k: 0.845352, samples/s: 853.299 1613091434.0116134
train: epoch 82, iter 400, loss: 2.439457, top_1: 0.652227, top_k: 0.853906, samples/s: 847.088 1613091464.2327042
train: epoch 82, iter 500, loss: 2.422785, top_1: 0.648789, top_k: 0.849531, samples/s: 845.750 1613091494.5016942
train: epoch 82, iter 600, loss: 2.626858, top_1: 0.644727, top_k: 0.848906, samples/s: 846.890 1613091524.7299368
train: epoch 82, iter 700, loss: 2.483202, top_1: 0.639648, top_k: 0.844141, samples/s: 846.011 1613091554.9896348
train: epoch 82, iter 800, loss: 2.349363, top_1: 0.641445, top_k: 0.848945, samples/s: 844.927 1613091585.2881188
train: epoch 82, iter 900, loss: 2.610215, top_1: 0.647773, top_k: 0.848125, samples/s: 847.243 1613091615.503819
train: epoch 82, iter 1000, loss: 2.593440, top_1: 0.634258, top_k: 0.843203, samples/s: 848.089 1613091645.6892707
train: epoch 82, iter 1100, loss: 2.605906, top_1: 0.642266, top_k: 0.843516, samples/s: 845.907 1613091675.9526298
train: epoch 82, iter 1200, loss: 2.682301, top_1: 0.637656, top_k: 0.846133, samples/s: 846.795 1613091706.184313
train: epoch 82, iter 1300, loss: 2.396619, top_1: 0.644922, top_k: 0.849258, samples/s: 844.448 1613091736.5000026
train: epoch 82, iter 1400, loss: 2.489588, top_1: 0.645195, top_k: 0.847539, samples/s: 849.790 1613091766.6249924
train: epoch 82, iter 1500, loss: 2.403680, top_1: 0.637930, top_k: 0.843633, samples/s: 845.892 1613091796.8890102
train: epoch 82, iter 1600, loss: 2.388245, top_1: 0.636484, top_k: 0.841641, samples/s: 847.391 1613091827.0993643
train: epoch 82, iter 1700, loss: 2.289577, top_1: 0.637656, top_k: 0.844258, samples/s: 846.324 1613091857.3477511
train: epoch 82, iter 1800, loss: 2.566834, top_1: 0.639102, top_k: 0.843203, samples/s: 845.872 1613091887.6124284
train: epoch 82, iter 1900, loss: 2.429051, top_1: 0.640938, top_k: 0.848672, samples/s: 846.579 1613091917.8517756
train: epoch 82, iter 2000, loss: 2.433302, top_1: 0.634141, top_k: 0.842930, samples/s: 847.246 1613091948.0675817
train: epoch 82, iter 2100, loss: 2.646139, top_1: 0.642617, top_k: 0.844648, samples/s: 845.920 1613091978.3302746
train: epoch 82, iter 2200, loss: 2.525613, top_1: 0.641289, top_k: 0.843828, samples/s: 847.456 1613092008.538785
train: epoch 82, iter 2300, loss: 2.641219, top_1: 0.646250, top_k: 0.845273, samples/s: 846.510 1613092038.7800272
train: epoch 82, iter 2400, loss: 2.603676, top_1: 0.635078, top_k: 0.840391, samples/s: 850.444 1613092068.8819284
train: epoch 82, iter 2500, loss: 2.305643, top_1: 0.645625, top_k: 0.847734, samples/s: 844.035 1613092099.2124228
train: epoch 82, iter 2600, loss: 2.445360, top_1: 0.631914, top_k: 0.843437, samples/s: 848.244 1613092129.3924203
train: epoch 82, iter 2700, loss: 2.288350, top_1: 0.639219, top_k: 0.845156, samples/s: 850.955 1613092159.4762864
train: epoch 82, iter 2800, loss: 2.598425, top_1: 0.641797, top_k: 0.844141, samples/s: 847.009 1613092189.7003772
train: epoch 82, iter 2900, loss: 2.498055, top_1: 0.635312, top_k: 0.844727, samples/s: 848.077 1613092219.8862195
train: epoch 82, iter 3000, loss: 2.481194, top_1: 0.637109, top_k: 0.844023, samples/s: 849.406 1613092250.0249453
train: epoch 82, iter 3100, loss: 2.458216, top_1: 0.643086, top_k: 0.843906, samples/s: 847.626 1613092280.2270083
train: epoch 82, iter 3200, loss: 2.625779, top_1: 0.638594, top_k: 0.840234, samples/s: 848.951 1613092310.3817823
train: epoch 82, iter 3300, loss: 2.572181, top_1: 0.638555, top_k: 0.843359, samples/s: 847.319 1613092340.5947332
train: epoch 82, iter 3400, loss: 2.308055, top_1: 0.637070, top_k: 0.843711, samples/s: 849.277 1613092370.7379901
train: epoch 82, iter 3500, loss: 2.536211, top_1: 0.638437, top_k: 0.842070, samples/s: 847.338 1613092400.9503071
train: epoch 82, iter 3600, loss: 2.564533, top_1: 0.636055, top_k: 0.842305, samples/s: 848.549 1613092431.1194508
train: epoch 82, iter 3700, loss: 2.369167, top_1: 0.637227, top_k: 0.841680, samples/s: 845.262 1613092461.4059372
train: epoch 82, iter 3800, loss: 2.433521, top_1: 0.639375, top_k: 0.843633, samples/s: 846.134 1613092491.661108
train: epoch 82, iter 3900, loss: 2.408269, top_1: 0.638945, top_k: 0.843906, samples/s: 849.299 1613092521.8036196
train: epoch 82, iter 4000, loss: 2.612033, top_1: 0.640820, top_k: 0.844492, samples/s: 844.891 1613092552.103469
train: epoch 82, iter 4100, loss: 2.427070, top_1: 0.637773, top_k: 0.840586, samples/s: 850.017 1613092582.220425
train: epoch 82, iter 4200, loss: 2.343255, top_1: 0.640977, top_k: 0.847461, samples/s: 846.740 1613092612.4541173
train: epoch 82, iter 4300, loss: 2.523937, top_1: 0.629297, top_k: 0.840547, samples/s: 846.324 1613092642.7025826
train: epoch 82, iter 4400, loss: 2.542531, top_1: 0.630781, top_k: 0.836250, samples/s: 844.045 1613092673.0326352
train: epoch 82, iter 4500, loss: 2.482687, top_1: 0.636563, top_k: 0.843164, samples/s: 848.722 1613092703.1956344
train: epoch 82, iter 4600, loss: 2.422813, top_1: 0.632266, top_k: 0.842500, samples/s: 848.537 1613092733.3652446
train: epoch 82, iter 4700, loss: 2.405432, top_1: 0.632930, top_k: 0.840508, samples/s: 848.890 1613092763.5222204
train: epoch 82, iter 4800, loss: 2.713092, top_1: 0.630703, top_k: 0.839023, samples/s: 847.421 1613092793.731589
train: epoch 82, iter 4900, loss: 2.677338, top_1: 0.632539, top_k: 0.841133, samples/s: 847.617 1613092823.9338677
train: epoch 82, iter 5000, loss: 2.438053, top_1: 0.640586, top_k: 0.845273, samples/s: 846.313 1613092854.1826751
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_82.
validation: epoch 82, iter 195, top_1: 0.680349, top_k: 0.886438, samples/s: 2451.796 1613092875.4437659
train: epoch 83, iter 100, loss: 2.521987, top_1: 0.648477, top_k: 0.852461, samples/s: 869.861 1613092925.3601336
train: epoch 83, iter 200, loss: 2.520507, top_1: 0.648008, top_k: 0.848359, samples/s: 868.431 1613092954.8386035
train: epoch 83, iter 300, loss: 2.292324, top_1: 0.646289, top_k: 0.850859, samples/s: 852.121 1613092984.8813205
train: epoch 83, iter 400, loss: 2.240519, top_1: 0.648320, top_k: 0.851484, samples/s: 845.516 1613093015.1586256
train: epoch 83, iter 500, loss: 2.468239, top_1: 0.645742, top_k: 0.849766, samples/s: 845.800 1613093045.4257672
train: epoch 83, iter 600, loss: 2.440405, top_1: 0.647734, top_k: 0.850313, samples/s: 847.783 1613093075.6222224
train: epoch 83, iter 700, loss: 2.492533, top_1: 0.654961, top_k: 0.852109, samples/s: 844.866 1613093105.9228537
train: epoch 83, iter 800, loss: 2.229675, top_1: 0.648242, top_k: 0.849180, samples/s: 844.501 1613093136.2366557
train: epoch 83, iter 900, loss: 2.470478, top_1: 0.646172, top_k: 0.844258, samples/s: 846.017 1613093166.496071
train: epoch 83, iter 1000, loss: 2.470675, top_1: 0.643711, top_k: 0.847305, samples/s: 845.562 1613093196.7717726
train: epoch 83, iter 1100, loss: 2.369984, top_1: 0.649258, top_k: 0.852617, samples/s: 844.737 1613093227.077087
train: epoch 83, iter 1200, loss: 2.441487, top_1: 0.640078, top_k: 0.843320, samples/s: 848.417 1613093257.2509942
train: epoch 83, iter 1300, loss: 2.595000, top_1: 0.637031, top_k: 0.842422, samples/s: 848.052 1613093287.437866
train: epoch 83, iter 1400, loss: 2.432628, top_1: 0.637969, top_k: 0.845313, samples/s: 847.747 1613093317.6354399
train: epoch 83, iter 1500, loss: 2.501513, top_1: 0.633164, top_k: 0.842969, samples/s: 847.255 1613093347.8506904
train: epoch 83, iter 1600, loss: 2.379507, top_1: 0.639883, top_k: 0.848750, samples/s: 845.869 1613093378.1154993
train: epoch 83, iter 1700, loss: 2.478353, top_1: 0.643945, top_k: 0.848477, samples/s: 846.355 1613093408.3627908
train: epoch 83, iter 1800, loss: 2.614851, top_1: 0.638477, top_k: 0.844844, samples/s: 849.707 1613093438.490898
train: epoch 83, iter 1900, loss: 2.532718, top_1: 0.637734, top_k: 0.840664, samples/s: 846.095 1613093468.7475135
train: epoch 83, iter 2000, loss: 2.413897, top_1: 0.641563, top_k: 0.845547, samples/s: 847.167 1613093498.9659321
train: epoch 83, iter 2100, loss: 2.561972, top_1: 0.645938, top_k: 0.847891, samples/s: 848.201 1613093529.1474738
train: epoch 83, iter 2200, loss: 2.278855, top_1: 0.638203, top_k: 0.846016, samples/s: 846.808 1613093559.3785968
train: epoch 83, iter 2300, loss: 2.709434, top_1: 0.642891, top_k: 0.851055, samples/s: 845.440 1613093589.6586952
train: epoch 83, iter 2400, loss: 2.370881, top_1: 0.640039, top_k: 0.845938, samples/s: 850.034 1613093619.7751024
train: epoch 83, iter 2500, loss: 2.504737, top_1: 0.641250, top_k: 0.848750, samples/s: 847.453 1613093649.9832404
train: epoch 83, iter 2600, loss: 2.477595, top_1: 0.644922, top_k: 0.843203, samples/s: 847.800 1613093680.1791236
train: epoch 83, iter 2700, loss: 2.531750, top_1: 0.643164, top_k: 0.845156, samples/s: 845.534 1613093710.4558628
train: epoch 83, iter 2800, loss: 2.417740, top_1: 0.643633, top_k: 0.845664, samples/s: 847.339 1613093740.6681132
train: epoch 83, iter 2900, loss: 2.610490, top_1: 0.639375, top_k: 0.842891, samples/s: 847.430 1613093770.8771045
train: epoch 83, iter 3000, loss: 2.261835, top_1: 0.637461, top_k: 0.844805, samples/s: 850.141 1613093800.989769
train: epoch 83, iter 3100, loss: 2.691370, top_1: 0.637539, top_k: 0.845117, samples/s: 842.722 1613093831.3675332
train: epoch 83, iter 3200, loss: 2.482681, top_1: 0.632070, top_k: 0.842383, samples/s: 851.353 1613093861.437258
train: epoch 83, iter 3300, loss: 2.466928, top_1: 0.637227, top_k: 0.843437, samples/s: 844.386 1613093891.755116
train: epoch 83, iter 3400, loss: 2.541349, top_1: 0.641406, top_k: 0.843867, samples/s: 848.243 1613093921.935157
train: epoch 83, iter 3500, loss: 2.579185, top_1: 0.639336, top_k: 0.845859, samples/s: 848.958 1613093952.0897756
train: epoch 83, iter 3600, loss: 2.450936, top_1: 0.639648, top_k: 0.840547, samples/s: 846.198 1613093982.3427794
train: epoch 83, iter 3700, loss: 2.800067, top_1: 0.637227, top_k: 0.840547, samples/s: 849.462 1613094012.47953
train: epoch 83, iter 3800, loss: 2.457319, top_1: 0.638359, top_k: 0.844375, samples/s: 844.901 1613094042.7789502
train: epoch 83, iter 3900, loss: 2.343217, top_1: 0.635938, top_k: 0.838594, samples/s: 848.405 1613094072.9532473
train: epoch 83, iter 4000, loss: 2.331370, top_1: 0.639336, top_k: 0.845547, samples/s: 849.381 1613094103.0927215
train: epoch 83, iter 4100, loss: 2.368816, top_1: 0.636094, top_k: 0.842969, samples/s: 847.835 1613094133.2872818
train: epoch 83, iter 4200, loss: 2.633450, top_1: 0.636367, top_k: 0.844883, samples/s: 846.715 1613094163.521857
train: epoch 83, iter 4300, loss: 2.492301, top_1: 0.640508, top_k: 0.847656, samples/s: 849.048 1613094193.673234
train: epoch 83, iter 4400, loss: 2.442295, top_1: 0.638594, top_k: 0.844297, samples/s: 847.883 1613094223.8661556
train: epoch 83, iter 4500, loss: 2.490446, top_1: 0.637461, top_k: 0.846172, samples/s: 843.994 1613094254.1980453
train: epoch 83, iter 4600, loss: 2.470894, top_1: 0.634961, top_k: 0.845234, samples/s: 847.340 1613094284.4102376
train: epoch 83, iter 4700, loss: 2.401732, top_1: 0.635117, top_k: 0.840859, samples/s: 847.533 1613094314.6156263
train: epoch 83, iter 4800, loss: 2.482003, top_1: 0.630898, top_k: 0.840664, samples/s: 850.290 1613094344.723025
train: epoch 83, iter 4900, loss: 2.397401, top_1: 0.636992, top_k: 0.841133, samples/s: 846.159 1613094374.9773366
train: epoch 83, iter 5000, loss: 2.541533, top_1: 0.643477, top_k: 0.845625, samples/s: 846.775 1613094405.209725
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_83.
validation: epoch 83, iter 195, top_1: 0.681871, top_k: 0.885717, samples/s: 2434.895 1613094426.636395
train: epoch 84, iter 100, loss: 2.486909, top_1: 0.655742, top_k: 0.851797, samples/s: 870.880 1613094482.1142468
train: epoch 84, iter 200, loss: 2.242021, top_1: 0.651875, top_k: 0.852891, samples/s: 867.189 1613094511.6349607
train: epoch 84, iter 300, loss: 2.406602, top_1: 0.648125, top_k: 0.850898, samples/s: 854.640 1613094541.589123
train: epoch 84, iter 400, loss: 2.473873, top_1: 0.650156, top_k: 0.853789, samples/s: 849.726 1613094571.7163944
train: epoch 84, iter 500, loss: 2.526459, top_1: 0.651172, top_k: 0.851641, samples/s: 843.762 1613094602.0567138
train: epoch 84, iter 600, loss: 2.377501, top_1: 0.649180, top_k: 0.849844, samples/s: 848.972 1613094632.21088
train: epoch 84, iter 700, loss: 2.400967, top_1: 0.643164, top_k: 0.848477, samples/s: 844.125 1613094662.5381453
train: epoch 84, iter 800, loss: 2.373742, top_1: 0.645820, top_k: 0.849727, samples/s: 847.465 1613094692.745875
train: epoch 84, iter 900, loss: 2.469503, top_1: 0.643672, top_k: 0.848594, samples/s: 843.384 1613094723.0997076
train: epoch 84, iter 1000, loss: 2.491262, top_1: 0.640703, top_k: 0.849180, samples/s: 849.577 1613094753.2324302
train: epoch 84, iter 1100, loss: 2.530183, top_1: 0.651289, top_k: 0.852891, samples/s: 844.320 1613094783.5526161
train: epoch 84, iter 1200, loss: 2.114175, top_1: 0.653086, top_k: 0.854805, samples/s: 847.947 1613094813.7432587
train: epoch 84, iter 1300, loss: 2.372241, top_1: 0.639805, top_k: 0.844961, samples/s: 846.743 1613094843.9767413
train: epoch 84, iter 1400, loss: 2.385978, top_1: 0.644297, top_k: 0.850117, samples/s: 847.709 1613094874.1757066
train: epoch 84, iter 1500, loss: 2.452473, top_1: 0.650352, top_k: 0.851367, samples/s: 848.180 1613094904.3580763
train: epoch 84, iter 1600, loss: 2.413871, top_1: 0.640312, top_k: 0.846484, samples/s: 845.704 1613094934.6286287
train: epoch 84, iter 1700, loss: 2.539190, top_1: 0.638203, top_k: 0.844375, samples/s: 845.064 1613094964.9223104
train: epoch 84, iter 1800, loss: 2.690146, top_1: 0.644609, top_k: 0.848633, samples/s: 849.478 1613094995.0584342
train: epoch 84, iter 1900, loss: 2.616286, top_1: 0.638320, top_k: 0.843906, samples/s: 846.613 1613095025.2965083
train: epoch 84, iter 2000, loss: 2.266516, top_1: 0.650039, top_k: 0.852500, samples/s: 848.036 1613095055.4839063
train: epoch 84, iter 2100, loss: 2.432685, top_1: 0.639219, top_k: 0.846289, samples/s: 845.550 1613095085.760057
train: epoch 84, iter 2200, loss: 2.541326, top_1: 0.633516, top_k: 0.843477, samples/s: 848.541 1613095115.9295337
train: epoch 84, iter 2300, loss: 2.524104, top_1: 0.641719, top_k: 0.845352, samples/s: 846.632 1613095146.1669433
train: epoch 84, iter 2400, loss: 2.574136, top_1: 0.640508, top_k: 0.841328, samples/s: 846.363 1613095176.4140222
train: epoch 84, iter 2500, loss: 2.663990, top_1: 0.639609, top_k: 0.846133, samples/s: 847.016 1613095206.6377435
train: epoch 84, iter 2600, loss: 2.495118, top_1: 0.642305, top_k: 0.844219, samples/s: 849.141 1613095236.7859054
train: epoch 84, iter 2700, loss: 2.624430, top_1: 0.637500, top_k: 0.844883, samples/s: 845.866 1613095267.0507321
train: epoch 84, iter 2800, loss: 2.455100, top_1: 0.642891, top_k: 0.846484, samples/s: 845.587 1613095297.3254607
train: epoch 84, iter 2900, loss: 2.630347, top_1: 0.645547, top_k: 0.845078, samples/s: 846.754 1613095327.558645
train: epoch 84, iter 3000, loss: 2.373429, top_1: 0.637227, top_k: 0.840898, samples/s: 847.272 1613095357.7732759
train: epoch 84, iter 3100, loss: 2.461683, top_1: 0.638281, top_k: 0.843945, samples/s: 849.391 1613095387.9124215
train: epoch 84, iter 3200, loss: 2.544002, top_1: 0.635781, top_k: 0.842695, samples/s: 845.302 1613095418.1974635
train: epoch 84, iter 3300, loss: 2.423209, top_1: 0.638320, top_k: 0.845078, samples/s: 847.971 1613095448.38726
train: epoch 84, iter 3400, loss: 2.480034, top_1: 0.641328, top_k: 0.844102, samples/s: 847.126 1613095478.606979
train: epoch 84, iter 3500, loss: 2.350692, top_1: 0.641211, top_k: 0.845625, samples/s: 843.348 1613095508.9622605
train: epoch 84, iter 3600, loss: 2.333868, top_1: 0.642773, top_k: 0.843789, samples/s: 848.800 1613095539.12245
train: epoch 84, iter 3700, loss: 2.392600, top_1: 0.639336, top_k: 0.845508, samples/s: 844.945 1613095569.4203246
train: epoch 84, iter 3800, loss: 2.461214, top_1: 0.638203, top_k: 0.843281, samples/s: 850.403 1613095599.5237052
train: epoch 84, iter 3900, loss: 2.251640, top_1: 0.640469, top_k: 0.845469, samples/s: 846.126 1613095629.779221
train: epoch 84, iter 4000, loss: 2.465324, top_1: 0.644961, top_k: 0.849453, samples/s: 847.061 1613095660.0012882
train: epoch 84, iter 4100, loss: 2.302239, top_1: 0.636055, top_k: 0.846250, samples/s: 846.874 1613095690.2301989
train: epoch 84, iter 4200, loss: 2.405465, top_1: 0.645430, top_k: 0.844258, samples/s: 849.308 1613095720.3723338
train: epoch 84, iter 4300, loss: 2.609416, top_1: 0.638242, top_k: 0.846875, samples/s: 846.352 1613095750.6198218
train: epoch 84, iter 4400, loss: 2.339397, top_1: 0.642578, top_k: 0.841484, samples/s: 850.530 1613095780.7187047
train: epoch 84, iter 4500, loss: 2.472936, top_1: 0.638984, top_k: 0.843984, samples/s: 847.043 1613095810.9414268
train: epoch 84, iter 4600, loss: 2.575809, top_1: 0.637656, top_k: 0.843594, samples/s: 847.577 1613095841.1451473
train: epoch 84, iter 4700, loss: 2.404531, top_1: 0.633984, top_k: 0.841602, samples/s: 845.473 1613095871.4241192
train: epoch 84, iter 4800, loss: 2.375454, top_1: 0.638633, top_k: 0.844023, samples/s: 849.375 1613095901.5639234
train: epoch 84, iter 4900, loss: 2.444079, top_1: 0.640000, top_k: 0.842969, samples/s: 846.891 1613095931.7922153
train: epoch 84, iter 5000, loss: 2.665887, top_1: 0.643945, top_k: 0.847031, samples/s: 849.661 1613095961.921804
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_84.
validation: epoch 84, iter 195, top_1: 0.679708, top_k: 0.888161, samples/s: 2435.563 1613095983.3168037
train: epoch 85, iter 100, loss: 2.418451, top_1: 0.650820, top_k: 0.853516, samples/s: 870.737 1613096033.5295525
train: epoch 85, iter 200, loss: 2.516745, top_1: 0.655820, top_k: 0.855117, samples/s: 867.353 1613096063.0445626
train: epoch 85, iter 300, loss: 2.377797, top_1: 0.649727, top_k: 0.851445, samples/s: 849.397 1613096093.1835961
train: epoch 85, iter 400, loss: 2.276404, top_1: 0.650586, top_k: 0.852422, samples/s: 846.385 1613096123.4298387
train: epoch 85, iter 500, loss: 2.500719, top_1: 0.646016, top_k: 0.850469, samples/s: 847.077 1613096153.651492
train: epoch 85, iter 600, loss: 2.390355, top_1: 0.648398, top_k: 0.850859, samples/s: 845.805 1613096183.9185107
train: epoch 85, iter 700, loss: 2.458823, top_1: 0.651641, top_k: 0.852812, samples/s: 846.708 1613096214.1532462
train: epoch 85, iter 800, loss: 2.297213, top_1: 0.650039, top_k: 0.851484, samples/s: 843.828 1613096244.4911637
train: epoch 85, iter 900, loss: 2.434481, top_1: 0.646367, top_k: 0.851992, samples/s: 847.319 1613096274.7040527
train: epoch 85, iter 1000, loss: 2.389900, top_1: 0.651602, top_k: 0.854531, samples/s: 845.722 1613096304.974126
train: epoch 85, iter 1100, loss: 2.450026, top_1: 0.652461, top_k: 0.854102, samples/s: 847.824 1613096335.1690555
train: epoch 85, iter 1200, loss: 2.377778, top_1: 0.647070, top_k: 0.849961, samples/s: 846.647 1613096365.4059467
train: epoch 85, iter 1300, loss: 2.413460, top_1: 0.647109, top_k: 0.850703, samples/s: 843.565 1613096395.7533557
train: epoch 85, iter 1400, loss: 2.316199, top_1: 0.648594, top_k: 0.849453, samples/s: 848.212 1613096425.9343812
train: epoch 85, iter 1500, loss: 2.596687, top_1: 0.644883, top_k: 0.849180, samples/s: 846.242 1613096456.1858804
train: epoch 85, iter 1600, loss: 2.461214, top_1: 0.648086, top_k: 0.845742, samples/s: 846.601 1613096486.4243956
train: epoch 85, iter 1700, loss: 2.525427, top_1: 0.646992, top_k: 0.846484, samples/s: 845.107 1613096516.7164292
train: epoch 85, iter 1800, loss: 2.584420, top_1: 0.641484, top_k: 0.845273, samples/s: 848.361 1613096546.8922932
train: epoch 85, iter 1900, loss: 2.519975, top_1: 0.641797, top_k: 0.845352, samples/s: 846.416 1613096577.137336
train: epoch 85, iter 2000, loss: 2.394435, top_1: 0.640352, top_k: 0.848086, samples/s: 847.555 1613096607.3419816
train: epoch 85, iter 2100, loss: 2.541484, top_1: 0.645586, top_k: 0.848398, samples/s: 847.010 1613096637.5658555
train: epoch 85, iter 2200, loss: 2.270737, top_1: 0.645508, top_k: 0.846758, samples/s: 845.985 1613096667.8264804
train: epoch 85, iter 2300, loss: 2.335880, top_1: 0.643633, top_k: 0.847891, samples/s: 846.084 1613096698.083479
train: epoch 85, iter 2400, loss: 2.543946, top_1: 0.636406, top_k: 0.839102, samples/s: 847.258 1613096728.2985764
train: epoch 85, iter 2500, loss: 2.392496, top_1: 0.645352, top_k: 0.850234, samples/s: 848.325 1613096758.4757497
train: epoch 85, iter 2600, loss: 2.592333, top_1: 0.641992, top_k: 0.847852, samples/s: 846.599 1613096788.7143323
train: epoch 85, iter 2700, loss: 2.387052, top_1: 0.645273, top_k: 0.845820, samples/s: 848.228 1613096818.8948646
train: epoch 85, iter 2800, loss: 2.517735, top_1: 0.639531, top_k: 0.844180, samples/s: 845.044 1613096849.189204
train: epoch 85, iter 2900, loss: 2.637269, top_1: 0.642188, top_k: 0.844648, samples/s: 848.510 1613096879.359808
train: epoch 85, iter 3000, loss: 2.415295, top_1: 0.645312, top_k: 0.847734, samples/s: 850.313 1613096909.4662697
train: epoch 85, iter 3100, loss: 2.448274, top_1: 0.643984, top_k: 0.849375, samples/s: 846.569 1613096939.7060041
train: epoch 85, iter 3200, loss: 2.423055, top_1: 0.641602, top_k: 0.842695, samples/s: 848.848 1613096969.864551
train: epoch 85, iter 3300, loss: 2.424965, top_1: 0.642070, top_k: 0.848164, samples/s: 845.152 1613097000.1549056
train: epoch 85, iter 3400, loss: 2.455033, top_1: 0.644453, top_k: 0.844570, samples/s: 850.017 1613097030.272011
train: epoch 85, iter 3500, loss: 2.664938, top_1: 0.639922, top_k: 0.846484, samples/s: 845.851 1613097060.537415
train: epoch 85, iter 3600, loss: 2.419613, top_1: 0.640625, top_k: 0.846094, samples/s: 845.785 1613097090.8051176
train: epoch 85, iter 3700, loss: 2.426279, top_1: 0.644961, top_k: 0.847500, samples/s: 847.553 1613097121.009759
train: epoch 85, iter 3800, loss: 2.462972, top_1: 0.648047, top_k: 0.848320, samples/s: 846.299 1613097151.2590487
train: epoch 85, iter 3900, loss: 2.421889, top_1: 0.642695, top_k: 0.845742, samples/s: 846.395 1613097181.5049357
train: epoch 85, iter 4000, loss: 2.427820, top_1: 0.641328, top_k: 0.845938, samples/s: 849.224 1613097211.6501584
train: epoch 85, iter 4100, loss: 2.633675, top_1: 0.640039, top_k: 0.847187, samples/s: 848.502 1613097241.82104
train: epoch 85, iter 4200, loss: 2.211676, top_1: 0.640938, top_k: 0.843633, samples/s: 846.905 1613097272.0486445
train: epoch 85, iter 4300, loss: 2.490278, top_1: 0.636484, top_k: 0.846914, samples/s: 846.098 1613097302.3052828
train: epoch 85, iter 4400, loss: 2.470799, top_1: 0.642656, top_k: 0.846523, samples/s: 846.261 1613097332.5559971
train: epoch 85, iter 4500, loss: 2.601068, top_1: 0.637813, top_k: 0.843633, samples/s: 845.729 1613097362.8256812
train: epoch 85, iter 4600, loss: 2.671448, top_1: 0.635586, top_k: 0.840664, samples/s: 849.355 1613097392.9661918
train: epoch 85, iter 4700, loss: 2.565861, top_1: 0.639648, top_k: 0.843672, samples/s: 844.845 1613097423.2676272
train: epoch 85, iter 4800, loss: 2.466198, top_1: 0.635898, top_k: 0.844648, samples/s: 845.571 1613097453.54311
train: epoch 85, iter 4900, loss: 2.657485, top_1: 0.643164, top_k: 0.845195, samples/s: 850.419 1613097483.6458168
train: epoch 85, iter 5000, loss: 2.559537, top_1: 0.642227, top_k: 0.845859, samples/s: 846.551 1613097513.886186
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_85.
validation: epoch 85, iter 195, top_1: 0.685136, top_k: 0.889724, samples/s: 2446.934 1613097535.18258
train: epoch 86, iter 100, loss: 2.514976, top_1: 0.647852, top_k: 0.848672, samples/s: 869.692 1613097585.2151585
train: epoch 86, iter 200, loss: 2.377298, top_1: 0.648086, top_k: 0.850820, samples/s: 867.446 1613097614.7270596
train: epoch 86, iter 300, loss: 2.241350, top_1: 0.659805, top_k: 0.857109, samples/s: 852.286 1613097644.7639573
train: epoch 86, iter 400, loss: 2.351896, top_1: 0.652539, top_k: 0.855313, samples/s: 847.532 1613097674.9692721
train: epoch 86, iter 500, loss: 2.448035, top_1: 0.654648, top_k: 0.855313, samples/s: 847.390 1613097705.1796305
train: epoch 86, iter 600, loss: 2.334464, top_1: 0.648125, top_k: 0.847617, samples/s: 842.969 1613097735.5485
train: epoch 86, iter 700, loss: 2.502162, top_1: 0.650234, top_k: 0.850313, samples/s: 850.249 1613097765.6573732
train: epoch 86, iter 800, loss: 2.603111, top_1: 0.650273, top_k: 0.851602, samples/s: 845.498 1613097795.9353254
train: epoch 86, iter 900, loss: 2.444718, top_1: 0.653789, top_k: 0.851367, samples/s: 844.731 1613097826.2409012
train: epoch 86, iter 1000, loss: 2.495780, top_1: 0.647617, top_k: 0.852109, samples/s: 845.310 1613097856.5256124
train: epoch 86, iter 1100, loss: 2.411873, top_1: 0.651797, top_k: 0.854922, samples/s: 843.805 1613097886.864436
train: epoch 86, iter 1200, loss: 2.361936, top_1: 0.648281, top_k: 0.852617, samples/s: 848.466 1613097917.036556
train: epoch 86, iter 1300, loss: 2.376675, top_1: 0.649414, top_k: 0.854219, samples/s: 845.448 1613097947.3162673
train: epoch 86, iter 1400, loss: 2.355794, top_1: 0.647383, top_k: 0.848047, samples/s: 844.090 1613097977.644795
train: epoch 86, iter 1500, loss: 2.417602, top_1: 0.648242, top_k: 0.850742, samples/s: 847.727 1613098007.8432138
train: epoch 86, iter 1600, loss: 2.167459, top_1: 0.645078, top_k: 0.845078, samples/s: 846.771 1613098038.0756564
train: epoch 86, iter 1700, loss: 2.405174, top_1: 0.645977, top_k: 0.848047, samples/s: 845.440 1613098068.355786
train: epoch 86, iter 1800, loss: 2.454766, top_1: 0.646016, top_k: 0.847734, samples/s: 845.007 1613098098.6514018
train: epoch 86, iter 1900, loss: 2.426972, top_1: 0.652656, top_k: 0.850547, samples/s: 845.449 1613098128.931265
train: epoch 86, iter 2000, loss: 2.343282, top_1: 0.640469, top_k: 0.843945, samples/s: 848.674 1613098159.0958426
train: epoch 86, iter 2100, loss: 2.475589, top_1: 0.650977, top_k: 0.851094, samples/s: 844.836 1613098189.3976192
train: epoch 86, iter 2200, loss: 2.598531, top_1: 0.648789, top_k: 0.848633, samples/s: 846.941 1613098219.6240232
train: epoch 86, iter 2300, loss: 2.712075, top_1: 0.642266, top_k: 0.849180, samples/s: 843.616 1613098249.9695935
train: epoch 86, iter 2400, loss: 2.496294, top_1: 0.646992, top_k: 0.848828, samples/s: 847.813 1613098280.1649249
train: epoch 86, iter 2500, loss: 2.405760, top_1: 0.647539, top_k: 0.855234, samples/s: 847.794 1613098310.3610482
train: epoch 86, iter 2600, loss: 2.383791, top_1: 0.641250, top_k: 0.848672, samples/s: 848.710 1613098340.5244498
train: epoch 86, iter 2700, loss: 2.435959, top_1: 0.642188, top_k: 0.846289, samples/s: 843.238 1613098370.8835745
train: epoch 86, iter 2800, loss: 2.317129, top_1: 0.642539, top_k: 0.846211, samples/s: 845.526 1613098401.1606588
train: epoch 86, iter 2900, loss: 2.505209, top_1: 0.646563, top_k: 0.850352, samples/s: 849.557 1613098431.2938905
train: epoch 86, iter 3000, loss: 2.571683, top_1: 0.644844, top_k: 0.846445, samples/s: 845.946 1613098461.555897
train: epoch 86, iter 3100, loss: 2.427275, top_1: 0.645508, top_k: 0.846562, samples/s: 845.676 1613098491.8275278
train: epoch 86, iter 3200, loss: 2.429392, top_1: 0.645781, top_k: 0.849023, samples/s: 848.303 1613098522.0054116
train: epoch 86, iter 3300, loss: 2.452939, top_1: 0.642969, top_k: 0.846602, samples/s: 848.793 1613098552.1658564
train: epoch 86, iter 3400, loss: 2.437572, top_1: 0.642305, top_k: 0.846211, samples/s: 844.626 1613098582.4752526
train: epoch 86, iter 3500, loss: 2.531523, top_1: 0.642969, top_k: 0.846172, samples/s: 847.201 1613098612.692322
train: epoch 86, iter 3600, loss: 2.542163, top_1: 0.646289, top_k: 0.848750, samples/s: 844.912 1613098642.991367
train: epoch 86, iter 3700, loss: 2.491634, top_1: 0.645156, top_k: 0.850000, samples/s: 850.551 1613098673.0895257
train: epoch 86, iter 3800, loss: 2.454473, top_1: 0.646953, top_k: 0.846953, samples/s: 845.963 1613098703.3509345
train: epoch 86, iter 3900, loss: 2.479485, top_1: 0.641953, top_k: 0.847344, samples/s: 848.410 1613098733.5249186
train: epoch 86, iter 4000, loss: 2.553706, top_1: 0.647656, top_k: 0.848633, samples/s: 847.318 1613098763.7379248
train: epoch 86, iter 4100, loss: 2.438833, top_1: 0.635898, top_k: 0.844063, samples/s: 847.110 1613098793.958285
train: epoch 86, iter 4200, loss: 2.361000, top_1: 0.642109, top_k: 0.847227, samples/s: 847.009 1613098824.1823769
train: epoch 86, iter 4300, loss: 2.498086, top_1: 0.640352, top_k: 0.846328, samples/s: 846.568 1613098854.4220355
train: epoch 86, iter 4400, loss: 2.566846, top_1: 0.641523, top_k: 0.844648, samples/s: 847.325 1613098884.6347847
train: epoch 86, iter 4500, loss: 2.491812, top_1: 0.638359, top_k: 0.843281, samples/s: 848.089 1613098914.82032
train: epoch 86, iter 4600, loss: 2.279060, top_1: 0.646445, top_k: 0.847148, samples/s: 845.613 1613098945.0941262
train: epoch 86, iter 4700, loss: 2.566545, top_1: 0.639570, top_k: 0.848008, samples/s: 847.126 1613098975.3139663
train: epoch 86, iter 4800, loss: 2.384181, top_1: 0.639883, top_k: 0.843516, samples/s: 847.961 1613099005.5040169
train: epoch 86, iter 4900, loss: 2.537080, top_1: 0.638242, top_k: 0.844414, samples/s: 847.283 1613099035.7182887
train: epoch 86, iter 5000, loss: 2.360613, top_1: 0.644297, top_k: 0.848359, samples/s: 846.445 1613099065.9627259
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_86.
validation: epoch 86, iter 195, top_1: 0.685757, top_k: 0.887540, samples/s: 2452.789 1613099087.2352304
train: epoch 87, iter 100, loss: 2.223258, top_1: 0.664414, top_k: 0.858867, samples/s: 867.679 1613099138.0064154
train: epoch 87, iter 200, loss: 2.327465, top_1: 0.655469, top_k: 0.854180, samples/s: 867.301 1613099167.5235245
train: epoch 87, iter 300, loss: 2.495909, top_1: 0.647070, top_k: 0.850000, samples/s: 850.094 1613099197.6375773
train: epoch 87, iter 400, loss: 2.490140, top_1: 0.656914, top_k: 0.856797, samples/s: 846.937 1613099227.8642375
train: epoch 87, iter 500, loss: 2.336298, top_1: 0.655391, top_k: 0.856758, samples/s: 844.344 1613099258.1836534
train: epoch 87, iter 600, loss: 2.436527, top_1: 0.654219, top_k: 0.854805, samples/s: 846.625 1613099288.4213536
train: epoch 87, iter 700, loss: 2.432382, top_1: 0.653945, top_k: 0.854961, samples/s: 845.730 1613099318.691036
train: epoch 87, iter 800, loss: 2.554903, top_1: 0.651211, top_k: 0.851641, samples/s: 845.093 1613099348.983453
train: epoch 87, iter 900, loss: 2.479892, top_1: 0.656914, top_k: 0.857891, samples/s: 844.533 1613099379.2961066
train: epoch 87, iter 1000, loss: 2.374749, top_1: 0.648867, top_k: 0.850000, samples/s: 849.426 1613099409.4340463
train: epoch 87, iter 1100, loss: 2.603674, top_1: 0.647031, top_k: 0.849727, samples/s: 842.002 1613099439.837823
train: epoch 87, iter 1200, loss: 2.489236, top_1: 0.648242, top_k: 0.851016, samples/s: 844.722 1613099470.1436887
train: epoch 87, iter 1300, loss: 2.635261, top_1: 0.644023, top_k: 0.848672, samples/s: 844.318 1613099500.464022
train: epoch 87, iter 1400, loss: 2.395366, top_1: 0.646484, top_k: 0.851484, samples/s: 844.946 1613099530.7618556
train: epoch 87, iter 1500, loss: 2.400850, top_1: 0.657305, top_k: 0.853398, samples/s: 846.670 1613099560.9979415
train: epoch 87, iter 1600, loss: 2.626910, top_1: 0.650039, top_k: 0.850742, samples/s: 847.536 1613099591.2030528
train: epoch 87, iter 1700, loss: 2.461985, top_1: 0.650820, top_k: 0.855547, samples/s: 845.547 1613099621.4794352
train: epoch 87, iter 1800, loss: 2.465482, top_1: 0.650781, top_k: 0.852539, samples/s: 847.192 1613099651.696894
train: epoch 87, iter 1900, loss: 2.369287, top_1: 0.647813, top_k: 0.851055, samples/s: 846.676 1613099681.932702
train: epoch 87, iter 2000, loss: 2.338424, top_1: 0.649961, top_k: 0.849883, samples/s: 844.728 1613099712.2384512
train: epoch 87, iter 2100, loss: 2.302286, top_1: 0.643164, top_k: 0.845742, samples/s: 846.577 1613099742.4777327
train: epoch 87, iter 2200, loss: 2.442873, top_1: 0.650703, top_k: 0.852461, samples/s: 846.568 1613099772.7175143
train: epoch 87, iter 2300, loss: 2.467257, top_1: 0.645352, top_k: 0.848242, samples/s: 845.070 1613099803.0108347
train: epoch 87, iter 2400, loss: 2.437355, top_1: 0.651602, top_k: 0.855508, samples/s: 845.741 1613099833.2802646
train: epoch 87, iter 2500, loss: 2.583419, top_1: 0.645898, top_k: 0.848633, samples/s: 848.770 1613099863.4415295
train: epoch 87, iter 2600, loss: 2.431989, top_1: 0.640742, top_k: 0.847617, samples/s: 846.936 1613099893.6681411
train: epoch 87, iter 2700, loss: 2.587590, top_1: 0.646250, top_k: 0.851328, samples/s: 848.262 1613099923.8475075
train: epoch 87, iter 2800, loss: 2.597901, top_1: 0.646719, top_k: 0.852695, samples/s: 843.670 1613099954.1910229
train: epoch 87, iter 2900, loss: 2.486368, top_1: 0.645430, top_k: 0.847227, samples/s: 848.088 1613099984.3766572
train: epoch 87, iter 3000, loss: 2.284244, top_1: 0.646602, top_k: 0.849531, samples/s: 847.283 1613100014.5908759
train: epoch 87, iter 3100, loss: 2.656490, top_1: 0.646641, top_k: 0.849844, samples/s: 845.258 1613100044.8773816
train: epoch 87, iter 3200, loss: 2.438200, top_1: 0.646758, top_k: 0.849102, samples/s: 847.392 1613100075.0878139
train: epoch 87, iter 3300, loss: 2.513664, top_1: 0.645234, top_k: 0.849414, samples/s: 849.019 1613100105.24018
train: epoch 87, iter 3400, loss: 2.264161, top_1: 0.647695, top_k: 0.849023, samples/s: 845.390 1613100135.5221336
train: epoch 87, iter 3500, loss: 2.435687, top_1: 0.642305, top_k: 0.845117, samples/s: 845.674 1613100165.793861
train: epoch 87, iter 3600, loss: 2.281606, top_1: 0.646094, top_k: 0.848828, samples/s: 847.149 1613100196.0127902
train: epoch 87, iter 3700, loss: 2.402153, top_1: 0.646484, top_k: 0.849531, samples/s: 845.358 1613100226.2957776
train: epoch 87, iter 3800, loss: 2.647484, top_1: 0.638594, top_k: 0.844727, samples/s: 847.618 1613100256.498073
train: epoch 87, iter 3900, loss: 2.543885, top_1: 0.635352, top_k: 0.845586, samples/s: 847.518 1613100286.703957
train: epoch 87, iter 4000, loss: 2.448679, top_1: 0.645430, top_k: 0.846406, samples/s: 845.457 1613100316.9834726
train: epoch 87, iter 4100, loss: 2.321851, top_1: 0.647383, top_k: 0.849258, samples/s: 845.648 1613100347.2560687
train: epoch 87, iter 4200, loss: 2.420810, top_1: 0.648828, top_k: 0.848906, samples/s: 848.036 1613100377.4438295
train: epoch 87, iter 4300, loss: 2.373624, top_1: 0.643125, top_k: 0.845547, samples/s: 845.533 1613100407.7202604
train: epoch 87, iter 4400, loss: 2.463666, top_1: 0.642461, top_k: 0.845195, samples/s: 847.797 1613100437.9161596
train: epoch 87, iter 4500, loss: 2.483558, top_1: 0.643945, top_k: 0.847305, samples/s: 847.125 1613100468.1360922
train: epoch 87, iter 4600, loss: 2.360894, top_1: 0.648125, top_k: 0.848672, samples/s: 848.339 1613100498.3126743
train: epoch 87, iter 4700, loss: 2.660424, top_1: 0.646289, top_k: 0.844727, samples/s: 845.174 1613100528.6022253
train: epoch 87, iter 4800, loss: 2.406432, top_1: 0.642969, top_k: 0.845977, samples/s: 849.533 1613100558.736503
train: epoch 87, iter 4900, loss: 2.680557, top_1: 0.641328, top_k: 0.848008, samples/s: 845.380 1613100589.0186784
train: epoch 87, iter 5000, loss: 2.389815, top_1: 0.649258, top_k: 0.851172, samples/s: 847.997 1613100619.2074203
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_87.
validation: epoch 87, iter 195, top_1: 0.687540, top_k: 0.892588, samples/s: 2402.027 1613100640.900743
train: epoch 88, iter 100, loss: 2.440315, top_1: 0.662344, top_k: 0.861602, samples/s: 870.965 1613100690.743024
train: epoch 88, iter 200, loss: 2.614077, top_1: 0.655391, top_k: 0.855586, samples/s: 865.000 1613100720.3383293
train: epoch 88, iter 300, loss: 2.508435, top_1: 0.659336, top_k: 0.855234, samples/s: 850.934 1613100750.422933
train: epoch 88, iter 400, loss: 2.270653, top_1: 0.652969, top_k: 0.854961, samples/s: 844.316 1613100780.74341
train: epoch 88, iter 500, loss: 2.724876, top_1: 0.656563, top_k: 0.856328, samples/s: 845.319 1613100811.027724
train: epoch 88, iter 600, loss: 2.451427, top_1: 0.655273, top_k: 0.856602, samples/s: 845.663 1613100841.2998798
train: epoch 88, iter 700, loss: 2.316616, top_1: 0.651016, top_k: 0.855430, samples/s: 845.898 1613100871.5635166
train: epoch 88, iter 800, loss: 2.406523, top_1: 0.655391, top_k: 0.856016, samples/s: 846.419 1613100901.8086367
train: epoch 88, iter 900, loss: 2.289421, top_1: 0.653906, top_k: 0.854883, samples/s: 843.310 1613100932.1652043
train: epoch 88, iter 1000, loss: 2.476376, top_1: 0.650977, top_k: 0.857187, samples/s: 849.491 1613100962.3009574
train: epoch 88, iter 1100, loss: 2.340757, top_1: 0.653086, top_k: 0.855391, samples/s: 843.493 1613100992.650855
train: epoch 88, iter 1200, loss: 2.433320, top_1: 0.664570, top_k: 0.854766, samples/s: 844.852 1613101022.9520931
train: epoch 88, iter 1300, loss: 2.532328, top_1: 0.649844, top_k: 0.852109, samples/s: 845.368 1613101053.2346573
train: epoch 88, iter 1400, loss: 2.445460, top_1: 0.651289, top_k: 0.850859, samples/s: 845.236 1613101083.5220993
train: epoch 88, iter 1500, loss: 2.360257, top_1: 0.655078, top_k: 0.854219, samples/s: 848.797 1613101113.6824856
train: epoch 88, iter 1600, loss: 2.456133, top_1: 0.650156, top_k: 0.853711, samples/s: 844.447 1613101143.9980567
train: epoch 88, iter 1700, loss: 2.379192, top_1: 0.649180, top_k: 0.853477, samples/s: 846.647 1613101174.2350683
train: epoch 88, iter 1800, loss: 2.437470, top_1: 0.648672, top_k: 0.849023, samples/s: 847.090 1613101204.456158
train: epoch 88, iter 1900, loss: 2.484119, top_1: 0.648594, top_k: 0.854219, samples/s: 850.772 1613101234.5464334
train: epoch 88, iter 2000, loss: 2.495626, top_1: 0.654453, top_k: 0.852461, samples/s: 843.945 1613101264.8801274
train: epoch 88, iter 2100, loss: 2.498544, top_1: 0.652578, top_k: 0.854375, samples/s: 848.857 1613101295.0383747
train: epoch 88, iter 2200, loss: 2.332254, top_1: 0.641797, top_k: 0.843633, samples/s: 848.479 1613101325.2099297
train: epoch 88, iter 2300, loss: 2.352989, top_1: 0.651484, top_k: 0.851445, samples/s: 844.710 1613101355.516335
train: epoch 88, iter 2400, loss: 2.526943, top_1: 0.647305, top_k: 0.851211, samples/s: 847.724 1613101385.714771
train: epoch 88, iter 2500, loss: 2.429317, top_1: 0.650781, top_k: 0.853437, samples/s: 847.379 1613101415.9255145
train: epoch 88, iter 2600, loss: 2.535060, top_1: 0.647734, top_k: 0.851250, samples/s: 850.278 1613101446.0333416
train: epoch 88, iter 2700, loss: 2.358528, top_1: 0.644609, top_k: 0.848047, samples/s: 844.947 1613101476.3310606
train: epoch 88, iter 2800, loss: 2.349804, top_1: 0.651367, top_k: 0.850547, samples/s: 850.194 1613101506.441821
train: epoch 88, iter 2900, loss: 2.338470, top_1: 0.645000, top_k: 0.849063, samples/s: 842.551 1613101536.8258004
train: epoch 88, iter 3000, loss: 2.452979, top_1: 0.650469, top_k: 0.849727, samples/s: 848.657 1613101566.991098
train: epoch 88, iter 3100, loss: 2.491221, top_1: 0.644727, top_k: 0.851523, samples/s: 844.295 1613101597.3123162
train: epoch 88, iter 3200, loss: 2.477036, top_1: 0.650000, top_k: 0.853516, samples/s: 846.036 1613101627.5710049
train: epoch 88, iter 3300, loss: 2.260094, top_1: 0.645117, top_k: 0.849727, samples/s: 844.718 1613101657.876941
train: epoch 88, iter 3400, loss: 2.352576, top_1: 0.650391, top_k: 0.852266, samples/s: 847.782 1613101688.0734828
train: epoch 88, iter 3500, loss: 2.397821, top_1: 0.646328, top_k: 0.846602, samples/s: 844.254 1613101718.3960493
train: epoch 88, iter 3600, loss: 2.408757, top_1: 0.644375, top_k: 0.849336, samples/s: 849.121 1613101748.5448449
train: epoch 88, iter 3700, loss: 2.313417, top_1: 0.651797, top_k: 0.852656, samples/s: 845.322 1613101778.8291485
train: epoch 88, iter 3800, loss: 2.709058, top_1: 0.643672, top_k: 0.849297, samples/s: 849.254 1613101808.9732926
train: epoch 88, iter 3900, loss: 2.588275, top_1: 0.647031, top_k: 0.848555, samples/s: 843.246 1613101839.3322494
train: epoch 88, iter 4000, loss: 2.507252, top_1: 0.643594, top_k: 0.851719, samples/s: 847.987 1613101869.5212848
train: epoch 88, iter 4100, loss: 2.469786, top_1: 0.641328, top_k: 0.847812, samples/s: 848.007 1613101899.7097597
train: epoch 88, iter 4200, loss: 2.445995, top_1: 0.649141, top_k: 0.849219, samples/s: 845.615 1613101929.9835377
train: epoch 88, iter 4300, loss: 2.424256, top_1: 0.649648, top_k: 0.851797, samples/s: 848.484 1613101960.1551085
train: epoch 88, iter 4400, loss: 2.525963, top_1: 0.651992, top_k: 0.853477, samples/s: 844.594 1613101990.4655373
train: epoch 88, iter 4500, loss: 2.408092, top_1: 0.647891, top_k: 0.849609, samples/s: 847.270 1613102020.6802623
train: epoch 88, iter 4600, loss: 2.396788, top_1: 0.647344, top_k: 0.846602, samples/s: 847.123 1613102050.900196
train: epoch 88, iter 4700, loss: 2.454216, top_1: 0.644961, top_k: 0.846055, samples/s: 847.447 1613102081.1084468
train: epoch 88, iter 4800, loss: 2.302272, top_1: 0.643437, top_k: 0.848086, samples/s: 846.189 1613102111.361811
train: epoch 88, iter 4900, loss: 2.643133, top_1: 0.651719, top_k: 0.851172, samples/s: 847.608 1613102141.5645201
train: epoch 88, iter 5000, loss: 2.530153, top_1: 0.648906, top_k: 0.853789, samples/s: 844.264 1613102171.8867874
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_88.
validation: epoch 88, iter 195, top_1: 0.690144, top_k: 0.892889, samples/s: 2402.944 1613102193.5698404
train: epoch 89, iter 100, loss: 2.556394, top_1: 0.663984, top_k: 0.860313, samples/s: 870.977 1613102243.4047666
train: epoch 89, iter 200, loss: 2.315441, top_1: 0.660391, top_k: 0.857383, samples/s: 866.930 1613102272.9341166
train: epoch 89, iter 300, loss: 2.537169, top_1: 0.657969, top_k: 0.859180, samples/s: 851.870 1613102302.9856415
train: epoch 89, iter 400, loss: 2.417452, top_1: 0.665273, top_k: 0.859805, samples/s: 846.874 1613102333.2144537
train: epoch 89, iter 500, loss: 2.386518, top_1: 0.657461, top_k: 0.858828, samples/s: 844.710 1613102363.5208294
train: epoch 89, iter 600, loss: 2.516572, top_1: 0.664805, top_k: 0.854102, samples/s: 846.940 1613102393.7473035
train: epoch 89, iter 700, loss: 2.156433, top_1: 0.655391, top_k: 0.856328, samples/s: 846.891 1613102423.9755027
train: epoch 89, iter 800, loss: 2.382344, top_1: 0.650703, top_k: 0.850977, samples/s: 844.819 1613102454.277813
train: epoch 89, iter 900, loss: 2.536175, top_1: 0.660625, top_k: 0.858477, samples/s: 847.131 1613102484.4974685
train: epoch 89, iter 1000, loss: 2.514592, top_1: 0.663984, top_k: 0.860273, samples/s: 845.338 1613102514.7812433
train: epoch 89, iter 1100, loss: 2.382313, top_1: 0.655117, top_k: 0.854336, samples/s: 845.126 1613102545.0725253
train: epoch 89, iter 1200, loss: 2.395827, top_1: 0.648711, top_k: 0.850977, samples/s: 847.584 1613102575.2760558
train: epoch 89, iter 1300, loss: 2.363090, top_1: 0.649414, top_k: 0.852305, samples/s: 847.255 1613102605.4911911
train: epoch 89, iter 1400, loss: 2.384103, top_1: 0.652617, top_k: 0.854531, samples/s: 844.784 1613102635.7948976
train: epoch 89, iter 1500, loss: 2.415776, top_1: 0.651055, top_k: 0.852695, samples/s: 845.831 1613102666.0609264
train: epoch 89, iter 1600, loss: 2.382724, top_1: 0.657539, top_k: 0.855273, samples/s: 847.809 1613102696.2564838
train: epoch 89, iter 1700, loss: 2.458848, top_1: 0.651563, top_k: 0.854883, samples/s: 846.108 1613102726.512653
train: epoch 89, iter 1800, loss: 2.427577, top_1: 0.651484, top_k: 0.853672, samples/s: 846.565 1613102756.752511
train: epoch 89, iter 1900, loss: 2.363722, top_1: 0.654102, top_k: 0.857187, samples/s: 846.431 1613102786.9971511
train: epoch 89, iter 2000, loss: 2.300855, top_1: 0.660586, top_k: 0.854141, samples/s: 846.148 1613102817.2518382
train: epoch 89, iter 2100, loss: 2.413770, top_1: 0.646055, top_k: 0.850664, samples/s: 846.386 1613102847.4980857
train: epoch 89, iter 2200, loss: 2.354439, top_1: 0.655469, top_k: 0.854297, samples/s: 847.139 1613102877.71753
train: epoch 89, iter 2300, loss: 2.504063, top_1: 0.656406, top_k: 0.856484, samples/s: 844.970 1613102908.0144382
train: epoch 89, iter 2400, loss: 2.475306, top_1: 0.653203, top_k: 0.854023, samples/s: 846.884 1613102938.2428074
train: epoch 89, iter 2500, loss: 2.366649, top_1: 0.649805, top_k: 0.850625, samples/s: 845.092 1613102968.5353856
train: epoch 89, iter 2600, loss: 2.452825, top_1: 0.647773, top_k: 0.852656, samples/s: 846.830 1613102998.765863
train: epoch 89, iter 2700, loss: 2.350546, top_1: 0.649922, top_k: 0.852305, samples/s: 850.176 1613103028.8772202
train: epoch 89, iter 2800, loss: 2.526056, top_1: 0.648359, top_k: 0.849961, samples/s: 845.631 1613103059.1505308
train: epoch 89, iter 2900, loss: 2.347321, top_1: 0.647422, top_k: 0.855586, samples/s: 849.689 1613103089.2791016
train: epoch 89, iter 3000, loss: 2.381457, top_1: 0.651680, top_k: 0.850391, samples/s: 846.752 1613103119.5123372
train: epoch 89, iter 3100, loss: 2.523703, top_1: 0.645664, top_k: 0.850195, samples/s: 849.604 1613103149.6442103
train: epoch 89, iter 3200, loss: 2.593505, top_1: 0.651055, top_k: 0.849180, samples/s: 843.174 1613103180.0058804
train: epoch 89, iter 3300, loss: 2.341325, top_1: 0.645156, top_k: 0.847773, samples/s: 845.281 1613103210.2912934
train: epoch 89, iter 3400, loss: 2.320989, top_1: 0.648320, top_k: 0.850156, samples/s: 847.803 1613103240.4872754
train: epoch 89, iter 3500, loss: 2.402766, top_1: 0.653242, top_k: 0.851758, samples/s: 845.348 1613103270.7704039
train: epoch 89, iter 3600, loss: 2.367224, top_1: 0.642891, top_k: 0.845000, samples/s: 846.191 1613103301.0236924
train: epoch 89, iter 3700, loss: 2.482279, top_1: 0.648203, top_k: 0.845703, samples/s: 847.270 1613103331.2382994
train: epoch 89, iter 3800, loss: 2.257951, top_1: 0.651250, top_k: 0.854805, samples/s: 846.623 1613103361.4761386
train: epoch 89, iter 3900, loss: 2.466547, top_1: 0.644375, top_k: 0.850820, samples/s: 845.833 1613103391.742141
train: epoch 89, iter 4000, loss: 2.416146, top_1: 0.643672, top_k: 0.846680, samples/s: 848.598 1613103421.9096162
train: epoch 89, iter 4100, loss: 2.495392, top_1: 0.652227, top_k: 0.852500, samples/s: 846.631 1613103452.147122
train: epoch 89, iter 4200, loss: 2.439799, top_1: 0.652578, top_k: 0.851992, samples/s: 847.012 1613103482.370972
train: epoch 89, iter 4300, loss: 2.298360, top_1: 0.647461, top_k: 0.846758, samples/s: 847.972 1613103512.5606582
train: epoch 89, iter 4400, loss: 2.393485, top_1: 0.650391, top_k: 0.850703, samples/s: 846.806 1613103542.7918386
train: epoch 89, iter 4500, loss: 2.438859, top_1: 0.643945, top_k: 0.851094, samples/s: 845.164 1613103573.0817866
train: epoch 89, iter 4600, loss: 2.555579, top_1: 0.644102, top_k: 0.847734, samples/s: 848.208 1613103603.2631602
train: epoch 89, iter 4700, loss: 2.627665, top_1: 0.647500, top_k: 0.846914, samples/s: 846.895 1613103633.491148
train: epoch 89, iter 4800, loss: 2.557397, top_1: 0.649180, top_k: 0.847969, samples/s: 847.283 1613103663.7054472
train: epoch 89, iter 4900, loss: 2.312089, top_1: 0.650820, top_k: 0.849297, samples/s: 847.723 1613103693.903863
train: epoch 89, iter 5000, loss: 2.290681, top_1: 0.659141, top_k: 0.854062, samples/s: 845.914 1613103724.1670384
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_89.
validation: epoch 89, iter 195, top_1: 0.693429, top_k: 0.892328, samples/s: 2465.810 1613103745.3103297
train: epoch 90, iter 100, loss: 2.552011, top_1: 0.660000, top_k: 0.857187, samples/s: 870.777 1613103795.2787166
train: epoch 90, iter 200, loss: 2.520991, top_1: 0.660703, top_k: 0.860039, samples/s: 866.917 1613103824.808645
train: epoch 90, iter 300, loss: 2.568948, top_1: 0.655703, top_k: 0.852383, samples/s: 851.269 1613103854.8814223
train: epoch 90, iter 400, loss: 2.437893, top_1: 0.659727, top_k: 0.858437, samples/s: 846.605 1613103885.119804
train: epoch 90, iter 500, loss: 2.723334, top_1: 0.660820, top_k: 0.856680, samples/s: 843.994 1613103915.4518085
train: epoch 90, iter 600, loss: 2.274970, top_1: 0.652617, top_k: 0.856211, samples/s: 844.316 1613103945.7721589
train: epoch 90, iter 700, loss: 2.582698, top_1: 0.655508, top_k: 0.855195, samples/s: 844.904 1613103976.071521
train: epoch 90, iter 800, loss: 2.531172, top_1: 0.659766, top_k: 0.859219, samples/s: 843.639 1613104006.4162831
train: epoch 90, iter 900, loss: 2.507643, top_1: 0.652031, top_k: 0.855195, samples/s: 851.231 1613104036.4903626
train: epoch 90, iter 1000, loss: 2.451959, top_1: 0.658711, top_k: 0.855117, samples/s: 845.244 1613104066.7773523
train: epoch 90, iter 1100, loss: 2.402232, top_1: 0.655781, top_k: 0.857383, samples/s: 843.794 1613104097.1166675
train: epoch 90, iter 1200, loss: 2.548933, top_1: 0.650352, top_k: 0.851094, samples/s: 848.442 1613104127.2899923
train: epoch 90, iter 1300, loss: 2.391087, top_1: 0.660820, top_k: 0.856797, samples/s: 846.563 1613104157.529416
train: epoch 90, iter 1400, loss: 2.543942, top_1: 0.657305, top_k: 0.855820, samples/s: 845.829 1613104187.7955456
train: epoch 90, iter 1500, loss: 2.385015, top_1: 0.654922, top_k: 0.855898, samples/s: 843.509 1613104218.1449835
train: epoch 90, iter 1600, loss: 2.296589, top_1: 0.654180, top_k: 0.855586, samples/s: 847.055 1613104248.3673587
train: epoch 90, iter 1700, loss: 2.328905, top_1: 0.653164, top_k: 0.858047, samples/s: 843.996 1613104278.6997888
train: epoch 90, iter 1800, loss: 2.351297, top_1: 0.654180, top_k: 0.854883, samples/s: 847.864 1613104308.8927703
train: epoch 90, iter 1900, loss: 2.452598, top_1: 0.654570, top_k: 0.850625, samples/s: 846.474 1613104339.1358404
train: epoch 90, iter 2000, loss: 2.133999, top_1: 0.658320, top_k: 0.853320, samples/s: 844.749 1613104369.4407022
train: epoch 90, iter 2100, loss: 2.553547, top_1: 0.652109, top_k: 0.851406, samples/s: 847.676 1613104399.6409721
train: epoch 90, iter 2200, loss: 2.353713, top_1: 0.656914, top_k: 0.852266, samples/s: 844.436 1613104429.957042
train: epoch 90, iter 2300, loss: 2.340741, top_1: 0.654180, top_k: 0.852461, samples/s: 847.468 1613104460.1646192
train: epoch 90, iter 2400, loss: 2.396810, top_1: 0.651992, top_k: 0.852578, samples/s: 848.510 1613104490.335117
train: epoch 90, iter 2500, loss: 2.408736, top_1: 0.659219, top_k: 0.851758, samples/s: 845.763 1613104520.6036236
train: epoch 90, iter 2600, loss: 2.469913, top_1: 0.655312, top_k: 0.857344, samples/s: 847.858 1613104550.7973728
train: epoch 90, iter 2700, loss: 2.295702, top_1: 0.650117, top_k: 0.850938, samples/s: 843.798 1613104581.1364272
train: epoch 90, iter 2800, loss: 2.452051, top_1: 0.654062, top_k: 0.853516, samples/s: 844.443 1613104611.4523447
train: epoch 90, iter 2900, loss: 2.470531, top_1: 0.649805, top_k: 0.852109, samples/s: 850.123 1613104641.5656137
train: epoch 90, iter 3000, loss: 2.427749, top_1: 0.649844, top_k: 0.846992, samples/s: 845.299 1613104671.850664
train: epoch 90, iter 3100, loss: 2.495998, top_1: 0.650117, top_k: 0.850859, samples/s: 847.158 1613104702.0693407
train: epoch 90, iter 3200, loss: 2.490335, top_1: 0.648477, top_k: 0.851094, samples/s: 847.269 1613104732.284076
train: epoch 90, iter 3300, loss: 2.607114, top_1: 0.647422, top_k: 0.854336, samples/s: 847.245 1613104762.4996448
train: epoch 90, iter 3400, loss: 2.399520, top_1: 0.654453, top_k: 0.852031, samples/s: 848.329 1613104792.6766217
train: epoch 90, iter 3500, loss: 2.607980, top_1: 0.651211, top_k: 0.852852, samples/s: 844.136 1613104823.0035722
train: epoch 90, iter 3600, loss: 2.482252, top_1: 0.652656, top_k: 0.852539, samples/s: 845.953 1613104853.265339
train: epoch 90, iter 3700, loss: 2.297621, top_1: 0.646445, top_k: 0.849375, samples/s: 850.553 1613104883.3632722
train: epoch 90, iter 3800, loss: 2.377622, top_1: 0.655820, top_k: 0.854570, samples/s: 845.803 1613104913.6303427
train: epoch 90, iter 3900, loss: 2.493959, top_1: 0.649570, top_k: 0.853203, samples/s: 847.106 1613104943.8509052
train: epoch 90, iter 4000, loss: 2.394741, top_1: 0.648359, top_k: 0.847500, samples/s: 847.811 1613104974.0463626
train: epoch 90, iter 4100, loss: 2.601532, top_1: 0.652383, top_k: 0.851758, samples/s: 845.668 1613105004.318314
train: epoch 90, iter 4200, loss: 2.449215, top_1: 0.643594, top_k: 0.847773, samples/s: 847.606 1613105034.5209599
train: epoch 90, iter 4300, loss: 2.420748, top_1: 0.649102, top_k: 0.847227, samples/s: 848.505 1613105064.6916125
train: epoch 90, iter 4400, loss: 2.339030, top_1: 0.650117, top_k: 0.852148, samples/s: 846.647 1613105094.9286542
train: epoch 90, iter 4500, loss: 2.289850, top_1: 0.651250, top_k: 0.853281, samples/s: 847.036 1613105125.1516566
train: epoch 90, iter 4600, loss: 2.400460, top_1: 0.649805, top_k: 0.851953, samples/s: 846.029 1613105155.41063
train: epoch 90, iter 4700, loss: 2.361033, top_1: 0.653711, top_k: 0.851992, samples/s: 846.971 1613105185.6359751
train: epoch 90, iter 4800, loss: 2.402857, top_1: 0.656367, top_k: 0.855391, samples/s: 849.042 1613105215.7875829
train: epoch 90, iter 4900, loss: 2.377819, top_1: 0.642930, top_k: 0.844453, samples/s: 843.911 1613105246.1226263
train: epoch 90, iter 5000, loss: 2.548534, top_1: 0.660078, top_k: 0.857109, samples/s: 850.955 1613105276.2067497
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_90.
validation: epoch 90, iter 195, top_1: 0.695112, top_k: 0.895733, samples/s: 2441.861 1613105297.5474432
train: epoch 91, iter 100, loss: 2.215465, top_1: 0.662500, top_k: 0.857461, samples/s: 871.112 1613105347.6954155
train: epoch 91, iter 200, loss: 2.252435, top_1: 0.659961, top_k: 0.858242, samples/s: 867.165 1613105377.2169435
train: epoch 91, iter 300, loss: 2.328261, top_1: 0.663789, top_k: 0.857187, samples/s: 848.519 1613105407.3870637
train: epoch 91, iter 400, loss: 2.293819, top_1: 0.661758, top_k: 0.860039, samples/s: 848.271 1613105437.5664632
train: epoch 91, iter 500, loss: 2.483598, top_1: 0.658438, top_k: 0.856797, samples/s: 844.225 1613105467.88977
train: epoch 91, iter 600, loss: 2.308565, top_1: 0.656836, top_k: 0.857227, samples/s: 847.354 1613105498.1014829
train: epoch 91, iter 700, loss: 2.267834, top_1: 0.662969, top_k: 0.859531, samples/s: 844.295 1613105528.4226751
train: epoch 91, iter 800, loss: 2.353270, top_1: 0.659609, top_k: 0.857617, samples/s: 846.486 1613105558.6652913
train: epoch 91, iter 900, loss: 2.291818, top_1: 0.657734, top_k: 0.859570, samples/s: 845.667 1613105588.9372756
train: epoch 91, iter 1000, loss: 2.430464, top_1: 0.658125, top_k: 0.854570, samples/s: 848.099 1613105619.1223917
train: epoch 91, iter 1100, loss: 2.471309, top_1: 0.653008, top_k: 0.853633, samples/s: 846.297 1613105649.3719244
train: epoch 91, iter 1200, loss: 2.268718, top_1: 0.653125, top_k: 0.853320, samples/s: 844.044 1613105679.7020464
train: epoch 91, iter 1300, loss: 2.445818, top_1: 0.657461, top_k: 0.855859, samples/s: 844.796 1613105710.0053084
train: epoch 91, iter 1400, loss: 2.216872, top_1: 0.661250, top_k: 0.858008, samples/s: 851.490 1613105740.0702043
train: epoch 91, iter 1500, loss: 2.349282, top_1: 0.658516, top_k: 0.857578, samples/s: 844.129 1613105770.3973541
train: epoch 91, iter 1600, loss: 2.378323, top_1: 0.655000, top_k: 0.856602, samples/s: 847.642 1613105800.5986907
train: epoch 91, iter 1700, loss: 2.449997, top_1: 0.648086, top_k: 0.850977, samples/s: 846.581 1613105830.8383625
train: epoch 91, iter 1800, loss: 2.488259, top_1: 0.653906, top_k: 0.856914, samples/s: 844.131 1613105861.165042
train: epoch 91, iter 1900, loss: 2.185667, top_1: 0.652344, top_k: 0.852891, samples/s: 846.582 1613105891.404541
train: epoch 91, iter 2000, loss: 2.491758, top_1: 0.655742, top_k: 0.855156, samples/s: 848.990 1613105921.5577958
train: epoch 91, iter 2100, loss: 2.496127, top_1: 0.660312, top_k: 0.856445, samples/s: 843.852 1613105951.8948119
train: epoch 91, iter 2200, loss: 2.303198, top_1: 0.653086, top_k: 0.857148, samples/s: 845.757 1613105982.163578
train: epoch 91, iter 2300, loss: 2.259710, top_1: 0.658945, top_k: 0.857383, samples/s: 846.643 1613106012.400602
train: epoch 91, iter 2400, loss: 2.426324, top_1: 0.653008, top_k: 0.853398, samples/s: 846.153 1613106042.655271
train: epoch 91, iter 2500, loss: 2.425247, top_1: 0.655664, top_k: 0.855117, samples/s: 848.560 1613106072.8238933
train: epoch 91, iter 2600, loss: 2.486704, top_1: 0.659258, top_k: 0.855469, samples/s: 843.770 1613106103.163913
train: epoch 91, iter 2700, loss: 2.330741, top_1: 0.654219, top_k: 0.853906, samples/s: 848.058 1613106133.3506274
train: epoch 91, iter 2800, loss: 2.499685, top_1: 0.650430, top_k: 0.852539, samples/s: 846.691 1613106163.5859132
train: epoch 91, iter 2900, loss: 2.419652, top_1: 0.656719, top_k: 0.852187, samples/s: 845.475 1613106193.8647132
train: epoch 91, iter 3000, loss: 2.609443, top_1: 0.649492, top_k: 0.854219, samples/s: 845.373 1613106224.1472938
train: epoch 91, iter 3100, loss: 2.284311, top_1: 0.656367, top_k: 0.854414, samples/s: 848.307 1613106254.3249454
train: epoch 91, iter 3200, loss: 2.540517, top_1: 0.649883, top_k: 0.852500, samples/s: 844.917 1613106284.62381
train: epoch 91, iter 3300, loss: 2.407451, top_1: 0.651094, top_k: 0.852383, samples/s: 844.600 1613106314.9339628
train: epoch 91, iter 3400, loss: 2.419805, top_1: 0.653828, top_k: 0.855156, samples/s: 849.202 1613106345.0799038
train: epoch 91, iter 3500, loss: 2.421856, top_1: 0.642148, top_k: 0.850039, samples/s: 845.629 1613106375.3533351
train: epoch 91, iter 3600, loss: 2.457232, top_1: 0.655664, top_k: 0.851992, samples/s: 848.311 1613106405.53094
train: epoch 91, iter 3700, loss: 2.460983, top_1: 0.649766, top_k: 0.852031, samples/s: 846.210 1613106435.783473
train: epoch 91, iter 3800, loss: 2.465915, top_1: 0.652891, top_k: 0.854297, samples/s: 850.047 1613106465.8994744
train: epoch 91, iter 3900, loss: 2.627925, top_1: 0.650898, top_k: 0.850742, samples/s: 841.737 1613106496.312713
train: epoch 91, iter 4000, loss: 2.412289, top_1: 0.646172, top_k: 0.850391, samples/s: 846.207 1613106526.5654137
train: epoch 91, iter 4100, loss: 2.482746, top_1: 0.649336, top_k: 0.852227, samples/s: 846.475 1613106556.8084714
train: epoch 91, iter 4200, loss: 2.431444, top_1: 0.654687, top_k: 0.854648, samples/s: 847.898 1613106587.0007465
train: epoch 91, iter 4300, loss: 2.455186, top_1: 0.648594, top_k: 0.851094, samples/s: 846.323 1613106617.249218
train: epoch 91, iter 4400, loss: 2.478533, top_1: 0.654297, top_k: 0.851562, samples/s: 845.190 1613106647.5382621
train: epoch 91, iter 4500, loss: 2.206966, top_1: 0.655547, top_k: 0.852617, samples/s: 844.895 1613106677.8379579
train: epoch 91, iter 4600, loss: 2.277658, top_1: 0.655039, top_k: 0.851719, samples/s: 848.225 1613106708.0185869
train: epoch 91, iter 4700, loss: 2.552600, top_1: 0.650117, top_k: 0.856641, samples/s: 845.552 1613106738.2946665
train: epoch 91, iter 4800, loss: 2.505899, top_1: 0.653008, top_k: 0.853789, samples/s: 846.590 1613106768.533644
train: epoch 91, iter 4900, loss: 2.385782, top_1: 0.648125, top_k: 0.850273, samples/s: 847.533 1613106798.7389493
train: epoch 91, iter 5000, loss: 2.318729, top_1: 0.657031, top_k: 0.859258, samples/s: 847.152 1613106828.9579039
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_91.
validation: epoch 91, iter 195, top_1: 0.696695, top_k: 0.895152, samples/s: 2454.208 1613106850.1935472
train: epoch 92, iter 100, loss: 2.476273, top_1: 0.662930, top_k: 0.861094, samples/s: 870.299 1613106901.483239
train: epoch 92, iter 200, loss: 2.221222, top_1: 0.662930, top_k: 0.857852, samples/s: 866.442 1613106931.0294266
train: epoch 92, iter 300, loss: 2.135566, top_1: 0.670977, top_k: 0.864727, samples/s: 852.017 1613106961.075709
train: epoch 92, iter 400, loss: 2.396543, top_1: 0.669492, top_k: 0.862656, samples/s: 842.831 1613106991.4495416
train: epoch 92, iter 500, loss: 2.212474, top_1: 0.662773, top_k: 0.857539, samples/s: 845.629 1613107021.72288
train: epoch 92, iter 600, loss: 2.303235, top_1: 0.665156, top_k: 0.861016, samples/s: 846.378 1613107051.9693124
train: epoch 92, iter 700, loss: 2.300150, top_1: 0.664375, top_k: 0.860898, samples/s: 843.429 1613107082.3216598
train: epoch 92, iter 800, loss: 2.319295, top_1: 0.668008, top_k: 0.861445, samples/s: 845.683 1613107112.5931287
train: epoch 92, iter 900, loss: 2.398417, top_1: 0.656563, top_k: 0.855703, samples/s: 844.121 1613107142.9204926
train: epoch 92, iter 1000, loss: 2.492528, top_1: 0.660000, top_k: 0.857812, samples/s: 847.245 1613107173.136126
train: epoch 92, iter 1100, loss: 2.418380, top_1: 0.653398, top_k: 0.856211, samples/s: 842.983 1613107203.5043588
train: epoch 92, iter 1200, loss: 2.326133, top_1: 0.664414, top_k: 0.858398, samples/s: 846.149 1613107233.7591355
train: epoch 92, iter 1300, loss: 2.623589, top_1: 0.659297, top_k: 0.857383, samples/s: 844.063 1613107264.088573
train: epoch 92, iter 1400, loss: 2.465862, top_1: 0.659805, top_k: 0.859219, samples/s: 845.914 1613107294.3517091
train: epoch 92, iter 1500, loss: 2.370619, top_1: 0.653477, top_k: 0.856797, samples/s: 847.678 1613107324.5518477
train: epoch 92, iter 1600, loss: 2.363966, top_1: 0.659453, top_k: 0.858437, samples/s: 841.822 1613107354.962097
train: epoch 92, iter 1700, loss: 2.491424, top_1: 0.654414, top_k: 0.853320, samples/s: 846.579 1613107385.2013712
train: epoch 92, iter 1800, loss: 2.443490, top_1: 0.658242, top_k: 0.856211, samples/s: 840.806 1613107415.6483238
train: epoch 92, iter 1900, loss: 2.425317, top_1: 0.658711, top_k: 0.858047, samples/s: 848.634 1613107445.814497
train: epoch 92, iter 2000, loss: 2.613105, top_1: 0.655352, top_k: 0.855039, samples/s: 845.287 1613107476.1000655
train: epoch 92, iter 2100, loss: 2.391637, top_1: 0.659336, top_k: 0.856250, samples/s: 846.389 1613107506.3461266
train: epoch 92, iter 2200, loss: 2.254282, top_1: 0.658594, top_k: 0.853789, samples/s: 845.141 1613107536.6369421
train: epoch 92, iter 2300, loss: 2.414310, top_1: 0.657109, top_k: 0.854492, samples/s: 846.112 1613107566.8930516
train: epoch 92, iter 2400, loss: 2.293137, top_1: 0.653516, top_k: 0.854258, samples/s: 846.613 1613107597.1310818
train: epoch 92, iter 2500, loss: 2.424249, top_1: 0.659258, top_k: 0.856641, samples/s: 843.805 1613107627.469915
train: epoch 92, iter 2600, loss: 2.425291, top_1: 0.658633, top_k: 0.858359, samples/s: 848.177 1613107657.6523087
train: epoch 92, iter 2700, loss: 2.399586, top_1: 0.658633, top_k: 0.853086, samples/s: 845.223 1613107687.9401104
train: epoch 92, iter 2800, loss: 2.545937, top_1: 0.650273, top_k: 0.851680, samples/s: 844.443 1613107718.2559743
train: epoch 92, iter 2900, loss: 2.565468, top_1: 0.661992, top_k: 0.859570, samples/s: 849.019 1613107748.4083664
train: epoch 92, iter 3000, loss: 2.406687, top_1: 0.658711, top_k: 0.860156, samples/s: 845.167 1613107778.6983514
train: epoch 92, iter 3100, loss: 2.530983, top_1: 0.654258, top_k: 0.854062, samples/s: 847.846 1613107808.8924248
train: epoch 92, iter 3200, loss: 2.565028, top_1: 0.657266, top_k: 0.855742, samples/s: 845.738 1613107839.1617987
train: epoch 92, iter 3300, loss: 2.499816, top_1: 0.653047, top_k: 0.855195, samples/s: 843.416 1613107869.5145779
train: epoch 92, iter 3400, loss: 2.593395, top_1: 0.664648, top_k: 0.860508, samples/s: 848.009 1613107899.7030003
train: epoch 92, iter 3500, loss: 2.448126, top_1: 0.663594, top_k: 0.859180, samples/s: 842.388 1613107930.0927405
train: epoch 92, iter 3600, loss: 2.457158, top_1: 0.649336, top_k: 0.852500, samples/s: 844.461 1613107960.4079
train: epoch 92, iter 3700, loss: 2.501356, top_1: 0.657227, top_k: 0.852461, samples/s: 845.541 1613107990.6844418
train: epoch 92, iter 3800, loss: 2.557763, top_1: 0.658398, top_k: 0.855039, samples/s: 846.308 1613108020.933505
train: epoch 92, iter 3900, loss: 2.315434, top_1: 0.652930, top_k: 0.855078, samples/s: 846.886 1613108051.1618717
train: epoch 92, iter 4000, loss: 2.403787, top_1: 0.658008, top_k: 0.854219, samples/s: 843.721 1613108081.5036037
train: epoch 92, iter 4100, loss: 2.118295, top_1: 0.653008, top_k: 0.854531, samples/s: 845.049 1613108111.7977726
train: epoch 92, iter 4200, loss: 2.173429, top_1: 0.650234, top_k: 0.852617, samples/s: 843.959 1613108142.1309927
train: epoch 92, iter 4300, loss: 2.387409, top_1: 0.652266, top_k: 0.853242, samples/s: 848.999 1613108172.284081
train: epoch 92, iter 4400, loss: 2.544113, top_1: 0.651172, top_k: 0.853125, samples/s: 843.300 1613108202.6410556
train: epoch 92, iter 4500, loss: 2.191989, top_1: 0.649922, top_k: 0.853945, samples/s: 848.565 1613108232.8096523
train: epoch 92, iter 4600, loss: 2.355127, top_1: 0.651133, top_k: 0.852656, samples/s: 841.406 1613108263.2349606
train: epoch 92, iter 4700, loss: 2.466382, top_1: 0.653281, top_k: 0.851836, samples/s: 847.662 1613108293.4356866
train: epoch 92, iter 4800, loss: 2.424714, top_1: 0.654883, top_k: 0.851211, samples/s: 846.398 1613108323.6815312
train: epoch 92, iter 4900, loss: 2.462777, top_1: 0.657383, top_k: 0.856367, samples/s: 844.588 1613108353.9921646
train: epoch 92, iter 5000, loss: 2.288500, top_1: 0.660547, top_k: 0.854688, samples/s: 848.053 1613108384.1788878
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_92.
validation: epoch 92, iter 195, top_1: 0.697135, top_k: 0.898858, samples/s: 2450.026 1613108405.4545174
train: epoch 93, iter 100, loss: 2.279546, top_1: 0.666758, top_k: 0.863906, samples/s: 871.370 1613108455.4862738
train: epoch 93, iter 200, loss: 2.375402, top_1: 0.673633, top_k: 0.868594, samples/s: 865.348 1613108485.0696988
train: epoch 93, iter 300, loss: 2.420568, top_1: 0.665781, top_k: 0.859414, samples/s: 846.838 1613108515.2997503
train: epoch 93, iter 400, loss: 2.517173, top_1: 0.665508, top_k: 0.862305, samples/s: 846.797 1613108545.5314176
train: epoch 93, iter 500, loss: 2.496584, top_1: 0.655039, top_k: 0.854570, samples/s: 845.092 1613108575.8239913
train: epoch 93, iter 600, loss: 2.231419, top_1: 0.667031, top_k: 0.863750, samples/s: 843.346 1613108606.179153
train: epoch 93, iter 700, loss: 2.286784, top_1: 0.669883, top_k: 0.865977, samples/s: 844.865 1613108636.4799824
train: epoch 93, iter 800, loss: 2.553705, top_1: 0.663516, top_k: 0.860352, samples/s: 848.870 1613108666.6376805
train: epoch 93, iter 900, loss: 2.310108, top_1: 0.662227, top_k: 0.858594, samples/s: 841.848 1613108697.0470223
train: epoch 93, iter 1000, loss: 2.473789, top_1: 0.668672, top_k: 0.859570, samples/s: 844.664 1613108727.3548985
train: epoch 93, iter 1100, loss: 2.497948, top_1: 0.663203, top_k: 0.862695, samples/s: 844.111 1613108757.6826513
train: epoch 93, iter 1200, loss: 2.386913, top_1: 0.663555, top_k: 0.859180, samples/s: 845.958 1613108787.9441645
train: epoch 93, iter 1300, loss: 2.462072, top_1: 0.658164, top_k: 0.856328, samples/s: 845.110 1613108818.2361147
train: epoch 93, iter 1400, loss: 2.238119, top_1: 0.668086, top_k: 0.863828, samples/s: 843.416 1613108848.588884
train: epoch 93, iter 1500, loss: 2.467933, top_1: 0.663086, top_k: 0.854219, samples/s: 850.107 1613108878.7027946
train: epoch 93, iter 1600, loss: 2.460803, top_1: 0.665039, top_k: 0.857891, samples/s: 846.531 1613108908.94385
train: epoch 93, iter 1700, loss: 2.297400, top_1: 0.661797, top_k: 0.858594, samples/s: 841.872 1613108939.3522568
train: epoch 93, iter 1800, loss: 2.296518, top_1: 0.657148, top_k: 0.854883, samples/s: 850.459 1613108969.453599
train: epoch 93, iter 1900, loss: 2.491835, top_1: 0.660781, top_k: 0.856992, samples/s: 842.824 1613108999.8277369
train: epoch 93, iter 2000, loss: 2.399351, top_1: 0.660391, top_k: 0.856719, samples/s: 847.995 1613109030.01654
train: epoch 93, iter 2100, loss: 2.362823, top_1: 0.655820, top_k: 0.853086, samples/s: 844.219 1613109060.3404875
train: epoch 93, iter 2200, loss: 2.115508, top_1: 0.664648, top_k: 0.859492, samples/s: 845.669 1613109090.6123028
train: epoch 93, iter 2300, loss: 2.280502, top_1: 0.660508, top_k: 0.857734, samples/s: 847.183 1613109120.8301895
train: epoch 93, iter 2400, loss: 2.409629, top_1: 0.661758, top_k: 0.855430, samples/s: 845.374 1613109151.1125143
train: epoch 93, iter 2500, loss: 2.303754, top_1: 0.660352, top_k: 0.859688, samples/s: 848.119 1613109181.2970555
train: epoch 93, iter 2600, loss: 2.450777, top_1: 0.665586, top_k: 0.858359, samples/s: 847.086 1613109211.5181913
train: epoch 93, iter 2700, loss: 2.271740, top_1: 0.655430, top_k: 0.855664, samples/s: 847.564 1613109241.7224162
train: epoch 93, iter 2800, loss: 2.306148, top_1: 0.659453, top_k: 0.854102, samples/s: 844.281 1613109272.0441287
train: epoch 93, iter 2900, loss: 2.514965, top_1: 0.655898, top_k: 0.855039, samples/s: 848.308 1613109302.2218962
train: epoch 93, iter 3000, loss: 2.331625, top_1: 0.657188, top_k: 0.856836, samples/s: 849.339 1613109332.3628926
train: epoch 93, iter 3100, loss: 2.225829, top_1: 0.658086, top_k: 0.859883, samples/s: 848.827 1613109362.522257
train: epoch 93, iter 3200, loss: 2.442450, top_1: 0.656445, top_k: 0.854141, samples/s: 844.699 1613109392.8288589
train: epoch 93, iter 3300, loss: 2.627773, top_1: 0.657227, top_k: 0.854023, samples/s: 846.080 1613109423.086031
train: epoch 93, iter 3400, loss: 2.461799, top_1: 0.664336, top_k: 0.859688, samples/s: 850.286 1613109453.1935723
train: epoch 93, iter 3500, loss: 2.496746, top_1: 0.657500, top_k: 0.858320, samples/s: 845.672 1613109483.4653482
train: epoch 93, iter 3600, loss: 2.425320, top_1: 0.659961, top_k: 0.859023, samples/s: 845.376 1613109513.7476945
train: epoch 93, iter 3700, loss: 2.253103, top_1: 0.658672, top_k: 0.859297, samples/s: 845.451 1613109544.027479
train: epoch 93, iter 3800, loss: 2.347506, top_1: 0.659141, top_k: 0.854492, samples/s: 847.151 1613109574.2464085
train: epoch 93, iter 3900, loss: 2.337045, top_1: 0.657695, top_k: 0.855664, samples/s: 845.505 1613109604.5240846
train: epoch 93, iter 4000, loss: 2.445379, top_1: 0.653828, top_k: 0.856133, samples/s: 848.324 1613109634.7012618
train: epoch 93, iter 4100, loss: 2.381785, top_1: 0.655586, top_k: 0.853594, samples/s: 846.601 1613109664.9397888
train: epoch 93, iter 4200, loss: 2.386123, top_1: 0.657031, top_k: 0.853398, samples/s: 846.109 1613109695.1960454
train: epoch 93, iter 4300, loss: 2.405525, top_1: 0.658320, top_k: 0.857344, samples/s: 848.411 1613109725.3700292
train: epoch 93, iter 4400, loss: 2.137047, top_1: 0.660195, top_k: 0.857539, samples/s: 849.602 1613109755.5017908
train: epoch 93, iter 4500, loss: 2.403997, top_1: 0.650781, top_k: 0.853711, samples/s: 846.024 1613109785.7609408
train: epoch 93, iter 4600, loss: 2.370764, top_1: 0.658359, top_k: 0.857031, samples/s: 846.645 1613109815.9979973
train: epoch 93, iter 4700, loss: 2.449144, top_1: 0.654844, top_k: 0.855547, samples/s: 847.610 1613109846.20058
train: epoch 93, iter 4800, loss: 2.474563, top_1: 0.655391, top_k: 0.851562, samples/s: 845.092 1613109876.4931371
train: epoch 93, iter 4900, loss: 2.494788, top_1: 0.658867, top_k: 0.859570, samples/s: 848.481 1613109906.664678
train: epoch 93, iter 5000, loss: 2.480813, top_1: 0.659609, top_k: 0.857031, samples/s: 845.228 1613109936.9524422
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_93.
validation: epoch 93, iter 195, top_1: 0.701583, top_k: 0.899299, samples/s: 2445.094 1613109958.2752173
train: epoch 94, iter 100, loss: 2.305331, top_1: 0.665703, top_k: 0.862422, samples/s: 871.083 1613110008.0990086
train: epoch 94, iter 200, loss: 2.441184, top_1: 0.667383, top_k: 0.861328, samples/s: 865.172 1613110037.6885266
train: epoch 94, iter 300, loss: 2.361562, top_1: 0.665195, top_k: 0.861406, samples/s: 851.752 1613110067.7443244
train: epoch 94, iter 400, loss: 2.440015, top_1: 0.670391, top_k: 0.863516, samples/s: 846.013 1613110098.0037994
train: epoch 94, iter 500, loss: 2.384899, top_1: 0.668750, top_k: 0.863594, samples/s: 844.959 1613110128.3012154
train: epoch 94, iter 600, loss: 2.195768, top_1: 0.673633, top_k: 0.864766, samples/s: 846.165 1613110158.5553448
train: epoch 94, iter 700, loss: 2.268268, top_1: 0.668164, top_k: 0.863047, samples/s: 847.087 1613110188.776533
train: epoch 94, iter 800, loss: 2.363895, top_1: 0.665508, top_k: 0.859883, samples/s: 844.222 1613110219.100348
train: epoch 94, iter 900, loss: 2.366914, top_1: 0.677031, top_k: 0.865156, samples/s: 847.879 1613110249.2932985
train: epoch 94, iter 1000, loss: 2.307974, top_1: 0.667070, top_k: 0.863125, samples/s: 845.001 1613110279.5890617
train: epoch 94, iter 1100, loss: 2.350588, top_1: 0.661367, top_k: 0.864219, samples/s: 848.219 1613110309.7699316
train: epoch 94, iter 1200, loss: 2.560124, top_1: 0.665312, top_k: 0.861055, samples/s: 845.613 1613110340.0438452
train: epoch 94, iter 1300, loss: 2.310598, top_1: 0.657188, top_k: 0.858320, samples/s: 846.425 1613110370.2887895
train: epoch 94, iter 1400, loss: 2.477780, top_1: 0.661797, top_k: 0.858672, samples/s: 847.169 1613110400.5070717
train: epoch 94, iter 1500, loss: 2.210973, top_1: 0.665977, top_k: 0.860938, samples/s: 847.110 1613110430.7273977
train: epoch 94, iter 1600, loss: 2.509201, top_1: 0.669023, top_k: 0.865000, samples/s: 845.960 1613110460.9889493
train: epoch 94, iter 1700, loss: 2.492924, top_1: 0.661836, top_k: 0.858203, samples/s: 848.167 1613110491.171634
train: epoch 94, iter 1800, loss: 2.394378, top_1: 0.661523, top_k: 0.858398, samples/s: 845.421 1613110521.45248
train: epoch 94, iter 1900, loss: 2.374746, top_1: 0.656367, top_k: 0.859883, samples/s: 845.989 1613110551.712913
train: epoch 94, iter 2000, loss: 2.211323, top_1: 0.662344, top_k: 0.860703, samples/s: 845.650 1613110581.9854052
train: epoch 94, iter 2100, loss: 2.621945, top_1: 0.654219, top_k: 0.854258, samples/s: 850.130 1613110612.098432
train: epoch 94, iter 2200, loss: 2.667062, top_1: 0.655625, top_k: 0.854883, samples/s: 846.768 1613110642.3310235
train: epoch 94, iter 2300, loss: 2.420403, top_1: 0.660703, top_k: 0.859336, samples/s: 849.413 1613110672.4694884
train: epoch 94, iter 2400, loss: 2.496175, top_1: 0.668203, top_k: 0.862969, samples/s: 845.648 1613110702.7421386
train: epoch 94, iter 2500, loss: 2.310627, top_1: 0.662695, top_k: 0.861094, samples/s: 849.143 1613110732.890243
train: epoch 94, iter 2600, loss: 2.413620, top_1: 0.661602, top_k: 0.862187, samples/s: 844.536 1613110763.202735
train: epoch 94, iter 2700, loss: 2.475890, top_1: 0.658945, top_k: 0.856875, samples/s: 848.576 1613110793.3709447
train: epoch 94, iter 2800, loss: 2.390249, top_1: 0.665859, top_k: 0.860820, samples/s: 849.162 1613110823.5182064
train: epoch 94, iter 2900, loss: 2.509702, top_1: 0.659219, top_k: 0.856328, samples/s: 846.009 1613110853.7780378
train: epoch 94, iter 3000, loss: 2.437634, top_1: 0.657500, top_k: 0.858125, samples/s: 851.317 1613110883.8489878
train: epoch 94, iter 3100, loss: 2.429428, top_1: 0.655000, top_k: 0.855625, samples/s: 848.406 1613110914.0232203
train: epoch 94, iter 3200, loss: 2.381040, top_1: 0.662656, top_k: 0.858516, samples/s: 845.279 1613110944.3091147
train: epoch 94, iter 3300, loss: 2.303953, top_1: 0.658867, top_k: 0.856289, samples/s: 848.400 1613110974.4835684
train: epoch 94, iter 3400, loss: 2.335099, top_1: 0.659883, top_k: 0.858945, samples/s: 847.787 1613111004.6798062
train: epoch 94, iter 3500, loss: 2.310024, top_1: 0.656445, top_k: 0.854258, samples/s: 849.600 1613111034.8116841
train: epoch 94, iter 3600, loss: 2.513353, top_1: 0.661719, top_k: 0.857969, samples/s: 846.408 1613111065.0570378
train: epoch 94, iter 3700, loss: 2.436550, top_1: 0.655000, top_k: 0.855117, samples/s: 848.959 1613111095.2116194
train: epoch 94, iter 3800, loss: 2.389749, top_1: 0.656211, top_k: 0.854570, samples/s: 848.459 1613111125.384084
train: epoch 94, iter 3900, loss: 2.333917, top_1: 0.658750, top_k: 0.855586, samples/s: 849.127 1613111155.5326211
train: epoch 94, iter 4000, loss: 2.494591, top_1: 0.661328, top_k: 0.859375, samples/s: 844.646 1613111185.841299
train: epoch 94, iter 4100, loss: 2.345040, top_1: 0.664180, top_k: 0.857344, samples/s: 847.878 1613111216.0342393
train: epoch 94, iter 4200, loss: 2.418353, top_1: 0.659727, top_k: 0.857578, samples/s: 848.007 1613111246.2226944
train: epoch 94, iter 4300, loss: 2.370901, top_1: 0.657500, top_k: 0.855977, samples/s: 848.405 1613111276.3969758
train: epoch 94, iter 4400, loss: 2.294535, top_1: 0.660078, top_k: 0.858789, samples/s: 846.070 1613111306.654419
train: epoch 94, iter 4500, loss: 2.447833, top_1: 0.657813, top_k: 0.856797, samples/s: 846.715 1613111336.8889298
train: epoch 94, iter 4600, loss: 2.261667, top_1: 0.657891, top_k: 0.858750, samples/s: 848.025 1613111367.076796
train: epoch 94, iter 4700, loss: 2.131625, top_1: 0.655977, top_k: 0.857383, samples/s: 846.487 1613111397.3194785
train: epoch 94, iter 4800, loss: 2.526102, top_1: 0.657383, top_k: 0.858437, samples/s: 849.465 1613111427.4561017
train: epoch 94, iter 4900, loss: 2.382063, top_1: 0.657305, top_k: 0.858477, samples/s: 843.912 1613111457.7909985
train: epoch 94, iter 5000, loss: 2.440007, top_1: 0.665703, top_k: 0.862187, samples/s: 847.656 1613111487.991891
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_94.
validation: epoch 94, iter 195, top_1: 0.698538, top_k: 0.897476, samples/s: 2408.553 1613111509.620203
train: epoch 95, iter 100, loss: 2.153929, top_1: 0.680703, top_k: 0.871445, samples/s: 870.637 1613111559.9456012
train: epoch 95, iter 200, loss: 2.501005, top_1: 0.669453, top_k: 0.863047, samples/s: 869.006 1613111589.4045186
train: epoch 95, iter 300, loss: 2.451690, top_1: 0.677031, top_k: 0.865391, samples/s: 848.950 1613111619.5594566
train: epoch 95, iter 400, loss: 2.363585, top_1: 0.669180, top_k: 0.864141, samples/s: 845.773 1613111649.827545
train: epoch 95, iter 500, loss: 2.344751, top_1: 0.663867, top_k: 0.861094, samples/s: 844.964 1613111680.1247702
train: epoch 95, iter 600, loss: 2.408773, top_1: 0.667148, top_k: 0.860586, samples/s: 846.417 1613111710.369791
train: epoch 95, iter 700, loss: 2.308196, top_1: 0.671250, top_k: 0.866133, samples/s: 847.371 1613111740.5809884
train: epoch 95, iter 800, loss: 2.545061, top_1: 0.663164, top_k: 0.862500, samples/s: 845.116 1613111770.8726
train: epoch 95, iter 900, loss: 2.393497, top_1: 0.665195, top_k: 0.861055, samples/s: 845.983 1613111801.1333923
train: epoch 95, iter 1000, loss: 2.355067, top_1: 0.669219, top_k: 0.864219, samples/s: 846.735 1613111831.36708
train: epoch 95, iter 1100, loss: 2.310572, top_1: 0.668242, top_k: 0.862812, samples/s: 843.163 1613111861.728999
train: epoch 95, iter 1200, loss: 2.453747, top_1: 0.667539, top_k: 0.863281, samples/s: 848.810 1613111891.8888412
train: epoch 95, iter 1300, loss: 2.337314, top_1: 0.669922, top_k: 0.861953, samples/s: 847.022 1613111922.112393
train: epoch 95, iter 1400, loss: 2.242615, top_1: 0.661719, top_k: 0.864062, samples/s: 848.337 1613111952.289041
train: epoch 95, iter 1500, loss: 2.426347, top_1: 0.663555, top_k: 0.859922, samples/s: 846.297 1613111982.5385115
train: epoch 95, iter 1600, loss: 2.422463, top_1: 0.667188, top_k: 0.860469, samples/s: 844.149 1613112012.8648977
train: epoch 95, iter 1700, loss: 2.278425, top_1: 0.662539, top_k: 0.859453, samples/s: 843.844 1613112043.2022934
train: epoch 95, iter 1800, loss: 2.173078, top_1: 0.663750, top_k: 0.859570, samples/s: 846.000 1613112073.4623184
train: epoch 95, iter 1900, loss: 2.496660, top_1: 0.660352, top_k: 0.861328, samples/s: 845.575 1613112103.7375832
train: epoch 95, iter 2000, loss: 2.184300, top_1: 0.661563, top_k: 0.858867, samples/s: 846.967 1613112133.9631078
train: epoch 95, iter 2100, loss: 2.249064, top_1: 0.664062, top_k: 0.864453, samples/s: 845.098 1613112164.2554424
train: epoch 95, iter 2200, loss: 2.561965, top_1: 0.663945, top_k: 0.861875, samples/s: 846.346 1613112194.5031064
train: epoch 95, iter 2300, loss: 2.260426, top_1: 0.665977, top_k: 0.859727, samples/s: 849.843 1613112224.6263213
train: epoch 95, iter 2400, loss: 2.411624, top_1: 0.667461, top_k: 0.863281, samples/s: 844.814 1613112254.9288635
train: epoch 95, iter 2500, loss: 2.714934, top_1: 0.656445, top_k: 0.857734, samples/s: 843.131 1613112285.291877
train: epoch 95, iter 2600, loss: 2.342978, top_1: 0.661406, top_k: 0.861875, samples/s: 844.137 1613112315.618692
train: epoch 95, iter 2700, loss: 2.430556, top_1: 0.661289, top_k: 0.858047, samples/s: 848.370 1613112345.7942061
train: epoch 95, iter 2800, loss: 2.446311, top_1: 0.662813, top_k: 0.856602, samples/s: 845.839 1613112376.059925
train: epoch 95, iter 2900, loss: 2.532978, top_1: 0.663633, top_k: 0.860625, samples/s: 848.211 1613112406.2411501
train: epoch 95, iter 3000, loss: 2.422828, top_1: 0.660000, top_k: 0.859414, samples/s: 844.226 1613112436.5647607
train: epoch 95, iter 3100, loss: 2.342821, top_1: 0.665703, top_k: 0.859570, samples/s: 847.121 1613112466.784823
train: epoch 95, iter 3200, loss: 2.520930, top_1: 0.663672, top_k: 0.860938, samples/s: 847.562 1613112496.9889958
train: epoch 95, iter 3300, loss: 2.469972, top_1: 0.660391, top_k: 0.860820, samples/s: 841.364 1613112527.4158359
train: epoch 95, iter 3400, loss: 2.593349, top_1: 0.662656, top_k: 0.857305, samples/s: 848.358 1613112557.5917583
train: epoch 95, iter 3500, loss: 2.306917, top_1: 0.659492, top_k: 0.861406, samples/s: 844.967 1613112587.8888056
train: epoch 95, iter 3600, loss: 2.490830, top_1: 0.659102, top_k: 0.858789, samples/s: 845.701 1613112618.1595328
train: epoch 95, iter 3700, loss: 2.238014, top_1: 0.658984, top_k: 0.855820, samples/s: 846.579 1613112648.398923
train: epoch 95, iter 3800, loss: 2.556981, top_1: 0.660430, top_k: 0.857266, samples/s: 845.538 1613112678.6754158
train: epoch 95, iter 3900, loss: 2.344222, top_1: 0.658281, top_k: 0.855898, samples/s: 846.355 1613112708.9228373
train: epoch 95, iter 4000, loss: 2.522099, top_1: 0.661172, top_k: 0.856719, samples/s: 843.996 1613112739.25471
train: epoch 95, iter 4100, loss: 2.452818, top_1: 0.663086, top_k: 0.859648, samples/s: 845.889 1613112769.5187116
train: epoch 95, iter 4200, loss: 2.286084, top_1: 0.660273, top_k: 0.858359, samples/s: 845.970 1613112799.779785
train: epoch 95, iter 4300, loss: 2.414235, top_1: 0.664258, top_k: 0.856914, samples/s: 845.106 1613112830.0718596
train: epoch 95, iter 4400, loss: 2.335686, top_1: 0.659375, top_k: 0.856289, samples/s: 846.161 1613112860.3261213
train: epoch 95, iter 4500, loss: 2.273257, top_1: 0.655781, top_k: 0.853828, samples/s: 848.353 1613112890.5022871
train: epoch 95, iter 4600, loss: 2.362238, top_1: 0.660664, top_k: 0.859219, samples/s: 845.390 1613112920.7841156
train: epoch 95, iter 4700, loss: 2.394581, top_1: 0.664531, top_k: 0.857812, samples/s: 845.554 1613112951.060159
train: epoch 95, iter 4800, loss: 2.387587, top_1: 0.652930, top_k: 0.856250, samples/s: 845.269 1613112981.346379
train: epoch 95, iter 4900, loss: 2.452303, top_1: 0.656328, top_k: 0.858164, samples/s: 848.208 1613113011.527718
train: epoch 95, iter 5000, loss: 2.315178, top_1: 0.666602, top_k: 0.860586, samples/s: 844.791 1613113041.8310812
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_95.
validation: epoch 95, iter 195, top_1: 0.699179, top_k: 0.896935, samples/s: 2464.596 1613113062.9868731
train: epoch 96, iter 100, loss: 2.365369, top_1: 0.674648, top_k: 0.863594, samples/s: 870.134 1613113117.7970169
train: epoch 96, iter 200, loss: 2.355318, top_1: 0.672813, top_k: 0.865547, samples/s: 866.396 1613113147.3446908
train: epoch 96, iter 300, loss: 2.269761, top_1: 0.672578, top_k: 0.862539, samples/s: 855.088 1613113177.2830327
train: epoch 96, iter 400, loss: 2.256544, top_1: 0.671602, top_k: 0.865000, samples/s: 846.173 1613113207.5369966
train: epoch 96, iter 500, loss: 2.337647, top_1: 0.673086, top_k: 0.865664, samples/s: 843.982 1613113237.8693855
train: epoch 96, iter 600, loss: 2.320912, top_1: 0.673086, top_k: 0.865430, samples/s: 844.779 1613113268.1731977
train: epoch 96, iter 700, loss: 2.280591, top_1: 0.671289, top_k: 0.865586, samples/s: 846.182 1613113298.4266455
train: epoch 96, iter 800, loss: 2.342068, top_1: 0.667734, top_k: 0.863086, samples/s: 848.122 1613113328.6110923
train: epoch 96, iter 900, loss: 2.373130, top_1: 0.664570, top_k: 0.863633, samples/s: 839.054 1613113359.1216426
train: epoch 96, iter 1000, loss: 2.416815, top_1: 0.664219, top_k: 0.861367, samples/s: 853.086 1613113389.1302953
train: epoch 96, iter 1100, loss: 2.263786, top_1: 0.668789, top_k: 0.865117, samples/s: 846.395 1613113419.3762774
train: epoch 96, iter 1200, loss: 2.264350, top_1: 0.668906, top_k: 0.862305, samples/s: 851.688 1613113449.4342315
train: epoch 96, iter 1300, loss: 2.165402, top_1: 0.672734, top_k: 0.868359, samples/s: 846.429 1613113479.6789465
train: epoch 96, iter 1400, loss: 2.349709, top_1: 0.673359, top_k: 0.864219, samples/s: 845.405 1613113509.9603374
train: epoch 96, iter 1500, loss: 2.285358, top_1: 0.670625, top_k: 0.864297, samples/s: 846.744 1613113540.193677
train: epoch 96, iter 1600, loss: 2.322608, top_1: 0.666992, top_k: 0.863984, samples/s: 848.206 1613113570.3750908
train: epoch 96, iter 1700, loss: 2.365507, top_1: 0.666758, top_k: 0.863125, samples/s: 845.872 1613113600.6396322
train: epoch 96, iter 1800, loss: 2.429200, top_1: 0.669648, top_k: 0.864062, samples/s: 845.837 1613113630.905535
train: epoch 96, iter 1900, loss: 2.212907, top_1: 0.660898, top_k: 0.858125, samples/s: 849.343 1613113661.0465477
train: epoch 96, iter 2000, loss: 2.337971, top_1: 0.664297, top_k: 0.860859, samples/s: 848.853 1613113691.2048535
train: epoch 96, iter 2100, loss: 2.352830, top_1: 0.665391, top_k: 0.862344, samples/s: 846.730 1613113721.4387486
train: epoch 96, iter 2200, loss: 2.288378, top_1: 0.670547, top_k: 0.862383, samples/s: 846.627 1613113751.6764874
train: epoch 96, iter 2300, loss: 2.167947, top_1: 0.668984, top_k: 0.862930, samples/s: 849.801 1613113781.8011923
train: epoch 96, iter 2400, loss: 2.322473, top_1: 0.657891, top_k: 0.859062, samples/s: 850.172 1613113811.9127393
train: epoch 96, iter 2500, loss: 2.230590, top_1: 0.662422, top_k: 0.859766, samples/s: 849.679 1613113842.041675
train: epoch 96, iter 2600, loss: 2.310598, top_1: 0.665156, top_k: 0.859023, samples/s: 848.517 1613113872.2119527
train: epoch 96, iter 2700, loss: 2.485656, top_1: 0.664570, top_k: 0.860039, samples/s: 846.613 1613113902.4500444
train: epoch 96, iter 2800, loss: 2.339562, top_1: 0.665859, top_k: 0.859883, samples/s: 848.238 1613113932.630296
train: epoch 96, iter 2900, loss: 2.141176, top_1: 0.662148, top_k: 0.859766, samples/s: 850.170 1613113962.74198
train: epoch 96, iter 3000, loss: 2.527034, top_1: 0.669570, top_k: 0.859258, samples/s: 847.411 1613113992.9515965
train: epoch 96, iter 3100, loss: 2.290234, top_1: 0.666680, top_k: 0.858555, samples/s: 850.186 1613114023.0626895
train: epoch 96, iter 3200, loss: 2.271003, top_1: 0.661680, top_k: 0.860234, samples/s: 847.771 1613114053.2595012
train: epoch 96, iter 3300, loss: 2.352827, top_1: 0.664766, top_k: 0.862773, samples/s: 851.024 1613114083.340912
train: epoch 96, iter 3400, loss: 2.491279, top_1: 0.665430, top_k: 0.862539, samples/s: 846.070 1613114113.598404
train: epoch 96, iter 3500, loss: 2.349262, top_1: 0.659375, top_k: 0.859180, samples/s: 846.042 1613114143.8570087
train: epoch 96, iter 3600, loss: 2.289807, top_1: 0.660664, top_k: 0.855273, samples/s: 848.687 1613114174.0212877
train: epoch 96, iter 3700, loss: 2.485478, top_1: 0.663047, top_k: 0.857695, samples/s: 847.772 1613114204.2180538
train: epoch 96, iter 3800, loss: 2.318124, top_1: 0.665781, top_k: 0.859766, samples/s: 847.610 1613114234.4206276
train: epoch 96, iter 3900, loss: 2.477385, top_1: 0.660586, top_k: 0.857227, samples/s: 849.464 1613114264.557301
train: epoch 96, iter 4000, loss: 2.319648, top_1: 0.664805, top_k: 0.858945, samples/s: 846.485 1613114294.7999945
train: epoch 96, iter 4100, loss: 2.332557, top_1: 0.664336, top_k: 0.861523, samples/s: 847.306 1613114325.013419
train: epoch 96, iter 4200, loss: 2.297171, top_1: 0.657422, top_k: 0.855352, samples/s: 847.886 1613114355.2060263
train: epoch 96, iter 4300, loss: 2.397585, top_1: 0.657617, top_k: 0.857930, samples/s: 846.743 1613114385.439521
train: epoch 96, iter 4400, loss: 2.388471, top_1: 0.666133, top_k: 0.862383, samples/s: 849.726 1613114415.5669286
train: epoch 96, iter 4500, loss: 2.371340, top_1: 0.663477, top_k: 0.857578, samples/s: 845.696 1613114445.8379292
train: epoch 96, iter 4600, loss: 2.409476, top_1: 0.662695, top_k: 0.859570, samples/s: 849.147 1613114475.985776
train: epoch 96, iter 4700, loss: 2.419501, top_1: 0.666172, top_k: 0.862148, samples/s: 847.506 1613114506.192025
train: epoch 96, iter 4800, loss: 2.352513, top_1: 0.661133, top_k: 0.857812, samples/s: 844.792 1613114536.4953938
train: epoch 96, iter 4900, loss: 2.458009, top_1: 0.662539, top_k: 0.858633, samples/s: 849.570 1613114566.628226
train: epoch 96, iter 5000, loss: 2.124326, top_1: 0.675742, top_k: 0.862773, samples/s: 850.989 1613114596.7108676
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_96.
validation: epoch 96, iter 195, top_1: 0.699659, top_k: 0.899619, samples/s: 2451.516 1613114617.9783344
train: epoch 97, iter 100, loss: 2.287241, top_1: 0.675586, top_k: 0.869102, samples/s: 866.298 1613114668.3075452
train: epoch 97, iter 200, loss: 2.282965, top_1: 0.670469, top_k: 0.865820, samples/s: 868.177 1613114697.794561
train: epoch 97, iter 300, loss: 2.216127, top_1: 0.666680, top_k: 0.866641, samples/s: 850.304 1613114727.9014082
train: epoch 97, iter 400, loss: 2.393303, top_1: 0.673242, top_k: 0.867266, samples/s: 844.438 1613114758.2174156
train: epoch 97, iter 500, loss: 2.448862, top_1: 0.678242, top_k: 0.867773, samples/s: 847.906 1613114788.409504
train: epoch 97, iter 600, loss: 2.459243, top_1: 0.677188, top_k: 0.869297, samples/s: 844.918 1613114818.7083118
train: epoch 97, iter 700, loss: 2.325330, top_1: 0.668477, top_k: 0.863047, samples/s: 850.304 1613114848.8152103
train: epoch 97, iter 800, loss: 2.359016, top_1: 0.672578, top_k: 0.864766, samples/s: 846.021 1613114879.0743945
train: epoch 97, iter 900, loss: 2.324172, top_1: 0.670625, top_k: 0.865430, samples/s: 845.757 1613114909.3431437
train: epoch 97, iter 1000, loss: 2.448444, top_1: 0.664844, top_k: 0.863242, samples/s: 850.479 1613114939.4439416
train: epoch 97, iter 1100, loss: 2.314456, top_1: 0.676172, top_k: 0.868555, samples/s: 847.398 1613114969.6540442
train: epoch 97, iter 1200, loss: 2.351552, top_1: 0.673594, top_k: 0.863984, samples/s: 846.943 1613114999.8803647
train: epoch 97, iter 1300, loss: 2.482465, top_1: 0.668359, top_k: 0.864375, samples/s: 845.949 1613115030.1422262
train: epoch 97, iter 1400, loss: 2.424100, top_1: 0.668359, top_k: 0.863086, samples/s: 844.554 1613115060.4541385
train: epoch 97, iter 1500, loss: 2.313796, top_1: 0.673008, top_k: 0.865469, samples/s: 849.781 1613115090.579537
train: epoch 97, iter 1600, loss: 2.386914, top_1: 0.669141, top_k: 0.861992, samples/s: 845.422 1613115120.8602207
train: epoch 97, iter 1700, loss: 2.345977, top_1: 0.671836, top_k: 0.864180, samples/s: 849.918 1613115150.980713
train: epoch 97, iter 1800, loss: 2.403123, top_1: 0.674375, top_k: 0.864844, samples/s: 845.986 1613115181.2412982
train: epoch 97, iter 1900, loss: 2.260442, top_1: 0.661992, top_k: 0.860391, samples/s: 847.759 1613115211.4386168
train: epoch 97, iter 2000, loss: 2.315022, top_1: 0.675859, top_k: 0.870078, samples/s: 847.205 1613115241.6556377
train: epoch 97, iter 2100, loss: 2.356537, top_1: 0.669531, top_k: 0.862617, samples/s: 848.747 1613115271.8176553
train: epoch 97, iter 2200, loss: 2.215525, top_1: 0.670781, top_k: 0.866094, samples/s: 848.226 1613115301.9983473
train: epoch 97, iter 2300, loss: 2.338890, top_1: 0.669414, top_k: 0.863789, samples/s: 848.672 1613115332.1632264
train: epoch 97, iter 2400, loss: 2.311994, top_1: 0.660742, top_k: 0.857461, samples/s: 847.387 1613115362.3736947
train: epoch 97, iter 2500, loss: 2.367300, top_1: 0.669727, top_k: 0.862969, samples/s: 845.470 1613115392.652664
train: epoch 97, iter 2600, loss: 2.345208, top_1: 0.664766, top_k: 0.861719, samples/s: 847.912 1613115422.8444376
train: epoch 97, iter 2700, loss: 2.290082, top_1: 0.669063, top_k: 0.865117, samples/s: 848.257 1613115453.0240946
train: epoch 97, iter 2800, loss: 2.484414, top_1: 0.665937, top_k: 0.858867, samples/s: 845.679 1613115483.295539
train: epoch 97, iter 2900, loss: 2.377869, top_1: 0.661289, top_k: 0.856367, samples/s: 847.169 1613115513.5139322
train: epoch 97, iter 3000, loss: 2.304878, top_1: 0.668281, top_k: 0.862734, samples/s: 845.956 1613115543.7755213
train: epoch 97, iter 3100, loss: 2.296161, top_1: 0.668555, top_k: 0.862148, samples/s: 846.119 1613115574.031348
train: epoch 97, iter 3200, loss: 2.429170, top_1: 0.661328, top_k: 0.863047, samples/s: 846.035 1613115604.2900143
train: epoch 97, iter 3300, loss: 2.380008, top_1: 0.671133, top_k: 0.866406, samples/s: 842.401 1613115634.6793249
train: epoch 97, iter 3400, loss: 2.455786, top_1: 0.663164, top_k: 0.860273, samples/s: 848.549 1613115664.8484998
train: epoch 97, iter 3500, loss: 2.535112, top_1: 0.664336, top_k: 0.860391, samples/s: 849.849 1613115694.9715638
train: epoch 97, iter 3600, loss: 2.416802, top_1: 0.663438, top_k: 0.860430, samples/s: 845.674 1613115725.2432864
train: epoch 97, iter 3700, loss: 2.498314, top_1: 0.666680, top_k: 0.860977, samples/s: 847.172 1613115755.4614043
train: epoch 97, iter 3800, loss: 2.412338, top_1: 0.664883, top_k: 0.860000, samples/s: 843.542 1613115785.809609
train: epoch 97, iter 3900, loss: 2.394567, top_1: 0.668359, top_k: 0.862852, samples/s: 847.620 1613115816.011793
train: epoch 97, iter 4000, loss: 2.473284, top_1: 0.664570, top_k: 0.860898, samples/s: 849.165 1613115846.1591327
train: epoch 97, iter 4100, loss: 2.277713, top_1: 0.663555, top_k: 0.862734, samples/s: 843.919 1613115876.493769
train: epoch 97, iter 4200, loss: 2.361383, top_1: 0.662891, top_k: 0.857617, samples/s: 848.532 1613115906.6634731
train: epoch 97, iter 4300, loss: 2.337988, top_1: 0.666953, top_k: 0.859531, samples/s: 847.794 1613115936.8595097
train: epoch 97, iter 4400, loss: 2.377085, top_1: 0.662617, top_k: 0.863398, samples/s: 847.946 1613115967.0501585
train: epoch 97, iter 4500, loss: 2.243071, top_1: 0.665273, top_k: 0.860586, samples/s: 846.451 1613115997.294057
train: epoch 97, iter 4600, loss: 2.372643, top_1: 0.664102, top_k: 0.861367, samples/s: 847.072 1613116027.5158246
train: epoch 97, iter 4700, loss: 2.338961, top_1: 0.657734, top_k: 0.855977, samples/s: 847.982 1613116057.7051945
train: epoch 97, iter 4800, loss: 2.309952, top_1: 0.664336, top_k: 0.859453, samples/s: 846.382 1613116087.9515598
train: epoch 97, iter 4900, loss: 2.289609, top_1: 0.665859, top_k: 0.861719, samples/s: 847.752 1613116118.1490242
train: epoch 97, iter 5000, loss: 2.453941, top_1: 0.664570, top_k: 0.866289, samples/s: 847.376 1613116148.3599463
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_97.
validation: epoch 97, iter 195, top_1: 0.705068, top_k: 0.902604, samples/s: 2416.205 1613116169.9187372
train: epoch 98, iter 100, loss: 2.181705, top_1: 0.682422, top_k: 0.873359, samples/s: 869.723 1613116220.4207537
train: epoch 98, iter 200, loss: 2.399836, top_1: 0.671836, top_k: 0.864844, samples/s: 865.073 1613116250.0137303
train: epoch 98, iter 300, loss: 2.280839, top_1: 0.677891, top_k: 0.864336, samples/s: 850.245 1613116280.1225798
train: epoch 98, iter 400, loss: 2.294301, top_1: 0.677734, top_k: 0.865703, samples/s: 845.516 1613116310.3999453
train: epoch 98, iter 500, loss: 2.295740, top_1: 0.672773, top_k: 0.866563, samples/s: 846.350 1613116340.6474807
train: epoch 98, iter 600, loss: 2.346227, top_1: 0.673047, top_k: 0.867578, samples/s: 844.389 1613116370.9653788
train: epoch 98, iter 700, loss: 2.541708, top_1: 0.666914, top_k: 0.861016, samples/s: 847.047 1613116401.1880088
train: epoch 98, iter 800, loss: 2.251740, top_1: 0.673047, top_k: 0.866094, samples/s: 846.520 1613116431.4294732
train: epoch 98, iter 900, loss: 2.287223, top_1: 0.674297, top_k: 0.867031, samples/s: 849.320 1613116461.5711565
train: epoch 98, iter 1000, loss: 2.398501, top_1: 0.667969, top_k: 0.862539, samples/s: 842.631 1613116491.9522517
train: epoch 98, iter 1100, loss: 2.139281, top_1: 0.674219, top_k: 0.865742, samples/s: 845.880 1613116522.216603
train: epoch 98, iter 1200, loss: 2.272813, top_1: 0.673359, top_k: 0.867461, samples/s: 849.161 1613116552.363988
train: epoch 98, iter 1300, loss: 2.414890, top_1: 0.677461, top_k: 0.865664, samples/s: 846.773 1613116582.5964005
train: epoch 98, iter 1400, loss: 2.326293, top_1: 0.676719, top_k: 0.865664, samples/s: 845.408 1613116612.8775666
train: epoch 98, iter 1500, loss: 2.260104, top_1: 0.675898, top_k: 0.865742, samples/s: 849.879 1613116642.9994726
train: epoch 98, iter 1600, loss: 2.354272, top_1: 0.674258, top_k: 0.868125, samples/s: 844.589 1613116673.3100786
train: epoch 98, iter 1700, loss: 2.382743, top_1: 0.667461, top_k: 0.863359, samples/s: 845.067 1613116703.6035306
train: epoch 98, iter 1800, loss: 2.194521, top_1: 0.669687, top_k: 0.862227, samples/s: 849.675 1613116733.7327077
train: epoch 98, iter 1900, loss: 2.457590, top_1: 0.675078, top_k: 0.864180, samples/s: 848.021 1613116763.9206705
train: epoch 98, iter 2000, loss: 2.382499, top_1: 0.669453, top_k: 0.863516, samples/s: 842.483 1613116794.307133
train: epoch 98, iter 2100, loss: 2.262173, top_1: 0.670742, top_k: 0.865313, samples/s: 848.695 1613116824.470992
train: epoch 98, iter 2200, loss: 2.287359, top_1: 0.674102, top_k: 0.864648, samples/s: 846.927 1613116854.6980104
train: epoch 98, iter 2300, loss: 2.378926, top_1: 0.670937, top_k: 0.861680, samples/s: 849.446 1613116884.8352144
train: epoch 98, iter 2400, loss: 2.345634, top_1: 0.673477, top_k: 0.865664, samples/s: 846.979 1613116915.0603056
train: epoch 98, iter 2500, loss: 2.486683, top_1: 0.675156, top_k: 0.866563, samples/s: 845.168 1613116945.3501973
train: epoch 98, iter 2600, loss: 2.337684, top_1: 0.667578, top_k: 0.865625, samples/s: 846.308 1613116975.599253
train: epoch 98, iter 2700, loss: 2.339201, top_1: 0.661563, top_k: 0.859023, samples/s: 847.495 1613117005.8059254
train: epoch 98, iter 2800, loss: 2.389162, top_1: 0.676133, top_k: 0.866836, samples/s: 844.436 1613117036.121922
train: epoch 98, iter 2900, loss: 2.343245, top_1: 0.665352, top_k: 0.862070, samples/s: 846.260 1613117066.3727047
train: epoch 98, iter 3000, loss: 2.533994, top_1: 0.664648, top_k: 0.861484, samples/s: 846.997 1613117096.5971448
train: epoch 98, iter 3100, loss: 2.381813, top_1: 0.668594, top_k: 0.861875, samples/s: 847.594 1613117126.8003464
train: epoch 98, iter 3200, loss: 2.358668, top_1: 0.669102, top_k: 0.864297, samples/s: 844.924 1613117157.098832
train: epoch 98, iter 3300, loss: 2.339861, top_1: 0.670898, top_k: 0.861953, samples/s: 847.974 1613117187.2885158
train: epoch 98, iter 3400, loss: 2.445580, top_1: 0.671875, top_k: 0.867930, samples/s: 847.259 1613117217.503594
train: epoch 98, iter 3500, loss: 2.181043, top_1: 0.660352, top_k: 0.861758, samples/s: 848.366 1613117247.6791525
train: epoch 98, iter 3600, loss: 2.189862, top_1: 0.669727, top_k: 0.862031, samples/s: 847.143 1613117277.8984036
train: epoch 98, iter 3700, loss: 2.393569, top_1: 0.674258, top_k: 0.869961, samples/s: 848.041 1613117308.0856135
train: epoch 98, iter 3800, loss: 2.431164, top_1: 0.665781, top_k: 0.859336, samples/s: 849.098 1613117338.235348
train: epoch 98, iter 3900, loss: 2.535282, top_1: 0.672070, top_k: 0.865430, samples/s: 846.435 1613117368.479815
train: epoch 98, iter 4000, loss: 2.500604, top_1: 0.664141, top_k: 0.862891, samples/s: 846.525 1613117398.7210822
train: epoch 98, iter 4100, loss: 2.378133, top_1: 0.664648, top_k: 0.862812, samples/s: 848.831 1613117428.8801982
train: epoch 98, iter 4200, loss: 2.389505, top_1: 0.666484, top_k: 0.862500, samples/s: 845.708 1613117459.1506572
train: epoch 98, iter 4300, loss: 2.459251, top_1: 0.669102, top_k: 0.863164, samples/s: 849.274 1613117489.2939804
train: epoch 98, iter 4400, loss: 2.488321, top_1: 0.664336, top_k: 0.858125, samples/s: 846.266 1613117519.5445983
train: epoch 98, iter 4500, loss: 2.365429, top_1: 0.666289, top_k: 0.862070, samples/s: 845.292 1613117549.8300238
train: epoch 98, iter 4600, loss: 2.223178, top_1: 0.666875, top_k: 0.861250, samples/s: 847.884 1613117580.0228143
train: epoch 98, iter 4700, loss: 2.447180, top_1: 0.665625, top_k: 0.860977, samples/s: 846.845 1613117610.252611
train: epoch 98, iter 4800, loss: 2.313189, top_1: 0.666133, top_k: 0.860156, samples/s: 843.001 1613117640.6203587
train: epoch 98, iter 4900, loss: 2.287061, top_1: 0.668125, top_k: 0.860234, samples/s: 850.081 1613117670.7352195
train: epoch 98, iter 5000, loss: 2.260963, top_1: 0.678047, top_k: 0.865313, samples/s: 848.078 1613117700.921108
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_98.
validation: epoch 98, iter 195, top_1: 0.707292, top_k: 0.902003, samples/s: 2430.776 1613117722.349893
train: epoch 99, iter 100, loss: 2.334622, top_1: 0.682578, top_k: 0.871289, samples/s: 870.327 1613117772.2836552
train: epoch 99, iter 200, loss: 2.228901, top_1: 0.684922, top_k: 0.874102, samples/s: 869.019 1613117801.742245
train: epoch 99, iter 300, loss: 2.253863, top_1: 0.685586, top_k: 0.872969, samples/s: 851.252 1613117831.8155982
train: epoch 99, iter 400, loss: 2.213512, top_1: 0.674258, top_k: 0.866602, samples/s: 844.189 1613117862.1405694
train: epoch 99, iter 500, loss: 2.323535, top_1: 0.672695, top_k: 0.866211, samples/s: 847.430 1613117892.3494582
train: epoch 99, iter 600, loss: 2.138371, top_1: 0.680430, top_k: 0.869102, samples/s: 843.788 1613117922.6889362
train: epoch 99, iter 700, loss: 2.366389, top_1: 0.678828, top_k: 0.870508, samples/s: 845.377 1613117952.9712865
train: epoch 99, iter 800, loss: 2.447492, top_1: 0.674648, top_k: 0.870547, samples/s: 844.784 1613117983.2747784
train: epoch 99, iter 900, loss: 2.342958, top_1: 0.679609, top_k: 0.868437, samples/s: 850.166 1613118013.3865457
train: epoch 99, iter 1000, loss: 2.383299, top_1: 0.676562, top_k: 0.868594, samples/s: 848.354 1613118043.5626955
train: epoch 99, iter 1100, loss: 2.293186, top_1: 0.674609, top_k: 0.866367, samples/s: 842.439 1613118073.950661
train: epoch 99, iter 1200, loss: 2.347069, top_1: 0.673164, top_k: 0.862773, samples/s: 848.734 1613118104.1132429
train: epoch 99, iter 1300, loss: 2.343860, top_1: 0.672109, top_k: 0.865234, samples/s: 845.484 1613118134.391738
train: epoch 99, iter 1400, loss: 2.319869, top_1: 0.675000, top_k: 0.864570, samples/s: 848.735 1613118164.5542183
train: epoch 99, iter 1500, loss: 2.439639, top_1: 0.671328, top_k: 0.864883, samples/s: 845.517 1613118194.831749
train: epoch 99, iter 1600, loss: 2.333716, top_1: 0.670039, top_k: 0.866406, samples/s: 848.486 1613118225.0030525
train: epoch 99, iter 1700, loss: 2.381192, top_1: 0.666211, top_k: 0.862852, samples/s: 845.602 1613118255.277237
train: epoch 99, iter 1800, loss: 2.428879, top_1: 0.672617, top_k: 0.866250, samples/s: 848.308 1613118285.4550269
train: epoch 99, iter 1900, loss: 2.129541, top_1: 0.672383, top_k: 0.861680, samples/s: 847.987 1613118315.6442118
train: epoch 99, iter 2000, loss: 2.287629, top_1: 0.667539, top_k: 0.864453, samples/s: 844.959 1613118345.9414907
train: epoch 99, iter 2100, loss: 2.463121, top_1: 0.667852, top_k: 0.862383, samples/s: 846.433 1613118376.1860642
train: epoch 99, iter 2200, loss: 2.372288, top_1: 0.672773, top_k: 0.864766, samples/s: 845.377 1613118406.4684281
train: epoch 99, iter 2300, loss: 2.219187, top_1: 0.674922, top_k: 0.866016, samples/s: 845.854 1613118436.733778
train: epoch 99, iter 2400, loss: 2.320003, top_1: 0.675664, top_k: 0.864375, samples/s: 846.450 1613118466.9777296
train: epoch 99, iter 2500, loss: 2.176603, top_1: 0.674375, top_k: 0.866719, samples/s: 847.673 1613118497.1780107
train: epoch 99, iter 2600, loss: 2.239781, top_1: 0.671836, top_k: 0.865039, samples/s: 849.042 1613118527.3296185
train: epoch 99, iter 2700, loss: 2.432540, top_1: 0.673047, top_k: 0.866602, samples/s: 842.412 1613118557.7186027
train: epoch 99, iter 2800, loss: 2.263692, top_1: 0.671406, top_k: 0.862578, samples/s: 848.915 1613118587.8746731
train: epoch 99, iter 2900, loss: 2.017790, top_1: 0.668828, top_k: 0.866484, samples/s: 848.042 1613118618.061896
train: epoch 99, iter 3000, loss: 2.339514, top_1: 0.670469, top_k: 0.863281, samples/s: 848.464 1613118648.2341084
train: epoch 99, iter 3100, loss: 2.390033, top_1: 0.662461, top_k: 0.861289, samples/s: 846.731 1613118678.4679744
train: epoch 99, iter 3200, loss: 2.441227, top_1: 0.668516, top_k: 0.861328, samples/s: 847.468 1613118708.6755924
train: epoch 99, iter 3300, loss: 2.329803, top_1: 0.670664, top_k: 0.864570, samples/s: 847.118 1613118738.8957129
train: epoch 99, iter 3400, loss: 2.514143, top_1: 0.667344, top_k: 0.859492, samples/s: 846.711 1613118769.1303167
train: epoch 99, iter 3500, loss: 2.303059, top_1: 0.664531, top_k: 0.863711, samples/s: 845.282 1613118799.4160767
train: epoch 99, iter 3600, loss: 2.266026, top_1: 0.667031, top_k: 0.862031, samples/s: 849.348 1613118829.556862
train: epoch 99, iter 3700, loss: 2.420705, top_1: 0.670859, top_k: 0.863672, samples/s: 846.777 1613118859.7892125
train: epoch 99, iter 3800, loss: 2.368902, top_1: 0.672578, top_k: 0.867539, samples/s: 848.986 1613118889.942745
train: epoch 99, iter 3900, loss: 2.390789, top_1: 0.667852, top_k: 0.866445, samples/s: 847.385 1613118920.1533043
train: epoch 99, iter 4000, loss: 2.429032, top_1: 0.667227, top_k: 0.863945, samples/s: 847.608 1613118950.35607
train: epoch 99, iter 4100, loss: 2.351427, top_1: 0.674219, top_k: 0.866680, samples/s: 845.835 1613118980.621917
train: epoch 99, iter 4200, loss: 2.363389, top_1: 0.668984, top_k: 0.861445, samples/s: 850.112 1613119010.735583
train: epoch 99, iter 4300, loss: 2.332769, top_1: 0.667656, top_k: 0.861094, samples/s: 848.115 1613119040.9201958
train: epoch 99, iter 4400, loss: 2.241317, top_1: 0.677266, top_k: 0.866367, samples/s: 845.155 1613119071.2105758
train: epoch 99, iter 4500, loss: 2.394551, top_1: 0.666602, top_k: 0.866797, samples/s: 846.797 1613119101.4421353
train: epoch 99, iter 4600, loss: 2.532865, top_1: 0.672461, top_k: 0.864180, samples/s: 850.770 1613119131.5325398
train: epoch 99, iter 4700, loss: 2.460962, top_1: 0.667813, top_k: 0.861133, samples/s: 848.580 1613119161.7005606
train: epoch 99, iter 4800, loss: 2.261453, top_1: 0.669102, top_k: 0.862227, samples/s: 845.207 1613119191.9890423
train: epoch 99, iter 4900, loss: 2.632121, top_1: 0.663438, top_k: 0.861523, samples/s: 847.744 1613119222.1867611
train: epoch 99, iter 5000, loss: 2.217437, top_1: 0.681914, top_k: 0.867969, samples/s: 848.324 1613119252.3638592
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_99.
validation: epoch 99, iter 195, top_1: 0.706490, top_k: 0.901863, samples/s: 2385.878 1613119274.2014818
train: epoch 100, iter 100, loss: 2.329324, top_1: 0.678281, top_k: 0.866445, samples/s: 871.749 1613119324.2484963
train: epoch 100, iter 200, loss: 2.383240, top_1: 0.681172, top_k: 0.869648, samples/s: 866.638 1613119353.7879968
train: epoch 100, iter 300, loss: 2.333692, top_1: 0.681797, top_k: 0.869062, samples/s: 849.498 1613119383.923414
train: epoch 100, iter 400, loss: 2.449523, top_1: 0.681406, top_k: 0.870625, samples/s: 847.175 1613119414.1415372
train: epoch 100, iter 500, loss: 2.266306, top_1: 0.680195, top_k: 0.871680, samples/s: 845.968 1613119444.402611
train: epoch 100, iter 600, loss: 2.338386, top_1: 0.681211, top_k: 0.871367, samples/s: 847.719 1613119474.6013992
train: epoch 100, iter 700, loss: 2.293591, top_1: 0.683086, top_k: 0.870234, samples/s: 844.306 1613119504.9221392
train: epoch 100, iter 800, loss: 2.499781, top_1: 0.681562, top_k: 0.872266, samples/s: 846.220 1613119535.174334
train: epoch 100, iter 900, loss: 2.424455, top_1: 0.678672, top_k: 0.867969, samples/s: 847.924 1613119565.365669
train: epoch 100, iter 1000, loss: 2.225040, top_1: 0.685547, top_k: 0.869883, samples/s: 847.659 1613119595.5665257
train: epoch 100, iter 1100, loss: 2.449000, top_1: 0.678867, top_k: 0.864219, samples/s: 848.619 1613119625.7332191
train: epoch 100, iter 1200, loss: 2.404375, top_1: 0.671992, top_k: 0.866406, samples/s: 843.979 1613119656.0657544
train: epoch 100, iter 1300, loss: 2.319875, top_1: 0.680977, top_k: 0.867070, samples/s: 846.806 1613119686.296904
train: epoch 100, iter 1400, loss: 2.348183, top_1: 0.673125, top_k: 0.865313, samples/s: 849.906 1613119716.4178839
train: epoch 100, iter 1500, loss: 2.418968, top_1: 0.680469, top_k: 0.870625, samples/s: 846.269 1613119746.668438
train: epoch 100, iter 1600, loss: 2.378627, top_1: 0.680039, top_k: 0.869219, samples/s: 847.677 1613119776.868567
train: epoch 100, iter 1700, loss: 2.257670, top_1: 0.674648, top_k: 0.869102, samples/s: 846.703 1613119807.1034367
train: epoch 100, iter 1800, loss: 2.202505, top_1: 0.678125, top_k: 0.866719, samples/s: 849.664 1613119837.2330012
train: epoch 100, iter 1900, loss: 2.275776, top_1: 0.676133, top_k: 0.868828, samples/s: 847.963 1613119867.4230032
train: epoch 100, iter 2000, loss: 2.374223, top_1: 0.672813, top_k: 0.865820, samples/s: 849.023 1613119897.5753047
train: epoch 100, iter 2100, loss: 2.200331, top_1: 0.675977, top_k: 0.867891, samples/s: 846.224 1613119927.8273504
train: epoch 100, iter 2200, loss: 2.244310, top_1: 0.666719, top_k: 0.863477, samples/s: 848.197 1613119958.0089898
train: epoch 100, iter 2300, loss: 2.385210, top_1: 0.671523, top_k: 0.865508, samples/s: 846.477 1613119988.252009
train: epoch 100, iter 2400, loss: 2.297463, top_1: 0.684180, top_k: 0.871289, samples/s: 848.155 1613120018.4351075
train: epoch 100, iter 2500, loss: 2.291295, top_1: 0.673164, top_k: 0.864414, samples/s: 847.959 1613120048.6253145
train: epoch 100, iter 2600, loss: 2.333214, top_1: 0.672539, top_k: 0.866680, samples/s: 848.807 1613120078.7852883
train: epoch 100, iter 2700, loss: 2.218331, top_1: 0.671992, top_k: 0.864883, samples/s: 847.913 1613120108.977005
train: epoch 100, iter 2800, loss: 2.441149, top_1: 0.671445, top_k: 0.865586, samples/s: 848.994 1613120139.1303225
train: epoch 100, iter 2900, loss: 2.431399, top_1: 0.672734, top_k: 0.863711, samples/s: 848.074 1613120169.3164165
train: epoch 100, iter 3000, loss: 2.403935, top_1: 0.676836, top_k: 0.868203, samples/s: 848.163 1613120199.4993265
train: epoch 100, iter 3100, loss: 2.401017, top_1: 0.667031, top_k: 0.863984, samples/s: 848.701 1613120229.6629896
train: epoch 100, iter 3200, loss: 2.262276, top_1: 0.672813, top_k: 0.866367, samples/s: 847.642 1613120259.864438
train: epoch 100, iter 3300, loss: 2.450247, top_1: 0.666758, top_k: 0.863203, samples/s: 849.986 1613120289.9826035
train: epoch 100, iter 3400, loss: 2.231391, top_1: 0.678281, top_k: 0.865820, samples/s: 844.997 1613120320.2785382
train: epoch 100, iter 3500, loss: 2.347159, top_1: 0.672305, top_k: 0.865156, samples/s: 849.883 1613120350.400432
train: epoch 100, iter 3600, loss: 2.448052, top_1: 0.675742, top_k: 0.866211, samples/s: 847.960 1613120380.5905383
train: epoch 100, iter 3700, loss: 2.259426, top_1: 0.675781, top_k: 0.868945, samples/s: 847.947 1613120410.7810283
train: epoch 100, iter 3800, loss: 2.424753, top_1: 0.672422, top_k: 0.863828, samples/s: 847.849 1613120440.9751267
train: epoch 100, iter 3900, loss: 2.321900, top_1: 0.667695, top_k: 0.863711, samples/s: 847.568 1613120471.1792586
train: epoch 100, iter 4000, loss: 2.385175, top_1: 0.672969, top_k: 0.865430, samples/s: 850.318 1613120501.285642
train: epoch 100, iter 4100, loss: 2.393795, top_1: 0.668711, top_k: 0.864141, samples/s: 850.108 1613120531.3993342
train: epoch 100, iter 4200, loss: 2.498501, top_1: 0.671133, top_k: 0.863320, samples/s: 847.502 1613120561.6058147
train: epoch 100, iter 4300, loss: 2.582816, top_1: 0.672461, top_k: 0.865547, samples/s: 846.791 1613120591.837673
train: epoch 100, iter 4400, loss: 2.178486, top_1: 0.674648, top_k: 0.864258, samples/s: 848.513 1613120622.0079815
train: epoch 100, iter 4500, loss: 2.454223, top_1: 0.666328, top_k: 0.861836, samples/s: 847.091 1613120652.2291293
train: epoch 100, iter 4600, loss: 2.353402, top_1: 0.666602, top_k: 0.862852, samples/s: 844.975 1613120682.5258949
train: epoch 100, iter 4700, loss: 2.437206, top_1: 0.672109, top_k: 0.865195, samples/s: 848.469 1613120712.6978822
train: epoch 100, iter 4800, loss: 2.328389, top_1: 0.668164, top_k: 0.864805, samples/s: 848.264 1613120742.8771033
train: epoch 100, iter 4900, loss: 2.290828, top_1: 0.669219, top_k: 0.864219, samples/s: 846.722 1613120773.1114154
train: epoch 100, iter 5000, loss: 2.450689, top_1: 0.675234, top_k: 0.865898, samples/s: 849.448 1613120803.248648
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_100.
validation: epoch 100, iter 195, top_1: 0.702284, top_k: 0.896274, samples/s: 2486.813 1613120824.2403188
train: epoch 101, iter 100, loss: 2.245111, top_1: 0.687227, top_k: 0.876016, samples/s: 871.126 1613120874.2518592
train: epoch 101, iter 200, loss: 2.415056, top_1: 0.688516, top_k: 0.871797, samples/s: 867.895 1613120903.7485723
train: epoch 101, iter 300, loss: 2.306169, top_1: 0.683242, top_k: 0.874297, samples/s: 852.651 1613120933.7724724
train: epoch 101, iter 400, loss: 2.193768, top_1: 0.681328, top_k: 0.870664, samples/s: 845.535 1613120964.04928
train: epoch 101, iter 500, loss: 2.307600, top_1: 0.677578, top_k: 0.869102, samples/s: 847.427 1613120994.2582629
train: epoch 101, iter 600, loss: 2.333743, top_1: 0.681641, top_k: 0.871445, samples/s: 845.442 1613121024.5383976
train: epoch 101, iter 700, loss: 2.472878, top_1: 0.674687, top_k: 0.868125, samples/s: 845.732 1613121054.8079796
train: epoch 101, iter 800, loss: 2.427452, top_1: 0.682109, top_k: 0.870156, samples/s: 848.080 1613121084.9938824
train: epoch 101, iter 900, loss: 2.306230, top_1: 0.675898, top_k: 0.865703, samples/s: 847.929 1613121115.1850688
train: epoch 101, iter 1000, loss: 2.366539, top_1: 0.677539, top_k: 0.871719, samples/s: 848.397 1613121145.3595157
train: epoch 101, iter 1100, loss: 2.492813, top_1: 0.675117, top_k: 0.869336, samples/s: 847.729 1613121175.557841
train: epoch 101, iter 1200, loss: 2.415942, top_1: 0.668945, top_k: 0.864570, samples/s: 845.807 1613121205.824796
train: epoch 101, iter 1300, loss: 2.288362, top_1: 0.679102, top_k: 0.872070, samples/s: 850.160 1613121235.9368849
train: epoch 101, iter 1400, loss: 2.255963, top_1: 0.682109, top_k: 0.872031, samples/s: 847.939 1613121266.1276946
train: epoch 101, iter 1500, loss: 2.371526, top_1: 0.680273, top_k: 0.867148, samples/s: 845.407 1613121296.4089236
train: epoch 101, iter 1600, loss: 2.452353, top_1: 0.673711, top_k: 0.868594, samples/s: 851.141 1613121326.4861944
train: epoch 101, iter 1700, loss: 2.491269, top_1: 0.680703, top_k: 0.867930, samples/s: 845.685 1613121356.7575843
train: epoch 101, iter 1800, loss: 2.556846, top_1: 0.677617, top_k: 0.872891, samples/s: 849.724 1613121386.884951
train: epoch 101, iter 1900, loss: 2.227861, top_1: 0.677344, top_k: 0.870117, samples/s: 846.780 1613121417.1172502
train: epoch 101, iter 2000, loss: 2.292796, top_1: 0.679883, top_k: 0.872891, samples/s: 847.249 1613121447.3325841
train: epoch 101, iter 2100, loss: 2.393685, top_1: 0.673281, top_k: 0.867617, samples/s: 846.743 1613121477.5661159
train: epoch 101, iter 2200, loss: 2.385007, top_1: 0.677148, top_k: 0.868867, samples/s: 850.099 1613121507.680226
train: epoch 101, iter 2300, loss: 2.311702, top_1: 0.675625, top_k: 0.871289, samples/s: 847.869 1613121537.8736303
train: epoch 101, iter 2400, loss: 2.058292, top_1: 0.680039, top_k: 0.872305, samples/s: 846.993 1613121568.098137
train: epoch 101, iter 2500, loss: 2.444489, top_1: 0.675039, top_k: 0.866211, samples/s: 846.750 1613121598.331404
train: epoch 101, iter 2600, loss: 2.421251, top_1: 0.674180, top_k: 0.866094, samples/s: 847.017 1613121628.5550733
train: epoch 101, iter 2700, loss: 2.387620, top_1: 0.671484, top_k: 0.864102, samples/s: 848.456 1613121658.7275565
train: epoch 101, iter 2800, loss: 2.412109, top_1: 0.676016, top_k: 0.868906, samples/s: 851.526 1613121688.7913132
train: epoch 101, iter 2900, loss: 2.440761, top_1: 0.674766, top_k: 0.866641, samples/s: 845.537 1613121719.067807
train: epoch 101, iter 3000, loss: 2.461890, top_1: 0.671836, top_k: 0.866172, samples/s: 849.173 1613121749.214849
train: epoch 101, iter 3100, loss: 2.406434, top_1: 0.673672, top_k: 0.865625, samples/s: 848.123 1613121779.3991807
train: epoch 101, iter 3200, loss: 2.418541, top_1: 0.677734, top_k: 0.870313, samples/s: 848.855 1613121809.5573642
train: epoch 101, iter 3300, loss: 2.394490, top_1: 0.670898, top_k: 0.864336, samples/s: 846.083 1613121839.814548
train: epoch 101, iter 3400, loss: 2.479220, top_1: 0.671172, top_k: 0.865352, samples/s: 849.707 1613121869.942458
train: epoch 101, iter 3500, loss: 2.396330, top_1: 0.680977, top_k: 0.867695, samples/s: 845.248 1613121900.2294917
train: epoch 101, iter 3600, loss: 2.312475, top_1: 0.663555, top_k: 0.860938, samples/s: 846.648 1613121930.4664145
train: epoch 101, iter 3700, loss: 2.324534, top_1: 0.674883, top_k: 0.867930, samples/s: 848.641 1613121960.6322901
train: epoch 101, iter 3800, loss: 2.237501, top_1: 0.675664, top_k: 0.865547, samples/s: 847.832 1613121990.8269348
train: epoch 101, iter 3900, loss: 2.397973, top_1: 0.676953, top_k: 0.866523, samples/s: 845.330 1613122021.1109562
train: epoch 101, iter 4000, loss: 2.306819, top_1: 0.676328, top_k: 0.869531, samples/s: 849.185 1613122051.2575302
train: epoch 101, iter 4100, loss: 2.290997, top_1: 0.673672, top_k: 0.863984, samples/s: 850.018 1613122081.3745484
train: epoch 101, iter 4200, loss: 2.556684, top_1: 0.670273, top_k: 0.863750, samples/s: 845.692 1613122111.6455576
train: epoch 101, iter 4300, loss: 2.406308, top_1: 0.673281, top_k: 0.864062, samples/s: 848.753 1613122141.807446
train: epoch 101, iter 4400, loss: 2.392882, top_1: 0.680820, top_k: 0.869570, samples/s: 848.567 1613122171.9759881
train: epoch 101, iter 4500, loss: 2.283407, top_1: 0.673906, top_k: 0.863594, samples/s: 846.600 1613122202.2145193
train: epoch 101, iter 4600, loss: 2.175723, top_1: 0.675859, top_k: 0.870039, samples/s: 848.608 1613122232.3816087
train: epoch 101, iter 4700, loss: 2.436912, top_1: 0.675742, top_k: 0.862773, samples/s: 848.525 1613122262.5516262
train: epoch 101, iter 4800, loss: 2.361488, top_1: 0.667852, top_k: 0.863555, samples/s: 846.846 1613122292.7813797
train: epoch 101, iter 4900, loss: 2.189209, top_1: 0.678906, top_k: 0.871992, samples/s: 847.847 1613122322.9756012
train: epoch 101, iter 5000, loss: 2.326475, top_1: 0.683281, top_k: 0.871602, samples/s: 849.771 1613122353.101364
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_101.
validation: epoch 101, iter 195, top_1: 0.711278, top_k: 0.903305, samples/s: 2419.221 1613122374.6262808
train: epoch 102, iter 100, loss: 2.397153, top_1: 0.684258, top_k: 0.872422, samples/s: 871.421 1613122425.6750004
train: epoch 102, iter 200, loss: 2.312892, top_1: 0.687813, top_k: 0.872930, samples/s: 869.050 1613122455.1324294
train: epoch 102, iter 300, loss: 2.330065, top_1: 0.693867, top_k: 0.878516, samples/s: 854.083 1613122485.106092
train: epoch 102, iter 400, loss: 2.285569, top_1: 0.685781, top_k: 0.875938, samples/s: 844.558 1613122515.417777
train: epoch 102, iter 500, loss: 2.396610, top_1: 0.677930, top_k: 0.869727, samples/s: 845.720 1613122545.6877532
train: epoch 102, iter 600, loss: 2.170074, top_1: 0.683555, top_k: 0.869844, samples/s: 846.557 1613122575.92788
train: epoch 102, iter 700, loss: 2.401200, top_1: 0.694727, top_k: 0.874609, samples/s: 848.885 1613122606.085139
train: epoch 102, iter 800, loss: 2.172296, top_1: 0.683008, top_k: 0.871563, samples/s: 845.894 1613122636.349014
train: epoch 102, iter 900, loss: 2.355127, top_1: 0.681445, top_k: 0.870195, samples/s: 846.583 1613122666.5883224
train: epoch 102, iter 1000, loss: 2.304194, top_1: 0.676641, top_k: 0.868281, samples/s: 846.874 1613122696.8169692
train: epoch 102, iter 1100, loss: 2.321453, top_1: 0.680312, top_k: 0.870469, samples/s: 844.858 1613122727.1179852
train: epoch 102, iter 1200, loss: 2.304236, top_1: 0.682227, top_k: 0.871484, samples/s: 851.845 1613122757.170316
train: epoch 102, iter 1300, loss: 2.290968, top_1: 0.682773, top_k: 0.875352, samples/s: 846.152 1613122787.4249558
train: epoch 102, iter 1400, loss: 2.322381, top_1: 0.684570, top_k: 0.873906, samples/s: 845.721 1613122817.6949806
train: epoch 102, iter 1500, loss: 2.568097, top_1: 0.679570, top_k: 0.869805, samples/s: 850.312 1613122847.8016202
train: epoch 102, iter 1600, loss: 2.217238, top_1: 0.682656, top_k: 0.869258, samples/s: 847.547 1613122878.0064325
train: epoch 102, iter 1700, loss: 2.272223, top_1: 0.680078, top_k: 0.871797, samples/s: 848.814 1613122908.1660962
train: epoch 102, iter 1800, loss: 2.303649, top_1: 0.680781, top_k: 0.868594, samples/s: 847.659 1613122938.3670356
train: epoch 102, iter 1900, loss: 2.372476, top_1: 0.686992, top_k: 0.874922, samples/s: 845.127 1613122968.6582842
train: epoch 102, iter 2000, loss: 2.318957, top_1: 0.679336, top_k: 0.869297, samples/s: 849.129 1613122998.8067944
train: epoch 102, iter 2100, loss: 2.352720, top_1: 0.678984, top_k: 0.869219, samples/s: 846.625 1613123029.0445466
train: epoch 102, iter 2200, loss: 2.329533, top_1: 0.680547, top_k: 0.870820, samples/s: 847.438 1613123059.253286
train: epoch 102, iter 2300, loss: 2.389686, top_1: 0.675586, top_k: 0.867891, samples/s: 850.129 1613123089.366311
train: epoch 102, iter 2400, loss: 2.449766, top_1: 0.679336, top_k: 0.869961, samples/s: 849.769 1613123119.4920983
train: epoch 102, iter 2500, loss: 2.382161, top_1: 0.674609, top_k: 0.866719, samples/s: 845.848 1613123149.7576675
train: epoch 102, iter 2600, loss: 2.500398, top_1: 0.673477, top_k: 0.865664, samples/s: 846.927 1613123179.9844549
train: epoch 102, iter 2700, loss: 2.320390, top_1: 0.679922, top_k: 0.868437, samples/s: 849.338 1613123210.1256428
train: epoch 102, iter 2800, loss: 2.413566, top_1: 0.681016, top_k: 0.868242, samples/s: 847.429 1613123240.3347442
train: epoch 102, iter 2900, loss: 2.251550, top_1: 0.682148, top_k: 0.868945, samples/s: 846.727 1613123270.568773
train: epoch 102, iter 3000, loss: 2.262295, top_1: 0.672031, top_k: 0.866133, samples/s: 849.377 1613123300.70851
train: epoch 102, iter 3100, loss: 2.377213, top_1: 0.669453, top_k: 0.867969, samples/s: 848.980 1613123330.8622446
train: epoch 102, iter 3200, loss: 2.331400, top_1: 0.675234, top_k: 0.866367, samples/s: 848.820 1613123361.021753
train: epoch 102, iter 3300, loss: 2.400736, top_1: 0.674609, top_k: 0.868281, samples/s: 848.248 1613123391.2016075
train: epoch 102, iter 3400, loss: 2.346443, top_1: 0.678047, top_k: 0.869336, samples/s: 849.530 1613123421.3359313
train: epoch 102, iter 3500, loss: 2.214983, top_1: 0.681523, top_k: 0.870352, samples/s: 845.857 1613123451.6010628
train: epoch 102, iter 3600, loss: 2.398907, top_1: 0.681289, top_k: 0.870273, samples/s: 849.787 1613123481.7263737
train: epoch 102, iter 3700, loss: 2.290247, top_1: 0.674258, top_k: 0.867852, samples/s: 846.226 1613123511.9783154
train: epoch 102, iter 3800, loss: 2.461743, top_1: 0.670859, top_k: 0.863867, samples/s: 850.036 1613123542.0946822
train: epoch 102, iter 3900, loss: 2.218656, top_1: 0.671328, top_k: 0.868906, samples/s: 848.280 1613123572.2733824
train: epoch 102, iter 4000, loss: 2.271636, top_1: 0.674727, top_k: 0.867695, samples/s: 848.422 1613123602.4470315
train: epoch 102, iter 4100, loss: 2.290773, top_1: 0.673945, top_k: 0.865586, samples/s: 849.848 1613123632.5701003
train: epoch 102, iter 4200, loss: 2.363031, top_1: 0.678633, top_k: 0.865352, samples/s: 849.596 1613123662.701971
train: epoch 102, iter 4300, loss: 2.372580, top_1: 0.677617, top_k: 0.867695, samples/s: 848.593 1613123692.8696516
train: epoch 102, iter 4400, loss: 2.246084, top_1: 0.680312, top_k: 0.869414, samples/s: 850.654 1613123722.9641016
train: epoch 102, iter 4500, loss: 2.257514, top_1: 0.676445, top_k: 0.867578, samples/s: 846.710 1613123753.1987407
train: epoch 102, iter 4600, loss: 2.354190, top_1: 0.674102, top_k: 0.866758, samples/s: 849.818 1613123783.3229246
train: epoch 102, iter 4700, loss: 2.161696, top_1: 0.674102, top_k: 0.864180, samples/s: 849.232 1613123813.4678032
train: epoch 102, iter 4800, loss: 2.358600, top_1: 0.677813, top_k: 0.870000, samples/s: 846.007 1613123843.7275949
train: epoch 102, iter 4900, loss: 2.324598, top_1: 0.673945, top_k: 0.867891, samples/s: 847.438 1613123873.9362953
train: epoch 102, iter 5000, loss: 2.195168, top_1: 0.686602, top_k: 0.871836, samples/s: 849.986 1613123904.0544312
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_102.
validation: epoch 102, iter 195, top_1: 0.705529, top_k: 0.902023, samples/s: 2398.612 1613123925.7640047
train: epoch 103, iter 100, loss: 2.233779, top_1: 0.681367, top_k: 0.874922, samples/s: 868.943 1613123975.9691248
train: epoch 103, iter 200, loss: 2.267953, top_1: 0.687148, top_k: 0.874648, samples/s: 868.620 1613124005.441104
train: epoch 103, iter 300, loss: 2.496707, top_1: 0.687148, top_k: 0.871016, samples/s: 852.260 1613124035.4789307
train: epoch 103, iter 400, loss: 2.327504, top_1: 0.696016, top_k: 0.878125, samples/s: 845.301 1613124065.7640269
train: epoch 103, iter 500, loss: 2.288787, top_1: 0.689844, top_k: 0.875977, samples/s: 848.251 1613124095.9437776
train: epoch 103, iter 600, loss: 2.027580, top_1: 0.685312, top_k: 0.876836, samples/s: 847.356 1613124126.155352
train: epoch 103, iter 700, loss: 2.320493, top_1: 0.690195, top_k: 0.874414, samples/s: 847.903 1613124156.3475475
train: epoch 103, iter 800, loss: 2.293698, top_1: 0.682070, top_k: 0.870117, samples/s: 847.767 1613124186.5445194
train: epoch 103, iter 900, loss: 2.413412, top_1: 0.683047, top_k: 0.871953, samples/s: 845.557 1613124216.8203413
train: epoch 103, iter 1000, loss: 2.155090, top_1: 0.680352, top_k: 0.872109, samples/s: 848.486 1613124246.991707
train: epoch 103, iter 1100, loss: 2.356218, top_1: 0.686133, top_k: 0.874102, samples/s: 849.608 1613124277.1233108
train: epoch 103, iter 1200, loss: 2.316182, top_1: 0.683555, top_k: 0.871484, samples/s: 846.178 1613124307.3769057
train: epoch 103, iter 1300, loss: 2.415341, top_1: 0.679648, top_k: 0.870000, samples/s: 848.834 1613124337.5360372
train: epoch 103, iter 1400, loss: 2.279740, top_1: 0.680781, top_k: 0.870352, samples/s: 846.666 1613124367.7723212
train: epoch 103, iter 1500, loss: 2.343881, top_1: 0.687656, top_k: 0.874023, samples/s: 847.938 1613124397.9632084
train: epoch 103, iter 1600, loss: 2.239051, top_1: 0.678359, top_k: 0.872305, samples/s: 846.943 1613124428.1895616
train: epoch 103, iter 1700, loss: 2.251939, top_1: 0.683828, top_k: 0.872891, samples/s: 848.127 1613124458.3736234
train: epoch 103, iter 1800, loss: 2.319543, top_1: 0.684805, top_k: 0.872227, samples/s: 846.714 1613124488.6082466
train: epoch 103, iter 1900, loss: 2.332804, top_1: 0.683594, top_k: 0.870586, samples/s: 851.134 1613124518.6857512
train: epoch 103, iter 2000, loss: 2.159537, top_1: 0.682852, top_k: 0.873555, samples/s: 844.624 1613124548.9949865
train: epoch 103, iter 2100, loss: 2.255450, top_1: 0.680234, top_k: 0.870078, samples/s: 849.842 1613124579.1182065
train: epoch 103, iter 2200, loss: 2.397330, top_1: 0.678125, top_k: 0.871953, samples/s: 846.604 1613124609.3567398
train: epoch 103, iter 2300, loss: 2.238671, top_1: 0.683789, top_k: 0.872422, samples/s: 849.805 1613124639.481237
train: epoch 103, iter 2400, loss: 2.376418, top_1: 0.679883, top_k: 0.869727, samples/s: 847.947 1613124669.6718235
train: epoch 103, iter 2500, loss: 2.204324, top_1: 0.681289, top_k: 0.871016, samples/s: 847.202 1613124699.8890133
train: epoch 103, iter 2600, loss: 2.371942, top_1: 0.670859, top_k: 0.866094, samples/s: 849.218 1613124730.0343235
train: epoch 103, iter 2700, loss: 2.294420, top_1: 0.681406, top_k: 0.873047, samples/s: 846.490 1613124760.2768602
train: epoch 103, iter 2800, loss: 2.322804, top_1: 0.682617, top_k: 0.869727, samples/s: 849.069 1613124790.427558
train: epoch 103, iter 2900, loss: 2.537318, top_1: 0.679922, top_k: 0.871445, samples/s: 848.388 1613124820.6024017
train: epoch 103, iter 3000, loss: 2.343290, top_1: 0.677109, top_k: 0.868359, samples/s: 850.672 1613124850.6962612
train: epoch 103, iter 3100, loss: 2.268481, top_1: 0.679453, top_k: 0.869727, samples/s: 846.322 1613124880.9447803
train: epoch 103, iter 3200, loss: 2.244495, top_1: 0.680625, top_k: 0.872305, samples/s: 847.932 1613124911.1358852
train: epoch 103, iter 3300, loss: 2.199730, top_1: 0.681367, top_k: 0.867539, samples/s: 847.774 1613124941.3326256
train: epoch 103, iter 3400, loss: 2.356390, top_1: 0.682656, top_k: 0.873477, samples/s: 850.656 1613124971.4270926
train: epoch 103, iter 3500, loss: 2.257544, top_1: 0.679492, top_k: 0.872344, samples/s: 852.208 1613125001.466654
train: epoch 103, iter 3600, loss: 2.476234, top_1: 0.680195, top_k: 0.870703, samples/s: 849.385 1613125031.6061356
train: epoch 103, iter 3700, loss: 2.230089, top_1: 0.678477, top_k: 0.868242, samples/s: 847.664 1613125061.8067422
train: epoch 103, iter 3800, loss: 2.186932, top_1: 0.676758, top_k: 0.868555, samples/s: 845.211 1613125092.095032
train: epoch 103, iter 3900, loss: 2.199832, top_1: 0.674766, top_k: 0.865781, samples/s: 850.988 1613125122.1777554
train: epoch 103, iter 4000, loss: 2.252399, top_1: 0.675234, top_k: 0.868320, samples/s: 847.501 1613125152.3842459
train: epoch 103, iter 4100, loss: 2.230724, top_1: 0.676289, top_k: 0.871992, samples/s: 848.024 1613125182.5720744
train: epoch 103, iter 4200, loss: 2.123965, top_1: 0.677422, top_k: 0.874062, samples/s: 848.061 1613125212.7584953
train: epoch 103, iter 4300, loss: 2.318212, top_1: 0.675547, top_k: 0.867188, samples/s: 848.395 1613125242.9331727
train: epoch 103, iter 4400, loss: 2.309660, top_1: 0.681094, top_k: 0.871445, samples/s: 847.294 1613125273.1470525
train: epoch 103, iter 4500, loss: 2.248154, top_1: 0.677773, top_k: 0.872891, samples/s: 847.846 1613125303.3411489
train: epoch 103, iter 4600, loss: 2.258565, top_1: 0.680391, top_k: 0.868320, samples/s: 851.322 1613125333.4120352
train: epoch 103, iter 4700, loss: 2.243014, top_1: 0.676914, top_k: 0.869062, samples/s: 848.125 1613125363.5962272
train: epoch 103, iter 4800, loss: 2.227038, top_1: 0.680703, top_k: 0.869453, samples/s: 846.326 1613125393.8446589
train: epoch 103, iter 4900, loss: 2.225038, top_1: 0.674063, top_k: 0.866484, samples/s: 847.362 1613125424.0560322
train: epoch 103, iter 5000, loss: 2.293981, top_1: 0.677188, top_k: 0.870547, samples/s: 848.072 1613125454.2421982
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_103.
validation: epoch 103, iter 195, top_1: 0.716446, top_k: 0.906811, samples/s: 2439.226 1613125475.6210022
train: epoch 104, iter 100, loss: 2.094396, top_1: 0.694336, top_k: 0.879570, samples/s: 868.736 1613125525.9463055
train: epoch 104, iter 200, loss: 2.307521, top_1: 0.688984, top_k: 0.872148, samples/s: 867.037 1613125555.472071
train: epoch 104, iter 300, loss: 2.222794, top_1: 0.695273, top_k: 0.879414, samples/s: 852.432 1613125585.5038733
train: epoch 104, iter 400, loss: 2.380654, top_1: 0.691016, top_k: 0.875547, samples/s: 848.422 1613125615.6775453
train: epoch 104, iter 500, loss: 2.178091, top_1: 0.688477, top_k: 0.874922, samples/s: 845.765 1613125645.945922
train: epoch 104, iter 600, loss: 2.324386, top_1: 0.685469, top_k: 0.872617, samples/s: 847.033 1613125676.1690922
train: epoch 104, iter 700, loss: 2.387809, top_1: 0.688594, top_k: 0.876328, samples/s: 847.399 1613125706.3791707
train: epoch 104, iter 800, loss: 2.215115, top_1: 0.686289, top_k: 0.876328, samples/s: 847.642 1613125736.5805829
train: epoch 104, iter 900, loss: 2.200085, top_1: 0.685742, top_k: 0.874727, samples/s: 845.139 1613125766.8715239
train: epoch 104, iter 1000, loss: 1.996022, top_1: 0.683164, top_k: 0.873516, samples/s: 845.942 1613125797.1335564
train: epoch 104, iter 1100, loss: 2.237192, top_1: 0.686875, top_k: 0.876992, samples/s: 848.083 1613125827.3194947
train: epoch 104, iter 1200, loss: 2.409791, top_1: 0.687500, top_k: 0.875156, samples/s: 847.001 1613125857.5435917
train: epoch 104, iter 1300, loss: 2.431573, top_1: 0.686406, top_k: 0.874102, samples/s: 844.933 1613125887.841911
train: epoch 104, iter 1400, loss: 2.381986, top_1: 0.689648, top_k: 0.876133, samples/s: 848.028 1613125918.0296123
train: epoch 104, iter 1500, loss: 2.066519, top_1: 0.690352, top_k: 0.874102, samples/s: 848.605 1613125948.1966505
train: epoch 104, iter 1600, loss: 2.199926, top_1: 0.687969, top_k: 0.873320, samples/s: 847.021 1613125978.4202871
train: epoch 104, iter 1700, loss: 2.226766, top_1: 0.686953, top_k: 0.874062, samples/s: 845.927 1613126008.6828718
train: epoch 104, iter 1800, loss: 2.233363, top_1: 0.688086, top_k: 0.874453, samples/s: 848.206 1613126038.8642619
train: epoch 104, iter 1900, loss: 2.171411, top_1: 0.684609, top_k: 0.872070, samples/s: 848.367 1613126069.0399413
train: epoch 104, iter 2000, loss: 2.324295, top_1: 0.679453, top_k: 0.871992, samples/s: 848.112 1613126099.2246017
train: epoch 104, iter 2100, loss: 2.394437, top_1: 0.685859, top_k: 0.876133, samples/s: 845.937 1613126129.486923
train: epoch 104, iter 2200, loss: 2.330559, top_1: 0.681914, top_k: 0.870977, samples/s: 847.378 1613126159.6977136
train: epoch 104, iter 2300, loss: 2.327058, top_1: 0.685273, top_k: 0.870820, samples/s: 846.372 1613126189.9445066
train: epoch 104, iter 2400, loss: 2.141362, top_1: 0.678750, top_k: 0.873633, samples/s: 847.183 1613126220.1622884
train: epoch 104, iter 2500, loss: 2.191736, top_1: 0.683984, top_k: 0.868477, samples/s: 849.373 1613126250.3021228
train: epoch 104, iter 2600, loss: 2.200520, top_1: 0.682266, top_k: 0.871719, samples/s: 846.917 1613126280.5293777
train: epoch 104, iter 2700, loss: 2.166360, top_1: 0.679766, top_k: 0.870000, samples/s: 846.282 1613126310.7794425
train: epoch 104, iter 2800, loss: 2.161667, top_1: 0.676328, top_k: 0.871406, samples/s: 848.896 1613126340.936286
train: epoch 104, iter 2900, loss: 2.237491, top_1: 0.681797, top_k: 0.869062, samples/s: 850.152 1613126371.0484986
train: epoch 104, iter 3000, loss: 2.310425, top_1: 0.681445, top_k: 0.870703, samples/s: 847.760 1613126401.2457707
train: epoch 104, iter 3100, loss: 2.548212, top_1: 0.680156, top_k: 0.873867, samples/s: 847.424 1613126431.4548848
train: epoch 104, iter 3200, loss: 2.333976, top_1: 0.682500, top_k: 0.874102, samples/s: 848.729 1613126461.617725
train: epoch 104, iter 3300, loss: 2.473289, top_1: 0.681875, top_k: 0.874414, samples/s: 850.196 1613126491.7283595
train: epoch 104, iter 3400, loss: 2.246977, top_1: 0.678750, top_k: 0.871328, samples/s: 845.215 1613126522.0165815
train: epoch 104, iter 3500, loss: 2.388423, top_1: 0.684766, top_k: 0.873125, samples/s: 850.771 1613126552.106963
train: epoch 104, iter 3600, loss: 2.413257, top_1: 0.680703, top_k: 0.870781, samples/s: 844.613 1613126582.416699
train: epoch 104, iter 3700, loss: 2.487697, top_1: 0.683516, top_k: 0.867500, samples/s: 847.575 1613126612.6204069
train: epoch 104, iter 3800, loss: 2.349880, top_1: 0.684414, top_k: 0.871055, samples/s: 848.808 1613126642.780401
train: epoch 104, iter 3900, loss: 2.442973, top_1: 0.681406, top_k: 0.872148, samples/s: 844.103 1613126673.108511
train: epoch 104, iter 4000, loss: 2.337160, top_1: 0.681094, top_k: 0.872500, samples/s: 849.669 1613126703.2378974
train: epoch 104, iter 4100, loss: 2.563671, top_1: 0.682383, top_k: 0.867969, samples/s: 846.137 1613126733.4930158
train: epoch 104, iter 4200, loss: 2.335947, top_1: 0.679453, top_k: 0.868477, samples/s: 848.380 1613126763.668079
train: epoch 104, iter 4300, loss: 2.247641, top_1: 0.678633, top_k: 0.868906, samples/s: 848.913 1613126793.8243525
train: epoch 104, iter 4400, loss: 2.366767, top_1: 0.678125, top_k: 0.867852, samples/s: 845.231 1613126824.1119168
train: epoch 104, iter 4500, loss: 2.289325, top_1: 0.683477, top_k: 0.871094, samples/s: 851.429 1613126854.179091
train: epoch 104, iter 4600, loss: 2.293993, top_1: 0.679648, top_k: 0.868437, samples/s: 846.064 1613126884.436801
train: epoch 104, iter 4700, loss: 2.339553, top_1: 0.675117, top_k: 0.868203, samples/s: 849.138 1613126914.5849843
train: epoch 104, iter 4800, loss: 2.200637, top_1: 0.680898, top_k: 0.872500, samples/s: 846.654 1613126944.8216858
train: epoch 104, iter 4900, loss: 2.228680, top_1: 0.678594, top_k: 0.867930, samples/s: 849.240 1613126974.9662328
train: epoch 104, iter 5000, loss: 2.152717, top_1: 0.684141, top_k: 0.873164, samples/s: 846.943 1613127005.1926303
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_104.
validation: epoch 104, iter 195, top_1: 0.717568, top_k: 0.907352, samples/s: 2446.725 1613127026.5024748
train: epoch 105, iter 100, loss: 2.308173, top_1: 0.689336, top_k: 0.878672, samples/s: 870.183 1613127076.3158379
train: epoch 105, iter 200, loss: 2.223499, top_1: 0.693750, top_k: 0.880742, samples/s: 867.668 1613127105.8201299
train: epoch 105, iter 300, loss: 2.337844, top_1: 0.691016, top_k: 0.881289, samples/s: 853.314 1613127135.8208733
train: epoch 105, iter 400, loss: 2.196518, top_1: 0.698789, top_k: 0.879961, samples/s: 845.521 1613127166.0980618
train: epoch 105, iter 500, loss: 2.098609, top_1: 0.698672, top_k: 0.881875, samples/s: 845.555 1613127196.3740578
train: epoch 105, iter 600, loss: 2.331953, top_1: 0.693711, top_k: 0.876992, samples/s: 845.503 1613127226.6517808
train: epoch 105, iter 700, loss: 2.335032, top_1: 0.689063, top_k: 0.876992, samples/s: 848.367 1613127256.8274136
train: epoch 105, iter 800, loss: 2.177695, top_1: 0.692891, top_k: 0.878945, samples/s: 844.062 1613127287.1569495
train: epoch 105, iter 900, loss: 2.237630, top_1: 0.687422, top_k: 0.877227, samples/s: 846.781 1613127317.3891401
train: epoch 105, iter 1000, loss: 2.243098, top_1: 0.690586, top_k: 0.876914, samples/s: 846.408 1613127347.6346495
train: epoch 105, iter 1100, loss: 2.338211, top_1: 0.686680, top_k: 0.875469, samples/s: 848.603 1613127377.8018277
train: epoch 105, iter 1200, loss: 2.463707, top_1: 0.690039, top_k: 0.879727, samples/s: 844.366 1613127408.1204677
train: epoch 105, iter 1300, loss: 2.294403, top_1: 0.686562, top_k: 0.874766, samples/s: 846.188 1613127438.373757
train: epoch 105, iter 1400, loss: 2.281098, top_1: 0.684219, top_k: 0.872695, samples/s: 843.036 1613127468.7401876
train: epoch 105, iter 1500, loss: 2.182817, top_1: 0.685039, top_k: 0.874687, samples/s: 848.229 1613127498.9206572
train: epoch 105, iter 1600, loss: 2.308968, top_1: 0.685430, top_k: 0.874766, samples/s: 850.191 1613127529.0316162
train: epoch 105, iter 1700, loss: 2.261687, top_1: 0.686406, top_k: 0.873516, samples/s: 847.003 1613127559.2558255
train: epoch 105, iter 1800, loss: 2.232940, top_1: 0.682305, top_k: 0.873008, samples/s: 846.320 1613127589.5044005
train: epoch 105, iter 1900, loss: 2.387061, top_1: 0.682266, top_k: 0.871719, samples/s: 848.809 1613127619.6642718
train: epoch 105, iter 2000, loss: 2.341160, top_1: 0.685742, top_k: 0.871016, samples/s: 850.693 1613127649.7575014
train: epoch 105, iter 2100, loss: 2.303258, top_1: 0.680234, top_k: 0.870781, samples/s: 848.048 1613127679.944395
train: epoch 105, iter 2200, loss: 2.456210, top_1: 0.685859, top_k: 0.874141, samples/s: 845.243 1613127710.2315147
train: epoch 105, iter 2300, loss: 2.413643, top_1: 0.687148, top_k: 0.873047, samples/s: 846.182 1613127740.48513
train: epoch 105, iter 2400, loss: 2.205068, top_1: 0.682109, top_k: 0.872695, samples/s: 845.968 1613127770.7463233
train: epoch 105, iter 2500, loss: 2.246382, top_1: 0.684805, top_k: 0.870039, samples/s: 847.346 1613127800.9583433
train: epoch 105, iter 2600, loss: 2.216557, top_1: 0.686797, top_k: 0.872578, samples/s: 847.899 1613127831.1505542
train: epoch 105, iter 2700, loss: 2.117626, top_1: 0.680039, top_k: 0.873672, samples/s: 849.147 1613127861.2985277
train: epoch 105, iter 2800, loss: 2.226882, top_1: 0.686445, top_k: 0.873437, samples/s: 847.437 1613127891.507208
train: epoch 105, iter 2900, loss: 2.229215, top_1: 0.684180, top_k: 0.872617, samples/s: 847.321 1613127921.7200332
train: epoch 105, iter 3000, loss: 2.208717, top_1: 0.683633, top_k: 0.871836, samples/s: 848.429 1613127951.8935304
train: epoch 105, iter 3100, loss: 2.289884, top_1: 0.685625, top_k: 0.871914, samples/s: 848.931 1613127982.0490615
train: epoch 105, iter 3200, loss: 2.311625, top_1: 0.684102, top_k: 0.871641, samples/s: 846.106 1613128012.3052552
train: epoch 105, iter 3300, loss: 2.207650, top_1: 0.676602, top_k: 0.870195, samples/s: 848.715 1613128042.4685755
train: epoch 105, iter 3400, loss: 2.299853, top_1: 0.681406, top_k: 0.869258, samples/s: 847.489 1613128072.6754453
train: epoch 105, iter 3500, loss: 2.411169, top_1: 0.684336, top_k: 0.872031, samples/s: 847.925 1613128102.8666883
train: epoch 105, iter 3600, loss: 2.417151, top_1: 0.681172, top_k: 0.873594, samples/s: 849.180 1613128133.0134356
train: epoch 105, iter 3700, loss: 2.273262, top_1: 0.689414, top_k: 0.875352, samples/s: 849.496 1613128163.1490023
train: epoch 105, iter 3800, loss: 2.288099, top_1: 0.680703, top_k: 0.870078, samples/s: 849.546 1613128193.282668
train: epoch 105, iter 3900, loss: 2.156720, top_1: 0.683906, top_k: 0.869414, samples/s: 848.916 1613128223.4388185
train: epoch 105, iter 4000, loss: 2.379966, top_1: 0.680469, top_k: 0.870547, samples/s: 846.526 1613128253.6800632
train: epoch 105, iter 4100, loss: 2.263314, top_1: 0.682695, top_k: 0.870781, samples/s: 847.664 1613128283.880692
train: epoch 105, iter 4200, loss: 2.341935, top_1: 0.682148, top_k: 0.873281, samples/s: 846.940 1613128314.107134
train: epoch 105, iter 4300, loss: 2.322711, top_1: 0.682891, top_k: 0.873047, samples/s: 848.884 1613128344.2643912
train: epoch 105, iter 4400, loss: 2.290902, top_1: 0.684258, top_k: 0.871250, samples/s: 844.485 1613128374.5787804
train: epoch 105, iter 4500, loss: 2.182600, top_1: 0.679844, top_k: 0.873047, samples/s: 852.633 1613128404.603322
train: epoch 105, iter 4600, loss: 2.347081, top_1: 0.685273, top_k: 0.873828, samples/s: 849.976 1613128434.721878
train: epoch 105, iter 4700, loss: 2.221964, top_1: 0.685352, top_k: 0.874492, samples/s: 849.303 1613128464.8641617
train: epoch 105, iter 4800, loss: 2.174822, top_1: 0.680547, top_k: 0.868047, samples/s: 844.233 1613128495.1876447
train: epoch 105, iter 4900, loss: 2.355825, top_1: 0.677969, top_k: 0.870508, samples/s: 850.113 1613128525.3012018
train: epoch 105, iter 5000, loss: 2.313866, top_1: 0.690273, top_k: 0.873945, samples/s: 847.861 1613128555.4949036
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_105.
validation: epoch 105, iter 195, top_1: 0.715365, top_k: 0.906170, samples/s: 2429.099 1613128576.9416022
train: epoch 106, iter 100, loss: 2.377725, top_1: 0.694102, top_k: 0.881797, samples/s: 868.478 1613128626.8998864
train: epoch 106, iter 200, loss: 2.211026, top_1: 0.688906, top_k: 0.877188, samples/s: 866.943 1613128656.4288223
train: epoch 106, iter 300, loss: 2.220537, top_1: 0.697187, top_k: 0.878867, samples/s: 850.547 1613128686.5271196
train: epoch 106, iter 400, loss: 2.129250, top_1: 0.696367, top_k: 0.882422, samples/s: 846.393 1613128716.7731571
train: epoch 106, iter 500, loss: 2.229249, top_1: 0.694609, top_k: 0.878789, samples/s: 845.840 1613128747.0388966
train: epoch 106, iter 600, loss: 2.272960, top_1: 0.697383, top_k: 0.877656, samples/s: 844.757 1613128777.3435142
train: epoch 106, iter 700, loss: 2.276739, top_1: 0.688711, top_k: 0.879336, samples/s: 846.206 1613128807.5961893
train: epoch 106, iter 800, loss: 2.478885, top_1: 0.688789, top_k: 0.876641, samples/s: 850.383 1613128837.7001565
train: epoch 106, iter 900, loss: 2.242164, top_1: 0.692578, top_k: 0.878867, samples/s: 843.747 1613128868.0411112
train: epoch 106, iter 1000, loss: 2.107110, top_1: 0.693906, top_k: 0.878281, samples/s: 845.067 1613128898.334567
train: epoch 106, iter 1100, loss: 2.260767, top_1: 0.686367, top_k: 0.873359, samples/s: 848.816 1613128928.494242
train: epoch 106, iter 1200, loss: 2.298332, top_1: 0.689375, top_k: 0.876250, samples/s: 844.998 1613128958.7901769
train: epoch 106, iter 1300, loss: 2.169806, top_1: 0.694844, top_k: 0.881406, samples/s: 846.704 1613128989.0250716
train: epoch 106, iter 1400, loss: 2.224328, top_1: 0.694414, top_k: 0.881328, samples/s: 848.748 1613129019.1870208
train: epoch 106, iter 1500, loss: 2.283776, top_1: 0.692461, top_k: 0.875508, samples/s: 845.778 1613129049.4550204
train: epoch 106, iter 1600, loss: 2.244621, top_1: 0.691133, top_k: 0.875234, samples/s: 850.249 1613129079.5639403
train: epoch 106, iter 1700, loss: 2.187784, top_1: 0.685039, top_k: 0.877148, samples/s: 846.485 1613129109.80664
train: epoch 106, iter 1800, loss: 2.427958, top_1: 0.689102, top_k: 0.873867, samples/s: 847.978 1613129139.9960046
train: epoch 106, iter 1900, loss: 2.237192, top_1: 0.691523, top_k: 0.879023, samples/s: 848.474 1613129170.167909
train: epoch 106, iter 2000, loss: 2.323333, top_1: 0.688789, top_k: 0.871250, samples/s: 848.314 1613129200.3454494
train: epoch 106, iter 2100, loss: 2.335133, top_1: 0.694063, top_k: 0.876055, samples/s: 847.651 1613129230.5464287
train: epoch 106, iter 2200, loss: 2.337015, top_1: 0.689531, top_k: 0.874531, samples/s: 848.119 1613129260.7309349
train: epoch 106, iter 2300, loss: 2.277635, top_1: 0.688047, top_k: 0.871953, samples/s: 848.211 1613129290.9120848
train: epoch 106, iter 2400, loss: 2.194561, top_1: 0.688008, top_k: 0.875508, samples/s: 845.521 1613129321.1892157
train: epoch 106, iter 2500, loss: 2.304604, top_1: 0.689727, top_k: 0.874727, samples/s: 847.946 1613129351.3798769
train: epoch 106, iter 2600, loss: 2.170098, top_1: 0.683555, top_k: 0.875820, samples/s: 847.082 1613129381.6012986
train: epoch 106, iter 2700, loss: 2.252078, top_1: 0.686211, top_k: 0.875195, samples/s: 846.930 1613129411.8280365
train: epoch 106, iter 2800, loss: 2.373236, top_1: 0.685078, top_k: 0.871016, samples/s: 849.928 1613129441.9482641
train: epoch 106, iter 2900, loss: 2.239014, top_1: 0.684688, top_k: 0.873164, samples/s: 846.750 1613129472.181555
train: epoch 106, iter 3000, loss: 2.205268, top_1: 0.687813, top_k: 0.874102, samples/s: 851.234 1613129502.2554893
train: epoch 106, iter 3100, loss: 1.967322, top_1: 0.689375, top_k: 0.878320, samples/s: 846.544 1613129532.496078
train: epoch 106, iter 3200, loss: 2.299702, top_1: 0.688906, top_k: 0.874023, samples/s: 847.746 1613129562.6938822
train: epoch 106, iter 3300, loss: 2.200339, top_1: 0.681797, top_k: 0.871563, samples/s: 847.144 1613129592.913044
train: epoch 106, iter 3400, loss: 2.338879, top_1: 0.684492, top_k: 0.872617, samples/s: 849.734 1613129623.0400763
train: epoch 106, iter 3500, loss: 2.412267, top_1: 0.688906, top_k: 0.872695, samples/s: 846.074 1613129653.2975624
train: epoch 106, iter 3600, loss: 2.165253, top_1: 0.687148, top_k: 0.875547, samples/s: 845.604 1613129683.571757
train: epoch 106, iter 3700, loss: 2.134506, top_1: 0.687109, top_k: 0.871406, samples/s: 848.902 1613129713.728371
train: epoch 106, iter 3800, loss: 2.279526, top_1: 0.681836, top_k: 0.873945, samples/s: 847.179 1613129743.9463284
train: epoch 106, iter 3900, loss: 2.347926, top_1: 0.684961, top_k: 0.874258, samples/s: 846.435 1613129774.190758
train: epoch 106, iter 4000, loss: 2.333562, top_1: 0.682930, top_k: 0.874648, samples/s: 847.926 1613129804.382127
train: epoch 106, iter 4100, loss: 2.234587, top_1: 0.688125, top_k: 0.872695, samples/s: 844.631 1613129834.6911745
train: epoch 106, iter 4200, loss: 2.342129, top_1: 0.682461, top_k: 0.873516, samples/s: 847.405 1613129864.9010453
train: epoch 106, iter 4300, loss: 2.204705, top_1: 0.681953, top_k: 0.873125, samples/s: 845.654 1613129895.1734533
train: epoch 106, iter 4400, loss: 2.246828, top_1: 0.686797, top_k: 0.875039, samples/s: 849.151 1613129925.3212593
train: epoch 106, iter 4500, loss: 2.244749, top_1: 0.685781, top_k: 0.871758, samples/s: 846.940 1613129955.547666
train: epoch 106, iter 4600, loss: 2.236531, top_1: 0.683281, top_k: 0.872617, samples/s: 846.044 1613129985.8061626
train: epoch 106, iter 4700, loss: 2.354581, top_1: 0.689336, top_k: 0.872109, samples/s: 849.635 1613130015.9367492
train: epoch 106, iter 4800, loss: 2.336534, top_1: 0.688008, top_k: 0.874062, samples/s: 848.118 1613130046.1211824
train: epoch 106, iter 4900, loss: 2.465138, top_1: 0.689414, top_k: 0.871797, samples/s: 845.762 1613130076.3897152
train: epoch 106, iter 5000, loss: 2.154552, top_1: 0.684688, top_k: 0.874609, samples/s: 847.298 1613130106.603483
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_106.
validation: epoch 106, iter 195, top_1: 0.718349, top_k: 0.907672, samples/s: 2402.924 1613130128.2849827
train: epoch 107, iter 100, loss: 2.167110, top_1: 0.700156, top_k: 0.882969, samples/s: 872.408 1613130177.9278305
train: epoch 107, iter 200, loss: 2.139374, top_1: 0.694727, top_k: 0.877344, samples/s: 866.553 1613130207.4702141
train: epoch 107, iter 300, loss: 2.090642, top_1: 0.699922, top_k: 0.882812, samples/s: 852.301 1613130237.5064704
train: epoch 107, iter 400, loss: 2.358281, top_1: 0.702344, top_k: 0.882812, samples/s: 848.966 1613130267.6608562
train: epoch 107, iter 500, loss: 2.198062, top_1: 0.696328, top_k: 0.882188, samples/s: 846.186 1613130297.914184
train: epoch 107, iter 600, loss: 2.335896, top_1: 0.698789, top_k: 0.879648, samples/s: 846.854 1613130328.143738
train: epoch 107, iter 700, loss: 2.226228, top_1: 0.694414, top_k: 0.878555, samples/s: 846.416 1613130358.3889399
train: epoch 107, iter 800, loss: 2.058536, top_1: 0.695898, top_k: 0.881094, samples/s: 847.108 1613130388.609332
train: epoch 107, iter 900, loss: 2.268036, top_1: 0.694063, top_k: 0.879023, samples/s: 846.117 1613130418.8651927
train: epoch 107, iter 1000, loss: 2.393420, top_1: 0.697266, top_k: 0.879492, samples/s: 848.132 1613130449.0492637
train: epoch 107, iter 1100, loss: 2.222692, top_1: 0.697070, top_k: 0.880898, samples/s: 847.790 1613130479.24534
train: epoch 107, iter 1200, loss: 2.232596, top_1: 0.695039, top_k: 0.880273, samples/s: 847.076 1613130509.4669125
train: epoch 107, iter 1300, loss: 2.323796, top_1: 0.695039, top_k: 0.880000, samples/s: 845.262 1613130539.7534032
train: epoch 107, iter 1400, loss: 2.351463, top_1: 0.693125, top_k: 0.876875, samples/s: 847.184 1613130569.9711177
train: epoch 107, iter 1500, loss: 2.336182, top_1: 0.691250, top_k: 0.874102, samples/s: 848.170 1613130600.1538758
train: epoch 107, iter 1600, loss: 2.204264, top_1: 0.690547, top_k: 0.877031, samples/s: 843.517 1613130630.5028956
train: epoch 107, iter 1700, loss: 2.152516, top_1: 0.688945, top_k: 0.873203, samples/s: 849.217 1613130660.6483521
train: epoch 107, iter 1800, loss: 2.341768, top_1: 0.693555, top_k: 0.878672, samples/s: 848.740 1613130690.810777
train: epoch 107, iter 1900, loss: 2.206438, top_1: 0.693477, top_k: 0.878047, samples/s: 846.890 1613130721.0389478
train: epoch 107, iter 2000, loss: 2.222219, top_1: 0.691484, top_k: 0.879258, samples/s: 848.625 1613130751.205392
train: epoch 107, iter 2100, loss: 2.514935, top_1: 0.696367, top_k: 0.877578, samples/s: 846.459 1613130781.449063
train: epoch 107, iter 2200, loss: 2.281735, top_1: 0.687695, top_k: 0.876523, samples/s: 848.131 1613130811.6330438
train: epoch 107, iter 2300, loss: 2.336040, top_1: 0.691914, top_k: 0.877188, samples/s: 846.032 1613130841.8920069
train: epoch 107, iter 2400, loss: 2.426085, top_1: 0.689258, top_k: 0.877500, samples/s: 850.024 1613130872.008815
train: epoch 107, iter 2500, loss: 2.245316, top_1: 0.691328, top_k: 0.875859, samples/s: 846.255 1613130902.25972
train: epoch 107, iter 2600, loss: 2.310645, top_1: 0.689258, top_k: 0.873672, samples/s: 847.468 1613130932.4673693
train: epoch 107, iter 2700, loss: 2.416277, top_1: 0.693672, top_k: 0.880352, samples/s: 847.784 1613130962.6637304
train: epoch 107, iter 2800, loss: 2.234566, top_1: 0.686680, top_k: 0.872695, samples/s: 847.128 1613130992.8834932
train: epoch 107, iter 2900, loss: 2.284260, top_1: 0.691992, top_k: 0.879531, samples/s: 847.264 1613131023.0983841
train: epoch 107, iter 3000, loss: 2.355551, top_1: 0.692969, top_k: 0.879219, samples/s: 849.465 1613131053.2350123
train: epoch 107, iter 3100, loss: 2.240647, top_1: 0.689922, top_k: 0.877031, samples/s: 845.797 1613131083.5022984
train: epoch 107, iter 3200, loss: 2.449258, top_1: 0.693203, top_k: 0.875273, samples/s: 849.352 1613131113.642877
train: epoch 107, iter 3300, loss: 2.282872, top_1: 0.683125, top_k: 0.875742, samples/s: 846.159 1613131143.8971624
train: epoch 107, iter 3400, loss: 2.441277, top_1: 0.685352, top_k: 0.874453, samples/s: 845.843 1613131174.1629395
train: epoch 107, iter 3500, loss: 2.298998, top_1: 0.682539, top_k: 0.877461, samples/s: 850.530 1613131204.2618356
train: epoch 107, iter 3600, loss: 2.197090, top_1: 0.688789, top_k: 0.875742, samples/s: 846.610 1613131234.5000196
train: epoch 107, iter 3700, loss: 2.275270, top_1: 0.685742, top_k: 0.875391, samples/s: 846.818 1613131264.7309084
train: epoch 107, iter 3800, loss: 2.334889, top_1: 0.682109, top_k: 0.874531, samples/s: 847.249 1613131294.9463263
train: epoch 107, iter 3900, loss: 2.245695, top_1: 0.693203, top_k: 0.881055, samples/s: 846.874 1613131325.1752036
train: epoch 107, iter 4000, loss: 2.170430, top_1: 0.688398, top_k: 0.876680, samples/s: 850.042 1613131355.2912865
train: epoch 107, iter 4100, loss: 2.253718, top_1: 0.690937, top_k: 0.875664, samples/s: 848.228 1613131385.4718063
train: epoch 107, iter 4200, loss: 2.407268, top_1: 0.688125, top_k: 0.875430, samples/s: 844.924 1613131415.7704902
train: epoch 107, iter 4300, loss: 2.219731, top_1: 0.686289, top_k: 0.872656, samples/s: 847.531 1613131445.9757993
train: epoch 107, iter 4400, loss: 2.281888, top_1: 0.685898, top_k: 0.875586, samples/s: 848.860 1613131476.133956
train: epoch 107, iter 4500, loss: 2.207609, top_1: 0.682109, top_k: 0.869805, samples/s: 846.079 1613131506.391188
train: epoch 107, iter 4600, loss: 2.159294, top_1: 0.686953, top_k: 0.873477, samples/s: 847.619 1613131536.5933552
train: epoch 107, iter 4700, loss: 2.318404, top_1: 0.685898, top_k: 0.875273, samples/s: 846.767 1613131566.8260822
train: epoch 107, iter 4800, loss: 2.359816, top_1: 0.687422, top_k: 0.875977, samples/s: 847.403 1613131597.035952
train: epoch 107, iter 4900, loss: 2.394352, top_1: 0.687930, top_k: 0.876406, samples/s: 848.681 1613131627.2003868
train: epoch 107, iter 5000, loss: 2.200013, top_1: 0.697344, top_k: 0.882891, samples/s: 845.655 1613131657.4728463
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_107.
validation: epoch 107, iter 195, top_1: 0.717528, top_k: 0.908754, samples/s: 2446.656 1613131678.7308247
train: epoch 108, iter 100, loss: 2.075606, top_1: 0.705742, top_k: 0.883281, samples/s: 872.010 1613131728.7488086
train: epoch 108, iter 200, loss: 2.105556, top_1: 0.705234, top_k: 0.884102, samples/s: 867.616 1613131758.2549138
train: epoch 108, iter 300, loss: 2.154232, top_1: 0.701562, top_k: 0.884961, samples/s: 850.591 1613131788.3517332
train: epoch 108, iter 400, loss: 2.272536, top_1: 0.699180, top_k: 0.877852, samples/s: 846.121 1613131818.6073384
train: epoch 108, iter 500, loss: 2.372441, top_1: 0.692813, top_k: 0.880352, samples/s: 846.074 1613131848.8648088
train: epoch 108, iter 600, loss: 2.351983, top_1: 0.696836, top_k: 0.881758, samples/s: 845.567 1613131879.1403391
train: epoch 108, iter 700, loss: 2.106988, top_1: 0.694102, top_k: 0.879297, samples/s: 847.970 1613131909.3300333
train: epoch 108, iter 800, loss: 2.238074, top_1: 0.701484, top_k: 0.882695, samples/s: 846.332 1613131939.5782945
train: epoch 108, iter 900, loss: 2.206234, top_1: 0.701289, top_k: 0.882812, samples/s: 847.826 1613131969.773139
train: epoch 108, iter 1000, loss: 2.204995, top_1: 0.700039, top_k: 0.880898, samples/s: 846.075 1613132000.0304859
train: epoch 108, iter 1100, loss: 2.304855, top_1: 0.695977, top_k: 0.881406, samples/s: 849.564 1613132030.1636262
train: epoch 108, iter 1200, loss: 2.168302, top_1: 0.693164, top_k: 0.876055, samples/s: 848.510 1613132060.3340983
train: epoch 108, iter 1300, loss: 2.308748, top_1: 0.692578, top_k: 0.878047, samples/s: 845.595 1613132090.608681
train: epoch 108, iter 1400, loss: 2.262130, top_1: 0.696406, top_k: 0.880273, samples/s: 847.287 1613132120.8227644
train: epoch 108, iter 1500, loss: 2.208014, top_1: 0.691680, top_k: 0.877812, samples/s: 843.503 1613132151.1724575
train: epoch 108, iter 1600, loss: 2.379003, top_1: 0.691094, top_k: 0.878750, samples/s: 848.298 1613132181.3504968
train: epoch 108, iter 1700, loss: 2.256219, top_1: 0.688672, top_k: 0.877773, samples/s: 844.245 1613132211.6734145
train: epoch 108, iter 1800, loss: 2.429181, top_1: 0.689180, top_k: 0.876172, samples/s: 852.520 1613132241.7020447
train: epoch 108, iter 1900, loss: 2.232376, top_1: 0.696055, top_k: 0.879453, samples/s: 845.831 1613132271.9681237
train: epoch 108, iter 2000, loss: 2.316984, top_1: 0.688672, top_k: 0.876641, samples/s: 845.281 1613132302.2540088
train: epoch 108, iter 2100, loss: 2.293390, top_1: 0.688867, top_k: 0.878281, samples/s: 848.397 1613132332.428559
train: epoch 108, iter 2200, loss: 2.374780, top_1: 0.692773, top_k: 0.878594, samples/s: 847.103 1613132362.649109
train: epoch 108, iter 2300, loss: 2.326446, top_1: 0.691953, top_k: 0.878594, samples/s: 849.918 1613132392.769686
train: epoch 108, iter 2400, loss: 2.391976, top_1: 0.690742, top_k: 0.876055, samples/s: 843.828 1613132423.1076362
train: epoch 108, iter 2500, loss: 2.240291, top_1: 0.697500, top_k: 0.878672, samples/s: 848.823 1613132453.267044
train: epoch 108, iter 2600, loss: 2.354991, top_1: 0.691562, top_k: 0.874727, samples/s: 849.690 1613132483.3956866
train: epoch 108, iter 2700, loss: 2.207382, top_1: 0.687500, top_k: 0.875469, samples/s: 845.744 1613132513.6648757
train: epoch 108, iter 2800, loss: 2.119760, top_1: 0.691016, top_k: 0.879102, samples/s: 846.210 1613132543.9173572
train: epoch 108, iter 2900, loss: 2.236962, top_1: 0.687187, top_k: 0.872578, samples/s: 851.975 1613132573.965282
train: epoch 108, iter 3000, loss: 2.381099, top_1: 0.694414, top_k: 0.880508, samples/s: 846.851 1613132604.1948526
train: epoch 108, iter 3100, loss: 2.220922, top_1: 0.687539, top_k: 0.872812, samples/s: 845.267 1613132634.4812057
train: epoch 108, iter 3200, loss: 2.324928, top_1: 0.693711, top_k: 0.876484, samples/s: 848.833 1613132664.6402657
train: epoch 108, iter 3300, loss: 2.243971, top_1: 0.696328, top_k: 0.879844, samples/s: 849.089 1613132694.7902415
train: epoch 108, iter 3400, loss: 2.355463, top_1: 0.691680, top_k: 0.876484, samples/s: 846.949 1613132725.016373
train: epoch 108, iter 3500, loss: 2.320985, top_1: 0.685781, top_k: 0.875664, samples/s: 849.483 1613132755.152235
train: epoch 108, iter 3600, loss: 2.254113, top_1: 0.693711, top_k: 0.878203, samples/s: 849.228 1613132785.297383
train: epoch 108, iter 3700, loss: 2.188143, top_1: 0.694219, top_k: 0.879531, samples/s: 847.820 1613132815.4923785
train: epoch 108, iter 3800, loss: 2.245559, top_1: 0.686055, top_k: 0.872656, samples/s: 848.443 1613132845.6653638
train: epoch 108, iter 3900, loss: 2.267824, top_1: 0.691914, top_k: 0.884062, samples/s: 846.718 1613132875.8997192
train: epoch 108, iter 4000, loss: 2.271363, top_1: 0.692266, top_k: 0.877422, samples/s: 849.407 1613132906.0384693
train: epoch 108, iter 4100, loss: 2.246263, top_1: 0.693945, top_k: 0.876758, samples/s: 846.087 1613132936.2952814
train: epoch 108, iter 4200, loss: 2.380831, top_1: 0.693320, top_k: 0.877344, samples/s: 849.957 1613132966.414544
train: epoch 108, iter 4300, loss: 2.255330, top_1: 0.692383, top_k: 0.874258, samples/s: 848.263 1613132996.5938113
train: epoch 108, iter 4400, loss: 2.188056, top_1: 0.692617, top_k: 0.874375, samples/s: 848.698 1613133026.7576723
train: epoch 108, iter 4500, loss: 2.324660, top_1: 0.694727, top_k: 0.880391, samples/s: 846.632 1613133056.9951942
train: epoch 108, iter 4600, loss: 2.158712, top_1: 0.688594, top_k: 0.873125, samples/s: 849.441 1613133087.1325903
train: epoch 108, iter 4700, loss: 2.437787, top_1: 0.690078, top_k: 0.874492, samples/s: 849.933 1613133117.2525754
train: epoch 108, iter 4800, loss: 2.441722, top_1: 0.690508, top_k: 0.877422, samples/s: 847.057 1613133147.4749768
train: epoch 108, iter 4900, loss: 2.309743, top_1: 0.688945, top_k: 0.874570, samples/s: 848.177 1613133177.6572995
train: epoch 108, iter 5000, loss: 2.309563, top_1: 0.693750, top_k: 0.875547, samples/s: 849.850 1613133207.7802744
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_108.
validation: epoch 108, iter 195, top_1: 0.720152, top_k: 0.909936, samples/s: 2431.921 1613133229.1992621
train: epoch 109, iter 100, loss: 2.311790, top_1: 0.705859, top_k: 0.886211, samples/s: 871.021 1613133284.26378
train: epoch 109, iter 200, loss: 2.224025, top_1: 0.701328, top_k: 0.884844, samples/s: 869.141 1613133313.7181962
train: epoch 109, iter 300, loss: 2.209230, top_1: 0.701680, top_k: 0.879219, samples/s: 858.043 1613133343.5534773
train: epoch 109, iter 400, loss: 2.213650, top_1: 0.702383, top_k: 0.884297, samples/s: 844.635 1613133373.862492
train: epoch 109, iter 500, loss: 2.300686, top_1: 0.701562, top_k: 0.883281, samples/s: 849.219 1613133404.0078037
train: epoch 109, iter 600, loss: 2.387766, top_1: 0.703320, top_k: 0.884570, samples/s: 846.130 1613133434.2631912
train: epoch 109, iter 700, loss: 2.276424, top_1: 0.696836, top_k: 0.880195, samples/s: 846.808 1613133464.4943423
train: epoch 109, iter 800, loss: 2.226428, top_1: 0.695156, top_k: 0.880938, samples/s: 850.368 1613133494.598962
train: epoch 109, iter 900, loss: 2.433887, top_1: 0.698750, top_k: 0.879375, samples/s: 844.658 1613133524.907176
train: epoch 109, iter 1000, loss: 2.189993, top_1: 0.692930, top_k: 0.876445, samples/s: 849.641 1613133555.0374472
train: epoch 109, iter 1100, loss: 2.283981, top_1: 0.700391, top_k: 0.885117, samples/s: 847.413 1613133585.2471385
train: epoch 109, iter 1200, loss: 2.201633, top_1: 0.702539, top_k: 0.881133, samples/s: 847.892 1613133615.4396546
train: epoch 109, iter 1300, loss: 2.196220, top_1: 0.697656, top_k: 0.879531, samples/s: 845.612 1613133645.7135756
train: epoch 109, iter 1400, loss: 2.154807, top_1: 0.702578, top_k: 0.883750, samples/s: 847.095 1613133675.934492
train: epoch 109, iter 1500, loss: 1.997231, top_1: 0.693398, top_k: 0.882227, samples/s: 848.572 1613133706.102844
train: epoch 109, iter 1600, loss: 2.171912, top_1: 0.696133, top_k: 0.881250, samples/s: 847.115 1613133736.3233309
train: epoch 109, iter 1700, loss: 2.424836, top_1: 0.690664, top_k: 0.876094, samples/s: 849.117 1613133766.471992
train: epoch 109, iter 1800, loss: 2.167248, top_1: 0.696445, top_k: 0.880586, samples/s: 844.596 1613133796.7824492
train: epoch 109, iter 1900, loss: 2.200522, top_1: 0.698438, top_k: 0.883437, samples/s: 851.008 1613133826.8644266
train: epoch 109, iter 2000, loss: 2.227698, top_1: 0.690547, top_k: 0.875547, samples/s: 845.509 1613133857.141976
train: epoch 109, iter 2100, loss: 2.157138, top_1: 0.698125, top_k: 0.883281, samples/s: 850.718 1613133887.2343006
train: epoch 109, iter 2200, loss: 2.247164, top_1: 0.695781, top_k: 0.877109, samples/s: 846.274 1613133917.4845033
train: epoch 109, iter 2300, loss: 2.173207, top_1: 0.692734, top_k: 0.878008, samples/s: 848.696 1613133947.6483507
train: epoch 109, iter 2400, loss: 2.209017, top_1: 0.695195, top_k: 0.880195, samples/s: 845.446 1613133977.9282925
train: epoch 109, iter 2500, loss: 2.194053, top_1: 0.691875, top_k: 0.877773, samples/s: 848.305 1613134008.1061478
train: epoch 109, iter 2600, loss: 2.197063, top_1: 0.690820, top_k: 0.876953, samples/s: 851.556 1613134038.168802
train: epoch 109, iter 2700, loss: 2.331769, top_1: 0.694961, top_k: 0.878320, samples/s: 852.047 1613134068.2140725
train: epoch 109, iter 2800, loss: 2.238198, top_1: 0.695859, top_k: 0.880195, samples/s: 845.780 1613134098.4819875
train: epoch 109, iter 2900, loss: 2.213411, top_1: 0.697695, top_k: 0.879648, samples/s: 849.996 1613134128.5997658
train: epoch 109, iter 3000, loss: 2.322509, top_1: 0.692031, top_k: 0.878711, samples/s: 849.051 1613134158.7510035
train: epoch 109, iter 3100, loss: 2.429990, top_1: 0.691367, top_k: 0.875820, samples/s: 847.591 1613134188.9542346
train: epoch 109, iter 3200, loss: 2.378588, top_1: 0.700937, top_k: 0.880977, samples/s: 847.892 1613134219.146816
train: epoch 109, iter 3300, loss: 2.510430, top_1: 0.696289, top_k: 0.880078, samples/s: 846.788 1613134249.3786852
train: epoch 109, iter 3400, loss: 2.298299, top_1: 0.694219, top_k: 0.878516, samples/s: 851.518 1613134279.4426088
train: epoch 109, iter 3500, loss: 2.263287, top_1: 0.694531, top_k: 0.879609, samples/s: 847.438 1613134309.6513498
train: epoch 109, iter 3600, loss: 2.260671, top_1: 0.697305, top_k: 0.881055, samples/s: 848.536 1613134339.820907
train: epoch 109, iter 3700, loss: 2.197400, top_1: 0.693008, top_k: 0.875781, samples/s: 848.264 1613134370.0003493
train: epoch 109, iter 3800, loss: 2.407737, top_1: 0.694844, top_k: 0.877148, samples/s: 849.430 1613134400.1381888
train: epoch 109, iter 3900, loss: 2.145683, top_1: 0.689219, top_k: 0.874844, samples/s: 846.146 1613134430.3929596
train: epoch 109, iter 4000, loss: 2.199043, top_1: 0.695117, top_k: 0.877109, samples/s: 851.606 1613134460.4537344
train: epoch 109, iter 4100, loss: 2.362047, top_1: 0.692266, top_k: 0.878164, samples/s: 845.440 1613134490.733943
train: epoch 109, iter 4200, loss: 2.382424, top_1: 0.687969, top_k: 0.876602, samples/s: 850.078 1613134520.848815
train: epoch 109, iter 4300, loss: 2.216166, top_1: 0.690977, top_k: 0.874805, samples/s: 852.471 1613134550.8791463
train: epoch 109, iter 4400, loss: 2.390456, top_1: 0.691016, top_k: 0.877852, samples/s: 846.130 1613134581.1344297
train: epoch 109, iter 4500, loss: 2.263252, top_1: 0.691875, top_k: 0.881172, samples/s: 848.011 1613134611.3227284
train: epoch 109, iter 4600, loss: 2.339260, top_1: 0.692148, top_k: 0.878906, samples/s: 850.876 1613134641.409422
train: epoch 109, iter 4700, loss: 2.320832, top_1: 0.693359, top_k: 0.873477, samples/s: 848.875 1613134671.566976
train: epoch 109, iter 4800, loss: 2.354469, top_1: 0.691758, top_k: 0.874883, samples/s: 850.528 1613134701.666009
train: epoch 109, iter 4900, loss: 2.242466, top_1: 0.698516, top_k: 0.877695, samples/s: 848.199 1613134731.8476288
train: epoch 109, iter 5000, loss: 2.095126, top_1: 0.698945, top_k: 0.881055, samples/s: 848.314 1613134762.025
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_109.
validation: epoch 109, iter 195, top_1: 0.714683, top_k: 0.907672, samples/s: 2419.676 1613134783.5643735
train: epoch 110, iter 100, loss: 2.191364, top_1: 0.705391, top_k: 0.883945, samples/s: 867.246 1613134833.4363348
train: epoch 110, iter 200, loss: 2.053583, top_1: 0.709453, top_k: 0.886406, samples/s: 869.502 1613134862.8784912
train: epoch 110, iter 300, loss: 2.316206, top_1: 0.706875, top_k: 0.883945, samples/s: 850.454 1613134892.9801126
train: epoch 110, iter 400, loss: 2.171454, top_1: 0.705898, top_k: 0.887734, samples/s: 849.879 1613134923.1020474
train: epoch 110, iter 500, loss: 2.383620, top_1: 0.697344, top_k: 0.882930, samples/s: 844.414 1613134953.4188416
train: epoch 110, iter 600, loss: 2.236992, top_1: 0.701641, top_k: 0.881680, samples/s: 847.853 1613134983.61278
train: epoch 110, iter 700, loss: 2.228874, top_1: 0.702539, top_k: 0.886445, samples/s: 846.173 1613135013.8665915
train: epoch 110, iter 800, loss: 2.133526, top_1: 0.701523, top_k: 0.884258, samples/s: 845.690 1613135044.1377995
train: epoch 110, iter 900, loss: 2.290615, top_1: 0.702656, top_k: 0.885000, samples/s: 848.152 1613135074.3210483
train: epoch 110, iter 1000, loss: 2.253194, top_1: 0.703945, top_k: 0.882148, samples/s: 846.217 1613135104.5734076
train: epoch 110, iter 1100, loss: 2.171810, top_1: 0.700937, top_k: 0.884023, samples/s: 848.998 1613135134.7264988
train: epoch 110, iter 1200, loss: 2.288445, top_1: 0.703711, top_k: 0.884687, samples/s: 847.226 1613135164.9427888
train: epoch 110, iter 1300, loss: 2.236092, top_1: 0.698047, top_k: 0.881328, samples/s: 848.235 1613135195.1231337
train: epoch 110, iter 1400, loss: 2.136132, top_1: 0.701836, top_k: 0.883320, samples/s: 846.001 1613135225.3830981
train: epoch 110, iter 1500, loss: 2.211086, top_1: 0.702422, top_k: 0.881719, samples/s: 848.272 1613135255.5622098
train: epoch 110, iter 1600, loss: 2.345205, top_1: 0.696836, top_k: 0.880586, samples/s: 846.307 1613135285.8112707
train: epoch 110, iter 1700, loss: 2.443266, top_1: 0.703125, top_k: 0.882227, samples/s: 849.196 1613135315.957355
train: epoch 110, iter 1800, loss: 2.404325, top_1: 0.701133, top_k: 0.882578, samples/s: 846.664 1613135346.1937041
train: epoch 110, iter 1900, loss: 2.218810, top_1: 0.696680, top_k: 0.879727, samples/s: 847.575 1613135376.3974924
train: epoch 110, iter 2000, loss: 2.207212, top_1: 0.698867, top_k: 0.884609, samples/s: 847.637 1613135406.5991027
train: epoch 110, iter 2100, loss: 2.176042, top_1: 0.700742, top_k: 0.880664, samples/s: 849.739 1613135436.7259295
train: epoch 110, iter 2200, loss: 2.139107, top_1: 0.695625, top_k: 0.879141, samples/s: 847.363 1613135466.9373217
train: epoch 110, iter 2300, loss: 2.270291, top_1: 0.699180, top_k: 0.883750, samples/s: 849.805 1613135497.0618596
train: epoch 110, iter 2400, loss: 2.247126, top_1: 0.697305, top_k: 0.878555, samples/s: 848.160 1613135527.244864
train: epoch 110, iter 2500, loss: 2.180762, top_1: 0.702383, top_k: 0.881328, samples/s: 847.695 1613135557.4443634
train: epoch 110, iter 2600, loss: 2.229662, top_1: 0.691602, top_k: 0.878516, samples/s: 847.761 1613135587.641589
train: epoch 110, iter 2700, loss: 2.159599, top_1: 0.700937, top_k: 0.881719, samples/s: 849.203 1613135617.7874885
train: epoch 110, iter 2800, loss: 2.293788, top_1: 0.695391, top_k: 0.880313, samples/s: 846.510 1613135648.0293984
train: epoch 110, iter 2900, loss: 2.182634, top_1: 0.697109, top_k: 0.879883, samples/s: 849.895 1613135678.1506708
train: epoch 110, iter 3000, loss: 2.174571, top_1: 0.695430, top_k: 0.879180, samples/s: 845.048 1613135708.4448109
train: epoch 110, iter 3100, loss: 2.170784, top_1: 0.696289, top_k: 0.880078, samples/s: 848.790 1613135738.6054342
train: epoch 110, iter 3200, loss: 2.277381, top_1: 0.691328, top_k: 0.879570, samples/s: 845.086 1613135768.898188
train: epoch 110, iter 3300, loss: 2.344265, top_1: 0.696250, top_k: 0.878359, samples/s: 849.646 1613135799.0283594
train: epoch 110, iter 3400, loss: 2.133910, top_1: 0.696875, top_k: 0.878711, samples/s: 844.287 1613135829.3497646
train: epoch 110, iter 3500, loss: 2.387725, top_1: 0.694375, top_k: 0.878125, samples/s: 847.448 1613135859.5581775
train: epoch 110, iter 3600, loss: 2.150409, top_1: 0.694492, top_k: 0.881602, samples/s: 848.317 1613135889.7356026
train: epoch 110, iter 3700, loss: 2.267196, top_1: 0.695781, top_k: 0.879922, samples/s: 847.758 1613135919.9329004
train: epoch 110, iter 3800, loss: 2.318702, top_1: 0.697695, top_k: 0.882266, samples/s: 850.901 1613135950.0185454
train: epoch 110, iter 3900, loss: 2.320520, top_1: 0.693945, top_k: 0.878945, samples/s: 848.964 1613135980.1729615
train: epoch 110, iter 4000, loss: 2.218394, top_1: 0.689727, top_k: 0.877031, samples/s: 845.889 1613136010.437056
train: epoch 110, iter 4100, loss: 2.290600, top_1: 0.699336, top_k: 0.881445, samples/s: 845.909 1613136040.700364
train: epoch 110, iter 4200, loss: 2.197206, top_1: 0.694688, top_k: 0.879727, samples/s: 851.335 1613136070.7707257
train: epoch 110, iter 4300, loss: 2.146373, top_1: 0.695469, top_k: 0.880234, samples/s: 847.338 1613136100.9830506
train: epoch 110, iter 4400, loss: 2.252799, top_1: 0.696328, top_k: 0.881445, samples/s: 846.535 1613136131.2239237
train: epoch 110, iter 4500, loss: 2.170403, top_1: 0.697734, top_k: 0.880234, samples/s: 851.325 1613136161.2947571
train: epoch 110, iter 4600, loss: 2.257721, top_1: 0.699531, top_k: 0.880313, samples/s: 847.556 1613136191.4991925
train: epoch 110, iter 4700, loss: 2.143356, top_1: 0.694609, top_k: 0.878672, samples/s: 848.673 1613136221.663944
train: epoch 110, iter 4800, loss: 2.313375, top_1: 0.692695, top_k: 0.877305, samples/s: 848.182 1613136251.8461485
train: epoch 110, iter 4900, loss: 2.254379, top_1: 0.695469, top_k: 0.877422, samples/s: 843.744 1613136282.1870556
train: epoch 110, iter 5000, loss: 2.286139, top_1: 0.700508, top_k: 0.879687, samples/s: 850.788 1613136312.2768278
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_110.
validation: epoch 110, iter 195, top_1: 0.722416, top_k: 0.911358, samples/s: 2454.343 1613136333.5274355
train: epoch 111, iter 100, loss: 2.185642, top_1: 0.705313, top_k: 0.884453, samples/s: 867.856 1613136383.5323753
train: epoch 111, iter 200, loss: 2.166789, top_1: 0.709766, top_k: 0.889648, samples/s: 868.315 1613136413.0146961
train: epoch 111, iter 300, loss: 2.269889, top_1: 0.701367, top_k: 0.881953, samples/s: 853.421 1613136443.0116963
train: epoch 111, iter 400, loss: 2.239063, top_1: 0.701680, top_k: 0.883750, samples/s: 844.252 1613136473.3344016
train: epoch 111, iter 500, loss: 2.137781, top_1: 0.713594, top_k: 0.891563, samples/s: 847.866 1613136503.5277545
train: epoch 111, iter 600, loss: 2.187477, top_1: 0.700859, top_k: 0.883320, samples/s: 845.019 1613136533.8229866
train: epoch 111, iter 700, loss: 2.087642, top_1: 0.707852, top_k: 0.886797, samples/s: 849.020 1613136563.9754186
train: epoch 111, iter 800, loss: 2.338608, top_1: 0.705000, top_k: 0.886992, samples/s: 846.528 1613136594.2165823
train: epoch 111, iter 900, loss: 2.252371, top_1: 0.709141, top_k: 0.885703, samples/s: 844.798 1613136624.5196483
train: epoch 111, iter 1000, loss: 2.427166, top_1: 0.709492, top_k: 0.885938, samples/s: 847.590 1613136654.722924
train: epoch 111, iter 1100, loss: 2.219779, top_1: 0.706562, top_k: 0.884102, samples/s: 846.648 1613136684.9598973
train: epoch 111, iter 1200, loss: 2.151902, top_1: 0.701875, top_k: 0.885039, samples/s: 847.407 1613136715.1695886
train: epoch 111, iter 1300, loss: 2.144827, top_1: 0.706211, top_k: 0.883672, samples/s: 847.539 1613136745.3747237
train: epoch 111, iter 1400, loss: 2.374031, top_1: 0.701992, top_k: 0.880352, samples/s: 846.295 1613136775.6242993
train: epoch 111, iter 1500, loss: 2.398605, top_1: 0.707656, top_k: 0.885547, samples/s: 848.170 1613136805.8073728
train: epoch 111, iter 1600, loss: 2.244665, top_1: 0.702578, top_k: 0.883516, samples/s: 848.613 1613136835.9737175
train: epoch 111, iter 1700, loss: 2.337400, top_1: 0.703125, top_k: 0.880586, samples/s: 844.146 1613136866.3006113
train: epoch 111, iter 1800, loss: 2.087049, top_1: 0.703359, top_k: 0.884492, samples/s: 850.014 1613136896.4173937
train: epoch 111, iter 1900, loss: 2.106772, top_1: 0.705937, top_k: 0.881289, samples/s: 845.867 1613136926.682299
train: epoch 111, iter 2000, loss: 2.298365, top_1: 0.704570, top_k: 0.884375, samples/s: 846.461 1613136956.925835
train: epoch 111, iter 2100, loss: 2.286466, top_1: 0.703945, top_k: 0.884336, samples/s: 847.116 1613136987.1459348
train: epoch 111, iter 2200, loss: 2.252278, top_1: 0.697383, top_k: 0.881523, samples/s: 849.158 1613137017.2934818
train: epoch 111, iter 2300, loss: 2.220557, top_1: 0.699375, top_k: 0.879258, samples/s: 851.756 1613137047.3490288
train: epoch 111, iter 2400, loss: 2.031335, top_1: 0.701172, top_k: 0.882031, samples/s: 844.874 1613137077.6493444
train: epoch 111, iter 2500, loss: 2.190042, top_1: 0.699883, top_k: 0.883437, samples/s: 851.402 1613137107.7174342
train: epoch 111, iter 2600, loss: 2.354422, top_1: 0.699922, top_k: 0.880195, samples/s: 848.386 1613137137.8923862
train: epoch 111, iter 2700, loss: 2.228679, top_1: 0.700703, top_k: 0.881484, samples/s: 845.974 1613137168.1534386
train: epoch 111, iter 2800, loss: 2.133345, top_1: 0.701055, top_k: 0.880742, samples/s: 849.136 1613137198.301668
train: epoch 111, iter 2900, loss: 2.357073, top_1: 0.698398, top_k: 0.882734, samples/s: 843.655 1613137228.6458921
train: epoch 111, iter 3000, loss: 2.091151, top_1: 0.699883, top_k: 0.880898, samples/s: 848.007 1613137258.8343377
train: epoch 111, iter 3100, loss: 2.112756, top_1: 0.701055, top_k: 0.882266, samples/s: 848.752 1613137288.9961941
train: epoch 111, iter 3200, loss: 2.379095, top_1: 0.698086, top_k: 0.882539, samples/s: 848.224 1613137319.1768491
train: epoch 111, iter 3300, loss: 2.089616, top_1: 0.697461, top_k: 0.880352, samples/s: 846.251 1613137349.4279623
train: epoch 111, iter 3400, loss: 2.286095, top_1: 0.696953, top_k: 0.881289, samples/s: 846.160 1613137379.6822655
train: epoch 111, iter 3500, loss: 2.289422, top_1: 0.696406, top_k: 0.880078, samples/s: 850.487 1613137409.7826576
train: epoch 111, iter 3600, loss: 2.351941, top_1: 0.697305, top_k: 0.881406, samples/s: 847.894 1613137439.9751737
train: epoch 111, iter 3700, loss: 2.348791, top_1: 0.695547, top_k: 0.881836, samples/s: 849.033 1613137470.1270506
train: epoch 111, iter 3800, loss: 2.285633, top_1: 0.693906, top_k: 0.878789, samples/s: 845.865 1613137500.3919868
train: epoch 111, iter 3900, loss: 2.264055, top_1: 0.702070, top_k: 0.880313, samples/s: 846.193 1613137530.645133
train: epoch 111, iter 4000, loss: 2.319194, top_1: 0.699414, top_k: 0.878125, samples/s: 850.319 1613137560.7515106
train: epoch 111, iter 4100, loss: 2.295870, top_1: 0.690547, top_k: 0.875742, samples/s: 848.909 1613137590.9077961
train: epoch 111, iter 4200, loss: 2.170594, top_1: 0.691953, top_k: 0.880273, samples/s: 845.208 1613137621.1962028
train: epoch 111, iter 4300, loss: 2.375834, top_1: 0.698906, top_k: 0.880273, samples/s: 848.435 1613137651.3694391
train: epoch 111, iter 4400, loss: 2.255028, top_1: 0.701562, top_k: 0.883555, samples/s: 847.513 1613137681.5754137
train: epoch 111, iter 4500, loss: 2.250667, top_1: 0.696914, top_k: 0.881289, samples/s: 847.487 1613137711.782364
train: epoch 111, iter 4600, loss: 2.384186, top_1: 0.702344, top_k: 0.880859, samples/s: 847.961 1613137741.9724498
train: epoch 111, iter 4700, loss: 2.399339, top_1: 0.694492, top_k: 0.878594, samples/s: 846.458 1613137772.216069
train: epoch 111, iter 4800, loss: 2.410801, top_1: 0.698828, top_k: 0.880391, samples/s: 848.843 1613137802.3748326
train: epoch 111, iter 4900, loss: 2.353052, top_1: 0.700195, top_k: 0.879336, samples/s: 850.319 1613137832.4811497
train: epoch 111, iter 5000, loss: 2.169015, top_1: 0.699766, top_k: 0.883945, samples/s: 849.473 1613137862.617467
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_111.
validation: epoch 111, iter 195, top_1: 0.721615, top_k: 0.909976, samples/s: 2483.860 1613137883.6139278
train: epoch 112, iter 100, loss: 2.141346, top_1: 0.707070, top_k: 0.887266, samples/s: 874.407 1613137933.9999282
train: epoch 112, iter 200, loss: 2.356877, top_1: 0.696875, top_k: 0.881992, samples/s: 868.912 1613137963.4620426
train: epoch 112, iter 300, loss: 2.421035, top_1: 0.710820, top_k: 0.887578, samples/s: 851.801 1613137993.5160081
train: epoch 112, iter 400, loss: 2.287852, top_1: 0.709414, top_k: 0.885781, samples/s: 850.711 1613138023.6085436
train: epoch 112, iter 500, loss: 2.094312, top_1: 0.713594, top_k: 0.890625, samples/s: 845.677 1613138053.880055
train: epoch 112, iter 600, loss: 2.131189, top_1: 0.706211, top_k: 0.885586, samples/s: 846.671 1613138084.1161544
train: epoch 112, iter 700, loss: 2.298408, top_1: 0.711914, top_k: 0.887617, samples/s: 846.503 1613138114.3581986
train: epoch 112, iter 800, loss: 2.318016, top_1: 0.709570, top_k: 0.888672, samples/s: 847.766 1613138144.5552127
train: epoch 112, iter 900, loss: 2.149607, top_1: 0.709961, top_k: 0.889297, samples/s: 846.433 1613138174.7998624
train: epoch 112, iter 1000, loss: 2.337718, top_1: 0.706406, top_k: 0.885312, samples/s: 849.088 1613138204.9498348
train: epoch 112, iter 1100, loss: 2.296667, top_1: 0.703164, top_k: 0.884258, samples/s: 846.569 1613138235.1895576
train: epoch 112, iter 1200, loss: 2.174755, top_1: 0.706719, top_k: 0.885273, samples/s: 847.935 1613138265.3804889
train: epoch 112, iter 1300, loss: 2.196225, top_1: 0.708633, top_k: 0.886484, samples/s: 844.606 1613138295.6904664
train: epoch 112, iter 1400, loss: 2.276073, top_1: 0.704414, top_k: 0.885312, samples/s: 853.304 1613138325.6914847
train: epoch 112, iter 1500, loss: 2.265828, top_1: 0.705273, top_k: 0.886641, samples/s: 842.862 1613138356.064272
train: epoch 112, iter 1600, loss: 2.246921, top_1: 0.706016, top_k: 0.885430, samples/s: 849.378 1613138386.2039156
train: epoch 112, iter 1700, loss: 2.364134, top_1: 0.701289, top_k: 0.882070, samples/s: 847.462 1613138416.4117458
train: epoch 112, iter 1800, loss: 2.107135, top_1: 0.704609, top_k: 0.882891, samples/s: 847.968 1613138446.6016142
train: epoch 112, iter 1900, loss: 2.251018, top_1: 0.706758, top_k: 0.885312, samples/s: 846.437 1613138476.8460486
train: epoch 112, iter 2000, loss: 2.086593, top_1: 0.708086, top_k: 0.891211, samples/s: 846.499 1613138507.0882032
train: epoch 112, iter 2100, loss: 2.203171, top_1: 0.704688, top_k: 0.880117, samples/s: 849.597 1613138537.2201533
train: epoch 112, iter 2200, loss: 2.262343, top_1: 0.706914, top_k: 0.886016, samples/s: 846.499 1613138567.4623625
train: epoch 112, iter 2300, loss: 2.194140, top_1: 0.702461, top_k: 0.885469, samples/s: 848.172 1613138597.644965
train: epoch 112, iter 2400, loss: 2.381503, top_1: 0.702656, top_k: 0.884687, samples/s: 850.056 1613138627.7606447
train: epoch 112, iter 2500, loss: 2.248823, top_1: 0.706523, top_k: 0.886133, samples/s: 848.222 1613138657.9414263
train: epoch 112, iter 2600, loss: 2.238495, top_1: 0.699414, top_k: 0.883242, samples/s: 848.417 1613138688.1153042
train: epoch 112, iter 2700, loss: 2.320828, top_1: 0.704180, top_k: 0.884180, samples/s: 845.931 1613138718.377717
train: epoch 112, iter 2800, loss: 2.271551, top_1: 0.706094, top_k: 0.885156, samples/s: 848.264 1613138748.5570438
train: epoch 112, iter 2900, loss: 2.273182, top_1: 0.704297, top_k: 0.885078, samples/s: 847.991 1613138778.7459965
train: epoch 112, iter 3000, loss: 2.195176, top_1: 0.702500, top_k: 0.885820, samples/s: 848.623 1613138808.9124923
train: epoch 112, iter 3100, loss: 2.227399, top_1: 0.702305, top_k: 0.883750, samples/s: 845.788 1613138839.1801546
train: epoch 112, iter 3200, loss: 2.355653, top_1: 0.701289, top_k: 0.886602, samples/s: 844.873 1613138869.480563
train: epoch 112, iter 3300, loss: 2.216048, top_1: 0.702266, top_k: 0.879023, samples/s: 848.192 1613138899.6624913
train: epoch 112, iter 3400, loss: 2.216457, top_1: 0.702852, top_k: 0.882734, samples/s: 846.863 1613138929.8917112
train: epoch 112, iter 3500, loss: 2.373869, top_1: 0.702852, top_k: 0.885312, samples/s: 845.387 1613138960.173651
train: epoch 112, iter 3600, loss: 2.263611, top_1: 0.697969, top_k: 0.880898, samples/s: 847.508 1613138990.3799675
train: epoch 112, iter 3700, loss: 2.146814, top_1: 0.698711, top_k: 0.881484, samples/s: 845.240 1613139020.6670957
train: epoch 112, iter 3800, loss: 2.127075, top_1: 0.698750, top_k: 0.881992, samples/s: 852.217 1613139050.7063158
train: epoch 112, iter 3900, loss: 2.295389, top_1: 0.693164, top_k: 0.877344, samples/s: 841.182 1613139081.139718
train: epoch 112, iter 4000, loss: 2.254102, top_1: 0.705352, top_k: 0.885508, samples/s: 855.496 1613139111.0638845
train: epoch 112, iter 4100, loss: 2.109032, top_1: 0.702461, top_k: 0.883633, samples/s: 847.588 1613139141.2672524
train: epoch 112, iter 4200, loss: 2.186476, top_1: 0.692148, top_k: 0.879219, samples/s: 848.680 1613139171.431741
train: epoch 112, iter 4300, loss: 2.343744, top_1: 0.702500, top_k: 0.882461, samples/s: 845.661 1613139201.7040014
train: epoch 112, iter 4400, loss: 2.174294, top_1: 0.698242, top_k: 0.881836, samples/s: 845.092 1613139231.9964736
train: epoch 112, iter 4500, loss: 2.241957, top_1: 0.696797, top_k: 0.879766, samples/s: 845.886 1613139262.2605991
train: epoch 112, iter 4600, loss: 2.077578, top_1: 0.700078, top_k: 0.879687, samples/s: 848.399 1613139292.4351106
train: epoch 112, iter 4700, loss: 2.394922, top_1: 0.701328, top_k: 0.882930, samples/s: 849.834 1613139322.5586405
train: epoch 112, iter 4800, loss: 2.165345, top_1: 0.703320, top_k: 0.882227, samples/s: 847.407 1613139352.7685328
train: epoch 112, iter 4900, loss: 2.150543, top_1: 0.692344, top_k: 0.878047, samples/s: 847.523 1613139382.974072
train: epoch 112, iter 5000, loss: 2.365870, top_1: 0.704258, top_k: 0.885156, samples/s: 850.430 1613139413.0764842
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_112.
validation: epoch 112, iter 195, top_1: 0.728365, top_k: 0.914283, samples/s: 2460.004 1613139434.2676878
train: epoch 113, iter 100, loss: 2.141299, top_1: 0.713125, top_k: 0.889102, samples/s: 872.155 1613139484.682693
train: epoch 113, iter 200, loss: 2.094622, top_1: 0.717695, top_k: 0.892109, samples/s: 868.300 1613139514.1654613
train: epoch 113, iter 300, loss: 2.215718, top_1: 0.720273, top_k: 0.893437, samples/s: 851.482 1613139544.2307262
train: epoch 113, iter 400, loss: 2.131908, top_1: 0.711016, top_k: 0.889336, samples/s: 846.559 1613139574.4707258
train: epoch 113, iter 500, loss: 2.322847, top_1: 0.715313, top_k: 0.890391, samples/s: 846.880 1613139604.6993587
train: epoch 113, iter 600, loss: 2.056304, top_1: 0.710820, top_k: 0.888672, samples/s: 846.306 1613139634.9485147
train: epoch 113, iter 700, loss: 2.244542, top_1: 0.712891, top_k: 0.890195, samples/s: 848.865 1613139665.1063488
train: epoch 113, iter 800, loss: 2.180502, top_1: 0.718906, top_k: 0.891641, samples/s: 844.419 1613139695.4230583
train: epoch 113, iter 900, loss: 2.199984, top_1: 0.714258, top_k: 0.891016, samples/s: 847.821 1613139725.6182263
train: epoch 113, iter 1000, loss: 2.118333, top_1: 0.710820, top_k: 0.887266, samples/s: 848.667 1613139755.7830396
train: epoch 113, iter 1100, loss: 2.104093, top_1: 0.705430, top_k: 0.886445, samples/s: 845.308 1613139786.067941
train: epoch 113, iter 1200, loss: 2.144453, top_1: 0.707891, top_k: 0.888242, samples/s: 849.249 1613139816.212118
train: epoch 113, iter 1300, loss: 2.158064, top_1: 0.708867, top_k: 0.887148, samples/s: 846.038 1613139846.4708462
train: epoch 113, iter 1400, loss: 2.252371, top_1: 0.710625, top_k: 0.889766, samples/s: 847.379 1613139876.68162
train: epoch 113, iter 1500, loss: 2.182414, top_1: 0.703828, top_k: 0.884766, samples/s: 848.817 1613139906.841293
train: epoch 113, iter 1600, loss: 2.201339, top_1: 0.703555, top_k: 0.883867, samples/s: 848.250 1613139937.0210268
train: epoch 113, iter 1700, loss: 2.201770, top_1: 0.702266, top_k: 0.886797, samples/s: 846.486 1613139967.2637622
train: epoch 113, iter 1800, loss: 2.225094, top_1: 0.707422, top_k: 0.885586, samples/s: 850.692 1613139997.356956
train: epoch 113, iter 1900, loss: 2.479078, top_1: 0.704883, top_k: 0.884609, samples/s: 847.572 1613140027.5608451
train: epoch 113, iter 2000, loss: 2.100157, top_1: 0.705352, top_k: 0.887578, samples/s: 847.787 1613140057.7571614
train: epoch 113, iter 2100, loss: 2.179347, top_1: 0.701914, top_k: 0.883711, samples/s: 849.502 1613140087.8924277
train: epoch 113, iter 2200, loss: 2.278899, top_1: 0.703086, top_k: 0.883672, samples/s: 845.946 1613140118.1543698
train: epoch 113, iter 2300, loss: 2.327308, top_1: 0.708086, top_k: 0.888203, samples/s: 847.477 1613140148.361645
train: epoch 113, iter 2400, loss: 2.271705, top_1: 0.705000, top_k: 0.883672, samples/s: 850.397 1613140178.4652977
train: epoch 113, iter 2500, loss: 2.210208, top_1: 0.702266, top_k: 0.883047, samples/s: 847.671 1613140208.6657515
train: epoch 113, iter 2600, loss: 2.104544, top_1: 0.704453, top_k: 0.884883, samples/s: 851.326 1613140238.7364507
train: epoch 113, iter 2700, loss: 2.165140, top_1: 0.709180, top_k: 0.884375, samples/s: 846.361 1613140268.983904
train: epoch 113, iter 2800, loss: 2.044050, top_1: 0.700195, top_k: 0.882344, samples/s: 847.545 1613140299.1884654
train: epoch 113, iter 2900, loss: 2.237115, top_1: 0.704883, top_k: 0.885859, samples/s: 847.296 1613140329.402568
train: epoch 113, iter 3000, loss: 2.381476, top_1: 0.699805, top_k: 0.879062, samples/s: 850.145 1613140359.5146952
train: epoch 113, iter 3100, loss: 2.275780, top_1: 0.706484, top_k: 0.887852, samples/s: 849.189 1613140389.661194
train: epoch 113, iter 3200, loss: 2.288010, top_1: 0.702109, top_k: 0.881367, samples/s: 848.298 1613140419.8393044
train: epoch 113, iter 3300, loss: 2.179578, top_1: 0.701680, top_k: 0.881367, samples/s: 845.664 1613140450.1112604
train: epoch 113, iter 3400, loss: 2.322640, top_1: 0.703867, top_k: 0.884727, samples/s: 849.125 1613140480.2599177
train: epoch 113, iter 3500, loss: 2.320021, top_1: 0.706289, top_k: 0.885430, samples/s: 847.114 1613140510.480215
train: epoch 113, iter 3600, loss: 2.359886, top_1: 0.704258, top_k: 0.884805, samples/s: 848.867 1613140540.6380641
train: epoch 113, iter 3700, loss: 2.101368, top_1: 0.709883, top_k: 0.888320, samples/s: 846.522 1613140570.8795013
train: epoch 113, iter 3800, loss: 2.139557, top_1: 0.705469, top_k: 0.886719, samples/s: 849.644 1613140601.0096612
train: epoch 113, iter 3900, loss: 2.232413, top_1: 0.699180, top_k: 0.882227, samples/s: 848.467 1613140631.1818297
train: epoch 113, iter 4000, loss: 2.229724, top_1: 0.704688, top_k: 0.883867, samples/s: 844.601 1613140661.4919775
train: epoch 113, iter 4100, loss: 2.193754, top_1: 0.698203, top_k: 0.880586, samples/s: 846.447 1613140691.7360692
train: epoch 113, iter 4200, loss: 2.153639, top_1: 0.704180, top_k: 0.885000, samples/s: 847.556 1613140721.940544
train: epoch 113, iter 4300, loss: 2.168166, top_1: 0.701680, top_k: 0.881914, samples/s: 844.952 1613140752.2380493
train: epoch 113, iter 4400, loss: 2.149083, top_1: 0.705273, top_k: 0.885703, samples/s: 847.664 1613140782.438676
train: epoch 113, iter 4500, loss: 2.211044, top_1: 0.698516, top_k: 0.881211, samples/s: 846.494 1613140812.6811585
train: epoch 113, iter 4600, loss: 2.255025, top_1: 0.704648, top_k: 0.883437, samples/s: 850.175 1613140842.792547
train: epoch 113, iter 4700, loss: 2.169314, top_1: 0.705000, top_k: 0.883906, samples/s: 845.778 1613140873.0606022
train: epoch 113, iter 4800, loss: 2.045126, top_1: 0.706992, top_k: 0.885820, samples/s: 846.731 1613140903.2945986
train: epoch 113, iter 4900, loss: 2.292362, top_1: 0.703867, top_k: 0.884102, samples/s: 848.311 1613140933.4721065
train: epoch 113, iter 5000, loss: 2.297083, top_1: 0.711719, top_k: 0.886953, samples/s: 848.217 1613140963.6530354
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_113.
validation: epoch 113, iter 195, top_1: 0.729908, top_k: 0.913842, samples/s: 2484.038 1613140984.6504767
train: epoch 114, iter 100, loss: 2.285965, top_1: 0.707812, top_k: 0.886563, samples/s: 872.112 1613141034.9094217
train: epoch 114, iter 200, loss: 1.963362, top_1: 0.713242, top_k: 0.890898, samples/s: 866.976 1613141064.4372506
train: epoch 114, iter 300, loss: 2.049498, top_1: 0.717266, top_k: 0.891875, samples/s: 851.951 1613141094.4858549
train: epoch 114, iter 400, loss: 2.127390, top_1: 0.707891, top_k: 0.887852, samples/s: 848.264 1613141124.6652172
train: epoch 114, iter 500, loss: 2.200449, top_1: 0.713750, top_k: 0.890273, samples/s: 845.494 1613141154.9434223
train: epoch 114, iter 600, loss: 2.145313, top_1: 0.713437, top_k: 0.888672, samples/s: 847.214 1613141185.160038
train: epoch 114, iter 700, loss: 2.095611, top_1: 0.708945, top_k: 0.885703, samples/s: 846.908 1613141215.387609
train: epoch 114, iter 800, loss: 2.147357, top_1: 0.713359, top_k: 0.888984, samples/s: 845.502 1613141245.6654642
train: epoch 114, iter 900, loss: 2.273349, top_1: 0.712148, top_k: 0.888359, samples/s: 845.908 1613141275.9288745
train: epoch 114, iter 1000, loss: 2.291503, top_1: 0.714102, top_k: 0.887891, samples/s: 848.466 1613141306.1009815
train: epoch 114, iter 1100, loss: 2.215054, top_1: 0.714531, top_k: 0.886797, samples/s: 843.936 1613141336.4349701
train: epoch 114, iter 1200, loss: 2.262184, top_1: 0.708906, top_k: 0.889727, samples/s: 847.319 1613141366.64792
train: epoch 114, iter 1300, loss: 2.329834, top_1: 0.706367, top_k: 0.885664, samples/s: 846.031 1613141396.9068813
train: epoch 114, iter 1400, loss: 2.150279, top_1: 0.717031, top_k: 0.892344, samples/s: 848.368 1613141427.0823808
train: epoch 114, iter 1500, loss: 2.021127, top_1: 0.711328, top_k: 0.888203, samples/s: 846.467 1613141457.3257537
train: epoch 114, iter 1600, loss: 2.244844, top_1: 0.706523, top_k: 0.888867, samples/s: 847.168 1613141487.5441318
train: epoch 114, iter 1700, loss: 2.183032, top_1: 0.710234, top_k: 0.889687, samples/s: 850.405 1613141517.647465
train: epoch 114, iter 1800, loss: 2.207354, top_1: 0.708594, top_k: 0.888047, samples/s: 845.546 1613141547.9237518
train: epoch 114, iter 1900, loss: 2.391680, top_1: 0.704375, top_k: 0.883945, samples/s: 848.933 1613141578.079199
train: epoch 114, iter 2000, loss: 2.104249, top_1: 0.710703, top_k: 0.885781, samples/s: 847.488 1613141608.2861085
train: epoch 114, iter 2100, loss: 2.212766, top_1: 0.706758, top_k: 0.888594, samples/s: 850.134 1613141638.3989584
train: epoch 114, iter 2200, loss: 2.390097, top_1: 0.710820, top_k: 0.885273, samples/s: 847.684 1613141668.5989888
train: epoch 114, iter 2300, loss: 2.359069, top_1: 0.699023, top_k: 0.884687, samples/s: 848.533 1613141698.768735
train: epoch 114, iter 2400, loss: 2.197407, top_1: 0.712227, top_k: 0.887695, samples/s: 849.478 1613141728.9048746
train: epoch 114, iter 2500, loss: 2.217539, top_1: 0.712227, top_k: 0.887773, samples/s: 848.023 1613141759.0926828
train: epoch 114, iter 2600, loss: 2.268838, top_1: 0.709336, top_k: 0.884922, samples/s: 846.641 1613141789.3298414
train: epoch 114, iter 2700, loss: 2.174507, top_1: 0.707383, top_k: 0.883711, samples/s: 849.903 1613141819.4509017
train: epoch 114, iter 2800, loss: 2.121857, top_1: 0.711289, top_k: 0.883164, samples/s: 848.945 1613141849.6059337
train: epoch 114, iter 2900, loss: 2.308206, top_1: 0.705625, top_k: 0.884687, samples/s: 847.700 1613141879.8052979
train: epoch 114, iter 3000, loss: 2.097488, top_1: 0.706172, top_k: 0.886953, samples/s: 848.026 1613141909.9930904
train: epoch 114, iter 3100, loss: 2.179340, top_1: 0.711680, top_k: 0.886797, samples/s: 847.705 1613141940.1923044
train: epoch 114, iter 3200, loss: 2.077422, top_1: 0.711094, top_k: 0.885352, samples/s: 848.880 1613141970.3497088
train: epoch 114, iter 3300, loss: 2.230256, top_1: 0.703828, top_k: 0.886055, samples/s: 847.010 1613142000.5735857
train: epoch 114, iter 3400, loss: 2.150903, top_1: 0.706641, top_k: 0.888594, samples/s: 848.287 1613142030.7520814
train: epoch 114, iter 3500, loss: 2.242353, top_1: 0.703945, top_k: 0.883242, samples/s: 847.989 1613142060.9412036
train: epoch 114, iter 3600, loss: 2.131697, top_1: 0.710117, top_k: 0.887695, samples/s: 848.823 1613142091.1006162
train: epoch 114, iter 3700, loss: 2.181664, top_1: 0.705664, top_k: 0.885938, samples/s: 848.269 1613142121.2796867
train: epoch 114, iter 3800, loss: 2.186908, top_1: 0.708438, top_k: 0.886133, samples/s: 843.589 1613142151.6263165
train: epoch 114, iter 3900, loss: 2.014791, top_1: 0.701953, top_k: 0.884648, samples/s: 848.172 1613142181.8088105
train: epoch 114, iter 4000, loss: 2.156847, top_1: 0.702422, top_k: 0.884141, samples/s: 847.112 1613142212.0291805
train: epoch 114, iter 4100, loss: 2.178018, top_1: 0.700937, top_k: 0.882070, samples/s: 847.874 1613142242.2222648
train: epoch 114, iter 4200, loss: 2.120662, top_1: 0.700937, top_k: 0.885391, samples/s: 849.927 1613142272.3425543
train: epoch 114, iter 4300, loss: 2.180318, top_1: 0.704180, top_k: 0.888594, samples/s: 844.884 1613142302.6425576
train: epoch 114, iter 4400, loss: 2.256440, top_1: 0.703008, top_k: 0.882578, samples/s: 847.511 1613142332.8486369
train: epoch 114, iter 4500, loss: 2.227535, top_1: 0.709648, top_k: 0.887188, samples/s: 846.287 1613142363.0984168
train: epoch 114, iter 4600, loss: 2.194762, top_1: 0.708984, top_k: 0.886016, samples/s: 848.812 1613142393.2582705
train: epoch 114, iter 4700, loss: 2.172498, top_1: 0.706719, top_k: 0.884297, samples/s: 847.972 1613142423.4479432
train: epoch 114, iter 4800, loss: 2.191526, top_1: 0.708398, top_k: 0.885781, samples/s: 847.606 1613142453.6506004
train: epoch 114, iter 4900, loss: 2.150628, top_1: 0.704648, top_k: 0.886016, samples/s: 849.765 1613142483.7766776
train: epoch 114, iter 5000, loss: 2.245144, top_1: 0.712734, top_k: 0.887813, samples/s: 845.533 1613142514.0533235
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_114.
validation: epoch 114, iter 195, top_1: 0.726442, top_k: 0.912780, samples/s: 2445.680 1613142535.3656795
train: epoch 115, iter 100, loss: 2.339052, top_1: 0.715781, top_k: 0.890508, samples/s: 870.537 1613142585.3991227
train: epoch 115, iter 200, loss: 2.187342, top_1: 0.722930, top_k: 0.891445, samples/s: 868.052 1613142614.8903918
train: epoch 115, iter 300, loss: 2.007554, top_1: 0.716289, top_k: 0.889102, samples/s: 849.404 1613142645.0291553
train: epoch 115, iter 400, loss: 2.202305, top_1: 0.718477, top_k: 0.893164, samples/s: 845.505 1613142675.3068793
train: epoch 115, iter 500, loss: 2.036473, top_1: 0.723203, top_k: 0.891289, samples/s: 847.831 1613142705.5015635
train: epoch 115, iter 600, loss: 2.130460, top_1: 0.715117, top_k: 0.891211, samples/s: 844.182 1613142735.8268242
train: epoch 115, iter 700, loss: 2.007367, top_1: 0.713711, top_k: 0.888789, samples/s: 846.304 1613142766.0759745
train: epoch 115, iter 800, loss: 2.143118, top_1: 0.717031, top_k: 0.891172, samples/s: 845.536 1613142796.3526444
train: epoch 115, iter 900, loss: 2.292551, top_1: 0.716562, top_k: 0.889961, samples/s: 843.416 1613142826.7053711
train: epoch 115, iter 1000, loss: 2.232758, top_1: 0.712305, top_k: 0.890391, samples/s: 848.917 1613142856.8615386
train: epoch 115, iter 1100, loss: 2.230865, top_1: 0.715859, top_k: 0.888437, samples/s: 847.066 1613142887.0833871
train: epoch 115, iter 1200, loss: 2.069775, top_1: 0.714688, top_k: 0.889922, samples/s: 844.792 1613142917.3866997
train: epoch 115, iter 1300, loss: 2.107418, top_1: 0.713594, top_k: 0.893359, samples/s: 849.488 1613142947.5225537
train: epoch 115, iter 1400, loss: 2.173732, top_1: 0.717617, top_k: 0.888633, samples/s: 848.085 1613142977.7082667
train: epoch 115, iter 1500, loss: 2.281525, top_1: 0.709648, top_k: 0.886602, samples/s: 847.177 1613143007.9262364
train: epoch 115, iter 1600, loss: 2.310569, top_1: 0.708867, top_k: 0.891055, samples/s: 846.798 1613143038.1576722
train: epoch 115, iter 1700, loss: 2.155552, top_1: 0.711797, top_k: 0.890234, samples/s: 847.769 1613143068.3546996
train: epoch 115, iter 1800, loss: 2.094903, top_1: 0.715117, top_k: 0.889570, samples/s: 845.610 1613143098.628591
train: epoch 115, iter 1900, loss: 2.313258, top_1: 0.711602, top_k: 0.887852, samples/s: 850.198 1613143128.7392695
train: epoch 115, iter 2000, loss: 1.997689, top_1: 0.711758, top_k: 0.888281, samples/s: 847.431 1613143158.9482646
train: epoch 115, iter 2100, loss: 2.174294, top_1: 0.712695, top_k: 0.887422, samples/s: 849.654 1613143189.0781236
train: epoch 115, iter 2200, loss: 2.337236, top_1: 0.713242, top_k: 0.888516, samples/s: 847.432 1613143219.2870095
train: epoch 115, iter 2300, loss: 2.154217, top_1: 0.717891, top_k: 0.891172, samples/s: 847.208 1613143249.504025
train: epoch 115, iter 2400, loss: 2.069136, top_1: 0.714375, top_k: 0.889297, samples/s: 845.690 1613143279.7751215
train: epoch 115, iter 2500, loss: 2.212407, top_1: 0.712891, top_k: 0.889922, samples/s: 848.897 1613143309.9318495
train: epoch 115, iter 2600, loss: 2.497368, top_1: 0.705352, top_k: 0.885703, samples/s: 848.649 1613143340.097559
train: epoch 115, iter 2700, loss: 2.173742, top_1: 0.713437, top_k: 0.888047, samples/s: 850.591 1613143370.1941497
train: epoch 115, iter 2800, loss: 2.278175, top_1: 0.712461, top_k: 0.887031, samples/s: 848.234 1613143400.3745055
train: epoch 115, iter 2900, loss: 2.001193, top_1: 0.719023, top_k: 0.890469, samples/s: 849.188 1613143430.5210168
train: epoch 115, iter 3000, loss: 2.234480, top_1: 0.714727, top_k: 0.892578, samples/s: 851.050 1613143460.6015542
train: epoch 115, iter 3100, loss: 2.154667, top_1: 0.711406, top_k: 0.889297, samples/s: 847.041 1613143490.8243868
train: epoch 115, iter 3200, loss: 2.279458, top_1: 0.711758, top_k: 0.888047, samples/s: 849.438 1613143520.9618583
train: epoch 115, iter 3300, loss: 2.237867, top_1: 0.708594, top_k: 0.889844, samples/s: 850.447 1613143551.0637238
train: epoch 115, iter 3400, loss: 2.030040, top_1: 0.707070, top_k: 0.887266, samples/s: 847.088 1613143581.2849662
train: epoch 115, iter 3500, loss: 2.178610, top_1: 0.709102, top_k: 0.887461, samples/s: 847.637 1613143611.4865272
train: epoch 115, iter 3600, loss: 2.297153, top_1: 0.713437, top_k: 0.888242, samples/s: 846.362 1613143641.7335892
train: epoch 115, iter 3700, loss: 2.227752, top_1: 0.710195, top_k: 0.886602, samples/s: 847.541 1613143671.9387093
train: epoch 115, iter 3800, loss: 2.177986, top_1: 0.709766, top_k: 0.887109, samples/s: 849.403 1613143702.0774827
train: epoch 115, iter 3900, loss: 2.077824, top_1: 0.709180, top_k: 0.886328, samples/s: 847.450 1613143732.285699
train: epoch 115, iter 4000, loss: 2.356256, top_1: 0.705547, top_k: 0.889375, samples/s: 849.019 1613143762.438276
train: epoch 115, iter 4100, loss: 2.189781, top_1: 0.707852, top_k: 0.890156, samples/s: 849.842 1613143792.5614939
train: epoch 115, iter 4200, loss: 2.052557, top_1: 0.708086, top_k: 0.887773, samples/s: 848.025 1613143822.7492704
train: epoch 115, iter 4300, loss: 2.148270, top_1: 0.701914, top_k: 0.880156, samples/s: 848.535 1613143852.9188883
train: epoch 115, iter 4400, loss: 2.193875, top_1: 0.712852, top_k: 0.884961, samples/s: 847.275 1613143883.1334655
train: epoch 115, iter 4500, loss: 2.171191, top_1: 0.707500, top_k: 0.886523, samples/s: 847.263 1613143913.3483267
train: epoch 115, iter 4600, loss: 2.167835, top_1: 0.704102, top_k: 0.885273, samples/s: 849.875 1613143943.4703984
train: epoch 115, iter 4700, loss: 2.246379, top_1: 0.706445, top_k: 0.885664, samples/s: 845.258 1613143973.757056
train: epoch 115, iter 4800, loss: 2.232796, top_1: 0.708672, top_k: 0.886367, samples/s: 850.262 1613144003.8653321
train: epoch 115, iter 4900, loss: 2.301066, top_1: 0.703359, top_k: 0.885781, samples/s: 845.903 1613144034.1289277
train: epoch 115, iter 5000, loss: 2.090950, top_1: 0.714375, top_k: 0.892813, samples/s: 848.680 1613144064.2933748
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_115.
validation: epoch 115, iter 195, top_1: 0.731170, top_k: 0.916887, samples/s: 2469.200 1613144085.4260185
train: epoch 116, iter 100, loss: 2.006527, top_1: 0.729688, top_k: 0.896914, samples/s: 870.404 1613144135.432965
train: epoch 116, iter 200, loss: 2.202695, top_1: 0.726055, top_k: 0.894766, samples/s: 867.649 1613144164.937889
train: epoch 116, iter 300, loss: 2.138991, top_1: 0.718906, top_k: 0.894687, samples/s: 853.108 1613144194.9458659
train: epoch 116, iter 400, loss: 2.127072, top_1: 0.720117, top_k: 0.891797, samples/s: 847.367 1613144225.157076
train: epoch 116, iter 500, loss: 2.100440, top_1: 0.726172, top_k: 0.894141, samples/s: 845.389 1613144255.4389539
train: epoch 116, iter 600, loss: 2.068709, top_1: 0.720742, top_k: 0.890391, samples/s: 845.395 1613144285.7206862
train: epoch 116, iter 700, loss: 2.190781, top_1: 0.720898, top_k: 0.894453, samples/s: 846.970 1613144315.946125
train: epoch 116, iter 800, loss: 2.325148, top_1: 0.710352, top_k: 0.889141, samples/s: 846.118 1613144346.2019598
train: epoch 116, iter 900, loss: 2.228075, top_1: 0.717070, top_k: 0.893047, samples/s: 844.351 1613144376.5210195
train: epoch 116, iter 1000, loss: 2.093727, top_1: 0.719375, top_k: 0.894414, samples/s: 848.180 1613144406.7037082
train: epoch 116, iter 1100, loss: 2.175899, top_1: 0.714453, top_k: 0.888789, samples/s: 847.130 1613144436.9230552
train: epoch 116, iter 1200, loss: 2.093858, top_1: 0.719180, top_k: 0.894102, samples/s: 848.771 1613144467.0848582
train: epoch 116, iter 1300, loss: 2.112814, top_1: 0.719297, top_k: 0.892578, samples/s: 845.222 1613144497.3721526
train: epoch 116, iter 1400, loss: 2.246901, top_1: 0.714961, top_k: 0.890391, samples/s: 848.726 1613144527.5349855
train: epoch 116, iter 1500, loss: 2.114259, top_1: 0.715664, top_k: 0.890547, samples/s: 847.551 1613144557.739764
train: epoch 116, iter 1600, loss: 2.357409, top_1: 0.714063, top_k: 0.889961, samples/s: 843.985 1613144588.0720358
train: epoch 116, iter 1700, loss: 2.309592, top_1: 0.714492, top_k: 0.890859, samples/s: 848.123 1613144618.25632
train: epoch 116, iter 1800, loss: 2.199882, top_1: 0.711758, top_k: 0.886289, samples/s: 845.903 1613144648.5198734
train: epoch 116, iter 1900, loss: 2.048705, top_1: 0.713984, top_k: 0.890078, samples/s: 849.236 1613144678.6645806
train: epoch 116, iter 2000, loss: 2.177563, top_1: 0.718203, top_k: 0.891836, samples/s: 847.037 1613144708.887532
train: epoch 116, iter 2100, loss: 2.171733, top_1: 0.713633, top_k: 0.888828, samples/s: 847.882 1613144739.0805335
train: epoch 116, iter 2200, loss: 2.262797, top_1: 0.713828, top_k: 0.886836, samples/s: 850.934 1613144769.1650336
train: epoch 116, iter 2300, loss: 2.120225, top_1: 0.718945, top_k: 0.892891, samples/s: 845.156 1613144799.455257
train: epoch 116, iter 2400, loss: 2.137918, top_1: 0.710703, top_k: 0.888945, samples/s: 849.244 1613144829.5997853
train: epoch 116, iter 2500, loss: 2.142127, top_1: 0.714141, top_k: 0.889219, samples/s: 848.040 1613144859.7869503
train: epoch 116, iter 2600, loss: 2.211979, top_1: 0.711875, top_k: 0.888867, samples/s: 847.218 1613144890.0034952
train: epoch 116, iter 2700, loss: 2.112437, top_1: 0.714297, top_k: 0.890977, samples/s: 848.396 1613144920.1780949
train: epoch 116, iter 2800, loss: 1.986400, top_1: 0.716719, top_k: 0.892734, samples/s: 847.207 1613144950.395094
train: epoch 116, iter 2900, loss: 2.233532, top_1: 0.711953, top_k: 0.889258, samples/s: 848.180 1613144980.5773437
train: epoch 116, iter 3000, loss: 2.305941, top_1: 0.716016, top_k: 0.887813, samples/s: 848.120 1613145010.7616549
train: epoch 116, iter 3100, loss: 2.099383, top_1: 0.708984, top_k: 0.887656, samples/s: 847.675 1613145040.961932
train: epoch 116, iter 3200, loss: 2.037880, top_1: 0.719570, top_k: 0.893359, samples/s: 847.545 1613145071.166882
train: epoch 116, iter 3300, loss: 2.163911, top_1: 0.715430, top_k: 0.892070, samples/s: 847.556 1613145101.3713274
train: epoch 116, iter 3400, loss: 2.189274, top_1: 0.715547, top_k: 0.890625, samples/s: 847.929 1613145131.5625105
train: epoch 116, iter 3500, loss: 2.272862, top_1: 0.714766, top_k: 0.889805, samples/s: 847.212 1613145161.7792614
train: epoch 116, iter 3600, loss: 2.095958, top_1: 0.711016, top_k: 0.887422, samples/s: 848.911 1613145191.9356513
train: epoch 116, iter 3700, loss: 2.399034, top_1: 0.708594, top_k: 0.885820, samples/s: 847.042 1613145222.1583612
train: epoch 116, iter 3800, loss: 2.157958, top_1: 0.710625, top_k: 0.890117, samples/s: 848.242 1613145252.3384812
train: epoch 116, iter 3900, loss: 2.339911, top_1: 0.711133, top_k: 0.888867, samples/s: 846.230 1613145282.5903573
train: epoch 116, iter 4000, loss: 2.208355, top_1: 0.708477, top_k: 0.891602, samples/s: 847.448 1613145312.7985773
train: epoch 116, iter 4100, loss: 2.041179, top_1: 0.710430, top_k: 0.888320, samples/s: 846.121 1613145343.0543172
train: epoch 116, iter 4200, loss: 2.173647, top_1: 0.712148, top_k: 0.889531, samples/s: 848.642 1613145373.220223
train: epoch 116, iter 4300, loss: 2.206133, top_1: 0.712344, top_k: 0.889141, samples/s: 848.563 1613145403.388883
train: epoch 116, iter 4400, loss: 2.261597, top_1: 0.706602, top_k: 0.887188, samples/s: 844.717 1613145433.6948962
train: epoch 116, iter 4500, loss: 2.367179, top_1: 0.707969, top_k: 0.886953, samples/s: 851.391 1613145463.7632532
train: epoch 116, iter 4600, loss: 1.978967, top_1: 0.710234, top_k: 0.887344, samples/s: 846.948 1613145493.9894307
train: epoch 116, iter 4700, loss: 2.183912, top_1: 0.714922, top_k: 0.890000, samples/s: 848.558 1613145524.1583009
train: epoch 116, iter 4800, loss: 2.220871, top_1: 0.711055, top_k: 0.891563, samples/s: 846.454 1613145554.4022307
train: epoch 116, iter 4900, loss: 2.240029, top_1: 0.711055, top_k: 0.886484, samples/s: 846.820 1613145584.6328893
train: epoch 116, iter 5000, loss: 2.070986, top_1: 0.723203, top_k: 0.893984, samples/s: 846.815 1613145614.8638718
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_116.
validation: epoch 116, iter 195, top_1: 0.735497, top_k: 0.916727, samples/s: 2469.777 1613145635.9664717
train: epoch 117, iter 100, loss: 1.917017, top_1: 0.729648, top_k: 0.897539, samples/s: 871.544 1613145686.158925
train: epoch 117, iter 200, loss: 2.205603, top_1: 0.722617, top_k: 0.896797, samples/s: 867.513 1613145715.6685445
train: epoch 117, iter 300, loss: 2.182901, top_1: 0.725234, top_k: 0.893750, samples/s: 851.049 1613145745.7489908
train: epoch 117, iter 400, loss: 2.041243, top_1: 0.720625, top_k: 0.895625, samples/s: 848.239 1613145775.9292157
train: epoch 117, iter 500, loss: 2.209518, top_1: 0.718516, top_k: 0.891719, samples/s: 845.173 1613145806.218879
train: epoch 117, iter 600, loss: 2.074328, top_1: 0.720977, top_k: 0.893867, samples/s: 847.157 1613145836.4375675
train: epoch 117, iter 700, loss: 2.023287, top_1: 0.721562, top_k: 0.891406, samples/s: 846.451 1613145866.6814768
train: epoch 117, iter 800, loss: 2.049469, top_1: 0.721055, top_k: 0.891250, samples/s: 846.764 1613145896.9142864
train: epoch 117, iter 900, loss: 2.218191, top_1: 0.715547, top_k: 0.889648, samples/s: 846.036 1613145927.172979
train: epoch 117, iter 1000, loss: 2.107378, top_1: 0.715938, top_k: 0.893164, samples/s: 849.392 1613145957.3122525
train: epoch 117, iter 1100, loss: 2.221644, top_1: 0.719648, top_k: 0.895547, samples/s: 843.827 1613145987.650162
train: epoch 117, iter 1200, loss: 2.245646, top_1: 0.719805, top_k: 0.894883, samples/s: 849.096 1613146017.79984
train: epoch 117, iter 1300, loss: 2.388764, top_1: 0.718984, top_k: 0.895703, samples/s: 846.082 1613146048.0569634
train: epoch 117, iter 1400, loss: 2.174213, top_1: 0.714727, top_k: 0.891250, samples/s: 846.174 1613146078.3108404
train: epoch 117, iter 1500, loss: 2.196609, top_1: 0.725000, top_k: 0.894062, samples/s: 847.947 1613146108.5014405
train: epoch 117, iter 1600, loss: 2.134464, top_1: 0.720859, top_k: 0.891523, samples/s: 846.057 1613146138.7594864
train: epoch 117, iter 1700, loss: 2.124368, top_1: 0.720352, top_k: 0.892891, samples/s: 848.650 1613146168.9249697
train: epoch 117, iter 1800, loss: 2.095775, top_1: 0.718906, top_k: 0.895273, samples/s: 846.953 1613146199.1510026
train: epoch 117, iter 1900, loss: 2.189718, top_1: 0.718828, top_k: 0.894023, samples/s: 847.393 1613146229.3612833
train: epoch 117, iter 2000, loss: 2.249473, top_1: 0.716953, top_k: 0.891523, samples/s: 847.707 1613146259.5604374
train: epoch 117, iter 2100, loss: 2.053905, top_1: 0.722695, top_k: 0.894961, samples/s: 846.174 1613146289.814258
train: epoch 117, iter 2200, loss: 2.188816, top_1: 0.720469, top_k: 0.891953, samples/s: 846.663 1613146320.0505788
train: epoch 117, iter 2300, loss: 2.318466, top_1: 0.713164, top_k: 0.889219, samples/s: 849.346 1613146350.191399
train: epoch 117, iter 2400, loss: 2.074409, top_1: 0.716250, top_k: 0.891055, samples/s: 846.056 1613146380.449388
train: epoch 117, iter 2500, loss: 2.125131, top_1: 0.715742, top_k: 0.890742, samples/s: 851.385 1613146410.5180135
train: epoch 117, iter 2600, loss: 2.133662, top_1: 0.718789, top_k: 0.891914, samples/s: 843.354 1613146440.8731277
train: epoch 117, iter 2700, loss: 2.070211, top_1: 0.714063, top_k: 0.888594, samples/s: 848.162 1613146471.0560498
train: epoch 117, iter 2800, loss: 1.975166, top_1: 0.718320, top_k: 0.888555, samples/s: 848.713 1613146501.2193532
train: epoch 117, iter 2900, loss: 2.224627, top_1: 0.713320, top_k: 0.887656, samples/s: 847.250 1613146531.4347768
train: epoch 117, iter 3000, loss: 2.110765, top_1: 0.718281, top_k: 0.889883, samples/s: 847.433 1613146561.643597
train: epoch 117, iter 3100, loss: 2.082165, top_1: 0.719922, top_k: 0.895859, samples/s: 846.193 1613146591.8967495
train: epoch 117, iter 3200, loss: 2.152813, top_1: 0.720625, top_k: 0.896758, samples/s: 844.634 1613146622.2057803
train: epoch 117, iter 3300, loss: 2.102728, top_1: 0.714727, top_k: 0.889844, samples/s: 848.379 1613146652.3809278
train: epoch 117, iter 3400, loss: 2.216889, top_1: 0.720078, top_k: 0.893203, samples/s: 848.913 1613146682.5371218
train: epoch 117, iter 3500, loss: 2.081215, top_1: 0.714609, top_k: 0.891875, samples/s: 845.194 1613146712.8261044
train: epoch 117, iter 3600, loss: 2.147053, top_1: 0.713437, top_k: 0.893555, samples/s: 846.581 1613146743.0654209
train: epoch 117, iter 3700, loss: 2.197156, top_1: 0.713906, top_k: 0.890234, samples/s: 847.858 1613146773.2590716
train: epoch 117, iter 3800, loss: 2.162582, top_1: 0.718672, top_k: 0.892773, samples/s: 848.639 1613146803.425079
train: epoch 117, iter 3900, loss: 2.127254, top_1: 0.717109, top_k: 0.892969, samples/s: 847.500 1613146833.6315284
train: epoch 117, iter 4000, loss: 2.005624, top_1: 0.719688, top_k: 0.893086, samples/s: 845.444 1613146863.911456
train: epoch 117, iter 4100, loss: 2.118008, top_1: 0.719258, top_k: 0.891563, samples/s: 850.588 1613146894.0083432
train: epoch 117, iter 4200, loss: 2.095448, top_1: 0.712852, top_k: 0.890938, samples/s: 847.597 1613146924.2113595
train: epoch 117, iter 4300, loss: 2.177768, top_1: 0.713398, top_k: 0.889336, samples/s: 846.059 1613146954.4693778
train: epoch 117, iter 4400, loss: 2.220779, top_1: 0.710156, top_k: 0.884766, samples/s: 846.969 1613146984.6947632
train: epoch 117, iter 4500, loss: 2.232181, top_1: 0.711680, top_k: 0.885820, samples/s: 847.562 1613147014.898987
train: epoch 117, iter 4600, loss: 2.112275, top_1: 0.711445, top_k: 0.886445, samples/s: 848.388 1613147045.0738566
train: epoch 117, iter 4700, loss: 2.258830, top_1: 0.717461, top_k: 0.889883, samples/s: 847.453 1613147075.2820978
train: epoch 117, iter 4800, loss: 2.245565, top_1: 0.710977, top_k: 0.885273, samples/s: 847.913 1613147105.4738517
train: epoch 117, iter 4900, loss: 2.168549, top_1: 0.715469, top_k: 0.890586, samples/s: 846.064 1613147135.7315123
train: epoch 117, iter 5000, loss: 2.076982, top_1: 0.717773, top_k: 0.896641, samples/s: 850.572 1613147165.8289266
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_117.
validation: epoch 117, iter 195, top_1: 0.737981, top_k: 0.918550, samples/s: 2446.067 1613147187.1360219
train: epoch 118, iter 100, loss: 2.336999, top_1: 0.730000, top_k: 0.898320, samples/s: 872.008 1613147237.1164892
train: epoch 118, iter 200, loss: 2.168333, top_1: 0.721875, top_k: 0.894414, samples/s: 869.551 1613147266.5569742
train: epoch 118, iter 300, loss: 2.283659, top_1: 0.725547, top_k: 0.894062, samples/s: 849.369 1613147296.6969807
train: epoch 118, iter 400, loss: 1.988127, top_1: 0.726562, top_k: 0.896133, samples/s: 848.679 1613147326.8614693
train: epoch 118, iter 500, loss: 2.197387, top_1: 0.721211, top_k: 0.891523, samples/s: 848.421 1613147357.0352168
train: epoch 118, iter 600, loss: 2.081986, top_1: 0.728945, top_k: 0.897422, samples/s: 845.951 1613147387.297045
train: epoch 118, iter 700, loss: 2.020935, top_1: 0.723594, top_k: 0.895820, samples/s: 844.744 1613147417.6019812
train: epoch 118, iter 800, loss: 2.112181, top_1: 0.721719, top_k: 0.892813, samples/s: 848.982 1613147447.7557783
train: epoch 118, iter 900, loss: 2.192154, top_1: 0.726055, top_k: 0.894766, samples/s: 849.893 1613147477.8771744
train: epoch 118, iter 1000, loss: 2.143192, top_1: 0.723516, top_k: 0.895312, samples/s: 846.495 1613147508.1196012
train: epoch 118, iter 1100, loss: 2.067947, top_1: 0.722344, top_k: 0.893984, samples/s: 848.778 1613147538.280618
train: epoch 118, iter 1200, loss: 2.042493, top_1: 0.724414, top_k: 0.893437, samples/s: 843.469 1613147568.6314964
train: epoch 118, iter 1300, loss: 2.229028, top_1: 0.720898, top_k: 0.892930, samples/s: 848.253 1613147598.8111107
train: epoch 118, iter 1400, loss: 2.181149, top_1: 0.722891, top_k: 0.894219, samples/s: 849.701 1613147628.939415
train: epoch 118, iter 1500, loss: 2.113727, top_1: 0.719180, top_k: 0.893047, samples/s: 844.912 1613147659.2384462
train: epoch 118, iter 1600, loss: 2.208876, top_1: 0.722773, top_k: 0.893516, samples/s: 850.142 1613147689.3510437
train: epoch 118, iter 1700, loss: 2.034724, top_1: 0.721562, top_k: 0.895547, samples/s: 847.153 1613147719.5699108
train: epoch 118, iter 1800, loss: 2.087617, top_1: 0.722031, top_k: 0.895781, samples/s: 848.902 1613147749.7264626
train: epoch 118, iter 1900, loss: 2.204154, top_1: 0.721992, top_k: 0.895078, samples/s: 845.675 1613147779.9981742
train: epoch 118, iter 2000, loss: 2.115981, top_1: 0.723008, top_k: 0.895430, samples/s: 847.077 1613147810.2197459
train: epoch 118, iter 2100, loss: 2.212095, top_1: 0.720391, top_k: 0.894727, samples/s: 849.165 1613147840.3669615
train: epoch 118, iter 2200, loss: 1.991138, top_1: 0.719609, top_k: 0.892695, samples/s: 849.441 1613147870.5044212
train: epoch 118, iter 2300, loss: 2.163426, top_1: 0.722617, top_k: 0.894062, samples/s: 847.590 1613147900.7076995
train: epoch 118, iter 2400, loss: 2.071957, top_1: 0.723281, top_k: 0.895703, samples/s: 845.369 1613147930.9903693
train: epoch 118, iter 2500, loss: 2.119725, top_1: 0.724336, top_k: 0.892695, samples/s: 848.936 1613147961.1458178
train: epoch 118, iter 2600, loss: 2.142180, top_1: 0.724063, top_k: 0.894648, samples/s: 848.772 1613147991.307023
train: epoch 118, iter 2700, loss: 2.231688, top_1: 0.718398, top_k: 0.889961, samples/s: 845.092 1613148021.5995808
train: epoch 118, iter 2800, loss: 2.129118, top_1: 0.721484, top_k: 0.895117, samples/s: 850.116 1613148051.7131333
train: epoch 118, iter 2900, loss: 2.047453, top_1: 0.718828, top_k: 0.893281, samples/s: 847.421 1613148081.9224768
train: epoch 118, iter 3000, loss: 2.194520, top_1: 0.721211, top_k: 0.891719, samples/s: 849.669 1613148112.0518515
train: epoch 118, iter 3100, loss: 2.191652, top_1: 0.716445, top_k: 0.892305, samples/s: 845.940 1613148142.3140006
train: epoch 118, iter 3200, loss: 2.176805, top_1: 0.711328, top_k: 0.891484, samples/s: 848.045 1613148172.5010583
train: epoch 118, iter 3300, loss: 2.064227, top_1: 0.715781, top_k: 0.894141, samples/s: 846.084 1613148202.7580626
train: epoch 118, iter 3400, loss: 2.256500, top_1: 0.718437, top_k: 0.892031, samples/s: 847.836 1613148232.9527028
train: epoch 118, iter 3500, loss: 2.193475, top_1: 0.719961, top_k: 0.891836, samples/s: 850.637 1613148263.0477653
train: epoch 118, iter 3600, loss: 2.304492, top_1: 0.719805, top_k: 0.890234, samples/s: 847.651 1613148293.2488987
train: epoch 118, iter 3700, loss: 2.106288, top_1: 0.716484, top_k: 0.890078, samples/s: 850.835 1613148323.3369305
train: epoch 118, iter 3800, loss: 2.188728, top_1: 0.722227, top_k: 0.895898, samples/s: 846.852 1613148353.5665464
train: epoch 118, iter 3900, loss: 2.142747, top_1: 0.717227, top_k: 0.892734, samples/s: 847.624 1613148383.7686672
train: epoch 118, iter 4000, loss: 2.239370, top_1: 0.720508, top_k: 0.894180, samples/s: 848.064 1613148413.9550667
train: epoch 118, iter 4100, loss: 2.131221, top_1: 0.719258, top_k: 0.892188, samples/s: 847.080 1613148444.1765397
train: epoch 118, iter 4200, loss: 2.289618, top_1: 0.723711, top_k: 0.892578, samples/s: 847.207 1613148474.3934371
train: epoch 118, iter 4300, loss: 2.108849, top_1: 0.716367, top_k: 0.891953, samples/s: 847.169 1613148504.6121593
train: epoch 118, iter 4400, loss: 2.083915, top_1: 0.713828, top_k: 0.891406, samples/s: 846.847 1613148534.841561
train: epoch 118, iter 4500, loss: 2.213517, top_1: 0.719805, top_k: 0.892305, samples/s: 848.228 1613148565.0225801
train: epoch 118, iter 4600, loss: 2.158472, top_1: 0.718828, top_k: 0.890742, samples/s: 845.964 1613148595.2834942
train: epoch 118, iter 4700, loss: 2.228085, top_1: 0.716211, top_k: 0.891445, samples/s: 850.223 1613148625.393249
train: epoch 118, iter 4800, loss: 2.145411, top_1: 0.717031, top_k: 0.891680, samples/s: 846.816 1613148655.6240654
train: epoch 118, iter 4900, loss: 2.134010, top_1: 0.718398, top_k: 0.892813, samples/s: 847.943 1613148685.8148215
train: epoch 118, iter 5000, loss: 2.132217, top_1: 0.718750, top_k: 0.892109, samples/s: 848.264 1613148715.993976
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_118.
validation: epoch 118, iter 195, top_1: 0.736198, top_k: 0.919251, samples/s: 2462.927 1613148737.171076
train: epoch 119, iter 100, loss: 2.075408, top_1: 0.730898, top_k: 0.898555, samples/s: 868.831 1613148787.5290384
train: epoch 119, iter 200, loss: 2.027788, top_1: 0.728711, top_k: 0.900859, samples/s: 869.324 1613148816.9771109
train: epoch 119, iter 300, loss: 2.132452, top_1: 0.726953, top_k: 0.896680, samples/s: 854.406 1613148846.93943
train: epoch 119, iter 400, loss: 2.115458, top_1: 0.726133, top_k: 0.896602, samples/s: 846.732 1613148877.1733596
train: epoch 119, iter 500, loss: 2.102697, top_1: 0.729922, top_k: 0.900430, samples/s: 844.919 1613148907.472122
train: epoch 119, iter 600, loss: 2.052770, top_1: 0.726406, top_k: 0.895469, samples/s: 846.531 1613148937.713141
train: epoch 119, iter 700, loss: 2.110293, top_1: 0.727187, top_k: 0.898086, samples/s: 846.551 1613148967.9536245
train: epoch 119, iter 800, loss: 2.327038, top_1: 0.724492, top_k: 0.897813, samples/s: 847.664 1613148998.1542723
train: epoch 119, iter 900, loss: 1.964401, top_1: 0.727617, top_k: 0.898359, samples/s: 849.214 1613149028.2997842
train: epoch 119, iter 1000, loss: 2.220896, top_1: 0.723203, top_k: 0.895781, samples/s: 846.265 1613149058.550337
train: epoch 119, iter 1100, loss: 2.230476, top_1: 0.723203, top_k: 0.897305, samples/s: 849.471 1613149088.6867228
train: epoch 119, iter 1200, loss: 2.116937, top_1: 0.725977, top_k: 0.897617, samples/s: 847.326 1613149118.8994002
train: epoch 119, iter 1300, loss: 2.187216, top_1: 0.727773, top_k: 0.895820, samples/s: 846.720 1613149149.1337805
train: epoch 119, iter 1400, loss: 2.004269, top_1: 0.724609, top_k: 0.892109, samples/s: 847.122 1613149179.3537745
train: epoch 119, iter 1500, loss: 2.163191, top_1: 0.727656, top_k: 0.897773, samples/s: 850.198 1613149209.4644108
train: epoch 119, iter 1600, loss: 2.131555, top_1: 0.727617, top_k: 0.896055, samples/s: 845.872 1613149239.728923
train: epoch 119, iter 1700, loss: 2.175568, top_1: 0.723398, top_k: 0.897148, samples/s: 847.980 1613149269.9183152
train: epoch 119, iter 1800, loss: 2.187815, top_1: 0.725547, top_k: 0.897773, samples/s: 847.756 1613149300.1157377
train: epoch 119, iter 1900, loss: 2.261098, top_1: 0.724570, top_k: 0.895273, samples/s: 850.851 1613149330.203228
train: epoch 119, iter 2000, loss: 2.241291, top_1: 0.721875, top_k: 0.895742, samples/s: 848.466 1613149360.3753886
train: epoch 119, iter 2100, loss: 2.235390, top_1: 0.725078, top_k: 0.896016, samples/s: 846.966 1613149390.6009285
train: epoch 119, iter 2200, loss: 2.071559, top_1: 0.719414, top_k: 0.894922, samples/s: 848.890 1613149420.7578902
train: epoch 119, iter 2300, loss: 2.085592, top_1: 0.728789, top_k: 0.900742, samples/s: 851.360 1613149450.827486
train: epoch 119, iter 2400, loss: 2.200158, top_1: 0.724688, top_k: 0.895898, samples/s: 847.111 1613149481.047891
train: epoch 119, iter 2500, loss: 2.206237, top_1: 0.719766, top_k: 0.894414, samples/s: 849.702 1613149511.1760223
train: epoch 119, iter 2600, loss: 2.344319, top_1: 0.724023, top_k: 0.897227, samples/s: 845.480 1613149541.4547517
train: epoch 119, iter 2700, loss: 2.156473, top_1: 0.721875, top_k: 0.895195, samples/s: 849.722 1613149571.5822892
train: epoch 119, iter 2800, loss: 2.079078, top_1: 0.725547, top_k: 0.893516, samples/s: 850.294 1613149601.6894631
train: epoch 119, iter 2900, loss: 2.084143, top_1: 0.725039, top_k: 0.896406, samples/s: 848.186 1613149631.8716137
train: epoch 119, iter 3000, loss: 2.230478, top_1: 0.722148, top_k: 0.893242, samples/s: 848.870 1613149662.0293417
train: epoch 119, iter 3100, loss: 2.143978, top_1: 0.721055, top_k: 0.893477, samples/s: 850.473 1613149692.1301713
train: epoch 119, iter 3200, loss: 2.290005, top_1: 0.719961, top_k: 0.893477, samples/s: 847.721 1613149722.3287976
train: epoch 119, iter 3300, loss: 2.173224, top_1: 0.726055, top_k: 0.896133, samples/s: 850.210 1613149752.4389675
train: epoch 119, iter 3400, loss: 2.190766, top_1: 0.719375, top_k: 0.891289, samples/s: 846.392 1613149782.6849842
train: epoch 119, iter 3500, loss: 2.082057, top_1: 0.726445, top_k: 0.896914, samples/s: 850.477 1613149812.7857394
train: epoch 119, iter 3600, loss: 2.077646, top_1: 0.717383, top_k: 0.892539, samples/s: 845.072 1613149843.0790238
train: epoch 119, iter 3700, loss: 2.263318, top_1: 0.723320, top_k: 0.894727, samples/s: 850.530 1613149873.1779714
train: epoch 119, iter 3800, loss: 2.208120, top_1: 0.721797, top_k: 0.891094, samples/s: 847.296 1613149903.3917842
train: epoch 119, iter 3900, loss: 2.164962, top_1: 0.720391, top_k: 0.892969, samples/s: 850.637 1613149933.486824
train: epoch 119, iter 4000, loss: 2.219653, top_1: 0.719453, top_k: 0.891914, samples/s: 851.121 1613149963.5647883
train: epoch 119, iter 4100, loss: 2.055307, top_1: 0.723437, top_k: 0.895547, samples/s: 846.623 1613149993.8026385
train: epoch 119, iter 4200, loss: 2.136123, top_1: 0.721406, top_k: 0.890977, samples/s: 851.458 1613150023.86867
train: epoch 119, iter 4300, loss: 2.319600, top_1: 0.720117, top_k: 0.891641, samples/s: 847.022 1613150054.092214
train: epoch 119, iter 4400, loss: 2.182892, top_1: 0.719727, top_k: 0.894766, samples/s: 848.717 1613150084.255434
train: epoch 119, iter 4500, loss: 2.105083, top_1: 0.721133, top_k: 0.894414, samples/s: 849.749 1613150114.3819623
train: epoch 119, iter 4600, loss: 2.196495, top_1: 0.716602, top_k: 0.891641, samples/s: 846.705 1613150144.6167004
train: epoch 119, iter 4700, loss: 2.361374, top_1: 0.718867, top_k: 0.893828, samples/s: 848.398 1613150174.7912307
train: epoch 119, iter 4800, loss: 2.134095, top_1: 0.722500, top_k: 0.893164, samples/s: 848.821 1613150204.9507737
train: epoch 119, iter 4900, loss: 2.142008, top_1: 0.722305, top_k: 0.892656, samples/s: 850.260 1613150235.0591726
train: epoch 119, iter 5000, loss: 2.044470, top_1: 0.729297, top_k: 0.896836, samples/s: 848.646 1613150265.2248788
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_119.
validation: epoch 119, iter 195, top_1: 0.736979, top_k: 0.918870, samples/s: 2484.716 1613150286.2142832
train: epoch 120, iter 100, loss: 1.955304, top_1: 0.739531, top_k: 0.906055, samples/s: 871.963 1613150336.5053003
train: epoch 120, iter 200, loss: 1.965117, top_1: 0.737266, top_k: 0.902227, samples/s: 866.321 1613150366.055476
train: epoch 120, iter 300, loss: 2.122381, top_1: 0.732383, top_k: 0.898594, samples/s: 853.725 1613150396.0416968
train: epoch 120, iter 400, loss: 2.320811, top_1: 0.735391, top_k: 0.899141, samples/s: 848.176 1613150426.2240832
train: epoch 120, iter 500, loss: 2.039149, top_1: 0.728477, top_k: 0.898008, samples/s: 847.584 1613150456.4276462
train: epoch 120, iter 600, loss: 2.047261, top_1: 0.727812, top_k: 0.899180, samples/s: 845.163 1613150486.7176504
train: epoch 120, iter 700, loss: 2.216146, top_1: 0.730000, top_k: 0.897148, samples/s: 849.416 1613150516.856
train: epoch 120, iter 800, loss: 2.089756, top_1: 0.724688, top_k: 0.895977, samples/s: 848.753 1613150547.017806
train: epoch 120, iter 900, loss: 1.948652, top_1: 0.734688, top_k: 0.901445, samples/s: 848.648 1613150577.1835036
train: epoch 120, iter 1000, loss: 2.211960, top_1: 0.725430, top_k: 0.896133, samples/s: 847.603 1613150607.3863084
train: epoch 120, iter 1100, loss: 2.132246, top_1: 0.727344, top_k: 0.897266, samples/s: 847.426 1613150637.5954292
train: epoch 120, iter 1200, loss: 2.017278, top_1: 0.727656, top_k: 0.895117, samples/s: 850.909 1613150667.680857
train: epoch 120, iter 1300, loss: 1.993525, top_1: 0.726211, top_k: 0.897422, samples/s: 847.030 1613150697.904188
train: epoch 120, iter 1400, loss: 1.981239, top_1: 0.727266, top_k: 0.898672, samples/s: 849.567 1613150728.0371933
train: epoch 120, iter 1500, loss: 2.003492, top_1: 0.732812, top_k: 0.898281, samples/s: 848.347 1613150758.2134647
train: epoch 120, iter 1600, loss: 2.171471, top_1: 0.729258, top_k: 0.899531, samples/s: 847.383 1613150788.4242177
train: epoch 120, iter 1700, loss: 2.277342, top_1: 0.729180, top_k: 0.895273, samples/s: 850.763 1613150818.5148244
train: epoch 120, iter 1800, loss: 2.260211, top_1: 0.726367, top_k: 0.898203, samples/s: 850.916 1613150848.6000896
train: epoch 120, iter 1900, loss: 2.210272, top_1: 0.726406, top_k: 0.897500, samples/s: 850.821 1613150878.6886485
train: epoch 120, iter 2000, loss: 2.217938, top_1: 0.730391, top_k: 0.899023, samples/s: 849.076 1613150908.8390923
train: epoch 120, iter 2100, loss: 2.134232, top_1: 0.726289, top_k: 0.894336, samples/s: 846.991 1613150939.0636103
train: epoch 120, iter 2200, loss: 2.132934, top_1: 0.729766, top_k: 0.896797, samples/s: 848.692 1613150969.2277267
train: epoch 120, iter 2300, loss: 2.172359, top_1: 0.728008, top_k: 0.898906, samples/s: 851.301 1613150999.299366
train: epoch 120, iter 2400, loss: 2.088599, top_1: 0.724844, top_k: 0.895898, samples/s: 849.877 1613151029.4214225
train: epoch 120, iter 2500, loss: 2.124285, top_1: 0.724648, top_k: 0.896172, samples/s: 846.767 1613151059.6539688
train: epoch 120, iter 2600, loss: 1.913280, top_1: 0.727383, top_k: 0.899219, samples/s: 848.718 1613151089.8172164
train: epoch 120, iter 2700, loss: 2.312325, top_1: 0.722148, top_k: 0.894492, samples/s: 850.710 1613151119.9097035
train: epoch 120, iter 2800, loss: 2.134626, top_1: 0.724688, top_k: 0.897266, samples/s: 848.971 1613151150.063754
train: epoch 120, iter 2900, loss: 2.073864, top_1: 0.724258, top_k: 0.893437, samples/s: 846.938 1613151180.2904072
train: epoch 120, iter 3000, loss: 2.079773, top_1: 0.724648, top_k: 0.894961, samples/s: 851.386 1613151210.3589635
train: epoch 120, iter 3100, loss: 1.951952, top_1: 0.724023, top_k: 0.896016, samples/s: 846.196 1613151240.612023
train: epoch 120, iter 3200, loss: 2.248677, top_1: 0.721211, top_k: 0.895273, samples/s: 848.975 1613151270.765949
train: epoch 120, iter 3300, loss: 2.008334, top_1: 0.725664, top_k: 0.897031, samples/s: 849.127 1613151300.9145708
train: epoch 120, iter 3400, loss: 2.120811, top_1: 0.726914, top_k: 0.896523, samples/s: 850.964 1613151330.9981577
train: epoch 120, iter 3500, loss: 2.285748, top_1: 0.724375, top_k: 0.896758, samples/s: 850.481 1613151361.098649
train: epoch 120, iter 3600, loss: 2.000159, top_1: 0.720742, top_k: 0.895703, samples/s: 850.352 1613151391.2038808
train: epoch 120, iter 3700, loss: 2.243720, top_1: 0.727344, top_k: 0.897500, samples/s: 850.593 1613151421.3005016
train: epoch 120, iter 3800, loss: 2.111665, top_1: 0.727266, top_k: 0.896758, samples/s: 848.185 1613151451.4827006
train: epoch 120, iter 3900, loss: 2.249976, top_1: 0.722695, top_k: 0.895547, samples/s: 849.517 1613151481.6173196
train: epoch 120, iter 4000, loss: 1.979615, top_1: 0.726250, top_k: 0.895391, samples/s: 851.753 1613151511.6729982
train: epoch 120, iter 4100, loss: 2.069930, top_1: 0.719023, top_k: 0.894219, samples/s: 847.552 1613151541.8776267
train: epoch 120, iter 4200, loss: 1.935516, top_1: 0.727461, top_k: 0.895039, samples/s: 849.858 1613151572.0003257
train: epoch 120, iter 4300, loss: 2.236811, top_1: 0.725625, top_k: 0.898086, samples/s: 849.932 1613151602.120388
train: epoch 120, iter 4400, loss: 2.190826, top_1: 0.719883, top_k: 0.894727, samples/s: 848.697 1613151632.2843225
train: epoch 120, iter 4500, loss: 2.217256, top_1: 0.721094, top_k: 0.893711, samples/s: 850.069 1613151662.3995786
train: epoch 120, iter 4600, loss: 2.126061, top_1: 0.727070, top_k: 0.895977, samples/s: 848.040 1613151692.586756
train: epoch 120, iter 4700, loss: 2.214923, top_1: 0.722891, top_k: 0.895000, samples/s: 850.106 1613151722.7007298
train: epoch 120, iter 4800, loss: 2.124914, top_1: 0.718633, top_k: 0.894687, samples/s: 850.929 1613151752.78542
train: epoch 120, iter 4900, loss: 2.234797, top_1: 0.725234, top_k: 0.897773, samples/s: 849.144 1613151782.933393
train: epoch 120, iter 5000, loss: 2.143384, top_1: 0.728945, top_k: 0.896758, samples/s: 851.633 1613151812.993393
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_120.
validation: epoch 120, iter 195, top_1: 0.741567, top_k: 0.920493, samples/s: 2430.390 1613151834.4141524
train: epoch 121, iter 100, loss: 2.054444, top_1: 0.738594, top_k: 0.904531, samples/s: 870.385 1613151890.327215
train: epoch 121, iter 200, loss: 2.110999, top_1: 0.736641, top_k: 0.903828, samples/s: 867.765 1613151919.8285549
train: epoch 121, iter 300, loss: 2.036729, top_1: 0.737539, top_k: 0.903242, samples/s: 858.776 1613151949.6381204
train: epoch 121, iter 400, loss: 2.058983, top_1: 0.737734, top_k: 0.902734, samples/s: 850.879 1613151979.7246587
train: epoch 121, iter 500, loss: 2.086627, top_1: 0.734453, top_k: 0.899180, samples/s: 849.996 1613152009.8424802
train: epoch 121, iter 600, loss: 2.226158, top_1: 0.734844, top_k: 0.898945, samples/s: 847.350 1613152040.0543115
train: epoch 121, iter 700, loss: 1.998577, top_1: 0.737812, top_k: 0.903008, samples/s: 850.711 1613152070.1467745
train: epoch 121, iter 800, loss: 2.094155, top_1: 0.733906, top_k: 0.901406, samples/s: 846.448 1613152100.390919
train: epoch 121, iter 900, loss: 2.145242, top_1: 0.733594, top_k: 0.902773, samples/s: 851.899 1613152130.441312
train: epoch 121, iter 1000, loss: 2.063582, top_1: 0.732852, top_k: 0.897266, samples/s: 847.798 1613152160.6372828
train: epoch 121, iter 1100, loss: 2.117616, top_1: 0.727031, top_k: 0.897773, samples/s: 852.675 1613152190.6604376
train: epoch 121, iter 1200, loss: 2.082954, top_1: 0.735156, top_k: 0.899141, samples/s: 849.197 1613152220.8065457
train: epoch 121, iter 1300, loss: 1.992849, top_1: 0.735156, top_k: 0.903008, samples/s: 847.634 1613152251.0082338
train: epoch 121, iter 1400, loss: 2.107194, top_1: 0.729531, top_k: 0.899727, samples/s: 851.221 1613152281.0827208
train: epoch 121, iter 1500, loss: 2.100281, top_1: 0.733164, top_k: 0.902617, samples/s: 850.749 1613152311.1738853
train: epoch 121, iter 1600, loss: 2.159114, top_1: 0.728242, top_k: 0.895742, samples/s: 847.838 1613152341.3683527
train: epoch 121, iter 1700, loss: 2.164816, top_1: 0.731563, top_k: 0.897109, samples/s: 849.577 1613152371.5009916
train: epoch 121, iter 1800, loss: 2.201779, top_1: 0.737070, top_k: 0.903320, samples/s: 850.911 1613152401.5863843
train: epoch 121, iter 1900, loss: 2.250302, top_1: 0.729258, top_k: 0.900977, samples/s: 849.657 1613152431.7161481
train: epoch 121, iter 2000, loss: 2.296671, top_1: 0.728398, top_k: 0.898164, samples/s: 850.350 1613152461.8214288
train: epoch 121, iter 2100, loss: 2.091622, top_1: 0.727187, top_k: 0.898047, samples/s: 853.416 1613152491.8184085
train: epoch 121, iter 2200, loss: 2.180947, top_1: 0.727734, top_k: 0.899883, samples/s: 849.354 1613152521.9589705
train: epoch 121, iter 2300, loss: 2.001023, top_1: 0.728867, top_k: 0.898125, samples/s: 850.012 1613152552.0762484
train: epoch 121, iter 2400, loss: 2.031736, top_1: 0.725391, top_k: 0.897578, samples/s: 848.967 1613152582.230561
train: epoch 121, iter 2500, loss: 2.061366, top_1: 0.729688, top_k: 0.901523, samples/s: 852.987 1613152612.2426808
train: epoch 121, iter 2600, loss: 2.349858, top_1: 0.733008, top_k: 0.899531, samples/s: 848.176 1613152642.4250875
train: epoch 121, iter 2700, loss: 2.235763, top_1: 0.727734, top_k: 0.899102, samples/s: 849.922 1613152672.5455477
train: epoch 121, iter 2800, loss: 2.136635, top_1: 0.730781, top_k: 0.897539, samples/s: 848.859 1613152702.7037106
train: epoch 121, iter 2900, loss: 2.212452, top_1: 0.725234, top_k: 0.897656, samples/s: 849.452 1613152732.840795
train: epoch 121, iter 3000, loss: 2.259037, top_1: 0.726445, top_k: 0.895781, samples/s: 851.907 1613152762.8909814
train: epoch 121, iter 3100, loss: 2.074215, top_1: 0.728867, top_k: 0.897813, samples/s: 848.820 1613152793.0505087
train: epoch 121, iter 3200, loss: 2.078174, top_1: 0.729883, top_k: 0.895430, samples/s: 849.964 1613152823.16944
train: epoch 121, iter 3300, loss: 2.142876, top_1: 0.730625, top_k: 0.898086, samples/s: 850.148 1613152853.281725
train: epoch 121, iter 3400, loss: 2.142216, top_1: 0.727109, top_k: 0.899141, samples/s: 848.337 1613152883.458518
train: epoch 121, iter 3500, loss: 2.157529, top_1: 0.722070, top_k: 0.893945, samples/s: 849.377 1613152913.5982516
train: epoch 121, iter 3600, loss: 2.017371, top_1: 0.730273, top_k: 0.900547, samples/s: 850.654 1613152943.692746
train: epoch 121, iter 3700, loss: 2.030153, top_1: 0.724766, top_k: 0.898320, samples/s: 848.532 1613152973.8624015
train: epoch 121, iter 3800, loss: 2.019851, top_1: 0.730781, top_k: 0.898398, samples/s: 848.016 1613153004.0505128
train: epoch 121, iter 3900, loss: 2.063296, top_1: 0.726992, top_k: 0.898438, samples/s: 851.440 1613153034.117351
train: epoch 121, iter 4000, loss: 2.191277, top_1: 0.726562, top_k: 0.898281, samples/s: 850.928 1613153064.2020316
train: epoch 121, iter 4100, loss: 2.050396, top_1: 0.729297, top_k: 0.900117, samples/s: 851.319 1613153094.2730012
train: epoch 121, iter 4200, loss: 2.139725, top_1: 0.726953, top_k: 0.893555, samples/s: 851.366 1613153124.3424382
train: epoch 121, iter 4300, loss: 1.933735, top_1: 0.725508, top_k: 0.896133, samples/s: 848.121 1613153154.526756
train: epoch 121, iter 4400, loss: 2.070373, top_1: 0.728164, top_k: 0.899023, samples/s: 850.652 1613153184.6212978
train: epoch 121, iter 4500, loss: 2.121122, top_1: 0.725078, top_k: 0.898281, samples/s: 847.532 1613153214.8267052
train: epoch 121, iter 4600, loss: 2.031940, top_1: 0.728320, top_k: 0.898516, samples/s: 850.310 1613153244.9333844
train: epoch 121, iter 4700, loss: 2.049260, top_1: 0.725859, top_k: 0.897227, samples/s: 847.848 1613153275.127489
train: epoch 121, iter 4800, loss: 2.148505, top_1: 0.721328, top_k: 0.895664, samples/s: 850.649 1613153305.2220874
train: epoch 121, iter 4900, loss: 2.134136, top_1: 0.725352, top_k: 0.895469, samples/s: 851.352 1613153335.291868
train: epoch 121, iter 5000, loss: 2.013159, top_1: 0.733242, top_k: 0.899766, samples/s: 848.812 1613153365.4517946
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_121.
validation: epoch 121, iter 195, top_1: 0.743009, top_k: 0.923397, samples/s: 2470.317 1613153386.5852842
train: epoch 122, iter 100, loss: 2.012284, top_1: 0.737930, top_k: 0.902813, samples/s: 870.260 1613153438.2706475
train: epoch 122, iter 200, loss: 1.986144, top_1: 0.740469, top_k: 0.902461, samples/s: 867.295 1613153467.7877457
train: epoch 122, iter 300, loss: 2.043501, top_1: 0.739609, top_k: 0.901797, samples/s: 858.908 1613153497.592884
train: epoch 122, iter 400, loss: 2.164166, top_1: 0.740469, top_k: 0.904180, samples/s: 847.796 1613153527.7888284
train: epoch 122, iter 500, loss: 1.924959, top_1: 0.741367, top_k: 0.904883, samples/s: 849.811 1613153557.9132414
train: epoch 122, iter 600, loss: 2.168309, top_1: 0.731953, top_k: 0.900508, samples/s: 850.019 1613153588.0302415
train: epoch 122, iter 700, loss: 2.020566, top_1: 0.734453, top_k: 0.902578, samples/s: 849.716 1613153618.1578896
train: epoch 122, iter 800, loss: 2.035767, top_1: 0.731406, top_k: 0.901836, samples/s: 849.764 1613153648.283876
train: epoch 122, iter 900, loss: 1.999463, top_1: 0.732109, top_k: 0.899844, samples/s: 849.572 1613153678.4167397
train: epoch 122, iter 1000, loss: 2.158678, top_1: 0.735977, top_k: 0.897813, samples/s: 848.773 1613153708.5778368
train: epoch 122, iter 1100, loss: 2.088574, top_1: 0.730039, top_k: 0.899062, samples/s: 849.869 1613153738.7002614
train: epoch 122, iter 1200, loss: 1.999253, top_1: 0.735820, top_k: 0.898750, samples/s: 848.011 1613153768.8884583
train: epoch 122, iter 1300, loss: 2.116694, top_1: 0.735234, top_k: 0.901289, samples/s: 849.754 1613153799.0148127
train: epoch 122, iter 1400, loss: 1.938249, top_1: 0.737539, top_k: 0.906133, samples/s: 852.922 1613153829.029359
train: epoch 122, iter 1500, loss: 2.238499, top_1: 0.731719, top_k: 0.898320, samples/s: 850.047 1613153859.1452992
train: epoch 122, iter 1600, loss: 2.039826, top_1: 0.737187, top_k: 0.901602, samples/s: 850.975 1613153889.2284455
train: epoch 122, iter 1700, loss: 2.164471, top_1: 0.735117, top_k: 0.901484, samples/s: 848.705 1613153919.3921044
train: epoch 122, iter 1800, loss: 1.990861, top_1: 0.734102, top_k: 0.898945, samples/s: 850.595 1613153949.488692
train: epoch 122, iter 1900, loss: 2.303010, top_1: 0.733906, top_k: 0.898906, samples/s: 849.535 1613153979.6227362
train: epoch 122, iter 2000, loss: 2.143771, top_1: 0.734062, top_k: 0.902969, samples/s: 849.299 1613154009.76527
train: epoch 122, iter 2100, loss: 2.136906, top_1: 0.730898, top_k: 0.900547, samples/s: 850.427 1613154039.8677788
train: epoch 122, iter 2200, loss: 2.217128, top_1: 0.728867, top_k: 0.899219, samples/s: 849.992 1613154069.9856722
train: epoch 122, iter 2300, loss: 2.073855, top_1: 0.736133, top_k: 0.904023, samples/s: 849.854 1613154100.1084666
train: epoch 122, iter 2400, loss: 2.152197, top_1: 0.732812, top_k: 0.902188, samples/s: 850.541 1613154130.2070236
train: epoch 122, iter 2500, loss: 2.210442, top_1: 0.735000, top_k: 0.901445, samples/s: 849.504 1613154160.342293
train: epoch 122, iter 2600, loss: 2.139219, top_1: 0.736719, top_k: 0.897930, samples/s: 850.086 1613154190.4567685
train: epoch 122, iter 2700, loss: 2.146434, top_1: 0.726641, top_k: 0.896836, samples/s: 851.134 1613154220.534323
train: epoch 122, iter 2800, loss: 2.259451, top_1: 0.732617, top_k: 0.897500, samples/s: 849.866 1613154250.6571438
train: epoch 122, iter 2900, loss: 1.871887, top_1: 0.730977, top_k: 0.901875, samples/s: 849.746 1613154280.783438
train: epoch 122, iter 3000, loss: 2.035855, top_1: 0.730898, top_k: 0.898711, samples/s: 849.441 1613154310.9212062
train: epoch 122, iter 3100, loss: 2.237098, top_1: 0.726055, top_k: 0.896406, samples/s: 850.356 1613154341.0259502
train: epoch 122, iter 3200, loss: 2.172698, top_1: 0.724453, top_k: 0.897852, samples/s: 849.823 1613154371.1498084
train: epoch 122, iter 3300, loss: 2.035060, top_1: 0.728477, top_k: 0.897617, samples/s: 852.665 1613154401.173337
train: epoch 122, iter 3400, loss: 1.982359, top_1: 0.728984, top_k: 0.898477, samples/s: 850.767 1613154431.2637804
train: epoch 122, iter 3500, loss: 2.201396, top_1: 0.732070, top_k: 0.899531, samples/s: 848.776 1613154461.424926
train: epoch 122, iter 3600, loss: 1.985490, top_1: 0.734141, top_k: 0.901445, samples/s: 851.846 1613154491.4772565
train: epoch 122, iter 3700, loss: 2.279089, top_1: 0.726719, top_k: 0.898242, samples/s: 851.035 1613154521.5611966
train: epoch 122, iter 3800, loss: 2.167076, top_1: 0.733203, top_k: 0.898320, samples/s: 851.181 1613154551.6340866
train: epoch 122, iter 3900, loss: 2.142874, top_1: 0.724492, top_k: 0.895352, samples/s: 852.780 1613154581.6535964
train: epoch 122, iter 4000, loss: 2.066857, top_1: 0.730234, top_k: 0.897969, samples/s: 852.885 1613154611.6694303
train: epoch 122, iter 4100, loss: 2.100384, top_1: 0.725703, top_k: 0.898438, samples/s: 850.615 1613154641.7653146
train: epoch 122, iter 4200, loss: 1.994703, top_1: 0.731367, top_k: 0.898867, samples/s: 848.477 1613154671.936977
train: epoch 122, iter 4300, loss: 1.905818, top_1: 0.730313, top_k: 0.898086, samples/s: 851.004 1613154702.0190353
train: epoch 122, iter 4400, loss: 2.052328, top_1: 0.730469, top_k: 0.898750, samples/s: 848.658 1613154732.1842887
train: epoch 122, iter 4500, loss: 2.213599, top_1: 0.728047, top_k: 0.895898, samples/s: 849.342 1613154762.3253388
train: epoch 122, iter 4600, loss: 2.086237, top_1: 0.727227, top_k: 0.898164, samples/s: 851.464 1613154792.3911502
train: epoch 122, iter 4700, loss: 2.194848, top_1: 0.727930, top_k: 0.897734, samples/s: 849.884 1613154822.5128617
train: epoch 122, iter 4800, loss: 2.134865, top_1: 0.729570, top_k: 0.897891, samples/s: 850.350 1613154852.6181936
train: epoch 122, iter 4900, loss: 2.194884, top_1: 0.725586, top_k: 0.896289, samples/s: 850.721 1613154882.7102573
train: epoch 122, iter 5000, loss: 1.998155, top_1: 0.738047, top_k: 0.901133, samples/s: 849.144 1613154912.8582788
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_122.
validation: epoch 122, iter 195, top_1: 0.744671, top_k: 0.923177, samples/s: 2457.782 1613154934.0508513
train: epoch 123, iter 100, loss: 2.015044, top_1: 0.740742, top_k: 0.903594, samples/s: 868.608 1613154985.4821749
train: epoch 123, iter 200, loss: 1.920528, top_1: 0.738867, top_k: 0.902969, samples/s: 868.893 1613155014.9451015
train: epoch 123, iter 300, loss: 2.096766, top_1: 0.737930, top_k: 0.902031, samples/s: 853.822 1613155044.92789
train: epoch 123, iter 400, loss: 2.021257, top_1: 0.735625, top_k: 0.899687, samples/s: 850.797 1613155075.0173073
train: epoch 123, iter 500, loss: 1.896624, top_1: 0.745391, top_k: 0.905547, samples/s: 851.878 1613155105.0683913
train: epoch 123, iter 600, loss: 2.101960, top_1: 0.739531, top_k: 0.899492, samples/s: 846.084 1613155135.325426
train: epoch 123, iter 700, loss: 2.036451, top_1: 0.738477, top_k: 0.901133, samples/s: 849.078 1613155165.4758637
train: epoch 123, iter 800, loss: 2.071979, top_1: 0.740781, top_k: 0.903203, samples/s: 849.741 1613155195.6025808
train: epoch 123, iter 900, loss: 1.952855, top_1: 0.739570, top_k: 0.904219, samples/s: 852.529 1613155225.6308832
train: epoch 123, iter 1000, loss: 2.012815, top_1: 0.741289, top_k: 0.907266, samples/s: 847.542 1613155255.8359587
train: epoch 123, iter 1100, loss: 2.100256, top_1: 0.738906, top_k: 0.903906, samples/s: 850.682 1613155285.9294918
train: epoch 123, iter 1200, loss: 2.029849, top_1: 0.740391, top_k: 0.902031, samples/s: 849.476 1613155316.0656307
train: epoch 123, iter 1300, loss: 2.045874, top_1: 0.738984, top_k: 0.905273, samples/s: 847.542 1613155346.2706711
train: epoch 123, iter 1400, loss: 2.161215, top_1: 0.736328, top_k: 0.901055, samples/s: 852.947 1613155376.2842703
train: epoch 123, iter 1500, loss: 2.236189, top_1: 0.738594, top_k: 0.901055, samples/s: 848.750 1613155406.4462194
train: epoch 123, iter 1600, loss: 2.007608, top_1: 0.739531, top_k: 0.905000, samples/s: 850.959 1613155436.530046
train: epoch 123, iter 1700, loss: 1.959001, top_1: 0.738281, top_k: 0.899766, samples/s: 850.281 1613155466.6376574
train: epoch 123, iter 1800, loss: 1.985726, top_1: 0.735430, top_k: 0.902773, samples/s: 851.043 1613155496.7183387
train: epoch 123, iter 1900, loss: 2.068769, top_1: 0.741797, top_k: 0.903867, samples/s: 846.417 1613155526.9635093
train: epoch 123, iter 2000, loss: 2.132341, top_1: 0.733477, top_k: 0.902578, samples/s: 851.248 1613155557.0370286
train: epoch 123, iter 2100, loss: 2.026159, top_1: 0.732461, top_k: 0.901602, samples/s: 847.961 1613155587.227138
train: epoch 123, iter 2200, loss: 1.969620, top_1: 0.738047, top_k: 0.903906, samples/s: 850.839 1613155617.315013
train: epoch 123, iter 2300, loss: 2.137499, top_1: 0.737578, top_k: 0.901563, samples/s: 848.028 1613155647.5027542
train: epoch 123, iter 2400, loss: 2.176285, top_1: 0.736484, top_k: 0.901016, samples/s: 849.243 1613155677.6473172
train: epoch 123, iter 2500, loss: 2.239443, top_1: 0.733281, top_k: 0.901289, samples/s: 850.863 1613155707.734299
train: epoch 123, iter 2600, loss: 2.187930, top_1: 0.733047, top_k: 0.900078, samples/s: 846.930 1613155737.9612796
train: epoch 123, iter 2700, loss: 2.009816, top_1: 0.733789, top_k: 0.902305, samples/s: 849.789 1613155768.0863187
train: epoch 123, iter 2800, loss: 2.029683, top_1: 0.732500, top_k: 0.899180, samples/s: 846.704 1613155798.3212495
train: epoch 123, iter 2900, loss: 2.041884, top_1: 0.732617, top_k: 0.902539, samples/s: 846.951 1613155828.5471902
train: epoch 123, iter 3000, loss: 2.025523, top_1: 0.736016, top_k: 0.899062, samples/s: 852.921 1613155858.561779
train: epoch 123, iter 3100, loss: 1.990470, top_1: 0.728789, top_k: 0.900195, samples/s: 849.290 1613155888.7044983
train: epoch 123, iter 3200, loss: 2.210490, top_1: 0.731328, top_k: 0.899258, samples/s: 849.673 1613155918.8338408
train: epoch 123, iter 3300, loss: 2.153440, top_1: 0.730742, top_k: 0.898438, samples/s: 848.333 1613155949.0105686
train: epoch 123, iter 3400, loss: 1.969212, top_1: 0.729258, top_k: 0.895938, samples/s: 850.945 1613155979.09486
train: epoch 123, iter 3500, loss: 1.950235, top_1: 0.735078, top_k: 0.904609, samples/s: 849.440 1613156009.23238
train: epoch 123, iter 3600, loss: 2.052700, top_1: 0.732227, top_k: 0.900547, samples/s: 851.826 1613156039.2853467
train: epoch 123, iter 3700, loss: 2.036975, top_1: 0.730742, top_k: 0.901094, samples/s: 847.822 1613156069.4804242
train: epoch 123, iter 3800, loss: 2.050892, top_1: 0.733906, top_k: 0.902930, samples/s: 851.037 1613156099.5613458
train: epoch 123, iter 3900, loss: 2.071717, top_1: 0.732422, top_k: 0.900742, samples/s: 849.470 1613156129.6978817
train: epoch 123, iter 4000, loss: 2.040081, top_1: 0.735469, top_k: 0.899414, samples/s: 849.308 1613156159.840067
train: epoch 123, iter 4100, loss: 2.152565, top_1: 0.729609, top_k: 0.897422, samples/s: 850.164 1613156189.9518251
train: epoch 123, iter 4200, loss: 2.095679, top_1: 0.734844, top_k: 0.905391, samples/s: 850.389 1613156220.0557907
train: epoch 123, iter 4300, loss: 2.082195, top_1: 0.729414, top_k: 0.901211, samples/s: 850.131 1613156250.1687644
train: epoch 123, iter 4400, loss: 2.006717, top_1: 0.736211, top_k: 0.901836, samples/s: 848.503 1613156280.3395643
train: epoch 123, iter 4500, loss: 2.016948, top_1: 0.739883, top_k: 0.903047, samples/s: 850.471 1613156310.4405394
train: epoch 123, iter 4600, loss: 2.039047, top_1: 0.732773, top_k: 0.899062, samples/s: 849.619 1613156340.571708
train: epoch 123, iter 4700, loss: 2.172306, top_1: 0.730977, top_k: 0.899219, samples/s: 846.460 1613156370.8153005
train: epoch 123, iter 4800, loss: 2.066842, top_1: 0.732383, top_k: 0.897383, samples/s: 853.245 1613156400.818414
train: epoch 123, iter 4900, loss: 2.003421, top_1: 0.736250, top_k: 0.899844, samples/s: 849.091 1613156430.9683607
train: epoch 123, iter 5000, loss: 2.016573, top_1: 0.740781, top_k: 0.901563, samples/s: 850.009 1613156461.0856712
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_123.
validation: epoch 123, iter 195, top_1: 0.748698, top_k: 0.923858, samples/s: 2465.926 1613156482.223774
train: epoch 124, iter 100, loss: 2.058549, top_1: 0.750117, top_k: 0.907539, samples/s: 869.143 1613156532.6138573
train: epoch 124, iter 200, loss: 1.961287, top_1: 0.749180, top_k: 0.910508, samples/s: 867.156 1613156562.1356356
train: epoch 124, iter 300, loss: 2.079240, top_1: 0.745234, top_k: 0.907578, samples/s: 852.874 1613156592.151735
train: epoch 124, iter 400, loss: 2.018167, top_1: 0.742891, top_k: 0.903789, samples/s: 848.822 1613156622.311234
train: epoch 124, iter 500, loss: 2.184993, top_1: 0.748398, top_k: 0.908789, samples/s: 851.154 1613156652.3879786
train: epoch 124, iter 600, loss: 2.111573, top_1: 0.737773, top_k: 0.903008, samples/s: 846.399 1613156682.633805
train: epoch 124, iter 700, loss: 2.277068, top_1: 0.736211, top_k: 0.899297, samples/s: 845.536 1613156712.9104297
train: epoch 124, iter 800, loss: 2.125918, top_1: 0.737187, top_k: 0.899219, samples/s: 848.191 1613156743.092373
train: epoch 124, iter 900, loss: 1.980103, top_1: 0.746328, top_k: 0.910625, samples/s: 846.499 1613156773.334476
train: epoch 124, iter 1000, loss: 2.106545, top_1: 0.744961, top_k: 0.904336, samples/s: 848.916 1613156803.490605
train: epoch 124, iter 1100, loss: 2.117090, top_1: 0.738867, top_k: 0.902734, samples/s: 849.766 1613156833.6165397
train: epoch 124, iter 1200, loss: 2.065750, top_1: 0.741211, top_k: 0.902500, samples/s: 848.919 1613156863.772528
train: epoch 124, iter 1300, loss: 2.118355, top_1: 0.735625, top_k: 0.903750, samples/s: 844.176 1613156894.0980449
train: epoch 124, iter 1400, loss: 2.064240, top_1: 0.736680, top_k: 0.905742, samples/s: 852.453 1613156924.1290004
train: epoch 124, iter 1500, loss: 2.243787, top_1: 0.738789, top_k: 0.905508, samples/s: 848.113 1613156954.3136587
train: epoch 124, iter 1600, loss: 2.113033, top_1: 0.733437, top_k: 0.903945, samples/s: 848.684 1613156984.478013
train: epoch 124, iter 1700, loss: 2.332967, top_1: 0.739414, top_k: 0.902930, samples/s: 846.998 1613157014.702423
train: epoch 124, iter 1800, loss: 1.996814, top_1: 0.742188, top_k: 0.904102, samples/s: 849.130 1613157044.8509219
train: epoch 124, iter 1900, loss: 1.962446, top_1: 0.736992, top_k: 0.903672, samples/s: 846.089 1613157075.1076956
train: epoch 124, iter 2000, loss: 2.082674, top_1: 0.736250, top_k: 0.902148, samples/s: 848.535 1613157105.2774632
train: epoch 124, iter 2100, loss: 2.198197, top_1: 0.738945, top_k: 0.903750, samples/s: 848.184 1613157135.459486
train: epoch 124, iter 2200, loss: 2.014649, top_1: 0.736680, top_k: 0.902578, samples/s: 849.823 1613157165.5834327
train: epoch 124, iter 2300, loss: 2.157357, top_1: 0.735273, top_k: 0.902148, samples/s: 847.908 1613157195.7753654
train: epoch 124, iter 2400, loss: 2.039507, top_1: 0.738359, top_k: 0.901602, samples/s: 849.947 1613157225.8949125
train: epoch 124, iter 2500, loss: 1.994830, top_1: 0.738320, top_k: 0.905781, samples/s: 849.649 1613157256.025036
train: epoch 124, iter 2600, loss: 2.153052, top_1: 0.734219, top_k: 0.901484, samples/s: 847.158 1613157286.2436953
train: epoch 124, iter 2700, loss: 1.993805, top_1: 0.736367, top_k: 0.900469, samples/s: 851.911 1613157316.2937238
train: epoch 124, iter 2800, loss: 2.078305, top_1: 0.734102, top_k: 0.902734, samples/s: 846.905 1613157346.5214746
train: epoch 124, iter 2900, loss: 2.101150, top_1: 0.737227, top_k: 0.903867, samples/s: 849.070 1613157376.6720862
train: epoch 124, iter 3000, loss: 2.018346, top_1: 0.737891, top_k: 0.903711, samples/s: 850.177 1613157406.7834427
train: epoch 124, iter 3100, loss: 2.039464, top_1: 0.731797, top_k: 0.903789, samples/s: 849.874 1613157436.9055998
train: epoch 124, iter 3200, loss: 1.972848, top_1: 0.739414, top_k: 0.902070, samples/s: 846.629 1613157467.1432147
train: epoch 124, iter 3300, loss: 2.081017, top_1: 0.739141, top_k: 0.903359, samples/s: 850.940 1613157497.2275267
train: epoch 124, iter 3400, loss: 2.044452, top_1: 0.737578, top_k: 0.904453, samples/s: 850.971 1613157527.3107917
train: epoch 124, iter 3500, loss: 2.166649, top_1: 0.738164, top_k: 0.903984, samples/s: 846.998 1613157557.5351572
train: epoch 124, iter 3600, loss: 2.036621, top_1: 0.737539, top_k: 0.903477, samples/s: 848.742 1613157587.6974268
train: epoch 124, iter 3700, loss: 2.047200, top_1: 0.729805, top_k: 0.898203, samples/s: 848.175 1613157617.8799477
train: epoch 124, iter 3800, loss: 2.170404, top_1: 0.737422, top_k: 0.904375, samples/s: 850.994 1613157647.9624386
train: epoch 124, iter 3900, loss: 2.164396, top_1: 0.734062, top_k: 0.901914, samples/s: 846.308 1613157678.2114751
train: epoch 124, iter 4000, loss: 2.031420, top_1: 0.739688, top_k: 0.902969, samples/s: 850.327 1613157708.3174963
train: epoch 124, iter 4100, loss: 2.159694, top_1: 0.740156, top_k: 0.901875, samples/s: 848.946 1613157738.4725778
train: epoch 124, iter 4200, loss: 1.982936, top_1: 0.731250, top_k: 0.897461, samples/s: 848.790 1613157768.6331115
train: epoch 124, iter 4300, loss: 2.101560, top_1: 0.737422, top_k: 0.901875, samples/s: 850.731 1613157798.7248108
train: epoch 124, iter 4400, loss: 1.973716, top_1: 0.732148, top_k: 0.901367, samples/s: 846.462 1613157828.968357
train: epoch 124, iter 4500, loss: 1.957259, top_1: 0.735156, top_k: 0.902695, samples/s: 847.054 1613157859.1907482
train: epoch 124, iter 4600, loss: 2.066992, top_1: 0.732461, top_k: 0.899102, samples/s: 849.046 1613157889.3421917
train: epoch 124, iter 4700, loss: 2.219754, top_1: 0.734297, top_k: 0.904844, samples/s: 847.302 1613157919.5558197
train: epoch 124, iter 4800, loss: 2.193300, top_1: 0.728477, top_k: 0.896094, samples/s: 844.646 1613157949.8642814
train: epoch 124, iter 4900, loss: 2.046494, top_1: 0.737539, top_k: 0.903594, samples/s: 855.123 1613157979.801594
train: epoch 124, iter 5000, loss: 2.149196, top_1: 0.742930, top_k: 0.906250, samples/s: 848.773 1613158009.9627297
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_124.
validation: epoch 124, iter 195, top_1: 0.746014, top_k: 0.922416, samples/s: 2450.100 1613158031.2402332
train: epoch 125, iter 100, loss: 2.228367, top_1: 0.754453, top_k: 0.910430, samples/s: 872.526 1613158081.233552
train: epoch 125, iter 200, loss: 2.154934, top_1: 0.756367, top_k: 0.911758, samples/s: 866.498 1613158110.7776558
train: epoch 125, iter 300, loss: 2.143581, top_1: 0.748242, top_k: 0.908008, samples/s: 856.427 1613158140.6692731
train: epoch 125, iter 400, loss: 1.881601, top_1: 0.748867, top_k: 0.909102, samples/s: 846.374 1613158170.916039
train: epoch 125, iter 500, loss: 1.980714, top_1: 0.752539, top_k: 0.908477, samples/s: 847.661 1613158201.1167622
train: epoch 125, iter 600, loss: 1.997696, top_1: 0.741445, top_k: 0.904219, samples/s: 845.759 1613158231.3853946
train: epoch 125, iter 700, loss: 2.088511, top_1: 0.745898, top_k: 0.907773, samples/s: 847.053 1613158261.6078994
train: epoch 125, iter 800, loss: 1.964150, top_1: 0.745273, top_k: 0.908633, samples/s: 850.105 1613158291.7218008
train: epoch 125, iter 900, loss: 2.045352, top_1: 0.743789, top_k: 0.905625, samples/s: 845.578 1613158321.996893
train: epoch 125, iter 1000, loss: 2.185183, top_1: 0.738867, top_k: 0.904648, samples/s: 849.951 1613158352.116277
train: epoch 125, iter 1100, loss: 2.267515, top_1: 0.738789, top_k: 0.901758, samples/s: 850.518 1613158382.215645
train: epoch 125, iter 1200, loss: 2.011783, top_1: 0.746797, top_k: 0.907852, samples/s: 846.478 1613158412.458624
train: epoch 125, iter 1300, loss: 2.020972, top_1: 0.744570, top_k: 0.906133, samples/s: 848.104 1613158442.643585
train: epoch 125, iter 1400, loss: 2.036309, top_1: 0.741094, top_k: 0.908438, samples/s: 848.854 1613158472.8019435
train: epoch 125, iter 1500, loss: 2.062929, top_1: 0.742305, top_k: 0.904062, samples/s: 849.140 1613158502.9500322
train: epoch 125, iter 1600, loss: 2.058592, top_1: 0.739883, top_k: 0.904766, samples/s: 846.567 1613158533.1898944
train: epoch 125, iter 1700, loss: 1.964914, top_1: 0.740508, top_k: 0.904727, samples/s: 849.814 1613158563.3140821
train: epoch 125, iter 1800, loss: 2.201014, top_1: 0.744297, top_k: 0.905000, samples/s: 848.123 1613158593.4983943
train: epoch 125, iter 1900, loss: 2.114923, top_1: 0.739180, top_k: 0.905430, samples/s: 849.436 1613158623.6361003
train: epoch 125, iter 2000, loss: 1.905997, top_1: 0.739023, top_k: 0.904609, samples/s: 847.243 1613158653.8516986
train: epoch 125, iter 2100, loss: 2.166406, top_1: 0.742109, top_k: 0.904766, samples/s: 846.984 1613158684.0765972
train: epoch 125, iter 2200, loss: 2.006522, top_1: 0.742227, top_k: 0.905352, samples/s: 850.666 1613158714.1706908
train: epoch 125, iter 2300, loss: 1.997266, top_1: 0.742422, top_k: 0.905039, samples/s: 847.883 1613158744.3635464
train: epoch 125, iter 2400, loss: 2.096462, top_1: 0.737578, top_k: 0.902578, samples/s: 849.722 1613158774.4910183
train: epoch 125, iter 2500, loss: 2.188847, top_1: 0.737656, top_k: 0.903203, samples/s: 847.841 1613158804.6853232
train: epoch 125, iter 2600, loss: 2.161363, top_1: 0.739609, top_k: 0.906445, samples/s: 848.153 1613158834.8685074
train: epoch 125, iter 2700, loss: 2.080998, top_1: 0.740938, top_k: 0.905664, samples/s: 850.855 1613158864.9558923
train: epoch 125, iter 2800, loss: 2.067168, top_1: 0.743828, top_k: 0.905820, samples/s: 844.799 1613158895.2590373
train: epoch 125, iter 2900, loss: 1.891873, top_1: 0.746523, top_k: 0.905039, samples/s: 849.724 1613158925.3864248
train: epoch 125, iter 3000, loss: 2.130987, top_1: 0.738555, top_k: 0.902695, samples/s: 847.482 1613158955.5935
train: epoch 125, iter 3100, loss: 2.080357, top_1: 0.739805, top_k: 0.902930, samples/s: 846.430 1613158985.8381786
train: epoch 125, iter 3200, loss: 2.090796, top_1: 0.738711, top_k: 0.902188, samples/s: 850.070 1613159015.9533348
train: epoch 125, iter 3300, loss: 2.077889, top_1: 0.741367, top_k: 0.906563, samples/s: 847.255 1613159046.1685934
train: epoch 125, iter 3400, loss: 2.088901, top_1: 0.738945, top_k: 0.905508, samples/s: 848.542 1613159076.3379896
train: epoch 125, iter 3500, loss: 2.215109, top_1: 0.736992, top_k: 0.903516, samples/s: 848.218 1613159106.5189767
train: epoch 125, iter 3600, loss: 2.160811, top_1: 0.741094, top_k: 0.904922, samples/s: 848.721 1613159136.6819162
train: epoch 125, iter 3700, loss: 2.175190, top_1: 0.739648, top_k: 0.902578, samples/s: 848.376 1613159166.857238
train: epoch 125, iter 3800, loss: 2.144989, top_1: 0.741719, top_k: 0.903594, samples/s: 848.169 1613159197.0399656
train: epoch 125, iter 3900, loss: 1.943620, top_1: 0.741641, top_k: 0.905859, samples/s: 849.411 1613159227.1785026
train: epoch 125, iter 4000, loss: 2.092838, top_1: 0.740430, top_k: 0.903828, samples/s: 850.787 1613159257.2683065
train: epoch 125, iter 4100, loss: 2.021052, top_1: 0.736680, top_k: 0.902734, samples/s: 845.887 1613159287.5322928
train: epoch 125, iter 4200, loss: 1.862153, top_1: 0.742539, top_k: 0.902305, samples/s: 846.653 1613159317.7691262
train: epoch 125, iter 4300, loss: 2.203999, top_1: 0.739102, top_k: 0.904492, samples/s: 848.676 1613159347.9337158
train: epoch 125, iter 4400, loss: 2.221304, top_1: 0.740156, top_k: 0.902969, samples/s: 845.905 1613159378.1971638
train: epoch 125, iter 4500, loss: 2.164158, top_1: 0.738984, top_k: 0.901836, samples/s: 848.251 1613159408.3768713
train: epoch 125, iter 4600, loss: 1.986471, top_1: 0.739492, top_k: 0.902617, samples/s: 850.074 1613159438.4919367
train: epoch 125, iter 4700, loss: 2.122592, top_1: 0.734688, top_k: 0.900703, samples/s: 849.155 1613159468.63954
train: epoch 125, iter 4800, loss: 2.112159, top_1: 0.740039, top_k: 0.902969, samples/s: 848.434 1613159498.8127997
train: epoch 125, iter 4900, loss: 2.083451, top_1: 0.734219, top_k: 0.899766, samples/s: 847.033 1613159529.0359576
train: epoch 125, iter 5000, loss: 1.858574, top_1: 0.747734, top_k: 0.910352, samples/s: 850.427 1613159559.138452
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_125.
validation: epoch 125, iter 195, top_1: 0.747316, top_k: 0.923678, samples/s: 2432.818 1613159580.5700953
train: epoch 126, iter 100, loss: 2.070922, top_1: 0.753672, top_k: 0.911211, samples/s: 870.301 1613159630.6163597
train: epoch 126, iter 200, loss: 2.182240, top_1: 0.753633, top_k: 0.909336, samples/s: 867.117 1613159660.1394558
train: epoch 126, iter 300, loss: 2.018448, top_1: 0.743672, top_k: 0.908672, samples/s: 851.423 1613159690.20678
train: epoch 126, iter 400, loss: 2.045578, top_1: 0.750391, top_k: 0.906680, samples/s: 847.599 1613159720.4097788
train: epoch 126, iter 500, loss: 1.950171, top_1: 0.750469, top_k: 0.910195, samples/s: 847.780 1613159750.6062732
train: epoch 126, iter 600, loss: 2.157230, top_1: 0.746758, top_k: 0.907188, samples/s: 845.363 1613159780.88909
train: epoch 126, iter 700, loss: 2.253280, top_1: 0.754531, top_k: 0.910859, samples/s: 847.551 1613159811.0937903
train: epoch 126, iter 800, loss: 2.110559, top_1: 0.751406, top_k: 0.907578, samples/s: 847.251 1613159841.3091052
train: epoch 126, iter 900, loss: 2.049190, top_1: 0.749883, top_k: 0.908125, samples/s: 847.399 1613159871.519173
train: epoch 126, iter 1000, loss: 1.910892, top_1: 0.751133, top_k: 0.908086, samples/s: 846.562 1613159901.7591748
train: epoch 126, iter 1100, loss: 2.059870, top_1: 0.753047, top_k: 0.908906, samples/s: 849.567 1613159931.892239
train: epoch 126, iter 1200, loss: 1.977112, top_1: 0.744219, top_k: 0.903984, samples/s: 845.002 1613159962.1879113
train: epoch 126, iter 1300, loss: 2.102283, top_1: 0.747266, top_k: 0.906563, samples/s: 850.323 1613159992.294232
train: epoch 126, iter 1400, loss: 2.055992, top_1: 0.745469, top_k: 0.905664, samples/s: 847.548 1613160022.4988854
train: epoch 126, iter 1500, loss: 1.879993, top_1: 0.749258, top_k: 0.907813, samples/s: 847.619 1613160052.7011254
train: epoch 126, iter 1600, loss: 2.048076, top_1: 0.748359, top_k: 0.908125, samples/s: 847.505 1613160082.90743
train: epoch 126, iter 1700, loss: 2.006729, top_1: 0.746758, top_k: 0.909219, samples/s: 845.662 1613160113.1795702
train: epoch 126, iter 1800, loss: 2.027958, top_1: 0.744297, top_k: 0.905977, samples/s: 850.847 1613160143.2673743
train: epoch 126, iter 1900, loss: 2.082760, top_1: 0.748984, top_k: 0.906680, samples/s: 847.492 1613160173.4741292
train: epoch 126, iter 2000, loss: 2.090668, top_1: 0.741211, top_k: 0.905352, samples/s: 848.811 1613160203.6339195
train: epoch 126, iter 2100, loss: 2.000169, top_1: 0.744219, top_k: 0.905820, samples/s: 850.047 1613160233.749859
train: epoch 126, iter 2200, loss: 2.006881, top_1: 0.747383, top_k: 0.907656, samples/s: 846.891 1613160263.978142
train: epoch 126, iter 2300, loss: 2.138673, top_1: 0.741914, top_k: 0.907031, samples/s: 847.906 1613160294.170212
train: epoch 126, iter 2400, loss: 2.012080, top_1: 0.745742, top_k: 0.906055, samples/s: 848.190 1613160324.3520153
train: epoch 126, iter 2500, loss: 2.116770, top_1: 0.744609, top_k: 0.905703, samples/s: 848.976 1613160354.5059893
train: epoch 126, iter 2600, loss: 1.984770, top_1: 0.740000, top_k: 0.902578, samples/s: 846.240 1613160384.7574522
train: epoch 126, iter 2700, loss: 2.089277, top_1: 0.743164, top_k: 0.904883, samples/s: 851.902 1613160414.8078625
train: epoch 126, iter 2800, loss: 2.263423, top_1: 0.744727, top_k: 0.908750, samples/s: 847.796 1613160445.0038435
train: epoch 126, iter 2900, loss: 2.286423, top_1: 0.741719, top_k: 0.904531, samples/s: 852.793 1613160475.0228093
train: epoch 126, iter 3000, loss: 1.840992, top_1: 0.745391, top_k: 0.904687, samples/s: 847.317 1613160505.2358365
train: epoch 126, iter 3100, loss: 2.171780, top_1: 0.742500, top_k: 0.903398, samples/s: 850.376 1613160535.3402097
train: epoch 126, iter 3200, loss: 2.063376, top_1: 0.744180, top_k: 0.904102, samples/s: 847.674 1613160565.5404742
train: epoch 126, iter 3300, loss: 1.961864, top_1: 0.746797, top_k: 0.905117, samples/s: 850.580 1613160595.6375716
train: epoch 126, iter 3400, loss: 1.978239, top_1: 0.743711, top_k: 0.902305, samples/s: 849.034 1613160625.7895389
train: epoch 126, iter 3500, loss: 2.002838, top_1: 0.742305, top_k: 0.902617, samples/s: 847.400 1613160655.9995549
train: epoch 126, iter 3600, loss: 1.999691, top_1: 0.744102, top_k: 0.907852, samples/s: 849.373 1613160686.1394777
train: epoch 126, iter 3700, loss: 1.999777, top_1: 0.743047, top_k: 0.905820, samples/s: 844.987 1613160716.4357526
train: epoch 126, iter 3800, loss: 1.977610, top_1: 0.740625, top_k: 0.905820, samples/s: 851.959 1613160746.4841413
train: epoch 126, iter 3900, loss: 1.953092, top_1: 0.746758, top_k: 0.905664, samples/s: 849.978 1613160776.6026044
train: epoch 126, iter 4000, loss: 2.126257, top_1: 0.745781, top_k: 0.907305, samples/s: 848.372 1613160806.7779856
train: epoch 126, iter 4100, loss: 2.052167, top_1: 0.742344, top_k: 0.908633, samples/s: 847.303 1613160836.9916017
train: epoch 126, iter 4200, loss: 2.056088, top_1: 0.748672, top_k: 0.905000, samples/s: 848.256 1613160867.1710715
train: epoch 126, iter 4300, loss: 1.934849, top_1: 0.738750, top_k: 0.907070, samples/s: 850.079 1613160897.2860281
train: epoch 126, iter 4400, loss: 2.187639, top_1: 0.742578, top_k: 0.907344, samples/s: 849.159 1613160927.4335186
train: epoch 126, iter 4500, loss: 2.116963, top_1: 0.735117, top_k: 0.906016, samples/s: 847.516 1613160957.639358
train: epoch 126, iter 4600, loss: 2.048898, top_1: 0.748906, top_k: 0.910000, samples/s: 847.677 1613160987.839523
train: epoch 126, iter 4700, loss: 2.027977, top_1: 0.746055, top_k: 0.905195, samples/s: 846.870 1613161018.0685773
train: epoch 126, iter 4800, loss: 2.209567, top_1: 0.737930, top_k: 0.905000, samples/s: 848.195 1613161048.2502239
train: epoch 126, iter 4900, loss: 2.061249, top_1: 0.742305, top_k: 0.905039, samples/s: 847.892 1613161078.4428294
train: epoch 126, iter 5000, loss: 1.939752, top_1: 0.751055, top_k: 0.907266, samples/s: 847.598 1613161108.6457257
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_126.
validation: epoch 126, iter 195, top_1: 0.752965, top_k: 0.926362, samples/s: 2461.185 1613161129.818649
train: epoch 127, iter 100, loss: 2.124144, top_1: 0.751250, top_k: 0.910000, samples/s: 871.860 1613161179.797354
train: epoch 127, iter 200, loss: 1.924411, top_1: 0.755234, top_k: 0.911484, samples/s: 868.767 1613161209.2643256
train: epoch 127, iter 300, loss: 1.983590, top_1: 0.751992, top_k: 0.910742, samples/s: 855.128 1613161239.201426
train: epoch 127, iter 400, loss: 1.867479, top_1: 0.753828, top_k: 0.908984, samples/s: 846.769 1613161269.433966
train: epoch 127, iter 500, loss: 2.029056, top_1: 0.749648, top_k: 0.908906, samples/s: 845.901 1613161299.6975832
train: epoch 127, iter 600, loss: 2.067815, top_1: 0.754570, top_k: 0.910352, samples/s: 848.139 1613161329.8814137
train: epoch 127, iter 700, loss: 2.035426, top_1: 0.759219, top_k: 0.911094, samples/s: 847.184 1613161360.0990238
train: epoch 127, iter 800, loss: 2.010947, top_1: 0.751133, top_k: 0.908555, samples/s: 847.157 1613161390.3178327
train: epoch 127, iter 900, loss: 2.004394, top_1: 0.750156, top_k: 0.908477, samples/s: 848.102 1613161420.5028353
train: epoch 127, iter 1000, loss: 2.007223, top_1: 0.750391, top_k: 0.909180, samples/s: 849.149 1613161450.6506677
train: epoch 127, iter 1100, loss: 1.934673, top_1: 0.752305, top_k: 0.910703, samples/s: 843.950 1613161480.9841864
train: epoch 127, iter 1200, loss: 1.920984, top_1: 0.751641, top_k: 0.908516, samples/s: 848.265 1613161511.1635122
train: epoch 127, iter 1300, loss: 2.051314, top_1: 0.750234, top_k: 0.909375, samples/s: 848.922 1613161541.319443
train: epoch 127, iter 1400, loss: 2.022223, top_1: 0.746836, top_k: 0.908750, samples/s: 846.249 1613161571.5704856
train: epoch 127, iter 1500, loss: 1.995015, top_1: 0.745430, top_k: 0.906953, samples/s: 850.197 1613161601.6811905
train: epoch 127, iter 1600, loss: 2.039607, top_1: 0.746367, top_k: 0.908672, samples/s: 846.300 1613161631.9306097
train: epoch 127, iter 1700, loss: 2.060145, top_1: 0.752812, top_k: 0.909375, samples/s: 851.461 1613161661.996579
train: epoch 127, iter 1800, loss: 1.908784, top_1: 0.752891, top_k: 0.908984, samples/s: 849.774 1613161692.122145
train: epoch 127, iter 1900, loss: 2.039107, top_1: 0.745078, top_k: 0.907227, samples/s: 847.244 1613161722.337795
train: epoch 127, iter 2000, loss: 1.823222, top_1: 0.748203, top_k: 0.909531, samples/s: 844.861 1613161752.638605
train: epoch 127, iter 2100, loss: 2.145206, top_1: 0.747773, top_k: 0.911953, samples/s: 853.838 1613161782.6209161
train: epoch 127, iter 2200, loss: 1.941550, top_1: 0.744336, top_k: 0.908242, samples/s: 847.496 1613161812.827559
train: epoch 127, iter 2300, loss: 1.989435, top_1: 0.746484, top_k: 0.908477, samples/s: 848.771 1613161842.988929
train: epoch 127, iter 2400, loss: 2.010051, top_1: 0.750977, top_k: 0.910078, samples/s: 851.173 1613161873.064994
train: epoch 127, iter 2500, loss: 2.203022, top_1: 0.747539, top_k: 0.908945, samples/s: 847.083 1613161903.2863593
train: epoch 127, iter 2600, loss: 2.096810, top_1: 0.744102, top_k: 0.906328, samples/s: 849.965 1613161933.4052677
train: epoch 127, iter 2700, loss: 2.175338, top_1: 0.748984, top_k: 0.908906, samples/s: 850.743 1613161963.4965265
train: epoch 127, iter 2800, loss: 2.080335, top_1: 0.747070, top_k: 0.908711, samples/s: 846.513 1613161993.738326
train: epoch 127, iter 2900, loss: 2.099617, top_1: 0.748672, top_k: 0.905508, samples/s: 851.810 1613162023.7919693
train: epoch 127, iter 3000, loss: 2.006518, top_1: 0.743750, top_k: 0.905352, samples/s: 847.866 1613162053.9853907
train: epoch 127, iter 3100, loss: 1.952986, top_1: 0.747422, top_k: 0.909648, samples/s: 850.043 1613162084.1015172
train: epoch 127, iter 3200, loss: 2.192744, top_1: 0.746523, top_k: 0.906055, samples/s: 846.979 1613162114.3265734
train: epoch 127, iter 3300, loss: 1.862567, top_1: 0.751758, top_k: 0.908438, samples/s: 851.776 1613162144.3813632
train: epoch 127, iter 3400, loss: 1.881771, top_1: 0.752148, top_k: 0.908906, samples/s: 847.993 1613162174.5702848
train: epoch 127, iter 3500, loss: 2.059824, top_1: 0.747461, top_k: 0.908086, samples/s: 847.751 1613162204.7678008
train: epoch 127, iter 3600, loss: 2.095396, top_1: 0.743945, top_k: 0.907109, samples/s: 847.980 1613162234.9572468
train: epoch 127, iter 3700, loss: 2.109293, top_1: 0.750195, top_k: 0.910195, samples/s: 845.920 1613162265.2201416
train: epoch 127, iter 3800, loss: 2.020667, top_1: 0.749414, top_k: 0.907734, samples/s: 848.041 1613162295.407419
train: epoch 127, iter 3900, loss: 2.013190, top_1: 0.749766, top_k: 0.908164, samples/s: 847.927 1613162325.5985982
train: epoch 127, iter 4000, loss: 2.126439, top_1: 0.739961, top_k: 0.905117, samples/s: 845.997 1613162355.8587847
train: epoch 127, iter 4100, loss: 1.918990, top_1: 0.745508, top_k: 0.908047, samples/s: 851.642 1613162385.9184215
train: epoch 127, iter 4200, loss: 2.023080, top_1: 0.748672, top_k: 0.911055, samples/s: 848.839 1613162416.0772731
train: epoch 127, iter 4300, loss: 2.137105, top_1: 0.744766, top_k: 0.907344, samples/s: 847.134 1613162446.296733
train: epoch 127, iter 4400, loss: 1.999578, top_1: 0.745703, top_k: 0.906172, samples/s: 847.475 1613162476.5042071
train: epoch 127, iter 4500, loss: 2.083012, top_1: 0.748516, top_k: 0.911055, samples/s: 849.560 1613162506.6374416
train: epoch 127, iter 4600, loss: 1.934481, top_1: 0.743437, top_k: 0.905508, samples/s: 847.093 1613162536.8583796
train: epoch 127, iter 4700, loss: 2.000675, top_1: 0.744219, top_k: 0.904414, samples/s: 849.697 1613162566.98685
train: epoch 127, iter 4800, loss: 2.118634, top_1: 0.743008, top_k: 0.904727, samples/s: 849.327 1613162597.1283064
train: epoch 127, iter 4900, loss: 2.015365, top_1: 0.746016, top_k: 0.904023, samples/s: 851.007 1613162627.2102633
train: epoch 127, iter 5000, loss: 1.970701, top_1: 0.752344, top_k: 0.907930, samples/s: 846.347 1613162657.457962
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_127.
validation: epoch 127, iter 195, top_1: 0.752284, top_k: 0.928125, samples/s: 2422.547 1613162678.9429753
train: epoch 128, iter 100, loss: 2.030473, top_1: 0.763594, top_k: 0.914570, samples/s: 871.332 1613162728.7992978
train: epoch 128, iter 200, loss: 1.881441, top_1: 0.758828, top_k: 0.911836, samples/s: 867.500 1613162758.3093433
train: epoch 128, iter 300, loss: 1.969348, top_1: 0.761953, top_k: 0.914570, samples/s: 855.087 1613162788.2477577
train: epoch 128, iter 400, loss: 2.013007, top_1: 0.752070, top_k: 0.913438, samples/s: 847.334 1613162818.4600997
train: epoch 128, iter 500, loss: 2.044011, top_1: 0.751055, top_k: 0.910898, samples/s: 846.449 1613162848.7041361
train: epoch 128, iter 600, loss: 2.009903, top_1: 0.754023, top_k: 0.910547, samples/s: 847.569 1613162878.90819
train: epoch 128, iter 700, loss: 1.987114, top_1: 0.757461, top_k: 0.914609, samples/s: 846.319 1613162909.156864
train: epoch 128, iter 800, loss: 2.203551, top_1: 0.753867, top_k: 0.913594, samples/s: 846.083 1613162939.413955
train: epoch 128, iter 900, loss: 1.973824, top_1: 0.752695, top_k: 0.908672, samples/s: 845.771 1613162969.6821468
train: epoch 128, iter 1000, loss: 2.056163, top_1: 0.754453, top_k: 0.912969, samples/s: 849.398 1613162999.8211348
train: epoch 128, iter 1100, loss: 2.009407, top_1: 0.753437, top_k: 0.909453, samples/s: 847.081 1613163030.0426636
train: epoch 128, iter 1200, loss: 2.025475, top_1: 0.756055, top_k: 0.911953, samples/s: 849.592 1613163060.174762
train: epoch 128, iter 1300, loss: 1.944512, top_1: 0.751484, top_k: 0.909062, samples/s: 847.286 1613163090.388886
train: epoch 128, iter 1400, loss: 2.190897, top_1: 0.753633, top_k: 0.907109, samples/s: 846.969 1613163120.6143284
train: epoch 128, iter 1500, loss: 2.003874, top_1: 0.752930, top_k: 0.910469, samples/s: 844.858 1613163150.9151819
train: epoch 128, iter 1600, loss: 1.974228, top_1: 0.752617, top_k: 0.910977, samples/s: 849.506 1613163181.0504012
train: epoch 128, iter 1700, loss: 2.020209, top_1: 0.755078, top_k: 0.912578, samples/s: 851.469 1613163211.116135
train: epoch 128, iter 1800, loss: 2.075104, top_1: 0.755195, top_k: 0.909648, samples/s: 846.632 1613163241.3535757
train: epoch 128, iter 1900, loss: 2.226832, top_1: 0.756289, top_k: 0.914375, samples/s: 847.596 1613163271.5566757
train: epoch 128, iter 2000, loss: 2.015371, top_1: 0.755898, top_k: 0.912148, samples/s: 846.819 1613163301.787391
train: epoch 128, iter 2100, loss: 1.961430, top_1: 0.751523, top_k: 0.911367, samples/s: 848.070 1613163331.9735749
train: epoch 128, iter 2200, loss: 2.186604, top_1: 0.751016, top_k: 0.907227, samples/s: 849.236 1613163362.1182752
train: epoch 128, iter 2300, loss: 2.001272, top_1: 0.751133, top_k: 0.910039, samples/s: 849.115 1613163392.2673101
train: epoch 128, iter 2400, loss: 1.894624, top_1: 0.753672, top_k: 0.909570, samples/s: 848.032 1613163422.4549224
train: epoch 128, iter 2500, loss: 2.152678, top_1: 0.752461, top_k: 0.908906, samples/s: 850.251 1613163452.5636
train: epoch 128, iter 2600, loss: 1.999267, top_1: 0.751836, top_k: 0.909141, samples/s: 848.085 1613163482.7493932
train: epoch 128, iter 2700, loss: 2.059864, top_1: 0.751523, top_k: 0.909492, samples/s: 848.943 1613163512.9044352
train: epoch 128, iter 2800, loss: 2.074180, top_1: 0.747500, top_k: 0.907734, samples/s: 846.990 1613163543.1290867
train: epoch 128, iter 2900, loss: 1.965063, top_1: 0.749727, top_k: 0.907344, samples/s: 847.474 1613163573.336517
train: epoch 128, iter 3000, loss: 1.995491, top_1: 0.749883, top_k: 0.910820, samples/s: 851.104 1613163603.4150727
train: epoch 128, iter 3100, loss: 2.151377, top_1: 0.748242, top_k: 0.908906, samples/s: 846.064 1613163633.6728718
train: epoch 128, iter 3200, loss: 2.088121, top_1: 0.746250, top_k: 0.907109, samples/s: 850.212 1613163663.7829745
train: epoch 128, iter 3300, loss: 2.096787, top_1: 0.752773, top_k: 0.909375, samples/s: 846.867 1613163694.0121584
train: epoch 128, iter 3400, loss: 1.915970, top_1: 0.752812, top_k: 0.909141, samples/s: 849.255 1613163724.1561868
train: epoch 128, iter 3500, loss: 2.084212, top_1: 0.751016, top_k: 0.911602, samples/s: 847.677 1613163754.3564224
train: epoch 128, iter 3600, loss: 2.118064, top_1: 0.754570, top_k: 0.909648, samples/s: 846.753 1613163784.5895238
train: epoch 128, iter 3700, loss: 2.124066, top_1: 0.750664, top_k: 0.910156, samples/s: 849.535 1613163814.7236772
train: epoch 128, iter 3800, loss: 1.983508, top_1: 0.748594, top_k: 0.908164, samples/s: 848.376 1613163844.8989847
train: epoch 128, iter 3900, loss: 2.000460, top_1: 0.749727, top_k: 0.909844, samples/s: 850.210 1613163875.0091522
train: epoch 128, iter 4000, loss: 1.807451, top_1: 0.749375, top_k: 0.905625, samples/s: 846.861 1613163905.238442
train: epoch 128, iter 4100, loss: 1.973585, top_1: 0.751328, top_k: 0.909023, samples/s: 846.941 1613163935.4648778
train: epoch 128, iter 4200, loss: 1.960155, top_1: 0.748086, top_k: 0.909961, samples/s: 848.822 1613163965.624302
train: epoch 128, iter 4300, loss: 1.974870, top_1: 0.748281, top_k: 0.907070, samples/s: 847.812 1613163995.8196635
train: epoch 128, iter 4400, loss: 2.012123, top_1: 0.748516, top_k: 0.908125, samples/s: 848.719 1613164025.982837
train: epoch 128, iter 4500, loss: 2.038198, top_1: 0.751289, top_k: 0.907109, samples/s: 848.199 1613164056.1643732
train: epoch 128, iter 4600, loss: 2.080680, top_1: 0.752930, top_k: 0.911289, samples/s: 850.862 1613164086.2514415
train: epoch 128, iter 4700, loss: 2.014959, top_1: 0.747578, top_k: 0.909453, samples/s: 848.646 1613164116.4172451
train: epoch 128, iter 4800, loss: 2.000981, top_1: 0.752070, top_k: 0.908164, samples/s: 848.678 1613164146.5816994
train: epoch 128, iter 4900, loss: 2.035247, top_1: 0.745078, top_k: 0.907148, samples/s: 847.972 1613164176.771469
train: epoch 128, iter 5000, loss: 1.838514, top_1: 0.756680, top_k: 0.910742, samples/s: 848.690 1613164206.9355752
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_128.
validation: epoch 128, iter 195, top_1: 0.754928, top_k: 0.926843, samples/s: 2477.365 1613164227.9827137
train: epoch 129, iter 100, loss: 2.163245, top_1: 0.757422, top_k: 0.912266, samples/s: 870.069 1613164278.9071891
train: epoch 129, iter 200, loss: 2.033764, top_1: 0.758086, top_k: 0.913164, samples/s: 869.509 1613164308.349158
train: epoch 129, iter 300, loss: 1.941223, top_1: 0.760742, top_k: 0.912305, samples/s: 852.794 1613164338.368076
train: epoch 129, iter 400, loss: 1.931449, top_1: 0.760391, top_k: 0.914922, samples/s: 848.347 1613164368.5444293
train: epoch 129, iter 500, loss: 2.079959, top_1: 0.759219, top_k: 0.913086, samples/s: 850.215 1613164398.6544595
train: epoch 129, iter 600, loss: 2.053366, top_1: 0.759141, top_k: 0.913516, samples/s: 844.979 1613164428.951039
train: epoch 129, iter 700, loss: 1.967108, top_1: 0.753320, top_k: 0.912344, samples/s: 847.524 1613164459.1566312
train: epoch 129, iter 800, loss: 1.870418, top_1: 0.756602, top_k: 0.913945, samples/s: 848.948 1613164489.3115673
train: epoch 129, iter 900, loss: 1.998552, top_1: 0.762461, top_k: 0.911250, samples/s: 850.687 1613164519.4049497
train: epoch 129, iter 1000, loss: 2.016629, top_1: 0.757969, top_k: 0.911836, samples/s: 849.971 1613164549.523587
train: epoch 129, iter 1100, loss: 2.003157, top_1: 0.758359, top_k: 0.910430, samples/s: 847.045 1613164579.7463932
train: epoch 129, iter 1200, loss: 1.927087, top_1: 0.756797, top_k: 0.911602, samples/s: 850.910 1613164609.8317006
train: epoch 129, iter 1300, loss: 2.036671, top_1: 0.759766, top_k: 0.914414, samples/s: 849.229 1613164639.9767754
train: epoch 129, iter 1400, loss: 1.896266, top_1: 0.756641, top_k: 0.913828, samples/s: 846.150 1613164670.2314358
train: epoch 129, iter 1500, loss: 2.057063, top_1: 0.755352, top_k: 0.911094, samples/s: 847.827 1613164700.4262471
train: epoch 129, iter 1600, loss: 1.884189, top_1: 0.756836, top_k: 0.910273, samples/s: 849.224 1613164730.5714233
train: epoch 129, iter 1700, loss: 1.978410, top_1: 0.754219, top_k: 0.913516, samples/s: 849.375 1613164760.7111864
train: epoch 129, iter 1800, loss: 2.000922, top_1: 0.751563, top_k: 0.909961, samples/s: 850.088 1613164790.8257704
train: epoch 129, iter 1900, loss: 1.943780, top_1: 0.758164, top_k: 0.913828, samples/s: 849.485 1613164820.9616694
train: epoch 129, iter 2000, loss: 1.951995, top_1: 0.748398, top_k: 0.908750, samples/s: 849.444 1613164851.098993
train: epoch 129, iter 2100, loss: 2.022214, top_1: 0.757227, top_k: 0.912266, samples/s: 846.133 1613164881.3542938
train: epoch 129, iter 2200, loss: 2.094891, top_1: 0.745625, top_k: 0.905117, samples/s: 852.614 1613164911.3796124
train: epoch 129, iter 2300, loss: 2.111960, top_1: 0.754727, top_k: 0.910586, samples/s: 846.038 1613164941.6383579
train: epoch 129, iter 2400, loss: 1.861774, top_1: 0.759609, top_k: 0.913047, samples/s: 851.604 1613164971.6992319
train: epoch 129, iter 2500, loss: 2.051549, top_1: 0.755156, top_k: 0.911055, samples/s: 846.844 1613165001.9291615
train: epoch 129, iter 2600, loss: 2.037576, top_1: 0.754023, top_k: 0.909219, samples/s: 848.070 1613165032.1153479
train: epoch 129, iter 2700, loss: 1.892839, top_1: 0.753047, top_k: 0.907188, samples/s: 848.627 1613165062.2822685
train: epoch 129, iter 2800, loss: 2.152541, top_1: 0.756836, top_k: 0.913086, samples/s: 847.983 1613165092.4709992
train: epoch 129, iter 2900, loss: 1.965575, top_1: 0.753398, top_k: 0.911328, samples/s: 848.280 1613165122.6500251
train: epoch 129, iter 3000, loss: 1.947380, top_1: 0.761523, top_k: 0.912617, samples/s: 848.983 1613165152.8033855
train: epoch 129, iter 3100, loss: 1.900687, top_1: 0.753164, top_k: 0.910625, samples/s: 851.398 1613165182.8716288
train: epoch 129, iter 3200, loss: 1.867785, top_1: 0.753242, top_k: 0.909453, samples/s: 849.130 1613165213.0200996
train: epoch 129, iter 3300, loss: 2.133584, top_1: 0.751016, top_k: 0.910352, samples/s: 849.121 1613165243.1689901
train: epoch 129, iter 3400, loss: 2.121339, top_1: 0.747812, top_k: 0.910117, samples/s: 848.437 1613165273.342129
train: epoch 129, iter 3500, loss: 1.955049, top_1: 0.752383, top_k: 0.910977, samples/s: 849.570 1613165303.474961
train: epoch 129, iter 3600, loss: 1.997303, top_1: 0.750547, top_k: 0.914609, samples/s: 849.767 1613165333.600811
train: epoch 129, iter 3700, loss: 1.957865, top_1: 0.751055, top_k: 0.909297, samples/s: 844.317 1613165363.9212925
train: epoch 129, iter 3800, loss: 2.114252, top_1: 0.755273, top_k: 0.911172, samples/s: 851.335 1613165393.9916587
train: epoch 129, iter 3900, loss: 1.971536, top_1: 0.754219, top_k: 0.910859, samples/s: 846.930 1613165424.2184932
train: epoch 129, iter 4000, loss: 2.090920, top_1: 0.758906, top_k: 0.911602, samples/s: 843.542 1613165454.566756
train: epoch 129, iter 4100, loss: 1.892742, top_1: 0.752578, top_k: 0.907305, samples/s: 853.267 1613165484.5696585
train: epoch 129, iter 4200, loss: 1.975626, top_1: 0.745664, top_k: 0.908867, samples/s: 849.103 1613165514.7185297
train: epoch 129, iter 4300, loss: 1.953437, top_1: 0.751016, top_k: 0.909375, samples/s: 850.265 1613165544.8271272
train: epoch 129, iter 4400, loss: 2.063497, top_1: 0.749922, top_k: 0.908711, samples/s: 850.097 1613165574.940939
train: epoch 129, iter 4500, loss: 1.934339, top_1: 0.753320, top_k: 0.908359, samples/s: 847.925 1613165605.1322842
train: epoch 129, iter 4600, loss: 1.963322, top_1: 0.752969, top_k: 0.908281, samples/s: 847.723 1613165635.3308349
train: epoch 129, iter 4700, loss: 2.111549, top_1: 0.753984, top_k: 0.912188, samples/s: 848.418 1613165665.504629
train: epoch 129, iter 4800, loss: 2.086920, top_1: 0.754414, top_k: 0.909570, samples/s: 851.323 1613165695.5755382
train: epoch 129, iter 4900, loss: 2.043993, top_1: 0.750547, top_k: 0.907227, samples/s: 850.116 1613165725.6890469
train: epoch 129, iter 5000, loss: 1.867888, top_1: 0.762539, top_k: 0.915781, samples/s: 848.505 1613165755.8597891
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_129.
validation: epoch 129, iter 195, top_1: 0.756811, top_k: 0.927244, samples/s: 2402.429 1613165777.5470703
train: epoch 130, iter 100, loss: 2.046378, top_1: 0.761563, top_k: 0.915625, samples/s: 870.714 1613165827.3983536
train: epoch 130, iter 200, loss: 2.025104, top_1: 0.761523, top_k: 0.913594, samples/s: 868.775 1613165856.8651428
train: epoch 130, iter 300, loss: 2.125177, top_1: 0.759180, top_k: 0.916523, samples/s: 855.200 1613165886.799647
train: epoch 130, iter 400, loss: 2.178806, top_1: 0.762930, top_k: 0.912773, samples/s: 848.617 1613165916.96634
train: epoch 130, iter 500, loss: 1.949650, top_1: 0.762031, top_k: 0.913438, samples/s: 848.178 1613165947.1486952
train: epoch 130, iter 600, loss: 1.928651, top_1: 0.761250, top_k: 0.912031, samples/s: 846.898 1613165977.37663
train: epoch 130, iter 700, loss: 2.058215, top_1: 0.763828, top_k: 0.915937, samples/s: 848.516 1613166007.5469847
train: epoch 130, iter 800, loss: 1.954983, top_1: 0.758711, top_k: 0.914531, samples/s: 846.712 1613166037.7815285
train: epoch 130, iter 900, loss: 2.092091, top_1: 0.761875, top_k: 0.918359, samples/s: 849.185 1613166067.9280868
train: epoch 130, iter 1000, loss: 1.951635, top_1: 0.761602, top_k: 0.914453, samples/s: 851.642 1613166097.9877217
train: epoch 130, iter 1100, loss: 2.012297, top_1: 0.757578, top_k: 0.911719, samples/s: 844.361 1613166128.3064458
train: epoch 130, iter 1200, loss: 2.008588, top_1: 0.754844, top_k: 0.910586, samples/s: 848.499 1613166158.4773858
train: epoch 130, iter 1300, loss: 1.949764, top_1: 0.761563, top_k: 0.915430, samples/s: 849.915 1613166188.598089
train: epoch 130, iter 1400, loss: 2.185393, top_1: 0.757812, top_k: 0.912461, samples/s: 847.859 1613166218.7918048
train: epoch 130, iter 1500, loss: 1.918592, top_1: 0.762109, top_k: 0.915469, samples/s: 849.922 1613166248.9122615
train: epoch 130, iter 1600, loss: 1.989551, top_1: 0.761523, top_k: 0.915273, samples/s: 847.588 1613166279.1155362
train: epoch 130, iter 1700, loss: 1.885317, top_1: 0.757891, top_k: 0.913008, samples/s: 843.591 1613166309.461969
train: epoch 130, iter 1800, loss: 2.124188, top_1: 0.760508, top_k: 0.914453, samples/s: 849.953 1613166339.581282
train: epoch 130, iter 1900, loss: 1.891675, top_1: 0.767422, top_k: 0.915352, samples/s: 850.319 1613166369.6877315
train: epoch 130, iter 2000, loss: 2.084373, top_1: 0.758359, top_k: 0.912461, samples/s: 846.760 1613166399.9206111
train: epoch 130, iter 2100, loss: 1.908780, top_1: 0.763008, top_k: 0.915703, samples/s: 847.854 1613166430.1145594
train: epoch 130, iter 2200, loss: 1.930285, top_1: 0.756680, top_k: 0.911953, samples/s: 849.247 1613166460.2588024
train: epoch 130, iter 2300, loss: 1.993193, top_1: 0.757734, top_k: 0.912227, samples/s: 848.750 1613166490.4207673
train: epoch 130, iter 2400, loss: 2.157478, top_1: 0.754141, top_k: 0.911523, samples/s: 849.351 1613166520.561486
train: epoch 130, iter 2500, loss: 1.932495, top_1: 0.758633, top_k: 0.910859, samples/s: 845.001 1613166550.8573527
train: epoch 130, iter 2600, loss: 1.782639, top_1: 0.756758, top_k: 0.913516, samples/s: 849.783 1613166580.982558
train: epoch 130, iter 2700, loss: 1.916402, top_1: 0.758516, top_k: 0.912344, samples/s: 847.858 1613166611.1763563
train: epoch 130, iter 2800, loss: 1.974299, top_1: 0.755195, top_k: 0.913750, samples/s: 848.098 1613166641.362028
train: epoch 130, iter 2900, loss: 1.975254, top_1: 0.762461, top_k: 0.916914, samples/s: 849.272 1613166671.504964
train: epoch 130, iter 3000, loss: 2.014636, top_1: 0.757500, top_k: 0.911094, samples/s: 849.831 1613166701.6289182
train: epoch 130, iter 3100, loss: 2.016599, top_1: 0.760039, top_k: 0.914531, samples/s: 848.795 1613166731.7889855
train: epoch 130, iter 3200, loss: 2.102700, top_1: 0.761641, top_k: 0.915625, samples/s: 850.207 1613166761.8993077
train: epoch 130, iter 3300, loss: 2.132716, top_1: 0.754102, top_k: 0.911211, samples/s: 851.355 1613166791.9690368
train: epoch 130, iter 3400, loss: 1.994643, top_1: 0.756172, top_k: 0.913281, samples/s: 848.139 1613166822.1528008
train: epoch 130, iter 3500, loss: 2.051342, top_1: 0.756172, top_k: 0.910117, samples/s: 848.548 1613166852.321984
train: epoch 130, iter 3600, loss: 1.948520, top_1: 0.753555, top_k: 0.911875, samples/s: 849.360 1613166882.462295
train: epoch 130, iter 3700, loss: 1.978836, top_1: 0.752891, top_k: 0.909961, samples/s: 848.038 1613166912.6497142
train: epoch 130, iter 3800, loss: 2.008471, top_1: 0.755508, top_k: 0.913008, samples/s: 848.311 1613166942.8273287
train: epoch 130, iter 3900, loss: 1.919245, top_1: 0.757383, top_k: 0.912695, samples/s: 850.489 1613166972.927594
train: epoch 130, iter 4000, loss: 2.119299, top_1: 0.756992, top_k: 0.916445, samples/s: 850.598 1613167003.0240757
train: epoch 130, iter 4100, loss: 1.890248, top_1: 0.757695, top_k: 0.912227, samples/s: 849.340 1613167033.165317
train: epoch 130, iter 4200, loss: 2.211587, top_1: 0.753281, top_k: 0.912109, samples/s: 847.820 1613167063.3603592
train: epoch 130, iter 4300, loss: 2.201374, top_1: 0.760078, top_k: 0.914375, samples/s: 848.650 1613167093.5258787
train: epoch 130, iter 4400, loss: 2.077058, top_1: 0.758711, top_k: 0.913867, samples/s: 849.713 1613167123.653719
train: epoch 130, iter 4500, loss: 2.134291, top_1: 0.755352, top_k: 0.912344, samples/s: 849.867 1613167153.776035
train: epoch 130, iter 4600, loss: 2.035846, top_1: 0.755156, top_k: 0.911992, samples/s: 847.384 1613167183.9866962
train: epoch 130, iter 4700, loss: 1.939943, top_1: 0.756523, top_k: 0.911172, samples/s: 852.585 1613167214.0129783
train: epoch 130, iter 4800, loss: 2.192262, top_1: 0.751641, top_k: 0.909687, samples/s: 848.137 1613167244.1967938
train: epoch 130, iter 4900, loss: 1.855046, top_1: 0.757227, top_k: 0.910156, samples/s: 848.559 1613167274.3655787
train: epoch 130, iter 5000, loss: 1.905563, top_1: 0.761523, top_k: 0.913906, samples/s: 849.274 1613167304.509265
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_130.
validation: epoch 130, iter 195, top_1: 0.755729, top_k: 0.927885, samples/s: 2450.606 1613167325.7447352
train: epoch 131, iter 100, loss: 2.145978, top_1: 0.764023, top_k: 0.915742, samples/s: 868.553 1613167375.8271992
train: epoch 131, iter 200, loss: 2.107385, top_1: 0.768203, top_k: 0.918750, samples/s: 868.158 1613167405.3150594
train: epoch 131, iter 300, loss: 1.832220, top_1: 0.766641, top_k: 0.918828, samples/s: 853.063 1613167435.3244188
train: epoch 131, iter 400, loss: 2.000383, top_1: 0.763242, top_k: 0.916367, samples/s: 849.977 1613167465.442908
train: epoch 131, iter 500, loss: 1.989358, top_1: 0.763437, top_k: 0.916836, samples/s: 847.789 1613167495.6390498
train: epoch 131, iter 600, loss: 1.813487, top_1: 0.764414, top_k: 0.916055, samples/s: 852.446 1613167525.670268
train: epoch 131, iter 700, loss: 2.059943, top_1: 0.770820, top_k: 0.918203, samples/s: 844.692 1613167555.9772732
train: epoch 131, iter 800, loss: 1.950648, top_1: 0.766875, top_k: 0.917070, samples/s: 848.217 1613167586.158221
train: epoch 131, iter 900, loss: 2.099067, top_1: 0.768164, top_k: 0.916914, samples/s: 849.228 1613167616.3032174
train: epoch 131, iter 1000, loss: 2.070576, top_1: 0.763828, top_k: 0.914414, samples/s: 849.448 1613167646.44039
train: epoch 131, iter 1100, loss: 1.939519, top_1: 0.767734, top_k: 0.918789, samples/s: 848.277 1613167676.6193125
train: epoch 131, iter 1200, loss: 1.909531, top_1: 0.770352, top_k: 0.917852, samples/s: 848.195 1613167706.8009534
train: epoch 131, iter 1300, loss: 2.086079, top_1: 0.760312, top_k: 0.915117, samples/s: 848.858 1613167736.9591534
train: epoch 131, iter 1400, loss: 2.075017, top_1: 0.766641, top_k: 0.918359, samples/s: 846.511 1613167767.2009394
train: epoch 131, iter 1500, loss: 2.107450, top_1: 0.763828, top_k: 0.914805, samples/s: 851.543 1613167797.2639976
train: epoch 131, iter 1600, loss: 1.909013, top_1: 0.762930, top_k: 0.915977, samples/s: 847.858 1613167827.4577267
train: epoch 131, iter 1700, loss: 1.939051, top_1: 0.760508, top_k: 0.918320, samples/s: 848.431 1613167857.6311028
train: epoch 131, iter 1800, loss: 1.907989, top_1: 0.760312, top_k: 0.915273, samples/s: 850.698 1613167887.7240593
train: epoch 131, iter 1900, loss: 2.086802, top_1: 0.761328, top_k: 0.915156, samples/s: 846.928 1613167917.9509602
train: epoch 131, iter 2000, loss: 2.265380, top_1: 0.755781, top_k: 0.913281, samples/s: 848.496 1613167948.1219158
train: epoch 131, iter 2100, loss: 1.940387, top_1: 0.759805, top_k: 0.915000, samples/s: 850.749 1613167978.2130997
train: epoch 131, iter 2200, loss: 2.002514, top_1: 0.760469, top_k: 0.914727, samples/s: 850.432 1613168008.3154237
train: epoch 131, iter 2300, loss: 2.031958, top_1: 0.764922, top_k: 0.917930, samples/s: 851.161 1613168038.3920093
train: epoch 131, iter 2400, loss: 2.033327, top_1: 0.756836, top_k: 0.912266, samples/s: 848.357 1613168068.5679345
train: epoch 131, iter 2500, loss: 2.052124, top_1: 0.762852, top_k: 0.916445, samples/s: 847.961 1613168098.758094
train: epoch 131, iter 2600, loss: 2.050658, top_1: 0.763125, top_k: 0.914062, samples/s: 846.851 1613168128.987725
train: epoch 131, iter 2700, loss: 2.038009, top_1: 0.760312, top_k: 0.915000, samples/s: 850.139 1613168159.100479
train: epoch 131, iter 2800, loss: 2.032707, top_1: 0.757852, top_k: 0.916055, samples/s: 851.967 1613168189.1484866
train: epoch 131, iter 2900, loss: 1.798133, top_1: 0.758633, top_k: 0.912266, samples/s: 849.072 1613168219.299111
train: epoch 131, iter 3000, loss: 2.028382, top_1: 0.760898, top_k: 0.913086, samples/s: 850.402 1613168249.4024355
train: epoch 131, iter 3100, loss: 1.982065, top_1: 0.763555, top_k: 0.913906, samples/s: 849.669 1613168279.5318766
train: epoch 131, iter 3200, loss: 1.861336, top_1: 0.759375, top_k: 0.911914, samples/s: 847.883 1613168309.7247841
train: epoch 131, iter 3300, loss: 1.898271, top_1: 0.761250, top_k: 0.913086, samples/s: 847.227 1613168339.941
train: epoch 131, iter 3400, loss: 2.014528, top_1: 0.762266, top_k: 0.916211, samples/s: 849.118 1613168370.0899231
train: epoch 131, iter 3500, loss: 1.867526, top_1: 0.757930, top_k: 0.914258, samples/s: 848.878 1613168400.2473955
train: epoch 131, iter 3600, loss: 2.109967, top_1: 0.756563, top_k: 0.912070, samples/s: 848.582 1613168430.4153771
train: epoch 131, iter 3700, loss: 2.107922, top_1: 0.759687, top_k: 0.914336, samples/s: 850.702 1613168460.5080502
train: epoch 131, iter 3800, loss: 2.022976, top_1: 0.754766, top_k: 0.911133, samples/s: 849.901 1613168490.6292858
train: epoch 131, iter 3900, loss: 1.848052, top_1: 0.760117, top_k: 0.916562, samples/s: 847.879 1613168520.8222337
train: epoch 131, iter 4000, loss: 1.957818, top_1: 0.761797, top_k: 0.914844, samples/s: 851.801 1613168550.8762739
train: epoch 131, iter 4100, loss: 1.959985, top_1: 0.757695, top_k: 0.910508, samples/s: 848.126 1613168581.060367
train: epoch 131, iter 4200, loss: 1.983521, top_1: 0.759062, top_k: 0.913906, samples/s: 851.020 1613168611.1419938
train: epoch 131, iter 4300, loss: 2.005238, top_1: 0.758242, top_k: 0.915781, samples/s: 846.285 1613168641.3918464
train: epoch 131, iter 4400, loss: 1.921245, top_1: 0.754570, top_k: 0.909102, samples/s: 850.481 1613168671.4923673
train: epoch 131, iter 4500, loss: 2.100348, top_1: 0.756953, top_k: 0.913750, samples/s: 848.946 1613168701.6474285
train: epoch 131, iter 4600, loss: 1.941501, top_1: 0.757500, top_k: 0.914258, samples/s: 851.555 1613168731.7101166
train: epoch 131, iter 4700, loss: 2.001843, top_1: 0.761680, top_k: 0.913828, samples/s: 848.083 1613168761.8958483
train: epoch 131, iter 4800, loss: 1.912655, top_1: 0.760117, top_k: 0.911758, samples/s: 850.532 1613168791.9947035
train: epoch 131, iter 4900, loss: 2.050922, top_1: 0.756875, top_k: 0.916172, samples/s: 852.302 1613168822.031014
train: epoch 131, iter 5000, loss: 1.900435, top_1: 0.768750, top_k: 0.917188, samples/s: 848.014 1613168852.2191365
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_131.
validation: epoch 131, iter 195, top_1: 0.755789, top_k: 0.929407, samples/s: 2439.116 1613168873.5895867
train: epoch 132, iter 100, loss: 2.022399, top_1: 0.772461, top_k: 0.919531, samples/s: 870.114 1613168923.439385
train: epoch 132, iter 200, loss: 2.092549, top_1: 0.770312, top_k: 0.915039, samples/s: 868.744 1613168952.907197
train: epoch 132, iter 300, loss: 1.962885, top_1: 0.775000, top_k: 0.921094, samples/s: 854.945 1613168982.8506382
train: epoch 132, iter 400, loss: 1.961124, top_1: 0.763867, top_k: 0.918750, samples/s: 847.558 1613169013.055114
train: epoch 132, iter 500, loss: 1.825590, top_1: 0.773633, top_k: 0.920820, samples/s: 847.446 1613169043.2635221
train: epoch 132, iter 600, loss: 1.951215, top_1: 0.771406, top_k: 0.920820, samples/s: 848.770 1613169073.424706
train: epoch 132, iter 700, loss: 2.085000, top_1: 0.767188, top_k: 0.916875, samples/s: 849.597 1613169103.5566835
train: epoch 132, iter 800, loss: 1.998415, top_1: 0.767734, top_k: 0.919141, samples/s: 847.077 1613169133.7781982
train: epoch 132, iter 900, loss: 1.908526, top_1: 0.766641, top_k: 0.915898, samples/s: 846.756 1613169164.0113003
train: epoch 132, iter 1000, loss: 2.040993, top_1: 0.763164, top_k: 0.913828, samples/s: 848.775 1613169194.172336
train: epoch 132, iter 1100, loss: 1.947197, top_1: 0.772578, top_k: 0.917656, samples/s: 849.262 1613169224.316212
train: epoch 132, iter 1200, loss: 2.144677, top_1: 0.767109, top_k: 0.915352, samples/s: 848.227 1613169254.496832
train: epoch 132, iter 1300, loss: 1.955095, top_1: 0.767813, top_k: 0.917031, samples/s: 848.246 1613169284.67669
train: epoch 132, iter 1400, loss: 1.977841, top_1: 0.762891, top_k: 0.917031, samples/s: 843.179 1613169315.03801
train: epoch 132, iter 1500, loss: 2.036945, top_1: 0.767656, top_k: 0.915312, samples/s: 851.841 1613169345.090524
train: epoch 132, iter 1600, loss: 1.836071, top_1: 0.768437, top_k: 0.919766, samples/s: 848.944 1613169375.2456594
train: epoch 132, iter 1700, loss: 1.925424, top_1: 0.765078, top_k: 0.914883, samples/s: 849.879 1613169405.367678
train: epoch 132, iter 1800, loss: 1.825656, top_1: 0.768750, top_k: 0.918555, samples/s: 847.697 1613169435.5671058
train: epoch 132, iter 1900, loss: 2.029108, top_1: 0.764531, top_k: 0.918164, samples/s: 848.196 1613169465.7487044
train: epoch 132, iter 2000, loss: 2.064281, top_1: 0.767656, top_k: 0.919961, samples/s: 851.042 1613169495.8295093
train: epoch 132, iter 2100, loss: 1.894839, top_1: 0.768203, top_k: 0.916797, samples/s: 850.277 1613169525.9373934
train: epoch 132, iter 2200, loss: 2.040672, top_1: 0.764609, top_k: 0.915195, samples/s: 847.030 1613169556.1606874
train: epoch 132, iter 2300, loss: 1.963300, top_1: 0.763828, top_k: 0.917070, samples/s: 849.546 1613169586.2943692
train: epoch 132, iter 2400, loss: 1.946883, top_1: 0.763828, top_k: 0.915742, samples/s: 850.115 1613169616.4078987
train: epoch 132, iter 2500, loss: 2.011160, top_1: 0.761836, top_k: 0.914922, samples/s: 847.052 1613169646.6304705
train: epoch 132, iter 2600, loss: 1.985632, top_1: 0.770625, top_k: 0.921562, samples/s: 848.722 1613169676.7938066
train: epoch 132, iter 2700, loss: 1.923206, top_1: 0.763281, top_k: 0.911758, samples/s: 854.168 1613169706.764133
train: epoch 132, iter 2800, loss: 2.011569, top_1: 0.768047, top_k: 0.916367, samples/s: 846.892 1613169736.9923446
train: epoch 132, iter 2900, loss: 2.107618, top_1: 0.759570, top_k: 0.916250, samples/s: 851.786 1613169767.046723
train: epoch 132, iter 3000, loss: 2.200673, top_1: 0.761875, top_k: 0.914375, samples/s: 851.803 1613169797.1007135
train: epoch 132, iter 3100, loss: 1.963755, top_1: 0.763945, top_k: 0.914062, samples/s: 849.820 1613169827.224747
train: epoch 132, iter 3200, loss: 1.969946, top_1: 0.764414, top_k: 0.915977, samples/s: 848.268 1613169857.404136
train: epoch 132, iter 3300, loss: 2.034261, top_1: 0.762539, top_k: 0.916445, samples/s: 847.224 1613169887.6200736
train: epoch 132, iter 3400, loss: 1.928349, top_1: 0.764414, top_k: 0.917969, samples/s: 849.634 1613169917.750786
train: epoch 132, iter 3500, loss: 1.957754, top_1: 0.762461, top_k: 0.915312, samples/s: 851.370 1613169947.8199282
train: epoch 132, iter 3600, loss: 2.147364, top_1: 0.760977, top_k: 0.916055, samples/s: 849.658 1613169977.949675
train: epoch 132, iter 3700, loss: 1.914204, top_1: 0.757930, top_k: 0.913320, samples/s: 847.886 1613170008.142498
train: epoch 132, iter 3800, loss: 2.053899, top_1: 0.761484, top_k: 0.914258, samples/s: 851.253 1613170038.2157671
train: epoch 132, iter 3900, loss: 2.101027, top_1: 0.766602, top_k: 0.918359, samples/s: 847.544 1613170068.4207067
train: epoch 132, iter 4000, loss: 1.939500, top_1: 0.770156, top_k: 0.921641, samples/s: 848.970 1613170098.574896
train: epoch 132, iter 4100, loss: 1.925623, top_1: 0.763750, top_k: 0.914609, samples/s: 849.452 1613170128.7119136
train: epoch 132, iter 4200, loss: 1.887498, top_1: 0.759961, top_k: 0.913242, samples/s: 848.061 1613170158.8984897
train: epoch 132, iter 4300, loss: 2.017853, top_1: 0.762031, top_k: 0.913125, samples/s: 850.912 1613170188.9838917
train: epoch 132, iter 4400, loss: 2.012983, top_1: 0.762344, top_k: 0.914531, samples/s: 850.969 1613170219.0671794
train: epoch 132, iter 4500, loss: 2.030304, top_1: 0.762891, top_k: 0.915937, samples/s: 850.648 1613170249.1619031
train: epoch 132, iter 4600, loss: 1.821759, top_1: 0.764180, top_k: 0.916172, samples/s: 852.157 1613170279.203378
train: epoch 132, iter 4700, loss: 1.946223, top_1: 0.768984, top_k: 0.918438, samples/s: 847.882 1613170309.3962286
train: epoch 132, iter 4800, loss: 2.002256, top_1: 0.765820, top_k: 0.916094, samples/s: 850.586 1613170339.493102
train: epoch 132, iter 4900, loss: 1.919191, top_1: 0.765703, top_k: 0.918984, samples/s: 849.907 1613170369.614031
train: epoch 132, iter 5000, loss: 1.874203, top_1: 0.771211, top_k: 0.919453, samples/s: 848.119 1613170399.7984796
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_132.
validation: epoch 132, iter 195, top_1: 0.760517, top_k: 0.931611, samples/s: 2423.282 1613170421.2893481
train: epoch 133, iter 100, loss: 1.872073, top_1: 0.775195, top_k: 0.921523, samples/s: 872.000 1613170477.3240547
train: epoch 133, iter 200, loss: 2.021495, top_1: 0.775898, top_k: 0.921055, samples/s: 868.055 1613170506.8155382
train: epoch 133, iter 300, loss: 1.971972, top_1: 0.771445, top_k: 0.919180, samples/s: 859.119 1613170536.613269
train: epoch 133, iter 400, loss: 1.909259, top_1: 0.772422, top_k: 0.917461, samples/s: 849.644 1613170566.7434683
train: epoch 133, iter 500, loss: 2.022254, top_1: 0.769023, top_k: 0.917344, samples/s: 849.538 1613170596.8775122
train: epoch 133, iter 600, loss: 1.877892, top_1: 0.773750, top_k: 0.922305, samples/s: 847.042 1613170627.1003292
train: epoch 133, iter 700, loss: 2.089380, top_1: 0.770234, top_k: 0.918516, samples/s: 849.032 1613170657.2523117
train: epoch 133, iter 800, loss: 2.004009, top_1: 0.770352, top_k: 0.918281, samples/s: 848.624 1613170687.4188983
train: epoch 133, iter 900, loss: 1.935646, top_1: 0.768672, top_k: 0.918008, samples/s: 847.256 1613170717.6340525
train: epoch 133, iter 1000, loss: 1.892757, top_1: 0.770547, top_k: 0.919297, samples/s: 849.051 1613170747.785341
train: epoch 133, iter 1100, loss: 1.940500, top_1: 0.770312, top_k: 0.916992, samples/s: 848.312 1613170777.9628696
train: epoch 133, iter 1200, loss: 1.883467, top_1: 0.767500, top_k: 0.916875, samples/s: 849.241 1613170808.1074793
train: epoch 133, iter 1300, loss: 1.926722, top_1: 0.775508, top_k: 0.923594, samples/s: 847.360 1613170838.3189187
train: epoch 133, iter 1400, loss: 1.913258, top_1: 0.769570, top_k: 0.915586, samples/s: 850.736 1613170868.4105551
train: epoch 133, iter 1500, loss: 1.959445, top_1: 0.771797, top_k: 0.918477, samples/s: 849.416 1613170898.548874
train: epoch 133, iter 1600, loss: 1.797870, top_1: 0.772891, top_k: 0.919180, samples/s: 850.441 1613170928.6509852
train: epoch 133, iter 1700, loss: 1.982620, top_1: 0.773945, top_k: 0.921484, samples/s: 846.983 1613170958.8758664
train: epoch 133, iter 1800, loss: 2.083649, top_1: 0.766133, top_k: 0.914414, samples/s: 846.540 1613170989.116676
train: epoch 133, iter 1900, loss: 1.901966, top_1: 0.769258, top_k: 0.918789, samples/s: 849.035 1613171019.2684772
train: epoch 133, iter 2000, loss: 1.976844, top_1: 0.772422, top_k: 0.918555, samples/s: 850.161 1613171049.38041
train: epoch 133, iter 2100, loss: 2.174889, top_1: 0.766484, top_k: 0.917969, samples/s: 849.830 1613171079.5040753
train: epoch 133, iter 2200, loss: 2.009825, top_1: 0.771367, top_k: 0.919531, samples/s: 850.128 1613171109.617332
train: epoch 133, iter 2300, loss: 1.989199, top_1: 0.763242, top_k: 0.915977, samples/s: 849.026 1613171139.7694619
train: epoch 133, iter 2400, loss: 2.049928, top_1: 0.773750, top_k: 0.921133, samples/s: 850.492 1613171169.8696985
train: epoch 133, iter 2500, loss: 1.941469, top_1: 0.767969, top_k: 0.918516, samples/s: 848.290 1613171200.0481095
train: epoch 133, iter 2600, loss: 2.034179, top_1: 0.768711, top_k: 0.917109, samples/s: 847.049 1613171230.2706127
train: epoch 133, iter 2700, loss: 2.043896, top_1: 0.770234, top_k: 0.917734, samples/s: 851.545 1613171260.333694
train: epoch 133, iter 2800, loss: 1.850522, top_1: 0.770078, top_k: 0.918242, samples/s: 849.020 1613171290.4860508
train: epoch 133, iter 2900, loss: 1.761447, top_1: 0.771445, top_k: 0.917813, samples/s: 850.272 1613171320.594117
train: epoch 133, iter 3000, loss: 1.986824, top_1: 0.765781, top_k: 0.916719, samples/s: 847.636 1613171350.7962584
train: epoch 133, iter 3100, loss: 1.941421, top_1: 0.765938, top_k: 0.915742, samples/s: 849.940 1613171380.9155486
train: epoch 133, iter 3200, loss: 1.897841, top_1: 0.770898, top_k: 0.918633, samples/s: 848.455 1613171411.0884075
train: epoch 133, iter 3300, loss: 1.874134, top_1: 0.767344, top_k: 0.918359, samples/s: 851.622 1613171441.1482987
train: epoch 133, iter 3400, loss: 1.916966, top_1: 0.766875, top_k: 0.917070, samples/s: 850.019 1613171471.2652826
train: epoch 133, iter 3500, loss: 1.997044, top_1: 0.765078, top_k: 0.918008, samples/s: 849.387 1613171501.4047196
train: epoch 133, iter 3600, loss: 2.004063, top_1: 0.767695, top_k: 0.914336, samples/s: 848.591 1613171531.5722797
train: epoch 133, iter 3700, loss: 1.964845, top_1: 0.763711, top_k: 0.918008, samples/s: 850.061 1613171561.6878805
train: epoch 133, iter 3800, loss: 1.977085, top_1: 0.769727, top_k: 0.920156, samples/s: 849.743 1613171591.8145418
train: epoch 133, iter 3900, loss: 2.014694, top_1: 0.769727, top_k: 0.918320, samples/s: 848.142 1613171621.99821
train: epoch 133, iter 4000, loss: 1.942164, top_1: 0.768281, top_k: 0.919492, samples/s: 849.503 1613171652.1334403
train: epoch 133, iter 4100, loss: 1.955807, top_1: 0.767188, top_k: 0.916328, samples/s: 847.313 1613171682.3466005
train: epoch 133, iter 4200, loss: 1.912059, top_1: 0.766172, top_k: 0.915312, samples/s: 849.417 1613171712.4850109
train: epoch 133, iter 4300, loss: 1.920110, top_1: 0.765234, top_k: 0.916758, samples/s: 847.321 1613171742.6978128
train: epoch 133, iter 4400, loss: 2.061901, top_1: 0.767109, top_k: 0.916094, samples/s: 849.579 1613171772.8303769
train: epoch 133, iter 4500, loss: 1.960783, top_1: 0.767734, top_k: 0.916172, samples/s: 848.063 1613171803.016882
train: epoch 133, iter 4600, loss: 1.922804, top_1: 0.769141, top_k: 0.917031, samples/s: 852.235 1613171833.0555587
train: epoch 133, iter 4700, loss: 2.002611, top_1: 0.768789, top_k: 0.918906, samples/s: 849.250 1613171863.1997993
train: epoch 133, iter 4800, loss: 1.983507, top_1: 0.768828, top_k: 0.919453, samples/s: 848.197 1613171893.3813813
train: epoch 133, iter 4900, loss: 1.870952, top_1: 0.768008, top_k: 0.919609, samples/s: 850.173 1613171923.4929652
train: epoch 133, iter 5000, loss: 2.068078, top_1: 0.771055, top_k: 0.917227, samples/s: 848.838 1613171953.651867
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_133.
validation: epoch 133, iter 195, top_1: 0.760757, top_k: 0.931290, samples/s: 2442.078 1613171974.950406
train: epoch 134, iter 100, loss: 1.790586, top_1: 0.780391, top_k: 0.923477, samples/s: 871.016 1613172025.679242
train: epoch 134, iter 200, loss: 1.956404, top_1: 0.781211, top_k: 0.922305, samples/s: 867.683 1613172055.1831224
train: epoch 134, iter 300, loss: 1.881659, top_1: 0.777109, top_k: 0.920781, samples/s: 856.248 1613172085.0808723
train: epoch 134, iter 400, loss: 2.016198, top_1: 0.776367, top_k: 0.920039, samples/s: 848.948 1613172115.235934
train: epoch 134, iter 500, loss: 1.858390, top_1: 0.774141, top_k: 0.918477, samples/s: 847.405 1613172145.445737
train: epoch 134, iter 600, loss: 2.011864, top_1: 0.778008, top_k: 0.920977, samples/s: 847.645 1613172175.6470463
train: epoch 134, iter 700, loss: 1.962733, top_1: 0.774961, top_k: 0.919687, samples/s: 847.364 1613172205.8583853
train: epoch 134, iter 800, loss: 2.059288, top_1: 0.778086, top_k: 0.921289, samples/s: 848.382 1613172236.0335464
train: epoch 134, iter 900, loss: 1.933372, top_1: 0.777109, top_k: 0.921016, samples/s: 851.150 1613172266.1105008
train: epoch 134, iter 1000, loss: 1.925779, top_1: 0.777031, top_k: 0.923281, samples/s: 849.881 1613172296.2323883
train: epoch 134, iter 1100, loss: 1.970850, top_1: 0.773828, top_k: 0.922734, samples/s: 849.683 1613172326.3612344
train: epoch 134, iter 1200, loss: 2.011630, top_1: 0.775469, top_k: 0.922344, samples/s: 847.167 1613172356.579708
train: epoch 134, iter 1300, loss: 2.035354, top_1: 0.772070, top_k: 0.919297, samples/s: 849.668 1613172386.7090821
train: epoch 134, iter 1400, loss: 1.915219, top_1: 0.775625, top_k: 0.917617, samples/s: 848.886 1613172416.8661036
train: epoch 134, iter 1500, loss: 1.942630, top_1: 0.770625, top_k: 0.920117, samples/s: 849.111 1613172447.0153713
train: epoch 134, iter 1600, loss: 1.952351, top_1: 0.774648, top_k: 0.921367, samples/s: 848.981 1613172477.16921
train: epoch 134, iter 1700, loss: 1.977141, top_1: 0.773594, top_k: 0.919375, samples/s: 848.498 1613172507.340046
train: epoch 134, iter 1800, loss: 1.846293, top_1: 0.776406, top_k: 0.922227, samples/s: 850.742 1613172537.4314601
train: epoch 134, iter 1900, loss: 1.951466, top_1: 0.771211, top_k: 0.919219, samples/s: 848.795 1613172567.5919049
train: epoch 134, iter 2000, loss: 1.937726, top_1: 0.769453, top_k: 0.919609, samples/s: 848.419 1613172597.7656143
train: epoch 134, iter 2100, loss: 1.911550, top_1: 0.776094, top_k: 0.923984, samples/s: 850.600 1613172627.8620074
train: epoch 134, iter 2200, loss: 1.781945, top_1: 0.777266, top_k: 0.921133, samples/s: 849.506 1613172657.9971588
train: epoch 134, iter 2300, loss: 1.975222, top_1: 0.772930, top_k: 0.920508, samples/s: 848.309 1613172688.1748304
train: epoch 134, iter 2400, loss: 2.013965, top_1: 0.772578, top_k: 0.919219, samples/s: 851.355 1613172718.244577
train: epoch 134, iter 2500, loss: 1.965909, top_1: 0.766992, top_k: 0.919531, samples/s: 847.765 1613172748.4416785
train: epoch 134, iter 2600, loss: 1.989817, top_1: 0.767539, top_k: 0.916914, samples/s: 850.833 1613172778.5297918
train: epoch 134, iter 2700, loss: 1.923919, top_1: 0.774766, top_k: 0.920195, samples/s: 850.011 1613172808.6469903
train: epoch 134, iter 2800, loss: 1.968429, top_1: 0.770586, top_k: 0.921484, samples/s: 850.480 1613172838.7476988
train: epoch 134, iter 2900, loss: 1.828996, top_1: 0.770117, top_k: 0.920156, samples/s: 850.317 1613172868.854181
train: epoch 134, iter 3000, loss: 1.939617, top_1: 0.772070, top_k: 0.919609, samples/s: 850.074 1613172898.9691453
train: epoch 134, iter 3100, loss: 1.912826, top_1: 0.771328, top_k: 0.920234, samples/s: 849.212 1613172929.1147768
train: epoch 134, iter 3200, loss: 2.035670, top_1: 0.768594, top_k: 0.917383, samples/s: 848.729 1613172959.2774224
train: epoch 134, iter 3300, loss: 1.849445, top_1: 0.773672, top_k: 0.923281, samples/s: 849.586 1613172989.4097347
train: epoch 134, iter 3400, loss: 1.800598, top_1: 0.769687, top_k: 0.916992, samples/s: 846.732 1613173019.6436121
train: epoch 134, iter 3500, loss: 2.037289, top_1: 0.769805, top_k: 0.920039, samples/s: 849.190 1613173049.790087
train: epoch 134, iter 3600, loss: 2.039994, top_1: 0.772813, top_k: 0.920078, samples/s: 851.029 1613173079.8712566
train: epoch 134, iter 3700, loss: 1.967262, top_1: 0.769062, top_k: 0.917656, samples/s: 850.897 1613173109.957117
train: epoch 134, iter 3800, loss: 2.032259, top_1: 0.769102, top_k: 0.918086, samples/s: 848.870 1613173140.114858
train: epoch 134, iter 3900, loss: 1.906845, top_1: 0.769766, top_k: 0.919961, samples/s: 849.076 1613173170.2653222
train: epoch 134, iter 4000, loss: 2.013008, top_1: 0.767813, top_k: 0.916133, samples/s: 847.397 1613173200.4754167
train: epoch 134, iter 4100, loss: 1.978876, top_1: 0.768359, top_k: 0.917656, samples/s: 850.605 1613173230.5717506
train: epoch 134, iter 4200, loss: 1.837469, top_1: 0.765352, top_k: 0.919023, samples/s: 850.301 1613173260.6786726
train: epoch 134, iter 4300, loss: 1.975977, top_1: 0.767422, top_k: 0.917891, samples/s: 849.969 1613173290.7974715
train: epoch 134, iter 4400, loss: 1.908108, top_1: 0.767930, top_k: 0.918555, samples/s: 847.773 1613173320.9942403
train: epoch 134, iter 4500, loss: 1.909578, top_1: 0.770703, top_k: 0.921172, samples/s: 852.746 1613173351.0148559
train: epoch 134, iter 4600, loss: 1.953553, top_1: 0.769336, top_k: 0.919648, samples/s: 847.687 1613173381.2146747
train: epoch 134, iter 4700, loss: 1.790193, top_1: 0.768437, top_k: 0.921016, samples/s: 849.563 1613173411.347835
train: epoch 134, iter 4800, loss: 2.058641, top_1: 0.769375, top_k: 0.922461, samples/s: 851.930 1613173441.3971996
train: epoch 134, iter 4900, loss: 1.781669, top_1: 0.772109, top_k: 0.921016, samples/s: 849.521 1613173471.5318284
train: epoch 134, iter 5000, loss: 1.816035, top_1: 0.777227, top_k: 0.921094, samples/s: 848.725 1613173501.6946638
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_134.
validation: epoch 134, iter 195, top_1: 0.759675, top_k: 0.930389, samples/s: 2485.784 1613173522.6724098
train: epoch 135, iter 100, loss: 1.775395, top_1: 0.781484, top_k: 0.922773, samples/s: 867.108 1613173573.1361387
train: epoch 135, iter 200, loss: 1.928442, top_1: 0.779531, top_k: 0.924531, samples/s: 865.810 1613173602.7038255
train: epoch 135, iter 300, loss: 1.996633, top_1: 0.776328, top_k: 0.923008, samples/s: 857.032 1613173632.574377
train: epoch 135, iter 400, loss: 2.012854, top_1: 0.780742, top_k: 0.921406, samples/s: 847.594 1613173662.7775881
train: epoch 135, iter 500, loss: 1.828046, top_1: 0.778711, top_k: 0.923125, samples/s: 848.689 1613173692.9417632
train: epoch 135, iter 600, loss: 1.914163, top_1: 0.778203, top_k: 0.923398, samples/s: 850.575 1613173723.0389445
train: epoch 135, iter 700, loss: 1.906478, top_1: 0.778398, top_k: 0.923906, samples/s: 847.365 1613173753.2502513
train: epoch 135, iter 800, loss: 1.880816, top_1: 0.777109, top_k: 0.921523, samples/s: 848.742 1613173783.4125943
train: epoch 135, iter 900, loss: 1.901856, top_1: 0.782813, top_k: 0.924414, samples/s: 849.054 1613173813.563795
train: epoch 135, iter 1000, loss: 1.913777, top_1: 0.779297, top_k: 0.923555, samples/s: 848.147 1613173843.7473161
train: epoch 135, iter 1100, loss: 1.874032, top_1: 0.778711, top_k: 0.924570, samples/s: 849.800 1613173873.871943
train: epoch 135, iter 1200, loss: 1.903984, top_1: 0.776250, top_k: 0.919570, samples/s: 847.872 1613173904.0652797
train: epoch 135, iter 1300, loss: 1.918795, top_1: 0.776328, top_k: 0.921914, samples/s: 852.751 1613173934.085739
train: epoch 135, iter 1400, loss: 1.968675, top_1: 0.776992, top_k: 0.922461, samples/s: 848.847 1613173964.2442245
train: epoch 135, iter 1500, loss: 2.035585, top_1: 0.780937, top_k: 0.922500, samples/s: 851.271 1613173994.3168826
train: epoch 135, iter 1600, loss: 1.995739, top_1: 0.778672, top_k: 0.922656, samples/s: 847.382 1613174024.5276752
train: epoch 135, iter 1700, loss: 2.028385, top_1: 0.776875, top_k: 0.922773, samples/s: 849.942 1613174054.647378
train: epoch 135, iter 1800, loss: 1.920954, top_1: 0.777266, top_k: 0.922109, samples/s: 849.833 1613174084.7709444
train: epoch 135, iter 1900, loss: 1.871014, top_1: 0.773008, top_k: 0.923516, samples/s: 851.024 1613174114.8523512
train: epoch 135, iter 2000, loss: 1.917180, top_1: 0.775039, top_k: 0.919219, samples/s: 851.148 1613174144.929294
train: epoch 135, iter 2100, loss: 1.942096, top_1: 0.778984, top_k: 0.921406, samples/s: 848.530 1613174175.099136
train: epoch 135, iter 2200, loss: 1.896278, top_1: 0.777227, top_k: 0.921602, samples/s: 852.182 1613174205.1396437
train: epoch 135, iter 2300, loss: 1.875427, top_1: 0.780898, top_k: 0.922422, samples/s: 850.169 1613174235.2513463
train: epoch 135, iter 2400, loss: 1.868439, top_1: 0.779023, top_k: 0.919883, samples/s: 850.404 1613174265.354641
train: epoch 135, iter 2500, loss: 2.070276, top_1: 0.775078, top_k: 0.920469, samples/s: 850.616 1613174295.450461
train: epoch 135, iter 2600, loss: 2.020508, top_1: 0.777109, top_k: 0.922305, samples/s: 850.053 1613174325.566217
train: epoch 135, iter 2700, loss: 1.907602, top_1: 0.774844, top_k: 0.922148, samples/s: 849.106 1613174355.7156277
train: epoch 135, iter 2800, loss: 1.873438, top_1: 0.777305, top_k: 0.920195, samples/s: 849.545 1613174385.8494003
train: epoch 135, iter 2900, loss: 1.931275, top_1: 0.775781, top_k: 0.921641, samples/s: 847.785 1613174416.0456836
train: epoch 135, iter 3000, loss: 1.965473, top_1: 0.777109, top_k: 0.919766, samples/s: 849.412 1613174446.1843154
train: epoch 135, iter 3100, loss: 1.880805, top_1: 0.778281, top_k: 0.921055, samples/s: 852.536 1613174476.212348
train: epoch 135, iter 3200, loss: 2.008980, top_1: 0.776172, top_k: 0.922773, samples/s: 849.020 1613174506.3647296
train: epoch 135, iter 3300, loss: 1.907557, top_1: 0.776641, top_k: 0.919766, samples/s: 849.209 1613174536.5103831
train: epoch 135, iter 3400, loss: 1.938833, top_1: 0.778164, top_k: 0.924297, samples/s: 849.153 1613174566.6581163
train: epoch 135, iter 3500, loss: 2.020007, top_1: 0.778398, top_k: 0.919844, samples/s: 851.404 1613174596.7260575
train: epoch 135, iter 3600, loss: 1.977587, top_1: 0.770312, top_k: 0.919297, samples/s: 849.053 1613174626.8773139
train: epoch 135, iter 3700, loss: 1.918144, top_1: 0.772852, top_k: 0.917969, samples/s: 848.132 1613174657.0613012
train: epoch 135, iter 3800, loss: 1.971930, top_1: 0.770469, top_k: 0.917344, samples/s: 850.511 1613174687.1608515
train: epoch 135, iter 3900, loss: 1.860496, top_1: 0.777539, top_k: 0.920664, samples/s: 847.644 1613174717.3622937
train: epoch 135, iter 4000, loss: 1.943707, top_1: 0.776445, top_k: 0.922852, samples/s: 850.963 1613174747.4458477
train: epoch 135, iter 4100, loss: 1.970045, top_1: 0.776797, top_k: 0.923711, samples/s: 850.616 1613174777.5416827
train: epoch 135, iter 4200, loss: 1.886863, top_1: 0.774648, top_k: 0.922188, samples/s: 850.626 1613174807.6370778
train: epoch 135, iter 4300, loss: 1.899390, top_1: 0.774961, top_k: 0.922148, samples/s: 848.276 1613174837.815903
train: epoch 135, iter 4400, loss: 1.958223, top_1: 0.777070, top_k: 0.924219, samples/s: 850.357 1613174867.9210107
train: epoch 135, iter 4500, loss: 2.018019, top_1: 0.773945, top_k: 0.921172, samples/s: 850.433 1613174898.023347
train: epoch 135, iter 4600, loss: 1.896255, top_1: 0.772305, top_k: 0.920039, samples/s: 850.974 1613174928.1065242
train: epoch 135, iter 4700, loss: 1.903319, top_1: 0.775469, top_k: 0.919609, samples/s: 850.047 1613174958.2224703
train: epoch 135, iter 4800, loss: 1.826136, top_1: 0.780156, top_k: 0.922188, samples/s: 848.240 1613174988.402633
train: epoch 135, iter 4900, loss: 1.904548, top_1: 0.773711, top_k: 0.923711, samples/s: 852.410 1613175018.4351478
train: epoch 135, iter 5000, loss: 1.900383, top_1: 0.783398, top_k: 0.924336, samples/s: 850.193 1613175048.545905
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_135.
validation: epoch 135, iter 195, top_1: 0.763782, top_k: 0.932292, samples/s: 2490.176 1613175069.4948716
train: epoch 136, iter 100, loss: 1.933113, top_1: 0.783477, top_k: 0.925195, samples/s: 869.313 1613175119.338409
train: epoch 136, iter 200, loss: 1.953107, top_1: 0.781836, top_k: 0.922734, samples/s: 867.389 1613175148.8521914
train: epoch 136, iter 300, loss: 1.979656, top_1: 0.785625, top_k: 0.924141, samples/s: 853.749 1613175178.8375616
train: epoch 136, iter 400, loss: 1.805837, top_1: 0.778516, top_k: 0.922891, samples/s: 847.784 1613175209.03405
train: epoch 136, iter 500, loss: 2.155797, top_1: 0.780312, top_k: 0.922070, samples/s: 850.388 1613175239.137821
train: epoch 136, iter 600, loss: 1.836530, top_1: 0.783945, top_k: 0.926250, samples/s: 847.847 1613175269.33203
train: epoch 136, iter 700, loss: 1.861535, top_1: 0.783164, top_k: 0.924883, samples/s: 849.310 1613175299.474048
train: epoch 136, iter 800, loss: 2.037570, top_1: 0.778672, top_k: 0.922305, samples/s: 847.962 1613175329.6641939
train: epoch 136, iter 900, loss: 1.990263, top_1: 0.785273, top_k: 0.925625, samples/s: 849.752 1613175359.790576
train: epoch 136, iter 1000, loss: 1.975147, top_1: 0.782578, top_k: 0.924414, samples/s: 848.063 1613175389.9770362
train: epoch 136, iter 1100, loss: 1.847214, top_1: 0.775469, top_k: 0.923398, samples/s: 849.231 1613175420.1219866
train: epoch 136, iter 1200, loss: 1.923381, top_1: 0.779141, top_k: 0.923203, samples/s: 848.476 1613175450.2937107
train: epoch 136, iter 1300, loss: 1.933830, top_1: 0.780234, top_k: 0.922461, samples/s: 849.101 1613175480.4432502
train: epoch 136, iter 1400, loss: 1.737905, top_1: 0.786328, top_k: 0.926758, samples/s: 848.766 1613175510.6047342
train: epoch 136, iter 1500, loss: 2.050000, top_1: 0.779687, top_k: 0.921680, samples/s: 849.013 1613175540.757313
train: epoch 136, iter 1600, loss: 1.953017, top_1: 0.778008, top_k: 0.920000, samples/s: 849.098 1613175570.9070287
train: epoch 136, iter 1700, loss: 1.864649, top_1: 0.778281, top_k: 0.921484, samples/s: 852.642 1613175600.931285
train: epoch 136, iter 1800, loss: 1.975324, top_1: 0.781836, top_k: 0.922578, samples/s: 849.586 1613175631.0636637
train: epoch 136, iter 1900, loss: 1.854559, top_1: 0.776914, top_k: 0.919687, samples/s: 848.150 1613175661.2470298
train: epoch 136, iter 2000, loss: 1.933589, top_1: 0.785625, top_k: 0.922969, samples/s: 850.282 1613175691.3546815
train: epoch 136, iter 2100, loss: 1.877133, top_1: 0.778906, top_k: 0.923750, samples/s: 849.873 1613175721.4767275
train: epoch 136, iter 2200, loss: 1.938470, top_1: 0.782305, top_k: 0.924570, samples/s: 849.638 1613175751.607353
train: epoch 136, iter 2300, loss: 1.864725, top_1: 0.780703, top_k: 0.922422, samples/s: 849.435 1613175781.7449656
train: epoch 136, iter 2400, loss: 1.889669, top_1: 0.777969, top_k: 0.923789, samples/s: 848.069 1613175811.931144
train: epoch 136, iter 2500, loss: 1.938772, top_1: 0.776445, top_k: 0.923633, samples/s: 850.531 1613175842.0300639
train: epoch 136, iter 2600, loss: 1.816189, top_1: 0.779531, top_k: 0.923594, samples/s: 850.542 1613175872.1285846
train: epoch 136, iter 2700, loss: 1.909159, top_1: 0.779297, top_k: 0.924102, samples/s: 848.788 1613175902.2892275
train: epoch 136, iter 2800, loss: 2.036830, top_1: 0.776055, top_k: 0.921875, samples/s: 852.180 1613175932.32985
train: epoch 136, iter 2900, loss: 1.936175, top_1: 0.777930, top_k: 0.922227, samples/s: 847.567 1613175962.5338519
train: epoch 136, iter 3000, loss: 1.962591, top_1: 0.776992, top_k: 0.923320, samples/s: 849.029 1613175992.6859696
train: epoch 136, iter 3100, loss: 1.952366, top_1: 0.776172, top_k: 0.918086, samples/s: 848.901 1613176022.8426766
train: epoch 136, iter 3200, loss: 2.061399, top_1: 0.777148, top_k: 0.921758, samples/s: 848.785 1613176053.0033169
train: epoch 136, iter 3300, loss: 1.908318, top_1: 0.778594, top_k: 0.922031, samples/s: 851.822 1613176083.0566654
train: epoch 136, iter 3400, loss: 1.881335, top_1: 0.777031, top_k: 0.923906, samples/s: 850.196 1613176113.1673603
train: epoch 136, iter 3500, loss: 2.107842, top_1: 0.777227, top_k: 0.919844, samples/s: 848.969 1613176143.3216004
train: epoch 136, iter 3600, loss: 1.963538, top_1: 0.773477, top_k: 0.919180, samples/s: 850.022 1613176173.4384246
train: epoch 136, iter 3700, loss: 1.836758, top_1: 0.777656, top_k: 0.923828, samples/s: 848.132 1613176203.6224174
train: epoch 136, iter 3800, loss: 1.888144, top_1: 0.778359, top_k: 0.922422, samples/s: 850.303 1613176233.7293212
train: epoch 136, iter 3900, loss: 2.051728, top_1: 0.778086, top_k: 0.922539, samples/s: 849.739 1613176263.8561997
train: epoch 136, iter 4000, loss: 2.006235, top_1: 0.776797, top_k: 0.921875, samples/s: 851.189 1613176293.9318414
train: epoch 136, iter 4100, loss: 1.792477, top_1: 0.779414, top_k: 0.924961, samples/s: 848.976 1613176324.0858274
train: epoch 136, iter 4200, loss: 1.976768, top_1: 0.778438, top_k: 0.921133, samples/s: 851.032 1613176354.1669476
train: epoch 136, iter 4300, loss: 2.071716, top_1: 0.773359, top_k: 0.921094, samples/s: 846.859 1613176384.396343
train: epoch 136, iter 4400, loss: 1.975779, top_1: 0.775273, top_k: 0.922461, samples/s: 849.859 1613176414.5189016
train: epoch 136, iter 4500, loss: 1.974792, top_1: 0.782383, top_k: 0.922891, samples/s: 850.238 1613176444.6282108
train: epoch 136, iter 4600, loss: 2.039847, top_1: 0.776992, top_k: 0.921641, samples/s: 849.704 1613176474.7563508
train: epoch 136, iter 4700, loss: 1.893723, top_1: 0.778086, top_k: 0.921953, samples/s: 850.527 1613176504.8552468
train: epoch 136, iter 4800, loss: 1.856843, top_1: 0.773242, top_k: 0.921406, samples/s: 848.744 1613176535.017468
train: epoch 136, iter 4900, loss: 2.039657, top_1: 0.774766, top_k: 0.923477, samples/s: 847.898 1613176565.2097843
train: epoch 136, iter 5000, loss: 1.871786, top_1: 0.781445, top_k: 0.925000, samples/s: 851.100 1613176595.2885334
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_136.
validation: epoch 136, iter 195, top_1: 0.766326, top_k: 0.933313, samples/s: 2440.463 1613176616.6381161
train: epoch 137, iter 100, loss: 2.010808, top_1: 0.784844, top_k: 0.924922, samples/s: 871.038 1613176666.558072
train: epoch 137, iter 200, loss: 1.979445, top_1: 0.787422, top_k: 0.925742, samples/s: 869.733 1613176695.9921129
train: epoch 137, iter 300, loss: 2.037793, top_1: 0.789766, top_k: 0.929258, samples/s: 853.283 1613176725.9938958
train: epoch 137, iter 400, loss: 1.978518, top_1: 0.785391, top_k: 0.923008, samples/s: 850.447 1613176756.0958464
train: epoch 137, iter 500, loss: 1.940160, top_1: 0.787734, top_k: 0.924687, samples/s: 846.384 1613176786.3419855
train: epoch 137, iter 600, loss: 1.859805, top_1: 0.786133, top_k: 0.928320, samples/s: 850.305 1613176816.4489064
train: epoch 137, iter 700, loss: 2.017386, top_1: 0.784258, top_k: 0.925352, samples/s: 847.534 1613176846.654141
train: epoch 137, iter 800, loss: 1.831236, top_1: 0.780156, top_k: 0.923438, samples/s: 850.765 1613176876.7446961
train: epoch 137, iter 900, loss: 1.950221, top_1: 0.785156, top_k: 0.926953, samples/s: 845.854 1613176907.0100317
train: epoch 137, iter 1000, loss: 1.899223, top_1: 0.782148, top_k: 0.926758, samples/s: 848.379 1613176937.1853027
train: epoch 137, iter 1100, loss: 2.008539, top_1: 0.787852, top_k: 0.924492, samples/s: 851.781 1613176967.2398727
train: epoch 137, iter 1200, loss: 2.036693, top_1: 0.786680, top_k: 0.925078, samples/s: 847.541 1613176997.4448652
train: epoch 137, iter 1300, loss: 1.844057, top_1: 0.786523, top_k: 0.924375, samples/s: 850.747 1613177027.5360556
train: epoch 137, iter 1400, loss: 1.832835, top_1: 0.784414, top_k: 0.927344, samples/s: 848.003 1613177057.7246854
train: epoch 137, iter 1500, loss: 1.931017, top_1: 0.784023, top_k: 0.924063, samples/s: 850.046 1613177087.8406765
train: epoch 137, iter 1600, loss: 1.987952, top_1: 0.780039, top_k: 0.923242, samples/s: 847.072 1613177118.0623467
train: epoch 137, iter 1700, loss: 1.883260, top_1: 0.782617, top_k: 0.926133, samples/s: 848.792 1613177148.222952
train: epoch 137, iter 1800, loss: 1.859223, top_1: 0.783477, top_k: 0.924883, samples/s: 849.725 1613177178.3502827
train: epoch 137, iter 1900, loss: 1.957085, top_1: 0.779141, top_k: 0.922617, samples/s: 849.146 1613177208.4982195
train: epoch 137, iter 2000, loss: 1.777598, top_1: 0.783828, top_k: 0.927188, samples/s: 847.804 1613177238.6939933
train: epoch 137, iter 2100, loss: 1.921657, top_1: 0.783984, top_k: 0.925547, samples/s: 848.122 1613177268.8782847
train: epoch 137, iter 2200, loss: 1.926769, top_1: 0.783711, top_k: 0.924102, samples/s: 851.006 1613177298.9602284
train: epoch 137, iter 2300, loss: 1.801308, top_1: 0.781211, top_k: 0.921797, samples/s: 847.885 1613177329.1530497
train: epoch 137, iter 2400, loss: 1.830318, top_1: 0.786602, top_k: 0.927852, samples/s: 849.333 1613177359.2943435
train: epoch 137, iter 2500, loss: 1.846650, top_1: 0.776992, top_k: 0.921367, samples/s: 845.700 1613177389.5651
train: epoch 137, iter 2600, loss: 1.910630, top_1: 0.784805, top_k: 0.924687, samples/s: 848.953 1613177419.7198873
train: epoch 137, iter 2700, loss: 1.781468, top_1: 0.783242, top_k: 0.925859, samples/s: 846.451 1613177449.9638445
train: epoch 137, iter 2800, loss: 2.008065, top_1: 0.782852, top_k: 0.924492, samples/s: 849.050 1613177480.115216
train: epoch 137, iter 2900, loss: 1.968322, top_1: 0.783281, top_k: 0.923398, samples/s: 847.349 1613177510.3271015
train: epoch 137, iter 3000, loss: 1.813982, top_1: 0.776641, top_k: 0.922656, samples/s: 849.053 1613177540.478291
train: epoch 137, iter 3100, loss: 1.951435, top_1: 0.784609, top_k: 0.926133, samples/s: 847.579 1613177570.68198
train: epoch 137, iter 3200, loss: 1.888361, top_1: 0.778594, top_k: 0.923242, samples/s: 848.710 1613177600.8454056
train: epoch 137, iter 3300, loss: 1.875230, top_1: 0.784570, top_k: 0.923945, samples/s: 848.706 1613177631.0089972
train: epoch 137, iter 3400, loss: 1.843849, top_1: 0.784687, top_k: 0.924961, samples/s: 848.388 1613177661.1839526
train: epoch 137, iter 3500, loss: 1.932446, top_1: 0.787773, top_k: 0.927773, samples/s: 849.788 1613177691.308998
train: epoch 137, iter 3600, loss: 1.983285, top_1: 0.784297, top_k: 0.925430, samples/s: 846.851 1613177721.5387452
train: epoch 137, iter 3700, loss: 1.909017, top_1: 0.780508, top_k: 0.922461, samples/s: 848.544 1613177751.7079742
train: epoch 137, iter 3800, loss: 1.854209, top_1: 0.779727, top_k: 0.923828, samples/s: 846.510 1613177781.949813
train: epoch 137, iter 3900, loss: 1.869601, top_1: 0.778438, top_k: 0.920547, samples/s: 850.659 1613177812.044136
train: epoch 137, iter 4000, loss: 1.889002, top_1: 0.782227, top_k: 0.924258, samples/s: 846.907 1613177842.2718248
train: epoch 137, iter 4100, loss: 1.904532, top_1: 0.781641, top_k: 0.924063, samples/s: 849.742 1613177872.3985941
train: epoch 137, iter 4200, loss: 1.843871, top_1: 0.781875, top_k: 0.923242, samples/s: 847.647 1613177902.5998516
train: epoch 137, iter 4300, loss: 1.997900, top_1: 0.779609, top_k: 0.920898, samples/s: 847.542 1613177932.8048806
train: epoch 137, iter 4400, loss: 1.930952, top_1: 0.778477, top_k: 0.921367, samples/s: 848.993 1613177962.9581375
train: epoch 137, iter 4500, loss: 1.927543, top_1: 0.778906, top_k: 0.923594, samples/s: 849.616 1613177993.089461
train: epoch 137, iter 4600, loss: 1.938632, top_1: 0.781133, top_k: 0.922695, samples/s: 845.299 1613178023.3746097
train: epoch 137, iter 4700, loss: 1.966067, top_1: 0.778867, top_k: 0.921016, samples/s: 850.282 1613178053.4823198
train: epoch 137, iter 4800, loss: 1.964716, top_1: 0.780937, top_k: 0.923398, samples/s: 849.406 1613178083.621551
train: epoch 137, iter 4900, loss: 1.847230, top_1: 0.780664, top_k: 0.921914, samples/s: 846.953 1613178113.846986
train: epoch 137, iter 5000, loss: 1.903397, top_1: 0.786523, top_k: 0.926484, samples/s: 846.934 1613178144.0740318
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_137.
validation: epoch 137, iter 195, top_1: 0.767248, top_k: 0.932712, samples/s: 2443.596 1613178165.4057899
train: epoch 138, iter 100, loss: 2.020365, top_1: 0.787813, top_k: 0.926562, samples/s: 871.008 1613178215.3709831
train: epoch 138, iter 200, loss: 2.102143, top_1: 0.788477, top_k: 0.924883, samples/s: 868.315 1613178244.85329
train: epoch 138, iter 300, loss: 1.913353, top_1: 0.791055, top_k: 0.929336, samples/s: 853.514 1613178274.8470578
train: epoch 138, iter 400, loss: 1.903255, top_1: 0.789961, top_k: 0.927383, samples/s: 844.994 1613178305.1430426
train: epoch 138, iter 500, loss: 1.938694, top_1: 0.787617, top_k: 0.925664, samples/s: 848.850 1613178335.3015087
train: epoch 138, iter 600, loss: 1.924745, top_1: 0.786133, top_k: 0.925391, samples/s: 849.473 1613178365.4379096
train: epoch 138, iter 700, loss: 2.144285, top_1: 0.786172, top_k: 0.926523, samples/s: 846.218 1613178395.6901436
train: epoch 138, iter 800, loss: 1.861711, top_1: 0.788281, top_k: 0.927617, samples/s: 845.512 1613178425.9676945
train: epoch 138, iter 900, loss: 1.878520, top_1: 0.792656, top_k: 0.926055, samples/s: 847.897 1613178456.1600006
train: epoch 138, iter 1000, loss: 1.812858, top_1: 0.786289, top_k: 0.925039, samples/s: 848.750 1613178486.3220117
train: epoch 138, iter 1100, loss: 1.886579, top_1: 0.785234, top_k: 0.924023, samples/s: 847.918 1613178516.5135846
train: epoch 138, iter 1200, loss: 1.945841, top_1: 0.780117, top_k: 0.923945, samples/s: 847.875 1613178546.7066975
train: epoch 138, iter 1300, loss: 1.832186, top_1: 0.792461, top_k: 0.926211, samples/s: 849.282 1613178576.8498418
train: epoch 138, iter 1400, loss: 1.833404, top_1: 0.789531, top_k: 0.930273, samples/s: 846.343 1613178607.0975301
train: epoch 138, iter 1500, loss: 2.027669, top_1: 0.790078, top_k: 0.928086, samples/s: 849.614 1613178637.2288475
train: epoch 138, iter 1600, loss: 2.068541, top_1: 0.785391, top_k: 0.925977, samples/s: 847.137 1613178667.4483798
train: epoch 138, iter 1700, loss: 1.843858, top_1: 0.793281, top_k: 0.927266, samples/s: 851.115 1613178697.5264926
train: epoch 138, iter 1800, loss: 1.816736, top_1: 0.790703, top_k: 0.928008, samples/s: 846.631 1613178727.7640266
train: epoch 138, iter 1900, loss: 1.894514, top_1: 0.787305, top_k: 0.925977, samples/s: 849.987 1613178757.8821557
train: epoch 138, iter 2000, loss: 1.934227, top_1: 0.789687, top_k: 0.927070, samples/s: 846.400 1613178788.1278481
train: epoch 138, iter 2100, loss: 1.961602, top_1: 0.786875, top_k: 0.926992, samples/s: 846.283 1613178818.3777626
train: epoch 138, iter 2200, loss: 1.959582, top_1: 0.789648, top_k: 0.925039, samples/s: 849.886 1613178848.4994183
train: epoch 138, iter 2300, loss: 1.860509, top_1: 0.782852, top_k: 0.924609, samples/s: 847.549 1613178878.7041512
train: epoch 138, iter 2400, loss: 1.941895, top_1: 0.785234, top_k: 0.928164, samples/s: 849.176 1613178908.851139
train: epoch 138, iter 2500, loss: 1.754022, top_1: 0.783359, top_k: 0.924492, samples/s: 849.876 1613178938.9730964
train: epoch 138, iter 2600, loss: 1.875829, top_1: 0.787617, top_k: 0.928711, samples/s: 847.540 1613178969.178212
train: epoch 138, iter 2700, loss: 1.859443, top_1: 0.787656, top_k: 0.928633, samples/s: 852.074 1613178999.2225509
train: epoch 138, iter 2800, loss: 1.858141, top_1: 0.784922, top_k: 0.924805, samples/s: 848.244 1613179029.402448
train: epoch 138, iter 2900, loss: 1.942891, top_1: 0.786289, top_k: 0.924609, samples/s: 848.978 1613179059.5564349
train: epoch 138, iter 3000, loss: 1.964337, top_1: 0.779922, top_k: 0.924023, samples/s: 850.224 1613179089.6661196
train: epoch 138, iter 3100, loss: 1.994496, top_1: 0.784453, top_k: 0.924570, samples/s: 849.328 1613179119.807563
train: epoch 138, iter 3200, loss: 1.982477, top_1: 0.783672, top_k: 0.925898, samples/s: 847.392 1613179150.0179136
train: epoch 138, iter 3300, loss: 1.886073, top_1: 0.783711, top_k: 0.924922, samples/s: 848.965 1613179180.1722643
train: epoch 138, iter 3400, loss: 1.838644, top_1: 0.786055, top_k: 0.926406, samples/s: 850.254 1613179210.280909
train: epoch 138, iter 3500, loss: 1.911642, top_1: 0.788750, top_k: 0.927930, samples/s: 849.335 1613179240.422135
train: epoch 138, iter 3600, loss: 1.908648, top_1: 0.788633, top_k: 0.926328, samples/s: 847.210 1613179270.6389623
train: epoch 138, iter 3700, loss: 1.851643, top_1: 0.788164, top_k: 0.928281, samples/s: 849.248 1613179300.7833946
train: epoch 138, iter 3800, loss: 1.784302, top_1: 0.786133, top_k: 0.925742, samples/s: 848.987 1613179330.9369416
train: epoch 138, iter 3900, loss: 1.843918, top_1: 0.788203, top_k: 0.926289, samples/s: 851.443 1613179361.0035014
train: epoch 138, iter 4000, loss: 1.871356, top_1: 0.786172, top_k: 0.927773, samples/s: 848.236 1613179391.1837537
train: epoch 138, iter 4100, loss: 1.824831, top_1: 0.785312, top_k: 0.927266, samples/s: 847.688 1613179421.383653
train: epoch 138, iter 4200, loss: 1.855208, top_1: 0.780820, top_k: 0.922734, samples/s: 851.381 1613179451.4524622
train: epoch 138, iter 4300, loss: 1.822855, top_1: 0.789648, top_k: 0.926953, samples/s: 848.866 1613179481.6102686
train: epoch 138, iter 4400, loss: 1.833448, top_1: 0.782031, top_k: 0.923633, samples/s: 849.009 1613179511.7631073
train: epoch 138, iter 4500, loss: 1.928039, top_1: 0.784492, top_k: 0.927422, samples/s: 853.041 1613179541.773306
train: epoch 138, iter 4600, loss: 1.825963, top_1: 0.783477, top_k: 0.922734, samples/s: 847.738 1613179571.9714146
train: epoch 138, iter 4700, loss: 1.990910, top_1: 0.783398, top_k: 0.923789, samples/s: 848.158 1613179602.1544745
train: epoch 138, iter 4800, loss: 1.846717, top_1: 0.787305, top_k: 0.926133, samples/s: 850.533 1613179632.2531748
train: epoch 138, iter 4900, loss: 2.029746, top_1: 0.783750, top_k: 0.925742, samples/s: 848.823 1613179662.4126158
train: epoch 138, iter 5000, loss: 1.875032, top_1: 0.793633, top_k: 0.928789, samples/s: 847.899 1613179692.604981
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_138.
validation: epoch 138, iter 195, top_1: 0.767949, top_k: 0.934936, samples/s: 2484.506 1613179713.589923
train: epoch 139, iter 100, loss: 1.843642, top_1: 0.791836, top_k: 0.927539, samples/s: 872.271 1613179763.7300894
train: epoch 139, iter 200, loss: 1.897000, top_1: 0.789844, top_k: 0.926406, samples/s: 866.759 1613179793.2652926
train: epoch 139, iter 300, loss: 1.821098, top_1: 0.790508, top_k: 0.927188, samples/s: 853.032 1613179823.275937
train: epoch 139, iter 400, loss: 1.887313, top_1: 0.791562, top_k: 0.929102, samples/s: 847.474 1613179853.4834058
train: epoch 139, iter 500, loss: 1.794362, top_1: 0.792891, top_k: 0.927617, samples/s: 847.782 1613179883.6797903
train: epoch 139, iter 600, loss: 1.962525, top_1: 0.794023, top_k: 0.926484, samples/s: 847.619 1613179913.8820434
train: epoch 139, iter 700, loss: 1.877273, top_1: 0.795078, top_k: 0.929688, samples/s: 848.634 1613179944.0482104
train: epoch 139, iter 800, loss: 1.806998, top_1: 0.793594, top_k: 0.927969, samples/s: 844.670 1613179974.355922
train: epoch 139, iter 900, loss: 1.943961, top_1: 0.789648, top_k: 0.926094, samples/s: 847.271 1613180004.5705125
train: epoch 139, iter 1000, loss: 1.849105, top_1: 0.788750, top_k: 0.927344, samples/s: 849.842 1613180034.6937628
train: epoch 139, iter 1100, loss: 1.750132, top_1: 0.790781, top_k: 0.926992, samples/s: 848.074 1613180064.8797872
train: epoch 139, iter 1200, loss: 1.989512, top_1: 0.788320, top_k: 0.927969, samples/s: 847.876 1613180095.0729418
train: epoch 139, iter 1300, loss: 1.988854, top_1: 0.788047, top_k: 0.927227, samples/s: 847.059 1613180125.2951348
train: epoch 139, iter 1400, loss: 1.988012, top_1: 0.789453, top_k: 0.928398, samples/s: 851.878 1613180155.3464117
train: epoch 139, iter 1500, loss: 1.872996, top_1: 0.790273, top_k: 0.929844, samples/s: 845.814 1613180185.6131399
train: epoch 139, iter 1600, loss: 1.804022, top_1: 0.793477, top_k: 0.928125, samples/s: 845.703 1613180215.883809
train: epoch 139, iter 1700, loss: 1.837708, top_1: 0.787656, top_k: 0.926406, samples/s: 849.220 1613180246.0291436
train: epoch 139, iter 1800, loss: 1.848248, top_1: 0.791133, top_k: 0.928281, samples/s: 849.076 1613180276.1796103
train: epoch 139, iter 1900, loss: 1.867283, top_1: 0.789727, top_k: 0.926914, samples/s: 847.683 1613180306.3795946
train: epoch 139, iter 2000, loss: 1.947869, top_1: 0.789375, top_k: 0.929805, samples/s: 850.398 1613180336.4830391
train: epoch 139, iter 2100, loss: 1.737294, top_1: 0.787227, top_k: 0.925781, samples/s: 847.187 1613180366.7007406
train: epoch 139, iter 2200, loss: 1.677035, top_1: 0.791602, top_k: 0.927695, samples/s: 850.394 1613180396.804444
train: epoch 139, iter 2300, loss: 2.004307, top_1: 0.789102, top_k: 0.925312, samples/s: 846.174 1613180427.0582266
train: epoch 139, iter 2400, loss: 1.760392, top_1: 0.791953, top_k: 0.929531, samples/s: 848.322 1613180457.2354655
train: epoch 139, iter 2500, loss: 1.915841, top_1: 0.793906, top_k: 0.928555, samples/s: 850.272 1613180487.3435009
train: epoch 139, iter 2600, loss: 1.901174, top_1: 0.784883, top_k: 0.924570, samples/s: 847.725 1613180517.54202
train: epoch 139, iter 2700, loss: 1.963666, top_1: 0.787383, top_k: 0.925742, samples/s: 847.993 1613180547.7309422
train: epoch 139, iter 2800, loss: 1.860784, top_1: 0.787109, top_k: 0.926641, samples/s: 848.574 1613180577.899104
train: epoch 139, iter 2900, loss: 1.794611, top_1: 0.794531, top_k: 0.928633, samples/s: 848.585 1613180608.0669703
train: epoch 139, iter 3000, loss: 1.867574, top_1: 0.788984, top_k: 0.926094, samples/s: 848.927 1613180638.2227964
train: epoch 139, iter 3100, loss: 1.820166, top_1: 0.789336, top_k: 0.927148, samples/s: 848.286 1613180668.401193
train: epoch 139, iter 3200, loss: 1.969853, top_1: 0.793242, top_k: 0.926953, samples/s: 847.525 1613180698.6068258
train: epoch 139, iter 3300, loss: 1.974200, top_1: 0.790781, top_k: 0.925742, samples/s: 851.001 1613180728.6890502
train: epoch 139, iter 3400, loss: 1.758899, top_1: 0.788320, top_k: 0.927734, samples/s: 847.061 1613180758.9111876
train: epoch 139, iter 3500, loss: 1.804438, top_1: 0.786914, top_k: 0.924766, samples/s: 847.621 1613180789.1134243
train: epoch 139, iter 3600, loss: 1.902391, top_1: 0.785039, top_k: 0.925430, samples/s: 851.110 1613180819.1917498
train: epoch 139, iter 3700, loss: 1.905783, top_1: 0.787930, top_k: 0.927578, samples/s: 844.525 1613180849.5047262
train: epoch 139, iter 3800, loss: 1.883754, top_1: 0.787461, top_k: 0.929023, samples/s: 852.758 1613180879.52494
train: epoch 139, iter 3900, loss: 1.869416, top_1: 0.787695, top_k: 0.928203, samples/s: 849.617 1613180909.6561012
train: epoch 139, iter 4000, loss: 1.912920, top_1: 0.790273, top_k: 0.926758, samples/s: 847.547 1613180939.8610044
train: epoch 139, iter 4100, loss: 1.942594, top_1: 0.789102, top_k: 0.926445, samples/s: 848.298 1613180970.0390193
train: epoch 139, iter 4200, loss: 1.856637, top_1: 0.785117, top_k: 0.927031, samples/s: 849.790 1613181000.1641161
train: epoch 139, iter 4300, loss: 1.766887, top_1: 0.792813, top_k: 0.927891, samples/s: 851.978 1613181030.2118483
train: epoch 139, iter 4400, loss: 2.008064, top_1: 0.785273, top_k: 0.928477, samples/s: 845.456 1613181060.491415
train: epoch 139, iter 4500, loss: 1.889232, top_1: 0.787500, top_k: 0.926680, samples/s: 849.918 1613181090.6119635
train: epoch 139, iter 4600, loss: 1.914974, top_1: 0.783633, top_k: 0.924687, samples/s: 848.357 1613181120.78787
train: epoch 139, iter 4700, loss: 1.960434, top_1: 0.787461, top_k: 0.926680, samples/s: 848.994 1613181150.941188
train: epoch 139, iter 4800, loss: 1.948786, top_1: 0.788750, top_k: 0.925742, samples/s: 850.538 1613181181.0397973
train: epoch 139, iter 4900, loss: 1.886656, top_1: 0.793086, top_k: 0.927813, samples/s: 845.134 1613181211.3308575
train: epoch 139, iter 5000, loss: 1.829607, top_1: 0.795273, top_k: 0.926719, samples/s: 854.436 1613181241.2920976
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_139.
validation: epoch 139, iter 195, top_1: 0.770613, top_k: 0.934756, samples/s: 2461.563 1613181262.4492934
train: epoch 140, iter 100, loss: 1.867827, top_1: 0.798047, top_k: 0.932148, samples/s: 869.528 1613181312.5849588
train: epoch 140, iter 200, loss: 1.886443, top_1: 0.798359, top_k: 0.932891, samples/s: 867.841 1613181342.0834246
train: epoch 140, iter 300, loss: 1.805426, top_1: 0.795937, top_k: 0.929609, samples/s: 852.023 1613181372.1296253
train: epoch 140, iter 400, loss: 1.933058, top_1: 0.796953, top_k: 0.931797, samples/s: 846.563 1613181402.3695583
train: epoch 140, iter 500, loss: 1.900867, top_1: 0.795273, top_k: 0.931719, samples/s: 846.693 1613181432.604762
train: epoch 140, iter 600, loss: 1.827858, top_1: 0.793125, top_k: 0.929219, samples/s: 849.911 1613181462.7256317
train: epoch 140, iter 700, loss: 1.873204, top_1: 0.792813, top_k: 0.927969, samples/s: 849.148 1613181492.8734102
train: epoch 140, iter 800, loss: 1.899843, top_1: 0.796641, top_k: 0.929883, samples/s: 844.963 1613181523.1706543
train: epoch 140, iter 900, loss: 2.030871, top_1: 0.793008, top_k: 0.930312, samples/s: 848.528 1613181553.340591
train: epoch 140, iter 1000, loss: 1.761181, top_1: 0.789687, top_k: 0.929375, samples/s: 846.983 1613181583.5654397
train: epoch 140, iter 1100, loss: 1.889596, top_1: 0.793359, top_k: 0.927930, samples/s: 846.455 1613181613.8092873
train: epoch 140, iter 1200, loss: 1.888470, top_1: 0.793242, top_k: 0.930000, samples/s: 848.745 1613181643.971457
train: epoch 140, iter 1300, loss: 1.925460, top_1: 0.799844, top_k: 0.931914, samples/s: 846.131 1613181674.2267652
train: epoch 140, iter 1400, loss: 1.904916, top_1: 0.792891, top_k: 0.929023, samples/s: 847.271 1613181704.4413602
train: epoch 140, iter 1500, loss: 1.934947, top_1: 0.791289, top_k: 0.925352, samples/s: 846.948 1613181734.667553
train: epoch 140, iter 1600, loss: 1.772159, top_1: 0.793633, top_k: 0.927578, samples/s: 847.238 1613181764.8834755
train: epoch 140, iter 1700, loss: 1.831310, top_1: 0.792539, top_k: 0.930430, samples/s: 847.743 1613181795.0812807
train: epoch 140, iter 1800, loss: 1.937923, top_1: 0.792578, top_k: 0.928594, samples/s: 850.426 1613181825.1838598
train: epoch 140, iter 1900, loss: 1.902832, top_1: 0.792188, top_k: 0.928555, samples/s: 846.353 1613181855.4313107
train: epoch 140, iter 2000, loss: 1.863275, top_1: 0.793984, top_k: 0.929648, samples/s: 849.022 1613181885.5836473
train: epoch 140, iter 2100, loss: 1.920373, top_1: 0.793789, top_k: 0.931523, samples/s: 847.028 1613181915.8069613
train: epoch 140, iter 2200, loss: 1.905776, top_1: 0.793281, top_k: 0.930820, samples/s: 849.654 1613181945.9368718
train: epoch 140, iter 2300, loss: 1.743610, top_1: 0.791602, top_k: 0.926445, samples/s: 850.034 1613181976.0532172
train: epoch 140, iter 2400, loss: 1.820942, top_1: 0.791406, top_k: 0.927070, samples/s: 847.933 1613182006.2443287
train: epoch 140, iter 2500, loss: 2.035444, top_1: 0.788594, top_k: 0.928320, samples/s: 849.436 1613182036.381989
train: epoch 140, iter 2600, loss: 1.937663, top_1: 0.797109, top_k: 0.933398, samples/s: 848.481 1613182066.553494
train: epoch 140, iter 2700, loss: 1.872307, top_1: 0.793359, top_k: 0.929883, samples/s: 847.342 1613182096.7656128
train: epoch 140, iter 2800, loss: 1.869443, top_1: 0.792305, top_k: 0.929688, samples/s: 848.418 1613182126.9395447
train: epoch 140, iter 2900, loss: 1.763806, top_1: 0.793320, top_k: 0.927969, samples/s: 847.459 1613182157.1474245
train: epoch 140, iter 3000, loss: 1.888654, top_1: 0.788945, top_k: 0.928906, samples/s: 848.554 1613182187.3163795
train: epoch 140, iter 3100, loss: 1.987537, top_1: 0.783672, top_k: 0.927266, samples/s: 848.439 1613182217.4894319
train: epoch 140, iter 3200, loss: 1.780523, top_1: 0.791758, top_k: 0.928242, samples/s: 849.093 1613182247.6395795
train: epoch 140, iter 3300, loss: 1.846053, top_1: 0.788711, top_k: 0.925508, samples/s: 845.883 1613182277.9034646
train: epoch 140, iter 3400, loss: 1.857590, top_1: 0.794023, top_k: 0.929570, samples/s: 848.769 1613182308.064833
train: epoch 140, iter 3500, loss: 1.834639, top_1: 0.789297, top_k: 0.928281, samples/s: 850.278 1613182338.172635
train: epoch 140, iter 3600, loss: 1.855687, top_1: 0.791406, top_k: 0.927539, samples/s: 846.648 1613182368.4099047
train: epoch 140, iter 3700, loss: 2.139094, top_1: 0.785664, top_k: 0.925352, samples/s: 848.773 1613182398.5707254
train: epoch 140, iter 3800, loss: 1.856603, top_1: 0.796523, top_k: 0.929141, samples/s: 847.072 1613182428.792428
train: epoch 140, iter 3900, loss: 1.969836, top_1: 0.794336, top_k: 0.928125, samples/s: 850.919 1613182458.8775973
train: epoch 140, iter 4000, loss: 1.959583, top_1: 0.789961, top_k: 0.927227, samples/s: 846.167 1613182489.1315978
train: epoch 140, iter 4100, loss: 1.909457, top_1: 0.795352, top_k: 0.929727, samples/s: 849.945 1613182519.251245
train: epoch 140, iter 4200, loss: 1.824724, top_1: 0.791914, top_k: 0.926172, samples/s: 848.747 1613182549.4132996
train: epoch 140, iter 4300, loss: 1.759011, top_1: 0.792500, top_k: 0.926719, samples/s: 850.855 1613182579.5007355
train: epoch 140, iter 4400, loss: 2.038486, top_1: 0.788008, top_k: 0.928789, samples/s: 848.489 1613182609.672047
train: epoch 140, iter 4500, loss: 1.809851, top_1: 0.791680, top_k: 0.926367, samples/s: 847.800 1613182639.8678617
train: epoch 140, iter 4600, loss: 1.853718, top_1: 0.792266, top_k: 0.929414, samples/s: 849.803 1613182669.992425
train: epoch 140, iter 4700, loss: 1.919330, top_1: 0.789336, top_k: 0.930859, samples/s: 847.638 1613182700.1940079
train: epoch 140, iter 4800, loss: 1.867787, top_1: 0.792773, top_k: 0.929961, samples/s: 847.030 1613182730.4173412
train: epoch 140, iter 4900, loss: 1.806542, top_1: 0.796641, top_k: 0.929258, samples/s: 849.042 1613182760.5688791
train: epoch 140, iter 5000, loss: 1.870442, top_1: 0.795898, top_k: 0.928242, samples/s: 847.256 1613182790.7842076
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_140.
validation: epoch 140, iter 195, top_1: 0.771675, top_k: 0.935056, samples/s: 2451.414 1613182812.0424855
train: epoch 141, iter 100, loss: 1.829734, top_1: 0.800977, top_k: 0.932344, samples/s: 871.229 1613182862.05264
train: epoch 141, iter 200, loss: 1.874777, top_1: 0.799648, top_k: 0.930000, samples/s: 868.244 1613182891.53744
train: epoch 141, iter 300, loss: 1.857222, top_1: 0.797852, top_k: 0.932109, samples/s: 851.823 1613182921.5905902
train: epoch 141, iter 400, loss: 1.888032, top_1: 0.800703, top_k: 0.930391, samples/s: 847.334 1613182951.8029969
train: epoch 141, iter 500, loss: 1.786443, top_1: 0.798867, top_k: 0.928984, samples/s: 848.263 1613182981.9824162
train: epoch 141, iter 600, loss: 1.886252, top_1: 0.797109, top_k: 0.930547, samples/s: 846.419 1613183012.2274187
train: epoch 141, iter 700, loss: 1.770126, top_1: 0.795312, top_k: 0.931445, samples/s: 848.279 1613183042.406108
train: epoch 141, iter 800, loss: 1.920786, top_1: 0.794648, top_k: 0.931641, samples/s: 848.769 1613183072.5674992
train: epoch 141, iter 900, loss: 1.850927, top_1: 0.793359, top_k: 0.928594, samples/s: 845.238 1613183102.8548474
train: epoch 141, iter 1000, loss: 1.870534, top_1: 0.800156, top_k: 0.931875, samples/s: 848.215 1613183133.0358915
train: epoch 141, iter 1100, loss: 1.881302, top_1: 0.799297, top_k: 0.931289, samples/s: 849.354 1613183163.1763704
train: epoch 141, iter 1200, loss: 1.840532, top_1: 0.793516, top_k: 0.929102, samples/s: 848.932 1613183193.3319747
train: epoch 141, iter 1300, loss: 1.832235, top_1: 0.795547, top_k: 0.928633, samples/s: 845.420 1613183223.612722
train: epoch 141, iter 1400, loss: 1.962653, top_1: 0.799766, top_k: 0.930937, samples/s: 850.451 1613183253.7143466
train: epoch 141, iter 1500, loss: 1.836324, top_1: 0.799063, top_k: 0.931641, samples/s: 844.780 1613183284.0181587
train: epoch 141, iter 1600, loss: 1.791086, top_1: 0.793633, top_k: 0.928008, samples/s: 852.997 1613183314.0300567
train: epoch 141, iter 1700, loss: 1.798530, top_1: 0.801562, top_k: 0.932813, samples/s: 847.845 1613183344.224219
train: epoch 141, iter 1800, loss: 1.826262, top_1: 0.798633, top_k: 0.932031, samples/s: 846.721 1613183374.4585176
train: epoch 141, iter 1900, loss: 1.746545, top_1: 0.796289, top_k: 0.929141, samples/s: 849.150 1613183404.6063132
train: epoch 141, iter 2000, loss: 1.938334, top_1: 0.797148, top_k: 0.931641, samples/s: 847.521 1613183434.8120186
train: epoch 141, iter 2100, loss: 1.878045, top_1: 0.794375, top_k: 0.929766, samples/s: 848.723 1613183464.9749744
train: epoch 141, iter 2200, loss: 1.900417, top_1: 0.797148, top_k: 0.930820, samples/s: 846.586 1613183495.214087
train: epoch 141, iter 2300, loss: 1.875319, top_1: 0.796875, top_k: 0.932344, samples/s: 847.732 1613183525.4122932
train: epoch 141, iter 2400, loss: 1.848589, top_1: 0.795391, top_k: 0.931953, samples/s: 850.677 1613183555.506003
train: epoch 141, iter 2500, loss: 1.876194, top_1: 0.802695, top_k: 0.931445, samples/s: 847.186 1613183585.723709
train: epoch 141, iter 2600, loss: 1.880211, top_1: 0.795859, top_k: 0.928828, samples/s: 846.740 1613183615.9573069
train: epoch 141, iter 2700, loss: 1.825561, top_1: 0.799531, top_k: 0.930000, samples/s: 848.060 1613183646.143761
train: epoch 141, iter 2800, loss: 1.760876, top_1: 0.796172, top_k: 0.932148, samples/s: 849.928 1613183676.2639568
train: epoch 141, iter 2900, loss: 1.866806, top_1: 0.787734, top_k: 0.925977, samples/s: 846.905 1613183706.4916687
train: epoch 141, iter 3000, loss: 1.938907, top_1: 0.794180, top_k: 0.928789, samples/s: 849.074 1613183736.642221
train: epoch 141, iter 3100, loss: 1.830993, top_1: 0.798008, top_k: 0.930156, samples/s: 848.701 1613183766.805974
train: epoch 141, iter 3200, loss: 1.819723, top_1: 0.795195, top_k: 0.929414, samples/s: 849.037 1613183796.957727
train: epoch 141, iter 3300, loss: 1.840258, top_1: 0.800977, top_k: 0.933164, samples/s: 847.698 1613183827.157173
train: epoch 141, iter 3400, loss: 1.891555, top_1: 0.795391, top_k: 0.929023, samples/s: 847.823 1613183857.3520973
train: epoch 141, iter 3500, loss: 1.697039, top_1: 0.795430, top_k: 0.929492, samples/s: 849.794 1613183887.4771245
train: epoch 141, iter 3600, loss: 1.792054, top_1: 0.794336, top_k: 0.931875, samples/s: 849.098 1613183917.626766
train: epoch 141, iter 3700, loss: 1.694096, top_1: 0.793750, top_k: 0.927383, samples/s: 849.600 1613183947.758512
train: epoch 141, iter 3800, loss: 1.818250, top_1: 0.791367, top_k: 0.929922, samples/s: 846.573 1613183977.9980981
train: epoch 141, iter 3900, loss: 1.966377, top_1: 0.796172, top_k: 0.929805, samples/s: 851.189 1613184008.073699
train: epoch 141, iter 4000, loss: 1.862730, top_1: 0.792344, top_k: 0.926836, samples/s: 847.704 1613184038.2729247
train: epoch 141, iter 4100, loss: 1.896705, top_1: 0.794531, top_k: 0.930195, samples/s: 850.307 1613184068.3795965
train: epoch 141, iter 4200, loss: 1.838521, top_1: 0.797930, top_k: 0.928438, samples/s: 851.332 1613184098.450251
train: epoch 141, iter 4300, loss: 1.773354, top_1: 0.796914, top_k: 0.929258, samples/s: 849.440 1613184128.5877051
train: epoch 141, iter 4400, loss: 1.876101, top_1: 0.791719, top_k: 0.928008, samples/s: 850.116 1613184158.7012744
train: epoch 141, iter 4500, loss: 1.896724, top_1: 0.789648, top_k: 0.928828, samples/s: 846.170 1613184188.9551
train: epoch 141, iter 4600, loss: 1.881950, top_1: 0.794180, top_k: 0.930664, samples/s: 848.164 1613184219.137937
train: epoch 141, iter 4700, loss: 1.829598, top_1: 0.791016, top_k: 0.925703, samples/s: 850.095 1613184249.2522397
train: epoch 141, iter 4800, loss: 1.814579, top_1: 0.794492, top_k: 0.931797, samples/s: 848.753 1613184279.4141397
train: epoch 141, iter 4900, loss: 1.810151, top_1: 0.793555, top_k: 0.929297, samples/s: 847.629 1613184309.6159964
train: epoch 141, iter 5000, loss: 1.802689, top_1: 0.801797, top_k: 0.932344, samples/s: 851.054 1613184339.6963499
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_141.
validation: epoch 141, iter 195, top_1: 0.769571, top_k: 0.936018, samples/s: 2446.497 1613184360.9984605
train: epoch 142, iter 100, loss: 1.809393, top_1: 0.802813, top_k: 0.930898, samples/s: 869.444 1613184410.5609365
train: epoch 142, iter 200, loss: 1.858268, top_1: 0.803008, top_k: 0.930547, samples/s: 869.753 1613184439.994508
train: epoch 142, iter 300, loss: 1.875401, top_1: 0.796992, top_k: 0.933516, samples/s: 853.771 1613184469.9791908
train: epoch 142, iter 400, loss: 1.805084, top_1: 0.800742, top_k: 0.934180, samples/s: 845.598 1613184500.2536142
train: epoch 142, iter 500, loss: 1.873070, top_1: 0.806055, top_k: 0.933086, samples/s: 848.305 1613184530.4314075
train: epoch 142, iter 600, loss: 2.086421, top_1: 0.799727, top_k: 0.930547, samples/s: 843.850 1613184560.7685022
train: epoch 142, iter 700, loss: 1.948493, top_1: 0.801836, top_k: 0.933164, samples/s: 847.452 1613184590.9766824
train: epoch 142, iter 800, loss: 1.794008, top_1: 0.800352, top_k: 0.931367, samples/s: 844.829 1613184621.278712
train: epoch 142, iter 900, loss: 1.918905, top_1: 0.798789, top_k: 0.929961, samples/s: 846.533 1613184651.519697
train: epoch 142, iter 1000, loss: 1.651583, top_1: 0.800156, top_k: 0.928633, samples/s: 847.900 1613184681.7119226
train: epoch 142, iter 1100, loss: 1.808793, top_1: 0.797813, top_k: 0.931172, samples/s: 847.637 1613184711.9136064
train: epoch 142, iter 1200, loss: 1.794597, top_1: 0.802695, top_k: 0.934297, samples/s: 846.665 1613184742.1499333
train: epoch 142, iter 1300, loss: 1.848017, top_1: 0.801055, top_k: 0.931211, samples/s: 849.909 1613184772.2706985
train: epoch 142, iter 1400, loss: 1.857636, top_1: 0.799648, top_k: 0.931289, samples/s: 845.038 1613184802.5651937
train: epoch 142, iter 1500, loss: 1.821446, top_1: 0.798477, top_k: 0.933008, samples/s: 848.970 1613184832.7194185
train: epoch 142, iter 1600, loss: 1.816137, top_1: 0.799453, top_k: 0.934258, samples/s: 844.929 1613184863.0178356
train: epoch 142, iter 1700, loss: 1.935697, top_1: 0.796211, top_k: 0.930625, samples/s: 850.474 1613184893.1186676
train: epoch 142, iter 1800, loss: 1.794995, top_1: 0.802148, top_k: 0.930664, samples/s: 847.325 1613184923.3313482
train: epoch 142, iter 1900, loss: 1.838244, top_1: 0.799570, top_k: 0.930039, samples/s: 844.476 1613184953.645994
train: epoch 142, iter 2000, loss: 2.066266, top_1: 0.799063, top_k: 0.932109, samples/s: 847.765 1613184983.843139
train: epoch 142, iter 2100, loss: 1.751338, top_1: 0.807266, top_k: 0.933789, samples/s: 851.682 1613185013.9012961
train: epoch 142, iter 2200, loss: 1.863621, top_1: 0.800312, top_k: 0.929063, samples/s: 847.409 1613185044.1109715
train: epoch 142, iter 2300, loss: 1.837918, top_1: 0.797734, top_k: 0.931016, samples/s: 848.215 1613185074.2920818
train: epoch 142, iter 2400, loss: 1.844806, top_1: 0.800352, top_k: 0.928633, samples/s: 846.579 1613185104.531398
train: epoch 142, iter 2500, loss: 1.907505, top_1: 0.799687, top_k: 0.932461, samples/s: 849.233 1613185134.6762307
train: epoch 142, iter 2600, loss: 1.768962, top_1: 0.798203, top_k: 0.930508, samples/s: 846.645 1613185164.9132817
train: epoch 142, iter 2700, loss: 1.785105, top_1: 0.797617, top_k: 0.930859, samples/s: 846.549 1613185195.1536849
train: epoch 142, iter 2800, loss: 1.934314, top_1: 0.798008, top_k: 0.930937, samples/s: 847.647 1613185225.3548353
train: epoch 142, iter 2900, loss: 1.736113, top_1: 0.801602, top_k: 0.933125, samples/s: 847.900 1613185255.5471601
train: epoch 142, iter 3000, loss: 1.751126, top_1: 0.793125, top_k: 0.928047, samples/s: 848.003 1613185285.735658
train: epoch 142, iter 3100, loss: 1.756693, top_1: 0.799023, top_k: 0.935039, samples/s: 849.188 1613185315.8821495
train: epoch 142, iter 3200, loss: 1.659349, top_1: 0.799609, top_k: 0.930391, samples/s: 845.466 1613185346.1613042
train: epoch 142, iter 3300, loss: 1.923613, top_1: 0.795195, top_k: 0.932461, samples/s: 848.492 1613185376.332431
train: epoch 142, iter 3400, loss: 1.898720, top_1: 0.797695, top_k: 0.930195, samples/s: 848.015 1613185406.5206356
train: epoch 142, iter 3500, loss: 1.826147, top_1: 0.801172, top_k: 0.932734, samples/s: 847.091 1613185436.7416434
train: epoch 142, iter 3600, loss: 1.975881, top_1: 0.791680, top_k: 0.928125, samples/s: 847.905 1613185466.9337819
train: epoch 142, iter 3700, loss: 1.899760, top_1: 0.800352, top_k: 0.932187, samples/s: 846.409 1613185497.179091
train: epoch 142, iter 3800, loss: 1.770582, top_1: 0.800664, top_k: 0.931094, samples/s: 849.627 1613185527.3100197
train: epoch 142, iter 3900, loss: 1.772992, top_1: 0.801562, top_k: 0.931953, samples/s: 849.458 1613185557.4468596
train: epoch 142, iter 4000, loss: 1.887089, top_1: 0.803711, top_k: 0.933203, samples/s: 848.187 1613185587.6288874
train: epoch 142, iter 4100, loss: 1.792652, top_1: 0.801406, top_k: 0.931367, samples/s: 850.237 1613185617.7381592
train: epoch 142, iter 4200, loss: 1.773181, top_1: 0.794883, top_k: 0.927305, samples/s: 843.855 1613185648.0751772
train: epoch 142, iter 4300, loss: 1.851276, top_1: 0.793789, top_k: 0.930195, samples/s: 848.459 1613185678.2475488
train: epoch 142, iter 4400, loss: 1.861405, top_1: 0.794570, top_k: 0.929531, samples/s: 845.945 1613185708.5094888
train: epoch 142, iter 4500, loss: 1.712662, top_1: 0.800664, top_k: 0.934063, samples/s: 847.945 1613185738.7001219
train: epoch 142, iter 4600, loss: 2.008793, top_1: 0.798086, top_k: 0.930000, samples/s: 846.826 1613185768.9306285
train: epoch 142, iter 4700, loss: 1.837313, top_1: 0.799609, top_k: 0.932148, samples/s: 847.207 1613185799.1475525
train: epoch 142, iter 4800, loss: 1.946546, top_1: 0.796992, top_k: 0.931406, samples/s: 848.743 1613185829.30984
train: epoch 142, iter 4900, loss: 1.769724, top_1: 0.798008, top_k: 0.930898, samples/s: 845.687 1613185859.5811555
train: epoch 142, iter 5000, loss: 1.754921, top_1: 0.802656, top_k: 0.933320, samples/s: 850.289 1613185889.6885371
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_142.
validation: epoch 142, iter 195, top_1: 0.772977, top_k: 0.936538, samples/s: 2457.753 1613185910.9044828
train: epoch 143, iter 100, loss: 1.823138, top_1: 0.803945, top_k: 0.933906, samples/s: 869.857 1613185960.63849
train: epoch 143, iter 200, loss: 1.817853, top_1: 0.803477, top_k: 0.934063, samples/s: 868.025 1613185990.1307297
train: epoch 143, iter 300, loss: 1.795214, top_1: 0.802969, top_k: 0.932734, samples/s: 853.835 1613186020.11304
train: epoch 143, iter 400, loss: 1.882438, top_1: 0.805859, top_k: 0.932383, samples/s: 847.138 1613186050.3325162
train: epoch 143, iter 500, loss: 1.804100, top_1: 0.808633, top_k: 0.935117, samples/s: 845.558 1613186080.6082783
train: epoch 143, iter 600, loss: 1.876726, top_1: 0.803438, top_k: 0.933711, samples/s: 846.607 1613186110.8466663
train: epoch 143, iter 700, loss: 1.740501, top_1: 0.806094, top_k: 0.933594, samples/s: 845.537 1613186141.1232767
train: epoch 143, iter 800, loss: 1.812419, top_1: 0.807734, top_k: 0.935781, samples/s: 845.506 1613186171.4010668
train: epoch 143, iter 900, loss: 1.883410, top_1: 0.804531, top_k: 0.935234, samples/s: 846.842 1613186201.6309502
train: epoch 143, iter 1000, loss: 1.836770, top_1: 0.804180, top_k: 0.936055, samples/s: 846.785 1613186231.8629563
train: epoch 143, iter 1100, loss: 1.844618, top_1: 0.803633, top_k: 0.933867, samples/s: 845.418 1613186262.1438134
train: epoch 143, iter 1200, loss: 1.858244, top_1: 0.803086, top_k: 0.933945, samples/s: 845.593 1613186292.4184988
train: epoch 143, iter 1300, loss: 1.923934, top_1: 0.802852, top_k: 0.931406, samples/s: 849.040 1613186322.570219
train: epoch 143, iter 1400, loss: 1.794713, top_1: 0.801406, top_k: 0.932578, samples/s: 850.761 1613186352.6609213
train: epoch 143, iter 1500, loss: 1.793232, top_1: 0.804609, top_k: 0.934688, samples/s: 846.601 1613186382.8995025
train: epoch 143, iter 1600, loss: 1.790009, top_1: 0.800273, top_k: 0.929492, samples/s: 849.761 1613186413.0256042
train: epoch 143, iter 1700, loss: 1.833523, top_1: 0.803320, top_k: 0.931172, samples/s: 845.966 1613186443.2867622
train: epoch 143, iter 1800, loss: 1.979911, top_1: 0.799141, top_k: 0.929922, samples/s: 844.198 1613186473.6114159
train: epoch 143, iter 1900, loss: 1.774503, top_1: 0.799609, top_k: 0.932031, samples/s: 850.702 1613186503.7042756
train: epoch 143, iter 2000, loss: 1.853011, top_1: 0.802578, top_k: 0.931680, samples/s: 848.673 1613186533.869005
train: epoch 143, iter 2100, loss: 1.962271, top_1: 0.803594, top_k: 0.932187, samples/s: 845.737 1613186564.1384442
train: epoch 143, iter 2200, loss: 1.967983, top_1: 0.803477, top_k: 0.933828, samples/s: 848.358 1613186594.314345
train: epoch 143, iter 2300, loss: 1.805910, top_1: 0.799375, top_k: 0.931172, samples/s: 847.644 1613186624.515716
train: epoch 143, iter 2400, loss: 1.866452, top_1: 0.797148, top_k: 0.930820, samples/s: 845.820 1613186654.7822118
train: epoch 143, iter 2500, loss: 1.862733, top_1: 0.804766, top_k: 0.933164, samples/s: 849.005 1613186684.9351804
train: epoch 143, iter 2600, loss: 1.977232, top_1: 0.796914, top_k: 0.929453, samples/s: 847.792 1613186715.1311843
train: epoch 143, iter 2700, loss: 1.899489, top_1: 0.799687, top_k: 0.934805, samples/s: 845.140 1613186745.4220426
train: epoch 143, iter 2800, loss: 1.957963, top_1: 0.801875, top_k: 0.934063, samples/s: 851.264 1613186775.4949524
train: epoch 143, iter 2900, loss: 1.891868, top_1: 0.801328, top_k: 0.930898, samples/s: 846.999 1613186805.719318
train: epoch 143, iter 3000, loss: 1.799729, top_1: 0.798828, top_k: 0.930508, samples/s: 849.246 1613186835.86374
train: epoch 143, iter 3100, loss: 1.803426, top_1: 0.807227, top_k: 0.934688, samples/s: 846.350 1613186866.1112783
train: epoch 143, iter 3200, loss: 1.834641, top_1: 0.806133, top_k: 0.933516, samples/s: 849.577 1613186896.2439406
train: epoch 143, iter 3300, loss: 1.900712, top_1: 0.802852, top_k: 0.935000, samples/s: 849.895 1613186926.3653178
train: epoch 143, iter 3400, loss: 1.799675, top_1: 0.805039, top_k: 0.932227, samples/s: 845.171 1613186956.654972
train: epoch 143, iter 3500, loss: 1.871858, top_1: 0.804492, top_k: 0.933398, samples/s: 849.836 1613186986.778421
train: epoch 143, iter 3600, loss: 1.873027, top_1: 0.802422, top_k: 0.934922, samples/s: 851.664 1613187016.83723
train: epoch 143, iter 3700, loss: 1.863626, top_1: 0.799023, top_k: 0.933008, samples/s: 846.804 1613187047.0685904
train: epoch 143, iter 3800, loss: 1.876046, top_1: 0.798516, top_k: 0.929883, samples/s: 848.719 1613187077.2317321
train: epoch 143, iter 3900, loss: 1.789312, top_1: 0.796680, top_k: 0.928984, samples/s: 845.622 1613187107.5052757
train: epoch 143, iter 4000, loss: 1.818359, top_1: 0.800898, top_k: 0.933008, samples/s: 850.436 1613187137.6074448
train: epoch 143, iter 4100, loss: 1.731789, top_1: 0.801172, top_k: 0.930352, samples/s: 845.518 1613187167.8847404
train: epoch 143, iter 4200, loss: 1.940247, top_1: 0.799336, top_k: 0.931562, samples/s: 847.464 1613187198.0925772
train: epoch 143, iter 4300, loss: 1.777076, top_1: 0.799297, top_k: 0.933047, samples/s: 850.857 1613187228.1798723
train: epoch 143, iter 4400, loss: 1.738554, top_1: 0.802852, top_k: 0.933438, samples/s: 845.851 1613187258.4452286
train: epoch 143, iter 4500, loss: 1.656555, top_1: 0.799023, top_k: 0.930430, samples/s: 848.012 1613187288.6335568
train: epoch 143, iter 4600, loss: 1.955374, top_1: 0.797969, top_k: 0.933086, samples/s: 848.208 1613187318.8148448
train: epoch 143, iter 4700, loss: 1.841765, top_1: 0.797773, top_k: 0.933438, samples/s: 848.616 1613187348.981542
train: epoch 143, iter 4800, loss: 2.005423, top_1: 0.796484, top_k: 0.930312, samples/s: 850.235 1613187379.0909307
train: epoch 143, iter 4900, loss: 1.815104, top_1: 0.802266, top_k: 0.933477, samples/s: 846.799 1613187409.3224068
train: epoch 143, iter 5000, loss: 1.827280, top_1: 0.807813, top_k: 0.935625, samples/s: 848.438 1613187439.4955368
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_143.
validation: epoch 143, iter 195, top_1: 0.771414, top_k: 0.935797, samples/s: 2480.020 1613187460.5233147
train: epoch 144, iter 100, loss: 1.828201, top_1: 0.806523, top_k: 0.935039, samples/s: 870.539 1613187510.5807736
train: epoch 144, iter 200, loss: 1.891230, top_1: 0.804297, top_k: 0.932031, samples/s: 867.805 1613187540.080558
train: epoch 144, iter 300, loss: 1.771729, top_1: 0.805312, top_k: 0.932578, samples/s: 853.469 1613187570.0757334
train: epoch 144, iter 400, loss: 1.833616, top_1: 0.805898, top_k: 0.932148, samples/s: 845.168 1613187600.3655486
train: epoch 144, iter 500, loss: 1.866535, top_1: 0.805742, top_k: 0.934102, samples/s: 846.416 1613187630.6107328
train: epoch 144, iter 600, loss: 1.725619, top_1: 0.806406, top_k: 0.933867, samples/s: 846.767 1613187660.8434744
train: epoch 144, iter 700, loss: 1.842103, top_1: 0.809453, top_k: 0.933711, samples/s: 846.740 1613187691.0769823
train: epoch 144, iter 800, loss: 1.823039, top_1: 0.806523, top_k: 0.931758, samples/s: 846.870 1613187721.3059871
train: epoch 144, iter 900, loss: 1.889668, top_1: 0.803125, top_k: 0.935703, samples/s: 844.714 1613187751.6120539
train: epoch 144, iter 1000, loss: 1.836096, top_1: 0.805781, top_k: 0.934063, samples/s: 845.743 1613187781.8813136
train: epoch 144, iter 1100, loss: 1.761099, top_1: 0.809297, top_k: 0.934180, samples/s: 849.714 1613187812.0091639
train: epoch 144, iter 1200, loss: 1.869029, top_1: 0.808008, top_k: 0.935352, samples/s: 847.726 1613187842.207497
train: epoch 144, iter 1300, loss: 1.742562, top_1: 0.803047, top_k: 0.930937, samples/s: 846.637 1613187872.4448738
train: epoch 144, iter 1400, loss: 1.959004, top_1: 0.804180, top_k: 0.933281, samples/s: 846.561 1613187902.6847684
train: epoch 144, iter 1500, loss: 2.052918, top_1: 0.803828, top_k: 0.932070, samples/s: 848.503 1613187932.8556602
train: epoch 144, iter 1600, loss: 1.819387, top_1: 0.804805, top_k: 0.933047, samples/s: 848.208 1613187963.036886
train: epoch 144, iter 1700, loss: 1.820207, top_1: 0.807109, top_k: 0.934531, samples/s: 847.785 1613187993.2332125
train: epoch 144, iter 1800, loss: 1.773947, top_1: 0.802344, top_k: 0.930586, samples/s: 848.108 1613188023.4180486
train: epoch 144, iter 1900, loss: 1.810906, top_1: 0.800000, top_k: 0.933086, samples/s: 848.390 1613188053.5928864
train: epoch 144, iter 2000, loss: 1.747029, top_1: 0.802734, top_k: 0.934141, samples/s: 847.533 1613188083.79823
train: epoch 144, iter 2100, loss: 1.822591, top_1: 0.804844, top_k: 0.930977, samples/s: 845.767 1613188114.0665603
train: epoch 144, iter 2200, loss: 1.719893, top_1: 0.808281, top_k: 0.933320, samples/s: 850.445 1613188144.1683993
train: epoch 144, iter 2300, loss: 1.746397, top_1: 0.803906, top_k: 0.931211, samples/s: 844.534 1613188174.481011
train: epoch 144, iter 2400, loss: 1.637239, top_1: 0.804531, top_k: 0.934063, samples/s: 849.042 1613188204.6326125
train: epoch 144, iter 2500, loss: 1.894993, top_1: 0.804961, top_k: 0.932969, samples/s: 844.248 1613188234.9554272
train: epoch 144, iter 2600, loss: 1.828911, top_1: 0.801797, top_k: 0.933906, samples/s: 850.148 1613188265.0678718
train: epoch 144, iter 2700, loss: 1.850469, top_1: 0.801367, top_k: 0.933320, samples/s: 850.117 1613188295.1813548
train: epoch 144, iter 2800, loss: 1.820412, top_1: 0.803711, top_k: 0.935391, samples/s: 844.296 1613188325.502531
train: epoch 144, iter 2900, loss: 1.743042, top_1: 0.803750, top_k: 0.931094, samples/s: 848.568 1613188355.670887
train: epoch 144, iter 3000, loss: 1.796922, top_1: 0.806328, top_k: 0.936328, samples/s: 848.704 1613188385.8345342
train: epoch 144, iter 3100, loss: 1.877713, top_1: 0.807344, top_k: 0.933789, samples/s: 846.635 1613188416.0718675
train: epoch 144, iter 3200, loss: 1.962871, top_1: 0.807148, top_k: 0.935156, samples/s: 847.683 1613188446.2719147
train: epoch 144, iter 3300, loss: 1.767550, top_1: 0.799570, top_k: 0.931602, samples/s: 846.962 1613188476.497592
train: epoch 144, iter 3400, loss: 1.839047, top_1: 0.806992, top_k: 0.933711, samples/s: 849.382 1613188506.637075
train: epoch 144, iter 3500, loss: 1.951893, top_1: 0.803867, top_k: 0.934531, samples/s: 846.786 1613188536.86906
train: epoch 144, iter 3600, loss: 1.874344, top_1: 0.802188, top_k: 0.934688, samples/s: 848.431 1613188567.0424414
train: epoch 144, iter 3700, loss: 1.879634, top_1: 0.803086, top_k: 0.931719, samples/s: 848.531 1613188597.2122478
train: epoch 144, iter 3800, loss: 1.759591, top_1: 0.805312, top_k: 0.934961, samples/s: 845.837 1613188627.4781468
train: epoch 144, iter 3900, loss: 1.913827, top_1: 0.806250, top_k: 0.933438, samples/s: 848.694 1613188657.6420274
train: epoch 144, iter 4000, loss: 1.890694, top_1: 0.805547, top_k: 0.934922, samples/s: 848.966 1613188687.796385
train: epoch 144, iter 4100, loss: 1.738586, top_1: 0.804453, top_k: 0.933125, samples/s: 848.988 1613188717.9499757
train: epoch 144, iter 4200, loss: 1.905342, top_1: 0.803398, top_k: 0.933281, samples/s: 847.702 1613188748.1491773
train: epoch 144, iter 4300, loss: 1.764451, top_1: 0.806680, top_k: 0.934023, samples/s: 850.058 1613188778.264808
train: epoch 144, iter 4400, loss: 1.670918, top_1: 0.802773, top_k: 0.935195, samples/s: 846.537 1613188808.5056057
train: epoch 144, iter 4500, loss: 1.810680, top_1: 0.808672, top_k: 0.935234, samples/s: 847.632 1613188838.7073739
train: epoch 144, iter 4600, loss: 1.752256, top_1: 0.807109, top_k: 0.936328, samples/s: 848.157 1613188868.8905635
train: epoch 144, iter 4700, loss: 1.861684, top_1: 0.801797, top_k: 0.934258, samples/s: 846.850 1613188899.120176
train: epoch 144, iter 4800, loss: 1.833577, top_1: 0.800859, top_k: 0.930859, samples/s: 846.179 1613188929.3738494
train: epoch 144, iter 4900, loss: 2.017959, top_1: 0.805703, top_k: 0.934258, samples/s: 850.532 1613188959.4726112
train: epoch 144, iter 5000, loss: 1.749287, top_1: 0.806289, top_k: 0.935625, samples/s: 844.606 1613188989.7826288
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_144.
validation: epoch 144, iter 195, top_1: 0.773618, top_k: 0.936679, samples/s: 2431.431 1613189011.2240763
train: epoch 145, iter 100, loss: 1.688179, top_1: 0.810039, top_k: 0.934570, samples/s: 871.252 1613189061.1629062
train: epoch 145, iter 200, loss: 1.839688, top_1: 0.809922, top_k: 0.934297, samples/s: 867.413 1613189090.6758788
train: epoch 145, iter 300, loss: 1.970338, top_1: 0.812227, top_k: 0.936445, samples/s: 848.966 1613189120.830204
train: epoch 145, iter 400, loss: 1.743803, top_1: 0.805820, top_k: 0.935195, samples/s: 847.257 1613189151.0454195
train: epoch 145, iter 500, loss: 1.897237, top_1: 0.806484, top_k: 0.935234, samples/s: 847.305 1613189181.2587993
train: epoch 145, iter 600, loss: 1.758716, top_1: 0.805508, top_k: 0.933086, samples/s: 846.142 1613189211.51375
train: epoch 145, iter 700, loss: 1.781251, top_1: 0.811914, top_k: 0.937617, samples/s: 846.515 1613189241.7554123
train: epoch 145, iter 800, loss: 1.826915, top_1: 0.809961, top_k: 0.936406, samples/s: 848.788 1613189271.9159818
train: epoch 145, iter 900, loss: 1.958846, top_1: 0.807148, top_k: 0.934883, samples/s: 845.764 1613189302.1845763
train: epoch 145, iter 1000, loss: 1.950802, top_1: 0.808477, top_k: 0.932969, samples/s: 847.210 1613189332.4013572
train: epoch 145, iter 1100, loss: 1.711798, top_1: 0.803711, top_k: 0.932461, samples/s: 846.861 1613189362.6306596
train: epoch 145, iter 1200, loss: 1.885579, top_1: 0.807383, top_k: 0.935508, samples/s: 847.125 1613189392.850567
train: epoch 145, iter 1300, loss: 1.651854, top_1: 0.810977, top_k: 0.937734, samples/s: 848.155 1613189423.033648
train: epoch 145, iter 1400, loss: 1.781524, top_1: 0.802930, top_k: 0.934531, samples/s: 845.683 1613189453.3051543
train: epoch 145, iter 1500, loss: 1.755521, top_1: 0.811055, top_k: 0.935547, samples/s: 847.093 1613189483.5261173
train: epoch 145, iter 1600, loss: 1.779812, top_1: 0.805937, top_k: 0.932930, samples/s: 850.678 1613189513.6196961
train: epoch 145, iter 1700, loss: 1.860489, top_1: 0.807617, top_k: 0.934844, samples/s: 844.833 1613189543.921624
train: epoch 145, iter 1800, loss: 1.833457, top_1: 0.812227, top_k: 0.938320, samples/s: 849.209 1613189574.0672681
train: epoch 145, iter 1900, loss: 1.911419, top_1: 0.810156, top_k: 0.937539, samples/s: 847.902 1613189604.259528
train: epoch 145, iter 2000, loss: 1.999813, top_1: 0.803750, top_k: 0.933867, samples/s: 846.347 1613189634.5070746
train: epoch 145, iter 2100, loss: 1.901129, top_1: 0.805859, top_k: 0.934414, samples/s: 845.918 1613189664.77008
train: epoch 145, iter 2200, loss: 1.751529, top_1: 0.809141, top_k: 0.934766, samples/s: 844.837 1613189695.0717251
train: epoch 145, iter 2300, loss: 1.803064, top_1: 0.807344, top_k: 0.935195, samples/s: 847.505 1613189725.2781327
train: epoch 145, iter 2400, loss: 1.773753, top_1: 0.803164, top_k: 0.933594, samples/s: 846.627 1613189755.5156755
train: epoch 145, iter 2500, loss: 1.842624, top_1: 0.805937, top_k: 0.935898, samples/s: 848.002 1613189785.7043722
train: epoch 145, iter 2600, loss: 1.848446, top_1: 0.804297, top_k: 0.933789, samples/s: 847.097 1613189815.9252408
train: epoch 145, iter 2700, loss: 1.938582, top_1: 0.807969, top_k: 0.934180, samples/s: 847.356 1613189846.1368446
train: epoch 145, iter 2800, loss: 1.745273, top_1: 0.811367, top_k: 0.935430, samples/s: 845.952 1613189876.3985095
train: epoch 145, iter 2900, loss: 1.847401, top_1: 0.808125, top_k: 0.934531, samples/s: 848.825 1613189906.557912
train: epoch 145, iter 3000, loss: 1.823222, top_1: 0.809727, top_k: 0.935117, samples/s: 844.911 1613189936.856866
train: epoch 145, iter 3100, loss: 1.878250, top_1: 0.802070, top_k: 0.931016, samples/s: 845.788 1613189967.1245952
train: epoch 145, iter 3200, loss: 1.901321, top_1: 0.799687, top_k: 0.932773, samples/s: 847.832 1613189997.3193069
train: epoch 145, iter 3300, loss: 1.758618, top_1: 0.807695, top_k: 0.933438, samples/s: 848.371 1613190027.4946856
train: epoch 145, iter 3400, loss: 1.963884, top_1: 0.805898, top_k: 0.935547, samples/s: 846.970 1613190057.7200727
train: epoch 145, iter 3500, loss: 1.847276, top_1: 0.808828, top_k: 0.936523, samples/s: 850.257 1613190087.828631
train: epoch 145, iter 3600, loss: 1.834180, top_1: 0.806680, top_k: 0.934688, samples/s: 844.487 1613190118.142945
train: epoch 145, iter 3700, loss: 1.906976, top_1: 0.807695, top_k: 0.933633, samples/s: 847.437 1613190148.3516467
train: epoch 145, iter 3800, loss: 1.802539, top_1: 0.806016, top_k: 0.935039, samples/s: 849.358 1613190178.4920285
train: epoch 145, iter 3900, loss: 1.861494, top_1: 0.801719, top_k: 0.933086, samples/s: 845.660 1613190208.764267
train: epoch 145, iter 4000, loss: 1.846625, top_1: 0.810469, top_k: 0.934102, samples/s: 846.907 1613190238.9918268
train: epoch 145, iter 4100, loss: 1.882054, top_1: 0.805508, top_k: 0.933828, samples/s: 849.388 1613190269.131286
train: epoch 145, iter 4200, loss: 1.731586, top_1: 0.806523, top_k: 0.936875, samples/s: 849.323 1613190299.2728815
train: epoch 145, iter 4300, loss: 1.715387, top_1: 0.800195, top_k: 0.930625, samples/s: 847.088 1613190329.4940197
train: epoch 145, iter 4400, loss: 1.772144, top_1: 0.804531, top_k: 0.932969, samples/s: 846.643 1613190359.7311902
train: epoch 145, iter 4500, loss: 1.759676, top_1: 0.800078, top_k: 0.933906, samples/s: 848.117 1613190389.915591
train: epoch 145, iter 4600, loss: 1.891264, top_1: 0.808164, top_k: 0.933086, samples/s: 849.595 1613190420.047637
train: epoch 145, iter 4700, loss: 1.866221, top_1: 0.809453, top_k: 0.934102, samples/s: 845.895 1613190450.3113708
train: epoch 145, iter 4800, loss: 1.796061, top_1: 0.807734, top_k: 0.936523, samples/s: 846.367 1613190480.5583165
train: epoch 145, iter 4900, loss: 1.796209, top_1: 0.807969, top_k: 0.935352, samples/s: 847.397 1613190510.768466
train: epoch 145, iter 5000, loss: 1.879854, top_1: 0.809375, top_k: 0.936289, samples/s: 848.871 1613190540.9261346
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_145.
validation: epoch 145, iter 195, top_1: 0.774379, top_k: 0.936859, samples/s: 2437.140 1613190562.316037
train: epoch 146, iter 100, loss: 1.837606, top_1: 0.809219, top_k: 0.936445, samples/s: 870.065 1613190617.6033657
train: epoch 146, iter 200, loss: 1.771081, top_1: 0.813008, top_k: 0.937227, samples/s: 867.104 1613190647.1268537
train: epoch 146, iter 300, loss: 1.814111, top_1: 0.810742, top_k: 0.937109, samples/s: 853.758 1613190677.1119385
train: epoch 146, iter 400, loss: 1.918120, top_1: 0.810898, top_k: 0.936602, samples/s: 847.355 1613190707.3236387
train: epoch 146, iter 500, loss: 1.873094, top_1: 0.812539, top_k: 0.938984, samples/s: 845.858 1613190737.5886374
train: epoch 146, iter 600, loss: 1.845554, top_1: 0.808984, top_k: 0.936719, samples/s: 846.108 1613190767.844852
train: epoch 146, iter 700, loss: 1.745242, top_1: 0.809609, top_k: 0.934609, samples/s: 847.751 1613190798.042408
train: epoch 146, iter 800, loss: 1.820556, top_1: 0.808711, top_k: 0.934648, samples/s: 841.645 1613190828.459091
train: epoch 146, iter 900, loss: 1.874514, top_1: 0.808477, top_k: 0.934453, samples/s: 851.063 1613190858.5390751
train: epoch 146, iter 1000, loss: 1.746399, top_1: 0.812031, top_k: 0.937773, samples/s: 845.821 1613190888.8055453
train: epoch 146, iter 1100, loss: 1.711579, top_1: 0.808281, top_k: 0.931758, samples/s: 847.315 1613190919.0186312
train: epoch 146, iter 1200, loss: 1.883456, top_1: 0.811953, top_k: 0.935703, samples/s: 847.795 1613190949.214641
train: epoch 146, iter 1300, loss: 1.807985, top_1: 0.811914, top_k: 0.936641, samples/s: 847.006 1613190979.4386785
train: epoch 146, iter 1400, loss: 1.826336, top_1: 0.808984, top_k: 0.936680, samples/s: 847.753 1613191009.6362553
train: epoch 146, iter 1500, loss: 1.875546, top_1: 0.806641, top_k: 0.934609, samples/s: 846.046 1613191039.8946073
train: epoch 146, iter 1600, loss: 1.796412, top_1: 0.805820, top_k: 0.934297, samples/s: 843.463 1613191070.2456298
train: epoch 146, iter 1700, loss: 1.788612, top_1: 0.809219, top_k: 0.933203, samples/s: 850.639 1613191100.3407078
train: epoch 146, iter 1800, loss: 1.806530, top_1: 0.809297, top_k: 0.934961, samples/s: 847.704 1613191130.5399082
train: epoch 146, iter 1900, loss: 1.812787, top_1: 0.807773, top_k: 0.935703, samples/s: 845.588 1613191160.8147304
train: epoch 146, iter 2000, loss: 1.802580, top_1: 0.808594, top_k: 0.934219, samples/s: 848.752 1613191190.976608
train: epoch 146, iter 2100, loss: 1.745303, top_1: 0.808008, top_k: 0.934102, samples/s: 847.152 1613191221.1955564
train: epoch 146, iter 2200, loss: 1.809387, top_1: 0.808633, top_k: 0.935195, samples/s: 845.215 1613191251.4837103
train: epoch 146, iter 2300, loss: 1.993913, top_1: 0.812422, top_k: 0.936875, samples/s: 848.730 1613191281.646324
train: epoch 146, iter 2400, loss: 1.827931, top_1: 0.806289, top_k: 0.933945, samples/s: 847.223 1613191311.8627262
train: epoch 146, iter 2500, loss: 1.817828, top_1: 0.808867, top_k: 0.938477, samples/s: 847.233 1613191342.07868
train: epoch 146, iter 2600, loss: 1.817239, top_1: 0.810859, top_k: 0.937187, samples/s: 846.197 1613191372.331674
train: epoch 146, iter 2700, loss: 1.810683, top_1: 0.809727, top_k: 0.935469, samples/s: 850.525 1613191402.4307535
train: epoch 146, iter 2800, loss: 1.902568, top_1: 0.808594, top_k: 0.936367, samples/s: 845.085 1613191432.7235806
train: epoch 146, iter 2900, loss: 1.765475, top_1: 0.808906, top_k: 0.935547, samples/s: 848.888 1613191462.8806634
train: epoch 146, iter 3000, loss: 1.980479, top_1: 0.807813, top_k: 0.934063, samples/s: 848.711 1613191493.0440905
train: epoch 146, iter 3100, loss: 1.784685, top_1: 0.808047, top_k: 0.935352, samples/s: 848.562 1613191523.212706
train: epoch 146, iter 3200, loss: 1.815693, top_1: 0.805977, top_k: 0.935703, samples/s: 844.746 1613191553.5176735
train: epoch 146, iter 3300, loss: 1.801904, top_1: 0.810234, top_k: 0.935820, samples/s: 850.373 1613191583.6221294
train: epoch 146, iter 3400, loss: 1.716197, top_1: 0.805937, top_k: 0.935937, samples/s: 844.963 1613191613.9193134
train: epoch 146, iter 3500, loss: 1.849969, top_1: 0.809648, top_k: 0.935156, samples/s: 846.556 1613191644.1594744
train: epoch 146, iter 3600, loss: 1.793171, top_1: 0.808672, top_k: 0.935664, samples/s: 847.156 1613191674.3783007
train: epoch 146, iter 3700, loss: 1.877450, top_1: 0.808555, top_k: 0.936055, samples/s: 850.002 1613191704.4957988
train: epoch 146, iter 3800, loss: 1.729851, top_1: 0.808672, top_k: 0.936289, samples/s: 846.428 1613191734.7405212
train: epoch 146, iter 3900, loss: 1.805388, top_1: 0.807813, top_k: 0.933320, samples/s: 847.250 1613191764.9559839
train: epoch 146, iter 4000, loss: 1.730465, top_1: 0.808359, top_k: 0.934883, samples/s: 847.388 1613191795.1663494
train: epoch 146, iter 4100, loss: 1.931574, top_1: 0.809336, top_k: 0.933281, samples/s: 848.430 1613191825.3398058
train: epoch 146, iter 4200, loss: 1.759052, top_1: 0.808164, top_k: 0.936133, samples/s: 847.807 1613191855.5352848
train: epoch 146, iter 4300, loss: 1.735720, top_1: 0.810312, top_k: 0.933359, samples/s: 848.759 1613191885.696977
train: epoch 146, iter 4400, loss: 1.871862, top_1: 0.808516, top_k: 0.935469, samples/s: 846.538 1613191915.9378529
train: epoch 146, iter 4500, loss: 1.751332, top_1: 0.812617, top_k: 0.935859, samples/s: 850.104 1613191946.051841
train: epoch 146, iter 4600, loss: 1.911400, top_1: 0.810703, top_k: 0.938086, samples/s: 847.370 1613191976.2628987
train: epoch 146, iter 4700, loss: 1.974346, top_1: 0.809883, top_k: 0.933047, samples/s: 848.591 1613192006.4305398
train: epoch 146, iter 4800, loss: 1.708378, top_1: 0.814219, top_k: 0.936953, samples/s: 846.787 1613192036.6625674
train: epoch 146, iter 4900, loss: 1.892010, top_1: 0.806602, top_k: 0.934336, samples/s: 849.201 1613192066.8085258
train: epoch 146, iter 5000, loss: 1.759629, top_1: 0.808281, top_k: 0.936445, samples/s: 848.407 1613192096.982719
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_146.
validation: epoch 146, iter 195, top_1: 0.776502, top_k: 0.937600, samples/s: 2460.159 1613192118.1942468
train: epoch 147, iter 100, loss: 1.726250, top_1: 0.809180, top_k: 0.936484, samples/s: 867.758 1613192168.359441
train: epoch 147, iter 200, loss: 1.788343, top_1: 0.810156, top_k: 0.934063, samples/s: 865.457 1613192197.9392855
train: epoch 147, iter 300, loss: 1.875838, top_1: 0.813125, top_k: 0.937852, samples/s: 853.408 1613192227.936691
train: epoch 147, iter 400, loss: 1.758264, top_1: 0.812148, top_k: 0.938789, samples/s: 847.006 1613192258.160664
train: epoch 147, iter 500, loss: 1.895227, top_1: 0.811992, top_k: 0.934023, samples/s: 847.075 1613192288.3822534
train: epoch 147, iter 600, loss: 1.823130, top_1: 0.809492, top_k: 0.934453, samples/s: 843.512 1613192318.731584
train: epoch 147, iter 700, loss: 1.753493, top_1: 0.814297, top_k: 0.936094, samples/s: 849.276 1613192348.874959
train: epoch 147, iter 800, loss: 1.737727, top_1: 0.814727, top_k: 0.934414, samples/s: 844.787 1613192379.178399
train: epoch 147, iter 900, loss: 1.819351, top_1: 0.813398, top_k: 0.936953, samples/s: 846.692 1613192409.41377
train: epoch 147, iter 1000, loss: 1.711460, top_1: 0.811875, top_k: 0.936445, samples/s: 846.426 1613192439.6585867
train: epoch 147, iter 1100, loss: 1.736346, top_1: 0.817227, top_k: 0.937187, samples/s: 846.328 1613192469.9068234
train: epoch 147, iter 1200, loss: 1.815700, top_1: 0.810547, top_k: 0.932109, samples/s: 848.108 1613192500.0917132
train: epoch 147, iter 1300, loss: 1.818745, top_1: 0.809180, top_k: 0.935586, samples/s: 843.311 1613192530.4482172
train: epoch 147, iter 1400, loss: 1.929023, top_1: 0.818906, top_k: 0.939805, samples/s: 847.196 1613192560.6656199
train: epoch 147, iter 1500, loss: 1.747527, top_1: 0.809297, top_k: 0.936328, samples/s: 849.763 1613192590.7915573
train: epoch 147, iter 1600, loss: 1.749980, top_1: 0.812461, top_k: 0.937891, samples/s: 843.879 1613192621.1277385
train: epoch 147, iter 1700, loss: 1.846850, top_1: 0.809141, top_k: 0.933125, samples/s: 847.918 1613192651.3192992
train: epoch 147, iter 1800, loss: 1.914521, top_1: 0.811172, top_k: 0.937227, samples/s: 845.240 1613192681.6065202
train: epoch 147, iter 1900, loss: 1.772835, top_1: 0.809883, top_k: 0.936211, samples/s: 848.831 1613192711.7657452
train: epoch 147, iter 2000, loss: 1.892050, top_1: 0.814219, top_k: 0.935156, samples/s: 845.703 1613192742.0364
train: epoch 147, iter 2100, loss: 1.767787, top_1: 0.811719, top_k: 0.938008, samples/s: 846.453 1613192772.280289
train: epoch 147, iter 2200, loss: 1.768724, top_1: 0.808867, top_k: 0.933594, samples/s: 846.071 1613192802.5377014
train: epoch 147, iter 2300, loss: 1.748673, top_1: 0.811484, top_k: 0.936562, samples/s: 846.824 1613192832.768354
train: epoch 147, iter 2400, loss: 1.735503, top_1: 0.810742, top_k: 0.936602, samples/s: 847.032 1613192862.991548
train: epoch 147, iter 2500, loss: 1.704242, top_1: 0.811797, top_k: 0.936406, samples/s: 845.783 1613192893.259298
train: epoch 147, iter 2600, loss: 1.664663, top_1: 0.811406, top_k: 0.939102, samples/s: 846.090 1613192923.516105
train: epoch 147, iter 2700, loss: 1.777527, top_1: 0.808086, top_k: 0.934844, samples/s: 848.642 1613192953.6819928
train: epoch 147, iter 2800, loss: 1.748146, top_1: 0.814453, top_k: 0.939609, samples/s: 847.050 1613192983.9045863
train: epoch 147, iter 2900, loss: 1.871674, top_1: 0.812656, top_k: 0.936133, samples/s: 846.201 1613193014.1573625
train: epoch 147, iter 3000, loss: 1.966203, top_1: 0.808906, top_k: 0.934688, samples/s: 846.503 1613193044.3994656
train: epoch 147, iter 3100, loss: 1.957485, top_1: 0.811953, top_k: 0.936992, samples/s: 848.316 1613193074.576869
train: epoch 147, iter 3200, loss: 1.702384, top_1: 0.811797, top_k: 0.936289, samples/s: 845.188 1613193104.86603
train: epoch 147, iter 3300, loss: 1.848970, top_1: 0.815664, top_k: 0.937109, samples/s: 848.438 1613193135.03905
train: epoch 147, iter 3400, loss: 1.920483, top_1: 0.805586, top_k: 0.934180, samples/s: 845.694 1613193165.3101225
train: epoch 147, iter 3500, loss: 1.818946, top_1: 0.809531, top_k: 0.935430, samples/s: 847.623 1613193195.5122764
train: epoch 147, iter 3600, loss: 1.952164, top_1: 0.805859, top_k: 0.933750, samples/s: 846.288 1613193225.7620525
train: epoch 147, iter 3700, loss: 1.948139, top_1: 0.812070, top_k: 0.935937, samples/s: 845.625 1613193256.035514
train: epoch 147, iter 3800, loss: 1.832114, top_1: 0.808516, top_k: 0.937617, samples/s: 848.528 1613193286.2053618
train: epoch 147, iter 3900, loss: 1.810465, top_1: 0.811484, top_k: 0.936289, samples/s: 844.302 1613193316.5262244
train: epoch 147, iter 4000, loss: 1.802148, top_1: 0.813164, top_k: 0.939102, samples/s: 847.643 1613193346.7277339
train: epoch 147, iter 4100, loss: 1.778592, top_1: 0.811992, top_k: 0.935508, samples/s: 847.268 1613193376.9424005
train: epoch 147, iter 4200, loss: 1.732127, top_1: 0.815352, top_k: 0.938984, samples/s: 846.521 1613193407.183873
train: epoch 147, iter 4300, loss: 1.737597, top_1: 0.809492, top_k: 0.935664, samples/s: 846.005 1613193437.4437544
train: epoch 147, iter 4400, loss: 1.925270, top_1: 0.812539, top_k: 0.933789, samples/s: 845.032 1613193467.7384381
train: epoch 147, iter 4500, loss: 1.800053, top_1: 0.810898, top_k: 0.934492, samples/s: 849.319 1613193497.880238
train: epoch 147, iter 4600, loss: 1.917524, top_1: 0.815156, top_k: 0.938086, samples/s: 843.865 1613193528.2168856
train: epoch 147, iter 4700, loss: 1.800278, top_1: 0.812695, top_k: 0.936836, samples/s: 849.020 1613193558.3696518
train: epoch 147, iter 4800, loss: 1.878025, top_1: 0.810703, top_k: 0.934727, samples/s: 843.385 1613193588.723184
train: epoch 147, iter 4900, loss: 1.850883, top_1: 0.813203, top_k: 0.936602, samples/s: 848.168 1613193618.9058902
train: epoch 147, iter 5000, loss: 1.714767, top_1: 0.810820, top_k: 0.937031, samples/s: 846.531 1613193649.1468875
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_147.
validation: epoch 147, iter 195, top_1: 0.775561, top_k: 0.937580, samples/s: 2441.119 1613193670.4895194
train: epoch 148, iter 100, loss: 1.741714, top_1: 0.818164, top_k: 0.938633, samples/s: 871.873 1613193720.3020823
train: epoch 148, iter 200, loss: 1.789645, top_1: 0.817617, top_k: 0.937148, samples/s: 865.090 1613193749.8943963
train: epoch 148, iter 300, loss: 1.725163, top_1: 0.808398, top_k: 0.934063, samples/s: 851.992 1613193779.9415915
train: epoch 148, iter 400, loss: 1.892039, top_1: 0.815742, top_k: 0.936875, samples/s: 844.850 1613193810.2429142
train: epoch 148, iter 500, loss: 1.955655, top_1: 0.816953, top_k: 0.936406, samples/s: 846.541 1613193840.4835544
train: epoch 148, iter 600, loss: 1.764445, top_1: 0.814961, top_k: 0.937187, samples/s: 847.210 1613193870.7004428
train: epoch 148, iter 700, loss: 1.902401, top_1: 0.814766, top_k: 0.937305, samples/s: 843.871 1613193901.0368743
train: epoch 148, iter 800, loss: 1.825327, top_1: 0.814375, top_k: 0.939492, samples/s: 845.506 1613193931.3146014
train: epoch 148, iter 900, loss: 1.687407, top_1: 0.818633, top_k: 0.939102, samples/s: 847.393 1613193961.524794
train: epoch 148, iter 1000, loss: 1.812814, top_1: 0.812617, top_k: 0.938086, samples/s: 842.323 1613193991.916939
train: epoch 148, iter 1100, loss: 1.757025, top_1: 0.810430, top_k: 0.936211, samples/s: 845.559 1613194022.1928883
train: epoch 148, iter 1200, loss: 1.920659, top_1: 0.815508, top_k: 0.935859, samples/s: 847.606 1613194052.3954906
train: epoch 148, iter 1300, loss: 1.812120, top_1: 0.808594, top_k: 0.935898, samples/s: 842.255 1613194082.790103
train: epoch 148, iter 1400, loss: 1.733114, top_1: 0.816719, top_k: 0.938008, samples/s: 844.497 1613194113.1039886
train: epoch 148, iter 1500, loss: 1.803030, top_1: 0.813242, top_k: 0.936602, samples/s: 847.234 1613194143.3200436
train: epoch 148, iter 1600, loss: 1.841680, top_1: 0.810000, top_k: 0.934297, samples/s: 842.528 1613194173.704808
train: epoch 148, iter 1700, loss: 1.838674, top_1: 0.814570, top_k: 0.937383, samples/s: 848.099 1613194203.8899746
train: epoch 148, iter 1800, loss: 1.860333, top_1: 0.811133, top_k: 0.936875, samples/s: 843.986 1613194234.2221909
train: epoch 148, iter 1900, loss: 1.913286, top_1: 0.812031, top_k: 0.937344, samples/s: 847.556 1613194264.4266946
train: epoch 148, iter 2000, loss: 1.902456, top_1: 0.817617, top_k: 0.937578, samples/s: 846.906 1613194294.6543586
train: epoch 148, iter 2100, loss: 1.738700, top_1: 0.816094, top_k: 0.939570, samples/s: 846.052 1613194324.9129262
train: epoch 148, iter 2200, loss: 1.815778, top_1: 0.813867, top_k: 0.935547, samples/s: 844.363 1613194355.2312794
train: epoch 148, iter 2300, loss: 1.873656, top_1: 0.813516, top_k: 0.935664, samples/s: 846.017 1613194385.4906914
train: epoch 148, iter 2400, loss: 1.747890, top_1: 0.815352, top_k: 0.938555, samples/s: 843.354 1613194415.84567
train: epoch 148, iter 2500, loss: 1.811311, top_1: 0.812695, top_k: 0.934492, samples/s: 846.708 1613194446.0805225
train: epoch 148, iter 2600, loss: 1.857548, top_1: 0.813516, top_k: 0.938789, samples/s: 845.517 1613194476.3577678
train: epoch 148, iter 2700, loss: 1.741935, top_1: 0.811953, top_k: 0.935117, samples/s: 846.245 1613194506.6092272
train: epoch 148, iter 2800, loss: 1.787717, top_1: 0.813320, top_k: 0.937148, samples/s: 845.529 1613194536.8860533
train: epoch 148, iter 2900, loss: 1.712545, top_1: 0.813320, top_k: 0.937461, samples/s: 846.298 1613194567.135375
train: epoch 148, iter 3000, loss: 1.805123, top_1: 0.817383, top_k: 0.938359, samples/s: 844.400 1613194597.4528522
train: epoch 148, iter 3100, loss: 1.774439, top_1: 0.815547, top_k: 0.939648, samples/s: 848.654 1613194627.6181958
train: epoch 148, iter 3200, loss: 1.882477, top_1: 0.815469, top_k: 0.935742, samples/s: 843.590 1613194657.964718
train: epoch 148, iter 3300, loss: 1.866573, top_1: 0.812227, top_k: 0.936055, samples/s: 846.283 1613194688.2146962
train: epoch 148, iter 3400, loss: 1.670434, top_1: 0.812461, top_k: 0.938086, samples/s: 846.489 1613194718.45716
train: epoch 148, iter 3500, loss: 1.810113, top_1: 0.808789, top_k: 0.934648, samples/s: 847.289 1613194748.671226
train: epoch 148, iter 3600, loss: 1.794313, top_1: 0.815820, top_k: 0.938125, samples/s: 847.169 1613194778.8895345
train: epoch 148, iter 3700, loss: 1.934902, top_1: 0.812734, top_k: 0.935664, samples/s: 846.991 1613194809.1141238
train: epoch 148, iter 3800, loss: 1.877500, top_1: 0.811133, top_k: 0.935117, samples/s: 847.765 1613194839.3112187
train: epoch 148, iter 3900, loss: 1.729316, top_1: 0.811406, top_k: 0.935547, samples/s: 846.624 1613194869.548963
train: epoch 148, iter 4000, loss: 1.778907, top_1: 0.814492, top_k: 0.938594, samples/s: 843.954 1613194899.882386
train: epoch 148, iter 4100, loss: 1.758649, top_1: 0.813672, top_k: 0.934961, samples/s: 846.424 1613194930.1273372
train: epoch 148, iter 4200, loss: 1.808550, top_1: 0.806445, top_k: 0.935937, samples/s: 851.126 1613194960.205051
train: epoch 148, iter 4300, loss: 1.783565, top_1: 0.815391, top_k: 0.936914, samples/s: 844.851 1613194990.5062718
train: epoch 148, iter 4400, loss: 1.736276, top_1: 0.814023, top_k: 0.937734, samples/s: 844.719 1613195020.8122444
train: epoch 148, iter 4500, loss: 1.816423, top_1: 0.814492, top_k: 0.939336, samples/s: 849.603 1613195050.9439213
train: epoch 148, iter 4600, loss: 1.695861, top_1: 0.812109, top_k: 0.937266, samples/s: 845.818 1613195081.2105472
train: epoch 148, iter 4700, loss: 1.760313, top_1: 0.814453, top_k: 0.938984, samples/s: 848.254 1613195111.3902
train: epoch 148, iter 4800, loss: 1.700306, top_1: 0.811484, top_k: 0.936133, samples/s: 849.898 1613195141.5114224
train: epoch 148, iter 4900, loss: 1.852118, top_1: 0.813125, top_k: 0.937266, samples/s: 842.736 1613195171.888595
train: epoch 148, iter 5000, loss: 1.770395, top_1: 0.814063, top_k: 0.937500, samples/s: 848.215 1613195202.0696094
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_148.
validation: epoch 148, iter 195, top_1: 0.773818, top_k: 0.937620, samples/s: 2429.929 1613195223.5178566
train: epoch 149, iter 100, loss: 1.753164, top_1: 0.815352, top_k: 0.936836, samples/s: 869.465 1613195273.589252
train: epoch 149, iter 200, loss: 1.801405, top_1: 0.818711, top_k: 0.940234, samples/s: 868.423 1613195303.067819
train: epoch 149, iter 300, loss: 1.882888, top_1: 0.809805, top_k: 0.936562, samples/s: 850.968 1613195333.15122
train: epoch 149, iter 400, loss: 1.876633, top_1: 0.814570, top_k: 0.937617, samples/s: 841.793 1613195363.5625007
train: epoch 149, iter 500, loss: 1.900469, top_1: 0.814961, top_k: 0.935781, samples/s: 848.638 1613195393.7284927
train: epoch 149, iter 600, loss: 1.843525, top_1: 0.811250, top_k: 0.936172, samples/s: 842.343 1613195424.1199656
train: epoch 149, iter 700, loss: 1.763529, top_1: 0.815664, top_k: 0.938711, samples/s: 849.241 1613195454.2645483
train: epoch 149, iter 800, loss: 1.703106, top_1: 0.815508, top_k: 0.937070, samples/s: 843.343 1613195484.6198626
train: epoch 149, iter 900, loss: 1.814593, top_1: 0.811641, top_k: 0.936133, samples/s: 844.581 1613195514.9307928
train: epoch 149, iter 1000, loss: 1.796953, top_1: 0.814883, top_k: 0.935117, samples/s: 847.500 1613195545.137713
train: epoch 149, iter 1100, loss: 1.737668, top_1: 0.816172, top_k: 0.937578, samples/s: 843.037 1613195575.5036056
train: epoch 149, iter 1200, loss: 1.706740, top_1: 0.819141, top_k: 0.940859, samples/s: 845.389 1613195605.7860339
train: epoch 149, iter 1300, loss: 1.734135, top_1: 0.813789, top_k: 0.937109, samples/s: 848.038 1613195635.9728403
train: epoch 149, iter 1400, loss: 1.787931, top_1: 0.812461, top_k: 0.935937, samples/s: 846.802 1613195666.204225
train: epoch 149, iter 1500, loss: 1.652974, top_1: 0.822461, top_k: 0.938242, samples/s: 843.365 1613195696.558806
train: epoch 149, iter 1600, loss: 1.827756, top_1: 0.816289, top_k: 0.938359, samples/s: 849.650 1613195726.6888976
train: epoch 149, iter 1700, loss: 1.708209, top_1: 0.813047, top_k: 0.937461, samples/s: 843.835 1613195757.0265124
train: epoch 149, iter 1800, loss: 1.867166, top_1: 0.814492, top_k: 0.936797, samples/s: 846.849 1613195787.2563221
train: epoch 149, iter 1900, loss: 1.764083, top_1: 0.813750, top_k: 0.937187, samples/s: 846.980 1613195817.4813466
train: epoch 149, iter 2000, loss: 1.730000, top_1: 0.811523, top_k: 0.934102, samples/s: 845.521 1613195847.7584665
train: epoch 149, iter 2100, loss: 1.717148, top_1: 0.813047, top_k: 0.938594, samples/s: 846.309 1613195878.007488
train: epoch 149, iter 2200, loss: 1.770216, top_1: 0.813086, top_k: 0.938008, samples/s: 844.836 1613195908.3091717
train: epoch 149, iter 2300, loss: 1.696092, top_1: 0.816758, top_k: 0.938086, samples/s: 848.985 1613195938.4629102
train: epoch 149, iter 2400, loss: 1.635132, top_1: 0.815039, top_k: 0.939063, samples/s: 843.635 1613195968.8076978
train: epoch 149, iter 2500, loss: 1.784420, top_1: 0.817148, top_k: 0.940352, samples/s: 849.020 1613195998.9601266
train: epoch 149, iter 2600, loss: 1.753961, top_1: 0.820000, top_k: 0.938594, samples/s: 847.003 1613196029.1843243
train: epoch 149, iter 2700, loss: 1.816556, top_1: 0.811328, top_k: 0.935391, samples/s: 845.720 1613196059.45448
train: epoch 149, iter 2800, loss: 1.791897, top_1: 0.815195, top_k: 0.936875, samples/s: 845.054 1613196089.74837
train: epoch 149, iter 2900, loss: 1.732849, top_1: 0.814922, top_k: 0.937695, samples/s: 846.396 1613196119.9943066
train: epoch 149, iter 3000, loss: 1.837304, top_1: 0.819336, top_k: 0.940781, samples/s: 847.781 1613196150.1907163
train: epoch 149, iter 3100, loss: 1.771913, top_1: 0.814805, top_k: 0.938008, samples/s: 844.776 1613196180.4946282
train: epoch 149, iter 3200, loss: 1.905306, top_1: 0.816133, top_k: 0.938164, samples/s: 846.567 1613196210.7343864
train: epoch 149, iter 3300, loss: 1.835263, top_1: 0.817227, top_k: 0.938438, samples/s: 845.518 1613196241.0117185
train: epoch 149, iter 3400, loss: 1.773627, top_1: 0.811484, top_k: 0.935078, samples/s: 848.342 1613196271.1882555
train: epoch 149, iter 3500, loss: 1.732894, top_1: 0.814609, top_k: 0.937539, samples/s: 846.556 1613196301.4284089
train: epoch 149, iter 3600, loss: 1.868710, top_1: 0.815078, top_k: 0.937539, samples/s: 847.126 1613196331.6481202
train: epoch 149, iter 3700, loss: 1.767218, top_1: 0.814961, top_k: 0.936914, samples/s: 848.668 1613196361.8131256
train: epoch 149, iter 3800, loss: 1.900987, top_1: 0.813125, top_k: 0.936562, samples/s: 846.756 1613196392.046122
train: epoch 149, iter 3900, loss: 1.864534, top_1: 0.815586, top_k: 0.937891, samples/s: 845.746 1613196422.3153327
train: epoch 149, iter 4000, loss: 1.692512, top_1: 0.815469, top_k: 0.936445, samples/s: 846.374 1613196452.5619566
train: epoch 149, iter 4100, loss: 1.821184, top_1: 0.815703, top_k: 0.936992, samples/s: 846.709 1613196482.7966251
train: epoch 149, iter 4200, loss: 1.646568, top_1: 0.815508, top_k: 0.937578, samples/s: 847.960 1613196512.9868178
train: epoch 149, iter 4300, loss: 1.771240, top_1: 0.816016, top_k: 0.938320, samples/s: 844.994 1613196543.2828712
train: epoch 149, iter 4400, loss: 1.707396, top_1: 0.816328, top_k: 0.938516, samples/s: 847.127 1613196573.5025632
train: epoch 149, iter 4500, loss: 1.831129, top_1: 0.813281, top_k: 0.935508, samples/s: 848.862 1613196603.660601
train: epoch 149, iter 4600, loss: 1.820136, top_1: 0.813555, top_k: 0.936680, samples/s: 848.106 1613196633.8456178
train: epoch 149, iter 4700, loss: 1.787796, top_1: 0.811055, top_k: 0.938633, samples/s: 845.992 1613196664.1058834
train: epoch 149, iter 4800, loss: 1.774577, top_1: 0.813203, top_k: 0.937227, samples/s: 845.214 1613196694.3941426
train: epoch 149, iter 4900, loss: 1.858647, top_1: 0.814648, top_k: 0.937656, samples/s: 847.657 1613196724.5949755
train: epoch 149, iter 5000, loss: 1.748021, top_1: 0.815703, top_k: 0.938867, samples/s: 845.736 1613196754.8644538
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_149.
validation: epoch 149, iter 195, top_1: 0.774479, top_k: 0.937901, samples/s: 2420.809 1613196776.3983977
train: epoch 150, iter 100, loss: 1.788376, top_1: 0.816172, top_k: 0.938008, samples/s: 870.865 1613196826.063353
train: epoch 150, iter 200, loss: 1.817317, top_1: 0.813945, top_k: 0.937383, samples/s: 864.645 1613196855.6708357
train: epoch 150, iter 300, loss: 1.691960, top_1: 0.813555, top_k: 0.937148, samples/s: 850.753 1613196885.7618382
train: epoch 150, iter 400, loss: 1.848261, top_1: 0.818125, top_k: 0.940195, samples/s: 845.905 1613196916.0252078
train: epoch 150, iter 500, loss: 1.725461, top_1: 0.818438, top_k: 0.939883, samples/s: 842.948 1613196946.3948734
train: epoch 150, iter 600, loss: 1.789994, top_1: 0.814531, top_k: 0.936367, samples/s: 847.807 1613196976.5903535
train: epoch 150, iter 700, loss: 1.904937, top_1: 0.814531, top_k: 0.936562, samples/s: 845.820 1613197006.8569427
train: epoch 150, iter 800, loss: 1.757102, top_1: 0.814336, top_k: 0.938672, samples/s: 845.364 1613197037.1396723
train: epoch 150, iter 900, loss: 1.910846, top_1: 0.813750, top_k: 0.936211, samples/s: 847.964 1613197067.3296745
train: epoch 150, iter 1000, loss: 1.845340, top_1: 0.815195, top_k: 0.936914, samples/s: 844.822 1613197097.6319396
train: epoch 150, iter 1100, loss: 1.784575, top_1: 0.817695, top_k: 0.937383, samples/s: 845.703 1613197127.9025855
train: epoch 150, iter 1200, loss: 2.002477, top_1: 0.817344, top_k: 0.937422, samples/s: 847.659 1613197158.1033487
train: epoch 150, iter 1300, loss: 1.647344, top_1: 0.808125, top_k: 0.936953, samples/s: 845.664 1613197188.3754692
train: epoch 150, iter 1400, loss: 1.898758, top_1: 0.814727, top_k: 0.938164, samples/s: 846.546 1613197218.6159892
train: epoch 150, iter 1500, loss: 1.781872, top_1: 0.816016, top_k: 0.937852, samples/s: 845.268 1613197248.9022756
train: epoch 150, iter 1600, loss: 1.855088, top_1: 0.818125, top_k: 0.939023, samples/s: 848.815 1613197279.0619028
train: epoch 150, iter 1700, loss: 1.892645, top_1: 0.818086, top_k: 0.940977, samples/s: 848.172 1613197309.244497
train: epoch 150, iter 1800, loss: 1.887961, top_1: 0.815078, top_k: 0.936992, samples/s: 843.583 1613197339.5913253
train: epoch 150, iter 1900, loss: 1.869511, top_1: 0.816211, top_k: 0.940234, samples/s: 844.788 1613197369.894763
train: epoch 150, iter 2000, loss: 1.791278, top_1: 0.812305, top_k: 0.937422, samples/s: 848.853 1613197400.0530028
train: epoch 150, iter 2100, loss: 1.819204, top_1: 0.817070, top_k: 0.938086, samples/s: 844.070 1613197430.3822913
train: epoch 150, iter 2200, loss: 1.659065, top_1: 0.822227, top_k: 0.939805, samples/s: 847.653 1613197460.583308
train: epoch 150, iter 2300, loss: 1.830188, top_1: 0.814961, top_k: 0.936641, samples/s: 846.964 1613197490.8088846
train: epoch 150, iter 2400, loss: 1.819499, top_1: 0.816719, top_k: 0.938516, samples/s: 848.781 1613197520.9697814
train: epoch 150, iter 2500, loss: 1.705729, top_1: 0.816836, top_k: 0.937578, samples/s: 843.356 1613197551.3247418
train: epoch 150, iter 2600, loss: 1.814615, top_1: 0.816094, top_k: 0.937422, samples/s: 849.229 1613197581.469815
train: epoch 150, iter 2700, loss: 1.862088, top_1: 0.815977, top_k: 0.939414, samples/s: 843.303 1613197611.8265648
train: epoch 150, iter 2800, loss: 1.723891, top_1: 0.817266, top_k: 0.940781, samples/s: 845.976 1613197642.087411
train: epoch 150, iter 2900, loss: 1.965233, top_1: 0.815977, top_k: 0.937266, samples/s: 846.663 1613197672.3238175
train: epoch 150, iter 3000, loss: 1.785554, top_1: 0.816055, top_k: 0.937891, samples/s: 847.399 1613197702.5339723
train: epoch 150, iter 3100, loss: 1.808313, top_1: 0.816523, top_k: 0.939531, samples/s: 846.379 1613197732.780435
train: epoch 150, iter 3200, loss: 1.847302, top_1: 0.812578, top_k: 0.936484, samples/s: 847.004 1613197763.0046318
train: epoch 150, iter 3300, loss: 1.707357, top_1: 0.821836, top_k: 0.939570, samples/s: 847.172 1613197793.2227335
train: epoch 150, iter 3400, loss: 1.702887, top_1: 0.814180, top_k: 0.939648, samples/s: 844.320 1613197823.542973
train: epoch 150, iter 3500, loss: 1.759517, top_1: 0.817969, top_k: 0.940508, samples/s: 846.513 1613197853.784771
train: epoch 150, iter 3600, loss: 1.867609, top_1: 0.815039, top_k: 0.937227, samples/s: 845.889 1613197884.048725
train: epoch 150, iter 3700, loss: 1.809122, top_1: 0.815977, top_k: 0.938672, samples/s: 845.806 1613197914.3157756
train: epoch 150, iter 3800, loss: 1.630115, top_1: 0.815430, top_k: 0.937578, samples/s: 846.144 1613197944.5706472
train: epoch 150, iter 3900, loss: 1.833836, top_1: 0.817578, top_k: 0.937344, samples/s: 847.634 1613197974.7723236
train: epoch 150, iter 4000, loss: 1.749683, top_1: 0.813789, top_k: 0.937305, samples/s: 848.099 1613198004.9574106
train: epoch 150, iter 4100, loss: 1.821542, top_1: 0.812813, top_k: 0.937500, samples/s: 846.715 1613198035.1919868
train: epoch 150, iter 4200, loss: 1.858834, top_1: 0.817578, top_k: 0.936836, samples/s: 846.702 1613198065.4268289
train: epoch 150, iter 4300, loss: 1.828170, top_1: 0.819688, top_k: 0.939648, samples/s: 847.495 1613198095.6336563
train: epoch 150, iter 4400, loss: 1.792521, top_1: 0.818516, top_k: 0.939297, samples/s: 846.229 1613198125.8854523
train: epoch 150, iter 4500, loss: 1.937795, top_1: 0.813945, top_k: 0.938594, samples/s: 849.772 1613198156.0111115
train: epoch 150, iter 4600, loss: 1.715975, top_1: 0.817070, top_k: 0.937813, samples/s: 844.286 1613198186.3326402
train: epoch 150, iter 4700, loss: 1.732847, top_1: 0.816523, top_k: 0.938672, samples/s: 846.418 1613198216.5776463
train: epoch 150, iter 4800, loss: 1.882330, top_1: 0.814570, top_k: 0.936914, samples/s: 847.484 1613198246.7847197
train: epoch 150, iter 4900, loss: 1.839421, top_1: 0.819219, top_k: 0.938359, samples/s: 847.696 1613198276.9842994
train: epoch 150, iter 5000, loss: 1.655224, top_1: 0.817813, top_k: 0.937227, samples/s: 845.525 1613198307.2613187
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_150.
validation: epoch 150, iter 195, top_1: 0.775581, top_k: 0.937540, samples/s: 2483.539 1613198328.249193
train: epoch 151, iter 100, loss: 1.867815, top_1: 0.817383, top_k: 0.941211, samples/s: 872.054 1613198378.6082797
train: epoch 151, iter 200, loss: 1.727004, top_1: 0.818984, top_k: 0.940625, samples/s: 868.671 1613198408.0786133
train: epoch 151, iter 300, loss: 1.836471, top_1: 0.815312, top_k: 0.936289, samples/s: 850.509 1613198438.1783063
train: epoch 151, iter 400, loss: 1.781594, top_1: 0.817695, top_k: 0.937500, samples/s: 845.992 1613198468.4384983
train: epoch 151, iter 500, loss: 1.812951, top_1: 0.812461, top_k: 0.938750, samples/s: 845.889 1613198498.7025802
train: epoch 151, iter 600, loss: 1.877829, top_1: 0.817813, top_k: 0.937461, samples/s: 850.675 1613198528.7963076
train: epoch 151, iter 700, loss: 1.872269, top_1: 0.818359, top_k: 0.938594, samples/s: 845.579 1613198559.0714638
train: epoch 151, iter 800, loss: 1.764653, top_1: 0.818594, top_k: 0.936406, samples/s: 843.666 1613198589.4151263
train: epoch 151, iter 900, loss: 1.865170, top_1: 0.818906, top_k: 0.941055, samples/s: 846.589 1613198619.6541238
train: epoch 151, iter 1000, loss: 1.705377, top_1: 0.820859, top_k: 0.938477, samples/s: 844.749 1613198649.9589756
train: epoch 151, iter 1100, loss: 1.831146, top_1: 0.817187, top_k: 0.937422, samples/s: 847.684 1613198680.1590252
train: epoch 151, iter 1200, loss: 1.706062, top_1: 0.819609, top_k: 0.939766, samples/s: 848.064 1613198710.3453667
train: epoch 151, iter 1300, loss: 1.742623, top_1: 0.816758, top_k: 0.938633, samples/s: 842.975 1613198740.713996
train: epoch 151, iter 1400, loss: 1.739535, top_1: 0.817656, top_k: 0.939688, samples/s: 848.799 1613198770.8742244
train: epoch 151, iter 1500, loss: 1.737648, top_1: 0.817813, top_k: 0.938008, samples/s: 845.824 1613198801.1405773
train: epoch 151, iter 1600, loss: 2.006363, top_1: 0.813672, top_k: 0.936680, samples/s: 846.649 1613198831.377498
train: epoch 151, iter 1700, loss: 1.816454, top_1: 0.819570, top_k: 0.939375, samples/s: 844.646 1613198861.6860993
train: epoch 151, iter 1800, loss: 1.803705, top_1: 0.818164, top_k: 0.937734, samples/s: 847.469 1613198891.8936527
train: epoch 151, iter 1900, loss: 1.861699, top_1: 0.815781, top_k: 0.938828, samples/s: 848.460 1613198922.0659275
train: epoch 151, iter 2000, loss: 1.776028, top_1: 0.813945, top_k: 0.936875, samples/s: 848.119 1613198952.250478
train: epoch 151, iter 2100, loss: 1.785636, top_1: 0.819883, top_k: 0.939922, samples/s: 847.363 1613198982.461753
train: epoch 151, iter 2200, loss: 1.939300, top_1: 0.811875, top_k: 0.935898, samples/s: 846.902 1613199012.689572
train: epoch 151, iter 2300, loss: 1.723700, top_1: 0.820977, top_k: 0.939063, samples/s: 851.750 1613199042.7454088
train: epoch 151, iter 2400, loss: 1.987674, top_1: 0.817891, top_k: 0.938281, samples/s: 843.996 1613199073.077374
train: epoch 151, iter 2500, loss: 1.642204, top_1: 0.817109, top_k: 0.939844, samples/s: 848.604 1613199103.2444825
train: epoch 151, iter 2600, loss: 1.813152, top_1: 0.817539, top_k: 0.938320, samples/s: 843.898 1613199133.579863
train: epoch 151, iter 2700, loss: 1.855150, top_1: 0.818047, top_k: 0.938047, samples/s: 846.496 1613199163.822479
train: epoch 151, iter 2800, loss: 1.780291, top_1: 0.815625, top_k: 0.939180, samples/s: 849.265 1613199193.9658952
train: epoch 151, iter 2900, loss: 1.715757, top_1: 0.815312, top_k: 0.937031, samples/s: 847.591 1613199224.1697197
train: epoch 151, iter 3000, loss: 1.889977, top_1: 0.814609, top_k: 0.938516, samples/s: 848.162 1613199254.3520937
train: epoch 151, iter 3100, loss: 1.779010, top_1: 0.818242, top_k: 0.939453, samples/s: 847.557 1613199284.5564916
train: epoch 151, iter 3200, loss: 1.762872, top_1: 0.815078, top_k: 0.939609, samples/s: 848.227 1613199314.737104
train: epoch 151, iter 3300, loss: 1.721252, top_1: 0.820859, top_k: 0.940156, samples/s: 847.347 1613199344.949085
train: epoch 151, iter 3400, loss: 1.927637, top_1: 0.818945, top_k: 0.939922, samples/s: 846.475 1613199375.1921234
train: epoch 151, iter 3500, loss: 1.973022, top_1: 0.819219, top_k: 0.940664, samples/s: 848.531 1613199405.3620005
train: epoch 151, iter 3600, loss: 1.759863, top_1: 0.817305, top_k: 0.940820, samples/s: 848.727 1613199435.5248346
train: epoch 151, iter 3700, loss: 1.728979, top_1: 0.816094, top_k: 0.937539, samples/s: 846.178 1613199465.778504
train: epoch 151, iter 3800, loss: 1.779976, top_1: 0.810781, top_k: 0.935937, samples/s: 847.144 1613199495.9976478
train: epoch 151, iter 3900, loss: 1.757824, top_1: 0.817695, top_k: 0.939375, samples/s: 847.781 1613199526.1941497
train: epoch 151, iter 4000, loss: 1.827160, top_1: 0.819922, top_k: 0.939180, samples/s: 846.517 1613199556.4357564
train: epoch 151, iter 4100, loss: 1.892427, top_1: 0.813750, top_k: 0.937070, samples/s: 847.296 1613199586.649408
train: epoch 151, iter 4200, loss: 1.771837, top_1: 0.817500, top_k: 0.940430, samples/s: 846.558 1613199616.8894908
train: epoch 151, iter 4300, loss: 1.878211, top_1: 0.817617, top_k: 0.938789, samples/s: 848.133 1613199647.0734856
train: epoch 151, iter 4400, loss: 1.808831, top_1: 0.819258, top_k: 0.940156, samples/s: 847.585 1613199677.2770066
train: epoch 151, iter 4500, loss: 1.904651, top_1: 0.819688, top_k: 0.939258, samples/s: 845.694 1613199707.5479767
train: epoch 151, iter 4600, loss: 1.818266, top_1: 0.814375, top_k: 0.939141, samples/s: 848.370 1613199737.7234812
train: epoch 151, iter 4700, loss: 1.843005, top_1: 0.816289, top_k: 0.938438, samples/s: 845.734 1613199767.9930432
train: epoch 151, iter 4800, loss: 1.803230, top_1: 0.814180, top_k: 0.935508, samples/s: 852.034 1613199798.0387883
train: epoch 151, iter 4900, loss: 1.996388, top_1: 0.816250, top_k: 0.938867, samples/s: 843.433 1613199828.3909252
train: epoch 151, iter 5000, loss: 1.698176, top_1: 0.815664, top_k: 0.938164, samples/s: 847.665 1613199858.5915265
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_151.
validation: epoch 151, iter 195, top_1: 0.771374, top_k: 0.935737, samples/s: 2487.526 1613199879.555108
train: epoch 152, iter 100, loss: 1.953672, top_1: 0.815703, top_k: 0.938242, samples/s: 872.570 1613199929.7320268
train: epoch 152, iter 200, loss: 1.759394, top_1: 0.818555, top_k: 0.938359, samples/s: 865.317 1613199959.31661
train: epoch 152, iter 300, loss: 1.747262, top_1: 0.817070, top_k: 0.939375, samples/s: 848.316 1613199989.49405
train: epoch 152, iter 400, loss: 1.765985, top_1: 0.818984, top_k: 0.940352, samples/s: 847.632 1613200019.695752
train: epoch 152, iter 500, loss: 1.910457, top_1: 0.815937, top_k: 0.936797, samples/s: 845.995 1613200049.9560766
train: epoch 152, iter 600, loss: 1.782644, top_1: 0.816914, top_k: 0.938945, samples/s: 847.806 1613200080.1516032
train: epoch 152, iter 700, loss: 1.741625, top_1: 0.816445, top_k: 0.938359, samples/s: 844.280 1613200110.473277
train: epoch 152, iter 800, loss: 1.759016, top_1: 0.818555, top_k: 0.938320, samples/s: 847.606 1613200140.6760917
train: epoch 152, iter 900, loss: 1.738855, top_1: 0.822422, top_k: 0.941797, samples/s: 843.756 1613200171.0165052
train: epoch 152, iter 1000, loss: 1.861055, top_1: 0.818164, top_k: 0.937305, samples/s: 845.336 1613200201.300386
train: epoch 152, iter 1100, loss: 1.781036, top_1: 0.820625, top_k: 0.941055, samples/s: 846.035 1613200231.5591977
train: epoch 152, iter 1200, loss: 1.813755, top_1: 0.814805, top_k: 0.937461, samples/s: 846.890 1613200261.7874694
train: epoch 152, iter 1300, loss: 1.868436, top_1: 0.816641, top_k: 0.939688, samples/s: 843.670 1613200292.1311004
train: epoch 152, iter 1400, loss: 1.868332, top_1: 0.816484, top_k: 0.938242, samples/s: 847.143 1613200322.350316
train: epoch 152, iter 1500, loss: 1.841104, top_1: 0.818008, top_k: 0.940039, samples/s: 846.588 1613200352.58929
train: epoch 152, iter 1600, loss: 1.846269, top_1: 0.819453, top_k: 0.938867, samples/s: 844.921 1613200382.8880363
train: epoch 152, iter 1700, loss: 1.780366, top_1: 0.819336, top_k: 0.938828, samples/s: 846.724 1613200413.1221614
train: epoch 152, iter 1800, loss: 1.634731, top_1: 0.814844, top_k: 0.938711, samples/s: 847.038 1613200443.3452158
train: epoch 152, iter 1900, loss: 1.828412, top_1: 0.818789, top_k: 0.939492, samples/s: 847.112 1613200473.5654852
train: epoch 152, iter 2000, loss: 1.777196, top_1: 0.815977, top_k: 0.938672, samples/s: 848.682 1613200503.7298343
train: epoch 152, iter 2100, loss: 1.736814, top_1: 0.819453, top_k: 0.939023, samples/s: 846.073 1613200533.9872856
train: epoch 152, iter 2200, loss: 1.832445, top_1: 0.818359, top_k: 0.939727, samples/s: 844.194 1613200564.312059
train: epoch 152, iter 2300, loss: 1.680704, top_1: 0.820312, top_k: 0.940586, samples/s: 847.992 1613200594.501133
train: epoch 152, iter 2400, loss: 1.810076, top_1: 0.818398, top_k: 0.939531, samples/s: 845.063 1613200624.7946515
train: epoch 152, iter 2500, loss: 1.730049, top_1: 0.815352, top_k: 0.939375, samples/s: 849.442 1613200654.93208
train: epoch 152, iter 2600, loss: 1.806295, top_1: 0.815586, top_k: 0.939688, samples/s: 847.504 1613200685.1384811
train: epoch 152, iter 2700, loss: 1.712477, top_1: 0.817734, top_k: 0.939141, samples/s: 844.141 1613200715.4651866
train: epoch 152, iter 2800, loss: 1.798749, top_1: 0.817969, top_k: 0.937773, samples/s: 844.004 1613200745.796803
train: epoch 152, iter 2900, loss: 1.793757, top_1: 0.819883, top_k: 0.938594, samples/s: 846.864 1613200776.0258718
train: epoch 152, iter 3000, loss: 1.676153, top_1: 0.819063, top_k: 0.937187, samples/s: 848.256 1613200806.205488
train: epoch 152, iter 3100, loss: 1.763185, top_1: 0.818555, top_k: 0.937500, samples/s: 844.647 1613200836.5140522
train: epoch 152, iter 3200, loss: 1.781909, top_1: 0.819844, top_k: 0.940156, samples/s: 847.556 1613200866.7184625
train: epoch 152, iter 3300, loss: 1.846764, top_1: 0.815898, top_k: 0.936836, samples/s: 848.157 1613200896.901597
train: epoch 152, iter 3400, loss: 1.860880, top_1: 0.813516, top_k: 0.934922, samples/s: 846.081 1613200927.1587656
train: epoch 152, iter 3500, loss: 1.788347, top_1: 0.823242, top_k: 0.938672, samples/s: 844.523 1613200957.4716914
train: epoch 152, iter 3600, loss: 1.824565, top_1: 0.814883, top_k: 0.937109, samples/s: 848.612 1613200987.6386397
train: epoch 152, iter 3700, loss: 1.748671, top_1: 0.819414, top_k: 0.939648, samples/s: 846.584 1613201017.8778749
train: epoch 152, iter 3800, loss: 1.855570, top_1: 0.818242, top_k: 0.937813, samples/s: 847.563 1613201048.0821342
train: epoch 152, iter 3900, loss: 1.794241, top_1: 0.817070, top_k: 0.935937, samples/s: 845.687 1613201078.3533719
train: epoch 152, iter 4000, loss: 1.819943, top_1: 0.818789, top_k: 0.939063, samples/s: 845.717 1613201108.623477
train: epoch 152, iter 4100, loss: 1.722123, top_1: 0.817578, top_k: 0.938789, samples/s: 846.237 1613201138.8751042
train: epoch 152, iter 4200, loss: 1.827193, top_1: 0.818438, top_k: 0.938594, samples/s: 845.116 1613201169.1667008
train: epoch 152, iter 4300, loss: 1.865547, top_1: 0.812930, top_k: 0.934414, samples/s: 843.548 1613201199.5148177
train: epoch 152, iter 4400, loss: 1.802865, top_1: 0.818828, top_k: 0.940469, samples/s: 845.359 1613201229.7977536
train: epoch 152, iter 4500, loss: 1.610638, top_1: 0.819961, top_k: 0.941836, samples/s: 846.582 1613201260.0369916
train: epoch 152, iter 4600, loss: 1.942724, top_1: 0.820781, top_k: 0.941289, samples/s: 847.182 1613201290.2548385
train: epoch 152, iter 4700, loss: 1.934475, top_1: 0.816211, top_k: 0.938984, samples/s: 845.428 1613201320.5353081
train: epoch 152, iter 4800, loss: 1.909509, top_1: 0.816836, top_k: 0.937070, samples/s: 846.132 1613201350.7906475
train: epoch 152, iter 4900, loss: 1.699003, top_1: 0.819688, top_k: 0.940430, samples/s: 843.182 1613201381.1519372
train: epoch 152, iter 5000, loss: 1.672154, top_1: 0.819219, top_k: 0.938945, samples/s: 849.855 1613201411.2746692
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_152.
validation: epoch 152, iter 195, top_1: 0.776342, top_k: 0.938702, samples/s: 2414.000 1613201432.8783693
train: epoch 153, iter 100, loss: 1.758096, top_1: 0.818984, top_k: 0.939141, samples/s: 871.468 1613201482.9782639
train: epoch 153, iter 200, loss: 1.687633, top_1: 0.822070, top_k: 0.940000, samples/s: 867.496 1613201512.4883223
train: epoch 153, iter 300, loss: 1.887800, top_1: 0.820156, top_k: 0.938438, samples/s: 848.507 1613201542.658987
train: epoch 153, iter 400, loss: 1.826064, top_1: 0.821875, top_k: 0.942344, samples/s: 847.133 1613201572.8785563
train: epoch 153, iter 500, loss: 1.779685, top_1: 0.818125, top_k: 0.939805, samples/s: 846.491 1613201603.121002
train: epoch 153, iter 600, loss: 1.768782, top_1: 0.820352, top_k: 0.939766, samples/s: 843.879 1613201633.4571004
train: epoch 153, iter 700, loss: 1.670011, top_1: 0.817461, top_k: 0.938203, samples/s: 844.607 1613201663.7671263
train: epoch 153, iter 800, loss: 1.800390, top_1: 0.815547, top_k: 0.939492, samples/s: 847.997 1613201693.9558108
train: epoch 153, iter 900, loss: 1.732962, top_1: 0.820547, top_k: 0.938906, samples/s: 845.974 1613201724.216787
train: epoch 153, iter 1000, loss: 1.662738, top_1: 0.816562, top_k: 0.941289, samples/s: 847.828 1613201754.4116647
train: epoch 153, iter 1100, loss: 1.764163, top_1: 0.821328, top_k: 0.940391, samples/s: 843.312 1613201784.768154
train: epoch 153, iter 1200, loss: 1.701983, top_1: 0.821328, top_k: 0.939102, samples/s: 845.133 1613201815.0592473
train: epoch 153, iter 1300, loss: 1.787491, top_1: 0.820273, top_k: 0.941172, samples/s: 846.714 1613201845.2937725
train: epoch 153, iter 1400, loss: 1.663458, top_1: 0.815039, top_k: 0.937930, samples/s: 844.777 1613201875.5976565
train: epoch 153, iter 1500, loss: 1.827119, top_1: 0.821211, top_k: 0.938672, samples/s: 847.156 1613201905.816322
train: epoch 153, iter 1600, loss: 1.776011, top_1: 0.816797, top_k: 0.938125, samples/s: 847.545 1613201936.0213115
train: epoch 153, iter 1700, loss: 1.711354, top_1: 0.819297, top_k: 0.939609, samples/s: 846.886 1613201966.249607
train: epoch 153, iter 1800, loss: 1.880301, top_1: 0.818047, top_k: 0.939297, samples/s: 849.405 1613201996.388431
train: epoch 153, iter 1900, loss: 1.685804, top_1: 0.818477, top_k: 0.937109, samples/s: 847.017 1613202026.6121492
train: epoch 153, iter 2000, loss: 1.741697, top_1: 0.816914, top_k: 0.935781, samples/s: 848.415 1613202056.7860196
train: epoch 153, iter 2100, loss: 1.804806, top_1: 0.819570, top_k: 0.938203, samples/s: 848.465 1613202086.9582586
train: epoch 153, iter 2200, loss: 1.799562, top_1: 0.815664, top_k: 0.935859, samples/s: 845.953 1613202117.2199419
train: epoch 153, iter 2300, loss: 1.870793, top_1: 0.816523, top_k: 0.937383, samples/s: 846.478 1613202147.462844
train: epoch 153, iter 2400, loss: 1.790543, top_1: 0.818672, top_k: 0.938203, samples/s: 844.479 1613202177.7775135
train: epoch 153, iter 2500, loss: 1.886478, top_1: 0.815781, top_k: 0.939805, samples/s: 846.236 1613202208.0290985
train: epoch 153, iter 2600, loss: 1.667648, top_1: 0.817383, top_k: 0.939961, samples/s: 846.751 1613202238.262273
train: epoch 153, iter 2700, loss: 1.739691, top_1: 0.812773, top_k: 0.936250, samples/s: 845.460 1613202268.5417147
train: epoch 153, iter 2800, loss: 1.794473, top_1: 0.812539, top_k: 0.937187, samples/s: 849.033 1613202298.6935816
train: epoch 153, iter 2900, loss: 1.854230, top_1: 0.814570, top_k: 0.936641, samples/s: 851.231 1613202328.7676616
train: epoch 153, iter 3000, loss: 1.684067, top_1: 0.819492, top_k: 0.940508, samples/s: 844.316 1613202359.0881383
train: epoch 153, iter 3100, loss: 1.799592, top_1: 0.815820, top_k: 0.938047, samples/s: 846.603 1613202389.3265746
train: epoch 153, iter 3200, loss: 1.708062, top_1: 0.820859, top_k: 0.938828, samples/s: 847.511 1613202419.5326946
train: epoch 153, iter 3300, loss: 1.728309, top_1: 0.818203, top_k: 0.938945, samples/s: 849.335 1613202449.6739323
train: epoch 153, iter 3400, loss: 1.756338, top_1: 0.821406, top_k: 0.941133, samples/s: 846.168 1613202479.927882
train: epoch 153, iter 3500, loss: 1.811485, top_1: 0.819727, top_k: 0.940273, samples/s: 848.342 1613202510.1044524
train: epoch 153, iter 3600, loss: 1.759145, top_1: 0.821406, top_k: 0.939336, samples/s: 847.637 1613202540.3060544
train: epoch 153, iter 3700, loss: 1.725773, top_1: 0.822852, top_k: 0.939805, samples/s: 847.857 1613202570.4997702
train: epoch 153, iter 3800, loss: 1.887093, top_1: 0.816211, top_k: 0.936758, samples/s: 846.909 1613202600.7274473
train: epoch 153, iter 3900, loss: 1.842260, top_1: 0.816523, top_k: 0.939023, samples/s: 848.255 1613202630.907025
train: epoch 153, iter 4000, loss: 1.706657, top_1: 0.814688, top_k: 0.937773, samples/s: 845.524 1613202661.1841433
train: epoch 153, iter 4100, loss: 1.802669, top_1: 0.812500, top_k: 0.935703, samples/s: 846.686 1613202691.4196823
train: epoch 153, iter 4200, loss: 1.715177, top_1: 0.821016, top_k: 0.938516, samples/s: 848.639 1613202721.585554
train: epoch 153, iter 4300, loss: 1.804807, top_1: 0.818633, top_k: 0.938906, samples/s: 844.858 1613202751.8864868
train: epoch 153, iter 4400, loss: 1.648556, top_1: 0.815430, top_k: 0.938203, samples/s: 847.629 1613202782.0883753
train: epoch 153, iter 4500, loss: 1.702995, top_1: 0.820352, top_k: 0.939531, samples/s: 845.853 1613202812.3536754
train: epoch 153, iter 4600, loss: 1.814221, top_1: 0.816875, top_k: 0.938516, samples/s: 847.582 1613202842.5572674
train: epoch 153, iter 4700, loss: 1.656231, top_1: 0.819844, top_k: 0.939414, samples/s: 847.783 1613202872.7536905
train: epoch 153, iter 4800, loss: 1.745836, top_1: 0.818945, top_k: 0.939688, samples/s: 847.360 1613202902.9651918
train: epoch 153, iter 4900, loss: 1.761824, top_1: 0.819805, top_k: 0.939258, samples/s: 845.184 1613202933.2544475
train: epoch 153, iter 5000, loss: 1.643229, top_1: 0.817695, top_k: 0.938867, samples/s: 848.200 1613202963.4359868
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_153.
validation: epoch 153, iter 195, top_1: 0.777103, top_k: 0.938361, samples/s: 2460.135 1613202984.6752908
train: epoch 154, iter 100, loss: 1.746720, top_1: 0.822930, top_k: 0.941562, samples/s: 868.155 1613203035.2439559
train: epoch 154, iter 200, loss: 1.803637, top_1: 0.819609, top_k: 0.939844, samples/s: 869.905 1613203064.672322
train: epoch 154, iter 300, loss: 1.892857, top_1: 0.819023, top_k: 0.940352, samples/s: 849.912 1613203094.793208
train: epoch 154, iter 400, loss: 1.669901, top_1: 0.818828, top_k: 0.939141, samples/s: 846.100 1613203125.049627
train: epoch 154, iter 500, loss: 1.828513, top_1: 0.814844, top_k: 0.936289, samples/s: 846.068 1613203155.3072178
train: epoch 154, iter 600, loss: 1.755435, top_1: 0.818242, top_k: 0.940625, samples/s: 845.671 1613203185.5790303
train: epoch 154, iter 700, loss: 1.792499, top_1: 0.818438, top_k: 0.941680, samples/s: 844.545 1613203215.891231
train: epoch 154, iter 800, loss: 1.870857, top_1: 0.819570, top_k: 0.940352, samples/s: 845.226 1613203246.178933
train: epoch 154, iter 900, loss: 1.711627, top_1: 0.817070, top_k: 0.941523, samples/s: 846.200 1613203276.431931
train: epoch 154, iter 1000, loss: 1.809612, top_1: 0.820703, top_k: 0.938750, samples/s: 847.937 1613203306.6228373
train: epoch 154, iter 1100, loss: 1.740703, top_1: 0.816055, top_k: 0.938633, samples/s: 844.275 1613203336.9447162
train: epoch 154, iter 1200, loss: 2.019102, top_1: 0.819570, top_k: 0.939727, samples/s: 848.863 1613203367.102647
train: epoch 154, iter 1300, loss: 1.762560, top_1: 0.819258, top_k: 0.939492, samples/s: 844.506 1613203397.4161928
train: epoch 154, iter 1400, loss: 1.750329, top_1: 0.815781, top_k: 0.936758, samples/s: 847.000 1613203427.6404982
train: epoch 154, iter 1500, loss: 1.726326, top_1: 0.817852, top_k: 0.937500, samples/s: 847.644 1613203457.8418498
train: epoch 154, iter 1600, loss: 1.673687, top_1: 0.814297, top_k: 0.935078, samples/s: 844.878 1613203488.1420894
train: epoch 154, iter 1700, loss: 1.744865, top_1: 0.820742, top_k: 0.942305, samples/s: 847.050 1613203518.3646233
train: epoch 154, iter 1800, loss: 1.756745, top_1: 0.818008, top_k: 0.939531, samples/s: 847.201 1613203548.5818818
train: epoch 154, iter 1900, loss: 1.755409, top_1: 0.818438, top_k: 0.937852, samples/s: 844.835 1613203578.8835752
train: epoch 154, iter 2000, loss: 1.684551, top_1: 0.820234, top_k: 0.937813, samples/s: 847.762 1613203609.080774
train: epoch 154, iter 2100, loss: 1.872733, top_1: 0.822734, top_k: 0.938945, samples/s: 845.989 1613203639.3412464
train: epoch 154, iter 2200, loss: 1.789637, top_1: 0.817500, top_k: 0.937813, samples/s: 847.799 1613203669.5369787
train: epoch 154, iter 2300, loss: 1.735119, top_1: 0.815977, top_k: 0.937109, samples/s: 847.314 1613203699.7501092
train: epoch 154, iter 2400, loss: 1.726124, top_1: 0.817461, top_k: 0.936953, samples/s: 845.708 1613203730.0206017
train: epoch 154, iter 2500, loss: 1.840277, top_1: 0.820039, top_k: 0.938359, samples/s: 847.394 1613203760.2309644
train: epoch 154, iter 2600, loss: 1.866919, top_1: 0.817969, top_k: 0.937344, samples/s: 848.024 1613203790.4188116
train: epoch 154, iter 2700, loss: 1.742832, top_1: 0.818711, top_k: 0.938477, samples/s: 849.751 1613203820.545206
train: epoch 154, iter 2800, loss: 1.924806, top_1: 0.819648, top_k: 0.940391, samples/s: 845.248 1613203850.8321815
train: epoch 154, iter 2900, loss: 1.788998, top_1: 0.820312, top_k: 0.938555, samples/s: 846.899 1613203881.0601065
train: epoch 154, iter 3000, loss: 1.862444, top_1: 0.821133, top_k: 0.938711, samples/s: 845.196 1613203911.3490164
train: epoch 154, iter 3100, loss: 1.696941, top_1: 0.822930, top_k: 0.944063, samples/s: 846.926 1613203941.5758674
train: epoch 154, iter 3200, loss: 1.778067, top_1: 0.816719, top_k: 0.937461, samples/s: 847.640 1613203971.7773762
train: epoch 154, iter 3300, loss: 1.773576, top_1: 0.817891, top_k: 0.938711, samples/s: 843.979 1613204002.1099374
train: epoch 154, iter 3400, loss: 1.744231, top_1: 0.821680, top_k: 0.938516, samples/s: 848.954 1613204032.2646675
train: epoch 154, iter 3500, loss: 1.867507, top_1: 0.816641, top_k: 0.937695, samples/s: 843.197 1613204062.62531
train: epoch 154, iter 3600, loss: 1.799226, top_1: 0.809727, top_k: 0.936797, samples/s: 846.759 1613204092.8582923
train: epoch 154, iter 3700, loss: 1.892302, top_1: 0.815273, top_k: 0.939102, samples/s: 844.926 1613204123.156811
train: epoch 154, iter 3800, loss: 1.805814, top_1: 0.821289, top_k: 0.940195, samples/s: 847.872 1613204153.349979
train: epoch 154, iter 3900, loss: 1.875975, top_1: 0.817148, top_k: 0.938438, samples/s: 845.722 1613204183.6200778
train: epoch 154, iter 4000, loss: 1.869546, top_1: 0.821484, top_k: 0.939492, samples/s: 845.098 1613204213.9122968
train: epoch 154, iter 4100, loss: 1.743409, top_1: 0.815078, top_k: 0.937656, samples/s: 846.147 1613204244.1671174
train: epoch 154, iter 4200, loss: 1.853271, top_1: 0.821328, top_k: 0.939063, samples/s: 850.270 1613204274.2752092
train: epoch 154, iter 4300, loss: 1.773034, top_1: 0.815547, top_k: 0.939102, samples/s: 848.967 1613204304.4294236
train: epoch 154, iter 4400, loss: 1.832949, top_1: 0.823086, top_k: 0.941367, samples/s: 844.933 1613204334.727708
train: epoch 154, iter 4500, loss: 1.719428, top_1: 0.820195, top_k: 0.941914, samples/s: 846.870 1613204364.9566774
train: epoch 154, iter 4600, loss: 1.925105, top_1: 0.816875, top_k: 0.938086, samples/s: 849.062 1613204395.1076496
train: epoch 154, iter 4700, loss: 1.786374, top_1: 0.817656, top_k: 0.937031, samples/s: 845.284 1613204425.3933597
train: epoch 154, iter 4800, loss: 1.805617, top_1: 0.815195, top_k: 0.935625, samples/s: 849.314 1613204455.5352674
train: epoch 154, iter 4900, loss: 1.824222, top_1: 0.823633, top_k: 0.940312, samples/s: 845.182 1613204485.824513
train: epoch 154, iter 5000, loss: 1.674484, top_1: 0.816914, top_k: 0.939023, samples/s: 846.804 1613204516.0559235
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_154.
validation: epoch 154, iter 195, top_1: 0.778325, top_k: 0.938802, samples/s: 2498.179 1613204536.9389117
train: epoch 155, iter 100, loss: 1.851769, top_1: 0.819336, top_k: 0.938320, samples/s: 870.123 1613204587.0047448
train: epoch 155, iter 200, loss: 1.613586, top_1: 0.822344, top_k: 0.939609, samples/s: 866.592 1613204616.5456848
train: epoch 155, iter 300, loss: 1.946631, top_1: 0.823164, top_k: 0.939961, samples/s: 847.763 1613204646.7428176
train: epoch 155, iter 400, loss: 1.824090, top_1: 0.819063, top_k: 0.940859, samples/s: 846.981 1613204676.967751
train: epoch 155, iter 500, loss: 1.733997, top_1: 0.816445, top_k: 0.939219, samples/s: 847.262 1613204707.1827705
train: epoch 155, iter 600, loss: 1.784040, top_1: 0.820117, top_k: 0.939023, samples/s: 846.403 1613204737.428407
train: epoch 155, iter 700, loss: 1.590153, top_1: 0.819805, top_k: 0.941484, samples/s: 844.806 1613204767.7312376
train: epoch 155, iter 800, loss: 1.719110, top_1: 0.819180, top_k: 0.940078, samples/s: 846.140 1613204797.9862611
train: epoch 155, iter 900, loss: 1.722996, top_1: 0.818945, top_k: 0.937695, samples/s: 844.946 1613204828.2840984
train: epoch 155, iter 1000, loss: 1.838859, top_1: 0.817891, top_k: 0.940703, samples/s: 848.708 1613204858.4475834
train: epoch 155, iter 1100, loss: 1.755670, top_1: 0.820117, top_k: 0.940742, samples/s: 845.506 1613204888.725326
train: epoch 155, iter 1200, loss: 1.809830, top_1: 0.821289, top_k: 0.940273, samples/s: 846.193 1613204918.9784994
train: epoch 155, iter 1300, loss: 1.817938, top_1: 0.817969, top_k: 0.936758, samples/s: 849.457 1613204949.1154027
train: epoch 155, iter 1400, loss: 1.719641, top_1: 0.816055, top_k: 0.937266, samples/s: 847.319 1613204979.328317
train: epoch 155, iter 1500, loss: 1.899523, top_1: 0.818086, top_k: 0.939141, samples/s: 847.137 1613205009.5476713
train: epoch 155, iter 1600, loss: 2.023222, top_1: 0.821055, top_k: 0.940703, samples/s: 844.378 1613205039.8660758
train: epoch 155, iter 1700, loss: 1.936230, top_1: 0.820742, top_k: 0.939961, samples/s: 850.162 1613205069.9777687
train: epoch 155, iter 1800, loss: 1.754187, top_1: 0.818633, top_k: 0.940039, samples/s: 846.567 1613205100.2175677
train: epoch 155, iter 1900, loss: 1.800249, top_1: 0.817227, top_k: 0.939688, samples/s: 846.650 1613205130.454426
train: epoch 155, iter 2000, loss: 1.722472, top_1: 0.823867, top_k: 0.941680, samples/s: 845.630 1613205160.7277648
train: epoch 155, iter 2100, loss: 1.743329, top_1: 0.810273, top_k: 0.935234, samples/s: 849.120 1613205190.8765795
train: epoch 155, iter 2200, loss: 1.695541, top_1: 0.820703, top_k: 0.938633, samples/s: 844.444 1613205221.1923664
train: epoch 155, iter 2300, loss: 1.831024, top_1: 0.815742, top_k: 0.936250, samples/s: 845.647 1613205251.465115
train: epoch 155, iter 2400, loss: 1.781529, top_1: 0.821094, top_k: 0.939570, samples/s: 848.954 1613205281.6198683
train: epoch 155, iter 2500, loss: 1.810212, top_1: 0.824570, top_k: 0.941289, samples/s: 845.983 1613205311.8805256
train: epoch 155, iter 2600, loss: 1.739510, top_1: 0.818438, top_k: 0.937344, samples/s: 848.993 1613205342.0338924
train: epoch 155, iter 2700, loss: 1.796486, top_1: 0.818984, top_k: 0.939531, samples/s: 847.735 1613205372.2319322
train: epoch 155, iter 2800, loss: 1.733292, top_1: 0.818477, top_k: 0.939570, samples/s: 846.915 1613205402.4593606
train: epoch 155, iter 2900, loss: 1.778080, top_1: 0.817969, top_k: 0.939727, samples/s: 845.664 1613205432.7314363
train: epoch 155, iter 3000, loss: 1.883387, top_1: 0.820078, top_k: 0.938945, samples/s: 849.407 1613205462.8700237
train: epoch 155, iter 3100, loss: 1.774506, top_1: 0.816914, top_k: 0.939492, samples/s: 848.233 1613205493.0505116
train: epoch 155, iter 3200, loss: 1.835964, top_1: 0.820508, top_k: 0.940195, samples/s: 846.772 1613205523.2829897
train: epoch 155, iter 3300, loss: 1.797636, top_1: 0.819102, top_k: 0.937813, samples/s: 846.705 1613205553.517811
train: epoch 155, iter 3400, loss: 1.882451, top_1: 0.819453, top_k: 0.937656, samples/s: 846.092 1613205583.7745745
train: epoch 155, iter 3500, loss: 1.743671, top_1: 0.819570, top_k: 0.939727, samples/s: 848.429 1613205613.9480064
train: epoch 155, iter 3600, loss: 1.956534, top_1: 0.816719, top_k: 0.938047, samples/s: 848.921 1613205644.1038945
train: epoch 155, iter 3700, loss: 1.809388, top_1: 0.815234, top_k: 0.938008, samples/s: 845.521 1613205674.38104
train: epoch 155, iter 3800, loss: 1.804324, top_1: 0.819063, top_k: 0.938633, samples/s: 850.314 1613205704.4876297
train: epoch 155, iter 3900, loss: 1.773358, top_1: 0.818320, top_k: 0.939297, samples/s: 846.327 1613205734.735911
train: epoch 155, iter 4000, loss: 1.658584, top_1: 0.817227, top_k: 0.938242, samples/s: 850.134 1613205764.848935
train: epoch 155, iter 4100, loss: 1.762708, top_1: 0.816914, top_k: 0.939492, samples/s: 845.582 1613205795.1239367
train: epoch 155, iter 4200, loss: 1.869093, top_1: 0.818789, top_k: 0.941523, samples/s: 848.334 1613205825.3007033
train: epoch 155, iter 4300, loss: 1.720207, top_1: 0.814961, top_k: 0.937266, samples/s: 847.694 1613205855.5003033
train: epoch 155, iter 4400, loss: 1.749601, top_1: 0.818047, top_k: 0.935977, samples/s: 849.758 1613205885.6264527
train: epoch 155, iter 4500, loss: 1.678215, top_1: 0.818203, top_k: 0.937187, samples/s: 846.947 1613205915.8527696
train: epoch 155, iter 4600, loss: 1.825427, top_1: 0.817305, top_k: 0.938477, samples/s: 846.952 1613205946.078697
train: epoch 155, iter 4700, loss: 1.810414, top_1: 0.816992, top_k: 0.939414, samples/s: 846.554 1613205976.3189797
train: epoch 155, iter 4800, loss: 1.894974, top_1: 0.819844, top_k: 0.938242, samples/s: 848.354 1613206006.4950593
train: epoch 155, iter 4900, loss: 1.954789, top_1: 0.816055, top_k: 0.938711, samples/s: 846.892 1613206036.7233317
train: epoch 155, iter 5000, loss: 1.858466, top_1: 0.813672, top_k: 0.937813, samples/s: 846.866 1613206066.9523644
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_155.
validation: epoch 155, iter 195, top_1: 0.778185, top_k: 0.939183, samples/s: 2455.794 1613206088.199072
train: epoch 156, iter 100, loss: 1.848176, top_1: 0.817734, top_k: 0.940000, samples/s: 867.556 1613206138.331941
train: epoch 156, iter 200, loss: 1.688601, top_1: 0.822031, top_k: 0.937891, samples/s: 866.530 1613206167.874978
train: epoch 156, iter 300, loss: 1.767567, top_1: 0.819805, top_k: 0.939766, samples/s: 851.451 1613206197.9413834
train: epoch 156, iter 400, loss: 1.751247, top_1: 0.818633, top_k: 0.941602, samples/s: 845.088 1613206228.23403
train: epoch 156, iter 500, loss: 1.753531, top_1: 0.819727, top_k: 0.937969, samples/s: 844.316 1613206258.5544858
train: epoch 156, iter 600, loss: 1.870505, top_1: 0.820977, top_k: 0.940859, samples/s: 847.572 1613206288.758375
train: epoch 156, iter 700, loss: 1.823794, top_1: 0.817031, top_k: 0.937930, samples/s: 846.422 1613206319.0033016
train: epoch 156, iter 800, loss: 1.807178, top_1: 0.817500, top_k: 0.941016, samples/s: 847.743 1613206349.2011993
train: epoch 156, iter 900, loss: 1.906254, top_1: 0.818750, top_k: 0.939453, samples/s: 844.606 1613206379.5112307
train: epoch 156, iter 1000, loss: 1.798198, top_1: 0.819453, top_k: 0.939531, samples/s: 846.270 1613206409.7615047
train: epoch 156, iter 1100, loss: 1.810329, top_1: 0.818438, top_k: 0.939375, samples/s: 843.007 1613206440.1290736
train: epoch 156, iter 1200, loss: 1.751540, top_1: 0.820156, top_k: 0.935859, samples/s: 849.191 1613206470.2753456
train: epoch 156, iter 1300, loss: 1.768212, top_1: 0.820781, top_k: 0.941875, samples/s: 845.813 1613206500.5421364
train: epoch 156, iter 1400, loss: 1.688325, top_1: 0.822383, top_k: 0.940859, samples/s: 846.880 1613206530.7706494
train: epoch 156, iter 1500, loss: 1.745668, top_1: 0.819063, top_k: 0.940547, samples/s: 846.250 1613206561.0218227
train: epoch 156, iter 1600, loss: 1.858219, top_1: 0.822734, top_k: 0.940117, samples/s: 845.053 1613206591.3158128
train: epoch 156, iter 1700, loss: 1.868823, top_1: 0.819688, top_k: 0.939531, samples/s: 846.823 1613206621.5464134
train: epoch 156, iter 1800, loss: 1.869164, top_1: 0.817734, top_k: 0.940078, samples/s: 845.056 1613206651.8403018
train: epoch 156, iter 1900, loss: 1.863068, top_1: 0.817617, top_k: 0.936523, samples/s: 847.107 1613206682.0607405
train: epoch 156, iter 2000, loss: 1.753098, top_1: 0.818438, top_k: 0.938438, samples/s: 847.767 1613206712.257765
train: epoch 156, iter 2100, loss: 1.941691, top_1: 0.818320, top_k: 0.940000, samples/s: 843.136 1613206742.620593
train: epoch 156, iter 2200, loss: 1.917819, top_1: 0.818008, top_k: 0.939492, samples/s: 847.019 1613206772.8442252
train: epoch 156, iter 2300, loss: 1.770776, top_1: 0.814258, top_k: 0.937148, samples/s: 844.898 1613206803.1437216
train: epoch 156, iter 2400, loss: 1.664808, top_1: 0.819570, top_k: 0.938828, samples/s: 846.751 1613206833.376994
train: epoch 156, iter 2500, loss: 1.817153, top_1: 0.817930, top_k: 0.936836, samples/s: 844.342 1613206863.6964362
train: epoch 156, iter 2600, loss: 1.898309, top_1: 0.817227, top_k: 0.939531, samples/s: 847.051 1613206893.9189148
train: epoch 156, iter 2700, loss: 1.750121, top_1: 0.815234, top_k: 0.937344, samples/s: 845.809 1613206924.185991
train: epoch 156, iter 2800, loss: 1.747632, top_1: 0.818750, top_k: 0.938984, samples/s: 848.341 1613206954.3623478
train: epoch 156, iter 2900, loss: 1.788729, top_1: 0.817852, top_k: 0.938789, samples/s: 846.102 1613206984.6187263
train: epoch 156, iter 3000, loss: 1.706991, top_1: 0.819805, top_k: 0.940234, samples/s: 843.720 1613207014.9605744
train: epoch 156, iter 3100, loss: 1.825703, top_1: 0.817852, top_k: 0.938398, samples/s: 848.213 1613207045.1416156
train: epoch 156, iter 3200, loss: 1.808815, top_1: 0.819336, top_k: 0.938359, samples/s: 844.659 1613207075.4497905
train: epoch 156, iter 3300, loss: 1.780440, top_1: 0.819102, top_k: 0.936602, samples/s: 846.107 1613207105.7059207
train: epoch 156, iter 3400, loss: 1.817036, top_1: 0.821875, top_k: 0.939844, samples/s: 846.790 1613207135.9378207
train: epoch 156, iter 3500, loss: 1.611280, top_1: 0.820234, top_k: 0.941133, samples/s: 845.616 1613207166.2116365
train: epoch 156, iter 3600, loss: 1.817268, top_1: 0.820625, top_k: 0.940469, samples/s: 846.390 1613207196.457688
train: epoch 156, iter 3700, loss: 1.887633, top_1: 0.819727, top_k: 0.940234, samples/s: 847.184 1613207226.6754491
train: epoch 156, iter 3800, loss: 1.989489, top_1: 0.816797, top_k: 0.938242, samples/s: 845.608 1613207256.9494772
train: epoch 156, iter 3900, loss: 1.832547, top_1: 0.817422, top_k: 0.938555, samples/s: 845.827 1613207287.2157629
train: epoch 156, iter 4000, loss: 1.757314, top_1: 0.820312, top_k: 0.938984, samples/s: 845.477 1613207317.494479
train: epoch 156, iter 4100, loss: 1.868225, top_1: 0.820195, top_k: 0.940547, samples/s: 848.090 1613207347.6799536
train: epoch 156, iter 4200, loss: 1.727824, top_1: 0.819727, top_k: 0.938633, samples/s: 846.067 1613207377.9378755
train: epoch 156, iter 4300, loss: 1.843004, top_1: 0.820547, top_k: 0.939805, samples/s: 845.013 1613207408.2331176
train: epoch 156, iter 4400, loss: 1.718502, top_1: 0.815547, top_k: 0.937578, samples/s: 849.271 1613207438.3765097
train: epoch 156, iter 4500, loss: 1.738567, top_1: 0.818906, top_k: 0.939219, samples/s: 846.130 1613207468.6319454
train: epoch 156, iter 4600, loss: 1.819228, top_1: 0.815273, top_k: 0.938477, samples/s: 845.620 1613207498.9056427
train: epoch 156, iter 4700, loss: 1.738228, top_1: 0.821914, top_k: 0.941406, samples/s: 848.838 1613207529.0644865
train: epoch 156, iter 4800, loss: 1.800732, top_1: 0.816953, top_k: 0.938672, samples/s: 844.169 1613207559.3901553
train: epoch 156, iter 4900, loss: 1.777332, top_1: 0.817891, top_k: 0.940820, samples/s: 847.815 1613207589.5854547
train: epoch 156, iter 5000, loss: 1.859150, top_1: 0.817187, top_k: 0.939102, samples/s: 849.767 1613207619.7113674
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_156.
validation: epoch 156, iter 195, top_1: 0.778786, top_k: 0.938882, samples/s: 2428.078 1613207641.1776376
train: epoch 157, iter 100, loss: 1.823767, top_1: 0.816562, top_k: 0.936875, samples/s: 871.020 1613207690.9546173
train: epoch 157, iter 200, loss: 1.683920, top_1: 0.818984, top_k: 0.939102, samples/s: 869.553 1613207720.3949823
train: epoch 157, iter 300, loss: 1.707786, top_1: 0.817148, top_k: 0.939727, samples/s: 850.197 1613207750.5055883
train: epoch 157, iter 400, loss: 1.817878, top_1: 0.822031, top_k: 0.940664, samples/s: 848.436 1613207780.6788497
train: epoch 157, iter 500, loss: 1.808012, top_1: 0.816719, top_k: 0.940273, samples/s: 843.039 1613207811.0451539
train: epoch 157, iter 600, loss: 1.745965, top_1: 0.815742, top_k: 0.938125, samples/s: 844.188 1613207841.3701365
train: epoch 157, iter 700, loss: 1.774437, top_1: 0.817383, top_k: 0.938086, samples/s: 846.817 1613207871.601049
train: epoch 157, iter 800, loss: 1.873143, top_1: 0.816055, top_k: 0.937695, samples/s: 846.108 1613207901.857154
train: epoch 157, iter 900, loss: 1.668604, top_1: 0.820859, top_k: 0.938906, samples/s: 844.813 1613207932.1597207
train: epoch 157, iter 1000, loss: 1.755179, top_1: 0.815820, top_k: 0.938008, samples/s: 846.981 1613207962.384668
train: epoch 157, iter 1100, loss: 1.705468, top_1: 0.822734, top_k: 0.940664, samples/s: 841.807 1613207992.795443
train: epoch 157, iter 1200, loss: 1.660784, top_1: 0.815625, top_k: 0.936758, samples/s: 846.018 1613208023.0549622
train: epoch 157, iter 1300, loss: 1.711117, top_1: 0.816875, top_k: 0.935547, samples/s: 848.694 1613208053.2188814
train: epoch 157, iter 1400, loss: 1.805489, top_1: 0.818750, top_k: 0.939570, samples/s: 842.253 1613208083.6135757
train: epoch 157, iter 1500, loss: 1.900769, top_1: 0.820742, top_k: 0.939141, samples/s: 845.606 1613208113.8876488
train: epoch 157, iter 1600, loss: 1.768022, top_1: 0.821602, top_k: 0.937305, samples/s: 848.941 1613208144.0428967
train: epoch 157, iter 1700, loss: 1.877941, top_1: 0.814609, top_k: 0.938164, samples/s: 846.146 1613208174.2977946
train: epoch 157, iter 1800, loss: 1.938332, top_1: 0.815781, top_k: 0.936992, samples/s: 846.717 1613208204.5321307
train: epoch 157, iter 1900, loss: 1.711527, top_1: 0.818281, top_k: 0.938398, samples/s: 847.354 1613208234.7438889
train: epoch 157, iter 2000, loss: 1.769488, top_1: 0.817383, top_k: 0.938750, samples/s: 849.663 1613208264.873479
train: epoch 157, iter 2100, loss: 1.849926, top_1: 0.821797, top_k: 0.940625, samples/s: 846.111 1613208295.129506
train: epoch 157, iter 2200, loss: 1.795533, top_1: 0.819219, top_k: 0.939023, samples/s: 848.276 1613208325.3083348
train: epoch 157, iter 2300, loss: 1.840496, top_1: 0.820625, top_k: 0.939297, samples/s: 844.772 1613208355.612416
train: epoch 157, iter 2400, loss: 1.772395, top_1: 0.819922, top_k: 0.938359, samples/s: 846.574 1613208385.8519504
train: epoch 157, iter 2500, loss: 1.630710, top_1: 0.816133, top_k: 0.938281, samples/s: 848.695 1613208416.0158463
train: epoch 157, iter 2600, loss: 1.768342, top_1: 0.819141, top_k: 0.937422, samples/s: 842.966 1613208446.384838
train: epoch 157, iter 2700, loss: 1.727840, top_1: 0.817109, top_k: 0.937266, samples/s: 849.066 1613208476.5356214
train: epoch 157, iter 2800, loss: 1.874633, top_1: 0.818594, top_k: 0.938320, samples/s: 845.593 1613208506.810281
train: epoch 157, iter 2900, loss: 1.657267, top_1: 0.813984, top_k: 0.939258, samples/s: 850.840 1613208536.8981051
train: epoch 157, iter 3000, loss: 1.792975, top_1: 0.819727, top_k: 0.935781, samples/s: 844.974 1613208567.194913
train: epoch 157, iter 3100, loss: 1.706121, top_1: 0.818398, top_k: 0.939414, samples/s: 849.540 1613208597.3288958
train: epoch 157, iter 3200, loss: 1.842701, top_1: 0.817539, top_k: 0.939727, samples/s: 848.574 1613208627.4971068
train: epoch 157, iter 3300, loss: 1.754778, top_1: 0.816680, top_k: 0.938281, samples/s: 847.068 1613208657.7190619
train: epoch 157, iter 3400, loss: 1.841508, top_1: 0.819141, top_k: 0.938242, samples/s: 847.346 1613208687.9311006
train: epoch 157, iter 3500, loss: 1.910161, top_1: 0.819180, top_k: 0.938906, samples/s: 845.785 1613208718.1987228
train: epoch 157, iter 3600, loss: 1.735939, top_1: 0.824297, top_k: 0.939648, samples/s: 846.725 1613208748.432964
train: epoch 157, iter 3700, loss: 1.826313, top_1: 0.815391, top_k: 0.939297, samples/s: 847.796 1613208778.6288166
train: epoch 157, iter 3800, loss: 1.702217, top_1: 0.817813, top_k: 0.941992, samples/s: 845.846 1613208808.894455
train: epoch 157, iter 3900, loss: 1.752388, top_1: 0.820625, top_k: 0.937773, samples/s: 847.416 1613208839.1039245
train: epoch 157, iter 4000, loss: 1.806435, top_1: 0.818047, top_k: 0.939766, samples/s: 846.787 1613208869.3357997
train: epoch 157, iter 4100, loss: 1.702032, top_1: 0.821797, top_k: 0.939336, samples/s: 850.459 1613208899.437232
train: epoch 157, iter 4200, loss: 1.705001, top_1: 0.820117, top_k: 0.940391, samples/s: 846.956 1613208929.663163
train: epoch 157, iter 4300, loss: 1.842326, top_1: 0.816953, top_k: 0.938047, samples/s: 845.014 1613208959.958501
train: epoch 157, iter 4400, loss: 1.767608, top_1: 0.814922, top_k: 0.938320, samples/s: 849.016 1613208990.1110203
train: epoch 157, iter 4500, loss: 1.695822, top_1: 0.822187, top_k: 0.940234, samples/s: 848.355 1613209020.2870889
train: epoch 157, iter 4600, loss: 1.689930, top_1: 0.815898, top_k: 0.936523, samples/s: 850.168 1613209050.398814
train: epoch 157, iter 4700, loss: 1.716031, top_1: 0.822266, top_k: 0.938008, samples/s: 848.441 1613209080.571781
train: epoch 157, iter 4800, loss: 1.819943, top_1: 0.821758, top_k: 0.938672, samples/s: 847.518 1613209110.7776656
train: epoch 157, iter 4900, loss: 1.730671, top_1: 0.822422, top_k: 0.940586, samples/s: 847.080 1613209140.9991357
train: epoch 157, iter 5000, loss: 1.774143, top_1: 0.819453, top_k: 0.938359, samples/s: 849.200 1613209171.1450589
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_157.
validation: epoch 157, iter 195, top_1: 0.779026, top_k: 0.939303, samples/s: 2443.206 1613209192.4637146
train: epoch 158, iter 100, loss: 1.797949, top_1: 0.822187, top_k: 0.937617, samples/s: 871.014 1613209247.8653684
train: epoch 158, iter 200, loss: 1.736134, top_1: 0.817266, top_k: 0.940508, samples/s: 869.673 1613209277.3016393
train: epoch 158, iter 300, loss: 1.899153, top_1: 0.821055, top_k: 0.940078, samples/s: 856.515 1613209307.1902359
train: epoch 158, iter 400, loss: 1.729840, top_1: 0.820039, top_k: 0.940234, samples/s: 843.438 1613209337.5422049
train: epoch 158, iter 500, loss: 1.873749, top_1: 0.817813, top_k: 0.937383, samples/s: 850.293 1613209367.6494193
train: epoch 158, iter 600, loss: 1.847838, top_1: 0.819648, top_k: 0.939414, samples/s: 846.509 1613209397.8912854
train: epoch 158, iter 700, loss: 1.902055, top_1: 0.814648, top_k: 0.934375, samples/s: 848.635 1613209428.057351
train: epoch 158, iter 800, loss: 1.839289, top_1: 0.819297, top_k: 0.938477, samples/s: 843.847 1613209458.3946712
train: epoch 158, iter 900, loss: 1.763875, top_1: 0.819297, top_k: 0.937930, samples/s: 845.217 1613209488.6826808
train: epoch 158, iter 1000, loss: 1.806791, top_1: 0.818359, top_k: 0.937969, samples/s: 846.265 1613209518.933321
train: epoch 158, iter 1100, loss: 1.751264, top_1: 0.820312, top_k: 0.942344, samples/s: 846.570 1613209549.1729124
train: epoch 158, iter 1200, loss: 1.690173, top_1: 0.820234, top_k: 0.939648, samples/s: 846.767 1613209579.4056413
train: epoch 158, iter 1300, loss: 1.859557, top_1: 0.819063, top_k: 0.938711, samples/s: 843.646 1613209609.750131
train: epoch 158, iter 1400, loss: 1.841792, top_1: 0.818008, top_k: 0.941055, samples/s: 847.924 1613209639.9415402
train: epoch 158, iter 1500, loss: 1.788978, top_1: 0.821680, top_k: 0.941133, samples/s: 848.029 1613209670.1290872
train: epoch 158, iter 1600, loss: 1.861083, top_1: 0.818945, top_k: 0.939648, samples/s: 846.973 1613209700.3543785
train: epoch 158, iter 1700, loss: 1.744659, top_1: 0.815703, top_k: 0.938281, samples/s: 847.377 1613209730.5653603
train: epoch 158, iter 1800, loss: 1.846879, top_1: 0.820430, top_k: 0.940898, samples/s: 847.402 1613209760.7753549
train: epoch 158, iter 1900, loss: 1.880728, top_1: 0.819258, top_k: 0.941484, samples/s: 848.283 1613209790.9539208
train: epoch 158, iter 2000, loss: 1.629413, top_1: 0.817500, top_k: 0.937695, samples/s: 845.506 1613209821.231557
train: epoch 158, iter 2100, loss: 1.678783, top_1: 0.819336, top_k: 0.938633, samples/s: 848.269 1613209851.410648
train: epoch 158, iter 2200, loss: 1.856764, top_1: 0.819609, top_k: 0.941211, samples/s: 849.077 1613209881.5610704
train: epoch 158, iter 2300, loss: 1.752911, top_1: 0.817383, top_k: 0.937461, samples/s: 845.323 1613209911.845427
train: epoch 158, iter 2400, loss: 1.796269, top_1: 0.817813, top_k: 0.938594, samples/s: 847.726 1613209942.0437636
train: epoch 158, iter 2500, loss: 1.752848, top_1: 0.818086, top_k: 0.938984, samples/s: 850.650 1613209972.13849
train: epoch 158, iter 2600, loss: 1.764992, top_1: 0.819922, top_k: 0.940859, samples/s: 846.645 1613210002.3754272
train: epoch 158, iter 2700, loss: 1.908618, top_1: 0.814492, top_k: 0.936055, samples/s: 847.749 1613210032.5730453
train: epoch 158, iter 2800, loss: 1.819712, top_1: 0.816641, top_k: 0.937930, samples/s: 844.809 1613210062.8757668
train: epoch 158, iter 2900, loss: 1.623814, top_1: 0.820898, top_k: 0.939258, samples/s: 845.521 1613210093.1529386
train: epoch 158, iter 3000, loss: 1.813390, top_1: 0.815078, top_k: 0.937930, samples/s: 844.483 1613210123.4673662
train: epoch 158, iter 3100, loss: 1.890959, top_1: 0.818789, top_k: 0.940391, samples/s: 847.544 1613210153.672298
train: epoch 158, iter 3200, loss: 1.661962, top_1: 0.821484, top_k: 0.939922, samples/s: 848.177 1613210183.854635
train: epoch 158, iter 3300, loss: 1.786001, top_1: 0.818750, top_k: 0.940117, samples/s: 846.593 1613210214.0935514
train: epoch 158, iter 3400, loss: 1.742350, top_1: 0.819023, top_k: 0.939414, samples/s: 846.675 1613210244.3294144
train: epoch 158, iter 3500, loss: 1.936052, top_1: 0.820039, top_k: 0.939258, samples/s: 848.006 1613210274.517867
train: epoch 158, iter 3600, loss: 1.705331, top_1: 0.818008, top_k: 0.941055, samples/s: 846.074 1613210304.7753255
train: epoch 158, iter 3700, loss: 1.756934, top_1: 0.815078, top_k: 0.935820, samples/s: 845.040 1613210335.0697718
train: epoch 158, iter 3800, loss: 1.873801, top_1: 0.818477, top_k: 0.937852, samples/s: 847.029 1613210365.293031
train: epoch 158, iter 3900, loss: 1.975820, top_1: 0.816328, top_k: 0.937383, samples/s: 846.588 1613210395.5319936
train: epoch 158, iter 4000, loss: 1.702886, top_1: 0.816445, top_k: 0.938047, samples/s: 846.747 1613210425.7654545
train: epoch 158, iter 4100, loss: 1.717309, top_1: 0.817305, top_k: 0.936836, samples/s: 845.511 1613210456.042967
train: epoch 158, iter 4200, loss: 1.700028, top_1: 0.821719, top_k: 0.939258, samples/s: 846.994 1613210486.267538
train: epoch 158, iter 4300, loss: 1.834583, top_1: 0.817383, top_k: 0.938867, samples/s: 849.386 1613210516.4069166
train: epoch 158, iter 4400, loss: 1.891116, top_1: 0.819609, top_k: 0.939102, samples/s: 845.873 1613210546.6715586
train: epoch 158, iter 4500, loss: 1.893553, top_1: 0.821797, top_k: 0.940586, samples/s: 845.967 1613210576.9327328
train: epoch 158, iter 4600, loss: 1.847149, top_1: 0.819023, top_k: 0.938750, samples/s: 843.662 1613210607.276666
train: epoch 158, iter 4700, loss: 1.855298, top_1: 0.822539, top_k: 0.940039, samples/s: 845.209 1613210637.5650487
train: epoch 158, iter 4800, loss: 1.738290, top_1: 0.819180, top_k: 0.939766, samples/s: 847.945 1613210667.7557352
train: epoch 158, iter 4900, loss: 1.787730, top_1: 0.821211, top_k: 0.941445, samples/s: 846.694 1613210697.9908895
train: epoch 158, iter 5000, loss: 1.824391, top_1: 0.819336, top_k: 0.941406, samples/s: 846.937 1613210728.2174814
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_158.
validation: epoch 158, iter 195, top_1: 0.779167, top_k: 0.939083, samples/s: 2444.878 1613210749.5428517
train: epoch 159, iter 100, loss: 1.748269, top_1: 0.822070, top_k: 0.941016, samples/s: 870.963 1613210799.2661865
train: epoch 159, iter 200, loss: 1.659872, top_1: 0.816367, top_k: 0.940000, samples/s: 866.226 1613210828.8196635
train: epoch 159, iter 300, loss: 1.823622, top_1: 0.822187, top_k: 0.939648, samples/s: 850.136 1613210858.9324737
train: epoch 159, iter 400, loss: 1.858561, top_1: 0.818242, top_k: 0.936914, samples/s: 847.369 1613210889.1435406
train: epoch 159, iter 500, loss: 1.804059, top_1: 0.816680, top_k: 0.940117, samples/s: 846.760 1613210919.376528
train: epoch 159, iter 600, loss: 1.815659, top_1: 0.813750, top_k: 0.940078, samples/s: 846.934 1613210949.6031208
train: epoch 159, iter 700, loss: 1.883812, top_1: 0.822383, top_k: 0.938789, samples/s: 842.996 1613210979.9710104
train: epoch 159, iter 800, loss: 1.722390, top_1: 0.822227, top_k: 0.940781, samples/s: 847.264 1613211010.1858728
train: epoch 159, iter 900, loss: 1.903641, top_1: 0.819609, top_k: 0.940352, samples/s: 841.368 1613211040.6125317
train: epoch 159, iter 1000, loss: 1.723683, top_1: 0.820078, top_k: 0.941250, samples/s: 849.619 1613211070.7436836
train: epoch 159, iter 1100, loss: 1.852054, top_1: 0.812969, top_k: 0.937383, samples/s: 846.949 1613211100.9698942
train: epoch 159, iter 1200, loss: 1.831896, top_1: 0.817539, top_k: 0.937148, samples/s: 844.740 1613211131.2750225
train: epoch 159, iter 1300, loss: 1.785707, top_1: 0.817539, top_k: 0.939922, samples/s: 849.808 1613211161.399519
train: epoch 159, iter 1400, loss: 1.826909, top_1: 0.822109, top_k: 0.939727, samples/s: 844.012 1613211191.7307897
train: epoch 159, iter 1500, loss: 1.787003, top_1: 0.818398, top_k: 0.941445, samples/s: 847.903 1613211221.9229443
train: epoch 159, iter 1600, loss: 1.829561, top_1: 0.821406, top_k: 0.938516, samples/s: 846.418 1613211252.1680636
train: epoch 159, iter 1700, loss: 1.628220, top_1: 0.820664, top_k: 0.937500, samples/s: 847.390 1613211282.378497
train: epoch 159, iter 1800, loss: 1.773536, top_1: 0.819336, top_k: 0.938438, samples/s: 846.102 1613211312.6349108
train: epoch 159, iter 1900, loss: 1.750185, top_1: 0.820234, top_k: 0.938242, samples/s: 849.958 1613211342.753956
train: epoch 159, iter 2000, loss: 1.744277, top_1: 0.816289, top_k: 0.940820, samples/s: 844.455 1613211373.069421
train: epoch 159, iter 2100, loss: 1.802142, top_1: 0.820664, top_k: 0.941328, samples/s: 847.168 1613211403.2877023
train: epoch 159, iter 2200, loss: 1.840736, top_1: 0.821484, top_k: 0.938750, samples/s: 846.939 1613211433.5142753
train: epoch 159, iter 2300, loss: 1.770017, top_1: 0.820625, top_k: 0.937813, samples/s: 849.521 1613211463.6488798
train: epoch 159, iter 2400, loss: 1.769886, top_1: 0.815664, top_k: 0.937070, samples/s: 844.593 1613211493.9594183
train: epoch 159, iter 2500, loss: 1.882745, top_1: 0.821758, top_k: 0.939414, samples/s: 844.632 1613211524.2683852
train: epoch 159, iter 2600, loss: 1.716539, top_1: 0.818516, top_k: 0.940625, samples/s: 847.920 1613211554.4599185
train: epoch 159, iter 2700, loss: 1.687017, top_1: 0.822500, top_k: 0.939023, samples/s: 848.123 1613211584.6441798
train: epoch 159, iter 2800, loss: 1.757799, top_1: 0.815156, top_k: 0.937734, samples/s: 846.441 1613211614.8885388
train: epoch 159, iter 2900, loss: 1.825156, top_1: 0.822227, top_k: 0.940586, samples/s: 848.552 1613211645.0575836
train: epoch 159, iter 3000, loss: 1.869858, top_1: 0.815820, top_k: 0.936016, samples/s: 845.849 1613211675.3229382
train: epoch 159, iter 3100, loss: 1.782853, top_1: 0.818594, top_k: 0.938945, samples/s: 846.034 1613211705.581802
train: epoch 159, iter 3200, loss: 1.772929, top_1: 0.819961, top_k: 0.938945, samples/s: 846.217 1613211735.8340418
train: epoch 159, iter 3300, loss: 1.847358, top_1: 0.821992, top_k: 0.937383, samples/s: 848.532 1613211766.0038612
train: epoch 159, iter 3400, loss: 1.887795, top_1: 0.821055, top_k: 0.939258, samples/s: 847.747 1613211796.2015042
train: epoch 159, iter 3500, loss: 1.699562, top_1: 0.823203, top_k: 0.941289, samples/s: 846.416 1613211826.4468355
train: epoch 159, iter 3600, loss: 1.880629, top_1: 0.817656, top_k: 0.937891, samples/s: 847.122 1613211856.6667042
train: epoch 159, iter 3700, loss: 1.722629, top_1: 0.816758, top_k: 0.939219, samples/s: 850.384 1613211886.770807
train: epoch 159, iter 3800, loss: 1.696549, top_1: 0.816680, top_k: 0.938750, samples/s: 846.444 1613211917.0149179
train: epoch 159, iter 3900, loss: 1.696187, top_1: 0.816523, top_k: 0.938203, samples/s: 846.806 1613211947.2462275
train: epoch 159, iter 4000, loss: 1.701546, top_1: 0.818164, top_k: 0.940195, samples/s: 848.951 1613211977.4010823
train: epoch 159, iter 4100, loss: 1.737950, top_1: 0.820312, top_k: 0.942305, samples/s: 849.137 1613212007.5492377
train: epoch 159, iter 4200, loss: 1.759612, top_1: 0.816875, top_k: 0.938789, samples/s: 848.856 1613212037.7075555
train: epoch 159, iter 4300, loss: 1.665297, top_1: 0.817852, top_k: 0.939453, samples/s: 846.282 1613212067.957501
train: epoch 159, iter 4400, loss: 1.854232, top_1: 0.817578, top_k: 0.937422, samples/s: 847.505 1613212098.1637876
train: epoch 159, iter 4500, loss: 1.676288, top_1: 0.819961, top_k: 0.939531, samples/s: 847.831 1613212128.3584917
train: epoch 159, iter 4600, loss: 1.702747, top_1: 0.821367, top_k: 0.940195, samples/s: 844.895 1613212158.6582148
train: epoch 159, iter 4700, loss: 1.671107, top_1: 0.815742, top_k: 0.937578, samples/s: 846.149 1613212188.912886
train: epoch 159, iter 4800, loss: 1.793374, top_1: 0.816250, top_k: 0.938477, samples/s: 847.875 1613212219.1060376
train: epoch 159, iter 4900, loss: 1.699935, top_1: 0.819336, top_k: 0.940000, samples/s: 847.662 1613212249.3066466
train: epoch 159, iter 5000, loss: 1.709102, top_1: 0.816562, top_k: 0.937617, samples/s: 848.064 1613212279.493103
Saving model to ./repvggB1g4/snapshots/model_save/snapshot_epoch_159.
validation: epoch 159, iter 195, top_1: 0.778746, top_k: 0.939203, samples/s: 2449.550 1613212300.7796302
