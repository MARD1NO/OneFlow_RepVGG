==================================================================
Running repvggB1: num_gpu_per_node = 4, num_nodes = 1.
==================================================================
dtype = float32
gpu_num_per_node = 4
num_nodes = 1
node_ips = ['192.168.1.13', '192.168.1.14']
ctrl_port = 50051
model = repvggB1
mixup = False
use_fp16 = None
use_xla = None
channel_last = False
pad_output = None
num_epochs = 160
model_load_dir = None
batch_size_per_device = 64
val_batch_size_per_device = 64
nccl_fusion_threshold_mb = 16
nccl_fusion_max_ops = 24
fuse_bn_relu = True
fuse_bn_add_relu = True
gpu_image_decoder = True
image_path = test_img/tiger.jpg
num_classes = 1000
num_examples = 1281167
num_val_examples = 50000
rgb_mean = [123.68, 116.779, 103.939]
rgb_std = [58.393, 57.12, 57.375]
image_shape = [3, 224, 224]
label_smoothing = 0.1
model_save_dir = ./repvggB1/snapshots/model_save/
log_dir = ./output
loss_print_every_n_iter = 100
image_size = 224
resize_shorter = 256
train_data_dir = /DATA/disk1/ImageNet/ofrecord/train
train_data_part_num = 256
val_data_dir = /DATA/disk1/ImageNet/ofrecord/validation
val_data_part_num = 256
optimizer = sgd
learning_rate = 0.1
wd = 3.0517578125e-05
momentum = 0.9
lr_decay = cosine
lr_decay_rate = 0.94
lr_decay_epochs = 2
warmup_epochs = 5
decay_rate = 0.9
epsilon = 1.0
gradient_clipping = 0.0
------------------------------------------------------------------
Time stamp: 2021-02-17-12:12:51
!!!!!===!!!! ./repvggB1/snapshots/model_save/
[1mWARNING: 'flow.train.CheckPoint' is deprecated. Please use the new API:[0m
flow.train.CheckPoint().save(path) => [1m[92mflow.checkpoint.save(path)[0m
flow.train.CheckPoint().load(path) => [1m[92mflow.load_variables(flow.checkpoint.get(path))[0m
flow.train.CheckPoint().init() is not needed any more.

Loading data from /DATA/disk1/ImageNet/ofrecord/train
No MixUp
Here is RepVGG B1
loss.shape (1,)
predictions:  (256, 1000)
Optimizer:  SGD
Loading data from /DATA/disk1/ImageNet/ofrecord/validation
Here is RepVGG B1
Saving model to ./repvggB1/snapshots/model_save/snapshot_initial_model.
Init model on demand.
train: epoch 0, iter 100, loss: 6.813658, top_1: 0.002969, top_k: 0.010664, samples/s: 695.825 1613535364.9914181
train: epoch 0, iter 200, loss: 6.742748, top_1: 0.005508, top_k: 0.019688, samples/s: 697.136 1613535401.7135353
train: epoch 0, iter 300, loss: 6.586526, top_1: 0.007734, top_k: 0.028086, samples/s: 702.137 1613535438.173142
train: epoch 0, iter 400, loss: 6.567481, top_1: 0.010313, top_k: 0.037930, samples/s: 699.951 1613535474.7472308
train: epoch 0, iter 500, loss: 6.314980, top_1: 0.012695, top_k: 0.048633, samples/s: 697.990 1613535511.4238503
train: epoch 0, iter 600, loss: 6.366217, top_1: 0.016055, top_k: 0.059141, samples/s: 700.608 1613535547.963647
train: epoch 0, iter 700, loss: 6.356454, top_1: 0.019375, top_k: 0.066250, samples/s: 699.035 1613535584.5855474
train: epoch 0, iter 800, loss: 6.217346, top_1: 0.022578, top_k: 0.077070, samples/s: 694.975 1613535621.4214666
train: epoch 0, iter 900, loss: 6.200869, top_1: 0.026953, top_k: 0.092266, samples/s: 692.234 1613535658.403226
train: epoch 0, iter 1000, loss: 5.911230, top_1: 0.029102, top_k: 0.102461, samples/s: 691.344 1613535695.4323783
train: epoch 0, iter 1100, loss: 6.021039, top_1: 0.035820, top_k: 0.111445, samples/s: 690.236 1613535732.5212471
train: epoch 0, iter 1200, loss: 5.910395, top_1: 0.039531, top_k: 0.121563, samples/s: 685.479 1613535769.867375
train: epoch 0, iter 1300, loss: 5.928655, top_1: 0.041797, top_k: 0.132344, samples/s: 688.124 1613535807.0698926
train: epoch 0, iter 1400, loss: 5.805922, top_1: 0.047344, top_k: 0.143789, samples/s: 688.540 1613535844.2500737
train: epoch 0, iter 1500, loss: 5.824656, top_1: 0.049219, top_k: 0.152344, samples/s: 689.722 1613535881.3663974
train: epoch 0, iter 1600, loss: 5.709649, top_1: 0.054805, top_k: 0.163320, samples/s: 685.465 1613535918.7134073
train: epoch 0, iter 1700, loss: 5.637671, top_1: 0.059687, top_k: 0.172891, samples/s: 686.905 1613535955.9819164
train: epoch 0, iter 1800, loss: 5.634551, top_1: 0.065117, top_k: 0.183086, samples/s: 685.605 1613535993.3213072
train: epoch 0, iter 1900, loss: 5.581543, top_1: 0.069492, top_k: 0.190547, samples/s: 686.349 1613536030.6199768
train: epoch 0, iter 2000, loss: 5.429009, top_1: 0.073633, top_k: 0.204766, samples/s: 686.082 1613536067.9332998
train: epoch 0, iter 2100, loss: 5.583772, top_1: 0.078750, top_k: 0.212266, samples/s: 685.611 1613536105.2723722
train: epoch 0, iter 2200, loss: 5.430038, top_1: 0.085000, top_k: 0.224961, samples/s: 683.313 1613536142.7367628
train: epoch 0, iter 2300, loss: 5.364809, top_1: 0.088945, top_k: 0.234687, samples/s: 685.479 1613536180.0829282
train: epoch 0, iter 2400, loss: 5.458021, top_1: 0.088359, top_k: 0.236797, samples/s: 684.039 1613536217.5077405
train: epoch 0, iter 2500, loss: 5.204662, top_1: 0.098125, top_k: 0.248594, samples/s: 689.057 1613536254.6599898
train: epoch 0, iter 2600, loss: 5.436420, top_1: 0.098398, top_k: 0.258164, samples/s: 685.938 1613536291.9810526
train: epoch 0, iter 2700, loss: 5.176053, top_1: 0.104961, top_k: 0.260391, samples/s: 683.416 1613536329.4399655
train: epoch 0, iter 2800, loss: 5.334340, top_1: 0.111914, top_k: 0.277187, samples/s: 684.523 1613536366.838327
train: epoch 0, iter 2900, loss: 5.289906, top_1: 0.118164, top_k: 0.286719, samples/s: 685.277 1613536404.1955152
train: epoch 0, iter 3000, loss: 5.279639, top_1: 0.118125, top_k: 0.291367, samples/s: 684.897 1613536441.5733025
train: epoch 0, iter 3100, loss: 5.047145, top_1: 0.125156, top_k: 0.300586, samples/s: 681.594 1613536479.132327
train: epoch 0, iter 3200, loss: 5.072096, top_1: 0.129023, top_k: 0.306602, samples/s: 686.199 1613536516.4392223
train: epoch 0, iter 3300, loss: 5.116064, top_1: 0.136758, top_k: 0.320234, samples/s: 684.376 1613536553.8455327
train: epoch 0, iter 3400, loss: 5.067853, top_1: 0.140742, top_k: 0.325352, samples/s: 684.337 1613536591.254092
train: epoch 0, iter 3500, loss: 5.012782, top_1: 0.140156, top_k: 0.329844, samples/s: 684.141 1613536628.6732674
train: epoch 0, iter 3600, loss: 5.123665, top_1: 0.143203, top_k: 0.328477, samples/s: 686.380 1613536665.9702568
train: epoch 0, iter 3700, loss: 4.935092, top_1: 0.150820, top_k: 0.346250, samples/s: 683.871 1613536703.404283
train: epoch 0, iter 3800, loss: 4.714399, top_1: 0.152109, top_k: 0.351406, samples/s: 681.730 1613536740.9557953
train: epoch 0, iter 3900, loss: 4.806409, top_1: 0.160430, top_k: 0.357422, samples/s: 685.083 1613536778.323982
train: epoch 0, iter 4000, loss: 4.810945, top_1: 0.165195, top_k: 0.365195, samples/s: 684.544 1613536815.7207553
train: epoch 0, iter 4100, loss: 4.882738, top_1: 0.169414, top_k: 0.376953, samples/s: 684.981 1613536853.0943034
train: epoch 0, iter 4200, loss: 4.719333, top_1: 0.171680, top_k: 0.380195, samples/s: 682.632 1613536890.5959017
train: epoch 0, iter 4300, loss: 4.727353, top_1: 0.175781, top_k: 0.383672, samples/s: 687.003 1613536927.8592553
train: epoch 0, iter 4400, loss: 4.553703, top_1: 0.178594, top_k: 0.389648, samples/s: 685.988 1613536965.177674
train: epoch 0, iter 4500, loss: 4.567660, top_1: 0.186289, top_k: 0.396719, samples/s: 684.616 1613537002.570858
train: epoch 0, iter 4600, loss: 4.530470, top_1: 0.185898, top_k: 0.401953, samples/s: 682.081 1613537040.1030514
train: epoch 0, iter 4700, loss: 4.541383, top_1: 0.191250, top_k: 0.410977, samples/s: 686.057 1613537077.4177206
train: epoch 0, iter 4800, loss: 4.454326, top_1: 0.194141, top_k: 0.408398, samples/s: 683.893 1613537114.8503854
train: epoch 0, iter 4900, loss: 4.546127, top_1: 0.201172, top_k: 0.417187, samples/s: 684.206 1613537152.266096
train: epoch 0, iter 5000, loss: 4.604246, top_1: 0.199492, top_k: 0.422500, samples/s: 681.330 1613537189.8396132
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_0.
validation: epoch 0, iter 195, top_1: 0.219050, top_k: 0.456070, samples/s: 2168.818 1613537213.9643757
train: epoch 1, iter 100, loss: 4.655204, top_1: 0.207109, top_k: 0.431875, samples/s: 699.996 1613537271.9938955
train: epoch 1, iter 200, loss: 4.422597, top_1: 0.212383, top_k: 0.440234, samples/s: 699.376 1613537308.5982723
train: epoch 1, iter 300, loss: 4.525722, top_1: 0.214609, top_k: 0.437031, samples/s: 681.675 1613537346.1526055
train: epoch 1, iter 400, loss: 4.413239, top_1: 0.221602, top_k: 0.450117, samples/s: 681.097 1613537383.7389097
train: epoch 1, iter 500, loss: 4.364058, top_1: 0.223555, top_k: 0.450820, samples/s: 683.491 1613537421.1936939
train: epoch 1, iter 600, loss: 4.372572, top_1: 0.226602, top_k: 0.452461, samples/s: 681.592 1613537458.752811
train: epoch 1, iter 700, loss: 4.449188, top_1: 0.230352, top_k: 0.456875, samples/s: 681.217 1613537496.3327112
train: epoch 1, iter 800, loss: 4.462657, top_1: 0.230313, top_k: 0.458789, samples/s: 682.735 1613537533.828894
train: epoch 1, iter 900, loss: 4.439210, top_1: 0.233750, top_k: 0.461445, samples/s: 682.702 1613537571.3269067
train: epoch 1, iter 1000, loss: 4.363678, top_1: 0.234648, top_k: 0.462656, samples/s: 683.229 1613537608.7960882
train: epoch 1, iter 1100, loss: 4.362631, top_1: 0.239180, top_k: 0.474258, samples/s: 683.087 1613537646.2730079
train: epoch 1, iter 1200, loss: 4.303268, top_1: 0.236172, top_k: 0.472852, samples/s: 682.241 1613537683.7964425
train: epoch 1, iter 1300, loss: 4.330834, top_1: 0.246562, top_k: 0.479609, samples/s: 682.164 1613537721.3240573
train: epoch 1, iter 1400, loss: 4.462309, top_1: 0.243711, top_k: 0.482461, samples/s: 683.884 1613537758.7572596
train: epoch 1, iter 1500, loss: 4.414381, top_1: 0.250703, top_k: 0.489961, samples/s: 681.932 1613537796.2976635
train: epoch 1, iter 1600, loss: 4.313255, top_1: 0.253281, top_k: 0.490352, samples/s: 683.463 1613537833.7539651
train: epoch 1, iter 1700, loss: 4.269283, top_1: 0.258359, top_k: 0.496250, samples/s: 684.031 1613537871.1793082
train: epoch 1, iter 1800, loss: 4.253704, top_1: 0.257305, top_k: 0.493672, samples/s: 685.250 1613537908.537858
train: epoch 1, iter 1900, loss: 4.198831, top_1: 0.260781, top_k: 0.498984, samples/s: 681.793 1613537946.0858922
train: epoch 1, iter 2000, loss: 4.122939, top_1: 0.261719, top_k: 0.501680, samples/s: 685.229 1613537983.4456525
train: epoch 1, iter 2100, loss: 4.235408, top_1: 0.261445, top_k: 0.504023, samples/s: 680.816 1613538021.0476148
train: epoch 1, iter 2200, loss: 4.092337, top_1: 0.271562, top_k: 0.507656, samples/s: 683.548 1613538058.4993856
train: epoch 1, iter 2300, loss: 4.206983, top_1: 0.269141, top_k: 0.513437, samples/s: 686.097 1613538095.8117425
train: epoch 1, iter 2400, loss: 4.108094, top_1: 0.273398, top_k: 0.514141, samples/s: 684.011 1613538133.238117
train: epoch 1, iter 2500, loss: 4.135136, top_1: 0.274180, top_k: 0.518633, samples/s: 682.288 1613538170.758954
train: epoch 1, iter 2600, loss: 4.203343, top_1: 0.282773, top_k: 0.520469, samples/s: 682.552 1613538208.2652485
train: epoch 1, iter 2700, loss: 4.086798, top_1: 0.276016, top_k: 0.520664, samples/s: 684.291 1613538245.676124
train: epoch 1, iter 2800, loss: 4.047688, top_1: 0.280313, top_k: 0.526563, samples/s: 682.893 1613538283.1637537
train: epoch 1, iter 2900, loss: 4.175685, top_1: 0.286836, top_k: 0.535781, samples/s: 683.864 1613538320.5981343
train: epoch 1, iter 3000, loss: 4.093788, top_1: 0.286211, top_k: 0.527891, samples/s: 681.227 1613538358.1773107
train: epoch 1, iter 3100, loss: 4.319438, top_1: 0.291875, top_k: 0.537188, samples/s: 682.984 1613538395.6599452
train: epoch 1, iter 3200, loss: 4.128177, top_1: 0.290977, top_k: 0.529180, samples/s: 684.758 1613538433.0454135
train: epoch 1, iter 3300, loss: 3.960515, top_1: 0.289531, top_k: 0.533047, samples/s: 681.062 1613538470.633763
train: epoch 1, iter 3400, loss: 3.938958, top_1: 0.294727, top_k: 0.545312, samples/s: 686.097 1613538507.9463706
train: epoch 1, iter 3500, loss: 4.092996, top_1: 0.295195, top_k: 0.541484, samples/s: 684.173 1613538545.3637533
train: epoch 1, iter 3600, loss: 3.955294, top_1: 0.300195, top_k: 0.547773, samples/s: 681.436 1613538582.93154
train: epoch 1, iter 3700, loss: 4.086228, top_1: 0.299609, top_k: 0.543672, samples/s: 681.270 1613538620.5084205
train: epoch 1, iter 3800, loss: 4.245432, top_1: 0.304180, top_k: 0.551562, samples/s: 682.325 1613538658.027135
train: epoch 1, iter 3900, loss: 4.003064, top_1: 0.302656, top_k: 0.551992, samples/s: 684.203 1613538695.4428961
train: epoch 1, iter 4000, loss: 3.966173, top_1: 0.306719, top_k: 0.553867, samples/s: 684.803 1613538732.8260548
train: epoch 1, iter 4100, loss: 4.063523, top_1: 0.303984, top_k: 0.549063, samples/s: 683.437 1613538770.2837102
train: epoch 1, iter 4200, loss: 3.872010, top_1: 0.315547, top_k: 0.555547, samples/s: 681.472 1613538807.849482
train: epoch 1, iter 4300, loss: 4.138319, top_1: 0.312109, top_k: 0.555391, samples/s: 682.583 1613538845.3540647
train: epoch 1, iter 4400, loss: 4.015574, top_1: 0.311133, top_k: 0.561641, samples/s: 681.482 1613538882.9192352
train: epoch 1, iter 4500, loss: 4.006192, top_1: 0.313398, top_k: 0.563438, samples/s: 682.700 1613538920.4174912
train: epoch 1, iter 4600, loss: 3.949256, top_1: 0.318203, top_k: 0.568281, samples/s: 681.666 1613538957.9723907
train: epoch 1, iter 4700, loss: 3.904871, top_1: 0.317695, top_k: 0.565625, samples/s: 684.110 1613538995.3933322
train: epoch 1, iter 4800, loss: 4.077962, top_1: 0.317656, top_k: 0.566836, samples/s: 682.013 1613539032.9292848
train: epoch 1, iter 4900, loss: 3.804928, top_1: 0.317734, top_k: 0.568516, samples/s: 682.310 1613539070.4489582
train: epoch 1, iter 5000, loss: 3.820758, top_1: 0.326406, top_k: 0.577305, samples/s: 683.478 1613539107.9044302
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_1.
validation: epoch 1, iter 195, top_1: 0.361418, top_k: 0.631851, samples/s: 2189.318 1613539131.8353393
train: epoch 2, iter 100, loss: 3.959580, top_1: 0.337891, top_k: 0.588711, samples/s: 702.640 1613539190.702972
train: epoch 2, iter 200, loss: 3.728995, top_1: 0.332344, top_k: 0.583164, samples/s: 699.994 1613539227.2746754
train: epoch 2, iter 300, loss: 3.817211, top_1: 0.338086, top_k: 0.584922, samples/s: 683.050 1613539264.7535787
train: epoch 2, iter 400, loss: 3.799328, top_1: 0.338164, top_k: 0.585625, samples/s: 681.039 1613539302.343183
train: epoch 2, iter 500, loss: 4.090182, top_1: 0.333906, top_k: 0.586172, samples/s: 681.399 1613539339.9130485
train: epoch 2, iter 600, loss: 3.919304, top_1: 0.337305, top_k: 0.586484, samples/s: 683.344 1613539377.3759162
train: epoch 2, iter 700, loss: 3.677149, top_1: 0.341914, top_k: 0.592266, samples/s: 684.543 1613539414.773153
train: epoch 2, iter 800, loss: 4.147630, top_1: 0.334922, top_k: 0.585313, samples/s: 680.821 1613539452.374794
train: epoch 2, iter 900, loss: 3.661112, top_1: 0.339844, top_k: 0.590352, samples/s: 681.544 1613539489.9365811
train: epoch 2, iter 1000, loss: 3.869010, top_1: 0.342617, top_k: 0.597734, samples/s: 682.307 1613539527.4563375
train: epoch 2, iter 1100, loss: 3.936318, top_1: 0.340586, top_k: 0.590703, samples/s: 686.398 1613539564.7523863
train: epoch 2, iter 1200, loss: 3.770881, top_1: 0.344570, top_k: 0.595547, samples/s: 683.036 1613539602.2321332
train: epoch 2, iter 1300, loss: 3.732175, top_1: 0.345977, top_k: 0.596719, samples/s: 681.629 1613539639.7891953
train: epoch 2, iter 1400, loss: 3.799047, top_1: 0.348359, top_k: 0.600000, samples/s: 684.203 1613539677.2049255
train: epoch 2, iter 1500, loss: 3.771707, top_1: 0.353320, top_k: 0.602461, samples/s: 683.082 1613539714.6821604
train: epoch 2, iter 1600, loss: 3.890255, top_1: 0.346445, top_k: 0.600078, samples/s: 682.959 1613539752.1660972
train: epoch 2, iter 1700, loss: 3.771452, top_1: 0.350195, top_k: 0.601641, samples/s: 682.125 1613539789.6958175
train: epoch 2, iter 1800, loss: 3.908271, top_1: 0.349297, top_k: 0.601484, samples/s: 684.432 1613539827.0991745
train: epoch 2, iter 1900, loss: 3.744761, top_1: 0.347383, top_k: 0.598320, samples/s: 679.810 1613539864.7567952
train: epoch 2, iter 2000, loss: 3.889221, top_1: 0.352305, top_k: 0.606172, samples/s: 684.162 1613539902.1748464
train: epoch 2, iter 2100, loss: 4.032036, top_1: 0.354687, top_k: 0.604609, samples/s: 681.744 1613539939.7256098
train: epoch 2, iter 2200, loss: 3.906156, top_1: 0.356172, top_k: 0.611914, samples/s: 684.840 1613539977.1065683
train: epoch 2, iter 2300, loss: 3.669851, top_1: 0.357305, top_k: 0.613086, samples/s: 681.246 1613540014.684846
train: epoch 2, iter 2400, loss: 3.582935, top_1: 0.360156, top_k: 0.611719, samples/s: 685.212 1613540052.0455022
train: epoch 2, iter 2500, loss: 3.757800, top_1: 0.360117, top_k: 0.607109, samples/s: 680.627 1613540089.6579475
train: epoch 2, iter 2600, loss: 3.764310, top_1: 0.360703, top_k: 0.615156, samples/s: 683.960 1613540127.086926
train: epoch 2, iter 2700, loss: 3.503793, top_1: 0.362734, top_k: 0.609375, samples/s: 682.252 1613540164.6098378
train: epoch 2, iter 2800, loss: 4.021161, top_1: 0.369141, top_k: 0.618828, samples/s: 684.120 1613540202.0301812
train: epoch 2, iter 2900, loss: 3.529332, top_1: 0.365977, top_k: 0.617305, samples/s: 683.729 1613540239.4718351
train: epoch 2, iter 3000, loss: 3.631987, top_1: 0.359023, top_k: 0.614023, samples/s: 683.411 1613540276.930962
train: epoch 2, iter 3100, loss: 3.562247, top_1: 0.367031, top_k: 0.622734, samples/s: 682.191 1613540314.4572368
train: epoch 2, iter 3200, loss: 3.600580, top_1: 0.371328, top_k: 0.625039, samples/s: 682.404 1613540351.9715807
train: epoch 2, iter 3300, loss: 3.741383, top_1: 0.370000, top_k: 0.623945, samples/s: 685.408 1613540389.321586
train: epoch 2, iter 3400, loss: 3.552907, top_1: 0.372852, top_k: 0.627031, samples/s: 682.908 1613540426.8084536
train: epoch 2, iter 3500, loss: 3.684683, top_1: 0.369102, top_k: 0.621758, samples/s: 681.174 1613540464.3906164
train: epoch 2, iter 3600, loss: 3.552288, top_1: 0.371250, top_k: 0.624961, samples/s: 685.081 1613540501.7584302
train: epoch 2, iter 3700, loss: 3.764977, top_1: 0.377461, top_k: 0.630938, samples/s: 682.953 1613540539.24266
train: epoch 2, iter 3800, loss: 3.643316, top_1: 0.368711, top_k: 0.624609, samples/s: 683.020 1613540576.723272
train: epoch 2, iter 3900, loss: 3.717861, top_1: 0.369297, top_k: 0.624922, samples/s: 682.766 1613540614.2179284
train: epoch 2, iter 4000, loss: 3.806442, top_1: 0.377617, top_k: 0.628867, samples/s: 681.360 1613540651.7898207
train: epoch 2, iter 4100, loss: 3.758187, top_1: 0.375000, top_k: 0.628398, samples/s: 682.779 1613540689.2836547
train: epoch 2, iter 4200, loss: 3.625199, top_1: 0.374102, top_k: 0.625039, samples/s: 682.282 1613540726.804774
train: epoch 2, iter 4300, loss: 3.428622, top_1: 0.380742, top_k: 0.630391, samples/s: 681.984 1613540764.3423123
train: epoch 2, iter 4400, loss: 3.642895, top_1: 0.377266, top_k: 0.629414, samples/s: 683.283 1613540801.8084385
train: epoch 2, iter 4500, loss: 3.695742, top_1: 0.377148, top_k: 0.626367, samples/s: 683.799 1613540839.246349
train: epoch 2, iter 4600, loss: 3.669222, top_1: 0.382109, top_k: 0.638125, samples/s: 681.269 1613540876.823385
train: epoch 2, iter 4700, loss: 3.469697, top_1: 0.378047, top_k: 0.629141, samples/s: 684.714 1613540914.2111413
train: epoch 2, iter 4800, loss: 3.508138, top_1: 0.385937, top_k: 0.638477, samples/s: 681.242 1613540951.789633
train: epoch 2, iter 4900, loss: 3.539716, top_1: 0.383672, top_k: 0.635156, samples/s: 683.622 1613540989.237179
train: epoch 2, iter 5000, loss: 3.418746, top_1: 0.389180, top_k: 0.642852, samples/s: 680.682 1613541026.846487
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_2.
validation: epoch 2, iter 195, top_1: 0.425601, top_k: 0.689984, samples/s: 2186.129 1613541050.8206718
train: epoch 3, iter 100, loss: 3.738028, top_1: 0.400273, top_k: 0.649766, samples/s: 702.617 1613541108.7110326
train: epoch 3, iter 200, loss: 3.820027, top_1: 0.393477, top_k: 0.644102, samples/s: 699.335 1613541145.317231
train: epoch 3, iter 300, loss: 3.386626, top_1: 0.394570, top_k: 0.649141, samples/s: 681.062 1613541182.9056742
train: epoch 3, iter 400, loss: 3.519192, top_1: 0.400352, top_k: 0.650625, samples/s: 680.291 1613541220.5365245
train: epoch 3, iter 500, loss: 3.650835, top_1: 0.398203, top_k: 0.649492, samples/s: 681.576 1613541258.0964916
train: epoch 3, iter 600, loss: 3.326751, top_1: 0.391172, top_k: 0.647070, samples/s: 681.106 1613541295.6824427
train: epoch 3, iter 700, loss: 3.532309, top_1: 0.396953, top_k: 0.647422, samples/s: 684.194 1613541333.0987778
train: epoch 3, iter 800, loss: 3.698103, top_1: 0.396914, top_k: 0.652148, samples/s: 684.475 1613541370.4996946
train: epoch 3, iter 900, loss: 3.420424, top_1: 0.389141, top_k: 0.646133, samples/s: 680.048 1613541408.1441443
train: epoch 3, iter 1000, loss: 3.531903, top_1: 0.395586, top_k: 0.647734, samples/s: 681.322 1613541445.7181616
train: epoch 3, iter 1100, loss: 3.735787, top_1: 0.399492, top_k: 0.650078, samples/s: 680.433 1613541483.3412917
train: epoch 3, iter 1200, loss: 3.732471, top_1: 0.396211, top_k: 0.647734, samples/s: 682.648 1613541520.8422806
train: epoch 3, iter 1300, loss: 3.570930, top_1: 0.393281, top_k: 0.645781, samples/s: 682.853 1613541558.331968
train: epoch 3, iter 1400, loss: 3.747754, top_1: 0.396094, top_k: 0.648594, samples/s: 680.420 1613541595.9557965
train: epoch 3, iter 1500, loss: 3.476838, top_1: 0.393750, top_k: 0.643008, samples/s: 681.723 1613541633.5077264
train: epoch 3, iter 1600, loss: 3.599349, top_1: 0.395977, top_k: 0.653203, samples/s: 685.267 1613541670.8653657
train: epoch 3, iter 1700, loss: 3.706110, top_1: 0.399961, top_k: 0.652227, samples/s: 683.268 1613541708.332397
train: epoch 3, iter 1800, loss: 3.472047, top_1: 0.401445, top_k: 0.654102, samples/s: 681.849 1613541745.8774693
train: epoch 3, iter 1900, loss: 3.421251, top_1: 0.402695, top_k: 0.651992, samples/s: 684.546 1613541783.274437
train: epoch 3, iter 2000, loss: 3.520035, top_1: 0.405469, top_k: 0.656289, samples/s: 682.011 1613541820.8105974
train: epoch 3, iter 2100, loss: 3.652025, top_1: 0.400352, top_k: 0.653242, samples/s: 682.883 1613541858.2992487
train: epoch 3, iter 2200, loss: 3.547415, top_1: 0.406367, top_k: 0.652422, samples/s: 681.500 1613541895.8629367
train: epoch 3, iter 2300, loss: 3.522800, top_1: 0.408906, top_k: 0.662109, samples/s: 683.419 1613541933.3216784
train: epoch 3, iter 2400, loss: 3.665465, top_1: 0.406836, top_k: 0.652617, samples/s: 684.794 1613541970.7051992
train: epoch 3, iter 2500, loss: 3.583183, top_1: 0.404453, top_k: 0.654102, samples/s: 684.370 1613542008.111771
train: epoch 3, iter 2600, loss: 3.484433, top_1: 0.407187, top_k: 0.653320, samples/s: 683.448 1613542045.569281
train: epoch 3, iter 2700, loss: 3.501567, top_1: 0.408555, top_k: 0.658438, samples/s: 683.648 1613542083.015078
train: epoch 3, iter 2800, loss: 3.390695, top_1: 0.408086, top_k: 0.659023, samples/s: 684.657 1613542120.4060867
train: epoch 3, iter 2900, loss: 3.536939, top_1: 0.411484, top_k: 0.663359, samples/s: 681.950 1613542157.9454393
train: epoch 3, iter 3000, loss: 3.430816, top_1: 0.406875, top_k: 0.658789, samples/s: 684.515 1613542195.344254
train: epoch 3, iter 3100, loss: 3.474605, top_1: 0.402930, top_k: 0.658984, samples/s: 681.543 1613542232.9060593
train: epoch 3, iter 3200, loss: 3.502716, top_1: 0.408906, top_k: 0.660430, samples/s: 683.740 1613542270.3471835
train: epoch 3, iter 3300, loss: 3.611525, top_1: 0.414023, top_k: 0.660117, samples/s: 684.119 1613542307.7675972
train: epoch 3, iter 3400, loss: 3.682029, top_1: 0.404961, top_k: 0.653906, samples/s: 684.916 1613542345.144432
train: epoch 3, iter 3500, loss: 3.358969, top_1: 0.409219, top_k: 0.659492, samples/s: 681.078 1613542382.7318792
train: epoch 3, iter 3600, loss: 3.644902, top_1: 0.408828, top_k: 0.663906, samples/s: 687.762 1613542419.9541264
train: epoch 3, iter 3700, loss: 3.687276, top_1: 0.406836, top_k: 0.654180, samples/s: 679.110 1613542457.6504743
train: epoch 3, iter 3800, loss: 3.497619, top_1: 0.409844, top_k: 0.663594, samples/s: 682.678 1613542495.1499186
train: epoch 3, iter 3900, loss: 3.408993, top_1: 0.410820, top_k: 0.662383, samples/s: 682.324 1613542532.6687095
train: epoch 3, iter 4000, loss: 3.424559, top_1: 0.405898, top_k: 0.657305, samples/s: 684.669 1613542570.0589554
train: epoch 3, iter 4100, loss: 3.723371, top_1: 0.408203, top_k: 0.657617, samples/s: 681.451 1613542607.6259081
train: epoch 3, iter 4200, loss: 3.586640, top_1: 0.411094, top_k: 0.660898, samples/s: 681.616 1613542645.183664
train: epoch 3, iter 4300, loss: 3.513762, top_1: 0.415234, top_k: 0.665977, samples/s: 681.360 1613542682.7555351
train: epoch 3, iter 4400, loss: 3.580646, top_1: 0.412656, top_k: 0.669141, samples/s: 683.874 1613542720.1893895
train: epoch 3, iter 4500, loss: 3.364626, top_1: 0.419102, top_k: 0.669102, samples/s: 683.429 1613542757.6475694
train: epoch 3, iter 4600, loss: 3.405896, top_1: 0.418633, top_k: 0.669844, samples/s: 684.488 1613542795.0477974
train: epoch 3, iter 4700, loss: 3.610404, top_1: 0.417187, top_k: 0.668398, samples/s: 682.177 1613542832.5747557
train: epoch 3, iter 4800, loss: 3.699697, top_1: 0.416836, top_k: 0.674219, samples/s: 685.227 1613542869.9346554
train: epoch 3, iter 4900, loss: 3.322276, top_1: 0.419297, top_k: 0.669414, samples/s: 681.999 1613542907.4719582
train: epoch 3, iter 5000, loss: 3.492391, top_1: 0.413203, top_k: 0.667813, samples/s: 686.639 1613542944.7543344
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_3.
validation: epoch 3, iter 195, top_1: 0.468670, top_k: 0.731891, samples/s: 2152.301 1613542969.073546
train: epoch 4, iter 100, loss: 3.393832, top_1: 0.431211, top_k: 0.682187, samples/s: 702.019 1613543026.7565775
train: epoch 4, iter 200, loss: 3.422823, top_1: 0.424258, top_k: 0.678516, samples/s: 699.530 1613543063.3523338
train: epoch 4, iter 300, loss: 3.347799, top_1: 0.425195, top_k: 0.675117, samples/s: 681.669 1613543100.9072728
train: epoch 4, iter 400, loss: 3.462601, top_1: 0.422969, top_k: 0.677031, samples/s: 682.887 1613543138.3951075
train: epoch 4, iter 500, loss: 3.308366, top_1: 0.429375, top_k: 0.681641, samples/s: 683.437 1613543175.8528674
train: epoch 4, iter 600, loss: 3.530288, top_1: 0.428047, top_k: 0.678320, samples/s: 681.919 1613543213.3938978
train: epoch 4, iter 700, loss: 3.462204, top_1: 0.429570, top_k: 0.679453, samples/s: 682.307 1613543250.9137628
train: epoch 4, iter 800, loss: 3.337046, top_1: 0.421211, top_k: 0.675703, samples/s: 683.048 1613543288.3928602
train: epoch 4, iter 900, loss: 3.442391, top_1: 0.422031, top_k: 0.675898, samples/s: 681.530 1613543325.9553456
train: epoch 4, iter 1000, loss: 3.523779, top_1: 0.427344, top_k: 0.677227, samples/s: 682.913 1613543363.4418042
train: epoch 4, iter 1100, loss: 3.348823, top_1: 0.430156, top_k: 0.680859, samples/s: 682.577 1613543400.9467146
train: epoch 4, iter 1200, loss: 3.467896, top_1: 0.425703, top_k: 0.674297, samples/s: 683.156 1613543438.4199283
train: epoch 4, iter 1300, loss: 3.401894, top_1: 0.423477, top_k: 0.671055, samples/s: 684.648 1613543475.8113525
train: epoch 4, iter 1400, loss: 3.230999, top_1: 0.434063, top_k: 0.680508, samples/s: 683.312 1613543513.2760007
train: epoch 4, iter 1500, loss: 3.378076, top_1: 0.428984, top_k: 0.678750, samples/s: 681.603 1613543550.8344014
train: epoch 4, iter 1600, loss: 3.520796, top_1: 0.426484, top_k: 0.677070, samples/s: 682.870 1613543588.3233497
train: epoch 4, iter 1700, loss: 3.462187, top_1: 0.429766, top_k: 0.676602, samples/s: 685.239 1613543625.682583
train: epoch 4, iter 1800, loss: 3.499289, top_1: 0.423594, top_k: 0.677031, samples/s: 681.382 1613543663.253267
train: epoch 4, iter 1900, loss: 3.525269, top_1: 0.428008, top_k: 0.679063, samples/s: 682.823 1613543700.7446167
train: epoch 4, iter 2000, loss: 3.237456, top_1: 0.433086, top_k: 0.685430, samples/s: 681.874 1613543738.2882538
train: epoch 4, iter 2100, loss: 3.194931, top_1: 0.434102, top_k: 0.679961, samples/s: 684.132 1613543775.7078223
train: epoch 4, iter 2200, loss: 3.491371, top_1: 0.424570, top_k: 0.673828, samples/s: 681.366 1613543813.2794795
train: epoch 4, iter 2300, loss: 3.297678, top_1: 0.429219, top_k: 0.681953, samples/s: 685.470 1613543850.6260755
train: epoch 4, iter 2400, loss: 3.536628, top_1: 0.431875, top_k: 0.677852, samples/s: 681.060 1613543888.2145243
train: epoch 4, iter 2500, loss: 3.464052, top_1: 0.428750, top_k: 0.682187, samples/s: 684.437 1613543925.6175146
train: epoch 4, iter 2600, loss: 3.289328, top_1: 0.429688, top_k: 0.677539, samples/s: 682.769 1613543963.111879
train: epoch 4, iter 2700, loss: 3.426977, top_1: 0.430781, top_k: 0.680156, samples/s: 681.869 1613544000.6558888
train: epoch 4, iter 2800, loss: 3.301613, top_1: 0.431719, top_k: 0.684141, samples/s: 683.195 1613544038.126813
train: epoch 4, iter 2900, loss: 3.497885, top_1: 0.424453, top_k: 0.675937, samples/s: 685.183 1613544075.4890826
train: epoch 4, iter 3000, loss: 3.209334, top_1: 0.429180, top_k: 0.678711, samples/s: 682.259 1613544113.01156
train: epoch 4, iter 3100, loss: 3.228367, top_1: 0.435820, top_k: 0.685508, samples/s: 684.969 1613544150.3855798
train: epoch 4, iter 3200, loss: 3.243639, top_1: 0.441172, top_k: 0.688047, samples/s: 683.287 1613544187.8515234
train: epoch 4, iter 3300, loss: 3.541349, top_1: 0.434375, top_k: 0.682813, samples/s: 683.439 1613544225.309104
train: epoch 4, iter 3400, loss: 3.519194, top_1: 0.433789, top_k: 0.686523, samples/s: 683.268 1613544262.776093
train: epoch 4, iter 3500, loss: 3.422060, top_1: 0.432734, top_k: 0.683945, samples/s: 682.843 1613544300.2663314
train: epoch 4, iter 3600, loss: 3.321081, top_1: 0.436563, top_k: 0.683984, samples/s: 684.742 1613544337.6527095
train: epoch 4, iter 3700, loss: 3.512722, top_1: 0.441563, top_k: 0.686953, samples/s: 685.508 1613544374.997291
train: epoch 4, iter 3800, loss: 3.285187, top_1: 0.436055, top_k: 0.682969, samples/s: 684.178 1613544412.4145238
train: epoch 4, iter 3900, loss: 3.436809, top_1: 0.429648, top_k: 0.679219, samples/s: 684.254 1613544449.8275285
train: epoch 4, iter 4000, loss: 3.353162, top_1: 0.433555, top_k: 0.684688, samples/s: 683.992 1613544487.254892
train: epoch 4, iter 4100, loss: 3.210339, top_1: 0.432461, top_k: 0.684609, samples/s: 681.940 1613544524.7947564
train: epoch 4, iter 4200, loss: 3.326786, top_1: 0.437812, top_k: 0.685117, samples/s: 681.142 1613544562.3787131
train: epoch 4, iter 4300, loss: 3.502234, top_1: 0.438203, top_k: 0.683477, samples/s: 683.254 1613544599.8464446
train: epoch 4, iter 4400, loss: 3.341297, top_1: 0.439297, top_k: 0.687539, samples/s: 682.148 1613544637.3750386
train: epoch 4, iter 4500, loss: 3.239516, top_1: 0.435430, top_k: 0.681719, samples/s: 682.920 1613544674.8610935
train: epoch 4, iter 4600, loss: 3.101115, top_1: 0.437031, top_k: 0.687617, samples/s: 681.719 1613544712.4132488
train: epoch 4, iter 4700, loss: 3.466356, top_1: 0.436641, top_k: 0.688359, samples/s: 683.628 1613544749.860432
train: epoch 4, iter 4800, loss: 3.395598, top_1: 0.436719, top_k: 0.685937, samples/s: 683.344 1613544787.323314
train: epoch 4, iter 4900, loss: 3.286625, top_1: 0.436602, top_k: 0.686562, samples/s: 683.825 1613544824.7597916
train: epoch 4, iter 5000, loss: 3.426936, top_1: 0.438477, top_k: 0.688320, samples/s: 684.427 1613544862.1632357
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_4.
validation: epoch 4, iter 195, top_1: 0.487420, top_k: 0.747937, samples/s: 2157.027 1613544886.437609
train: epoch 5, iter 100, loss: 3.458458, top_1: 0.448359, top_k: 0.692930, samples/s: 702.903 1613544944.1846778
train: epoch 5, iter 200, loss: 3.168909, top_1: 0.440117, top_k: 0.690430, samples/s: 699.842 1613544980.7647731
train: epoch 5, iter 300, loss: 3.278540, top_1: 0.444414, top_k: 0.693984, samples/s: 683.366 1613545018.2259617
train: epoch 5, iter 400, loss: 3.346046, top_1: 0.443828, top_k: 0.690937, samples/s: 679.541 1613545055.8988478
train: epoch 5, iter 500, loss: 3.289380, top_1: 0.450156, top_k: 0.699492, samples/s: 680.701 1613545093.506658
train: epoch 5, iter 600, loss: 3.329165, top_1: 0.448516, top_k: 0.692187, samples/s: 682.351 1613545131.0240433
train: epoch 5, iter 700, loss: 3.455990, top_1: 0.449297, top_k: 0.696680, samples/s: 682.534 1613545168.5312393
train: epoch 5, iter 800, loss: 3.366635, top_1: 0.446367, top_k: 0.691875, samples/s: 681.165 1613545206.1139643
train: epoch 5, iter 900, loss: 3.361337, top_1: 0.445937, top_k: 0.693750, samples/s: 682.054 1613545243.647659
train: epoch 5, iter 1000, loss: 3.278273, top_1: 0.447539, top_k: 0.695078, samples/s: 682.547 1613545281.1542473
train: epoch 5, iter 1100, loss: 3.436656, top_1: 0.445547, top_k: 0.690117, samples/s: 682.975 1613545318.63732
train: epoch 5, iter 1200, loss: 3.165062, top_1: 0.448125, top_k: 0.698320, samples/s: 680.131 1613545356.2771866
train: epoch 5, iter 1300, loss: 3.394541, top_1: 0.449883, top_k: 0.698555, samples/s: 684.303 1613545393.6874306
train: epoch 5, iter 1400, loss: 3.339416, top_1: 0.455000, top_k: 0.704141, samples/s: 684.948 1613545431.062611
train: epoch 5, iter 1500, loss: 3.504203, top_1: 0.447305, top_k: 0.697539, samples/s: 681.574 1613545468.6227922
train: epoch 5, iter 1600, loss: 3.322175, top_1: 0.443711, top_k: 0.695625, samples/s: 685.079 1613545505.990643
train: epoch 5, iter 1700, loss: 3.248302, top_1: 0.447109, top_k: 0.698125, samples/s: 684.421 1613545543.394526
train: epoch 5, iter 1800, loss: 3.232319, top_1: 0.457930, top_k: 0.702305, samples/s: 682.952 1613545580.878895
train: epoch 5, iter 1900, loss: 3.344860, top_1: 0.448008, top_k: 0.696328, samples/s: 683.101 1613545618.3551326
train: epoch 5, iter 2000, loss: 3.252457, top_1: 0.449297, top_k: 0.696328, samples/s: 684.952 1613545655.7298963
train: epoch 5, iter 2100, loss: 3.433204, top_1: 0.446953, top_k: 0.696367, samples/s: 685.293 1613545693.0862448
train: epoch 5, iter 2200, loss: 3.270578, top_1: 0.450508, top_k: 0.701523, samples/s: 683.375 1613545730.5472896
train: epoch 5, iter 2300, loss: 3.526647, top_1: 0.447148, top_k: 0.693594, samples/s: 685.643 1613545767.8845763
train: epoch 5, iter 2400, loss: 3.416997, top_1: 0.449688, top_k: 0.698125, samples/s: 682.246 1613545805.4076276
train: epoch 5, iter 2500, loss: 3.575506, top_1: 0.455391, top_k: 0.705625, samples/s: 683.678 1613545842.8522172
train: epoch 5, iter 2600, loss: 3.099284, top_1: 0.449414, top_k: 0.699258, samples/s: 683.115 1613545880.327519
train: epoch 5, iter 2700, loss: 3.477482, top_1: 0.451914, top_k: 0.700313, samples/s: 685.136 1613545917.6925032
train: epoch 5, iter 2800, loss: 3.218957, top_1: 0.448125, top_k: 0.699375, samples/s: 682.417 1613545955.206132
train: epoch 5, iter 2900, loss: 3.196563, top_1: 0.450078, top_k: 0.703789, samples/s: 685.258 1613545992.5644002
train: epoch 5, iter 3000, loss: 3.298089, top_1: 0.456914, top_k: 0.699688, samples/s: 682.698 1613546030.0627046
train: epoch 5, iter 3100, loss: 3.459550, top_1: 0.450273, top_k: 0.699414, samples/s: 686.545 1613546067.351266
train: epoch 5, iter 3200, loss: 3.436543, top_1: 0.452148, top_k: 0.697617, samples/s: 686.648 1613546104.6334338
train: epoch 5, iter 3300, loss: 3.252434, top_1: 0.451484, top_k: 0.701836, samples/s: 680.259 1613546142.2662482
train: epoch 5, iter 3400, loss: 3.202417, top_1: 0.449102, top_k: 0.701758, samples/s: 684.511 1613546179.6650748
train: epoch 5, iter 3500, loss: 3.395630, top_1: 0.448008, top_k: 0.698047, samples/s: 685.000 1613546217.0373251
train: epoch 5, iter 3600, loss: 3.445917, top_1: 0.460703, top_k: 0.704531, samples/s: 681.613 1613546254.595331
train: epoch 5, iter 3700, loss: 3.334045, top_1: 0.458281, top_k: 0.704531, samples/s: 684.326 1613546292.0043106
train: epoch 5, iter 3800, loss: 3.271186, top_1: 0.452383, top_k: 0.698750, samples/s: 683.724 1613546329.446445
train: epoch 5, iter 3900, loss: 3.334377, top_1: 0.450898, top_k: 0.701680, samples/s: 683.644 1613546366.8927288
train: epoch 5, iter 4000, loss: 3.311420, top_1: 0.460000, top_k: 0.704570, samples/s: 683.275 1613546404.359401
train: epoch 5, iter 4100, loss: 3.439059, top_1: 0.452773, top_k: 0.695391, samples/s: 684.030 1613546441.7846344
train: epoch 5, iter 4200, loss: 3.176296, top_1: 0.462187, top_k: 0.706914, samples/s: 684.558 1613546479.1809967
train: epoch 5, iter 4300, loss: 3.315115, top_1: 0.452461, top_k: 0.702148, samples/s: 683.232 1613546516.650099
train: epoch 5, iter 4400, loss: 3.332424, top_1: 0.454648, top_k: 0.704570, samples/s: 683.265 1613546554.1171553
train: epoch 5, iter 4500, loss: 3.393729, top_1: 0.450234, top_k: 0.702422, samples/s: 684.036 1613546591.542085
train: epoch 5, iter 4600, loss: 3.444265, top_1: 0.468516, top_k: 0.709688, samples/s: 681.757 1613546629.0921245
train: epoch 5, iter 4700, loss: 3.272629, top_1: 0.461914, top_k: 0.708828, samples/s: 682.473 1613546666.6028166
train: epoch 5, iter 4800, loss: 3.412601, top_1: 0.458828, top_k: 0.705586, samples/s: 685.377 1613546703.954471
train: epoch 5, iter 4900, loss: 3.214144, top_1: 0.459922, top_k: 0.705391, samples/s: 684.539 1613546741.3519795
train: epoch 5, iter 5000, loss: 3.394729, top_1: 0.464570, top_k: 0.712773, samples/s: 682.885 1613546778.8399892
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_5.
validation: epoch 5, iter 195, top_1: 0.506591, top_k: 0.763782, samples/s: 2157.012 1613546803.0864499
train: epoch 6, iter 100, loss: 3.282824, top_1: 0.467539, top_k: 0.716133, samples/s: 702.778 1613546860.65528
train: epoch 6, iter 200, loss: 3.271282, top_1: 0.466445, top_k: 0.712812, samples/s: 697.367 1613546897.3646693
train: epoch 6, iter 300, loss: 3.141894, top_1: 0.465586, top_k: 0.714609, samples/s: 679.718 1613546935.0274506
train: epoch 6, iter 400, loss: 3.206786, top_1: 0.460938, top_k: 0.710508, samples/s: 681.669 1613546972.5822494
train: epoch 6, iter 500, loss: 3.455608, top_1: 0.460469, top_k: 0.704570, samples/s: 681.266 1613547010.1594954
train: epoch 6, iter 600, loss: 3.307567, top_1: 0.465078, top_k: 0.711445, samples/s: 681.611 1613547047.7174325
train: epoch 6, iter 700, loss: 3.159163, top_1: 0.462461, top_k: 0.714023, samples/s: 682.955 1613547085.2015934
train: epoch 6, iter 800, loss: 3.345928, top_1: 0.465625, top_k: 0.711406, samples/s: 682.682 1613547122.7007387
train: epoch 6, iter 900, loss: 3.312384, top_1: 0.465117, top_k: 0.716914, samples/s: 681.106 1613547160.2867925
train: epoch 6, iter 1000, loss: 3.347919, top_1: 0.469102, top_k: 0.716250, samples/s: 682.516 1613547197.7949557
train: epoch 6, iter 1100, loss: 3.175102, top_1: 0.466094, top_k: 0.713906, samples/s: 683.147 1613547235.2686129
train: epoch 6, iter 1200, loss: 2.967560, top_1: 0.471367, top_k: 0.718086, samples/s: 683.156 1613547272.7416947
train: epoch 6, iter 1300, loss: 3.272947, top_1: 0.467227, top_k: 0.715625, samples/s: 679.745 1613547310.4029384
train: epoch 6, iter 1400, loss: 3.230625, top_1: 0.470234, top_k: 0.716797, samples/s: 680.437 1613547348.025801
train: epoch 6, iter 1500, loss: 3.211311, top_1: 0.470039, top_k: 0.717031, samples/s: 683.822 1613547385.4624808
train: epoch 6, iter 1600, loss: 3.163240, top_1: 0.469375, top_k: 0.711719, samples/s: 682.588 1613547422.96675
train: epoch 6, iter 1700, loss: 3.290266, top_1: 0.467617, top_k: 0.716953, samples/s: 681.830 1613547460.5127652
train: epoch 6, iter 1800, loss: 3.323560, top_1: 0.467383, top_k: 0.709570, samples/s: 684.801 1613547497.8959234
train: epoch 6, iter 1900, loss: 3.294630, top_1: 0.462930, top_k: 0.710781, samples/s: 680.363 1613547535.5229084
train: epoch 6, iter 2000, loss: 3.014573, top_1: 0.469141, top_k: 0.715625, samples/s: 682.516 1613547573.031193
train: epoch 6, iter 2100, loss: 3.049861, top_1: 0.474336, top_k: 0.717344, samples/s: 681.272 1613547610.6078303
train: epoch 6, iter 2200, loss: 3.124867, top_1: 0.471953, top_k: 0.724727, samples/s: 682.381 1613547648.123594
train: epoch 6, iter 2300, loss: 3.369888, top_1: 0.464570, top_k: 0.713984, samples/s: 681.252 1613547685.7014627
train: epoch 6, iter 2400, loss: 3.261066, top_1: 0.468516, top_k: 0.710938, samples/s: 683.549 1613547723.1530309
train: epoch 6, iter 2500, loss: 3.274701, top_1: 0.470313, top_k: 0.718945, samples/s: 683.487 1613547760.6080403
train: epoch 6, iter 2600, loss: 3.136412, top_1: 0.465039, top_k: 0.712539, samples/s: 683.551 1613547798.0594444
train: epoch 6, iter 2700, loss: 3.116732, top_1: 0.470977, top_k: 0.719922, samples/s: 681.594 1613547835.6185465
train: epoch 6, iter 2800, loss: 3.165514, top_1: 0.469062, top_k: 0.716328, samples/s: 682.987 1613547873.1014776
train: epoch 6, iter 2900, loss: 3.225806, top_1: 0.469102, top_k: 0.713242, samples/s: 685.877 1613547910.4253266
train: epoch 6, iter 3000, loss: 3.186856, top_1: 0.466445, top_k: 0.715859, samples/s: 682.167 1613547947.9531798
train: epoch 6, iter 3100, loss: 3.168575, top_1: 0.470859, top_k: 0.717461, samples/s: 683.606 1613547985.4013271
train: epoch 6, iter 3200, loss: 3.162405, top_1: 0.466836, top_k: 0.715820, samples/s: 680.371 1613548023.0278387
train: epoch 6, iter 3300, loss: 3.315625, top_1: 0.469883, top_k: 0.715625, samples/s: 682.866 1613548060.5168097
train: epoch 6, iter 3400, loss: 3.313388, top_1: 0.469727, top_k: 0.717891, samples/s: 683.599 1613548097.9656901
train: epoch 6, iter 3500, loss: 3.302611, top_1: 0.477227, top_k: 0.718984, samples/s: 682.484 1613548135.475708
train: epoch 6, iter 3600, loss: 3.198459, top_1: 0.476719, top_k: 0.721719, samples/s: 684.130 1613548172.895572
train: epoch 6, iter 3700, loss: 3.333096, top_1: 0.470938, top_k: 0.717383, samples/s: 682.626 1613548210.397758
train: epoch 6, iter 3800, loss: 3.261364, top_1: 0.466758, top_k: 0.716836, samples/s: 679.731 1613548248.0597222
train: epoch 6, iter 3900, loss: 3.319180, top_1: 0.473945, top_k: 0.713437, samples/s: 685.243 1613548285.41869
train: epoch 6, iter 4000, loss: 3.116613, top_1: 0.473555, top_k: 0.719453, samples/s: 681.333 1613548322.992095
train: epoch 6, iter 4100, loss: 3.184392, top_1: 0.473477, top_k: 0.719297, samples/s: 683.709 1613548360.434888
train: epoch 6, iter 4200, loss: 3.323615, top_1: 0.469922, top_k: 0.716914, samples/s: 682.637 1613548397.9365723
train: epoch 6, iter 4300, loss: 3.251670, top_1: 0.479961, top_k: 0.722305, samples/s: 684.674 1613548435.3267221
train: epoch 6, iter 4400, loss: 2.981927, top_1: 0.473867, top_k: 0.715508, samples/s: 683.188 1613548472.7980733
train: epoch 6, iter 4500, loss: 3.328347, top_1: 0.469922, top_k: 0.717695, samples/s: 685.020 1613548510.169138
train: epoch 6, iter 4600, loss: 3.238212, top_1: 0.470430, top_k: 0.718281, samples/s: 684.520 1613548547.5676992
train: epoch 6, iter 4700, loss: 3.255630, top_1: 0.476562, top_k: 0.721953, samples/s: 680.691 1613548585.1764407
train: epoch 6, iter 4800, loss: 3.165875, top_1: 0.474219, top_k: 0.720547, samples/s: 684.012 1613548622.6027029
train: epoch 6, iter 4900, loss: 3.069184, top_1: 0.478633, top_k: 0.727070, samples/s: 681.264 1613548660.1799586
train: epoch 6, iter 5000, loss: 3.206510, top_1: 0.471211, top_k: 0.717148, samples/s: 679.252 1613548697.8684998
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_6.
validation: epoch 6, iter 195, top_1: 0.530609, top_k: 0.783053, samples/s: 2163.767 1613548721.8483546
train: epoch 7, iter 100, loss: 3.273524, top_1: 0.477891, top_k: 0.723008, samples/s: 703.958 1613548778.9928708
train: epoch 7, iter 200, loss: 3.051493, top_1: 0.483594, top_k: 0.724805, samples/s: 695.738 1613548815.7882633
train: epoch 7, iter 300, loss: 3.340243, top_1: 0.478438, top_k: 0.724570, samples/s: 680.103 1613548853.429607
train: epoch 7, iter 400, loss: 3.029355, top_1: 0.488672, top_k: 0.725234, samples/s: 681.457 1613548890.9961815
train: epoch 7, iter 500, loss: 3.079256, top_1: 0.491367, top_k: 0.732812, samples/s: 679.686 1613548928.6607108
train: epoch 7, iter 600, loss: 3.126451, top_1: 0.482070, top_k: 0.724766, samples/s: 680.476 1613548966.2813663
train: epoch 7, iter 700, loss: 3.050156, top_1: 0.478047, top_k: 0.724102, samples/s: 683.607 1613549003.7297866
train: epoch 7, iter 800, loss: 3.189084, top_1: 0.477383, top_k: 0.724375, samples/s: 685.143 1613549041.0942864
train: epoch 7, iter 900, loss: 3.210130, top_1: 0.487617, top_k: 0.729688, samples/s: 681.221 1613549078.673966
train: epoch 7, iter 1000, loss: 3.179300, top_1: 0.481953, top_k: 0.725195, samples/s: 681.619 1613549116.2315814
train: epoch 7, iter 1100, loss: 3.447320, top_1: 0.476719, top_k: 0.722812, samples/s: 682.703 1613549153.7295265
train: epoch 7, iter 1200, loss: 3.186695, top_1: 0.477422, top_k: 0.719375, samples/s: 682.153 1613549191.2578743
train: epoch 7, iter 1300, loss: 3.258097, top_1: 0.488438, top_k: 0.730156, samples/s: 680.378 1613549228.8839266
train: epoch 7, iter 1400, loss: 3.337323, top_1: 0.479883, top_k: 0.730703, samples/s: 684.420 1613549266.2879083
train: epoch 7, iter 1500, loss: 3.385815, top_1: 0.476875, top_k: 0.717969, samples/s: 682.185 1613549303.8143172
train: epoch 7, iter 1600, loss: 3.259656, top_1: 0.479063, top_k: 0.724922, samples/s: 683.215 1613549341.2842047
train: epoch 7, iter 1700, loss: 3.312872, top_1: 0.478711, top_k: 0.726953, samples/s: 682.238 1613549378.8078372
train: epoch 7, iter 1800, loss: 3.297587, top_1: 0.480195, top_k: 0.723516, samples/s: 682.205 1613549416.3332732
train: epoch 7, iter 1900, loss: 3.052654, top_1: 0.483750, top_k: 0.727031, samples/s: 683.654 1613549453.7789888
train: epoch 7, iter 2000, loss: 3.150557, top_1: 0.483945, top_k: 0.733711, samples/s: 682.198 1613549491.304781
train: epoch 7, iter 2100, loss: 3.337943, top_1: 0.482109, top_k: 0.724414, samples/s: 683.533 1613549528.7572503
train: epoch 7, iter 2200, loss: 3.012403, top_1: 0.483945, top_k: 0.726094, samples/s: 679.541 1613549566.4296882
train: epoch 7, iter 2300, loss: 3.246362, top_1: 0.486641, top_k: 0.723633, samples/s: 684.047 1613549603.8540573
train: epoch 7, iter 2400, loss: 3.195656, top_1: 0.481797, top_k: 0.724883, samples/s: 682.694 1613549641.3525045
train: epoch 7, iter 2500, loss: 3.192050, top_1: 0.476211, top_k: 0.722539, samples/s: 682.331 1613549678.8709507
train: epoch 7, iter 2600, loss: 3.487000, top_1: 0.481914, top_k: 0.721250, samples/s: 683.066 1613549716.3491125
train: epoch 7, iter 2700, loss: 3.082120, top_1: 0.483008, top_k: 0.725469, samples/s: 683.259 1613549753.816474
train: epoch 7, iter 2800, loss: 3.084097, top_1: 0.480234, top_k: 0.725469, samples/s: 682.867 1613549791.305488
train: epoch 7, iter 2900, loss: 3.226165, top_1: 0.477148, top_k: 0.724492, samples/s: 680.638 1613549828.9195006
train: epoch 7, iter 3000, loss: 3.163012, top_1: 0.478320, top_k: 0.722617, samples/s: 684.701 1613549866.305801
train: epoch 7, iter 3100, loss: 3.192831, top_1: 0.481289, top_k: 0.727969, samples/s: 684.994 1613549903.6783972
train: epoch 7, iter 3200, loss: 3.075490, top_1: 0.486445, top_k: 0.727344, samples/s: 684.985 1613549941.0515487
train: epoch 7, iter 3300, loss: 3.168460, top_1: 0.480898, top_k: 0.722383, samples/s: 684.141 1613549978.4707718
train: epoch 7, iter 3400, loss: 3.262293, top_1: 0.486914, top_k: 0.725234, samples/s: 684.809 1613550015.8534367
train: epoch 7, iter 3500, loss: 3.192233, top_1: 0.481953, top_k: 0.725977, samples/s: 683.710 1613550053.2962987
train: epoch 7, iter 3600, loss: 3.334821, top_1: 0.488125, top_k: 0.728320, samples/s: 682.559 1613550090.8021357
train: epoch 7, iter 3700, loss: 2.941637, top_1: 0.480430, top_k: 0.724844, samples/s: 682.974 1613550128.2851713
train: epoch 7, iter 3800, loss: 3.229391, top_1: 0.484805, top_k: 0.728594, samples/s: 683.778 1613550165.724199
train: epoch 7, iter 3900, loss: 2.969579, top_1: 0.483789, top_k: 0.726719, samples/s: 685.364 1613550203.076718
train: epoch 7, iter 4000, loss: 3.346845, top_1: 0.486797, top_k: 0.728437, samples/s: 682.312 1613550240.5962155
train: epoch 7, iter 4100, loss: 3.203011, top_1: 0.487422, top_k: 0.728555, samples/s: 683.000 1613550278.077892
train: epoch 7, iter 4200, loss: 3.010254, top_1: 0.483828, top_k: 0.726367, samples/s: 682.479 1613550315.5882418
train: epoch 7, iter 4300, loss: 2.960038, top_1: 0.486406, top_k: 0.729141, samples/s: 683.359 1613550353.050243
train: epoch 7, iter 4400, loss: 3.158266, top_1: 0.480898, top_k: 0.726367, samples/s: 683.871 1613550390.4842508
train: epoch 7, iter 4500, loss: 3.158984, top_1: 0.482695, top_k: 0.727070, samples/s: 685.306 1613550427.8397942
train: epoch 7, iter 4600, loss: 3.216343, top_1: 0.482930, top_k: 0.724336, samples/s: 684.456 1613550465.241706
train: epoch 7, iter 4700, loss: 3.108888, top_1: 0.485586, top_k: 0.731836, samples/s: 684.586 1613550502.6366076
train: epoch 7, iter 4800, loss: 3.115030, top_1: 0.494063, top_k: 0.734258, samples/s: 683.157 1613550540.1096475
train: epoch 7, iter 4900, loss: 2.920335, top_1: 0.485430, top_k: 0.728984, samples/s: 683.568 1613550577.5602522
train: epoch 7, iter 5000, loss: 2.970040, top_1: 0.484922, top_k: 0.728828, samples/s: 683.495 1613550615.014862
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_7.
validation: epoch 7, iter 195, top_1: 0.540605, top_k: 0.786759, samples/s: 2175.930 1613550639.1348782
train: epoch 8, iter 100, loss: 3.180473, top_1: 0.492383, top_k: 0.735391, samples/s: 703.094 1613550696.8812714
train: epoch 8, iter 200, loss: 3.007856, top_1: 0.501289, top_k: 0.740586, samples/s: 698.989 1613550733.5054934
train: epoch 8, iter 300, loss: 2.899265, top_1: 0.489336, top_k: 0.733789, samples/s: 681.401 1613550771.0752478
train: epoch 8, iter 400, loss: 3.044531, top_1: 0.493867, top_k: 0.729648, samples/s: 681.765 1613550808.6248734
train: epoch 8, iter 500, loss: 3.081267, top_1: 0.489766, top_k: 0.736250, samples/s: 682.095 1613550846.156193
train: epoch 8, iter 600, loss: 3.214341, top_1: 0.493086, top_k: 0.735977, samples/s: 683.461 1613550883.6126416
train: epoch 8, iter 700, loss: 3.390484, top_1: 0.491719, top_k: 0.731563, samples/s: 681.038 1613550921.202378
train: epoch 8, iter 800, loss: 3.295238, top_1: 0.489805, top_k: 0.735781, samples/s: 680.320 1613550958.8317227
train: epoch 8, iter 900, loss: 2.991228, top_1: 0.498203, top_k: 0.741094, samples/s: 683.881 1613550996.265068
train: epoch 8, iter 1000, loss: 3.141941, top_1: 0.491719, top_k: 0.739102, samples/s: 681.576 1613551033.8251188
train: epoch 8, iter 1100, loss: 3.256460, top_1: 0.486719, top_k: 0.734688, samples/s: 682.456 1613551071.3366544
train: epoch 8, iter 1200, loss: 3.293251, top_1: 0.485312, top_k: 0.728164, samples/s: 683.418 1613551108.7954876
train: epoch 8, iter 1300, loss: 3.092801, top_1: 0.493359, top_k: 0.731250, samples/s: 681.747 1613551146.3459308
train: epoch 8, iter 1400, loss: 3.287313, top_1: 0.488477, top_k: 0.734219, samples/s: 682.430 1613551183.8590267
train: epoch 8, iter 1500, loss: 3.372358, top_1: 0.491992, top_k: 0.730820, samples/s: 684.557 1613551221.2553785
train: epoch 8, iter 1600, loss: 2.984604, top_1: 0.498711, top_k: 0.735898, samples/s: 682.924 1613551258.7413347
train: epoch 8, iter 1700, loss: 3.071099, top_1: 0.494844, top_k: 0.737734, samples/s: 682.947 1613551296.22588
train: epoch 8, iter 1800, loss: 3.356853, top_1: 0.490391, top_k: 0.735625, samples/s: 685.056 1613551333.5950968
train: epoch 8, iter 1900, loss: 3.189294, top_1: 0.490234, top_k: 0.731523, samples/s: 682.195 1613551371.1211014
train: epoch 8, iter 2000, loss: 3.176557, top_1: 0.490703, top_k: 0.730625, samples/s: 685.137 1613551408.4858346
train: epoch 8, iter 2100, loss: 3.134253, top_1: 0.499570, top_k: 0.740742, samples/s: 683.133 1613551445.9602792
train: epoch 8, iter 2200, loss: 2.977399, top_1: 0.495273, top_k: 0.736758, samples/s: 683.315 1613551483.4247403
train: epoch 8, iter 2300, loss: 3.233748, top_1: 0.484375, top_k: 0.733008, samples/s: 684.219 1613551520.8396492
train: epoch 8, iter 2400, loss: 3.093464, top_1: 0.488828, top_k: 0.729258, samples/s: 683.481 1613551558.294912
train: epoch 8, iter 2500, loss: 3.117033, top_1: 0.488555, top_k: 0.735938, samples/s: 682.077 1613551595.8273966
train: epoch 8, iter 2600, loss: 3.134248, top_1: 0.495117, top_k: 0.736992, samples/s: 683.906 1613551633.259479
train: epoch 8, iter 2700, loss: 3.093205, top_1: 0.490352, top_k: 0.733008, samples/s: 682.895 1613551670.7470045
train: epoch 8, iter 2800, loss: 3.143909, top_1: 0.495352, top_k: 0.737578, samples/s: 683.646 1613551708.1931157
train: epoch 8, iter 2900, loss: 3.193285, top_1: 0.489883, top_k: 0.735625, samples/s: 683.048 1613551745.6722035
train: epoch 8, iter 3000, loss: 3.128516, top_1: 0.489727, top_k: 0.733672, samples/s: 685.157 1613551783.0359209
train: epoch 8, iter 3100, loss: 3.020751, top_1: 0.491992, top_k: 0.732656, samples/s: 683.521 1613551820.489035
train: epoch 8, iter 3200, loss: 3.119579, top_1: 0.493672, top_k: 0.733242, samples/s: 683.476 1613551857.9447014
train: epoch 8, iter 3300, loss: 3.085936, top_1: 0.492656, top_k: 0.735664, samples/s: 685.674 1613551895.2802343
train: epoch 8, iter 3400, loss: 3.147284, top_1: 0.483203, top_k: 0.732148, samples/s: 684.030 1613551932.7053614
train: epoch 8, iter 3500, loss: 3.137128, top_1: 0.496250, top_k: 0.734922, samples/s: 684.886 1613551970.084484
train: epoch 8, iter 3600, loss: 3.138270, top_1: 0.491016, top_k: 0.733047, samples/s: 683.972 1613552007.512347
train: epoch 8, iter 3700, loss: 3.136325, top_1: 0.489180, top_k: 0.735586, samples/s: 683.977 1613552044.9404693
train: epoch 8, iter 3800, loss: 3.211160, top_1: 0.497227, top_k: 0.739102, samples/s: 685.117 1613552082.3063889
train: epoch 8, iter 3900, loss: 3.032376, top_1: 0.495391, top_k: 0.735273, samples/s: 684.253 1613552119.7194302
train: epoch 8, iter 4000, loss: 3.201682, top_1: 0.485312, top_k: 0.730273, samples/s: 685.088 1613552157.086934
train: epoch 8, iter 4100, loss: 3.105462, top_1: 0.496016, top_k: 0.737578, samples/s: 685.012 1613552194.4584665
train: epoch 8, iter 4200, loss: 3.167672, top_1: 0.489687, top_k: 0.735078, samples/s: 683.299 1613552231.9239016
train: epoch 8, iter 4300, loss: 2.781832, top_1: 0.491367, top_k: 0.734766, samples/s: 687.387 1613552269.1663983
train: epoch 8, iter 4400, loss: 3.283823, top_1: 0.490352, top_k: 0.735664, samples/s: 682.757 1613552306.6614597
train: epoch 8, iter 4500, loss: 3.130480, top_1: 0.496719, top_k: 0.740430, samples/s: 682.881 1613552344.1495905
train: epoch 8, iter 4600, loss: 2.950529, top_1: 0.495742, top_k: 0.738164, samples/s: 685.343 1613552381.5032446
train: epoch 8, iter 4700, loss: 3.213888, top_1: 0.498867, top_k: 0.738555, samples/s: 685.254 1613552418.86159
train: epoch 8, iter 4800, loss: 3.221952, top_1: 0.495430, top_k: 0.735313, samples/s: 683.779 1613552456.300585
train: epoch 8, iter 4900, loss: 3.146394, top_1: 0.493008, top_k: 0.736914, samples/s: 683.562 1613552493.7513938
train: epoch 8, iter 5000, loss: 3.154716, top_1: 0.497188, top_k: 0.738633, samples/s: 682.908 1613552531.2380846
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_8.
validation: epoch 8, iter 195, top_1: 0.526683, top_k: 0.778886, samples/s: 2164.798 1613552555.4138806
train: epoch 9, iter 100, loss: 2.982764, top_1: 0.510898, top_k: 0.748594, samples/s: 703.323 1613552612.8757973
train: epoch 9, iter 200, loss: 2.939885, top_1: 0.507461, top_k: 0.747461, samples/s: 698.909 1613552649.5044775
train: epoch 9, iter 300, loss: 3.162175, top_1: 0.509297, top_k: 0.748789, samples/s: 682.315 1613552687.0235918
train: epoch 9, iter 400, loss: 3.018055, top_1: 0.503086, top_k: 0.745000, samples/s: 680.049 1613552724.6679542
train: epoch 9, iter 500, loss: 3.172652, top_1: 0.500000, top_k: 0.739961, samples/s: 684.105 1613552762.0890076
train: epoch 9, iter 600, loss: 3.205955, top_1: 0.498867, top_k: 0.739453, samples/s: 679.655 1613552799.7552648
train: epoch 9, iter 700, loss: 3.080303, top_1: 0.502578, top_k: 0.740352, samples/s: 682.462 1613552837.266527
train: epoch 9, iter 800, loss: 3.184566, top_1: 0.496758, top_k: 0.737969, samples/s: 680.860 1613552874.8659358
train: epoch 9, iter 900, loss: 2.908658, top_1: 0.494141, top_k: 0.736094, samples/s: 681.102 1613552912.4521177
train: epoch 9, iter 1000, loss: 2.910042, top_1: 0.500195, top_k: 0.738398, samples/s: 683.102 1613552949.928212
train: epoch 9, iter 1100, loss: 2.813300, top_1: 0.502539, top_k: 0.743945, samples/s: 682.490 1613552987.4379473
train: epoch 9, iter 1200, loss: 3.089588, top_1: 0.497148, top_k: 0.740430, samples/s: 682.966 1613553024.9215322
train: epoch 9, iter 1300, loss: 3.085310, top_1: 0.499883, top_k: 0.740469, samples/s: 680.415 1613553062.5457106
train: epoch 9, iter 1400, loss: 3.075631, top_1: 0.505469, top_k: 0.741758, samples/s: 684.547 1613553099.9426775
train: epoch 9, iter 1500, loss: 3.086776, top_1: 0.498906, top_k: 0.741641, samples/s: 685.092 1613553137.3098536
train: epoch 9, iter 1600, loss: 3.070735, top_1: 0.497383, top_k: 0.741055, samples/s: 685.121 1613553174.675627
train: epoch 9, iter 1700, loss: 3.099257, top_1: 0.500703, top_k: 0.740625, samples/s: 684.298 1613553212.086203
train: epoch 9, iter 1800, loss: 3.162532, top_1: 0.498984, top_k: 0.741680, samples/s: 683.305 1613553249.5511522
train: epoch 9, iter 1900, loss: 2.957080, top_1: 0.500195, top_k: 0.736367, samples/s: 685.194 1613553286.9127913
train: epoch 9, iter 2000, loss: 3.181914, top_1: 0.501484, top_k: 0.742148, samples/s: 684.164 1613553324.3307183
train: epoch 9, iter 2100, loss: 3.075968, top_1: 0.502344, top_k: 0.742930, samples/s: 685.979 1613553361.649691
train: epoch 9, iter 2200, loss: 2.991858, top_1: 0.503008, top_k: 0.741680, samples/s: 684.726 1613553399.0369093
train: epoch 9, iter 2300, loss: 3.053694, top_1: 0.500391, top_k: 0.741172, samples/s: 685.387 1613553436.3880222
train: epoch 9, iter 2400, loss: 3.129708, top_1: 0.504961, top_k: 0.740195, samples/s: 682.491 1613553473.8976955
train: epoch 9, iter 2500, loss: 2.982096, top_1: 0.499023, top_k: 0.735781, samples/s: 686.068 1613553511.2117696
train: epoch 9, iter 2600, loss: 3.140525, top_1: 0.500977, top_k: 0.739219, samples/s: 684.674 1613553548.6017869
train: epoch 9, iter 2700, loss: 3.115645, top_1: 0.497188, top_k: 0.737969, samples/s: 685.792 1613553585.9308918
train: epoch 9, iter 2800, loss: 3.064095, top_1: 0.499336, top_k: 0.736367, samples/s: 682.955 1613553623.4150963
train: epoch 9, iter 2900, loss: 3.064179, top_1: 0.498203, top_k: 0.739258, samples/s: 686.495 1613553660.7059705
train: epoch 9, iter 3000, loss: 3.036900, top_1: 0.497422, top_k: 0.737109, samples/s: 682.145 1613553698.2346263
train: epoch 9, iter 3100, loss: 3.030303, top_1: 0.496680, top_k: 0.739336, samples/s: 683.141 1613553735.708545
train: epoch 9, iter 3200, loss: 3.295129, top_1: 0.500703, top_k: 0.741445, samples/s: 684.859 1613553773.0885704
train: epoch 9, iter 3300, loss: 3.093778, top_1: 0.499141, top_k: 0.736406, samples/s: 682.451 1613553810.6004298
train: epoch 9, iter 3400, loss: 3.119374, top_1: 0.501211, top_k: 0.745195, samples/s: 685.008 1613553847.9722416
train: epoch 9, iter 3500, loss: 2.974658, top_1: 0.491875, top_k: 0.735039, samples/s: 685.699 1613553885.3062813
train: epoch 9, iter 3600, loss: 3.142379, top_1: 0.499805, top_k: 0.745859, samples/s: 684.168 1613553922.7240298
train: epoch 9, iter 3700, loss: 2.843352, top_1: 0.502148, top_k: 0.741602, samples/s: 682.984 1613553960.2066603
train: epoch 9, iter 3800, loss: 2.953548, top_1: 0.493672, top_k: 0.738125, samples/s: 684.680 1613553997.5963824
train: epoch 9, iter 3900, loss: 3.017022, top_1: 0.500000, top_k: 0.743086, samples/s: 685.086 1613554034.9638636
train: epoch 9, iter 4000, loss: 3.231350, top_1: 0.497070, top_k: 0.740508, samples/s: 684.420 1613554072.3678935
train: epoch 9, iter 4100, loss: 2.945776, top_1: 0.497188, top_k: 0.738945, samples/s: 684.673 1613554109.7582176
train: epoch 9, iter 4200, loss: 2.986553, top_1: 0.502344, top_k: 0.741758, samples/s: 683.948 1613554147.1877797
train: epoch 9, iter 4300, loss: 3.010885, top_1: 0.499883, top_k: 0.742930, samples/s: 685.509 1613554184.5322087
train: epoch 9, iter 4400, loss: 3.070135, top_1: 0.498750, top_k: 0.735313, samples/s: 681.910 1613554222.0739279
train: epoch 9, iter 4500, loss: 3.249457, top_1: 0.501016, top_k: 0.741523, samples/s: 684.185 1613554259.4907296
train: epoch 9, iter 4600, loss: 3.189585, top_1: 0.496445, top_k: 0.738398, samples/s: 685.863 1613554296.815979
train: epoch 9, iter 4700, loss: 2.933858, top_1: 0.501836, top_k: 0.741094, samples/s: 683.597 1613554334.2649615
train: epoch 9, iter 4800, loss: 2.910114, top_1: 0.506211, top_k: 0.744570, samples/s: 684.633 1613554371.6571615
train: epoch 9, iter 4900, loss: 3.088711, top_1: 0.503203, top_k: 0.743633, samples/s: 685.154 1613554409.021111
train: epoch 9, iter 5000, loss: 3.273670, top_1: 0.503984, top_k: 0.743633, samples/s: 682.718 1613554446.518213
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_9.
validation: epoch 9, iter 195, top_1: 0.549439, top_k: 0.800100, samples/s: 2142.554 1613554470.9324005
train: epoch 10, iter 100, loss: 3.050696, top_1: 0.514727, top_k: 0.755273, samples/s: 704.106 1613554536.0415194
train: epoch 10, iter 200, loss: 2.924014, top_1: 0.511563, top_k: 0.753086, samples/s: 699.448 1613554572.6419759
train: epoch 10, iter 300, loss: 3.142647, top_1: 0.506914, top_k: 0.746836, samples/s: 688.640 1613554609.8165646
train: epoch 10, iter 400, loss: 2.946334, top_1: 0.500234, top_k: 0.741445, samples/s: 682.784 1613554647.3100913
train: epoch 10, iter 500, loss: 3.293876, top_1: 0.507031, top_k: 0.745117, samples/s: 682.277 1613554684.8315165
train: epoch 10, iter 600, loss: 3.196559, top_1: 0.514062, top_k: 0.753516, samples/s: 682.067 1613554722.3645067
train: epoch 10, iter 700, loss: 3.039305, top_1: 0.511875, top_k: 0.744531, samples/s: 685.753 1613554759.6956985
train: epoch 10, iter 800, loss: 3.096817, top_1: 0.507383, top_k: 0.746680, samples/s: 681.410 1613554797.2648365
train: epoch 10, iter 900, loss: 3.097925, top_1: 0.509141, top_k: 0.746133, samples/s: 683.939 1613554834.695153
train: epoch 10, iter 1000, loss: 2.958766, top_1: 0.505781, top_k: 0.745039, samples/s: 684.643 1613554872.086821
train: epoch 10, iter 1100, loss: 3.140117, top_1: 0.503398, top_k: 0.742578, samples/s: 682.094 1613554909.61837
train: epoch 10, iter 1200, loss: 2.951709, top_1: 0.506055, top_k: 0.746680, samples/s: 684.422 1613554947.0221932
train: epoch 10, iter 1300, loss: 3.070040, top_1: 0.506211, top_k: 0.745625, samples/s: 684.054 1613554984.4461625
train: epoch 10, iter 1400, loss: 3.016600, top_1: 0.510078, top_k: 0.751797, samples/s: 682.124 1613555021.9759917
train: epoch 10, iter 1500, loss: 3.057873, top_1: 0.504570, top_k: 0.746250, samples/s: 685.075 1613555059.3440702
train: epoch 10, iter 1600, loss: 3.102534, top_1: 0.504531, top_k: 0.745352, samples/s: 683.115 1613555096.8195531
train: epoch 10, iter 1700, loss: 3.103247, top_1: 0.501719, top_k: 0.745898, samples/s: 682.006 1613555134.3558154
train: epoch 10, iter 1800, loss: 2.907123, top_1: 0.506016, top_k: 0.744883, samples/s: 684.993 1613555171.728574
train: epoch 10, iter 1900, loss: 3.276235, top_1: 0.506992, top_k: 0.745977, samples/s: 686.538 1613555209.0171258
train: epoch 10, iter 2000, loss: 3.209821, top_1: 0.504766, top_k: 0.743945, samples/s: 681.463 1613555246.5832915
train: epoch 10, iter 2100, loss: 3.007516, top_1: 0.509648, top_k: 0.746523, samples/s: 684.854 1613555283.963592
train: epoch 10, iter 2200, loss: 3.027156, top_1: 0.502188, top_k: 0.745273, samples/s: 683.787 1613555321.4021204
train: epoch 10, iter 2300, loss: 3.154980, top_1: 0.505352, top_k: 0.748047, samples/s: 683.016 1613555358.8828132
train: epoch 10, iter 2400, loss: 3.028482, top_1: 0.504219, top_k: 0.746445, samples/s: 683.571 1613555396.3333375
train: epoch 10, iter 2500, loss: 2.886432, top_1: 0.506719, top_k: 0.746406, samples/s: 685.693 1613555433.667833
train: epoch 10, iter 2600, loss: 2.914984, top_1: 0.508047, top_k: 0.744453, samples/s: 685.175 1613555471.0305562
train: epoch 10, iter 2700, loss: 3.019432, top_1: 0.508711, top_k: 0.746797, samples/s: 683.477 1613555508.486072
train: epoch 10, iter 2800, loss: 3.292880, top_1: 0.500469, top_k: 0.739023, samples/s: 684.165 1613555545.9039125
train: epoch 10, iter 2900, loss: 2.952734, top_1: 0.503164, top_k: 0.746484, samples/s: 683.704 1613555583.3471174
train: epoch 10, iter 3000, loss: 3.060125, top_1: 0.512969, top_k: 0.752578, samples/s: 683.489 1613555620.8020158
train: epoch 10, iter 3100, loss: 3.152437, top_1: 0.503203, top_k: 0.742070, samples/s: 682.247 1613555658.3249588
train: epoch 10, iter 3200, loss: 2.981555, top_1: 0.507422, top_k: 0.747305, samples/s: 684.407 1613555695.7297194
train: epoch 10, iter 3300, loss: 3.191524, top_1: 0.502617, top_k: 0.746797, samples/s: 683.563 1613555733.1804247
train: epoch 10, iter 3400, loss: 3.135355, top_1: 0.509922, top_k: 0.752578, samples/s: 684.180 1613555770.597594
train: epoch 10, iter 3500, loss: 2.951457, top_1: 0.510234, top_k: 0.746328, samples/s: 684.910 1613555807.974794
train: epoch 10, iter 3600, loss: 3.256853, top_1: 0.507227, top_k: 0.747852, samples/s: 684.414 1613555845.3789337
train: epoch 10, iter 3700, loss: 3.191430, top_1: 0.504219, top_k: 0.740586, samples/s: 683.229 1613555882.848149
train: epoch 10, iter 3800, loss: 3.047001, top_1: 0.505625, top_k: 0.749180, samples/s: 684.170 1613555920.2657404
train: epoch 10, iter 3900, loss: 2.989032, top_1: 0.507578, top_k: 0.747773, samples/s: 684.927 1613555957.6420043
train: epoch 10, iter 4000, loss: 2.913000, top_1: 0.501602, top_k: 0.745547, samples/s: 685.043 1613555995.0118878
train: epoch 10, iter 4100, loss: 3.063972, top_1: 0.505781, top_k: 0.746055, samples/s: 683.766 1613556032.4515996
train: epoch 10, iter 4200, loss: 3.214558, top_1: 0.501914, top_k: 0.745547, samples/s: 686.372 1613556069.7491508
train: epoch 10, iter 4300, loss: 3.102504, top_1: 0.501953, top_k: 0.743281, samples/s: 682.740 1613556107.245119
train: epoch 10, iter 4400, loss: 2.792259, top_1: 0.508086, top_k: 0.746914, samples/s: 684.568 1613556144.64098
train: epoch 10, iter 4500, loss: 2.932251, top_1: 0.506250, top_k: 0.746953, samples/s: 683.322 1613556182.105046
train: epoch 10, iter 4600, loss: 3.159846, top_1: 0.502617, top_k: 0.744062, samples/s: 688.883 1613556219.266606
train: epoch 10, iter 4700, loss: 3.026239, top_1: 0.506172, top_k: 0.745234, samples/s: 680.628 1613556256.878909
train: epoch 10, iter 4800, loss: 2.991840, top_1: 0.508789, top_k: 0.745508, samples/s: 685.620 1613556294.2173347
train: epoch 10, iter 4900, loss: 3.057065, top_1: 0.511250, top_k: 0.749492, samples/s: 684.168 1613556331.6351285
train: epoch 10, iter 5000, loss: 3.046778, top_1: 0.511680, top_k: 0.751641, samples/s: 686.311 1613556368.9360182
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_10.
validation: epoch 10, iter 195, top_1: 0.561739, top_k: 0.807652, samples/s: 2174.090 1613556393.0191011
train: epoch 11, iter 100, loss: 3.090497, top_1: 0.513828, top_k: 0.756133, samples/s: 703.281 1613556451.0654922
train: epoch 11, iter 200, loss: 3.093171, top_1: 0.511953, top_k: 0.751328, samples/s: 698.196 1613556487.7316854
train: epoch 11, iter 300, loss: 2.972144, top_1: 0.514922, top_k: 0.753203, samples/s: 682.375 1613556525.2475114
train: epoch 11, iter 400, loss: 2.999449, top_1: 0.522188, top_k: 0.756797, samples/s: 682.085 1613556562.7794242
train: epoch 11, iter 500, loss: 3.060194, top_1: 0.512070, top_k: 0.750898, samples/s: 683.839 1613556600.21525
train: epoch 11, iter 600, loss: 3.066512, top_1: 0.513047, top_k: 0.754492, samples/s: 681.661 1613556637.7705743
train: epoch 11, iter 700, loss: 3.075250, top_1: 0.515898, top_k: 0.756016, samples/s: 681.884 1613556675.3136103
train: epoch 11, iter 800, loss: 2.909848, top_1: 0.513555, top_k: 0.751875, samples/s: 683.658 1613556712.7592
train: epoch 11, iter 900, loss: 3.289440, top_1: 0.506602, top_k: 0.745156, samples/s: 682.489 1613556750.2689586
train: epoch 11, iter 1000, loss: 3.157788, top_1: 0.507734, top_k: 0.749727, samples/s: 682.614 1613556787.7719104
train: epoch 11, iter 1100, loss: 2.968107, top_1: 0.512891, top_k: 0.753906, samples/s: 682.775 1613556825.2659688
train: epoch 11, iter 1200, loss: 3.047518, top_1: 0.510312, top_k: 0.749336, samples/s: 682.446 1613556862.778094
train: epoch 11, iter 1300, loss: 3.022105, top_1: 0.515117, top_k: 0.754336, samples/s: 681.973 1613556900.3162425
train: epoch 11, iter 1400, loss: 3.087781, top_1: 0.511680, top_k: 0.751289, samples/s: 684.649 1613556937.7076695
train: epoch 11, iter 1500, loss: 3.063947, top_1: 0.517344, top_k: 0.752148, samples/s: 683.038 1613556975.187281
train: epoch 11, iter 1600, loss: 3.106082, top_1: 0.515586, top_k: 0.754375, samples/s: 681.956 1613557012.7263174
train: epoch 11, iter 1700, loss: 3.051353, top_1: 0.509414, top_k: 0.749336, samples/s: 684.477 1613557050.1271815
train: epoch 11, iter 1800, loss: 3.029178, top_1: 0.517109, top_k: 0.756953, samples/s: 681.198 1613557087.7080514
train: epoch 11, iter 1900, loss: 3.073070, top_1: 0.504844, top_k: 0.749336, samples/s: 684.009 1613557125.134448
train: epoch 11, iter 2000, loss: 2.928646, top_1: 0.508789, top_k: 0.747539, samples/s: 682.692 1613557162.633045
train: epoch 11, iter 2100, loss: 3.100057, top_1: 0.509219, top_k: 0.754883, samples/s: 682.647 1613557200.1339853
train: epoch 11, iter 2200, loss: 3.024108, top_1: 0.517031, top_k: 0.751992, samples/s: 684.283 1613557237.5455344
train: epoch 11, iter 2300, loss: 2.960964, top_1: 0.513320, top_k: 0.749141, samples/s: 682.562 1613557275.0512378
train: epoch 11, iter 2400, loss: 2.948234, top_1: 0.514453, top_k: 0.752422, samples/s: 684.677 1613557312.4410522
train: epoch 11, iter 2500, loss: 2.950364, top_1: 0.512148, top_k: 0.751953, samples/s: 685.457 1613557349.788511
train: epoch 11, iter 2600, loss: 2.876768, top_1: 0.510898, top_k: 0.752891, samples/s: 683.240 1613557387.25705
train: epoch 11, iter 2700, loss: 2.893375, top_1: 0.518633, top_k: 0.753359, samples/s: 685.347 1613557424.6103222
train: epoch 11, iter 2800, loss: 2.960238, top_1: 0.516523, top_k: 0.753047, samples/s: 683.130 1613557462.0849128
train: epoch 11, iter 2900, loss: 3.012814, top_1: 0.509219, top_k: 0.748672, samples/s: 684.411 1613557499.4893005
train: epoch 11, iter 3000, loss: 3.096193, top_1: 0.508789, top_k: 0.746328, samples/s: 683.438 1613557536.9470358
train: epoch 11, iter 3100, loss: 2.911320, top_1: 0.514805, top_k: 0.751953, samples/s: 683.596 1613557574.3961024
train: epoch 11, iter 3200, loss: 2.860834, top_1: 0.508828, top_k: 0.748750, samples/s: 683.325 1613557611.8599281
train: epoch 11, iter 3300, loss: 3.035218, top_1: 0.513867, top_k: 0.753281, samples/s: 682.607 1613557649.363231
train: epoch 11, iter 3400, loss: 2.820782, top_1: 0.515664, top_k: 0.747969, samples/s: 685.513 1613557686.707491
train: epoch 11, iter 3500, loss: 2.998408, top_1: 0.507266, top_k: 0.751484, samples/s: 685.707 1613557724.0411928
train: epoch 11, iter 3600, loss: 3.225660, top_1: 0.510938, top_k: 0.749180, samples/s: 684.248 1613557761.4545393
train: epoch 11, iter 3700, loss: 3.223696, top_1: 0.515117, top_k: 0.752656, samples/s: 685.573 1613557798.7954662
train: epoch 11, iter 3800, loss: 2.948560, top_1: 0.512227, top_k: 0.747617, samples/s: 682.908 1613557836.2823327
train: epoch 11, iter 3900, loss: 2.934791, top_1: 0.512930, top_k: 0.754570, samples/s: 685.357 1613557873.6350439
train: epoch 11, iter 4000, loss: 3.009812, top_1: 0.509414, top_k: 0.753164, samples/s: 684.291 1613557911.0460637
train: epoch 11, iter 4100, loss: 3.126259, top_1: 0.509531, top_k: 0.749492, samples/s: 684.233 1613557948.460119
train: epoch 11, iter 4200, loss: 3.108078, top_1: 0.508828, top_k: 0.748906, samples/s: 685.658 1613557985.796513
train: epoch 11, iter 4300, loss: 2.987035, top_1: 0.509258, top_k: 0.750781, samples/s: 685.209 1613558023.157414
train: epoch 11, iter 4400, loss: 3.086943, top_1: 0.507461, top_k: 0.744258, samples/s: 681.648 1613558060.713446
train: epoch 11, iter 4500, loss: 3.043993, top_1: 0.519219, top_k: 0.754961, samples/s: 684.581 1613558098.1086853
train: epoch 11, iter 4600, loss: 3.110593, top_1: 0.507930, top_k: 0.749531, samples/s: 684.989 1613558135.481523
train: epoch 11, iter 4700, loss: 2.960387, top_1: 0.514531, top_k: 0.751406, samples/s: 685.184 1613558172.8437376
train: epoch 11, iter 4800, loss: 3.178148, top_1: 0.510820, top_k: 0.750625, samples/s: 684.970 1613558210.2176418
train: epoch 11, iter 4900, loss: 3.064062, top_1: 0.507383, top_k: 0.743555, samples/s: 685.837 1613558247.5442066
train: epoch 11, iter 5000, loss: 3.070043, top_1: 0.507383, top_k: 0.749336, samples/s: 682.899 1613558285.031586
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_11.
validation: epoch 11, iter 195, top_1: 0.565465, top_k: 0.807893, samples/s: 2157.677 1613558309.2578697
train: epoch 12, iter 100, loss: 2.946221, top_1: 0.520352, top_k: 0.757539, samples/s: 703.229 1613558366.9923966
train: epoch 12, iter 200, loss: 2.807635, top_1: 0.525703, top_k: 0.768086, samples/s: 699.018 1613558403.6154077
train: epoch 12, iter 300, loss: 2.905252, top_1: 0.521953, top_k: 0.765234, samples/s: 685.247 1613558440.9740777
train: epoch 12, iter 400, loss: 2.970709, top_1: 0.520469, top_k: 0.757148, samples/s: 681.909 1613558478.5157082
train: epoch 12, iter 500, loss: 2.973644, top_1: 0.522109, top_k: 0.758555, samples/s: 683.941 1613558515.9458232
train: epoch 12, iter 600, loss: 2.938255, top_1: 0.525117, top_k: 0.757969, samples/s: 682.371 1613558553.4620502
train: epoch 12, iter 700, loss: 2.907532, top_1: 0.527969, top_k: 0.761797, samples/s: 685.154 1613558590.825854
train: epoch 12, iter 800, loss: 3.174388, top_1: 0.520664, top_k: 0.755313, samples/s: 683.226 1613558628.2952323
train: epoch 12, iter 900, loss: 2.962482, top_1: 0.525312, top_k: 0.758984, samples/s: 683.289 1613558665.7610621
train: epoch 12, iter 1000, loss: 2.969569, top_1: 0.520078, top_k: 0.758750, samples/s: 684.807 1613558703.1438193
train: epoch 12, iter 1100, loss: 2.962548, top_1: 0.519531, top_k: 0.753867, samples/s: 682.576 1613558740.648834
train: epoch 12, iter 1200, loss: 2.977633, top_1: 0.519570, top_k: 0.757891, samples/s: 686.709 1613558777.928071
train: epoch 12, iter 1300, loss: 3.105906, top_1: 0.513594, top_k: 0.753711, samples/s: 684.914 1613558815.3049386
train: epoch 12, iter 1400, loss: 2.972262, top_1: 0.515547, top_k: 0.759336, samples/s: 685.369 1613558852.6570907
train: epoch 12, iter 1500, loss: 2.967619, top_1: 0.517695, top_k: 0.752344, samples/s: 685.320 1613558890.0119004
train: epoch 12, iter 1600, loss: 2.980937, top_1: 0.518125, top_k: 0.757344, samples/s: 687.108 1613558927.2695165
train: epoch 12, iter 1700, loss: 3.053294, top_1: 0.520781, top_k: 0.756250, samples/s: 683.533 1613558964.72203
train: epoch 12, iter 1800, loss: 3.116247, top_1: 0.517461, top_k: 0.756211, samples/s: 686.677 1613559002.0030456
train: epoch 12, iter 1900, loss: 3.127985, top_1: 0.516406, top_k: 0.755742, samples/s: 684.298 1613559039.4136815
train: epoch 12, iter 2000, loss: 2.949842, top_1: 0.519570, top_k: 0.761836, samples/s: 684.148 1613559076.832435
train: epoch 12, iter 2100, loss: 3.165158, top_1: 0.513945, top_k: 0.753008, samples/s: 683.731 1613559114.2740777
train: epoch 12, iter 2200, loss: 3.038053, top_1: 0.512031, top_k: 0.752500, samples/s: 684.447 1613559151.6765738
train: epoch 12, iter 2300, loss: 2.916564, top_1: 0.516445, top_k: 0.758437, samples/s: 683.634 1613559189.123448
train: epoch 12, iter 2400, loss: 3.174409, top_1: 0.518398, top_k: 0.753984, samples/s: 688.077 1613559226.328585
train: epoch 12, iter 2500, loss: 2.764698, top_1: 0.521055, top_k: 0.753008, samples/s: 685.420 1613559263.6780138
train: epoch 12, iter 2600, loss: 3.102850, top_1: 0.510859, top_k: 0.752031, samples/s: 685.175 1613559301.040703
train: epoch 12, iter 2700, loss: 2.986426, top_1: 0.520156, top_k: 0.758320, samples/s: 685.811 1613559338.368772
train: epoch 12, iter 2800, loss: 3.148419, top_1: 0.510625, top_k: 0.747070, samples/s: 685.511 1613559375.713229
train: epoch 12, iter 2900, loss: 3.123610, top_1: 0.516328, top_k: 0.753047, samples/s: 685.147 1613559413.077445
train: epoch 12, iter 3000, loss: 2.970968, top_1: 0.516250, top_k: 0.755742, samples/s: 685.132 1613559450.4425247
train: epoch 12, iter 3100, loss: 3.210689, top_1: 0.517500, top_k: 0.754453, samples/s: 686.488 1613559487.7337778
train: epoch 12, iter 3200, loss: 2.909755, top_1: 0.515469, top_k: 0.755234, samples/s: 686.523 1613559525.0230088
train: epoch 12, iter 3300, loss: 3.081049, top_1: 0.518867, top_k: 0.757773, samples/s: 684.646 1613559562.4146209
train: epoch 12, iter 3400, loss: 2.891903, top_1: 0.512031, top_k: 0.753555, samples/s: 684.591 1613559599.8092988
train: epoch 12, iter 3500, loss: 2.873245, top_1: 0.514844, top_k: 0.752773, samples/s: 686.067 1613559637.123432
train: epoch 12, iter 3600, loss: 3.080654, top_1: 0.511719, top_k: 0.756914, samples/s: 683.933 1613559674.5540216
train: epoch 12, iter 3700, loss: 3.087306, top_1: 0.516563, top_k: 0.755586, samples/s: 687.607 1613559711.784505
train: epoch 12, iter 3800, loss: 3.158856, top_1: 0.514570, top_k: 0.749883, samples/s: 684.583 1613559749.1796236
train: epoch 12, iter 3900, loss: 2.996454, top_1: 0.523359, top_k: 0.755273, samples/s: 683.713 1613559786.6221337
train: epoch 12, iter 4000, loss: 2.900670, top_1: 0.521523, top_k: 0.754297, samples/s: 684.785 1613559824.0062087
train: epoch 12, iter 4100, loss: 2.966322, top_1: 0.517734, top_k: 0.755078, samples/s: 683.989 1613559861.4337296
train: epoch 12, iter 4200, loss: 3.057058, top_1: 0.514023, top_k: 0.747852, samples/s: 684.716 1613559898.8214738
train: epoch 12, iter 4300, loss: 3.076149, top_1: 0.516523, top_k: 0.755313, samples/s: 683.983 1613559936.249349
train: epoch 12, iter 4400, loss: 3.000899, top_1: 0.515586, top_k: 0.757070, samples/s: 686.388 1613559973.5460567
train: epoch 12, iter 4500, loss: 2.844078, top_1: 0.517930, top_k: 0.759687, samples/s: 686.331 1613560010.8457801
train: epoch 12, iter 4600, loss: 3.145197, top_1: 0.517461, top_k: 0.754883, samples/s: 685.071 1613560048.2141218
train: epoch 12, iter 4700, loss: 3.061122, top_1: 0.511484, top_k: 0.752148, samples/s: 684.159 1613560085.6323771
train: epoch 12, iter 4800, loss: 3.159351, top_1: 0.511680, top_k: 0.756719, samples/s: 686.392 1613560122.9288213
train: epoch 12, iter 4900, loss: 3.075699, top_1: 0.520742, top_k: 0.762344, samples/s: 684.992 1613560160.3014567
train: epoch 12, iter 5000, loss: 3.041227, top_1: 0.518633, top_k: 0.751836, samples/s: 684.074 1613560197.724305
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_12.
validation: epoch 12, iter 195, top_1: 0.559135, top_k: 0.803506, samples/s: 2144.263 1613560222.1164227
train: epoch 13, iter 100, loss: 2.859236, top_1: 0.526953, top_k: 0.764961, samples/s: 701.977 1613560279.7899098
train: epoch 13, iter 200, loss: 3.082922, top_1: 0.520977, top_k: 0.760000, samples/s: 698.466 1613560316.4416802
train: epoch 13, iter 300, loss: 2.959042, top_1: 0.522305, top_k: 0.761523, samples/s: 683.604 1613560353.8904462
train: epoch 13, iter 400, loss: 2.963847, top_1: 0.521953, top_k: 0.758945, samples/s: 683.352 1613560391.3525403
train: epoch 13, iter 500, loss: 2.989545, top_1: 0.527656, top_k: 0.766758, samples/s: 683.895 1613560428.7853258
train: epoch 13, iter 600, loss: 2.877317, top_1: 0.533750, top_k: 0.767070, samples/s: 685.000 1613560466.1575131
train: epoch 13, iter 700, loss: 3.074305, top_1: 0.525039, top_k: 0.761172, samples/s: 682.395 1613560503.6724753
train: epoch 13, iter 800, loss: 2.967090, top_1: 0.527344, top_k: 0.764687, samples/s: 684.355 1613560541.0798986
train: epoch 13, iter 900, loss: 3.152655, top_1: 0.520781, top_k: 0.762109, samples/s: 683.409 1613560578.5392122
train: epoch 13, iter 1000, loss: 2.862065, top_1: 0.519062, top_k: 0.758555, samples/s: 684.535 1613560615.936754
train: epoch 13, iter 1100, loss: 2.739960, top_1: 0.520430, top_k: 0.756016, samples/s: 682.460 1613560653.4480984
train: epoch 13, iter 1200, loss: 2.878375, top_1: 0.528164, top_k: 0.760898, samples/s: 685.007 1613560690.8200765
train: epoch 13, iter 1300, loss: 2.914296, top_1: 0.522344, top_k: 0.760508, samples/s: 682.139 1613560728.3490562
train: epoch 13, iter 1400, loss: 3.100076, top_1: 0.522539, top_k: 0.760078, samples/s: 682.892 1613560765.8367155
train: epoch 13, iter 1500, loss: 3.021355, top_1: 0.522695, top_k: 0.758008, samples/s: 685.476 1613560803.1829915
train: epoch 13, iter 1600, loss: 3.096312, top_1: 0.526602, top_k: 0.763164, samples/s: 682.048 1613560840.716995
train: epoch 13, iter 1700, loss: 3.131122, top_1: 0.527227, top_k: 0.758164, samples/s: 685.049 1613560878.0864713
train: epoch 13, iter 1800, loss: 3.148123, top_1: 0.521719, top_k: 0.757578, samples/s: 684.758 1613560915.4720454
train: epoch 13, iter 1900, loss: 3.092079, top_1: 0.518945, top_k: 0.757773, samples/s: 681.754 1613560953.0222242
train: epoch 13, iter 2000, loss: 2.904949, top_1: 0.516250, top_k: 0.756250, samples/s: 683.748 1613560990.4628985
train: epoch 13, iter 2100, loss: 2.839635, top_1: 0.518477, top_k: 0.756875, samples/s: 684.328 1613561027.8717496
train: epoch 13, iter 2200, loss: 2.745968, top_1: 0.524062, top_k: 0.760742, samples/s: 685.262 1613561065.2298152
train: epoch 13, iter 2300, loss: 3.079307, top_1: 0.520547, top_k: 0.757656, samples/s: 681.608 1613561102.7880652
train: epoch 13, iter 2400, loss: 2.842632, top_1: 0.520977, top_k: 0.760195, samples/s: 684.918 1613561140.1648057
train: epoch 13, iter 2500, loss: 3.133618, top_1: 0.525430, top_k: 0.762070, samples/s: 686.214 1613561177.470906
train: epoch 13, iter 2600, loss: 2.817739, top_1: 0.521133, top_k: 0.759258, samples/s: 682.600 1613561214.9746387
train: epoch 13, iter 2700, loss: 2.930962, top_1: 0.517422, top_k: 0.761445, samples/s: 682.142 1613561252.5034387
train: epoch 13, iter 2800, loss: 2.915737, top_1: 0.525352, top_k: 0.760234, samples/s: 683.000 1613561289.9850912
train: epoch 13, iter 2900, loss: 3.076729, top_1: 0.517305, top_k: 0.755859, samples/s: 683.264 1613561327.4522722
train: epoch 13, iter 3000, loss: 3.142966, top_1: 0.515117, top_k: 0.751484, samples/s: 684.884 1613561364.830961
train: epoch 13, iter 3100, loss: 2.825990, top_1: 0.522852, top_k: 0.761328, samples/s: 685.598 1613561402.17061
train: epoch 13, iter 3200, loss: 3.094000, top_1: 0.518750, top_k: 0.760469, samples/s: 682.133 1613561439.699966
train: epoch 13, iter 3300, loss: 2.998543, top_1: 0.521563, top_k: 0.759414, samples/s: 685.283 1613561477.056783
train: epoch 13, iter 3400, loss: 3.019437, top_1: 0.515039, top_k: 0.752227, samples/s: 683.840 1613561514.4923942
train: epoch 13, iter 3500, loss: 2.961285, top_1: 0.521563, top_k: 0.761328, samples/s: 685.824 1613561551.819828
train: epoch 13, iter 3600, loss: 2.920771, top_1: 0.519258, top_k: 0.757695, samples/s: 682.616 1613561589.3226001
train: epoch 13, iter 3700, loss: 2.904530, top_1: 0.516328, top_k: 0.751641, samples/s: 686.307 1613561626.6237087
train: epoch 13, iter 3800, loss: 3.069264, top_1: 0.520273, top_k: 0.757344, samples/s: 682.172 1613561664.1508672
train: epoch 13, iter 3900, loss: 2.980130, top_1: 0.518203, top_k: 0.755039, samples/s: 687.643 1613561701.3795373
train: epoch 13, iter 4000, loss: 2.889038, top_1: 0.523398, top_k: 0.758750, samples/s: 682.412 1613561738.8934937
train: epoch 13, iter 4100, loss: 2.913964, top_1: 0.520195, top_k: 0.754336, samples/s: 686.582 1613561776.1796837
train: epoch 13, iter 4200, loss: 2.951737, top_1: 0.527422, top_k: 0.760234, samples/s: 682.170 1613561813.7070246
train: epoch 13, iter 4300, loss: 2.951756, top_1: 0.518945, top_k: 0.756289, samples/s: 681.832 1613561851.2529273
train: epoch 13, iter 4400, loss: 3.010792, top_1: 0.524766, top_k: 0.757773, samples/s: 683.866 1613561888.6871805
train: epoch 13, iter 4500, loss: 3.128952, top_1: 0.526133, top_k: 0.759727, samples/s: 682.245 1613561926.2103088
train: epoch 13, iter 4600, loss: 3.013838, top_1: 0.515078, top_k: 0.755508, samples/s: 685.807 1613561963.5386233
train: epoch 13, iter 4700, loss: 2.987241, top_1: 0.522969, top_k: 0.757422, samples/s: 682.770 1613562001.0329926
train: epoch 13, iter 4800, loss: 2.977371, top_1: 0.522891, top_k: 0.760000, samples/s: 684.340 1613562038.4413092
train: epoch 13, iter 4900, loss: 3.024721, top_1: 0.520664, top_k: 0.759844, samples/s: 683.977 1613562075.8694363
train: epoch 13, iter 5000, loss: 3.035311, top_1: 0.526680, top_k: 0.759062, samples/s: 684.848 1613562113.250032
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_13.
validation: epoch 13, iter 195, top_1: 0.575521, top_k: 0.817388, samples/s: 2161.560 1613562137.476091
train: epoch 14, iter 100, loss: 2.967652, top_1: 0.540117, top_k: 0.771211, samples/s: 703.735 1613562194.9038787
train: epoch 14, iter 200, loss: 2.960329, top_1: 0.524258, top_k: 0.761563, samples/s: 697.196 1613562231.6226425
train: epoch 14, iter 300, loss: 3.190016, top_1: 0.527031, top_k: 0.764414, samples/s: 684.793 1613562269.0058396
train: epoch 14, iter 400, loss: 2.876201, top_1: 0.528750, top_k: 0.766484, samples/s: 685.294 1613562306.3622253
train: epoch 14, iter 500, loss: 3.043537, top_1: 0.534023, top_k: 0.766094, samples/s: 683.453 1613562343.8190494
train: epoch 14, iter 600, loss: 2.980336, top_1: 0.532930, top_k: 0.767188, samples/s: 683.619 1613562381.2668374
train: epoch 14, iter 700, loss: 3.228043, top_1: 0.533242, top_k: 0.763906, samples/s: 682.427 1613562418.7799926
train: epoch 14, iter 800, loss: 3.057246, top_1: 0.524961, top_k: 0.759492, samples/s: 682.256 1613562456.3025079
train: epoch 14, iter 900, loss: 2.870657, top_1: 0.527305, top_k: 0.762852, samples/s: 682.723 1613562493.7994812
train: epoch 14, iter 1000, loss: 3.016641, top_1: 0.526328, top_k: 0.763242, samples/s: 682.821 1613562531.2908907
train: epoch 14, iter 1100, loss: 3.009814, top_1: 0.527813, top_k: 0.766094, samples/s: 683.684 1613562568.7352002
train: epoch 14, iter 1200, loss: 2.984757, top_1: 0.526367, top_k: 0.766094, samples/s: 682.944 1613562606.2198515
train: epoch 14, iter 1300, loss: 2.993638, top_1: 0.528320, top_k: 0.762852, samples/s: 685.376 1613562643.5717916
train: epoch 14, iter 1400, loss: 2.973772, top_1: 0.522344, top_k: 0.762148, samples/s: 685.200 1613562680.932989
train: epoch 14, iter 1500, loss: 2.968750, top_1: 0.524727, top_k: 0.763750, samples/s: 682.500 1613562718.442163
train: epoch 14, iter 1600, loss: 2.976046, top_1: 0.527109, top_k: 0.762266, samples/s: 685.340 1613562755.7959633
train: epoch 14, iter 1700, loss: 2.985757, top_1: 0.529727, top_k: 0.764492, samples/s: 684.969 1613562793.1699476
train: epoch 14, iter 1800, loss: 2.950052, top_1: 0.523867, top_k: 0.759687, samples/s: 681.690 1613562830.7235992
train: epoch 14, iter 1900, loss: 3.252589, top_1: 0.525820, top_k: 0.759766, samples/s: 687.455 1613562867.962405
train: epoch 14, iter 2000, loss: 2.917732, top_1: 0.529805, top_k: 0.767500, samples/s: 681.796 1613562905.5103707
train: epoch 14, iter 2100, loss: 3.049260, top_1: 0.528750, top_k: 0.760156, samples/s: 682.686 1613562943.009299
train: epoch 14, iter 2200, loss: 2.845002, top_1: 0.528125, top_k: 0.761172, samples/s: 685.475 1613562980.3555753
train: epoch 14, iter 2300, loss: 2.816996, top_1: 0.526836, top_k: 0.763164, samples/s: 686.118 1613563017.6670368
train: epoch 14, iter 2400, loss: 3.164969, top_1: 0.523906, top_k: 0.761953, samples/s: 682.576 1613563055.1720052
train: epoch 14, iter 2500, loss: 2.957554, top_1: 0.524727, top_k: 0.762773, samples/s: 684.371 1613563092.5786688
train: epoch 14, iter 2600, loss: 2.982345, top_1: 0.530508, top_k: 0.768086, samples/s: 684.421 1613563129.9824576
train: epoch 14, iter 2700, loss: 2.829980, top_1: 0.524766, top_k: 0.761172, samples/s: 685.780 1613563167.3122058
train: epoch 14, iter 2800, loss: 2.953629, top_1: 0.526055, top_k: 0.762695, samples/s: 684.706 1613563204.7005563
train: epoch 14, iter 2900, loss: 2.921254, top_1: 0.525859, top_k: 0.760391, samples/s: 686.360 1613563241.9987698
train: epoch 14, iter 3000, loss: 2.999697, top_1: 0.518164, top_k: 0.759180, samples/s: 683.114 1613563279.4741924
train: epoch 14, iter 3100, loss: 2.890249, top_1: 0.525156, top_k: 0.763398, samples/s: 683.038 1613563316.9537506
train: epoch 14, iter 3200, loss: 2.911025, top_1: 0.524102, top_k: 0.761172, samples/s: 684.350 1613563354.3615716
train: epoch 14, iter 3300, loss: 2.973618, top_1: 0.526523, top_k: 0.763867, samples/s: 686.286 1613563391.663753
train: epoch 14, iter 3400, loss: 2.959439, top_1: 0.528828, top_k: 0.763125, samples/s: 683.880 1613563429.09729
train: epoch 14, iter 3500, loss: 2.876796, top_1: 0.529531, top_k: 0.766602, samples/s: 685.900 1613563466.4205408
train: epoch 14, iter 3600, loss: 2.884019, top_1: 0.523164, top_k: 0.756875, samples/s: 683.239 1613563503.8891525
train: epoch 14, iter 3700, loss: 2.936772, top_1: 0.528359, top_k: 0.761797, samples/s: 685.731 1613563541.2215548
train: epoch 14, iter 3800, loss: 3.001775, top_1: 0.524648, top_k: 0.760859, samples/s: 684.764 1613563578.606662
train: epoch 14, iter 3900, loss: 2.860576, top_1: 0.517773, top_k: 0.752070, samples/s: 683.702 1613563616.049965
train: epoch 14, iter 4000, loss: 3.016006, top_1: 0.524492, top_k: 0.760703, samples/s: 683.220 1613563653.5194824
train: epoch 14, iter 4100, loss: 2.975371, top_1: 0.522578, top_k: 0.760508, samples/s: 684.199 1613563690.9355574
train: epoch 14, iter 4200, loss: 3.016089, top_1: 0.527461, top_k: 0.762305, samples/s: 682.943 1613563728.4204297
train: epoch 14, iter 4300, loss: 3.130306, top_1: 0.524844, top_k: 0.762188, samples/s: 684.908 1613563765.7977111
train: epoch 14, iter 4400, loss: 3.108739, top_1: 0.519844, top_k: 0.759727, samples/s: 686.137 1613563803.1080384
train: epoch 14, iter 4500, loss: 3.077952, top_1: 0.528438, top_k: 0.762813, samples/s: 684.739 1613563840.4945326
train: epoch 14, iter 4600, loss: 2.857469, top_1: 0.524297, top_k: 0.760469, samples/s: 684.663 1613563877.8852026
train: epoch 14, iter 4700, loss: 2.970577, top_1: 0.518203, top_k: 0.753555, samples/s: 686.725 1613563915.1635442
train: epoch 14, iter 4800, loss: 3.020762, top_1: 0.528047, top_k: 0.761680, samples/s: 683.764 1613563952.6033244
train: epoch 14, iter 4900, loss: 2.884392, top_1: 0.526914, top_k: 0.761602, samples/s: 686.509 1613563989.8934414
train: epoch 14, iter 5000, loss: 3.020144, top_1: 0.523516, top_k: 0.759531, samples/s: 683.520 1613564027.3465087
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_14.
validation: epoch 14, iter 195, top_1: 0.570373, top_k: 0.813902, samples/s: 2182.901 1613564051.3368123
train: epoch 15, iter 100, loss: 2.823339, top_1: 0.535273, top_k: 0.768711, samples/s: 702.302 1613564108.884757
train: epoch 15, iter 200, loss: 2.926621, top_1: 0.526563, top_k: 0.765898, samples/s: 698.394 1613564145.5405226
train: epoch 15, iter 300, loss: 3.111952, top_1: 0.530078, top_k: 0.768984, samples/s: 684.195 1613564182.9565017
train: epoch 15, iter 400, loss: 2.991530, top_1: 0.533047, top_k: 0.768398, samples/s: 684.080 1613564220.3789692
train: epoch 15, iter 500, loss: 2.700341, top_1: 0.536602, top_k: 0.773398, samples/s: 682.643 1613564257.8803663
train: epoch 15, iter 600, loss: 3.036546, top_1: 0.530898, top_k: 0.766992, samples/s: 682.800 1613564295.3729475
train: epoch 15, iter 700, loss: 2.880045, top_1: 0.533398, top_k: 0.767617, samples/s: 685.516 1613564332.717121
train: epoch 15, iter 800, loss: 2.911862, top_1: 0.527539, top_k: 0.766680, samples/s: 682.834 1613564370.2079182
train: epoch 15, iter 900, loss: 2.882831, top_1: 0.533594, top_k: 0.766680, samples/s: 685.484 1613564407.553864
train: epoch 15, iter 1000, loss: 3.165674, top_1: 0.531445, top_k: 0.766680, samples/s: 684.881 1613564444.9325514
train: epoch 15, iter 1100, loss: 3.014528, top_1: 0.538398, top_k: 0.771445, samples/s: 682.258 1613564482.4550204
train: epoch 15, iter 1200, loss: 3.024848, top_1: 0.527891, top_k: 0.764961, samples/s: 687.580 1613564519.687009
train: epoch 15, iter 1300, loss: 3.070325, top_1: 0.532617, top_k: 0.766758, samples/s: 681.405 1613564557.2564404
train: epoch 15, iter 1400, loss: 2.900286, top_1: 0.533281, top_k: 0.772461, samples/s: 685.266 1613564594.6142778
train: epoch 15, iter 1500, loss: 2.937040, top_1: 0.533203, top_k: 0.770977, samples/s: 684.324 1613564632.0235012
train: epoch 15, iter 1600, loss: 3.035526, top_1: 0.533477, top_k: 0.768906, samples/s: 684.355 1613564669.430977
train: epoch 15, iter 1700, loss: 3.007479, top_1: 0.528594, top_k: 0.765781, samples/s: 686.560 1613564706.718366
train: epoch 15, iter 1800, loss: 3.072176, top_1: 0.523398, top_k: 0.759922, samples/s: 684.219 1613564744.1332397
train: epoch 15, iter 1900, loss: 3.137166, top_1: 0.522734, top_k: 0.760898, samples/s: 684.157 1613564781.551625
train: epoch 15, iter 2000, loss: 2.825641, top_1: 0.530000, top_k: 0.764414, samples/s: 685.458 1613564818.8989134
train: epoch 15, iter 2100, loss: 3.013176, top_1: 0.535312, top_k: 0.769453, samples/s: 684.148 1613564856.3177302
train: epoch 15, iter 2200, loss: 2.970744, top_1: 0.530000, top_k: 0.762930, samples/s: 683.787 1613564893.7561646
train: epoch 15, iter 2300, loss: 2.852908, top_1: 0.526055, top_k: 0.763711, samples/s: 684.870 1613564931.1356122
train: epoch 15, iter 2400, loss: 2.913063, top_1: 0.528086, top_k: 0.763281, samples/s: 682.953 1613564968.6198967
train: epoch 15, iter 2500, loss: 3.029358, top_1: 0.528438, top_k: 0.766367, samples/s: 684.246 1613565006.0332367
train: epoch 15, iter 2600, loss: 2.989766, top_1: 0.529883, top_k: 0.762305, samples/s: 682.384 1613565043.5488482
train: epoch 15, iter 2700, loss: 2.992572, top_1: 0.530977, top_k: 0.765898, samples/s: 684.891 1613565080.9269862
train: epoch 15, iter 2800, loss: 2.703302, top_1: 0.528750, top_k: 0.767461, samples/s: 683.355 1613565118.3892248
train: epoch 15, iter 2900, loss: 3.073369, top_1: 0.526992, top_k: 0.761875, samples/s: 684.134 1613565155.8088381
train: epoch 15, iter 3000, loss: 2.792888, top_1: 0.531797, top_k: 0.762656, samples/s: 684.282 1613565193.220322
train: epoch 15, iter 3100, loss: 2.995645, top_1: 0.530391, top_k: 0.767109, samples/s: 683.935 1613565230.6508222
train: epoch 15, iter 3200, loss: 2.980369, top_1: 0.531602, top_k: 0.764453, samples/s: 683.354 1613565268.1131165
train: epoch 15, iter 3300, loss: 2.972483, top_1: 0.534102, top_k: 0.767969, samples/s: 685.051 1613565305.4825835
train: epoch 15, iter 3400, loss: 2.995511, top_1: 0.527227, top_k: 0.762773, samples/s: 684.531 1613565342.88047
train: epoch 15, iter 3500, loss: 3.017955, top_1: 0.524687, top_k: 0.765664, samples/s: 687.542 1613565380.1145964
train: epoch 15, iter 3600, loss: 2.765726, top_1: 0.530078, top_k: 0.763437, samples/s: 684.074 1613565417.5374553
train: epoch 15, iter 3700, loss: 2.899898, top_1: 0.525781, top_k: 0.760703, samples/s: 687.841 1613565454.7552645
train: epoch 15, iter 3800, loss: 3.038774, top_1: 0.516641, top_k: 0.758477, samples/s: 682.452 1613565492.267014
train: epoch 15, iter 3900, loss: 2.941076, top_1: 0.526328, top_k: 0.766133, samples/s: 684.574 1613565529.6626604
train: epoch 15, iter 4000, loss: 2.958238, top_1: 0.524531, top_k: 0.759492, samples/s: 684.069 1613565567.0857973
train: epoch 15, iter 4100, loss: 3.004083, top_1: 0.527695, top_k: 0.763789, samples/s: 685.331 1613565604.4400167
train: epoch 15, iter 4200, loss: 3.016358, top_1: 0.529687, top_k: 0.760977, samples/s: 685.618 1613565641.7785175
train: epoch 15, iter 4300, loss: 2.900249, top_1: 0.524961, top_k: 0.761641, samples/s: 684.955 1613565679.1532807
train: epoch 15, iter 4400, loss: 3.169636, top_1: 0.526953, top_k: 0.764766, samples/s: 684.805 1613565716.5362835
train: epoch 15, iter 4500, loss: 2.819012, top_1: 0.531211, top_k: 0.768047, samples/s: 685.508 1613565753.8807158
train: epoch 15, iter 4600, loss: 3.073060, top_1: 0.528750, top_k: 0.764062, samples/s: 681.431 1613565791.4488366
train: epoch 15, iter 4700, loss: 2.952991, top_1: 0.527813, top_k: 0.763984, samples/s: 684.886 1613565828.8273518
train: epoch 15, iter 4800, loss: 3.044386, top_1: 0.529570, top_k: 0.766602, samples/s: 684.870 1613565866.2066426
train: epoch 15, iter 4900, loss: 2.849933, top_1: 0.521250, top_k: 0.759961, samples/s: 685.634 1613565903.5444164
train: epoch 15, iter 5000, loss: 2.689002, top_1: 0.525195, top_k: 0.762188, samples/s: 685.867 1613565940.869381
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_15.
validation: epoch 15, iter 195, top_1: 0.560377, top_k: 0.806370, samples/s: 2172.043 1613565964.9689136
train: epoch 16, iter 100, loss: 2.730620, top_1: 0.545742, top_k: 0.778984, samples/s: 701.539 1613566022.836559
train: epoch 16, iter 200, loss: 3.007681, top_1: 0.542070, top_k: 0.774883, samples/s: 698.431 1613566059.4903986
train: epoch 16, iter 300, loss: 3.105233, top_1: 0.541758, top_k: 0.774531, samples/s: 683.380 1613566096.9509614
train: epoch 16, iter 400, loss: 3.106955, top_1: 0.536992, top_k: 0.772734, samples/s: 681.400 1613566134.5205913
train: epoch 16, iter 500, loss: 2.889360, top_1: 0.528789, top_k: 0.768906, samples/s: 685.500 1613566171.8657267
train: epoch 16, iter 600, loss: 2.860297, top_1: 0.537031, top_k: 0.771797, samples/s: 682.545 1613566209.372467
train: epoch 16, iter 700, loss: 2.796744, top_1: 0.535742, top_k: 0.766680, samples/s: 683.945 1613566246.8022656
train: epoch 16, iter 800, loss: 2.816578, top_1: 0.531250, top_k: 0.767109, samples/s: 682.799 1613566284.2950094
train: epoch 16, iter 900, loss: 3.096565, top_1: 0.544687, top_k: 0.772813, samples/s: 682.895 1613566321.7824397
train: epoch 16, iter 1000, loss: 2.853913, top_1: 0.532852, top_k: 0.769961, samples/s: 684.591 1613566359.1770687
train: epoch 16, iter 1100, loss: 2.615241, top_1: 0.538438, top_k: 0.772461, samples/s: 684.796 1613566396.5604959
train: epoch 16, iter 1200, loss: 2.824599, top_1: 0.537773, top_k: 0.775312, samples/s: 682.490 1613566434.0701435
train: epoch 16, iter 1300, loss: 2.858485, top_1: 0.538945, top_k: 0.771641, samples/s: 685.792 1613566471.3992188
train: epoch 16, iter 1400, loss: 2.885883, top_1: 0.533906, top_k: 0.767461, samples/s: 684.360 1613566508.8064578
train: epoch 16, iter 1500, loss: 2.779990, top_1: 0.537930, top_k: 0.769570, samples/s: 685.366 1613566546.1587481
train: epoch 16, iter 1600, loss: 3.073579, top_1: 0.532656, top_k: 0.771484, samples/s: 683.980 1613566583.5867884
train: epoch 16, iter 1700, loss: 2.841055, top_1: 0.528477, top_k: 0.768398, samples/s: 684.389 1613566620.9923663
train: epoch 16, iter 1800, loss: 2.928310, top_1: 0.527969, top_k: 0.762383, samples/s: 685.361 1613566658.3449526
train: epoch 16, iter 1900, loss: 2.975234, top_1: 0.532305, top_k: 0.762109, samples/s: 684.298 1613566695.7555542
train: epoch 16, iter 2000, loss: 2.888035, top_1: 0.528828, top_k: 0.768633, samples/s: 683.236 1613566733.2242002
train: epoch 16, iter 2100, loss: 3.093263, top_1: 0.530664, top_k: 0.768047, samples/s: 683.843 1613566770.6597364
train: epoch 16, iter 2200, loss: 2.956574, top_1: 0.537461, top_k: 0.771367, samples/s: 685.305 1613566808.0154245
train: epoch 16, iter 2300, loss: 2.855261, top_1: 0.526953, top_k: 0.766563, samples/s: 686.169 1613566845.324011
train: epoch 16, iter 2400, loss: 2.912371, top_1: 0.532852, top_k: 0.770039, samples/s: 685.950 1613566882.6444452
train: epoch 16, iter 2500, loss: 3.023551, top_1: 0.529375, top_k: 0.765977, samples/s: 685.760 1613566919.9753907
train: epoch 16, iter 2600, loss: 2.895895, top_1: 0.532188, top_k: 0.765547, samples/s: 687.137 1613566957.2313523
train: epoch 16, iter 2700, loss: 2.909238, top_1: 0.529023, top_k: 0.760742, samples/s: 684.800 1613566994.6145175
train: epoch 16, iter 2800, loss: 3.066735, top_1: 0.522930, top_k: 0.764375, samples/s: 683.586 1613567032.0641854
train: epoch 16, iter 2900, loss: 2.975778, top_1: 0.530000, top_k: 0.766016, samples/s: 684.343 1613567069.4723136
train: epoch 16, iter 3000, loss: 2.775127, top_1: 0.533594, top_k: 0.768359, samples/s: 684.089 1613567106.8943198
train: epoch 16, iter 3100, loss: 3.008385, top_1: 0.531953, top_k: 0.766992, samples/s: 683.990 1613567144.321788
train: epoch 16, iter 3200, loss: 2.920940, top_1: 0.539336, top_k: 0.773047, samples/s: 683.811 1613567181.7589374
train: epoch 16, iter 3300, loss: 2.861363, top_1: 0.526953, top_k: 0.763906, samples/s: 683.789 1613567219.1974173
train: epoch 16, iter 3400, loss: 3.056891, top_1: 0.536133, top_k: 0.768555, samples/s: 684.206 1613567256.6130455
train: epoch 16, iter 3500, loss: 3.050476, top_1: 0.532617, top_k: 0.768984, samples/s: 683.725 1613567294.0550058
train: epoch 16, iter 3600, loss: 2.927831, top_1: 0.529648, top_k: 0.766406, samples/s: 683.988 1613567331.4825547
train: epoch 16, iter 3700, loss: 2.961303, top_1: 0.529687, top_k: 0.763750, samples/s: 686.946 1613567368.7490196
train: epoch 16, iter 3800, loss: 3.021220, top_1: 0.529844, top_k: 0.765781, samples/s: 683.065 1613567406.227176
train: epoch 16, iter 3900, loss: 3.063479, top_1: 0.533945, top_k: 0.762422, samples/s: 682.650 1613567443.727998
train: epoch 16, iter 4000, loss: 2.867833, top_1: 0.534453, top_k: 0.770117, samples/s: 685.644 1613567481.065226
train: epoch 16, iter 4100, loss: 2.828982, top_1: 0.528398, top_k: 0.766992, samples/s: 684.817 1613567518.4474828
train: epoch 16, iter 4200, loss: 2.853898, top_1: 0.528750, top_k: 0.767578, samples/s: 682.297 1613567555.9678228
train: epoch 16, iter 4300, loss: 3.186665, top_1: 0.527617, top_k: 0.764766, samples/s: 684.704 1613567593.35619
train: epoch 16, iter 4400, loss: 2.976581, top_1: 0.534180, top_k: 0.766133, samples/s: 685.919 1613567630.6784434
train: epoch 16, iter 4500, loss: 2.853894, top_1: 0.537109, top_k: 0.768359, samples/s: 681.979 1613567668.2164137
train: epoch 16, iter 4600, loss: 2.937467, top_1: 0.531719, top_k: 0.766875, samples/s: 684.864 1613567705.5959747
train: epoch 16, iter 4700, loss: 3.023808, top_1: 0.531328, top_k: 0.763320, samples/s: 684.399 1613567743.0010424
train: epoch 16, iter 4800, loss: 2.994132, top_1: 0.526406, top_k: 0.762500, samples/s: 682.374 1613567780.517123
train: epoch 16, iter 4900, loss: 2.929694, top_1: 0.530312, top_k: 0.768789, samples/s: 685.919 1613567817.8392372
train: epoch 16, iter 5000, loss: 2.913183, top_1: 0.530781, top_k: 0.763516, samples/s: 682.695 1613567855.337762
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_16.
validation: epoch 16, iter 195, top_1: 0.589002, top_k: 0.824299, samples/s: 2169.922 1613567879.5075998
train: epoch 17, iter 100, loss: 2.788434, top_1: 0.541016, top_k: 0.777344, samples/s: 703.145 1613567936.8098636
train: epoch 17, iter 200, loss: 3.028343, top_1: 0.541992, top_k: 0.774961, samples/s: 699.834 1613567973.3901594
train: epoch 17, iter 300, loss: 2.713006, top_1: 0.541992, top_k: 0.775312, samples/s: 685.791 1613568010.7191095
train: epoch 17, iter 400, loss: 3.077070, top_1: 0.539453, top_k: 0.772109, samples/s: 685.796 1613568048.047985
train: epoch 17, iter 500, loss: 2.966187, top_1: 0.541758, top_k: 0.771016, samples/s: 681.012 1613568085.6390202
train: epoch 17, iter 600, loss: 2.803658, top_1: 0.536094, top_k: 0.770586, samples/s: 685.090 1613568123.0064268
train: epoch 17, iter 700, loss: 2.979487, top_1: 0.534609, top_k: 0.767656, samples/s: 686.345 1613568160.3054194
train: epoch 17, iter 800, loss: 2.884369, top_1: 0.535664, top_k: 0.772852, samples/s: 684.520 1613568197.7038748
train: epoch 17, iter 900, loss: 2.980364, top_1: 0.533125, top_k: 0.770625, samples/s: 686.090 1613568235.016761
train: epoch 17, iter 1000, loss: 3.030874, top_1: 0.538164, top_k: 0.771680, samples/s: 683.760 1613568272.4567802
train: epoch 17, iter 1100, loss: 2.755750, top_1: 0.538945, top_k: 0.772891, samples/s: 684.425 1613568309.8604476
train: epoch 17, iter 1200, loss: 3.044904, top_1: 0.535234, top_k: 0.768164, samples/s: 686.537 1613568347.1490526
train: epoch 17, iter 1300, loss: 2.994395, top_1: 0.534727, top_k: 0.768984, samples/s: 683.001 1613568384.6306763
train: epoch 17, iter 1400, loss: 2.838951, top_1: 0.534336, top_k: 0.769023, samples/s: 685.604 1613568421.969981
train: epoch 17, iter 1500, loss: 3.001385, top_1: 0.530352, top_k: 0.766016, samples/s: 684.606 1613568459.3636923
train: epoch 17, iter 1600, loss: 3.094065, top_1: 0.540937, top_k: 0.773008, samples/s: 684.917 1613568496.7405026
train: epoch 17, iter 1700, loss: 2.958895, top_1: 0.536914, top_k: 0.769141, samples/s: 683.790 1613568534.179049
train: epoch 17, iter 1800, loss: 3.060514, top_1: 0.535937, top_k: 0.768711, samples/s: 684.433 1613568571.5821247
train: epoch 17, iter 1900, loss: 2.922566, top_1: 0.532031, top_k: 0.769102, samples/s: 684.179 1613568608.9993198
train: epoch 17, iter 2000, loss: 3.110854, top_1: 0.533516, top_k: 0.767813, samples/s: 684.438 1613568646.4022899
train: epoch 17, iter 2100, loss: 2.959438, top_1: 0.537578, top_k: 0.767070, samples/s: 684.303 1613568683.812621
train: epoch 17, iter 2200, loss: 2.886503, top_1: 0.531641, top_k: 0.764609, samples/s: 685.261 1613568721.1706176
train: epoch 17, iter 2300, loss: 3.027214, top_1: 0.539492, top_k: 0.765312, samples/s: 684.337 1613568758.5790854
train: epoch 17, iter 2400, loss: 2.877177, top_1: 0.540195, top_k: 0.772227, samples/s: 685.966 1613568795.8986278
train: epoch 17, iter 2500, loss: 2.782796, top_1: 0.536992, top_k: 0.771836, samples/s: 686.851 1613568833.1702995
train: epoch 17, iter 2600, loss: 2.963688, top_1: 0.536016, top_k: 0.768242, samples/s: 685.063 1613568870.5390892
train: epoch 17, iter 2700, loss: 2.978697, top_1: 0.533125, top_k: 0.769648, samples/s: 683.144 1613568908.0129008
train: epoch 17, iter 2800, loss: 2.951045, top_1: 0.534766, top_k: 0.770000, samples/s: 685.027 1613568945.3837223
train: epoch 17, iter 2900, loss: 2.960108, top_1: 0.534844, top_k: 0.768477, samples/s: 686.534 1613568982.6725001
train: epoch 17, iter 3000, loss: 3.042007, top_1: 0.529297, top_k: 0.769180, samples/s: 685.196 1613569020.0340538
train: epoch 17, iter 3100, loss: 2.970299, top_1: 0.529180, top_k: 0.767695, samples/s: 682.849 1613569057.5239801
train: epoch 17, iter 3200, loss: 3.117954, top_1: 0.527695, top_k: 0.763984, samples/s: 685.259 1613569094.8821025
train: epoch 17, iter 3300, loss: 2.767205, top_1: 0.538789, top_k: 0.774766, samples/s: 685.855 1613569132.2077746
train: epoch 17, iter 3400, loss: 2.891976, top_1: 0.535859, top_k: 0.768633, samples/s: 683.782 1613569169.6466985
train: epoch 17, iter 3500, loss: 2.817795, top_1: 0.537656, top_k: 0.769414, samples/s: 686.437 1613569206.9406812
train: epoch 17, iter 3600, loss: 2.884850, top_1: 0.531250, top_k: 0.771328, samples/s: 684.125 1613569244.3606591
train: epoch 17, iter 3700, loss: 2.916000, top_1: 0.539258, top_k: 0.772930, samples/s: 683.439 1613569281.818264
train: epoch 17, iter 3800, loss: 2.956784, top_1: 0.533086, top_k: 0.768984, samples/s: 686.607 1613569319.1031508
train: epoch 17, iter 3900, loss: 3.012177, top_1: 0.534258, top_k: 0.766406, samples/s: 684.317 1613569356.512672
train: epoch 17, iter 4000, loss: 2.699616, top_1: 0.531953, top_k: 0.766875, samples/s: 684.020 1613569393.9385636
train: epoch 17, iter 4100, loss: 2.826641, top_1: 0.533438, top_k: 0.770234, samples/s: 684.408 1613569431.3431444
train: epoch 17, iter 4200, loss: 2.936838, top_1: 0.531445, top_k: 0.764687, samples/s: 686.703 1613569468.6227098
train: epoch 17, iter 4300, loss: 2.981824, top_1: 0.539687, top_k: 0.774102, samples/s: 681.653 1613569506.1784234
train: epoch 17, iter 4400, loss: 3.008183, top_1: 0.531758, top_k: 0.768711, samples/s: 685.612 1613569543.5173578
train: epoch 17, iter 4500, loss: 2.886043, top_1: 0.541602, top_k: 0.771641, samples/s: 689.717 1613569580.634038
train: epoch 17, iter 4600, loss: 2.961656, top_1: 0.532773, top_k: 0.768633, samples/s: 685.959 1613569617.954038
train: epoch 17, iter 4700, loss: 3.022167, top_1: 0.533633, top_k: 0.768633, samples/s: 685.164 1613569655.3174174
train: epoch 17, iter 4800, loss: 3.003045, top_1: 0.534766, top_k: 0.767930, samples/s: 685.848 1613569692.643436
train: epoch 17, iter 4900, loss: 2.939925, top_1: 0.535000, top_k: 0.769648, samples/s: 683.308 1613569730.1082149
train: epoch 17, iter 5000, loss: 3.036412, top_1: 0.532539, top_k: 0.770781, samples/s: 685.614 1613569767.4470053
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_17.
validation: epoch 17, iter 195, top_1: 0.585857, top_k: 0.824760, samples/s: 2147.877 1613569791.7752864
train: epoch 18, iter 100, loss: 2.825971, top_1: 0.552578, top_k: 0.781719, samples/s: 703.350 1613569849.4984355
train: epoch 18, iter 200, loss: 2.939780, top_1: 0.542305, top_k: 0.777266, samples/s: 698.916 1613569886.1269722
train: epoch 18, iter 300, loss: 2.975232, top_1: 0.538047, top_k: 0.775742, samples/s: 686.383 1613569923.4236643
train: epoch 18, iter 400, loss: 2.896780, top_1: 0.543828, top_k: 0.776992, samples/s: 683.252 1613569960.891559
train: epoch 18, iter 500, loss: 3.015924, top_1: 0.541367, top_k: 0.771445, samples/s: 683.755 1613569998.3318725
train: epoch 18, iter 600, loss: 2.855349, top_1: 0.543633, top_k: 0.779102, samples/s: 685.771 1613570035.6620862
train: epoch 18, iter 700, loss: 2.953805, top_1: 0.535703, top_k: 0.772734, samples/s: 684.711 1613570073.0501442
train: epoch 18, iter 800, loss: 2.961205, top_1: 0.536758, top_k: 0.775430, samples/s: 683.627 1613570110.497501
train: epoch 18, iter 900, loss: 2.957064, top_1: 0.533711, top_k: 0.771133, samples/s: 685.300 1613570147.8532767
train: epoch 18, iter 1000, loss: 2.901012, top_1: 0.539805, top_k: 0.775859, samples/s: 684.848 1613570185.2338617
train: epoch 18, iter 1100, loss: 2.998530, top_1: 0.546328, top_k: 0.779062, samples/s: 685.037 1613570222.6041374
train: epoch 18, iter 1200, loss: 2.755016, top_1: 0.540078, top_k: 0.768984, samples/s: 684.892 1613570259.9822981
train: epoch 18, iter 1300, loss: 3.063841, top_1: 0.537852, top_k: 0.769727, samples/s: 686.107 1613570297.2943616
train: epoch 18, iter 1400, loss: 3.028115, top_1: 0.530820, top_k: 0.772500, samples/s: 686.043 1613570334.6097603
train: epoch 18, iter 1500, loss: 2.797331, top_1: 0.538750, top_k: 0.770938, samples/s: 684.149 1613570372.0285592
train: epoch 18, iter 1600, loss: 2.951635, top_1: 0.544727, top_k: 0.776914, samples/s: 688.038 1613570409.2357326
train: epoch 18, iter 1700, loss: 2.862443, top_1: 0.541914, top_k: 0.774258, samples/s: 683.525 1613570446.6887276
train: epoch 18, iter 1800, loss: 2.852127, top_1: 0.535430, top_k: 0.768516, samples/s: 684.382 1613570484.094745
train: epoch 18, iter 1900, loss: 2.849217, top_1: 0.540547, top_k: 0.770781, samples/s: 685.656 1613570521.4311316
train: epoch 18, iter 2000, loss: 2.961879, top_1: 0.541211, top_k: 0.773711, samples/s: 686.647 1613570558.71383
train: epoch 18, iter 2100, loss: 2.892996, top_1: 0.536406, top_k: 0.769180, samples/s: 683.662 1613570596.1592665
train: epoch 18, iter 2200, loss: 2.957346, top_1: 0.540898, top_k: 0.772734, samples/s: 683.769 1613570633.5987704
train: epoch 18, iter 2300, loss: 2.864898, top_1: 0.540430, top_k: 0.770586, samples/s: 686.878 1613570670.868845
train: epoch 18, iter 2400, loss: 2.969569, top_1: 0.532695, top_k: 0.767266, samples/s: 688.969 1613570708.0257764
train: epoch 18, iter 2500, loss: 2.937715, top_1: 0.540078, top_k: 0.774727, samples/s: 684.679 1613570745.4155412
train: epoch 18, iter 2600, loss: 3.079341, top_1: 0.541914, top_k: 0.776328, samples/s: 686.357 1613570782.7139647
train: epoch 18, iter 2700, loss: 3.049290, top_1: 0.541172, top_k: 0.777422, samples/s: 684.898 1613570820.0917916
train: epoch 18, iter 2800, loss: 3.241881, top_1: 0.538242, top_k: 0.770234, samples/s: 686.342 1613570857.390961
train: epoch 18, iter 2900, loss: 2.912006, top_1: 0.533906, top_k: 0.767422, samples/s: 685.000 1613570894.763278
train: epoch 18, iter 3000, loss: 3.035787, top_1: 0.535820, top_k: 0.770312, samples/s: 682.478 1613570932.2735848
train: epoch 18, iter 3100, loss: 3.066437, top_1: 0.538945, top_k: 0.771641, samples/s: 685.262 1613570969.631493
train: epoch 18, iter 3200, loss: 2.889677, top_1: 0.539648, top_k: 0.769766, samples/s: 684.957 1613571007.0060675
train: epoch 18, iter 3300, loss: 2.873763, top_1: 0.537188, top_k: 0.771016, samples/s: 685.033 1613571044.376612
train: epoch 18, iter 3400, loss: 2.867301, top_1: 0.535937, top_k: 0.772227, samples/s: 687.659 1613571081.6044183
train: epoch 18, iter 3500, loss: 2.962254, top_1: 0.537148, top_k: 0.772461, samples/s: 684.670 1613571118.9946816
train: epoch 18, iter 3600, loss: 2.990339, top_1: 0.540312, top_k: 0.768359, samples/s: 683.650 1613571156.4407878
train: epoch 18, iter 3700, loss: 2.617321, top_1: 0.538516, top_k: 0.775469, samples/s: 686.579 1613571193.7270937
train: epoch 18, iter 3800, loss: 2.916145, top_1: 0.543516, top_k: 0.771953, samples/s: 683.498 1613571231.1815038
train: epoch 18, iter 3900, loss: 3.026126, top_1: 0.536523, top_k: 0.769805, samples/s: 687.366 1613571268.425111
train: epoch 18, iter 4000, loss: 2.799074, top_1: 0.538984, top_k: 0.771953, samples/s: 685.578 1613571305.765834
train: epoch 18, iter 4100, loss: 2.875374, top_1: 0.539414, top_k: 0.770938, samples/s: 684.989 1613571343.1386685
train: epoch 18, iter 4200, loss: 2.876581, top_1: 0.535234, top_k: 0.768437, samples/s: 686.650 1613571380.4212127
train: epoch 18, iter 4300, loss: 3.249007, top_1: 0.535195, top_k: 0.763672, samples/s: 687.786 1613571417.6419973
train: epoch 18, iter 4400, loss: 2.750873, top_1: 0.535898, top_k: 0.770234, samples/s: 684.386 1613571455.0477679
train: epoch 18, iter 4500, loss: 2.917284, top_1: 0.538359, top_k: 0.774336, samples/s: 684.341 1613571492.456073
train: epoch 18, iter 4600, loss: 2.896589, top_1: 0.533672, top_k: 0.771172, samples/s: 686.844 1613571529.728031
train: epoch 18, iter 4700, loss: 2.871007, top_1: 0.541406, top_k: 0.770195, samples/s: 686.800 1613571567.002416
train: epoch 18, iter 4800, loss: 2.882098, top_1: 0.537266, top_k: 0.767773, samples/s: 688.314 1613571604.194706
train: epoch 18, iter 4900, loss: 2.766644, top_1: 0.538984, top_k: 0.771719, samples/s: 686.230 1613571641.4999356
train: epoch 18, iter 5000, loss: 2.820647, top_1: 0.534102, top_k: 0.770742, samples/s: 687.120 1613571678.756951
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_18.
validation: epoch 18, iter 195, top_1: 0.575280, top_k: 0.819371, samples/s: 2179.628 1613571702.7894502
train: epoch 19, iter 100, loss: 2.886295, top_1: 0.543984, top_k: 0.778477, samples/s: 699.013 1613571760.3475604
train: epoch 19, iter 200, loss: 2.854187, top_1: 0.542383, top_k: 0.775117, samples/s: 700.982 1613571796.868007
train: epoch 19, iter 300, loss: 2.810216, top_1: 0.540039, top_k: 0.774258, samples/s: 683.997 1613571834.2948446
train: epoch 19, iter 400, loss: 2.928830, top_1: 0.550273, top_k: 0.776406, samples/s: 684.320 1613571871.7042217
train: epoch 19, iter 500, loss: 2.928102, top_1: 0.545469, top_k: 0.778594, samples/s: 685.191 1613571909.0660775
train: epoch 19, iter 600, loss: 3.008302, top_1: 0.545547, top_k: 0.781211, samples/s: 686.383 1613571946.362919
train: epoch 19, iter 700, loss: 2.871939, top_1: 0.546523, top_k: 0.773398, samples/s: 684.828 1613571983.74467
train: epoch 19, iter 800, loss: 3.031984, top_1: 0.548906, top_k: 0.782188, samples/s: 686.270 1613572021.0476518
train: epoch 19, iter 900, loss: 2.876441, top_1: 0.543594, top_k: 0.773750, samples/s: 683.292 1613572058.5133817
train: epoch 19, iter 1000, loss: 3.046807, top_1: 0.543867, top_k: 0.775312, samples/s: 686.072 1613572095.8272305
train: epoch 19, iter 1100, loss: 2.720801, top_1: 0.542773, top_k: 0.776484, samples/s: 684.276 1613572133.239064
train: epoch 19, iter 1200, loss: 2.817863, top_1: 0.543359, top_k: 0.773906, samples/s: 685.965 1613572170.5587797
train: epoch 19, iter 1300, loss: 2.660171, top_1: 0.544844, top_k: 0.782539, samples/s: 684.923 1613572207.9352202
train: epoch 19, iter 1400, loss: 2.971104, top_1: 0.538789, top_k: 0.773906, samples/s: 687.036 1613572245.1967473
train: epoch 19, iter 1500, loss: 2.781405, top_1: 0.537773, top_k: 0.770898, samples/s: 683.108 1613572282.6724536
train: epoch 19, iter 1600, loss: 2.798098, top_1: 0.545508, top_k: 0.776406, samples/s: 684.697 1613572320.0612204
train: epoch 19, iter 1700, loss: 2.861167, top_1: 0.535703, top_k: 0.770703, samples/s: 685.517 1613572357.4053552
train: epoch 19, iter 1800, loss: 2.840648, top_1: 0.534219, top_k: 0.771914, samples/s: 683.542 1613572394.8573565
train: epoch 19, iter 1900, loss: 2.951800, top_1: 0.541367, top_k: 0.772188, samples/s: 687.698 1613572432.082938
train: epoch 19, iter 2000, loss: 3.148748, top_1: 0.537266, top_k: 0.771719, samples/s: 684.979 1613572469.4563417
train: epoch 19, iter 2100, loss: 2.833221, top_1: 0.539023, top_k: 0.771758, samples/s: 686.760 1613572506.7329159
train: epoch 19, iter 2200, loss: 2.873621, top_1: 0.537969, top_k: 0.778477, samples/s: 684.368 1613572544.1396956
train: epoch 19, iter 2300, loss: 2.809963, top_1: 0.546445, top_k: 0.782617, samples/s: 686.429 1613572581.4341242
train: epoch 19, iter 2400, loss: 2.834472, top_1: 0.543555, top_k: 0.776406, samples/s: 688.349 1613572618.6246083
train: epoch 19, iter 2500, loss: 3.046440, top_1: 0.545352, top_k: 0.774453, samples/s: 685.228 1613572655.9844325
train: epoch 19, iter 2600, loss: 3.039165, top_1: 0.535234, top_k: 0.770039, samples/s: 683.321 1613572693.4485142
train: epoch 19, iter 2700, loss: 2.955235, top_1: 0.542734, top_k: 0.771055, samples/s: 687.920 1613572730.6621091
train: epoch 19, iter 2800, loss: 2.895186, top_1: 0.539375, top_k: 0.776602, samples/s: 686.081 1613572767.975413
train: epoch 19, iter 2900, loss: 2.959766, top_1: 0.541797, top_k: 0.774414, samples/s: 686.544 1613572805.2637062
train: epoch 19, iter 3000, loss: 3.013176, top_1: 0.538672, top_k: 0.774062, samples/s: 684.984 1613572842.6367617
train: epoch 19, iter 3100, loss: 2.869223, top_1: 0.534844, top_k: 0.769023, samples/s: 687.863 1613572879.8535104
train: epoch 19, iter 3200, loss: 2.944428, top_1: 0.535156, top_k: 0.772305, samples/s: 684.434 1613572917.2567358
train: epoch 19, iter 3300, loss: 2.851385, top_1: 0.537734, top_k: 0.771289, samples/s: 687.612 1613572954.4870303
train: epoch 19, iter 3400, loss: 2.949231, top_1: 0.548867, top_k: 0.778008, samples/s: 683.172 1613572991.9593341
train: epoch 19, iter 3500, loss: 2.949205, top_1: 0.535508, top_k: 0.773398, samples/s: 685.148 1613573029.323406
train: epoch 19, iter 3600, loss: 2.932561, top_1: 0.541250, top_k: 0.773047, samples/s: 687.233 1613573066.5743546
train: epoch 19, iter 3700, loss: 2.849971, top_1: 0.541289, top_k: 0.773086, samples/s: 685.771 1613573103.9045553
train: epoch 19, iter 3800, loss: 2.772753, top_1: 0.537617, top_k: 0.773477, samples/s: 688.961 1613573141.061915
train: epoch 19, iter 3900, loss: 2.754729, top_1: 0.536953, top_k: 0.772734, samples/s: 684.045 1613573178.4863105
train: epoch 19, iter 4000, loss: 2.960427, top_1: 0.545664, top_k: 0.773438, samples/s: 688.848 1613573215.6498713
train: epoch 19, iter 4100, loss: 2.997133, top_1: 0.539141, top_k: 0.772188, samples/s: 683.728 1613573253.0915382
train: epoch 19, iter 4200, loss: 3.072068, top_1: 0.540156, top_k: 0.772148, samples/s: 685.414 1613573290.441307
train: epoch 19, iter 4300, loss: 2.899854, top_1: 0.541641, top_k: 0.772227, samples/s: 686.167 1613573327.7500467
train: epoch 19, iter 4400, loss: 2.986709, top_1: 0.535000, top_k: 0.769531, samples/s: 688.748 1613573364.918907
train: epoch 19, iter 4500, loss: 2.981684, top_1: 0.541680, top_k: 0.775039, samples/s: 684.383 1613573402.3247802
train: epoch 19, iter 4600, loss: 2.928887, top_1: 0.540547, top_k: 0.776953, samples/s: 687.226 1613573439.5759792
train: epoch 19, iter 4700, loss: 2.896684, top_1: 0.546562, top_k: 0.775078, samples/s: 684.965 1613573476.9502454
train: epoch 19, iter 4800, loss: 2.721672, top_1: 0.543555, top_k: 0.778828, samples/s: 685.944 1613573514.271051
train: epoch 19, iter 4900, loss: 3.017748, top_1: 0.544414, top_k: 0.773516, samples/s: 686.027 1613573551.587434
train: epoch 19, iter 5000, loss: 2.626174, top_1: 0.539883, top_k: 0.775234, samples/s: 685.263 1613573588.9453812
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_19.
validation: epoch 19, iter 195, top_1: 0.578886, top_k: 0.820373, samples/s: 2143.242 1613573613.3421288
train: epoch 20, iter 100, loss: 2.835945, top_1: 0.545937, top_k: 0.777969, samples/s: 702.770 1613573670.6727695
train: epoch 20, iter 200, loss: 2.971288, top_1: 0.546094, top_k: 0.778242, samples/s: 699.321 1613573707.2796338
train: epoch 20, iter 300, loss: 2.685412, top_1: 0.545312, top_k: 0.782656, samples/s: 685.631 1613573744.6175146
train: epoch 20, iter 400, loss: 2.803163, top_1: 0.544961, top_k: 0.774062, samples/s: 681.836 1613573782.1634712
train: epoch 20, iter 500, loss: 2.735591, top_1: 0.551641, top_k: 0.779570, samples/s: 684.631 1613573819.5556169
train: epoch 20, iter 600, loss: 2.826235, top_1: 0.552383, top_k: 0.782031, samples/s: 685.562 1613573856.8972347
train: epoch 20, iter 700, loss: 2.762317, top_1: 0.547188, top_k: 0.776602, samples/s: 685.155 1613573894.261042
train: epoch 20, iter 800, loss: 2.634878, top_1: 0.547578, top_k: 0.779297, samples/s: 679.765 1613573931.9211183
train: epoch 20, iter 900, loss: 2.854310, top_1: 0.551055, top_k: 0.780352, samples/s: 689.315 1613573969.0593524
train: epoch 20, iter 1000, loss: 2.950619, top_1: 0.548828, top_k: 0.780977, samples/s: 684.045 1613574006.4838946
train: epoch 20, iter 1100, loss: 2.653815, top_1: 0.552188, top_k: 0.781133, samples/s: 685.407 1613574043.8339736
train: epoch 20, iter 1200, loss: 2.866641, top_1: 0.541875, top_k: 0.773984, samples/s: 685.050 1613574081.2034698
train: epoch 20, iter 1300, loss: 2.851087, top_1: 0.544453, top_k: 0.777344, samples/s: 683.380 1613574118.664349
train: epoch 20, iter 1400, loss: 3.192466, top_1: 0.543047, top_k: 0.774297, samples/s: 686.772 1613574155.9400892
train: epoch 20, iter 1500, loss: 2.752173, top_1: 0.544414, top_k: 0.780078, samples/s: 683.037 1613574193.4197736
train: epoch 20, iter 1600, loss: 3.196981, top_1: 0.547656, top_k: 0.775742, samples/s: 686.221 1613574230.7255673
train: epoch 20, iter 1700, loss: 2.795753, top_1: 0.544414, top_k: 0.776719, samples/s: 687.128 1613574267.9821277
train: epoch 20, iter 1800, loss: 3.191695, top_1: 0.545391, top_k: 0.776445, samples/s: 683.645 1613574305.4284322
train: epoch 20, iter 1900, loss: 2.720988, top_1: 0.540273, top_k: 0.774180, samples/s: 686.030 1613574342.744523
train: epoch 20, iter 2000, loss: 3.060468, top_1: 0.546484, top_k: 0.781641, samples/s: 684.790 1613574380.128359
train: epoch 20, iter 2100, loss: 2.923404, top_1: 0.542070, top_k: 0.776211, samples/s: 683.948 1613574417.5581024
train: epoch 20, iter 2200, loss: 2.888292, top_1: 0.542578, top_k: 0.776563, samples/s: 682.833 1613574455.048863
train: epoch 20, iter 2300, loss: 2.860406, top_1: 0.544180, top_k: 0.775781, samples/s: 685.020 1613574492.420089
train: epoch 20, iter 2400, loss: 2.796210, top_1: 0.546992, top_k: 0.775625, samples/s: 685.308 1613574529.7755728
train: epoch 20, iter 2500, loss: 2.834884, top_1: 0.544453, top_k: 0.775000, samples/s: 683.329 1613574567.239211
train: epoch 20, iter 2600, loss: 2.864662, top_1: 0.539766, top_k: 0.775898, samples/s: 685.358 1613574604.591992
train: epoch 20, iter 2700, loss: 2.889407, top_1: 0.544063, top_k: 0.774805, samples/s: 685.615 1613574641.9307773
train: epoch 20, iter 2800, loss: 2.798624, top_1: 0.540391, top_k: 0.775508, samples/s: 685.049 1613574679.3003716
train: epoch 20, iter 2900, loss: 2.683237, top_1: 0.543359, top_k: 0.777188, samples/s: 684.136 1613574716.7197287
train: epoch 20, iter 3000, loss: 2.748950, top_1: 0.541875, top_k: 0.777266, samples/s: 686.945 1613574753.9862819
train: epoch 20, iter 3100, loss: 2.875506, top_1: 0.539961, top_k: 0.776211, samples/s: 684.824 1613574791.3681571
train: epoch 20, iter 3200, loss: 2.904600, top_1: 0.549375, top_k: 0.778906, samples/s: 683.510 1613574828.8218849
train: epoch 20, iter 3300, loss: 2.875094, top_1: 0.544766, top_k: 0.775703, samples/s: 683.257 1613574866.2895114
train: epoch 20, iter 3400, loss: 2.979526, top_1: 0.539297, top_k: 0.775937, samples/s: 687.507 1613574903.5254939
train: epoch 20, iter 3500, loss: 3.092097, top_1: 0.541719, top_k: 0.775547, samples/s: 685.600 1613574940.8649619
train: epoch 20, iter 3600, loss: 2.943186, top_1: 0.544297, top_k: 0.777656, samples/s: 687.072 1613574978.1246119
train: epoch 20, iter 3700, loss: 2.823596, top_1: 0.536445, top_k: 0.773594, samples/s: 685.198 1613575015.485958
train: epoch 20, iter 3800, loss: 2.895978, top_1: 0.538672, top_k: 0.772383, samples/s: 686.907 1613575052.7545762
train: epoch 20, iter 3900, loss: 2.742344, top_1: 0.544961, top_k: 0.774102, samples/s: 682.638 1613575090.2561738
train: epoch 20, iter 4000, loss: 3.148277, top_1: 0.537422, top_k: 0.769180, samples/s: 684.977 1613575127.6296868
train: epoch 20, iter 4100, loss: 2.780022, top_1: 0.548594, top_k: 0.777930, samples/s: 683.624 1613575165.077131
train: epoch 20, iter 4200, loss: 2.912892, top_1: 0.539297, top_k: 0.777148, samples/s: 685.375 1613575202.4289742
train: epoch 20, iter 4300, loss: 2.982624, top_1: 0.548203, top_k: 0.776523, samples/s: 684.178 1613575239.8460379
train: epoch 20, iter 4400, loss: 2.767053, top_1: 0.542813, top_k: 0.774531, samples/s: 684.985 1613575277.2192323
train: epoch 20, iter 4500, loss: 2.827807, top_1: 0.538750, top_k: 0.770039, samples/s: 683.770 1613575314.6586087
train: epoch 20, iter 4600, loss: 2.961887, top_1: 0.542344, top_k: 0.773164, samples/s: 685.927 1613575351.9804842
train: epoch 20, iter 4700, loss: 2.879711, top_1: 0.543359, top_k: 0.772070, samples/s: 686.394 1613575389.2768016
train: epoch 20, iter 4800, loss: 2.939770, top_1: 0.538984, top_k: 0.771953, samples/s: 681.383 1613575426.8475046
train: epoch 20, iter 4900, loss: 2.825103, top_1: 0.539336, top_k: 0.771992, samples/s: 684.310 1613575464.2574904
train: epoch 20, iter 5000, loss: 2.872019, top_1: 0.545547, top_k: 0.776992, samples/s: 683.869 1613575501.6914518
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_20.
validation: epoch 20, iter 195, top_1: 0.606791, top_k: 0.839603, samples/s: 2173.103 1613575525.7697802
train: epoch 21, iter 100, loss: 2.737500, top_1: 0.560312, top_k: 0.793438, samples/s: 702.377 1613575582.9664416
train: epoch 21, iter 200, loss: 2.898659, top_1: 0.557187, top_k: 0.782695, samples/s: 699.053 1613575619.5875344
train: epoch 21, iter 300, loss: 2.865591, top_1: 0.552891, top_k: 0.788398, samples/s: 681.719 1613575657.1394565
train: epoch 21, iter 400, loss: 2.840187, top_1: 0.558047, top_k: 0.788125, samples/s: 683.150 1613575694.6127994
train: epoch 21, iter 500, loss: 2.806151, top_1: 0.549570, top_k: 0.784922, samples/s: 682.707 1613575732.1107042
train: epoch 21, iter 600, loss: 3.127425, top_1: 0.551523, top_k: 0.778242, samples/s: 680.456 1613575769.732572
train: epoch 21, iter 700, loss: 2.748208, top_1: 0.549805, top_k: 0.780312, samples/s: 683.152 1613575807.2059212
train: epoch 21, iter 800, loss: 2.988801, top_1: 0.546719, top_k: 0.779062, samples/s: 682.345 1613575844.7235248
train: epoch 21, iter 900, loss: 2.761663, top_1: 0.553477, top_k: 0.782383, samples/s: 683.741 1613575882.1646576
train: epoch 21, iter 1000, loss: 2.840099, top_1: 0.544805, top_k: 0.778867, samples/s: 683.026 1613575919.6449254
train: epoch 21, iter 1100, loss: 3.083408, top_1: 0.547617, top_k: 0.778633, samples/s: 684.587 1613575957.0397468
train: epoch 21, iter 1200, loss: 2.821600, top_1: 0.548945, top_k: 0.782148, samples/s: 683.531 1613575994.4922552
train: epoch 21, iter 1300, loss: 2.866394, top_1: 0.547109, top_k: 0.781094, samples/s: 682.412 1613576032.0063
train: epoch 21, iter 1400, loss: 2.817207, top_1: 0.549141, top_k: 0.779141, samples/s: 685.332 1613576069.3603842
train: epoch 21, iter 1500, loss: 2.943860, top_1: 0.547695, top_k: 0.777617, samples/s: 682.270 1613576106.8822608
train: epoch 21, iter 1600, loss: 2.999549, top_1: 0.541523, top_k: 0.775742, samples/s: 684.034 1613576144.3073204
train: epoch 21, iter 1700, loss: 2.918820, top_1: 0.550742, top_k: 0.780469, samples/s: 682.434 1613576181.8201091
train: epoch 21, iter 1800, loss: 2.774145, top_1: 0.544648, top_k: 0.776602, samples/s: 682.215 1613576219.3449097
train: epoch 21, iter 1900, loss: 2.789635, top_1: 0.553281, top_k: 0.780273, samples/s: 684.855 1613576256.7250934
train: epoch 21, iter 2000, loss: 3.020033, top_1: 0.541992, top_k: 0.776016, samples/s: 686.262 1613576294.0285108
train: epoch 21, iter 2100, loss: 2.885906, top_1: 0.547422, top_k: 0.778438, samples/s: 681.876 1613576331.5720744
train: epoch 21, iter 2200, loss: 2.950479, top_1: 0.546680, top_k: 0.774844, samples/s: 685.037 1613576368.942419
train: epoch 21, iter 2300, loss: 2.786510, top_1: 0.542773, top_k: 0.776641, samples/s: 682.990 1613576406.4245398
train: epoch 21, iter 2400, loss: 2.748847, top_1: 0.543945, top_k: 0.779570, samples/s: 686.187 1613576443.7322586
train: epoch 21, iter 2500, loss: 2.987511, top_1: 0.545625, top_k: 0.778711, samples/s: 682.995 1613576481.2142835
train: epoch 21, iter 2600, loss: 2.892051, top_1: 0.542383, top_k: 0.771094, samples/s: 685.011 1613576518.5859106
train: epoch 21, iter 2700, loss: 2.806892, top_1: 0.552266, top_k: 0.780859, samples/s: 683.236 1613576556.054623
train: epoch 21, iter 2800, loss: 2.828816, top_1: 0.541875, top_k: 0.774492, samples/s: 683.932 1613576593.4852033
train: epoch 21, iter 2900, loss: 2.907405, top_1: 0.550352, top_k: 0.776211, samples/s: 683.390 1613576630.9455802
train: epoch 21, iter 3000, loss: 2.716959, top_1: 0.545469, top_k: 0.776250, samples/s: 685.158 1613576668.309195
train: epoch 21, iter 3100, loss: 2.694118, top_1: 0.538789, top_k: 0.776250, samples/s: 683.786 1613576705.747766
train: epoch 21, iter 3200, loss: 2.933757, top_1: 0.546445, top_k: 0.776328, samples/s: 684.131 1613576743.167541
train: epoch 21, iter 3300, loss: 2.848403, top_1: 0.540547, top_k: 0.774727, samples/s: 683.977 1613576780.595615
train: epoch 21, iter 3400, loss: 2.707650, top_1: 0.550156, top_k: 0.778789, samples/s: 684.197 1613576818.011728
train: epoch 21, iter 3500, loss: 3.059418, top_1: 0.544727, top_k: 0.775000, samples/s: 684.965 1613576855.3859317
train: epoch 21, iter 3600, loss: 2.870095, top_1: 0.541602, top_k: 0.774141, samples/s: 682.417 1613576892.899601
train: epoch 21, iter 3700, loss: 2.769392, top_1: 0.541953, top_k: 0.773125, samples/s: 681.562 1613576930.460387
train: epoch 21, iter 3800, loss: 3.022645, top_1: 0.548672, top_k: 0.779336, samples/s: 683.223 1613576967.929909
train: epoch 21, iter 3900, loss: 2.835629, top_1: 0.540937, top_k: 0.774727, samples/s: 682.521 1613577005.4378777
train: epoch 21, iter 4000, loss: 2.967173, top_1: 0.539609, top_k: 0.773789, samples/s: 685.132 1613577042.80294
train: epoch 21, iter 4100, loss: 2.857466, top_1: 0.544648, top_k: 0.773828, samples/s: 684.082 1613577080.2254097
train: epoch 21, iter 4200, loss: 2.899595, top_1: 0.545078, top_k: 0.777500, samples/s: 684.663 1613577117.6159341
train: epoch 21, iter 4300, loss: 3.018842, top_1: 0.542773, top_k: 0.775547, samples/s: 683.198 1613577155.0868762
train: epoch 21, iter 4400, loss: 2.951728, top_1: 0.545469, top_k: 0.778281, samples/s: 681.306 1613577192.6616786
train: epoch 21, iter 4500, loss: 2.902758, top_1: 0.540781, top_k: 0.772422, samples/s: 681.934 1613577230.20206
train: epoch 21, iter 4600, loss: 2.921069, top_1: 0.542617, top_k: 0.775859, samples/s: 685.746 1613577267.5335882
train: epoch 21, iter 4700, loss: 2.817466, top_1: 0.540820, top_k: 0.770820, samples/s: 682.326 1613577305.052394
train: epoch 21, iter 4800, loss: 2.912253, top_1: 0.538867, top_k: 0.777383, samples/s: 682.906 1613577342.539277
train: epoch 21, iter 4900, loss: 2.705205, top_1: 0.542031, top_k: 0.779570, samples/s: 684.605 1613577379.9330928
train: epoch 21, iter 5000, loss: 2.970843, top_1: 0.542422, top_k: 0.774258, samples/s: 685.034 1613577417.303543
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_21.
validation: epoch 21, iter 195, top_1: 0.590745, top_k: 0.829647, samples/s: 2141.290 1613577441.7222056
train: epoch 22, iter 100, loss: 2.746505, top_1: 0.566992, top_k: 0.791289, samples/s: 703.091 1613577499.5241997
train: epoch 22, iter 200, loss: 2.848691, top_1: 0.544531, top_k: 0.778672, samples/s: 698.255 1613577536.1869812
train: epoch 22, iter 300, loss: 2.954718, top_1: 0.553789, top_k: 0.785742, samples/s: 682.790 1613577573.680226
train: epoch 22, iter 400, loss: 2.953842, top_1: 0.548438, top_k: 0.780430, samples/s: 682.370 1613577611.1964831
train: epoch 22, iter 500, loss: 2.689826, top_1: 0.554180, top_k: 0.783711, samples/s: 682.763 1613577648.6911438
train: epoch 22, iter 600, loss: 2.787975, top_1: 0.553789, top_k: 0.781992, samples/s: 680.337 1613577686.319577
train: epoch 22, iter 700, loss: 2.844736, top_1: 0.548203, top_k: 0.778789, samples/s: 682.462 1613577723.8307548
train: epoch 22, iter 800, loss: 2.761157, top_1: 0.551250, top_k: 0.784961, samples/s: 682.546 1613577761.337572
train: epoch 22, iter 900, loss: 2.615910, top_1: 0.552227, top_k: 0.784609, samples/s: 680.887 1613577798.935532
train: epoch 22, iter 1000, loss: 2.781089, top_1: 0.555859, top_k: 0.782148, samples/s: 680.988 1613577836.527963
train: epoch 22, iter 1100, loss: 2.751869, top_1: 0.548633, top_k: 0.781602, samples/s: 683.632 1613577873.9750407
train: epoch 22, iter 1200, loss: 2.841531, top_1: 0.546719, top_k: 0.776875, samples/s: 683.224 1613577911.4443526
train: epoch 22, iter 1300, loss: 3.199430, top_1: 0.554023, top_k: 0.778867, samples/s: 684.920 1613577948.820968
train: epoch 22, iter 1400, loss: 2.810938, top_1: 0.551758, top_k: 0.784062, samples/s: 682.271 1613577986.342843
train: epoch 22, iter 1500, loss: 2.931606, top_1: 0.549063, top_k: 0.777109, samples/s: 683.663 1613578023.7881017
train: epoch 22, iter 1600, loss: 2.742218, top_1: 0.545352, top_k: 0.779180, samples/s: 683.586 1613578061.2376463
train: epoch 22, iter 1700, loss: 3.016025, top_1: 0.549609, top_k: 0.778984, samples/s: 684.748 1613578098.623736
train: epoch 22, iter 1800, loss: 2.931733, top_1: 0.553906, top_k: 0.784180, samples/s: 685.371 1613578135.9758658
train: epoch 22, iter 1900, loss: 3.089002, top_1: 0.548750, top_k: 0.780156, samples/s: 682.708 1613578173.4734144
train: epoch 22, iter 2000, loss: 2.827937, top_1: 0.547422, top_k: 0.779219, samples/s: 683.678 1613578210.9180295
train: epoch 22, iter 2100, loss: 2.701321, top_1: 0.550469, top_k: 0.783516, samples/s: 684.042 1613578248.342662
train: epoch 22, iter 2200, loss: 3.012933, top_1: 0.540977, top_k: 0.772852, samples/s: 684.076 1613578285.765397
train: epoch 22, iter 2300, loss: 2.868589, top_1: 0.548945, top_k: 0.781133, samples/s: 685.512 1613578323.1096382
train: epoch 22, iter 2400, loss: 2.917972, top_1: 0.552578, top_k: 0.782109, samples/s: 682.125 1613578360.6395442
train: epoch 22, iter 2500, loss: 2.893091, top_1: 0.548516, top_k: 0.778984, samples/s: 683.011 1613578398.1205075
train: epoch 22, iter 2600, loss: 2.836699, top_1: 0.541758, top_k: 0.775469, samples/s: 682.349 1613578435.6380847
train: epoch 22, iter 2700, loss: 2.877523, top_1: 0.541641, top_k: 0.775742, samples/s: 685.213 1613578472.998754
train: epoch 22, iter 2800, loss: 2.933569, top_1: 0.546016, top_k: 0.779219, samples/s: 684.792 1613578510.38237
train: epoch 22, iter 2900, loss: 2.949618, top_1: 0.547227, top_k: 0.776367, samples/s: 683.957 1613578547.8116531
train: epoch 22, iter 3000, loss: 2.993546, top_1: 0.549102, top_k: 0.778125, samples/s: 682.372 1613578585.3277838
train: epoch 22, iter 3100, loss: 2.952306, top_1: 0.543789, top_k: 0.780469, samples/s: 684.191 1613578622.7443042
train: epoch 22, iter 3200, loss: 2.824867, top_1: 0.546289, top_k: 0.774336, samples/s: 680.786 1613578660.347889
train: epoch 22, iter 3300, loss: 2.990958, top_1: 0.545312, top_k: 0.778672, samples/s: 685.024 1613578697.7188804
train: epoch 22, iter 3400, loss: 2.861238, top_1: 0.541953, top_k: 0.775625, samples/s: 684.237 1613578735.1327739
train: epoch 22, iter 3500, loss: 2.965812, top_1: 0.547109, top_k: 0.775273, samples/s: 681.807 1613578772.6800387
train: epoch 22, iter 3600, loss: 2.787060, top_1: 0.543477, top_k: 0.776680, samples/s: 682.686 1613578810.178918
train: epoch 22, iter 3700, loss: 2.712379, top_1: 0.543242, top_k: 0.776523, samples/s: 683.880 1613578847.6124349
train: epoch 22, iter 3800, loss: 2.882398, top_1: 0.547852, top_k: 0.775234, samples/s: 684.651 1613578885.0037436
train: epoch 22, iter 3900, loss: 2.752609, top_1: 0.545273, top_k: 0.778555, samples/s: 684.985 1613578922.3767793
train: epoch 22, iter 4000, loss: 2.953983, top_1: 0.545234, top_k: 0.776250, samples/s: 685.617 1613578959.7154455
train: epoch 22, iter 4100, loss: 2.926626, top_1: 0.543789, top_k: 0.775312, samples/s: 680.786 1613578997.3191206
train: epoch 22, iter 4200, loss: 2.901387, top_1: 0.552148, top_k: 0.780859, samples/s: 686.381 1613579034.616179
train: epoch 22, iter 4300, loss: 2.768784, top_1: 0.551016, top_k: 0.779961, samples/s: 683.034 1613579072.0959704
train: epoch 22, iter 4400, loss: 2.656049, top_1: 0.545859, top_k: 0.775078, samples/s: 683.342 1613579109.5589256
train: epoch 22, iter 4500, loss: 2.707299, top_1: 0.549570, top_k: 0.778125, samples/s: 684.717 1613579146.9466581
train: epoch 22, iter 4600, loss: 2.929587, top_1: 0.544180, top_k: 0.776484, samples/s: 684.072 1613579184.3694842
train: epoch 22, iter 4700, loss: 2.667840, top_1: 0.543945, top_k: 0.777461, samples/s: 686.810 1613579221.6433544
train: epoch 22, iter 4800, loss: 3.123794, top_1: 0.545156, top_k: 0.777617, samples/s: 682.846 1613579259.1335042
train: epoch 22, iter 4900, loss: 2.842313, top_1: 0.544023, top_k: 0.777383, samples/s: 683.871 1613579296.5675154
train: epoch 22, iter 5000, loss: 2.697895, top_1: 0.547148, top_k: 0.778281, samples/s: 683.648 1613579334.013564
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_22.
validation: epoch 22, iter 195, top_1: 0.602123, top_k: 0.839583, samples/s: 2147.725 1613579358.369241
train: epoch 23, iter 100, loss: 2.820632, top_1: 0.561953, top_k: 0.788750, samples/s: 703.830 1613579422.1326056
train: epoch 23, iter 200, loss: 2.914501, top_1: 0.562227, top_k: 0.791250, samples/s: 700.950 1613579458.6545827
train: epoch 23, iter 300, loss: 2.834548, top_1: 0.552305, top_k: 0.782188, samples/s: 684.573 1613579496.0500567
train: epoch 23, iter 400, loss: 2.995151, top_1: 0.554844, top_k: 0.787891, samples/s: 686.833 1613579533.3226213
train: epoch 23, iter 500, loss: 2.679734, top_1: 0.553398, top_k: 0.782969, samples/s: 682.154 1613579570.8508515
train: epoch 23, iter 600, loss: 2.658898, top_1: 0.552773, top_k: 0.786914, samples/s: 682.267 1613579608.372774
train: epoch 23, iter 700, loss: 2.778822, top_1: 0.550859, top_k: 0.781719, samples/s: 685.912 1613579645.6953034
train: epoch 23, iter 800, loss: 2.973087, top_1: 0.553750, top_k: 0.784687, samples/s: 683.866 1613579683.129621
train: epoch 23, iter 900, loss: 2.918409, top_1: 0.557773, top_k: 0.786211, samples/s: 685.599 1613579720.4692497
train: epoch 23, iter 1000, loss: 2.847252, top_1: 0.550586, top_k: 0.779961, samples/s: 684.102 1613579757.8905394
train: epoch 23, iter 1100, loss: 2.965806, top_1: 0.554063, top_k: 0.784336, samples/s: 684.308 1613579795.3006454
train: epoch 23, iter 1200, loss: 2.673225, top_1: 0.550195, top_k: 0.783711, samples/s: 684.647 1613579832.6921408
train: epoch 23, iter 1300, loss: 2.791492, top_1: 0.554375, top_k: 0.785977, samples/s: 685.943 1613579870.0129683
train: epoch 23, iter 1400, loss: 2.828074, top_1: 0.549102, top_k: 0.780820, samples/s: 682.710 1613579907.5105665
train: epoch 23, iter 1500, loss: 2.962112, top_1: 0.551875, top_k: 0.778750, samples/s: 684.206 1613579944.9262805
train: epoch 23, iter 1600, loss: 2.824202, top_1: 0.550859, top_k: 0.784258, samples/s: 683.283 1613579982.3923528
train: epoch 23, iter 1700, loss: 2.782748, top_1: 0.554570, top_k: 0.783125, samples/s: 683.431 1613580019.8504798
train: epoch 23, iter 1800, loss: 2.841540, top_1: 0.549766, top_k: 0.777148, samples/s: 686.637 1613580057.13366
train: epoch 23, iter 1900, loss: 2.845424, top_1: 0.547305, top_k: 0.779531, samples/s: 682.511 1613580094.642136
train: epoch 23, iter 2000, loss: 2.854832, top_1: 0.551055, top_k: 0.782578, samples/s: 686.122 1613580131.9533615
train: epoch 23, iter 2100, loss: 2.897019, top_1: 0.552539, top_k: 0.778008, samples/s: 682.302 1613580169.4733312
train: epoch 23, iter 2200, loss: 2.896417, top_1: 0.551562, top_k: 0.784883, samples/s: 686.702 1613580206.7530046
train: epoch 23, iter 2300, loss: 2.724133, top_1: 0.546445, top_k: 0.782070, samples/s: 684.356 1613580244.160457
train: epoch 23, iter 2400, loss: 2.891369, top_1: 0.548359, top_k: 0.779258, samples/s: 686.187 1613580281.4681
train: epoch 23, iter 2500, loss: 2.897122, top_1: 0.549297, top_k: 0.783516, samples/s: 682.330 1613580318.9865646
train: epoch 23, iter 2600, loss: 2.983597, top_1: 0.548477, top_k: 0.782266, samples/s: 684.627 1613580356.3792377
train: epoch 23, iter 2700, loss: 2.800113, top_1: 0.552188, top_k: 0.781992, samples/s: 684.012 1613580393.8054767
train: epoch 23, iter 2800, loss: 2.670402, top_1: 0.555391, top_k: 0.782813, samples/s: 683.880 1613580431.238952
train: epoch 23, iter 2900, loss: 2.813118, top_1: 0.551914, top_k: 0.782383, samples/s: 683.152 1613580468.7123146
train: epoch 23, iter 3000, loss: 2.871997, top_1: 0.551367, top_k: 0.780820, samples/s: 684.940 1613580506.0878296
train: epoch 23, iter 3100, loss: 2.895817, top_1: 0.556523, top_k: 0.781445, samples/s: 684.810 1613580543.4705398
train: epoch 23, iter 3200, loss: 3.014276, top_1: 0.551016, top_k: 0.779844, samples/s: 683.694 1613580580.9141197
train: epoch 23, iter 3300, loss: 2.579819, top_1: 0.549219, top_k: 0.781367, samples/s: 683.219 1613580618.3838274
train: epoch 23, iter 3400, loss: 3.011993, top_1: 0.553672, top_k: 0.783516, samples/s: 684.586 1613580655.778719
train: epoch 23, iter 3500, loss: 2.782603, top_1: 0.551094, top_k: 0.779531, samples/s: 683.597 1613580693.2277112
train: epoch 23, iter 3600, loss: 2.965844, top_1: 0.542539, top_k: 0.775117, samples/s: 683.069 1613580730.7056599
train: epoch 23, iter 3700, loss: 2.544168, top_1: 0.550859, top_k: 0.781680, samples/s: 682.868 1613580768.194558
train: epoch 23, iter 3800, loss: 2.793721, top_1: 0.549102, top_k: 0.780312, samples/s: 684.493 1613580805.5944505
train: epoch 23, iter 3900, loss: 2.712168, top_1: 0.549648, top_k: 0.779375, samples/s: 685.113 1613580842.9604206
train: epoch 23, iter 4000, loss: 3.138335, top_1: 0.548438, top_k: 0.779961, samples/s: 684.218 1613580880.3755035
train: epoch 23, iter 4100, loss: 3.048558, top_1: 0.549883, top_k: 0.779102, samples/s: 683.612 1613580917.8236618
train: epoch 23, iter 4200, loss: 2.846873, top_1: 0.546094, top_k: 0.778242, samples/s: 683.844 1613580955.2590952
train: epoch 23, iter 4300, loss: 2.997195, top_1: 0.550586, top_k: 0.777266, samples/s: 683.885 1613580992.692299
train: epoch 23, iter 4400, loss: 2.954549, top_1: 0.550234, top_k: 0.780000, samples/s: 685.206 1613581030.0533113
train: epoch 23, iter 4500, loss: 2.855098, top_1: 0.545508, top_k: 0.780664, samples/s: 682.947 1613581067.5379493
train: epoch 23, iter 4600, loss: 3.072049, top_1: 0.546953, top_k: 0.777852, samples/s: 683.456 1613581104.9946482
train: epoch 23, iter 4700, loss: 2.900629, top_1: 0.543945, top_k: 0.778359, samples/s: 685.755 1613581142.3257778
train: epoch 23, iter 4800, loss: 2.899026, top_1: 0.553281, top_k: 0.778750, samples/s: 682.851 1613581179.815658
train: epoch 23, iter 4900, loss: 2.939860, top_1: 0.550937, top_k: 0.783594, samples/s: 681.472 1613581217.3813753
train: epoch 23, iter 5000, loss: 2.744775, top_1: 0.542305, top_k: 0.775508, samples/s: 684.063 1613581254.8047867
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_23.
validation: epoch 23, iter 195, top_1: 0.594872, top_k: 0.834175, samples/s: 2154.271 1613581279.108078
train: epoch 24, iter 100, loss: 2.823961, top_1: 0.559648, top_k: 0.791172, samples/s: 703.158 1613581336.8756938
train: epoch 24, iter 200, loss: 2.864993, top_1: 0.564336, top_k: 0.794258, samples/s: 699.736 1613581373.461018
train: epoch 24, iter 300, loss: 2.861095, top_1: 0.555352, top_k: 0.785117, samples/s: 682.027 1613581410.9960523
train: epoch 24, iter 400, loss: 2.790624, top_1: 0.560312, top_k: 0.790547, samples/s: 682.368 1613581448.512505
train: epoch 24, iter 500, loss: 2.931157, top_1: 0.556875, top_k: 0.790547, samples/s: 682.424 1613581486.0257664
train: epoch 24, iter 600, loss: 2.874084, top_1: 0.554453, top_k: 0.784687, samples/s: 681.715 1613581523.5781853
train: epoch 24, iter 700, loss: 2.717746, top_1: 0.549844, top_k: 0.782773, samples/s: 684.524 1613581560.9764066
train: epoch 24, iter 800, loss: 2.943482, top_1: 0.554492, top_k: 0.781836, samples/s: 683.410 1613581598.435674
train: epoch 24, iter 900, loss: 2.887718, top_1: 0.551641, top_k: 0.780156, samples/s: 684.627 1613581635.828341
train: epoch 24, iter 1000, loss: 2.969230, top_1: 0.554023, top_k: 0.783008, samples/s: 681.723 1613581673.3802154
train: epoch 24, iter 1100, loss: 2.953919, top_1: 0.548906, top_k: 0.779141, samples/s: 681.502 1613581710.9443173
train: epoch 24, iter 1200, loss: 2.950245, top_1: 0.552656, top_k: 0.785898, samples/s: 682.391 1613581748.459452
train: epoch 24, iter 1300, loss: 2.791756, top_1: 0.553242, top_k: 0.786094, samples/s: 683.426 1613581785.917785
train: epoch 24, iter 1400, loss: 2.864073, top_1: 0.554648, top_k: 0.784922, samples/s: 683.899 1613581823.350175
train: epoch 24, iter 1500, loss: 2.852946, top_1: 0.549609, top_k: 0.778438, samples/s: 682.127 1613581860.8797338
train: epoch 24, iter 1600, loss: 2.834920, top_1: 0.559375, top_k: 0.786133, samples/s: 682.992 1613581898.3619943
train: epoch 24, iter 1700, loss: 2.929508, top_1: 0.555000, top_k: 0.788984, samples/s: 683.187 1613581935.833438
train: epoch 24, iter 1800, loss: 2.897233, top_1: 0.553086, top_k: 0.784258, samples/s: 683.939 1613581973.2636466
train: epoch 24, iter 1900, loss: 2.890032, top_1: 0.557109, top_k: 0.785820, samples/s: 682.735 1613582010.7599006
train: epoch 24, iter 2000, loss: 2.959470, top_1: 0.548672, top_k: 0.782070, samples/s: 681.336 1613582048.3331175
train: epoch 24, iter 2100, loss: 2.862470, top_1: 0.555234, top_k: 0.779766, samples/s: 683.733 1613582085.7745142
train: epoch 24, iter 2200, loss: 2.744309, top_1: 0.556953, top_k: 0.784492, samples/s: 683.615 1613582123.2225375
train: epoch 24, iter 2300, loss: 2.931634, top_1: 0.554648, top_k: 0.785625, samples/s: 682.989 1613582160.7048953
train: epoch 24, iter 2400, loss: 2.750072, top_1: 0.548203, top_k: 0.781094, samples/s: 683.700 1613582198.1482356
train: epoch 24, iter 2500, loss: 2.775846, top_1: 0.551680, top_k: 0.785312, samples/s: 685.011 1613582235.519767
train: epoch 24, iter 2600, loss: 2.773635, top_1: 0.555195, top_k: 0.784687, samples/s: 681.377 1613582273.090834
train: epoch 24, iter 2700, loss: 2.985772, top_1: 0.549141, top_k: 0.780820, samples/s: 686.330 1613582310.3905818
train: epoch 24, iter 2800, loss: 2.845897, top_1: 0.554922, top_k: 0.788320, samples/s: 681.174 1613582347.972806
train: epoch 24, iter 2900, loss: 2.820571, top_1: 0.556758, top_k: 0.785078, samples/s: 683.957 1613582385.4019685
train: epoch 24, iter 3000, loss: 3.123641, top_1: 0.552305, top_k: 0.784141, samples/s: 683.397 1613582422.861974
train: epoch 24, iter 3100, loss: 2.776865, top_1: 0.553086, top_k: 0.781484, samples/s: 684.449 1613582460.2642972
train: epoch 24, iter 3200, loss: 2.886999, top_1: 0.548945, top_k: 0.780937, samples/s: 684.358 1613582497.671589
train: epoch 24, iter 3300, loss: 2.970839, top_1: 0.548203, top_k: 0.780117, samples/s: 683.755 1613582535.1119418
train: epoch 24, iter 3400, loss: 2.903856, top_1: 0.551133, top_k: 0.785117, samples/s: 682.175 1613582572.6389835
train: epoch 24, iter 3500, loss: 2.848313, top_1: 0.545781, top_k: 0.779375, samples/s: 685.640 1613582609.9763613
train: epoch 24, iter 3600, loss: 2.765904, top_1: 0.549063, top_k: 0.777461, samples/s: 684.621 1613582647.3691986
train: epoch 24, iter 3700, loss: 2.925652, top_1: 0.548516, top_k: 0.777188, samples/s: 682.129 1613582684.8987436
train: epoch 24, iter 3800, loss: 2.923097, top_1: 0.553359, top_k: 0.782305, samples/s: 683.780 1613582722.3377762
train: epoch 24, iter 3900, loss: 2.946508, top_1: 0.550586, top_k: 0.783398, samples/s: 683.904 1613582759.769996
train: epoch 24, iter 4000, loss: 3.093078, top_1: 0.553047, top_k: 0.780352, samples/s: 685.535 1613582797.1130226
train: epoch 24, iter 4100, loss: 2.728760, top_1: 0.549531, top_k: 0.779062, samples/s: 682.489 1613582834.6227832
train: epoch 24, iter 4200, loss: 2.692527, top_1: 0.552578, top_k: 0.780352, samples/s: 682.732 1613582872.1192389
train: epoch 24, iter 4300, loss: 3.016802, top_1: 0.538242, top_k: 0.778125, samples/s: 683.847 1613582909.5544455
train: epoch 24, iter 4400, loss: 2.877297, top_1: 0.548047, top_k: 0.778320, samples/s: 684.164 1613582946.9723876
train: epoch 24, iter 4500, loss: 2.790581, top_1: 0.543828, top_k: 0.774023, samples/s: 687.304 1613582984.2192893
train: epoch 24, iter 4600, loss: 2.807460, top_1: 0.552891, top_k: 0.784414, samples/s: 681.864 1613583021.7634826
train: epoch 24, iter 4700, loss: 2.690593, top_1: 0.550859, top_k: 0.779766, samples/s: 682.307 1613583059.283201
train: epoch 24, iter 4800, loss: 2.952703, top_1: 0.555820, top_k: 0.787695, samples/s: 684.813 1613583096.6656764
train: epoch 24, iter 4900, loss: 2.919188, top_1: 0.546406, top_k: 0.778633, samples/s: 682.280 1613583134.1869977
train: epoch 24, iter 5000, loss: 2.962287, top_1: 0.550391, top_k: 0.780586, samples/s: 683.733 1613583171.62848
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_24.
validation: epoch 24, iter 195, top_1: 0.595593, top_k: 0.834135, samples/s: 2147.923 1613583195.9819696
train: epoch 25, iter 100, loss: 3.023512, top_1: 0.570820, top_k: 0.796875, samples/s: 703.853 1613583253.4495897
train: epoch 25, iter 200, loss: 2.853758, top_1: 0.562930, top_k: 0.791680, samples/s: 696.517 1613583290.204128
train: epoch 25, iter 300, loss: 2.812454, top_1: 0.557070, top_k: 0.787734, samples/s: 683.609 1613583327.6521492
train: epoch 25, iter 400, loss: 2.933697, top_1: 0.558086, top_k: 0.784883, samples/s: 680.385 1613583365.2779934
train: epoch 25, iter 500, loss: 2.939918, top_1: 0.560312, top_k: 0.787969, samples/s: 682.143 1613583402.8068273
train: epoch 25, iter 600, loss: 2.822408, top_1: 0.559063, top_k: 0.785703, samples/s: 682.561 1613583440.312617
train: epoch 25, iter 700, loss: 2.743254, top_1: 0.553164, top_k: 0.786094, samples/s: 682.416 1613583477.8263042
train: epoch 25, iter 800, loss: 2.953483, top_1: 0.554180, top_k: 0.784531, samples/s: 683.674 1613583515.2711265
train: epoch 25, iter 900, loss: 2.867348, top_1: 0.554102, top_k: 0.787539, samples/s: 682.497 1613583552.780461
train: epoch 25, iter 1000, loss: 2.876983, top_1: 0.553398, top_k: 0.781602, samples/s: 686.133 1613583590.0909991
train: epoch 25, iter 1100, loss: 2.729084, top_1: 0.555469, top_k: 0.781211, samples/s: 683.124 1613583627.5659802
train: epoch 25, iter 1200, loss: 2.731294, top_1: 0.553438, top_k: 0.783789, samples/s: 682.695 1613583665.0642984
train: epoch 25, iter 1300, loss: 2.795773, top_1: 0.559063, top_k: 0.788711, samples/s: 685.034 1613583702.4348025
train: epoch 25, iter 1400, loss: 2.915181, top_1: 0.552734, top_k: 0.782891, samples/s: 687.242 1613583739.6851215
train: epoch 25, iter 1500, loss: 2.924599, top_1: 0.558398, top_k: 0.787539, samples/s: 681.034 1613583777.2749994
train: epoch 25, iter 1600, loss: 2.915256, top_1: 0.554609, top_k: 0.785508, samples/s: 684.590 1613583814.6696253
train: epoch 25, iter 1700, loss: 2.853253, top_1: 0.559609, top_k: 0.783516, samples/s: 682.029 1613583852.2047055
train: epoch 25, iter 1800, loss: 2.896543, top_1: 0.558164, top_k: 0.787031, samples/s: 684.392 1613583889.6101747
train: epoch 25, iter 1900, loss: 2.974864, top_1: 0.552148, top_k: 0.784844, samples/s: 684.671 1613583927.000372
train: epoch 25, iter 2000, loss: 2.808670, top_1: 0.554922, top_k: 0.781875, samples/s: 683.665 1613583964.445561
train: epoch 25, iter 2100, loss: 2.766062, top_1: 0.551172, top_k: 0.779727, samples/s: 683.206 1613584001.9159775
train: epoch 25, iter 2200, loss: 2.953885, top_1: 0.547617, top_k: 0.780273, samples/s: 685.371 1613584039.2680264
train: epoch 25, iter 2300, loss: 2.729826, top_1: 0.554648, top_k: 0.786523, samples/s: 683.237 1613584076.7367203
train: epoch 25, iter 2400, loss: 2.800653, top_1: 0.551250, top_k: 0.784023, samples/s: 684.240 1613584114.1504664
train: epoch 25, iter 2500, loss: 2.887070, top_1: 0.553633, top_k: 0.782891, samples/s: 684.282 1613584151.5619462
train: epoch 25, iter 2600, loss: 2.561580, top_1: 0.555977, top_k: 0.788008, samples/s: 684.781 1613584188.9461613
train: epoch 25, iter 2700, loss: 2.761788, top_1: 0.555859, top_k: 0.787109, samples/s: 684.608 1613584226.3397949
train: epoch 25, iter 2800, loss: 2.797528, top_1: 0.552539, top_k: 0.783828, samples/s: 681.682 1613584263.893989
train: epoch 25, iter 2900, loss: 2.789726, top_1: 0.552227, top_k: 0.778281, samples/s: 683.823 1613584301.330453
train: epoch 25, iter 3000, loss: 2.855872, top_1: 0.555664, top_k: 0.786289, samples/s: 683.672 1613584338.775452
train: epoch 25, iter 3100, loss: 2.810230, top_1: 0.556016, top_k: 0.784609, samples/s: 682.789 1613584376.2686937
train: epoch 25, iter 3200, loss: 2.833523, top_1: 0.552852, top_k: 0.782109, samples/s: 684.094 1613584413.6903543
train: epoch 25, iter 3300, loss: 2.744296, top_1: 0.552695, top_k: 0.783906, samples/s: 683.990 1613584451.1178567
train: epoch 25, iter 3400, loss: 2.730145, top_1: 0.555195, top_k: 0.786914, samples/s: 684.224 1613584488.5325208
train: epoch 25, iter 3500, loss: 2.859868, top_1: 0.552695, top_k: 0.781719, samples/s: 682.426 1613584526.0457551
train: epoch 25, iter 3600, loss: 2.891209, top_1: 0.548164, top_k: 0.780508, samples/s: 683.954 1613584563.475219
train: epoch 25, iter 3700, loss: 2.964153, top_1: 0.550742, top_k: 0.782539, samples/s: 683.752 1613584600.9155505
train: epoch 25, iter 3800, loss: 2.889216, top_1: 0.548945, top_k: 0.780742, samples/s: 685.881 1613584638.239917
train: epoch 25, iter 3900, loss: 2.842892, top_1: 0.557617, top_k: 0.783555, samples/s: 683.720 1613584675.682082
train: epoch 25, iter 4000, loss: 2.740570, top_1: 0.551211, top_k: 0.783789, samples/s: 683.902 1613584713.1143837
train: epoch 25, iter 4100, loss: 2.876222, top_1: 0.552266, top_k: 0.781914, samples/s: 685.366 1613584750.4666975
train: epoch 25, iter 4200, loss: 2.992445, top_1: 0.553516, top_k: 0.787031, samples/s: 682.335 1613584787.9849057
train: epoch 25, iter 4300, loss: 2.875168, top_1: 0.549531, top_k: 0.777891, samples/s: 685.613 1613584825.3238096
train: epoch 25, iter 4400, loss: 3.014053, top_1: 0.552500, top_k: 0.785195, samples/s: 684.369 1613584862.7304764
train: epoch 25, iter 4500, loss: 2.844130, top_1: 0.546875, top_k: 0.783984, samples/s: 684.130 1613584900.150289
train: epoch 25, iter 4600, loss: 2.960368, top_1: 0.549727, top_k: 0.780195, samples/s: 683.822 1613584937.586828
train: epoch 25, iter 4700, loss: 2.929119, top_1: 0.549844, top_k: 0.779492, samples/s: 683.557 1613584975.0381174
train: epoch 25, iter 4800, loss: 2.950886, top_1: 0.556172, top_k: 0.784727, samples/s: 683.331 1613585012.5016856
train: epoch 25, iter 4900, loss: 2.952895, top_1: 0.553984, top_k: 0.783711, samples/s: 683.893 1613585049.9344628
train: epoch 25, iter 5000, loss: 2.896642, top_1: 0.554180, top_k: 0.781250, samples/s: 683.497 1613585087.3888712
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_25.
validation: epoch 25, iter 195, top_1: 0.607352, top_k: 0.842087, samples/s: 2172.748 1613585111.518721
train: epoch 26, iter 100, loss: 2.720834, top_1: 0.570859, top_k: 0.793828, samples/s: 702.865 1613585168.8910859
train: epoch 26, iter 200, loss: 2.864013, top_1: 0.570508, top_k: 0.799219, samples/s: 696.511 1613585205.6459286
train: epoch 26, iter 300, loss: 2.828633, top_1: 0.564141, top_k: 0.792813, samples/s: 682.071 1613585243.1784742
train: epoch 26, iter 400, loss: 2.917303, top_1: 0.561133, top_k: 0.794336, samples/s: 681.539 1613585280.7404063
train: epoch 26, iter 500, loss: 2.667434, top_1: 0.565039, top_k: 0.788828, samples/s: 679.517 1613585318.4143257
train: epoch 26, iter 600, loss: 2.894807, top_1: 0.556641, top_k: 0.788906, samples/s: 683.787 1613585355.8528895
train: epoch 26, iter 700, loss: 2.939209, top_1: 0.557969, top_k: 0.788945, samples/s: 683.670 1613585393.2978394
train: epoch 26, iter 800, loss: 2.773718, top_1: 0.554219, top_k: 0.785078, samples/s: 681.338 1613585430.8709838
train: epoch 26, iter 900, loss: 2.608824, top_1: 0.561172, top_k: 0.785898, samples/s: 683.821 1613585468.3076575
train: epoch 26, iter 1000, loss: 2.910549, top_1: 0.558945, top_k: 0.788086, samples/s: 681.553 1613585505.8688745
train: epoch 26, iter 1100, loss: 2.689198, top_1: 0.561406, top_k: 0.789180, samples/s: 684.844 1613585543.2496746
train: epoch 26, iter 1200, loss: 2.823896, top_1: 0.549180, top_k: 0.780000, samples/s: 684.285 1613585580.6609395
train: epoch 26, iter 1300, loss: 2.901406, top_1: 0.546797, top_k: 0.779805, samples/s: 683.419 1613585618.1197026
train: epoch 26, iter 1400, loss: 2.770127, top_1: 0.551484, top_k: 0.783242, samples/s: 684.171 1613585655.5372772
train: epoch 26, iter 1500, loss: 3.004732, top_1: 0.545586, top_k: 0.779102, samples/s: 684.575 1613585692.932696
train: epoch 26, iter 1600, loss: 2.837676, top_1: 0.551758, top_k: 0.785508, samples/s: 681.371 1613585730.503859
train: epoch 26, iter 1700, loss: 2.899967, top_1: 0.553125, top_k: 0.782031, samples/s: 685.182 1613585767.8662612
train: epoch 26, iter 1800, loss: 2.880862, top_1: 0.558906, top_k: 0.784609, samples/s: 686.711 1613585805.1453278
train: epoch 26, iter 1900, loss: 3.039660, top_1: 0.553594, top_k: 0.786602, samples/s: 684.980 1613585842.5188031
train: epoch 26, iter 2000, loss: 2.794027, top_1: 0.556367, top_k: 0.781211, samples/s: 681.938 1613585880.0588536
train: epoch 26, iter 2100, loss: 2.875103, top_1: 0.555117, top_k: 0.783398, samples/s: 684.976 1613585917.4324243
train: epoch 26, iter 2200, loss: 2.710533, top_1: 0.557266, top_k: 0.790469, samples/s: 682.640 1613585954.9337904
train: epoch 26, iter 2300, loss: 2.681602, top_1: 0.560859, top_k: 0.790312, samples/s: 684.540 1613585992.3313258
train: epoch 26, iter 2400, loss: 2.927052, top_1: 0.557031, top_k: 0.783398, samples/s: 683.691 1613586029.7751117
train: epoch 26, iter 2500, loss: 2.603106, top_1: 0.556797, top_k: 0.789414, samples/s: 682.311 1613586067.2945943
train: epoch 26, iter 2600, loss: 2.814009, top_1: 0.552305, top_k: 0.787109, samples/s: 683.353 1613586104.7569392
train: epoch 26, iter 2700, loss: 2.686047, top_1: 0.550391, top_k: 0.782148, samples/s: 682.585 1613586142.2614589
train: epoch 26, iter 2800, loss: 2.897905, top_1: 0.556758, top_k: 0.787695, samples/s: 682.264 1613586179.783553
train: epoch 26, iter 2900, loss: 2.951221, top_1: 0.554414, top_k: 0.789648, samples/s: 685.750 1613586217.1148992
train: epoch 26, iter 3000, loss: 2.681082, top_1: 0.556055, top_k: 0.787188, samples/s: 681.469 1613586254.6807795
train: epoch 26, iter 3100, loss: 2.838050, top_1: 0.556680, top_k: 0.782695, samples/s: 685.499 1613586292.025869
train: epoch 26, iter 3200, loss: 2.852770, top_1: 0.550469, top_k: 0.781914, samples/s: 680.907 1613586329.6227074
train: epoch 26, iter 3300, loss: 2.793220, top_1: 0.551836, top_k: 0.778438, samples/s: 683.836 1613586367.0585454
train: epoch 26, iter 3400, loss: 2.934502, top_1: 0.555234, top_k: 0.783594, samples/s: 683.663 1613586404.5039275
train: epoch 26, iter 3500, loss: 2.934356, top_1: 0.556523, top_k: 0.781016, samples/s: 684.579 1613586441.8991864
train: epoch 26, iter 3600, loss: 3.022280, top_1: 0.550156, top_k: 0.780391, samples/s: 683.312 1613586479.3637822
train: epoch 26, iter 3700, loss: 2.714323, top_1: 0.561641, top_k: 0.786914, samples/s: 683.933 1613586516.7942617
train: epoch 26, iter 3800, loss: 2.936949, top_1: 0.555430, top_k: 0.782578, samples/s: 681.665 1613586554.3494315
train: epoch 26, iter 3900, loss: 2.741321, top_1: 0.554648, top_k: 0.781445, samples/s: 684.334 1613586591.758065
train: epoch 26, iter 4000, loss: 2.797131, top_1: 0.549453, top_k: 0.780586, samples/s: 682.880 1613586629.246302
train: epoch 26, iter 4100, loss: 2.710052, top_1: 0.549102, top_k: 0.783672, samples/s: 683.834 1613586666.6822486
train: epoch 26, iter 4200, loss: 2.674013, top_1: 0.551602, top_k: 0.782852, samples/s: 683.860 1613586704.1167772
train: epoch 26, iter 4300, loss: 2.900972, top_1: 0.551523, top_k: 0.780937, samples/s: 682.671 1613586741.6165314
train: epoch 26, iter 4400, loss: 2.859361, top_1: 0.555078, top_k: 0.783164, samples/s: 685.572 1613586778.9577074
train: epoch 26, iter 4500, loss: 2.747880, top_1: 0.552969, top_k: 0.783633, samples/s: 682.698 1613586816.4558892
train: epoch 26, iter 4600, loss: 2.967194, top_1: 0.548398, top_k: 0.780547, samples/s: 684.212 1613586853.871284
train: epoch 26, iter 4700, loss: 2.856894, top_1: 0.547227, top_k: 0.778516, samples/s: 683.208 1613586891.3415477
train: epoch 26, iter 4800, loss: 2.859568, top_1: 0.549531, top_k: 0.784336, samples/s: 683.360 1613586928.8035252
train: epoch 26, iter 4900, loss: 2.869075, top_1: 0.551211, top_k: 0.785391, samples/s: 683.446 1613586966.2607636
train: epoch 26, iter 5000, loss: 2.751669, top_1: 0.551836, top_k: 0.783164, samples/s: 683.129 1613587003.7353783
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_26.
validation: epoch 26, iter 195, top_1: 0.604808, top_k: 0.838762, samples/s: 2165.267 1613587027.8913827
train: epoch 27, iter 100, loss: 2.652420, top_1: 0.568242, top_k: 0.796914, samples/s: 702.585 1613587085.9704878
train: epoch 27, iter 200, loss: 2.606237, top_1: 0.567813, top_k: 0.791797, samples/s: 698.185 1613587122.6369827
train: epoch 27, iter 300, loss: 2.714013, top_1: 0.570859, top_k: 0.797383, samples/s: 683.468 1613587160.092838
train: epoch 27, iter 400, loss: 2.876825, top_1: 0.560742, top_k: 0.786289, samples/s: 682.144 1613587197.62169
train: epoch 27, iter 500, loss: 2.680057, top_1: 0.564336, top_k: 0.792422, samples/s: 680.510 1613587235.240518
train: epoch 27, iter 600, loss: 2.806466, top_1: 0.557578, top_k: 0.789922, samples/s: 681.543 1613587272.8023093
train: epoch 27, iter 700, loss: 2.874271, top_1: 0.562734, top_k: 0.788008, samples/s: 681.216 1613587310.3820982
train: epoch 27, iter 800, loss: 2.770697, top_1: 0.560430, top_k: 0.788594, samples/s: 682.844 1613587347.872476
train: epoch 27, iter 900, loss: 2.932732, top_1: 0.558867, top_k: 0.788633, samples/s: 682.236 1613587385.396077
train: epoch 27, iter 1000, loss: 2.930820, top_1: 0.564023, top_k: 0.791719, samples/s: 681.520 1613587422.9592
train: epoch 27, iter 1100, loss: 3.061924, top_1: 0.559609, top_k: 0.788789, samples/s: 679.253 1613587460.647677
train: epoch 27, iter 1200, loss: 2.853397, top_1: 0.557930, top_k: 0.787891, samples/s: 681.936 1613587498.1878471
train: epoch 27, iter 1300, loss: 2.649636, top_1: 0.559258, top_k: 0.786953, samples/s: 684.117 1613587535.6082184
train: epoch 27, iter 1400, loss: 2.914513, top_1: 0.556758, top_k: 0.787852, samples/s: 682.591 1613587573.1123836
train: epoch 27, iter 1500, loss: 2.763458, top_1: 0.558359, top_k: 0.790234, samples/s: 683.752 1613587610.5529099
train: epoch 27, iter 1600, loss: 2.894145, top_1: 0.550547, top_k: 0.780039, samples/s: 680.868 1613587648.152052
train: epoch 27, iter 1700, loss: 2.776427, top_1: 0.557266, top_k: 0.788906, samples/s: 685.045 1613587685.5217822
train: epoch 27, iter 1800, loss: 3.039306, top_1: 0.560000, top_k: 0.787813, samples/s: 681.072 1613587723.1095793
train: epoch 27, iter 1900, loss: 2.853200, top_1: 0.556133, top_k: 0.785664, samples/s: 682.474 1613587760.620181
train: epoch 27, iter 2000, loss: 2.767595, top_1: 0.560156, top_k: 0.789414, samples/s: 682.454 1613587798.1319282
train: epoch 27, iter 2100, loss: 2.992116, top_1: 0.555117, top_k: 0.782969, samples/s: 683.075 1613587835.609522
train: epoch 27, iter 2200, loss: 2.814801, top_1: 0.556836, top_k: 0.789219, samples/s: 681.507 1613587873.1733463
train: epoch 27, iter 2300, loss: 2.928860, top_1: 0.557383, top_k: 0.787227, samples/s: 682.390 1613587910.6885247
train: epoch 27, iter 2400, loss: 2.799998, top_1: 0.555430, top_k: 0.785781, samples/s: 685.341 1613587948.0421348
train: epoch 27, iter 2500, loss: 2.800910, top_1: 0.559375, top_k: 0.788906, samples/s: 680.944 1613587985.6370492
train: epoch 27, iter 2600, loss: 2.748811, top_1: 0.561172, top_k: 0.787266, samples/s: 685.217 1613588022.997519
train: epoch 27, iter 2700, loss: 2.721617, top_1: 0.552891, top_k: 0.784062, samples/s: 681.644 1613588060.5536883
train: epoch 27, iter 2800, loss: 2.866897, top_1: 0.555312, top_k: 0.789180, samples/s: 683.197 1613588098.0246892
train: epoch 27, iter 2900, loss: 2.842753, top_1: 0.559883, top_k: 0.787578, samples/s: 682.840 1613588135.5150142
train: epoch 27, iter 3000, loss: 2.805102, top_1: 0.559336, top_k: 0.788945, samples/s: 681.281 1613588173.0913465
train: epoch 27, iter 3100, loss: 2.764669, top_1: 0.551562, top_k: 0.786016, samples/s: 681.220 1613588210.6709404
train: epoch 27, iter 3200, loss: 2.721639, top_1: 0.557539, top_k: 0.787734, samples/s: 684.428 1613588248.0745277
train: epoch 27, iter 3300, loss: 2.959003, top_1: 0.554102, top_k: 0.786211, samples/s: 683.718 1613588285.5168626
train: epoch 27, iter 3400, loss: 2.830487, top_1: 0.560391, top_k: 0.789922, samples/s: 681.607 1613588323.0751963
train: epoch 27, iter 3500, loss: 2.714288, top_1: 0.557500, top_k: 0.788711, samples/s: 682.601 1613588360.5787158
train: epoch 27, iter 3600, loss: 2.856281, top_1: 0.553828, top_k: 0.784414, samples/s: 683.134 1613588398.0531087
train: epoch 27, iter 3700, loss: 2.685682, top_1: 0.554336, top_k: 0.783398, samples/s: 683.982 1613588435.4810174
train: epoch 27, iter 3800, loss: 2.942527, top_1: 0.554141, top_k: 0.783867, samples/s: 680.552 1613588473.0974844
train: epoch 27, iter 3900, loss: 2.816554, top_1: 0.556523, top_k: 0.787148, samples/s: 685.731 1613588510.429997
train: epoch 27, iter 4000, loss: 2.928889, top_1: 0.553398, top_k: 0.783477, samples/s: 683.659 1613588547.8755214
train: epoch 27, iter 4100, loss: 2.801028, top_1: 0.553633, top_k: 0.783359, samples/s: 682.018 1613588585.4112246
train: epoch 27, iter 4200, loss: 2.919226, top_1: 0.552773, top_k: 0.785039, samples/s: 683.795 1613588622.849276
train: epoch 27, iter 4300, loss: 2.670083, top_1: 0.552734, top_k: 0.782422, samples/s: 683.109 1613588660.325013
train: epoch 27, iter 4400, loss: 2.915663, top_1: 0.552813, top_k: 0.784492, samples/s: 683.202 1613588697.7956307
train: epoch 27, iter 4500, loss: 2.758809, top_1: 0.556289, top_k: 0.783867, samples/s: 684.737 1613588735.1822596
train: epoch 27, iter 4600, loss: 3.011921, top_1: 0.556680, top_k: 0.787305, samples/s: 683.037 1613588772.6619036
train: epoch 27, iter 4700, loss: 3.006943, top_1: 0.553164, top_k: 0.782656, samples/s: 684.737 1613588810.0485435
train: epoch 27, iter 4800, loss: 2.867495, top_1: 0.557070, top_k: 0.785312, samples/s: 682.648 1613588847.5496004
train: epoch 27, iter 4900, loss: 2.814134, top_1: 0.552461, top_k: 0.779297, samples/s: 685.091 1613588884.916864
train: epoch 27, iter 5000, loss: 2.731130, top_1: 0.560664, top_k: 0.788711, samples/s: 684.412 1613588922.321269
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_27.
validation: epoch 27, iter 195, top_1: 0.592548, top_k: 0.832853, samples/s: 2145.630 1613588946.677764
train: epoch 28, iter 100, loss: 2.829133, top_1: 0.567813, top_k: 0.798047, samples/s: 702.229 1613589005.1350422
train: epoch 28, iter 200, loss: 3.067986, top_1: 0.570898, top_k: 0.791992, samples/s: 697.284 1613589041.8489177
train: epoch 28, iter 300, loss: 2.729570, top_1: 0.564688, top_k: 0.796055, samples/s: 683.655 1613589079.2946703
train: epoch 28, iter 400, loss: 2.882755, top_1: 0.569844, top_k: 0.797383, samples/s: 681.369 1613589116.8661516
train: epoch 28, iter 500, loss: 2.963423, top_1: 0.561133, top_k: 0.790156, samples/s: 684.824 1613589154.248043
train: epoch 28, iter 600, loss: 2.768430, top_1: 0.562891, top_k: 0.785977, samples/s: 681.311 1613589191.8226376
train: epoch 28, iter 700, loss: 2.633058, top_1: 0.563906, top_k: 0.788828, samples/s: 683.118 1613589229.297775
train: epoch 28, iter 800, loss: 3.034830, top_1: 0.568203, top_k: 0.793047, samples/s: 682.940 1613589266.7828732
train: epoch 28, iter 900, loss: 2.634047, top_1: 0.563633, top_k: 0.789062, samples/s: 682.781 1613589304.2765627
train: epoch 28, iter 1000, loss: 2.853167, top_1: 0.562539, top_k: 0.790742, samples/s: 681.809 1613589341.8237646
train: epoch 28, iter 1100, loss: 2.919959, top_1: 0.564727, top_k: 0.789258, samples/s: 681.240 1613589379.4022727
train: epoch 28, iter 1200, loss: 2.910561, top_1: 0.556719, top_k: 0.793828, samples/s: 681.329 1613589416.9759078
train: epoch 28, iter 1300, loss: 2.751603, top_1: 0.559727, top_k: 0.787656, samples/s: 680.153 1613589454.614524
train: epoch 28, iter 1400, loss: 2.814620, top_1: 0.564297, top_k: 0.792578, samples/s: 684.202 1613589492.030372
train: epoch 28, iter 1500, loss: 2.796759, top_1: 0.558438, top_k: 0.787930, samples/s: 682.226 1613589529.5544925
train: epoch 28, iter 1600, loss: 2.910236, top_1: 0.558125, top_k: 0.787852, samples/s: 681.665 1613589567.1096642
train: epoch 28, iter 1700, loss: 2.919209, top_1: 0.558555, top_k: 0.789219, samples/s: 683.360 1613589604.5716372
train: epoch 28, iter 1800, loss: 2.984099, top_1: 0.554414, top_k: 0.787109, samples/s: 683.636 1613589642.0184064
train: epoch 28, iter 1900, loss: 2.959914, top_1: 0.561875, top_k: 0.791719, samples/s: 681.418 1613589679.5872648
train: epoch 28, iter 2000, loss: 2.835062, top_1: 0.563047, top_k: 0.790430, samples/s: 681.310 1613589717.1618264
train: epoch 28, iter 2100, loss: 2.881911, top_1: 0.559297, top_k: 0.785742, samples/s: 682.775 1613589754.6557555
train: epoch 28, iter 2200, loss: 2.893790, top_1: 0.559766, top_k: 0.792422, samples/s: 682.462 1613589792.1671126
train: epoch 28, iter 2300, loss: 3.052127, top_1: 0.556172, top_k: 0.787383, samples/s: 683.494 1613589829.6216643
train: epoch 28, iter 2400, loss: 2.734325, top_1: 0.553867, top_k: 0.786094, samples/s: 683.862 1613589867.0561883
train: epoch 28, iter 2500, loss: 2.782906, top_1: 0.559805, top_k: 0.788320, samples/s: 682.914 1613589904.5425684
train: epoch 28, iter 2600, loss: 2.778146, top_1: 0.555234, top_k: 0.789805, samples/s: 683.053 1613589942.0213523
train: epoch 28, iter 2700, loss: 2.709429, top_1: 0.556602, top_k: 0.789023, samples/s: 682.682 1613589979.520482
train: epoch 28, iter 2800, loss: 3.032936, top_1: 0.556641, top_k: 0.786797, samples/s: 683.054 1613590016.9992614
train: epoch 28, iter 2900, loss: 2.709363, top_1: 0.555234, top_k: 0.785742, samples/s: 682.956 1613590054.4832745
train: epoch 28, iter 3000, loss: 2.867487, top_1: 0.558984, top_k: 0.789883, samples/s: 684.091 1613590091.9052167
train: epoch 28, iter 3100, loss: 2.954044, top_1: 0.554492, top_k: 0.785195, samples/s: 682.885 1613590129.3932252
train: epoch 28, iter 3200, loss: 2.854181, top_1: 0.556406, top_k: 0.785234, samples/s: 684.679 1613590166.7831047
train: epoch 28, iter 3300, loss: 2.761467, top_1: 0.556445, top_k: 0.782383, samples/s: 682.130 1613590204.3126135
train: epoch 28, iter 3400, loss: 2.594402, top_1: 0.563164, top_k: 0.792500, samples/s: 683.158 1613590241.7856681
train: epoch 28, iter 3500, loss: 2.954599, top_1: 0.565742, top_k: 0.790937, samples/s: 683.670 1613590279.2306056
train: epoch 28, iter 3600, loss: 2.678534, top_1: 0.559688, top_k: 0.789414, samples/s: 682.962 1613590316.714457
train: epoch 28, iter 3700, loss: 2.813658, top_1: 0.563281, top_k: 0.790703, samples/s: 682.233 1613590354.2382355
train: epoch 28, iter 3800, loss: 3.061934, top_1: 0.555000, top_k: 0.785859, samples/s: 684.077 1613590391.6610055
train: epoch 28, iter 3900, loss: 2.964131, top_1: 0.556602, top_k: 0.786211, samples/s: 685.440 1613590429.0092194
train: epoch 28, iter 4000, loss: 3.127572, top_1: 0.554531, top_k: 0.781406, samples/s: 683.251 1613590466.4772396
train: epoch 28, iter 4100, loss: 2.922565, top_1: 0.554258, top_k: 0.785742, samples/s: 683.510 1613590503.9309165
train: epoch 28, iter 4200, loss: 2.840981, top_1: 0.553672, top_k: 0.783789, samples/s: 684.150 1613590541.3496695
train: epoch 28, iter 4300, loss: 2.944779, top_1: 0.552539, top_k: 0.784570, samples/s: 682.506 1613590578.8584304
train: epoch 28, iter 4400, loss: 2.917810, top_1: 0.554805, top_k: 0.786367, samples/s: 683.068 1613590616.3363855
train: epoch 28, iter 4500, loss: 3.117985, top_1: 0.561562, top_k: 0.788242, samples/s: 684.297 1613590653.7471201
train: epoch 28, iter 4600, loss: 2.953080, top_1: 0.556367, top_k: 0.785625, samples/s: 683.549 1613590691.1987402
train: epoch 28, iter 4700, loss: 2.849687, top_1: 0.559102, top_k: 0.785977, samples/s: 684.287 1613590728.6099396
train: epoch 28, iter 4800, loss: 2.882777, top_1: 0.559688, top_k: 0.785352, samples/s: 683.474 1613590766.0655448
train: epoch 28, iter 4900, loss: 2.817548, top_1: 0.554102, top_k: 0.784453, samples/s: 685.467 1613590803.4124227
train: epoch 28, iter 5000, loss: 2.849197, top_1: 0.557852, top_k: 0.787148, samples/s: 684.285 1613590840.8237216
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_28.
validation: epoch 28, iter 195, top_1: 0.614463, top_k: 0.845713, samples/s: 2162.952 1613590865.0056722
train: epoch 29, iter 100, loss: 2.884062, top_1: 0.561445, top_k: 0.794141, samples/s: 703.618 1613590923.1897476
train: epoch 29, iter 200, loss: 2.809208, top_1: 0.572266, top_k: 0.796289, samples/s: 696.688 1613590959.9349923
train: epoch 29, iter 300, loss: 2.625500, top_1: 0.565312, top_k: 0.796289, samples/s: 686.065 1613590997.24928
train: epoch 29, iter 400, loss: 2.846980, top_1: 0.568711, top_k: 0.796250, samples/s: 677.486 1613591035.035989
train: epoch 29, iter 500, loss: 2.666535, top_1: 0.565508, top_k: 0.791953, samples/s: 682.954 1613591072.520213
train: epoch 29, iter 600, loss: 2.695310, top_1: 0.564961, top_k: 0.792891, samples/s: 683.323 1613591109.9841475
train: epoch 29, iter 700, loss: 2.800581, top_1: 0.561914, top_k: 0.793242, samples/s: 683.044 1613591147.4635203
train: epoch 29, iter 800, loss: 2.678873, top_1: 0.565391, top_k: 0.791914, samples/s: 684.287 1613591184.8747203
train: epoch 29, iter 900, loss: 2.721049, top_1: 0.565742, top_k: 0.792891, samples/s: 681.995 1613591222.4115613
train: epoch 29, iter 1000, loss: 2.830728, top_1: 0.560742, top_k: 0.796680, samples/s: 683.503 1613591259.8657796
train: epoch 29, iter 1100, loss: 2.662344, top_1: 0.565273, top_k: 0.794453, samples/s: 683.136 1613591297.3399959
train: epoch 29, iter 1200, loss: 2.823974, top_1: 0.564844, top_k: 0.792422, samples/s: 681.572 1613591334.900158
train: epoch 29, iter 1300, loss: 2.705542, top_1: 0.566289, top_k: 0.789922, samples/s: 683.912 1613591372.3319566
train: epoch 29, iter 1400, loss: 2.843478, top_1: 0.558555, top_k: 0.790859, samples/s: 683.079 1613591409.8093104
train: epoch 29, iter 1500, loss: 2.940061, top_1: 0.556953, top_k: 0.785859, samples/s: 684.768 1613591447.19414
train: epoch 29, iter 1600, loss: 2.758852, top_1: 0.561562, top_k: 0.791641, samples/s: 681.833 1613591484.739982
train: epoch 29, iter 1700, loss: 2.513999, top_1: 0.558750, top_k: 0.791016, samples/s: 682.288 1613591522.2607713
train: epoch 29, iter 1800, loss: 2.766819, top_1: 0.560352, top_k: 0.789219, samples/s: 684.543 1613591559.6580765
train: epoch 29, iter 1900, loss: 2.984352, top_1: 0.561562, top_k: 0.788750, samples/s: 682.830 1613591597.1490843
train: epoch 29, iter 2000, loss: 2.830005, top_1: 0.566758, top_k: 0.791289, samples/s: 682.132 1613591634.6784484
train: epoch 29, iter 2100, loss: 2.913074, top_1: 0.558398, top_k: 0.788008, samples/s: 683.211 1613591672.14857
train: epoch 29, iter 2200, loss: 2.754623, top_1: 0.561602, top_k: 0.789727, samples/s: 683.838 1613591709.5844135
train: epoch 29, iter 2300, loss: 2.904597, top_1: 0.565508, top_k: 0.788086, samples/s: 683.565 1613591747.0351002
train: epoch 29, iter 2400, loss: 2.775305, top_1: 0.563086, top_k: 0.790234, samples/s: 681.195 1613591784.616205
train: epoch 29, iter 2500, loss: 2.974417, top_1: 0.561133, top_k: 0.791328, samples/s: 684.008 1613591822.0426104
train: epoch 29, iter 2600, loss: 2.658974, top_1: 0.558750, top_k: 0.789844, samples/s: 682.060 1613591859.5759468
train: epoch 29, iter 2700, loss: 2.879458, top_1: 0.559023, top_k: 0.786133, samples/s: 683.189 1613591897.047278
train: epoch 29, iter 2800, loss: 2.848664, top_1: 0.562148, top_k: 0.787305, samples/s: 681.534 1613591934.6096003
train: epoch 29, iter 2900, loss: 2.684916, top_1: 0.557578, top_k: 0.784766, samples/s: 681.683 1613591972.163716
train: epoch 29, iter 3000, loss: 2.894601, top_1: 0.561406, top_k: 0.792773, samples/s: 683.726 1613592009.6054873
train: epoch 29, iter 3100, loss: 2.884848, top_1: 0.563203, top_k: 0.788867, samples/s: 682.533 1613592047.112883
train: epoch 29, iter 3200, loss: 2.986631, top_1: 0.557344, top_k: 0.783906, samples/s: 682.398 1613592084.627699
train: epoch 29, iter 3300, loss: 2.730541, top_1: 0.558906, top_k: 0.784883, samples/s: 683.525 1613592122.0805304
train: epoch 29, iter 3400, loss: 2.789716, top_1: 0.557930, top_k: 0.787070, samples/s: 682.351 1613592159.5979855
train: epoch 29, iter 3500, loss: 2.825741, top_1: 0.556992, top_k: 0.786445, samples/s: 683.517 1613592197.051279
train: epoch 29, iter 3600, loss: 2.791437, top_1: 0.556680, top_k: 0.792656, samples/s: 683.296 1613592234.5167134
train: epoch 29, iter 3700, loss: 2.732749, top_1: 0.557695, top_k: 0.787383, samples/s: 683.290 1613592271.982618
train: epoch 29, iter 3800, loss: 2.827202, top_1: 0.557383, top_k: 0.784961, samples/s: 683.341 1613592309.4455705
train: epoch 29, iter 3900, loss: 2.579817, top_1: 0.557266, top_k: 0.787305, samples/s: 684.185 1613592346.8622994
train: epoch 29, iter 4000, loss: 2.513246, top_1: 0.565234, top_k: 0.791680, samples/s: 681.738 1613592384.4135373
train: epoch 29, iter 4100, loss: 2.751407, top_1: 0.557969, top_k: 0.786797, samples/s: 684.754 1613592421.7990723
train: epoch 29, iter 4200, loss: 3.004285, top_1: 0.560781, top_k: 0.786797, samples/s: 683.508 1613592459.2529838
train: epoch 29, iter 4300, loss: 2.879555, top_1: 0.558555, top_k: 0.786719, samples/s: 683.123 1613592496.7278864
train: epoch 29, iter 4400, loss: 2.863460, top_1: 0.559688, top_k: 0.788320, samples/s: 683.344 1613592534.1906857
train: epoch 29, iter 4500, loss: 2.824092, top_1: 0.555547, top_k: 0.784609, samples/s: 684.610 1613592571.584205
train: epoch 29, iter 4600, loss: 2.906139, top_1: 0.559453, top_k: 0.787578, samples/s: 684.588 1613592608.9790037
train: epoch 29, iter 4700, loss: 2.865425, top_1: 0.557383, top_k: 0.785937, samples/s: 684.353 1613592646.3866296
train: epoch 29, iter 4800, loss: 2.966475, top_1: 0.552539, top_k: 0.785703, samples/s: 685.881 1613592683.7108378
train: epoch 29, iter 4900, loss: 2.915785, top_1: 0.554141, top_k: 0.784336, samples/s: 681.107 1613592721.296715
train: epoch 29, iter 5000, loss: 2.746892, top_1: 0.557969, top_k: 0.785508, samples/s: 684.284 1613592758.7080178
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_29.
validation: epoch 29, iter 195, top_1: 0.614223, top_k: 0.846434, samples/s: 2175.801 1613592782.777646
train: epoch 30, iter 100, loss: 2.787484, top_1: 0.568516, top_k: 0.795937, samples/s: 703.010 1613592840.7638378
train: epoch 30, iter 200, loss: 2.772480, top_1: 0.566133, top_k: 0.794219, samples/s: 698.152 1613592877.4320264
train: epoch 30, iter 300, loss: 2.657483, top_1: 0.571523, top_k: 0.799258, samples/s: 685.900 1613592914.7552688
train: epoch 30, iter 400, loss: 2.776326, top_1: 0.569141, top_k: 0.795937, samples/s: 681.539 1613592952.317261
train: epoch 30, iter 500, loss: 2.860809, top_1: 0.566602, top_k: 0.793008, samples/s: 683.871 1613592989.751216
train: epoch 30, iter 600, loss: 2.736674, top_1: 0.558633, top_k: 0.791562, samples/s: 682.247 1613593027.2742543
train: epoch 30, iter 700, loss: 2.829874, top_1: 0.564531, top_k: 0.789961, samples/s: 683.365 1613593064.7359152
train: epoch 30, iter 800, loss: 2.711327, top_1: 0.562852, top_k: 0.788945, samples/s: 683.362 1613593102.19787
train: epoch 30, iter 900, loss: 2.591079, top_1: 0.567773, top_k: 0.800391, samples/s: 681.755 1613593139.747982
train: epoch 30, iter 1000, loss: 2.796925, top_1: 0.565469, top_k: 0.793125, samples/s: 683.577 1613593177.1980143
train: epoch 30, iter 1100, loss: 2.558202, top_1: 0.567227, top_k: 0.795312, samples/s: 684.225 1613593214.6126726
train: epoch 30, iter 1200, loss: 2.969674, top_1: 0.567773, top_k: 0.795273, samples/s: 681.264 1613593252.1898975
train: epoch 30, iter 1300, loss: 2.877768, top_1: 0.559883, top_k: 0.790000, samples/s: 682.444 1613593289.7020304
train: epoch 30, iter 1400, loss: 2.651657, top_1: 0.568594, top_k: 0.792383, samples/s: 682.939 1613593327.1870747
train: epoch 30, iter 1500, loss: 2.706068, top_1: 0.569102, top_k: 0.794922, samples/s: 685.533 1613593364.5303783
train: epoch 30, iter 1600, loss: 2.802979, top_1: 0.562266, top_k: 0.792344, samples/s: 681.512 1613593402.0939395
train: epoch 30, iter 1700, loss: 2.655560, top_1: 0.563750, top_k: 0.790586, samples/s: 684.071 1613593439.51696
train: epoch 30, iter 1800, loss: 2.791423, top_1: 0.561641, top_k: 0.790039, samples/s: 683.826 1613593476.9533353
train: epoch 30, iter 1900, loss: 2.837609, top_1: 0.560742, top_k: 0.789180, samples/s: 683.408 1613593514.4126766
train: epoch 30, iter 2000, loss: 2.894976, top_1: 0.566328, top_k: 0.792930, samples/s: 682.614 1613593551.91559
train: epoch 30, iter 2100, loss: 2.805363, top_1: 0.566797, top_k: 0.794922, samples/s: 683.725 1613593589.3575313
train: epoch 30, iter 2200, loss: 2.987105, top_1: 0.568906, top_k: 0.794531, samples/s: 683.295 1613593626.8229856
train: epoch 30, iter 2300, loss: 2.847671, top_1: 0.566445, top_k: 0.793711, samples/s: 684.075 1613593664.2458045
train: epoch 30, iter 2400, loss: 2.888631, top_1: 0.560977, top_k: 0.792969, samples/s: 684.285 1613593701.6571767
train: epoch 30, iter 2500, loss: 2.608596, top_1: 0.564258, top_k: 0.789453, samples/s: 682.492 1613593739.166821
train: epoch 30, iter 2600, loss: 2.811226, top_1: 0.559297, top_k: 0.788438, samples/s: 682.298 1613593776.6870499
train: epoch 30, iter 2700, loss: 2.918293, top_1: 0.552500, top_k: 0.785859, samples/s: 683.388 1613593814.147501
train: epoch 30, iter 2800, loss: 2.737969, top_1: 0.557891, top_k: 0.786484, samples/s: 685.486 1613593851.493252
train: epoch 30, iter 2900, loss: 2.759717, top_1: 0.560703, top_k: 0.787969, samples/s: 683.916 1613593888.9247406
train: epoch 30, iter 3000, loss: 2.832226, top_1: 0.557578, top_k: 0.787305, samples/s: 682.000 1613593926.4613976
train: epoch 30, iter 3100, loss: 3.180681, top_1: 0.562109, top_k: 0.788398, samples/s: 682.280 1613593963.9826245
train: epoch 30, iter 3200, loss: 2.956571, top_1: 0.558047, top_k: 0.788125, samples/s: 680.999 1613594001.5744429
train: epoch 30, iter 3300, loss: 2.871252, top_1: 0.558711, top_k: 0.783594, samples/s: 686.369 1613594038.8721642
train: epoch 30, iter 3400, loss: 2.852777, top_1: 0.559336, top_k: 0.786172, samples/s: 683.089 1613594076.3489318
train: epoch 30, iter 3500, loss: 2.662079, top_1: 0.558594, top_k: 0.790625, samples/s: 683.970 1613594113.777427
train: epoch 30, iter 3600, loss: 3.072240, top_1: 0.558711, top_k: 0.787539, samples/s: 684.656 1613594151.1685681
train: epoch 30, iter 3700, loss: 2.845441, top_1: 0.561445, top_k: 0.790586, samples/s: 684.482 1613594188.5690532
train: epoch 30, iter 3800, loss: 2.928673, top_1: 0.560898, top_k: 0.788516, samples/s: 682.833 1613594226.059878
train: epoch 30, iter 3900, loss: 2.998786, top_1: 0.562383, top_k: 0.793047, samples/s: 684.324 1613594263.4691093
train: epoch 30, iter 4000, loss: 3.069442, top_1: 0.555195, top_k: 0.785742, samples/s: 682.241 1613594300.9925723
train: epoch 30, iter 4100, loss: 2.768159, top_1: 0.559609, top_k: 0.785820, samples/s: 681.568 1613594338.5530071
train: epoch 30, iter 4200, loss: 2.843748, top_1: 0.562734, top_k: 0.786250, samples/s: 684.488 1613594375.9532022
train: epoch 30, iter 4300, loss: 2.704589, top_1: 0.552422, top_k: 0.788438, samples/s: 683.871 1613594413.387155
train: epoch 30, iter 4400, loss: 2.891347, top_1: 0.560820, top_k: 0.787773, samples/s: 682.815 1613594450.8790329
train: epoch 30, iter 4500, loss: 2.687255, top_1: 0.558789, top_k: 0.787969, samples/s: 685.887 1613594488.202931
train: epoch 30, iter 4600, loss: 2.928552, top_1: 0.561094, top_k: 0.783906, samples/s: 684.394 1613594525.6082373
train: epoch 30, iter 4700, loss: 2.735909, top_1: 0.561406, top_k: 0.785703, samples/s: 684.706 1613594562.9966094
train: epoch 30, iter 4800, loss: 2.891844, top_1: 0.559414, top_k: 0.787031, samples/s: 682.776 1613594600.490535
train: epoch 30, iter 4900, loss: 2.912026, top_1: 0.558984, top_k: 0.788398, samples/s: 686.077 1613594637.8042095
train: epoch 30, iter 5000, loss: 2.685565, top_1: 0.566602, top_k: 0.791328, samples/s: 683.287 1613594675.2702417
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_30.
validation: epoch 30, iter 195, top_1: 0.528506, top_k: 0.776382, samples/s: 2162.407 1613594699.5353844
train: epoch 31, iter 100, loss: 2.664600, top_1: 0.564961, top_k: 0.790508, samples/s: 701.027 1613594757.2925622
train: epoch 31, iter 200, loss: 2.635580, top_1: 0.572500, top_k: 0.797891, samples/s: 698.630 1613594793.9358861
train: epoch 31, iter 300, loss: 3.020874, top_1: 0.571484, top_k: 0.799805, samples/s: 683.463 1613594831.3920527
train: epoch 31, iter 400, loss: 2.656389, top_1: 0.562695, top_k: 0.794609, samples/s: 683.405 1613594868.8515525
train: epoch 31, iter 500, loss: 2.764031, top_1: 0.565977, top_k: 0.797383, samples/s: 682.466 1613594906.3625488
train: epoch 31, iter 600, loss: 2.807829, top_1: 0.563945, top_k: 0.794844, samples/s: 683.596 1613594943.8114789
train: epoch 31, iter 700, loss: 2.775946, top_1: 0.563984, top_k: 0.792695, samples/s: 681.276 1613594981.388121
train: epoch 31, iter 800, loss: 2.895090, top_1: 0.564961, top_k: 0.790547, samples/s: 681.999 1613595018.9246953
train: epoch 31, iter 900, loss: 2.937023, top_1: 0.569375, top_k: 0.795625, samples/s: 684.444 1613595056.327429
train: epoch 31, iter 1000, loss: 2.640372, top_1: 0.571602, top_k: 0.799727, samples/s: 682.247 1613595093.8504484
train: epoch 31, iter 1100, loss: 2.860898, top_1: 0.562773, top_k: 0.793008, samples/s: 684.328 1613595131.2593715
train: epoch 31, iter 1200, loss: 2.698880, top_1: 0.567500, top_k: 0.794648, samples/s: 680.576 1613595168.8745475
train: epoch 31, iter 1300, loss: 3.006515, top_1: 0.560195, top_k: 0.787461, samples/s: 683.355 1613595206.336825
train: epoch 31, iter 1400, loss: 2.800932, top_1: 0.561367, top_k: 0.791289, samples/s: 683.990 1613595243.7641735
train: epoch 31, iter 1500, loss: 2.811839, top_1: 0.556250, top_k: 0.789570, samples/s: 685.234 1613595281.123766
train: epoch 31, iter 1600, loss: 2.579501, top_1: 0.560508, top_k: 0.790273, samples/s: 681.975 1613595318.6618025
train: epoch 31, iter 1700, loss: 2.748335, top_1: 0.567500, top_k: 0.796992, samples/s: 682.466 1613595356.1727686
train: epoch 31, iter 1800, loss: 2.865366, top_1: 0.561289, top_k: 0.787734, samples/s: 682.753 1613595393.668088
train: epoch 31, iter 1900, loss: 3.104997, top_1: 0.562031, top_k: 0.790000, samples/s: 684.505 1613595431.0673144
train: epoch 31, iter 2000, loss: 2.745636, top_1: 0.566016, top_k: 0.792305, samples/s: 683.871 1613595468.501333
train: epoch 31, iter 2100, loss: 2.847461, top_1: 0.558828, top_k: 0.788594, samples/s: 684.926 1613595505.877494
train: epoch 31, iter 2200, loss: 2.693970, top_1: 0.562500, top_k: 0.786680, samples/s: 683.266 1613595543.3446918
train: epoch 31, iter 2300, loss: 2.788687, top_1: 0.561211, top_k: 0.790742, samples/s: 683.484 1613595580.7998407
train: epoch 31, iter 2400, loss: 2.669585, top_1: 0.562344, top_k: 0.793789, samples/s: 684.280 1613595618.2114298
train: epoch 31, iter 2500, loss: 2.777161, top_1: 0.562383, top_k: 0.792773, samples/s: 681.866 1613595655.7554924
train: epoch 31, iter 2600, loss: 2.971021, top_1: 0.567227, top_k: 0.791211, samples/s: 683.980 1613595693.1833684
train: epoch 31, iter 2700, loss: 2.705997, top_1: 0.559336, top_k: 0.791562, samples/s: 682.017 1613595730.7191727
train: epoch 31, iter 2800, loss: 2.740411, top_1: 0.561289, top_k: 0.794531, samples/s: 684.215 1613595768.1343422
train: epoch 31, iter 2900, loss: 2.835298, top_1: 0.553164, top_k: 0.787852, samples/s: 684.033 1613595805.559413
train: epoch 31, iter 3000, loss: 2.821176, top_1: 0.562266, top_k: 0.789883, samples/s: 681.582 1613595843.1191566
train: epoch 31, iter 3100, loss: 2.614918, top_1: 0.570234, top_k: 0.794766, samples/s: 685.611 1613595880.4581618
train: epoch 31, iter 3200, loss: 2.786797, top_1: 0.557148, top_k: 0.788945, samples/s: 684.424 1613595917.8618271
train: epoch 31, iter 3300, loss: 2.894950, top_1: 0.562539, top_k: 0.788906, samples/s: 681.028 1613595955.451988
train: epoch 31, iter 3400, loss: 2.888283, top_1: 0.559688, top_k: 0.791055, samples/s: 685.663 1613595992.7881744
train: epoch 31, iter 3500, loss: 2.759746, top_1: 0.561484, top_k: 0.787813, samples/s: 686.337 1613596030.0876112
train: epoch 31, iter 3600, loss: 2.959256, top_1: 0.564063, top_k: 0.790742, samples/s: 681.626 1613596067.6448786
train: epoch 31, iter 3700, loss: 2.570266, top_1: 0.563008, top_k: 0.790078, samples/s: 684.218 1613596105.0598104
train: epoch 31, iter 3800, loss: 2.671852, top_1: 0.565430, top_k: 0.789687, samples/s: 683.992 1613596142.4872494
train: epoch 31, iter 3900, loss: 2.990345, top_1: 0.566914, top_k: 0.792695, samples/s: 684.091 1613596179.9091015
train: epoch 31, iter 4000, loss: 2.699415, top_1: 0.567500, top_k: 0.794687, samples/s: 684.439 1613596217.3119905
train: epoch 31, iter 4100, loss: 2.887641, top_1: 0.557305, top_k: 0.789492, samples/s: 680.985 1613596254.9046519
train: epoch 31, iter 4200, loss: 2.855662, top_1: 0.560391, top_k: 0.786875, samples/s: 685.715 1613596292.2378745
train: epoch 31, iter 4300, loss: 2.860686, top_1: 0.560898, top_k: 0.787461, samples/s: 682.343 1613596329.7557251
train: epoch 31, iter 4400, loss: 2.860684, top_1: 0.559453, top_k: 0.789531, samples/s: 684.092 1613596367.177582
train: epoch 31, iter 4500, loss: 2.747701, top_1: 0.563750, top_k: 0.788516, samples/s: 684.613 1613596404.5710053
train: epoch 31, iter 4600, loss: 2.899234, top_1: 0.562734, top_k: 0.789883, samples/s: 684.894 1613596441.9490557
train: epoch 31, iter 4700, loss: 2.924548, top_1: 0.563828, top_k: 0.788516, samples/s: 685.126 1613596479.3144405
train: epoch 31, iter 4800, loss: 2.946867, top_1: 0.561758, top_k: 0.789492, samples/s: 682.994 1613596516.7964082
train: epoch 31, iter 4900, loss: 2.778491, top_1: 0.567031, top_k: 0.794883, samples/s: 683.407 1613596554.2558231
train: epoch 31, iter 5000, loss: 2.843036, top_1: 0.565469, top_k: 0.790234, samples/s: 685.328 1613596591.6101768
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_31.
validation: epoch 31, iter 195, top_1: 0.613642, top_k: 0.846595, samples/s: 2158.885 1613596615.836313
train: epoch 32, iter 100, loss: 2.727061, top_1: 0.574766, top_k: 0.800195, samples/s: 702.516 1613596673.9953253
train: epoch 32, iter 200, loss: 2.556815, top_1: 0.574336, top_k: 0.799219, samples/s: 698.238 1613596710.659235
train: epoch 32, iter 300, loss: 2.527225, top_1: 0.576602, top_k: 0.800586, samples/s: 685.557 1613596748.0008876
train: epoch 32, iter 400, loss: 2.753727, top_1: 0.571211, top_k: 0.795234, samples/s: 682.411 1613596785.5148377
train: epoch 32, iter 500, loss: 2.652014, top_1: 0.569609, top_k: 0.799531, samples/s: 682.377 1613596823.030853
train: epoch 32, iter 600, loss: 2.697603, top_1: 0.569531, top_k: 0.793789, samples/s: 684.447 1613596860.4332027
train: epoch 32, iter 700, loss: 2.915976, top_1: 0.569141, top_k: 0.795625, samples/s: 681.330 1613596898.0068016
train: epoch 32, iter 800, loss: 2.732682, top_1: 0.571992, top_k: 0.797070, samples/s: 686.257 1613596935.3107088
train: epoch 32, iter 900, loss: 2.731931, top_1: 0.568398, top_k: 0.795195, samples/s: 683.840 1613596972.7463107
train: epoch 32, iter 1000, loss: 2.781434, top_1: 0.562344, top_k: 0.793047, samples/s: 686.540 1613597010.0347931
train: epoch 32, iter 1100, loss: 2.914469, top_1: 0.563672, top_k: 0.795547, samples/s: 683.951 1613597047.4643507
train: epoch 32, iter 1200, loss: 2.985163, top_1: 0.569570, top_k: 0.798203, samples/s: 685.786 1613597084.793808
train: epoch 32, iter 1300, loss: 2.796778, top_1: 0.569414, top_k: 0.798359, samples/s: 684.379 1613597122.1998749
train: epoch 32, iter 1400, loss: 2.998514, top_1: 0.565898, top_k: 0.790977, samples/s: 683.882 1613597159.6333025
train: epoch 32, iter 1500, loss: 2.764315, top_1: 0.565156, top_k: 0.790820, samples/s: 686.916 1613597196.9013064
train: epoch 32, iter 1600, loss: 2.713369, top_1: 0.568867, top_k: 0.790391, samples/s: 682.717 1613597234.3986416
train: epoch 32, iter 1700, loss: 2.796751, top_1: 0.565352, top_k: 0.788672, samples/s: 685.813 1613597271.7266042
train: epoch 32, iter 1800, loss: 2.729591, top_1: 0.564258, top_k: 0.793906, samples/s: 686.592 1613597309.0122025
train: epoch 32, iter 1900, loss: 2.935771, top_1: 0.567656, top_k: 0.790469, samples/s: 684.315 1613597346.4218605
train: epoch 32, iter 2000, loss: 2.759912, top_1: 0.559531, top_k: 0.791250, samples/s: 688.153 1613597383.6229646
train: epoch 32, iter 2100, loss: 2.726391, top_1: 0.565937, top_k: 0.791836, samples/s: 685.611 1613597420.961847
train: epoch 32, iter 2200, loss: 2.821764, top_1: 0.567383, top_k: 0.792578, samples/s: 686.141 1613597458.2720175
train: epoch 32, iter 2300, loss: 2.709563, top_1: 0.560781, top_k: 0.788828, samples/s: 683.826 1613597495.7084491
train: epoch 32, iter 2400, loss: 2.871066, top_1: 0.564688, top_k: 0.790781, samples/s: 684.520 1613597533.1069694
train: epoch 32, iter 2500, loss: 2.948380, top_1: 0.569727, top_k: 0.794219, samples/s: 685.573 1613597570.4480171
train: epoch 32, iter 2600, loss: 2.977298, top_1: 0.557500, top_k: 0.789023, samples/s: 684.234 1613597607.8619692
train: epoch 32, iter 2700, loss: 2.837768, top_1: 0.565664, top_k: 0.792109, samples/s: 685.236 1613597645.2214105
train: epoch 32, iter 2800, loss: 2.812302, top_1: 0.565781, top_k: 0.791602, samples/s: 686.683 1613597682.502081
train: epoch 32, iter 2900, loss: 2.633592, top_1: 0.565039, top_k: 0.791211, samples/s: 687.431 1613597719.7421162
train: epoch 32, iter 3000, loss: 2.833476, top_1: 0.561094, top_k: 0.790117, samples/s: 684.323 1613597757.1514475
train: epoch 32, iter 3100, loss: 2.784293, top_1: 0.563945, top_k: 0.793711, samples/s: 689.124 1613597794.3000135
train: epoch 32, iter 3200, loss: 2.778843, top_1: 0.563281, top_k: 0.791016, samples/s: 684.560 1613597831.696254
train: epoch 32, iter 3300, loss: 2.839025, top_1: 0.560117, top_k: 0.789258, samples/s: 685.836 1613597869.0229816
train: epoch 32, iter 3400, loss: 2.860588, top_1: 0.561719, top_k: 0.789375, samples/s: 684.560 1613597906.4192922
train: epoch 32, iter 3500, loss: 3.057631, top_1: 0.565352, top_k: 0.791562, samples/s: 686.090 1613597943.7322156
train: epoch 32, iter 3600, loss: 3.031806, top_1: 0.564648, top_k: 0.791445, samples/s: 686.819 1613597981.0054822
train: epoch 32, iter 3700, loss: 2.691227, top_1: 0.563945, top_k: 0.791055, samples/s: 684.290 1613598018.416511
train: epoch 32, iter 3800, loss: 2.775115, top_1: 0.568516, top_k: 0.788984, samples/s: 683.552 1613598055.867939
train: epoch 32, iter 3900, loss: 2.655092, top_1: 0.564492, top_k: 0.788516, samples/s: 686.673 1613598093.1490517
train: epoch 32, iter 4000, loss: 2.841715, top_1: 0.568711, top_k: 0.789414, samples/s: 681.900 1613598130.6913383
train: epoch 32, iter 4100, loss: 2.780454, top_1: 0.562969, top_k: 0.789648, samples/s: 685.703 1613598168.0251708
train: epoch 32, iter 4200, loss: 2.769574, top_1: 0.566211, top_k: 0.795234, samples/s: 685.273 1613598205.38261
train: epoch 32, iter 4300, loss: 2.905148, top_1: 0.567773, top_k: 0.791250, samples/s: 685.632 1613598242.7203157
train: epoch 32, iter 4400, loss: 2.875287, top_1: 0.556406, top_k: 0.786055, samples/s: 685.363 1613598280.072828
train: epoch 32, iter 4500, loss: 2.711438, top_1: 0.567187, top_k: 0.789336, samples/s: 684.167 1613598317.4905567
train: epoch 32, iter 4600, loss: 2.786004, top_1: 0.558672, top_k: 0.788086, samples/s: 684.737 1613598354.8772187
train: epoch 32, iter 4700, loss: 2.812764, top_1: 0.557852, top_k: 0.785977, samples/s: 688.195 1613598392.076005
train: epoch 32, iter 4800, loss: 2.768427, top_1: 0.561211, top_k: 0.789766, samples/s: 683.002 1613598429.557625
train: epoch 32, iter 4900, loss: 2.796080, top_1: 0.562031, top_k: 0.788398, samples/s: 683.981 1613598466.985566
train: epoch 32, iter 5000, loss: 2.709958, top_1: 0.557070, top_k: 0.789062, samples/s: 684.271 1613598504.397543
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_32.
validation: epoch 32, iter 195, top_1: 0.619371, top_k: 0.847596, samples/s: 2173.961 1613598528.44746
train: epoch 33, iter 100, loss: 2.789220, top_1: 0.574922, top_k: 0.803125, samples/s: 702.338 1613598585.8774357
train: epoch 33, iter 200, loss: 2.909056, top_1: 0.573477, top_k: 0.799102, samples/s: 699.278 1613598622.486538
train: epoch 33, iter 300, loss: 2.537998, top_1: 0.573320, top_k: 0.795859, samples/s: 685.239 1613598659.8458807
train: epoch 33, iter 400, loss: 2.710914, top_1: 0.573750, top_k: 0.801758, samples/s: 683.549 1613598697.2973516
train: epoch 33, iter 500, loss: 2.907691, top_1: 0.573203, top_k: 0.798789, samples/s: 681.982 1613598734.8350606
train: epoch 33, iter 600, loss: 2.905810, top_1: 0.570039, top_k: 0.795469, samples/s: 683.157 1613598772.3081753
train: epoch 33, iter 700, loss: 2.825400, top_1: 0.568984, top_k: 0.796055, samples/s: 684.260 1613598809.7208147
train: epoch 33, iter 800, loss: 2.667172, top_1: 0.567227, top_k: 0.799805, samples/s: 684.671 1613598847.111091
train: epoch 33, iter 900, loss: 2.706523, top_1: 0.567109, top_k: 0.795234, samples/s: 682.971 1613598884.5943825
train: epoch 33, iter 1000, loss: 2.846903, top_1: 0.570273, top_k: 0.795898, samples/s: 687.029 1613598921.8562365
train: epoch 33, iter 1100, loss: 2.937249, top_1: 0.569336, top_k: 0.796641, samples/s: 684.652 1613598959.2473955
train: epoch 33, iter 1200, loss: 2.924716, top_1: 0.564727, top_k: 0.795391, samples/s: 685.958 1613598996.5675175
train: epoch 33, iter 1300, loss: 2.894630, top_1: 0.566250, top_k: 0.796211, samples/s: 684.975 1613599033.9411407
train: epoch 33, iter 1400, loss: 2.777380, top_1: 0.567813, top_k: 0.793750, samples/s: 684.090 1613599071.363122
train: epoch 33, iter 1500, loss: 2.658704, top_1: 0.567383, top_k: 0.794141, samples/s: 683.218 1613599108.8327825
train: epoch 33, iter 1600, loss: 2.623131, top_1: 0.563867, top_k: 0.793711, samples/s: 684.637 1613599146.2249966
train: epoch 33, iter 1700, loss: 2.704040, top_1: 0.567539, top_k: 0.794063, samples/s: 684.092 1613599183.6468616
train: epoch 33, iter 1800, loss: 2.556355, top_1: 0.565273, top_k: 0.794844, samples/s: 684.994 1613599221.0194223
train: epoch 33, iter 1900, loss: 2.733696, top_1: 0.572305, top_k: 0.796250, samples/s: 685.131 1613599258.3845189
train: epoch 33, iter 2000, loss: 2.599619, top_1: 0.567930, top_k: 0.794531, samples/s: 686.853 1613599295.6560104
train: epoch 33, iter 2100, loss: 2.884486, top_1: 0.567500, top_k: 0.790430, samples/s: 686.369 1613599332.9536934
train: epoch 33, iter 2200, loss: 2.626965, top_1: 0.565078, top_k: 0.797500, samples/s: 687.079 1613599370.2129045
train: epoch 33, iter 2300, loss: 2.682838, top_1: 0.564336, top_k: 0.789922, samples/s: 684.474 1613599407.6138923
train: epoch 33, iter 2400, loss: 2.838951, top_1: 0.561133, top_k: 0.788945, samples/s: 687.013 1613599444.876678
train: epoch 33, iter 2500, loss: 2.695940, top_1: 0.563477, top_k: 0.789297, samples/s: 684.528 1613599482.2747338
train: epoch 33, iter 2600, loss: 2.687823, top_1: 0.565820, top_k: 0.792344, samples/s: 682.272 1613599519.7964275
train: epoch 33, iter 2700, loss: 2.667956, top_1: 0.560234, top_k: 0.792539, samples/s: 684.695 1613599557.1853309
train: epoch 33, iter 2800, loss: 2.674508, top_1: 0.565547, top_k: 0.793398, samples/s: 685.863 1613599594.5105479
train: epoch 33, iter 2900, loss: 2.901162, top_1: 0.560742, top_k: 0.788906, samples/s: 686.789 1613599631.7854502
train: epoch 33, iter 3000, loss: 2.673287, top_1: 0.567734, top_k: 0.792656, samples/s: 685.245 1613599669.1443481
train: epoch 33, iter 3100, loss: 2.586463, top_1: 0.570312, top_k: 0.793867, samples/s: 684.196 1613599706.5605133
train: epoch 33, iter 3200, loss: 2.690871, top_1: 0.569570, top_k: 0.794141, samples/s: 681.991 1613599744.0977058
train: epoch 33, iter 3300, loss: 2.621979, top_1: 0.563281, top_k: 0.794805, samples/s: 685.030 1613599781.4683065
train: epoch 33, iter 3400, loss: 2.835255, top_1: 0.568438, top_k: 0.794219, samples/s: 686.443 1613599818.7619548
train: epoch 33, iter 3500, loss: 2.971188, top_1: 0.566016, top_k: 0.792344, samples/s: 685.808 1613599856.090285
train: epoch 33, iter 3600, loss: 2.909257, top_1: 0.566328, top_k: 0.790937, samples/s: 684.695 1613599893.4791915
train: epoch 33, iter 3700, loss: 2.668099, top_1: 0.565391, top_k: 0.793828, samples/s: 684.752 1613599930.8649588
train: epoch 33, iter 3800, loss: 2.731821, top_1: 0.558555, top_k: 0.789453, samples/s: 684.741 1613599968.2513225
train: epoch 33, iter 3900, loss: 2.864445, top_1: 0.565469, top_k: 0.793594, samples/s: 686.253 1613600005.5553057
train: epoch 33, iter 4000, loss: 2.795262, top_1: 0.570156, top_k: 0.793984, samples/s: 688.374 1613600042.7444358
train: epoch 33, iter 4100, loss: 2.773814, top_1: 0.564727, top_k: 0.792227, samples/s: 686.740 1613600080.0219097
train: epoch 33, iter 4200, loss: 2.575252, top_1: 0.567070, top_k: 0.791172, samples/s: 684.342 1613600117.4301836
train: epoch 33, iter 4300, loss: 2.860232, top_1: 0.561602, top_k: 0.788281, samples/s: 686.497 1613600154.7210155
train: epoch 33, iter 4400, loss: 2.939773, top_1: 0.568047, top_k: 0.792734, samples/s: 687.432 1613600191.9610329
train: epoch 33, iter 4500, loss: 2.939969, top_1: 0.565664, top_k: 0.794766, samples/s: 688.066 1613600229.1666985
train: epoch 33, iter 4600, loss: 2.910880, top_1: 0.559102, top_k: 0.791289, samples/s: 683.018 1613600266.6473753
train: epoch 33, iter 4700, loss: 2.581592, top_1: 0.565547, top_k: 0.792188, samples/s: 687.201 1613600303.8999777
train: epoch 33, iter 4800, loss: 3.014805, top_1: 0.566250, top_k: 0.793320, samples/s: 686.300 1613600341.2014372
train: epoch 33, iter 4900, loss: 2.760626, top_1: 0.561367, top_k: 0.786953, samples/s: 687.694 1613600378.4271927
train: epoch 33, iter 5000, loss: 2.645334, top_1: 0.568359, top_k: 0.790078, samples/s: 684.694 1613600415.816251
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_33.
validation: epoch 33, iter 195, top_1: 0.618570, top_k: 0.847897, samples/s: 2148.546 1613600440.1853924
train: epoch 34, iter 100, loss: 2.570692, top_1: 0.583008, top_k: 0.804453, samples/s: 703.268 1613600497.6550338
train: epoch 34, iter 200, loss: 2.674393, top_1: 0.578242, top_k: 0.801328, samples/s: 700.033 1613600534.2247517
train: epoch 34, iter 300, loss: 2.792772, top_1: 0.578984, top_k: 0.802344, samples/s: 685.754 1613600571.5558646
train: epoch 34, iter 400, loss: 2.876662, top_1: 0.580000, top_k: 0.799453, samples/s: 686.409 1613600608.851447
train: epoch 34, iter 500, loss: 2.880306, top_1: 0.574336, top_k: 0.799531, samples/s: 684.177 1613600646.2685733
train: epoch 34, iter 600, loss: 2.875462, top_1: 0.570937, top_k: 0.798047, samples/s: 686.282 1613600683.5709941
train: epoch 34, iter 700, loss: 2.721102, top_1: 0.578516, top_k: 0.801562, samples/s: 685.647 1613600720.908006
train: epoch 34, iter 800, loss: 3.044152, top_1: 0.575430, top_k: 0.800039, samples/s: 684.149 1613600758.3267603
train: epoch 34, iter 900, loss: 2.647949, top_1: 0.576055, top_k: 0.797617, samples/s: 685.397 1613600795.677466
train: epoch 34, iter 1000, loss: 2.700768, top_1: 0.569570, top_k: 0.792734, samples/s: 686.245 1613600832.9817662
train: epoch 34, iter 1100, loss: 2.851398, top_1: 0.575469, top_k: 0.800312, samples/s: 685.330 1613600870.3360844
train: epoch 34, iter 1200, loss: 2.869474, top_1: 0.569609, top_k: 0.796797, samples/s: 684.355 1613600907.7435865
train: epoch 34, iter 1300, loss: 2.672242, top_1: 0.576016, top_k: 0.798711, samples/s: 686.558 1613600945.0310807
train: epoch 34, iter 1400, loss: 2.810520, top_1: 0.567813, top_k: 0.794063, samples/s: 685.701 1613600982.3651562
train: epoch 34, iter 1500, loss: 2.857580, top_1: 0.569180, top_k: 0.796250, samples/s: 687.620 1613601019.5950544
train: epoch 34, iter 1600, loss: 2.769392, top_1: 0.570586, top_k: 0.795781, samples/s: 687.112 1613601056.8524098
train: epoch 34, iter 1700, loss: 2.867111, top_1: 0.569688, top_k: 0.796484, samples/s: 686.795 1613601094.1269128
train: epoch 34, iter 1800, loss: 2.881758, top_1: 0.573906, top_k: 0.796562, samples/s: 687.162 1613601131.3816712
train: epoch 34, iter 1900, loss: 2.793673, top_1: 0.564141, top_k: 0.794648, samples/s: 686.212 1613601168.6878254
train: epoch 34, iter 2000, loss: 2.855490, top_1: 0.563750, top_k: 0.794336, samples/s: 690.169 1613601205.7802207
train: epoch 34, iter 2100, loss: 2.730016, top_1: 0.566602, top_k: 0.796367, samples/s: 684.146 1613601243.199116
train: epoch 34, iter 2200, loss: 2.885212, top_1: 0.566406, top_k: 0.796406, samples/s: 686.955 1613601280.4651084
train: epoch 34, iter 2300, loss: 2.803866, top_1: 0.572891, top_k: 0.799492, samples/s: 686.199 1613601317.7719817
train: epoch 34, iter 2400, loss: 2.733855, top_1: 0.569570, top_k: 0.797656, samples/s: 688.030 1613601354.9797003
train: epoch 34, iter 2500, loss: 2.764238, top_1: 0.568867, top_k: 0.795977, samples/s: 684.958 1613601392.354193
train: epoch 34, iter 2600, loss: 2.790908, top_1: 0.569297, top_k: 0.795781, samples/s: 685.819 1613601429.68192
train: epoch 34, iter 2700, loss: 2.773578, top_1: 0.571602, top_k: 0.797813, samples/s: 687.776 1613601466.903386
train: epoch 34, iter 2800, loss: 2.695810, top_1: 0.567148, top_k: 0.793711, samples/s: 686.165 1613601504.212183
train: epoch 34, iter 2900, loss: 2.645927, top_1: 0.565000, top_k: 0.791875, samples/s: 686.340 1613601541.5114703
train: epoch 34, iter 3000, loss: 2.532404, top_1: 0.564727, top_k: 0.793203, samples/s: 685.751 1613601578.842827
train: epoch 34, iter 3100, loss: 2.743238, top_1: 0.565703, top_k: 0.794063, samples/s: 684.641 1613601616.2346916
train: epoch 34, iter 3200, loss: 2.753042, top_1: 0.564023, top_k: 0.791328, samples/s: 686.680 1613601653.5155156
train: epoch 34, iter 3300, loss: 2.783291, top_1: 0.564492, top_k: 0.791172, samples/s: 684.593 1613601690.9099057
train: epoch 34, iter 3400, loss: 2.653766, top_1: 0.565781, top_k: 0.793555, samples/s: 684.511 1613601728.3089454
train: epoch 34, iter 3500, loss: 2.834615, top_1: 0.567031, top_k: 0.794531, samples/s: 685.977 1613601765.6279874
train: epoch 34, iter 3600, loss: 2.688194, top_1: 0.567461, top_k: 0.793555, samples/s: 687.044 1613601802.8890405
train: epoch 34, iter 3700, loss: 2.779114, top_1: 0.567031, top_k: 0.794531, samples/s: 687.765 1613601840.1110501
train: epoch 34, iter 3800, loss: 2.736564, top_1: 0.567656, top_k: 0.799570, samples/s: 684.883 1613601877.4897573
train: epoch 34, iter 3900, loss: 2.728401, top_1: 0.569180, top_k: 0.794453, samples/s: 685.022 1613601914.8607914
train: epoch 34, iter 4000, loss: 2.665460, top_1: 0.565078, top_k: 0.791641, samples/s: 686.639 1613601952.143858
train: epoch 34, iter 4100, loss: 2.750808, top_1: 0.567813, top_k: 0.794219, samples/s: 685.835 1613601989.4705613
train: epoch 34, iter 4200, loss: 2.652580, top_1: 0.564492, top_k: 0.793008, samples/s: 686.154 1613602026.7800682
train: epoch 34, iter 4300, loss: 2.680351, top_1: 0.561211, top_k: 0.792500, samples/s: 683.308 1613602064.2448716
train: epoch 34, iter 4400, loss: 2.886656, top_1: 0.563984, top_k: 0.792109, samples/s: 686.909 1613602101.5132823
train: epoch 34, iter 4500, loss: 2.734967, top_1: 0.563711, top_k: 0.790977, samples/s: 688.106 1613602138.7167714
train: epoch 34, iter 4600, loss: 2.915362, top_1: 0.566094, top_k: 0.793516, samples/s: 683.811 1613602176.1539812
train: epoch 34, iter 4700, loss: 2.974780, top_1: 0.565898, top_k: 0.796680, samples/s: 685.997 1613602213.4720182
train: epoch 34, iter 4800, loss: 2.761217, top_1: 0.564609, top_k: 0.789766, samples/s: 685.400 1613602250.822451
train: epoch 34, iter 4900, loss: 2.591280, top_1: 0.569531, top_k: 0.796250, samples/s: 686.414 1613602288.117755
train: epoch 34, iter 5000, loss: 2.722779, top_1: 0.572461, top_k: 0.794297, samples/s: 685.261 1613602325.4756627
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_34.
validation: epoch 34, iter 195, top_1: 0.617488, top_k: 0.848237, samples/s: 2177.244 1613602349.5153065
train: epoch 35, iter 100, loss: 2.707302, top_1: 0.586914, top_k: 0.805273, samples/s: 702.453 1613602413.1080852
train: epoch 35, iter 200, loss: 2.793415, top_1: 0.576797, top_k: 0.800977, samples/s: 699.889 1613602449.6853065
train: epoch 35, iter 300, loss: 2.772465, top_1: 0.577148, top_k: 0.800781, samples/s: 687.876 1613602486.9013584
train: epoch 35, iter 400, loss: 2.772553, top_1: 0.575703, top_k: 0.801562, samples/s: 684.110 1613602524.3222764
train: epoch 35, iter 500, loss: 2.695228, top_1: 0.581211, top_k: 0.803281, samples/s: 683.996 1613602561.7493625
train: epoch 35, iter 600, loss: 2.887432, top_1: 0.565469, top_k: 0.797188, samples/s: 682.961 1613602599.233095
train: epoch 35, iter 700, loss: 2.687780, top_1: 0.571328, top_k: 0.799297, samples/s: 682.881 1613602636.7214346
train: epoch 35, iter 800, loss: 2.767878, top_1: 0.573828, top_k: 0.802344, samples/s: 688.035 1613602673.9288723
train: epoch 35, iter 900, loss: 2.616914, top_1: 0.570195, top_k: 0.797344, samples/s: 685.766 1613602711.2593153
train: epoch 35, iter 1000, loss: 2.727692, top_1: 0.575977, top_k: 0.800273, samples/s: 684.289 1613602748.6704314
train: epoch 35, iter 1100, loss: 2.814587, top_1: 0.578203, top_k: 0.802656, samples/s: 687.331 1613602785.915952
train: epoch 35, iter 1200, loss: 2.708663, top_1: 0.570820, top_k: 0.799141, samples/s: 683.470 1613602823.3718793
train: epoch 35, iter 1300, loss: 2.809424, top_1: 0.575391, top_k: 0.801172, samples/s: 684.784 1613602860.7558615
train: epoch 35, iter 1400, loss: 2.893330, top_1: 0.571211, top_k: 0.800117, samples/s: 685.974 1613602898.0751235
train: epoch 35, iter 1500, loss: 2.912449, top_1: 0.572227, top_k: 0.798789, samples/s: 685.914 1613602935.3975434
train: epoch 35, iter 1600, loss: 2.837336, top_1: 0.570195, top_k: 0.797695, samples/s: 686.955 1613602972.6634793
train: epoch 35, iter 1700, loss: 2.651173, top_1: 0.572031, top_k: 0.799375, samples/s: 683.969 1613603010.0921044
train: epoch 35, iter 1800, loss: 2.939612, top_1: 0.570000, top_k: 0.796719, samples/s: 686.132 1613603047.4026783
train: epoch 35, iter 1900, loss: 2.838734, top_1: 0.565937, top_k: 0.790469, samples/s: 682.194 1613603084.9285636
train: epoch 35, iter 2000, loss: 2.763989, top_1: 0.566641, top_k: 0.796641, samples/s: 685.759 1613603122.2595444
train: epoch 35, iter 2100, loss: 2.702650, top_1: 0.568516, top_k: 0.792461, samples/s: 685.972 1613603159.5788467
train: epoch 35, iter 2200, loss: 2.620299, top_1: 0.566250, top_k: 0.795078, samples/s: 683.686 1613603197.0229888
train: epoch 35, iter 2300, loss: 2.658868, top_1: 0.567344, top_k: 0.792188, samples/s: 686.241 1613603234.3276846
train: epoch 35, iter 2400, loss: 2.671438, top_1: 0.567031, top_k: 0.797070, samples/s: 684.883 1613603271.7062855
train: epoch 35, iter 2500, loss: 2.906673, top_1: 0.570937, top_k: 0.796133, samples/s: 687.030 1613603308.9681585
train: epoch 35, iter 2600, loss: 2.749099, top_1: 0.566758, top_k: 0.793945, samples/s: 687.773 1613603346.1897151
train: epoch 35, iter 2700, loss: 2.751307, top_1: 0.570898, top_k: 0.798984, samples/s: 685.146 1613603383.554035
train: epoch 35, iter 2800, loss: 2.721903, top_1: 0.569297, top_k: 0.794141, samples/s: 685.873 1613603420.8787024
train: epoch 35, iter 2900, loss: 2.734968, top_1: 0.571016, top_k: 0.792070, samples/s: 684.526 1613603458.2768142
train: epoch 35, iter 3000, loss: 2.642891, top_1: 0.567266, top_k: 0.794805, samples/s: 687.272 1613603495.5255399
train: epoch 35, iter 3100, loss: 2.937137, top_1: 0.570781, top_k: 0.792852, samples/s: 685.199 1613603532.8870633
train: epoch 35, iter 3200, loss: 2.626151, top_1: 0.571992, top_k: 0.793906, samples/s: 684.908 1613603570.2643938
train: epoch 35, iter 3300, loss: 2.781462, top_1: 0.577070, top_k: 0.797461, samples/s: 684.085 1613603607.6866114
train: epoch 35, iter 3400, loss: 2.791036, top_1: 0.569844, top_k: 0.794297, samples/s: 684.777 1613603645.0709834
train: epoch 35, iter 3500, loss: 2.900676, top_1: 0.563828, top_k: 0.791836, samples/s: 686.619 1613603682.3551488
train: epoch 35, iter 3600, loss: 2.667851, top_1: 0.563359, top_k: 0.793008, samples/s: 685.859 1613603719.680629
train: epoch 35, iter 3700, loss: 2.763306, top_1: 0.572578, top_k: 0.799336, samples/s: 686.114 1613603756.9922028
train: epoch 35, iter 3800, loss: 2.865692, top_1: 0.566523, top_k: 0.791875, samples/s: 685.881 1613603794.3164074
train: epoch 35, iter 3900, loss: 2.633913, top_1: 0.568203, top_k: 0.791367, samples/s: 684.404 1613603831.7213366
train: epoch 35, iter 4000, loss: 2.757511, top_1: 0.564453, top_k: 0.789219, samples/s: 688.113 1613603868.9244556
train: epoch 35, iter 4100, loss: 2.641021, top_1: 0.570898, top_k: 0.792148, samples/s: 684.668 1613603906.3149006
train: epoch 35, iter 4200, loss: 2.652364, top_1: 0.567070, top_k: 0.795156, samples/s: 685.551 1613603943.6570377
train: epoch 35, iter 4300, loss: 2.928387, top_1: 0.563555, top_k: 0.788359, samples/s: 686.511 1613603980.947045
train: epoch 35, iter 4400, loss: 2.833890, top_1: 0.568945, top_k: 0.793672, samples/s: 687.937 1613604018.1598394
train: epoch 35, iter 4500, loss: 2.705937, top_1: 0.571016, top_k: 0.796055, samples/s: 687.174 1613604055.4138916
train: epoch 35, iter 4600, loss: 2.722941, top_1: 0.564961, top_k: 0.791719, samples/s: 685.693 1613604092.7483993
train: epoch 35, iter 4700, loss: 2.654605, top_1: 0.565117, top_k: 0.792500, samples/s: 685.795 1613604130.0773056
train: epoch 35, iter 4800, loss: 2.773272, top_1: 0.564805, top_k: 0.788359, samples/s: 684.951 1613604167.452126
train: epoch 35, iter 4900, loss: 2.721152, top_1: 0.563359, top_k: 0.793125, samples/s: 688.390 1613604204.640418
train: epoch 35, iter 5000, loss: 2.681383, top_1: 0.573867, top_k: 0.799492, samples/s: 685.636 1613604241.978026
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_35.
validation: epoch 35, iter 195, top_1: 0.608954, top_k: 0.842308, samples/s: 2171.174 1613604266.0613592
train: epoch 36, iter 100, loss: 2.728836, top_1: 0.591562, top_k: 0.813164, samples/s: 703.060 1613604323.9932957
train: epoch 36, iter 200, loss: 2.782593, top_1: 0.583477, top_k: 0.804531, samples/s: 700.822 1613604360.522154
train: epoch 36, iter 300, loss: 2.766528, top_1: 0.590039, top_k: 0.810508, samples/s: 685.214 1613604397.882427
train: epoch 36, iter 400, loss: 2.736414, top_1: 0.574219, top_k: 0.803125, samples/s: 685.582 1613604435.223017
train: epoch 36, iter 500, loss: 2.668638, top_1: 0.574102, top_k: 0.800352, samples/s: 683.376 1613604472.6841362
train: epoch 36, iter 600, loss: 2.780732, top_1: 0.574414, top_k: 0.800625, samples/s: 685.179 1613604510.0466123
train: epoch 36, iter 700, loss: 2.757606, top_1: 0.574297, top_k: 0.801328, samples/s: 681.300 1613604547.6218293
train: epoch 36, iter 800, loss: 2.775089, top_1: 0.574180, top_k: 0.799102, samples/s: 687.606 1613604584.85234
train: epoch 36, iter 900, loss: 2.712836, top_1: 0.571758, top_k: 0.796797, samples/s: 685.050 1613604622.221977
train: epoch 36, iter 1000, loss: 2.904198, top_1: 0.576562, top_k: 0.800352, samples/s: 683.944 1613604659.6519337
train: epoch 36, iter 1100, loss: 2.648038, top_1: 0.571875, top_k: 0.795547, samples/s: 684.471 1613604697.0531108
train: epoch 36, iter 1200, loss: 2.769573, top_1: 0.566797, top_k: 0.798125, samples/s: 684.824 1613604734.4349914
train: epoch 36, iter 1300, loss: 2.798165, top_1: 0.574688, top_k: 0.800664, samples/s: 688.428 1613604771.6211455
train: epoch 36, iter 1400, loss: 2.857885, top_1: 0.577773, top_k: 0.800898, samples/s: 682.167 1613604809.1486104
train: epoch 36, iter 1500, loss: 2.997888, top_1: 0.574844, top_k: 0.800898, samples/s: 683.806 1613604846.5860887
train: epoch 36, iter 1600, loss: 2.837776, top_1: 0.571914, top_k: 0.792383, samples/s: 683.994 1613604884.0133328
train: epoch 36, iter 1700, loss: 2.850057, top_1: 0.575937, top_k: 0.798633, samples/s: 685.930 1613604921.3349457
train: epoch 36, iter 1800, loss: 2.638434, top_1: 0.573242, top_k: 0.800586, samples/s: 682.754 1613604958.8300848
train: epoch 36, iter 1900, loss: 2.559590, top_1: 0.571172, top_k: 0.796602, samples/s: 687.331 1613604996.075618
train: epoch 36, iter 2000, loss: 2.799230, top_1: 0.570508, top_k: 0.797344, samples/s: 687.205 1613605033.3279564
train: epoch 36, iter 2100, loss: 2.864610, top_1: 0.566328, top_k: 0.791836, samples/s: 683.704 1613605070.7711132
train: epoch 36, iter 2200, loss: 2.733207, top_1: 0.567422, top_k: 0.795156, samples/s: 683.275 1613605108.2377162
train: epoch 36, iter 2300, loss: 2.796583, top_1: 0.569531, top_k: 0.795859, samples/s: 686.865 1613605145.5085611
train: epoch 36, iter 2400, loss: 2.869258, top_1: 0.569414, top_k: 0.795742, samples/s: 686.402 1613605182.8044913
train: epoch 36, iter 2500, loss: 2.867795, top_1: 0.565781, top_k: 0.791719, samples/s: 686.456 1613605220.097495
train: epoch 36, iter 2600, loss: 2.929430, top_1: 0.568281, top_k: 0.797031, samples/s: 684.878 1613605257.4763932
train: epoch 36, iter 2700, loss: 2.768126, top_1: 0.571602, top_k: 0.796914, samples/s: 687.755 1613605294.698914
train: epoch 36, iter 2800, loss: 2.789235, top_1: 0.568359, top_k: 0.795078, samples/s: 684.531 1613605332.0967965
train: epoch 36, iter 2900, loss: 2.712449, top_1: 0.568047, top_k: 0.796719, samples/s: 685.752 1613605369.4280643
train: epoch 36, iter 3000, loss: 2.654080, top_1: 0.568320, top_k: 0.794531, samples/s: 686.834 1613605406.7005663
train: epoch 36, iter 3100, loss: 2.671542, top_1: 0.567891, top_k: 0.792891, samples/s: 688.158 1613605443.9012022
train: epoch 36, iter 3200, loss: 2.815502, top_1: 0.568477, top_k: 0.795781, samples/s: 684.994 1613605481.2738237
train: epoch 36, iter 3300, loss: 2.669085, top_1: 0.571914, top_k: 0.792070, samples/s: 688.695 1613605518.4456372
train: epoch 36, iter 3400, loss: 2.889012, top_1: 0.573164, top_k: 0.797969, samples/s: 684.307 1613605555.855625
train: epoch 36, iter 3500, loss: 2.849999, top_1: 0.566133, top_k: 0.792305, samples/s: 685.526 1613605593.1992445
train: epoch 36, iter 3600, loss: 2.820852, top_1: 0.565352, top_k: 0.790977, samples/s: 686.258 1613605630.5030527
train: epoch 36, iter 3700, loss: 2.831100, top_1: 0.568477, top_k: 0.796953, samples/s: 684.899 1613605667.8807702
train: epoch 36, iter 3800, loss: 2.861968, top_1: 0.568125, top_k: 0.793047, samples/s: 685.516 1613605705.224978
train: epoch 36, iter 3900, loss: 2.950382, top_1: 0.570430, top_k: 0.797383, samples/s: 687.886 1613605742.440386
train: epoch 36, iter 4000, loss: 2.922731, top_1: 0.573555, top_k: 0.796289, samples/s: 686.740 1613605779.7179947
train: epoch 36, iter 4100, loss: 2.777200, top_1: 0.566914, top_k: 0.791484, samples/s: 684.498 1613605817.1175516
train: epoch 36, iter 4200, loss: 3.073377, top_1: 0.567852, top_k: 0.793125, samples/s: 688.180 1613605854.3172362
train: epoch 36, iter 4300, loss: 2.936017, top_1: 0.568477, top_k: 0.793125, samples/s: 686.590 1613605891.6029592
train: epoch 36, iter 4400, loss: 2.904820, top_1: 0.566523, top_k: 0.792422, samples/s: 683.941 1613605929.0330293
train: epoch 36, iter 4500, loss: 2.689013, top_1: 0.568164, top_k: 0.797070, samples/s: 687.808 1613605966.2527816
train: epoch 36, iter 4600, loss: 2.773532, top_1: 0.566953, top_k: 0.792539, samples/s: 687.102 1613606003.5106947
train: epoch 36, iter 4700, loss: 2.882871, top_1: 0.566875, top_k: 0.794180, samples/s: 685.632 1613606040.8484888
train: epoch 36, iter 4800, loss: 2.745026, top_1: 0.565664, top_k: 0.792891, samples/s: 683.763 1613606078.2883415
train: epoch 36, iter 4900, loss: 2.704442, top_1: 0.570078, top_k: 0.799727, samples/s: 685.275 1613606115.6456938
train: epoch 36, iter 5000, loss: 2.795604, top_1: 0.572695, top_k: 0.798516, samples/s: 687.962 1613606152.8570535
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_36.
validation: epoch 36, iter 195, top_1: 0.625942, top_k: 0.851562, samples/s: 2173.684 1613606176.9433308
train: epoch 37, iter 100, loss: 2.703014, top_1: 0.583203, top_k: 0.802148, samples/s: 702.379 1613606234.3172746
train: epoch 37, iter 200, loss: 2.615095, top_1: 0.582227, top_k: 0.802383, samples/s: 701.972 1613606270.7861302
train: epoch 37, iter 300, loss: 2.781548, top_1: 0.579844, top_k: 0.802969, samples/s: 684.622 1613606308.1788266
train: epoch 37, iter 400, loss: 2.743022, top_1: 0.585391, top_k: 0.804844, samples/s: 683.614 1613606345.6268065
train: epoch 37, iter 500, loss: 2.608342, top_1: 0.583086, top_k: 0.805508, samples/s: 682.567 1613606383.132327
train: epoch 37, iter 600, loss: 2.766494, top_1: 0.578008, top_k: 0.801914, samples/s: 684.781 1613606420.5165532
train: epoch 37, iter 700, loss: 2.769710, top_1: 0.577461, top_k: 0.801250, samples/s: 684.452 1613606457.9188075
train: epoch 37, iter 800, loss: 2.839035, top_1: 0.570937, top_k: 0.796758, samples/s: 684.557 1613606495.3152034
train: epoch 37, iter 900, loss: 2.639485, top_1: 0.570937, top_k: 0.800156, samples/s: 682.604 1613606532.818677
train: epoch 37, iter 1000, loss: 2.680676, top_1: 0.570703, top_k: 0.797148, samples/s: 685.974 1613606570.1378992
train: epoch 37, iter 1100, loss: 2.897125, top_1: 0.575430, top_k: 0.800234, samples/s: 686.167 1613606607.4464617
train: epoch 37, iter 1200, loss: 2.877444, top_1: 0.564922, top_k: 0.795977, samples/s: 685.304 1613606644.8022394
train: epoch 37, iter 1300, loss: 2.668259, top_1: 0.578242, top_k: 0.803594, samples/s: 686.584 1613606682.0882204
train: epoch 37, iter 1400, loss: 2.827038, top_1: 0.574414, top_k: 0.801328, samples/s: 683.882 1613606719.5215037
train: epoch 37, iter 1500, loss: 2.836820, top_1: 0.576602, top_k: 0.797969, samples/s: 686.234 1613606756.8267071
train: epoch 37, iter 1600, loss: 2.781410, top_1: 0.570625, top_k: 0.798203, samples/s: 684.760 1613606794.2119431
train: epoch 37, iter 1700, loss: 2.913883, top_1: 0.574883, top_k: 0.798750, samples/s: 684.253 1613606831.6251166
train: epoch 37, iter 1800, loss: 2.735860, top_1: 0.571445, top_k: 0.798047, samples/s: 686.042 1613606868.9405725
train: epoch 37, iter 1900, loss: 2.695712, top_1: 0.572539, top_k: 0.798438, samples/s: 683.587 1613606906.3900497
train: epoch 37, iter 2000, loss: 2.844317, top_1: 0.574297, top_k: 0.798945, samples/s: 687.329 1613606943.6357012
train: epoch 37, iter 2100, loss: 2.813691, top_1: 0.573867, top_k: 0.797891, samples/s: 684.218 1613606981.0506349
train: epoch 37, iter 2200, loss: 2.727655, top_1: 0.573086, top_k: 0.796562, samples/s: 685.585 1613607018.391078
train: epoch 37, iter 2300, loss: 2.721177, top_1: 0.572539, top_k: 0.797070, samples/s: 686.011 1613607055.7082253
train: epoch 37, iter 2400, loss: 2.866236, top_1: 0.572148, top_k: 0.797422, samples/s: 685.308 1613607093.0636966
train: epoch 37, iter 2500, loss: 2.829573, top_1: 0.568359, top_k: 0.794063, samples/s: 685.227 1613607130.4236207
train: epoch 37, iter 2600, loss: 2.598841, top_1: 0.566992, top_k: 0.793320, samples/s: 686.596 1613607167.708951
train: epoch 37, iter 2700, loss: 2.666079, top_1: 0.569531, top_k: 0.793789, samples/s: 686.722 1613607204.9874926
train: epoch 37, iter 2800, loss: 2.644963, top_1: 0.572344, top_k: 0.798750, samples/s: 687.106 1613607242.2453146
train: epoch 37, iter 2900, loss: 2.662649, top_1: 0.567266, top_k: 0.794102, samples/s: 685.248 1613607279.6040087
train: epoch 37, iter 3000, loss: 2.669526, top_1: 0.571875, top_k: 0.798281, samples/s: 683.663 1613607317.0492983
train: epoch 37, iter 3100, loss: 2.850224, top_1: 0.569727, top_k: 0.797773, samples/s: 684.529 1613607354.4473753
train: epoch 37, iter 3200, loss: 2.676799, top_1: 0.571016, top_k: 0.797930, samples/s: 684.268 1613607391.859539
train: epoch 37, iter 3300, loss: 2.742854, top_1: 0.572773, top_k: 0.798203, samples/s: 687.633 1613607429.0886536
train: epoch 37, iter 3400, loss: 2.585189, top_1: 0.573320, top_k: 0.798320, samples/s: 683.615 1613607466.5367453
train: epoch 37, iter 3500, loss: 2.640544, top_1: 0.569180, top_k: 0.795391, samples/s: 687.085 1613607503.795608
train: epoch 37, iter 3600, loss: 2.674857, top_1: 0.569453, top_k: 0.794219, samples/s: 686.709 1613607541.074844
train: epoch 37, iter 3700, loss: 2.804765, top_1: 0.569922, top_k: 0.796211, samples/s: 684.801 1613607578.4578943
train: epoch 37, iter 3800, loss: 2.677167, top_1: 0.571367, top_k: 0.795586, samples/s: 685.366 1613607615.810298
train: epoch 37, iter 3900, loss: 2.772995, top_1: 0.571602, top_k: 0.797070, samples/s: 686.039 1613607653.1259286
train: epoch 37, iter 4000, loss: 2.838308, top_1: 0.572305, top_k: 0.794961, samples/s: 685.977 1613607690.4449203
train: epoch 37, iter 4100, loss: 2.687171, top_1: 0.580469, top_k: 0.801523, samples/s: 687.050 1613607727.7056618
train: epoch 37, iter 4200, loss: 2.886967, top_1: 0.574141, top_k: 0.796719, samples/s: 685.307 1613607765.0612116
train: epoch 37, iter 4300, loss: 2.719133, top_1: 0.568477, top_k: 0.795742, samples/s: 684.680 1613607802.4509592
train: epoch 37, iter 4400, loss: 2.706116, top_1: 0.575234, top_k: 0.798594, samples/s: 686.485 1613607839.7423706
train: epoch 37, iter 4500, loss: 2.973479, top_1: 0.564414, top_k: 0.795625, samples/s: 686.018 1613607877.0591924
train: epoch 37, iter 4600, loss: 2.927759, top_1: 0.567187, top_k: 0.796562, samples/s: 686.272 1613607914.362207
train: epoch 37, iter 4700, loss: 2.931673, top_1: 0.570977, top_k: 0.797070, samples/s: 685.082 1613607951.7299001
train: epoch 37, iter 4800, loss: 2.748575, top_1: 0.563633, top_k: 0.793906, samples/s: 688.929 1613607988.8891346
train: epoch 37, iter 4900, loss: 2.850642, top_1: 0.570859, top_k: 0.799687, samples/s: 685.220 1613608026.2494032
train: epoch 37, iter 5000, loss: 2.629858, top_1: 0.571484, top_k: 0.797344, samples/s: 684.746 1613608063.6355104
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_37.
validation: epoch 37, iter 195, top_1: 0.620833, top_k: 0.850421, samples/s: 2166.118 1613608087.7944233
train: epoch 38, iter 100, loss: 2.588238, top_1: 0.579141, top_k: 0.805898, samples/s: 703.044 1613608145.3833127
train: epoch 38, iter 200, loss: 2.737023, top_1: 0.581641, top_k: 0.803594, samples/s: 699.437 1613608181.9844513
train: epoch 38, iter 300, loss: 2.708072, top_1: 0.582070, top_k: 0.807969, samples/s: 683.985 1613608219.4118366
train: epoch 38, iter 400, loss: 2.626390, top_1: 0.580273, top_k: 0.804336, samples/s: 685.742 1613608256.7437308
train: epoch 38, iter 500, loss: 2.691528, top_1: 0.576133, top_k: 0.804336, samples/s: 686.186 1613608294.0514035
train: epoch 38, iter 600, loss: 2.858886, top_1: 0.573008, top_k: 0.797031, samples/s: 683.931 1613608331.4819863
train: epoch 38, iter 700, loss: 2.750412, top_1: 0.580937, top_k: 0.803750, samples/s: 686.240 1613608368.7866838
train: epoch 38, iter 800, loss: 2.603505, top_1: 0.575937, top_k: 0.795430, samples/s: 684.413 1613608406.1911294
train: epoch 38, iter 900, loss: 2.864884, top_1: 0.580547, top_k: 0.805781, samples/s: 684.206 1613608443.6066577
train: epoch 38, iter 1000, loss: 2.889175, top_1: 0.570469, top_k: 0.798984, samples/s: 685.673 1613608480.9422915
train: epoch 38, iter 1100, loss: 2.974712, top_1: 0.571445, top_k: 0.798945, samples/s: 688.259 1613608518.1376362
train: epoch 38, iter 1200, loss: 2.895563, top_1: 0.576719, top_k: 0.798555, samples/s: 683.311 1613608555.6022856
train: epoch 38, iter 1300, loss: 2.968741, top_1: 0.573047, top_k: 0.797891, samples/s: 685.841 1613608592.9286642
train: epoch 38, iter 1400, loss: 2.729104, top_1: 0.575664, top_k: 0.800156, samples/s: 686.409 1613608630.224222
train: epoch 38, iter 1500, loss: 2.568276, top_1: 0.578438, top_k: 0.802656, samples/s: 687.803 1613608667.444088
train: epoch 38, iter 1600, loss: 2.917985, top_1: 0.578945, top_k: 0.801797, samples/s: 683.818 1613608704.880886
train: epoch 38, iter 1700, loss: 2.719172, top_1: 0.574414, top_k: 0.798438, samples/s: 686.950 1613608742.1471574
train: epoch 38, iter 1800, loss: 2.873867, top_1: 0.575625, top_k: 0.800625, samples/s: 688.331 1613608779.3384895
train: epoch 38, iter 1900, loss: 2.974855, top_1: 0.574609, top_k: 0.800781, samples/s: 685.582 1613608816.679094
train: epoch 38, iter 2000, loss: 2.812002, top_1: 0.574688, top_k: 0.796484, samples/s: 687.846 1613608853.8967338
train: epoch 38, iter 2100, loss: 2.789862, top_1: 0.580156, top_k: 0.800586, samples/s: 687.081 1613608891.1557977
train: epoch 38, iter 2200, loss: 2.654459, top_1: 0.577891, top_k: 0.802695, samples/s: 685.824 1613608928.483054
train: epoch 38, iter 2300, loss: 2.543766, top_1: 0.574023, top_k: 0.796602, samples/s: 687.314 1613608965.729618
train: epoch 38, iter 2400, loss: 2.721155, top_1: 0.568242, top_k: 0.799609, samples/s: 687.200 1613609002.9822698
train: epoch 38, iter 2500, loss: 2.855804, top_1: 0.568750, top_k: 0.796797, samples/s: 683.006 1613609040.4635766
train: epoch 38, iter 2600, loss: 2.732833, top_1: 0.573086, top_k: 0.796484, samples/s: 689.483 1613609077.5928862
train: epoch 38, iter 2700, loss: 2.877012, top_1: 0.576250, top_k: 0.800742, samples/s: 687.432 1613609114.8329499
train: epoch 38, iter 2800, loss: 2.667744, top_1: 0.572891, top_k: 0.798203, samples/s: 685.984 1613609152.1515546
train: epoch 38, iter 2900, loss: 2.584739, top_1: 0.572187, top_k: 0.801133, samples/s: 688.073 1613609189.3569427
train: epoch 38, iter 3000, loss: 2.944339, top_1: 0.574922, top_k: 0.795664, samples/s: 687.616 1613609226.5869632
train: epoch 38, iter 3100, loss: 2.814806, top_1: 0.576523, top_k: 0.798984, samples/s: 688.915 1613609263.7469118
train: epoch 38, iter 3200, loss: 2.779159, top_1: 0.569844, top_k: 0.795469, samples/s: 686.113 1613609301.0584524
train: epoch 38, iter 3300, loss: 2.907465, top_1: 0.570117, top_k: 0.793398, samples/s: 688.656 1613609338.2323658
train: epoch 38, iter 3400, loss: 2.718990, top_1: 0.572109, top_k: 0.800000, samples/s: 686.461 1613609375.5251296
train: epoch 38, iter 3500, loss: 2.902980, top_1: 0.570859, top_k: 0.796289, samples/s: 687.607 1613609412.7556896
train: epoch 38, iter 3600, loss: 2.678282, top_1: 0.572930, top_k: 0.804023, samples/s: 688.434 1613609449.9415462
train: epoch 38, iter 3700, loss: 2.771312, top_1: 0.572500, top_k: 0.796562, samples/s: 688.541 1613609487.1215954
train: epoch 38, iter 3800, loss: 2.802210, top_1: 0.572422, top_k: 0.795625, samples/s: 688.404 1613609524.3090754
train: epoch 38, iter 3900, loss: 2.658680, top_1: 0.571445, top_k: 0.797969, samples/s: 687.023 1613609561.5712976
train: epoch 38, iter 4000, loss: 2.830493, top_1: 0.574688, top_k: 0.801016, samples/s: 687.072 1613609598.8307195
train: epoch 38, iter 4100, loss: 2.638506, top_1: 0.574844, top_k: 0.798750, samples/s: 683.366 1613609636.2924254
train: epoch 38, iter 4200, loss: 2.768809, top_1: 0.573438, top_k: 0.796211, samples/s: 686.315 1613609673.5931158
train: epoch 38, iter 4300, loss: 2.691601, top_1: 0.571992, top_k: 0.797188, samples/s: 688.731 1613609710.7629192
train: epoch 38, iter 4400, loss: 2.714247, top_1: 0.570898, top_k: 0.797891, samples/s: 686.137 1613609748.0731795
train: epoch 38, iter 4500, loss: 2.690924, top_1: 0.570859, top_k: 0.797070, samples/s: 689.029 1613609785.226984
train: epoch 38, iter 4600, loss: 2.571761, top_1: 0.571523, top_k: 0.795937, samples/s: 686.646 1613609822.5095356
train: epoch 38, iter 4700, loss: 2.916665, top_1: 0.572422, top_k: 0.795039, samples/s: 690.211 1613609859.599759
train: epoch 38, iter 4800, loss: 2.894536, top_1: 0.570508, top_k: 0.796992, samples/s: 686.137 1613609896.910115
train: epoch 38, iter 4900, loss: 2.943093, top_1: 0.574023, top_k: 0.801250, samples/s: 685.612 1613609934.2490084
train: epoch 38, iter 5000, loss: 2.473208, top_1: 0.577461, top_k: 0.799648, samples/s: 687.481 1613609971.486366
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_38.
validation: epoch 38, iter 195, top_1: 0.631971, top_k: 0.857973, samples/s: 2176.697 1613609995.5325184
train: epoch 39, iter 100, loss: 2.687868, top_1: 0.593711, top_k: 0.808828, samples/s: 704.206 1613610052.937092
train: epoch 39, iter 200, loss: 2.604499, top_1: 0.585156, top_k: 0.811367, samples/s: 700.278 1613610089.4940886
train: epoch 39, iter 300, loss: 2.780885, top_1: 0.576914, top_k: 0.801836, samples/s: 684.891 1613610126.8722582
train: epoch 39, iter 400, loss: 2.760146, top_1: 0.583594, top_k: 0.803555, samples/s: 684.863 1613610164.2519908
train: epoch 39, iter 500, loss: 2.664435, top_1: 0.584492, top_k: 0.808906, samples/s: 685.669 1613610201.587771
train: epoch 39, iter 600, loss: 2.856964, top_1: 0.579375, top_k: 0.804570, samples/s: 682.293 1613610239.108325
train: epoch 39, iter 700, loss: 2.923826, top_1: 0.575781, top_k: 0.801602, samples/s: 684.120 1613610276.5286436
train: epoch 39, iter 800, loss: 2.614961, top_1: 0.575117, top_k: 0.801094, samples/s: 682.489 1613610314.0383613
train: epoch 39, iter 900, loss: 2.755918, top_1: 0.579375, top_k: 0.805391, samples/s: 685.799 1613610351.3671842
train: epoch 39, iter 1000, loss: 2.978210, top_1: 0.575039, top_k: 0.805117, samples/s: 687.260 1613610388.6164067
train: epoch 39, iter 1100, loss: 2.694966, top_1: 0.578516, top_k: 0.801211, samples/s: 684.023 1613610426.0421534
train: epoch 39, iter 1200, loss: 2.794823, top_1: 0.577812, top_k: 0.801445, samples/s: 684.530 1613610463.4400647
train: epoch 39, iter 1300, loss: 2.808762, top_1: 0.572500, top_k: 0.797422, samples/s: 684.862 1613610500.8198626
train: epoch 39, iter 1400, loss: 2.607800, top_1: 0.578359, top_k: 0.800117, samples/s: 685.912 1613610538.1423807
train: epoch 39, iter 1500, loss: 2.891415, top_1: 0.574258, top_k: 0.801484, samples/s: 681.882 1613610575.6854784
train: epoch 39, iter 1600, loss: 2.477175, top_1: 0.576445, top_k: 0.804258, samples/s: 686.527 1613610612.9746487
train: epoch 39, iter 1700, loss: 2.899220, top_1: 0.576133, top_k: 0.801992, samples/s: 687.343 1613610650.2195687
train: epoch 39, iter 1800, loss: 2.802083, top_1: 0.568945, top_k: 0.800898, samples/s: 683.790 1613610687.6579795
train: epoch 39, iter 1900, loss: 2.928179, top_1: 0.576875, top_k: 0.802305, samples/s: 687.167 1613610724.9123595
train: epoch 39, iter 2000, loss: 2.791885, top_1: 0.573516, top_k: 0.797813, samples/s: 688.147 1613610762.1137388
train: epoch 39, iter 2100, loss: 2.757116, top_1: 0.572187, top_k: 0.798555, samples/s: 684.082 1613610799.5361238
train: epoch 39, iter 2200, loss: 2.757655, top_1: 0.578477, top_k: 0.799453, samples/s: 686.145 1613610836.8459945
train: epoch 39, iter 2300, loss: 2.798128, top_1: 0.568125, top_k: 0.795898, samples/s: 683.749 1613610874.2866163
train: epoch 39, iter 2400, loss: 2.766413, top_1: 0.570820, top_k: 0.794609, samples/s: 687.668 1613610911.5138383
train: epoch 39, iter 2500, loss: 2.899413, top_1: 0.570000, top_k: 0.798242, samples/s: 684.264 1613610948.9263797
train: epoch 39, iter 2600, loss: 2.669660, top_1: 0.574453, top_k: 0.797227, samples/s: 683.358 1613610986.388421
train: epoch 39, iter 2700, loss: 2.776850, top_1: 0.576875, top_k: 0.803516, samples/s: 685.678 1613611023.7237523
train: epoch 39, iter 2800, loss: 2.867613, top_1: 0.574102, top_k: 0.800000, samples/s: 683.104 1613611061.1997588
train: epoch 39, iter 2900, loss: 2.761029, top_1: 0.578750, top_k: 0.805156, samples/s: 685.230 1613611098.5594182
train: epoch 39, iter 3000, loss: 2.768315, top_1: 0.576250, top_k: 0.799648, samples/s: 686.122 1613611135.870609
train: epoch 39, iter 3100, loss: 2.749686, top_1: 0.573750, top_k: 0.797695, samples/s: 684.183 1613611173.287406
train: epoch 39, iter 3200, loss: 2.711531, top_1: 0.578594, top_k: 0.802344, samples/s: 685.405 1613611210.6376755
train: epoch 39, iter 3300, loss: 2.677174, top_1: 0.576211, top_k: 0.801055, samples/s: 686.523 1613611247.9269953
train: epoch 39, iter 3400, loss: 2.824133, top_1: 0.572344, top_k: 0.796445, samples/s: 687.246 1613611285.1771123
train: epoch 39, iter 3500, loss: 2.598528, top_1: 0.571758, top_k: 0.800625, samples/s: 681.834 1613611322.722885
train: epoch 39, iter 3600, loss: 2.906757, top_1: 0.570508, top_k: 0.798477, samples/s: 684.480 1613611360.1235373
train: epoch 39, iter 3700, loss: 2.965264, top_1: 0.572383, top_k: 0.799805, samples/s: 683.377 1613611397.5845857
train: epoch 39, iter 3800, loss: 2.839676, top_1: 0.572578, top_k: 0.796484, samples/s: 684.937 1613611434.9602077
train: epoch 39, iter 3900, loss: 2.757534, top_1: 0.573164, top_k: 0.798008, samples/s: 683.513 1613611472.4138002
train: epoch 39, iter 4000, loss: 2.700349, top_1: 0.574063, top_k: 0.798945, samples/s: 683.422 1613611509.872434
train: epoch 39, iter 4100, loss: 2.613927, top_1: 0.568789, top_k: 0.793203, samples/s: 682.961 1613611547.3562663
train: epoch 39, iter 4200, loss: 2.778884, top_1: 0.576406, top_k: 0.799297, samples/s: 685.931 1613611584.6778316
train: epoch 39, iter 4300, loss: 2.612111, top_1: 0.575898, top_k: 0.799023, samples/s: 683.040 1613611622.1573117
train: epoch 39, iter 4400, loss: 2.608922, top_1: 0.571992, top_k: 0.794766, samples/s: 684.548 1613611659.5542047
train: epoch 39, iter 4500, loss: 2.718905, top_1: 0.571562, top_k: 0.799023, samples/s: 680.621 1613611697.1669657
train: epoch 39, iter 4600, loss: 2.889516, top_1: 0.571367, top_k: 0.796211, samples/s: 683.972 1613611734.5952966
train: epoch 39, iter 4700, loss: 2.951185, top_1: 0.567383, top_k: 0.791328, samples/s: 686.236 1613611771.9003892
train: epoch 39, iter 4800, loss: 2.857672, top_1: 0.572148, top_k: 0.801328, samples/s: 683.265 1613611809.36745
train: epoch 39, iter 4900, loss: 2.875705, top_1: 0.575586, top_k: 0.801328, samples/s: 685.011 1613611846.7391515
train: epoch 39, iter 5000, loss: 2.832143, top_1: 0.577422, top_k: 0.800742, samples/s: 683.530 1613611884.1917684
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_39.
validation: epoch 39, iter 195, top_1: 0.623017, top_k: 0.854447, samples/s: 2150.971 1613611908.5004175
train: epoch 40, iter 100, loss: 2.681033, top_1: 0.580352, top_k: 0.802461, samples/s: 702.716 1613611966.4450421
train: epoch 40, iter 200, loss: 2.733627, top_1: 0.579688, top_k: 0.802383, samples/s: 699.951 1613612003.0191386
train: epoch 40, iter 300, loss: 2.718452, top_1: 0.581641, top_k: 0.803711, samples/s: 683.497 1613612040.4734898
train: epoch 40, iter 400, loss: 2.728429, top_1: 0.584180, top_k: 0.806406, samples/s: 680.321 1613612078.1028662
train: epoch 40, iter 500, loss: 2.780212, top_1: 0.580898, top_k: 0.801211, samples/s: 682.756 1613612115.5979657
train: epoch 40, iter 600, loss: 2.682534, top_1: 0.583711, top_k: 0.805078, samples/s: 681.920 1613612153.1389675
train: epoch 40, iter 700, loss: 2.785314, top_1: 0.579766, top_k: 0.797969, samples/s: 682.221 1613612190.6634762
train: epoch 40, iter 800, loss: 2.673428, top_1: 0.574648, top_k: 0.796758, samples/s: 684.838 1613612228.0446446
train: epoch 40, iter 900, loss: 2.685962, top_1: 0.577969, top_k: 0.802930, samples/s: 686.212 1613612265.3509521
train: epoch 40, iter 1000, loss: 2.756230, top_1: 0.577812, top_k: 0.802930, samples/s: 683.005 1613612302.8323767
train: epoch 40, iter 1100, loss: 2.688716, top_1: 0.582109, top_k: 0.801211, samples/s: 686.768 1613612340.1084616
train: epoch 40, iter 1200, loss: 2.714962, top_1: 0.577969, top_k: 0.802266, samples/s: 683.510 1613612377.5621762
train: epoch 40, iter 1300, loss: 2.968010, top_1: 0.574844, top_k: 0.802930, samples/s: 686.602 1613612414.8472393
train: epoch 40, iter 1400, loss: 2.716738, top_1: 0.578008, top_k: 0.799102, samples/s: 683.298 1613612452.312579
train: epoch 40, iter 1500, loss: 2.783726, top_1: 0.574141, top_k: 0.797891, samples/s: 685.995 1613612489.6306963
train: epoch 40, iter 1600, loss: 2.895492, top_1: 0.578516, top_k: 0.801953, samples/s: 684.974 1613612527.0043674
train: epoch 40, iter 1700, loss: 2.661707, top_1: 0.574258, top_k: 0.797969, samples/s: 684.530 1613612564.4021409
train: epoch 40, iter 1800, loss: 2.703230, top_1: 0.583398, top_k: 0.803906, samples/s: 685.979 1613612601.7210782
train: epoch 40, iter 1900, loss: 2.703676, top_1: 0.578242, top_k: 0.802969, samples/s: 684.705 1613612639.109519
train: epoch 40, iter 2000, loss: 2.647799, top_1: 0.577344, top_k: 0.803203, samples/s: 684.477 1613612676.510343
train: epoch 40, iter 2100, loss: 2.632679, top_1: 0.574141, top_k: 0.799766, samples/s: 687.062 1613612713.7704155
train: epoch 40, iter 2200, loss: 2.812691, top_1: 0.573008, top_k: 0.801445, samples/s: 684.386 1613612751.1762524
train: epoch 40, iter 2300, loss: 2.886529, top_1: 0.576797, top_k: 0.801680, samples/s: 685.731 1613612788.5085578
train: epoch 40, iter 2400, loss: 2.690979, top_1: 0.574961, top_k: 0.803477, samples/s: 682.588 1613612826.0129068
train: epoch 40, iter 2500, loss: 2.699038, top_1: 0.577578, top_k: 0.803359, samples/s: 683.896 1613612863.4455135
train: epoch 40, iter 2600, loss: 2.749049, top_1: 0.578047, top_k: 0.800859, samples/s: 685.402 1613612900.7957842
train: epoch 40, iter 2700, loss: 2.594967, top_1: 0.581914, top_k: 0.805000, samples/s: 684.081 1613612938.2182913
train: epoch 40, iter 2800, loss: 2.600615, top_1: 0.579063, top_k: 0.803906, samples/s: 685.373 1613612975.5702894
train: epoch 40, iter 2900, loss: 2.735888, top_1: 0.579063, top_k: 0.805664, samples/s: 682.713 1613613013.0677385
train: epoch 40, iter 3000, loss: 2.708225, top_1: 0.572656, top_k: 0.803984, samples/s: 683.100 1613613050.543875
train: epoch 40, iter 3100, loss: 2.774729, top_1: 0.578398, top_k: 0.801797, samples/s: 684.202 1613613087.9598525
train: epoch 40, iter 3200, loss: 2.720857, top_1: 0.573867, top_k: 0.800977, samples/s: 683.935 1613613125.3901844
train: epoch 40, iter 3300, loss: 2.766925, top_1: 0.575391, top_k: 0.800078, samples/s: 686.039 1613613162.7059438
train: epoch 40, iter 3400, loss: 2.673033, top_1: 0.581211, top_k: 0.803906, samples/s: 683.165 1613613200.1785395
train: epoch 40, iter 3500, loss: 2.807396, top_1: 0.574102, top_k: 0.799180, samples/s: 685.382 1613613237.530025
train: epoch 40, iter 3600, loss: 2.739653, top_1: 0.570820, top_k: 0.799805, samples/s: 685.076 1613613274.8981369
train: epoch 40, iter 3700, loss: 2.578757, top_1: 0.568750, top_k: 0.798281, samples/s: 681.949 1613613312.4375744
train: epoch 40, iter 3800, loss: 2.716086, top_1: 0.571289, top_k: 0.795547, samples/s: 683.418 1613613349.896451
train: epoch 40, iter 3900, loss: 2.781347, top_1: 0.574648, top_k: 0.800000, samples/s: 686.128 1613613387.207243
train: epoch 40, iter 4000, loss: 2.713076, top_1: 0.573398, top_k: 0.796719, samples/s: 681.822 1613613424.7536745
train: epoch 40, iter 4100, loss: 2.817013, top_1: 0.570977, top_k: 0.798398, samples/s: 682.602 1613613462.257138
train: epoch 40, iter 4200, loss: 2.733423, top_1: 0.572031, top_k: 0.797656, samples/s: 684.412 1613613499.6615689
train: epoch 40, iter 4300, loss: 2.910944, top_1: 0.574023, top_k: 0.795742, samples/s: 685.570 1613613537.0026968
train: epoch 40, iter 4400, loss: 2.844477, top_1: 0.565117, top_k: 0.795312, samples/s: 683.875 1613613574.4363837
train: epoch 40, iter 4500, loss: 2.654214, top_1: 0.573516, top_k: 0.797930, samples/s: 681.893 1613613611.9790006
train: epoch 40, iter 4600, loss: 2.862630, top_1: 0.572773, top_k: 0.797500, samples/s: 682.145 1613613649.5076966
train: epoch 40, iter 4700, loss: 2.687530, top_1: 0.573906, top_k: 0.795039, samples/s: 683.405 1613613686.9671938
train: epoch 40, iter 4800, loss: 2.867473, top_1: 0.573867, top_k: 0.796562, samples/s: 684.234 1613613724.3812246
train: epoch 40, iter 4900, loss: 2.853076, top_1: 0.574023, top_k: 0.799805, samples/s: 683.529 1613613761.8339534
train: epoch 40, iter 5000, loss: 2.816243, top_1: 0.574023, top_k: 0.800430, samples/s: 681.752 1613613799.3843374
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_40.
validation: epoch 40, iter 195, top_1: 0.625881, top_k: 0.852925, samples/s: 2157.797 1613613823.6329217
train: epoch 41, iter 100, loss: 2.745136, top_1: 0.575664, top_k: 0.802266, samples/s: 703.882 1613613881.7133303
train: epoch 41, iter 200, loss: 2.876329, top_1: 0.583750, top_k: 0.809609, samples/s: 699.694 1613613918.3010445
train: epoch 41, iter 300, loss: 2.734097, top_1: 0.584648, top_k: 0.807773, samples/s: 681.343 1613613955.8736405
train: epoch 41, iter 400, loss: 2.898571, top_1: 0.576523, top_k: 0.801719, samples/s: 684.667 1613613993.2640686
train: epoch 41, iter 500, loss: 2.835571, top_1: 0.579023, top_k: 0.804219, samples/s: 681.837 1613614030.8097346
train: epoch 41, iter 600, loss: 2.366827, top_1: 0.586797, top_k: 0.806406, samples/s: 682.427 1613614068.3228557
train: epoch 41, iter 700, loss: 2.805911, top_1: 0.582383, top_k: 0.809180, samples/s: 682.095 1613614105.8543787
train: epoch 41, iter 800, loss: 2.572519, top_1: 0.577969, top_k: 0.801602, samples/s: 683.132 1613614143.328827
train: epoch 41, iter 900, loss: 2.573200, top_1: 0.583867, top_k: 0.805273, samples/s: 682.522 1613614180.8367612
train: epoch 41, iter 1000, loss: 2.733434, top_1: 0.579063, top_k: 0.800820, samples/s: 681.883 1613614218.3798227
train: epoch 41, iter 1100, loss: 2.769196, top_1: 0.577617, top_k: 0.801367, samples/s: 682.037 1613614255.9144187
train: epoch 41, iter 1200, loss: 2.739583, top_1: 0.583242, top_k: 0.806523, samples/s: 681.709 1613614293.467135
train: epoch 41, iter 1300, loss: 2.725512, top_1: 0.575469, top_k: 0.799141, samples/s: 682.180 1613614330.9938116
train: epoch 41, iter 1400, loss: 2.633951, top_1: 0.575391, top_k: 0.802461, samples/s: 682.608 1613614368.4971068
train: epoch 41, iter 1500, loss: 2.652817, top_1: 0.579297, top_k: 0.803906, samples/s: 686.089 1613614405.810057
train: epoch 41, iter 1600, loss: 2.803475, top_1: 0.575781, top_k: 0.804883, samples/s: 682.878 1613614443.2983594
train: epoch 41, iter 1700, loss: 2.763869, top_1: 0.577305, top_k: 0.805703, samples/s: 683.468 1613614480.7544746
train: epoch 41, iter 1800, loss: 3.022212, top_1: 0.580547, top_k: 0.802734, samples/s: 681.546 1613614518.3161345
train: epoch 41, iter 1900, loss: 2.700093, top_1: 0.582578, top_k: 0.802578, samples/s: 687.136 1613614555.572239
train: epoch 41, iter 2000, loss: 2.737145, top_1: 0.581250, top_k: 0.803125, samples/s: 679.358 1613614593.2548807
train: epoch 41, iter 2100, loss: 2.775660, top_1: 0.580078, top_k: 0.800898, samples/s: 684.747 1613614630.6409092
train: epoch 41, iter 2200, loss: 2.805423, top_1: 0.571133, top_k: 0.797969, samples/s: 681.490 1613614668.205651
train: epoch 41, iter 2300, loss: 2.564339, top_1: 0.580820, top_k: 0.801680, samples/s: 682.120 1613614705.7357183
train: epoch 41, iter 2400, loss: 2.529585, top_1: 0.580703, top_k: 0.803125, samples/s: 683.876 1613614743.1694136
train: epoch 41, iter 2500, loss: 2.691002, top_1: 0.578555, top_k: 0.802188, samples/s: 681.272 1613614780.746174
train: epoch 41, iter 2600, loss: 2.686494, top_1: 0.577031, top_k: 0.800430, samples/s: 683.056 1613614818.2248065
train: epoch 41, iter 2700, loss: 2.871511, top_1: 0.573789, top_k: 0.799922, samples/s: 683.567 1613614855.6753292
train: epoch 41, iter 2800, loss: 2.668299, top_1: 0.575273, top_k: 0.800273, samples/s: 681.908 1613614893.2171228
train: epoch 41, iter 2900, loss: 2.859810, top_1: 0.577656, top_k: 0.800547, samples/s: 684.146 1613614930.6360343
train: epoch 41, iter 3000, loss: 2.427739, top_1: 0.577031, top_k: 0.799336, samples/s: 682.871 1613614968.1247911
train: epoch 41, iter 3100, loss: 2.595654, top_1: 0.576484, top_k: 0.799805, samples/s: 682.435 1613615005.6375597
train: epoch 41, iter 3200, loss: 2.857476, top_1: 0.576562, top_k: 0.796445, samples/s: 683.903 1613615043.0696993
train: epoch 41, iter 3300, loss: 2.692469, top_1: 0.579414, top_k: 0.803789, samples/s: 683.749 1613615080.5103958
train: epoch 41, iter 3400, loss: 3.066879, top_1: 0.580234, top_k: 0.802773, samples/s: 682.123 1613615118.0402453
train: epoch 41, iter 3500, loss: 2.757275, top_1: 0.575273, top_k: 0.798008, samples/s: 682.962 1613615155.5239646
train: epoch 41, iter 3600, loss: 2.791537, top_1: 0.575156, top_k: 0.799375, samples/s: 683.595 1613615192.9731045
train: epoch 41, iter 3700, loss: 2.757675, top_1: 0.568086, top_k: 0.797930, samples/s: 681.305 1613615230.548052
train: epoch 41, iter 3800, loss: 2.613058, top_1: 0.572266, top_k: 0.801133, samples/s: 682.785 1613615268.041584
train: epoch 41, iter 3900, loss: 2.814722, top_1: 0.566016, top_k: 0.795312, samples/s: 682.673 1613615305.5411432
train: epoch 41, iter 4000, loss: 2.805041, top_1: 0.576445, top_k: 0.799336, samples/s: 685.518 1613615342.8852422
train: epoch 41, iter 4100, loss: 2.843315, top_1: 0.576484, top_k: 0.801484, samples/s: 683.693 1613615380.328848
train: epoch 41, iter 4200, loss: 2.813753, top_1: 0.577070, top_k: 0.798438, samples/s: 682.442 1613615417.8411942
train: epoch 41, iter 4300, loss: 2.714933, top_1: 0.577227, top_k: 0.799727, samples/s: 680.256 1613615455.4741504
train: epoch 41, iter 4400, loss: 2.778958, top_1: 0.580742, top_k: 0.802734, samples/s: 682.565 1613615492.979753
train: epoch 41, iter 4500, loss: 2.543305, top_1: 0.576836, top_k: 0.802109, samples/s: 683.129 1613615530.4543133
train: epoch 41, iter 4600, loss: 2.982399, top_1: 0.575859, top_k: 0.802344, samples/s: 683.921 1613615567.8855486
train: epoch 41, iter 4700, loss: 2.853502, top_1: 0.573984, top_k: 0.798086, samples/s: 682.010 1613615605.4216468
train: epoch 41, iter 4800, loss: 2.761768, top_1: 0.578125, top_k: 0.804102, samples/s: 680.200 1613615643.0576344
train: epoch 41, iter 4900, loss: 2.723569, top_1: 0.575391, top_k: 0.800586, samples/s: 680.751 1613615680.6630847
train: epoch 41, iter 5000, loss: 2.604192, top_1: 0.577461, top_k: 0.801719, samples/s: 681.919 1613615718.2042468
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_41.
validation: epoch 41, iter 195, top_1: 0.626442, top_k: 0.854427, samples/s: 2149.983 1613615742.5050745
train: epoch 42, iter 100, loss: 2.553593, top_1: 0.589297, top_k: 0.808711, samples/s: 702.695 1613615800.3614006
train: epoch 42, iter 200, loss: 2.613436, top_1: 0.587422, top_k: 0.809336, samples/s: 697.198 1613615837.0798278
train: epoch 42, iter 300, loss: 2.901440, top_1: 0.582578, top_k: 0.806133, samples/s: 682.848 1613615874.5697377
train: epoch 42, iter 400, loss: 2.738573, top_1: 0.588711, top_k: 0.810430, samples/s: 681.073 1613615912.1574569
train: epoch 42, iter 500, loss: 2.680432, top_1: 0.582852, top_k: 0.807695, samples/s: 681.051 1613615949.746465
train: epoch 42, iter 600, loss: 2.608670, top_1: 0.578047, top_k: 0.798867, samples/s: 680.993 1613615987.338593
train: epoch 42, iter 700, loss: 2.720354, top_1: 0.583594, top_k: 0.806367, samples/s: 682.355 1613616024.85576
train: epoch 42, iter 800, loss: 2.791481, top_1: 0.581836, top_k: 0.803945, samples/s: 682.032 1613616062.3906443
train: epoch 42, iter 900, loss: 2.856632, top_1: 0.573242, top_k: 0.801992, samples/s: 679.398 1613616100.0710785
train: epoch 42, iter 1000, loss: 2.591100, top_1: 0.582305, top_k: 0.807422, samples/s: 680.895 1613616137.668603
train: epoch 42, iter 1100, loss: 2.725470, top_1: 0.580742, top_k: 0.799961, samples/s: 681.155 1613616175.2519224
train: epoch 42, iter 1200, loss: 2.915128, top_1: 0.581797, top_k: 0.802891, samples/s: 682.709 1613616212.7495327
train: epoch 42, iter 1300, loss: 2.801192, top_1: 0.577617, top_k: 0.804219, samples/s: 681.828 1613616250.2956784
train: epoch 42, iter 1400, loss: 2.834776, top_1: 0.583594, top_k: 0.802617, samples/s: 681.126 1613616287.880496
train: epoch 42, iter 1500, loss: 2.736575, top_1: 0.577305, top_k: 0.803672, samples/s: 683.718 1613616325.322798
train: epoch 42, iter 1600, loss: 2.718786, top_1: 0.578867, top_k: 0.805742, samples/s: 681.859 1613616362.8671386
train: epoch 42, iter 1700, loss: 2.658106, top_1: 0.586992, top_k: 0.805820, samples/s: 685.216 1613616400.2276998
train: epoch 42, iter 1800, loss: 2.818350, top_1: 0.580078, top_k: 0.803906, samples/s: 680.627 1613616437.8400743
train: epoch 42, iter 1900, loss: 2.743193, top_1: 0.583711, top_k: 0.805195, samples/s: 682.552 1613616475.3463898
train: epoch 42, iter 2000, loss: 2.762047, top_1: 0.576914, top_k: 0.803242, samples/s: 680.342 1613616512.9744465
train: epoch 42, iter 2100, loss: 2.885438, top_1: 0.577930, top_k: 0.803594, samples/s: 684.480 1613616550.3751938
train: epoch 42, iter 2200, loss: 2.838686, top_1: 0.581289, top_k: 0.803281, samples/s: 681.929 1613616587.9156368
train: epoch 42, iter 2300, loss: 2.560276, top_1: 0.578945, top_k: 0.802383, samples/s: 682.763 1613616625.4103515
train: epoch 42, iter 2400, loss: 2.763939, top_1: 0.578750, top_k: 0.803516, samples/s: 681.663 1613616662.965703
train: epoch 42, iter 2500, loss: 2.863103, top_1: 0.576562, top_k: 0.801953, samples/s: 682.861 1613616700.4548926
train: epoch 42, iter 2600, loss: 2.861436, top_1: 0.582266, top_k: 0.807305, samples/s: 681.610 1613616738.0130265
train: epoch 42, iter 2700, loss: 2.929543, top_1: 0.578203, top_k: 0.802227, samples/s: 680.471 1613616775.634084
train: epoch 42, iter 2800, loss: 2.784012, top_1: 0.583477, top_k: 0.802617, samples/s: 681.301 1613616813.2091887
train: epoch 42, iter 2900, loss: 2.768922, top_1: 0.582578, top_k: 0.804805, samples/s: 683.868 1613616850.6434011
train: epoch 42, iter 3000, loss: 2.705691, top_1: 0.582070, top_k: 0.802617, samples/s: 681.718 1613616888.1954558
train: epoch 42, iter 3100, loss: 2.712388, top_1: 0.580234, top_k: 0.803398, samples/s: 679.664 1613616925.8611345
train: epoch 42, iter 3200, loss: 2.667738, top_1: 0.575273, top_k: 0.802227, samples/s: 682.738 1613616963.3571908
train: epoch 42, iter 3300, loss: 2.751877, top_1: 0.577031, top_k: 0.798047, samples/s: 681.106 1613617000.9432569
train: epoch 42, iter 3400, loss: 2.596004, top_1: 0.576680, top_k: 0.800937, samples/s: 680.366 1613617038.5699658
train: epoch 42, iter 3500, loss: 2.719159, top_1: 0.575742, top_k: 0.800195, samples/s: 682.793 1613617076.0630753
train: epoch 42, iter 3600, loss: 2.723255, top_1: 0.573242, top_k: 0.799023, samples/s: 682.075 1613617113.5955896
train: epoch 42, iter 3700, loss: 2.626255, top_1: 0.574609, top_k: 0.798867, samples/s: 680.501 1613617151.214899
train: epoch 42, iter 3800, loss: 2.643254, top_1: 0.573984, top_k: 0.798516, samples/s: 682.124 1613617188.7447433
train: epoch 42, iter 3900, loss: 2.713778, top_1: 0.576523, top_k: 0.803984, samples/s: 682.555 1613617226.250912
train: epoch 42, iter 4000, loss: 2.815961, top_1: 0.575195, top_k: 0.799023, samples/s: 681.022 1613617263.8413603
train: epoch 42, iter 4100, loss: 2.764606, top_1: 0.578711, top_k: 0.805273, samples/s: 680.376 1613617301.467724
train: epoch 42, iter 4200, loss: 2.642611, top_1: 0.572383, top_k: 0.796367, samples/s: 683.652 1613617338.9136484
train: epoch 42, iter 4300, loss: 2.874104, top_1: 0.576914, top_k: 0.798711, samples/s: 680.478 1613617376.5342932
train: epoch 42, iter 4400, loss: 2.748914, top_1: 0.579219, top_k: 0.799883, samples/s: 679.534 1613617414.2071602
train: epoch 42, iter 4500, loss: 2.773909, top_1: 0.575781, top_k: 0.801797, samples/s: 682.549 1613617451.713583
train: epoch 42, iter 4600, loss: 2.834168, top_1: 0.578086, top_k: 0.799219, samples/s: 679.777 1613617489.3730485
train: epoch 42, iter 4700, loss: 2.541619, top_1: 0.580469, top_k: 0.804414, samples/s: 679.031 1613617527.0737457
train: epoch 42, iter 4800, loss: 2.925017, top_1: 0.579844, top_k: 0.799570, samples/s: 681.365 1613617564.6453965
train: epoch 42, iter 4900, loss: 2.878075, top_1: 0.574258, top_k: 0.799023, samples/s: 678.873 1613617602.3550653
train: epoch 42, iter 5000, loss: 2.870746, top_1: 0.577930, top_k: 0.801133, samples/s: 681.066 1613617639.943097
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_42.
validation: epoch 42, iter 195, top_1: 0.632332, top_k: 0.855689, samples/s: 2124.976 1613617664.567806
train: epoch 43, iter 100, loss: 2.758601, top_1: 0.584609, top_k: 0.808750, samples/s: 702.648 1613617722.0648906
train: epoch 43, iter 200, loss: 2.722110, top_1: 0.594258, top_k: 0.815586, samples/s: 695.719 1613617758.8615706
train: epoch 43, iter 300, loss: 2.849016, top_1: 0.590391, top_k: 0.809844, samples/s: 680.939 1613617796.4564073
train: epoch 43, iter 400, loss: 2.656781, top_1: 0.579922, top_k: 0.804141, samples/s: 680.630 1613617834.068729
train: epoch 43, iter 500, loss: 2.798251, top_1: 0.588594, top_k: 0.809063, samples/s: 678.352 1613617871.807155
train: epoch 43, iter 600, loss: 2.775268, top_1: 0.589961, top_k: 0.807578, samples/s: 679.758 1613617909.4676664
train: epoch 43, iter 700, loss: 2.631963, top_1: 0.583320, top_k: 0.806602, samples/s: 679.323 1613617947.152332
train: epoch 43, iter 800, loss: 2.753487, top_1: 0.583711, top_k: 0.805586, samples/s: 676.947 1613617984.9691505
train: epoch 43, iter 900, loss: 2.693638, top_1: 0.579844, top_k: 0.805898, samples/s: 678.885 1613618022.6780028
train: epoch 43, iter 1000, loss: 2.658931, top_1: 0.581719, top_k: 0.806328, samples/s: 678.972 1613618060.3820577
train: epoch 43, iter 1100, loss: 2.745653, top_1: 0.578047, top_k: 0.802227, samples/s: 680.787 1613618097.9856215
train: epoch 43, iter 1200, loss: 2.805965, top_1: 0.585234, top_k: 0.806367, samples/s: 677.471 1613618135.7732472
train: epoch 43, iter 1300, loss: 2.603487, top_1: 0.581328, top_k: 0.805625, samples/s: 681.216 1613618173.3531072
train: epoch 43, iter 1400, loss: 2.760899, top_1: 0.577695, top_k: 0.802227, samples/s: 681.662 1613618210.908337
train: epoch 43, iter 1500, loss: 2.673285, top_1: 0.582539, top_k: 0.806953, samples/s: 677.516 1613618248.69349
train: epoch 43, iter 1600, loss: 2.625815, top_1: 0.584414, top_k: 0.802617, samples/s: 681.547 1613618286.255105
train: epoch 43, iter 1700, loss: 2.804585, top_1: 0.582266, top_k: 0.806211, samples/s: 679.048 1613618323.954907
train: epoch 43, iter 1800, loss: 2.611965, top_1: 0.580781, top_k: 0.806289, samples/s: 680.503 1613618361.5741034
train: epoch 43, iter 1900, loss: 2.633191, top_1: 0.578945, top_k: 0.802852, samples/s: 679.526 1613618399.2474008
train: epoch 43, iter 2000, loss: 2.667694, top_1: 0.584648, top_k: 0.805117, samples/s: 679.558 1613618436.9190154
train: epoch 43, iter 2100, loss: 2.614555, top_1: 0.581406, top_k: 0.806484, samples/s: 679.690 1613618474.5831153
train: epoch 43, iter 2200, loss: 2.682320, top_1: 0.580664, top_k: 0.804727, samples/s: 682.318 1613618512.1023254
train: epoch 43, iter 2300, loss: 2.923439, top_1: 0.579102, top_k: 0.804375, samples/s: 679.734 1613618549.7641523
train: epoch 43, iter 2400, loss: 2.774587, top_1: 0.578359, top_k: 0.802305, samples/s: 679.694 1613618587.4281583
train: epoch 43, iter 2500, loss: 2.672894, top_1: 0.575625, top_k: 0.801680, samples/s: 679.232 1613618625.1177804
train: epoch 43, iter 2600, loss: 2.736356, top_1: 0.587500, top_k: 0.808359, samples/s: 678.298 1613618662.8592596
train: epoch 43, iter 2700, loss: 2.702186, top_1: 0.578359, top_k: 0.802617, samples/s: 678.045 1613618700.6147923
train: epoch 43, iter 2800, loss: 2.934836, top_1: 0.579102, top_k: 0.802852, samples/s: 680.254 1613618738.247872
train: epoch 43, iter 2900, loss: 2.692787, top_1: 0.581328, top_k: 0.801758, samples/s: 676.294 1613618776.1012485
train: epoch 43, iter 3000, loss: 2.722080, top_1: 0.576758, top_k: 0.802109, samples/s: 681.254 1613618813.6790378
train: epoch 43, iter 3100, loss: 2.771038, top_1: 0.575391, top_k: 0.802852, samples/s: 679.172 1613618851.37192
train: epoch 43, iter 3200, loss: 2.616148, top_1: 0.579883, top_k: 0.798555, samples/s: 680.365 1613618888.998836
train: epoch 43, iter 3300, loss: 2.781064, top_1: 0.578047, top_k: 0.802227, samples/s: 678.439 1613618926.732534
train: epoch 43, iter 3400, loss: 2.746948, top_1: 0.581992, top_k: 0.804922, samples/s: 679.537 1613618964.4052563
train: epoch 43, iter 3500, loss: 2.665734, top_1: 0.571758, top_k: 0.797383, samples/s: 678.300 1613619002.146566
train: epoch 43, iter 3600, loss: 2.767664, top_1: 0.571992, top_k: 0.799648, samples/s: 680.226 1613619039.7811587
train: epoch 43, iter 3700, loss: 3.035467, top_1: 0.577070, top_k: 0.803867, samples/s: 679.937 1613619077.4317384
train: epoch 43, iter 3800, loss: 2.705962, top_1: 0.576680, top_k: 0.800508, samples/s: 680.683 1613619115.0410545
train: epoch 43, iter 3900, loss: 2.821251, top_1: 0.575078, top_k: 0.801602, samples/s: 677.078 1613619152.8505313
train: epoch 43, iter 4000, loss: 2.871886, top_1: 0.585117, top_k: 0.806641, samples/s: 682.992 1613619190.3326504
train: epoch 43, iter 4100, loss: 2.681764, top_1: 0.583438, top_k: 0.803164, samples/s: 679.532 1613619228.0055866
train: epoch 43, iter 4200, loss: 2.782912, top_1: 0.581523, top_k: 0.806719, samples/s: 676.546 1613619265.8448675
train: epoch 43, iter 4300, loss: 2.698346, top_1: 0.577109, top_k: 0.801328, samples/s: 678.473 1613619303.5765836
train: epoch 43, iter 4400, loss: 2.825402, top_1: 0.582500, top_k: 0.806797, samples/s: 679.434 1613619341.255095
train: epoch 43, iter 4500, loss: 2.835484, top_1: 0.572852, top_k: 0.800508, samples/s: 680.147 1613619378.8939328
train: epoch 43, iter 4600, loss: 2.959030, top_1: 0.585625, top_k: 0.804883, samples/s: 676.902 1613619416.7133276
train: epoch 43, iter 4700, loss: 2.719902, top_1: 0.580156, top_k: 0.802773, samples/s: 680.827 1613619454.3146532
train: epoch 43, iter 4800, loss: 2.852950, top_1: 0.576836, top_k: 0.801055, samples/s: 677.637 1613619492.09307
train: epoch 43, iter 4900, loss: 2.790595, top_1: 0.580781, top_k: 0.798516, samples/s: 682.077 1613619529.6254933
train: epoch 43, iter 5000, loss: 2.738604, top_1: 0.574727, top_k: 0.798047, samples/s: 679.097 1613619567.3226106
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_43.
validation: epoch 43, iter 195, top_1: 0.627344, top_k: 0.854147, samples/s: 2123.370 1613619591.9509943
train: epoch 44, iter 100, loss: 2.622343, top_1: 0.585547, top_k: 0.807930, samples/s: 703.842 1613619649.4395537
train: epoch 44, iter 200, loss: 2.820832, top_1: 0.588047, top_k: 0.807109, samples/s: 692.436 1613619686.4105217
train: epoch 44, iter 300, loss: 2.662354, top_1: 0.588047, top_k: 0.809648, samples/s: 678.725 1613619724.1281958
train: epoch 44, iter 400, loss: 2.746841, top_1: 0.585898, top_k: 0.807031, samples/s: 676.098 1613619761.9926085
train: epoch 44, iter 500, loss: 2.590682, top_1: 0.586094, top_k: 0.809961, samples/s: 677.106 1613619799.800597
train: epoch 44, iter 600, loss: 2.625621, top_1: 0.584844, top_k: 0.807461, samples/s: 677.882 1613619837.565339
train: epoch 44, iter 700, loss: 2.657956, top_1: 0.582617, top_k: 0.809766, samples/s: 675.988 1613619875.4357772
train: epoch 44, iter 800, loss: 2.623666, top_1: 0.586367, top_k: 0.812383, samples/s: 678.234 1613619913.180889
train: epoch 44, iter 900, loss: 2.768555, top_1: 0.588828, top_k: 0.812773, samples/s: 676.857 1613619951.0027664
train: epoch 44, iter 1000, loss: 2.940924, top_1: 0.580977, top_k: 0.801445, samples/s: 678.132 1613619988.7534385
train: epoch 44, iter 1100, loss: 2.776123, top_1: 0.583633, top_k: 0.808984, samples/s: 678.676 1613620026.4739707
train: epoch 44, iter 1200, loss: 2.619769, top_1: 0.581172, top_k: 0.804805, samples/s: 678.809 1613620064.1870892
train: epoch 44, iter 1300, loss: 2.715455, top_1: 0.586445, top_k: 0.808281, samples/s: 676.487 1613620102.029674
train: epoch 44, iter 1400, loss: 2.643793, top_1: 0.581680, top_k: 0.805898, samples/s: 680.270 1613620139.6618247
train: epoch 44, iter 1500, loss: 2.647567, top_1: 0.583164, top_k: 0.808242, samples/s: 678.112 1613620177.413594
train: epoch 44, iter 1600, loss: 2.609138, top_1: 0.586875, top_k: 0.809766, samples/s: 677.794 1613620215.1833005
train: epoch 44, iter 1700, loss: 2.860240, top_1: 0.582187, top_k: 0.802852, samples/s: 678.789 1613620252.8975115
train: epoch 44, iter 1800, loss: 2.690577, top_1: 0.582305, top_k: 0.807891, samples/s: 680.427 1613620290.5209608
train: epoch 44, iter 1900, loss: 2.753633, top_1: 0.580859, top_k: 0.804531, samples/s: 678.875 1613620328.230417
train: epoch 44, iter 2000, loss: 2.823544, top_1: 0.577422, top_k: 0.803164, samples/s: 679.469 1613620365.9069026
train: epoch 44, iter 2100, loss: 2.653382, top_1: 0.585273, top_k: 0.801797, samples/s: 679.196 1613620403.5984602
train: epoch 44, iter 2200, loss: 2.447267, top_1: 0.578750, top_k: 0.802383, samples/s: 676.234 1613620441.4552228
train: epoch 44, iter 2300, loss: 2.737600, top_1: 0.580273, top_k: 0.801367, samples/s: 679.274 1613620479.1424336
train: epoch 44, iter 2400, loss: 2.719708, top_1: 0.576562, top_k: 0.803516, samples/s: 680.010 1613620516.789019
train: epoch 44, iter 2500, loss: 2.918494, top_1: 0.578633, top_k: 0.803125, samples/s: 679.847 1613620554.4445283
train: epoch 44, iter 2600, loss: 2.651793, top_1: 0.578242, top_k: 0.801133, samples/s: 677.703 1613620592.2192006
train: epoch 44, iter 2700, loss: 2.631855, top_1: 0.584375, top_k: 0.804688, samples/s: 678.594 1613620629.944265
train: epoch 44, iter 2800, loss: 2.697598, top_1: 0.585391, top_k: 0.808789, samples/s: 678.779 1613620667.6589274
train: epoch 44, iter 2900, loss: 2.802458, top_1: 0.581719, top_k: 0.805977, samples/s: 679.858 1613620705.3139408
train: epoch 44, iter 3000, loss: 2.589127, top_1: 0.584102, top_k: 0.805391, samples/s: 680.828 1613620742.9152348
train: epoch 44, iter 3100, loss: 2.738008, top_1: 0.578242, top_k: 0.803008, samples/s: 676.475 1613620780.7584114
train: epoch 44, iter 3200, loss: 2.557250, top_1: 0.582305, top_k: 0.806445, samples/s: 683.627 1613620818.2058423
train: epoch 44, iter 3300, loss: 2.682535, top_1: 0.585547, top_k: 0.804805, samples/s: 680.445 1613620855.8282495
train: epoch 44, iter 3400, loss: 2.644461, top_1: 0.576172, top_k: 0.799687, samples/s: 676.404 1613620893.6754756
train: epoch 44, iter 3500, loss: 2.688917, top_1: 0.580586, top_k: 0.802344, samples/s: 677.510 1613620931.4608338
train: epoch 44, iter 3600, loss: 2.645688, top_1: 0.576211, top_k: 0.800195, samples/s: 680.238 1613620969.094755
train: epoch 44, iter 3700, loss: 2.766047, top_1: 0.580078, top_k: 0.802578, samples/s: 678.177 1613621006.8429809
train: epoch 44, iter 3800, loss: 2.776648, top_1: 0.576758, top_k: 0.802813, samples/s: 678.383 1613621044.5798256
train: epoch 44, iter 3900, loss: 2.683769, top_1: 0.580352, top_k: 0.797617, samples/s: 679.037 1613621082.280232
train: epoch 44, iter 4000, loss: 2.773880, top_1: 0.583086, top_k: 0.808008, samples/s: 681.551 1613621119.8416672
train: epoch 44, iter 4100, loss: 2.632957, top_1: 0.581484, top_k: 0.805117, samples/s: 677.688 1613621157.617155
train: epoch 44, iter 4200, loss: 2.669896, top_1: 0.576992, top_k: 0.802695, samples/s: 680.992 1613621195.2094913
train: epoch 44, iter 4300, loss: 2.809700, top_1: 0.578086, top_k: 0.803438, samples/s: 678.319 1613621232.9497528
train: epoch 44, iter 4400, loss: 2.605606, top_1: 0.583281, top_k: 0.805117, samples/s: 679.837 1613621270.605759
train: epoch 44, iter 4500, loss: 2.830798, top_1: 0.579766, top_k: 0.802109, samples/s: 678.920 1613621308.3127697
train: epoch 44, iter 4600, loss: 2.583463, top_1: 0.578008, top_k: 0.801641, samples/s: 678.377 1613621346.049877
train: epoch 44, iter 4700, loss: 2.760240, top_1: 0.580664, top_k: 0.800977, samples/s: 680.249 1613621383.683217
train: epoch 44, iter 4800, loss: 2.568978, top_1: 0.580039, top_k: 0.806602, samples/s: 680.652 1613621421.2941546
train: epoch 44, iter 4900, loss: 2.917093, top_1: 0.583281, top_k: 0.803359, samples/s: 679.731 1613621458.9560668
train: epoch 44, iter 5000, loss: 2.725854, top_1: 0.579609, top_k: 0.803867, samples/s: 678.944 1613621496.6617582
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_44.
validation: epoch 44, iter 195, top_1: 0.632252, top_k: 0.858213, samples/s: 2157.315 1613621520.9273722
train: epoch 45, iter 100, loss: 2.645448, top_1: 0.589141, top_k: 0.811719, samples/s: 701.371 1613621579.0105941
train: epoch 45, iter 200, loss: 2.599853, top_1: 0.594453, top_k: 0.813008, samples/s: 696.547 1613621615.7632537
train: epoch 45, iter 300, loss: 2.793367, top_1: 0.594180, top_k: 0.814336, samples/s: 678.485 1613621653.4946604
train: epoch 45, iter 400, loss: 2.747730, top_1: 0.589453, top_k: 0.808516, samples/s: 679.301 1613621691.1801565
train: epoch 45, iter 500, loss: 2.729411, top_1: 0.586758, top_k: 0.809180, samples/s: 679.097 1613621728.877355
train: epoch 45, iter 600, loss: 2.530152, top_1: 0.593594, top_k: 0.807734, samples/s: 677.193 1613621766.6803722
train: epoch 45, iter 700, loss: 2.788510, top_1: 0.593906, top_k: 0.814844, samples/s: 679.290 1613621804.3668556
train: epoch 45, iter 800, loss: 2.729762, top_1: 0.594414, top_k: 0.814883, samples/s: 678.620 1613621842.0904095
train: epoch 45, iter 900, loss: 2.662375, top_1: 0.583125, top_k: 0.805664, samples/s: 677.967 1613621879.8504295
train: epoch 45, iter 1000, loss: 2.812341, top_1: 0.586406, top_k: 0.807813, samples/s: 677.899 1613621917.614164
train: epoch 45, iter 1100, loss: 2.758980, top_1: 0.586797, top_k: 0.808672, samples/s: 678.630 1613621955.3372257
train: epoch 45, iter 1200, loss: 2.926115, top_1: 0.582148, top_k: 0.806562, samples/s: 679.033 1613621993.0377746
train: epoch 45, iter 1300, loss: 2.923855, top_1: 0.580156, top_k: 0.804883, samples/s: 679.738 1613622030.6993847
train: epoch 45, iter 1400, loss: 2.660278, top_1: 0.592500, top_k: 0.812109, samples/s: 679.580 1613622068.369733
train: epoch 45, iter 1500, loss: 2.692679, top_1: 0.590000, top_k: 0.812891, samples/s: 677.631 1613622106.1483896
train: epoch 45, iter 1600, loss: 2.755047, top_1: 0.588672, top_k: 0.810156, samples/s: 680.204 1613622143.7841022
train: epoch 45, iter 1700, loss: 2.700433, top_1: 0.585508, top_k: 0.805078, samples/s: 677.406 1613622181.5752938
train: epoch 45, iter 1800, loss: 2.608425, top_1: 0.581875, top_k: 0.804609, samples/s: 678.484 1613622219.306557
train: epoch 45, iter 1900, loss: 2.526061, top_1: 0.583398, top_k: 0.801523, samples/s: 680.241 1613622256.9402034
train: epoch 45, iter 2000, loss: 2.961935, top_1: 0.582461, top_k: 0.807539, samples/s: 678.310 1613622294.6811018
train: epoch 45, iter 2100, loss: 2.926505, top_1: 0.583125, top_k: 0.804375, samples/s: 679.452 1613622332.3584743
train: epoch 45, iter 2200, loss: 2.776624, top_1: 0.581641, top_k: 0.807734, samples/s: 679.577 1613622370.0290532
train: epoch 45, iter 2300, loss: 2.876770, top_1: 0.583320, top_k: 0.806133, samples/s: 682.135 1613622407.558181
train: epoch 45, iter 2400, loss: 2.670561, top_1: 0.578984, top_k: 0.806211, samples/s: 676.067 1613622445.4243202
train: epoch 45, iter 2500, loss: 2.675430, top_1: 0.580117, top_k: 0.805859, samples/s: 680.351 1613622483.0518787
train: epoch 45, iter 2600, loss: 2.713082, top_1: 0.577695, top_k: 0.801133, samples/s: 678.500 1613622520.7822633
train: epoch 45, iter 2700, loss: 2.738753, top_1: 0.581328, top_k: 0.804375, samples/s: 679.387 1613622558.4633236
train: epoch 45, iter 2800, loss: 2.684371, top_1: 0.581953, top_k: 0.806172, samples/s: 680.562 1613622596.0792089
train: epoch 45, iter 2900, loss: 2.639535, top_1: 0.587773, top_k: 0.806719, samples/s: 677.913 1613622633.8422728
train: epoch 45, iter 3000, loss: 2.789517, top_1: 0.579336, top_k: 0.800898, samples/s: 680.666 1613622671.45245
train: epoch 45, iter 3100, loss: 2.815401, top_1: 0.582266, top_k: 0.807227, samples/s: 678.941 1613622709.1582315
train: epoch 45, iter 3200, loss: 2.623908, top_1: 0.586680, top_k: 0.810703, samples/s: 682.964 1613622746.6418662
train: epoch 45, iter 3300, loss: 2.748307, top_1: 0.581758, top_k: 0.808086, samples/s: 679.509 1613622784.3161826
train: epoch 45, iter 3400, loss: 2.734682, top_1: 0.581367, top_k: 0.804805, samples/s: 680.733 1613622821.9226277
train: epoch 45, iter 3500, loss: 2.831867, top_1: 0.580117, top_k: 0.803047, samples/s: 679.022 1613622859.6238768
train: epoch 45, iter 3600, loss: 2.715734, top_1: 0.577539, top_k: 0.805039, samples/s: 680.117 1613622897.2645102
train: epoch 45, iter 3700, loss: 2.635046, top_1: 0.581094, top_k: 0.804141, samples/s: 679.966 1613622934.9134498
train: epoch 45, iter 3800, loss: 2.718173, top_1: 0.583477, top_k: 0.805547, samples/s: 678.304 1613622972.6546133
train: epoch 45, iter 3900, loss: 2.711188, top_1: 0.584336, top_k: 0.806016, samples/s: 679.529 1613623010.3278394
train: epoch 45, iter 4000, loss: 2.672482, top_1: 0.586211, top_k: 0.807187, samples/s: 681.940 1613623047.867885
train: epoch 45, iter 4100, loss: 2.711775, top_1: 0.579805, top_k: 0.800859, samples/s: 678.488 1613623085.5987723
train: epoch 45, iter 4200, loss: 2.747511, top_1: 0.579961, top_k: 0.801914, samples/s: 679.727 1613623123.2610025
train: epoch 45, iter 4300, loss: 2.719734, top_1: 0.575742, top_k: 0.802227, samples/s: 679.655 1613623160.9271896
train: epoch 45, iter 4400, loss: 2.804913, top_1: 0.584453, top_k: 0.805117, samples/s: 678.641 1613623198.649602
train: epoch 45, iter 4500, loss: 2.927483, top_1: 0.585508, top_k: 0.808633, samples/s: 678.743 1613623236.3663807
train: epoch 45, iter 4600, loss: 2.869355, top_1: 0.579141, top_k: 0.803516, samples/s: 681.919 1613623273.9074795
train: epoch 45, iter 4700, loss: 2.698498, top_1: 0.578555, top_k: 0.803516, samples/s: 679.666 1613623311.5730057
train: epoch 45, iter 4800, loss: 2.668723, top_1: 0.583945, top_k: 0.805508, samples/s: 680.118 1613623349.213402
train: epoch 45, iter 4900, loss: 2.625185, top_1: 0.582344, top_k: 0.804570, samples/s: 678.732 1613623386.9308078
train: epoch 45, iter 5000, loss: 2.566862, top_1: 0.585938, top_k: 0.809375, samples/s: 679.068 1613623424.629649
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_45.
validation: epoch 45, iter 195, top_1: 0.631550, top_k: 0.855469, samples/s: 2149.260 1613623448.9853907
train: epoch 46, iter 100, loss: 2.753463, top_1: 0.601836, top_k: 0.817305, samples/s: 703.244 1613623506.5154686
train: epoch 46, iter 200, loss: 2.589956, top_1: 0.590234, top_k: 0.813945, samples/s: 692.362 1613623543.49038
train: epoch 46, iter 300, loss: 2.638738, top_1: 0.594141, top_k: 0.815430, samples/s: 679.777 1613623581.1497877
train: epoch 46, iter 400, loss: 2.853914, top_1: 0.592891, top_k: 0.809727, samples/s: 676.178 1613623619.0096695
train: epoch 46, iter 500, loss: 2.472188, top_1: 0.595000, top_k: 0.812383, samples/s: 679.608 1613623656.678344
train: epoch 46, iter 600, loss: 2.680171, top_1: 0.592109, top_k: 0.812109, samples/s: 679.209 1613623694.3693633
train: epoch 46, iter 700, loss: 2.745244, top_1: 0.590234, top_k: 0.811016, samples/s: 676.900 1613623732.1888313
train: epoch 46, iter 800, loss: 2.759278, top_1: 0.586523, top_k: 0.808672, samples/s: 679.622 1613623769.8568354
train: epoch 46, iter 900, loss: 2.500311, top_1: 0.593828, top_k: 0.814453, samples/s: 676.418 1613623807.70328
train: epoch 46, iter 1000, loss: 2.702847, top_1: 0.590039, top_k: 0.812344, samples/s: 679.183 1613623845.3955536
train: epoch 46, iter 1100, loss: 2.676833, top_1: 0.584844, top_k: 0.810859, samples/s: 678.798 1613623883.1092262
train: epoch 46, iter 1200, loss: 2.537341, top_1: 0.591562, top_k: 0.809648, samples/s: 677.801 1613623920.8785653
train: epoch 46, iter 1300, loss: 2.686168, top_1: 0.591328, top_k: 0.809961, samples/s: 677.558 1613623958.6612926
train: epoch 46, iter 1400, loss: 2.638763, top_1: 0.594883, top_k: 0.813516, samples/s: 678.961 1613623996.3659751
train: epoch 46, iter 1500, loss: 2.914685, top_1: 0.582227, top_k: 0.807773, samples/s: 676.783 1613624034.1919537
train: epoch 46, iter 1600, loss: 2.785128, top_1: 0.590508, top_k: 0.809375, samples/s: 678.250 1613624071.9361632
train: epoch 46, iter 1700, loss: 2.827016, top_1: 0.586602, top_k: 0.809883, samples/s: 679.071 1613624109.634739
train: epoch 46, iter 1800, loss: 2.541068, top_1: 0.583086, top_k: 0.808906, samples/s: 676.595 1613624147.4712276
train: epoch 46, iter 1900, loss: 2.677715, top_1: 0.592344, top_k: 0.814961, samples/s: 678.298 1613624185.2127533
train: epoch 46, iter 2000, loss: 2.492801, top_1: 0.583516, top_k: 0.809961, samples/s: 680.579 1613624222.8278146
train: epoch 46, iter 2100, loss: 2.604256, top_1: 0.580352, top_k: 0.805586, samples/s: 677.980 1613624260.5869455
train: epoch 46, iter 2200, loss: 2.664066, top_1: 0.590781, top_k: 0.811406, samples/s: 678.005 1613624298.344747
train: epoch 46, iter 2300, loss: 2.781376, top_1: 0.579805, top_k: 0.804258, samples/s: 678.334 1613624336.0842767
train: epoch 46, iter 2400, loss: 2.764955, top_1: 0.581484, top_k: 0.807383, samples/s: 677.550 1613624373.8674142
train: epoch 46, iter 2500, loss: 2.748468, top_1: 0.584336, top_k: 0.808125, samples/s: 680.716 1613624411.4749002
train: epoch 46, iter 2600, loss: 2.794510, top_1: 0.581523, top_k: 0.806172, samples/s: 680.179 1613624449.11201
train: epoch 46, iter 2700, loss: 2.541203, top_1: 0.585547, top_k: 0.808906, samples/s: 676.140 1613624486.9740226
train: epoch 46, iter 2800, loss: 2.639337, top_1: 0.583359, top_k: 0.801172, samples/s: 681.985 1613624524.5114436
train: epoch 46, iter 2900, loss: 2.692530, top_1: 0.579258, top_k: 0.805117, samples/s: 677.410 1613624562.3024392
train: epoch 46, iter 3000, loss: 2.899440, top_1: 0.582930, top_k: 0.803594, samples/s: 678.795 1613624600.0163743
train: epoch 46, iter 3100, loss: 2.712429, top_1: 0.584375, top_k: 0.800977, samples/s: 680.450 1613624637.6386206
train: epoch 46, iter 3200, loss: 2.877219, top_1: 0.581406, top_k: 0.804180, samples/s: 679.666 1613624675.304132
train: epoch 46, iter 3300, loss: 2.786691, top_1: 0.582539, top_k: 0.804922, samples/s: 680.150 1613624712.942918
train: epoch 46, iter 3400, loss: 2.691539, top_1: 0.582422, top_k: 0.803477, samples/s: 677.270 1613624750.7416618
train: epoch 46, iter 3500, loss: 2.627942, top_1: 0.584648, top_k: 0.803242, samples/s: 678.363 1613624788.4796891
train: epoch 46, iter 3600, loss: 2.557174, top_1: 0.587578, top_k: 0.808516, samples/s: 678.720 1613624826.1977506
train: epoch 46, iter 3700, loss: 2.707147, top_1: 0.580078, top_k: 0.802891, samples/s: 677.962 1613624863.9579482
train: epoch 46, iter 3800, loss: 2.829758, top_1: 0.586523, top_k: 0.805820, samples/s: 680.382 1613624901.583857
train: epoch 46, iter 3900, loss: 2.817245, top_1: 0.581836, top_k: 0.806328, samples/s: 677.884 1613624939.3483448
train: epoch 46, iter 4000, loss: 2.820420, top_1: 0.577031, top_k: 0.803906, samples/s: 677.806 1613624977.117295
train: epoch 46, iter 4100, loss: 2.810465, top_1: 0.583477, top_k: 0.803555, samples/s: 679.932 1613625014.768158
train: epoch 46, iter 4200, loss: 2.904805, top_1: 0.579414, top_k: 0.804258, samples/s: 679.760 1613625052.428573
train: epoch 46, iter 4300, loss: 2.755444, top_1: 0.584531, top_k: 0.806914, samples/s: 678.293 1613625090.170366
train: epoch 46, iter 4400, loss: 2.670614, top_1: 0.582422, top_k: 0.801211, samples/s: 680.210 1613625127.805768
train: epoch 46, iter 4500, loss: 2.587791, top_1: 0.581602, top_k: 0.805000, samples/s: 679.907 1613625165.457939
train: epoch 46, iter 4600, loss: 2.815078, top_1: 0.579102, top_k: 0.802773, samples/s: 679.264 1613625203.1457481
train: epoch 46, iter 4700, loss: 2.809660, top_1: 0.578047, top_k: 0.802578, samples/s: 680.227 1613625240.780311
train: epoch 46, iter 4800, loss: 2.765972, top_1: 0.580234, top_k: 0.807695, samples/s: 677.700 1613625278.5551457
train: epoch 46, iter 4900, loss: 2.462415, top_1: 0.582461, top_k: 0.803789, samples/s: 677.357 1613625316.349001
train: epoch 46, iter 5000, loss: 2.716409, top_1: 0.583594, top_k: 0.806719, samples/s: 680.947 1613625353.9437523
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_46.
validation: epoch 46, iter 195, top_1: 0.638522, top_k: 0.861058, samples/s: 2154.689 1613625378.2393658
train: epoch 47, iter 100, loss: 2.787810, top_1: 0.593359, top_k: 0.815664, samples/s: 703.413 1613625442.4579873
train: epoch 47, iter 200, loss: 2.574299, top_1: 0.601133, top_k: 0.820391, samples/s: 697.185 1613625479.177068
train: epoch 47, iter 300, loss: 2.690650, top_1: 0.598125, top_k: 0.818984, samples/s: 678.573 1613625516.9032195
train: epoch 47, iter 400, loss: 2.559765, top_1: 0.590430, top_k: 0.811484, samples/s: 678.369 1613625554.640804
train: epoch 47, iter 500, loss: 2.709555, top_1: 0.589453, top_k: 0.811211, samples/s: 678.310 1613625592.3817072
train: epoch 47, iter 600, loss: 2.740435, top_1: 0.588320, top_k: 0.806484, samples/s: 677.534 1613625630.165699
train: epoch 47, iter 700, loss: 2.824389, top_1: 0.589297, top_k: 0.808516, samples/s: 679.337 1613625667.8495705
train: epoch 47, iter 800, loss: 2.695600, top_1: 0.589648, top_k: 0.809570, samples/s: 676.906 1613625705.6686518
train: epoch 47, iter 900, loss: 2.468961, top_1: 0.590898, top_k: 0.812031, samples/s: 676.634 1613625743.5029085
train: epoch 47, iter 1000, loss: 2.622588, top_1: 0.590039, top_k: 0.813906, samples/s: 678.610 1613625781.2271225
train: epoch 47, iter 1100, loss: 2.684368, top_1: 0.590508, top_k: 0.811211, samples/s: 677.645 1613625819.005053
train: epoch 47, iter 1200, loss: 2.565864, top_1: 0.587500, top_k: 0.807227, samples/s: 677.937 1613625856.766788
train: epoch 47, iter 1300, loss: 2.683504, top_1: 0.595898, top_k: 0.812109, samples/s: 676.773 1613625894.5932245
train: epoch 47, iter 1400, loss: 2.531918, top_1: 0.595039, top_k: 0.814180, samples/s: 678.737 1613625932.310364
train: epoch 47, iter 1500, loss: 2.429338, top_1: 0.589844, top_k: 0.811055, samples/s: 677.050 1613625970.1215522
train: epoch 47, iter 1600, loss: 2.721572, top_1: 0.587734, top_k: 0.808594, samples/s: 677.511 1613626007.9069104
train: epoch 47, iter 1700, loss: 2.636394, top_1: 0.585000, top_k: 0.806289, samples/s: 680.437 1613626045.5297687
train: epoch 47, iter 1800, loss: 2.743939, top_1: 0.581445, top_k: 0.805273, samples/s: 676.480 1613626083.3727493
train: epoch 47, iter 1900, loss: 2.664605, top_1: 0.584375, top_k: 0.805586, samples/s: 677.223 1613626121.1741405
train: epoch 47, iter 2000, loss: 2.650353, top_1: 0.586875, top_k: 0.806133, samples/s: 676.674 1613626159.006262
train: epoch 47, iter 2100, loss: 2.773249, top_1: 0.588164, top_k: 0.808867, samples/s: 679.908 1613626196.65836
train: epoch 47, iter 2200, loss: 2.712903, top_1: 0.580820, top_k: 0.803789, samples/s: 679.798 1613626234.316599
train: epoch 47, iter 2300, loss: 2.708112, top_1: 0.580156, top_k: 0.804297, samples/s: 677.529 1613626272.1010177
train: epoch 47, iter 2400, loss: 2.755849, top_1: 0.586016, top_k: 0.804961, samples/s: 678.720 1613626309.8190699
train: epoch 47, iter 2500, loss: 2.923096, top_1: 0.584648, top_k: 0.802422, samples/s: 680.556 1613626347.4354587
train: epoch 47, iter 2600, loss: 2.820724, top_1: 0.586758, top_k: 0.806094, samples/s: 676.406 1613626385.282501
train: epoch 47, iter 2700, loss: 2.643206, top_1: 0.581914, top_k: 0.806094, samples/s: 677.838 1613626423.0496304
train: epoch 47, iter 2800, loss: 2.755318, top_1: 0.590547, top_k: 0.812695, samples/s: 680.860 1613626460.6491072
train: epoch 47, iter 2900, loss: 2.731477, top_1: 0.584766, top_k: 0.808867, samples/s: 676.699 1613626498.4798229
train: epoch 47, iter 3000, loss: 2.671785, top_1: 0.583477, top_k: 0.804688, samples/s: 676.968 1613626536.2954118
train: epoch 47, iter 3100, loss: 2.769595, top_1: 0.585859, top_k: 0.806914, samples/s: 678.956 1613626574.0003867
train: epoch 47, iter 3200, loss: 2.593624, top_1: 0.583125, top_k: 0.808438, samples/s: 675.839 1613626611.8791988
train: epoch 47, iter 3300, loss: 2.689299, top_1: 0.585977, top_k: 0.806211, samples/s: 679.435 1613626649.5576148
train: epoch 47, iter 3400, loss: 2.875609, top_1: 0.583750, top_k: 0.805039, samples/s: 677.996 1613626687.3158944
train: epoch 47, iter 3500, loss: 2.872175, top_1: 0.576445, top_k: 0.801211, samples/s: 678.918 1613626725.0229855
train: epoch 47, iter 3600, loss: 2.571018, top_1: 0.579961, top_k: 0.808555, samples/s: 676.846 1613626762.8454983
train: epoch 47, iter 3700, loss: 2.523879, top_1: 0.580898, top_k: 0.804805, samples/s: 677.654 1613626800.62292
train: epoch 47, iter 3800, loss: 2.761557, top_1: 0.578242, top_k: 0.802188, samples/s: 676.401 1613626838.4702864
train: epoch 47, iter 3900, loss: 2.638008, top_1: 0.585000, top_k: 0.805859, samples/s: 678.721 1613626876.188202
train: epoch 47, iter 4000, loss: 2.617627, top_1: 0.583828, top_k: 0.804688, samples/s: 677.737 1613626913.96105
train: epoch 47, iter 4100, loss: 2.811517, top_1: 0.582422, top_k: 0.802461, samples/s: 678.975 1613626951.6648624
train: epoch 47, iter 4200, loss: 2.702662, top_1: 0.579609, top_k: 0.806367, samples/s: 677.396 1613626989.4567237
train: epoch 47, iter 4300, loss: 3.083524, top_1: 0.588555, top_k: 0.806523, samples/s: 677.985 1613627027.2156
train: epoch 47, iter 4400, loss: 2.682342, top_1: 0.583984, top_k: 0.808594, samples/s: 676.095 1613627065.0801494
train: epoch 47, iter 4500, loss: 2.553111, top_1: 0.586367, top_k: 0.804961, samples/s: 679.703 1613627102.7436478
train: epoch 47, iter 4600, loss: 2.660655, top_1: 0.590703, top_k: 0.810664, samples/s: 677.248 1613627140.5436559
train: epoch 47, iter 4700, loss: 2.527689, top_1: 0.587773, top_k: 0.806680, samples/s: 677.373 1613627178.3367796
train: epoch 47, iter 4800, loss: 2.637956, top_1: 0.575664, top_k: 0.802500, samples/s: 679.200 1613627216.0281427
train: epoch 47, iter 4900, loss: 2.582396, top_1: 0.585781, top_k: 0.806055, samples/s: 678.274 1613627253.7710016
train: epoch 47, iter 5000, loss: 2.623069, top_1: 0.583789, top_k: 0.809961, samples/s: 678.356 1613627291.5092094
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_47.
validation: epoch 47, iter 195, top_1: 0.635337, top_k: 0.858794, samples/s: 2143.687 1613627315.925194
train: epoch 48, iter 100, loss: 2.585867, top_1: 0.594141, top_k: 0.812852, samples/s: 703.314 1613627373.8148391
train: epoch 48, iter 200, loss: 2.657616, top_1: 0.596758, top_k: 0.816055, samples/s: 694.359 1613627410.6833544
train: epoch 48, iter 300, loss: 2.522587, top_1: 0.594336, top_k: 0.814180, samples/s: 677.559 1613627448.4661775
train: epoch 48, iter 400, loss: 2.651196, top_1: 0.600664, top_k: 0.814883, samples/s: 676.934 1613627486.2836838
train: epoch 48, iter 500, loss: 2.773298, top_1: 0.597305, top_k: 0.819688, samples/s: 676.868 1613627524.1050053
train: epoch 48, iter 600, loss: 2.691121, top_1: 0.592578, top_k: 0.811328, samples/s: 678.184 1613627561.8529449
train: epoch 48, iter 700, loss: 2.727306, top_1: 0.590898, top_k: 0.811250, samples/s: 674.512 1613627599.806096
train: epoch 48, iter 800, loss: 2.651001, top_1: 0.586328, top_k: 0.810273, samples/s: 680.045 1613627637.4507127
train: epoch 48, iter 900, loss: 2.675125, top_1: 0.595508, top_k: 0.813398, samples/s: 676.221 1613627675.3081372
train: epoch 48, iter 1000, loss: 2.645028, top_1: 0.586250, top_k: 0.806406, samples/s: 675.426 1613627713.2101874
train: epoch 48, iter 1100, loss: 2.624357, top_1: 0.586680, top_k: 0.807578, samples/s: 676.822 1613627751.0339115
train: epoch 48, iter 1200, loss: 2.529824, top_1: 0.591641, top_k: 0.809609, samples/s: 676.504 1613627788.8755708
train: epoch 48, iter 1300, loss: 2.541177, top_1: 0.586133, top_k: 0.808164, samples/s: 678.034 1613627826.631707
train: epoch 48, iter 1400, loss: 2.625745, top_1: 0.593672, top_k: 0.812070, samples/s: 677.464 1613627864.4198132
train: epoch 48, iter 1500, loss: 2.621727, top_1: 0.588086, top_k: 0.810898, samples/s: 676.577 1613627902.257296
train: epoch 48, iter 1600, loss: 2.598368, top_1: 0.592656, top_k: 0.811328, samples/s: 679.447 1613627939.9350438
train: epoch 48, iter 1700, loss: 2.520855, top_1: 0.586797, top_k: 0.808320, samples/s: 677.031 1613627977.7471583
train: epoch 48, iter 1800, loss: 2.637959, top_1: 0.592930, top_k: 0.814453, samples/s: 677.124 1613628015.5541108
train: epoch 48, iter 1900, loss: 2.608941, top_1: 0.587070, top_k: 0.807695, samples/s: 678.979 1613628053.257842
train: epoch 48, iter 2000, loss: 2.664382, top_1: 0.586836, top_k: 0.809414, samples/s: 676.192 1613628091.1168847
train: epoch 48, iter 2100, loss: 2.654376, top_1: 0.590586, top_k: 0.809961, samples/s: 679.557 1613628128.7884665
train: epoch 48, iter 2200, loss: 2.813388, top_1: 0.585859, top_k: 0.807383, samples/s: 676.746 1613628166.6165814
train: epoch 48, iter 2300, loss: 2.913463, top_1: 0.584961, top_k: 0.808867, samples/s: 676.908 1613628204.435593
train: epoch 48, iter 2400, loss: 2.643694, top_1: 0.586523, top_k: 0.808867, samples/s: 678.082 1613628242.1891088
train: epoch 48, iter 2500, loss: 2.671487, top_1: 0.589453, top_k: 0.808906, samples/s: 675.647 1613628280.0787408
train: epoch 48, iter 2600, loss: 2.678364, top_1: 0.584258, top_k: 0.807930, samples/s: 680.806 1613628317.6811464
train: epoch 48, iter 2700, loss: 2.565341, top_1: 0.586016, top_k: 0.805000, samples/s: 675.928 1613628355.5550663
train: epoch 48, iter 2800, loss: 2.721674, top_1: 0.579258, top_k: 0.807969, samples/s: 677.860 1613628393.3209403
train: epoch 48, iter 2900, loss: 2.545282, top_1: 0.585391, top_k: 0.803320, samples/s: 679.295 1613628431.0071478
train: epoch 48, iter 3000, loss: 3.002786, top_1: 0.586602, top_k: 0.807031, samples/s: 677.045 1613628468.818526
train: epoch 48, iter 3100, loss: 2.736410, top_1: 0.586367, top_k: 0.805195, samples/s: 678.126 1613628506.569509
train: epoch 48, iter 3200, loss: 2.811086, top_1: 0.585195, top_k: 0.804727, samples/s: 677.393 1613628544.3615367
train: epoch 48, iter 3300, loss: 2.767614, top_1: 0.585977, top_k: 0.805430, samples/s: 678.589 1613628582.0867763
train: epoch 48, iter 3400, loss: 2.622083, top_1: 0.586992, top_k: 0.812539, samples/s: 676.869 1613628619.9080877
train: epoch 48, iter 3500, loss: 2.640740, top_1: 0.590000, top_k: 0.807344, samples/s: 678.493 1613628657.6387799
train: epoch 48, iter 3600, loss: 2.676472, top_1: 0.586406, top_k: 0.806133, samples/s: 678.372 1613628695.3761852
train: epoch 48, iter 3700, loss: 2.820782, top_1: 0.588047, top_k: 0.810312, samples/s: 676.241 1613628733.2324862
train: epoch 48, iter 3800, loss: 2.549490, top_1: 0.589219, top_k: 0.804141, samples/s: 678.523 1613628770.9613779
train: epoch 48, iter 3900, loss: 2.787440, top_1: 0.590000, top_k: 0.810156, samples/s: 678.394 1613628808.6976473
train: epoch 48, iter 4000, loss: 2.882573, top_1: 0.583398, top_k: 0.806914, samples/s: 677.334 1613628846.4928703
train: epoch 48, iter 4100, loss: 2.693860, top_1: 0.585195, top_k: 0.810273, samples/s: 679.597 1613628884.1622772
train: epoch 48, iter 4200, loss: 2.804439, top_1: 0.580820, top_k: 0.807656, samples/s: 675.597 1613628922.054589
train: epoch 48, iter 4300, loss: 2.535589, top_1: 0.584883, top_k: 0.806641, samples/s: 679.851 1613628959.7099438
train: epoch 48, iter 4400, loss: 2.472253, top_1: 0.591172, top_k: 0.809961, samples/s: 678.469 1613628997.44199
train: epoch 48, iter 4500, loss: 2.750829, top_1: 0.586992, top_k: 0.808242, samples/s: 678.781 1613629035.156684
train: epoch 48, iter 4600, loss: 2.732345, top_1: 0.583828, top_k: 0.806055, samples/s: 676.557 1613629072.9953473
train: epoch 48, iter 4700, loss: 2.617768, top_1: 0.582852, top_k: 0.808047, samples/s: 680.796 1613629110.5983312
train: epoch 48, iter 4800, loss: 2.771302, top_1: 0.586406, top_k: 0.806797, samples/s: 678.161 1613629148.3475258
train: epoch 48, iter 4900, loss: 2.803938, top_1: 0.585156, top_k: 0.806406, samples/s: 675.982 1613629186.2183297
train: epoch 48, iter 5000, loss: 2.667898, top_1: 0.591445, top_k: 0.812617, samples/s: 680.408 1613629223.8427181
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_48.
validation: epoch 48, iter 195, top_1: 0.639483, top_k: 0.863281, samples/s: 2173.887 1613629247.9952018
train: epoch 49, iter 100, loss: 2.448680, top_1: 0.603359, top_k: 0.819805, samples/s: 702.849 1613629305.2835383
train: epoch 49, iter 200, loss: 2.539655, top_1: 0.596133, top_k: 0.812227, samples/s: 693.530 1613629342.1961412
train: epoch 49, iter 300, loss: 2.808808, top_1: 0.598516, top_k: 0.814766, samples/s: 680.463 1613629379.8177872
train: epoch 49, iter 400, loss: 2.661049, top_1: 0.599219, top_k: 0.816562, samples/s: 676.986 1613629417.6322677
train: epoch 49, iter 500, loss: 2.663019, top_1: 0.598594, top_k: 0.816250, samples/s: 676.344 1613629455.4827225
train: epoch 49, iter 600, loss: 2.774449, top_1: 0.596133, top_k: 0.814688, samples/s: 680.667 1613629493.0929108
train: epoch 49, iter 700, loss: 2.665830, top_1: 0.586445, top_k: 0.807852, samples/s: 676.914 1613629530.9116392
train: epoch 49, iter 800, loss: 2.653859, top_1: 0.594297, top_k: 0.814180, samples/s: 679.203 1613629568.6028473
train: epoch 49, iter 900, loss: 2.748968, top_1: 0.585195, top_k: 0.807109, samples/s: 677.864 1613629606.3685105
train: epoch 49, iter 1000, loss: 2.743306, top_1: 0.592617, top_k: 0.813242, samples/s: 678.647 1613629644.0905771
train: epoch 49, iter 1100, loss: 2.600603, top_1: 0.590977, top_k: 0.809102, samples/s: 679.333 1613629681.7745104
train: epoch 49, iter 1200, loss: 2.780507, top_1: 0.592187, top_k: 0.809180, samples/s: 679.931 1613629719.4254606
train: epoch 49, iter 1300, loss: 2.748176, top_1: 0.599258, top_k: 0.814844, samples/s: 676.535 1613629757.265332
train: epoch 49, iter 1400, loss: 2.634390, top_1: 0.591523, top_k: 0.813164, samples/s: 682.630 1613629794.7673476
train: epoch 49, iter 1500, loss: 2.647985, top_1: 0.591875, top_k: 0.809180, samples/s: 674.717 1613629832.7091424
train: epoch 49, iter 1600, loss: 2.747597, top_1: 0.593242, top_k: 0.815352, samples/s: 680.697 1613629870.3175886
train: epoch 49, iter 1700, loss: 2.566179, top_1: 0.587773, top_k: 0.811133, samples/s: 677.326 1613629908.11334
train: epoch 49, iter 1800, loss: 2.686873, top_1: 0.586836, top_k: 0.808867, samples/s: 678.698 1613629945.8326576
train: epoch 49, iter 1900, loss: 2.721744, top_1: 0.586406, top_k: 0.810664, samples/s: 678.251 1613629983.5767493
train: epoch 49, iter 2000, loss: 2.493796, top_1: 0.589727, top_k: 0.808164, samples/s: 679.016 1613630021.2784016
train: epoch 49, iter 2100, loss: 2.866748, top_1: 0.583633, top_k: 0.809883, samples/s: 681.114 1613630058.8639638
train: epoch 49, iter 2200, loss: 2.802716, top_1: 0.587852, top_k: 0.809922, samples/s: 678.550 1613630096.5914793
train: epoch 49, iter 2300, loss: 2.763802, top_1: 0.588164, top_k: 0.811641, samples/s: 679.167 1613630134.2847068
train: epoch 49, iter 2400, loss: 2.675335, top_1: 0.591484, top_k: 0.811680, samples/s: 678.662 1613630172.0059593
train: epoch 49, iter 2500, loss: 2.500948, top_1: 0.586289, top_k: 0.806953, samples/s: 678.995 1613630209.708672
train: epoch 49, iter 2600, loss: 2.784361, top_1: 0.584961, top_k: 0.807227, samples/s: 677.527 1613630247.4932141
train: epoch 49, iter 2700, loss: 2.675938, top_1: 0.588828, top_k: 0.810234, samples/s: 679.784 1613630285.1522608
train: epoch 49, iter 2800, loss: 2.758562, top_1: 0.588906, top_k: 0.813281, samples/s: 677.819 1613630322.9203978
train: epoch 49, iter 2900, loss: 2.604878, top_1: 0.590742, top_k: 0.809688, samples/s: 680.730 1613630360.5270097
train: epoch 49, iter 3000, loss: 2.722825, top_1: 0.578867, top_k: 0.800859, samples/s: 679.077 1613630398.22535
train: epoch 49, iter 3100, loss: 2.892292, top_1: 0.584180, top_k: 0.805547, samples/s: 679.492 1613630435.9005857
train: epoch 49, iter 3200, loss: 2.724204, top_1: 0.581992, top_k: 0.802148, samples/s: 679.677 1613630473.5655057
train: epoch 49, iter 3300, loss: 2.640352, top_1: 0.584375, top_k: 0.805977, samples/s: 677.177 1613630511.369486
train: epoch 49, iter 3400, loss: 2.833086, top_1: 0.583672, top_k: 0.805664, samples/s: 681.897 1613630548.9118428
train: epoch 49, iter 3500, loss: 2.763026, top_1: 0.579414, top_k: 0.805117, samples/s: 675.614 1613630586.80333
train: epoch 49, iter 3600, loss: 2.688583, top_1: 0.585859, top_k: 0.807187, samples/s: 681.790 1613630624.3515446
train: epoch 49, iter 3700, loss: 2.846584, top_1: 0.588945, top_k: 0.808398, samples/s: 677.290 1613630662.149254
train: epoch 49, iter 3800, loss: 2.822673, top_1: 0.588594, top_k: 0.807500, samples/s: 680.633 1613630699.7612925
train: epoch 49, iter 3900, loss: 2.803917, top_1: 0.588789, top_k: 0.808789, samples/s: 679.953 1613630737.4108975
train: epoch 49, iter 4000, loss: 2.646470, top_1: 0.586562, top_k: 0.805781, samples/s: 676.140 1613630775.272906
train: epoch 49, iter 4100, loss: 2.727072, top_1: 0.584961, top_k: 0.805547, samples/s: 678.774 1613630812.9880342
train: epoch 49, iter 4200, loss: 2.756668, top_1: 0.585664, top_k: 0.809180, samples/s: 678.325 1613630850.7281175
train: epoch 49, iter 4300, loss: 2.841009, top_1: 0.587891, top_k: 0.806250, samples/s: 678.893 1613630888.4363537
train: epoch 49, iter 4400, loss: 2.854389, top_1: 0.588750, top_k: 0.810625, samples/s: 680.607 1613630926.049953
train: epoch 49, iter 4500, loss: 2.788579, top_1: 0.588945, top_k: 0.809883, samples/s: 678.553 1613630963.777299
train: epoch 49, iter 4600, loss: 2.584222, top_1: 0.592031, top_k: 0.809883, samples/s: 678.211 1613631001.523647
train: epoch 49, iter 4700, loss: 2.809678, top_1: 0.586172, top_k: 0.809180, samples/s: 676.787 1613631039.3493292
train: epoch 49, iter 4800, loss: 2.684055, top_1: 0.582891, top_k: 0.806562, samples/s: 679.286 1613631077.035938
train: epoch 49, iter 4900, loss: 2.817400, top_1: 0.584727, top_k: 0.807383, samples/s: 677.848 1613631114.80256
train: epoch 49, iter 5000, loss: 2.642460, top_1: 0.592187, top_k: 0.809414, samples/s: 677.319 1613631152.5986855
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_49.
validation: epoch 49, iter 195, top_1: 0.639002, top_k: 0.863421, samples/s: 2160.635 1613631176.8414876
train: epoch 50, iter 100, loss: 2.710396, top_1: 0.600820, top_k: 0.818008, samples/s: 703.117 1613631234.7428422
train: epoch 50, iter 200, loss: 2.425681, top_1: 0.600586, top_k: 0.818438, samples/s: 692.804 1613631271.6942146
train: epoch 50, iter 300, loss: 2.782065, top_1: 0.603281, top_k: 0.819453, samples/s: 677.097 1613631309.502572
train: epoch 50, iter 400, loss: 2.517903, top_1: 0.596250, top_k: 0.813945, samples/s: 675.439 1613631347.4039543
train: epoch 50, iter 500, loss: 2.629318, top_1: 0.597891, top_k: 0.812891, samples/s: 678.800 1613631385.1175327
train: epoch 50, iter 600, loss: 2.700514, top_1: 0.589414, top_k: 0.810547, samples/s: 676.456 1613631422.9617386
train: epoch 50, iter 700, loss: 2.648005, top_1: 0.592852, top_k: 0.817344, samples/s: 677.934 1613631460.723533
train: epoch 50, iter 800, loss: 2.681584, top_1: 0.595039, top_k: 0.814375, samples/s: 675.841 1613631498.602305
train: epoch 50, iter 900, loss: 2.729292, top_1: 0.592969, top_k: 0.809883, samples/s: 676.557 1613631536.441015
train: epoch 50, iter 1000, loss: 2.406881, top_1: 0.592578, top_k: 0.814688, samples/s: 678.437 1613631574.1747923
train: epoch 50, iter 1100, loss: 2.673790, top_1: 0.589688, top_k: 0.812500, samples/s: 676.347 1613631612.025162
train: epoch 50, iter 1200, loss: 2.916893, top_1: 0.594961, top_k: 0.814805, samples/s: 677.995 1613631649.7835383
train: epoch 50, iter 1300, loss: 2.631184, top_1: 0.585391, top_k: 0.812422, samples/s: 676.900 1613631687.6030042
train: epoch 50, iter 1400, loss: 2.687811, top_1: 0.596250, top_k: 0.815156, samples/s: 678.511 1613631725.332684
train: epoch 50, iter 1500, loss: 2.882440, top_1: 0.594102, top_k: 0.813633, samples/s: 676.862 1613631763.1542969
train: epoch 50, iter 1600, loss: 2.705355, top_1: 0.587734, top_k: 0.808906, samples/s: 677.494 1613631800.9406364
train: epoch 50, iter 1700, loss: 2.595387, top_1: 0.589844, top_k: 0.809727, samples/s: 677.624 1613631838.7196026
train: epoch 50, iter 1800, loss: 2.575402, top_1: 0.595391, top_k: 0.813789, samples/s: 677.641 1613631876.4978688
train: epoch 50, iter 1900, loss: 2.549115, top_1: 0.589805, top_k: 0.810937, samples/s: 675.555 1613631914.3925266
train: epoch 50, iter 2000, loss: 2.768217, top_1: 0.589805, top_k: 0.811641, samples/s: 678.315 1613631952.1331058
train: epoch 50, iter 2100, loss: 2.854642, top_1: 0.586484, top_k: 0.810078, samples/s: 676.637 1613631989.967884
train: epoch 50, iter 2200, loss: 2.721333, top_1: 0.588203, top_k: 0.807617, samples/s: 678.238 1613632027.7122326
train: epoch 50, iter 2300, loss: 2.466655, top_1: 0.587187, top_k: 0.805820, samples/s: 675.592 1613632065.605481
train: epoch 50, iter 2400, loss: 2.726413, top_1: 0.595078, top_k: 0.810469, samples/s: 677.538 1613632103.3887224
train: epoch 50, iter 2500, loss: 2.710131, top_1: 0.592539, top_k: 0.807031, samples/s: 678.683 1613632141.1088517
train: epoch 50, iter 2600, loss: 2.735129, top_1: 0.591211, top_k: 0.815000, samples/s: 674.667 1613632179.0534449
train: epoch 50, iter 2700, loss: 2.924892, top_1: 0.588125, top_k: 0.805977, samples/s: 680.044 1613632216.6980975
train: epoch 50, iter 2800, loss: 2.951726, top_1: 0.581992, top_k: 0.805898, samples/s: 673.686 1613632254.6979446
train: epoch 50, iter 2900, loss: 2.837523, top_1: 0.589258, top_k: 0.810312, samples/s: 676.567 1613632292.5361009
train: epoch 50, iter 3000, loss: 2.636409, top_1: 0.583633, top_k: 0.807578, samples/s: 677.705 1613632330.3106604
train: epoch 50, iter 3100, loss: 2.560375, top_1: 0.595391, top_k: 0.814492, samples/s: 676.034 1613632368.1785266
train: epoch 50, iter 3200, loss: 2.702124, top_1: 0.590313, top_k: 0.810273, samples/s: 676.593 1613632406.0150428
train: epoch 50, iter 3300, loss: 2.700553, top_1: 0.588984, top_k: 0.813672, samples/s: 676.002 1613632443.884895
train: epoch 50, iter 3400, loss: 2.673967, top_1: 0.588008, top_k: 0.807500, samples/s: 675.840 1613632481.7636163
train: epoch 50, iter 3500, loss: 2.605708, top_1: 0.590742, top_k: 0.808359, samples/s: 676.889 1613632519.5837398
train: epoch 50, iter 3600, loss: 2.777512, top_1: 0.586836, top_k: 0.808047, samples/s: 677.515 1613632557.3688285
train: epoch 50, iter 3700, loss: 2.767084, top_1: 0.589023, top_k: 0.811445, samples/s: 674.978 1613632595.2960205
train: epoch 50, iter 3800, loss: 2.505081, top_1: 0.586562, top_k: 0.805430, samples/s: 675.781 1613632633.1782472
train: epoch 50, iter 3900, loss: 2.795999, top_1: 0.589023, top_k: 0.810273, samples/s: 675.056 1613632671.1008816
train: epoch 50, iter 4000, loss: 2.628255, top_1: 0.589102, top_k: 0.809727, samples/s: 677.352 1613632708.8951871
train: epoch 50, iter 4100, loss: 2.641793, top_1: 0.589922, top_k: 0.810156, samples/s: 678.198 1613632746.6422815
train: epoch 50, iter 4200, loss: 2.818321, top_1: 0.584609, top_k: 0.806094, samples/s: 674.804 1613632784.5792308
train: epoch 50, iter 4300, loss: 2.519341, top_1: 0.582969, top_k: 0.803320, samples/s: 677.684 1613632822.3549988
train: epoch 50, iter 4400, loss: 2.668455, top_1: 0.589023, top_k: 0.812656, samples/s: 675.979 1613632860.226006
train: epoch 50, iter 4500, loss: 2.833663, top_1: 0.578984, top_k: 0.802305, samples/s: 679.389 1613632897.9069412
train: epoch 50, iter 4600, loss: 2.565727, top_1: 0.589766, top_k: 0.809766, samples/s: 677.562 1613632935.689474
train: epoch 50, iter 4700, loss: 2.911014, top_1: 0.585781, top_k: 0.804375, samples/s: 674.015 1613632973.6707203
train: epoch 50, iter 4800, loss: 2.785288, top_1: 0.590234, top_k: 0.809727, samples/s: 677.654 1613633011.4481413
train: epoch 50, iter 4900, loss: 2.577835, top_1: 0.587031, top_k: 0.810820, samples/s: 675.704 1613633049.3345532
train: epoch 50, iter 5000, loss: 2.801808, top_1: 0.589453, top_k: 0.811992, samples/s: 675.593 1613633087.2272098
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_50.
validation: epoch 50, iter 195, top_1: 0.645733, top_k: 0.866927, samples/s: 2143.790 1613633111.6699736
train: epoch 51, iter 100, loss: 2.721611, top_1: 0.595078, top_k: 0.818398, samples/s: 704.475 1613633169.2606459
train: epoch 51, iter 200, loss: 2.726907, top_1: 0.600664, top_k: 0.818320, samples/s: 693.088 1613633206.1970553
train: epoch 51, iter 300, loss: 2.718153, top_1: 0.586445, top_k: 0.810977, samples/s: 674.329 1613633244.1604574
train: epoch 51, iter 400, loss: 2.551385, top_1: 0.599766, top_k: 0.819727, samples/s: 676.050 1613633282.0275285
train: epoch 51, iter 500, loss: 2.692828, top_1: 0.599805, top_k: 0.818984, samples/s: 676.919 1613633319.8458152
train: epoch 51, iter 600, loss: 2.662953, top_1: 0.593047, top_k: 0.814023, samples/s: 675.234 1613633357.7586691
train: epoch 51, iter 700, loss: 2.687135, top_1: 0.595234, top_k: 0.816250, samples/s: 675.492 1613633395.6569197
train: epoch 51, iter 800, loss: 2.635427, top_1: 0.598398, top_k: 0.818516, samples/s: 676.163 1613633433.517608
train: epoch 51, iter 900, loss: 2.638553, top_1: 0.596367, top_k: 0.811914, samples/s: 674.447 1613633471.4748821
train: epoch 51, iter 1000, loss: 2.727930, top_1: 0.599180, top_k: 0.819688, samples/s: 678.459 1613633509.2073061
train: epoch 51, iter 1100, loss: 2.645396, top_1: 0.591680, top_k: 0.811953, samples/s: 675.377 1613633547.112094
train: epoch 51, iter 1200, loss: 2.588158, top_1: 0.595586, top_k: 0.814258, samples/s: 677.000 1613633584.9259439
train: epoch 51, iter 1300, loss: 2.726225, top_1: 0.597656, top_k: 0.816211, samples/s: 675.847 1613633622.8042598
train: epoch 51, iter 1400, loss: 2.418941, top_1: 0.590625, top_k: 0.810742, samples/s: 675.056 1613633660.7270436
train: epoch 51, iter 1500, loss: 2.726682, top_1: 0.595430, top_k: 0.813750, samples/s: 676.254 1613633698.5825827
train: epoch 51, iter 1600, loss: 2.736717, top_1: 0.584023, top_k: 0.804961, samples/s: 677.266 1613633736.381741
train: epoch 51, iter 1700, loss: 2.778428, top_1: 0.591836, top_k: 0.811094, samples/s: 675.517 1613633774.278526
train: epoch 51, iter 1800, loss: 2.730919, top_1: 0.590039, top_k: 0.810078, samples/s: 679.015 1613633811.9802747
train: epoch 51, iter 1900, loss: 2.741002, top_1: 0.588945, top_k: 0.809844, samples/s: 676.430 1613633849.8260074
train: epoch 51, iter 2000, loss: 2.817653, top_1: 0.591250, top_k: 0.813438, samples/s: 677.911 1613633887.5890985
train: epoch 51, iter 2100, loss: 2.836869, top_1: 0.590742, top_k: 0.813359, samples/s: 675.802 1613633925.4700158
train: epoch 51, iter 2200, loss: 2.544814, top_1: 0.592969, top_k: 0.813008, samples/s: 676.625 1613633963.3048599
train: epoch 51, iter 2300, loss: 2.731230, top_1: 0.601914, top_k: 0.820312, samples/s: 678.351 1613634001.0434647
train: epoch 51, iter 2400, loss: 2.676667, top_1: 0.592305, top_k: 0.814180, samples/s: 675.238 1613634038.9559653
train: epoch 51, iter 2500, loss: 2.618453, top_1: 0.586367, top_k: 0.806836, samples/s: 677.154 1613634076.7611892
train: epoch 51, iter 2600, loss: 2.720628, top_1: 0.589883, top_k: 0.810508, samples/s: 678.324 1613634114.5013676
train: epoch 51, iter 2700, loss: 2.719491, top_1: 0.587187, top_k: 0.809023, samples/s: 675.195 1613634152.4163513
train: epoch 51, iter 2800, loss: 2.857610, top_1: 0.584375, top_k: 0.806602, samples/s: 679.738 1613634190.0778153
train: epoch 51, iter 2900, loss: 2.695455, top_1: 0.590859, top_k: 0.810664, samples/s: 674.613 1613634228.0256116
train: epoch 51, iter 3000, loss: 2.651664, top_1: 0.585391, top_k: 0.808125, samples/s: 677.134 1613634265.8320475
train: epoch 51, iter 3100, loss: 2.745582, top_1: 0.592070, top_k: 0.809531, samples/s: 676.182 1613634303.6916285
train: epoch 51, iter 3200, loss: 2.810008, top_1: 0.592500, top_k: 0.812148, samples/s: 676.132 1613634341.5540636
train: epoch 51, iter 3300, loss: 2.600385, top_1: 0.589961, top_k: 0.809297, samples/s: 675.677 1613634379.4419966
train: epoch 51, iter 3400, loss: 2.730742, top_1: 0.589023, top_k: 0.809102, samples/s: 677.561 1613634417.2245567
train: epoch 51, iter 3500, loss: 2.787635, top_1: 0.589336, top_k: 0.814219, samples/s: 675.317 1613634455.1325934
train: epoch 51, iter 3600, loss: 2.770499, top_1: 0.591875, top_k: 0.808945, samples/s: 677.323 1613634492.9285414
train: epoch 51, iter 3700, loss: 2.600433, top_1: 0.592891, top_k: 0.809375, samples/s: 674.597 1613634530.877089
train: epoch 51, iter 3800, loss: 2.555995, top_1: 0.589453, top_k: 0.810508, samples/s: 675.366 1613634568.782547
train: epoch 51, iter 3900, loss: 2.580665, top_1: 0.586016, top_k: 0.809922, samples/s: 677.760 1613634606.553945
train: epoch 51, iter 4000, loss: 2.634058, top_1: 0.586602, top_k: 0.810937, samples/s: 676.495 1613634644.395974
train: epoch 51, iter 4100, loss: 2.569024, top_1: 0.588750, top_k: 0.808516, samples/s: 677.074 1613634682.2057657
train: epoch 51, iter 4200, loss: 2.701366, top_1: 0.592148, top_k: 0.809727, samples/s: 680.065 1613634719.8492565
train: epoch 51, iter 4300, loss: 2.712778, top_1: 0.588125, top_k: 0.809961, samples/s: 677.454 1613634757.637814
train: epoch 51, iter 4400, loss: 2.548274, top_1: 0.582578, top_k: 0.805742, samples/s: 677.154 1613634795.4429696
train: epoch 51, iter 4500, loss: 2.755925, top_1: 0.587930, top_k: 0.810664, samples/s: 678.842 1613634833.1542935
train: epoch 51, iter 4600, loss: 2.619813, top_1: 0.591523, top_k: 0.808633, samples/s: 677.189 1613634870.957643
train: epoch 51, iter 4700, loss: 2.682071, top_1: 0.593555, top_k: 0.813711, samples/s: 677.140 1613634908.763768
train: epoch 51, iter 4800, loss: 2.683388, top_1: 0.589961, top_k: 0.812266, samples/s: 677.987 1613634946.5225465
train: epoch 51, iter 4900, loss: 2.583409, top_1: 0.586367, top_k: 0.808359, samples/s: 680.327 1613634984.151573
train: epoch 51, iter 5000, loss: 2.710468, top_1: 0.592148, top_k: 0.810859, samples/s: 676.082 1613635022.016775
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_51.
validation: epoch 51, iter 195, top_1: 0.643510, top_k: 0.864203, samples/s: 2173.417 1613635046.1146672
train: epoch 52, iter 100, loss: 2.398007, top_1: 0.598672, top_k: 0.816836, samples/s: 702.285 1613635104.116874
train: epoch 52, iter 200, loss: 2.703643, top_1: 0.597305, top_k: 0.814219, samples/s: 693.522 1613635141.0298119
train: epoch 52, iter 300, loss: 2.537907, top_1: 0.599570, top_k: 0.817031, samples/s: 676.767 1613635178.856738
train: epoch 52, iter 400, loss: 2.423429, top_1: 0.596562, top_k: 0.817734, samples/s: 677.297 1613635216.6540253
train: epoch 52, iter 500, loss: 2.579696, top_1: 0.596641, top_k: 0.817227, samples/s: 677.469 1613635254.4417274
train: epoch 52, iter 600, loss: 2.550771, top_1: 0.601289, top_k: 0.817109, samples/s: 681.306 1613635292.0166438
train: epoch 52, iter 700, loss: 2.571530, top_1: 0.603672, top_k: 0.824570, samples/s: 674.624 1613635329.963673
train: epoch 52, iter 800, loss: 2.443724, top_1: 0.601367, top_k: 0.817383, samples/s: 678.073 1613635367.7176962
train: epoch 52, iter 900, loss: 2.770252, top_1: 0.600625, top_k: 0.818633, samples/s: 675.563 1613635405.6120887
train: epoch 52, iter 1000, loss: 2.455878, top_1: 0.593633, top_k: 0.813711, samples/s: 678.250 1613635443.3562355
train: epoch 52, iter 1100, loss: 2.821659, top_1: 0.597969, top_k: 0.818281, samples/s: 677.762 1613635481.127645
train: epoch 52, iter 1200, loss: 2.682152, top_1: 0.599961, top_k: 0.816523, samples/s: 679.386 1613635518.8087118
train: epoch 52, iter 1300, loss: 2.669702, top_1: 0.594180, top_k: 0.815273, samples/s: 676.293 1613635556.6621144
train: epoch 52, iter 1400, loss: 2.842384, top_1: 0.597461, top_k: 0.816094, samples/s: 677.253 1613635594.4618351
train: epoch 52, iter 1500, loss: 2.480669, top_1: 0.586133, top_k: 0.808750, samples/s: 678.530 1613635632.1904745
train: epoch 52, iter 1600, loss: 2.742608, top_1: 0.592578, top_k: 0.816250, samples/s: 676.914 1613635670.009146
train: epoch 52, iter 1700, loss: 2.620760, top_1: 0.593477, top_k: 0.810703, samples/s: 679.757 1613635707.669683
train: epoch 52, iter 1800, loss: 2.637649, top_1: 0.600156, top_k: 0.816211, samples/s: 678.094 1613635745.4225323
train: epoch 52, iter 1900, loss: 2.881710, top_1: 0.589844, top_k: 0.807695, samples/s: 679.134 1613635783.117593
train: epoch 52, iter 2000, loss: 2.777380, top_1: 0.588281, top_k: 0.810859, samples/s: 676.868 1613635820.9388857
train: epoch 52, iter 2100, loss: 2.717474, top_1: 0.591055, top_k: 0.812148, samples/s: 679.031 1613635858.6396434
train: epoch 52, iter 2200, loss: 2.632791, top_1: 0.593594, top_k: 0.810820, samples/s: 679.149 1613635896.3339174
train: epoch 52, iter 2300, loss: 2.770709, top_1: 0.596484, top_k: 0.817695, samples/s: 677.277 1613635934.1322713
train: epoch 52, iter 2400, loss: 2.486526, top_1: 0.590742, top_k: 0.811211, samples/s: 680.558 1613635971.748444
train: epoch 52, iter 2500, loss: 2.665941, top_1: 0.591797, top_k: 0.812266, samples/s: 680.392 1613636009.3737774
train: epoch 52, iter 2600, loss: 2.506214, top_1: 0.592773, top_k: 0.816328, samples/s: 677.502 1613636047.1596882
train: epoch 52, iter 2700, loss: 2.595604, top_1: 0.593516, top_k: 0.814219, samples/s: 679.472 1613636084.836
train: epoch 52, iter 2800, loss: 2.610511, top_1: 0.589453, top_k: 0.812383, samples/s: 678.311 1613636122.5768657
train: epoch 52, iter 2900, loss: 2.580510, top_1: 0.591406, top_k: 0.808672, samples/s: 678.118 1613636160.3284018
train: epoch 52, iter 3000, loss: 2.690728, top_1: 0.591680, top_k: 0.813594, samples/s: 677.172 1613636198.1326654
train: epoch 52, iter 3100, loss: 2.906188, top_1: 0.592539, top_k: 0.810703, samples/s: 681.030 1613636235.7228823
train: epoch 52, iter 3200, loss: 2.613837, top_1: 0.591719, top_k: 0.809023, samples/s: 677.981 1613636273.4820628
train: epoch 52, iter 3300, loss: 2.764048, top_1: 0.591953, top_k: 0.810078, samples/s: 680.926 1613636311.0779002
train: epoch 52, iter 3400, loss: 2.556869, top_1: 0.593555, top_k: 0.810937, samples/s: 679.103 1613636348.774714
train: epoch 52, iter 3500, loss: 2.635814, top_1: 0.591445, top_k: 0.814453, samples/s: 678.419 1613636386.5095143
train: epoch 52, iter 3600, loss: 2.740255, top_1: 0.593281, top_k: 0.813398, samples/s: 679.561 1613636424.1808867
train: epoch 52, iter 3700, loss: 2.738359, top_1: 0.588516, top_k: 0.813320, samples/s: 680.223 1613636461.815625
train: epoch 52, iter 3800, loss: 2.519958, top_1: 0.593008, top_k: 0.815937, samples/s: 679.111 1613636499.5119298
train: epoch 52, iter 3900, loss: 2.633579, top_1: 0.590117, top_k: 0.811523, samples/s: 679.431 1613636537.1905434
train: epoch 52, iter 4000, loss: 2.834680, top_1: 0.599297, top_k: 0.815039, samples/s: 676.691 1613636575.02168
train: epoch 52, iter 4100, loss: 2.448877, top_1: 0.591172, top_k: 0.813477, samples/s: 679.937 1613636612.6722307
train: epoch 52, iter 4200, loss: 2.932859, top_1: 0.587109, top_k: 0.811641, samples/s: 675.781 1613636650.5543373
train: epoch 52, iter 4300, loss: 2.636720, top_1: 0.591094, top_k: 0.809258, samples/s: 679.854 1613636688.2094462
train: epoch 52, iter 4400, loss: 2.715174, top_1: 0.589414, top_k: 0.810742, samples/s: 677.224 1613636726.0108173
train: epoch 52, iter 4500, loss: 2.743186, top_1: 0.590703, top_k: 0.808828, samples/s: 680.540 1613636763.6279807
train: epoch 52, iter 4600, loss: 2.923223, top_1: 0.589219, top_k: 0.807813, samples/s: 680.250 1613636801.2611325
train: epoch 52, iter 4700, loss: 2.588521, top_1: 0.589531, top_k: 0.806602, samples/s: 677.535 1613636839.045197
train: epoch 52, iter 4800, loss: 2.673901, top_1: 0.582227, top_k: 0.810312, samples/s: 677.893 1613636876.8092818
train: epoch 52, iter 4900, loss: 2.637286, top_1: 0.591133, top_k: 0.807852, samples/s: 678.372 1613636914.546612
train: epoch 52, iter 5000, loss: 2.569468, top_1: 0.596016, top_k: 0.813125, samples/s: 680.867 1613636952.1458018
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_52.
validation: epoch 52, iter 195, top_1: 0.643009, top_k: 0.864143, samples/s: 2161.404 1613636976.3642745
train: epoch 53, iter 100, loss: 2.819524, top_1: 0.601602, top_k: 0.819844, samples/s: 702.566 1613637033.4090745
train: epoch 53, iter 200, loss: 2.585972, top_1: 0.603164, top_k: 0.820586, samples/s: 694.314 1613637070.2802517
train: epoch 53, iter 300, loss: 2.510886, top_1: 0.602383, top_k: 0.822656, samples/s: 679.648 1613637107.946582
train: epoch 53, iter 400, loss: 2.732303, top_1: 0.600742, top_k: 0.818516, samples/s: 675.628 1613637145.8372154
train: epoch 53, iter 500, loss: 2.676818, top_1: 0.603984, top_k: 0.819805, samples/s: 677.292 1613637183.6348953
train: epoch 53, iter 600, loss: 2.684294, top_1: 0.596992, top_k: 0.818945, samples/s: 677.854 1613637221.4010673
train: epoch 53, iter 700, loss: 2.664844, top_1: 0.601562, top_k: 0.820937, samples/s: 676.013 1613637259.27013
train: epoch 53, iter 800, loss: 2.766525, top_1: 0.596875, top_k: 0.813359, samples/s: 680.003 1613637296.9169893
train: epoch 53, iter 900, loss: 2.551141, top_1: 0.593281, top_k: 0.814492, samples/s: 673.977 1613637334.9005685
train: epoch 53, iter 1000, loss: 2.576597, top_1: 0.602461, top_k: 0.821328, samples/s: 679.802 1613637372.5586116
train: epoch 53, iter 1100, loss: 2.822179, top_1: 0.598437, top_k: 0.816250, samples/s: 678.397 1613637410.2946079
train: epoch 53, iter 1200, loss: 2.501367, top_1: 0.603320, top_k: 0.819375, samples/s: 678.715 1613637448.0129051
train: epoch 53, iter 1300, loss: 2.405797, top_1: 0.595391, top_k: 0.816992, samples/s: 677.781 1613637485.7831864
train: epoch 53, iter 1400, loss: 2.698557, top_1: 0.590859, top_k: 0.811367, samples/s: 676.053 1613637523.650082
train: epoch 53, iter 1500, loss: 2.585338, top_1: 0.594219, top_k: 0.813750, samples/s: 682.780 1613637561.1439526
train: epoch 53, iter 1600, loss: 2.553234, top_1: 0.598359, top_k: 0.814531, samples/s: 676.849 1613637598.9661906
train: epoch 53, iter 1700, loss: 2.703835, top_1: 0.601094, top_k: 0.814883, samples/s: 679.003 1613637636.6685457
train: epoch 53, iter 1800, loss: 2.893326, top_1: 0.593320, top_k: 0.815117, samples/s: 677.597 1613637674.4490428
train: epoch 53, iter 1900, loss: 2.509790, top_1: 0.592891, top_k: 0.815781, samples/s: 681.952 1613637711.9884627
train: epoch 53, iter 2000, loss: 2.565145, top_1: 0.593984, top_k: 0.817930, samples/s: 677.309 1613637749.7850807
train: epoch 53, iter 2100, loss: 2.748670, top_1: 0.589414, top_k: 0.811992, samples/s: 679.832 1613637787.441495
train: epoch 53, iter 2200, loss: 2.678481, top_1: 0.597031, top_k: 0.815742, samples/s: 678.370 1613637825.1790187
train: epoch 53, iter 2300, loss: 2.733344, top_1: 0.593906, top_k: 0.811211, samples/s: 676.892 1613637862.9989307
train: epoch 53, iter 2400, loss: 2.820118, top_1: 0.596094, top_k: 0.818555, samples/s: 681.129 1613637900.5835953
train: epoch 53, iter 2500, loss: 2.617551, top_1: 0.596641, top_k: 0.814688, samples/s: 678.334 1613637938.323125
train: epoch 53, iter 2600, loss: 2.762547, top_1: 0.596289, top_k: 0.816523, samples/s: 680.577 1613637975.9381895
train: epoch 53, iter 2700, loss: 2.509535, top_1: 0.592891, top_k: 0.815898, samples/s: 679.212 1613638013.6289518
train: epoch 53, iter 2800, loss: 2.689266, top_1: 0.593828, top_k: 0.811836, samples/s: 677.726 1613638051.4022722
train: epoch 53, iter 2900, loss: 2.713775, top_1: 0.591289, top_k: 0.807930, samples/s: 678.839 1613638089.1137927
train: epoch 53, iter 3000, loss: 2.584206, top_1: 0.590430, top_k: 0.813359, samples/s: 677.499 1613638126.8998249
train: epoch 53, iter 3100, loss: 2.613318, top_1: 0.594180, top_k: 0.813203, samples/s: 677.013 1613638164.712981
train: epoch 53, iter 3200, loss: 2.748069, top_1: 0.592266, top_k: 0.812266, samples/s: 678.935 1613638202.4191227
train: epoch 53, iter 3300, loss: 2.562178, top_1: 0.597539, top_k: 0.814375, samples/s: 679.580 1613638240.0893614
train: epoch 53, iter 3400, loss: 2.458180, top_1: 0.592852, top_k: 0.812422, samples/s: 676.650 1613638277.922913
train: epoch 53, iter 3500, loss: 2.747551, top_1: 0.591680, top_k: 0.812461, samples/s: 677.398 1613638315.7145123
train: epoch 53, iter 3600, loss: 2.665637, top_1: 0.592422, top_k: 0.810000, samples/s: 679.025 1613638353.4156637
train: epoch 53, iter 3700, loss: 2.397604, top_1: 0.593633, top_k: 0.810703, samples/s: 677.830 1613638391.1832058
train: epoch 53, iter 3800, loss: 2.483606, top_1: 0.589570, top_k: 0.809805, samples/s: 678.509 1613638428.9130464
train: epoch 53, iter 3900, loss: 2.703969, top_1: 0.590625, top_k: 0.812422, samples/s: 678.279 1613638466.6556017
train: epoch 53, iter 4000, loss: 2.952200, top_1: 0.590273, top_k: 0.814453, samples/s: 676.655 1613638504.4887154
train: epoch 53, iter 4100, loss: 2.655832, top_1: 0.589336, top_k: 0.808672, samples/s: 677.987 1613638542.2475119
train: epoch 53, iter 4200, loss: 2.576059, top_1: 0.590430, top_k: 0.816562, samples/s: 679.435 1613638579.9259508
train: epoch 53, iter 4300, loss: 2.607059, top_1: 0.594766, top_k: 0.810898, samples/s: 677.844 1613638617.6926777
train: epoch 53, iter 4400, loss: 2.895167, top_1: 0.593789, top_k: 0.810937, samples/s: 678.241 1613638655.4374518
train: epoch 53, iter 4500, loss: 2.678733, top_1: 0.590469, top_k: 0.815156, samples/s: 679.310 1613638693.122733
train: epoch 53, iter 4600, loss: 2.758613, top_1: 0.595352, top_k: 0.811758, samples/s: 679.506 1613638730.7971175
train: epoch 53, iter 4700, loss: 2.851095, top_1: 0.585195, top_k: 0.808203, samples/s: 678.404 1613638768.532708
train: epoch 53, iter 4800, loss: 2.685823, top_1: 0.595234, top_k: 0.810586, samples/s: 677.544 1613638806.316341
train: epoch 53, iter 4900, loss: 2.714575, top_1: 0.589766, top_k: 0.812500, samples/s: 678.886 1613638844.0250716
train: epoch 53, iter 5000, loss: 2.537510, top_1: 0.590977, top_k: 0.810547, samples/s: 676.717 1613638881.854919
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_53.
validation: epoch 53, iter 195, top_1: 0.642127, top_k: 0.863642, samples/s: 2147.590 1613638906.208107
train: epoch 54, iter 100, loss: 2.674124, top_1: 0.607695, top_k: 0.822734, samples/s: 702.660 1613638963.7812507
train: epoch 54, iter 200, loss: 2.481978, top_1: 0.605078, top_k: 0.822422, samples/s: 694.001 1613639000.669068
train: epoch 54, iter 300, loss: 2.761695, top_1: 0.600313, top_k: 0.818086, samples/s: 676.172 1613639038.5289817
train: epoch 54, iter 400, loss: 2.729505, top_1: 0.600234, top_k: 0.818047, samples/s: 677.657 1613639076.3062248
train: epoch 54, iter 500, loss: 2.459475, top_1: 0.594648, top_k: 0.816133, samples/s: 676.225 1613639114.163484
train: epoch 54, iter 600, loss: 2.673211, top_1: 0.601680, top_k: 0.818242, samples/s: 679.789 1613639151.8221753
train: epoch 54, iter 700, loss: 2.826073, top_1: 0.599766, top_k: 0.816445, samples/s: 674.893 1613639189.754084
train: epoch 54, iter 800, loss: 2.710140, top_1: 0.593203, top_k: 0.812930, samples/s: 675.899 1613639227.6296992
train: epoch 54, iter 900, loss: 2.739539, top_1: 0.596406, top_k: 0.816211, samples/s: 678.011 1613639265.3870602
train: epoch 54, iter 1000, loss: 2.649947, top_1: 0.596680, top_k: 0.814648, samples/s: 677.929 1613639303.1491432
train: epoch 54, iter 1100, loss: 2.647008, top_1: 0.596602, top_k: 0.816289, samples/s: 678.677 1613639340.869515
train: epoch 54, iter 1200, loss: 2.648250, top_1: 0.603906, top_k: 0.818789, samples/s: 678.037 1613639378.6256084
train: epoch 54, iter 1300, loss: 2.507920, top_1: 0.593203, top_k: 0.814258, samples/s: 680.109 1613639416.2665203
train: epoch 54, iter 1400, loss: 2.522743, top_1: 0.601328, top_k: 0.816406, samples/s: 676.229 1613639454.123634
train: epoch 54, iter 1500, loss: 2.596177, top_1: 0.595625, top_k: 0.811680, samples/s: 678.235 1613639491.8686209
train: epoch 54, iter 1600, loss: 2.833372, top_1: 0.596211, top_k: 0.813477, samples/s: 680.099 1613639529.5102482
train: epoch 54, iter 1700, loss: 2.488432, top_1: 0.596719, top_k: 0.815078, samples/s: 676.086 1613639567.3752253
train: epoch 54, iter 1800, loss: 2.754884, top_1: 0.592109, top_k: 0.812813, samples/s: 678.550 1613639605.1028116
train: epoch 54, iter 1900, loss: 2.621323, top_1: 0.597266, top_k: 0.815195, samples/s: 677.714 1613639642.8767438
train: epoch 54, iter 2000, loss: 2.533980, top_1: 0.600781, top_k: 0.820273, samples/s: 679.933 1613639680.5275772
train: epoch 54, iter 2100, loss: 2.578774, top_1: 0.600313, top_k: 0.818242, samples/s: 678.100 1613639718.2801535
train: epoch 54, iter 2200, loss: 2.756622, top_1: 0.595469, top_k: 0.817617, samples/s: 679.211 1613639755.9708095
train: epoch 54, iter 2300, loss: 2.620137, top_1: 0.587578, top_k: 0.811797, samples/s: 676.479 1613639793.813873
train: epoch 54, iter 2400, loss: 2.763877, top_1: 0.596211, top_k: 0.817187, samples/s: 678.442 1613639831.547424
train: epoch 54, iter 2500, loss: 2.673698, top_1: 0.597070, top_k: 0.814063, samples/s: 677.453 1613639869.336009
train: epoch 54, iter 2600, loss: 2.652256, top_1: 0.590391, top_k: 0.815000, samples/s: 679.667 1613639907.0014744
train: epoch 54, iter 2700, loss: 2.662356, top_1: 0.592578, top_k: 0.814727, samples/s: 677.620 1613639944.780808
train: epoch 54, iter 2800, loss: 2.619923, top_1: 0.593164, top_k: 0.812773, samples/s: 680.329 1613639982.4096694
train: epoch 54, iter 2900, loss: 2.596941, top_1: 0.591719, top_k: 0.811523, samples/s: 677.055 1613640020.2204177
train: epoch 54, iter 3000, loss: 2.696868, top_1: 0.594766, top_k: 0.812148, samples/s: 679.789 1613640057.8792145
train: epoch 54, iter 3100, loss: 2.758507, top_1: 0.593828, top_k: 0.813750, samples/s: 676.341 1613640095.7299426
train: epoch 54, iter 3200, loss: 2.884627, top_1: 0.590977, top_k: 0.807930, samples/s: 680.334 1613640133.3584688
train: epoch 54, iter 3300, loss: 2.799432, top_1: 0.594805, top_k: 0.811992, samples/s: 677.435 1613640171.1481066
train: epoch 54, iter 3400, loss: 2.629723, top_1: 0.597500, top_k: 0.812852, samples/s: 677.970 1613640208.9079137
train: epoch 54, iter 3500, loss: 2.671182, top_1: 0.598867, top_k: 0.818711, samples/s: 676.458 1613640246.7519855
train: epoch 54, iter 3600, loss: 2.853191, top_1: 0.592812, top_k: 0.814844, samples/s: 678.246 1613640284.4964378
train: epoch 54, iter 3700, loss: 2.716001, top_1: 0.592344, top_k: 0.814961, samples/s: 679.070 1613640322.195067
train: epoch 54, iter 3800, loss: 2.670059, top_1: 0.599414, top_k: 0.820195, samples/s: 674.650 1613640360.1407397
train: epoch 54, iter 3900, loss: 2.846717, top_1: 0.590859, top_k: 0.812578, samples/s: 677.170 1613640397.9451199
train: epoch 54, iter 4000, loss: 2.708373, top_1: 0.594297, top_k: 0.812227, samples/s: 678.263 1613640435.6885366
train: epoch 54, iter 4100, loss: 2.721529, top_1: 0.592070, top_k: 0.810937, samples/s: 678.074 1613640473.4425864
train: epoch 54, iter 4200, loss: 2.624887, top_1: 0.590859, top_k: 0.806719, samples/s: 678.700 1613640511.1617048
train: epoch 54, iter 4300, loss: 2.879875, top_1: 0.591602, top_k: 0.815781, samples/s: 677.605 1613640548.9417655
train: epoch 54, iter 4400, loss: 2.583119, top_1: 0.589961, top_k: 0.809805, samples/s: 674.008 1613640586.9235823
train: epoch 54, iter 4500, loss: 2.867468, top_1: 0.592070, top_k: 0.810312, samples/s: 678.735 1613640624.6408389
train: epoch 54, iter 4600, loss: 2.818241, top_1: 0.589297, top_k: 0.813203, samples/s: 680.139 1613640662.2801874
train: epoch 54, iter 4700, loss: 2.747288, top_1: 0.588437, top_k: 0.810273, samples/s: 675.380 1613640700.1847768
train: epoch 54, iter 4800, loss: 2.687366, top_1: 0.588945, top_k: 0.811328, samples/s: 680.036 1613640737.8298056
train: epoch 54, iter 4900, loss: 2.692782, top_1: 0.590352, top_k: 0.813320, samples/s: 675.164 1613640775.7465317
train: epoch 54, iter 5000, loss: 2.416884, top_1: 0.596328, top_k: 0.813203, samples/s: 676.865 1613640813.567946
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_54.
validation: epoch 54, iter 195, top_1: 0.638702, top_k: 0.861338, samples/s: 2169.171 1613640837.7133636
train: epoch 55, iter 100, loss: 2.550194, top_1: 0.608125, top_k: 0.824961, samples/s: 701.859 1613640895.6871405
train: epoch 55, iter 200, loss: 2.686043, top_1: 0.602930, top_k: 0.819805, samples/s: 692.568 1613640932.6512785
train: epoch 55, iter 300, loss: 2.660704, top_1: 0.597656, top_k: 0.815625, samples/s: 675.652 1613640970.540337
train: epoch 55, iter 400, loss: 2.716467, top_1: 0.603008, top_k: 0.823711, samples/s: 675.796 1613641008.421605
train: epoch 55, iter 500, loss: 2.581124, top_1: 0.606250, top_k: 0.819766, samples/s: 675.820 1613641046.3015177
train: epoch 55, iter 600, loss: 2.793338, top_1: 0.607266, top_k: 0.825664, samples/s: 676.374 1613641084.1503153
train: epoch 55, iter 700, loss: 2.461503, top_1: 0.603516, top_k: 0.820508, samples/s: 677.215 1613641121.9522476
train: epoch 55, iter 800, loss: 2.615323, top_1: 0.596211, top_k: 0.815312, samples/s: 676.436 1613641159.7977567
train: epoch 55, iter 900, loss: 2.390875, top_1: 0.598711, top_k: 0.817031, samples/s: 677.731 1613641197.5707963
train: epoch 55, iter 1000, loss: 2.570570, top_1: 0.604609, top_k: 0.822656, samples/s: 676.779 1613641235.3969576
train: epoch 55, iter 1100, loss: 2.717907, top_1: 0.591328, top_k: 0.814258, samples/s: 676.588 1613641273.2338955
train: epoch 55, iter 1200, loss: 2.665139, top_1: 0.600703, top_k: 0.822422, samples/s: 675.490 1613641311.1323304
train: epoch 55, iter 1300, loss: 2.504532, top_1: 0.598672, top_k: 0.818125, samples/s: 676.050 1613641348.9993806
train: epoch 55, iter 1400, loss: 2.737287, top_1: 0.595117, top_k: 0.815977, samples/s: 677.098 1613641386.807742
train: epoch 55, iter 1500, loss: 2.405545, top_1: 0.603047, top_k: 0.820039, samples/s: 677.628 1613641424.5865955
train: epoch 55, iter 1600, loss: 2.634746, top_1: 0.596680, top_k: 0.811055, samples/s: 675.757 1613641462.4699929
train: epoch 55, iter 1700, loss: 2.623854, top_1: 0.599844, top_k: 0.817617, samples/s: 674.953 1613641500.3985887
train: epoch 55, iter 1800, loss: 2.574602, top_1: 0.590781, top_k: 0.815312, samples/s: 676.844 1613641538.2211537
train: epoch 55, iter 1900, loss: 2.914612, top_1: 0.595391, top_k: 0.818438, samples/s: 674.446 1613641576.1782718
train: epoch 55, iter 2000, loss: 2.768909, top_1: 0.597422, top_k: 0.814961, samples/s: 676.503 1613641614.0198877
train: epoch 55, iter 2100, loss: 2.596449, top_1: 0.600703, top_k: 0.815703, samples/s: 678.039 1613641651.775867
train: epoch 55, iter 2200, loss: 2.634551, top_1: 0.597578, top_k: 0.815625, samples/s: 674.338 1613641689.7390301
train: epoch 55, iter 2300, loss: 2.690316, top_1: 0.602852, top_k: 0.820195, samples/s: 677.401 1613641727.5304604
train: epoch 55, iter 2400, loss: 2.670466, top_1: 0.594414, top_k: 0.812500, samples/s: 678.708 1613641765.2492733
train: epoch 55, iter 2500, loss: 2.778937, top_1: 0.596602, top_k: 0.818867, samples/s: 675.667 1613641803.1376421
train: epoch 55, iter 2600, loss: 2.522554, top_1: 0.601445, top_k: 0.816250, samples/s: 676.730 1613641840.9666731
train: epoch 55, iter 2700, loss: 2.737231, top_1: 0.594531, top_k: 0.813867, samples/s: 675.236 1613641878.879393
train: epoch 55, iter 2800, loss: 2.743351, top_1: 0.593789, top_k: 0.814375, samples/s: 678.162 1613641916.628456
train: epoch 55, iter 2900, loss: 2.729853, top_1: 0.590313, top_k: 0.815234, samples/s: 677.577 1613641954.4101322
train: epoch 55, iter 3000, loss: 2.701662, top_1: 0.601172, top_k: 0.819922, samples/s: 676.624 1613641992.244962
train: epoch 55, iter 3100, loss: 2.647848, top_1: 0.592773, top_k: 0.811328, samples/s: 674.709 1613642030.1873677
train: epoch 55, iter 3200, loss: 2.522655, top_1: 0.590664, top_k: 0.813594, samples/s: 677.438 1613642067.9767418
train: epoch 55, iter 3300, loss: 2.706179, top_1: 0.595117, top_k: 0.810937, samples/s: 677.163 1613642105.7816164
train: epoch 55, iter 3400, loss: 2.526320, top_1: 0.593477, top_k: 0.813398, samples/s: 675.988 1613642143.6520681
train: epoch 55, iter 3500, loss: 3.020052, top_1: 0.594453, top_k: 0.817031, samples/s: 676.935 1613642181.46954
train: epoch 55, iter 3600, loss: 2.682787, top_1: 0.598594, top_k: 0.814258, samples/s: 678.474 1613642219.2014155
train: epoch 55, iter 3700, loss: 2.606026, top_1: 0.590234, top_k: 0.816133, samples/s: 678.193 1613642256.948782
train: epoch 55, iter 3800, loss: 2.709411, top_1: 0.598398, top_k: 0.818281, samples/s: 676.346 1613642294.799152
train: epoch 55, iter 3900, loss: 2.668836, top_1: 0.593164, top_k: 0.811055, samples/s: 676.825 1613642332.62285
train: epoch 55, iter 4000, loss: 2.697544, top_1: 0.594023, top_k: 0.810820, samples/s: 678.564 1613642370.3495736
train: epoch 55, iter 4100, loss: 2.710551, top_1: 0.592773, top_k: 0.812891, samples/s: 679.094 1613642408.0468893
train: epoch 55, iter 4200, loss: 2.633559, top_1: 0.596328, top_k: 0.815859, samples/s: 675.938 1613642445.9202192
train: epoch 55, iter 4300, loss: 2.570451, top_1: 0.598164, top_k: 0.814570, samples/s: 680.546 1613642483.5370636
train: epoch 55, iter 4400, loss: 2.678695, top_1: 0.591992, top_k: 0.809805, samples/s: 676.600 1613642521.3732457
train: epoch 55, iter 4500, loss: 2.657218, top_1: 0.597812, top_k: 0.815352, samples/s: 679.291 1613642559.0596268
train: epoch 55, iter 4600, loss: 2.862373, top_1: 0.595625, top_k: 0.816367, samples/s: 675.501 1613642596.9573205
train: epoch 55, iter 4700, loss: 2.791125, top_1: 0.598164, top_k: 0.816758, samples/s: 678.235 1613642634.7023816
train: epoch 55, iter 4800, loss: 2.621348, top_1: 0.589063, top_k: 0.811602, samples/s: 678.460 1613642672.4348254
train: epoch 55, iter 4900, loss: 2.870029, top_1: 0.591562, top_k: 0.812930, samples/s: 675.692 1613642710.3218534
train: epoch 55, iter 5000, loss: 2.531872, top_1: 0.598047, top_k: 0.819688, samples/s: 678.796 1613642748.0357156
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_55.
validation: epoch 55, iter 195, top_1: 0.644231, top_k: 0.865925, samples/s: 2159.202 1613642772.2920384
train: epoch 56, iter 100, loss: 2.710975, top_1: 0.609414, top_k: 0.825586, samples/s: 702.499 1613642829.614766
train: epoch 56, iter 200, loss: 2.720897, top_1: 0.605234, top_k: 0.822070, samples/s: 694.047 1613642866.4998274
train: epoch 56, iter 300, loss: 2.524882, top_1: 0.603711, top_k: 0.819102, samples/s: 676.375 1613642904.3489087
train: epoch 56, iter 400, loss: 2.467177, top_1: 0.600977, top_k: 0.821250, samples/s: 677.022 1613642942.1612124
train: epoch 56, iter 500, loss: 2.456765, top_1: 0.605703, top_k: 0.819492, samples/s: 675.779 1613642980.0434754
train: epoch 56, iter 600, loss: 2.613728, top_1: 0.607227, top_k: 0.825234, samples/s: 676.476 1613643017.8866372
train: epoch 56, iter 700, loss: 2.624956, top_1: 0.611523, top_k: 0.824219, samples/s: 673.934 1613643055.8725657
train: epoch 56, iter 800, loss: 2.759809, top_1: 0.598437, top_k: 0.815117, samples/s: 679.164 1613643093.5658526
train: epoch 56, iter 900, loss: 2.591644, top_1: 0.601602, top_k: 0.816562, samples/s: 676.206 1613643131.4242785
train: epoch 56, iter 1000, loss: 2.455511, top_1: 0.599102, top_k: 0.817539, samples/s: 676.574 1613643169.261947
train: epoch 56, iter 1100, loss: 2.683982, top_1: 0.607969, top_k: 0.824102, samples/s: 680.646 1613643206.87328
train: epoch 56, iter 1200, loss: 2.392152, top_1: 0.598633, top_k: 0.818711, samples/s: 674.333 1613643244.8366787
train: epoch 56, iter 1300, loss: 2.641335, top_1: 0.601328, top_k: 0.817187, samples/s: 676.982 1613643282.6514935
train: epoch 56, iter 1400, loss: 2.794709, top_1: 0.599414, top_k: 0.817070, samples/s: 679.215 1613643320.3421783
train: epoch 56, iter 1500, loss: 2.692803, top_1: 0.596289, top_k: 0.818203, samples/s: 676.877 1613643358.162928
train: epoch 56, iter 1600, loss: 2.721105, top_1: 0.605391, top_k: 0.822031, samples/s: 677.948 1613643395.9239645
train: epoch 56, iter 1700, loss: 2.786005, top_1: 0.600781, top_k: 0.819297, samples/s: 675.230 1613643433.8369827
train: epoch 56, iter 1800, loss: 2.749804, top_1: 0.589141, top_k: 0.812969, samples/s: 677.915 1613643471.5998003
train: epoch 56, iter 1900, loss: 2.595234, top_1: 0.592930, top_k: 0.812734, samples/s: 677.022 1613643509.412463
train: epoch 56, iter 2000, loss: 2.683498, top_1: 0.596133, top_k: 0.815703, samples/s: 679.186 1613643547.1046693
train: epoch 56, iter 2100, loss: 2.760183, top_1: 0.594531, top_k: 0.815039, samples/s: 676.158 1613643584.9655523
train: epoch 56, iter 2200, loss: 2.857430, top_1: 0.594922, top_k: 0.813438, samples/s: 676.017 1613643622.8344393
train: epoch 56, iter 2300, loss: 2.600883, top_1: 0.595039, top_k: 0.815469, samples/s: 678.599 1613643660.5592058
train: epoch 56, iter 2400, loss: 2.687682, top_1: 0.596523, top_k: 0.816875, samples/s: 675.804 1613643698.4400504
train: epoch 56, iter 2500, loss: 2.609988, top_1: 0.599258, top_k: 0.816797, samples/s: 678.295 1613643736.1817641
train: epoch 56, iter 2600, loss: 2.628373, top_1: 0.595742, top_k: 0.815859, samples/s: 677.864 1613643773.9474652
train: epoch 56, iter 2700, loss: 2.643866, top_1: 0.600313, top_k: 0.818281, samples/s: 677.087 1613643811.7565122
train: epoch 56, iter 2800, loss: 2.639815, top_1: 0.597031, top_k: 0.814023, samples/s: 675.128 1613643849.6751828
train: epoch 56, iter 2900, loss: 2.650741, top_1: 0.590977, top_k: 0.814258, samples/s: 680.151 1613643887.3139145
train: epoch 56, iter 3000, loss: 2.499609, top_1: 0.599766, top_k: 0.817734, samples/s: 674.894 1613643925.2457302
train: epoch 56, iter 3100, loss: 2.669393, top_1: 0.599141, top_k: 0.813398, samples/s: 676.162 1613643963.106507
train: epoch 56, iter 3200, loss: 2.680907, top_1: 0.594336, top_k: 0.811367, samples/s: 680.010 1613644000.7530348
train: epoch 56, iter 3300, loss: 2.727420, top_1: 0.594688, top_k: 0.815977, samples/s: 677.146 1613644038.5586727
train: epoch 56, iter 3400, loss: 2.808540, top_1: 0.593906, top_k: 0.810625, samples/s: 677.827 1613644076.3264956
train: epoch 56, iter 3500, loss: 2.733467, top_1: 0.598633, top_k: 0.816914, samples/s: 676.906 1613644114.1456423
train: epoch 56, iter 3600, loss: 2.732962, top_1: 0.598906, top_k: 0.815586, samples/s: 675.522 1613644152.0422127
train: epoch 56, iter 3700, loss: 2.740096, top_1: 0.595039, top_k: 0.817578, samples/s: 677.083 1613644189.851409
train: epoch 56, iter 3800, loss: 2.819488, top_1: 0.595273, top_k: 0.810391, samples/s: 678.451 1613644227.5845084
train: epoch 56, iter 3900, loss: 2.632786, top_1: 0.592773, top_k: 0.811445, samples/s: 678.512 1613644265.3141415
train: epoch 56, iter 4000, loss: 2.756051, top_1: 0.596914, top_k: 0.815000, samples/s: 677.865 1613644303.0797074
train: epoch 56, iter 4100, loss: 2.650424, top_1: 0.594258, top_k: 0.812891, samples/s: 673.343 1613644341.098993
train: epoch 56, iter 4200, loss: 2.679179, top_1: 0.592422, top_k: 0.812539, samples/s: 676.347 1613644378.9493952
train: epoch 56, iter 4300, loss: 2.837994, top_1: 0.597109, top_k: 0.816250, samples/s: 676.877 1613644416.7701206
train: epoch 56, iter 4400, loss: 2.517934, top_1: 0.600859, top_k: 0.819961, samples/s: 677.364 1613644454.5636055
train: epoch 56, iter 4500, loss: 2.687428, top_1: 0.591758, top_k: 0.812773, samples/s: 675.619 1613644492.4548323
train: epoch 56, iter 4600, loss: 2.348436, top_1: 0.604062, top_k: 0.820039, samples/s: 676.715 1613644530.2846835
train: epoch 56, iter 4700, loss: 2.543505, top_1: 0.603594, top_k: 0.816797, samples/s: 675.564 1613644568.1789365
train: epoch 56, iter 4800, loss: 2.517360, top_1: 0.591914, top_k: 0.811484, samples/s: 676.252 1613644606.0345566
train: epoch 56, iter 4900, loss: 2.580595, top_1: 0.595703, top_k: 0.815039, samples/s: 674.905 1613644643.9657993
train: epoch 56, iter 5000, loss: 2.737660, top_1: 0.597500, top_k: 0.814922, samples/s: 673.243 1613644681.9907994
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_56.
validation: epoch 56, iter 195, top_1: 0.648978, top_k: 0.866767, samples/s: 2148.897 1613644706.3614764
train: epoch 57, iter 100, loss: 2.631819, top_1: 0.608945, top_k: 0.824531, samples/s: 704.478 1613644763.6011312
train: epoch 57, iter 200, loss: 2.445830, top_1: 0.606289, top_k: 0.821367, samples/s: 689.141 1613644800.748745
train: epoch 57, iter 300, loss: 2.497974, top_1: 0.602930, top_k: 0.820469, samples/s: 675.572 1613644838.6424632
train: epoch 57, iter 400, loss: 2.705675, top_1: 0.606523, top_k: 0.821211, samples/s: 672.067 1613644876.7337933
train: epoch 57, iter 500, loss: 2.551772, top_1: 0.602656, top_k: 0.818086, samples/s: 676.564 1613644914.5721276
train: epoch 57, iter 600, loss: 2.400900, top_1: 0.605273, top_k: 0.822422, samples/s: 673.185 1613644952.6003532
train: epoch 57, iter 700, loss: 2.557846, top_1: 0.602734, top_k: 0.821445, samples/s: 673.087 1613644990.634019
train: epoch 57, iter 800, loss: 2.747378, top_1: 0.608555, top_k: 0.828320, samples/s: 674.459 1613645028.5904403
train: epoch 57, iter 900, loss: 2.603983, top_1: 0.604805, top_k: 0.818867, samples/s: 674.379 1613645066.5512938
train: epoch 57, iter 1000, loss: 2.662130, top_1: 0.608516, top_k: 0.824766, samples/s: 674.651 1613645104.496806
train: epoch 57, iter 1100, loss: 2.627176, top_1: 0.598242, top_k: 0.817461, samples/s: 672.085 1613645142.5872695
train: epoch 57, iter 1200, loss: 2.805178, top_1: 0.599688, top_k: 0.816406, samples/s: 672.702 1613645180.6427135
train: epoch 57, iter 1300, loss: 2.616555, top_1: 0.596211, top_k: 0.815352, samples/s: 674.948 1613645218.5715702
train: epoch 57, iter 1400, loss: 2.526087, top_1: 0.601992, top_k: 0.817227, samples/s: 674.316 1613645256.5359232
train: epoch 57, iter 1500, loss: 2.512182, top_1: 0.601172, top_k: 0.815508, samples/s: 672.830 1613645294.58419
train: epoch 57, iter 1600, loss: 2.844453, top_1: 0.607930, top_k: 0.824375, samples/s: 674.612 1613645332.5319808
train: epoch 57, iter 1700, loss: 2.719512, top_1: 0.598984, top_k: 0.818555, samples/s: 676.158 1613645370.3929253
train: epoch 57, iter 1800, loss: 2.632156, top_1: 0.598750, top_k: 0.814492, samples/s: 674.259 1613645408.3605204
train: epoch 57, iter 1900, loss: 2.647944, top_1: 0.604062, top_k: 0.818594, samples/s: 673.029 1613645446.3975363
train: epoch 57, iter 2000, loss: 2.608455, top_1: 0.600938, top_k: 0.818398, samples/s: 675.553 1613645484.2923896
train: epoch 57, iter 2100, loss: 2.748476, top_1: 0.599492, top_k: 0.816250, samples/s: 675.248 1613645522.2043147
train: epoch 57, iter 2200, loss: 2.558675, top_1: 0.601836, top_k: 0.816133, samples/s: 675.131 1613645560.1229105
train: epoch 57, iter 2300, loss: 2.649530, top_1: 0.598906, top_k: 0.817500, samples/s: 671.605 1613645598.240506
train: epoch 57, iter 2400, loss: 2.652375, top_1: 0.600391, top_k: 0.817305, samples/s: 674.330 1613645636.2041054
train: epoch 57, iter 2500, loss: 2.627983, top_1: 0.595625, top_k: 0.813438, samples/s: 674.643 1613645674.1500814
train: epoch 57, iter 2600, loss: 2.595102, top_1: 0.597734, top_k: 0.814023, samples/s: 672.972 1613645712.1902797
train: epoch 57, iter 2700, loss: 2.498376, top_1: 0.601367, top_k: 0.819180, samples/s: 673.972 1613645750.174193
train: epoch 57, iter 2800, loss: 2.595940, top_1: 0.600273, top_k: 0.818867, samples/s: 674.977 1613645788.1013122
train: epoch 57, iter 2900, loss: 2.405288, top_1: 0.596953, top_k: 0.819375, samples/s: 672.286 1613645826.1803174
train: epoch 57, iter 3000, loss: 2.737997, top_1: 0.601250, top_k: 0.815703, samples/s: 673.902 1613645864.168064
train: epoch 57, iter 3100, loss: 2.657554, top_1: 0.600430, top_k: 0.814805, samples/s: 673.822 1613645902.1603653
train: epoch 57, iter 3200, loss: 2.606537, top_1: 0.596719, top_k: 0.814961, samples/s: 675.034 1613645940.0844002
train: epoch 57, iter 3300, loss: 2.584781, top_1: 0.594141, top_k: 0.811875, samples/s: 671.208 1613645978.2244802
train: epoch 57, iter 3400, loss: 2.823733, top_1: 0.599258, top_k: 0.817930, samples/s: 673.195 1613646016.2521603
train: epoch 57, iter 3500, loss: 2.586111, top_1: 0.600781, top_k: 0.813945, samples/s: 673.760 1613646054.2478662
train: epoch 57, iter 3600, loss: 2.539769, top_1: 0.597266, top_k: 0.818594, samples/s: 674.883 1613646092.1803577
train: epoch 57, iter 3700, loss: 2.652668, top_1: 0.594727, top_k: 0.817031, samples/s: 673.289 1613646130.2026696
train: epoch 57, iter 3800, loss: 2.526742, top_1: 0.599492, top_k: 0.817305, samples/s: 672.596 1613646168.264147
train: epoch 57, iter 3900, loss: 2.630105, top_1: 0.597227, top_k: 0.813672, samples/s: 674.051 1613646206.2434516
train: epoch 57, iter 4000, loss: 2.772802, top_1: 0.592422, top_k: 0.814805, samples/s: 674.151 1613646244.2170706
train: epoch 57, iter 4100, loss: 2.526502, top_1: 0.599414, top_k: 0.816992, samples/s: 674.313 1613646282.1817045
train: epoch 57, iter 4200, loss: 2.496834, top_1: 0.597930, top_k: 0.814023, samples/s: 671.470 1613646320.3070393
train: epoch 57, iter 4300, loss: 2.705927, top_1: 0.594219, top_k: 0.813320, samples/s: 675.992 1613646358.1772504
train: epoch 57, iter 4400, loss: 2.587371, top_1: 0.600508, top_k: 0.818320, samples/s: 671.045 1613646396.3267646
train: epoch 57, iter 4500, loss: 2.639807, top_1: 0.595117, top_k: 0.816289, samples/s: 671.950 1613646434.424826
train: epoch 57, iter 4600, loss: 2.603293, top_1: 0.595938, top_k: 0.814414, samples/s: 675.141 1613646472.3427682
train: epoch 57, iter 4700, loss: 2.643821, top_1: 0.593203, top_k: 0.816680, samples/s: 671.013 1613646510.4940736
train: epoch 57, iter 4800, loss: 2.866847, top_1: 0.599844, top_k: 0.819336, samples/s: 677.531 1613646548.2783716
train: epoch 57, iter 4900, loss: 2.713423, top_1: 0.594141, top_k: 0.812852, samples/s: 671.673 1613646586.3921416
train: epoch 57, iter 5000, loss: 2.671952, top_1: 0.602891, top_k: 0.819805, samples/s: 672.085 1613646624.4825592
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_57.
validation: epoch 57, iter 195, top_1: 0.653105, top_k: 0.869631, samples/s: 2138.599 1613646648.9583406
train: epoch 58, iter 100, loss: 2.637254, top_1: 0.621211, top_k: 0.831367, samples/s: 702.739 1613646707.322942
train: epoch 58, iter 200, loss: 2.692304, top_1: 0.611523, top_k: 0.823867, samples/s: 690.981 1613646744.3717406
train: epoch 58, iter 300, loss: 2.481078, top_1: 0.607070, top_k: 0.824883, samples/s: 670.085 1613646782.5758429
train: epoch 58, iter 400, loss: 2.646789, top_1: 0.601211, top_k: 0.818555, samples/s: 672.734 1613646820.629523
train: epoch 58, iter 500, loss: 2.794632, top_1: 0.607305, top_k: 0.824336, samples/s: 671.094 1613646858.7762127
train: epoch 58, iter 600, loss: 2.667012, top_1: 0.603906, top_k: 0.822422, samples/s: 675.100 1613646896.6964912
train: epoch 58, iter 700, loss: 2.599673, top_1: 0.603906, top_k: 0.822891, samples/s: 673.836 1613646934.6878748
train: epoch 58, iter 800, loss: 2.477907, top_1: 0.608086, top_k: 0.821875, samples/s: 675.098 1613646972.6082091
train: epoch 58, iter 900, loss: 2.802700, top_1: 0.604570, top_k: 0.821211, samples/s: 671.929 1613647010.707492
train: epoch 58, iter 1000, loss: 2.763106, top_1: 0.601562, top_k: 0.823203, samples/s: 670.526 1613647048.8865407
train: epoch 58, iter 1100, loss: 2.637132, top_1: 0.606758, top_k: 0.827344, samples/s: 674.463 1613647086.8425996
train: epoch 58, iter 1200, loss: 2.660476, top_1: 0.603633, top_k: 0.818047, samples/s: 671.822 1613647124.9479349
train: epoch 58, iter 1300, loss: 2.568726, top_1: 0.596328, top_k: 0.815781, samples/s: 671.144 1613647163.0916884
train: epoch 58, iter 1400, loss: 2.771945, top_1: 0.602031, top_k: 0.821953, samples/s: 672.548 1613647201.1560214
train: epoch 58, iter 1500, loss: 2.778906, top_1: 0.603047, top_k: 0.820430, samples/s: 675.736 1613647239.0406249
train: epoch 58, iter 1600, loss: 2.754005, top_1: 0.600000, top_k: 0.817031, samples/s: 673.150 1613647277.070845
train: epoch 58, iter 1700, loss: 2.741745, top_1: 0.603906, top_k: 0.822344, samples/s: 673.332 1613647315.0907063
train: epoch 58, iter 1800, loss: 2.676820, top_1: 0.601836, top_k: 0.822070, samples/s: 674.428 1613647353.0488026
train: epoch 58, iter 1900, loss: 2.599552, top_1: 0.600391, top_k: 0.818516, samples/s: 673.639 1613647391.0513418
train: epoch 58, iter 2000, loss: 2.717076, top_1: 0.600352, top_k: 0.820156, samples/s: 674.656 1613647428.9965172
train: epoch 58, iter 2100, loss: 2.712626, top_1: 0.604453, top_k: 0.817148, samples/s: 676.074 1613647466.8622758
train: epoch 58, iter 2200, loss: 2.572860, top_1: 0.603984, top_k: 0.820078, samples/s: 674.819 1613647504.7982657
train: epoch 58, iter 2300, loss: 2.700835, top_1: 0.598555, top_k: 0.818711, samples/s: 674.675 1613647542.7424695
train: epoch 58, iter 2400, loss: 2.598973, top_1: 0.598203, top_k: 0.817227, samples/s: 674.973 1613647580.6699553
train: epoch 58, iter 2500, loss: 2.618449, top_1: 0.600234, top_k: 0.816562, samples/s: 674.095 1613647618.6468043
train: epoch 58, iter 2600, loss: 2.612466, top_1: 0.599063, top_k: 0.821133, samples/s: 676.154 1613647656.5079367
train: epoch 58, iter 2700, loss: 2.751503, top_1: 0.601680, top_k: 0.818711, samples/s: 676.018 1613647694.3767984
train: epoch 58, iter 2800, loss: 2.635278, top_1: 0.599492, top_k: 0.818125, samples/s: 675.623 1613647732.2677784
train: epoch 58, iter 2900, loss: 2.738930, top_1: 0.601562, top_k: 0.820547, samples/s: 674.268 1613647770.2348533
train: epoch 58, iter 3000, loss: 2.669242, top_1: 0.600586, top_k: 0.813164, samples/s: 674.106 1613647808.2110648
train: epoch 58, iter 3100, loss: 2.699998, top_1: 0.604883, top_k: 0.820508, samples/s: 678.625 1613647845.9343667
train: epoch 58, iter 3200, loss: 2.667953, top_1: 0.594414, top_k: 0.814141, samples/s: 673.180 1613647883.9628417
train: epoch 58, iter 3300, loss: 2.738018, top_1: 0.596758, top_k: 0.816289, samples/s: 675.613 1613647921.8543835
train: epoch 58, iter 3400, loss: 2.679689, top_1: 0.595781, top_k: 0.814961, samples/s: 675.548 1613647959.7495222
train: epoch 58, iter 3500, loss: 2.541924, top_1: 0.604297, top_k: 0.821758, samples/s: 675.476 1613647997.6487474
train: epoch 58, iter 3600, loss: 2.639172, top_1: 0.599297, top_k: 0.815664, samples/s: 673.996 1613648035.631131
train: epoch 58, iter 3700, loss: 2.603224, top_1: 0.601211, top_k: 0.817813, samples/s: 680.942 1613648073.2261627
train: epoch 58, iter 3800, loss: 2.533116, top_1: 0.594297, top_k: 0.813047, samples/s: 674.151 1613648111.1998487
train: epoch 58, iter 3900, loss: 2.482172, top_1: 0.598750, top_k: 0.818242, samples/s: 674.705 1613648149.142348
train: epoch 58, iter 4000, loss: 2.618979, top_1: 0.598750, top_k: 0.818516, samples/s: 675.207 1613648187.056638
train: epoch 58, iter 4100, loss: 2.649113, top_1: 0.609219, top_k: 0.816328, samples/s: 675.659 1613648224.9455307
train: epoch 58, iter 4200, loss: 2.638849, top_1: 0.598477, top_k: 0.820039, samples/s: 675.252 1613648262.857392
train: epoch 58, iter 4300, loss: 2.637385, top_1: 0.596992, top_k: 0.816797, samples/s: 674.030 1613648300.837858
train: epoch 58, iter 4400, loss: 2.847161, top_1: 0.597812, top_k: 0.818359, samples/s: 678.381 1613648338.5747402
train: epoch 58, iter 4500, loss: 2.555950, top_1: 0.596055, top_k: 0.813555, samples/s: 674.627 1613648376.5216768
train: epoch 58, iter 4600, loss: 2.690869, top_1: 0.601602, top_k: 0.814805, samples/s: 676.459 1613648414.3657265
train: epoch 58, iter 4700, loss: 2.606056, top_1: 0.593906, top_k: 0.817930, samples/s: 675.518 1613648452.262563
train: epoch 58, iter 4800, loss: 2.707711, top_1: 0.601328, top_k: 0.819297, samples/s: 675.341 1613648490.16943
train: epoch 58, iter 4900, loss: 2.644883, top_1: 0.592695, top_k: 0.813867, samples/s: 676.137 1613648528.031551
train: epoch 58, iter 5000, loss: 2.484883, top_1: 0.598398, top_k: 0.817773, samples/s: 676.899 1613648565.8511004
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_58.
validation: epoch 58, iter 195, top_1: 0.651262, top_k: 0.869050, samples/s: 2136.869 1613648590.3397386
train: epoch 59, iter 100, loss: 2.698198, top_1: 0.611484, top_k: 0.826172, samples/s: 702.459 1613648648.584242
train: epoch 59, iter 200, loss: 2.599554, top_1: 0.608867, top_k: 0.825742, samples/s: 691.681 1613648685.5954933
train: epoch 59, iter 300, loss: 2.535814, top_1: 0.612734, top_k: 0.828008, samples/s: 674.833 1613648723.5307722
train: epoch 59, iter 400, loss: 2.570481, top_1: 0.612266, top_k: 0.829453, samples/s: 675.947 1613648761.4035292
train: epoch 59, iter 500, loss: 2.543061, top_1: 0.612422, top_k: 0.825898, samples/s: 673.615 1613648799.407421
train: epoch 59, iter 600, loss: 2.628468, top_1: 0.610000, top_k: 0.826250, samples/s: 675.841 1613648837.2862315
train: epoch 59, iter 700, loss: 2.577404, top_1: 0.605195, top_k: 0.823008, samples/s: 676.444 1613648875.131212
train: epoch 59, iter 800, loss: 2.409018, top_1: 0.606484, top_k: 0.823516, samples/s: 675.711 1613648913.017192
train: epoch 59, iter 900, loss: 2.506829, top_1: 0.600781, top_k: 0.821055, samples/s: 674.070 1613648950.9954863
train: epoch 59, iter 1000, loss: 2.686333, top_1: 0.604297, top_k: 0.819922, samples/s: 676.739 1613648988.8239224
train: epoch 59, iter 1100, loss: 2.615427, top_1: 0.607734, top_k: 0.821289, samples/s: 675.743 1613649026.7081056
train: epoch 59, iter 1200, loss: 2.649787, top_1: 0.605898, top_k: 0.821562, samples/s: 672.913 1613649064.7518497
train: epoch 59, iter 1300, loss: 2.726024, top_1: 0.610664, top_k: 0.822539, samples/s: 676.160 1613649102.6126344
train: epoch 59, iter 1400, loss: 2.876906, top_1: 0.600586, top_k: 0.821211, samples/s: 675.783 1613649140.494585
train: epoch 59, iter 1500, loss: 2.629111, top_1: 0.608477, top_k: 0.826992, samples/s: 678.563 1613649178.2214153
train: epoch 59, iter 1600, loss: 2.530972, top_1: 0.603984, top_k: 0.820859, samples/s: 674.911 1613649216.1522563
train: epoch 59, iter 1700, loss: 2.710195, top_1: 0.605859, top_k: 0.824766, samples/s: 677.336 1613649253.9473605
train: epoch 59, iter 1800, loss: 2.655062, top_1: 0.604453, top_k: 0.821523, samples/s: 673.101 1613649291.9804006
train: epoch 59, iter 1900, loss: 2.569598, top_1: 0.605273, top_k: 0.820234, samples/s: 678.281 1613649329.7228456
train: epoch 59, iter 2000, loss: 2.580938, top_1: 0.601836, top_k: 0.818906, samples/s: 675.251 1613649367.6346476
train: epoch 59, iter 2100, loss: 2.644328, top_1: 0.600664, top_k: 0.822305, samples/s: 675.638 1613649405.5247095
train: epoch 59, iter 2200, loss: 2.606319, top_1: 0.599492, top_k: 0.820430, samples/s: 678.743 1613649443.2414477
train: epoch 59, iter 2300, loss: 2.709698, top_1: 0.599688, top_k: 0.816836, samples/s: 673.704 1613649481.2403753
train: epoch 59, iter 2400, loss: 2.625422, top_1: 0.594922, top_k: 0.818477, samples/s: 678.190 1613649518.9879563
train: epoch 59, iter 2500, loss: 2.769752, top_1: 0.596250, top_k: 0.813203, samples/s: 676.526 1613649556.8283577
train: epoch 59, iter 2600, loss: 2.972681, top_1: 0.602578, top_k: 0.818398, samples/s: 675.100 1613649594.748648
train: epoch 59, iter 2700, loss: 2.703844, top_1: 0.603867, top_k: 0.817148, samples/s: 678.843 1613649632.4597738
train: epoch 59, iter 2800, loss: 2.778621, top_1: 0.598008, top_k: 0.816953, samples/s: 676.751 1613649670.2876256
train: epoch 59, iter 2900, loss: 2.712025, top_1: 0.603477, top_k: 0.823281, samples/s: 676.188 1613649708.1469827
train: epoch 59, iter 3000, loss: 2.556099, top_1: 0.599141, top_k: 0.819766, samples/s: 676.528 1613649745.9872358
train: epoch 59, iter 3100, loss: 2.551528, top_1: 0.601328, top_k: 0.817461, samples/s: 675.330 1613649783.89466
train: epoch 59, iter 3200, loss: 2.556884, top_1: 0.597578, top_k: 0.815273, samples/s: 678.311 1613649821.6353986
train: epoch 59, iter 3300, loss: 2.589274, top_1: 0.601094, top_k: 0.817461, samples/s: 676.960 1613649859.4515617
train: epoch 59, iter 3400, loss: 2.581681, top_1: 0.597227, top_k: 0.818281, samples/s: 676.734 1613649897.2803192
train: epoch 59, iter 3500, loss: 2.633213, top_1: 0.600234, top_k: 0.816953, samples/s: 676.306 1613649935.132909
train: epoch 59, iter 3600, loss: 2.743853, top_1: 0.599180, top_k: 0.817148, samples/s: 676.703 1613649972.9634817
train: epoch 59, iter 3700, loss: 2.776711, top_1: 0.599102, top_k: 0.815937, samples/s: 676.933 1613650010.7810614
train: epoch 59, iter 3800, loss: 2.790031, top_1: 0.603516, top_k: 0.818359, samples/s: 676.084 1613650048.6462424
train: epoch 59, iter 3900, loss: 2.618930, top_1: 0.602578, top_k: 0.817187, samples/s: 677.640 1613650086.424433
train: epoch 59, iter 4000, loss: 2.548539, top_1: 0.602148, top_k: 0.822500, samples/s: 675.451 1613650124.3250077
train: epoch 59, iter 4100, loss: 2.582298, top_1: 0.601484, top_k: 0.818203, samples/s: 676.758 1613650162.1524603
train: epoch 59, iter 4200, loss: 2.471201, top_1: 0.602187, top_k: 0.818047, samples/s: 677.022 1613650199.9650652
train: epoch 59, iter 4300, loss: 2.665431, top_1: 0.598437, top_k: 0.816523, samples/s: 676.505 1613650237.8065145
train: epoch 59, iter 4400, loss: 2.753291, top_1: 0.599141, top_k: 0.817695, samples/s: 675.383 1613650275.7109833
train: epoch 59, iter 4500, loss: 2.543653, top_1: 0.599102, top_k: 0.815078, samples/s: 679.600 1613650313.3803067
train: epoch 59, iter 4600, loss: 2.512677, top_1: 0.597500, top_k: 0.818594, samples/s: 676.259 1613650351.2355323
train: epoch 59, iter 4700, loss: 2.589824, top_1: 0.600742, top_k: 0.817930, samples/s: 676.914 1613650389.0543253
train: epoch 59, iter 4800, loss: 2.600085, top_1: 0.596797, top_k: 0.813516, samples/s: 676.944 1613650426.8713095
train: epoch 59, iter 4900, loss: 2.700306, top_1: 0.597461, top_k: 0.816992, samples/s: 675.629 1613650464.7619374
train: epoch 59, iter 5000, loss: 2.627586, top_1: 0.597852, top_k: 0.818672, samples/s: 675.750 1613650502.6457312
Saving model to ./repvggB1/snapshots/model_save/snapshot_epoch_59.
validation: epoch 59, iter 195, top_1: 0.650501, top_k: 0.869371, samples/s: 2156.023 1613650526.9361894
train: epoch 60, iter 100, loss: 2.681146, top_1: 0.607539, top_k: 0.823125, samples/s: 702.629 1613650589.7441332
train: epoch 60, iter 200, loss: 2.450952, top_1: 0.614922, top_k: 0.828828, samples/s: 697.728 1613650626.4348874
train: epoch 60, iter 300, loss: 2.623055, top_1: 0.610391, top_k: 0.827656, samples/s: 679.075 1613650664.1330884
train: epoch 60, iter 400, loss: 2.675039, top_1: 0.608984, top_k: 0.823555, samples/s: 677.310 1613650701.929585
train: epoch 60, iter 500, loss: 2.571866, top_1: 0.609570, top_k: 0.825156, samples/s: 673.824 1613650739.9217482
train: epoch 60, iter 600, loss: 2.561268, top_1: 0.606250, top_k: 0.821719, samples/s: 677.620 1613650777.7010515
train: epoch 60, iter 700, loss: 2.645025, top_1: 0.606289, top_k: 0.824883, samples/s: 674.538 1613650815.652946
train: epoch 60, iter 800, loss: 2.780285, top_1: 0.610625, top_k: 0.823047, samples/s: 676.682 1613650853.484598
train: epoch 60, iter 900, loss: 2.443802, top_1: 0.605508, top_k: 0.823125, samples/s: 674.665 1613650891.4293869
train: epoch 60, iter 1000, loss: 2.522508, top_1: 0.605586, top_k: 0.823867, samples/s: 674.181 1613650929.4014013
train: epoch 60, iter 1100, loss: 2.678196, top_1: 0.603516, top_k: 0.823242, samples/s: 676.864 1613650967.2228377
train: epoch 60, iter 1200, loss: 2.696670, top_1: 0.608477, top_k: 0.826094, samples/s: 676.447 1613651005.0676181
train: epoch 60, iter 1300, loss: 2.559076, top_1: 0.601719, top_k: 0.822891, samples/s: 674.689 1613651043.0110056
train: epoch 60, iter 1400, loss: 2.595703, top_1: 0.609805, top_k: 0.826055, samples/s: 674.210 1613651080.9813895
train: epoch 60, iter 1500, loss: 2.687391, top_1: 0.606094, top_k: 0.821367, samples/s: 677.816 1613651118.7497146
train: epoch 60, iter 1600, loss: 2.713990, top_1: 0.603047, top_k: 0.824688, samples/s: 674.293 1613651156.715384
train: epoch 60, iter 1700, loss: 2.569612, top_1: 0.604492, top_k: 0.822812, samples/s: 675.597 1613651194.607804
train: epoch 60, iter 1800, loss: 2.753473, top_1: 0.602656, top_k: 0.821758, samples/s: 675.262 1613651232.5190403
train: epoch 60, iter 1900, loss: 2.590281, top_1: 0.604766, top_k: 0.821016, samples/s: 677.277 1613651270.3174589
train: epoch 60, iter 2000, loss: 2.553645, top_1: 0.603750, top_k: 0.820391, samples/s: 674.172 1613651308.2899585
train: epoch 60, iter 2100, loss: 2.573468, top_1: 0.602109, top_k: 0.819688, samples/s: 677.362 1613651346.0837278
train: epoch 60, iter 2200, loss: 2.535707, top_1: 0.605664, top_k: 0.821445, samples/s: 676.704 1613651383.9141269
train: epoch 60, iter 2300, loss: 2.700600, top_1: 0.604805, top_k: 0.824375, samples/s: 676.759 1613651421.741424
train: epoch 60, iter 2400, loss: 2.754491, top_1: 0.606875, top_k: 0.819609, samples/s: 677.609 1613651459.5213978
train: epoch 60, iter 2500, loss: 2.888165, top_1: 0.599375, top_k: 0.815820, samples/s: 674.096 1613651497.498134
train: epoch 60, iter 2600, loss: 2.744851, top_1: 0.598750, top_k: 0.816602, samples/s: 677.928 1613651535.2602506
train: epoch 60, iter 2700, loss: 2.814638, top_1: 0.602969, top_k: 0.820078, samples/s: 676.149 1613651573.1217382
train: epoch 60, iter 2800, loss: 2.573762, top_1: 0.594453, top_k: 0.816953, samples/s: 674.958 1613651611.0499942
train: epoch 60, iter 2900, loss: 2.478026, top_1: 0.597070, top_k: 0.815078, samples/s: 676.705 1613651648.8803663
train: epoch 60, iter 3000, loss: 2.535933, top_1: 0.600039, top_k: 0.815273, samples/s: 674.971 1613651686.8078856
train: epoch 60, iter 3100, loss: 2.694079, top_1: 0.605977, top_k: 0.821094, samples/s: 677.321 1613651724.6038282
train: epoch 60, iter 3200, loss: 2.555677, top_1: 0.601992, top_k: 0.818906, samples/s: 676.433 1613651762.4493537
train: epoch 60, iter 3300, loss: 2.497477, top_1: 0.603555, top_k: 0.820781, samples/s: 674.587 1613651800.3984733
train: epoch 60, iter 3400, loss: 2.597535, top_1: 0.597695, top_k: 0.816602, samples/s: 674.941 1613651838.3277984
train: epoch 60, iter 3500, loss: 2.923430, top_1: 0.603555, top_k: 0.818320, samples/s: 679.151 1613651876.0218034
train: epoch 60, iter 3600, loss: 2.547621, top_1: 0.607266, top_k: 0.825703, samples/s: 675.064 1613651913.9441392
train: epoch 60, iter 3700, loss: 2.572708, top_1: 0.593125, top_k: 0.816328, samples/s: 676.583 1613651951.7814515
train: epoch 60, iter 3800, loss: 2.450008, top_1: 0.598711, top_k: 0.818789, samples/s: 674.842 1613651989.7163024
train: epoch 60, iter 3900, loss: 2.699588, top_1: 0.602266, top_k: 0.819336, samples/s: 675.240 1613652027.6287162
